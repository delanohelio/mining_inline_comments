{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDA1NDIzMzE4", "number": 11459, "reviewThreads": {"totalCount": 42, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNDowNToxN1rOELQs8g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxNjoyNToxMVrOEhUwAQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMjQzNDQyOnYy", "diffSide": "RIGHT", "path": "sdks/java/io/influxdb/build.gradle", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNDowNToxN1rOGsxb1Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNDowNToxN1rOGsxb1Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYwMDQ2OQ==", "bodyText": "Please, extract it as entity of project.ext.library in BeamModulePlugin.groovy", "url": "https://github.com/apache/beam/pull/11459#discussion_r449600469", "createdAt": "2020-07-03T14:05:17Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/build.gradle", "diffHunk": "@@ -0,0 +1,34 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one\n+* or more contributor license agreements.  See the NOTICE file\n+* distributed with this work for additional information\n+* regarding copyright ownership.  The ASF licenses this file\n+* to you under the Apache License, Version 2.0 (the\n+* License); you may not use this file except in compliance\n+* with the License.  You may obtain a copy of the License at\n+*\n+*     http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an AS IS BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+ \n+plugins { id 'org.apache.beam.module' }\n+applyJavaNature(automaticModuleName: 'org.apache.beam.sdk.io.influxdb')\n+provideIntegrationTestingDependencies()\n+enableJavaPerformanceTesting()\n+\n+description = \"Apache Beam :: SDKs :: Java :: IO :: InfluxDB\"\n+ext.summary = \"IO to read and write on InfluxDB\"\n+\n+dependencies {\n+  compile project(path: \":sdks:java:core\", configuration: \"shadow\")\n+  compile 'org.influxdb:influxdb-java:2.17'", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 29}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMjQzODYyOnYy", "diffSide": "RIGHT", "path": "sdks/java/io/influxdb/build.gradle", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNDowNjo0M1rOGsxeVQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNDowNjo0M1rOGsxeVQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYwMTEwOQ==", "bodyText": "testRuntimeOnly project(path: \":runners:direct-java\", configuration: \"shadow\")", "url": "https://github.com/apache/beam/pull/11459#discussion_r449601109", "createdAt": "2020-07-03T14:06:43Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/build.gradle", "diffHunk": "@@ -0,0 +1,34 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one\n+* or more contributor license agreements.  See the NOTICE file\n+* distributed with this work for additional information\n+* regarding copyright ownership.  The ASF licenses this file\n+* to you under the Apache License, Version 2.0 (the\n+* License); you may not use this file except in compliance\n+* with the License.  You may obtain a copy of the License at\n+*\n+*     http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an AS IS BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+ \n+plugins { id 'org.apache.beam.module' }\n+applyJavaNature(automaticModuleName: 'org.apache.beam.sdk.io.influxdb')\n+provideIntegrationTestingDependencies()\n+enableJavaPerformanceTesting()\n+\n+description = \"Apache Beam :: SDKs :: Java :: IO :: InfluxDB\"\n+ext.summary = \"IO to read and write on InfluxDB\"\n+\n+dependencies {\n+  compile project(path: \":sdks:java:core\", configuration: \"shadow\")\n+  compile 'org.influxdb:influxdb-java:2.17'\n+  testCompile library.java.junit\n+  testRuntimeOnly project(\":runners:direct-java\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMjQ0OTA5OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/influxdb/build.gradle", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNDoxMDoyMVrOGsxk4g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNDoxMDoyMVrOGsxk4g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYwMjc4Ng==", "bodyText": "I don't think it's needed. Please, remove", "url": "https://github.com/apache/beam/pull/11459#discussion_r449602786", "createdAt": "2020-07-03T14:10:21Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/build.gradle", "diffHunk": "@@ -0,0 +1,34 @@\n+/*\n+* Licensed to the Apache Software Foundation (ASF) under one\n+* or more contributor license agreements.  See the NOTICE file\n+* distributed with this work for additional information\n+* regarding copyright ownership.  The ASF licenses this file\n+* to you under the Apache License, Version 2.0 (the\n+* License); you may not use this file except in compliance\n+* with the License.  You may obtain a copy of the License at\n+*\n+*     http://www.apache.org/licenses/LICENSE-2.0\n+*\n+* Unless required by applicable law or agreed to in writing, software\n+* distributed under the License is distributed on an AS IS BASIS,\n+* WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+* See the License for the specific language governing permissions and\n+* limitations under the License.\n+*/\n+ \n+plugins { id 'org.apache.beam.module' }\n+applyJavaNature(automaticModuleName: 'org.apache.beam.sdk.io.influxdb')\n+provideIntegrationTestingDependencies()\n+enableJavaPerformanceTesting()\n+\n+description = \"Apache Beam :: SDKs :: Java :: IO :: InfluxDB\"\n+ext.summary = \"IO to read and write on InfluxDB\"\n+\n+dependencies {\n+  compile project(path: \":sdks:java:core\", configuration: \"shadow\")\n+  compile 'org.influxdb:influxdb-java:2.17'\n+  testCompile library.java.junit\n+  testRuntimeOnly project(\":runners:direct-java\")\n+  testCompile group: 'org.apache.beam', name: 'beam-runners-direct-java', version: '2.15.0'", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMjQ1MTMyOnYy", "diffSide": "RIGHT", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/DBShardInformation.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNDoxMTowNVrOGsxmOg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNDoxMTowNVrOGsxmOg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYwMzEzMA==", "bodyText": "Add class Javadoc and remove public", "url": "https://github.com/apache/beam/pull/11459#discussion_r449603130", "createdAt": "2020-07-03T14:11:05Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/DBShardInformation.java", "diffHunk": "@@ -0,0 +1,48 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.influxdb.dto.QueryResult.Series;\n+\n+public class DBShardInformation {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMjQ1MjM2OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/LineProtocolConvertable.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNDoxMTozMVrOGsxm6w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNDoxMTozMVrOGsxm6w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYwMzMwNw==", "bodyText": "Please, add class Javadoc", "url": "https://github.com/apache/beam/pull/11459#discussion_r449603307", "createdAt": "2020-07-03T14:11:31Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/LineProtocolConvertable.java", "diffHunk": "@@ -0,0 +1,22 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+public interface LineProtocolConvertable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMjQ1MjY2OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/ShardInformation.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNDoxMTo0MFrOGsxnIw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNDoxMTo0MFrOGsxnIw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYwMzM2Mw==", "bodyText": "Please, add class Javadoc", "url": "https://github.com/apache/beam/pull/11459#discussion_r449603363", "createdAt": "2020-07-03T14:11:40Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/ShardInformation.java", "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import java.util.List;\n+import java.util.Objects;\n+import org.joda.time.DateTime;\n+\n+public class ShardInformation implements Comparable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMjQ2NjE5OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNDoxNjozN1rOGsxvfQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNDoxNjozN1rOGsxvfQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYwNTUwMQ==", "bodyText": "Please, rename the class name to InfluxDbIO to be compatible with other IOs, like MongoDbIO", "url": "https://github.com/apache/beam/pull/11459#discussion_r449605501", "createdAt": "2020-07-03T14:16:37Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 127}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMjQ3NDczOnYy", "diffSide": "RIGHT", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNDoxOTo0MlrOGsx0uw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNDoxOTo0MlrOGsx0uw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYwNjg0Mw==", "bodyText": "nit: \"You have ...\"", "url": "https://github.com/apache/beam/pull/11459#discussion_r449606843", "createdAt": "2020-07-03T14:19:42Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 72}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMjUxOTgyOnYy", "diffSide": "RIGHT", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNDozNTo1MFrOGsyPhA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNDozNTo1MFrOGsyPhA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTYxMzcwMA==", "bodyText": "Is it a blocking operation?", "url": "https://github.com/apache/beam/pull/11459#discussion_r449613700", "createdAt": "2020-07-03T14:35:50Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(noOfBlocks)) {\n+                noOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> noOfBlocksValueItr = noOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueItr = sizeOfBlocksValue.iterator();\n+      long size = 0;\n+      while (noOfBlocksValueItr.hasNext() && sizeOfBlocksValueItr.hasNext()) {\n+        size = size + (noOfBlocksValueItr.next() * sizeOfBlocksValueItr.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(),\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          if (sInfo.getStartTime().compareTo(spec.startDateTime()) > 0) {\n+            sources.add(\n+                new InfluxDBSource(\n+                    spec.withMetrics(spec.metrics())\n+                        .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                        .withToDateTime(sInfo.getStartTime())\n+                        .withFromDateTime(sInfo.getEndTime())));\n+          }\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    if (spec.query() == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        return String.format(\n+            \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+            spec.retentionPolicy(),\n+            String.join(\",\", spec.metrics()),\n+            spec.toDateTime(),\n+            spec.fromDateTime());\n+      } else {\n+        return String.format(\n+            \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+      }\n+    }\n+    return spec.query();\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDBIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List current;\n+\n+    public BoundedInfluxDbReader(InfluxDBIO.InfluxDBSource source) {\n+      this.source = source;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDBIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        if (spec.database() != null) {\n+          influxDB.setDatabase(spec.database());\n+        }\n+        if (spec.retentionPolicy() != null) {\n+          influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        }\n+        String query = getQueryToRun(spec);\n+        QueryResult queryResult = influxDB.query(new Query(query, spec.database()));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          seriesIterator = resultIterator.next().getSeries().iterator();\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkArgument(dataSourceConfiguration() != null, \"withConfiguration() is required\");\n+      checkArgument(database() != null && !database().isEmpty(), \"withDatabase() is required\");\n+      checkArgument(\n+          checkDatabase(\n+              database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+      builder.addIfNotNull(DisplayData.item(\"noOfElementsToBatch\", noOfElementsToBatch()));\n+      builder.addIfNotNull(DisplayData.item(\"flushDuration\", flushDuration()));\n+    }\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String retentionPolicy();\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract boolean sslEnabled();\n+\n+    abstract int noOfElementsToBatch();\n+\n+    abstract int flushDuration();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setNoOfElementsToBatch(int noOfElementsToBatch);\n+\n+      abstract Builder setFlushDuration(int flushDuration);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Write build();\n+    }\n+\n+    public Write withConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    public Write withDatabase(String database) {\n+      return builder().setDatabase(database).build();\n+    }\n+\n+    public Write withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Write withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Write withNoOfElementsToBatch(int noOfElementsToBatch) {\n+      return builder().setNoOfElementsToBatch(noOfElementsToBatch).build();\n+    }\n+\n+    public Write withFlushDuration(int flushDuration) {\n+      return builder().setFlushDuration(flushDuration).build();\n+    }\n+\n+    public Write withRetentionPolicy(String rp) {\n+      return builder().setRetentionPolicy(rp).build();\n+    }\n+\n+    private class InfluxWriterFn<T> extends DoFn<T, Void> {\n+\n+      private final Write spec;\n+      private InfluxDB connection;\n+\n+      InfluxWriterFn(Write write) {\n+        this.spec = write;\n+      }\n+\n+      @Setup\n+      public void setup() {\n+        connection =\n+            getConnection(\n+                spec.dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled());\n+        int flushDuration = spec.flushDuration();\n+        int noOfBatchPoints = spec.noOfElementsToBatch();\n+        connection.enableBatch(\n+            BatchOptions.DEFAULTS.actions(noOfBatchPoints).flushDuration(flushDuration));\n+        connection.setRetentionPolicy(spec.retentionPolicy());\n+        connection.setDatabase(spec.database());\n+      }\n+\n+      @ProcessElement\n+      public void processElement(ProcessContext c) {\n+        connection.write(c.element().toString());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 598}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMjY5OTUwOnYy", "diffSide": "RIGHT", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNTo0NzozN1rOGsz6yQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNTo0NzozN1rOGsz6yQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY0MTE2MQ==", "bodyText": "Would it make sense to take as input a PCollection of LineProtocolConvertable (instead of just String) or create own wrapper class, something like InfluxDbRecord implements LineProtocolConvertable?", "url": "https://github.com/apache/beam/pull/11459#discussion_r449641161", "createdAt": "2020-07-03T15:47:37Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(noOfBlocks)) {\n+                noOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> noOfBlocksValueItr = noOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueItr = sizeOfBlocksValue.iterator();\n+      long size = 0;\n+      while (noOfBlocksValueItr.hasNext() && sizeOfBlocksValueItr.hasNext()) {\n+        size = size + (noOfBlocksValueItr.next() * sizeOfBlocksValueItr.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(),\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          if (sInfo.getStartTime().compareTo(spec.startDateTime()) > 0) {\n+            sources.add(\n+                new InfluxDBSource(\n+                    spec.withMetrics(spec.metrics())\n+                        .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                        .withToDateTime(sInfo.getStartTime())\n+                        .withFromDateTime(sInfo.getEndTime())));\n+          }\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    if (spec.query() == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        return String.format(\n+            \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+            spec.retentionPolicy(),\n+            String.join(\",\", spec.metrics()),\n+            spec.toDateTime(),\n+            spec.fromDateTime());\n+      } else {\n+        return String.format(\n+            \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+      }\n+    }\n+    return spec.query();\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDBIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List current;\n+\n+    public BoundedInfluxDbReader(InfluxDBIO.InfluxDBSource source) {\n+      this.source = source;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDBIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        if (spec.database() != null) {\n+          influxDB.setDatabase(spec.database());\n+        }\n+        if (spec.retentionPolicy() != null) {\n+          influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        }\n+        String query = getQueryToRun(spec);\n+        QueryResult queryResult = influxDB.query(new Query(query, spec.database()));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          seriesIterator = resultIterator.next().getSeries().iterator();\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 478}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMjcwNDAxOnYy", "diffSide": "RIGHT", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNTo0OTo0MVrOGsz9XA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNTo0OTo0MVrOGsz9XA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY0MTgyMA==", "bodyText": "What is a case when user would need to set it to true? It could be potential security issue.", "url": "https://github.com/apache/beam/pull/11459#discussion_r449641820", "createdAt": "2020-07-03T15:49:41Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 251}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMjc3MzExOnYy", "diffSide": "RIGHT", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/DBShardInformation.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNjoyNDoxOFrOGs0k8Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNjoyNDoxOFrOGs0k8Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1MTk1Mw==", "bodyText": "This class can be package-private.", "url": "https://github.com/apache/beam/pull/11459#discussion_r449651953", "createdAt": "2020-07-03T16:24:18Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/DBShardInformation.java", "diffHunk": "@@ -0,0 +1,48 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.influxdb.dto.QueryResult.Series;\n+\n+public class DBShardInformation {\n+\n+  private Map<String, List<ShardInformation>> shardInformation = new HashMap<>();\n+\n+  public DBShardInformation() {}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMjc3OTcyOnYy", "diffSide": "RIGHT", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNjoyODowOVrOGs0osA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNjoyODowOVrOGs0osA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1MjkxMg==", "bodyText": "nit: checkState", "url": "https://github.com/apache/beam/pull/11459#discussion_r449652912", "createdAt": "2020-07-03T16:28:09Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 268}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMjc4MTcwOnYy", "diffSide": "RIGHT", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNjoyOTozNFrOGs0p4w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNjoyOTozNFrOGs0p4w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1MzIxOQ==", "bodyText": "nit: numOfBlocksValue", "url": "https://github.com/apache/beam/pull/11459#discussion_r449653219", "createdAt": "2020-07-03T16:29:34Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 302}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMjc4NTkwOnYy", "diffSide": "RIGHT", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNjozMTo0M1rOGs0sFw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNjozMTo0M1rOGs0sFw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1Mzc4Mw==", "bodyText": "How big this result can be in terms of amount of returned data?", "url": "https://github.com/apache/beam/pull/11459#discussion_r449653783", "createdAt": "2020-07-03T16:31:43Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 316}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMjc5Mjk4OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNjozNTo1N1rOGs0wJw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNjozNTo1N1rOGs0wJw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1NDgyMw==", "bodyText": "nit: numOfBlocks", "url": "https://github.com/apache/beam/pull/11459#discussion_r449654823", "createdAt": "2020-07-03T16:35:57Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 300}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMjgwMjc4OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNjo0MToyN1rOGs01sA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNjo0MToyN1rOGs01sA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1NjI0MA==", "bodyText": "nit: numOfBlocksValueIterator", "url": "https://github.com/apache/beam/pull/11459#discussion_r449656240", "createdAt": "2020-07-03T16:41:27Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(noOfBlocks)) {\n+                noOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> noOfBlocksValueItr = noOfBlocksValue.iterator();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 332}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMjgwMzI3OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNjo0MTo0OFrOGs02Dw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNjo0MTo0OFrOGs02Dw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1NjMzNQ==", "bodyText": "nit: sizeOfBlocksValueIterator", "url": "https://github.com/apache/beam/pull/11459#discussion_r449656335", "createdAt": "2020-07-03T16:41:48Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(noOfBlocks)) {\n+                noOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> noOfBlocksValueItr = noOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueItr = sizeOfBlocksValue.iterator();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 333}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMjgwNzE0OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNjo0NDoxOVrOGs04fw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNjo0NDoxOVrOGs04fw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1Njk1OQ==", "bodyText": "It's not possible to split with query?", "url": "https://github.com/apache/beam/pull/11459#discussion_r449656959", "createdAt": "2020-07-03T16:44:19Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(noOfBlocks)) {\n+                noOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> noOfBlocksValueItr = noOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueItr = sizeOfBlocksValue.iterator();\n+      long size = 0;\n+      while (noOfBlocksValueItr.hasNext() && sizeOfBlocksValueItr.hasNext()) {\n+        size = size + (noOfBlocksValueItr.next() * sizeOfBlocksValueItr.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(),\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          if (sInfo.getStartTime().compareTo(spec.startDateTime()) > 0) {\n+            sources.add(\n+                new InfluxDBSource(\n+                    spec.withMetrics(spec.metrics())\n+                        .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                        .withToDateTime(sInfo.getStartTime())\n+                        .withFromDateTime(sInfo.getEndTime())));\n+          }\n+        }\n+      } else {\n+        sources.add(this);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 363}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMjgxMjc3OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNjo0Nzo0MlrOGs070Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxNTo0MDozMVrOGzX3xA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1NzgwOQ==", "bodyText": "Is it needed to allow user to configure this? Can we set just sufficient default value?", "url": "https://github.com/apache/beam/pull/11459#discussion_r449657809", "createdAt": "2020-07-03T16:47:42Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(noOfBlocks)) {\n+                noOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> noOfBlocksValueItr = noOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueItr = sizeOfBlocksValue.iterator();\n+      long size = 0;\n+      while (noOfBlocksValueItr.hasNext() && sizeOfBlocksValueItr.hasNext()) {\n+        size = size + (noOfBlocksValueItr.next() * sizeOfBlocksValueItr.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(),\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          if (sInfo.getStartTime().compareTo(spec.startDateTime()) > 0) {\n+            sources.add(\n+                new InfluxDBSource(\n+                    spec.withMetrics(spec.metrics())\n+                        .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                        .withToDateTime(sInfo.getStartTime())\n+                        .withFromDateTime(sInfo.getEndTime())));\n+          }\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    if (spec.query() == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        return String.format(\n+            \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+            spec.retentionPolicy(),\n+            String.join(\",\", spec.metrics()),\n+            spec.toDateTime(),\n+            spec.fromDateTime());\n+      } else {\n+        return String.format(\n+            \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+      }\n+    }\n+    return spec.query();\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDBIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List current;\n+\n+    public BoundedInfluxDbReader(InfluxDBIO.InfluxDBSource source) {\n+      this.source = source;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDBIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        if (spec.database() != null) {\n+          influxDB.setDatabase(spec.database());\n+        }\n+        if (spec.retentionPolicy() != null) {\n+          influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        }\n+        String query = getQueryToRun(spec);\n+        QueryResult queryResult = influxDB.query(new Query(query, spec.database()));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          seriesIterator = resultIterator.next().getSeries().iterator();\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkArgument(dataSourceConfiguration() != null, \"withConfiguration() is required\");\n+      checkArgument(database() != null && !database().isEmpty(), \"withDatabase() is required\");\n+      checkArgument(\n+          checkDatabase(\n+              database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+      builder.addIfNotNull(DisplayData.item(\"noOfElementsToBatch\", noOfElementsToBatch()));\n+      builder.addIfNotNull(DisplayData.item(\"flushDuration\", flushDuration()));\n+    }\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String retentionPolicy();\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract boolean sslEnabled();\n+\n+    abstract int noOfElementsToBatch();\n+\n+    abstract int flushDuration();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setNoOfElementsToBatch(int noOfElementsToBatch);\n+\n+      abstract Builder setFlushDuration(int flushDuration);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Write build();\n+    }\n+\n+    public Write withConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    public Write withDatabase(String database) {\n+      return builder().setDatabase(database).build();\n+    }\n+\n+    public Write withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Write withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Write withNoOfElementsToBatch(int noOfElementsToBatch) {\n+      return builder().setNoOfElementsToBatch(noOfElementsToBatch).build();\n+    }\n+\n+    public Write withFlushDuration(int flushDuration) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 566}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzI2NzExMw==", "bodyText": "If not applied, it uses the default value https://github.com/bipinupd/beam/blob/BEAM-2546/sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java#L133", "url": "https://github.com/apache/beam/pull/11459#discussion_r453267113", "createdAt": "2020-07-12T04:50:34Z", "author": {"login": "bipinupd"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(noOfBlocks)) {\n+                noOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> noOfBlocksValueItr = noOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueItr = sizeOfBlocksValue.iterator();\n+      long size = 0;\n+      while (noOfBlocksValueItr.hasNext() && sizeOfBlocksValueItr.hasNext()) {\n+        size = size + (noOfBlocksValueItr.next() * sizeOfBlocksValueItr.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(),\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          if (sInfo.getStartTime().compareTo(spec.startDateTime()) > 0) {\n+            sources.add(\n+                new InfluxDBSource(\n+                    spec.withMetrics(spec.metrics())\n+                        .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                        .withToDateTime(sInfo.getStartTime())\n+                        .withFromDateTime(sInfo.getEndTime())));\n+          }\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    if (spec.query() == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        return String.format(\n+            \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+            spec.retentionPolicy(),\n+            String.join(\",\", spec.metrics()),\n+            spec.toDateTime(),\n+            spec.fromDateTime());\n+      } else {\n+        return String.format(\n+            \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+      }\n+    }\n+    return spec.query();\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDBIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List current;\n+\n+    public BoundedInfluxDbReader(InfluxDBIO.InfluxDBSource source) {\n+      this.source = source;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDBIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        if (spec.database() != null) {\n+          influxDB.setDatabase(spec.database());\n+        }\n+        if (spec.retentionPolicy() != null) {\n+          influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        }\n+        String query = getQueryToRun(spec);\n+        QueryResult queryResult = influxDB.query(new Query(query, spec.database()));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          seriesIterator = resultIterator.next().getSeries().iterator();\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkArgument(dataSourceConfiguration() != null, \"withConfiguration() is required\");\n+      checkArgument(database() != null && !database().isEmpty(), \"withDatabase() is required\");\n+      checkArgument(\n+          checkDatabase(\n+              database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+      builder.addIfNotNull(DisplayData.item(\"noOfElementsToBatch\", noOfElementsToBatch()));\n+      builder.addIfNotNull(DisplayData.item(\"flushDuration\", flushDuration()));\n+    }\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String retentionPolicy();\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract boolean sslEnabled();\n+\n+    abstract int noOfElementsToBatch();\n+\n+    abstract int flushDuration();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setNoOfElementsToBatch(int noOfElementsToBatch);\n+\n+      abstract Builder setFlushDuration(int flushDuration);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Write build();\n+    }\n+\n+    public Write withConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    public Write withDatabase(String database) {\n+      return builder().setDatabase(database).build();\n+    }\n+\n+    public Write withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Write withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Write withNoOfElementsToBatch(int noOfElementsToBatch) {\n+      return builder().setNoOfElementsToBatch(noOfElementsToBatch).build();\n+    }\n+\n+    public Write withFlushDuration(int flushDuration) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1NzgwOQ=="}, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 566}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjUyMTY2OA==", "bodyText": "Beam tends to reduce number of knobs exposed to user API.\nIs it quite possible that it will be required to change? Can we check in a loop (with a quite large timeout to prevent infinite loop) that everything was flushed?", "url": "https://github.com/apache/beam/pull/11459#discussion_r456521668", "createdAt": "2020-07-17T15:40:31Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(noOfBlocks)) {\n+                noOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> noOfBlocksValueItr = noOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueItr = sizeOfBlocksValue.iterator();\n+      long size = 0;\n+      while (noOfBlocksValueItr.hasNext() && sizeOfBlocksValueItr.hasNext()) {\n+        size = size + (noOfBlocksValueItr.next() * sizeOfBlocksValueItr.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(),\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          if (sInfo.getStartTime().compareTo(spec.startDateTime()) > 0) {\n+            sources.add(\n+                new InfluxDBSource(\n+                    spec.withMetrics(spec.metrics())\n+                        .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                        .withToDateTime(sInfo.getStartTime())\n+                        .withFromDateTime(sInfo.getEndTime())));\n+          }\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    if (spec.query() == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        return String.format(\n+            \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+            spec.retentionPolicy(),\n+            String.join(\",\", spec.metrics()),\n+            spec.toDateTime(),\n+            spec.fromDateTime());\n+      } else {\n+        return String.format(\n+            \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+      }\n+    }\n+    return spec.query();\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDBIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List current;\n+\n+    public BoundedInfluxDbReader(InfluxDBIO.InfluxDBSource source) {\n+      this.source = source;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDBIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        if (spec.database() != null) {\n+          influxDB.setDatabase(spec.database());\n+        }\n+        if (spec.retentionPolicy() != null) {\n+          influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        }\n+        String query = getQueryToRun(spec);\n+        QueryResult queryResult = influxDB.query(new Query(query, spec.database()));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          seriesIterator = resultIterator.next().getSeries().iterator();\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkArgument(dataSourceConfiguration() != null, \"withConfiguration() is required\");\n+      checkArgument(database() != null && !database().isEmpty(), \"withDatabase() is required\");\n+      checkArgument(\n+          checkDatabase(\n+              database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+      builder.addIfNotNull(DisplayData.item(\"noOfElementsToBatch\", noOfElementsToBatch()));\n+      builder.addIfNotNull(DisplayData.item(\"flushDuration\", flushDuration()));\n+    }\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String retentionPolicy();\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract boolean sslEnabled();\n+\n+    abstract int noOfElementsToBatch();\n+\n+    abstract int flushDuration();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setNoOfElementsToBatch(int noOfElementsToBatch);\n+\n+      abstract Builder setFlushDuration(int flushDuration);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Write build();\n+    }\n+\n+    public Write withConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    public Write withDatabase(String database) {\n+      return builder().setDatabase(database).build();\n+    }\n+\n+    public Write withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Write withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Write withNoOfElementsToBatch(int noOfElementsToBatch) {\n+      return builder().setNoOfElementsToBatch(noOfElementsToBatch).build();\n+    }\n+\n+    public Write withFlushDuration(int flushDuration) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1NzgwOQ=="}, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 566}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMjgxMzQyOnYy", "diffSide": "RIGHT", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNjo0ODoxMlrOGs08Ow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNjo0ODoxMlrOGs08Ow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1NzkxNQ==", "bodyText": "nit: numOfElementsToBatch", "url": "https://github.com/apache/beam/pull/11459#discussion_r449657915", "createdAt": "2020-07-03T16:48:12Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(noOfBlocks)) {\n+                noOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> noOfBlocksValueItr = noOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueItr = sizeOfBlocksValue.iterator();\n+      long size = 0;\n+      while (noOfBlocksValueItr.hasNext() && sizeOfBlocksValueItr.hasNext()) {\n+        size = size + (noOfBlocksValueItr.next() * sizeOfBlocksValueItr.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(),\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          if (sInfo.getStartTime().compareTo(spec.startDateTime()) > 0) {\n+            sources.add(\n+                new InfluxDBSource(\n+                    spec.withMetrics(spec.metrics())\n+                        .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                        .withToDateTime(sInfo.getStartTime())\n+                        .withFromDateTime(sInfo.getEndTime())));\n+          }\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    if (spec.query() == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        return String.format(\n+            \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+            spec.retentionPolicy(),\n+            String.join(\",\", spec.metrics()),\n+            spec.toDateTime(),\n+            spec.fromDateTime());\n+      } else {\n+        return String.format(\n+            \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+      }\n+    }\n+    return spec.query();\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDBIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List current;\n+\n+    public BoundedInfluxDbReader(InfluxDBIO.InfluxDBSource source) {\n+      this.source = source;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDBIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        if (spec.database() != null) {\n+          influxDB.setDatabase(spec.database());\n+        }\n+        if (spec.retentionPolicy() != null) {\n+          influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        }\n+        String query = getQueryToRun(spec);\n+        QueryResult queryResult = influxDB.query(new Query(query, spec.database()));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          seriesIterator = resultIterator.next().getSeries().iterator();\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkArgument(dataSourceConfiguration() != null, \"withConfiguration() is required\");\n+      checkArgument(database() != null && !database().isEmpty(), \"withDatabase() is required\");\n+      checkArgument(\n+          checkDatabase(\n+              database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+      builder.addIfNotNull(DisplayData.item(\"noOfElementsToBatch\", noOfElementsToBatch()));\n+      builder.addIfNotNull(DisplayData.item(\"flushDuration\", flushDuration()));\n+    }\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String retentionPolicy();\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract boolean sslEnabled();\n+\n+    abstract int noOfElementsToBatch();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 517}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMjgxNTE5OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNjo0OToyNlrOGs09Vg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxNTo0ODozM1rOGzYJgg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1ODE5OA==", "bodyText": "What is a reason to have unsafe https client?", "url": "https://github.com/apache/beam/pull/11459#discussion_r449658198", "createdAt": "2020-07-03T16:49:26Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(noOfBlocks)) {\n+                noOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> noOfBlocksValueItr = noOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueItr = sizeOfBlocksValue.iterator();\n+      long size = 0;\n+      while (noOfBlocksValueItr.hasNext() && sizeOfBlocksValueItr.hasNext()) {\n+        size = size + (noOfBlocksValueItr.next() * sizeOfBlocksValueItr.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(),\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          if (sInfo.getStartTime().compareTo(spec.startDateTime()) > 0) {\n+            sources.add(\n+                new InfluxDBSource(\n+                    spec.withMetrics(spec.metrics())\n+                        .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                        .withToDateTime(sInfo.getStartTime())\n+                        .withFromDateTime(sInfo.getEndTime())));\n+          }\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    if (spec.query() == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        return String.format(\n+            \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+            spec.retentionPolicy(),\n+            String.join(\",\", spec.metrics()),\n+            spec.toDateTime(),\n+            spec.fromDateTime());\n+      } else {\n+        return String.format(\n+            \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+      }\n+    }\n+    return spec.query();\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDBIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List current;\n+\n+    public BoundedInfluxDbReader(InfluxDBIO.InfluxDBSource source) {\n+      this.source = source;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDBIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        if (spec.database() != null) {\n+          influxDB.setDatabase(spec.database());\n+        }\n+        if (spec.retentionPolicy() != null) {\n+          influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        }\n+        String query = getQueryToRun(spec);\n+        QueryResult queryResult = influxDB.query(new Query(query, spec.database()));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          seriesIterator = resultIterator.next().getSeries().iterator();\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkArgument(dataSourceConfiguration() != null, \"withConfiguration() is required\");\n+      checkArgument(database() != null && !database().isEmpty(), \"withDatabase() is required\");\n+      checkArgument(\n+          checkDatabase(\n+              database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+      builder.addIfNotNull(DisplayData.item(\"noOfElementsToBatch\", noOfElementsToBatch()));\n+      builder.addIfNotNull(DisplayData.item(\"flushDuration\", flushDuration()));\n+    }\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String retentionPolicy();\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract boolean sslEnabled();\n+\n+    abstract int noOfElementsToBatch();\n+\n+    abstract int flushDuration();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setNoOfElementsToBatch(int noOfElementsToBatch);\n+\n+      abstract Builder setFlushDuration(int flushDuration);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Write build();\n+    }\n+\n+    public Write withConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    public Write withDatabase(String database) {\n+      return builder().setDatabase(database).build();\n+    }\n+\n+    public Write withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Write withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Write withNoOfElementsToBatch(int noOfElementsToBatch) {\n+      return builder().setNoOfElementsToBatch(noOfElementsToBatch).build();\n+    }\n+\n+    public Write withFlushDuration(int flushDuration) {\n+      return builder().setFlushDuration(flushDuration).build();\n+    }\n+\n+    public Write withRetentionPolicy(String rp) {\n+      return builder().setRetentionPolicy(rp).build();\n+    }\n+\n+    private class InfluxWriterFn<T> extends DoFn<T, Void> {\n+\n+      private final Write spec;\n+      private InfluxDB connection;\n+\n+      InfluxWriterFn(Write write) {\n+        this.spec = write;\n+      }\n+\n+      @Setup\n+      public void setup() {\n+        connection =\n+            getConnection(\n+                spec.dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled());\n+        int flushDuration = spec.flushDuration();\n+        int noOfBatchPoints = spec.noOfElementsToBatch();\n+        connection.enableBatch(\n+            BatchOptions.DEFAULTS.actions(noOfBatchPoints).flushDuration(flushDuration));\n+        connection.setRetentionPolicy(spec.retentionPolicy());\n+        connection.setDatabase(spec.database());\n+      }\n+\n+      @ProcessElement\n+      public void processElement(ProcessContext c) {\n+        connection.write(c.element().toString());\n+      }\n+\n+      @FinishBundle\n+      public void finishBundle() {\n+        connection.flush();\n+      }\n+\n+      @Teardown\n+      public void tearDown() {\n+        if (connection != null) {\n+          connection.flush();\n+          connection.close();\n+          connection = null;\n+        }\n+      }\n+\n+      @Override\n+      public void populateDisplayData(DisplayData.Builder builder) {\n+        builder.delegate(Write.this);\n+      }\n+    }\n+  }\n+\n+  private static OkHttpClient.Builder getUnsafeOkHttpClient() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 622}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzI2MTMyNA==", "bodyText": "For the cases where InfluxDB is run without proper SSL in internal servers", "url": "https://github.com/apache/beam/pull/11459#discussion_r453261324", "createdAt": "2020-07-12T03:23:03Z", "author": {"login": "bipinupd"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(noOfBlocks)) {\n+                noOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> noOfBlocksValueItr = noOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueItr = sizeOfBlocksValue.iterator();\n+      long size = 0;\n+      while (noOfBlocksValueItr.hasNext() && sizeOfBlocksValueItr.hasNext()) {\n+        size = size + (noOfBlocksValueItr.next() * sizeOfBlocksValueItr.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(),\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          if (sInfo.getStartTime().compareTo(spec.startDateTime()) > 0) {\n+            sources.add(\n+                new InfluxDBSource(\n+                    spec.withMetrics(spec.metrics())\n+                        .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                        .withToDateTime(sInfo.getStartTime())\n+                        .withFromDateTime(sInfo.getEndTime())));\n+          }\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    if (spec.query() == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        return String.format(\n+            \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+            spec.retentionPolicy(),\n+            String.join(\",\", spec.metrics()),\n+            spec.toDateTime(),\n+            spec.fromDateTime());\n+      } else {\n+        return String.format(\n+            \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+      }\n+    }\n+    return spec.query();\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDBIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List current;\n+\n+    public BoundedInfluxDbReader(InfluxDBIO.InfluxDBSource source) {\n+      this.source = source;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDBIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        if (spec.database() != null) {\n+          influxDB.setDatabase(spec.database());\n+        }\n+        if (spec.retentionPolicy() != null) {\n+          influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        }\n+        String query = getQueryToRun(spec);\n+        QueryResult queryResult = influxDB.query(new Query(query, spec.database()));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          seriesIterator = resultIterator.next().getSeries().iterator();\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkArgument(dataSourceConfiguration() != null, \"withConfiguration() is required\");\n+      checkArgument(database() != null && !database().isEmpty(), \"withDatabase() is required\");\n+      checkArgument(\n+          checkDatabase(\n+              database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+      builder.addIfNotNull(DisplayData.item(\"noOfElementsToBatch\", noOfElementsToBatch()));\n+      builder.addIfNotNull(DisplayData.item(\"flushDuration\", flushDuration()));\n+    }\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String retentionPolicy();\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract boolean sslEnabled();\n+\n+    abstract int noOfElementsToBatch();\n+\n+    abstract int flushDuration();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setNoOfElementsToBatch(int noOfElementsToBatch);\n+\n+      abstract Builder setFlushDuration(int flushDuration);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Write build();\n+    }\n+\n+    public Write withConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    public Write withDatabase(String database) {\n+      return builder().setDatabase(database).build();\n+    }\n+\n+    public Write withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Write withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Write withNoOfElementsToBatch(int noOfElementsToBatch) {\n+      return builder().setNoOfElementsToBatch(noOfElementsToBatch).build();\n+    }\n+\n+    public Write withFlushDuration(int flushDuration) {\n+      return builder().setFlushDuration(flushDuration).build();\n+    }\n+\n+    public Write withRetentionPolicy(String rp) {\n+      return builder().setRetentionPolicy(rp).build();\n+    }\n+\n+    private class InfluxWriterFn<T> extends DoFn<T, Void> {\n+\n+      private final Write spec;\n+      private InfluxDB connection;\n+\n+      InfluxWriterFn(Write write) {\n+        this.spec = write;\n+      }\n+\n+      @Setup\n+      public void setup() {\n+        connection =\n+            getConnection(\n+                spec.dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled());\n+        int flushDuration = spec.flushDuration();\n+        int noOfBatchPoints = spec.noOfElementsToBatch();\n+        connection.enableBatch(\n+            BatchOptions.DEFAULTS.actions(noOfBatchPoints).flushDuration(flushDuration));\n+        connection.setRetentionPolicy(spec.retentionPolicy());\n+        connection.setDatabase(spec.database());\n+      }\n+\n+      @ProcessElement\n+      public void processElement(ProcessContext c) {\n+        connection.write(c.element().toString());\n+      }\n+\n+      @FinishBundle\n+      public void finishBundle() {\n+        connection.flush();\n+      }\n+\n+      @Teardown\n+      public void tearDown() {\n+        if (connection != null) {\n+          connection.flush();\n+          connection.close();\n+          connection = null;\n+        }\n+      }\n+\n+      @Override\n+      public void populateDisplayData(DisplayData.Builder builder) {\n+        builder.delegate(Write.this);\n+      }\n+    }\n+  }\n+\n+  private static OkHttpClient.Builder getUnsafeOkHttpClient() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1ODE5OA=="}, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 622}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjUyNjIxMA==", "bodyText": "I don't think that we have to expose it into user API and implement it inside IO. Can we just allow user to provide a custom client implementation for this case?", "url": "https://github.com/apache/beam/pull/11459#discussion_r456526210", "createdAt": "2020-07-17T15:48:33Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(noOfBlocks)) {\n+                noOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> noOfBlocksValueItr = noOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueItr = sizeOfBlocksValue.iterator();\n+      long size = 0;\n+      while (noOfBlocksValueItr.hasNext() && sizeOfBlocksValueItr.hasNext()) {\n+        size = size + (noOfBlocksValueItr.next() * sizeOfBlocksValueItr.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(),\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          if (sInfo.getStartTime().compareTo(spec.startDateTime()) > 0) {\n+            sources.add(\n+                new InfluxDBSource(\n+                    spec.withMetrics(spec.metrics())\n+                        .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                        .withToDateTime(sInfo.getStartTime())\n+                        .withFromDateTime(sInfo.getEndTime())));\n+          }\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    if (spec.query() == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        return String.format(\n+            \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+            spec.retentionPolicy(),\n+            String.join(\",\", spec.metrics()),\n+            spec.toDateTime(),\n+            spec.fromDateTime());\n+      } else {\n+        return String.format(\n+            \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+      }\n+    }\n+    return spec.query();\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDBIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List current;\n+\n+    public BoundedInfluxDbReader(InfluxDBIO.InfluxDBSource source) {\n+      this.source = source;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDBIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        if (spec.database() != null) {\n+          influxDB.setDatabase(spec.database());\n+        }\n+        if (spec.retentionPolicy() != null) {\n+          influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        }\n+        String query = getQueryToRun(spec);\n+        QueryResult queryResult = influxDB.query(new Query(query, spec.database()));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          seriesIterator = resultIterator.next().getSeries().iterator();\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkArgument(dataSourceConfiguration() != null, \"withConfiguration() is required\");\n+      checkArgument(database() != null && !database().isEmpty(), \"withDatabase() is required\");\n+      checkArgument(\n+          checkDatabase(\n+              database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+      builder.addIfNotNull(DisplayData.item(\"noOfElementsToBatch\", noOfElementsToBatch()));\n+      builder.addIfNotNull(DisplayData.item(\"flushDuration\", flushDuration()));\n+    }\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String retentionPolicy();\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract boolean sslEnabled();\n+\n+    abstract int noOfElementsToBatch();\n+\n+    abstract int flushDuration();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setNoOfElementsToBatch(int noOfElementsToBatch);\n+\n+      abstract Builder setFlushDuration(int flushDuration);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Write build();\n+    }\n+\n+    public Write withConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    public Write withDatabase(String database) {\n+      return builder().setDatabase(database).build();\n+    }\n+\n+    public Write withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Write withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Write withNoOfElementsToBatch(int noOfElementsToBatch) {\n+      return builder().setNoOfElementsToBatch(noOfElementsToBatch).build();\n+    }\n+\n+    public Write withFlushDuration(int flushDuration) {\n+      return builder().setFlushDuration(flushDuration).build();\n+    }\n+\n+    public Write withRetentionPolicy(String rp) {\n+      return builder().setRetentionPolicy(rp).build();\n+    }\n+\n+    private class InfluxWriterFn<T> extends DoFn<T, Void> {\n+\n+      private final Write spec;\n+      private InfluxDB connection;\n+\n+      InfluxWriterFn(Write write) {\n+        this.spec = write;\n+      }\n+\n+      @Setup\n+      public void setup() {\n+        connection =\n+            getConnection(\n+                spec.dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled());\n+        int flushDuration = spec.flushDuration();\n+        int noOfBatchPoints = spec.noOfElementsToBatch();\n+        connection.enableBatch(\n+            BatchOptions.DEFAULTS.actions(noOfBatchPoints).flushDuration(flushDuration));\n+        connection.setRetentionPolicy(spec.retentionPolicy());\n+        connection.setDatabase(spec.database());\n+      }\n+\n+      @ProcessElement\n+      public void processElement(ProcessContext c) {\n+        connection.write(c.element().toString());\n+      }\n+\n+      @FinishBundle\n+      public void finishBundle() {\n+        connection.flush();\n+      }\n+\n+      @Teardown\n+      public void tearDown() {\n+        if (connection != null) {\n+          connection.flush();\n+          connection.close();\n+          connection = null;\n+        }\n+      }\n+\n+      @Override\n+      public void populateDisplayData(DisplayData.Builder builder) {\n+        builder.delegate(Write.this);\n+      }\n+    }\n+  }\n+\n+  private static OkHttpClient.Builder getUnsafeOkHttpClient() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1ODE5OA=="}, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 622}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMjgxNTUyOnYy", "diffSide": "RIGHT", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNjo0OTo0MVrOGs09hg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMlQwMzoyMDo1NlrOGwQ3dg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1ODI0Ng==", "bodyText": "Is it needed to allow user to configure this? Can we set just sufficient default value?", "url": "https://github.com/apache/beam/pull/11459#discussion_r449658246", "createdAt": "2020-07-03T16:49:41Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(noOfBlocks)) {\n+                noOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> noOfBlocksValueItr = noOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueItr = sizeOfBlocksValue.iterator();\n+      long size = 0;\n+      while (noOfBlocksValueItr.hasNext() && sizeOfBlocksValueItr.hasNext()) {\n+        size = size + (noOfBlocksValueItr.next() * sizeOfBlocksValueItr.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(),\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          if (sInfo.getStartTime().compareTo(spec.startDateTime()) > 0) {\n+            sources.add(\n+                new InfluxDBSource(\n+                    spec.withMetrics(spec.metrics())\n+                        .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                        .withToDateTime(sInfo.getStartTime())\n+                        .withFromDateTime(sInfo.getEndTime())));\n+          }\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    if (spec.query() == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        return String.format(\n+            \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+            spec.retentionPolicy(),\n+            String.join(\",\", spec.metrics()),\n+            spec.toDateTime(),\n+            spec.fromDateTime());\n+      } else {\n+        return String.format(\n+            \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+      }\n+    }\n+    return spec.query();\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDBIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List current;\n+\n+    public BoundedInfluxDbReader(InfluxDBIO.InfluxDBSource source) {\n+      this.source = source;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDBIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        if (spec.database() != null) {\n+          influxDB.setDatabase(spec.database());\n+        }\n+        if (spec.retentionPolicy() != null) {\n+          influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        }\n+        String query = getQueryToRun(spec);\n+        QueryResult queryResult = influxDB.query(new Query(query, spec.database()));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          seriesIterator = resultIterator.next().getSeries().iterator();\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkArgument(dataSourceConfiguration() != null, \"withConfiguration() is required\");\n+      checkArgument(database() != null && !database().isEmpty(), \"withDatabase() is required\");\n+      checkArgument(\n+          checkDatabase(\n+              database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+      builder.addIfNotNull(DisplayData.item(\"noOfElementsToBatch\", noOfElementsToBatch()));\n+      builder.addIfNotNull(DisplayData.item(\"flushDuration\", flushDuration()));\n+    }\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String retentionPolicy();\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract boolean sslEnabled();\n+\n+    abstract int noOfElementsToBatch();\n+\n+    abstract int flushDuration();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setNoOfElementsToBatch(int noOfElementsToBatch);\n+\n+      abstract Builder setFlushDuration(int flushDuration);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Write build();\n+    }\n+\n+    public Write withConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    public Write withDatabase(String database) {\n+      return builder().setDatabase(database).build();\n+    }\n+\n+    public Write withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Write withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Write withNoOfElementsToBatch(int noOfElementsToBatch) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 562}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzI2MTE3NA==", "bodyText": "If not supplied.. It uses the default https://github.com/bipinupd/beam/blob/BEAM-2546/sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java#L134", "url": "https://github.com/apache/beam/pull/11459#discussion_r453261174", "createdAt": "2020-07-12T03:20:56Z", "author": {"login": "bipinupd"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(noOfBlocks)) {\n+                noOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> noOfBlocksValueItr = noOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueItr = sizeOfBlocksValue.iterator();\n+      long size = 0;\n+      while (noOfBlocksValueItr.hasNext() && sizeOfBlocksValueItr.hasNext()) {\n+        size = size + (noOfBlocksValueItr.next() * sizeOfBlocksValueItr.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(),\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          if (sInfo.getStartTime().compareTo(spec.startDateTime()) > 0) {\n+            sources.add(\n+                new InfluxDBSource(\n+                    spec.withMetrics(spec.metrics())\n+                        .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                        .withToDateTime(sInfo.getStartTime())\n+                        .withFromDateTime(sInfo.getEndTime())));\n+          }\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    if (spec.query() == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        return String.format(\n+            \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+            spec.retentionPolicy(),\n+            String.join(\",\", spec.metrics()),\n+            spec.toDateTime(),\n+            spec.fromDateTime());\n+      } else {\n+        return String.format(\n+            \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+      }\n+    }\n+    return spec.query();\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDBIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List current;\n+\n+    public BoundedInfluxDbReader(InfluxDBIO.InfluxDBSource source) {\n+      this.source = source;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDBIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        if (spec.database() != null) {\n+          influxDB.setDatabase(spec.database());\n+        }\n+        if (spec.retentionPolicy() != null) {\n+          influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        }\n+        String query = getQueryToRun(spec);\n+        QueryResult queryResult = influxDB.query(new Query(query, spec.database()));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          seriesIterator = resultIterator.next().getSeries().iterator();\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkArgument(dataSourceConfiguration() != null, \"withConfiguration() is required\");\n+      checkArgument(database() != null && !database().isEmpty(), \"withDatabase() is required\");\n+      checkArgument(\n+          checkDatabase(\n+              database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+      builder.addIfNotNull(DisplayData.item(\"noOfElementsToBatch\", noOfElementsToBatch()));\n+      builder.addIfNotNull(DisplayData.item(\"flushDuration\", flushDuration()));\n+    }\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String retentionPolicy();\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract boolean sslEnabled();\n+\n+    abstract int noOfElementsToBatch();\n+\n+    abstract int flushDuration();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setNoOfElementsToBatch(int noOfElementsToBatch);\n+\n+      abstract Builder setFlushDuration(int flushDuration);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Write build();\n+    }\n+\n+    public Write withConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    public Write withDatabase(String database) {\n+      return builder().setDatabase(database).build();\n+    }\n+\n+    public Write withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Write withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Write withNoOfElementsToBatch(int noOfElementsToBatch) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1ODI0Ng=="}, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 562}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMjgxNjUyOnYy", "diffSide": "RIGHT", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNjo1MDoxN1rOGs0-FQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNjo1MDoxN1rOGs0-FQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1ODM4OQ==", "bodyText": "nit: numOfBatchPoints", "url": "https://github.com/apache/beam/pull/11459#discussion_r449658389", "createdAt": "2020-07-03T16:50:17Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(noOfBlocks)) {\n+                noOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> noOfBlocksValueItr = noOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueItr = sizeOfBlocksValue.iterator();\n+      long size = 0;\n+      while (noOfBlocksValueItr.hasNext() && sizeOfBlocksValueItr.hasNext()) {\n+        size = size + (noOfBlocksValueItr.next() * sizeOfBlocksValueItr.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(),\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          if (sInfo.getStartTime().compareTo(spec.startDateTime()) > 0) {\n+            sources.add(\n+                new InfluxDBSource(\n+                    spec.withMetrics(spec.metrics())\n+                        .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                        .withToDateTime(sInfo.getStartTime())\n+                        .withFromDateTime(sInfo.getEndTime())));\n+          }\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    if (spec.query() == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        return String.format(\n+            \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+            spec.retentionPolicy(),\n+            String.join(\",\", spec.metrics()),\n+            spec.toDateTime(),\n+            spec.fromDateTime());\n+      } else {\n+        return String.format(\n+            \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+      }\n+    }\n+    return spec.query();\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDBIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List current;\n+\n+    public BoundedInfluxDbReader(InfluxDBIO.InfluxDBSource source) {\n+      this.source = source;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDBIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        if (spec.database() != null) {\n+          influxDB.setDatabase(spec.database());\n+        }\n+        if (spec.retentionPolicy() != null) {\n+          influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        }\n+        String query = getQueryToRun(spec);\n+        QueryResult queryResult = influxDB.query(new Query(query, spec.database()));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          seriesIterator = resultIterator.next().getSeries().iterator();\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkArgument(dataSourceConfiguration() != null, \"withConfiguration() is required\");\n+      checkArgument(database() != null && !database().isEmpty(), \"withDatabase() is required\");\n+      checkArgument(\n+          checkDatabase(\n+              database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+      builder.addIfNotNull(DisplayData.item(\"noOfElementsToBatch\", noOfElementsToBatch()));\n+      builder.addIfNotNull(DisplayData.item(\"flushDuration\", flushDuration()));\n+    }\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String retentionPolicy();\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract boolean sslEnabled();\n+\n+    abstract int noOfElementsToBatch();\n+\n+    abstract int flushDuration();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setNoOfElementsToBatch(int noOfElementsToBatch);\n+\n+      abstract Builder setFlushDuration(int flushDuration);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Write build();\n+    }\n+\n+    public Write withConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    public Write withDatabase(String database) {\n+      return builder().setDatabase(database).build();\n+    }\n+\n+    public Write withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Write withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Write withNoOfElementsToBatch(int noOfElementsToBatch) {\n+      return builder().setNoOfElementsToBatch(noOfElementsToBatch).build();\n+    }\n+\n+    public Write withFlushDuration(int flushDuration) {\n+      return builder().setFlushDuration(flushDuration).build();\n+    }\n+\n+    public Write withRetentionPolicy(String rp) {\n+      return builder().setRetentionPolicy(rp).build();\n+    }\n+\n+    private class InfluxWriterFn<T> extends DoFn<T, Void> {\n+\n+      private final Write spec;\n+      private InfluxDB connection;\n+\n+      InfluxWriterFn(Write write) {\n+        this.spec = write;\n+      }\n+\n+      @Setup\n+      public void setup() {\n+        connection =\n+            getConnection(\n+                spec.dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled());\n+        int flushDuration = spec.flushDuration();\n+        int noOfBatchPoints = spec.noOfElementsToBatch();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 589}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMjgyMTc2OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNjo1MzozMVrOGs1BBg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNjo1MzozMVrOGs1BBg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY1OTE0Mg==", "bodyText": "If InfluxDB  is not serialisable then it should be transient.", "url": "https://github.com/apache/beam/pull/11459#discussion_r449659142", "createdAt": "2020-07-03T16:53:31Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(noOfBlocks)) {\n+                noOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> noOfBlocksValueItr = noOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueItr = sizeOfBlocksValue.iterator();\n+      long size = 0;\n+      while (noOfBlocksValueItr.hasNext() && sizeOfBlocksValueItr.hasNext()) {\n+        size = size + (noOfBlocksValueItr.next() * sizeOfBlocksValueItr.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(),\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          if (sInfo.getStartTime().compareTo(spec.startDateTime()) > 0) {\n+            sources.add(\n+                new InfluxDBSource(\n+                    spec.withMetrics(spec.metrics())\n+                        .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                        .withToDateTime(sInfo.getStartTime())\n+                        .withFromDateTime(sInfo.getEndTime())));\n+          }\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    if (spec.query() == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        return String.format(\n+            \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+            spec.retentionPolicy(),\n+            String.join(\",\", spec.metrics()),\n+            spec.toDateTime(),\n+            spec.fromDateTime());\n+      } else {\n+        return String.format(\n+            \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+      }\n+    }\n+    return spec.query();\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDBIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List current;\n+\n+    public BoundedInfluxDbReader(InfluxDBIO.InfluxDBSource source) {\n+      this.source = source;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDBIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        if (spec.database() != null) {\n+          influxDB.setDatabase(spec.database());\n+        }\n+        if (spec.retentionPolicy() != null) {\n+          influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        }\n+        String query = getQueryToRun(spec);\n+        QueryResult queryResult = influxDB.query(new Query(query, spec.database()));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          seriesIterator = resultIterator.next().getSeries().iterator();\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkArgument(dataSourceConfiguration() != null, \"withConfiguration() is required\");\n+      checkArgument(database() != null && !database().isEmpty(), \"withDatabase() is required\");\n+      checkArgument(\n+          checkDatabase(\n+              database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+      builder.addIfNotNull(DisplayData.item(\"noOfElementsToBatch\", noOfElementsToBatch()));\n+      builder.addIfNotNull(DisplayData.item(\"flushDuration\", flushDuration()));\n+    }\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String retentionPolicy();\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract boolean sslEnabled();\n+\n+    abstract int noOfElementsToBatch();\n+\n+    abstract int flushDuration();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setNoOfElementsToBatch(int noOfElementsToBatch);\n+\n+      abstract Builder setFlushDuration(int flushDuration);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Write build();\n+    }\n+\n+    public Write withConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    public Write withDatabase(String database) {\n+      return builder().setDatabase(database).build();\n+    }\n+\n+    public Write withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Write withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Write withNoOfElementsToBatch(int noOfElementsToBatch) {\n+      return builder().setNoOfElementsToBatch(noOfElementsToBatch).build();\n+    }\n+\n+    public Write withFlushDuration(int flushDuration) {\n+      return builder().setFlushDuration(flushDuration).build();\n+    }\n+\n+    public Write withRetentionPolicy(String rp) {\n+      return builder().setRetentionPolicy(rp).build();\n+    }\n+\n+    private class InfluxWriterFn<T> extends DoFn<T, Void> {\n+\n+      private final Write spec;\n+      private InfluxDB connection;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 577}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMjgyODI4OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNjo1NzozMlrOGs1EwA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wM1QxNjo1NzozMlrOGs1EwA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTY2MDA5Ng==", "bodyText": "Do we need to handle for every connection.query() an empty result  (if possible) or any exceptions if they can happen?", "url": "https://github.com/apache/beam/pull/11459#discussion_r449660096", "createdAt": "2020-07-03T16:57:32Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,829 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>you have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database by converting each T. The T should implement getLineProtocol() from {@link\n+ * LineProtocolConvertable}.\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDBIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDBIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDBIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNoOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDBIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkArgument(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkArgument(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkArgument(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String noOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> noOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(noOfBlocks)) {\n+                noOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> noOfBlocksValueItr = noOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueItr = sizeOfBlocksValue.iterator();\n+      long size = 0;\n+      while (noOfBlocksValueItr.hasNext() && sizeOfBlocksValueItr.hasNext()) {\n+        size = size + (noOfBlocksValueItr.next() * sizeOfBlocksValueItr.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(),\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          if (sInfo.getStartTime().compareTo(spec.startDateTime()) > 0) {\n+            sources.add(\n+                new InfluxDBSource(\n+                    spec.withMetrics(spec.metrics())\n+                        .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                        .withToDateTime(sInfo.getStartTime())\n+                        .withFromDateTime(sInfo.getEndTime())));\n+          }\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    if (spec.query() == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        return String.format(\n+            \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+            spec.retentionPolicy(),\n+            String.join(\",\", spec.metrics()),\n+            spec.toDateTime(),\n+            spec.fromDateTime());\n+      } else {\n+        return String.format(\n+            \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+      }\n+    }\n+    return spec.query();\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDBIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List current;\n+\n+    public BoundedInfluxDbReader(InfluxDBIO.InfluxDBSource source) {\n+      this.source = source;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDBIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        if (spec.database() != null) {\n+          influxDB.setDatabase(spec.database());\n+        }\n+        if (spec.retentionPolicy() != null) {\n+          influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        }\n+        String query = getQueryToRun(spec);\n+        QueryResult queryResult = influxDB.query(new Query(query, spec.database()));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          seriesIterator = resultIterator.next().getSeries().iterator();\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkArgument(dataSourceConfiguration() != null, \"withConfiguration() is required\");\n+      checkArgument(database() != null && !database().isEmpty(), \"withDatabase() is required\");\n+      checkArgument(\n+          checkDatabase(\n+              database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+      builder.addIfNotNull(DisplayData.item(\"noOfElementsToBatch\", noOfElementsToBatch()));\n+      builder.addIfNotNull(DisplayData.item(\"flushDuration\", flushDuration()));\n+    }\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String retentionPolicy();\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract boolean sslEnabled();\n+\n+    abstract int noOfElementsToBatch();\n+\n+    abstract int flushDuration();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setNoOfElementsToBatch(int noOfElementsToBatch);\n+\n+      abstract Builder setFlushDuration(int flushDuration);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Write build();\n+    }\n+\n+    public Write withConfiguration(DataSourceConfiguration configuration) {\n+      checkArgument(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    public Write withDatabase(String database) {\n+      return builder().setDatabase(database).build();\n+    }\n+\n+    public Write withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Write withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Write withNoOfElementsToBatch(int noOfElementsToBatch) {\n+      return builder().setNoOfElementsToBatch(noOfElementsToBatch).build();\n+    }\n+\n+    public Write withFlushDuration(int flushDuration) {\n+      return builder().setFlushDuration(flushDuration).build();\n+    }\n+\n+    public Write withRetentionPolicy(String rp) {\n+      return builder().setRetentionPolicy(rp).build();\n+    }\n+\n+    private class InfluxWriterFn<T> extends DoFn<T, Void> {\n+\n+      private final Write spec;\n+      private InfluxDB connection;\n+\n+      InfluxWriterFn(Write write) {\n+        this.spec = write;\n+      }\n+\n+      @Setup\n+      public void setup() {\n+        connection =\n+            getConnection(\n+                spec.dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled());\n+        int flushDuration = spec.flushDuration();\n+        int noOfBatchPoints = spec.noOfElementsToBatch();\n+        connection.enableBatch(\n+            BatchOptions.DEFAULTS.actions(noOfBatchPoints).flushDuration(flushDuration));\n+        connection.setRetentionPolicy(spec.retentionPolicy());\n+        connection.setDatabase(spec.database());\n+      }\n+\n+      @ProcessElement\n+      public void processElement(ProcessContext c) {\n+        connection.write(c.element().toString());\n+      }\n+\n+      @FinishBundle\n+      public void finishBundle() {\n+        connection.flush();\n+      }\n+\n+      @Teardown\n+      public void tearDown() {\n+        if (connection != null) {\n+          connection.flush();\n+          connection.close();\n+          connection = null;\n+        }\n+      }\n+\n+      @Override\n+      public void populateDisplayData(DisplayData.Builder builder) {\n+        builder.delegate(Write.this);\n+      }\n+    }\n+  }\n+\n+  private static OkHttpClient.Builder getUnsafeOkHttpClient() {\n+    try {\n+      // Create a trust manager that does not validate certificate chains\n+      final TrustManager[] trustAllCerts =\n+          new TrustManager[] {\n+            new X509TrustManager() {\n+              @Override\n+              public void checkClientTrusted(\n+                  java.security.cert.X509Certificate[] chain, String authType) {}\n+\n+              @Override\n+              public void checkServerTrusted(\n+                  java.security.cert.X509Certificate[] chain, String authType) {}\n+\n+              @Override\n+              public java.security.cert.X509Certificate[] getAcceptedIssuers() {\n+                return new java.security.cert.X509Certificate[] {};\n+              }\n+            }\n+          };\n+\n+      // Install the all-trusting trust manager\n+      final SSLContext sslContext = SSLContext.getInstance(\"SSL\");\n+      sslContext.init(null, trustAllCerts, new java.security.SecureRandom());\n+      // Create an ssl socket factory with our all-trusting manager\n+      final SSLSocketFactory sslSocketFactory = sslContext.getSocketFactory();\n+\n+      OkHttpClient.Builder builder = new OkHttpClient.Builder();\n+      builder.sslSocketFactory(sslSocketFactory, (X509TrustManager) trustAllCerts[0]);\n+      builder.hostnameVerifier((hostname, session) -> true);\n+      return builder;\n+    } catch (Exception e) {\n+      throw new RuntimeException(e);\n+    }\n+  }\n+  /** A POJO describing a DataSourceConfiguration such as URL, userName and password. */\n+  @AutoValue\n+  public abstract static class DataSourceConfiguration implements Serializable {\n+\n+    @Nullable\n+    abstract ValueProvider<String> url();\n+\n+    @Nullable\n+    abstract ValueProvider<String> userName();\n+\n+    @Nullable\n+    abstract ValueProvider<String> password();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+\n+      abstract Builder setUrl(ValueProvider<String> url);\n+\n+      abstract Builder setUserName(ValueProvider<String> userName);\n+\n+      abstract Builder setPassword(ValueProvider<String> password);\n+\n+      abstract DataSourceConfiguration build();\n+    }\n+\n+    public static DataSourceConfiguration create(String url, String userName, String password) {\n+      checkArgument(url != null, \"url can not be null\");\n+      checkArgument(userName != null, \"userName can not be null\");\n+      checkArgument(password != null, \"password can not be null\");\n+\n+      return create(\n+          ValueProvider.StaticValueProvider.of(url),\n+          ValueProvider.StaticValueProvider.of(userName),\n+          ValueProvider.StaticValueProvider.of(password));\n+    }\n+\n+    public static DataSourceConfiguration create(\n+        ValueProvider<String> url, ValueProvider<String> userName, ValueProvider<String> password) {\n+      checkArgument(url != null, \"url can not be null\");\n+      checkArgument(userName != null, \"userName can not be null\");\n+      checkArgument(password != null, \"password can not be null\");\n+\n+      return new AutoValue_InfluxDBIO_DataSourceConfiguration.Builder()\n+          .setUrl(url)\n+          .setUserName(userName)\n+          .setPassword(password)\n+          .build();\n+    }\n+\n+    public DataSourceConfiguration withUsername(String userName) {\n+      return withUsername(ValueProvider.StaticValueProvider.of(userName));\n+    }\n+\n+    public DataSourceConfiguration withUsername(ValueProvider<String> userName) {\n+      return builder().setUserName(userName).build();\n+    }\n+\n+    public DataSourceConfiguration withPassword(String password) {\n+      return withPassword(ValueProvider.StaticValueProvider.of(password));\n+    }\n+\n+    public DataSourceConfiguration withPassword(ValueProvider<String> password) {\n+      return builder().setPassword(password).build();\n+    }\n+\n+    public DataSourceConfiguration withUrl(String url) {\n+      return withPassword(ValueProvider.StaticValueProvider.of(url));\n+    }\n+\n+    public DataSourceConfiguration withUrl(ValueProvider<String> url) {\n+      return builder().setPassword(url).build();\n+    }\n+\n+    void populateDisplayData(DisplayData.Builder builder) {\n+\n+      builder.addIfNotNull(DisplayData.item(\"url\", url()));\n+      builder.addIfNotNull(DisplayData.item(\"userName\", userName()));\n+      builder.addIfNotNull(DisplayData.item(\"password\", password()));\n+    }\n+  }\n+\n+  private static class DataSourceProviderFromDataSourceConfiguration\n+      implements SerializableFunction<Void, DataSourceConfiguration>, HasDisplayData {\n+    private final DataSourceConfiguration config;\n+    private static DataSourceProviderFromDataSourceConfiguration instance;\n+\n+    private DataSourceProviderFromDataSourceConfiguration(DataSourceConfiguration config) {\n+      this.config = config;\n+    }\n+\n+    public static SerializableFunction<Void, DataSourceConfiguration> of(\n+        DataSourceConfiguration config) {\n+      if (instance == null) {\n+        instance = new DataSourceProviderFromDataSourceConfiguration(config);\n+      }\n+      return instance;\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      config.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public DataSourceConfiguration apply(Void input) {\n+      return config;\n+    }\n+  }\n+\n+  private static List<ShardInformation> getDBShardedInformation(\n+      String database,\n+      DataSourceConfiguration configuration,\n+      boolean sslInvalidHostNameAllowed,\n+      boolean sslEnabled) {\n+    String query = \"show shards\";\n+    DBShardInformation dbInfo = new DBShardInformation();\n+    try (InfluxDB connection =\n+        getConnection(configuration, sslInvalidHostNameAllowed, sslEnabled)) {\n+      QueryResult result = connection.query(new Query(query));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7907afb2eeb4f89fe5135fd64aa6e9e2c58c995b"}, "originalPosition": 777}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NzY5MTAyOnYy", "diffSide": "RIGHT", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/DBShardInformation.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxNToyMTozOFrOGzXNQw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxNToyMTozOFrOGzXNQw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjUxMDc4Nw==", "bodyText": "Please, add Javadoc to this class.", "url": "https://github.com/apache/beam/pull/11459#discussion_r456510787", "createdAt": "2020-07-17T15:21:38Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/DBShardInformation.java", "diffHunk": "@@ -0,0 +1,48 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.influxdb.dto.QueryResult.Series;\n+\n+class DBShardInformation {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1670ecb173d554f58e250265484e6a89ab23a5b9"}, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NzY5ODEwOnYy", "diffSide": "RIGHT", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/ShardInformation.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxNToyMzozMFrOGzXRlQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxNToyMzozMFrOGzXRlQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjUxMTg5Mw==", "bodyText": "Please, add class Javadoc", "url": "https://github.com/apache/beam/pull/11459#discussion_r456511893", "createdAt": "2020-07-17T15:23:30Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/ShardInformation.java", "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import java.util.List;\n+import java.util.Objects;\n+import org.joda.time.DateTime;\n+\n+class ShardInformation implements Comparable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1670ecb173d554f58e250265484e6a89ab23a5b9"}, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0Nzc5ODM3OnYy", "diffSide": "RIGHT", "path": "buildSrc/src/main/groovy/org/apache/beam/gradle/BeamModulePlugin.groovy", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxNTo1MToyNlrOGzYPvw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxNTo1MToyNlrOGzYPvw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjUyNzgwNw==", "bodyText": "The latest version is 2.19. Could you bump it?", "url": "https://github.com/apache/beam/pull/11459#discussion_r456527807", "createdAt": "2020-07-17T15:51:26Z", "author": {"login": "aromanenko-dev"}, "path": "buildSrc/src/main/groovy/org/apache/beam/gradle/BeamModulePlugin.groovy", "diffHunk": "@@ -387,6 +387,7 @@ class BeamModulePlugin implements Plugin<Project> {\n     def guava_version = \"25.1-jre\"\n     def hadoop_version = \"2.8.5\"\n     def hamcrest_version = \"2.1\"\n+    def influxdb_version = \"2.17\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1670ecb173d554f58e250265484e6a89ab23a5b9"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0NzgzMTYyOnYy", "diffSide": "RIGHT", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxNjowMToyNFrOGzYlZw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxNjowMToyNFrOGzYlZw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjUzMzM1MQ==", "bodyText": "I believe it would be better to provide for user a way to create custom client with ClientProvider implementation (see KinesisIO.Read withAWSClientsProvider(AWSClientsProvider), for example).", "url": "https://github.com/apache/beam/pull/11459#discussion_r456533351", "createdAt": "2020-07-17T16:01:24Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,830 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>You have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database. InfluxDB line protocol reference\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDbIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDbIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDbIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNumOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDbIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkState(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1670ecb173d554f58e250265484e6a89ab23a5b9"}, "originalPosition": 246}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0Nzg0ODIwOnYy", "diffSide": "RIGHT", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxNjowNjoxMVrOGzYvqg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxNjowNjoxMVrOGzYvqg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjUzNTk3OA==", "bodyText": "Does it just put a record into output queue when it will be flushed later?", "url": "https://github.com/apache/beam/pull/11459#discussion_r456535978", "createdAt": "2020-07-17T16:06:11Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,830 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>You have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database. InfluxDB line protocol reference\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDbIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDbIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDbIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNumOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDbIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkState(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkState(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkState(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkState(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String numOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> numOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(numOfBlocks)) {\n+                numOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> numOfBlocksValueIterator = numOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueIterator = sizeOfBlocksValue.iterator();\n+      long size = 0;\n+      while (numOfBlocksValueIterator.hasNext() && sizeOfBlocksValueIterator.hasNext()) {\n+        size = size + (numOfBlocksValueIterator.next() * sizeOfBlocksValueIterator.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(),\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          if (sInfo.getStartTime().compareTo(spec.startDateTime()) > 0) {\n+            sources.add(\n+                new InfluxDBSource(\n+                    spec.withMetrics(spec.metrics())\n+                        .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                        .withToDateTime(sInfo.getStartTime())\n+                        .withFromDateTime(sInfo.getEndTime())));\n+          }\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    if (spec.query() == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        String retVal =\n+            String.format(\n+                \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+                spec.retentionPolicy(),\n+                String.join(\",\", spec.metrics()),\n+                spec.toDateTime(),\n+                spec.fromDateTime());\n+        return retVal;\n+      } else {\n+        return String.format(\n+            \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+      }\n+    }\n+    return spec.query();\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDbIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List current;\n+\n+    public BoundedInfluxDbReader(InfluxDbIO.InfluxDBSource source) {\n+      this.source = source;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDbIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        if (spec.database() != null) {\n+          influxDB.setDatabase(spec.database());\n+        }\n+        if (spec.retentionPolicy() != null) {\n+          influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        }\n+        String query = getQueryToRun(spec);\n+        QueryResult queryResult = influxDB.query(new Query(query, spec.database()));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          seriesIterator = resultIterator.next().getSeries().iterator();\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkState(dataSourceConfiguration() != null, \"withConfiguration() is required\");\n+      checkState(database() != null && !database().isEmpty(), \"withDatabase() is required\");\n+      checkState(\n+          checkDatabase(\n+              database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+      builder.addIfNotNull(DisplayData.item(\"numOfElementsToBatch\", numOfElementsToBatch()));\n+      builder.addIfNotNull(DisplayData.item(\"flushDuration\", flushDuration()));\n+    }\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String retentionPolicy();\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract boolean sslEnabled();\n+\n+    abstract int numOfElementsToBatch();\n+\n+    abstract int flushDuration();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setNumOfElementsToBatch(int numOfElementsToBatch);\n+\n+      abstract Builder setFlushDuration(int flushDuration);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Write build();\n+    }\n+\n+    public Write withConfiguration(DataSourceConfiguration configuration) {\n+      checkState(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    public Write withDatabase(String database) {\n+      return builder().setDatabase(database).build();\n+    }\n+\n+    public Write withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Write withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Write withNumOfElementsToBatch(int numOfElementsToBatch) {\n+      return builder().setNumOfElementsToBatch(numOfElementsToBatch).build();\n+    }\n+\n+    public Write withFlushDuration(int flushDuration) {\n+      return builder().setFlushDuration(flushDuration).build();\n+    }\n+\n+    public Write withRetentionPolicy(String rp) {\n+      return builder().setRetentionPolicy(rp).build();\n+    }\n+\n+    private class InfluxWriterFn extends DoFn<String, Void> {\n+\n+      private final Write spec;\n+      private transient InfluxDB connection;\n+\n+      InfluxWriterFn(Write write) {\n+        this.spec = write;\n+      }\n+\n+      @Setup\n+      public void setup() {\n+        connection =\n+            getConnection(\n+                spec.dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled());\n+        int flushDuration = spec.flushDuration();\n+        int numOfBatchPoints = spec.numOfElementsToBatch();\n+        connection.enableBatch(\n+            BatchOptions.DEFAULTS.actions(numOfBatchPoints).flushDuration(flushDuration));\n+        connection.setRetentionPolicy(spec.retentionPolicy());\n+        connection.setDatabase(spec.database());\n+      }\n+\n+      @ProcessElement\n+      public void processElement(ProcessContext c) {\n+        connection.write(c.element());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1670ecb173d554f58e250265484e6a89ab23a5b9"}, "originalPosition": 599}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0Nzg1MDMzOnYy", "diffSide": "RIGHT", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxNjowNjo1NFrOGzYxCg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QxNjowNjo1NFrOGzYxCg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjUzNjMzMA==", "bodyText": "Does it guarantee that all records were flushed properly?", "url": "https://github.com/apache/beam/pull/11459#discussion_r456536330", "createdAt": "2020-07-17T16:06:54Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDBIO.java", "diffHunk": "@@ -0,0 +1,830 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+import static org.influxdb.BatchOptions.DEFAULT_BATCH_INTERVAL_DURATION;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.annotation.Nullable;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.transforms.display.HasDisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.influxdb.BatchOptions;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.joda.time.DateTime;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write to InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDBIO {@link #read()} returns a bounded collection of {@code String} as a {@code\n+ * PCollection<String>}.\n+ *\n+ * <p>You have to provide a {@link DataSourceConfiguration} using<br>\n+ * {@link DataSourceConfiguration#create(String, String, String)}(url, userName and password).\n+ * Optionally, {@link DataSourceConfiguration#withUsername(String)} and {@link\n+ * DataSourceConfiguration#withPassword(String)} allows you to define userName and password.\n+ *\n+ * <p>For example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <p>Read with query example:\n+ *\n+ * <pre>{@code\n+ * PCollection<String> collection = pipeline.apply(InfluxDBIO.read()\n+ *   .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *          \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withDatabase(\"metrics\")\n+ *   .withQuery(\"SELECT * FROM CPU\")\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ * }</pre>\n+ *\n+ * <h3>Writing to InfluxDB </h3>\n+ *\n+ * <p>InfluxDB sink supports writing records into a database. It writes a {@link PCollection} to the\n+ * database. InfluxDB line protocol reference\n+ *\n+ * <p>Like the {@link #read()}, to configure the {@link #write()}, you have to provide a {@link\n+ * DataSourceConfiguration}.\n+ *\n+ * <pre>{@code\n+ * pipeline\n+ *   .apply(...)\n+ *   .apply(InfluxDb.write()\n+ *      .withDataSourceConfiguration(InfluxDBIO.DataSourceConfiguration.create(\n+ *            \"https://localhost:8086\",\"userName\",\"password\"))\n+ *   .withRetentionPolicy(\"autogen\")\n+ *   .withDatabase(\"metrics\")\n+ *   .withSslInvalidHostNameAllowed(true)\n+ *   .withSslEnabled(true));\n+ *    );\n+ * }</pre>\n+ *\n+ * *\n+ */\n+@Experimental(Experimental.Kind.SOURCE_SINK)\n+public class InfluxDbIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDbIO.class);\n+\n+  public static Write write() {\n+    return new AutoValue_InfluxDbIO_Write.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setFlushDuration(DEFAULT_BATCH_INTERVAL_DURATION)\n+        .setNumOfElementsToBatch(DEFAULT_BUFFER_LIMIT)\n+        .build();\n+  }\n+\n+  public static Read read() {\n+    return new AutoValue_InfluxDbIO_Read.Builder()\n+        .setSslEnabled(false)\n+        .setSslInvalidHostNameAllowed(false)\n+        .setStartDateTime(DateTime.parse(\"1677-09-21T00:12:43.145224194Z\"))\n+        .setEndDateTime(DateTime.parse(\"2262-04-11T23:47:16.854775806Z\"))\n+        .setRetentionPolicy(\"autogen\")\n+        .build();\n+  }\n+\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract String retentionPolicy();\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String query();\n+\n+    abstract boolean sslEnabled();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    @Nullable\n+    abstract List<String> metrics();\n+\n+    abstract DateTime startDateTime();\n+\n+    abstract DateTime endDateTime();\n+\n+    @Nullable\n+    abstract DateTime fromDateTime();\n+\n+    @Nullable\n+    abstract DateTime toDateTime();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(DateTime toDateTime);\n+\n+      abstract Builder setFromDateTime(DateTime fromDateTime);\n+\n+      abstract Builder setStartDateTime(DateTime startDateTime);\n+\n+      abstract Builder setEndDateTime(DateTime endDateTime);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setMetrics(List<String> metrics);\n+\n+      abstract Read build();\n+    }\n+\n+    /** Reads from the InfluxDB instance indicated by the given configuration. */\n+    public Read withDataSourceConfiguration(DataSourceConfiguration configuration) {\n+      checkState(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    /** Reads from the specified database. */\n+    public Read withDatabase(String database) {\n+      return builder()\n+          .setDatabase(database)\n+          .setDataSourceConfiguration(dataSourceConfiguration())\n+          .build();\n+    }\n+\n+    public Read withToDateTime(DateTime toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+\n+    public Read withFromDateTime(DateTime fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+\n+    public Read withStartDateTime(DateTime startDateTime) {\n+      return builder().setStartDateTime(startDateTime).build();\n+    }\n+\n+    public Read withEndDateTime(DateTime endDateTime) {\n+      return builder().setEndDateTime(endDateTime).build();\n+    }\n+\n+    public Read withMetrics(List<String> metrics) {\n+      return builder().setMetrics(metrics).build();\n+    }\n+\n+    public Read withMetrics(String... metrics) {\n+      return withMetrics(Arrays.asList(metrics));\n+    }\n+\n+    public Read withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Read withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      checkState(dataSourceConfiguration() != null, \"configuration is required\");\n+      checkState(query() != null || database() != null, \"database or query is required\");\n+      if (database() != null) {\n+        checkState(\n+            checkDatabase(\n+                database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+            \"Database %s does not exist\",\n+            database());\n+      }\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+    }\n+  }\n+\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String numOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> numOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        String query = spec.query();\n+        if (query == null) {\n+          query =\n+              String.format(\n+                  \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+        }\n+        QueryResult result = connection.query(new Query(query, spec.database()));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(numOfBlocks)) {\n+                numOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> numOfBlocksValueIterator = numOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueIterator = sizeOfBlocksValue.iterator();\n+      long size = 0;\n+      while (numOfBlocksValueIterator.hasNext() && sizeOfBlocksValueIterator.hasNext()) {\n+        size = size + (numOfBlocksValueIterator.next() * sizeOfBlocksValueIterator.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(),\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          if (sInfo.getStartTime().compareTo(spec.startDateTime()) > 0) {\n+            sources.add(\n+                new InfluxDBSource(\n+                    spec.withMetrics(spec.metrics())\n+                        .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                        .withToDateTime(sInfo.getStartTime())\n+                        .withFromDateTime(sInfo.getEndTime())));\n+          }\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    if (spec.query() == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        String retVal =\n+            String.format(\n+                \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+                spec.retentionPolicy(),\n+                String.join(\",\", spec.metrics()),\n+                spec.toDateTime(),\n+                spec.fromDateTime());\n+        return retVal;\n+      } else {\n+        return String.format(\n+            \"SELECT * FROM %s.%s\", spec.retentionPolicy(), String.join(\",\", spec.metrics()));\n+      }\n+    }\n+    return spec.query();\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDbIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List current;\n+\n+    public BoundedInfluxDbReader(InfluxDbIO.InfluxDBSource source) {\n+      this.source = source;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDbIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(\n+              spec.dataSourceConfiguration(),\n+              spec.sslInvalidHostNameAllowed(),\n+              spec.sslEnabled())) {\n+        if (spec.database() != null) {\n+          influxDB.setDatabase(spec.database());\n+        }\n+        if (spec.retentionPolicy() != null) {\n+          influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        }\n+        String query = getQueryToRun(spec);\n+        QueryResult queryResult = influxDB.query(new Query(query, spec.database()));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          seriesIterator = resultIterator.next().getSeries().iterator();\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkState(dataSourceConfiguration() != null, \"withConfiguration() is required\");\n+      checkState(database() != null && !database().isEmpty(), \"withDatabase() is required\");\n+      checkState(\n+          checkDatabase(\n+              database(), dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"sslEnabled\", sslEnabled()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"sslInvalidHostNameAllowed\", sslInvalidHostNameAllowed()));\n+      builder.addIfNotNull(DisplayData.item(\"numOfElementsToBatch\", numOfElementsToBatch()));\n+      builder.addIfNotNull(DisplayData.item(\"flushDuration\", flushDuration()));\n+    }\n+\n+    @Nullable\n+    abstract String database();\n+\n+    @Nullable\n+    abstract String retentionPolicy();\n+\n+    abstract boolean sslInvalidHostNameAllowed();\n+\n+    abstract boolean sslEnabled();\n+\n+    abstract int numOfElementsToBatch();\n+\n+    abstract int flushDuration();\n+\n+    @Nullable\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setSslInvalidHostNameAllowed(boolean value);\n+\n+      abstract Builder setNumOfElementsToBatch(int numOfElementsToBatch);\n+\n+      abstract Builder setFlushDuration(int flushDuration);\n+\n+      abstract Builder setSslEnabled(boolean sslEnabled);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Write build();\n+    }\n+\n+    public Write withConfiguration(DataSourceConfiguration configuration) {\n+      checkState(configuration != null, \"configuration can not be null\");\n+      return builder().setDataSourceConfiguration(configuration).build();\n+    }\n+\n+    public Write withDatabase(String database) {\n+      return builder().setDatabase(database).build();\n+    }\n+\n+    public Write withSslEnabled(boolean sslEnabled) {\n+      return builder().setSslEnabled(sslEnabled).build();\n+    }\n+\n+    public Write withSslInvalidHostNameAllowed(boolean value) {\n+      return builder().setSslInvalidHostNameAllowed(value).build();\n+    }\n+\n+    public Write withNumOfElementsToBatch(int numOfElementsToBatch) {\n+      return builder().setNumOfElementsToBatch(numOfElementsToBatch).build();\n+    }\n+\n+    public Write withFlushDuration(int flushDuration) {\n+      return builder().setFlushDuration(flushDuration).build();\n+    }\n+\n+    public Write withRetentionPolicy(String rp) {\n+      return builder().setRetentionPolicy(rp).build();\n+    }\n+\n+    private class InfluxWriterFn extends DoFn<String, Void> {\n+\n+      private final Write spec;\n+      private transient InfluxDB connection;\n+\n+      InfluxWriterFn(Write write) {\n+        this.spec = write;\n+      }\n+\n+      @Setup\n+      public void setup() {\n+        connection =\n+            getConnection(\n+                spec.dataSourceConfiguration(), sslInvalidHostNameAllowed(), sslEnabled());\n+        int flushDuration = spec.flushDuration();\n+        int numOfBatchPoints = spec.numOfElementsToBatch();\n+        connection.enableBatch(\n+            BatchOptions.DEFAULTS.actions(numOfBatchPoints).flushDuration(flushDuration));\n+        connection.setRetentionPolicy(spec.retentionPolicy());\n+        connection.setDatabase(spec.database());\n+      }\n+\n+      @ProcessElement\n+      public void processElement(ProcessContext c) {\n+        connection.write(c.element());\n+      }\n+\n+      @FinishBundle\n+      public void finishBundle() {\n+        connection.flush();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1670ecb173d554f58e250265484e6a89ab23a5b9"}, "originalPosition": 604}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAzMzYwMjMzOnYy", "diffSide": "RIGHT", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDbIO.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxNTo0MTozOVrOHOjNVw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMVQxNjo0MDozMVrOHVZg9A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTAxODk2Nw==", "bodyText": "nit: InfluxDbIO.read()", "url": "https://github.com/apache/beam/pull/11459#discussion_r485018967", "createdAt": "2020-09-08T15:41:39Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDbIO.java", "diffHunk": "@@ -0,0 +1,662 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.annotations.Experimental.Kind;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.options.ValueProvider.StaticValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.checkerframework.checker.nullness.qual.Nullable;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDB.ConsistencyLevel;\n+import org.influxdb.InfluxDBException;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write from InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDB return a bounded collection of String as {@code PCollection<String>}. The String\n+ * follows the line protocol\n+ * (https://docs.influxdata.com/influxdb/v1.8/write_protocols/line_protocol_tutorial/). To Configure\n+ * the InfluxDB source, you whave to provide the connection URL, the credentials to connect to\n+ * InfluxDB and the Database name\n+ *\n+ * <pre>{@code\n+ *  pipeline.apply(\n+ *    InfluxDB.read(\"https://influxdb\", \"userName\", \"password\", \"database\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fada15c2d1a3fe10b3d9e3ba54820a4533c831f2"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjIwMDE4MA==", "bodyText": "Still not fixed, missing an \"IO\" suffix in the \"InfluxDB\" - it has to be InfluxDbIO", "url": "https://github.com/apache/beam/pull/11459#discussion_r492200180", "createdAt": "2020-09-21T16:40:31Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDbIO.java", "diffHunk": "@@ -0,0 +1,662 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.annotations.Experimental.Kind;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.options.ValueProvider.StaticValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.checkerframework.checker.nullness.qual.Nullable;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDB.ConsistencyLevel;\n+import org.influxdb.InfluxDBException;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write from InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDB return a bounded collection of String as {@code PCollection<String>}. The String\n+ * follows the line protocol\n+ * (https://docs.influxdata.com/influxdb/v1.8/write_protocols/line_protocol_tutorial/). To Configure\n+ * the InfluxDB source, you whave to provide the connection URL, the credentials to connect to\n+ * InfluxDB and the Database name\n+ *\n+ * <pre>{@code\n+ *  pipeline.apply(\n+ *    InfluxDB.read(\"https://influxdb\", \"userName\", \"password\", \"database\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTAxODk2Nw=="}, "originalCommit": {"oid": "fada15c2d1a3fe10b3d9e3ba54820a4533c831f2"}, "originalPosition": 75}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAzMzYwMzY1OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDbIO.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxNTo0MTo1NFrOHOjOGA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMVQxNjo0MDo1NVrOHVZh7g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTAxOTE2MA==", "bodyText": "nit: InfluxDbIO.write()", "url": "https://github.com/apache/beam/pull/11459#discussion_r485019160", "createdAt": "2020-09-08T15:41:54Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDbIO.java", "diffHunk": "@@ -0,0 +1,662 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.annotations.Experimental.Kind;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.options.ValueProvider.StaticValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.checkerframework.checker.nullness.qual.Nullable;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDB.ConsistencyLevel;\n+import org.influxdb.InfluxDBException;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write from InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDB return a bounded collection of String as {@code PCollection<String>}. The String\n+ * follows the line protocol\n+ * (https://docs.influxdata.com/influxdb/v1.8/write_protocols/line_protocol_tutorial/). To Configure\n+ * the InfluxDB source, you whave to provide the connection URL, the credentials to connect to\n+ * InfluxDB and the Database name\n+ *\n+ * <pre>{@code\n+ *  pipeline.apply(\n+ *    InfluxDB.read(\"https://influxdb\", \"userName\", \"password\", \"database\")\n+ *      .withQuery(\"select * from metric\");\n+ *      //Reads data based on the query from the InfluxDB\n+ * }\n+ *\n+ * <p> The source also accepts optional configuration: {@code withRetentionPolicy()}  an</p>\n+ *\n+ *\n+ * <h3>Writing to InfluxDB</h3>\n+ *\n+ * <p>InfluxDB sink supports writing data (as line protocol)  to InfluxDB\n+ * To configure a InfluxDB sink, you must specify a URL {@code InfluxDBURL}, {@code userName}, {@code password}, {@code database}\n+ * <pre>{@code\n+ * pipeleine\n+ *    .apply(...)\n+ *    .appply(InfluxDB.write(https://influxdb\", \"userName\", \"password\", \"database\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fada15c2d1a3fe10b3d9e3ba54820a4533c831f2"}, "originalPosition": 90}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjIwMDQzMA==", "bodyText": "The same - missing an \"IO\" suffix in the \"InfluxDB\" - it has to be InfluxDbIO", "url": "https://github.com/apache/beam/pull/11459#discussion_r492200430", "createdAt": "2020-09-21T16:40:55Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDbIO.java", "diffHunk": "@@ -0,0 +1,662 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.annotations.Experimental.Kind;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.options.ValueProvider.StaticValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.checkerframework.checker.nullness.qual.Nullable;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDB.ConsistencyLevel;\n+import org.influxdb.InfluxDBException;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write from InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDB return a bounded collection of String as {@code PCollection<String>}. The String\n+ * follows the line protocol\n+ * (https://docs.influxdata.com/influxdb/v1.8/write_protocols/line_protocol_tutorial/). To Configure\n+ * the InfluxDB source, you whave to provide the connection URL, the credentials to connect to\n+ * InfluxDB and the Database name\n+ *\n+ * <pre>{@code\n+ *  pipeline.apply(\n+ *    InfluxDB.read(\"https://influxdb\", \"userName\", \"password\", \"database\")\n+ *      .withQuery(\"select * from metric\");\n+ *      //Reads data based on the query from the InfluxDB\n+ * }\n+ *\n+ * <p> The source also accepts optional configuration: {@code withRetentionPolicy()}  an</p>\n+ *\n+ *\n+ * <h3>Writing to InfluxDB</h3>\n+ *\n+ * <p>InfluxDB sink supports writing data (as line protocol)  to InfluxDB\n+ * To configure a InfluxDB sink, you must specify a URL {@code InfluxDBURL}, {@code userName}, {@code password}, {@code database}\n+ * <pre>{@code\n+ * pipeleine\n+ *    .apply(...)\n+ *    .appply(InfluxDB.write(https://influxdb\", \"userName\", \"password\", \"database\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTAxOTE2MA=="}, "originalCommit": {"oid": "fada15c2d1a3fe10b3d9e3ba54820a4533c831f2"}, "originalPosition": 90}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAzMzYxNzc3OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDbIO.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxNTo0NToxOFrOHOjWzA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxNTo0NToxOFrOHOjWzA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTAyMTM4OA==", "bodyText": "nit: DEFAULT_RETENTION_POLICY since it's a constant string", "url": "https://github.com/apache/beam/pull/11459#discussion_r485021388", "createdAt": "2020-09-08T15:45:18Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDbIO.java", "diffHunk": "@@ -0,0 +1,662 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.annotations.Experimental.Kind;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.options.ValueProvider.StaticValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.checkerframework.checker.nullness.qual.Nullable;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDB.ConsistencyLevel;\n+import org.influxdb.InfluxDBException;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write from InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDB return a bounded collection of String as {@code PCollection<String>}. The String\n+ * follows the line protocol\n+ * (https://docs.influxdata.com/influxdb/v1.8/write_protocols/line_protocol_tutorial/). To Configure\n+ * the InfluxDB source, you whave to provide the connection URL, the credentials to connect to\n+ * InfluxDB and the Database name\n+ *\n+ * <pre>{@code\n+ *  pipeline.apply(\n+ *    InfluxDB.read(\"https://influxdb\", \"userName\", \"password\", \"database\")\n+ *      .withQuery(\"select * from metric\");\n+ *      //Reads data based on the query from the InfluxDB\n+ * }\n+ *\n+ * <p> The source also accepts optional configuration: {@code withRetentionPolicy()}  an</p>\n+ *\n+ *\n+ * <h3>Writing to InfluxDB</h3>\n+ *\n+ * <p>InfluxDB sink supports writing data (as line protocol)  to InfluxDB\n+ * To configure a InfluxDB sink, you must specify a URL {@code InfluxDBURL}, {@code userName}, {@code password}, {@code database}\n+ * <pre>{@code\n+ * pipeleine\n+ *    .apply(...)\n+ *    .appply(InfluxDB.write(https://influxdb\", \"userName\", \"password\", \"database\")\n+ *\n+ * }\n+ * </pre>\n+ * </pre>\n+ */\n+@Experimental(Kind.SOURCE_SINK)\n+public class InfluxDbIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDbIO.class);\n+\n+  private static final String defaultRetentionPolicy = \"autogen\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fada15c2d1a3fe10b3d9e3ba54820a4533c831f2"}, "originalPosition": 100}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAzMzYyNDE3OnYy", "diffSide": "RIGHT", "path": ".test-infra/kubernetes/influxdb/influxdb.yml", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxNTo0Njo1MVrOHOjaxg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QxNDozNDoyOVrOHTlXFw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTAyMjQwNg==", "bodyText": "Are these real or fake credentials?", "url": "https://github.com/apache/beam/pull/11459#discussion_r485022406", "createdAt": "2020-09-08T15:46:51Z", "author": {"login": "aromanenko-dev"}, "path": ".test-infra/kubernetes/influxdb/influxdb.yml", "diffHunk": "@@ -0,0 +1,76 @@\n+#    Licensed to the Apache Software Foundation (ASF) under one or more\n+#    contributor license agreements.  See the NOTICE file distributed with\n+#    this work for additional information regarding copyright ownership.\n+#    The ASF licenses this file to You under the Apache License, Version 2.0\n+#    (the \"License\"); you may not use this file except in compliance with\n+#    the License.  You may obtain a copy of the License at\n+#\n+#       http://www.apache.org/licenses/LICENSE-2.0\n+#\n+#    Unless required by applicable law or agreed to in writing, software\n+#    distributed under the License is distributed on an \"AS IS\" BASIS,\n+#    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+#    See the License for the specific language governing permissions and\n+#    limitations under the License.\n+\n+apiVersion: v1\n+kind: Secret\n+metadata:\n+  name: influxdb-creds\n+data:\n+  INFLUXDB_USER: c3VwZXJzYWRtaW4=\n+  INFLUXDB_USER_PASSWORD: c3VwZXJzZWNyZXRwYXNzd29yZA==", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fada15c2d1a3fe10b3d9e3ba54820a4533c831f2"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDI5NzExMQ==", "bodyText": "Base64 encoded values for credentials. It is used to instantiate the container and used to test integration test.", "url": "https://github.com/apache/beam/pull/11459#discussion_r490297111", "createdAt": "2020-09-17T14:34:29Z", "author": {"login": "bipinupd"}, "path": ".test-infra/kubernetes/influxdb/influxdb.yml", "diffHunk": "@@ -0,0 +1,76 @@\n+#    Licensed to the Apache Software Foundation (ASF) under one or more\n+#    contributor license agreements.  See the NOTICE file distributed with\n+#    this work for additional information regarding copyright ownership.\n+#    The ASF licenses this file to You under the Apache License, Version 2.0\n+#    (the \"License\"); you may not use this file except in compliance with\n+#    the License.  You may obtain a copy of the License at\n+#\n+#       http://www.apache.org/licenses/LICENSE-2.0\n+#\n+#    Unless required by applicable law or agreed to in writing, software\n+#    distributed under the License is distributed on an \"AS IS\" BASIS,\n+#    WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+#    See the License for the specific language governing permissions and\n+#    limitations under the License.\n+\n+apiVersion: v1\n+kind: Secret\n+metadata:\n+  name: influxdb-creds\n+data:\n+  INFLUXDB_USER: c3VwZXJzYWRtaW4=\n+  INFLUXDB_USER_PASSWORD: c3VwZXJzZWNyZXRwYXNzd29yZA==", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTAyMjQwNg=="}, "originalCommit": {"oid": "fada15c2d1a3fe10b3d9e3ba54820a4533c831f2"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAzMzY0Mjk3OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDbIO.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxNTo1MTowN1rOHOjmNw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxNTo1MTowN1rOHOjmNw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTAyNTMzNQ==", "bodyText": "nit: remove  an in the end of the sentence.", "url": "https://github.com/apache/beam/pull/11459#discussion_r485025335", "createdAt": "2020-09-08T15:51:07Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDbIO.java", "diffHunk": "@@ -0,0 +1,662 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.annotations.Experimental.Kind;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.options.ValueProvider.StaticValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.checkerframework.checker.nullness.qual.Nullable;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDB.ConsistencyLevel;\n+import org.influxdb.InfluxDBException;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write from InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDB return a bounded collection of String as {@code PCollection<String>}. The String\n+ * follows the line protocol\n+ * (https://docs.influxdata.com/influxdb/v1.8/write_protocols/line_protocol_tutorial/). To Configure\n+ * the InfluxDB source, you whave to provide the connection URL, the credentials to connect to\n+ * InfluxDB and the Database name\n+ *\n+ * <pre>{@code\n+ *  pipeline.apply(\n+ *    InfluxDB.read(\"https://influxdb\", \"userName\", \"password\", \"database\")\n+ *      .withQuery(\"select * from metric\");\n+ *      //Reads data based on the query from the InfluxDB\n+ * }\n+ *\n+ * <p> The source also accepts optional configuration: {@code withRetentionPolicy()}  an</p>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fada15c2d1a3fe10b3d9e3ba54820a4533c831f2"}, "originalPosition": 80}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAzMzcwMzE2OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDbIO.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxNjowNDo1OVrOHOkKzg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxNjowNDo1OVrOHOkKzg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTAzNDcwMg==", "bodyText": "Please, keep write() method without arguments for consistency with other IOs and add withDataSourceConfiguration(DataSourceConfiguration conf), which will be required to configure data source, and withDatabase(String) to set database name (see JdbcIO.write() as an example).\nSo, for the user it would be something like:\nInfluxDbIO.write().withDataSourceConfiguration(DataSourceConfiguration.create(...)).withDatabase(\"...\");", "url": "https://github.com/apache/beam/pull/11459#discussion_r485034702", "createdAt": "2020-09-08T16:04:59Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDbIO.java", "diffHunk": "@@ -0,0 +1,662 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.annotations.Experimental.Kind;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.options.ValueProvider.StaticValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.checkerframework.checker.nullness.qual.Nullable;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDB.ConsistencyLevel;\n+import org.influxdb.InfluxDBException;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write from InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDB return a bounded collection of String as {@code PCollection<String>}. The String\n+ * follows the line protocol\n+ * (https://docs.influxdata.com/influxdb/v1.8/write_protocols/line_protocol_tutorial/). To Configure\n+ * the InfluxDB source, you whave to provide the connection URL, the credentials to connect to\n+ * InfluxDB and the Database name\n+ *\n+ * <pre>{@code\n+ *  pipeline.apply(\n+ *    InfluxDB.read(\"https://influxdb\", \"userName\", \"password\", \"database\")\n+ *      .withQuery(\"select * from metric\");\n+ *      //Reads data based on the query from the InfluxDB\n+ * }\n+ *\n+ * <p> The source also accepts optional configuration: {@code withRetentionPolicy()}  an</p>\n+ *\n+ *\n+ * <h3>Writing to InfluxDB</h3>\n+ *\n+ * <p>InfluxDB sink supports writing data (as line protocol)  to InfluxDB\n+ * To configure a InfluxDB sink, you must specify a URL {@code InfluxDBURL}, {@code userName}, {@code password}, {@code database}\n+ * <pre>{@code\n+ * pipeleine\n+ *    .apply(...)\n+ *    .appply(InfluxDB.write(https://influxdb\", \"userName\", \"password\", \"database\")\n+ *\n+ * }\n+ * </pre>\n+ * </pre>\n+ */\n+@Experimental(Kind.SOURCE_SINK)\n+public class InfluxDbIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDbIO.class);\n+\n+  private static final String defaultRetentionPolicy = \"autogen\";\n+\n+  /** Disallow construction of utility class. */\n+  private InfluxDbIO() {}\n+\n+  public static Write write(String influxDbUrl, String username, String password, String database) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fada15c2d1a3fe10b3d9e3ba54820a4533c831f2"}, "originalPosition": 105}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAzMzcyMjg0OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDbIO.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxNjowOTo1NFrOHOkW3Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxNjowOTo1NFrOHOkW3Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTAzNzc4OQ==", "bodyText": "The same recommendation as for write() method above - please, make read() without arguments.", "url": "https://github.com/apache/beam/pull/11459#discussion_r485037789", "createdAt": "2020-09-08T16:09:54Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDbIO.java", "diffHunk": "@@ -0,0 +1,662 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.annotations.Experimental.Kind;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.options.ValueProvider.StaticValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.checkerframework.checker.nullness.qual.Nullable;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDB.ConsistencyLevel;\n+import org.influxdb.InfluxDBException;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write from InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDB return a bounded collection of String as {@code PCollection<String>}. The String\n+ * follows the line protocol\n+ * (https://docs.influxdata.com/influxdb/v1.8/write_protocols/line_protocol_tutorial/). To Configure\n+ * the InfluxDB source, you whave to provide the connection URL, the credentials to connect to\n+ * InfluxDB and the Database name\n+ *\n+ * <pre>{@code\n+ *  pipeline.apply(\n+ *    InfluxDB.read(\"https://influxdb\", \"userName\", \"password\", \"database\")\n+ *      .withQuery(\"select * from metric\");\n+ *      //Reads data based on the query from the InfluxDB\n+ * }\n+ *\n+ * <p> The source also accepts optional configuration: {@code withRetentionPolicy()}  an</p>\n+ *\n+ *\n+ * <h3>Writing to InfluxDB</h3>\n+ *\n+ * <p>InfluxDB sink supports writing data (as line protocol)  to InfluxDB\n+ * To configure a InfluxDB sink, you must specify a URL {@code InfluxDBURL}, {@code userName}, {@code password}, {@code database}\n+ * <pre>{@code\n+ * pipeleine\n+ *    .apply(...)\n+ *    .appply(InfluxDB.write(https://influxdb\", \"userName\", \"password\", \"database\")\n+ *\n+ * }\n+ * </pre>\n+ * </pre>\n+ */\n+@Experimental(Kind.SOURCE_SINK)\n+public class InfluxDbIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDbIO.class);\n+\n+  private static final String defaultRetentionPolicy = \"autogen\";\n+\n+  /** Disallow construction of utility class. */\n+  private InfluxDbIO() {}\n+\n+  public static Write write(String influxDbUrl, String username, String password, String database) {\n+    return new AutoValue_InfluxDbIO_Write.Builder()\n+        .setDataSourceConfiguration(\n+            DataSourceConfiguration.create(\n+                StaticValueProvider.of(influxDbUrl),\n+                StaticValueProvider.of(username),\n+                StaticValueProvider.of(password)))\n+        .setDatabase(database)\n+        .setRetentionPolicy(defaultRetentionPolicy)\n+        .setDisableCertificateValidation(false)\n+        .setBatchSize(DEFAULT_BUFFER_LIMIT)\n+        .setConsistencyLevel(ConsistencyLevel.QUORUM)\n+        .build();\n+  }\n+\n+  public static Read read(String influxDbUrl, String username, String password, String database) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fada15c2d1a3fe10b3d9e3ba54820a4533c831f2"}, "originalPosition": 120}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAzMzc0MTAwOnYy", "diffSide": "RIGHT", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDbIO.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxNjoxNDozM1rOHOkiEw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMVQxNjo1MTo0OVrOHVZ7aQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0MDY1OQ==", "bodyText": "Do we really want to display credentials in plain text mode?", "url": "https://github.com/apache/beam/pull/11459#discussion_r485040659", "createdAt": "2020-09-08T16:14:33Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDbIO.java", "diffHunk": "@@ -0,0 +1,662 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.annotations.Experimental.Kind;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.options.ValueProvider.StaticValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.checkerframework.checker.nullness.qual.Nullable;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDB.ConsistencyLevel;\n+import org.influxdb.InfluxDBException;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write from InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDB return a bounded collection of String as {@code PCollection<String>}. The String\n+ * follows the line protocol\n+ * (https://docs.influxdata.com/influxdb/v1.8/write_protocols/line_protocol_tutorial/). To Configure\n+ * the InfluxDB source, you whave to provide the connection URL, the credentials to connect to\n+ * InfluxDB and the Database name\n+ *\n+ * <pre>{@code\n+ *  pipeline.apply(\n+ *    InfluxDB.read(\"https://influxdb\", \"userName\", \"password\", \"database\")\n+ *      .withQuery(\"select * from metric\");\n+ *      //Reads data based on the query from the InfluxDB\n+ * }\n+ *\n+ * <p> The source also accepts optional configuration: {@code withRetentionPolicy()}  an</p>\n+ *\n+ *\n+ * <h3>Writing to InfluxDB</h3>\n+ *\n+ * <p>InfluxDB sink supports writing data (as line protocol)  to InfluxDB\n+ * To configure a InfluxDB sink, you must specify a URL {@code InfluxDBURL}, {@code userName}, {@code password}, {@code database}\n+ * <pre>{@code\n+ * pipeleine\n+ *    .apply(...)\n+ *    .appply(InfluxDB.write(https://influxdb\", \"userName\", \"password\", \"database\")\n+ *\n+ * }\n+ * </pre>\n+ * </pre>\n+ */\n+@Experimental(Kind.SOURCE_SINK)\n+public class InfluxDbIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDbIO.class);\n+\n+  private static final String defaultRetentionPolicy = \"autogen\";\n+\n+  /** Disallow construction of utility class. */\n+  private InfluxDbIO() {}\n+\n+  public static Write write(String influxDbUrl, String username, String password, String database) {\n+    return new AutoValue_InfluxDbIO_Write.Builder()\n+        .setDataSourceConfiguration(\n+            DataSourceConfiguration.create(\n+                StaticValueProvider.of(influxDbUrl),\n+                StaticValueProvider.of(username),\n+                StaticValueProvider.of(password)))\n+        .setDatabase(database)\n+        .setRetentionPolicy(defaultRetentionPolicy)\n+        .setDisableCertificateValidation(false)\n+        .setBatchSize(DEFAULT_BUFFER_LIMIT)\n+        .setConsistencyLevel(ConsistencyLevel.QUORUM)\n+        .build();\n+  }\n+\n+  public static Read read(String influxDbUrl, String username, String password, String database) {\n+    return new AutoValue_InfluxDbIO_Read.Builder()\n+        .setDataSourceConfiguration(\n+            DataSourceConfiguration.create(\n+                StaticValueProvider.of(influxDbUrl),\n+                StaticValueProvider.of(username),\n+                StaticValueProvider.of(password)))\n+        .setDatabase(database)\n+        .setDisableCertificateValidation(false)\n+        .setRetentionPolicy(defaultRetentionPolicy)\n+        .build();\n+  }\n+\n+  ///////////////////////// Read  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n+\n+  /**\n+   * A {@link PTransform} to read from InfluxDB metric or data related to query. See {@link\n+   * InfluxDB} for more information on usage and configuration.\n+   */\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract String retentionPolicy();\n+\n+    abstract String database();\n+\n+    abstract @Nullable String query();\n+\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract @Nullable String metric();\n+\n+    abstract @Nullable String fromDateTime();\n+\n+    abstract @Nullable String toDateTime();\n+\n+    abstract boolean disableCertificateValidation();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(String toDateTime);\n+\n+      public abstract Builder setDisableCertificateValidation(boolean value);\n+\n+      abstract Builder setFromDateTime(String fromDateTime);\n+\n+      abstract Builder setMetric(@Nullable String metric);\n+\n+      abstract Read build();\n+    }\n+    /** Read metric data till the toDateTime. * */\n+    public Read withToDateTime(String toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+    /** Read metric data from the fromDateTime. * */\n+    public Read withFromDateTime(String fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+    /** Sets the metric to use. * */\n+    public Read withMetric(@Nullable String metric) {\n+      return builder().setMetric(metric).build();\n+    }\n+    /** Disable SSL certification validation. * */\n+    public Read withDisableCertificateValidation(boolean disableCertificateValidation) {\n+      return builder().setDisableCertificateValidation(disableCertificateValidation).build();\n+    }\n+    /** Sets the retention policy to use. * */\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+    /** Sets the query to use. * */\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      dataSourceConfiguration().populateDisplayData(builder);\n+      builder.addIfNotNull(DisplayData.item(\"metric\", metric()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"fromDateTime\", fromDateTime()));\n+      builder.addIfNotNull(DisplayData.item(\"toDateTime\", toDateTime()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"disableCertificateValidation\", disableCertificateValidation()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+    }\n+  }\n+  /** A InfluxDb {@link BoundedSource} reading {@link String} from a given instance. */\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String numOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> numOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(spec.dataSourceConfiguration(), spec.disableCertificateValidation())) {\n+        String query = spec.query();\n+        final String db = spec.database();\n+        if (query == null) {\n+          checkState(spec.metric() != null, \"Both query and metrics are empty\");\n+          query = String.format(\"SELECT * FROM %s.%s\", spec.retentionPolicy(), spec.metric());\n+        }\n+        QueryResult result = connection.query(new Query(\"EXPLAIN \" + query, db));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(numOfBlocks)) {\n+                numOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> numOfBlocksValueIterator = numOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueIterator = sizeOfBlocksValue.iterator();\n+      long size = 0L;\n+      while (numOfBlocksValueIterator.hasNext() && sizeOfBlocksValueIterator.hasNext()) {\n+        size = size + (numOfBlocksValueIterator.next() * sizeOfBlocksValueIterator.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) throws Exception {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(), spec.dataSourceConfiguration(), spec.disableCertificateValidation());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      String metric = spec.metric();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          sources.add(\n+              new InfluxDBSource(\n+                  spec.withMetric(metric)\n+                      .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                      .withToDateTime(sInfo.getStartTime())\n+                      .withFromDateTime(sInfo.getEndTime())));\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    String query = spec.query();\n+    if (query == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        String retVal =\n+            String.format(\n+                \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+                spec.retentionPolicy(), spec.metric(), spec.toDateTime(), spec.fromDateTime());\n+        return retVal;\n+      } else {\n+        return String.format(\"SELECT * FROM %s.%s\", spec.retentionPolicy(), spec.metric());\n+      }\n+    } else {\n+      return query;\n+    }\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDbIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List<Object> current;\n+\n+    public BoundedInfluxDbReader(InfluxDbIO.InfluxDBSource source) {\n+      this.source = source;\n+      this.seriesIterator = Collections.emptyIterator();\n+      this.resultIterator = Collections.emptyIterator();\n+      this.valuesIterator = Collections.emptyIterator();\n+      this.current = Collections.EMPTY_LIST;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDbIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(spec.dataSourceConfiguration(), spec.disableCertificateValidation())) {\n+        final String db = spec.database();\n+        influxDB.setDatabase(spec.database());\n+        influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        String query = getQueryToRun(spec);\n+        final QueryResult queryResult = influxDB.query(new Query(query, db));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          Result result = resultIterator.next();\n+          if (result != null && result.getSeries() != null) {\n+            seriesIterator = result.getSeries().iterator();\n+          }\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource<String> getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  /** A {@link PTransform} to write to a InfluxDB datasource. */\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkState(\n+          checkDatabase(database(), dataSourceConfiguration(), disableCertificateValidation()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"batchSize\", batchSize()));\n+      builder.addIfNotNull(DisplayData.item(\"consistencyLevel\", consistencyLevel().value()));\n+    }\n+\n+    abstract String database();\n+\n+    abstract String retentionPolicy();\n+\n+    abstract int batchSize();\n+\n+    abstract boolean disableCertificateValidation();\n+\n+    abstract ConsistencyLevel consistencyLevel();\n+\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setBatchSize(int batchSize);\n+\n+      abstract Builder setConsistencyLevel(ConsistencyLevel consistencyLevel);\n+\n+      public abstract Builder setDisableCertificateValidation(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Write build();\n+    }\n+    /** Number of elements to batch. * */\n+    public Write withBatchSize(int batchSize) {\n+      return builder().setBatchSize(batchSize).build();\n+    }\n+    /** Disable SSL certification validation. * */\n+    public Write withDisableCertificateValidation(boolean disableCertificateValidation) {\n+      return builder().setDisableCertificateValidation(disableCertificateValidation).build();\n+    }\n+    /** Sets the retention policy to use. * */\n+    public Write withRetentionPolicy(String rp) {\n+      return builder().setRetentionPolicy(rp).build();\n+    }\n+    /**\n+     * Sets the consistency level to use. ALL(\"all\") Write succeeds only if write reached all\n+     * cluster members. ANY(\"any\") Write succeeds if write reached at least one cluster members.\n+     * ONE(\"one\") Write succeeds if write reached at least one cluster members. QUORUM(\"quorum\")\n+     * Write succeeds only if write reached a quorum of cluster members.\n+     */\n+    public Write withConsistencyLevel(ConsistencyLevel consistencyLevel) {\n+      return builder().setConsistencyLevel(consistencyLevel).build();\n+    }\n+\n+    static class InfluxWriterFn extends DoFn<String, Void> {\n+\n+      private final Write spec;\n+      private List<String> batch;\n+\n+      InfluxWriterFn(Write write) {\n+        this.spec = write;\n+      }\n+\n+      @StartBundle\n+      public void startBundle() {\n+        batch = new ArrayList<>();\n+      }\n+\n+      @ProcessElement\n+      public void processElement(ProcessContext context) {\n+        batch.add(context.element());\n+        if (batch.size() >= spec.batchSize()) {\n+          flush();\n+        }\n+      }\n+\n+      @FinishBundle\n+      public void finishBundle() {\n+        flush();\n+      }\n+\n+      @Teardown\n+      public void tearDown() {\n+        flush();\n+      }\n+\n+      private void flush() {\n+        if (batch.isEmpty()) {\n+          return;\n+        }\n+        try (InfluxDB connection =\n+            getConnection(spec.dataSourceConfiguration(), spec.disableCertificateValidation())) {\n+          connection.setDatabase(spec.database());\n+          connection.enableBatch();\n+          connection.setConsistency(spec.consistencyLevel());\n+          connection.write(batch);\n+        } catch (InfluxDBException exception) {\n+          throw exception;\n+        }\n+        batch.clear();\n+      }\n+    }\n+  }\n+\n+  /** A POJO describing a DataSourceConfiguration such as URL, userName and password. */\n+  @AutoValue\n+  public abstract static class DataSourceConfiguration implements Serializable {\n+\n+    abstract ValueProvider<String> url();\n+\n+    abstract ValueProvider<String> userName();\n+\n+    abstract ValueProvider<String> password();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+\n+      abstract Builder setUrl(ValueProvider<String> url);\n+\n+      abstract Builder setUserName(ValueProvider<String> userName);\n+\n+      abstract Builder setPassword(ValueProvider<String> password);\n+\n+      abstract DataSourceConfiguration build();\n+    }\n+\n+    public static DataSourceConfiguration create(\n+        ValueProvider<String> url, ValueProvider<String> userName, ValueProvider<String> password) {\n+      return new AutoValue_InfluxDbIO_DataSourceConfiguration.Builder()\n+          .setUrl(url)\n+          .setUserName(userName)\n+          .setPassword(password)\n+          .build();\n+    }\n+\n+    void populateDisplayData(DisplayData.Builder builder) {\n+      builder.add(DisplayData.item(\"url\", url()));\n+      builder.add(DisplayData.item(\"userName\", userName()));\n+      builder.add(DisplayData.item(\"password\", password()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fada15c2d1a3fe10b3d9e3ba54820a4533c831f2"}, "originalPosition": 568}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjIwNjk1Mw==", "bodyText": "Please, remove credentials from displayed data", "url": "https://github.com/apache/beam/pull/11459#discussion_r492206953", "createdAt": "2020-09-21T16:51:49Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDbIO.java", "diffHunk": "@@ -0,0 +1,662 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.annotations.Experimental.Kind;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.options.ValueProvider.StaticValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.checkerframework.checker.nullness.qual.Nullable;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDB.ConsistencyLevel;\n+import org.influxdb.InfluxDBException;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write from InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDB return a bounded collection of String as {@code PCollection<String>}. The String\n+ * follows the line protocol\n+ * (https://docs.influxdata.com/influxdb/v1.8/write_protocols/line_protocol_tutorial/). To Configure\n+ * the InfluxDB source, you whave to provide the connection URL, the credentials to connect to\n+ * InfluxDB and the Database name\n+ *\n+ * <pre>{@code\n+ *  pipeline.apply(\n+ *    InfluxDB.read(\"https://influxdb\", \"userName\", \"password\", \"database\")\n+ *      .withQuery(\"select * from metric\");\n+ *      //Reads data based on the query from the InfluxDB\n+ * }\n+ *\n+ * <p> The source also accepts optional configuration: {@code withRetentionPolicy()}  an</p>\n+ *\n+ *\n+ * <h3>Writing to InfluxDB</h3>\n+ *\n+ * <p>InfluxDB sink supports writing data (as line protocol)  to InfluxDB\n+ * To configure a InfluxDB sink, you must specify a URL {@code InfluxDBURL}, {@code userName}, {@code password}, {@code database}\n+ * <pre>{@code\n+ * pipeleine\n+ *    .apply(...)\n+ *    .appply(InfluxDB.write(https://influxdb\", \"userName\", \"password\", \"database\")\n+ *\n+ * }\n+ * </pre>\n+ * </pre>\n+ */\n+@Experimental(Kind.SOURCE_SINK)\n+public class InfluxDbIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDbIO.class);\n+\n+  private static final String defaultRetentionPolicy = \"autogen\";\n+\n+  /** Disallow construction of utility class. */\n+  private InfluxDbIO() {}\n+\n+  public static Write write(String influxDbUrl, String username, String password, String database) {\n+    return new AutoValue_InfluxDbIO_Write.Builder()\n+        .setDataSourceConfiguration(\n+            DataSourceConfiguration.create(\n+                StaticValueProvider.of(influxDbUrl),\n+                StaticValueProvider.of(username),\n+                StaticValueProvider.of(password)))\n+        .setDatabase(database)\n+        .setRetentionPolicy(defaultRetentionPolicy)\n+        .setDisableCertificateValidation(false)\n+        .setBatchSize(DEFAULT_BUFFER_LIMIT)\n+        .setConsistencyLevel(ConsistencyLevel.QUORUM)\n+        .build();\n+  }\n+\n+  public static Read read(String influxDbUrl, String username, String password, String database) {\n+    return new AutoValue_InfluxDbIO_Read.Builder()\n+        .setDataSourceConfiguration(\n+            DataSourceConfiguration.create(\n+                StaticValueProvider.of(influxDbUrl),\n+                StaticValueProvider.of(username),\n+                StaticValueProvider.of(password)))\n+        .setDatabase(database)\n+        .setDisableCertificateValidation(false)\n+        .setRetentionPolicy(defaultRetentionPolicy)\n+        .build();\n+  }\n+\n+  ///////////////////////// Read  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n+\n+  /**\n+   * A {@link PTransform} to read from InfluxDB metric or data related to query. See {@link\n+   * InfluxDB} for more information on usage and configuration.\n+   */\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract String retentionPolicy();\n+\n+    abstract String database();\n+\n+    abstract @Nullable String query();\n+\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract @Nullable String metric();\n+\n+    abstract @Nullable String fromDateTime();\n+\n+    abstract @Nullable String toDateTime();\n+\n+    abstract boolean disableCertificateValidation();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(String toDateTime);\n+\n+      public abstract Builder setDisableCertificateValidation(boolean value);\n+\n+      abstract Builder setFromDateTime(String fromDateTime);\n+\n+      abstract Builder setMetric(@Nullable String metric);\n+\n+      abstract Read build();\n+    }\n+    /** Read metric data till the toDateTime. * */\n+    public Read withToDateTime(String toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+    /** Read metric data from the fromDateTime. * */\n+    public Read withFromDateTime(String fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+    /** Sets the metric to use. * */\n+    public Read withMetric(@Nullable String metric) {\n+      return builder().setMetric(metric).build();\n+    }\n+    /** Disable SSL certification validation. * */\n+    public Read withDisableCertificateValidation(boolean disableCertificateValidation) {\n+      return builder().setDisableCertificateValidation(disableCertificateValidation).build();\n+    }\n+    /** Sets the retention policy to use. * */\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+    /** Sets the query to use. * */\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      dataSourceConfiguration().populateDisplayData(builder);\n+      builder.addIfNotNull(DisplayData.item(\"metric\", metric()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"fromDateTime\", fromDateTime()));\n+      builder.addIfNotNull(DisplayData.item(\"toDateTime\", toDateTime()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"disableCertificateValidation\", disableCertificateValidation()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+    }\n+  }\n+  /** A InfluxDb {@link BoundedSource} reading {@link String} from a given instance. */\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String numOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> numOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(spec.dataSourceConfiguration(), spec.disableCertificateValidation())) {\n+        String query = spec.query();\n+        final String db = spec.database();\n+        if (query == null) {\n+          checkState(spec.metric() != null, \"Both query and metrics are empty\");\n+          query = String.format(\"SELECT * FROM %s.%s\", spec.retentionPolicy(), spec.metric());\n+        }\n+        QueryResult result = connection.query(new Query(\"EXPLAIN \" + query, db));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(numOfBlocks)) {\n+                numOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> numOfBlocksValueIterator = numOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueIterator = sizeOfBlocksValue.iterator();\n+      long size = 0L;\n+      while (numOfBlocksValueIterator.hasNext() && sizeOfBlocksValueIterator.hasNext()) {\n+        size = size + (numOfBlocksValueIterator.next() * sizeOfBlocksValueIterator.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) throws Exception {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(), spec.dataSourceConfiguration(), spec.disableCertificateValidation());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      String metric = spec.metric();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          sources.add(\n+              new InfluxDBSource(\n+                  spec.withMetric(metric)\n+                      .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                      .withToDateTime(sInfo.getStartTime())\n+                      .withFromDateTime(sInfo.getEndTime())));\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    String query = spec.query();\n+    if (query == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        String retVal =\n+            String.format(\n+                \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+                spec.retentionPolicy(), spec.metric(), spec.toDateTime(), spec.fromDateTime());\n+        return retVal;\n+      } else {\n+        return String.format(\"SELECT * FROM %s.%s\", spec.retentionPolicy(), spec.metric());\n+      }\n+    } else {\n+      return query;\n+    }\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDbIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List<Object> current;\n+\n+    public BoundedInfluxDbReader(InfluxDbIO.InfluxDBSource source) {\n+      this.source = source;\n+      this.seriesIterator = Collections.emptyIterator();\n+      this.resultIterator = Collections.emptyIterator();\n+      this.valuesIterator = Collections.emptyIterator();\n+      this.current = Collections.EMPTY_LIST;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDbIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(spec.dataSourceConfiguration(), spec.disableCertificateValidation())) {\n+        final String db = spec.database();\n+        influxDB.setDatabase(spec.database());\n+        influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        String query = getQueryToRun(spec);\n+        final QueryResult queryResult = influxDB.query(new Query(query, db));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          Result result = resultIterator.next();\n+          if (result != null && result.getSeries() != null) {\n+            seriesIterator = result.getSeries().iterator();\n+          }\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource<String> getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  /** A {@link PTransform} to write to a InfluxDB datasource. */\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkState(\n+          checkDatabase(database(), dataSourceConfiguration(), disableCertificateValidation()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"batchSize\", batchSize()));\n+      builder.addIfNotNull(DisplayData.item(\"consistencyLevel\", consistencyLevel().value()));\n+    }\n+\n+    abstract String database();\n+\n+    abstract String retentionPolicy();\n+\n+    abstract int batchSize();\n+\n+    abstract boolean disableCertificateValidation();\n+\n+    abstract ConsistencyLevel consistencyLevel();\n+\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setBatchSize(int batchSize);\n+\n+      abstract Builder setConsistencyLevel(ConsistencyLevel consistencyLevel);\n+\n+      public abstract Builder setDisableCertificateValidation(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Write build();\n+    }\n+    /** Number of elements to batch. * */\n+    public Write withBatchSize(int batchSize) {\n+      return builder().setBatchSize(batchSize).build();\n+    }\n+    /** Disable SSL certification validation. * */\n+    public Write withDisableCertificateValidation(boolean disableCertificateValidation) {\n+      return builder().setDisableCertificateValidation(disableCertificateValidation).build();\n+    }\n+    /** Sets the retention policy to use. * */\n+    public Write withRetentionPolicy(String rp) {\n+      return builder().setRetentionPolicy(rp).build();\n+    }\n+    /**\n+     * Sets the consistency level to use. ALL(\"all\") Write succeeds only if write reached all\n+     * cluster members. ANY(\"any\") Write succeeds if write reached at least one cluster members.\n+     * ONE(\"one\") Write succeeds if write reached at least one cluster members. QUORUM(\"quorum\")\n+     * Write succeeds only if write reached a quorum of cluster members.\n+     */\n+    public Write withConsistencyLevel(ConsistencyLevel consistencyLevel) {\n+      return builder().setConsistencyLevel(consistencyLevel).build();\n+    }\n+\n+    static class InfluxWriterFn extends DoFn<String, Void> {\n+\n+      private final Write spec;\n+      private List<String> batch;\n+\n+      InfluxWriterFn(Write write) {\n+        this.spec = write;\n+      }\n+\n+      @StartBundle\n+      public void startBundle() {\n+        batch = new ArrayList<>();\n+      }\n+\n+      @ProcessElement\n+      public void processElement(ProcessContext context) {\n+        batch.add(context.element());\n+        if (batch.size() >= spec.batchSize()) {\n+          flush();\n+        }\n+      }\n+\n+      @FinishBundle\n+      public void finishBundle() {\n+        flush();\n+      }\n+\n+      @Teardown\n+      public void tearDown() {\n+        flush();\n+      }\n+\n+      private void flush() {\n+        if (batch.isEmpty()) {\n+          return;\n+        }\n+        try (InfluxDB connection =\n+            getConnection(spec.dataSourceConfiguration(), spec.disableCertificateValidation())) {\n+          connection.setDatabase(spec.database());\n+          connection.enableBatch();\n+          connection.setConsistency(spec.consistencyLevel());\n+          connection.write(batch);\n+        } catch (InfluxDBException exception) {\n+          throw exception;\n+        }\n+        batch.clear();\n+      }\n+    }\n+  }\n+\n+  /** A POJO describing a DataSourceConfiguration such as URL, userName and password. */\n+  @AutoValue\n+  public abstract static class DataSourceConfiguration implements Serializable {\n+\n+    abstract ValueProvider<String> url();\n+\n+    abstract ValueProvider<String> userName();\n+\n+    abstract ValueProvider<String> password();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+\n+      abstract Builder setUrl(ValueProvider<String> url);\n+\n+      abstract Builder setUserName(ValueProvider<String> userName);\n+\n+      abstract Builder setPassword(ValueProvider<String> password);\n+\n+      abstract DataSourceConfiguration build();\n+    }\n+\n+    public static DataSourceConfiguration create(\n+        ValueProvider<String> url, ValueProvider<String> userName, ValueProvider<String> password) {\n+      return new AutoValue_InfluxDbIO_DataSourceConfiguration.Builder()\n+          .setUrl(url)\n+          .setUserName(userName)\n+          .setPassword(password)\n+          .build();\n+    }\n+\n+    void populateDisplayData(DisplayData.Builder builder) {\n+      builder.add(DisplayData.item(\"url\", url()));\n+      builder.add(DisplayData.item(\"userName\", userName()));\n+      builder.add(DisplayData.item(\"password\", password()));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0MDY1OQ=="}, "originalCommit": {"oid": "fada15c2d1a3fe10b3d9e3ba54820a4533c831f2"}, "originalPosition": 568}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAzMzc1NTk1OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDbIO.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxNjoxNzo1NlrOHOkq4Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxNjoxNzo1NlrOHOkq4Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0MjkxMw==", "bodyText": "What s states for? Please, name it explicitly.", "url": "https://github.com/apache/beam/pull/11459#discussion_r485042913", "createdAt": "2020-09-08T16:17:56Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDbIO.java", "diffHunk": "@@ -0,0 +1,662 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.annotations.Experimental.Kind;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.options.ValueProvider.StaticValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.checkerframework.checker.nullness.qual.Nullable;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDB.ConsistencyLevel;\n+import org.influxdb.InfluxDBException;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write from InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDB return a bounded collection of String as {@code PCollection<String>}. The String\n+ * follows the line protocol\n+ * (https://docs.influxdata.com/influxdb/v1.8/write_protocols/line_protocol_tutorial/). To Configure\n+ * the InfluxDB source, you whave to provide the connection URL, the credentials to connect to\n+ * InfluxDB and the Database name\n+ *\n+ * <pre>{@code\n+ *  pipeline.apply(\n+ *    InfluxDB.read(\"https://influxdb\", \"userName\", \"password\", \"database\")\n+ *      .withQuery(\"select * from metric\");\n+ *      //Reads data based on the query from the InfluxDB\n+ * }\n+ *\n+ * <p> The source also accepts optional configuration: {@code withRetentionPolicy()}  an</p>\n+ *\n+ *\n+ * <h3>Writing to InfluxDB</h3>\n+ *\n+ * <p>InfluxDB sink supports writing data (as line protocol)  to InfluxDB\n+ * To configure a InfluxDB sink, you must specify a URL {@code InfluxDBURL}, {@code userName}, {@code password}, {@code database}\n+ * <pre>{@code\n+ * pipeleine\n+ *    .apply(...)\n+ *    .appply(InfluxDB.write(https://influxdb\", \"userName\", \"password\", \"database\")\n+ *\n+ * }\n+ * </pre>\n+ * </pre>\n+ */\n+@Experimental(Kind.SOURCE_SINK)\n+public class InfluxDbIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDbIO.class);\n+\n+  private static final String defaultRetentionPolicy = \"autogen\";\n+\n+  /** Disallow construction of utility class. */\n+  private InfluxDbIO() {}\n+\n+  public static Write write(String influxDbUrl, String username, String password, String database) {\n+    return new AutoValue_InfluxDbIO_Write.Builder()\n+        .setDataSourceConfiguration(\n+            DataSourceConfiguration.create(\n+                StaticValueProvider.of(influxDbUrl),\n+                StaticValueProvider.of(username),\n+                StaticValueProvider.of(password)))\n+        .setDatabase(database)\n+        .setRetentionPolicy(defaultRetentionPolicy)\n+        .setDisableCertificateValidation(false)\n+        .setBatchSize(DEFAULT_BUFFER_LIMIT)\n+        .setConsistencyLevel(ConsistencyLevel.QUORUM)\n+        .build();\n+  }\n+\n+  public static Read read(String influxDbUrl, String username, String password, String database) {\n+    return new AutoValue_InfluxDbIO_Read.Builder()\n+        .setDataSourceConfiguration(\n+            DataSourceConfiguration.create(\n+                StaticValueProvider.of(influxDbUrl),\n+                StaticValueProvider.of(username),\n+                StaticValueProvider.of(password)))\n+        .setDatabase(database)\n+        .setDisableCertificateValidation(false)\n+        .setRetentionPolicy(defaultRetentionPolicy)\n+        .build();\n+  }\n+\n+  ///////////////////////// Read  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n+\n+  /**\n+   * A {@link PTransform} to read from InfluxDB metric or data related to query. See {@link\n+   * InfluxDB} for more information on usage and configuration.\n+   */\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract String retentionPolicy();\n+\n+    abstract String database();\n+\n+    abstract @Nullable String query();\n+\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract @Nullable String metric();\n+\n+    abstract @Nullable String fromDateTime();\n+\n+    abstract @Nullable String toDateTime();\n+\n+    abstract boolean disableCertificateValidation();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(String toDateTime);\n+\n+      public abstract Builder setDisableCertificateValidation(boolean value);\n+\n+      abstract Builder setFromDateTime(String fromDateTime);\n+\n+      abstract Builder setMetric(@Nullable String metric);\n+\n+      abstract Read build();\n+    }\n+    /** Read metric data till the toDateTime. * */\n+    public Read withToDateTime(String toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+    /** Read metric data from the fromDateTime. * */\n+    public Read withFromDateTime(String fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+    /** Sets the metric to use. * */\n+    public Read withMetric(@Nullable String metric) {\n+      return builder().setMetric(metric).build();\n+    }\n+    /** Disable SSL certification validation. * */\n+    public Read withDisableCertificateValidation(boolean disableCertificateValidation) {\n+      return builder().setDisableCertificateValidation(disableCertificateValidation).build();\n+    }\n+    /** Sets the retention policy to use. * */\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+    /** Sets the query to use. * */\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      dataSourceConfiguration().populateDisplayData(builder);\n+      builder.addIfNotNull(DisplayData.item(\"metric\", metric()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"fromDateTime\", fromDateTime()));\n+      builder.addIfNotNull(DisplayData.item(\"toDateTime\", toDateTime()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"disableCertificateValidation\", disableCertificateValidation()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+    }\n+  }\n+  /** A InfluxDb {@link BoundedSource} reading {@link String} from a given instance. */\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String numOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> numOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(spec.dataSourceConfiguration(), spec.disableCertificateValidation())) {\n+        String query = spec.query();\n+        final String db = spec.database();\n+        if (query == null) {\n+          checkState(spec.metric() != null, \"Both query and metrics are empty\");\n+          query = String.format(\"SELECT * FROM %s.%s\", spec.retentionPolicy(), spec.metric());\n+        }\n+        QueryResult result = connection.query(new Query(\"EXPLAIN \" + query, db));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fada15c2d1a3fe10b3d9e3ba54820a4533c831f2"}, "originalPosition": 251}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAzMzc4NDMzOnYy", "diffSide": "RIGHT", "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDbIO.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxNjoyNToxMVrOHOk7_Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxNjoyNToxMVrOHOk7_Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA0NzI5Mw==", "bodyText": "nit: rename Result result", "url": "https://github.com/apache/beam/pull/11459#discussion_r485047293", "createdAt": "2020-09-08T16:25:11Z", "author": {"login": "aromanenko-dev"}, "path": "sdks/java/io/influxdb/src/main/java/org/apache/beam/sdk/io/influxdb/InfluxDbIO.java", "diffHunk": "@@ -0,0 +1,662 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.influxdb;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+import static org.influxdb.BatchOptions.DEFAULT_BUFFER_LIMIT;\n+\n+import com.google.auto.value.AutoValue;\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Iterator;\n+import java.util.LinkedHashSet;\n+import java.util.List;\n+import javax.net.ssl.SSLContext;\n+import javax.net.ssl.SSLSocketFactory;\n+import javax.net.ssl.TrustManager;\n+import javax.net.ssl.X509TrustManager;\n+import okhttp3.OkHttpClient;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.annotations.Experimental.Kind;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.io.BoundedSource;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.ValueProvider;\n+import org.apache.beam.sdk.options.ValueProvider.StaticValueProvider;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.display.DisplayData;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.checkerframework.checker.nullness.qual.Nullable;\n+import org.influxdb.InfluxDB;\n+import org.influxdb.InfluxDB.ConsistencyLevel;\n+import org.influxdb.InfluxDBException;\n+import org.influxdb.InfluxDBFactory;\n+import org.influxdb.dto.Query;\n+import org.influxdb.dto.QueryResult;\n+import org.influxdb.dto.QueryResult.Result;\n+import org.influxdb.dto.QueryResult.Series;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * IO to read and write from InfluxDB.\n+ *\n+ * <h3>Reading from InfluxDB</h3>\n+ *\n+ * <p>InfluxDB return a bounded collection of String as {@code PCollection<String>}. The String\n+ * follows the line protocol\n+ * (https://docs.influxdata.com/influxdb/v1.8/write_protocols/line_protocol_tutorial/). To Configure\n+ * the InfluxDB source, you whave to provide the connection URL, the credentials to connect to\n+ * InfluxDB and the Database name\n+ *\n+ * <pre>{@code\n+ *  pipeline.apply(\n+ *    InfluxDB.read(\"https://influxdb\", \"userName\", \"password\", \"database\")\n+ *      .withQuery(\"select * from metric\");\n+ *      //Reads data based on the query from the InfluxDB\n+ * }\n+ *\n+ * <p> The source also accepts optional configuration: {@code withRetentionPolicy()}  an</p>\n+ *\n+ *\n+ * <h3>Writing to InfluxDB</h3>\n+ *\n+ * <p>InfluxDB sink supports writing data (as line protocol)  to InfluxDB\n+ * To configure a InfluxDB sink, you must specify a URL {@code InfluxDBURL}, {@code userName}, {@code password}, {@code database}\n+ * <pre>{@code\n+ * pipeleine\n+ *    .apply(...)\n+ *    .appply(InfluxDB.write(https://influxdb\", \"userName\", \"password\", \"database\")\n+ *\n+ * }\n+ * </pre>\n+ * </pre>\n+ */\n+@Experimental(Kind.SOURCE_SINK)\n+public class InfluxDbIO {\n+  private static final Logger LOG = LoggerFactory.getLogger(InfluxDbIO.class);\n+\n+  private static final String defaultRetentionPolicy = \"autogen\";\n+\n+  /** Disallow construction of utility class. */\n+  private InfluxDbIO() {}\n+\n+  public static Write write(String influxDbUrl, String username, String password, String database) {\n+    return new AutoValue_InfluxDbIO_Write.Builder()\n+        .setDataSourceConfiguration(\n+            DataSourceConfiguration.create(\n+                StaticValueProvider.of(influxDbUrl),\n+                StaticValueProvider.of(username),\n+                StaticValueProvider.of(password)))\n+        .setDatabase(database)\n+        .setRetentionPolicy(defaultRetentionPolicy)\n+        .setDisableCertificateValidation(false)\n+        .setBatchSize(DEFAULT_BUFFER_LIMIT)\n+        .setConsistencyLevel(ConsistencyLevel.QUORUM)\n+        .build();\n+  }\n+\n+  public static Read read(String influxDbUrl, String username, String password, String database) {\n+    return new AutoValue_InfluxDbIO_Read.Builder()\n+        .setDataSourceConfiguration(\n+            DataSourceConfiguration.create(\n+                StaticValueProvider.of(influxDbUrl),\n+                StaticValueProvider.of(username),\n+                StaticValueProvider.of(password)))\n+        .setDatabase(database)\n+        .setDisableCertificateValidation(false)\n+        .setRetentionPolicy(defaultRetentionPolicy)\n+        .build();\n+  }\n+\n+  ///////////////////////// Read  \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\n+\n+  /**\n+   * A {@link PTransform} to read from InfluxDB metric or data related to query. See {@link\n+   * InfluxDB} for more information on usage and configuration.\n+   */\n+  @AutoValue\n+  public abstract static class Read extends PTransform<PBegin, PCollection<String>> {\n+\n+    abstract String retentionPolicy();\n+\n+    abstract String database();\n+\n+    abstract @Nullable String query();\n+\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract @Nullable String metric();\n+\n+    abstract @Nullable String fromDateTime();\n+\n+    abstract @Nullable String toDateTime();\n+\n+    abstract boolean disableCertificateValidation();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Builder setQuery(String query);\n+\n+      abstract Builder setToDateTime(String toDateTime);\n+\n+      public abstract Builder setDisableCertificateValidation(boolean value);\n+\n+      abstract Builder setFromDateTime(String fromDateTime);\n+\n+      abstract Builder setMetric(@Nullable String metric);\n+\n+      abstract Read build();\n+    }\n+    /** Read metric data till the toDateTime. * */\n+    public Read withToDateTime(String toDateTime) {\n+      return builder().setToDateTime(toDateTime).build();\n+    }\n+    /** Read metric data from the fromDateTime. * */\n+    public Read withFromDateTime(String fromDateTime) {\n+      return builder().setFromDateTime(fromDateTime).build();\n+    }\n+    /** Sets the metric to use. * */\n+    public Read withMetric(@Nullable String metric) {\n+      return builder().setMetric(metric).build();\n+    }\n+    /** Disable SSL certification validation. * */\n+    public Read withDisableCertificateValidation(boolean disableCertificateValidation) {\n+      return builder().setDisableCertificateValidation(disableCertificateValidation).build();\n+    }\n+    /** Sets the retention policy to use. * */\n+    public Read withRetentionPolicy(String retentionPolicy) {\n+      return builder().setRetentionPolicy(retentionPolicy).build();\n+    }\n+    /** Sets the query to use. * */\n+    public Read withQuery(String query) {\n+      return builder().setQuery(query).build();\n+    }\n+\n+    @Override\n+    public PCollection<String> expand(PBegin input) {\n+      return input.apply(org.apache.beam.sdk.io.Read.from(new InfluxDBSource(this)));\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      dataSourceConfiguration().populateDisplayData(builder);\n+      builder.addIfNotNull(DisplayData.item(\"metric\", metric()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"fromDateTime\", fromDateTime()));\n+      builder.addIfNotNull(DisplayData.item(\"toDateTime\", toDateTime()));\n+      builder.addIfNotNull(\n+          DisplayData.item(\"disableCertificateValidation\", disableCertificateValidation()));\n+      builder.addIfNotNull(DisplayData.item(\"query\", query()));\n+    }\n+  }\n+  /** A InfluxDb {@link BoundedSource} reading {@link String} from a given instance. */\n+  static class InfluxDBSource extends BoundedSource<String> {\n+    private final Read spec;\n+\n+    InfluxDBSource(Read read) {\n+      this.spec = read;\n+    }\n+\n+    @Override\n+    public long getEstimatedSizeBytes(PipelineOptions pipelineOptions) {\n+      String numOfBlocks = \"NUMBER OF BLOCKS\";\n+      String sizeOfBlocks = \"SIZE OF BLOCKS\";\n+      LinkedHashSet<Long> numOfBlocksValue = new LinkedHashSet<>();\n+      LinkedHashSet<Long> sizeOfBlocksValue = new LinkedHashSet<>();\n+      try (InfluxDB connection =\n+          getConnection(spec.dataSourceConfiguration(), spec.disableCertificateValidation())) {\n+        String query = spec.query();\n+        final String db = spec.database();\n+        if (query == null) {\n+          checkState(spec.metric() != null, \"Both query and metrics are empty\");\n+          query = String.format(\"SELECT * FROM %s.%s\", spec.retentionPolicy(), spec.metric());\n+        }\n+        QueryResult result = connection.query(new Query(\"EXPLAIN \" + query, db));\n+        List<Result> results = result.getResults();\n+        for (Result res : results) {\n+          for (Series series : res.getSeries()) {\n+            for (List<Object> data : series.getValues()) {\n+              String s = data.get(0).toString();\n+              if (s.startsWith(numOfBlocks)) {\n+                numOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+              if (s.startsWith(sizeOfBlocks)) {\n+                sizeOfBlocksValue.add(Long.parseLong(s.split(\":\", -1)[1].trim()));\n+              }\n+            }\n+          }\n+        }\n+      }\n+\n+      Iterator<Long> numOfBlocksValueIterator = numOfBlocksValue.iterator();\n+      Iterator<Long> sizeOfBlocksValueIterator = sizeOfBlocksValue.iterator();\n+      long size = 0L;\n+      while (numOfBlocksValueIterator.hasNext() && sizeOfBlocksValueIterator.hasNext()) {\n+        size = size + (numOfBlocksValueIterator.next() * sizeOfBlocksValueIterator.next());\n+      }\n+      return size;\n+    }\n+\n+    @Override\n+    public List<? extends BoundedSource<String>> split(\n+        long desiredElementsInABundle, PipelineOptions options) throws Exception {\n+      List<ShardInformation> shardInfo =\n+          getDBShardedInformation(\n+              spec.database(), spec.dataSourceConfiguration(), spec.disableCertificateValidation());\n+      List<BoundedSource<String>> sources = new ArrayList<>();\n+      String metric = spec.metric();\n+      if (spec.query() == null) {\n+        for (ShardInformation sInfo : shardInfo) {\n+          sources.add(\n+              new InfluxDBSource(\n+                  spec.withMetric(metric)\n+                      .withRetentionPolicy(sInfo.getRetentionPolicy())\n+                      .withToDateTime(sInfo.getStartTime())\n+                      .withFromDateTime(sInfo.getEndTime())));\n+        }\n+      } else {\n+        sources.add(this);\n+      }\n+      return sources;\n+    }\n+\n+    @Override\n+    public BoundedReader<String> createReader(PipelineOptions pipelineOptions) {\n+      return new BoundedInfluxDbReader(this);\n+    }\n+\n+    @Override\n+    public void validate() {\n+      spec.validate(null /* input */);\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      spec.populateDisplayData(builder);\n+    }\n+\n+    @Override\n+    public Coder<String> getOutputCoder() {\n+      return StringUtf8Coder.of();\n+    }\n+  }\n+\n+  private static String getQueryToRun(Read spec) {\n+    String query = spec.query();\n+    if (query == null) {\n+      if (spec.toDateTime() != null && spec.fromDateTime() != null) {\n+        String retVal =\n+            String.format(\n+                \"SELECT * FROM %s.%s WHERE time >= '%s' and time <= '%s'\",\n+                spec.retentionPolicy(), spec.metric(), spec.toDateTime(), spec.fromDateTime());\n+        return retVal;\n+      } else {\n+        return String.format(\"SELECT * FROM %s.%s\", spec.retentionPolicy(), spec.metric());\n+      }\n+    } else {\n+      return query;\n+    }\n+  }\n+\n+  private static class BoundedInfluxDbReader extends BoundedSource.BoundedReader<String> {\n+    private final InfluxDbIO.InfluxDBSource source;\n+    private Iterator<Result> resultIterator;\n+    private Iterator<Series> seriesIterator;\n+    private Iterator<List<Object>> valuesIterator;\n+    private List<Object> current;\n+\n+    public BoundedInfluxDbReader(InfluxDbIO.InfluxDBSource source) {\n+      this.source = source;\n+      this.seriesIterator = Collections.emptyIterator();\n+      this.resultIterator = Collections.emptyIterator();\n+      this.valuesIterator = Collections.emptyIterator();\n+      this.current = Collections.EMPTY_LIST;\n+    }\n+\n+    @Override\n+    public boolean start() {\n+      InfluxDbIO.Read spec = source.spec;\n+      try (InfluxDB influxDB =\n+          getConnection(spec.dataSourceConfiguration(), spec.disableCertificateValidation())) {\n+        final String db = spec.database();\n+        influxDB.setDatabase(spec.database());\n+        influxDB.setRetentionPolicy(spec.retentionPolicy());\n+        String query = getQueryToRun(spec);\n+        final QueryResult queryResult = influxDB.query(new Query(query, db));\n+        resultIterator = queryResult.getResults().iterator();\n+        if (resultIterator.hasNext()) {\n+          Result result = resultIterator.next();\n+          if (result != null && result.getSeries() != null) {\n+            seriesIterator = result.getSeries().iterator();\n+          }\n+        }\n+        if (seriesIterator.hasNext()) {\n+          valuesIterator = seriesIterator.next().getValues().iterator();\n+        }\n+      }\n+      return advance();\n+    }\n+\n+    @Override\n+    public boolean advance() {\n+      if (valuesIterator.hasNext()) {\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (seriesIterator.hasNext()) {\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else if (resultIterator.hasNext()) {\n+        seriesIterator = resultIterator.next().getSeries().iterator();\n+        valuesIterator = seriesIterator.next().getValues().iterator();\n+        current = valuesIterator.next();\n+        return true;\n+      } else {\n+        return false;\n+      }\n+    }\n+\n+    @Override\n+    public BoundedSource<String> getCurrentSource() {\n+      return source;\n+    }\n+\n+    @Override\n+    public String getCurrent() {\n+      return current.toString();\n+    }\n+\n+    @Override\n+    public void close() {}\n+  }\n+\n+  /** A {@link PTransform} to write to a InfluxDB datasource. */\n+  @AutoValue\n+  public abstract static class Write extends PTransform<PCollection<String>, PDone> {\n+\n+    @Override\n+    public PDone expand(PCollection<String> input) {\n+      checkState(\n+          checkDatabase(database(), dataSourceConfiguration(), disableCertificateValidation()),\n+          \"Database %s does not exist\",\n+          database());\n+      input.apply(ParDo.of(new InfluxWriterFn(this)));\n+      return PDone.in(input.getPipeline());\n+    }\n+\n+    @Override\n+    public void populateDisplayData(DisplayData.Builder builder) {\n+      super.populateDisplayData(builder);\n+      builder.addIfNotNull(\n+          DisplayData.item(\"dataSourceConfiguration\", dataSourceConfiguration().toString()));\n+      builder.addIfNotNull(DisplayData.item(\"database\", database()));\n+      builder.addIfNotNull(DisplayData.item(\"retentionPolicy\", retentionPolicy()));\n+      builder.addIfNotNull(DisplayData.item(\"batchSize\", batchSize()));\n+      builder.addIfNotNull(DisplayData.item(\"consistencyLevel\", consistencyLevel().value()));\n+    }\n+\n+    abstract String database();\n+\n+    abstract String retentionPolicy();\n+\n+    abstract int batchSize();\n+\n+    abstract boolean disableCertificateValidation();\n+\n+    abstract ConsistencyLevel consistencyLevel();\n+\n+    abstract DataSourceConfiguration dataSourceConfiguration();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+      abstract Builder setDataSourceConfiguration(DataSourceConfiguration configuration);\n+\n+      abstract Builder setDatabase(String database);\n+\n+      abstract Builder setBatchSize(int batchSize);\n+\n+      abstract Builder setConsistencyLevel(ConsistencyLevel consistencyLevel);\n+\n+      public abstract Builder setDisableCertificateValidation(boolean value);\n+\n+      abstract Builder setRetentionPolicy(String retentionPolicy);\n+\n+      abstract Write build();\n+    }\n+    /** Number of elements to batch. * */\n+    public Write withBatchSize(int batchSize) {\n+      return builder().setBatchSize(batchSize).build();\n+    }\n+    /** Disable SSL certification validation. * */\n+    public Write withDisableCertificateValidation(boolean disableCertificateValidation) {\n+      return builder().setDisableCertificateValidation(disableCertificateValidation).build();\n+    }\n+    /** Sets the retention policy to use. * */\n+    public Write withRetentionPolicy(String rp) {\n+      return builder().setRetentionPolicy(rp).build();\n+    }\n+    /**\n+     * Sets the consistency level to use. ALL(\"all\") Write succeeds only if write reached all\n+     * cluster members. ANY(\"any\") Write succeeds if write reached at least one cluster members.\n+     * ONE(\"one\") Write succeeds if write reached at least one cluster members. QUORUM(\"quorum\")\n+     * Write succeeds only if write reached a quorum of cluster members.\n+     */\n+    public Write withConsistencyLevel(ConsistencyLevel consistencyLevel) {\n+      return builder().setConsistencyLevel(consistencyLevel).build();\n+    }\n+\n+    static class InfluxWriterFn extends DoFn<String, Void> {\n+\n+      private final Write spec;\n+      private List<String> batch;\n+\n+      InfluxWriterFn(Write write) {\n+        this.spec = write;\n+      }\n+\n+      @StartBundle\n+      public void startBundle() {\n+        batch = new ArrayList<>();\n+      }\n+\n+      @ProcessElement\n+      public void processElement(ProcessContext context) {\n+        batch.add(context.element());\n+        if (batch.size() >= spec.batchSize()) {\n+          flush();\n+        }\n+      }\n+\n+      @FinishBundle\n+      public void finishBundle() {\n+        flush();\n+      }\n+\n+      @Teardown\n+      public void tearDown() {\n+        flush();\n+      }\n+\n+      private void flush() {\n+        if (batch.isEmpty()) {\n+          return;\n+        }\n+        try (InfluxDB connection =\n+            getConnection(spec.dataSourceConfiguration(), spec.disableCertificateValidation())) {\n+          connection.setDatabase(spec.database());\n+          connection.enableBatch();\n+          connection.setConsistency(spec.consistencyLevel());\n+          connection.write(batch);\n+        } catch (InfluxDBException exception) {\n+          throw exception;\n+        }\n+        batch.clear();\n+      }\n+    }\n+  }\n+\n+  /** A POJO describing a DataSourceConfiguration such as URL, userName and password. */\n+  @AutoValue\n+  public abstract static class DataSourceConfiguration implements Serializable {\n+\n+    abstract ValueProvider<String> url();\n+\n+    abstract ValueProvider<String> userName();\n+\n+    abstract ValueProvider<String> password();\n+\n+    abstract Builder builder();\n+\n+    @AutoValue.Builder\n+    abstract static class Builder {\n+\n+      abstract Builder setUrl(ValueProvider<String> url);\n+\n+      abstract Builder setUserName(ValueProvider<String> userName);\n+\n+      abstract Builder setPassword(ValueProvider<String> password);\n+\n+      abstract DataSourceConfiguration build();\n+    }\n+\n+    public static DataSourceConfiguration create(\n+        ValueProvider<String> url, ValueProvider<String> userName, ValueProvider<String> password) {\n+      return new AutoValue_InfluxDbIO_DataSourceConfiguration.Builder()\n+          .setUrl(url)\n+          .setUserName(userName)\n+          .setPassword(password)\n+          .build();\n+    }\n+\n+    void populateDisplayData(DisplayData.Builder builder) {\n+      builder.add(DisplayData.item(\"url\", url()));\n+      builder.add(DisplayData.item(\"userName\", userName()));\n+      builder.add(DisplayData.item(\"password\", password()));\n+    }\n+  }\n+\n+  private static List<ShardInformation> getDBShardedInformation(\n+      String database, DataSourceConfiguration configuration, boolean disableCertificateValidation)\n+      throws Exception {\n+    String query = \"SHOW SHARDS\";\n+    DBShardInformation dbInfo = new DBShardInformation();\n+    try (InfluxDB connection = getConnection(configuration, disableCertificateValidation)) {\n+      QueryResult result = connection.query(new Query(query));\n+      List<Result> results = result.getResults();\n+      for (Result res : results) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fada15c2d1a3fe10b3d9e3ba54820a4533c831f2"}, "originalPosition": 580}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1319, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}