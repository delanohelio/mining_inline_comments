{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDU4MjAzODQ0", "number": 12403, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QxNzoxNzoyMlrOEUsHrA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQxNzoxMzozMFrOEaoZLQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwMTI5ODM2OnYy", "diffSide": "RIGHT", "path": "runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/BatchModeExecutionContext.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QxNzoxNzoyMlrOG7B4FQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QyMzozMjo0NVrOHB-OzA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDU0OTkwOQ==", "bodyText": "Can we use the same name as above (\"cumulativeThrottlingSeconds\") and move it to a constant (and also do ms to sec conversion when setting) ?", "url": "https://github.com/apache/beam/pull/12403#discussion_r464549909", "createdAt": "2020-08-03T17:17:22Z", "author": {"login": "chamikaramj"}, "path": "runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/BatchModeExecutionContext.java", "diffHunk": "@@ -543,6 +547,16 @@ public Long extractThrottleTime() {\n         totalThrottleTime += httpClientApiThrottlingTime.getCumulative();\n       }\n \n+      CounterCell bigqueryStreamingInsertThrottleTime =\n+          container.tryGetCounter(\n+              MetricName.named(\n+                  BIGQUERY_STREAMING_INSERT_THROTTLE_TIME_NAMESPACE,\n+                  BIGQUERY_STREAMING_INSERT_THROTTLE_TIME_NAME));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "09077d0e6bbfbbb79e8d417801ea7b5dd0b9148e"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDg5NDIwMg==", "bodyText": "+1\nIt would be great if we could use the same constant for all three use cases.", "url": "https://github.com/apache/beam/pull/12403#discussion_r464894202", "createdAt": "2020-08-04T08:41:00Z", "author": {"login": "ihji"}, "path": "runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/BatchModeExecutionContext.java", "diffHunk": "@@ -543,6 +547,16 @@ public Long extractThrottleTime() {\n         totalThrottleTime += httpClientApiThrottlingTime.getCumulative();\n       }\n \n+      CounterCell bigqueryStreamingInsertThrottleTime =\n+          container.tryGetCounter(\n+              MetricName.named(\n+                  BIGQUERY_STREAMING_INSERT_THROTTLE_TIME_NAMESPACE,\n+                  BIGQUERY_STREAMING_INSERT_THROTTLE_TIME_NAME));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDU0OTkwOQ=="}, "originalCommit": {"oid": "09077d0e6bbfbbb79e8d417801ea7b5dd0b9148e"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDIzMDA1Mg==", "bodyText": "Here we can use seconds, but on the streaming side msec is needed. That's the reason why I kept msec.\nFor consistency, we can change all counters to use msec originally, and do msec to sec conversion here. WDYT?", "url": "https://github.com/apache/beam/pull/12403#discussion_r470230052", "createdAt": "2020-08-13T20:31:07Z", "author": {"login": "robinyqiu"}, "path": "runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/BatchModeExecutionContext.java", "diffHunk": "@@ -543,6 +547,16 @@ public Long extractThrottleTime() {\n         totalThrottleTime += httpClientApiThrottlingTime.getCumulative();\n       }\n \n+      CounterCell bigqueryStreamingInsertThrottleTime =\n+          container.tryGetCounter(\n+              MetricName.named(\n+                  BIGQUERY_STREAMING_INSERT_THROTTLE_TIME_NAMESPACE,\n+                  BIGQUERY_STREAMING_INSERT_THROTTLE_TIME_NAME));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDU0OTkwOQ=="}, "originalCommit": {"oid": "09077d0e6bbfbbb79e8d417801ea7b5dd0b9148e"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTgzMDIyMA==", "bodyText": "Hi @chamikaramj @ihji ! I have made the change such that BQ, GCS, and Datastore all report throttled time in milliseconds at the beginning, and they now share the common counter name for consistency. The millisecond to second conversion is done only when later a throttled time in seconds is expected by worker side code. PTAL", "url": "https://github.com/apache/beam/pull/12403#discussion_r471830220", "createdAt": "2020-08-17T23:32:45Z", "author": {"login": "robinyqiu"}, "path": "runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/BatchModeExecutionContext.java", "diffHunk": "@@ -543,6 +547,16 @@ public Long extractThrottleTime() {\n         totalThrottleTime += httpClientApiThrottlingTime.getCumulative();\n       }\n \n+      CounterCell bigqueryStreamingInsertThrottleTime =\n+          container.tryGetCounter(\n+              MetricName.named(\n+                  BIGQUERY_STREAMING_INSERT_THROTTLE_TIME_NAMESPACE,\n+                  BIGQUERY_STREAMING_INSERT_THROTTLE_TIME_NAME));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDU0OTkwOQ=="}, "originalCommit": {"oid": "09077d0e6bbfbbb79e8d417801ea7b5dd0b9148e"}, "originalPosition": 19}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwMTMwMzMxOnYy", "diffSide": "RIGHT", "path": "runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/StreamingDataflowWorker.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QxNzoxODo0OVrOG7B7NQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xM1QyMDoyODoxM1rOHAcehg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDU1MDcwOQ==", "bodyText": "Is there a reason why we needed to use a  unique name for BQ but not for GCS or Datastore ?", "url": "https://github.com/apache/beam/pull/12403#discussion_r464550709", "createdAt": "2020-08-03T17:18:49Z", "author": {"login": "chamikaramj"}, "path": "runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/StreamingDataflowWorker.java", "diffHunk": "@@ -520,8 +526,11 @@ public int getSize() {\n     private void translateKnownStepCounters(CounterUpdate stepCounterUpdate) {\n       CounterStructuredName structuredName =\n           stepCounterUpdate.getStructuredNameAndMetadata().getName();\n-      if (THROTTLING_MSECS_METRIC_NAME.getNamespace().equals(structuredName.getOriginNamespace())\n-          && THROTTLING_MSECS_METRIC_NAME.getName().equals(structuredName.getName())) {\n+      if ((THROTTLING_MSECS_METRIC_NAME.getNamespace().equals(structuredName.getOriginNamespace())\n+              && THROTTLING_MSECS_METRIC_NAME.getName().equals(structuredName.getName()))\n+          || (BIGQUERY_STREAMING_INSERT_THROTTLE_TIME_NAMESPACE.equals(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "09077d0e6bbfbbb79e8d417801ea7b5dd0b9148e"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDIyODYxNA==", "bodyText": "Yes. GCS and Datastore counters are only consumed by batch worker (the THROTTLING_MSECS_METRIC_NAME counter here is a separate counter; I am not sure what this is. Maybe all throttling metrics should go to this counter? @ihji I saw you have a JIRA about it, not sure if this what you want to do).\nHere in the streaming case, precision is on millisecond (whereas GCS and DataStore only store seconds)", "url": "https://github.com/apache/beam/pull/12403#discussion_r470228614", "createdAt": "2020-08-13T20:28:13Z", "author": {"login": "robinyqiu"}, "path": "runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/StreamingDataflowWorker.java", "diffHunk": "@@ -520,8 +526,11 @@ public int getSize() {\n     private void translateKnownStepCounters(CounterUpdate stepCounterUpdate) {\n       CounterStructuredName structuredName =\n           stepCounterUpdate.getStructuredNameAndMetadata().getName();\n-      if (THROTTLING_MSECS_METRIC_NAME.getNamespace().equals(structuredName.getOriginNamespace())\n-          && THROTTLING_MSECS_METRIC_NAME.getName().equals(structuredName.getName())) {\n+      if ((THROTTLING_MSECS_METRIC_NAME.getNamespace().equals(structuredName.getOriginNamespace())\n+              && THROTTLING_MSECS_METRIC_NAME.getName().equals(structuredName.getName()))\n+          || (BIGQUERY_STREAMING_INSERT_THROTTLE_TIME_NAMESPACE.equals(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDU1MDcwOQ=="}, "originalCommit": {"oid": "09077d0e6bbfbbb79e8d417801ea7b5dd0b9148e"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwMTMxMTk1OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryServicesImpl.java", "isResolved": false, "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QxNzoyMTozOFrOG7CAtA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQyMzo1Mzo0MVrOHCqjHQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDU1MjExNg==", "bodyText": "This is for failures. Probably you need to increment the counter for backoff1 for rate limit errors above.\ncc: @ihji", "url": "https://github.com/apache/beam/pull/12403#discussion_r464552116", "createdAt": "2020-08-03T17:21:38Z", "author": {"login": "chamikaramj"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryServicesImpl.java", "diffHunk": "@@ -867,6 +872,7 @@ public void deleteDataset(String projectId, String datasetId)\n         }\n         try {\n           sleeper.sleep(nextBackoffMillis);\n+          throttlingMilliSeconds.inc(nextBackoffMillis);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "09077d0e6bbfbbb79e8d417801ea7b5dd0b9148e"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDIyNTgzMw==", "bodyText": "The retried failures here are transient failures, which I believe include throttling. I have thought about incrementing backoff1 but that is executed in a future (a parallel thread). If we accumulate counters over all threads then I think we will over calculate the number. So I add the counter here in the main thread.", "url": "https://github.com/apache/beam/pull/12403#discussion_r470225833", "createdAt": "2020-08-13T20:23:02Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryServicesImpl.java", "diffHunk": "@@ -867,6 +872,7 @@ public void deleteDataset(String projectId, String datasetId)\n         }\n         try {\n           sleeper.sleep(nextBackoffMillis);\n+          throttlingMilliSeconds.inc(nextBackoffMillis);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDU1MjExNg=="}, "originalCommit": {"oid": "09077d0e6bbfbbb79e8d417801ea7b5dd0b9148e"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTg2NDQ0Ng==", "bodyText": "Throttling results in rate limit errors, right ? If so that would be captured by backoff1 I think. Prob. Heejong can confirm.", "url": "https://github.com/apache/beam/pull/12403#discussion_r471864446", "createdAt": "2020-08-18T01:39:02Z", "author": {"login": "chamikaramj"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryServicesImpl.java", "diffHunk": "@@ -867,6 +872,7 @@ public void deleteDataset(String projectId, String datasetId)\n         }\n         try {\n           sleeper.sleep(nextBackoffMillis);\n+          throttlingMilliSeconds.inc(nextBackoffMillis);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDU1MjExNg=="}, "originalCommit": {"oid": "09077d0e6bbfbbb79e8d417801ea7b5dd0b9148e"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUwMTg2NA==", "bodyText": "My major concern on accumulating backoff1 is that we may over calculate, because we will be adding time being throttled on all threads.", "url": "https://github.com/apache/beam/pull/12403#discussion_r472501864", "createdAt": "2020-08-18T21:24:51Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryServicesImpl.java", "diffHunk": "@@ -867,6 +872,7 @@ public void deleteDataset(String projectId, String datasetId)\n         }\n         try {\n           sleeper.sleep(nextBackoffMillis);\n+          throttlingMilliSeconds.inc(nextBackoffMillis);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDU1MjExNg=="}, "originalCommit": {"oid": "09077d0e6bbfbbb79e8d417801ea7b5dd0b9148e"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUwNzczNw==", "bodyText": "Yes, we should use backoff1. Rate limit errors only reach to this point after 2 minutes of backoffs by backoff1 silently inside of the future. Why do you think it's over-calculated? Each thread is doing its own insert job and it doesn't look strange to me to calculate the total throttling time by adding all backoff times from parallel threads.", "url": "https://github.com/apache/beam/pull/12403#discussion_r472507737", "createdAt": "2020-08-18T21:37:44Z", "author": {"login": "ihji"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryServicesImpl.java", "diffHunk": "@@ -867,6 +872,7 @@ public void deleteDataset(String projectId, String datasetId)\n         }\n         try {\n           sleeper.sleep(nextBackoffMillis);\n+          throttlingMilliSeconds.inc(nextBackoffMillis);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDU1MjExNg=="}, "originalCommit": {"oid": "09077d0e6bbfbbb79e8d417801ea7b5dd0b9148e"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUxNDIzOA==", "bodyText": "Yes, we should use backoff1. Rate limit errors only reach to this point after 2 minutes of backoffs by backoff1 silently inside of the future.\n\nI see. That make sense to me.\n\nWhy do you think it's over-calculated?\n\nBecause I am not sure how this metrics is used downstream. I vaguely remember Dataflow autoscaling will use this number divided by the total time spent on work item to yield a fraction which signals throttling. If the total time is not accumulating time spent on all threads then we may over-calculate.", "url": "https://github.com/apache/beam/pull/12403#discussion_r472514238", "createdAt": "2020-08-18T21:52:12Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryServicesImpl.java", "diffHunk": "@@ -867,6 +872,7 @@ public void deleteDataset(String projectId, String datasetId)\n         }\n         try {\n           sleeper.sleep(nextBackoffMillis);\n+          throttlingMilliSeconds.inc(nextBackoffMillis);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDU1MjExNg=="}, "originalCommit": {"oid": "09077d0e6bbfbbb79e8d417801ea7b5dd0b9148e"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjUyMTc0MQ==", "bodyText": "Yeah, I think that's a valid concern. We probably need to figure out the time requests are throttled without including backoff due to other errors. Is there a way to get throttled time from all parallel threads and just use the maximum ?", "url": "https://github.com/apache/beam/pull/12403#discussion_r472521741", "createdAt": "2020-08-18T22:10:13Z", "author": {"login": "chamikaramj"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryServicesImpl.java", "diffHunk": "@@ -867,6 +872,7 @@ public void deleteDataset(String projectId, String datasetId)\n         }\n         try {\n           sleeper.sleep(nextBackoffMillis);\n+          throttlingMilliSeconds.inc(nextBackoffMillis);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDU1MjExNg=="}, "originalCommit": {"oid": "09077d0e6bbfbbb79e8d417801ea7b5dd0b9148e"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjU1NjMxNw==", "bodyText": "Is there a way to get throttled time from all parallel threads and just use the maximum?\n\nYes I think this is the right thing to do. Made the change already. PTAL. WDYT, @ihji?", "url": "https://github.com/apache/beam/pull/12403#discussion_r472556317", "createdAt": "2020-08-18T23:53:41Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryServicesImpl.java", "diffHunk": "@@ -867,6 +872,7 @@ public void deleteDataset(String projectId, String datasetId)\n         }\n         try {\n           sleeper.sleep(nextBackoffMillis);\n+          throttlingMilliSeconds.inc(nextBackoffMillis);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDU1MjExNg=="}, "originalCommit": {"oid": "09077d0e6bbfbbb79e8d417801ea7b5dd0b9148e"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2MzYwMjM3OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryServicesImpl.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQxNzoxMzozMFrOHELnIQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQwMTowMDo1NVrOHEYE_Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE0NjU5Mw==", "bodyText": "Please consider adding this to Python as well (in  a separate PR).\ncc: @pabloem", "url": "https://github.com/apache/beam/pull/12403#discussion_r474146593", "createdAt": "2020-08-20T17:13:30Z", "author": {"login": "chamikaramj"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryServicesImpl.java", "diffHunk": "@@ -424,6 +427,9 @@ public Job getJob(JobReference jobRef, Sleeper sleeper, BackOff backoff)\n     private final PipelineOptions options;\n     private final long maxRowsPerBatch;\n     private final long maxRowBatchSize;\n+    // aggregate the total time spent in exponential backoff", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "621a4c375dd4f2bdc2eaee0bb5b3601ce1802513"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDM1MDg0NQ==", "bodyText": "Will do in a new PR.", "url": "https://github.com/apache/beam/pull/12403#discussion_r474350845", "createdAt": "2020-08-21T01:00:55Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryServicesImpl.java", "diffHunk": "@@ -424,6 +427,9 @@ public Job getJob(JobReference jobRef, Sleeper sleeper, BackOff backoff)\n     private final PipelineOptions options;\n     private final long maxRowsPerBatch;\n     private final long maxRowBatchSize;\n+    // aggregate the total time spent in exponential backoff", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE0NjU5Mw=="}, "originalCommit": {"oid": "621a4c375dd4f2bdc2eaee0bb5b3601ce1802513"}, "originalPosition": 21}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 716, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}