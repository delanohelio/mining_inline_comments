{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzk1ODY2Mjc1", "number": 11264, "reviewThreads": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNTo0NjoyMVrODvMMog==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNjowODo1OVrODvM1Sw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwODA5NTA2OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/convert.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNTo0NjoyMVrOGBeJvg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNTo0NjoyMVrOGBeJvg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDE5NTc3NA==", "bodyText": "Could you add something like \".. by retrieving the name of these variables in the calling context\"", "url": "https://github.com/apache/beam/pull/11264#discussion_r404195774", "createdAt": "2020-04-06T15:46:21Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/convert.py", "diffHunk": "@@ -0,0 +1,71 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+from __future__ import absolute_import\n+\n+import inspect\n+\n+from apache_beam import pvalue\n+from apache_beam.dataframe import expressions\n+from apache_beam.dataframe import frame_base\n+from apache_beam.dataframe import transforms\n+\n+\n+def to_dataframe(pc):\n+  pass\n+\n+\n+# TODO: Or should this be called as_dataframe?\n+def to_dataframe(pcoll, proxy):\n+  return frame_base.DeferredFrame.wrap(\n+      expressions.PlaceholderExpression(proxy, pcoll))\n+\n+\n+# TODO: Or should this be called from_dataframe?\n+def to_pcollection(*dataframes, **kwargs):\n+  label = kwargs.pop('label', None)\n+  assert not kwargs  # TODO(Py3): Use PEP 3102\n+  if label is None:\n+    # Attempt to come up with a reasonable, stable label.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f96077e14233b23390e64ce15fcaabf1d2efeb5"}, "originalPosition": 42}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwODEyMzQ0OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/transforms.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNTo1MjozOVrOGBeb9w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNTo1MjozOVrOGBeb9w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDIwMDQzOQ==", "bodyText": "This looks like something that should be \"package-private\". Should it get an underscore prefix?", "url": "https://github.com/apache/beam/pull/11264#discussion_r404200439", "createdAt": "2020-04-06T15:52:39Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/transforms.py", "diffHunk": "@@ -0,0 +1,255 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+from __future__ import absolute_import\n+\n+import pandas as pd\n+\n+import apache_beam as beam\n+from apache_beam import transforms\n+from apache_beam.dataframe import expressions\n+from apache_beam.dataframe import frame_base\n+from apache_beam.dataframe import frames  # pylint: disable=unused-import\n+\n+\n+class DataframeTransform(transforms.PTransform):\n+  \"\"\"A PTransform for applying function that takes and returns dataframes\n+  to one or more PCollections.\n+\n+  For example, if pcoll is a PCollection of dataframes, one could write::\n+\n+      pcoll | DataframeTransform(lambda df: df.group_by('key').sum(), proxy=...)\n+\n+  To pass multiple PCollections, pass a tuple of PCollections wich will be\n+  passed to the callable as positional arguments, or a dictionary of\n+  PCollections, in which case they will be passed as keyword arguments.\n+  \"\"\"\n+  def __init__(self, func, proxy):\n+    self._func = func\n+    self._proxy = proxy\n+\n+  def expand(self, input_pcolls):\n+    def wrap_as_dict(values):\n+      if isinstance(values, dict):\n+        return values\n+      elif isinstance(values, tuple):\n+        return dict(enumerate(values))\n+      else:\n+        return {None: values}\n+\n+    # TODO: Infer the proxy from the input schema.\n+    def proxy(key):\n+      if key is None:\n+        return self._proxy\n+      else:\n+        return self._proxy[key]\n+\n+    # The input can be a dictionary, tuple, or plain PCollection.\n+    # Wrap as a dict for homogeneity.\n+    # TODO: Possibly inject batching here.\n+    input_dict = wrap_as_dict(input_pcolls)\n+    placeholders = {\n+        key: frame_base.DeferredFrame.wrap(\n+            expressions.PlaceholderExpression(proxy(key)))\n+        for key in input_dict.keys()\n+    }\n+\n+    # The calling convention of the user-supplied func varies according to the\n+    # type of the input.\n+    if isinstance(input_pcolls, dict):\n+      result_frames = self._func(**placeholders)\n+    elif isinstance(input_pcolls, tuple):\n+      result_frames = self._func(\n+          *(value for _, value in sorted(placeholders.items())))\n+    else:\n+      result_frames = self._func(placeholders[None])\n+\n+    # Likewise the output may be a dict, tuple, or raw (deferred) Dataframe.\n+    result_dict = wrap_as_dict(result_frames)\n+\n+    result_pcolls = {\n+        placeholders[key]._expr: pcoll\n+        for key, pcoll in input_dict.items()\n+    } | 'Eval' >> DataframeExpressionsTransform(\n+        {key: df._expr\n+         for key, df in result_dict.items()})\n+\n+    # Convert the result back into a set of PCollections.\n+    if isinstance(result_frames, dict):\n+      return result_pcolls\n+    elif isinstance(result_frames, tuple):\n+      return tuple((value for _, value in sorted(result_pcolls.items())))\n+    else:\n+      return result_pcolls[None]\n+\n+\n+class DataframeExpressionsTransform(transforms.PTransform):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f96077e14233b23390e64ce15fcaabf1d2efeb5"}, "originalPosition": 99}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwODE4NDY3OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/convert.py", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNjowNTo1OFrOGBfB5Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQxODowMzo1MFrOGIhAVQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDIxMDE0OQ==", "bodyText": "I like as_dataframe if it were a method on PCollection since it's fluent - df = pcol.as_dataframe()\nSimilarly, below from_dataframe would be fluent as a static method on PCollection, but PCollection.from_dataframe feels too verbose.\nWould you agree we want something like the following to be as easy and intuitive as possible?\npcol = p | \"Read from Source\" >> beam.io.SomeSchemaSource(foo)\n\ndf = pcol.as_dataframe()\ndf_agg = df[df[\"measurement\" > threshold]].groupby(\"id\").count()\n\nPCollection.from_dataframe(df_agg) | \"Write to Sink\" >> beam.io.SomeSink(bar)", "url": "https://github.com/apache/beam/pull/11264#discussion_r404210149", "createdAt": "2020-04-06T16:05:58Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/convert.py", "diffHunk": "@@ -0,0 +1,71 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+from __future__ import absolute_import\n+\n+import inspect\n+\n+from apache_beam import pvalue\n+from apache_beam.dataframe import expressions\n+from apache_beam.dataframe import frame_base\n+from apache_beam.dataframe import transforms\n+\n+\n+def to_dataframe(pc):\n+  pass\n+\n+\n+# TODO: Or should this be called as_dataframe?", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f96077e14233b23390e64ce15fcaabf1d2efeb5"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzc0OTE2Mw==", "bodyText": "So far we haven't added any methods to PCollection, but I'm open to the idea (thought it'd be a big change to the API that should be done wholistically, see https://lists.apache.org/thread.html/fcb422d61437a634662b24100d4e2d46a940ee766848b699023081d9%40%3Cdev.beam.apache.org%3E ) For now, at least, it seems a bit much to make dataframe-methods on PCollection itself.\nShort of that, can you think of any fluent styles for\nfrom apache_beam import dataframe as ???\n...\npcol = p | \"Read from Source\" >> beam.io.SomeSchemaSource(foo)\ndf = ???", "url": "https://github.com/apache/beam/pull/11264#discussion_r407749163", "createdAt": "2020-04-13T22:07:52Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/convert.py", "diffHunk": "@@ -0,0 +1,71 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+from __future__ import absolute_import\n+\n+import inspect\n+\n+from apache_beam import pvalue\n+from apache_beam.dataframe import expressions\n+from apache_beam.dataframe import frame_base\n+from apache_beam.dataframe import transforms\n+\n+\n+def to_dataframe(pc):\n+  pass\n+\n+\n+# TODO: Or should this be called as_dataframe?", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDIxMDE0OQ=="}, "originalCommit": {"oid": "3f96077e14233b23390e64ce15fcaabf1d2efeb5"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTUyNzk1Ng==", "bodyText": "Yeah definitely fair to not make changes to PCollection yet. Another option would be methods on DeferredDataframe, like #as_pcollection():\npcol = p | \"Read from Source\" >> beam.io.SomeSchemaSource(foo)\n\ndf = to_dataframe(pcol)\ndf_agg = df[df[\"measurement\" > threshold]].groupby(\"id\").count()\n\ndf_agg.as_pcollection() | \"Write to Sink\" >> beam.io.SomeSink(bar)\nThis is just a bikeshed though. This is still very experimental so I don't think we're locking ourselves into anything.", "url": "https://github.com/apache/beam/pull/11264#discussion_r411527956", "createdAt": "2020-04-20T16:41:23Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/convert.py", "diffHunk": "@@ -0,0 +1,71 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+from __future__ import absolute_import\n+\n+import inspect\n+\n+from apache_beam import pvalue\n+from apache_beam.dataframe import expressions\n+from apache_beam.dataframe import frame_base\n+from apache_beam.dataframe import transforms\n+\n+\n+def to_dataframe(pc):\n+  pass\n+\n+\n+# TODO: Or should this be called as_dataframe?", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDIxMDE0OQ=="}, "originalCommit": {"oid": "3f96077e14233b23390e64ce15fcaabf1d2efeb5"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTU4MjU0OQ==", "bodyText": "Yeah, it's all experimental at this point. We can keep churning on the best API while we flesh out functionality.", "url": "https://github.com/apache/beam/pull/11264#discussion_r411582549", "createdAt": "2020-04-20T18:03:50Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/convert.py", "diffHunk": "@@ -0,0 +1,71 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+from __future__ import absolute_import\n+\n+import inspect\n+\n+from apache_beam import pvalue\n+from apache_beam.dataframe import expressions\n+from apache_beam.dataframe import frame_base\n+from apache_beam.dataframe import transforms\n+\n+\n+def to_dataframe(pc):\n+  pass\n+\n+\n+# TODO: Or should this be called as_dataframe?", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDIxMDE0OQ=="}, "originalCommit": {"oid": "3f96077e14233b23390e64ce15fcaabf1d2efeb5"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwODE4NzQwOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/convert.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNjowNjozOFrOGBfDng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNjowNjozOFrOGBfDng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDIxMDU5MA==", "bodyText": "Could you add typehints and docstrings here and on to_dataframe?", "url": "https://github.com/apache/beam/pull/11264#discussion_r404210590", "createdAt": "2020-04-06T16:06:38Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/convert.py", "diffHunk": "@@ -0,0 +1,71 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+from __future__ import absolute_import\n+\n+import inspect\n+\n+from apache_beam import pvalue\n+from apache_beam.dataframe import expressions\n+from apache_beam.dataframe import frame_base\n+from apache_beam.dataframe import transforms\n+\n+\n+def to_dataframe(pc):\n+  pass\n+\n+\n+# TODO: Or should this be called as_dataframe?\n+def to_dataframe(pcoll, proxy):\n+  return frame_base.DeferredFrame.wrap(\n+      expressions.PlaceholderExpression(proxy, pcoll))\n+\n+\n+# TODO: Or should this be called from_dataframe?\n+def to_pcollection(*dataframes, **kwargs):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f96077e14233b23390e64ce15fcaabf1d2efeb5"}, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUwODE5OTE1OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/transforms.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxNjowODo1OVrOGBfKng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xM1QyMTo1NzoxOVrOGE2yAw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDIxMjM4Mg==", "bodyText": "Could this be streamlined with calls to to_dataframe and to_pcollection?", "url": "https://github.com/apache/beam/pull/11264#discussion_r404212382", "createdAt": "2020-04-06T16:08:59Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/transforms.py", "diffHunk": "@@ -0,0 +1,255 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+from __future__ import absolute_import\n+\n+import pandas as pd\n+\n+import apache_beam as beam\n+from apache_beam import transforms\n+from apache_beam.dataframe import expressions\n+from apache_beam.dataframe import frame_base\n+from apache_beam.dataframe import frames  # pylint: disable=unused-import\n+\n+\n+class DataframeTransform(transforms.PTransform):\n+  \"\"\"A PTransform for applying function that takes and returns dataframes\n+  to one or more PCollections.\n+\n+  For example, if pcoll is a PCollection of dataframes, one could write::\n+\n+      pcoll | DataframeTransform(lambda df: df.group_by('key').sum(), proxy=...)\n+\n+  To pass multiple PCollections, pass a tuple of PCollections wich will be\n+  passed to the callable as positional arguments, or a dictionary of\n+  PCollections, in which case they will be passed as keyword arguments.\n+  \"\"\"\n+  def __init__(self, func, proxy):\n+    self._func = func\n+    self._proxy = proxy\n+\n+  def expand(self, input_pcolls):\n+    def wrap_as_dict(values):\n+      if isinstance(values, dict):\n+        return values\n+      elif isinstance(values, tuple):\n+        return dict(enumerate(values))\n+      else:\n+        return {None: values}\n+\n+    # TODO: Infer the proxy from the input schema.\n+    def proxy(key):\n+      if key is None:\n+        return self._proxy\n+      else:\n+        return self._proxy[key]\n+\n+    # The input can be a dictionary, tuple, or plain PCollection.\n+    # Wrap as a dict for homogeneity.\n+    # TODO: Possibly inject batching here.\n+    input_dict = wrap_as_dict(input_pcolls)\n+    placeholders = {\n+        key: frame_base.DeferredFrame.wrap(\n+            expressions.PlaceholderExpression(proxy(key)))\n+        for key in input_dict.keys()\n+    }\n+\n+    # The calling convention of the user-supplied func varies according to the\n+    # type of the input.\n+    if isinstance(input_pcolls, dict):\n+      result_frames = self._func(**placeholders)\n+    elif isinstance(input_pcolls, tuple):\n+      result_frames = self._func(\n+          *(value for _, value in sorted(placeholders.items())))\n+    else:\n+      result_frames = self._func(placeholders[None])\n+\n+    # Likewise the output may be a dict, tuple, or raw (deferred) Dataframe.\n+    result_dict = wrap_as_dict(result_frames)\n+\n+    result_pcolls = {\n+        placeholders[key]._expr: pcoll\n+        for key, pcoll in input_dict.items()\n+    } | 'Eval' >> DataframeExpressionsTransform(\n+        {key: df._expr\n+         for key, df in result_dict.items()})\n+\n+    # Convert the result back into a set of PCollections.\n+    if isinstance(result_frames, dict):\n+      return result_pcolls\n+    elif isinstance(result_frames, tuple):\n+      return tuple((value for _, value in sorted(result_pcolls.items())))\n+    else:\n+      return result_pcolls[None]", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f96077e14233b23390e64ce15fcaabf1d2efeb5"}, "originalPosition": 96}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzc0NTAyNw==", "bodyText": "Yes. Done.", "url": "https://github.com/apache/beam/pull/11264#discussion_r407745027", "createdAt": "2020-04-13T21:57:19Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/transforms.py", "diffHunk": "@@ -0,0 +1,255 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+from __future__ import absolute_import\n+\n+import pandas as pd\n+\n+import apache_beam as beam\n+from apache_beam import transforms\n+from apache_beam.dataframe import expressions\n+from apache_beam.dataframe import frame_base\n+from apache_beam.dataframe import frames  # pylint: disable=unused-import\n+\n+\n+class DataframeTransform(transforms.PTransform):\n+  \"\"\"A PTransform for applying function that takes and returns dataframes\n+  to one or more PCollections.\n+\n+  For example, if pcoll is a PCollection of dataframes, one could write::\n+\n+      pcoll | DataframeTransform(lambda df: df.group_by('key').sum(), proxy=...)\n+\n+  To pass multiple PCollections, pass a tuple of PCollections wich will be\n+  passed to the callable as positional arguments, or a dictionary of\n+  PCollections, in which case they will be passed as keyword arguments.\n+  \"\"\"\n+  def __init__(self, func, proxy):\n+    self._func = func\n+    self._proxy = proxy\n+\n+  def expand(self, input_pcolls):\n+    def wrap_as_dict(values):\n+      if isinstance(values, dict):\n+        return values\n+      elif isinstance(values, tuple):\n+        return dict(enumerate(values))\n+      else:\n+        return {None: values}\n+\n+    # TODO: Infer the proxy from the input schema.\n+    def proxy(key):\n+      if key is None:\n+        return self._proxy\n+      else:\n+        return self._proxy[key]\n+\n+    # The input can be a dictionary, tuple, or plain PCollection.\n+    # Wrap as a dict for homogeneity.\n+    # TODO: Possibly inject batching here.\n+    input_dict = wrap_as_dict(input_pcolls)\n+    placeholders = {\n+        key: frame_base.DeferredFrame.wrap(\n+            expressions.PlaceholderExpression(proxy(key)))\n+        for key in input_dict.keys()\n+    }\n+\n+    # The calling convention of the user-supplied func varies according to the\n+    # type of the input.\n+    if isinstance(input_pcolls, dict):\n+      result_frames = self._func(**placeholders)\n+    elif isinstance(input_pcolls, tuple):\n+      result_frames = self._func(\n+          *(value for _, value in sorted(placeholders.items())))\n+    else:\n+      result_frames = self._func(placeholders[None])\n+\n+    # Likewise the output may be a dict, tuple, or raw (deferred) Dataframe.\n+    result_dict = wrap_as_dict(result_frames)\n+\n+    result_pcolls = {\n+        placeholders[key]._expr: pcoll\n+        for key, pcoll in input_dict.items()\n+    } | 'Eval' >> DataframeExpressionsTransform(\n+        {key: df._expr\n+         for key, df in result_dict.items()})\n+\n+    # Convert the result back into a set of PCollections.\n+    if isinstance(result_frames, dict):\n+      return result_pcolls\n+    elif isinstance(result_frames, tuple):\n+      return tuple((value for _, value in sorted(result_pcolls.items())))\n+    else:\n+      return result_pcolls[None]", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDIxMjM4Mg=="}, "originalCommit": {"oid": "3f96077e14233b23390e64ce15fcaabf1d2efeb5"}, "originalPosition": 96}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1565, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}