{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDYwNTY3MjIz", "number": 12440, "title": "[BEAM-10619] Report ratio of implemented pandas tests", "bodyText": "The report looks like this when run with pytest -s:\napache_beam/dataframe/pandas_doctests_test.py 829 total test cases.\n722 will implement, 107 won't implement.\n257 skipped.\n69.0% (572/829) of all test cases pass or raise WontImplementError\n.676 total test cases.\n631 will implement, 45 won't implement.\n265 skipped.\n60.8% (411/676) of all test cases pass or raise WontImplementError\n\n\nThank you for your contribution! Follow this checklist to help us incorporate your contribution quickly and easily:\n\n Choose reviewer(s) and mention them in a comment (R: @username).\n Format the pull request title like [BEAM-XXX] Fixes bug in ApproximateQuantiles, where you replace BEAM-XXX with the appropriate JIRA issue, if applicable. This will automatically link the pull request to the issue.\n Update CHANGES.md with noteworthy changes.\n If this contribution is large, please file an Apache Individual Contributor License Agreement.\n\nSee the Contributor Guide for more tips on how to make review process smoother.\nPost-Commit Tests Status (on master branch)\n\n\n\nLang\nSDK\nDataflow\nFlink\nSamza\nSpark\nTwister2\n\n\n\n\nGo\n\n---\n\n---\n\n---\n\n\nJava\n\n\n\n\n\n\n\n\nPython\n\n\n\n---\n\n---\n\n\nXLang\n\n---\n\n---\n\n---\n\n\n\nPre-Commit Tests Status (on master branch)\n\n\n\n---\nJava\nPython\nGo\nWebsite\n\n\n\n\nNon-portable\n\n\n\n\n\n\nPortable\n---\n\n---\n---\n\n\n\nSee .test-infra/jenkins/README for trigger phrase, status and link of all Jenkins jobs.", "createdAt": "2020-07-31T22:21:04Z", "url": "https://github.com/apache/beam/pull/12440", "merged": true, "mergeCommit": {"oid": "c484cdc11d63a36cff1589d59482f28db1a97f5e"}, "closed": true, "closedAt": "2020-08-07T22:30:45Z", "author": {"login": "TheNeuralBit"}, "timelineItems": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc7Vx1PgFqTQ2MDIyMTA3Ng==", "endCursor": "Y3Vyc29yOnYyOpPPAAABc8q8NdgH2gAyNDYwNTY3MjIzOmRiZmJhZWI1ZmUyNTkyMmEwN2U1MjA4OTI1Y2E1YWIxOTM5YmNhN2I=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDYwMjIxMDc2", "url": "https://github.com/apache/beam/pull/12440#pullrequestreview-460221076", "createdAt": "2020-08-03T17:42:48Z", "commit": {"oid": "69b1b391628860a75b63d0dc9b5f0153af8eb017"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QxNzo0Mjo0OFrOG7C2WA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QxNzo0ODo0NlrOG7DCkw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDU2NTg0OA==", "bodyText": "It'd be nice to track how many actually triggered this error (and perhaps track the reasons why).", "url": "https://github.com/apache/beam/pull/12440#discussion_r464565848", "createdAt": "2020-08-03T17:42:48Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/doctests.py", "diffHunk": "@@ -290,34 +298,60 @@ def to_callable(cond):\n     super(BeamDataframeDoctestRunner, self).__init__(\n         checker=_DeferrredDataframeOutputChecker(self._test_env, use_beam),\n         **kwargs)\n+    self.skipped = 0\n+    self.wont_implement = 0\n \n   def run(self, test, **kwargs):\n     self._checker.reset()\n-    if test.name in self._skip:\n-      for example in test.examples:\n-        if any(should_skip(example) for should_skip in self._skip[test.name]):\n-          example.source = 'pass'\n-          example.want = ''\n     for example in test.examples:\n-      if example.exc_msg is None:\n+      if any(should_skip(example)\n+             for should_skip in self._skip.get(test.name, [])):\n+        example.source = 'pass'\n+        example.want = ''\n+        self.skipped += 1\n+      elif example.exc_msg is None and any(\n+          wont_implement(example)\n+          for wont_implement in self._wont_implement.get(test.name, [])):\n         # Don't fail doctests that raise this error.\n         example.exc_msg = (\n             'apache_beam.dataframe.frame_base.WontImplementError: ...')\n+        self.wont_implement += 1", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "69b1b391628860a75b63d0dc9b5f0153af8eb017"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDU2NjUyMQ==", "bodyText": "Worth printing the stats regardless of failure?", "url": "https://github.com/apache/beam/pull/12440#discussion_r464566521", "createdAt": "2020-08-03T17:44:04Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/doctests.py", "diffHunk": "@@ -290,34 +298,60 @@ def to_callable(cond):\n     super(BeamDataframeDoctestRunner, self).__init__(\n         checker=_DeferrredDataframeOutputChecker(self._test_env, use_beam),\n         **kwargs)\n+    self.skipped = 0\n+    self.wont_implement = 0\n \n   def run(self, test, **kwargs):\n     self._checker.reset()\n-    if test.name in self._skip:\n-      for example in test.examples:\n-        if any(should_skip(example) for should_skip in self._skip[test.name]):\n-          example.source = 'pass'\n-          example.want = ''\n     for example in test.examples:\n-      if example.exc_msg is None:\n+      if any(should_skip(example)\n+             for should_skip in self._skip.get(test.name, [])):\n+        example.source = 'pass'\n+        example.want = ''\n+        self.skipped += 1\n+      elif example.exc_msg is None and any(\n+          wont_implement(example)\n+          for wont_implement in self._wont_implement.get(test.name, [])):\n         # Don't fail doctests that raise this error.\n         example.exc_msg = (\n             'apache_beam.dataframe.frame_base.WontImplementError: ...')\n+        self.wont_implement += 1\n     with self._test_env.context():\n-      return super(BeamDataframeDoctestRunner, self).run(test, **kwargs)\n+      result = super(BeamDataframeDoctestRunner, self).run(test, **kwargs)\n+      return result\n \n   def fake_pandas_module(self):\n     return self._test_env.fake_pandas_module()\n \n+  def summarize(self):\n+    super(BeamDataframeDoctestRunner, self).summarize()\n+    if self.failures:\n+      return", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "69b1b391628860a75b63d0dc9b5f0153af8eb017"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDU2NzQ1OQ==", "bodyText": "The way this is implemented, self.tries includes the skipped ones (which get mutated to pass). I suppose we could instead remove them from the examples list altogether.", "url": "https://github.com/apache/beam/pull/12440#discussion_r464567459", "createdAt": "2020-08-03T17:45:44Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/doctests.py", "diffHunk": "@@ -290,34 +298,60 @@ def to_callable(cond):\n     super(BeamDataframeDoctestRunner, self).__init__(\n         checker=_DeferrredDataframeOutputChecker(self._test_env, use_beam),\n         **kwargs)\n+    self.skipped = 0\n+    self.wont_implement = 0\n \n   def run(self, test, **kwargs):\n     self._checker.reset()\n-    if test.name in self._skip:\n-      for example in test.examples:\n-        if any(should_skip(example) for should_skip in self._skip[test.name]):\n-          example.source = 'pass'\n-          example.want = ''\n     for example in test.examples:\n-      if example.exc_msg is None:\n+      if any(should_skip(example)\n+             for should_skip in self._skip.get(test.name, [])):\n+        example.source = 'pass'\n+        example.want = ''\n+        self.skipped += 1\n+      elif example.exc_msg is None and any(\n+          wont_implement(example)\n+          for wont_implement in self._wont_implement.get(test.name, [])):\n         # Don't fail doctests that raise this error.\n         example.exc_msg = (\n             'apache_beam.dataframe.frame_base.WontImplementError: ...')\n+        self.wont_implement += 1\n     with self._test_env.context():\n-      return super(BeamDataframeDoctestRunner, self).run(test, **kwargs)\n+      result = super(BeamDataframeDoctestRunner, self).run(test, **kwargs)\n+      return result\n \n   def fake_pandas_module(self):\n     return self._test_env.fake_pandas_module()\n \n+  def summarize(self):\n+    super(BeamDataframeDoctestRunner, self).summarize()\n+    if self.failures:\n+      return\n+    total_test_cases = self.skipped + self.tries", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "69b1b391628860a75b63d0dc9b5f0153af8eb017"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDU2ODk3OQ==", "bodyText": "Just because they're not won't implement, doesn't mean we will (e.g .they could be skipped, or they're already implemented in which case the future tense is odd). Maybe break this down as\nXxx total test cases.\n    Xxx skipped\n    Xxx won't implement\n        Yyy reason A\n        Yyy reason B\n        ...\n    Xxx passed", "url": "https://github.com/apache/beam/pull/12440#discussion_r464568979", "createdAt": "2020-08-03T17:48:46Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/doctests.py", "diffHunk": "@@ -290,34 +298,60 @@ def to_callable(cond):\n     super(BeamDataframeDoctestRunner, self).__init__(\n         checker=_DeferrredDataframeOutputChecker(self._test_env, use_beam),\n         **kwargs)\n+    self.skipped = 0\n+    self.wont_implement = 0\n \n   def run(self, test, **kwargs):\n     self._checker.reset()\n-    if test.name in self._skip:\n-      for example in test.examples:\n-        if any(should_skip(example) for should_skip in self._skip[test.name]):\n-          example.source = 'pass'\n-          example.want = ''\n     for example in test.examples:\n-      if example.exc_msg is None:\n+      if any(should_skip(example)\n+             for should_skip in self._skip.get(test.name, [])):\n+        example.source = 'pass'\n+        example.want = ''\n+        self.skipped += 1\n+      elif example.exc_msg is None and any(\n+          wont_implement(example)\n+          for wont_implement in self._wont_implement.get(test.name, [])):\n         # Don't fail doctests that raise this error.\n         example.exc_msg = (\n             'apache_beam.dataframe.frame_base.WontImplementError: ...')\n+        self.wont_implement += 1\n     with self._test_env.context():\n-      return super(BeamDataframeDoctestRunner, self).run(test, **kwargs)\n+      result = super(BeamDataframeDoctestRunner, self).run(test, **kwargs)\n+      return result\n \n   def fake_pandas_module(self):\n     return self._test_env.fake_pandas_module()\n \n+  def summarize(self):\n+    super(BeamDataframeDoctestRunner, self).summarize()\n+    if self.failures:\n+      return\n+    total_test_cases = self.skipped + self.tries\n+    will_implement = total_test_cases - self.wont_implement\n+    print(\"%d total test cases.\" % total_test_cases)\n+    print(\n+        \"%d will implement, %d won't implement.\" %", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "69b1b391628860a75b63d0dc9b5f0153af8eb017"}, "originalPosition": 75}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "41830e56916ff583bbda6b299f62ebf8888995b2", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/41830e56916ff583bbda6b299f62ebf8888995b2", "committedDate": "2020-08-06T22:38:39Z", "message": "pandas_doctest_test now logs a report about the number of skipped vs wont implement vs passing tests"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9224526a5da4b0190ce401ceb7c202c23fac110c", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/9224526a5da4b0190ce401ceb7c202c23fac110c", "committedDate": "2020-08-06T22:34:32Z", "message": "address pr comments"}, "afterCommit": {"oid": "41830e56916ff583bbda6b299f62ebf8888995b2", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/41830e56916ff583bbda6b299f62ebf8888995b2", "committedDate": "2020-08-06T22:38:39Z", "message": "pandas_doctest_test now logs a report about the number of skipped vs wont implement vs passing tests"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDYyOTY2ODk1", "url": "https://github.com/apache/beam/pull/12440#pullrequestreview-462966895", "createdAt": "2020-08-07T00:47:52Z", "commit": {"oid": "41830e56916ff583bbda6b299f62ebf8888995b2"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwMDo0Nzo1M1rOG9Iyag==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wN1QwMDo0Nzo1M1rOG9Iyag==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Njc2MDI5OA==", "bodyText": "Maybe rename this to \"wont_implement_ok\"?", "url": "https://github.com/apache/beam/pull/12440#discussion_r466760298", "createdAt": "2020-08-07T00:47:53Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/pandas_doctests_test.py", "diffHunk": "@@ -90,6 +113,16 @@ def test_series_tests(self):\n     result = doctests.testmod(\n         pd.core.series,\n         use_beam=False,\n+        report=True,\n+        wont_implement={", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "41830e56916ff583bbda6b299f62ebf8888995b2"}, "originalPosition": 38}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d6965c8b67467dd76ed14a23a1b9b999804cbfbe", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/d6965c8b67467dd76ed14a23a1b9b999804cbfbe", "committedDate": "2020-08-07T19:48:18Z", "message": "wont_implement_ok"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e182a0728a3a7bb7bd02a583862c0d90f04035f0", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/e182a0728a3a7bb7bd02a583862c0d90f04035f0", "committedDate": "2020-08-07T20:37:17Z", "message": "fix tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b3dd9653e269c919d2130dab53847f8cf6c356e3", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/b3dd9653e269c919d2130dab53847f8cf6c356e3", "committedDate": "2020-08-07T21:02:30Z", "message": "yapf"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dbfbaeb5fe25922a07e5208925ca5ab1939bca7b", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/dbfbaeb5fe25922a07e5208925ca5ab1939bca7b", "committedDate": "2020-08-07T21:03:19Z", "message": "Merge remote-tracking branch 'origin/master' into pandas-report-implemented"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3662, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}