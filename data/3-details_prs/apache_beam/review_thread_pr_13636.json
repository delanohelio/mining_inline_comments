{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTQ2OTc3MTQx", "number": 13636, "reviewThreads": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0zMFQxNzo0OToyNVrOFKI06w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQyMzo1NToyN1rOFRqjPw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ2MTc0Njk5OnYy", "diffSide": "RIGHT", "path": "examples/java/src/test/java/org/apache/beam/examples/complete/kafkatopubsub/KafkaToPubsubE2ETest.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0zMFQxNzo0OToyNVrOIMyLgw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQwNzoyMTo1NFrOITSchA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDI3NTk3MQ==", "bodyText": "You might look at using TestPubsub to create the test topic instead of creating it manually. TestPubsub also has a method that you can use to check the topic receives some expected messages, which would save you from creating the readFromPubsub transform to signal success from within the pipeline: \n  \n    \n      beam/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsub/TestPubsub.java\n    \n    \n         Line 342\n      in\n      5e17b69\n    \n    \n    \n    \n\n        \n          \n             public PollingAssertion assertThatTopicEventuallyReceives(Matcher<PubsubMessage>... matchers) { \n        \n    \n  \n\n\nIt will be tricky to make this work with the pubsub test container though, since we'll need to start the test container before the TestPubsub Rule initializes its topic. This would be really useful infrastructure though as it would allow us to run many other pubsub tests against the fake instead of prod pubsub.", "url": "https://github.com/apache/beam/pull/13636#discussion_r550275971", "createdAt": "2020-12-30T17:49:25Z", "author": {"login": "TheNeuralBit"}, "path": "examples/java/src/test/java/org/apache/beam/examples/complete/kafkatopubsub/KafkaToPubsubE2ETest.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.examples.complete.kafkatopubsub;\n+\n+import static org.apache.beam.examples.complete.kafkatopubsub.transforms.FormatTransform.readFromKafka;\n+\n+import com.google.auth.Credentials;\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.function.Supplier;\n+import org.apache.beam.examples.complete.kafkatopubsub.utils.RunKafkaContainer;\n+import org.apache.beam.runners.direct.DirectOptions;\n+import org.apache.beam.sdk.PipelineResult;\n+import org.apache.beam.sdk.extensions.gcp.auth.NoopCredentialFactory;\n+import org.apache.beam.sdk.extensions.gcp.options.GcpOptions;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubClient;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubIO;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubJsonClient;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubOptions;\n+import org.apache.beam.sdk.io.gcp.pubsub.TestPubsubSignal;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.testing.TestPipeline;\n+import org.apache.beam.sdk.transforms.Values;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.joda.time.Duration;\n+import org.junit.BeforeClass;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.testcontainers.containers.PubSubEmulatorContainer;\n+import org.testcontainers.utility.DockerImageName;\n+\n+/** E2E test for {@link KafkaToPubsub} pipeline. */\n+public class KafkaToPubsubE2ETest {\n+\n+  @Rule public final transient TestPipeline pipeline = TestPipeline.fromOptions(OPTIONS);\n+  @Rule public transient TestPubsubSignal signal = TestPubsubSignal.fromOptions(OPTIONS);\n+\n+  private static final String PUBSUB_EMULATOR_IMAGE =\n+      \"gcr.io/google.com/cloudsdktool/cloud-sdk:316.0.0-emulators\";\n+  private static final String PUBSUB_MESSAGE = \"test pubsub message\";\n+  private static final String PROJECT_ID = \"try-kafka-pubsub\";\n+  private static final String TOPIC_NAME = \"listen-to-kafka\";\n+  private static final PubsubClient.TopicPath TOPIC_PATH =\n+      PubsubClient.topicPathFromName(PROJECT_ID, TOPIC_NAME);\n+  private static final PipelineOptions OPTIONS = TestPipeline.testingPipelineOptions();\n+\n+  @BeforeClass\n+  public static void beforeClass() throws Exception {\n+    Credentials credentials = NoopCredentialFactory.fromOptions(OPTIONS).getCredential();\n+    OPTIONS.as(GcpOptions.class).setGcpCredential(credentials);\n+    OPTIONS.as(GcpOptions.class).setProject(PROJECT_ID);\n+    setupPubsubContainer(OPTIONS.as(PubsubOptions.class));\n+    createPubsubTopicForTest(OPTIONS.as(PubsubOptions.class));\n+  }\n+\n+  @Test\n+  public void testKafkaToPubsubE2E() throws IOException {\n+    pipeline.getOptions().as(DirectOptions.class).setBlockOnRun(false);\n+\n+    RunKafkaContainer rkc = new RunKafkaContainer(PUBSUB_MESSAGE);\n+    String bootstrapServer = rkc.getBootstrapServer();\n+    String[] kafkaTopicsList = new String[] {rkc.getTopicName()};\n+\n+    String pubsubTopicPath = TOPIC_PATH.getPath();\n+\n+    Map<String, Object> kafkaConfig = new HashMap<>();\n+    Map<String, String> sslConfig = new HashMap<>();\n+\n+    PCollection<KV<String, String>> readStrings =\n+        pipeline.apply(\n+            \"readFromKafka\",\n+            readFromKafka(bootstrapServer, Arrays.asList(kafkaTopicsList), kafkaConfig, sslConfig));\n+\n+    PCollection<String> readFromPubsub =\n+        readStrings\n+            .apply(Values.create())\n+            .apply(\"writeToPubSub\", PubsubIO.writeStrings().to(pubsubTopicPath))\n+            .getPipeline()\n+            .apply(\"readFromPubsub\", PubsubIO.readStrings().fromTopic(pubsubTopicPath));\n+\n+    readFromPubsub.apply(\n+        \"waitForTestMessage\",\n+        signal.signalSuccessWhen(\n+            readFromPubsub.getCoder(),\n+            input -> {\n+              if (input == null) {\n+                return false;\n+              }\n+              return input.stream().anyMatch(message -> Objects.equals(message, PUBSUB_MESSAGE));\n+            }));\n+\n+    Supplier<Void> start = signal.waitForStart(Duration.standardSeconds(10));\n+    pipeline.apply(signal.signalStart());\n+    PipelineResult job = pipeline.run();\n+    start.get();\n+    signal.waitForSuccess(Duration.standardMinutes(2));\n+    try {\n+      job.cancel();\n+    } catch (IOException | UnsupportedOperationException e) {\n+      throw new AssertionError(\"Could not stop pipeline.\", e);\n+    }\n+  }\n+\n+  private static void setupPubsubContainer(PubsubOptions options) {\n+    PubSubEmulatorContainer emulator =\n+        new PubSubEmulatorContainer(DockerImageName.parse(PUBSUB_EMULATOR_IMAGE));\n+    emulator.start();\n+    String pubsubUrl = emulator.getEmulatorEndpoint();\n+    options.setPubsubRootUrl(\"http://\" + pubsubUrl);\n+  }\n+\n+  private static void createPubsubTopicForTest(PubsubOptions options) {\n+    try {\n+      PubsubClient pubsubClient = PubsubJsonClient.FACTORY.newClient(null, null, options);\n+      pubsubClient.createTopic(TOPIC_PATH);\n+    } catch (Exception e) {\n+      throw new RuntimeException(e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc7b38a6753b514a6df07dc56e20e7fd4500fd8c"}, "originalPosition": 136}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ4MTIxNQ==", "bodyText": "Thank you for the suggestion, changed to using TestPubsub", "url": "https://github.com/apache/beam/pull/13636#discussion_r556481215", "createdAt": "2021-01-13T12:23:17Z", "author": {"login": "ramazan-yapparov"}, "path": "examples/java/src/test/java/org/apache/beam/examples/complete/kafkatopubsub/KafkaToPubsubE2ETest.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.examples.complete.kafkatopubsub;\n+\n+import static org.apache.beam.examples.complete.kafkatopubsub.transforms.FormatTransform.readFromKafka;\n+\n+import com.google.auth.Credentials;\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.function.Supplier;\n+import org.apache.beam.examples.complete.kafkatopubsub.utils.RunKafkaContainer;\n+import org.apache.beam.runners.direct.DirectOptions;\n+import org.apache.beam.sdk.PipelineResult;\n+import org.apache.beam.sdk.extensions.gcp.auth.NoopCredentialFactory;\n+import org.apache.beam.sdk.extensions.gcp.options.GcpOptions;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubClient;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubIO;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubJsonClient;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubOptions;\n+import org.apache.beam.sdk.io.gcp.pubsub.TestPubsubSignal;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.testing.TestPipeline;\n+import org.apache.beam.sdk.transforms.Values;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.joda.time.Duration;\n+import org.junit.BeforeClass;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.testcontainers.containers.PubSubEmulatorContainer;\n+import org.testcontainers.utility.DockerImageName;\n+\n+/** E2E test for {@link KafkaToPubsub} pipeline. */\n+public class KafkaToPubsubE2ETest {\n+\n+  @Rule public final transient TestPipeline pipeline = TestPipeline.fromOptions(OPTIONS);\n+  @Rule public transient TestPubsubSignal signal = TestPubsubSignal.fromOptions(OPTIONS);\n+\n+  private static final String PUBSUB_EMULATOR_IMAGE =\n+      \"gcr.io/google.com/cloudsdktool/cloud-sdk:316.0.0-emulators\";\n+  private static final String PUBSUB_MESSAGE = \"test pubsub message\";\n+  private static final String PROJECT_ID = \"try-kafka-pubsub\";\n+  private static final String TOPIC_NAME = \"listen-to-kafka\";\n+  private static final PubsubClient.TopicPath TOPIC_PATH =\n+      PubsubClient.topicPathFromName(PROJECT_ID, TOPIC_NAME);\n+  private static final PipelineOptions OPTIONS = TestPipeline.testingPipelineOptions();\n+\n+  @BeforeClass\n+  public static void beforeClass() throws Exception {\n+    Credentials credentials = NoopCredentialFactory.fromOptions(OPTIONS).getCredential();\n+    OPTIONS.as(GcpOptions.class).setGcpCredential(credentials);\n+    OPTIONS.as(GcpOptions.class).setProject(PROJECT_ID);\n+    setupPubsubContainer(OPTIONS.as(PubsubOptions.class));\n+    createPubsubTopicForTest(OPTIONS.as(PubsubOptions.class));\n+  }\n+\n+  @Test\n+  public void testKafkaToPubsubE2E() throws IOException {\n+    pipeline.getOptions().as(DirectOptions.class).setBlockOnRun(false);\n+\n+    RunKafkaContainer rkc = new RunKafkaContainer(PUBSUB_MESSAGE);\n+    String bootstrapServer = rkc.getBootstrapServer();\n+    String[] kafkaTopicsList = new String[] {rkc.getTopicName()};\n+\n+    String pubsubTopicPath = TOPIC_PATH.getPath();\n+\n+    Map<String, Object> kafkaConfig = new HashMap<>();\n+    Map<String, String> sslConfig = new HashMap<>();\n+\n+    PCollection<KV<String, String>> readStrings =\n+        pipeline.apply(\n+            \"readFromKafka\",\n+            readFromKafka(bootstrapServer, Arrays.asList(kafkaTopicsList), kafkaConfig, sslConfig));\n+\n+    PCollection<String> readFromPubsub =\n+        readStrings\n+            .apply(Values.create())\n+            .apply(\"writeToPubSub\", PubsubIO.writeStrings().to(pubsubTopicPath))\n+            .getPipeline()\n+            .apply(\"readFromPubsub\", PubsubIO.readStrings().fromTopic(pubsubTopicPath));\n+\n+    readFromPubsub.apply(\n+        \"waitForTestMessage\",\n+        signal.signalSuccessWhen(\n+            readFromPubsub.getCoder(),\n+            input -> {\n+              if (input == null) {\n+                return false;\n+              }\n+              return input.stream().anyMatch(message -> Objects.equals(message, PUBSUB_MESSAGE));\n+            }));\n+\n+    Supplier<Void> start = signal.waitForStart(Duration.standardSeconds(10));\n+    pipeline.apply(signal.signalStart());\n+    PipelineResult job = pipeline.run();\n+    start.get();\n+    signal.waitForSuccess(Duration.standardMinutes(2));\n+    try {\n+      job.cancel();\n+    } catch (IOException | UnsupportedOperationException e) {\n+      throw new AssertionError(\"Could not stop pipeline.\", e);\n+    }\n+  }\n+\n+  private static void setupPubsubContainer(PubsubOptions options) {\n+    PubSubEmulatorContainer emulator =\n+        new PubSubEmulatorContainer(DockerImageName.parse(PUBSUB_EMULATOR_IMAGE));\n+    emulator.start();\n+    String pubsubUrl = emulator.getEmulatorEndpoint();\n+    options.setPubsubRootUrl(\"http://\" + pubsubUrl);\n+  }\n+\n+  private static void createPubsubTopicForTest(PubsubOptions options) {\n+    try {\n+      PubsubClient pubsubClient = PubsubJsonClient.FACTORY.newClient(null, null, options);\n+      pubsubClient.createTopic(TOPIC_PATH);\n+    } catch (Exception e) {\n+      throw new RuntimeException(e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDI3NTk3MQ=="}, "originalCommit": {"oid": "bc7b38a6753b514a6df07dc56e20e7fd4500fd8c"}, "originalPosition": 136}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Njk1MjEzNw==", "bodyText": "Awesome! Thanks for making TestPubSub work with the emulator container \ud83d\udc4d\nIs the trick to making sure the test container is run before TestPubsub to make the container a @ClassRule?", "url": "https://github.com/apache/beam/pull/13636#discussion_r556952137", "createdAt": "2021-01-13T23:49:01Z", "author": {"login": "TheNeuralBit"}, "path": "examples/java/src/test/java/org/apache/beam/examples/complete/kafkatopubsub/KafkaToPubsubE2ETest.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.examples.complete.kafkatopubsub;\n+\n+import static org.apache.beam.examples.complete.kafkatopubsub.transforms.FormatTransform.readFromKafka;\n+\n+import com.google.auth.Credentials;\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.function.Supplier;\n+import org.apache.beam.examples.complete.kafkatopubsub.utils.RunKafkaContainer;\n+import org.apache.beam.runners.direct.DirectOptions;\n+import org.apache.beam.sdk.PipelineResult;\n+import org.apache.beam.sdk.extensions.gcp.auth.NoopCredentialFactory;\n+import org.apache.beam.sdk.extensions.gcp.options.GcpOptions;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubClient;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubIO;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubJsonClient;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubOptions;\n+import org.apache.beam.sdk.io.gcp.pubsub.TestPubsubSignal;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.testing.TestPipeline;\n+import org.apache.beam.sdk.transforms.Values;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.joda.time.Duration;\n+import org.junit.BeforeClass;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.testcontainers.containers.PubSubEmulatorContainer;\n+import org.testcontainers.utility.DockerImageName;\n+\n+/** E2E test for {@link KafkaToPubsub} pipeline. */\n+public class KafkaToPubsubE2ETest {\n+\n+  @Rule public final transient TestPipeline pipeline = TestPipeline.fromOptions(OPTIONS);\n+  @Rule public transient TestPubsubSignal signal = TestPubsubSignal.fromOptions(OPTIONS);\n+\n+  private static final String PUBSUB_EMULATOR_IMAGE =\n+      \"gcr.io/google.com/cloudsdktool/cloud-sdk:316.0.0-emulators\";\n+  private static final String PUBSUB_MESSAGE = \"test pubsub message\";\n+  private static final String PROJECT_ID = \"try-kafka-pubsub\";\n+  private static final String TOPIC_NAME = \"listen-to-kafka\";\n+  private static final PubsubClient.TopicPath TOPIC_PATH =\n+      PubsubClient.topicPathFromName(PROJECT_ID, TOPIC_NAME);\n+  private static final PipelineOptions OPTIONS = TestPipeline.testingPipelineOptions();\n+\n+  @BeforeClass\n+  public static void beforeClass() throws Exception {\n+    Credentials credentials = NoopCredentialFactory.fromOptions(OPTIONS).getCredential();\n+    OPTIONS.as(GcpOptions.class).setGcpCredential(credentials);\n+    OPTIONS.as(GcpOptions.class).setProject(PROJECT_ID);\n+    setupPubsubContainer(OPTIONS.as(PubsubOptions.class));\n+    createPubsubTopicForTest(OPTIONS.as(PubsubOptions.class));\n+  }\n+\n+  @Test\n+  public void testKafkaToPubsubE2E() throws IOException {\n+    pipeline.getOptions().as(DirectOptions.class).setBlockOnRun(false);\n+\n+    RunKafkaContainer rkc = new RunKafkaContainer(PUBSUB_MESSAGE);\n+    String bootstrapServer = rkc.getBootstrapServer();\n+    String[] kafkaTopicsList = new String[] {rkc.getTopicName()};\n+\n+    String pubsubTopicPath = TOPIC_PATH.getPath();\n+\n+    Map<String, Object> kafkaConfig = new HashMap<>();\n+    Map<String, String> sslConfig = new HashMap<>();\n+\n+    PCollection<KV<String, String>> readStrings =\n+        pipeline.apply(\n+            \"readFromKafka\",\n+            readFromKafka(bootstrapServer, Arrays.asList(kafkaTopicsList), kafkaConfig, sslConfig));\n+\n+    PCollection<String> readFromPubsub =\n+        readStrings\n+            .apply(Values.create())\n+            .apply(\"writeToPubSub\", PubsubIO.writeStrings().to(pubsubTopicPath))\n+            .getPipeline()\n+            .apply(\"readFromPubsub\", PubsubIO.readStrings().fromTopic(pubsubTopicPath));\n+\n+    readFromPubsub.apply(\n+        \"waitForTestMessage\",\n+        signal.signalSuccessWhen(\n+            readFromPubsub.getCoder(),\n+            input -> {\n+              if (input == null) {\n+                return false;\n+              }\n+              return input.stream().anyMatch(message -> Objects.equals(message, PUBSUB_MESSAGE));\n+            }));\n+\n+    Supplier<Void> start = signal.waitForStart(Duration.standardSeconds(10));\n+    pipeline.apply(signal.signalStart());\n+    PipelineResult job = pipeline.run();\n+    start.get();\n+    signal.waitForSuccess(Duration.standardMinutes(2));\n+    try {\n+      job.cancel();\n+    } catch (IOException | UnsupportedOperationException e) {\n+      throw new AssertionError(\"Could not stop pipeline.\", e);\n+    }\n+  }\n+\n+  private static void setupPubsubContainer(PubsubOptions options) {\n+    PubSubEmulatorContainer emulator =\n+        new PubSubEmulatorContainer(DockerImageName.parse(PUBSUB_EMULATOR_IMAGE));\n+    emulator.start();\n+    String pubsubUrl = emulator.getEmulatorEndpoint();\n+    options.setPubsubRootUrl(\"http://\" + pubsubUrl);\n+  }\n+\n+  private static void createPubsubTopicForTest(PubsubOptions options) {\n+    try {\n+      PubsubClient pubsubClient = PubsubJsonClient.FACTORY.newClient(null, null, options);\n+      pubsubClient.createTopic(TOPIC_PATH);\n+    } catch (Exception e) {\n+      throw new RuntimeException(e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDI3NTk3MQ=="}, "originalCommit": {"oid": "bc7b38a6753b514a6df07dc56e20e7fd4500fd8c"}, "originalPosition": 136}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzA5NjA2OA==", "bodyText": "Exactly", "url": "https://github.com/apache/beam/pull/13636#discussion_r557096068", "createdAt": "2021-01-14T07:21:54Z", "author": {"login": "ramazan-yapparov"}, "path": "examples/java/src/test/java/org/apache/beam/examples/complete/kafkatopubsub/KafkaToPubsubE2ETest.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.examples.complete.kafkatopubsub;\n+\n+import static org.apache.beam.examples.complete.kafkatopubsub.transforms.FormatTransform.readFromKafka;\n+\n+import com.google.auth.Credentials;\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.function.Supplier;\n+import org.apache.beam.examples.complete.kafkatopubsub.utils.RunKafkaContainer;\n+import org.apache.beam.runners.direct.DirectOptions;\n+import org.apache.beam.sdk.PipelineResult;\n+import org.apache.beam.sdk.extensions.gcp.auth.NoopCredentialFactory;\n+import org.apache.beam.sdk.extensions.gcp.options.GcpOptions;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubClient;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubIO;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubJsonClient;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubOptions;\n+import org.apache.beam.sdk.io.gcp.pubsub.TestPubsubSignal;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.testing.TestPipeline;\n+import org.apache.beam.sdk.transforms.Values;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.joda.time.Duration;\n+import org.junit.BeforeClass;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.testcontainers.containers.PubSubEmulatorContainer;\n+import org.testcontainers.utility.DockerImageName;\n+\n+/** E2E test for {@link KafkaToPubsub} pipeline. */\n+public class KafkaToPubsubE2ETest {\n+\n+  @Rule public final transient TestPipeline pipeline = TestPipeline.fromOptions(OPTIONS);\n+  @Rule public transient TestPubsubSignal signal = TestPubsubSignal.fromOptions(OPTIONS);\n+\n+  private static final String PUBSUB_EMULATOR_IMAGE =\n+      \"gcr.io/google.com/cloudsdktool/cloud-sdk:316.0.0-emulators\";\n+  private static final String PUBSUB_MESSAGE = \"test pubsub message\";\n+  private static final String PROJECT_ID = \"try-kafka-pubsub\";\n+  private static final String TOPIC_NAME = \"listen-to-kafka\";\n+  private static final PubsubClient.TopicPath TOPIC_PATH =\n+      PubsubClient.topicPathFromName(PROJECT_ID, TOPIC_NAME);\n+  private static final PipelineOptions OPTIONS = TestPipeline.testingPipelineOptions();\n+\n+  @BeforeClass\n+  public static void beforeClass() throws Exception {\n+    Credentials credentials = NoopCredentialFactory.fromOptions(OPTIONS).getCredential();\n+    OPTIONS.as(GcpOptions.class).setGcpCredential(credentials);\n+    OPTIONS.as(GcpOptions.class).setProject(PROJECT_ID);\n+    setupPubsubContainer(OPTIONS.as(PubsubOptions.class));\n+    createPubsubTopicForTest(OPTIONS.as(PubsubOptions.class));\n+  }\n+\n+  @Test\n+  public void testKafkaToPubsubE2E() throws IOException {\n+    pipeline.getOptions().as(DirectOptions.class).setBlockOnRun(false);\n+\n+    RunKafkaContainer rkc = new RunKafkaContainer(PUBSUB_MESSAGE);\n+    String bootstrapServer = rkc.getBootstrapServer();\n+    String[] kafkaTopicsList = new String[] {rkc.getTopicName()};\n+\n+    String pubsubTopicPath = TOPIC_PATH.getPath();\n+\n+    Map<String, Object> kafkaConfig = new HashMap<>();\n+    Map<String, String> sslConfig = new HashMap<>();\n+\n+    PCollection<KV<String, String>> readStrings =\n+        pipeline.apply(\n+            \"readFromKafka\",\n+            readFromKafka(bootstrapServer, Arrays.asList(kafkaTopicsList), kafkaConfig, sslConfig));\n+\n+    PCollection<String> readFromPubsub =\n+        readStrings\n+            .apply(Values.create())\n+            .apply(\"writeToPubSub\", PubsubIO.writeStrings().to(pubsubTopicPath))\n+            .getPipeline()\n+            .apply(\"readFromPubsub\", PubsubIO.readStrings().fromTopic(pubsubTopicPath));\n+\n+    readFromPubsub.apply(\n+        \"waitForTestMessage\",\n+        signal.signalSuccessWhen(\n+            readFromPubsub.getCoder(),\n+            input -> {\n+              if (input == null) {\n+                return false;\n+              }\n+              return input.stream().anyMatch(message -> Objects.equals(message, PUBSUB_MESSAGE));\n+            }));\n+\n+    Supplier<Void> start = signal.waitForStart(Duration.standardSeconds(10));\n+    pipeline.apply(signal.signalStart());\n+    PipelineResult job = pipeline.run();\n+    start.get();\n+    signal.waitForSuccess(Duration.standardMinutes(2));\n+    try {\n+      job.cancel();\n+    } catch (IOException | UnsupportedOperationException e) {\n+      throw new AssertionError(\"Could not stop pipeline.\", e);\n+    }\n+  }\n+\n+  private static void setupPubsubContainer(PubsubOptions options) {\n+    PubSubEmulatorContainer emulator =\n+        new PubSubEmulatorContainer(DockerImageName.parse(PUBSUB_EMULATOR_IMAGE));\n+    emulator.start();\n+    String pubsubUrl = emulator.getEmulatorEndpoint();\n+    options.setPubsubRootUrl(\"http://\" + pubsubUrl);\n+  }\n+\n+  private static void createPubsubTopicForTest(PubsubOptions options) {\n+    try {\n+      PubsubClient pubsubClient = PubsubJsonClient.FACTORY.newClient(null, null, options);\n+      pubsubClient.createTopic(TOPIC_PATH);\n+    } catch (Exception e) {\n+      throw new RuntimeException(e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDI3NTk3MQ=="}, "originalCommit": {"oid": "bc7b38a6753b514a6df07dc56e20e7fd4500fd8c"}, "originalPosition": 136}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ2MTc1OTc1OnYy", "diffSide": "RIGHT", "path": "examples/java/src/test/java/org/apache/beam/examples/complete/kafkatopubsub/utils/RunKafkaContainer.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0zMFQxNzo1NjowNlrOIMySxg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xM1QxMjoyMzo1NFrOISs8JA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDI3NzgzMA==", "bodyText": "Could you instead inject the data in the test after the pipeline has started?", "url": "https://github.com/apache/beam/pull/13636#discussion_r550277830", "createdAt": "2020-12-30T17:56:06Z", "author": {"login": "TheNeuralBit"}, "path": "examples/java/src/test/java/org/apache/beam/examples/complete/kafkatopubsub/utils/RunKafkaContainer.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.examples.complete.kafkatopubsub.utils;\n+\n+import java.util.UUID;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+import org.apache.kafka.clients.producer.KafkaProducer;\n+import org.apache.kafka.clients.producer.ProducerConfig;\n+import org.apache.kafka.clients.producer.ProducerRecord;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.testcontainers.containers.KafkaContainer;\n+import org.testcontainers.utility.DockerImageName;\n+\n+/** Run kafka container in separate thread to produce message. */\n+public class RunKafkaContainer {\n+\n+  private static final String KAFKA_IMAGE_NAME = \"confluentinc/cp-kafka:5.4.3\";\n+  private final String topicName;\n+  private final KafkaProducer<String, String> producer;\n+  private final String bootstrapServer;\n+\n+  public RunKafkaContainer(String pubsubMessage) {\n+    bootstrapServer = setupKafkaContainer();\n+    topicName = \"messages-topic\";\n+    producer =\n+        new KafkaProducer<>(\n+            ImmutableMap.of(\n+                ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,\n+                bootstrapServer,\n+                ProducerConfig.CLIENT_ID_CONFIG,\n+                UUID.randomUUID().toString()),\n+            new StringSerializer(),\n+            new StringSerializer());\n+    Runnable kafkaProducer =\n+        () -> {\n+          try {\n+            producer.send(new ProducerRecord<>(topicName, \"testcontainers\", pubsubMessage)).get();\n+            System.out.println(\"Producer sent\");\n+          } catch (ExecutionException | InterruptedException e) {\n+            throw new RuntimeException(\"Something went wrong in kafka producer\", e);\n+          }\n+        };\n+    // Without saving `.schedule(...)` result to variable checkframework will fail\n+    @SuppressWarnings(\"unused\")\n+    ScheduledFuture<?> schedule =\n+        Executors.newSingleThreadScheduledExecutor().schedule(kafkaProducer, 10, TimeUnit.SECONDS);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc7b38a6753b514a6df07dc56e20e7fd4500fd8c"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ4MTU3Mg==", "bodyText": "Fixed, thanks", "url": "https://github.com/apache/beam/pull/13636#discussion_r556481572", "createdAt": "2021-01-13T12:23:54Z", "author": {"login": "ramazan-yapparov"}, "path": "examples/java/src/test/java/org/apache/beam/examples/complete/kafkatopubsub/utils/RunKafkaContainer.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.examples.complete.kafkatopubsub.utils;\n+\n+import java.util.UUID;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+import org.apache.kafka.clients.producer.KafkaProducer;\n+import org.apache.kafka.clients.producer.ProducerConfig;\n+import org.apache.kafka.clients.producer.ProducerRecord;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.testcontainers.containers.KafkaContainer;\n+import org.testcontainers.utility.DockerImageName;\n+\n+/** Run kafka container in separate thread to produce message. */\n+public class RunKafkaContainer {\n+\n+  private static final String KAFKA_IMAGE_NAME = \"confluentinc/cp-kafka:5.4.3\";\n+  private final String topicName;\n+  private final KafkaProducer<String, String> producer;\n+  private final String bootstrapServer;\n+\n+  public RunKafkaContainer(String pubsubMessage) {\n+    bootstrapServer = setupKafkaContainer();\n+    topicName = \"messages-topic\";\n+    producer =\n+        new KafkaProducer<>(\n+            ImmutableMap.of(\n+                ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,\n+                bootstrapServer,\n+                ProducerConfig.CLIENT_ID_CONFIG,\n+                UUID.randomUUID().toString()),\n+            new StringSerializer(),\n+            new StringSerializer());\n+    Runnable kafkaProducer =\n+        () -> {\n+          try {\n+            producer.send(new ProducerRecord<>(topicName, \"testcontainers\", pubsubMessage)).get();\n+            System.out.println(\"Producer sent\");\n+          } catch (ExecutionException | InterruptedException e) {\n+            throw new RuntimeException(\"Something went wrong in kafka producer\", e);\n+          }\n+        };\n+    // Without saving `.schedule(...)` result to variable checkframework will fail\n+    @SuppressWarnings(\"unused\")\n+    ScheduledFuture<?> schedule =\n+        Executors.newSingleThreadScheduledExecutor().schedule(kafkaProducer, 10, TimeUnit.SECONDS);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDI3NzgzMA=="}, "originalCommit": {"oid": "bc7b38a6753b514a6df07dc56e20e7fd4500fd8c"}, "originalPosition": 65}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ2MTc2MDQwOnYy", "diffSide": "RIGHT", "path": "examples/java/src/test/java/org/apache/beam/examples/complete/kafkatopubsub/KafkaToPubsubE2ETest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0zMFQxNzo1NjoyMlrOIMyTHg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xM1QxMjoyNDo0MlrOISs9yg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDI3NzkxOA==", "bodyText": "It would be preferable to run the exact KafkaToPubsub pipeline, then use utilities outside of the pipeline to inject data to the kafka topic, and then to verify the pubsub topic receives the expected messages. As noted in my other comment TestPubsub can help with the latter.", "url": "https://github.com/apache/beam/pull/13636#discussion_r550277918", "createdAt": "2020-12-30T17:56:22Z", "author": {"login": "TheNeuralBit"}, "path": "examples/java/src/test/java/org/apache/beam/examples/complete/kafkatopubsub/KafkaToPubsubE2ETest.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.examples.complete.kafkatopubsub;\n+\n+import static org.apache.beam.examples.complete.kafkatopubsub.transforms.FormatTransform.readFromKafka;\n+\n+import com.google.auth.Credentials;\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.function.Supplier;\n+import org.apache.beam.examples.complete.kafkatopubsub.utils.RunKafkaContainer;\n+import org.apache.beam.runners.direct.DirectOptions;\n+import org.apache.beam.sdk.PipelineResult;\n+import org.apache.beam.sdk.extensions.gcp.auth.NoopCredentialFactory;\n+import org.apache.beam.sdk.extensions.gcp.options.GcpOptions;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubClient;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubIO;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubJsonClient;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubOptions;\n+import org.apache.beam.sdk.io.gcp.pubsub.TestPubsubSignal;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.testing.TestPipeline;\n+import org.apache.beam.sdk.transforms.Values;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.joda.time.Duration;\n+import org.junit.BeforeClass;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.testcontainers.containers.PubSubEmulatorContainer;\n+import org.testcontainers.utility.DockerImageName;\n+\n+/** E2E test for {@link KafkaToPubsub} pipeline. */\n+public class KafkaToPubsubE2ETest {\n+\n+  @Rule public final transient TestPipeline pipeline = TestPipeline.fromOptions(OPTIONS);\n+  @Rule public transient TestPubsubSignal signal = TestPubsubSignal.fromOptions(OPTIONS);\n+\n+  private static final String PUBSUB_EMULATOR_IMAGE =\n+      \"gcr.io/google.com/cloudsdktool/cloud-sdk:316.0.0-emulators\";\n+  private static final String PUBSUB_MESSAGE = \"test pubsub message\";\n+  private static final String PROJECT_ID = \"try-kafka-pubsub\";\n+  private static final String TOPIC_NAME = \"listen-to-kafka\";\n+  private static final PubsubClient.TopicPath TOPIC_PATH =\n+      PubsubClient.topicPathFromName(PROJECT_ID, TOPIC_NAME);\n+  private static final PipelineOptions OPTIONS = TestPipeline.testingPipelineOptions();\n+\n+  @BeforeClass\n+  public static void beforeClass() throws Exception {\n+    Credentials credentials = NoopCredentialFactory.fromOptions(OPTIONS).getCredential();\n+    OPTIONS.as(GcpOptions.class).setGcpCredential(credentials);\n+    OPTIONS.as(GcpOptions.class).setProject(PROJECT_ID);\n+    setupPubsubContainer(OPTIONS.as(PubsubOptions.class));\n+    createPubsubTopicForTest(OPTIONS.as(PubsubOptions.class));\n+  }\n+\n+  @Test\n+  public void testKafkaToPubsubE2E() throws IOException {\n+    pipeline.getOptions().as(DirectOptions.class).setBlockOnRun(false);\n+\n+    RunKafkaContainer rkc = new RunKafkaContainer(PUBSUB_MESSAGE);\n+    String bootstrapServer = rkc.getBootstrapServer();\n+    String[] kafkaTopicsList = new String[] {rkc.getTopicName()};\n+\n+    String pubsubTopicPath = TOPIC_PATH.getPath();\n+\n+    Map<String, Object> kafkaConfig = new HashMap<>();\n+    Map<String, String> sslConfig = new HashMap<>();\n+\n+    PCollection<KV<String, String>> readStrings =\n+        pipeline.apply(\n+            \"readFromKafka\",\n+            readFromKafka(bootstrapServer, Arrays.asList(kafkaTopicsList), kafkaConfig, sslConfig));\n+\n+    PCollection<String> readFromPubsub =\n+        readStrings\n+            .apply(Values.create())\n+            .apply(\"writeToPubSub\", PubsubIO.writeStrings().to(pubsubTopicPath))\n+            .getPipeline()\n+            .apply(\"readFromPubsub\", PubsubIO.readStrings().fromTopic(pubsubTopicPath));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc7b38a6753b514a6df07dc56e20e7fd4500fd8c"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NjQ4MTk5NA==", "bodyText": "Fixed that, now instead of building the pipeline in the test we execute KafkaToPubsub#run method", "url": "https://github.com/apache/beam/pull/13636#discussion_r556481994", "createdAt": "2021-01-13T12:24:42Z", "author": {"login": "ramazan-yapparov"}, "path": "examples/java/src/test/java/org/apache/beam/examples/complete/kafkatopubsub/KafkaToPubsubE2ETest.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.examples.complete.kafkatopubsub;\n+\n+import static org.apache.beam.examples.complete.kafkatopubsub.transforms.FormatTransform.readFromKafka;\n+\n+import com.google.auth.Credentials;\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.function.Supplier;\n+import org.apache.beam.examples.complete.kafkatopubsub.utils.RunKafkaContainer;\n+import org.apache.beam.runners.direct.DirectOptions;\n+import org.apache.beam.sdk.PipelineResult;\n+import org.apache.beam.sdk.extensions.gcp.auth.NoopCredentialFactory;\n+import org.apache.beam.sdk.extensions.gcp.options.GcpOptions;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubClient;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubIO;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubJsonClient;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubOptions;\n+import org.apache.beam.sdk.io.gcp.pubsub.TestPubsubSignal;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.testing.TestPipeline;\n+import org.apache.beam.sdk.transforms.Values;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.joda.time.Duration;\n+import org.junit.BeforeClass;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.testcontainers.containers.PubSubEmulatorContainer;\n+import org.testcontainers.utility.DockerImageName;\n+\n+/** E2E test for {@link KafkaToPubsub} pipeline. */\n+public class KafkaToPubsubE2ETest {\n+\n+  @Rule public final transient TestPipeline pipeline = TestPipeline.fromOptions(OPTIONS);\n+  @Rule public transient TestPubsubSignal signal = TestPubsubSignal.fromOptions(OPTIONS);\n+\n+  private static final String PUBSUB_EMULATOR_IMAGE =\n+      \"gcr.io/google.com/cloudsdktool/cloud-sdk:316.0.0-emulators\";\n+  private static final String PUBSUB_MESSAGE = \"test pubsub message\";\n+  private static final String PROJECT_ID = \"try-kafka-pubsub\";\n+  private static final String TOPIC_NAME = \"listen-to-kafka\";\n+  private static final PubsubClient.TopicPath TOPIC_PATH =\n+      PubsubClient.topicPathFromName(PROJECT_ID, TOPIC_NAME);\n+  private static final PipelineOptions OPTIONS = TestPipeline.testingPipelineOptions();\n+\n+  @BeforeClass\n+  public static void beforeClass() throws Exception {\n+    Credentials credentials = NoopCredentialFactory.fromOptions(OPTIONS).getCredential();\n+    OPTIONS.as(GcpOptions.class).setGcpCredential(credentials);\n+    OPTIONS.as(GcpOptions.class).setProject(PROJECT_ID);\n+    setupPubsubContainer(OPTIONS.as(PubsubOptions.class));\n+    createPubsubTopicForTest(OPTIONS.as(PubsubOptions.class));\n+  }\n+\n+  @Test\n+  public void testKafkaToPubsubE2E() throws IOException {\n+    pipeline.getOptions().as(DirectOptions.class).setBlockOnRun(false);\n+\n+    RunKafkaContainer rkc = new RunKafkaContainer(PUBSUB_MESSAGE);\n+    String bootstrapServer = rkc.getBootstrapServer();\n+    String[] kafkaTopicsList = new String[] {rkc.getTopicName()};\n+\n+    String pubsubTopicPath = TOPIC_PATH.getPath();\n+\n+    Map<String, Object> kafkaConfig = new HashMap<>();\n+    Map<String, String> sslConfig = new HashMap<>();\n+\n+    PCollection<KV<String, String>> readStrings =\n+        pipeline.apply(\n+            \"readFromKafka\",\n+            readFromKafka(bootstrapServer, Arrays.asList(kafkaTopicsList), kafkaConfig, sslConfig));\n+\n+    PCollection<String> readFromPubsub =\n+        readStrings\n+            .apply(Values.create())\n+            .apply(\"writeToPubSub\", PubsubIO.writeStrings().to(pubsubTopicPath))\n+            .getPipeline()\n+            .apply(\"readFromPubsub\", PubsubIO.readStrings().fromTopic(pubsubTopicPath));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDI3NzkxOA=="}, "originalCommit": {"oid": "bc7b38a6753b514a6df07dc56e20e7fd4500fd8c"}, "originalPosition": 98}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUwNjQ4NzgyOnYy", "diffSide": "RIGHT", "path": "examples/java/src/test/java/org/apache/beam/examples/complete/kafkatopubsub/KafkaToPubsubE2ETest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xM1QyMzo1NDo1MlrOITJxxQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xM1QyMzo1NDo1MlrOITJxxQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Njk1NDA1Mw==", "bodyText": "Could you rename this to KafkaToPubsubIT? Our build files assume *Test is a unit test and *IT is an integration test.", "url": "https://github.com/apache/beam/pull/13636#discussion_r556954053", "createdAt": "2021-01-13T23:54:52Z", "author": {"login": "TheNeuralBit"}, "path": "examples/java/src/test/java/org/apache/beam/examples/complete/kafkatopubsub/KafkaToPubsubE2ETest.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.examples.complete.kafkatopubsub;\n+\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.hasProperty;\n+\n+import com.google.auth.Credentials;\n+import java.nio.charset.StandardCharsets;\n+import java.util.UUID;\n+import java.util.concurrent.ExecutionException;\n+import org.apache.beam.examples.complete.kafkatopubsub.options.KafkaToPubsubOptions;\n+import org.apache.beam.examples.complete.kafkatopubsub.transforms.FormatTransform.FORMAT;\n+import org.apache.beam.runners.direct.DirectOptions;\n+import org.apache.beam.sdk.PipelineResult;\n+import org.apache.beam.sdk.extensions.gcp.auth.NoopCredentialFactory;\n+import org.apache.beam.sdk.extensions.gcp.options.GcpOptions;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubOptions;\n+import org.apache.beam.sdk.io.gcp.pubsub.TestPubsub;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.testing.TestPipeline;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.producer.KafkaProducer;\n+import org.apache.kafka.clients.producer.ProducerConfig;\n+import org.apache.kafka.clients.producer.ProducerRecord;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.joda.time.Duration;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.testcontainers.containers.KafkaContainer;\n+import org.testcontainers.containers.PubSubEmulatorContainer;\n+import org.testcontainers.utility.DockerImageName;\n+\n+/** E2E test for {@link KafkaToPubsub} pipeline. */\n+public class KafkaToPubsubE2ETest {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "00208863d8ad96f082856cfe034a2f3052fb524c"}, "originalPosition": 54}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUwNjQ5NjY1OnYy", "diffSide": "RIGHT", "path": "examples/java/src/test/java/org/apache/beam/examples/complete/kafkatopubsub/KafkaToPubsubE2ETest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xM1QyMzo1ODoxNVrOITJ2rw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xM1QyMzo1ODoxNVrOITJ2rw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Njk1NTMxMQ==", "bodyText": "We have a precommit check that should run this example on Dataflow. It looks like this test isn't run there now, but that's likely because the name is Test and not IT.\nWhen you rename the test and this runs on Dataflow, this timeout won't be long enough, since Dataflow takes several minutes to start up workers. You should bump it up to 10 minutes probably.", "url": "https://github.com/apache/beam/pull/13636#discussion_r556955311", "createdAt": "2021-01-13T23:58:15Z", "author": {"login": "TheNeuralBit"}, "path": "examples/java/src/test/java/org/apache/beam/examples/complete/kafkatopubsub/KafkaToPubsubE2ETest.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.examples.complete.kafkatopubsub;\n+\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.hasProperty;\n+\n+import com.google.auth.Credentials;\n+import java.nio.charset.StandardCharsets;\n+import java.util.UUID;\n+import java.util.concurrent.ExecutionException;\n+import org.apache.beam.examples.complete.kafkatopubsub.options.KafkaToPubsubOptions;\n+import org.apache.beam.examples.complete.kafkatopubsub.transforms.FormatTransform.FORMAT;\n+import org.apache.beam.runners.direct.DirectOptions;\n+import org.apache.beam.sdk.PipelineResult;\n+import org.apache.beam.sdk.extensions.gcp.auth.NoopCredentialFactory;\n+import org.apache.beam.sdk.extensions.gcp.options.GcpOptions;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubOptions;\n+import org.apache.beam.sdk.io.gcp.pubsub.TestPubsub;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.testing.TestPipeline;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.producer.KafkaProducer;\n+import org.apache.kafka.clients.producer.ProducerConfig;\n+import org.apache.kafka.clients.producer.ProducerRecord;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.joda.time.Duration;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.testcontainers.containers.KafkaContainer;\n+import org.testcontainers.containers.PubSubEmulatorContainer;\n+import org.testcontainers.utility.DockerImageName;\n+\n+/** E2E test for {@link KafkaToPubsub} pipeline. */\n+public class KafkaToPubsubE2ETest {\n+  private static final String PUBSUB_EMULATOR_IMAGE =\n+      \"gcr.io/google.com/cloudsdktool/cloud-sdk:316.0.0-emulators\";\n+  private static final String KAFKA_IMAGE_NAME = \"confluentinc/cp-kafka:5.4.3\";\n+  private static final String PUBSUB_MESSAGE = \"test pubsub message\";\n+  private static final String KAFKA_TOPIC_NAME = \"messages-topic\";\n+  private static final String PROJECT_ID = \"try-kafka-pubsub\";\n+  private static final PipelineOptions OPTIONS = TestPipeline.testingPipelineOptions();\n+\n+  @ClassRule\n+  public static final PubSubEmulatorContainer PUB_SUB_EMULATOR_CONTAINER =\n+      new PubSubEmulatorContainer(DockerImageName.parse(PUBSUB_EMULATOR_IMAGE));\n+\n+  @ClassRule\n+  public static final KafkaContainer KAFKA_CONTAINER =\n+      new KafkaContainer(DockerImageName.parse(KAFKA_IMAGE_NAME));\n+\n+  @Rule public final transient TestPipeline pipeline = TestPipeline.fromOptions(OPTIONS);\n+  @Rule public final transient TestPubsub testPubsub = TestPubsub.fromOptions(OPTIONS);\n+\n+  @BeforeClass\n+  public static void beforeClass() throws Exception {\n+    Credentials credentials = NoopCredentialFactory.fromOptions(OPTIONS).getCredential();\n+    OPTIONS.as(DirectOptions.class).setBlockOnRun(false);\n+    OPTIONS.as(GcpOptions.class).setGcpCredential(credentials);\n+    OPTIONS.as(GcpOptions.class).setProject(PROJECT_ID);\n+    OPTIONS\n+        .as(PubsubOptions.class)\n+        .setPubsubRootUrl(\"http://\" + PUB_SUB_EMULATOR_CONTAINER.getEmulatorEndpoint());\n+    OPTIONS.as(KafkaToPubsubOptions.class).setOutputFormat(FORMAT.PUBSUB);\n+    OPTIONS\n+        .as(KafkaToPubsubOptions.class)\n+        .setBootstrapServers(KAFKA_CONTAINER.getBootstrapServers());\n+    OPTIONS.as(KafkaToPubsubOptions.class).setInputTopics(KAFKA_TOPIC_NAME);\n+    OPTIONS\n+        .as(KafkaToPubsubOptions.class)\n+        .setKafkaConsumerConfig(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG + \"=earliest\");\n+  }\n+\n+  @Before\n+  public void setUp() {\n+    OPTIONS.as(KafkaToPubsubOptions.class).setOutputTopic(testPubsub.topicPath().getPath());\n+  }\n+\n+  @Test\n+  public void testKafkaToPubsubE2E() throws Exception {\n+    PipelineResult job = KafkaToPubsub.run(pipeline, OPTIONS.as(KafkaToPubsubOptions.class));\n+\n+    sendKafkaMessage();\n+    testPubsub\n+        .assertThatTopicEventuallyReceives(\n+            hasProperty(\"payload\", equalTo(PUBSUB_MESSAGE.getBytes(StandardCharsets.UTF_8))))\n+        .waitForUpTo(Duration.standardMinutes(1));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "00208863d8ad96f082856cfe034a2f3052fb524c"}, "originalPosition": 106}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUwNjQ5OTExOnYy", "diffSide": "RIGHT", "path": "examples/java/build.gradle", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xM1QyMzo1OToyM1rOITJ4LA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQyMzo1NzowOVrOIYOi5A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Njk1NTY5Mg==", "bodyText": "Can we do without this?", "url": "https://github.com/apache/beam/pull/13636#discussion_r556955692", "createdAt": "2021-01-13T23:59:23Z", "author": {"login": "TheNeuralBit"}, "path": "examples/java/build.gradle", "diffHunk": "@@ -56,6 +56,7 @@ dependencies {\n   compile library.java.vendored_guava_26_0_jre\n   compile library.java.kafka_clients\n   compile project(path: \":sdks:java:core\", configuration: \"shadow\")\n+  compile project(path: \":runners:direct-java\", configuration: \"shadow\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "00208863d8ad96f082856cfe034a2f3052fb524c"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjI3NTA0NA==", "bodyText": "Took a closer look at this. It looks like the dependency is necessary because DirectOptions is referenced in the new test. Could you make it a testCompile dependency?", "url": "https://github.com/apache/beam/pull/13636#discussion_r562275044", "createdAt": "2021-01-21T23:57:09Z", "author": {"login": "TheNeuralBit"}, "path": "examples/java/build.gradle", "diffHunk": "@@ -56,6 +56,7 @@ dependencies {\n   compile library.java.vendored_guava_26_0_jre\n   compile library.java.kafka_clients\n   compile project(path: \":sdks:java:core\", configuration: \"shadow\")\n+  compile project(path: \":runners:direct-java\", configuration: \"shadow\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Njk1NTY5Mg=="}, "originalCommit": {"oid": "00208863d8ad96f082856cfe034a2f3052fb524c"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU0MDY3MjYzOnYy", "diffSide": "RIGHT", "path": "examples/java/src/main/java/org/apache/beam/examples/complete/kafkatopubsub/kafka/consumer/Utils.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQyMzo1NToyN1rOIYOgqg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQxMDoxNDo1MFrOIZfu7g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjI3NDQ3NA==", "bodyText": "nit: If I were writing this I would probably combine these two lines and avoid creating the Pair:\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    .map(kv -> Pair.of(kv[0], kv[1]))\n          \n          \n            \n                    .collect(Collectors.toMap(Pair::getKey, Pair::getValue));\n          \n          \n            \n                    .collect(Collectors.toMap(kv -> kv[0], kv -> kv[1]));\n          \n      \n    \n    \n  \n\nIf you prefer it with the Pair that's fine too.\nOne thing I think we should change is make this a private static method in KafkaToPubsub, since it's only used there.", "url": "https://github.com/apache/beam/pull/13636#discussion_r562274474", "createdAt": "2021-01-21T23:55:27Z", "author": {"login": "TheNeuralBit"}, "path": "examples/java/src/main/java/org/apache/beam/examples/complete/kafkatopubsub/kafka/consumer/Utils.java", "diffHunk": "@@ -162,4 +165,11 @@ public static boolean isSslSpecified(KafkaToPubsubOptions options) {\n         || options.getKeystorePath() != null\n         || options.getKeyPassword() != null;\n   }\n+\n+  public static Map<String, Object> parseKafkaConsumerConfig(String kafkaConsumerConfig) {\n+    return Arrays.stream(kafkaConsumerConfig.split(\";\"))\n+        .map(s -> s.split(\"=\"))\n+        .map(kv -> Pair.of(kv[0], kv[1]))\n+        .collect(Collectors.toMap(Pair::getKey, Pair::getValue));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "24ddb6e9eee92445696aa162abe3aa5daaafdeb8"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzYwNTIzMA==", "bodyText": "Removed Pair related code, but left method in place.\nThis class is created for such methods, in my opinion it is better to declare them in Utils in order to leave main class as clean as possible", "url": "https://github.com/apache/beam/pull/13636#discussion_r563605230", "createdAt": "2021-01-25T10:14:50Z", "author": {"login": "ramazan-yapparov"}, "path": "examples/java/src/main/java/org/apache/beam/examples/complete/kafkatopubsub/kafka/consumer/Utils.java", "diffHunk": "@@ -162,4 +165,11 @@ public static boolean isSslSpecified(KafkaToPubsubOptions options) {\n         || options.getKeystorePath() != null\n         || options.getKeyPassword() != null;\n   }\n+\n+  public static Map<String, Object> parseKafkaConsumerConfig(String kafkaConsumerConfig) {\n+    return Arrays.stream(kafkaConsumerConfig.split(\";\"))\n+        .map(s -> s.split(\"=\"))\n+        .map(kv -> Pair.of(kv[0], kv[1]))\n+        .collect(Collectors.toMap(Pair::getKey, Pair::getValue));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjI3NDQ3NA=="}, "originalCommit": {"oid": "24ddb6e9eee92445696aa162abe3aa5daaafdeb8"}, "originalPosition": 24}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2483, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}