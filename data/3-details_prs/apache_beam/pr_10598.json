{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzYzMjY3MjYz", "number": 10598, "title": "[BEAM-8626] Implement status fn api handler in python sdk", "bodyText": "Please add a meaningful description for your change here\n\nThank you for your contribution! Follow this checklist to help us incorporate your contribution quickly and easily:\n\n Choose reviewer(s) and mention them in a comment (R: @username).\n Format the pull request title like [BEAM-XXX] Fixes bug in ApproximateQuantiles, where you replace BEAM-XXX with the appropriate JIRA issue, if applicable. This will automatically link the pull request to the issue.\n If this contribution is large, please file an Apache Individual Contributor License Agreement.\n\nSee the Contributor Guide for more tips on how to make review process smoother.\nPost-Commit Tests Status (on master branch)\n\n\n\nLang\nSDK\nApex\nDataflow\nFlink\nGearpump\nSamza\nSpark\n\n\n\n\nGo\n\n---\n---\n\n---\n---\n\n\n\nJava\n\n\n\n\n\n\n\n\n\nPython\n\n---\n\n\n---\n---\n\n\n\nXLang\n---\n---\n---\n\n---\n---\n---\n\n\n\nPre-Commit Tests Status (on master branch)\n\n\n\n---\nJava\nPython\nGo\nWebsite\n\n\n\n\nNon-portable\n\n\n\n\n\n\nPortable\n---\n\n---\n---\n\n\n\nSee .test-infra/jenkins/README for trigger phrase, status and link of all Jenkins jobs.", "createdAt": "2020-01-15T18:04:30Z", "url": "https://github.com/apache/beam/pull/10598", "merged": true, "mergeCommit": {"oid": "d1b70d6a0f99722fbeaa6bd503d054a4138db369"}, "closed": true, "closedAt": "2020-01-28T02:21:57Z", "author": {"login": "y1chi"}, "timelineItems": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABb6qQU9gBqjI5NTE5NDEzMjE=", "endCursor": "Y3Vyc29yOnYyOpPPAAABb9l4uEgBqjI5Nzg2NjAzNzA=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8ba0a4229a04a5ff40a33374f948da346ffe2361", "author": {"user": {"login": "y1chi", "name": "Yichi Zhang"}}, "url": "https://github.com/apache/beam/commit/8ba0a4229a04a5ff40a33374f948da346ffe2361", "committedDate": "2020-01-15T18:03:30Z", "message": "[BEAM-8626] Implement status fn api handler in python sdk"}, "afterCommit": {"oid": "93665a903e1b015fe097c488971b808dd8125c70", "author": {"user": {"login": "y1chi", "name": "Yichi Zhang"}}, "url": "https://github.com/apache/beam/commit/93665a903e1b015fe097c488971b808dd8125c70", "committedDate": "2020-01-15T18:56:13Z", "message": "[BEAM-8626] Implement status fn api handler in python sdk"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "93665a903e1b015fe097c488971b808dd8125c70", "author": {"user": {"login": "y1chi", "name": "Yichi Zhang"}}, "url": "https://github.com/apache/beam/commit/93665a903e1b015fe097c488971b808dd8125c70", "committedDate": "2020-01-15T18:56:13Z", "message": "[BEAM-8626] Implement status fn api handler in python sdk"}, "afterCommit": {"oid": "7cc279797f17fcf40f3baefa3479e2d4fc75af47", "author": {"user": {"login": "y1chi", "name": "Yichi Zhang"}}, "url": "https://github.com/apache/beam/commit/7cc279797f17fcf40f3baefa3479e2d4fc75af47", "committedDate": "2020-01-15T21:11:25Z", "message": "[BEAM-8626] Implement status fn api handler in python sdk"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ0MzM1ODMz", "url": "https://github.com/apache/beam/pull/10598#pullrequestreview-344335833", "createdAt": "2020-01-17T02:38:04Z", "commit": {"oid": "7cc279797f17fcf40f3baefa3479e2d4fc75af47"}, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QwMjozODowNFrOFetZQA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QwMzoyMjowOVrOFet4Lg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc0NTM0NA==", "bodyText": "Let's add documentation and move it to sdks/python/apache_beam/testing/util.py", "url": "https://github.com/apache/beam/pull/10598#discussion_r367745344", "createdAt": "2020-01-17T02:38:04Z", "author": {"login": "angoenka"}, "path": "sdks/python/apache_beam/runners/test/utils.py", "diffHunk": "@@ -0,0 +1,49 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import absolute_import\n+\n+import sys\n+import threading\n+\n+from future.utils import raise_\n+\n+\n+def timeout(timeout_secs):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7cc279797f17fcf40f3baefa3479e2d4fc75af47"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc0NTYyNw==", "bodyText": "Let's add it as the last entry to keep the ordering of the arguments same and backward compatible,", "url": "https://github.com/apache/beam/pull/10598#discussion_r367745627", "createdAt": "2020-01-17T02:39:40Z", "author": {"login": "angoenka"}, "path": "sdks/python/apache_beam/runners/worker/sdk_worker.py", "diffHunk": "@@ -73,6 +74,7 @@ class SdkHarness(object):\n \n   def __init__(self,\n                control_address,  # type: str\n+               status_address=None,  # type: Optional[str, unicode]", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7cc279797f17fcf40f3baefa3479e2d4fc75af47"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc0NjQ1OQ==", "bodyText": "Let's move it in sdk_worker_main where we keep other reporting related code.", "url": "https://github.com/apache/beam/pull/10598#discussion_r367746459", "createdAt": "2020-01-17T02:44:00Z", "author": {"login": "angoenka"}, "path": "sdks/python/apache_beam/runners/worker/sdk_worker.py", "diffHunk": "@@ -110,6 +112,15 @@ def __init__(self,\n         data_channel_factory=self._data_channel_factory,\n         fns=self._fns)\n \n+    if status_address:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7cc279797f17fcf40f3baefa3479e2d4fc75af47"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc0ODU5OA==", "bodyText": "We have thread dump code in sdk_worker_main.py under get_thread_dump.\nShall we reuse it or move it here.", "url": "https://github.com/apache/beam/pull/10598#discussion_r367748598", "createdAt": "2020-01-17T02:55:40Z", "author": {"login": "angoenka"}, "path": "sdks/python/apache_beam/runners/worker/worker_status.py", "diffHunk": "@@ -0,0 +1,139 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\"\"\"Worker status api handler for reporting SDK harness debug info.\"\"\"\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+\n+import queue\n+import sys\n+import threading\n+import traceback\n+from collections import defaultdict\n+\n+import grpc\n+\n+from apache_beam.portability.api import beam_fn_api_pb2\n+from apache_beam.portability.api import beam_fn_api_pb2_grpc\n+from apache_beam.runners.worker.channel_factory import GRPCChannelFactory\n+from apache_beam.runners.worker.worker_id_interceptor import WorkerIdInterceptor\n+\n+\n+def thread_dump():", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7cc279797f17fcf40f3baefa3479e2d4fc75af47"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc1MTY4NQ==", "bodyText": "We can also expose it over a http server on dynamic port.", "url": "https://github.com/apache/beam/pull/10598#discussion_r367751685", "createdAt": "2020-01-17T03:13:40Z", "author": {"login": "angoenka"}, "path": "sdks/python/apache_beam/runners/worker/worker_status.py", "diffHunk": "@@ -0,0 +1,139 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\"\"\"Worker status api handler for reporting SDK harness debug info.\"\"\"\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+\n+import queue\n+import sys\n+import threading\n+import traceback\n+from collections import defaultdict\n+\n+import grpc\n+\n+from apache_beam.portability.api import beam_fn_api_pb2\n+from apache_beam.portability.api import beam_fn_api_pb2_grpc\n+from apache_beam.runners.worker.channel_factory import GRPCChannelFactory\n+from apache_beam.runners.worker.worker_id_interceptor import WorkerIdInterceptor\n+\n+\n+def thread_dump():\n+  # deduplicate threads with same stack trace\n+  stack_traces = defaultdict(list)\n+  frames = sys._current_frames()  # pylint: disable=protected-access\n+\n+  for t in threading.enumerate():\n+    stack_trace = ''.join(traceback.format_stack(frames[t.ident]))\n+    thread_ident_name = (t.ident, t.name)\n+    stack_traces[stack_trace].append(thread_ident_name)\n+\n+  all_traces = ['=' * 10 + 'THREAD DUMP' + '=' * 10]\n+  for stack, identity in stack_traces.items():\n+    ident, name = identity[0]\n+    trace = '--- Thread #%s name: %s %s---\\n' % (\n+        ident, name, 'and other %d threads' %\n+        (len(identity) - 1) if len(identity) > 1 else '')\n+    if len(identity) > 1:\n+      trace += 'threads: %s\\n' % identity\n+    trace += stack\n+    all_traces.append(trace)\n+  all_traces.append('=' * 30)\n+  return '\\n'.join(x.encode('utf-8') for x in all_traces)\n+\n+\n+def active_processing_bundles_state(bundle_process_cache):\n+  active_bundles = ['=' * 10 + 'ACTIVE PROCESSING BUNDLES' + '=' * 10]\n+  if not bundle_process_cache.active_bundle_processors:\n+    active_bundles.append(\"No active processing bundles.\")\n+  else:\n+    cache = []\n+    for instruction in list(\n+        bundle_process_cache.active_bundle_processors.keys()):\n+      processor = bundle_process_cache.lookup(instruction)\n+      if processor:\n+        info = processor.state_sampler.get_info()\n+        cache.append((instruction,\n+                      processor.process_bundle_descriptor.id,\n+                      info.tracked_thread, info.time_since_transition))\n+    # reverse sort active bundle by time since last transition, keep top 10.\n+    cache.sort(key=lambda x: x[-1], reverse=True)\n+    for s in cache[:10]:\n+      state = '--- instruction %s ---\\n' % s[0]\n+      state += 'ProcessBundleDescriptorId: %s\\n' % s[1]\n+      state += \"tracked thread: %s\\n\" % s[2]\n+      state += \"time since transition: %.2f seconds\\n\" % (s[3] / 1e9)\n+      active_bundles.append(state)\n+\n+  active_bundles.append('=' * 30)\n+  return '\\n'.join(x.encode('utf-8') for x in active_bundles)\n+\n+\n+DONE = object()\n+\n+\n+class FnApiWorkerStatusHandler(object):\n+  def __init__(self, status_address, bundle_process_cache=None):\n+    self._alive = True\n+    self._bundle_process_cache = bundle_process_cache\n+    ch = GRPCChannelFactory.insecure_channel(status_address)\n+    grpc.channel_ready_future(ch).result(timeout=60)\n+    self._status_channel = grpc.intercept_channel(ch, WorkerIdInterceptor())\n+    self._status_stub = beam_fn_api_pb2_grpc.BeamFnWorkerStatusStub(\n+        self._status_channel)\n+    self._responses = queue.Queue()\n+    self._server = threading.Thread(target=lambda: self._serve(),\n+                                    name='fn_api_status_handler')\n+    self._server.daemon = True\n+    self._server.start()\n+\n+  def _get_responses(self):\n+    while True:\n+      response = self._responses.get()\n+      if response is DONE:\n+        self._alive = False\n+        return\n+      yield response\n+\n+  def _serve(self):\n+    while self._alive:\n+      for request in self._status_stub.WorkerStatus(self._get_responses()):\n+        try:\n+          response = self.generate_status_response()\n+        except Exception:\n+          traceback_string = traceback.format_exc()\n+          self._responses.put(\n+              beam_fn_api_pb2.WorkerStatusResponse(\n+                  id=request.id,\n+                  error=\"Exception encountered while generating \"\n+                  \"status page: %s\" % traceback_string))\n+          continue\n+\n+        self._responses.put(\n+            beam_fn_api_pb2.WorkerStatusResponse(id=request.id,\n+                                                 status_info=response))\n+\n+  def generate_status_response(self):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7cc279797f17fcf40f3baefa3479e2d4fc75af47"}, "originalPosition": 131}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc1MjU4OA==", "bodyText": "We can move the response collection here and avoid continue later on to make code simple.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                      response = self.generate_status_response()\n          \n          \n            \n                      self._responses.put(beam_fn_api_pb2.WorkerStatusResponse(id=request.id, status_info=self.generate_status_response()))", "url": "https://github.com/apache/beam/pull/10598#discussion_r367752588", "createdAt": "2020-01-17T03:18:32Z", "author": {"login": "angoenka"}, "path": "sdks/python/apache_beam/runners/worker/worker_status.py", "diffHunk": "@@ -0,0 +1,139 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\"\"\"Worker status api handler for reporting SDK harness debug info.\"\"\"\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+\n+import queue\n+import sys\n+import threading\n+import traceback\n+from collections import defaultdict\n+\n+import grpc\n+\n+from apache_beam.portability.api import beam_fn_api_pb2\n+from apache_beam.portability.api import beam_fn_api_pb2_grpc\n+from apache_beam.runners.worker.channel_factory import GRPCChannelFactory\n+from apache_beam.runners.worker.worker_id_interceptor import WorkerIdInterceptor\n+\n+\n+def thread_dump():\n+  # deduplicate threads with same stack trace\n+  stack_traces = defaultdict(list)\n+  frames = sys._current_frames()  # pylint: disable=protected-access\n+\n+  for t in threading.enumerate():\n+    stack_trace = ''.join(traceback.format_stack(frames[t.ident]))\n+    thread_ident_name = (t.ident, t.name)\n+    stack_traces[stack_trace].append(thread_ident_name)\n+\n+  all_traces = ['=' * 10 + 'THREAD DUMP' + '=' * 10]\n+  for stack, identity in stack_traces.items():\n+    ident, name = identity[0]\n+    trace = '--- Thread #%s name: %s %s---\\n' % (\n+        ident, name, 'and other %d threads' %\n+        (len(identity) - 1) if len(identity) > 1 else '')\n+    if len(identity) > 1:\n+      trace += 'threads: %s\\n' % identity\n+    trace += stack\n+    all_traces.append(trace)\n+  all_traces.append('=' * 30)\n+  return '\\n'.join(x.encode('utf-8') for x in all_traces)\n+\n+\n+def active_processing_bundles_state(bundle_process_cache):\n+  active_bundles = ['=' * 10 + 'ACTIVE PROCESSING BUNDLES' + '=' * 10]\n+  if not bundle_process_cache.active_bundle_processors:\n+    active_bundles.append(\"No active processing bundles.\")\n+  else:\n+    cache = []\n+    for instruction in list(\n+        bundle_process_cache.active_bundle_processors.keys()):\n+      processor = bundle_process_cache.lookup(instruction)\n+      if processor:\n+        info = processor.state_sampler.get_info()\n+        cache.append((instruction,\n+                      processor.process_bundle_descriptor.id,\n+                      info.tracked_thread, info.time_since_transition))\n+    # reverse sort active bundle by time since last transition, keep top 10.\n+    cache.sort(key=lambda x: x[-1], reverse=True)\n+    for s in cache[:10]:\n+      state = '--- instruction %s ---\\n' % s[0]\n+      state += 'ProcessBundleDescriptorId: %s\\n' % s[1]\n+      state += \"tracked thread: %s\\n\" % s[2]\n+      state += \"time since transition: %.2f seconds\\n\" % (s[3] / 1e9)\n+      active_bundles.append(state)\n+\n+  active_bundles.append('=' * 30)\n+  return '\\n'.join(x.encode('utf-8') for x in active_bundles)\n+\n+\n+DONE = object()\n+\n+\n+class FnApiWorkerStatusHandler(object):\n+  def __init__(self, status_address, bundle_process_cache=None):\n+    self._alive = True\n+    self._bundle_process_cache = bundle_process_cache\n+    ch = GRPCChannelFactory.insecure_channel(status_address)\n+    grpc.channel_ready_future(ch).result(timeout=60)\n+    self._status_channel = grpc.intercept_channel(ch, WorkerIdInterceptor())\n+    self._status_stub = beam_fn_api_pb2_grpc.BeamFnWorkerStatusStub(\n+        self._status_channel)\n+    self._responses = queue.Queue()\n+    self._server = threading.Thread(target=lambda: self._serve(),\n+                                    name='fn_api_status_handler')\n+    self._server.daemon = True\n+    self._server.start()\n+\n+  def _get_responses(self):\n+    while True:\n+      response = self._responses.get()\n+      if response is DONE:\n+        self._alive = False\n+        return\n+      yield response\n+\n+  def _serve(self):\n+    while self._alive:\n+      for request in self._status_stub.WorkerStatus(self._get_responses()):\n+        try:\n+          response = self.generate_status_response()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7cc279797f17fcf40f3baefa3479e2d4fc75af47"}, "originalPosition": 117}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc1MzI2Mg==", "bodyText": "We can remove this if we move addition of response above.", "url": "https://github.com/apache/beam/pull/10598#discussion_r367753262", "createdAt": "2020-01-17T03:22:09Z", "author": {"login": "angoenka"}, "path": "sdks/python/apache_beam/runners/worker/worker_status.py", "diffHunk": "@@ -0,0 +1,139 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\"\"\"Worker status api handler for reporting SDK harness debug info.\"\"\"\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+\n+import queue\n+import sys\n+import threading\n+import traceback\n+from collections import defaultdict\n+\n+import grpc\n+\n+from apache_beam.portability.api import beam_fn_api_pb2\n+from apache_beam.portability.api import beam_fn_api_pb2_grpc\n+from apache_beam.runners.worker.channel_factory import GRPCChannelFactory\n+from apache_beam.runners.worker.worker_id_interceptor import WorkerIdInterceptor\n+\n+\n+def thread_dump():\n+  # deduplicate threads with same stack trace\n+  stack_traces = defaultdict(list)\n+  frames = sys._current_frames()  # pylint: disable=protected-access\n+\n+  for t in threading.enumerate():\n+    stack_trace = ''.join(traceback.format_stack(frames[t.ident]))\n+    thread_ident_name = (t.ident, t.name)\n+    stack_traces[stack_trace].append(thread_ident_name)\n+\n+  all_traces = ['=' * 10 + 'THREAD DUMP' + '=' * 10]\n+  for stack, identity in stack_traces.items():\n+    ident, name = identity[0]\n+    trace = '--- Thread #%s name: %s %s---\\n' % (\n+        ident, name, 'and other %d threads' %\n+        (len(identity) - 1) if len(identity) > 1 else '')\n+    if len(identity) > 1:\n+      trace += 'threads: %s\\n' % identity\n+    trace += stack\n+    all_traces.append(trace)\n+  all_traces.append('=' * 30)\n+  return '\\n'.join(x.encode('utf-8') for x in all_traces)\n+\n+\n+def active_processing_bundles_state(bundle_process_cache):\n+  active_bundles = ['=' * 10 + 'ACTIVE PROCESSING BUNDLES' + '=' * 10]\n+  if not bundle_process_cache.active_bundle_processors:\n+    active_bundles.append(\"No active processing bundles.\")\n+  else:\n+    cache = []\n+    for instruction in list(\n+        bundle_process_cache.active_bundle_processors.keys()):\n+      processor = bundle_process_cache.lookup(instruction)\n+      if processor:\n+        info = processor.state_sampler.get_info()\n+        cache.append((instruction,\n+                      processor.process_bundle_descriptor.id,\n+                      info.tracked_thread, info.time_since_transition))\n+    # reverse sort active bundle by time since last transition, keep top 10.\n+    cache.sort(key=lambda x: x[-1], reverse=True)\n+    for s in cache[:10]:\n+      state = '--- instruction %s ---\\n' % s[0]\n+      state += 'ProcessBundleDescriptorId: %s\\n' % s[1]\n+      state += \"tracked thread: %s\\n\" % s[2]\n+      state += \"time since transition: %.2f seconds\\n\" % (s[3] / 1e9)\n+      active_bundles.append(state)\n+\n+  active_bundles.append('=' * 30)\n+  return '\\n'.join(x.encode('utf-8') for x in active_bundles)\n+\n+\n+DONE = object()\n+\n+\n+class FnApiWorkerStatusHandler(object):\n+  def __init__(self, status_address, bundle_process_cache=None):\n+    self._alive = True\n+    self._bundle_process_cache = bundle_process_cache\n+    ch = GRPCChannelFactory.insecure_channel(status_address)\n+    grpc.channel_ready_future(ch).result(timeout=60)\n+    self._status_channel = grpc.intercept_channel(ch, WorkerIdInterceptor())\n+    self._status_stub = beam_fn_api_pb2_grpc.BeamFnWorkerStatusStub(\n+        self._status_channel)\n+    self._responses = queue.Queue()\n+    self._server = threading.Thread(target=lambda: self._serve(),\n+                                    name='fn_api_status_handler')\n+    self._server.daemon = True\n+    self._server.start()\n+\n+  def _get_responses(self):\n+    while True:\n+      response = self._responses.get()\n+      if response is DONE:\n+        self._alive = False\n+        return\n+      yield response\n+\n+  def _serve(self):\n+    while self._alive:\n+      for request in self._status_stub.WorkerStatus(self._get_responses()):\n+        try:\n+          response = self.generate_status_response()\n+        except Exception:\n+          traceback_string = traceback.format_exc()\n+          self._responses.put(\n+              beam_fn_api_pb2.WorkerStatusResponse(\n+                  id=request.id,\n+                  error=\"Exception encountered while generating \"\n+                  \"status page: %s\" % traceback_string))\n+          continue\n+\n+        self._responses.put(\n+            beam_fn_api_pb2.WorkerStatusResponse(id=request.id,\n+                                                 status_info=response))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7cc279797f17fcf40f3baefa3479e2d4fc75af47"}, "originalPosition": 129}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ2MTIyNzg5", "url": "https://github.com/apache/beam/pull/10598#pullrequestreview-346122789", "createdAt": "2020-01-21T19:11:23Z", "commit": {"oid": "20b8aac09c9d72c07b5c155b2afb9fc1dca351fa"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMVQxOToxMToyNFrOFgFkgA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMVQxOToyNzowN1rOFgGCbg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE5MDAxNg==", "bodyText": "Sounds good", "url": "https://github.com/apache/beam/pull/10598#discussion_r369190016", "createdAt": "2020-01-21T19:11:24Z", "author": {"login": "angoenka"}, "path": "sdks/python/apache_beam/runners/worker/sdk_worker.py", "diffHunk": "@@ -110,6 +112,15 @@ def __init__(self,\n         data_channel_factory=self._data_channel_factory,\n         fns=self._fns)\n \n+    if status_address:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc0NjQ1OQ=="}, "originalCommit": {"oid": "7cc279797f17fcf40f3baefa3479e2d4fc75af47"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE5MzgyNg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    _LOGGER.info('Error creating worker status request handler, skipping '\n          \n          \n            \n                    _LOGGER.warn('Error creating worker status request handler, skipping '", "url": "https://github.com/apache/beam/pull/10598#discussion_r369193826", "createdAt": "2020-01-21T19:19:17Z", "author": {"login": "angoenka"}, "path": "sdks/python/apache_beam/runners/worker/sdk_worker.py", "diffHunk": "@@ -110,6 +112,15 @@ def __init__(self,\n         data_channel_factory=self._data_channel_factory,\n         fns=self._fns)\n \n+    if status_address:\n+      try:\n+        self._status_handler = FnApiWorkerStatusHandler(\n+            status_address, self._bundle_processor_cache)\n+      except Exception:\n+        traceback_string = traceback.format_exc()\n+        _LOGGER.info('Error creating worker status request handler, skipping '", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "20b8aac09c9d72c07b5c155b2afb9fc1dca351fa"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE5NDU0Mw==", "bodyText": "Lets add a jira to clean StatusServer from here completely once we have rolled out Debug capture.", "url": "https://github.com/apache/beam/pull/10598#discussion_r369194543", "createdAt": "2020-01-21T19:20:47Z", "author": {"login": "angoenka"}, "path": "sdks/python/apache_beam/runners/worker/sdk_worker_main.py", "diffHunk": "@@ -78,8 +67,7 @@ def do_GET(self):  # pylint: disable=invalid-name\n         self.send_header('Content-Type', 'text/plain')\n         self.end_headers()\n \n-        for line in StatusServer.get_thread_dump():\n-          self.wfile.write(line.encode('utf-8'))\n+        self.wfile.write(thread_dump())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "20b8aac09c9d72c07b5c155b2afb9fc1dca351fa"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE5NTA1MA==", "bodyText": "As mentioned above, Lets add a jira to clean StatusServer in sdk_worker_main", "url": "https://github.com/apache/beam/pull/10598#discussion_r369195050", "createdAt": "2020-01-21T19:21:51Z", "author": {"login": "angoenka"}, "path": "sdks/python/apache_beam/runners/worker/worker_status.py", "diffHunk": "@@ -0,0 +1,139 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\"\"\"Worker status api handler for reporting SDK harness debug info.\"\"\"\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+\n+import queue\n+import sys\n+import threading\n+import traceback\n+from collections import defaultdict\n+\n+import grpc\n+\n+from apache_beam.portability.api import beam_fn_api_pb2\n+from apache_beam.portability.api import beam_fn_api_pb2_grpc\n+from apache_beam.runners.worker.channel_factory import GRPCChannelFactory\n+from apache_beam.runners.worker.worker_id_interceptor import WorkerIdInterceptor\n+\n+\n+def thread_dump():", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc0ODU5OA=="}, "originalCommit": {"oid": "7cc279797f17fcf40f3baefa3479e2d4fc75af47"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE5NjUxMA==", "bodyText": "Let's add a jira to group threads which have same thread stack for easier analysis and reducing text size.\nThis can be a starter task for new beam contributors.", "url": "https://github.com/apache/beam/pull/10598#discussion_r369196510", "createdAt": "2020-01-21T19:24:47Z", "author": {"login": "angoenka"}, "path": "sdks/python/apache_beam/runners/worker/worker_status.py", "diffHunk": "@@ -0,0 +1,148 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\"\"\"Worker status api handler for reporting SDK harness debug info.\"\"\"\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+\n+import queue\n+import sys\n+import threading\n+import traceback\n+from collections import defaultdict\n+\n+import grpc\n+\n+from apache_beam.portability.api import beam_fn_api_pb2\n+from apache_beam.portability.api import beam_fn_api_pb2_grpc\n+from apache_beam.runners.worker.channel_factory import GRPCChannelFactory\n+from apache_beam.runners.worker.worker_id_interceptor import WorkerIdInterceptor\n+\n+\n+def thread_dump():\n+  \"\"\"Get a thread dump for the current SDK worker harness. \"\"\"\n+  # deduplicate threads with same stack trace\n+  stack_traces = defaultdict(list)\n+  frames = sys._current_frames()  # pylint: disable=protected-access\n+\n+  for t in threading.enumerate():\n+    stack_trace = ''.join(traceback.format_stack(frames[t.ident]))\n+    thread_ident_name = (t.ident, t.name)\n+    stack_traces[stack_trace].append(thread_ident_name)\n+\n+  all_traces = ['=' * 10 + 'THREAD DUMP' + '=' * 10]\n+  for stack, identity in stack_traces.items():", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "20b8aac09c9d72c07b5c155b2afb9fc1dca351fa"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE5NzY3OA==", "bodyText": "This can be private method.", "url": "https://github.com/apache/beam/pull/10598#discussion_r369197678", "createdAt": "2020-01-21T19:27:07Z", "author": {"login": "angoenka"}, "path": "sdks/python/apache_beam/runners/worker/worker_status.py", "diffHunk": "@@ -0,0 +1,148 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\"\"\"Worker status api handler for reporting SDK harness debug info.\"\"\"\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+\n+import queue\n+import sys\n+import threading\n+import traceback\n+from collections import defaultdict\n+\n+import grpc\n+\n+from apache_beam.portability.api import beam_fn_api_pb2\n+from apache_beam.portability.api import beam_fn_api_pb2_grpc\n+from apache_beam.runners.worker.channel_factory import GRPCChannelFactory\n+from apache_beam.runners.worker.worker_id_interceptor import WorkerIdInterceptor\n+\n+\n+def thread_dump():\n+  \"\"\"Get a thread dump for the current SDK worker harness. \"\"\"\n+  # deduplicate threads with same stack trace\n+  stack_traces = defaultdict(list)\n+  frames = sys._current_frames()  # pylint: disable=protected-access\n+\n+  for t in threading.enumerate():\n+    stack_trace = ''.join(traceback.format_stack(frames[t.ident]))\n+    thread_ident_name = (t.ident, t.name)\n+    stack_traces[stack_trace].append(thread_ident_name)\n+\n+  all_traces = ['=' * 10 + 'THREAD DUMP' + '=' * 10]\n+  for stack, identity in stack_traces.items():\n+    ident, name = identity[0]\n+    trace = '--- Thread #%s name: %s %s---\\n' % (\n+        ident, name, 'and other %d threads' %\n+        (len(identity) - 1) if len(identity) > 1 else '')\n+    if len(identity) > 1:\n+      trace += 'threads: %s\\n' % identity\n+    trace += stack\n+    all_traces.append(trace)\n+  all_traces.append('=' * 30)\n+  return '\\n'.join(x.encode('utf-8') for x in all_traces)\n+\n+\n+def active_processing_bundles_state(bundle_process_cache):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "20b8aac09c9d72c07b5c155b2afb9fc1dca351fa"}, "originalPosition": 61}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ2MjA0MTE5", "url": "https://github.com/apache/beam/pull/10598#pullrequestreview-346204119", "createdAt": "2020-01-21T21:29:08Z", "commit": {"oid": "20b8aac09c9d72c07b5c155b2afb9fc1dca351fa"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMVQyMToyOTowOFrOFgJYvg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMVQyMTo0MTowNVrOFgJtLw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTI1MjU0Mg==", "bodyText": "You are right. It's already in this PR.\nWe can print names of all the threads along with count so that we don't miss any information.", "url": "https://github.com/apache/beam/pull/10598#discussion_r369252542", "createdAt": "2020-01-21T21:29:08Z", "author": {"login": "angoenka"}, "path": "sdks/python/apache_beam/runners/worker/worker_status.py", "diffHunk": "@@ -0,0 +1,148 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\"\"\"Worker status api handler for reporting SDK harness debug info.\"\"\"\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+\n+import queue\n+import sys\n+import threading\n+import traceback\n+from collections import defaultdict\n+\n+import grpc\n+\n+from apache_beam.portability.api import beam_fn_api_pb2\n+from apache_beam.portability.api import beam_fn_api_pb2_grpc\n+from apache_beam.runners.worker.channel_factory import GRPCChannelFactory\n+from apache_beam.runners.worker.worker_id_interceptor import WorkerIdInterceptor\n+\n+\n+def thread_dump():\n+  \"\"\"Get a thread dump for the current SDK worker harness. \"\"\"\n+  # deduplicate threads with same stack trace\n+  stack_traces = defaultdict(list)\n+  frames = sys._current_frames()  # pylint: disable=protected-access\n+\n+  for t in threading.enumerate():\n+    stack_trace = ''.join(traceback.format_stack(frames[t.ident]))\n+    thread_ident_name = (t.ident, t.name)\n+    stack_traces[stack_trace].append(thread_ident_name)\n+\n+  all_traces = ['=' * 10 + 'THREAD DUMP' + '=' * 10]\n+  for stack, identity in stack_traces.items():", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE5NjUxMA=="}, "originalCommit": {"oid": "20b8aac09c9d72c07b5c155b2afb9fc1dca351fa"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTI1Nzc3NQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                trace = '--- Thread #%s name: %s %s---\\n' % (\n          \n          \n            \n                trace = '--- Threads (%d) %s --- \\n' % (len(identity), [ident+':'+name for (ident, name) in identity])", "url": "https://github.com/apache/beam/pull/10598#discussion_r369257775", "createdAt": "2020-01-21T21:41:05Z", "author": {"login": "angoenka"}, "path": "sdks/python/apache_beam/runners/worker/worker_status.py", "diffHunk": "@@ -0,0 +1,148 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\"\"\"Worker status api handler for reporting SDK harness debug info.\"\"\"\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+\n+import queue\n+import sys\n+import threading\n+import traceback\n+from collections import defaultdict\n+\n+import grpc\n+\n+from apache_beam.portability.api import beam_fn_api_pb2\n+from apache_beam.portability.api import beam_fn_api_pb2_grpc\n+from apache_beam.runners.worker.channel_factory import GRPCChannelFactory\n+from apache_beam.runners.worker.worker_id_interceptor import WorkerIdInterceptor\n+\n+\n+def thread_dump():\n+  \"\"\"Get a thread dump for the current SDK worker harness. \"\"\"\n+  # deduplicate threads with same stack trace\n+  stack_traces = defaultdict(list)\n+  frames = sys._current_frames()  # pylint: disable=protected-access\n+\n+  for t in threading.enumerate():\n+    stack_trace = ''.join(traceback.format_stack(frames[t.ident]))\n+    thread_ident_name = (t.ident, t.name)\n+    stack_traces[stack_trace].append(thread_ident_name)\n+\n+  all_traces = ['=' * 10 + 'THREAD DUMP' + '=' * 10]\n+  for stack, identity in stack_traces.items():\n+    ident, name = identity[0]\n+    trace = '--- Thread #%s name: %s %s---\\n' % (", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "20b8aac09c9d72c07b5c155b2afb9fc1dca351fa"}, "originalPosition": 50}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ2MjgyNjcz", "url": "https://github.com/apache/beam/pull/10598#pullrequestreview-346282673", "createdAt": "2020-01-22T00:30:52Z", "commit": {"oid": "af3077778a69509b1d7f9b5cca2ad3d58850efd4"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "af3077778a69509b1d7f9b5cca2ad3d58850efd4", "author": {"user": {"login": "y1chi", "name": "Yichi Zhang"}}, "url": "https://github.com/apache/beam/commit/af3077778a69509b1d7f9b5cca2ad3d58850efd4", "committedDate": "2020-01-21T21:02:56Z", "message": "fixup"}, "afterCommit": {"oid": "04c14a176eaa47bc6ca35683299d5679908544cd", "author": {"user": {"login": "y1chi", "name": "Yichi Zhang"}}, "url": "https://github.com/apache/beam/commit/04c14a176eaa47bc6ca35683299d5679908544cd", "committedDate": "2020-01-23T21:50:58Z", "message": "fixup"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "747cd9c3a61e8267757d68097f91168dc166878a", "author": {"user": {"login": "y1chi", "name": "Yichi Zhang"}}, "url": "https://github.com/apache/beam/commit/747cd9c3a61e8267757d68097f91168dc166878a", "committedDate": "2020-01-23T21:52:07Z", "message": "[BEAM-8626] Implement status fn api handler in python sdk"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "549d7c1ea927248f6fb9e5b32ffd4ce4f67ac322", "author": {"user": {"login": "y1chi", "name": "Yichi Zhang"}}, "url": "https://github.com/apache/beam/commit/549d7c1ea927248f6fb9e5b32ffd4ce4f67ac322", "committedDate": "2020-01-23T21:52:07Z", "message": "Address comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d753736697021e998784be7b78260bab39b76a52", "author": {"user": {"login": "y1chi", "name": "Yichi Zhang"}}, "url": "https://github.com/apache/beam/commit/d753736697021e998784be7b78260bab39b76a52", "committedDate": "2020-01-23T21:55:25Z", "message": "fixup"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "04c14a176eaa47bc6ca35683299d5679908544cd", "author": {"user": {"login": "y1chi", "name": "Yichi Zhang"}}, "url": "https://github.com/apache/beam/commit/04c14a176eaa47bc6ca35683299d5679908544cd", "committedDate": "2020-01-23T21:50:58Z", "message": "fixup"}, "afterCommit": {"oid": "d753736697021e998784be7b78260bab39b76a52", "author": {"user": {"login": "y1chi", "name": "Yichi Zhang"}}, "url": "https://github.com/apache/beam/commit/d753736697021e998784be7b78260bab39b76a52", "committedDate": "2020-01-23T21:55:25Z", "message": "fixup"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9116e0a1802f32dd8298465d3f48759b0a078198", "author": {"user": {"login": "y1chi", "name": "Yichi Zhang"}}, "url": "https://github.com/apache/beam/commit/9116e0a1802f32dd8298465d3f48759b0a078198", "committedDate": "2020-01-23T23:31:20Z", "message": "fix test"}, "afterCommit": {"oid": "2e0247981f834ec5df61475b284f605e034bc635", "author": {"user": {"login": "y1chi", "name": "Yichi Zhang"}}, "url": "https://github.com/apache/beam/commit/2e0247981f834ec5df61475b284f605e034bc635", "committedDate": "2020-01-24T21:21:02Z", "message": "fix test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b1bd4660efce5bfd03536f27e6e7d6de37994c11", "author": {"user": {"login": "y1chi", "name": "Yichi Zhang"}}, "url": "https://github.com/apache/beam/commit/b1bd4660efce5bfd03536f27e6e7d6de37994c11", "committedDate": "2020-01-24T21:32:34Z", "message": "fix test"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "2e0247981f834ec5df61475b284f605e034bc635", "author": {"user": {"login": "y1chi", "name": "Yichi Zhang"}}, "url": "https://github.com/apache/beam/commit/2e0247981f834ec5df61475b284f605e034bc635", "committedDate": "2020-01-24T21:21:02Z", "message": "fix test"}, "afterCommit": {"oid": "b1bd4660efce5bfd03536f27e6e7d6de37994c11", "author": {"user": {"login": "y1chi", "name": "Yichi Zhang"}}, "url": "https://github.com/apache/beam/commit/b1bd4660efce5bfd03536f27e6e7d6de37994c11", "committedDate": "2020-01-24T21:32:34Z", "message": "fix test"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3836, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}