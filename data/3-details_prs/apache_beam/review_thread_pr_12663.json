{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDcxNzYzMDg1", "number": 12663, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxNzo1MTozM1rOEbDhsQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxNzo1MTozM1rOEbDhsQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2ODA0Nzg1OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxNzo1MTozM1rOHE2Fdg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQyMzoyMjoyNFrOHF56SA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDg0MjQ4Ng==", "bodyText": "In Python, BigQuery does not insert rows in parallel threads and retry within each of them, instead it backs off on all retry-able inserts together.", "url": "https://github.com/apache/beam/pull/12663#discussion_r474842486", "createdAt": "2020-08-21T17:51:33Z", "author": {"login": "robinyqiu"}, "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -1257,6 +1260,7 @@ def _flush_batch(self, destination):\n         _LOGGER.info(\n             'Sleeping %s seconds before retrying insertion.', retry_backoff)\n         time.sleep(retry_backoff)\n+        self._throttled_secs.inc(retry_backoff)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3e80a2113a4e06c9c1efe566b3db872cb96c8e91"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDkxMzczOQ==", "bodyText": "I wonder if we should make this a Metrics.distribution type metric? @rezarokni do you have an opinion about this? Since the metric may be exported to monitoring systems, a counter may just show a 'sometimes increasing' chart vs a distribution showing a rate of increase?", "url": "https://github.com/apache/beam/pull/12663#discussion_r474913739", "createdAt": "2020-08-21T19:54:46Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -1257,6 +1260,7 @@ def _flush_batch(self, destination):\n         _LOGGER.info(\n             'Sleeping %s seconds before retrying insertion.', retry_backoff)\n         time.sleep(retry_backoff)\n+        self._throttled_secs.inc(retry_backoff)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDg0MjQ4Ng=="}, "originalCommit": {"oid": "3e80a2113a4e06c9c1efe566b3db872cb96c8e91"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDkyOTg0MA==", "bodyText": "I think we can consider that as an improvement. Currently the metric is reported to autoscalar, so I simply made it a counter, similar to the ones in GCS and DataStore", "url": "https://github.com/apache/beam/pull/12663#discussion_r474929840", "createdAt": "2020-08-21T20:14:41Z", "author": {"login": "robinyqiu"}, "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -1257,6 +1260,7 @@ def _flush_batch(self, destination):\n         _LOGGER.info(\n             'Sleeping %s seconds before retrying insertion.', retry_backoff)\n         time.sleep(retry_backoff)\n+        self._throttled_secs.inc(retry_backoff)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDg0MjQ4Ng=="}, "originalCommit": {"oid": "3e80a2113a4e06c9c1efe566b3db872cb96c8e91"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTk1MzczNg==", "bodyText": "@pabloem Sorry missed this one...\nYes agree with Metrics for this type of value, as the ever increasing number will just chart as a liner value without the ability to usefully capture the changes.", "url": "https://github.com/apache/beam/pull/12663#discussion_r475953736", "createdAt": "2020-08-24T23:22:24Z", "author": {"login": "rezarokni"}, "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -1257,6 +1260,7 @@ def _flush_batch(self, destination):\n         _LOGGER.info(\n             'Sleeping %s seconds before retrying insertion.', retry_backoff)\n         time.sleep(retry_backoff)\n+        self._throttled_secs.inc(retry_backoff)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDg0MjQ4Ng=="}, "originalCommit": {"oid": "3e80a2113a4e06c9c1efe566b3db872cb96c8e91"}, "originalPosition": 14}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 566, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}