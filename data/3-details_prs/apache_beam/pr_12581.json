{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDY3NzY0NjM5", "number": 12581, "title": "[BEAM-10378] Add Azure Blob Storage Filesystem", "bodyText": "This PR implements a filesystem for Azure Blobstore.  It is mostly complete, with the exception of the following TODOs that I will resolve in a separate PR:\n\n\nAdd more pipeline options to the filesystem, including adding more credential options to authenticate an azure blob service client.  These will be added in AzureOptions.java, BlobstoreOptions.java, and DefaultAzureClientBuilderFactory.java.  I also plan to write a file called AzureModule.java, similar to the AwsModule.java file in aws/options, to parse credentials passed as pipeline options.\n\n\nCreate mocks for unit tests, to be used in AzureBlobStoreFileSystemTest.java.  The current tests in AzureBlobStoreFileSystemTest are integration tests, using an actual Azure client, that can be run by setting the AZURE_STORAGE_CONNECTION_STRING environment variable.\n\n\n\nThank you for your contribution! Follow this checklist to help us incorporate your contribution quickly and easily:\n\n Choose reviewer(s) and mention them in a comment (R: @username).\n Format the pull request title like [BEAM-XXX] Fixes bug in ApproximateQuantiles, where you replace BEAM-XXX with the appropriate JIRA issue, if applicable. This will automatically link the pull request to the issue.\n Update CHANGES.md with noteworthy changes.\n If this contribution is large, please file an Apache Individual Contributor License Agreement.\n\nSee the Contributor Guide for more tips on how to make review process smoother.\nPost-Commit Tests Status (on master branch)\n\n\n\nLang\nSDK\nDataflow\nFlink\nSamza\nSpark\nTwister2\n\n\n\n\nGo\n\n---\n\n---\n\n---\n\n\nJava\n\n\n\n\n\n\n\n\nPython\n\n\n\n---\n\n---\n\n\nXLang\n\n---\n\n---\n\n---\n\n\n\nPre-Commit Tests Status (on master branch)\n\n\n\n---\nJava\nPython\nGo\nWebsite\n\n\n\n\nNon-portable\n\n\n\n\n\n\nPortable\n---\n\n---\n---\n\n\n\nSee .test-infra/jenkins/README for trigger phrase, status and link of all Jenkins jobs.\nGitHub Actions Tests Status (on master branch)\n\nSee CI.md for more information about GitHub Actions CI.", "createdAt": "2020-08-14T04:44:56Z", "url": "https://github.com/apache/beam/pull/12581", "merged": true, "mergeCommit": {"oid": "f7b49b66e2c195d6cc28b28b65333e551d6857ef"}, "closed": true, "closedAt": "2020-08-20T06:00:22Z", "author": {"login": "ettirapp"}, "timelineItems": {"totalCount": 43, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc-t3a_gBqjM2NTQ4Mjg4MjY=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdAnrThAH2gAyNDY3NzY0NjM5OmZiMTQ2N2RmZGVjYTEyZDdmNjZjODNlYzRjMWFlOGNjZGY1Y2JjOGE=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "dd22277c65791dea7fbd927f187f720b51faae29", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/dd22277c65791dea7fbd927f187f720b51faae29", "committedDate": "2020-08-14T05:22:46Z", "message": "Merge branch 'another-azure-branch' of https://github.com/ettirapp/beam into another-azure-branch"}, "afterCommit": {"oid": "ccbf79b0b763dc41b912eeff2d5192af7d30d5bd", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/ccbf79b0b763dc41b912eeff2d5192af7d30d5bd", "committedDate": "2020-08-14T05:17:07Z", "message": "squashing and renaming a bunch of commits after resolving git badness"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ccbf79b0b763dc41b912eeff2d5192af7d30d5bd", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/ccbf79b0b763dc41b912eeff2d5192af7d30d5bd", "committedDate": "2020-08-14T05:17:07Z", "message": "squashing and renaming a bunch of commits after resolving git badness"}, "afterCommit": {"oid": "a1fa0b716e743d3776cd4798df7ee684aeab5de4", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/a1fa0b716e743d3776cd4798df7ee684aeab5de4", "committedDate": "2020-08-14T05:39:13Z", "message": "implemented an azure blob storage filesystem"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a1fa0b716e743d3776cd4798df7ee684aeab5de4", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/a1fa0b716e743d3776cd4798df7ee684aeab5de4", "committedDate": "2020-08-14T05:39:13Z", "message": "implemented an azure blob storage filesystem"}, "afterCommit": {"oid": "a511aeae89f6b16de4cd1ae0ee12cd0dd4b2220f", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/a511aeae89f6b16de4cd1ae0ee12cd0dd4b2220f", "committedDate": "2020-08-14T05:40:26Z", "message": "implemented an azure blob storage filesystem"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a511aeae89f6b16de4cd1ae0ee12cd0dd4b2220f", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/a511aeae89f6b16de4cd1ae0ee12cd0dd4b2220f", "committedDate": "2020-08-14T05:40:26Z", "message": "implemented an azure blob storage filesystem"}, "afterCommit": {"oid": "919ceb6d8177b0f87d3592e88b034d8f6457d7c7", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/919ceb6d8177b0f87d3592e88b034d8f6457d7c7", "committedDate": "2020-08-14T14:48:02Z", "message": "implemented an azure blob storage filesystem\n\nremoved ignored test from this PR"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "919ceb6d8177b0f87d3592e88b034d8f6457d7c7", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/919ceb6d8177b0f87d3592e88b034d8f6457d7c7", "committedDate": "2020-08-14T14:48:02Z", "message": "implemented an azure blob storage filesystem\n\nremoved ignored test from this PR"}, "afterCommit": {"oid": "275680df5e61c764c2238b6c1793e062b5149abd", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/275680df5e61c764c2238b6c1793e062b5149abd", "committedDate": "2020-08-14T15:41:43Z", "message": "implemented an azure blob storage filesystem\n\nremoved ignored test from this PR\n\nremoved unused file"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0e713c0b01692aad010dcdff7b72fc103e3205b4", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/0e713c0b01692aad010dcdff7b72fc103e3205b4", "committedDate": "2020-08-14T16:01:11Z", "message": "fixed a typo\n\nsmall fixes"}, "afterCommit": {"oid": "7edf1f03966f077867b4490518e0488fa9a1738c", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/7edf1f03966f077867b4490518e0488fa9a1738c", "committedDate": "2020-08-14T16:06:57Z", "message": "implemented an azure blob storage filesystem\n\nremoved ignored test from this PR\n\nremoved unused file\n\nfixed a typo\n\nsmall fixes"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "7edf1f03966f077867b4490518e0488fa9a1738c", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/7edf1f03966f077867b4490518e0488fa9a1738c", "committedDate": "2020-08-14T16:06:57Z", "message": "implemented an azure blob storage filesystem\n\nremoved ignored test from this PR\n\nremoved unused file\n\nfixed a typo\n\nsmall fixes"}, "afterCommit": {"oid": "d7cd86fa3c53a371d39258a4b265a8a2acdeb013", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/d7cd86fa3c53a371d39258a4b265a8a2acdeb013", "committedDate": "2020-08-14T16:19:59Z", "message": "implemented an azure blob storage filesystem\n\nremoved ignored test from this PR\n\nremoved unused file\n\nfixed a typo\n\nsmall fixes\n\nsmall fixes"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d7cd86fa3c53a371d39258a4b265a8a2acdeb013", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/d7cd86fa3c53a371d39258a4b265a8a2acdeb013", "committedDate": "2020-08-14T16:19:59Z", "message": "implemented an azure blob storage filesystem\n\nremoved ignored test from this PR\n\nremoved unused file\n\nfixed a typo\n\nsmall fixes\n\nsmall fixes"}, "afterCommit": {"oid": "a91d5b5cd81ad68218614f98e9d5ed6bbb434bbd", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/a91d5b5cd81ad68218614f98e9d5ed6bbb434bbd", "committedDate": "2020-08-14T16:35:00Z", "message": "implemented an azure blob storage filesystem\n\nremoved ignored test from this PR\n\nremoved unused file\n\nfixed a typo\n\nsmall fixes\n\nsmall fixes\n\nsmall fixes"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a91d5b5cd81ad68218614f98e9d5ed6bbb434bbd", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/a91d5b5cd81ad68218614f98e9d5ed6bbb434bbd", "committedDate": "2020-08-14T16:35:00Z", "message": "implemented an azure blob storage filesystem\n\nremoved ignored test from this PR\n\nremoved unused file\n\nfixed a typo\n\nsmall fixes\n\nsmall fixes\n\nsmall fixes"}, "afterCommit": {"oid": "6b1d7c9add5d3d05ed5e2517c851b972abdc1f17", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/6b1d7c9add5d3d05ed5e2517c851b972abdc1f17", "committedDate": "2020-08-14T17:07:11Z", "message": "implemented an azure blob storage filesystem\n\nremoved ignored test from this PR\n\nremoved unused file\n\nfixed a typo\n\nsmall fixes\n\nsmall fixes\n\nsmall fixes\n\nsmall fixes for readability"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "6b1d7c9add5d3d05ed5e2517c851b972abdc1f17", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/6b1d7c9add5d3d05ed5e2517c851b972abdc1f17", "committedDate": "2020-08-14T17:07:11Z", "message": "implemented an azure blob storage filesystem\n\nremoved ignored test from this PR\n\nremoved unused file\n\nfixed a typo\n\nsmall fixes\n\nsmall fixes\n\nsmall fixes\n\nsmall fixes for readability"}, "afterCommit": {"oid": "ce3c80a82e7a60d79a8a1116b6c111f084571ce4", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/ce3c80a82e7a60d79a8a1116b6c111f084571ce4", "committedDate": "2020-08-14T17:46:33Z", "message": "implemented an azure blob storage filesystem\n\nremoved ignored test from this PR\n\nremoved unused file\n\nfixed a typo\n\nsmall fixes\n\nsmall fixes\n\nsmall fixes\n\nsmall fixes for readability\n\ncleaning code"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ce3c80a82e7a60d79a8a1116b6c111f084571ce4", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/ce3c80a82e7a60d79a8a1116b6c111f084571ce4", "committedDate": "2020-08-14T17:46:33Z", "message": "implemented an azure blob storage filesystem\n\nremoved ignored test from this PR\n\nremoved unused file\n\nfixed a typo\n\nsmall fixes\n\nsmall fixes\n\nsmall fixes\n\nsmall fixes for readability\n\ncleaning code"}, "afterCommit": {"oid": "a4471727d5bba7d22bc9525324e4deec104f0ab8", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/a4471727d5bba7d22bc9525324e4deec104f0ab8", "committedDate": "2020-08-14T18:01:36Z", "message": "implemented an azure blob storage filesystem\n\nremoved ignored test from this PR\n\nremoved unused file\n\nfixed a typo\n\nsmall fixes\n\nsmall fixes\n\nsmall fixes\n\nsmall fixes for readability\n\ncleaning code\n\nsmall fixes"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a4471727d5bba7d22bc9525324e4deec104f0ab8", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/a4471727d5bba7d22bc9525324e4deec104f0ab8", "committedDate": "2020-08-14T18:01:36Z", "message": "implemented an azure blob storage filesystem\n\nremoved ignored test from this PR\n\nremoved unused file\n\nfixed a typo\n\nsmall fixes\n\nsmall fixes\n\nsmall fixes\n\nsmall fixes for readability\n\ncleaning code\n\nsmall fixes"}, "afterCommit": {"oid": "58325cb61a8b8f226b0f8d88131ea7b2337d529d", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/58325cb61a8b8f226b0f8d88131ea7b2337d529d", "committedDate": "2020-08-14T18:37:03Z", "message": "implemented an azure blob storage filesystem\n\nremoved ignored test from this PR\n\nremoved unused file\n\nfixed a typo\n\nsmall fixes\n\nsmall fixes\n\nsmall fixes\n\nsmall fixes for readability\n\ncleaning code\n\nsmall fixes\n\nignore mockito config, move test file"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ea69858d095f9582f3f18b688d9ceb4406a682e7", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/ea69858d095f9582f3f18b688d9ceb4406a682e7", "committedDate": "2020-08-16T15:28:09Z", "message": "Merge branch 'another-azure-branch' of https://github.com/ettirapp/beam into another-azure-branch"}, "afterCommit": {"oid": "707b16b94245a4df3c834d705651f6d21c61dc36", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/707b16b94245a4df3c834d705651f6d21c61dc36", "committedDate": "2020-08-16T15:31:48Z", "message": "implemented an azure blob storage filesystem\n\nremoved ignored test from this PR\n\nremoved unused file\n\nfixed a typo\n\nsmall fixes\n\nsmall fixes\n\nsmall fixes\n\nsmall fixes for readability\n\ncleaning code\n\nsmall fixes\n\nignore mockito config, move test file\n\nimplemented an azure blob storage filesystem\n\nremoved ignored test from this PR\n\nremoved unused file\n\nfixed a typo\n\nsmall fixes\n\nsmall fixes\n\nsmall fixes\n\nsmall fixes for readability\n\ncleaning code\n\nsmall fixes\n\nignore mockito config, move test file\n\nimplemented an azure blob storage filesystem\n\nremoved ignored test from this PR\n\nremoved unused file\n\nfixed a typo\n\nsmall fixes\n\nsmall fixes\n\nsmall fixes\n\nsmall fixes for readability\n\ncleaning code\n\nsmall fixes\n\nignore mockito config, move test file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/f456095e9b54d3256dd1148c217156fb6826950b", "committedDate": "2020-08-16T18:17:31Z", "message": "implemented an azure blob storage filesystem\n\nremoved ignored test from this PR\n\nremoved unused file\n\nfixed a typo\n\nsmall fixes\n\nsmall fixes\n\nsmall fixes\n\nsmall fixes for readability\n\ncleaning code\n\nsmall fixes\n\nignore mockito config, move test file\n\nimplemented an azure blob storage filesystem\n\nremoved ignored test from this PR\n\nremoved unused file\n\nfixed a typo\n\nsmall fixes\n\nsmall fixes\n\nsmall fixes\n\nsmall fixes for readability\n\ncleaning code\n\nsmall fixes\n\nignore mockito config, move test file\n\nimplemented an azure blob storage filesystem\n\nremoved ignored test from this PR\n\nremoved unused file\n\nfixed a typo\n\nsmall fixes\n\nsmall fixes\n\nsmall fixes\n\nsmall fixes for readability\n\ncleaning code\n\nsmall fixes\n\nignore mockito config, move test file\n\norganized dependencies\n\nfixed a typo"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "707b16b94245a4df3c834d705651f6d21c61dc36", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/707b16b94245a4df3c834d705651f6d21c61dc36", "committedDate": "2020-08-16T15:31:48Z", "message": "implemented an azure blob storage filesystem\n\nremoved ignored test from this PR\n\nremoved unused file\n\nfixed a typo\n\nsmall fixes\n\nsmall fixes\n\nsmall fixes\n\nsmall fixes for readability\n\ncleaning code\n\nsmall fixes\n\nignore mockito config, move test file\n\nimplemented an azure blob storage filesystem\n\nremoved ignored test from this PR\n\nremoved unused file\n\nfixed a typo\n\nsmall fixes\n\nsmall fixes\n\nsmall fixes\n\nsmall fixes for readability\n\ncleaning code\n\nsmall fixes\n\nignore mockito config, move test file\n\nimplemented an azure blob storage filesystem\n\nremoved ignored test from this PR\n\nremoved unused file\n\nfixed a typo\n\nsmall fixes\n\nsmall fixes\n\nsmall fixes\n\nsmall fixes for readability\n\ncleaning code\n\nsmall fixes\n\nignore mockito config, move test file"}, "afterCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/f456095e9b54d3256dd1148c217156fb6826950b", "committedDate": "2020-08-16T18:17:31Z", "message": "implemented an azure blob storage filesystem\n\nremoved ignored test from this PR\n\nremoved unused file\n\nfixed a typo\n\nsmall fixes\n\nsmall fixes\n\nsmall fixes\n\nsmall fixes for readability\n\ncleaning code\n\nsmall fixes\n\nignore mockito config, move test file\n\nimplemented an azure blob storage filesystem\n\nremoved ignored test from this PR\n\nremoved unused file\n\nfixed a typo\n\nsmall fixes\n\nsmall fixes\n\nsmall fixes\n\nsmall fixes for readability\n\ncleaning code\n\nsmall fixes\n\nignore mockito config, move test file\n\nimplemented an azure blob storage filesystem\n\nremoved ignored test from this PR\n\nremoved unused file\n\nfixed a typo\n\nsmall fixes\n\nsmall fixes\n\nsmall fixes\n\nsmall fixes for readability\n\ncleaning code\n\nsmall fixes\n\nignore mockito config, move test file\n\norganized dependencies\n\nfixed a typo"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY4MTA2ODY2", "url": "https://github.com/apache/beam/pull/12581#pullrequestreview-468106866", "createdAt": "2020-08-16T23:53:23Z", "commit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "state": "COMMENTED", "comments": {"totalCount": 13, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNlQyMzo1MzoyM1rOHBWR7A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxODoxMzo0MFrOHB0mug==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTE3NTY2MA==", "bodyText": "I think you can return Long directly and the caller should check whether it's null.", "url": "https://github.com/apache/beam/pull/12581#discussion_r471175660", "createdAt": "2020-08-16T23:53:23Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzfsResourceId.java", "diffHunk": "@@ -93,6 +101,22 @@ public String getScheme() {\n     return SCHEME;\n   }\n \n+  Optional<Long> getSize() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTE5NTEzNg==", "bodyText": "Is this resolved now?", "url": "https://github.com/apache/beam/pull/12581#discussion_r471195136", "createdAt": "2020-08-17T01:57:06Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzfsResourceId.java", "diffHunk": "@@ -156,8 +190,6 @@ public int hashCode() {\n   @Override\n   public ResourceId resolve(String other, ResolveOptions resolveOptions) {\n     checkState(isDirectory(), \"Expected this resource to be a directory, but was [%s]\", toString());\n-    // TODO: check if resolve options are an illegal name in any way, see:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 120}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTYwMTAwNA==", "bodyText": "How do we pick up the number 8640000  here? If it should be a constant, we can make it as static final.", "url": "https://github.com/apache/beam/pull/12581#discussion_r471601004", "createdAt": "2020-08-17T16:36:41Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "diffHunk": "@@ -17,67 +17,438 @@\n  */\n package org.apache.beam.sdk.io.azure.blobstore;\n \n+import static java.nio.channels.Channels.newChannel;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobItem;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.BlobStorageException;\n+import com.azure.storage.blob.models.ListBlobsOptions;\n+import com.microsoft.azure.storage.CloudStorageAccount;\n+import com.microsoft.azure.storage.SharedAccessAccountPolicy;\n+import java.io.FileNotFoundException;\n import java.io.IOException;\n+import java.io.OutputStream;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.time.Duration;\n+import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Date;\n+import java.util.Iterator;\n import java.util.List;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n import org.apache.beam.sdk.io.FileSystem;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreClientBuilderFactory;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n import org.apache.beam.sdk.io.fs.CreateOptions;\n import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.util.InstanceBuilder;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Supplier;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Suppliers;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableSet;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n class AzureBlobStoreFileSystem extends FileSystem<AzfsResourceId> {\n \n+  private static final Logger LOG = LoggerFactory.getLogger(AzureBlobStoreFileSystem.class);\n+\n+  private static final ImmutableSet<String> NON_READ_SEEK_EFFICIENT_ENCODINGS =\n+      ImmutableSet.of(\"gzip\");\n+\n+  private Supplier<BlobServiceClient> client;\n+  private final BlobstoreOptions options;\n+\n+  AzureBlobStoreFileSystem(BlobstoreOptions options) {\n+    this.options = checkNotNull(options, \"options\");\n+\n+    BlobServiceClientBuilder builder =\n+        InstanceBuilder.ofType(BlobstoreClientBuilderFactory.class)\n+            .fromClass(options.getBlobstoreClientFactoryClass())\n+            .build()\n+            .createBuilder(options);\n+\n+    // The Supplier is to make sure we don't call .build() unless we are actually using Azure.\n+    client = Suppliers.memoize(builder::buildClient);\n+  }\n+\n+  @VisibleForTesting\n+  void setClient(BlobServiceClient client) {\n+    this.client = Suppliers.ofInstance(client);\n+  }\n+\n+  @VisibleForTesting\n+  BlobServiceClient getClient() {\n+    return client.get();\n+  }\n+\n   @Override\n   protected String getScheme() {\n-    return \"azfs\";\n+    return AzfsResourceId.SCHEME;\n   }\n \n   @Override\n-  protected List<MatchResult> match(List<String> specs) throws IOException {\n-    // TODO\n-    return null;\n+  protected List<MatchResult> match(List<String> specs) {\n+    List<AzfsResourceId> paths =\n+        specs.stream().map(AzfsResourceId::fromUri).collect(Collectors.toList());\n+    List<AzfsResourceId> globs = new ArrayList<>();\n+    List<AzfsResourceId> nonGlobs = new ArrayList<>();\n+    List<Boolean> isGlobBooleans = new ArrayList<>();\n+\n+    for (AzfsResourceId path : paths) {\n+      if (path.isWildcard()) {\n+        globs.add(path);\n+        isGlobBooleans.add(true);\n+      } else {\n+        nonGlobs.add(path);\n+        isGlobBooleans.add(false);\n+      }\n+    }\n+\n+    Iterator<MatchResult> globMatches = matchGlobPaths(globs).iterator();\n+    Iterator<MatchResult> nonGlobMatches = matchNonGlobPaths(nonGlobs).iterator();\n+\n+    ImmutableList.Builder<MatchResult> matchResults = ImmutableList.builder();\n+    for (Boolean isGlob : isGlobBooleans) {\n+      if (isGlob) {\n+        checkState(globMatches.hasNext(), \"Expect globMatches has next.\");\n+        matchResults.add(globMatches.next());\n+      } else {\n+        checkState(nonGlobMatches.hasNext(), \"Expect nonGlobMatches has next.\");\n+        matchResults.add(nonGlobMatches.next());\n+      }\n+    }\n+    checkState(!globMatches.hasNext(), \"Expect no more elements in globMatches.\");\n+    checkState(!nonGlobMatches.hasNext(), \"Expect no more elements in nonGlobMatches.\");\n+\n+    return matchResults.build();\n+  }\n+\n+  /**\n+   * Expands glob expressions to regular expressions.\n+   *\n+   * @param globExp the glob expression to expand\n+   * @return a string with the regular expression this glob expands to\n+   */\n+  @VisibleForTesting\n+  static String wildcardToRegexp(String globExp) {\n+    StringBuilder dst = new StringBuilder();\n+    char[] src = globExp.replace(\"**/*\", \"**\").toCharArray();\n+    int i = 0;\n+    while (i < src.length) {\n+      char c = src[i++];\n+      switch (c) {\n+        case '*':\n+          // One char lookahead for **\n+          if (i < src.length && src[i] == '*') {\n+            dst.append(\".*\");\n+            ++i;\n+          } else {\n+            dst.append(\"[^/]*\");\n+          }\n+          break;\n+        case '?':\n+          dst.append(\"[^/]\");\n+          break;\n+        case '.':\n+        case '+':\n+        case '{':\n+        case '}':\n+        case '(':\n+        case ')':\n+        case '|':\n+        case '^':\n+        case '$':\n+          // These need to be escaped in regular expressions\n+          dst.append('\\\\').append(c);\n+          break;\n+        case '\\\\':\n+          i = doubleSlashes(dst, src, i);\n+          break;\n+        default:\n+          dst.append(c);\n+          break;\n+      }\n+    }\n+    return dst.toString();\n+  }\n+\n+  private static int doubleSlashes(StringBuilder dst, char[] src, int i) {\n+    // Emit the next character without special interpretation\n+    dst.append(\"\\\\\\\\\");\n+    if ((i - 1) != src.length) {\n+      dst.append(src[i]);\n+      i++;\n+    } else {\n+      // A backslash at the very end is treated like an escaped backslash\n+      dst.append('\\\\');\n+    }\n+    return i;\n+  }\n+\n+  private List<MatchResult> matchGlobPaths(List<AzfsResourceId> globs) {\n+    return FluentIterable.from(globs).transform(this::expand).toList();\n+  }\n+\n+  /** Expands a pattern into {@link MatchResult}. */\n+  @VisibleForTesting\n+  MatchResult expand(AzfsResourceId azfsPattern) {\n+\n+    checkArgument(azfsPattern.isWildcard(), \"is Wildcard\");\n+    String blobPrefix = azfsPattern.getBlobNonWildcardPrefix();\n+    Pattern wildcardAsRegexp = Pattern.compile(wildcardToRegexp(azfsPattern.getBlob()));\n+\n+    LOG.debug(\n+        \"matching files in container {}, prefix {} against pattern {}\",\n+        azfsPattern.getContainer(),\n+        blobPrefix,\n+        wildcardAsRegexp.toString());\n+\n+    ListBlobsOptions listOptions = new ListBlobsOptions().setPrefix(blobPrefix);\n+    Duration timeout = Duration.ZERO.plusMinutes(1);\n+\n+    String account = azfsPattern.getAccount();\n+    String container = azfsPattern.getContainer();\n+    BlobContainerClient blobContainerClient = client.get().getBlobContainerClient(container);\n+    PagedIterable<BlobItem> blobs = blobContainerClient.listBlobs(listOptions, timeout);\n+    List<MatchResult.Metadata> results = new ArrayList<>();\n+\n+    blobs.forEach(\n+        blob -> {\n+          String name = blob.getName();\n+          if (wildcardAsRegexp.matcher(name).matches() && !name.endsWith(\"/\")) {\n+            LOG.debug(\"Matched object: {}\", name);\n+\n+            BlobProperties properties = blobContainerClient.getBlobClient(name).getProperties();\n+            AzfsResourceId rid =\n+                AzfsResourceId.fromComponents(account, container, name)\n+                    .withSize(properties.getBlobSize())\n+                    .withLastModified(Date.from(properties.getLastModified().toInstant()));\n+\n+            results.add(toMetadata(rid, properties.getContentEncoding()));\n+          }\n+        });\n+\n+    return MatchResult.create(MatchResult.Status.OK, results);\n+  }\n+\n+  private MatchResult.Metadata toMetadata(AzfsResourceId path, String contentEncoding) {\n+\n+    checkArgument(path.getSize().isPresent(), \"path has size\");\n+    boolean isReadSeekEfficient = !NON_READ_SEEK_EFFICIENT_ENCODINGS.contains(contentEncoding);\n+\n+    return MatchResult.Metadata.builder()\n+        .setIsReadSeekEfficient(isReadSeekEfficient)\n+        .setResourceId(path)\n+        .setSizeBytes(path.getSize().get())\n+        .setLastModifiedMillis(path.getLastModified().transform(Date::getTime).or(0L))\n+        .build();\n+  }\n+\n+  /**\n+   * Returns {@link MatchResult MatchResults} for the given {@link AzfsResourceId paths}.\n+   *\n+   * <p>The number of returned {@link MatchResult MatchResults} equals to the number of given {@link\n+   * AzfsResourceId paths}. Each {@link MatchResult} contains one {@link MatchResult.Metadata}.\n+   */\n+  @VisibleForTesting\n+  private Iterable<MatchResult> matchNonGlobPaths(List<AzfsResourceId> paths) {\n+    ImmutableList.Builder<MatchResult> toReturn = ImmutableList.builder();\n+    for (AzfsResourceId path : paths) {\n+      toReturn.add(toMatchResult(path));\n+    }\n+    return toReturn.build();\n+  }\n+\n+  private MatchResult toMatchResult(AzfsResourceId path) {\n+    BlobClient blobClient =\n+        client.get().getBlobContainerClient(path.getContainer()).getBlobClient(path.getBlob());\n+    BlobProperties blobProperties;\n+\n+    try {\n+      blobProperties = blobClient.getProperties();\n+    } catch (BlobStorageException e) {\n+      if (e.getStatusCode() == 404) {\n+        return MatchResult.create(MatchResult.Status.NOT_FOUND, new FileNotFoundException());\n+      }\n+      return MatchResult.create(MatchResult.Status.ERROR, new IOException(e));\n+    }\n+\n+    return MatchResult.create(\n+        MatchResult.Status.OK,\n+        ImmutableList.of(\n+            toMetadata(\n+                path.withSize(blobProperties.getBlobSize())\n+                    .withLastModified(Date.from(blobProperties.getLastModified().toInstant())),\n+                blobProperties.getContentEncoding())));\n   }\n \n   @Override\n   protected WritableByteChannel create(AzfsResourceId resourceId, CreateOptions createOptions)\n       throws IOException {\n-    // TODO\n-    return null;\n+    BlobContainerClient blobContainerClient =\n+        client.get().getBlobContainerClient(resourceId.getContainer());\n+    if (!blobContainerClient.exists()) {\n+      throw new UnsupportedOperationException(\"create does not create containers.\");\n+    }\n+\n+    BlobClient blobClient = blobContainerClient.getBlobClient(resourceId.getBlob());\n+    // The getBlobOutputStream method overwrites existing blobs,\n+    // so throw an error in this case to prevent data loss\n+    if (blobClient.exists()) {\n+      throw new IOException(\"This filename is already in use.\");\n+    }\n+\n+    OutputStream outputStream;\n+    try {\n+      outputStream = blobClient.getBlockBlobClient().getBlobOutputStream();\n+    } catch (BlobStorageException e) {\n+      throw (IOException) e.getCause();\n+    }\n+    return newChannel(outputStream);\n   }\n \n   @Override\n   protected ReadableByteChannel open(AzfsResourceId resourceId) throws IOException {\n-    // TODO\n-    return null;\n+    BlobClient blobClient =\n+        client\n+            .get()\n+            .getBlobContainerClient(resourceId.getContainer())\n+            .getBlobClient(resourceId.getBlob());\n+    if (!blobClient.exists()) {\n+      throw new FileNotFoundException(\"The requested file doesn't exist.\");\n+    }\n+    return new AzureReadableSeekableByteChannel(blobClient);\n   }\n \n   @Override\n   protected void copy(List<AzfsResourceId> srcPaths, List<AzfsResourceId> destPaths)\n       throws IOException {\n-    // TODO\n+    checkArgument(\n+        srcPaths.size() == destPaths.size(),\n+        \"sizes of source paths and destination paths do not match\");\n+\n+    Iterator<AzfsResourceId> sourcePathsIterator = srcPaths.iterator();\n+    Iterator<AzfsResourceId> destinationPathsIterator = destPaths.iterator();\n+    while (sourcePathsIterator.hasNext()) {\n+      final AzfsResourceId sourcePath = sourcePathsIterator.next();\n+      final AzfsResourceId destinationPath = destinationPathsIterator.next();\n+      copy(sourcePath, destinationPath);\n+    }\n   }\n \n   @VisibleForTesting\n   void copy(AzfsResourceId sourcePath, AzfsResourceId destinationPath) throws IOException {\n-    // TODO\n+    checkArgument(\n+        sourcePath.getBlob() != null && destinationPath.getBlob() != null,\n+        \"This method is intended to copy file-like resources, not directories.\");\n+\n+    // get source blob client\n+    BlobClient srcBlobClient =\n+        client\n+            .get()\n+            .getBlobContainerClient(sourcePath.getContainer())\n+            .getBlobClient(sourcePath.getBlob());\n+    if (!srcBlobClient.exists()) {\n+      throw new FileNotFoundException(\"The copy source does not exist.\");\n+    }\n+\n+    // get destination blob client\n+    BlobContainerClient destBlobContainerClient =\n+        client.get().getBlobContainerClient(destinationPath.getContainer());\n+    if (!destBlobContainerClient.exists()) {\n+      client.get().createBlobContainer(destinationPath.getContainer());\n+    }\n+    BlobClient destBlobClient = destBlobContainerClient.getBlobClient(destinationPath.getBlob());\n+\n+    destBlobClient.copyFromUrl(srcBlobClient.getBlobUrl() + generateSasToken());\n+  }\n+\n+  @VisibleForTesting\n+  String generateSasToken() throws IOException {\n+    SharedAccessAccountPolicy sharedAccessAccountPolicy = new SharedAccessAccountPolicy();\n+    long date = new Date().getTime();\n+    long expiryDate = new Date(date + 8640000).getTime();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 377}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTYwNjAwMA==", "bodyText": "Please have a class-level javadoc to explain what the class is for.", "url": "https://github.com/apache/beam/pull/12581#discussion_r471606000", "createdAt": "2020-08-17T16:45:23Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "diffHunk": "@@ -17,67 +17,438 @@\n  */\n package org.apache.beam.sdk.io.azure.blobstore;\n \n+import static java.nio.channels.Channels.newChannel;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobItem;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.BlobStorageException;\n+import com.azure.storage.blob.models.ListBlobsOptions;\n+import com.microsoft.azure.storage.CloudStorageAccount;\n+import com.microsoft.azure.storage.SharedAccessAccountPolicy;\n+import java.io.FileNotFoundException;\n import java.io.IOException;\n+import java.io.OutputStream;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.time.Duration;\n+import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Date;\n+import java.util.Iterator;\n import java.util.List;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n import org.apache.beam.sdk.io.FileSystem;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreClientBuilderFactory;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n import org.apache.beam.sdk.io.fs.CreateOptions;\n import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.util.InstanceBuilder;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Supplier;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Suppliers;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableSet;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n class AzureBlobStoreFileSystem extends FileSystem<AzfsResourceId> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTYzMTUwNw==", "bodyText": "Can you elaborate more on the error msg? Like the pattern should be wildcard?", "url": "https://github.com/apache/beam/pull/12581#discussion_r471631507", "createdAt": "2020-08-17T17:16:00Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "diffHunk": "@@ -17,67 +17,438 @@\n  */\n package org.apache.beam.sdk.io.azure.blobstore;\n \n+import static java.nio.channels.Channels.newChannel;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobItem;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.BlobStorageException;\n+import com.azure.storage.blob.models.ListBlobsOptions;\n+import com.microsoft.azure.storage.CloudStorageAccount;\n+import com.microsoft.azure.storage.SharedAccessAccountPolicy;\n+import java.io.FileNotFoundException;\n import java.io.IOException;\n+import java.io.OutputStream;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.time.Duration;\n+import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Date;\n+import java.util.Iterator;\n import java.util.List;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n import org.apache.beam.sdk.io.FileSystem;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreClientBuilderFactory;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n import org.apache.beam.sdk.io.fs.CreateOptions;\n import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.util.InstanceBuilder;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Supplier;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Suppliers;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableSet;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n class AzureBlobStoreFileSystem extends FileSystem<AzfsResourceId> {\n \n+  private static final Logger LOG = LoggerFactory.getLogger(AzureBlobStoreFileSystem.class);\n+\n+  private static final ImmutableSet<String> NON_READ_SEEK_EFFICIENT_ENCODINGS =\n+      ImmutableSet.of(\"gzip\");\n+\n+  private Supplier<BlobServiceClient> client;\n+  private final BlobstoreOptions options;\n+\n+  AzureBlobStoreFileSystem(BlobstoreOptions options) {\n+    this.options = checkNotNull(options, \"options\");\n+\n+    BlobServiceClientBuilder builder =\n+        InstanceBuilder.ofType(BlobstoreClientBuilderFactory.class)\n+            .fromClass(options.getBlobstoreClientFactoryClass())\n+            .build()\n+            .createBuilder(options);\n+\n+    // The Supplier is to make sure we don't call .build() unless we are actually using Azure.\n+    client = Suppliers.memoize(builder::buildClient);\n+  }\n+\n+  @VisibleForTesting\n+  void setClient(BlobServiceClient client) {\n+    this.client = Suppliers.ofInstance(client);\n+  }\n+\n+  @VisibleForTesting\n+  BlobServiceClient getClient() {\n+    return client.get();\n+  }\n+\n   @Override\n   protected String getScheme() {\n-    return \"azfs\";\n+    return AzfsResourceId.SCHEME;\n   }\n \n   @Override\n-  protected List<MatchResult> match(List<String> specs) throws IOException {\n-    // TODO\n-    return null;\n+  protected List<MatchResult> match(List<String> specs) {\n+    List<AzfsResourceId> paths =\n+        specs.stream().map(AzfsResourceId::fromUri).collect(Collectors.toList());\n+    List<AzfsResourceId> globs = new ArrayList<>();\n+    List<AzfsResourceId> nonGlobs = new ArrayList<>();\n+    List<Boolean> isGlobBooleans = new ArrayList<>();\n+\n+    for (AzfsResourceId path : paths) {\n+      if (path.isWildcard()) {\n+        globs.add(path);\n+        isGlobBooleans.add(true);\n+      } else {\n+        nonGlobs.add(path);\n+        isGlobBooleans.add(false);\n+      }\n+    }\n+\n+    Iterator<MatchResult> globMatches = matchGlobPaths(globs).iterator();\n+    Iterator<MatchResult> nonGlobMatches = matchNonGlobPaths(nonGlobs).iterator();\n+\n+    ImmutableList.Builder<MatchResult> matchResults = ImmutableList.builder();\n+    for (Boolean isGlob : isGlobBooleans) {\n+      if (isGlob) {\n+        checkState(globMatches.hasNext(), \"Expect globMatches has next.\");\n+        matchResults.add(globMatches.next());\n+      } else {\n+        checkState(nonGlobMatches.hasNext(), \"Expect nonGlobMatches has next.\");\n+        matchResults.add(nonGlobMatches.next());\n+      }\n+    }\n+    checkState(!globMatches.hasNext(), \"Expect no more elements in globMatches.\");\n+    checkState(!nonGlobMatches.hasNext(), \"Expect no more elements in nonGlobMatches.\");\n+\n+    return matchResults.build();\n+  }\n+\n+  /**\n+   * Expands glob expressions to regular expressions.\n+   *\n+   * @param globExp the glob expression to expand\n+   * @return a string with the regular expression this glob expands to\n+   */\n+  @VisibleForTesting\n+  static String wildcardToRegexp(String globExp) {\n+    StringBuilder dst = new StringBuilder();\n+    char[] src = globExp.replace(\"**/*\", \"**\").toCharArray();\n+    int i = 0;\n+    while (i < src.length) {\n+      char c = src[i++];\n+      switch (c) {\n+        case '*':\n+          // One char lookahead for **\n+          if (i < src.length && src[i] == '*') {\n+            dst.append(\".*\");\n+            ++i;\n+          } else {\n+            dst.append(\"[^/]*\");\n+          }\n+          break;\n+        case '?':\n+          dst.append(\"[^/]\");\n+          break;\n+        case '.':\n+        case '+':\n+        case '{':\n+        case '}':\n+        case '(':\n+        case ')':\n+        case '|':\n+        case '^':\n+        case '$':\n+          // These need to be escaped in regular expressions\n+          dst.append('\\\\').append(c);\n+          break;\n+        case '\\\\':\n+          i = doubleSlashes(dst, src, i);\n+          break;\n+        default:\n+          dst.append(c);\n+          break;\n+      }\n+    }\n+    return dst.toString();\n+  }\n+\n+  private static int doubleSlashes(StringBuilder dst, char[] src, int i) {\n+    // Emit the next character without special interpretation\n+    dst.append(\"\\\\\\\\\");\n+    if ((i - 1) != src.length) {\n+      dst.append(src[i]);\n+      i++;\n+    } else {\n+      // A backslash at the very end is treated like an escaped backslash\n+      dst.append('\\\\');\n+    }\n+    return i;\n+  }\n+\n+  private List<MatchResult> matchGlobPaths(List<AzfsResourceId> globs) {\n+    return FluentIterable.from(globs).transform(this::expand).toList();\n+  }\n+\n+  /** Expands a pattern into {@link MatchResult}. */\n+  @VisibleForTesting\n+  MatchResult expand(AzfsResourceId azfsPattern) {\n+\n+    checkArgument(azfsPattern.isWildcard(), \"is Wildcard\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 197}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTYzODAzNw==", "bodyText": "Duration.ofMinutes(1)", "url": "https://github.com/apache/beam/pull/12581#discussion_r471638037", "createdAt": "2020-08-17T17:21:16Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "diffHunk": "@@ -17,67 +17,438 @@\n  */\n package org.apache.beam.sdk.io.azure.blobstore;\n \n+import static java.nio.channels.Channels.newChannel;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobItem;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.BlobStorageException;\n+import com.azure.storage.blob.models.ListBlobsOptions;\n+import com.microsoft.azure.storage.CloudStorageAccount;\n+import com.microsoft.azure.storage.SharedAccessAccountPolicy;\n+import java.io.FileNotFoundException;\n import java.io.IOException;\n+import java.io.OutputStream;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.time.Duration;\n+import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Date;\n+import java.util.Iterator;\n import java.util.List;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n import org.apache.beam.sdk.io.FileSystem;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreClientBuilderFactory;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n import org.apache.beam.sdk.io.fs.CreateOptions;\n import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.util.InstanceBuilder;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Supplier;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Suppliers;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableSet;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n class AzureBlobStoreFileSystem extends FileSystem<AzfsResourceId> {\n \n+  private static final Logger LOG = LoggerFactory.getLogger(AzureBlobStoreFileSystem.class);\n+\n+  private static final ImmutableSet<String> NON_READ_SEEK_EFFICIENT_ENCODINGS =\n+      ImmutableSet.of(\"gzip\");\n+\n+  private Supplier<BlobServiceClient> client;\n+  private final BlobstoreOptions options;\n+\n+  AzureBlobStoreFileSystem(BlobstoreOptions options) {\n+    this.options = checkNotNull(options, \"options\");\n+\n+    BlobServiceClientBuilder builder =\n+        InstanceBuilder.ofType(BlobstoreClientBuilderFactory.class)\n+            .fromClass(options.getBlobstoreClientFactoryClass())\n+            .build()\n+            .createBuilder(options);\n+\n+    // The Supplier is to make sure we don't call .build() unless we are actually using Azure.\n+    client = Suppliers.memoize(builder::buildClient);\n+  }\n+\n+  @VisibleForTesting\n+  void setClient(BlobServiceClient client) {\n+    this.client = Suppliers.ofInstance(client);\n+  }\n+\n+  @VisibleForTesting\n+  BlobServiceClient getClient() {\n+    return client.get();\n+  }\n+\n   @Override\n   protected String getScheme() {\n-    return \"azfs\";\n+    return AzfsResourceId.SCHEME;\n   }\n \n   @Override\n-  protected List<MatchResult> match(List<String> specs) throws IOException {\n-    // TODO\n-    return null;\n+  protected List<MatchResult> match(List<String> specs) {\n+    List<AzfsResourceId> paths =\n+        specs.stream().map(AzfsResourceId::fromUri).collect(Collectors.toList());\n+    List<AzfsResourceId> globs = new ArrayList<>();\n+    List<AzfsResourceId> nonGlobs = new ArrayList<>();\n+    List<Boolean> isGlobBooleans = new ArrayList<>();\n+\n+    for (AzfsResourceId path : paths) {\n+      if (path.isWildcard()) {\n+        globs.add(path);\n+        isGlobBooleans.add(true);\n+      } else {\n+        nonGlobs.add(path);\n+        isGlobBooleans.add(false);\n+      }\n+    }\n+\n+    Iterator<MatchResult> globMatches = matchGlobPaths(globs).iterator();\n+    Iterator<MatchResult> nonGlobMatches = matchNonGlobPaths(nonGlobs).iterator();\n+\n+    ImmutableList.Builder<MatchResult> matchResults = ImmutableList.builder();\n+    for (Boolean isGlob : isGlobBooleans) {\n+      if (isGlob) {\n+        checkState(globMatches.hasNext(), \"Expect globMatches has next.\");\n+        matchResults.add(globMatches.next());\n+      } else {\n+        checkState(nonGlobMatches.hasNext(), \"Expect nonGlobMatches has next.\");\n+        matchResults.add(nonGlobMatches.next());\n+      }\n+    }\n+    checkState(!globMatches.hasNext(), \"Expect no more elements in globMatches.\");\n+    checkState(!nonGlobMatches.hasNext(), \"Expect no more elements in nonGlobMatches.\");\n+\n+    return matchResults.build();\n+  }\n+\n+  /**\n+   * Expands glob expressions to regular expressions.\n+   *\n+   * @param globExp the glob expression to expand\n+   * @return a string with the regular expression this glob expands to\n+   */\n+  @VisibleForTesting\n+  static String wildcardToRegexp(String globExp) {\n+    StringBuilder dst = new StringBuilder();\n+    char[] src = globExp.replace(\"**/*\", \"**\").toCharArray();\n+    int i = 0;\n+    while (i < src.length) {\n+      char c = src[i++];\n+      switch (c) {\n+        case '*':\n+          // One char lookahead for **\n+          if (i < src.length && src[i] == '*') {\n+            dst.append(\".*\");\n+            ++i;\n+          } else {\n+            dst.append(\"[^/]*\");\n+          }\n+          break;\n+        case '?':\n+          dst.append(\"[^/]\");\n+          break;\n+        case '.':\n+        case '+':\n+        case '{':\n+        case '}':\n+        case '(':\n+        case ')':\n+        case '|':\n+        case '^':\n+        case '$':\n+          // These need to be escaped in regular expressions\n+          dst.append('\\\\').append(c);\n+          break;\n+        case '\\\\':\n+          i = doubleSlashes(dst, src, i);\n+          break;\n+        default:\n+          dst.append(c);\n+          break;\n+      }\n+    }\n+    return dst.toString();\n+  }\n+\n+  private static int doubleSlashes(StringBuilder dst, char[] src, int i) {\n+    // Emit the next character without special interpretation\n+    dst.append(\"\\\\\\\\\");\n+    if ((i - 1) != src.length) {\n+      dst.append(src[i]);\n+      i++;\n+    } else {\n+      // A backslash at the very end is treated like an escaped backslash\n+      dst.append('\\\\');\n+    }\n+    return i;\n+  }\n+\n+  private List<MatchResult> matchGlobPaths(List<AzfsResourceId> globs) {\n+    return FluentIterable.from(globs).transform(this::expand).toList();\n+  }\n+\n+  /** Expands a pattern into {@link MatchResult}. */\n+  @VisibleForTesting\n+  MatchResult expand(AzfsResourceId azfsPattern) {\n+\n+    checkArgument(azfsPattern.isWildcard(), \"is Wildcard\");\n+    String blobPrefix = azfsPattern.getBlobNonWildcardPrefix();\n+    Pattern wildcardAsRegexp = Pattern.compile(wildcardToRegexp(azfsPattern.getBlob()));\n+\n+    LOG.debug(\n+        \"matching files in container {}, prefix {} against pattern {}\",\n+        azfsPattern.getContainer(),\n+        blobPrefix,\n+        wildcardAsRegexp.toString());\n+\n+    ListBlobsOptions listOptions = new ListBlobsOptions().setPrefix(blobPrefix);\n+    Duration timeout = Duration.ZERO.plusMinutes(1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 208}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY0MzE5MA==", "bodyText": "Please make the error message specific.", "url": "https://github.com/apache/beam/pull/12581#discussion_r471643190", "createdAt": "2020-08-17T17:25:29Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "diffHunk": "@@ -17,67 +17,438 @@\n  */\n package org.apache.beam.sdk.io.azure.blobstore;\n \n+import static java.nio.channels.Channels.newChannel;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobItem;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.BlobStorageException;\n+import com.azure.storage.blob.models.ListBlobsOptions;\n+import com.microsoft.azure.storage.CloudStorageAccount;\n+import com.microsoft.azure.storage.SharedAccessAccountPolicy;\n+import java.io.FileNotFoundException;\n import java.io.IOException;\n+import java.io.OutputStream;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.time.Duration;\n+import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Date;\n+import java.util.Iterator;\n import java.util.List;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n import org.apache.beam.sdk.io.FileSystem;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreClientBuilderFactory;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n import org.apache.beam.sdk.io.fs.CreateOptions;\n import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.util.InstanceBuilder;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Supplier;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Suppliers;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableSet;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n class AzureBlobStoreFileSystem extends FileSystem<AzfsResourceId> {\n \n+  private static final Logger LOG = LoggerFactory.getLogger(AzureBlobStoreFileSystem.class);\n+\n+  private static final ImmutableSet<String> NON_READ_SEEK_EFFICIENT_ENCODINGS =\n+      ImmutableSet.of(\"gzip\");\n+\n+  private Supplier<BlobServiceClient> client;\n+  private final BlobstoreOptions options;\n+\n+  AzureBlobStoreFileSystem(BlobstoreOptions options) {\n+    this.options = checkNotNull(options, \"options\");\n+\n+    BlobServiceClientBuilder builder =\n+        InstanceBuilder.ofType(BlobstoreClientBuilderFactory.class)\n+            .fromClass(options.getBlobstoreClientFactoryClass())\n+            .build()\n+            .createBuilder(options);\n+\n+    // The Supplier is to make sure we don't call .build() unless we are actually using Azure.\n+    client = Suppliers.memoize(builder::buildClient);\n+  }\n+\n+  @VisibleForTesting\n+  void setClient(BlobServiceClient client) {\n+    this.client = Suppliers.ofInstance(client);\n+  }\n+\n+  @VisibleForTesting\n+  BlobServiceClient getClient() {\n+    return client.get();\n+  }\n+\n   @Override\n   protected String getScheme() {\n-    return \"azfs\";\n+    return AzfsResourceId.SCHEME;\n   }\n \n   @Override\n-  protected List<MatchResult> match(List<String> specs) throws IOException {\n-    // TODO\n-    return null;\n+  protected List<MatchResult> match(List<String> specs) {\n+    List<AzfsResourceId> paths =\n+        specs.stream().map(AzfsResourceId::fromUri).collect(Collectors.toList());\n+    List<AzfsResourceId> globs = new ArrayList<>();\n+    List<AzfsResourceId> nonGlobs = new ArrayList<>();\n+    List<Boolean> isGlobBooleans = new ArrayList<>();\n+\n+    for (AzfsResourceId path : paths) {\n+      if (path.isWildcard()) {\n+        globs.add(path);\n+        isGlobBooleans.add(true);\n+      } else {\n+        nonGlobs.add(path);\n+        isGlobBooleans.add(false);\n+      }\n+    }\n+\n+    Iterator<MatchResult> globMatches = matchGlobPaths(globs).iterator();\n+    Iterator<MatchResult> nonGlobMatches = matchNonGlobPaths(nonGlobs).iterator();\n+\n+    ImmutableList.Builder<MatchResult> matchResults = ImmutableList.builder();\n+    for (Boolean isGlob : isGlobBooleans) {\n+      if (isGlob) {\n+        checkState(globMatches.hasNext(), \"Expect globMatches has next.\");\n+        matchResults.add(globMatches.next());\n+      } else {\n+        checkState(nonGlobMatches.hasNext(), \"Expect nonGlobMatches has next.\");\n+        matchResults.add(nonGlobMatches.next());\n+      }\n+    }\n+    checkState(!globMatches.hasNext(), \"Expect no more elements in globMatches.\");\n+    checkState(!nonGlobMatches.hasNext(), \"Expect no more elements in nonGlobMatches.\");\n+\n+    return matchResults.build();\n+  }\n+\n+  /**\n+   * Expands glob expressions to regular expressions.\n+   *\n+   * @param globExp the glob expression to expand\n+   * @return a string with the regular expression this glob expands to\n+   */\n+  @VisibleForTesting\n+  static String wildcardToRegexp(String globExp) {\n+    StringBuilder dst = new StringBuilder();\n+    char[] src = globExp.replace(\"**/*\", \"**\").toCharArray();\n+    int i = 0;\n+    while (i < src.length) {\n+      char c = src[i++];\n+      switch (c) {\n+        case '*':\n+          // One char lookahead for **\n+          if (i < src.length && src[i] == '*') {\n+            dst.append(\".*\");\n+            ++i;\n+          } else {\n+            dst.append(\"[^/]*\");\n+          }\n+          break;\n+        case '?':\n+          dst.append(\"[^/]\");\n+          break;\n+        case '.':\n+        case '+':\n+        case '{':\n+        case '}':\n+        case '(':\n+        case ')':\n+        case '|':\n+        case '^':\n+        case '$':\n+          // These need to be escaped in regular expressions\n+          dst.append('\\\\').append(c);\n+          break;\n+        case '\\\\':\n+          i = doubleSlashes(dst, src, i);\n+          break;\n+        default:\n+          dst.append(c);\n+          break;\n+      }\n+    }\n+    return dst.toString();\n+  }\n+\n+  private static int doubleSlashes(StringBuilder dst, char[] src, int i) {\n+    // Emit the next character without special interpretation\n+    dst.append(\"\\\\\\\\\");\n+    if ((i - 1) != src.length) {\n+      dst.append(src[i]);\n+      i++;\n+    } else {\n+      // A backslash at the very end is treated like an escaped backslash\n+      dst.append('\\\\');\n+    }\n+    return i;\n+  }\n+\n+  private List<MatchResult> matchGlobPaths(List<AzfsResourceId> globs) {\n+    return FluentIterable.from(globs).transform(this::expand).toList();\n+  }\n+\n+  /** Expands a pattern into {@link MatchResult}. */\n+  @VisibleForTesting\n+  MatchResult expand(AzfsResourceId azfsPattern) {\n+\n+    checkArgument(azfsPattern.isWildcard(), \"is Wildcard\");\n+    String blobPrefix = azfsPattern.getBlobNonWildcardPrefix();\n+    Pattern wildcardAsRegexp = Pattern.compile(wildcardToRegexp(azfsPattern.getBlob()));\n+\n+    LOG.debug(\n+        \"matching files in container {}, prefix {} against pattern {}\",\n+        azfsPattern.getContainer(),\n+        blobPrefix,\n+        wildcardAsRegexp.toString());\n+\n+    ListBlobsOptions listOptions = new ListBlobsOptions().setPrefix(blobPrefix);\n+    Duration timeout = Duration.ZERO.plusMinutes(1);\n+\n+    String account = azfsPattern.getAccount();\n+    String container = azfsPattern.getContainer();\n+    BlobContainerClient blobContainerClient = client.get().getBlobContainerClient(container);\n+    PagedIterable<BlobItem> blobs = blobContainerClient.listBlobs(listOptions, timeout);\n+    List<MatchResult.Metadata> results = new ArrayList<>();\n+\n+    blobs.forEach(\n+        blob -> {\n+          String name = blob.getName();\n+          if (wildcardAsRegexp.matcher(name).matches() && !name.endsWith(\"/\")) {\n+            LOG.debug(\"Matched object: {}\", name);\n+\n+            BlobProperties properties = blobContainerClient.getBlobClient(name).getProperties();\n+            AzfsResourceId rid =\n+                AzfsResourceId.fromComponents(account, container, name)\n+                    .withSize(properties.getBlobSize())\n+                    .withLastModified(Date.from(properties.getLastModified().toInstant()));\n+\n+            results.add(toMetadata(rid, properties.getContentEncoding()));\n+          }\n+        });\n+\n+    return MatchResult.create(MatchResult.Status.OK, results);\n+  }\n+\n+  private MatchResult.Metadata toMetadata(AzfsResourceId path, String contentEncoding) {\n+\n+    checkArgument(path.getSize().isPresent(), \"path has size\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 237}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY1MTA2MA==", "bodyText": "Why is it an UnsupportedOperationException ? Under what kind of condition the blobContainerClient.exists() will be false?", "url": "https://github.com/apache/beam/pull/12581#discussion_r471651060", "createdAt": "2020-08-17T17:34:42Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "diffHunk": "@@ -17,67 +17,438 @@\n  */\n package org.apache.beam.sdk.io.azure.blobstore;\n \n+import static java.nio.channels.Channels.newChannel;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobItem;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.BlobStorageException;\n+import com.azure.storage.blob.models.ListBlobsOptions;\n+import com.microsoft.azure.storage.CloudStorageAccount;\n+import com.microsoft.azure.storage.SharedAccessAccountPolicy;\n+import java.io.FileNotFoundException;\n import java.io.IOException;\n+import java.io.OutputStream;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.time.Duration;\n+import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Date;\n+import java.util.Iterator;\n import java.util.List;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n import org.apache.beam.sdk.io.FileSystem;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreClientBuilderFactory;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n import org.apache.beam.sdk.io.fs.CreateOptions;\n import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.util.InstanceBuilder;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Supplier;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Suppliers;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableSet;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n class AzureBlobStoreFileSystem extends FileSystem<AzfsResourceId> {\n \n+  private static final Logger LOG = LoggerFactory.getLogger(AzureBlobStoreFileSystem.class);\n+\n+  private static final ImmutableSet<String> NON_READ_SEEK_EFFICIENT_ENCODINGS =\n+      ImmutableSet.of(\"gzip\");\n+\n+  private Supplier<BlobServiceClient> client;\n+  private final BlobstoreOptions options;\n+\n+  AzureBlobStoreFileSystem(BlobstoreOptions options) {\n+    this.options = checkNotNull(options, \"options\");\n+\n+    BlobServiceClientBuilder builder =\n+        InstanceBuilder.ofType(BlobstoreClientBuilderFactory.class)\n+            .fromClass(options.getBlobstoreClientFactoryClass())\n+            .build()\n+            .createBuilder(options);\n+\n+    // The Supplier is to make sure we don't call .build() unless we are actually using Azure.\n+    client = Suppliers.memoize(builder::buildClient);\n+  }\n+\n+  @VisibleForTesting\n+  void setClient(BlobServiceClient client) {\n+    this.client = Suppliers.ofInstance(client);\n+  }\n+\n+  @VisibleForTesting\n+  BlobServiceClient getClient() {\n+    return client.get();\n+  }\n+\n   @Override\n   protected String getScheme() {\n-    return \"azfs\";\n+    return AzfsResourceId.SCHEME;\n   }\n \n   @Override\n-  protected List<MatchResult> match(List<String> specs) throws IOException {\n-    // TODO\n-    return null;\n+  protected List<MatchResult> match(List<String> specs) {\n+    List<AzfsResourceId> paths =\n+        specs.stream().map(AzfsResourceId::fromUri).collect(Collectors.toList());\n+    List<AzfsResourceId> globs = new ArrayList<>();\n+    List<AzfsResourceId> nonGlobs = new ArrayList<>();\n+    List<Boolean> isGlobBooleans = new ArrayList<>();\n+\n+    for (AzfsResourceId path : paths) {\n+      if (path.isWildcard()) {\n+        globs.add(path);\n+        isGlobBooleans.add(true);\n+      } else {\n+        nonGlobs.add(path);\n+        isGlobBooleans.add(false);\n+      }\n+    }\n+\n+    Iterator<MatchResult> globMatches = matchGlobPaths(globs).iterator();\n+    Iterator<MatchResult> nonGlobMatches = matchNonGlobPaths(nonGlobs).iterator();\n+\n+    ImmutableList.Builder<MatchResult> matchResults = ImmutableList.builder();\n+    for (Boolean isGlob : isGlobBooleans) {\n+      if (isGlob) {\n+        checkState(globMatches.hasNext(), \"Expect globMatches has next.\");\n+        matchResults.add(globMatches.next());\n+      } else {\n+        checkState(nonGlobMatches.hasNext(), \"Expect nonGlobMatches has next.\");\n+        matchResults.add(nonGlobMatches.next());\n+      }\n+    }\n+    checkState(!globMatches.hasNext(), \"Expect no more elements in globMatches.\");\n+    checkState(!nonGlobMatches.hasNext(), \"Expect no more elements in nonGlobMatches.\");\n+\n+    return matchResults.build();\n+  }\n+\n+  /**\n+   * Expands glob expressions to regular expressions.\n+   *\n+   * @param globExp the glob expression to expand\n+   * @return a string with the regular expression this glob expands to\n+   */\n+  @VisibleForTesting\n+  static String wildcardToRegexp(String globExp) {\n+    StringBuilder dst = new StringBuilder();\n+    char[] src = globExp.replace(\"**/*\", \"**\").toCharArray();\n+    int i = 0;\n+    while (i < src.length) {\n+      char c = src[i++];\n+      switch (c) {\n+        case '*':\n+          // One char lookahead for **\n+          if (i < src.length && src[i] == '*') {\n+            dst.append(\".*\");\n+            ++i;\n+          } else {\n+            dst.append(\"[^/]*\");\n+          }\n+          break;\n+        case '?':\n+          dst.append(\"[^/]\");\n+          break;\n+        case '.':\n+        case '+':\n+        case '{':\n+        case '}':\n+        case '(':\n+        case ')':\n+        case '|':\n+        case '^':\n+        case '$':\n+          // These need to be escaped in regular expressions\n+          dst.append('\\\\').append(c);\n+          break;\n+        case '\\\\':\n+          i = doubleSlashes(dst, src, i);\n+          break;\n+        default:\n+          dst.append(c);\n+          break;\n+      }\n+    }\n+    return dst.toString();\n+  }\n+\n+  private static int doubleSlashes(StringBuilder dst, char[] src, int i) {\n+    // Emit the next character without special interpretation\n+    dst.append(\"\\\\\\\\\");\n+    if ((i - 1) != src.length) {\n+      dst.append(src[i]);\n+      i++;\n+    } else {\n+      // A backslash at the very end is treated like an escaped backslash\n+      dst.append('\\\\');\n+    }\n+    return i;\n+  }\n+\n+  private List<MatchResult> matchGlobPaths(List<AzfsResourceId> globs) {\n+    return FluentIterable.from(globs).transform(this::expand).toList();\n+  }\n+\n+  /** Expands a pattern into {@link MatchResult}. */\n+  @VisibleForTesting\n+  MatchResult expand(AzfsResourceId azfsPattern) {\n+\n+    checkArgument(azfsPattern.isWildcard(), \"is Wildcard\");\n+    String blobPrefix = azfsPattern.getBlobNonWildcardPrefix();\n+    Pattern wildcardAsRegexp = Pattern.compile(wildcardToRegexp(azfsPattern.getBlob()));\n+\n+    LOG.debug(\n+        \"matching files in container {}, prefix {} against pattern {}\",\n+        azfsPattern.getContainer(),\n+        blobPrefix,\n+        wildcardAsRegexp.toString());\n+\n+    ListBlobsOptions listOptions = new ListBlobsOptions().setPrefix(blobPrefix);\n+    Duration timeout = Duration.ZERO.plusMinutes(1);\n+\n+    String account = azfsPattern.getAccount();\n+    String container = azfsPattern.getContainer();\n+    BlobContainerClient blobContainerClient = client.get().getBlobContainerClient(container);\n+    PagedIterable<BlobItem> blobs = blobContainerClient.listBlobs(listOptions, timeout);\n+    List<MatchResult.Metadata> results = new ArrayList<>();\n+\n+    blobs.forEach(\n+        blob -> {\n+          String name = blob.getName();\n+          if (wildcardAsRegexp.matcher(name).matches() && !name.endsWith(\"/\")) {\n+            LOG.debug(\"Matched object: {}\", name);\n+\n+            BlobProperties properties = blobContainerClient.getBlobClient(name).getProperties();\n+            AzfsResourceId rid =\n+                AzfsResourceId.fromComponents(account, container, name)\n+                    .withSize(properties.getBlobSize())\n+                    .withLastModified(Date.from(properties.getLastModified().toInstant()));\n+\n+            results.add(toMetadata(rid, properties.getContentEncoding()));\n+          }\n+        });\n+\n+    return MatchResult.create(MatchResult.Status.OK, results);\n+  }\n+\n+  private MatchResult.Metadata toMetadata(AzfsResourceId path, String contentEncoding) {\n+\n+    checkArgument(path.getSize().isPresent(), \"path has size\");\n+    boolean isReadSeekEfficient = !NON_READ_SEEK_EFFICIENT_ENCODINGS.contains(contentEncoding);\n+\n+    return MatchResult.Metadata.builder()\n+        .setIsReadSeekEfficient(isReadSeekEfficient)\n+        .setResourceId(path)\n+        .setSizeBytes(path.getSize().get())\n+        .setLastModifiedMillis(path.getLastModified().transform(Date::getTime).or(0L))\n+        .build();\n+  }\n+\n+  /**\n+   * Returns {@link MatchResult MatchResults} for the given {@link AzfsResourceId paths}.\n+   *\n+   * <p>The number of returned {@link MatchResult MatchResults} equals to the number of given {@link\n+   * AzfsResourceId paths}. Each {@link MatchResult} contains one {@link MatchResult.Metadata}.\n+   */\n+  @VisibleForTesting\n+  private Iterable<MatchResult> matchNonGlobPaths(List<AzfsResourceId> paths) {\n+    ImmutableList.Builder<MatchResult> toReturn = ImmutableList.builder();\n+    for (AzfsResourceId path : paths) {\n+      toReturn.add(toMatchResult(path));\n+    }\n+    return toReturn.build();\n+  }\n+\n+  private MatchResult toMatchResult(AzfsResourceId path) {\n+    BlobClient blobClient =\n+        client.get().getBlobContainerClient(path.getContainer()).getBlobClient(path.getBlob());\n+    BlobProperties blobProperties;\n+\n+    try {\n+      blobProperties = blobClient.getProperties();\n+    } catch (BlobStorageException e) {\n+      if (e.getStatusCode() == 404) {\n+        return MatchResult.create(MatchResult.Status.NOT_FOUND, new FileNotFoundException());\n+      }\n+      return MatchResult.create(MatchResult.Status.ERROR, new IOException(e));\n+    }\n+\n+    return MatchResult.create(\n+        MatchResult.Status.OK,\n+        ImmutableList.of(\n+            toMetadata(\n+                path.withSize(blobProperties.getBlobSize())\n+                    .withLastModified(Date.from(blobProperties.getLastModified().toInstant())),\n+                blobProperties.getContentEncoding())));\n   }\n \n   @Override\n   protected WritableByteChannel create(AzfsResourceId resourceId, CreateOptions createOptions)\n       throws IOException {\n-    // TODO\n-    return null;\n+    BlobContainerClient blobContainerClient =\n+        client.get().getBlobContainerClient(resourceId.getContainer());\n+    if (!blobContainerClient.exists()) {\n+      throw new UnsupportedOperationException(\"create does not create containers.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 294}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY1Nzc5MA==", "bodyText": "Can we make the constant string racwdlup  and co  as static final attribute of the class?", "url": "https://github.com/apache/beam/pull/12581#discussion_r471657790", "createdAt": "2020-08-17T17:47:36Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "diffHunk": "@@ -17,67 +17,438 @@\n  */\n package org.apache.beam.sdk.io.azure.blobstore;\n \n+import static java.nio.channels.Channels.newChannel;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobItem;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.BlobStorageException;\n+import com.azure.storage.blob.models.ListBlobsOptions;\n+import com.microsoft.azure.storage.CloudStorageAccount;\n+import com.microsoft.azure.storage.SharedAccessAccountPolicy;\n+import java.io.FileNotFoundException;\n import java.io.IOException;\n+import java.io.OutputStream;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.time.Duration;\n+import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Date;\n+import java.util.Iterator;\n import java.util.List;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n import org.apache.beam.sdk.io.FileSystem;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreClientBuilderFactory;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n import org.apache.beam.sdk.io.fs.CreateOptions;\n import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.util.InstanceBuilder;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Supplier;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Suppliers;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableSet;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n class AzureBlobStoreFileSystem extends FileSystem<AzfsResourceId> {\n \n+  private static final Logger LOG = LoggerFactory.getLogger(AzureBlobStoreFileSystem.class);\n+\n+  private static final ImmutableSet<String> NON_READ_SEEK_EFFICIENT_ENCODINGS =\n+      ImmutableSet.of(\"gzip\");\n+\n+  private Supplier<BlobServiceClient> client;\n+  private final BlobstoreOptions options;\n+\n+  AzureBlobStoreFileSystem(BlobstoreOptions options) {\n+    this.options = checkNotNull(options, \"options\");\n+\n+    BlobServiceClientBuilder builder =\n+        InstanceBuilder.ofType(BlobstoreClientBuilderFactory.class)\n+            .fromClass(options.getBlobstoreClientFactoryClass())\n+            .build()\n+            .createBuilder(options);\n+\n+    // The Supplier is to make sure we don't call .build() unless we are actually using Azure.\n+    client = Suppliers.memoize(builder::buildClient);\n+  }\n+\n+  @VisibleForTesting\n+  void setClient(BlobServiceClient client) {\n+    this.client = Suppliers.ofInstance(client);\n+  }\n+\n+  @VisibleForTesting\n+  BlobServiceClient getClient() {\n+    return client.get();\n+  }\n+\n   @Override\n   protected String getScheme() {\n-    return \"azfs\";\n+    return AzfsResourceId.SCHEME;\n   }\n \n   @Override\n-  protected List<MatchResult> match(List<String> specs) throws IOException {\n-    // TODO\n-    return null;\n+  protected List<MatchResult> match(List<String> specs) {\n+    List<AzfsResourceId> paths =\n+        specs.stream().map(AzfsResourceId::fromUri).collect(Collectors.toList());\n+    List<AzfsResourceId> globs = new ArrayList<>();\n+    List<AzfsResourceId> nonGlobs = new ArrayList<>();\n+    List<Boolean> isGlobBooleans = new ArrayList<>();\n+\n+    for (AzfsResourceId path : paths) {\n+      if (path.isWildcard()) {\n+        globs.add(path);\n+        isGlobBooleans.add(true);\n+      } else {\n+        nonGlobs.add(path);\n+        isGlobBooleans.add(false);\n+      }\n+    }\n+\n+    Iterator<MatchResult> globMatches = matchGlobPaths(globs).iterator();\n+    Iterator<MatchResult> nonGlobMatches = matchNonGlobPaths(nonGlobs).iterator();\n+\n+    ImmutableList.Builder<MatchResult> matchResults = ImmutableList.builder();\n+    for (Boolean isGlob : isGlobBooleans) {\n+      if (isGlob) {\n+        checkState(globMatches.hasNext(), \"Expect globMatches has next.\");\n+        matchResults.add(globMatches.next());\n+      } else {\n+        checkState(nonGlobMatches.hasNext(), \"Expect nonGlobMatches has next.\");\n+        matchResults.add(nonGlobMatches.next());\n+      }\n+    }\n+    checkState(!globMatches.hasNext(), \"Expect no more elements in globMatches.\");\n+    checkState(!nonGlobMatches.hasNext(), \"Expect no more elements in nonGlobMatches.\");\n+\n+    return matchResults.build();\n+  }\n+\n+  /**\n+   * Expands glob expressions to regular expressions.\n+   *\n+   * @param globExp the glob expression to expand\n+   * @return a string with the regular expression this glob expands to\n+   */\n+  @VisibleForTesting\n+  static String wildcardToRegexp(String globExp) {\n+    StringBuilder dst = new StringBuilder();\n+    char[] src = globExp.replace(\"**/*\", \"**\").toCharArray();\n+    int i = 0;\n+    while (i < src.length) {\n+      char c = src[i++];\n+      switch (c) {\n+        case '*':\n+          // One char lookahead for **\n+          if (i < src.length && src[i] == '*') {\n+            dst.append(\".*\");\n+            ++i;\n+          } else {\n+            dst.append(\"[^/]*\");\n+          }\n+          break;\n+        case '?':\n+          dst.append(\"[^/]\");\n+          break;\n+        case '.':\n+        case '+':\n+        case '{':\n+        case '}':\n+        case '(':\n+        case ')':\n+        case '|':\n+        case '^':\n+        case '$':\n+          // These need to be escaped in regular expressions\n+          dst.append('\\\\').append(c);\n+          break;\n+        case '\\\\':\n+          i = doubleSlashes(dst, src, i);\n+          break;\n+        default:\n+          dst.append(c);\n+          break;\n+      }\n+    }\n+    return dst.toString();\n+  }\n+\n+  private static int doubleSlashes(StringBuilder dst, char[] src, int i) {\n+    // Emit the next character without special interpretation\n+    dst.append(\"\\\\\\\\\");\n+    if ((i - 1) != src.length) {\n+      dst.append(src[i]);\n+      i++;\n+    } else {\n+      // A backslash at the very end is treated like an escaped backslash\n+      dst.append('\\\\');\n+    }\n+    return i;\n+  }\n+\n+  private List<MatchResult> matchGlobPaths(List<AzfsResourceId> globs) {\n+    return FluentIterable.from(globs).transform(this::expand).toList();\n+  }\n+\n+  /** Expands a pattern into {@link MatchResult}. */\n+  @VisibleForTesting\n+  MatchResult expand(AzfsResourceId azfsPattern) {\n+\n+    checkArgument(azfsPattern.isWildcard(), \"is Wildcard\");\n+    String blobPrefix = azfsPattern.getBlobNonWildcardPrefix();\n+    Pattern wildcardAsRegexp = Pattern.compile(wildcardToRegexp(azfsPattern.getBlob()));\n+\n+    LOG.debug(\n+        \"matching files in container {}, prefix {} against pattern {}\",\n+        azfsPattern.getContainer(),\n+        blobPrefix,\n+        wildcardAsRegexp.toString());\n+\n+    ListBlobsOptions listOptions = new ListBlobsOptions().setPrefix(blobPrefix);\n+    Duration timeout = Duration.ZERO.plusMinutes(1);\n+\n+    String account = azfsPattern.getAccount();\n+    String container = azfsPattern.getContainer();\n+    BlobContainerClient blobContainerClient = client.get().getBlobContainerClient(container);\n+    PagedIterable<BlobItem> blobs = blobContainerClient.listBlobs(listOptions, timeout);\n+    List<MatchResult.Metadata> results = new ArrayList<>();\n+\n+    blobs.forEach(\n+        blob -> {\n+          String name = blob.getName();\n+          if (wildcardAsRegexp.matcher(name).matches() && !name.endsWith(\"/\")) {\n+            LOG.debug(\"Matched object: {}\", name);\n+\n+            BlobProperties properties = blobContainerClient.getBlobClient(name).getProperties();\n+            AzfsResourceId rid =\n+                AzfsResourceId.fromComponents(account, container, name)\n+                    .withSize(properties.getBlobSize())\n+                    .withLastModified(Date.from(properties.getLastModified().toInstant()));\n+\n+            results.add(toMetadata(rid, properties.getContentEncoding()));\n+          }\n+        });\n+\n+    return MatchResult.create(MatchResult.Status.OK, results);\n+  }\n+\n+  private MatchResult.Metadata toMetadata(AzfsResourceId path, String contentEncoding) {\n+\n+    checkArgument(path.getSize().isPresent(), \"path has size\");\n+    boolean isReadSeekEfficient = !NON_READ_SEEK_EFFICIENT_ENCODINGS.contains(contentEncoding);\n+\n+    return MatchResult.Metadata.builder()\n+        .setIsReadSeekEfficient(isReadSeekEfficient)\n+        .setResourceId(path)\n+        .setSizeBytes(path.getSize().get())\n+        .setLastModifiedMillis(path.getLastModified().transform(Date::getTime).or(0L))\n+        .build();\n+  }\n+\n+  /**\n+   * Returns {@link MatchResult MatchResults} for the given {@link AzfsResourceId paths}.\n+   *\n+   * <p>The number of returned {@link MatchResult MatchResults} equals to the number of given {@link\n+   * AzfsResourceId paths}. Each {@link MatchResult} contains one {@link MatchResult.Metadata}.\n+   */\n+  @VisibleForTesting\n+  private Iterable<MatchResult> matchNonGlobPaths(List<AzfsResourceId> paths) {\n+    ImmutableList.Builder<MatchResult> toReturn = ImmutableList.builder();\n+    for (AzfsResourceId path : paths) {\n+      toReturn.add(toMatchResult(path));\n+    }\n+    return toReturn.build();\n+  }\n+\n+  private MatchResult toMatchResult(AzfsResourceId path) {\n+    BlobClient blobClient =\n+        client.get().getBlobContainerClient(path.getContainer()).getBlobClient(path.getBlob());\n+    BlobProperties blobProperties;\n+\n+    try {\n+      blobProperties = blobClient.getProperties();\n+    } catch (BlobStorageException e) {\n+      if (e.getStatusCode() == 404) {\n+        return MatchResult.create(MatchResult.Status.NOT_FOUND, new FileNotFoundException());\n+      }\n+      return MatchResult.create(MatchResult.Status.ERROR, new IOException(e));\n+    }\n+\n+    return MatchResult.create(\n+        MatchResult.Status.OK,\n+        ImmutableList.of(\n+            toMetadata(\n+                path.withSize(blobProperties.getBlobSize())\n+                    .withLastModified(Date.from(blobProperties.getLastModified().toInstant())),\n+                blobProperties.getContentEncoding())));\n   }\n \n   @Override\n   protected WritableByteChannel create(AzfsResourceId resourceId, CreateOptions createOptions)\n       throws IOException {\n-    // TODO\n-    return null;\n+    BlobContainerClient blobContainerClient =\n+        client.get().getBlobContainerClient(resourceId.getContainer());\n+    if (!blobContainerClient.exists()) {\n+      throw new UnsupportedOperationException(\"create does not create containers.\");\n+    }\n+\n+    BlobClient blobClient = blobContainerClient.getBlobClient(resourceId.getBlob());\n+    // The getBlobOutputStream method overwrites existing blobs,\n+    // so throw an error in this case to prevent data loss\n+    if (blobClient.exists()) {\n+      throw new IOException(\"This filename is already in use.\");\n+    }\n+\n+    OutputStream outputStream;\n+    try {\n+      outputStream = blobClient.getBlockBlobClient().getBlobOutputStream();\n+    } catch (BlobStorageException e) {\n+      throw (IOException) e.getCause();\n+    }\n+    return newChannel(outputStream);\n   }\n \n   @Override\n   protected ReadableByteChannel open(AzfsResourceId resourceId) throws IOException {\n-    // TODO\n-    return null;\n+    BlobClient blobClient =\n+        client\n+            .get()\n+            .getBlobContainerClient(resourceId.getContainer())\n+            .getBlobClient(resourceId.getBlob());\n+    if (!blobClient.exists()) {\n+      throw new FileNotFoundException(\"The requested file doesn't exist.\");\n+    }\n+    return new AzureReadableSeekableByteChannel(blobClient);\n   }\n \n   @Override\n   protected void copy(List<AzfsResourceId> srcPaths, List<AzfsResourceId> destPaths)\n       throws IOException {\n-    // TODO\n+    checkArgument(\n+        srcPaths.size() == destPaths.size(),\n+        \"sizes of source paths and destination paths do not match\");\n+\n+    Iterator<AzfsResourceId> sourcePathsIterator = srcPaths.iterator();\n+    Iterator<AzfsResourceId> destinationPathsIterator = destPaths.iterator();\n+    while (sourcePathsIterator.hasNext()) {\n+      final AzfsResourceId sourcePath = sourcePathsIterator.next();\n+      final AzfsResourceId destinationPath = destinationPathsIterator.next();\n+      copy(sourcePath, destinationPath);\n+    }\n   }\n \n   @VisibleForTesting\n   void copy(AzfsResourceId sourcePath, AzfsResourceId destinationPath) throws IOException {\n-    // TODO\n+    checkArgument(\n+        sourcePath.getBlob() != null && destinationPath.getBlob() != null,\n+        \"This method is intended to copy file-like resources, not directories.\");\n+\n+    // get source blob client\n+    BlobClient srcBlobClient =\n+        client\n+            .get()\n+            .getBlobContainerClient(sourcePath.getContainer())\n+            .getBlobClient(sourcePath.getBlob());\n+    if (!srcBlobClient.exists()) {\n+      throw new FileNotFoundException(\"The copy source does not exist.\");\n+    }\n+\n+    // get destination blob client\n+    BlobContainerClient destBlobContainerClient =\n+        client.get().getBlobContainerClient(destinationPath.getContainer());\n+    if (!destBlobContainerClient.exists()) {\n+      client.get().createBlobContainer(destinationPath.getContainer());\n+    }\n+    BlobClient destBlobClient = destBlobContainerClient.getBlobClient(destinationPath.getBlob());\n+\n+    destBlobClient.copyFromUrl(srcBlobClient.getBlobUrl() + generateSasToken());\n+  }\n+\n+  @VisibleForTesting\n+  String generateSasToken() throws IOException {\n+    SharedAccessAccountPolicy sharedAccessAccountPolicy = new SharedAccessAccountPolicy();\n+    long date = new Date().getTime();\n+    long expiryDate = new Date(date + 8640000).getTime();\n+\n+    sharedAccessAccountPolicy.setPermissionsFromString(\"racwdlup\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 379}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY1ODcyOA==", "bodyText": "Please make the comment as the javadoc.", "url": "https://github.com/apache/beam/pull/12581#discussion_r471658728", "createdAt": "2020-08-17T17:49:14Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "diffHunk": "@@ -17,67 +17,438 @@\n  */\n package org.apache.beam.sdk.io.azure.blobstore;\n \n+import static java.nio.channels.Channels.newChannel;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobItem;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.BlobStorageException;\n+import com.azure.storage.blob.models.ListBlobsOptions;\n+import com.microsoft.azure.storage.CloudStorageAccount;\n+import com.microsoft.azure.storage.SharedAccessAccountPolicy;\n+import java.io.FileNotFoundException;\n import java.io.IOException;\n+import java.io.OutputStream;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.time.Duration;\n+import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Date;\n+import java.util.Iterator;\n import java.util.List;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n import org.apache.beam.sdk.io.FileSystem;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreClientBuilderFactory;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n import org.apache.beam.sdk.io.fs.CreateOptions;\n import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.util.InstanceBuilder;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Supplier;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Suppliers;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableSet;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n class AzureBlobStoreFileSystem extends FileSystem<AzfsResourceId> {\n \n+  private static final Logger LOG = LoggerFactory.getLogger(AzureBlobStoreFileSystem.class);\n+\n+  private static final ImmutableSet<String> NON_READ_SEEK_EFFICIENT_ENCODINGS =\n+      ImmutableSet.of(\"gzip\");\n+\n+  private Supplier<BlobServiceClient> client;\n+  private final BlobstoreOptions options;\n+\n+  AzureBlobStoreFileSystem(BlobstoreOptions options) {\n+    this.options = checkNotNull(options, \"options\");\n+\n+    BlobServiceClientBuilder builder =\n+        InstanceBuilder.ofType(BlobstoreClientBuilderFactory.class)\n+            .fromClass(options.getBlobstoreClientFactoryClass())\n+            .build()\n+            .createBuilder(options);\n+\n+    // The Supplier is to make sure we don't call .build() unless we are actually using Azure.\n+    client = Suppliers.memoize(builder::buildClient);\n+  }\n+\n+  @VisibleForTesting\n+  void setClient(BlobServiceClient client) {\n+    this.client = Suppliers.ofInstance(client);\n+  }\n+\n+  @VisibleForTesting\n+  BlobServiceClient getClient() {\n+    return client.get();\n+  }\n+\n   @Override\n   protected String getScheme() {\n-    return \"azfs\";\n+    return AzfsResourceId.SCHEME;\n   }\n \n   @Override\n-  protected List<MatchResult> match(List<String> specs) throws IOException {\n-    // TODO\n-    return null;\n+  protected List<MatchResult> match(List<String> specs) {\n+    List<AzfsResourceId> paths =\n+        specs.stream().map(AzfsResourceId::fromUri).collect(Collectors.toList());\n+    List<AzfsResourceId> globs = new ArrayList<>();\n+    List<AzfsResourceId> nonGlobs = new ArrayList<>();\n+    List<Boolean> isGlobBooleans = new ArrayList<>();\n+\n+    for (AzfsResourceId path : paths) {\n+      if (path.isWildcard()) {\n+        globs.add(path);\n+        isGlobBooleans.add(true);\n+      } else {\n+        nonGlobs.add(path);\n+        isGlobBooleans.add(false);\n+      }\n+    }\n+\n+    Iterator<MatchResult> globMatches = matchGlobPaths(globs).iterator();\n+    Iterator<MatchResult> nonGlobMatches = matchNonGlobPaths(nonGlobs).iterator();\n+\n+    ImmutableList.Builder<MatchResult> matchResults = ImmutableList.builder();\n+    for (Boolean isGlob : isGlobBooleans) {\n+      if (isGlob) {\n+        checkState(globMatches.hasNext(), \"Expect globMatches has next.\");\n+        matchResults.add(globMatches.next());\n+      } else {\n+        checkState(nonGlobMatches.hasNext(), \"Expect nonGlobMatches has next.\");\n+        matchResults.add(nonGlobMatches.next());\n+      }\n+    }\n+    checkState(!globMatches.hasNext(), \"Expect no more elements in globMatches.\");\n+    checkState(!nonGlobMatches.hasNext(), \"Expect no more elements in nonGlobMatches.\");\n+\n+    return matchResults.build();\n+  }\n+\n+  /**\n+   * Expands glob expressions to regular expressions.\n+   *\n+   * @param globExp the glob expression to expand\n+   * @return a string with the regular expression this glob expands to\n+   */\n+  @VisibleForTesting\n+  static String wildcardToRegexp(String globExp) {\n+    StringBuilder dst = new StringBuilder();\n+    char[] src = globExp.replace(\"**/*\", \"**\").toCharArray();\n+    int i = 0;\n+    while (i < src.length) {\n+      char c = src[i++];\n+      switch (c) {\n+        case '*':\n+          // One char lookahead for **\n+          if (i < src.length && src[i] == '*') {\n+            dst.append(\".*\");\n+            ++i;\n+          } else {\n+            dst.append(\"[^/]*\");\n+          }\n+          break;\n+        case '?':\n+          dst.append(\"[^/]\");\n+          break;\n+        case '.':\n+        case '+':\n+        case '{':\n+        case '}':\n+        case '(':\n+        case ')':\n+        case '|':\n+        case '^':\n+        case '$':\n+          // These need to be escaped in regular expressions\n+          dst.append('\\\\').append(c);\n+          break;\n+        case '\\\\':\n+          i = doubleSlashes(dst, src, i);\n+          break;\n+        default:\n+          dst.append(c);\n+          break;\n+      }\n+    }\n+    return dst.toString();\n+  }\n+\n+  private static int doubleSlashes(StringBuilder dst, char[] src, int i) {\n+    // Emit the next character without special interpretation\n+    dst.append(\"\\\\\\\\\");\n+    if ((i - 1) != src.length) {\n+      dst.append(src[i]);\n+      i++;\n+    } else {\n+      // A backslash at the very end is treated like an escaped backslash\n+      dst.append('\\\\');\n+    }\n+    return i;\n+  }\n+\n+  private List<MatchResult> matchGlobPaths(List<AzfsResourceId> globs) {\n+    return FluentIterable.from(globs).transform(this::expand).toList();\n+  }\n+\n+  /** Expands a pattern into {@link MatchResult}. */\n+  @VisibleForTesting\n+  MatchResult expand(AzfsResourceId azfsPattern) {\n+\n+    checkArgument(azfsPattern.isWildcard(), \"is Wildcard\");\n+    String blobPrefix = azfsPattern.getBlobNonWildcardPrefix();\n+    Pattern wildcardAsRegexp = Pattern.compile(wildcardToRegexp(azfsPattern.getBlob()));\n+\n+    LOG.debug(\n+        \"matching files in container {}, prefix {} against pattern {}\",\n+        azfsPattern.getContainer(),\n+        blobPrefix,\n+        wildcardAsRegexp.toString());\n+\n+    ListBlobsOptions listOptions = new ListBlobsOptions().setPrefix(blobPrefix);\n+    Duration timeout = Duration.ZERO.plusMinutes(1);\n+\n+    String account = azfsPattern.getAccount();\n+    String container = azfsPattern.getContainer();\n+    BlobContainerClient blobContainerClient = client.get().getBlobContainerClient(container);\n+    PagedIterable<BlobItem> blobs = blobContainerClient.listBlobs(listOptions, timeout);\n+    List<MatchResult.Metadata> results = new ArrayList<>();\n+\n+    blobs.forEach(\n+        blob -> {\n+          String name = blob.getName();\n+          if (wildcardAsRegexp.matcher(name).matches() && !name.endsWith(\"/\")) {\n+            LOG.debug(\"Matched object: {}\", name);\n+\n+            BlobProperties properties = blobContainerClient.getBlobClient(name).getProperties();\n+            AzfsResourceId rid =\n+                AzfsResourceId.fromComponents(account, container, name)\n+                    .withSize(properties.getBlobSize())\n+                    .withLastModified(Date.from(properties.getLastModified().toInstant()));\n+\n+            results.add(toMetadata(rid, properties.getContentEncoding()));\n+          }\n+        });\n+\n+    return MatchResult.create(MatchResult.Status.OK, results);\n+  }\n+\n+  private MatchResult.Metadata toMetadata(AzfsResourceId path, String contentEncoding) {\n+\n+    checkArgument(path.getSize().isPresent(), \"path has size\");\n+    boolean isReadSeekEfficient = !NON_READ_SEEK_EFFICIENT_ENCODINGS.contains(contentEncoding);\n+\n+    return MatchResult.Metadata.builder()\n+        .setIsReadSeekEfficient(isReadSeekEfficient)\n+        .setResourceId(path)\n+        .setSizeBytes(path.getSize().get())\n+        .setLastModifiedMillis(path.getLastModified().transform(Date::getTime).or(0L))\n+        .build();\n+  }\n+\n+  /**\n+   * Returns {@link MatchResult MatchResults} for the given {@link AzfsResourceId paths}.\n+   *\n+   * <p>The number of returned {@link MatchResult MatchResults} equals to the number of given {@link\n+   * AzfsResourceId paths}. Each {@link MatchResult} contains one {@link MatchResult.Metadata}.\n+   */\n+  @VisibleForTesting\n+  private Iterable<MatchResult> matchNonGlobPaths(List<AzfsResourceId> paths) {\n+    ImmutableList.Builder<MatchResult> toReturn = ImmutableList.builder();\n+    for (AzfsResourceId path : paths) {\n+      toReturn.add(toMatchResult(path));\n+    }\n+    return toReturn.build();\n+  }\n+\n+  private MatchResult toMatchResult(AzfsResourceId path) {\n+    BlobClient blobClient =\n+        client.get().getBlobContainerClient(path.getContainer()).getBlobClient(path.getBlob());\n+    BlobProperties blobProperties;\n+\n+    try {\n+      blobProperties = blobClient.getProperties();\n+    } catch (BlobStorageException e) {\n+      if (e.getStatusCode() == 404) {\n+        return MatchResult.create(MatchResult.Status.NOT_FOUND, new FileNotFoundException());\n+      }\n+      return MatchResult.create(MatchResult.Status.ERROR, new IOException(e));\n+    }\n+\n+    return MatchResult.create(\n+        MatchResult.Status.OK,\n+        ImmutableList.of(\n+            toMetadata(\n+                path.withSize(blobProperties.getBlobSize())\n+                    .withLastModified(Date.from(blobProperties.getLastModified().toInstant())),\n+                blobProperties.getContentEncoding())));\n   }\n \n   @Override\n   protected WritableByteChannel create(AzfsResourceId resourceId, CreateOptions createOptions)\n       throws IOException {\n-    // TODO\n-    return null;\n+    BlobContainerClient blobContainerClient =\n+        client.get().getBlobContainerClient(resourceId.getContainer());\n+    if (!blobContainerClient.exists()) {\n+      throw new UnsupportedOperationException(\"create does not create containers.\");\n+    }\n+\n+    BlobClient blobClient = blobContainerClient.getBlobClient(resourceId.getBlob());\n+    // The getBlobOutputStream method overwrites existing blobs,\n+    // so throw an error in this case to prevent data loss\n+    if (blobClient.exists()) {\n+      throw new IOException(\"This filename is already in use.\");\n+    }\n+\n+    OutputStream outputStream;\n+    try {\n+      outputStream = blobClient.getBlockBlobClient().getBlobOutputStream();\n+    } catch (BlobStorageException e) {\n+      throw (IOException) e.getCause();\n+    }\n+    return newChannel(outputStream);\n   }\n \n   @Override\n   protected ReadableByteChannel open(AzfsResourceId resourceId) throws IOException {\n-    // TODO\n-    return null;\n+    BlobClient blobClient =\n+        client\n+            .get()\n+            .getBlobContainerClient(resourceId.getContainer())\n+            .getBlobClient(resourceId.getBlob());\n+    if (!blobClient.exists()) {\n+      throw new FileNotFoundException(\"The requested file doesn't exist.\");\n+    }\n+    return new AzureReadableSeekableByteChannel(blobClient);\n   }\n \n   @Override\n   protected void copy(List<AzfsResourceId> srcPaths, List<AzfsResourceId> destPaths)\n       throws IOException {\n-    // TODO\n+    checkArgument(\n+        srcPaths.size() == destPaths.size(),\n+        \"sizes of source paths and destination paths do not match\");\n+\n+    Iterator<AzfsResourceId> sourcePathsIterator = srcPaths.iterator();\n+    Iterator<AzfsResourceId> destinationPathsIterator = destPaths.iterator();\n+    while (sourcePathsIterator.hasNext()) {\n+      final AzfsResourceId sourcePath = sourcePathsIterator.next();\n+      final AzfsResourceId destinationPath = destinationPathsIterator.next();\n+      copy(sourcePath, destinationPath);\n+    }\n   }\n \n   @VisibleForTesting\n   void copy(AzfsResourceId sourcePath, AzfsResourceId destinationPath) throws IOException {\n-    // TODO\n+    checkArgument(\n+        sourcePath.getBlob() != null && destinationPath.getBlob() != null,\n+        \"This method is intended to copy file-like resources, not directories.\");\n+\n+    // get source blob client\n+    BlobClient srcBlobClient =\n+        client\n+            .get()\n+            .getBlobContainerClient(sourcePath.getContainer())\n+            .getBlobClient(sourcePath.getBlob());\n+    if (!srcBlobClient.exists()) {\n+      throw new FileNotFoundException(\"The copy source does not exist.\");\n+    }\n+\n+    // get destination blob client\n+    BlobContainerClient destBlobContainerClient =\n+        client.get().getBlobContainerClient(destinationPath.getContainer());\n+    if (!destBlobContainerClient.exists()) {\n+      client.get().createBlobContainer(destinationPath.getContainer());\n+    }\n+    BlobClient destBlobClient = destBlobContainerClient.getBlobClient(destinationPath.getBlob());\n+\n+    destBlobClient.copyFromUrl(srcBlobClient.getBlobUrl() + generateSasToken());\n+  }\n+\n+  @VisibleForTesting\n+  String generateSasToken() throws IOException {\n+    SharedAccessAccountPolicy sharedAccessAccountPolicy = new SharedAccessAccountPolicy();\n+    long date = new Date().getTime();\n+    long expiryDate = new Date(date + 8640000).getTime();\n+\n+    sharedAccessAccountPolicy.setPermissionsFromString(\"racwdlup\");\n+    sharedAccessAccountPolicy.setSharedAccessStartTime(new Date(date));\n+    sharedAccessAccountPolicy.setSharedAccessExpiryTime(new Date(expiryDate));\n+    sharedAccessAccountPolicy.setResourceTypeFromString(\n+        \"co\"); // container, object, add s for service\n+    sharedAccessAccountPolicy.setServiceFromString(\"b\"); // blob, add \"fqt\" for file, queue, table\n+\n+    String storageConnectionString = options.getAzureConnectionString();\n+    try {\n+      CloudStorageAccount storageAccount = CloudStorageAccount.parse(storageConnectionString);\n+      return \"?\" + storageAccount.generateSharedAccessSignature(sharedAccessAccountPolicy);\n+    } catch (Exception e) {\n+      throw (IOException) e.getCause();\n+    }\n   }\n \n   @Override\n   protected void rename(List<AzfsResourceId> srcResourceIds, List<AzfsResourceId> destResourceIds)\n       throws IOException {\n-    // TODO\n+    copy(srcResourceIds, destResourceIds);\n+    delete(srcResourceIds);\n   }\n \n+  // This method with delete a virtual folder or a blob", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 403}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY2NzczNw==", "bodyText": "It seems like you have already separated the Azure options and Blob options.", "url": "https://github.com/apache/beam/pull/12581#discussion_r471667737", "createdAt": "2020-08-17T18:05:30Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/options/AzureOptions.java", "diffHunk": "@@ -0,0 +1,86 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.azure.options;\n+\n+import com.azure.core.credential.TokenCredential;\n+import com.azure.core.util.Configuration;\n+import com.azure.identity.DefaultAzureCredentialBuilder;\n+import org.apache.beam.sdk.options.Default;\n+import org.apache.beam.sdk.options.DefaultValueFactory;\n+import org.apache.beam.sdk.options.Description;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+\n+public interface AzureOptions extends PipelineOptions {\n+\n+  // TODO: Add any other azure options that users should be able to configure\n+  // TODO: Confirm that Azure options are in this file, Blobstore options in BlobstoreOptions", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY3MDgyOA==", "bodyText": "It assumes that the running env has AZURE_STORAGE_CONNECTION_STRING, which should be false for most of time.", "url": "https://github.com/apache/beam/pull/12581#discussion_r471670828", "createdAt": "2020-08-17T18:10:17Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/azure/src/test/java/org/apache/beam/sdk/io/azure/blobstore/AzfsTestUtils.java", "diffHunk": "@@ -0,0 +1,42 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.azure.blobstore;\n+\n+import com.azure.storage.blob.BlobServiceClient;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n+import org.apache.beam.sdk.options.PipelineOptionsFactory;\n+import org.mockito.Mockito;\n+\n+class AzfsTestUtils {\n+  static BlobstoreOptions azfsOptions() {\n+    BlobstoreOptions options = PipelineOptionsFactory.as(BlobstoreOptions.class);\n+    options.setAzureConnectionString(System.getenv(\"AZURE_STORAGE_CONNECTION_STRING\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY3MjUwNg==", "bodyText": "Is it used anywhere?", "url": "https://github.com/apache/beam/pull/12581#discussion_r471672506", "createdAt": "2020-08-17T18:13:40Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/azure/src/test/java/org/apache/beam/sdk/io/azure/blobstore/AzfsTestUtils.java", "diffHunk": "@@ -0,0 +1,42 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.azure.blobstore;\n+\n+import com.azure.storage.blob.BlobServiceClient;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n+import org.apache.beam.sdk.options.PipelineOptionsFactory;\n+import org.mockito.Mockito;\n+\n+class AzfsTestUtils {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 25}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "137b77741eb30678c027efd29562118de41760f6", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/137b77741eb30678c027efd29562118de41760f6", "committedDate": "2020-08-17T18:28:51Z", "message": "added options to azure filesystem"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "58f7f028d109a5110c9258c681e07f2ec8e62ddb", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/58f7f028d109a5110c9258c681e07f2ec8e62ddb", "committedDate": "2020-08-17T19:02:02Z", "message": "added experimental annotation"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY3NzcwODM5", "url": "https://github.com/apache/beam/pull/12581#pullrequestreview-467770839", "createdAt": "2020-08-14T18:06:13Z", "commit": {"oid": "a4471727d5bba7d22bc9525324e4deec104f0ab8"}, "state": "COMMENTED", "comments": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQxODowNjoxM1rOHA96oQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxOTo0NTo1M1rOHB4fZA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDc3NjQ4MQ==", "bodyText": "you can move this to src/test/resources", "url": "https://github.com/apache/beam/pull/12581#discussion_r470776481", "createdAt": "2020-08-14T18:06:13Z", "author": {"login": "pabloem"}, "path": "sdks/java/io/azure/testingFiles/in.txt", "diffHunk": "@@ -0,0 +1,23 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a4471727d5bba7d22bc9525324e4deec104f0ab8"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg5MjU0Mg==", "bodyText": "is it possible to have blob == null and also container == null so that it's an account?", "url": "https://github.com/apache/beam/pull/12581#discussion_r470892542", "createdAt": "2020-08-14T22:35:29Z", "author": {"login": "pabloem"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzfsResourceId.java", "diffHunk": "@@ -105,6 +129,17 @@ boolean isWildcard() {\n     return GLOB_PREFIX.matcher(blob).matches();\n   }\n \n+  String getBlobNonWildcardPrefix() {\n+    Matcher m = GLOB_PREFIX.matcher(getBlob());\n+    checkArgument(\n+        m.matches(), String.format(\"Glob expression: [%s] is not expandable.\", getBlob()));\n+    return m.group(\"PREFIX\");\n+  }\n+\n+  public boolean isContainer() {\n+    return blob == null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "58325cb61a8b8f226b0f8d88131ea7b2337d529d"}, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY1MTUyMw==", "bodyText": "I see that this code is duplicated in other filesystems. Would you be willing to move this to something like FileSystemUtils.java to live right next to FileSystem.java and remove the duplicated code from other places? (this can be done as part of a follow-up PR, but can you file a JIRA ticket to track it?)", "url": "https://github.com/apache/beam/pull/12581#discussion_r471651523", "createdAt": "2020-08-17T17:35:35Z", "author": {"login": "pabloem"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "diffHunk": "@@ -17,67 +17,438 @@\n  */\n package org.apache.beam.sdk.io.azure.blobstore;\n \n+import static java.nio.channels.Channels.newChannel;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobItem;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.BlobStorageException;\n+import com.azure.storage.blob.models.ListBlobsOptions;\n+import com.microsoft.azure.storage.CloudStorageAccount;\n+import com.microsoft.azure.storage.SharedAccessAccountPolicy;\n+import java.io.FileNotFoundException;\n import java.io.IOException;\n+import java.io.OutputStream;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.time.Duration;\n+import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Date;\n+import java.util.Iterator;\n import java.util.List;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n import org.apache.beam.sdk.io.FileSystem;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreClientBuilderFactory;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n import org.apache.beam.sdk.io.fs.CreateOptions;\n import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.util.InstanceBuilder;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Supplier;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Suppliers;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableSet;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n class AzureBlobStoreFileSystem extends FileSystem<AzfsResourceId> {\n \n+  private static final Logger LOG = LoggerFactory.getLogger(AzureBlobStoreFileSystem.class);\n+\n+  private static final ImmutableSet<String> NON_READ_SEEK_EFFICIENT_ENCODINGS =\n+      ImmutableSet.of(\"gzip\");\n+\n+  private Supplier<BlobServiceClient> client;\n+  private final BlobstoreOptions options;\n+\n+  AzureBlobStoreFileSystem(BlobstoreOptions options) {\n+    this.options = checkNotNull(options, \"options\");\n+\n+    BlobServiceClientBuilder builder =\n+        InstanceBuilder.ofType(BlobstoreClientBuilderFactory.class)\n+            .fromClass(options.getBlobstoreClientFactoryClass())\n+            .build()\n+            .createBuilder(options);\n+\n+    // The Supplier is to make sure we don't call .build() unless we are actually using Azure.\n+    client = Suppliers.memoize(builder::buildClient);\n+  }\n+\n+  @VisibleForTesting\n+  void setClient(BlobServiceClient client) {\n+    this.client = Suppliers.ofInstance(client);\n+  }\n+\n+  @VisibleForTesting\n+  BlobServiceClient getClient() {\n+    return client.get();\n+  }\n+\n   @Override\n   protected String getScheme() {\n-    return \"azfs\";\n+    return AzfsResourceId.SCHEME;\n   }\n \n   @Override\n-  protected List<MatchResult> match(List<String> specs) throws IOException {\n-    // TODO\n-    return null;\n+  protected List<MatchResult> match(List<String> specs) {\n+    List<AzfsResourceId> paths =\n+        specs.stream().map(AzfsResourceId::fromUri).collect(Collectors.toList());\n+    List<AzfsResourceId> globs = new ArrayList<>();\n+    List<AzfsResourceId> nonGlobs = new ArrayList<>();\n+    List<Boolean> isGlobBooleans = new ArrayList<>();\n+\n+    for (AzfsResourceId path : paths) {\n+      if (path.isWildcard()) {\n+        globs.add(path);\n+        isGlobBooleans.add(true);\n+      } else {\n+        nonGlobs.add(path);\n+        isGlobBooleans.add(false);\n+      }\n+    }\n+\n+    Iterator<MatchResult> globMatches = matchGlobPaths(globs).iterator();\n+    Iterator<MatchResult> nonGlobMatches = matchNonGlobPaths(nonGlobs).iterator();\n+\n+    ImmutableList.Builder<MatchResult> matchResults = ImmutableList.builder();\n+    for (Boolean isGlob : isGlobBooleans) {\n+      if (isGlob) {\n+        checkState(globMatches.hasNext(), \"Expect globMatches has next.\");\n+        matchResults.add(globMatches.next());\n+      } else {\n+        checkState(nonGlobMatches.hasNext(), \"Expect nonGlobMatches has next.\");\n+        matchResults.add(nonGlobMatches.next());\n+      }\n+    }\n+    checkState(!globMatches.hasNext(), \"Expect no more elements in globMatches.\");\n+    checkState(!nonGlobMatches.hasNext(), \"Expect no more elements in nonGlobMatches.\");\n+\n+    return matchResults.build();\n+  }\n+\n+  /**\n+   * Expands glob expressions to regular expressions.\n+   *\n+   * @param globExp the glob expression to expand\n+   * @return a string with the regular expression this glob expands to\n+   */\n+  @VisibleForTesting\n+  static String wildcardToRegexp(String globExp) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 134}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY1NDA2NQ==", "bodyText": "it's not that important, but name here contains only the blob name, right? Can you include the container and account in the log?", "url": "https://github.com/apache/beam/pull/12581#discussion_r471654065", "createdAt": "2020-08-17T17:40:29Z", "author": {"login": "pabloem"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "diffHunk": "@@ -17,67 +17,438 @@\n  */\n package org.apache.beam.sdk.io.azure.blobstore;\n \n+import static java.nio.channels.Channels.newChannel;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobItem;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.BlobStorageException;\n+import com.azure.storage.blob.models.ListBlobsOptions;\n+import com.microsoft.azure.storage.CloudStorageAccount;\n+import com.microsoft.azure.storage.SharedAccessAccountPolicy;\n+import java.io.FileNotFoundException;\n import java.io.IOException;\n+import java.io.OutputStream;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.time.Duration;\n+import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Date;\n+import java.util.Iterator;\n import java.util.List;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n import org.apache.beam.sdk.io.FileSystem;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreClientBuilderFactory;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n import org.apache.beam.sdk.io.fs.CreateOptions;\n import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.util.InstanceBuilder;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Supplier;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Suppliers;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableSet;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n class AzureBlobStoreFileSystem extends FileSystem<AzfsResourceId> {\n \n+  private static final Logger LOG = LoggerFactory.getLogger(AzureBlobStoreFileSystem.class);\n+\n+  private static final ImmutableSet<String> NON_READ_SEEK_EFFICIENT_ENCODINGS =\n+      ImmutableSet.of(\"gzip\");\n+\n+  private Supplier<BlobServiceClient> client;\n+  private final BlobstoreOptions options;\n+\n+  AzureBlobStoreFileSystem(BlobstoreOptions options) {\n+    this.options = checkNotNull(options, \"options\");\n+\n+    BlobServiceClientBuilder builder =\n+        InstanceBuilder.ofType(BlobstoreClientBuilderFactory.class)\n+            .fromClass(options.getBlobstoreClientFactoryClass())\n+            .build()\n+            .createBuilder(options);\n+\n+    // The Supplier is to make sure we don't call .build() unless we are actually using Azure.\n+    client = Suppliers.memoize(builder::buildClient);\n+  }\n+\n+  @VisibleForTesting\n+  void setClient(BlobServiceClient client) {\n+    this.client = Suppliers.ofInstance(client);\n+  }\n+\n+  @VisibleForTesting\n+  BlobServiceClient getClient() {\n+    return client.get();\n+  }\n+\n   @Override\n   protected String getScheme() {\n-    return \"azfs\";\n+    return AzfsResourceId.SCHEME;\n   }\n \n   @Override\n-  protected List<MatchResult> match(List<String> specs) throws IOException {\n-    // TODO\n-    return null;\n+  protected List<MatchResult> match(List<String> specs) {\n+    List<AzfsResourceId> paths =\n+        specs.stream().map(AzfsResourceId::fromUri).collect(Collectors.toList());\n+    List<AzfsResourceId> globs = new ArrayList<>();\n+    List<AzfsResourceId> nonGlobs = new ArrayList<>();\n+    List<Boolean> isGlobBooleans = new ArrayList<>();\n+\n+    for (AzfsResourceId path : paths) {\n+      if (path.isWildcard()) {\n+        globs.add(path);\n+        isGlobBooleans.add(true);\n+      } else {\n+        nonGlobs.add(path);\n+        isGlobBooleans.add(false);\n+      }\n+    }\n+\n+    Iterator<MatchResult> globMatches = matchGlobPaths(globs).iterator();\n+    Iterator<MatchResult> nonGlobMatches = matchNonGlobPaths(nonGlobs).iterator();\n+\n+    ImmutableList.Builder<MatchResult> matchResults = ImmutableList.builder();\n+    for (Boolean isGlob : isGlobBooleans) {\n+      if (isGlob) {\n+        checkState(globMatches.hasNext(), \"Expect globMatches has next.\");\n+        matchResults.add(globMatches.next());\n+      } else {\n+        checkState(nonGlobMatches.hasNext(), \"Expect nonGlobMatches has next.\");\n+        matchResults.add(nonGlobMatches.next());\n+      }\n+    }\n+    checkState(!globMatches.hasNext(), \"Expect no more elements in globMatches.\");\n+    checkState(!nonGlobMatches.hasNext(), \"Expect no more elements in nonGlobMatches.\");\n+\n+    return matchResults.build();\n+  }\n+\n+  /**\n+   * Expands glob expressions to regular expressions.\n+   *\n+   * @param globExp the glob expression to expand\n+   * @return a string with the regular expression this glob expands to\n+   */\n+  @VisibleForTesting\n+  static String wildcardToRegexp(String globExp) {\n+    StringBuilder dst = new StringBuilder();\n+    char[] src = globExp.replace(\"**/*\", \"**\").toCharArray();\n+    int i = 0;\n+    while (i < src.length) {\n+      char c = src[i++];\n+      switch (c) {\n+        case '*':\n+          // One char lookahead for **\n+          if (i < src.length && src[i] == '*') {\n+            dst.append(\".*\");\n+            ++i;\n+          } else {\n+            dst.append(\"[^/]*\");\n+          }\n+          break;\n+        case '?':\n+          dst.append(\"[^/]\");\n+          break;\n+        case '.':\n+        case '+':\n+        case '{':\n+        case '}':\n+        case '(':\n+        case ')':\n+        case '|':\n+        case '^':\n+        case '$':\n+          // These need to be escaped in regular expressions\n+          dst.append('\\\\').append(c);\n+          break;\n+        case '\\\\':\n+          i = doubleSlashes(dst, src, i);\n+          break;\n+        default:\n+          dst.append(c);\n+          break;\n+      }\n+    }\n+    return dst.toString();\n+  }\n+\n+  private static int doubleSlashes(StringBuilder dst, char[] src, int i) {\n+    // Emit the next character without special interpretation\n+    dst.append(\"\\\\\\\\\");\n+    if ((i - 1) != src.length) {\n+      dst.append(src[i]);\n+      i++;\n+    } else {\n+      // A backslash at the very end is treated like an escaped backslash\n+      dst.append('\\\\');\n+    }\n+    return i;\n+  }\n+\n+  private List<MatchResult> matchGlobPaths(List<AzfsResourceId> globs) {\n+    return FluentIterable.from(globs).transform(this::expand).toList();\n+  }\n+\n+  /** Expands a pattern into {@link MatchResult}. */\n+  @VisibleForTesting\n+  MatchResult expand(AzfsResourceId azfsPattern) {\n+\n+    checkArgument(azfsPattern.isWildcard(), \"is Wildcard\");\n+    String blobPrefix = azfsPattern.getBlobNonWildcardPrefix();\n+    Pattern wildcardAsRegexp = Pattern.compile(wildcardToRegexp(azfsPattern.getBlob()));\n+\n+    LOG.debug(\n+        \"matching files in container {}, prefix {} against pattern {}\",\n+        azfsPattern.getContainer(),\n+        blobPrefix,\n+        wildcardAsRegexp.toString());\n+\n+    ListBlobsOptions listOptions = new ListBlobsOptions().setPrefix(blobPrefix);\n+    Duration timeout = Duration.ZERO.plusMinutes(1);\n+\n+    String account = azfsPattern.getAccount();\n+    String container = azfsPattern.getContainer();\n+    BlobContainerClient blobContainerClient = client.get().getBlobContainerClient(container);\n+    PagedIterable<BlobItem> blobs = blobContainerClient.listBlobs(listOptions, timeout);\n+    List<MatchResult.Metadata> results = new ArrayList<>();\n+\n+    blobs.forEach(\n+        blob -> {\n+          String name = blob.getName();\n+          if (wildcardAsRegexp.matcher(name).matches() && !name.endsWith(\"/\")) {\n+            LOG.debug(\"Matched object: {}\", name);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 220}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY1NjkwNg==", "bodyText": "What happens if there are no matches whatsoever? I guess results would be empty and that's it?", "url": "https://github.com/apache/beam/pull/12581#discussion_r471656906", "createdAt": "2020-08-17T17:46:10Z", "author": {"login": "pabloem"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "diffHunk": "@@ -17,67 +17,438 @@\n  */\n package org.apache.beam.sdk.io.azure.blobstore;\n \n+import static java.nio.channels.Channels.newChannel;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobItem;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.BlobStorageException;\n+import com.azure.storage.blob.models.ListBlobsOptions;\n+import com.microsoft.azure.storage.CloudStorageAccount;\n+import com.microsoft.azure.storage.SharedAccessAccountPolicy;\n+import java.io.FileNotFoundException;\n import java.io.IOException;\n+import java.io.OutputStream;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.time.Duration;\n+import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Date;\n+import java.util.Iterator;\n import java.util.List;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n import org.apache.beam.sdk.io.FileSystem;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreClientBuilderFactory;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n import org.apache.beam.sdk.io.fs.CreateOptions;\n import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.util.InstanceBuilder;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Supplier;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Suppliers;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableSet;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n class AzureBlobStoreFileSystem extends FileSystem<AzfsResourceId> {\n \n+  private static final Logger LOG = LoggerFactory.getLogger(AzureBlobStoreFileSystem.class);\n+\n+  private static final ImmutableSet<String> NON_READ_SEEK_EFFICIENT_ENCODINGS =\n+      ImmutableSet.of(\"gzip\");\n+\n+  private Supplier<BlobServiceClient> client;\n+  private final BlobstoreOptions options;\n+\n+  AzureBlobStoreFileSystem(BlobstoreOptions options) {\n+    this.options = checkNotNull(options, \"options\");\n+\n+    BlobServiceClientBuilder builder =\n+        InstanceBuilder.ofType(BlobstoreClientBuilderFactory.class)\n+            .fromClass(options.getBlobstoreClientFactoryClass())\n+            .build()\n+            .createBuilder(options);\n+\n+    // The Supplier is to make sure we don't call .build() unless we are actually using Azure.\n+    client = Suppliers.memoize(builder::buildClient);\n+  }\n+\n+  @VisibleForTesting\n+  void setClient(BlobServiceClient client) {\n+    this.client = Suppliers.ofInstance(client);\n+  }\n+\n+  @VisibleForTesting\n+  BlobServiceClient getClient() {\n+    return client.get();\n+  }\n+\n   @Override\n   protected String getScheme() {\n-    return \"azfs\";\n+    return AzfsResourceId.SCHEME;\n   }\n \n   @Override\n-  protected List<MatchResult> match(List<String> specs) throws IOException {\n-    // TODO\n-    return null;\n+  protected List<MatchResult> match(List<String> specs) {\n+    List<AzfsResourceId> paths =\n+        specs.stream().map(AzfsResourceId::fromUri).collect(Collectors.toList());\n+    List<AzfsResourceId> globs = new ArrayList<>();\n+    List<AzfsResourceId> nonGlobs = new ArrayList<>();\n+    List<Boolean> isGlobBooleans = new ArrayList<>();\n+\n+    for (AzfsResourceId path : paths) {\n+      if (path.isWildcard()) {\n+        globs.add(path);\n+        isGlobBooleans.add(true);\n+      } else {\n+        nonGlobs.add(path);\n+        isGlobBooleans.add(false);\n+      }\n+    }\n+\n+    Iterator<MatchResult> globMatches = matchGlobPaths(globs).iterator();\n+    Iterator<MatchResult> nonGlobMatches = matchNonGlobPaths(nonGlobs).iterator();\n+\n+    ImmutableList.Builder<MatchResult> matchResults = ImmutableList.builder();\n+    for (Boolean isGlob : isGlobBooleans) {\n+      if (isGlob) {\n+        checkState(globMatches.hasNext(), \"Expect globMatches has next.\");\n+        matchResults.add(globMatches.next());\n+      } else {\n+        checkState(nonGlobMatches.hasNext(), \"Expect nonGlobMatches has next.\");\n+        matchResults.add(nonGlobMatches.next());\n+      }\n+    }\n+    checkState(!globMatches.hasNext(), \"Expect no more elements in globMatches.\");\n+    checkState(!nonGlobMatches.hasNext(), \"Expect no more elements in nonGlobMatches.\");\n+\n+    return matchResults.build();\n+  }\n+\n+  /**\n+   * Expands glob expressions to regular expressions.\n+   *\n+   * @param globExp the glob expression to expand\n+   * @return a string with the regular expression this glob expands to\n+   */\n+  @VisibleForTesting\n+  static String wildcardToRegexp(String globExp) {\n+    StringBuilder dst = new StringBuilder();\n+    char[] src = globExp.replace(\"**/*\", \"**\").toCharArray();\n+    int i = 0;\n+    while (i < src.length) {\n+      char c = src[i++];\n+      switch (c) {\n+        case '*':\n+          // One char lookahead for **\n+          if (i < src.length && src[i] == '*') {\n+            dst.append(\".*\");\n+            ++i;\n+          } else {\n+            dst.append(\"[^/]*\");\n+          }\n+          break;\n+        case '?':\n+          dst.append(\"[^/]\");\n+          break;\n+        case '.':\n+        case '+':\n+        case '{':\n+        case '}':\n+        case '(':\n+        case ')':\n+        case '|':\n+        case '^':\n+        case '$':\n+          // These need to be escaped in regular expressions\n+          dst.append('\\\\').append(c);\n+          break;\n+        case '\\\\':\n+          i = doubleSlashes(dst, src, i);\n+          break;\n+        default:\n+          dst.append(c);\n+          break;\n+      }\n+    }\n+    return dst.toString();\n+  }\n+\n+  private static int doubleSlashes(StringBuilder dst, char[] src, int i) {\n+    // Emit the next character without special interpretation\n+    dst.append(\"\\\\\\\\\");\n+    if ((i - 1) != src.length) {\n+      dst.append(src[i]);\n+      i++;\n+    } else {\n+      // A backslash at the very end is treated like an escaped backslash\n+      dst.append('\\\\');\n+    }\n+    return i;\n+  }\n+\n+  private List<MatchResult> matchGlobPaths(List<AzfsResourceId> globs) {\n+    return FluentIterable.from(globs).transform(this::expand).toList();\n+  }\n+\n+  /** Expands a pattern into {@link MatchResult}. */\n+  @VisibleForTesting\n+  MatchResult expand(AzfsResourceId azfsPattern) {\n+\n+    checkArgument(azfsPattern.isWildcard(), \"is Wildcard\");\n+    String blobPrefix = azfsPattern.getBlobNonWildcardPrefix();\n+    Pattern wildcardAsRegexp = Pattern.compile(wildcardToRegexp(azfsPattern.getBlob()));\n+\n+    LOG.debug(\n+        \"matching files in container {}, prefix {} against pattern {}\",\n+        azfsPattern.getContainer(),\n+        blobPrefix,\n+        wildcardAsRegexp.toString());\n+\n+    ListBlobsOptions listOptions = new ListBlobsOptions().setPrefix(blobPrefix);\n+    Duration timeout = Duration.ZERO.plusMinutes(1);\n+\n+    String account = azfsPattern.getAccount();\n+    String container = azfsPattern.getContainer();\n+    BlobContainerClient blobContainerClient = client.get().getBlobContainerClient(container);\n+    PagedIterable<BlobItem> blobs = blobContainerClient.listBlobs(listOptions, timeout);\n+    List<MatchResult.Metadata> results = new ArrayList<>();\n+\n+    blobs.forEach(\n+        blob -> {\n+          String name = blob.getName();\n+          if (wildcardAsRegexp.matcher(name).matches() && !name.endsWith(\"/\")) {\n+            LOG.debug(\"Matched object: {}\", name);\n+\n+            BlobProperties properties = blobContainerClient.getBlobClient(name).getProperties();\n+            AzfsResourceId rid =\n+                AzfsResourceId.fromComponents(account, container, name)\n+                    .withSize(properties.getBlobSize())\n+                    .withLastModified(Date.from(properties.getLastModified().toInstant()));\n+\n+            results.add(toMetadata(rid, properties.getContentEncoding()));\n+          }\n+        });\n+\n+    return MatchResult.create(MatchResult.Status.OK, results);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 232}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY1OTQwNw==", "bodyText": "For line 133 and 134 Can you add something like \"Internal error encountered in AzureBlobStoreFileSystem: Expect no more elements in ...\" ?", "url": "https://github.com/apache/beam/pull/12581#discussion_r471659407", "createdAt": "2020-08-17T17:50:19Z", "author": {"login": "pabloem"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "diffHunk": "@@ -17,67 +17,438 @@\n  */\n package org.apache.beam.sdk.io.azure.blobstore;\n \n+import static java.nio.channels.Channels.newChannel;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobItem;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.BlobStorageException;\n+import com.azure.storage.blob.models.ListBlobsOptions;\n+import com.microsoft.azure.storage.CloudStorageAccount;\n+import com.microsoft.azure.storage.SharedAccessAccountPolicy;\n+import java.io.FileNotFoundException;\n import java.io.IOException;\n+import java.io.OutputStream;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.time.Duration;\n+import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Date;\n+import java.util.Iterator;\n import java.util.List;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n import org.apache.beam.sdk.io.FileSystem;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreClientBuilderFactory;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n import org.apache.beam.sdk.io.fs.CreateOptions;\n import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.util.InstanceBuilder;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Supplier;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Suppliers;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableSet;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n class AzureBlobStoreFileSystem extends FileSystem<AzfsResourceId> {\n \n+  private static final Logger LOG = LoggerFactory.getLogger(AzureBlobStoreFileSystem.class);\n+\n+  private static final ImmutableSet<String> NON_READ_SEEK_EFFICIENT_ENCODINGS =\n+      ImmutableSet.of(\"gzip\");\n+\n+  private Supplier<BlobServiceClient> client;\n+  private final BlobstoreOptions options;\n+\n+  AzureBlobStoreFileSystem(BlobstoreOptions options) {\n+    this.options = checkNotNull(options, \"options\");\n+\n+    BlobServiceClientBuilder builder =\n+        InstanceBuilder.ofType(BlobstoreClientBuilderFactory.class)\n+            .fromClass(options.getBlobstoreClientFactoryClass())\n+            .build()\n+            .createBuilder(options);\n+\n+    // The Supplier is to make sure we don't call .build() unless we are actually using Azure.\n+    client = Suppliers.memoize(builder::buildClient);\n+  }\n+\n+  @VisibleForTesting\n+  void setClient(BlobServiceClient client) {\n+    this.client = Suppliers.ofInstance(client);\n+  }\n+\n+  @VisibleForTesting\n+  BlobServiceClient getClient() {\n+    return client.get();\n+  }\n+\n   @Override\n   protected String getScheme() {\n-    return \"azfs\";\n+    return AzfsResourceId.SCHEME;\n   }\n \n   @Override\n-  protected List<MatchResult> match(List<String> specs) throws IOException {\n-    // TODO\n-    return null;\n+  protected List<MatchResult> match(List<String> specs) {\n+    List<AzfsResourceId> paths =\n+        specs.stream().map(AzfsResourceId::fromUri).collect(Collectors.toList());\n+    List<AzfsResourceId> globs = new ArrayList<>();\n+    List<AzfsResourceId> nonGlobs = new ArrayList<>();\n+    List<Boolean> isGlobBooleans = new ArrayList<>();\n+\n+    for (AzfsResourceId path : paths) {\n+      if (path.isWildcard()) {\n+        globs.add(path);\n+        isGlobBooleans.add(true);\n+      } else {\n+        nonGlobs.add(path);\n+        isGlobBooleans.add(false);\n+      }\n+    }\n+\n+    Iterator<MatchResult> globMatches = matchGlobPaths(globs).iterator();\n+    Iterator<MatchResult> nonGlobMatches = matchNonGlobPaths(nonGlobs).iterator();\n+\n+    ImmutableList.Builder<MatchResult> matchResults = ImmutableList.builder();\n+    for (Boolean isGlob : isGlobBooleans) {\n+      if (isGlob) {\n+        checkState(globMatches.hasNext(), \"Expect globMatches has next.\");\n+        matchResults.add(globMatches.next());\n+      } else {\n+        checkState(nonGlobMatches.hasNext(), \"Expect nonGlobMatches has next.\");\n+        matchResults.add(nonGlobMatches.next());\n+      }\n+    }\n+    checkState(!globMatches.hasNext(), \"Expect no more elements in globMatches.\");\n+    checkState(!nonGlobMatches.hasNext(), \"Expect no more elements in nonGlobMatches.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 122}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY2MTAwMQ==", "bodyText": "Should this be i-1? or should it actually be i+1? I understand this code comes from elsewhere (thus it's a good idea to standardize and make it a utility) - can you add a unit test with a file pattern containing a backslash at the end to see what happens?", "url": "https://github.com/apache/beam/pull/12581#discussion_r471661001", "createdAt": "2020-08-17T17:53:03Z", "author": {"login": "pabloem"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "diffHunk": "@@ -17,67 +17,438 @@\n  */\n package org.apache.beam.sdk.io.azure.blobstore;\n \n+import static java.nio.channels.Channels.newChannel;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobItem;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.BlobStorageException;\n+import com.azure.storage.blob.models.ListBlobsOptions;\n+import com.microsoft.azure.storage.CloudStorageAccount;\n+import com.microsoft.azure.storage.SharedAccessAccountPolicy;\n+import java.io.FileNotFoundException;\n import java.io.IOException;\n+import java.io.OutputStream;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.time.Duration;\n+import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Date;\n+import java.util.Iterator;\n import java.util.List;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n import org.apache.beam.sdk.io.FileSystem;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreClientBuilderFactory;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n import org.apache.beam.sdk.io.fs.CreateOptions;\n import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.util.InstanceBuilder;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Supplier;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Suppliers;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableSet;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n class AzureBlobStoreFileSystem extends FileSystem<AzfsResourceId> {\n \n+  private static final Logger LOG = LoggerFactory.getLogger(AzureBlobStoreFileSystem.class);\n+\n+  private static final ImmutableSet<String> NON_READ_SEEK_EFFICIENT_ENCODINGS =\n+      ImmutableSet.of(\"gzip\");\n+\n+  private Supplier<BlobServiceClient> client;\n+  private final BlobstoreOptions options;\n+\n+  AzureBlobStoreFileSystem(BlobstoreOptions options) {\n+    this.options = checkNotNull(options, \"options\");\n+\n+    BlobServiceClientBuilder builder =\n+        InstanceBuilder.ofType(BlobstoreClientBuilderFactory.class)\n+            .fromClass(options.getBlobstoreClientFactoryClass())\n+            .build()\n+            .createBuilder(options);\n+\n+    // The Supplier is to make sure we don't call .build() unless we are actually using Azure.\n+    client = Suppliers.memoize(builder::buildClient);\n+  }\n+\n+  @VisibleForTesting\n+  void setClient(BlobServiceClient client) {\n+    this.client = Suppliers.ofInstance(client);\n+  }\n+\n+  @VisibleForTesting\n+  BlobServiceClient getClient() {\n+    return client.get();\n+  }\n+\n   @Override\n   protected String getScheme() {\n-    return \"azfs\";\n+    return AzfsResourceId.SCHEME;\n   }\n \n   @Override\n-  protected List<MatchResult> match(List<String> specs) throws IOException {\n-    // TODO\n-    return null;\n+  protected List<MatchResult> match(List<String> specs) {\n+    List<AzfsResourceId> paths =\n+        specs.stream().map(AzfsResourceId::fromUri).collect(Collectors.toList());\n+    List<AzfsResourceId> globs = new ArrayList<>();\n+    List<AzfsResourceId> nonGlobs = new ArrayList<>();\n+    List<Boolean> isGlobBooleans = new ArrayList<>();\n+\n+    for (AzfsResourceId path : paths) {\n+      if (path.isWildcard()) {\n+        globs.add(path);\n+        isGlobBooleans.add(true);\n+      } else {\n+        nonGlobs.add(path);\n+        isGlobBooleans.add(false);\n+      }\n+    }\n+\n+    Iterator<MatchResult> globMatches = matchGlobPaths(globs).iterator();\n+    Iterator<MatchResult> nonGlobMatches = matchNonGlobPaths(nonGlobs).iterator();\n+\n+    ImmutableList.Builder<MatchResult> matchResults = ImmutableList.builder();\n+    for (Boolean isGlob : isGlobBooleans) {\n+      if (isGlob) {\n+        checkState(globMatches.hasNext(), \"Expect globMatches has next.\");\n+        matchResults.add(globMatches.next());\n+      } else {\n+        checkState(nonGlobMatches.hasNext(), \"Expect nonGlobMatches has next.\");\n+        matchResults.add(nonGlobMatches.next());\n+      }\n+    }\n+    checkState(!globMatches.hasNext(), \"Expect no more elements in globMatches.\");\n+    checkState(!nonGlobMatches.hasNext(), \"Expect no more elements in nonGlobMatches.\");\n+\n+    return matchResults.build();\n+  }\n+\n+  /**\n+   * Expands glob expressions to regular expressions.\n+   *\n+   * @param globExp the glob expression to expand\n+   * @return a string with the regular expression this glob expands to\n+   */\n+  @VisibleForTesting\n+  static String wildcardToRegexp(String globExp) {\n+    StringBuilder dst = new StringBuilder();\n+    char[] src = globExp.replace(\"**/*\", \"**\").toCharArray();\n+    int i = 0;\n+    while (i < src.length) {\n+      char c = src[i++];\n+      switch (c) {\n+        case '*':\n+          // One char lookahead for **\n+          if (i < src.length && src[i] == '*') {\n+            dst.append(\".*\");\n+            ++i;\n+          } else {\n+            dst.append(\"[^/]*\");\n+          }\n+          break;\n+        case '?':\n+          dst.append(\"[^/]\");\n+          break;\n+        case '.':\n+        case '+':\n+        case '{':\n+        case '}':\n+        case '(':\n+        case ')':\n+        case '|':\n+        case '^':\n+        case '$':\n+          // These need to be escaped in regular expressions\n+          dst.append('\\\\').append(c);\n+          break;\n+        case '\\\\':\n+          i = doubleSlashes(dst, src, i);\n+          break;\n+        default:\n+          dst.append(c);\n+          break;\n+      }\n+    }\n+    return dst.toString();\n+  }\n+\n+  private static int doubleSlashes(StringBuilder dst, char[] src, int i) {\n+    // Emit the next character without special interpretation\n+    dst.append(\"\\\\\\\\\");\n+    if ((i - 1) != src.length) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 179}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY2MzY4OQ==", "bodyText": "Can you LOG.info the fact that a container is being created?", "url": "https://github.com/apache/beam/pull/12581#discussion_r471663689", "createdAt": "2020-08-17T17:57:51Z", "author": {"login": "pabloem"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "diffHunk": "@@ -17,67 +17,438 @@\n  */\n package org.apache.beam.sdk.io.azure.blobstore;\n \n+import static java.nio.channels.Channels.newChannel;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobItem;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.BlobStorageException;\n+import com.azure.storage.blob.models.ListBlobsOptions;\n+import com.microsoft.azure.storage.CloudStorageAccount;\n+import com.microsoft.azure.storage.SharedAccessAccountPolicy;\n+import java.io.FileNotFoundException;\n import java.io.IOException;\n+import java.io.OutputStream;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.time.Duration;\n+import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Date;\n+import java.util.Iterator;\n import java.util.List;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n import org.apache.beam.sdk.io.FileSystem;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreClientBuilderFactory;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n import org.apache.beam.sdk.io.fs.CreateOptions;\n import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.util.InstanceBuilder;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Supplier;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Suppliers;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableSet;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n class AzureBlobStoreFileSystem extends FileSystem<AzfsResourceId> {\n \n+  private static final Logger LOG = LoggerFactory.getLogger(AzureBlobStoreFileSystem.class);\n+\n+  private static final ImmutableSet<String> NON_READ_SEEK_EFFICIENT_ENCODINGS =\n+      ImmutableSet.of(\"gzip\");\n+\n+  private Supplier<BlobServiceClient> client;\n+  private final BlobstoreOptions options;\n+\n+  AzureBlobStoreFileSystem(BlobstoreOptions options) {\n+    this.options = checkNotNull(options, \"options\");\n+\n+    BlobServiceClientBuilder builder =\n+        InstanceBuilder.ofType(BlobstoreClientBuilderFactory.class)\n+            .fromClass(options.getBlobstoreClientFactoryClass())\n+            .build()\n+            .createBuilder(options);\n+\n+    // The Supplier is to make sure we don't call .build() unless we are actually using Azure.\n+    client = Suppliers.memoize(builder::buildClient);\n+  }\n+\n+  @VisibleForTesting\n+  void setClient(BlobServiceClient client) {\n+    this.client = Suppliers.ofInstance(client);\n+  }\n+\n+  @VisibleForTesting\n+  BlobServiceClient getClient() {\n+    return client.get();\n+  }\n+\n   @Override\n   protected String getScheme() {\n-    return \"azfs\";\n+    return AzfsResourceId.SCHEME;\n   }\n \n   @Override\n-  protected List<MatchResult> match(List<String> specs) throws IOException {\n-    // TODO\n-    return null;\n+  protected List<MatchResult> match(List<String> specs) {\n+    List<AzfsResourceId> paths =\n+        specs.stream().map(AzfsResourceId::fromUri).collect(Collectors.toList());\n+    List<AzfsResourceId> globs = new ArrayList<>();\n+    List<AzfsResourceId> nonGlobs = new ArrayList<>();\n+    List<Boolean> isGlobBooleans = new ArrayList<>();\n+\n+    for (AzfsResourceId path : paths) {\n+      if (path.isWildcard()) {\n+        globs.add(path);\n+        isGlobBooleans.add(true);\n+      } else {\n+        nonGlobs.add(path);\n+        isGlobBooleans.add(false);\n+      }\n+    }\n+\n+    Iterator<MatchResult> globMatches = matchGlobPaths(globs).iterator();\n+    Iterator<MatchResult> nonGlobMatches = matchNonGlobPaths(nonGlobs).iterator();\n+\n+    ImmutableList.Builder<MatchResult> matchResults = ImmutableList.builder();\n+    for (Boolean isGlob : isGlobBooleans) {\n+      if (isGlob) {\n+        checkState(globMatches.hasNext(), \"Expect globMatches has next.\");\n+        matchResults.add(globMatches.next());\n+      } else {\n+        checkState(nonGlobMatches.hasNext(), \"Expect nonGlobMatches has next.\");\n+        matchResults.add(nonGlobMatches.next());\n+      }\n+    }\n+    checkState(!globMatches.hasNext(), \"Expect no more elements in globMatches.\");\n+    checkState(!nonGlobMatches.hasNext(), \"Expect no more elements in nonGlobMatches.\");\n+\n+    return matchResults.build();\n+  }\n+\n+  /**\n+   * Expands glob expressions to regular expressions.\n+   *\n+   * @param globExp the glob expression to expand\n+   * @return a string with the regular expression this glob expands to\n+   */\n+  @VisibleForTesting\n+  static String wildcardToRegexp(String globExp) {\n+    StringBuilder dst = new StringBuilder();\n+    char[] src = globExp.replace(\"**/*\", \"**\").toCharArray();\n+    int i = 0;\n+    while (i < src.length) {\n+      char c = src[i++];\n+      switch (c) {\n+        case '*':\n+          // One char lookahead for **\n+          if (i < src.length && src[i] == '*') {\n+            dst.append(\".*\");\n+            ++i;\n+          } else {\n+            dst.append(\"[^/]*\");\n+          }\n+          break;\n+        case '?':\n+          dst.append(\"[^/]\");\n+          break;\n+        case '.':\n+        case '+':\n+        case '{':\n+        case '}':\n+        case '(':\n+        case ')':\n+        case '|':\n+        case '^':\n+        case '$':\n+          // These need to be escaped in regular expressions\n+          dst.append('\\\\').append(c);\n+          break;\n+        case '\\\\':\n+          i = doubleSlashes(dst, src, i);\n+          break;\n+        default:\n+          dst.append(c);\n+          break;\n+      }\n+    }\n+    return dst.toString();\n+  }\n+\n+  private static int doubleSlashes(StringBuilder dst, char[] src, int i) {\n+    // Emit the next character without special interpretation\n+    dst.append(\"\\\\\\\\\");\n+    if ((i - 1) != src.length) {\n+      dst.append(src[i]);\n+      i++;\n+    } else {\n+      // A backslash at the very end is treated like an escaped backslash\n+      dst.append('\\\\');\n+    }\n+    return i;\n+  }\n+\n+  private List<MatchResult> matchGlobPaths(List<AzfsResourceId> globs) {\n+    return FluentIterable.from(globs).transform(this::expand).toList();\n+  }\n+\n+  /** Expands a pattern into {@link MatchResult}. */\n+  @VisibleForTesting\n+  MatchResult expand(AzfsResourceId azfsPattern) {\n+\n+    checkArgument(azfsPattern.isWildcard(), \"is Wildcard\");\n+    String blobPrefix = azfsPattern.getBlobNonWildcardPrefix();\n+    Pattern wildcardAsRegexp = Pattern.compile(wildcardToRegexp(azfsPattern.getBlob()));\n+\n+    LOG.debug(\n+        \"matching files in container {}, prefix {} against pattern {}\",\n+        azfsPattern.getContainer(),\n+        blobPrefix,\n+        wildcardAsRegexp.toString());\n+\n+    ListBlobsOptions listOptions = new ListBlobsOptions().setPrefix(blobPrefix);\n+    Duration timeout = Duration.ZERO.plusMinutes(1);\n+\n+    String account = azfsPattern.getAccount();\n+    String container = azfsPattern.getContainer();\n+    BlobContainerClient blobContainerClient = client.get().getBlobContainerClient(container);\n+    PagedIterable<BlobItem> blobs = blobContainerClient.listBlobs(listOptions, timeout);\n+    List<MatchResult.Metadata> results = new ArrayList<>();\n+\n+    blobs.forEach(\n+        blob -> {\n+          String name = blob.getName();\n+          if (wildcardAsRegexp.matcher(name).matches() && !name.endsWith(\"/\")) {\n+            LOG.debug(\"Matched object: {}\", name);\n+\n+            BlobProperties properties = blobContainerClient.getBlobClient(name).getProperties();\n+            AzfsResourceId rid =\n+                AzfsResourceId.fromComponents(account, container, name)\n+                    .withSize(properties.getBlobSize())\n+                    .withLastModified(Date.from(properties.getLastModified().toInstant()));\n+\n+            results.add(toMetadata(rid, properties.getContentEncoding()));\n+          }\n+        });\n+\n+    return MatchResult.create(MatchResult.Status.OK, results);\n+  }\n+\n+  private MatchResult.Metadata toMetadata(AzfsResourceId path, String contentEncoding) {\n+\n+    checkArgument(path.getSize().isPresent(), \"path has size\");\n+    boolean isReadSeekEfficient = !NON_READ_SEEK_EFFICIENT_ENCODINGS.contains(contentEncoding);\n+\n+    return MatchResult.Metadata.builder()\n+        .setIsReadSeekEfficient(isReadSeekEfficient)\n+        .setResourceId(path)\n+        .setSizeBytes(path.getSize().get())\n+        .setLastModifiedMillis(path.getLastModified().transform(Date::getTime).or(0L))\n+        .build();\n+  }\n+\n+  /**\n+   * Returns {@link MatchResult MatchResults} for the given {@link AzfsResourceId paths}.\n+   *\n+   * <p>The number of returned {@link MatchResult MatchResults} equals to the number of given {@link\n+   * AzfsResourceId paths}. Each {@link MatchResult} contains one {@link MatchResult.Metadata}.\n+   */\n+  @VisibleForTesting\n+  private Iterable<MatchResult> matchNonGlobPaths(List<AzfsResourceId> paths) {\n+    ImmutableList.Builder<MatchResult> toReturn = ImmutableList.builder();\n+    for (AzfsResourceId path : paths) {\n+      toReturn.add(toMatchResult(path));\n+    }\n+    return toReturn.build();\n+  }\n+\n+  private MatchResult toMatchResult(AzfsResourceId path) {\n+    BlobClient blobClient =\n+        client.get().getBlobContainerClient(path.getContainer()).getBlobClient(path.getBlob());\n+    BlobProperties blobProperties;\n+\n+    try {\n+      blobProperties = blobClient.getProperties();\n+    } catch (BlobStorageException e) {\n+      if (e.getStatusCode() == 404) {\n+        return MatchResult.create(MatchResult.Status.NOT_FOUND, new FileNotFoundException());\n+      }\n+      return MatchResult.create(MatchResult.Status.ERROR, new IOException(e));\n+    }\n+\n+    return MatchResult.create(\n+        MatchResult.Status.OK,\n+        ImmutableList.of(\n+            toMetadata(\n+                path.withSize(blobProperties.getBlobSize())\n+                    .withLastModified(Date.from(blobProperties.getLastModified().toInstant())),\n+                blobProperties.getContentEncoding())));\n   }\n \n   @Override\n   protected WritableByteChannel create(AzfsResourceId resourceId, CreateOptions createOptions)\n       throws IOException {\n-    // TODO\n-    return null;\n+    BlobContainerClient blobContainerClient =\n+        client.get().getBlobContainerClient(resourceId.getContainer());\n+    if (!blobContainerClient.exists()) {\n+      throw new UnsupportedOperationException(\"create does not create containers.\");\n+    }\n+\n+    BlobClient blobClient = blobContainerClient.getBlobClient(resourceId.getBlob());\n+    // The getBlobOutputStream method overwrites existing blobs,\n+    // so throw an error in this case to prevent data loss\n+    if (blobClient.exists()) {\n+      throw new IOException(\"This filename is already in use.\");\n+    }\n+\n+    OutputStream outputStream;\n+    try {\n+      outputStream = blobClient.getBlockBlobClient().getBlobOutputStream();\n+    } catch (BlobStorageException e) {\n+      throw (IOException) e.getCause();\n+    }\n+    return newChannel(outputStream);\n   }\n \n   @Override\n   protected ReadableByteChannel open(AzfsResourceId resourceId) throws IOException {\n-    // TODO\n-    return null;\n+    BlobClient blobClient =\n+        client\n+            .get()\n+            .getBlobContainerClient(resourceId.getContainer())\n+            .getBlobClient(resourceId.getBlob());\n+    if (!blobClient.exists()) {\n+      throw new FileNotFoundException(\"The requested file doesn't exist.\");\n+    }\n+    return new AzureReadableSeekableByteChannel(blobClient);\n   }\n \n   @Override\n   protected void copy(List<AzfsResourceId> srcPaths, List<AzfsResourceId> destPaths)\n       throws IOException {\n-    // TODO\n+    checkArgument(\n+        srcPaths.size() == destPaths.size(),\n+        \"sizes of source paths and destination paths do not match\");\n+\n+    Iterator<AzfsResourceId> sourcePathsIterator = srcPaths.iterator();\n+    Iterator<AzfsResourceId> destinationPathsIterator = destPaths.iterator();\n+    while (sourcePathsIterator.hasNext()) {\n+      final AzfsResourceId sourcePath = sourcePathsIterator.next();\n+      final AzfsResourceId destinationPath = destinationPathsIterator.next();\n+      copy(sourcePath, destinationPath);\n+    }\n   }\n \n   @VisibleForTesting\n   void copy(AzfsResourceId sourcePath, AzfsResourceId destinationPath) throws IOException {\n-    // TODO\n+    checkArgument(\n+        sourcePath.getBlob() != null && destinationPath.getBlob() != null,\n+        \"This method is intended to copy file-like resources, not directories.\");\n+\n+    // get source blob client\n+    BlobClient srcBlobClient =\n+        client\n+            .get()\n+            .getBlobContainerClient(sourcePath.getContainer())\n+            .getBlobClient(sourcePath.getBlob());\n+    if (!srcBlobClient.exists()) {\n+      throw new FileNotFoundException(\"The copy source does not exist.\");\n+    }\n+\n+    // get destination blob client\n+    BlobContainerClient destBlobContainerClient =\n+        client.get().getBlobContainerClient(destinationPath.getContainer());\n+    if (!destBlobContainerClient.exists()) {\n+      client.get().createBlobContainer(destinationPath.getContainer());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 366}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY2NTA5Mg==", "bodyText": "remove this line", "url": "https://github.com/apache/beam/pull/12581#discussion_r471665092", "createdAt": "2020-08-17T18:00:24Z", "author": {"login": "pabloem"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "diffHunk": "@@ -17,67 +17,438 @@\n  */\n package org.apache.beam.sdk.io.azure.blobstore;\n \n+import static java.nio.channels.Channels.newChannel;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobItem;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.BlobStorageException;\n+import com.azure.storage.blob.models.ListBlobsOptions;\n+import com.microsoft.azure.storage.CloudStorageAccount;\n+import com.microsoft.azure.storage.SharedAccessAccountPolicy;\n+import java.io.FileNotFoundException;\n import java.io.IOException;\n+import java.io.OutputStream;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.time.Duration;\n+import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Date;\n+import java.util.Iterator;\n import java.util.List;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n import org.apache.beam.sdk.io.FileSystem;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreClientBuilderFactory;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n import org.apache.beam.sdk.io.fs.CreateOptions;\n import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.util.InstanceBuilder;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Supplier;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Suppliers;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableSet;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n class AzureBlobStoreFileSystem extends FileSystem<AzfsResourceId> {\n \n+  private static final Logger LOG = LoggerFactory.getLogger(AzureBlobStoreFileSystem.class);\n+\n+  private static final ImmutableSet<String> NON_READ_SEEK_EFFICIENT_ENCODINGS =\n+      ImmutableSet.of(\"gzip\");\n+\n+  private Supplier<BlobServiceClient> client;\n+  private final BlobstoreOptions options;\n+\n+  AzureBlobStoreFileSystem(BlobstoreOptions options) {\n+    this.options = checkNotNull(options, \"options\");\n+\n+    BlobServiceClientBuilder builder =\n+        InstanceBuilder.ofType(BlobstoreClientBuilderFactory.class)\n+            .fromClass(options.getBlobstoreClientFactoryClass())\n+            .build()\n+            .createBuilder(options);\n+\n+    // The Supplier is to make sure we don't call .build() unless we are actually using Azure.\n+    client = Suppliers.memoize(builder::buildClient);\n+  }\n+\n+  @VisibleForTesting\n+  void setClient(BlobServiceClient client) {\n+    this.client = Suppliers.ofInstance(client);\n+  }\n+\n+  @VisibleForTesting\n+  BlobServiceClient getClient() {\n+    return client.get();\n+  }\n+\n   @Override\n   protected String getScheme() {\n-    return \"azfs\";\n+    return AzfsResourceId.SCHEME;\n   }\n \n   @Override\n-  protected List<MatchResult> match(List<String> specs) throws IOException {\n-    // TODO\n-    return null;\n+  protected List<MatchResult> match(List<String> specs) {\n+    List<AzfsResourceId> paths =\n+        specs.stream().map(AzfsResourceId::fromUri).collect(Collectors.toList());\n+    List<AzfsResourceId> globs = new ArrayList<>();\n+    List<AzfsResourceId> nonGlobs = new ArrayList<>();\n+    List<Boolean> isGlobBooleans = new ArrayList<>();\n+\n+    for (AzfsResourceId path : paths) {\n+      if (path.isWildcard()) {\n+        globs.add(path);\n+        isGlobBooleans.add(true);\n+      } else {\n+        nonGlobs.add(path);\n+        isGlobBooleans.add(false);\n+      }\n+    }\n+\n+    Iterator<MatchResult> globMatches = matchGlobPaths(globs).iterator();\n+    Iterator<MatchResult> nonGlobMatches = matchNonGlobPaths(nonGlobs).iterator();\n+\n+    ImmutableList.Builder<MatchResult> matchResults = ImmutableList.builder();\n+    for (Boolean isGlob : isGlobBooleans) {\n+      if (isGlob) {\n+        checkState(globMatches.hasNext(), \"Expect globMatches has next.\");\n+        matchResults.add(globMatches.next());\n+      } else {\n+        checkState(nonGlobMatches.hasNext(), \"Expect nonGlobMatches has next.\");\n+        matchResults.add(nonGlobMatches.next());\n+      }\n+    }\n+    checkState(!globMatches.hasNext(), \"Expect no more elements in globMatches.\");\n+    checkState(!nonGlobMatches.hasNext(), \"Expect no more elements in nonGlobMatches.\");\n+\n+    return matchResults.build();\n+  }\n+\n+  /**\n+   * Expands glob expressions to regular expressions.\n+   *\n+   * @param globExp the glob expression to expand\n+   * @return a string with the regular expression this glob expands to\n+   */\n+  @VisibleForTesting\n+  static String wildcardToRegexp(String globExp) {\n+    StringBuilder dst = new StringBuilder();\n+    char[] src = globExp.replace(\"**/*\", \"**\").toCharArray();\n+    int i = 0;\n+    while (i < src.length) {\n+      char c = src[i++];\n+      switch (c) {\n+        case '*':\n+          // One char lookahead for **\n+          if (i < src.length && src[i] == '*') {\n+            dst.append(\".*\");\n+            ++i;\n+          } else {\n+            dst.append(\"[^/]*\");\n+          }\n+          break;\n+        case '?':\n+          dst.append(\"[^/]\");\n+          break;\n+        case '.':\n+        case '+':\n+        case '{':\n+        case '}':\n+        case '(':\n+        case ')':\n+        case '|':\n+        case '^':\n+        case '$':\n+          // These need to be escaped in regular expressions\n+          dst.append('\\\\').append(c);\n+          break;\n+        case '\\\\':\n+          i = doubleSlashes(dst, src, i);\n+          break;\n+        default:\n+          dst.append(c);\n+          break;\n+      }\n+    }\n+    return dst.toString();\n+  }\n+\n+  private static int doubleSlashes(StringBuilder dst, char[] src, int i) {\n+    // Emit the next character without special interpretation\n+    dst.append(\"\\\\\\\\\");\n+    if ((i - 1) != src.length) {\n+      dst.append(src[i]);\n+      i++;\n+    } else {\n+      // A backslash at the very end is treated like an escaped backslash\n+      dst.append('\\\\');\n+    }\n+    return i;\n+  }\n+\n+  private List<MatchResult> matchGlobPaths(List<AzfsResourceId> globs) {\n+    return FluentIterable.from(globs).transform(this::expand).toList();\n+  }\n+\n+  /** Expands a pattern into {@link MatchResult}. */\n+  @VisibleForTesting\n+  MatchResult expand(AzfsResourceId azfsPattern) {\n+\n+    checkArgument(azfsPattern.isWildcard(), \"is Wildcard\");\n+    String blobPrefix = azfsPattern.getBlobNonWildcardPrefix();\n+    Pattern wildcardAsRegexp = Pattern.compile(wildcardToRegexp(azfsPattern.getBlob()));\n+\n+    LOG.debug(\n+        \"matching files in container {}, prefix {} against pattern {}\",\n+        azfsPattern.getContainer(),\n+        blobPrefix,\n+        wildcardAsRegexp.toString());\n+\n+    ListBlobsOptions listOptions = new ListBlobsOptions().setPrefix(blobPrefix);\n+    Duration timeout = Duration.ZERO.plusMinutes(1);\n+\n+    String account = azfsPattern.getAccount();\n+    String container = azfsPattern.getContainer();\n+    BlobContainerClient blobContainerClient = client.get().getBlobContainerClient(container);\n+    PagedIterable<BlobItem> blobs = blobContainerClient.listBlobs(listOptions, timeout);\n+    List<MatchResult.Metadata> results = new ArrayList<>();\n+\n+    blobs.forEach(\n+        blob -> {\n+          String name = blob.getName();\n+          if (wildcardAsRegexp.matcher(name).matches() && !name.endsWith(\"/\")) {\n+            LOG.debug(\"Matched object: {}\", name);\n+\n+            BlobProperties properties = blobContainerClient.getBlobClient(name).getProperties();\n+            AzfsResourceId rid =\n+                AzfsResourceId.fromComponents(account, container, name)\n+                    .withSize(properties.getBlobSize())\n+                    .withLastModified(Date.from(properties.getLastModified().toInstant()));\n+\n+            results.add(toMetadata(rid, properties.getContentEncoding()));\n+          }\n+        });\n+\n+    return MatchResult.create(MatchResult.Status.OK, results);\n+  }\n+\n+  private MatchResult.Metadata toMetadata(AzfsResourceId path, String contentEncoding) {\n+\n+    checkArgument(path.getSize().isPresent(), \"path has size\");\n+    boolean isReadSeekEfficient = !NON_READ_SEEK_EFFICIENT_ENCODINGS.contains(contentEncoding);\n+\n+    return MatchResult.Metadata.builder()\n+        .setIsReadSeekEfficient(isReadSeekEfficient)\n+        .setResourceId(path)\n+        .setSizeBytes(path.getSize().get())\n+        .setLastModifiedMillis(path.getLastModified().transform(Date::getTime).or(0L))\n+        .build();\n+  }\n+\n+  /**\n+   * Returns {@link MatchResult MatchResults} for the given {@link AzfsResourceId paths}.\n+   *\n+   * <p>The number of returned {@link MatchResult MatchResults} equals to the number of given {@link\n+   * AzfsResourceId paths}. Each {@link MatchResult} contains one {@link MatchResult.Metadata}.\n+   */\n+  @VisibleForTesting\n+  private Iterable<MatchResult> matchNonGlobPaths(List<AzfsResourceId> paths) {\n+    ImmutableList.Builder<MatchResult> toReturn = ImmutableList.builder();\n+    for (AzfsResourceId path : paths) {\n+      toReturn.add(toMatchResult(path));\n+    }\n+    return toReturn.build();\n+  }\n+\n+  private MatchResult toMatchResult(AzfsResourceId path) {\n+    BlobClient blobClient =\n+        client.get().getBlobContainerClient(path.getContainer()).getBlobClient(path.getBlob());\n+    BlobProperties blobProperties;\n+\n+    try {\n+      blobProperties = blobClient.getProperties();\n+    } catch (BlobStorageException e) {\n+      if (e.getStatusCode() == 404) {\n+        return MatchResult.create(MatchResult.Status.NOT_FOUND, new FileNotFoundException());\n+      }\n+      return MatchResult.create(MatchResult.Status.ERROR, new IOException(e));\n+    }\n+\n+    return MatchResult.create(\n+        MatchResult.Status.OK,\n+        ImmutableList.of(\n+            toMetadata(\n+                path.withSize(blobProperties.getBlobSize())\n+                    .withLastModified(Date.from(blobProperties.getLastModified().toInstant())),\n+                blobProperties.getContentEncoding())));\n   }\n \n   @Override\n   protected WritableByteChannel create(AzfsResourceId resourceId, CreateOptions createOptions)\n       throws IOException {\n-    // TODO\n-    return null;\n+    BlobContainerClient blobContainerClient =\n+        client.get().getBlobContainerClient(resourceId.getContainer());\n+    if (!blobContainerClient.exists()) {\n+      throw new UnsupportedOperationException(\"create does not create containers.\");\n+    }\n+\n+    BlobClient blobClient = blobContainerClient.getBlobClient(resourceId.getBlob());\n+    // The getBlobOutputStream method overwrites existing blobs,\n+    // so throw an error in this case to prevent data loss\n+    if (blobClient.exists()) {\n+      throw new IOException(\"This filename is already in use.\");\n+    }\n+\n+    OutputStream outputStream;\n+    try {\n+      outputStream = blobClient.getBlockBlobClient().getBlobOutputStream();\n+    } catch (BlobStorageException e) {\n+      throw (IOException) e.getCause();\n+    }\n+    return newChannel(outputStream);\n   }\n \n   @Override\n   protected ReadableByteChannel open(AzfsResourceId resourceId) throws IOException {\n-    // TODO\n-    return null;\n+    BlobClient blobClient =\n+        client\n+            .get()\n+            .getBlobContainerClient(resourceId.getContainer())\n+            .getBlobClient(resourceId.getBlob());\n+    if (!blobClient.exists()) {\n+      throw new FileNotFoundException(\"The requested file doesn't exist.\");\n+    }\n+    return new AzureReadableSeekableByteChannel(blobClient);\n   }\n \n   @Override\n   protected void copy(List<AzfsResourceId> srcPaths, List<AzfsResourceId> destPaths)\n       throws IOException {\n-    // TODO\n+    checkArgument(\n+        srcPaths.size() == destPaths.size(),\n+        \"sizes of source paths and destination paths do not match\");\n+\n+    Iterator<AzfsResourceId> sourcePathsIterator = srcPaths.iterator();\n+    Iterator<AzfsResourceId> destinationPathsIterator = destPaths.iterator();\n+    while (sourcePathsIterator.hasNext()) {\n+      final AzfsResourceId sourcePath = sourcePathsIterator.next();\n+      final AzfsResourceId destinationPath = destinationPathsIterator.next();\n+      copy(sourcePath, destinationPath);\n+    }\n   }\n \n   @VisibleForTesting\n   void copy(AzfsResourceId sourcePath, AzfsResourceId destinationPath) throws IOException {\n-    // TODO\n+    checkArgument(\n+        sourcePath.getBlob() != null && destinationPath.getBlob() != null,\n+        \"This method is intended to copy file-like resources, not directories.\");\n+\n+    // get source blob client\n+    BlobClient srcBlobClient =\n+        client\n+            .get()\n+            .getBlobContainerClient(sourcePath.getContainer())\n+            .getBlobClient(sourcePath.getBlob());\n+    if (!srcBlobClient.exists()) {\n+      throw new FileNotFoundException(\"The copy source does not exist.\");\n+    }\n+\n+    // get destination blob client\n+    BlobContainerClient destBlobContainerClient =\n+        client.get().getBlobContainerClient(destinationPath.getContainer());\n+    if (!destBlobContainerClient.exists()) {\n+      client.get().createBlobContainer(destinationPath.getContainer());\n+    }\n+    BlobClient destBlobClient = destBlobContainerClient.getBlobClient(destinationPath.getBlob());\n+\n+    destBlobClient.copyFromUrl(srcBlobClient.getBlobUrl() + generateSasToken());\n+  }\n+\n+  @VisibleForTesting\n+  String generateSasToken() throws IOException {\n+    SharedAccessAccountPolicy sharedAccessAccountPolicy = new SharedAccessAccountPolicy();\n+    long date = new Date().getTime();\n+    long expiryDate = new Date(date + 8640000).getTime();\n+\n+    sharedAccessAccountPolicy.setPermissionsFromString(\"racwdlup\");\n+    sharedAccessAccountPolicy.setSharedAccessStartTime(new Date(date));\n+    sharedAccessAccountPolicy.setSharedAccessExpiryTime(new Date(expiryDate));\n+    sharedAccessAccountPolicy.setResourceTypeFromString(\n+        \"co\"); // container, object, add s for service\n+    sharedAccessAccountPolicy.setServiceFromString(\"b\"); // blob, add \"fqt\" for file, queue, table\n+\n+    String storageConnectionString = options.getAzureConnectionString();\n+    try {\n+      CloudStorageAccount storageAccount = CloudStorageAccount.parse(storageConnectionString);\n+      return \"?\" + storageAccount.generateSharedAccessSignature(sharedAccessAccountPolicy);\n+    } catch (Exception e) {\n+      throw (IOException) e.getCause();\n+    }\n   }\n \n   @Override\n   protected void rename(List<AzfsResourceId> srcResourceIds, List<AzfsResourceId> destResourceIds)\n       throws IOException {\n-    // TODO\n+    copy(srcResourceIds, destResourceIds);\n+    delete(srcResourceIds);\n   }\n \n+  // This method with delete a virtual folder or a blob\n   @Override\n   protected void delete(Collection<AzfsResourceId> resourceIds) throws IOException {\n-    // TODO\n+    for (AzfsResourceId resourceId : resourceIds) {\n+      if (resourceId.getBlob() == null) {\n+        throw new IOException(\"delete does not delete containers.\");\n+      }\n+\n+      BlobContainerClient container =\n+          client.get().getBlobContainerClient(resourceId.getContainer());\n+\n+      // deleting a blob that is not a directory\n+      if (!resourceId.isDirectory()) {\n+        BlobClient blob = container.getBlobClient(resourceId.getBlob());\n+        if (!blob.exists()) {\n+          throw new FileNotFoundException(\"The resource to delete does not exist.\");\n+        }\n+        blob.delete();\n+      }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 423}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTczNTMzMw==", "bodyText": "These configuration-related variables seem to be non-serializable. I think we need to implement the special Json serializer before moving forward with adding these changes. We can remove these changes from this PR (and rely purely on a String-type connectionString) and add them in a follow-up PR, or get the Json serializer in this PR. What do you think?", "url": "https://github.com/apache/beam/pull/12581#discussion_r471735333", "createdAt": "2020-08-17T19:44:13Z", "author": {"login": "pabloem"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/options/AzureOptions.java", "diffHunk": "@@ -0,0 +1,86 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.azure.options;\n+\n+import com.azure.core.credential.TokenCredential;\n+import com.azure.core.util.Configuration;\n+import com.azure.identity.DefaultAzureCredentialBuilder;\n+import org.apache.beam.sdk.options.Default;\n+import org.apache.beam.sdk.options.DefaultValueFactory;\n+import org.apache.beam.sdk.options.Description;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+\n+public interface AzureOptions extends PipelineOptions {\n+\n+  // TODO: Add any other azure options that users should be able to configure\n+  // TODO: Confirm that Azure options are in this file, Blobstore options in BlobstoreOptions\n+\n+  /** The Azure service endpoint used by the Azure client. */\n+  @Description(\"Azure service endpoint used by the Azure client\")\n+  String getAzureServiceEndpoint();\n+\n+  void setAzureServiceEndpoint(String value);\n+\n+  /**\n+   * The credential instance that should be used to authenticate against Azure services. The option\n+   * value must contain a \"@type\" field and an Azure credentials provider class as the field value.\n+   */\n+  @Description(\n+      \"The credential instance that should be used to authenticate \"\n+          + \"against Azure services. The option value must contain \\\"@type\\\" field \"\n+          + \"and an Azure credentials provider class name as the field value.\")\n+  @Default.InstanceFactory(AzureUserCredentialsFactory.class)\n+  TokenCredential getAzureCredentialsProvider();\n+\n+  void setAzureCredentialsProvider(TokenCredential value);\n+\n+  /** Attempts to load Azure credentials. */\n+  class AzureUserCredentialsFactory implements DefaultValueFactory<TokenCredential> {\n+\n+    @Override\n+    public TokenCredential create(PipelineOptions options) {\n+      return new DefaultAzureCredentialBuilder().build();\n+    }\n+  }\n+\n+  /** The client configuration instance that should be used to configure Azure service clients. */\n+  @Description(\n+      \"The client configuration instance that should be used to configure Azure service clients\")\n+  @Default.InstanceFactory(ConfigurationFactory.class)\n+  Configuration getClientConfiguration();\n+\n+  void setClientConfiguration(Configuration configuration);\n+\n+  /** The client configuration instance that should be used to configure Azure service clients. */\n+  @Description(\n+      \"The client configuration instance that should be used to configure Azure http client configuration parameters.\"\n+          + \"Mentioned parameters are the available parameters that can be set. Set only those that need custom changes.\")\n+  @Default.InstanceFactory(ConfigurationFactory.class)\n+  Configuration getAzureHttpConfiguration();\n+\n+  void setAzureHttpConfiguration(Configuration configuration);\n+\n+  /** Default Azure client configuration. */\n+  class ConfigurationFactory implements DefaultValueFactory<Configuration> {\n+\n+    @Override\n+    public Configuration create(PipelineOptions options) {\n+      return new Configuration();\n+    }\n+  }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTczNjE2NA==", "bodyText": "this comment is more related to the options classes, but you can add this annotation to AzureOptions and BlobstoreOptions, so that we will be able to move options around. As discussed in person, when in doubt about where to put an option, err on the side of caution, and put them in BlobstoreOptions.", "url": "https://github.com/apache/beam/pull/12581#discussion_r471736164", "createdAt": "2020-08-17T19:45:53Z", "author": {"login": "pabloem"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/options/package-info.java", "diffHunk": "@@ -0,0 +1,23 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+/** Defines IO connectors for Microsoft Azure Blobstore. */\n+@Experimental(Kind.FILESYSTEM)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 19}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1bbc9479faa2240743ad37050e63f9547e124b30", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/1bbc9479faa2240743ad37050e63f9547e124b30", "committedDate": "2020-08-17T22:55:24Z", "message": "adding mocks to azure filesystem tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4799c220ed088e72e394296b3e6303b038b2cbd1", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/4799c220ed088e72e394296b3e6303b038b2cbd1", "committedDate": "2020-08-17T23:33:00Z", "message": "adding mocks to azure filesystem test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5fb8001b8a1aac042f8a3046dc9342611b9a0484", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/5fb8001b8a1aac042f8a3046dc9342611b9a0484", "committedDate": "2020-08-17T23:36:31Z", "message": "resolving various reviewer comments\n\napplied spotless to fix formatting"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f534b04960424ec73aa1d157233efcc25e3aa69b", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/f534b04960424ec73aa1d157233efcc25e3aa69b", "committedDate": "2020-08-17T23:27:54Z", "message": "resolving various reviewer comments"}, "afterCommit": {"oid": "5fb8001b8a1aac042f8a3046dc9342611b9a0484", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/5fb8001b8a1aac042f8a3046dc9342611b9a0484", "committedDate": "2020-08-17T23:36:31Z", "message": "resolving various reviewer comments\n\napplied spotless to fix formatting"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8b4fd2a8080336d65913e4cdde1fdda5fe91f8e6", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/8b4fd2a8080336d65913e4cdde1fdda5fe91f8e6", "committedDate": "2020-08-18T01:27:25Z", "message": "adding mocks to filesystem test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8f073fd9c1b350a767ed66cfb62c6c56afd53efb", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/8f073fd9c1b350a767ed66cfb62c6c56afd53efb", "committedDate": "2020-08-18T01:30:19Z", "message": "adding mocks to filesystem test"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY5ODE3NDIy", "url": "https://github.com/apache/beam/pull/12581#pullrequestreview-469817422", "createdAt": "2020-08-18T20:45:11Z", "commit": {"oid": "5fb8001b8a1aac042f8a3046dc9342611b9a0484"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQyMDo0NToxMVrOHCmB-g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQyMDo0NToxMVrOHCmB-g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjQ4MjI5OA==", "bodyText": "Constants usually have uppercase names, like so:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              private static final int expiryTime = 86400000;\n          \n          \n            \n              private static final int DEFAULT_EXPIRY_TIME = 86400000;", "url": "https://github.com/apache/beam/pull/12581#discussion_r472482298", "createdAt": "2020-08-18T20:45:11Z", "author": {"login": "pabloem"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "diffHunk": "@@ -68,6 +68,8 @@\n   private static final ImmutableSet<String> NON_READ_SEEK_EFFICIENT_ENCODINGS =\n       ImmutableSet.of(\"gzip\");\n \n+  private static final int expiryTime = 86400000;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5fb8001b8a1aac042f8a3046dc9342611b9a0484"}, "originalPosition": 4}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6f30dc6a8be69026b1a39debdceb95023cbacfbf", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/6f30dc6a8be69026b1a39debdceb95023cbacfbf", "committedDate": "2020-08-19T02:29:39Z", "message": "working on options and mocks"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7ec96941cb879245caa2e8edaa7701469de6dfcf", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/7ec96941cb879245caa2e8edaa7701469de6dfcf", "committedDate": "2020-08-19T02:48:04Z", "message": "adding options and unit tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "26690cb6941af77369d1533a6424313d33000abf", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/26690cb6941af77369d1533a6424313d33000abf", "committedDate": "2020-08-19T03:00:22Z", "message": "applied spotless"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4cf0f99721238f74803609cdd93d36c3903c11e4", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/4cf0f99721238f74803609cdd93d36c3903c11e4", "committedDate": "2020-08-19T03:21:01Z", "message": "Update sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java\n\nCo-authored-by: Pablo <pabloem@users.noreply.github.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c2d91af03b59baa1e2865bc3d68f68daf17abec1", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/c2d91af03b59baa1e2865bc3d68f68daf17abec1", "committedDate": "2020-08-19T03:36:47Z", "message": "incorporating reviewer feeback"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4d14586568f2df76318bae05a55fdf73d3bc4d20", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/4d14586568f2df76318bae05a55fdf73d3bc4d20", "committedDate": "2020-08-19T04:36:20Z", "message": "fixed a checkstyle issue, annotated tests in progress with @Ignore"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f97873dc95e43804cce90a0af45a8d6dd80e7c5d", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/f97873dc95e43804cce90a0af45a8d6dd80e7c5d", "committedDate": "2020-08-19T15:04:43Z", "message": "adding javadoc"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9aea1b2a4846e156ceeeb880d798fd1896d14045", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/9aea1b2a4846e156ceeeb880d798fd1896d14045", "committedDate": "2020-08-19T15:54:53Z", "message": "fixing a bug in AzureReadableSeekableByteChannel read"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDcwNjMyNjIx", "url": "https://github.com/apache/beam/pull/12581#pullrequestreview-470632621", "createdAt": "2020-08-19T16:23:04Z", "commit": {"oid": "9aea1b2a4846e156ceeeb880d798fd1896d14045"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQxNjoyMzowNFrOHDPG4w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQxNjoyMzowNFrOHDPG4w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzE1NTI5OQ==", "bodyText": "I recommend you remove all the LOG.info lines from this class. Because there may be 100s or 1000s of AzureReadableSeekableByteChannel objects in a Beam pipeline, this logging may overwhelm the logging system", "url": "https://github.com/apache/beam/pull/12581#discussion_r473155299", "createdAt": "2020-08-19T16:23:04Z", "author": {"login": "pabloem"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureReadableSeekableByteChannel.java", "diffHunk": "@@ -44,23 +50,22 @@ public int read(ByteBuffer dst) throws IOException {\n     if (closed) {\n       throw new ClosedChannelException();\n     }\n-    if (!dst.hasRemaining()) {\n-      return 0;\n-    }\n \n     int read = 0;\n     if (dst.hasArray()) {\n       // Stores up to dst.remaining() bytes into dst.array() starting at dst.position().\n       // But dst can have an offset with its backing array, hence the + dst.arrayOffset().\n       read = inputStream.read(dst.array(), dst.position() + dst.arrayOffset(), dst.remaining());\n+      LOG.info(\"PArray: \" + StandardCharsets.UTF_8.decode(dst).toString());\n     } else {\n       byte[] myarray = new byte[dst.remaining()];\n       read = inputStream.read(myarray, 0, myarray.length);\n       dst.put(myarray);\n+      LOG.info(\"Array: \" + Arrays.toString(myarray));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9aea1b2a4846e156ceeeb880d798fd1896d14045"}, "originalPosition": 43}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "aab24bfc50fd379a2a013ebe0ef52ef047756a48", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/aab24bfc50fd379a2a013ebe0ef52ef047756a48", "committedDate": "2020-08-19T16:27:11Z", "message": "removing logger from azure bytechannel"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDcwNjU2OTIy", "url": "https://github.com/apache/beam/pull/12581#pullrequestreview-470656922", "createdAt": "2020-08-19T16:52:32Z", "commit": {"oid": "aab24bfc50fd379a2a013ebe0ef52ef047756a48"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQxNjo1MjozMlrOHDQh2w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQxNzoxMDoxM1rOHDRbIA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzE3ODU4Nw==", "bodyText": "perfect. thanks!", "url": "https://github.com/apache/beam/pull/12581#discussion_r473178587", "createdAt": "2020-08-19T16:52:32Z", "author": {"login": "pabloem"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "diffHunk": "@@ -17,67 +17,438 @@\n  */\n package org.apache.beam.sdk.io.azure.blobstore;\n \n+import static java.nio.channels.Channels.newChannel;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobItem;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.BlobStorageException;\n+import com.azure.storage.blob.models.ListBlobsOptions;\n+import com.microsoft.azure.storage.CloudStorageAccount;\n+import com.microsoft.azure.storage.SharedAccessAccountPolicy;\n+import java.io.FileNotFoundException;\n import java.io.IOException;\n+import java.io.OutputStream;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.time.Duration;\n+import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Date;\n+import java.util.Iterator;\n import java.util.List;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n import org.apache.beam.sdk.io.FileSystem;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreClientBuilderFactory;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n import org.apache.beam.sdk.io.fs.CreateOptions;\n import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.util.InstanceBuilder;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Supplier;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Suppliers;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableSet;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n class AzureBlobStoreFileSystem extends FileSystem<AzfsResourceId> {\n \n+  private static final Logger LOG = LoggerFactory.getLogger(AzureBlobStoreFileSystem.class);\n+\n+  private static final ImmutableSet<String> NON_READ_SEEK_EFFICIENT_ENCODINGS =\n+      ImmutableSet.of(\"gzip\");\n+\n+  private Supplier<BlobServiceClient> client;\n+  private final BlobstoreOptions options;\n+\n+  AzureBlobStoreFileSystem(BlobstoreOptions options) {\n+    this.options = checkNotNull(options, \"options\");\n+\n+    BlobServiceClientBuilder builder =\n+        InstanceBuilder.ofType(BlobstoreClientBuilderFactory.class)\n+            .fromClass(options.getBlobstoreClientFactoryClass())\n+            .build()\n+            .createBuilder(options);\n+\n+    // The Supplier is to make sure we don't call .build() unless we are actually using Azure.\n+    client = Suppliers.memoize(builder::buildClient);\n+  }\n+\n+  @VisibleForTesting\n+  void setClient(BlobServiceClient client) {\n+    this.client = Suppliers.ofInstance(client);\n+  }\n+\n+  @VisibleForTesting\n+  BlobServiceClient getClient() {\n+    return client.get();\n+  }\n+\n   @Override\n   protected String getScheme() {\n-    return \"azfs\";\n+    return AzfsResourceId.SCHEME;\n   }\n \n   @Override\n-  protected List<MatchResult> match(List<String> specs) throws IOException {\n-    // TODO\n-    return null;\n+  protected List<MatchResult> match(List<String> specs) {\n+    List<AzfsResourceId> paths =\n+        specs.stream().map(AzfsResourceId::fromUri).collect(Collectors.toList());\n+    List<AzfsResourceId> globs = new ArrayList<>();\n+    List<AzfsResourceId> nonGlobs = new ArrayList<>();\n+    List<Boolean> isGlobBooleans = new ArrayList<>();\n+\n+    for (AzfsResourceId path : paths) {\n+      if (path.isWildcard()) {\n+        globs.add(path);\n+        isGlobBooleans.add(true);\n+      } else {\n+        nonGlobs.add(path);\n+        isGlobBooleans.add(false);\n+      }\n+    }\n+\n+    Iterator<MatchResult> globMatches = matchGlobPaths(globs).iterator();\n+    Iterator<MatchResult> nonGlobMatches = matchNonGlobPaths(nonGlobs).iterator();\n+\n+    ImmutableList.Builder<MatchResult> matchResults = ImmutableList.builder();\n+    for (Boolean isGlob : isGlobBooleans) {\n+      if (isGlob) {\n+        checkState(globMatches.hasNext(), \"Expect globMatches has next.\");\n+        matchResults.add(globMatches.next());\n+      } else {\n+        checkState(nonGlobMatches.hasNext(), \"Expect nonGlobMatches has next.\");\n+        matchResults.add(nonGlobMatches.next());\n+      }\n+    }\n+    checkState(!globMatches.hasNext(), \"Expect no more elements in globMatches.\");\n+    checkState(!nonGlobMatches.hasNext(), \"Expect no more elements in nonGlobMatches.\");\n+\n+    return matchResults.build();\n+  }\n+\n+  /**\n+   * Expands glob expressions to regular expressions.\n+   *\n+   * @param globExp the glob expression to expand\n+   * @return a string with the regular expression this glob expands to\n+   */\n+  @VisibleForTesting\n+  static String wildcardToRegexp(String globExp) {\n+    StringBuilder dst = new StringBuilder();\n+    char[] src = globExp.replace(\"**/*\", \"**\").toCharArray();\n+    int i = 0;\n+    while (i < src.length) {\n+      char c = src[i++];\n+      switch (c) {\n+        case '*':\n+          // One char lookahead for **\n+          if (i < src.length && src[i] == '*') {\n+            dst.append(\".*\");\n+            ++i;\n+          } else {\n+            dst.append(\"[^/]*\");\n+          }\n+          break;\n+        case '?':\n+          dst.append(\"[^/]\");\n+          break;\n+        case '.':\n+        case '+':\n+        case '{':\n+        case '}':\n+        case '(':\n+        case ')':\n+        case '|':\n+        case '^':\n+        case '$':\n+          // These need to be escaped in regular expressions\n+          dst.append('\\\\').append(c);\n+          break;\n+        case '\\\\':\n+          i = doubleSlashes(dst, src, i);\n+          break;\n+        default:\n+          dst.append(c);\n+          break;\n+      }\n+    }\n+    return dst.toString();\n+  }\n+\n+  private static int doubleSlashes(StringBuilder dst, char[] src, int i) {\n+    // Emit the next character without special interpretation\n+    dst.append(\"\\\\\\\\\");\n+    if ((i - 1) != src.length) {\n+      dst.append(src[i]);\n+      i++;\n+    } else {\n+      // A backslash at the very end is treated like an escaped backslash\n+      dst.append('\\\\');\n+    }\n+    return i;\n+  }\n+\n+  private List<MatchResult> matchGlobPaths(List<AzfsResourceId> globs) {\n+    return FluentIterable.from(globs).transform(this::expand).toList();\n+  }\n+\n+  /** Expands a pattern into {@link MatchResult}. */\n+  @VisibleForTesting\n+  MatchResult expand(AzfsResourceId azfsPattern) {\n+\n+    checkArgument(azfsPattern.isWildcard(), \"is Wildcard\");\n+    String blobPrefix = azfsPattern.getBlobNonWildcardPrefix();\n+    Pattern wildcardAsRegexp = Pattern.compile(wildcardToRegexp(azfsPattern.getBlob()));\n+\n+    LOG.debug(\n+        \"matching files in container {}, prefix {} against pattern {}\",\n+        azfsPattern.getContainer(),\n+        blobPrefix,\n+        wildcardAsRegexp.toString());\n+\n+    ListBlobsOptions listOptions = new ListBlobsOptions().setPrefix(blobPrefix);\n+    Duration timeout = Duration.ZERO.plusMinutes(1);\n+\n+    String account = azfsPattern.getAccount();\n+    String container = azfsPattern.getContainer();\n+    BlobContainerClient blobContainerClient = client.get().getBlobContainerClient(container);\n+    PagedIterable<BlobItem> blobs = blobContainerClient.listBlobs(listOptions, timeout);\n+    List<MatchResult.Metadata> results = new ArrayList<>();\n+\n+    blobs.forEach(\n+        blob -> {\n+          String name = blob.getName();\n+          if (wildcardAsRegexp.matcher(name).matches() && !name.endsWith(\"/\")) {\n+            LOG.debug(\"Matched object: {}\", name);\n+\n+            BlobProperties properties = blobContainerClient.getBlobClient(name).getProperties();\n+            AzfsResourceId rid =\n+                AzfsResourceId.fromComponents(account, container, name)\n+                    .withSize(properties.getBlobSize())\n+                    .withLastModified(Date.from(properties.getLastModified().toInstant()));\n+\n+            results.add(toMetadata(rid, properties.getContentEncoding()));\n+          }\n+        });\n+\n+    return MatchResult.create(MatchResult.Status.OK, results);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY1NjkwNg=="}, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 232}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzE5MzI0OA==", "bodyText": "The Environment Configuration property is failing to serialize, and thus it's preventing me from running the pipeline on DirectRunner. We can work around this by writing a custom JSON serializer (like in S3). But maybe we can remove environmentConfiguration for now and add it on a later change?", "url": "https://github.com/apache/beam/pull/12581#discussion_r473193248", "createdAt": "2020-08-19T17:10:13Z", "author": {"login": "pabloem"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/options/BlobstoreOptions.java", "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.azure.options;\n+\n+import com.azure.core.credential.TokenCredential;\n+import com.azure.core.http.HttpClient;\n+import com.azure.core.http.HttpPipeline;\n+import com.azure.core.http.policy.HttpPipelinePolicy;\n+import com.azure.core.util.Configuration;\n+import com.azure.identity.DefaultAzureCredentialBuilder;\n+import com.azure.storage.blob.models.CustomerProvidedKey;\n+import com.azure.storage.common.StorageSharedKeyCredential;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.annotations.Experimental.Kind;\n+import org.apache.beam.sdk.io.azure.blobstore.DefaultBlobstoreClientBuilderFactory;\n+import org.apache.beam.sdk.options.Default;\n+import org.apache.beam.sdk.options.DefaultValueFactory;\n+import org.apache.beam.sdk.options.Description;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.checkerframework.checker.nullness.qual.Nullable;\n+\n+// TODO: Tag each option with @Default or @Nullable\n+\n+@Experimental(Kind.FILESYSTEM)\n+/** Options used to configure Microsoft Azure Blob Storage. */\n+public interface BlobstoreOptions extends PipelineOptions {\n+\n+  @Description(\n+      \"Factory class that should be created and used to create a builder of Azure Blobstore client.\"\n+          + \"Override the default value if you need a Azure client with custom properties.\")\n+  @Default.Class(DefaultBlobstoreClientBuilderFactory.class)\n+  Class<? extends BlobstoreClientBuilderFactory> getBlobstoreClientFactoryClass();\n+\n+  void setBlobstoreClientFactoryClass(\n+      Class<? extends BlobstoreClientBuilderFactory> blobstoreClientFactoryClass);\n+\n+  @Description(\"Adds a pipeline policy to apply on each request sent to the blob service client.\")\n+  @Nullable\n+  HttpPipelinePolicy getPipelinePolicy();\n+\n+  void setPipelinePolicy(HttpPipelinePolicy pipelinePolicy);\n+\n+  /** The client configuration instance that should be used to configure Azure service clients. */\n+  @Description(\n+      \"The configuration instance used to retrieve environment configuration values \"\n+          + \"when building an Azure Blobstore client. Set only those that need custom changes.\")\n+  @Default.InstanceFactory(BlobstoreOptions.ConfigurationFactory.class)\n+  @Nullable\n+  Configuration getEnvironmentConfiguration();\n+\n+  void setEnvironmentConfiguration(Configuration configuration);\n+\n+  /** Default Azure client configuration. */\n+  class ConfigurationFactory implements DefaultValueFactory<Configuration> {\n+\n+    @Override\n+    public Configuration create(PipelineOptions options) {\n+      return new Configuration();\n+    }\n+  }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aab24bfc50fd379a2a013ebe0ef52ef047756a48"}, "originalPosition": 76}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e2f7eb278887104294ba087ea49a73d7b6987ac5", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/e2f7eb278887104294ba087ea49a73d7b6987ac5", "committedDate": "2020-08-19T17:16:39Z", "message": "removed non-serializable option"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4bc1857b7fab3c8383e4d80d7284333a7165857d", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/4bc1857b7fab3c8383e4d80d7284333a7165857d", "committedDate": "2020-08-19T17:27:10Z", "message": "removed non-serializable configuration option"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDcxMDQxNTI5", "url": "https://github.com/apache/beam/pull/12581#pullrequestreview-471041529", "createdAt": "2020-08-20T00:01:19Z", "commit": {"oid": "4bc1857b7fab3c8383e4d80d7284333a7165857d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQwMDowMToyMFrOHDhWwQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQwMDowMToyMFrOHDhWwQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzQ1NDI3Mw==", "bodyText": "Please file a JIRA issue to track this.", "url": "https://github.com/apache/beam/pull/12581#discussion_r473454273", "createdAt": "2020-08-20T00:01:20Z", "author": {"login": "pabloem"}, "path": "sdks/java/io/azure/src/test/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystemTest.java", "diffHunk": "@@ -0,0 +1,352 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.azure.blobstore;\n+\n+import static java.util.UUID.randomUUID;\n+import static org.apache.beam.sdk.io.fs.CreateOptions.StandardCreateOptions.builder;\n+import static org.hamcrest.Matchers.contains;\n+import static org.junit.Assert.assertArrayEquals;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertThat;\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.ArgumentMatchers.anyString;\n+import static org.mockito.Mockito.doAnswer;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.models.BlobItem;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.ListBlobsOptions;\n+import com.azure.storage.blob.specialized.BlobInputStream;\n+import com.azure.storage.blob.specialized.BlobOutputStream;\n+import com.azure.storage.blob.specialized.BlockBlobClient;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.ReadableByteChannel;\n+import java.nio.channels.WritableByteChannel;\n+import java.time.Duration;\n+import java.time.OffsetDateTime;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n+import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.options.PipelineOptionsFactory;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.junit.Before;\n+import org.junit.Ignore;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.JUnit4;\n+import org.mockito.Mockito;\n+\n+@RunWith(JUnit4.class)\n+@SuppressWarnings(\"CannotMockFinalClass\") // Mockito 2 and above can mock final classes\n+public class AzureBlobStoreFileSystemTest {\n+\n+  private static AzureBlobStoreFileSystem azureBlobStoreFileSystem;\n+  BlobstoreOptions options = PipelineOptionsFactory.as(BlobstoreOptions.class);\n+  BlobstoreOptions spyOptions = Mockito.spy(options);\n+  BlobServiceClient mockedServiceClient = Mockito.mock(BlobServiceClient.class);\n+  BlobContainerClient mockedContainerClient = Mockito.mock(BlobContainerClient.class);\n+  BlobClient mockedBlobClient = Mockito.mock(BlobClient.class);\n+  BlockBlobClient mockedBlockBlob = Mockito.mock(BlockBlobClient.class);\n+  BlobProperties mockedProperties = Mockito.mock(BlobProperties.class);\n+  PagedIterable<BlobItem> mockedPagedIterable = Mockito.mock(PagedIterable.class);\n+  BlobOutputStream mockedOutputStream = Mockito.mock(BlobOutputStream.class);\n+  BlobItem mockedBlobItem = Mockito.mock(BlobItem.class);\n+  BlobInputStream mockedInputStream = Mockito.mock(BlobInputStream.class);\n+\n+  @Before\n+  public void beforeClass() {\n+    azureBlobStoreFileSystem = new AzureBlobStoreFileSystem(spyOptions);\n+    azureBlobStoreFileSystem.setClient(mockedServiceClient);\n+\n+    boolean[] containerCreated = {false};\n+    when(mockedServiceClient.createBlobContainer(anyString()))\n+        .thenAnswer(\n+            (invocation) -> {\n+              containerCreated[0] = true;\n+              return mockedContainerClient;\n+            });\n+    when(mockedContainerClient.exists()).thenAnswer((invocation) -> containerCreated[0]);\n+    boolean[] blobCreated = {false};\n+    doAnswer(\n+            invocation -> {\n+              blobCreated[0] = true;\n+              return null;\n+            })\n+        .when(mockedBlobClient)\n+        .uploadFromFile(anyString());\n+    when(mockedBlobClient.exists()).thenAnswer((invocation) -> blobCreated[0]);\n+    when(azureBlobStoreFileSystem.getClient().getBlobContainerClient(anyString()))\n+        .thenReturn(mockedContainerClient);\n+    when(mockedContainerClient.getBlobClient(anyString())).thenReturn(mockedBlobClient);\n+    when(mockedBlobClient.getBlockBlobClient()).thenReturn(mockedBlockBlob);\n+    when(mockedBlobClient.getProperties()).thenReturn(mockedProperties);\n+    when(mockedProperties.getBlobSize()).thenReturn(Long.valueOf(1));\n+    when(mockedProperties.getLastModified()).thenReturn(OffsetDateTime.now());\n+    when(mockedContainerClient.listBlobs(any(ListBlobsOptions.class), any(Duration.class)))\n+        .thenReturn(mockedPagedIterable);\n+    when(mockedContainerClient.listBlobsByHierarchy(any(String.class)))\n+        .thenReturn(mockedPagedIterable);\n+    when(mockedBlockBlob.getBlobOutputStream())\n+        .thenAnswer(\n+            (i) -> {\n+              blobCreated[0] = true;\n+              return mockedOutputStream;\n+            });\n+    when(mockedBlobItem.getName()).thenReturn(\"name\");\n+    when(spyOptions.getSasToken()).thenReturn(\"sas-token\");\n+    when(mockedBlobClient.openInputStream()).thenReturn(mockedInputStream);\n+  }\n+\n+  @Test\n+  public void testGetScheme() {\n+    assertEquals(\"azfs\", azureBlobStoreFileSystem.getScheme());\n+  }\n+\n+  @Test\n+  public void testGlobTranslation() {\n+    assertEquals(\"foo\", AzureBlobStoreFileSystem.wildcardToRegexp(\"foo\"));\n+    assertEquals(\"fo[^/]*o\", AzureBlobStoreFileSystem.wildcardToRegexp(\"fo*o\"));\n+    assertEquals(\"f[^/]*o\\\\.[^/]\", AzureBlobStoreFileSystem.wildcardToRegexp(\"f*o.?\"));\n+    assertEquals(\"foo-[0-9][^/]*\", AzureBlobStoreFileSystem.wildcardToRegexp(\"foo-[0-9]*\"));\n+    assertEquals(\"foo-[0-9].*\", AzureBlobStoreFileSystem.wildcardToRegexp(\"foo-[0-9]**\"));\n+    assertEquals(\".*foo\", AzureBlobStoreFileSystem.wildcardToRegexp(\"**/*foo\"));\n+    assertEquals(\".*foo\", AzureBlobStoreFileSystem.wildcardToRegexp(\"**foo\"));\n+    assertEquals(\"foo/[^/]*\", AzureBlobStoreFileSystem.wildcardToRegexp(\"foo/*\"));\n+    assertEquals(\"foo[^/]*\", AzureBlobStoreFileSystem.wildcardToRegexp(\"foo*\"));\n+    assertEquals(\"foo/[^/]*/[^/]*/[^/]*\", AzureBlobStoreFileSystem.wildcardToRegexp(\"foo/*/*/*\"));\n+    assertEquals(\"foo/[^/]*/.*\", AzureBlobStoreFileSystem.wildcardToRegexp(\"foo/*/**\"));\n+    assertEquals(\"foo.*baz\", AzureBlobStoreFileSystem.wildcardToRegexp(\"foo**baz\"));\n+  }\n+\n+  @Test\n+  @SuppressWarnings(\"CheckReturnValue\")\n+  public void testCopy() throws IOException {\n+    List<AzfsResourceId> src =\n+        new ArrayList<>(\n+            Arrays.asList(AzfsResourceId.fromComponents(\"account\", \"container\", \"from\")));\n+    List<AzfsResourceId> dest =\n+        new ArrayList<>(Arrays.asList(AzfsResourceId.fromComponents(\"account\", \"container\", \"to\")));\n+    when(mockedBlobClient.exists()).thenReturn(true);\n+    azureBlobStoreFileSystem.copy(src, dest);\n+    verify(mockedBlobClient, times(1)).copyFromUrl(any(String.class));\n+  }\n+\n+  @Test\n+  public void testWriteAndRead() throws IOException {\n+    azureBlobStoreFileSystem.getClient().createBlobContainer(\"testcontainer\");\n+\n+    byte[] writtenArray = new byte[] {0};\n+    ByteBuffer bb = ByteBuffer.allocate(writtenArray.length);\n+    bb.put(writtenArray);\n+\n+    // First create an object and write data to it\n+    AzfsResourceId path = AzfsResourceId.fromUri(\"azfs://account/testcontainer/foo/bar.txt\");\n+    WritableByteChannel writableByteChannel =\n+        azureBlobStoreFileSystem.create(path, builder().setMimeType(\"application/text\").build());\n+    writableByteChannel.write(bb);\n+    writableByteChannel.close();\n+\n+    // Now read the same object\n+    ByteBuffer bb2 = ByteBuffer.allocate(writtenArray.length);\n+    ReadableByteChannel open = azureBlobStoreFileSystem.open(path);\n+    open.read(bb2);\n+\n+    // And compare the content with the one that was written\n+    byte[] readArray = bb2.array();\n+    assertArrayEquals(readArray, writtenArray);\n+    open.close();\n+  }\n+\n+  @Test\n+  @Ignore\n+  public void testGlobExpansion() throws IOException {\n+    // TODO: Write this test with mocks - see GcsFileSystemTest", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4bc1857b7fab3c8383e4d80d7284333a7165857d"}, "originalPosition": 188}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDcxMDQxNjIw", "url": "https://github.com/apache/beam/pull/12581#pullrequestreview-471041620", "createdAt": "2020-08-20T00:01:37Z", "commit": {"oid": "4bc1857b7fab3c8383e4d80d7284333a7165857d"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDcxMDk4NjQ1", "url": "https://github.com/apache/beam/pull/12581#pullrequestreview-471098645", "createdAt": "2020-08-20T03:16:38Z", "commit": {"oid": "4bc1857b7fab3c8383e4d80d7284333a7165857d"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQwMzoxNjozOFrOHDn_ng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQwMzoxNjozOFrOHDn_ng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzU2MzAzOA==", "bodyText": "I don't think this test suite is necessary for IT since test cases here should be covered by the unit tests already. I would image the IT we want is a a pipeline reading from azure file system and writing to azure file system. @pabloem what do you think?", "url": "https://github.com/apache/beam/pull/12581#discussion_r473563038", "createdAt": "2020-08-20T03:16:38Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/azure/src/test/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystemIT.java", "diffHunk": "@@ -0,0 +1,353 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.azure.blobstore;\n+\n+import static java.util.UUID.randomUUID;\n+import static org.apache.beam.sdk.io.fs.CreateOptions.StandardCreateOptions.builder;\n+import static org.hamcrest.Matchers.contains;\n+import static org.junit.Assert.assertArrayEquals;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertThat;\n+import static org.junit.Assert.assertThrows;\n+import static org.junit.Assert.assertTrue;\n+\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import java.io.File;\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.ReadableByteChannel;\n+import java.nio.channels.WritableByteChannel;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n+import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.options.PipelineOptionsFactory;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.commons.io.FileUtils;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.JUnit4;\n+\n+@RunWith(JUnit4.class)\n+public class AzureBlobStoreFileSystemIT {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4bc1857b7fab3c8383e4d80d7284333a7165857d"}, "originalPosition": 53}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fb1467dfdeca12d7f66c83ec4c1ae8ccdf5cbc8a", "author": {"user": {"login": "ettirapp", "name": "Etta Newman"}}, "url": "https://github.com/apache/beam/commit/fb1467dfdeca12d7f66c83ec4c1ae8ccdf5cbc8a", "committedDate": "2020-08-20T03:30:50Z", "message": "removed integration tests - they will be in a followup PR"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3541, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}