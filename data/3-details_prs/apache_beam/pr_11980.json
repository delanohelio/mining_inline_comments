{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDMyNzU0NDk1", "number": 11980, "title": "[BEAM-9546] DataframeTransform can now consume a schema-aware PCollection", "bodyText": "Adds batching of schema'd PCollections into dataframes based on BatchElements transform.\nPost-Commit Tests Status (on master branch)\n\n\n\nLang\nSDK\nApex\nDataflow\nFlink\nSamza\nSpark\n\n\n\n\nGo\n\n---\n---\n\n---\n\n\n\nJava\n\n\n\n\n\n\n\n\nPython\n\n---\n\n\n---\n\n\n\nXLang\n---\n---\n---\n\n---\n---\n\n\n\nPre-Commit Tests Status (on master branch)\n\n\n\n---\nJava\nPython\nGo\nWebsite\n\n\n\n\nNon-portable\n\n\n\n\n\n\nPortable\n---\n\n---\n---\n\n\n\nSee .test-infra/jenkins/README for trigger phrase, status and link of all Jenkins jobs.", "createdAt": "2020-06-10T23:35:24Z", "url": "https://github.com/apache/beam/pull/11980", "merged": true, "mergeCommit": {"oid": "cfa448d121297398312d09c531258a72b413488b"}, "closed": true, "closedAt": "2020-08-20T23:17:29Z", "author": {"login": "TheNeuralBit"}, "timelineItems": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc8Zj68ABqjM2MzEzMjc0MjQ=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdAlGcvAFqTQ3MTA1MDk5OA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ff822ac3bbbfc9f6fe76d1b4cab80f4e8bc4d04e", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/ff822ac3bbbfc9f6fe76d1b4cab80f4e8bc4d04e", "committedDate": "2020-06-10T23:28:34Z", "message": "WIP: Integrate proxy generation"}, "afterCommit": {"oid": "55c492088bcd5b7b2b8bd8fbeb46fbf68b167a30", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/55c492088bcd5b7b2b8bd8fbeb46fbf68b167a30", "committedDate": "2020-08-07T00:47:24Z", "message": "Add BatchRowsAsDataframe and generate_proxy, integrated into DataFrameTransform"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f658cb2c6e7a02985efc6cb3e17b268a0018bb08", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/f658cb2c6e7a02985efc6cb3e17b268a0018bb08", "committedDate": "2020-08-07T20:32:59Z", "message": "Add BatchRowsAsDataframe and generate_proxy, integrated into DataFrameTransform"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "55c492088bcd5b7b2b8bd8fbeb46fbf68b167a30", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/55c492088bcd5b7b2b8bd8fbeb46fbf68b167a30", "committedDate": "2020-08-07T00:47:24Z", "message": "Add BatchRowsAsDataframe and generate_proxy, integrated into DataFrameTransform"}, "afterCommit": {"oid": "f658cb2c6e7a02985efc6cb3e17b268a0018bb08", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/f658cb2c6e7a02985efc6cb3e17b268a0018bb08", "committedDate": "2020-08-07T20:32:59Z", "message": "Add BatchRowsAsDataframe and generate_proxy, integrated into DataFrameTransform"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e8ab82a3e73e553deb3fecf0e21cefe7f85a9a42", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/e8ab82a3e73e553deb3fecf0e21cefe7f85a9a42", "committedDate": "2020-08-07T21:16:19Z", "message": "lint"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "424b4939b6e19abf9beefc787c046b34a513c47e", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/424b4939b6e19abf9beefc787c046b34a513c47e", "committedDate": "2020-08-07T22:29:40Z", "message": "fix ci failures"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539", "committedDate": "2020-08-07T23:51:28Z", "message": "yapf?"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY3ODU2MTY1", "url": "https://github.com/apache/beam/pull/11980#pullrequestreview-467856165", "createdAt": "2020-08-14T20:26:50Z", "commit": {"oid": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539"}, "state": "COMMENTED", "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQyMDoyNjo1MVrOHBCZ5Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQyMDo1MDo1OFrOHBC9MQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1MDAyMQ==", "bodyText": "Woo hoo!", "url": "https://github.com/apache/beam/pull/11980#discussion_r470850021", "createdAt": "2020-08-14T20:26:51Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/convert.py", "diffHunk": "@@ -36,7 +37,7 @@\n # TODO: Or should this be called as_dataframe?\n def to_dataframe(\n     pcoll,  # type: pvalue.PCollection\n-    proxy,  # type: pandas.core.generic.NDFrame\n+    proxy=None,  # type: pandas.core.generic.NDFrame", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1MjAxNw==", "bodyText": "Rather than subclassing, it would probably be cleaner to make this just a PTransform whose expand method returns\n`pcoll | BatchElements(...) | Pardo(...)`.\n\nIf you want to accept all the parameter from BatchElements, you could construct the BatchElements instance in your constructor.", "url": "https://github.com/apache/beam/pull/11980#discussion_r470852017", "createdAt": "2020-08-14T20:31:58Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/schemas.py", "diffHunk": "@@ -0,0 +1,82 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Utilities for relating schema-aware PCollections and dataframe transforms.\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+from typing import NamedTuple\n+from typing import TypeVar\n+\n+import pandas as pd\n+\n+from apache_beam import typehints\n+from apache_beam.transforms.core import DoFn\n+from apache_beam.transforms.core import ParDo\n+from apache_beam.transforms.util import BatchElements\n+from apache_beam.typehints.schemas import named_fields_from_element_type\n+\n+__all__ = ('BatchRowsAsDataFrame', 'generate_proxy')\n+\n+T = TypeVar('T', bound=NamedTuple)\n+\n+\n+@typehints.with_input_types(T)\n+@typehints.with_output_types(pd.DataFrame)\n+class BatchRowsAsDataFrame(BatchElements):\n+  \"\"\"A transform that batches schema-aware PCollection elements into DataFrames\n+\n+  Batching parameters are inherited from\n+  :class:`~apache_beam.transforms.util.BatchElements`.\n+  \"\"\"\n+  def __init__(self, *args, **kwargs):\n+    super(BatchRowsAsDataFrame, self).__init__(*args, **kwargs)\n+    self._batch_elements_transform = BatchElements(*args, **kwargs)\n+\n+  def expand(self, pcoll):\n+    return super(BatchRowsAsDataFrame, self).expand(pcoll) | ParDo(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1MjcwOA==", "bodyText": "Rather than letting this be a full DoFn, you could just let columns be a local variable in the map above, and then write\n... | Map(lambda batch: pd.DataFrame.from_records(batch, columns))", "url": "https://github.com/apache/beam/pull/11980#discussion_r470852708", "createdAt": "2020-08-14T20:33:49Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/schemas.py", "diffHunk": "@@ -0,0 +1,82 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Utilities for relating schema-aware PCollections and dataframe transforms.\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+from typing import NamedTuple\n+from typing import TypeVar\n+\n+import pandas as pd\n+\n+from apache_beam import typehints\n+from apache_beam.transforms.core import DoFn\n+from apache_beam.transforms.core import ParDo\n+from apache_beam.transforms.util import BatchElements\n+from apache_beam.typehints.schemas import named_fields_from_element_type\n+\n+__all__ = ('BatchRowsAsDataFrame', 'generate_proxy')\n+\n+T = TypeVar('T', bound=NamedTuple)\n+\n+\n+@typehints.with_input_types(T)\n+@typehints.with_output_types(pd.DataFrame)\n+class BatchRowsAsDataFrame(BatchElements):\n+  \"\"\"A transform that batches schema-aware PCollection elements into DataFrames\n+\n+  Batching parameters are inherited from\n+  :class:`~apache_beam.transforms.util.BatchElements`.\n+  \"\"\"\n+  def __init__(self, *args, **kwargs):\n+    super(BatchRowsAsDataFrame, self).__init__(*args, **kwargs)\n+    self._batch_elements_transform = BatchElements(*args, **kwargs)\n+\n+  def expand(self, pcoll):\n+    return super(BatchRowsAsDataFrame, self).expand(pcoll) | ParDo(\n+        _RowBatchToDataFrameDoFn(pcoll.element_type))\n+\n+\n+class _RowBatchToDataFrameDoFn(DoFn):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1MzU2Nw==", "bodyText": "Nit. We typically have the style of importing modules, and then using qualified names (which results in less churn and makes it a bit easier to figure out where things come from). Instead of core, it's typical to do import apache_beam as beam and use beam.DoFn, etc.", "url": "https://github.com/apache/beam/pull/11980#discussion_r470853567", "createdAt": "2020-08-14T20:36:05Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/schemas.py", "diffHunk": "@@ -0,0 +1,82 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Utilities for relating schema-aware PCollections and dataframe transforms.\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+from typing import NamedTuple\n+from typing import TypeVar\n+\n+import pandas as pd\n+\n+from apache_beam import typehints\n+from apache_beam.transforms.core import DoFn", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1NDE5Mw==", "bodyText": "Can we get rid of this one too? (Or at least drop a TODO to do it in a subsequent PR?)", "url": "https://github.com/apache/beam/pull/11980#discussion_r470854193", "createdAt": "2020-08-14T20:37:53Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/schemas_test.py", "diffHunk": "@@ -0,0 +1,110 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Tests for schemas.\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import unittest\n+from typing import NamedTuple\n+\n+import future.tests.base  # pylint: disable=unused-import\n+# patches unittest.testcase to be python3 compatible\n+import pandas as pd\n+from past.builtins import unicode\n+\n+import apache_beam as beam\n+from apache_beam.coders import RowCoder\n+from apache_beam.coders.typecoders import registry as coders_registry\n+from apache_beam.dataframe import schemas\n+from apache_beam.dataframe import transforms\n+from apache_beam.testing.test_pipeline import TestPipeline\n+from apache_beam.testing.util import assert_that\n+\n+Simple = NamedTuple(\n+    'Simple', [('name', unicode), ('id', int), ('height', float)])\n+coders_registry.register_coder(Simple, RowCoder)\n+Animal = NamedTuple('Animal', [('animal', unicode), ('max_speed', float)])\n+coders_registry.register_coder(Animal, RowCoder)\n+\n+\n+def matches_df(expected):\n+  def check_df_pcoll_equal(actual):\n+    actual = pd.concat(actual)\n+    sorted_actual = actual.sort_values(by=list(actual.columns)).reset_index(\n+        drop=True)\n+    sorted_expected = expected.sort_values(\n+        by=list(expected.columns)).reset_index(drop=True)\n+    if not sorted_actual.equals(sorted_expected):\n+      raise AssertionError(\n+          'Dataframes not equal: \\n\\nActual:\\n%s\\n\\nExpected:\\n%s' %\n+          (sorted_actual, sorted_expected))\n+\n+  return check_df_pcoll_equal\n+\n+\n+class SchemasTest(unittest.TestCase):\n+  def test_simple_df(self):\n+    expected = pd.DataFrame({\n+        'name': list(unicode(i) for i in range(5)),\n+        'id': list(range(5)),\n+        'height': list(float(i) for i in range(5))\n+    },\n+                            columns=['name', 'id', 'height'])\n+\n+    with TestPipeline() as p:\n+      res = (\n+          p\n+          | beam.Create([\n+              Simple(name=unicode(i), id=i, height=float(i)) for i in range(5)\n+          ])\n+          | schemas.BatchRowsAsDataFrame(min_batch_size=10, max_batch_size=10))\n+      assert_that(res, matches_df(expected))\n+\n+  def test_generate_proxy(self):\n+    expected = pd.DataFrame({\n+        'animal': pd.Series(dtype=unicode), 'max_speed': pd.Series(dtype=float)\n+    })\n+\n+    self.assertTrue(schemas.generate_proxy(Animal).equals(expected))\n+\n+  def test_batch_with_df_transform(self):\n+    with TestPipeline() as p:\n+      res = (\n+          p\n+          | beam.Create([\n+              Animal('Falcon', 380.0),\n+              Animal('Falcon', 370.0),\n+              Animal('Parrot', 24.0),\n+              Animal('Parrot', 26.0)\n+          ])\n+          | schemas.BatchRowsAsDataFrame()\n+          | transforms.DataframeTransform(\n+              lambda df: df.groupby('animal').mean(),\n+              proxy=schemas.generate_proxy(Animal)))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539"}, "originalPosition": 100}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1NDQzMw==", "bodyText": "Maybe do a test using to_dataframe?", "url": "https://github.com/apache/beam/pull/11980#discussion_r470854433", "createdAt": "2020-08-14T20:38:30Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/schemas_test.py", "diffHunk": "@@ -0,0 +1,110 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Tests for schemas.\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import unittest\n+from typing import NamedTuple\n+\n+import future.tests.base  # pylint: disable=unused-import\n+# patches unittest.testcase to be python3 compatible\n+import pandas as pd\n+from past.builtins import unicode\n+\n+import apache_beam as beam\n+from apache_beam.coders import RowCoder\n+from apache_beam.coders.typecoders import registry as coders_registry\n+from apache_beam.dataframe import schemas\n+from apache_beam.dataframe import transforms\n+from apache_beam.testing.test_pipeline import TestPipeline\n+from apache_beam.testing.util import assert_that\n+\n+Simple = NamedTuple(\n+    'Simple', [('name', unicode), ('id', int), ('height', float)])\n+coders_registry.register_coder(Simple, RowCoder)\n+Animal = NamedTuple('Animal', [('animal', unicode), ('max_speed', float)])\n+coders_registry.register_coder(Animal, RowCoder)\n+\n+\n+def matches_df(expected):\n+  def check_df_pcoll_equal(actual):\n+    actual = pd.concat(actual)\n+    sorted_actual = actual.sort_values(by=list(actual.columns)).reset_index(\n+        drop=True)\n+    sorted_expected = expected.sort_values(\n+        by=list(expected.columns)).reset_index(drop=True)\n+    if not sorted_actual.equals(sorted_expected):\n+      raise AssertionError(\n+          'Dataframes not equal: \\n\\nActual:\\n%s\\n\\nExpected:\\n%s' %\n+          (sorted_actual, sorted_expected))\n+\n+  return check_df_pcoll_equal\n+\n+\n+class SchemasTest(unittest.TestCase):\n+  def test_simple_df(self):\n+    expected = pd.DataFrame({\n+        'name': list(unicode(i) for i in range(5)),\n+        'id': list(range(5)),\n+        'height': list(float(i) for i in range(5))\n+    },\n+                            columns=['name', 'id', 'height'])\n+\n+    with TestPipeline() as p:\n+      res = (\n+          p\n+          | beam.Create([\n+              Simple(name=unicode(i), id=i, height=float(i)) for i in range(5)\n+          ])\n+          | schemas.BatchRowsAsDataFrame(min_batch_size=10, max_batch_size=10))\n+      assert_that(res, matches_df(expected))\n+\n+  def test_generate_proxy(self):\n+    expected = pd.DataFrame({\n+        'animal': pd.Series(dtype=unicode), 'max_speed': pd.Series(dtype=float)\n+    })\n+\n+    self.assertTrue(schemas.generate_proxy(Animal).equals(expected))\n+\n+  def test_batch_with_df_transform(self):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1Nzk3NA==", "bodyText": "This threw me because I was expecting the result to be ['Aardvark', 'Ant']. I see now that it's filtering down to the column names that start with A, but perhaps the filter could be written a bit differently to make it more obvious (e.g. filter on the values, let the regex be 'Anim*', or use another operation).", "url": "https://github.com/apache/beam/pull/11980#discussion_r470857974", "createdAt": "2020-08-14T20:48:12Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/transforms_test.py", "diffHunk": "@@ -112,6 +133,64 @@ def test_scalar(self):\n       self.run_scenario(\n           df, lambda df: df.groupby('key').sum().val / df.val.agg(sum))\n \n+  def test_batching_named_tuple_input(self):\n+    with beam.Pipeline() as p:\n+      result = (\n+          p | beam.Create([\n+              AnimalSpeed('Aardvark', 5),\n+              AnimalSpeed('Ant', 2),\n+              AnimalSpeed('Elephant', 35),\n+              AnimalSpeed('Zebra', 40)\n+          ]).with_output_types(AnimalSpeed)\n+          | transforms.DataframeTransform(lambda df: df.filter(regex='A.*')))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539"}, "originalPosition": 123}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1ODgwMQ==", "bodyText": "Or a type constraint. (Not all our type hints are types.)", "url": "https://github.com/apache/beam/pull/11980#discussion_r470858801", "createdAt": "2020-08-14T20:50:22Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/pvalue.py", "diffHunk": "@@ -88,7 +88,7 @@ class PValue(object):\n   def __init__(self,\n                pipeline,  # type: Pipeline\n                tag=None,  # type: Optional[str]\n-               element_type=None,  # type: Optional[object]\n+               element_type=None,  # type: Optional[type]", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1OTA1Nw==", "bodyText": "Is this worth a JIRA?", "url": "https://github.com/apache/beam/pull/11980#discussion_r470859057", "createdAt": "2020-08-14T20:50:58Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/typehints/schemas.py", "diffHunk": "@@ -251,3 +258,23 @@ def named_tuple_from_schema(schema):\n \n def named_tuple_to_schema(named_tuple):\n   return typing_to_runner_api(named_tuple).row_type.schema\n+\n+\n+def schema_from_element_type(element_type):  # (type) -> schema_pb2.Schema\n+  \"\"\"Get a schema for the given PCollection element_type.\n+\n+  Returns schema as a list of (name, python_type) tuples\"\"\"\n+  if isinstance(element_type, row_type.RowTypeConstraint):\n+    # TODO: Make sure beam.Row generated schemas are registered and de-duped", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539"}, "originalPosition": 32}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c0c552c841600ecf951d5174790f6fdfec510c33", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/c0c552c841600ecf951d5174790f6fdfec510c33", "committedDate": "2020-08-18T16:51:59Z", "message": "Address PR comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "66d258d22ee7f21b96c7bdcd77f523281773135d", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/66d258d22ee7f21b96c7bdcd77f523281773135d", "committedDate": "2020-08-18T16:52:26Z", "message": "Update DataframeTransform docstring"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "00c5b16afe00cb1a982bd4c90d46b36d465b82a0", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/00c5b16afe00cb1a982bd4c90d46b36d465b82a0", "committedDate": "2020-08-18T16:55:28Z", "message": "lint"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY5NjAxNzg4", "url": "https://github.com/apache/beam/pull/11980#pullrequestreview-469601788", "createdAt": "2020-08-18T16:00:49Z", "commit": {"oid": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539"}, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQxNjowMDo0OVrOHCbXpQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQxNjoxMjoyOFrOHCb0rQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjMwNzYyMQ==", "bodyText": "Done", "url": "https://github.com/apache/beam/pull/11980#discussion_r472307621", "createdAt": "2020-08-18T16:00:49Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/schemas.py", "diffHunk": "@@ -0,0 +1,82 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Utilities for relating schema-aware PCollections and dataframe transforms.\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+from typing import NamedTuple\n+from typing import TypeVar\n+\n+import pandas as pd\n+\n+from apache_beam import typehints\n+from apache_beam.transforms.core import DoFn\n+from apache_beam.transforms.core import ParDo\n+from apache_beam.transforms.util import BatchElements\n+from apache_beam.typehints.schemas import named_fields_from_element_type\n+\n+__all__ = ('BatchRowsAsDataFrame', 'generate_proxy')\n+\n+T = TypeVar('T', bound=NamedTuple)\n+\n+\n+@typehints.with_input_types(T)\n+@typehints.with_output_types(pd.DataFrame)\n+class BatchRowsAsDataFrame(BatchElements):\n+  \"\"\"A transform that batches schema-aware PCollection elements into DataFrames\n+\n+  Batching parameters are inherited from\n+  :class:`~apache_beam.transforms.util.BatchElements`.\n+  \"\"\"\n+  def __init__(self, *args, **kwargs):\n+    super(BatchRowsAsDataFrame, self).__init__(*args, **kwargs)\n+    self._batch_elements_transform = BatchElements(*args, **kwargs)\n+\n+  def expand(self, pcoll):\n+    return super(BatchRowsAsDataFrame, self).expand(pcoll) | ParDo(\n+        _RowBatchToDataFrameDoFn(pcoll.element_type))\n+\n+\n+class _RowBatchToDataFrameDoFn(DoFn):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1MjcwOA=="}, "originalCommit": {"oid": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjMwODM0Ng==", "bodyText": "Done! Looks like I actually started to do it that way with the unused self._batch_elements_transform but then changed my mind", "url": "https://github.com/apache/beam/pull/11980#discussion_r472308346", "createdAt": "2020-08-18T16:01:55Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/schemas.py", "diffHunk": "@@ -0,0 +1,82 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Utilities for relating schema-aware PCollections and dataframe transforms.\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+from typing import NamedTuple\n+from typing import TypeVar\n+\n+import pandas as pd\n+\n+from apache_beam import typehints\n+from apache_beam.transforms.core import DoFn\n+from apache_beam.transforms.core import ParDo\n+from apache_beam.transforms.util import BatchElements\n+from apache_beam.typehints.schemas import named_fields_from_element_type\n+\n+__all__ = ('BatchRowsAsDataFrame', 'generate_proxy')\n+\n+T = TypeVar('T', bound=NamedTuple)\n+\n+\n+@typehints.with_input_types(T)\n+@typehints.with_output_types(pd.DataFrame)\n+class BatchRowsAsDataFrame(BatchElements):\n+  \"\"\"A transform that batches schema-aware PCollection elements into DataFrames\n+\n+  Batching parameters are inherited from\n+  :class:`~apache_beam.transforms.util.BatchElements`.\n+  \"\"\"\n+  def __init__(self, *args, **kwargs):\n+    super(BatchRowsAsDataFrame, self).__init__(*args, **kwargs)\n+    self._batch_elements_transform = BatchElements(*args, **kwargs)\n+\n+  def expand(self, pcoll):\n+    return super(BatchRowsAsDataFrame, self).expand(pcoll) | ParDo(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1MjAxNw=="}, "originalCommit": {"oid": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjMwODQxMg==", "bodyText": "Done", "url": "https://github.com/apache/beam/pull/11980#discussion_r472308412", "createdAt": "2020-08-18T16:02:02Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/schemas.py", "diffHunk": "@@ -0,0 +1,82 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Utilities for relating schema-aware PCollections and dataframe transforms.\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+from typing import NamedTuple\n+from typing import TypeVar\n+\n+import pandas as pd\n+\n+from apache_beam import typehints\n+from apache_beam.transforms.core import DoFn", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1MzU2Nw=="}, "originalCommit": {"oid": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjMwODUzNQ==", "bodyText": "I added a test using to_dataframe in transforms_test: test_batching_beam_row_to_dataframe.\nI intended for these tests to just test schemas.py, while transforms_test verifies the integration with DataframeTransform. The one below was a stepping stone to integrating, we could even remove it now.", "url": "https://github.com/apache/beam/pull/11980#discussion_r472308535", "createdAt": "2020-08-18T16:02:13Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/schemas_test.py", "diffHunk": "@@ -0,0 +1,110 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Tests for schemas.\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import unittest\n+from typing import NamedTuple\n+\n+import future.tests.base  # pylint: disable=unused-import\n+# patches unittest.testcase to be python3 compatible\n+import pandas as pd\n+from past.builtins import unicode\n+\n+import apache_beam as beam\n+from apache_beam.coders import RowCoder\n+from apache_beam.coders.typecoders import registry as coders_registry\n+from apache_beam.dataframe import schemas\n+from apache_beam.dataframe import transforms\n+from apache_beam.testing.test_pipeline import TestPipeline\n+from apache_beam.testing.util import assert_that\n+\n+Simple = NamedTuple(\n+    'Simple', [('name', unicode), ('id', int), ('height', float)])\n+coders_registry.register_coder(Simple, RowCoder)\n+Animal = NamedTuple('Animal', [('animal', unicode), ('max_speed', float)])\n+coders_registry.register_coder(Animal, RowCoder)\n+\n+\n+def matches_df(expected):\n+  def check_df_pcoll_equal(actual):\n+    actual = pd.concat(actual)\n+    sorted_actual = actual.sort_values(by=list(actual.columns)).reset_index(\n+        drop=True)\n+    sorted_expected = expected.sort_values(\n+        by=list(expected.columns)).reset_index(drop=True)\n+    if not sorted_actual.equals(sorted_expected):\n+      raise AssertionError(\n+          'Dataframes not equal: \\n\\nActual:\\n%s\\n\\nExpected:\\n%s' %\n+          (sorted_actual, sorted_expected))\n+\n+  return check_df_pcoll_equal\n+\n+\n+class SchemasTest(unittest.TestCase):\n+  def test_simple_df(self):\n+    expected = pd.DataFrame({\n+        'name': list(unicode(i) for i in range(5)),\n+        'id': list(range(5)),\n+        'height': list(float(i) for i in range(5))\n+    },\n+                            columns=['name', 'id', 'height'])\n+\n+    with TestPipeline() as p:\n+      res = (\n+          p\n+          | beam.Create([\n+              Simple(name=unicode(i), id=i, height=float(i)) for i in range(5)\n+          ])\n+          | schemas.BatchRowsAsDataFrame(min_batch_size=10, max_batch_size=10))\n+      assert_that(res, matches_df(expected))\n+\n+  def test_generate_proxy(self):\n+    expected = pd.DataFrame({\n+        'animal': pd.Series(dtype=unicode), 'max_speed': pd.Series(dtype=float)\n+    })\n+\n+    self.assertTrue(schemas.generate_proxy(Animal).equals(expected))\n+\n+  def test_batch_with_df_transform(self):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1NDQzMw=="}, "originalCommit": {"oid": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjMxMTAyMw==", "bodyText": "Note there's actually a diff here from the original check_correct. It sorts by value and resets the index rather than sorting by index.  I had to do this because the concatenated indices of the batches (e.g. [0,1,2,0,1,0,]) wouldn't match the index in my expected df (e.g. [0,1,2,3,4,5]).", "url": "https://github.com/apache/beam/pull/11980#discussion_r472311023", "createdAt": "2020-08-18T16:06:07Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/transforms_test.py", "diffHunk": "@@ -17,17 +17,61 @@\n from __future__ import absolute_import\n from __future__ import division\n \n+import typing\n import unittest\n \n import pandas as pd\n+from past.builtins import unicode\n \n import apache_beam as beam\n+from apache_beam import coders\n from apache_beam.dataframe import expressions\n from apache_beam.dataframe import frame_base\n from apache_beam.dataframe import transforms\n from apache_beam.testing.util import assert_that\n \n \n+def sort_by_value_and_drop_index(df):\n+  if isinstance(df, pd.DataFrame):\n+    sorted_df = df.sort_values(by=list(df.columns))\n+  else:\n+    sorted_df = df.sort_values()\n+  return sorted_df.reset_index(drop=True)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjMxMTgwNg==", "bodyText": "You and me both :) I just reused the operation from test_filter above. Changed it to Anim.* in both places", "url": "https://github.com/apache/beam/pull/11980#discussion_r472311806", "createdAt": "2020-08-18T16:07:17Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/transforms_test.py", "diffHunk": "@@ -112,6 +133,64 @@ def test_scalar(self):\n       self.run_scenario(\n           df, lambda df: df.groupby('key').sum().val / df.val.agg(sum))\n \n+  def test_batching_named_tuple_input(self):\n+    with beam.Pipeline() as p:\n+      result = (\n+          p | beam.Create([\n+              AnimalSpeed('Aardvark', 5),\n+              AnimalSpeed('Ant', 2),\n+              AnimalSpeed('Elephant', 35),\n+              AnimalSpeed('Zebra', 40)\n+          ]).with_output_types(AnimalSpeed)\n+          | transforms.DataframeTransform(lambda df: df.filter(regex='A.*')))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1Nzk3NA=="}, "originalCommit": {"oid": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539"}, "originalPosition": 123}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjMxNTA1Mw==", "bodyText": "Done", "url": "https://github.com/apache/beam/pull/11980#discussion_r472315053", "createdAt": "2020-08-18T16:12:28Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/pvalue.py", "diffHunk": "@@ -88,7 +88,7 @@ class PValue(object):\n   def __init__(self,\n                pipeline,  # type: Pipeline\n                tag=None,  # type: Optional[str]\n-               element_type=None,  # type: Optional[object]\n+               element_type=None,  # type: Optional[type]", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1ODgwMQ=="}, "originalCommit": {"oid": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDcxMDUwOTk4", "url": "https://github.com/apache/beam/pull/11980#pullrequestreview-471050998", "createdAt": "2020-08-20T00:30:46Z", "commit": {"oid": "00c5b16afe00cb1a982bd4c90d46b36d465b82a0"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4236, "cost": 1, "resetAt": "2021-10-28T16:48:13Z"}}}