{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQ2NDk4NzM1", "number": 12202, "title": "[BEAM-10407,10408] SchemaIOTableProviderWrapper and implementations for Avro and Parquet", "bodyText": "Implemented SchemaIO and SchemaCapableIOProvider for Avro and Parquet, shifting logic to core Beam. Created generalized table and tableprovider wrappers in Beam SQL, implementing for Pubsub, Avro, and Parquet.\nR:@TheNeuralBit\nR:@robinyqiu\n\nPost-Commit Tests Status (on master branch)\n\n\n\nLang\nSDK\nDataflow\nFlink\nSamza\nSpark\nTwister2\n\n\n\n\nGo\n\n---\n\n---\n\n---\n\n\nJava\n\n\n\n\n\n\n\n\nPython\n\n\n\n---\n\n---\n\n\nXLang\n---\n---\n\n---\n\n---\n\n\n\nPre-Commit Tests Status (on master branch)\n\n\n\n---\nJava\nPython\nGo\nWebsite\n\n\n\n\nNon-portable\n\n\n\n\n\n\nPortable\n---\n\n---\n---\n\n\n\nSee .test-infra/jenkins/README for trigger phrase, status and link of all Jenkins jobs.", "createdAt": "2020-07-08T21:38:12Z", "url": "https://github.com/apache/beam/pull/12202", "merged": true, "mergeCommit": {"oid": "33f14ec1b315996b4569b4694a0ff5bf95626f8a"}, "closed": true, "closedAt": "2020-07-22T19:22:30Z", "author": {"login": "sclukas77"}, "timelineItems": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABczEHjAgFqTQ0NTE4NjcyMA==", "endCursor": "Y3Vyc29yOnYyOpPPAAABc3foL2AFqTQ1MzYwMjQ2Ng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ1MTg2NzIw", "url": "https://github.com/apache/beam/pull/12202#pullrequestreview-445186720", "createdAt": "2020-07-08T23:06:38Z", "commit": {"oid": "60394123a7b9fd1a44b8c9c4860a489d0f911eda"}, "state": "COMMENTED", "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOFQyMzowNjozOFrOGu8IPw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQwMDo0MToyN1rOGu9zsg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTg3MjgzMQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            @AutoService(TableProvider.class)\n          \n          \n            \n            public abstract class SchemaCapableIOTableProviderWrapper extends InMemoryMetaTableProvider {\n          \n          \n            \n            abstract class SchemaCapableIOTableProviderWrapper extends InMemoryMetaTableProvider {\n          \n      \n    \n    \n  \n\nI think this AutoService annotation is what's causing the Java PreCommit to fail. The AutoService annotation makes it so that a call ServiceLoader.load(TableProvider.class) will try to instantiate this class if it's in the classpath, and it's not possible to instantiate this since its abstract.\nSpecifically this is the ServiceLoader call that's biting you:\n\n  \n    \n      beam/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/BeamCalciteSchemaFactory.java\n    \n    \n        Lines 85 to 86\n      in\n      1a260cd\n    \n    \n    \n    \n\n        \n          \n           for (TableProvider provider : \n        \n\n        \n          \n               ServiceLoader.load(TableProvider.class, getClass().getClassLoader())) { \n        \n    \n  \n\n\nI think we should also make this package-private", "url": "https://github.com/apache/beam/pull/12202#discussion_r451872831", "createdAt": "2020-07-08T23:06:38Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/SchemaCapableIOTableProviderWrapper.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.meta.provider;\n+\n+import static org.apache.beam.sdk.util.RowJsonUtils.newObjectMapperWith;\n+\n+import com.alibaba.fastjson.JSONObject;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import com.google.auto.service.AutoService;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.annotations.Internal;\n+import org.apache.beam.sdk.extensions.sql.meta.BeamSqlTable;\n+import org.apache.beam.sdk.extensions.sql.meta.Table;\n+import org.apache.beam.sdk.schemas.io.InvalidConfigurationException;\n+import org.apache.beam.sdk.schemas.io.InvalidSchemaException;\n+import org.apache.beam.sdk.schemas.io.SchemaCapableIOProvider;\n+import org.apache.beam.sdk.schemas.io.SchemaIO;\n+import org.apache.beam.sdk.util.RowJson;\n+import org.apache.beam.sdk.values.Row;\n+\n+/**\n+ * A general {@link TableProvider} for IOs for consumption by Beam SQL.\n+ *\n+ * <p>Can create child classes for IOs to pass {@link #schemaCapableIOProvider} that is specific to\n+ * the IO.\n+ */\n+@Internal\n+@Experimental\n+@AutoService(TableProvider.class)\n+public abstract class SchemaCapableIOTableProviderWrapper extends InMemoryMetaTableProvider {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "60394123a7b9fd1a44b8c9c4860a489d0f911eda"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTg4OTg4Ng==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            public class SchemaIOTableWrapper extends BaseBeamTable implements Serializable {\n          \n          \n            \n            class SchemaIOTableWrapper extends BaseBeamTable implements Serializable {\n          \n      \n    \n    \n  \n\nI think this can be package-private. It might also make sense to make it an inner class of SchemaIOTableProviderWrapper, but I'll leave that up to you", "url": "https://github.com/apache/beam/pull/12202#discussion_r451889886", "createdAt": "2020-07-09T00:03:06Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/SchemaIOTableWrapper.java", "diffHunk": "@@ -15,54 +15,63 @@\n  * See the License for the specific language governing permissions and\n  * limitations under the License.\n  */\n-package org.apache.beam.sdk.extensions.sql.meta.provider.parquet;\n+package org.apache.beam.sdk.extensions.sql.meta.provider;\n \n import java.io.Serializable;\n-import org.apache.avro.generic.GenericRecord;\n+\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.annotations.Internal;\n import org.apache.beam.sdk.extensions.sql.impl.BeamTableStatistics;\n-import org.apache.beam.sdk.extensions.sql.meta.BeamSqlTable;\n-import org.apache.beam.sdk.extensions.sql.meta.SchemaBaseBeamTable;\n-import org.apache.beam.sdk.io.parquet.ParquetIO;\n+import org.apache.beam.sdk.extensions.sql.meta.BaseBeamTable;\n+import org.apache.beam.sdk.extensions.sql.meta.Table;\n import org.apache.beam.sdk.options.PipelineOptions;\n import org.apache.beam.sdk.schemas.Schema;\n-import org.apache.beam.sdk.schemas.utils.AvroUtils;\n+import org.apache.beam.sdk.schemas.io.SchemaIO;\n import org.apache.beam.sdk.transforms.PTransform;\n import org.apache.beam.sdk.values.PBegin;\n import org.apache.beam.sdk.values.PCollection;\n-import org.apache.beam.sdk.values.PDone;\n+import org.apache.beam.sdk.values.POutput;\n import org.apache.beam.sdk.values.Row;\n+@Internal\n+@Experimental\n+/**\n+ * A generalized {@link Table} for IOs to create IO readers and writers.\n+ */\n+public class SchemaIOTableWrapper extends BaseBeamTable implements Serializable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "60394123a7b9fd1a44b8c9c4860a489d0f911eda"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTg5NTI5MQ==", "bodyText": "Hmm this is actually something that will need to be different for each IO. Parquet and Avro are both bounded data sources, while pubsub is unbounded.\nCan you add this to the SchemaIO interface and plumb it through here?", "url": "https://github.com/apache/beam/pull/12202#discussion_r451895291", "createdAt": "2020-07-09T00:22:07Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/SchemaIOTableWrapper.java", "diffHunk": "@@ -15,54 +15,63 @@\n  * See the License for the specific language governing permissions and\n  * limitations under the License.\n  */\n-package org.apache.beam.sdk.extensions.sql.meta.provider.parquet;\n+package org.apache.beam.sdk.extensions.sql.meta.provider;\n \n import java.io.Serializable;\n-import org.apache.avro.generic.GenericRecord;\n+\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.annotations.Internal;\n import org.apache.beam.sdk.extensions.sql.impl.BeamTableStatistics;\n-import org.apache.beam.sdk.extensions.sql.meta.BeamSqlTable;\n-import org.apache.beam.sdk.extensions.sql.meta.SchemaBaseBeamTable;\n-import org.apache.beam.sdk.io.parquet.ParquetIO;\n+import org.apache.beam.sdk.extensions.sql.meta.BaseBeamTable;\n+import org.apache.beam.sdk.extensions.sql.meta.Table;\n import org.apache.beam.sdk.options.PipelineOptions;\n import org.apache.beam.sdk.schemas.Schema;\n-import org.apache.beam.sdk.schemas.utils.AvroUtils;\n+import org.apache.beam.sdk.schemas.io.SchemaIO;\n import org.apache.beam.sdk.transforms.PTransform;\n import org.apache.beam.sdk.values.PBegin;\n import org.apache.beam.sdk.values.PCollection;\n-import org.apache.beam.sdk.values.PDone;\n+import org.apache.beam.sdk.values.POutput;\n import org.apache.beam.sdk.values.Row;\n+@Internal\n+@Experimental\n+/**\n+ * A generalized {@link Table} for IOs to create IO readers and writers.\n+ */\n+public class SchemaIOTableWrapper extends BaseBeamTable implements Serializable {\n+  protected final SchemaIO schemaIO;\n \n-/** {@link ParquetTable} is a {@link BeamSqlTable}. */\n-public class ParquetTable extends SchemaBaseBeamTable implements Serializable {\n-  private final String filePattern;\n+  private SchemaIOTableWrapper(SchemaIO schemaIO) {\n+    this.schemaIO = schemaIO;\n+  }\n \n-  public ParquetTable(Schema beamSchema, String filePattern) {\n-    super(beamSchema);\n-    this.filePattern = filePattern;\n+  static SchemaIOTableWrapper fromSchemaIO(SchemaIO schemaIO) {\n+    return new SchemaIOTableWrapper(schemaIO);\n   }\n \n   @Override\n-  public PCollection<Row> buildIOReader(PBegin begin) {\n-    PTransform<PCollection<GenericRecord>, PCollection<Row>> readConverter =\n-        GenericRecordReadConverter.builder().beamSchema(schema).build();\n+  public PCollection.IsBounded isBounded() {\n+    return PCollection.IsBounded.UNBOUNDED;\n+  }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "60394123a7b9fd1a44b8c9c4860a489d0f911eda"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTg5NTYyOA==", "bodyText": "This will also need to be different for avro/parquet vs. pubsub. It could just be determined from the same method on SchemaIO", "url": "https://github.com/apache/beam/pull/12202#discussion_r451895628", "createdAt": "2020-07-09T00:23:22Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/SchemaIOTableWrapper.java", "diffHunk": "@@ -15,54 +15,63 @@\n  * See the License for the specific language governing permissions and\n  * limitations under the License.\n  */\n-package org.apache.beam.sdk.extensions.sql.meta.provider.parquet;\n+package org.apache.beam.sdk.extensions.sql.meta.provider;\n \n import java.io.Serializable;\n-import org.apache.avro.generic.GenericRecord;\n+\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.annotations.Internal;\n import org.apache.beam.sdk.extensions.sql.impl.BeamTableStatistics;\n-import org.apache.beam.sdk.extensions.sql.meta.BeamSqlTable;\n-import org.apache.beam.sdk.extensions.sql.meta.SchemaBaseBeamTable;\n-import org.apache.beam.sdk.io.parquet.ParquetIO;\n+import org.apache.beam.sdk.extensions.sql.meta.BaseBeamTable;\n+import org.apache.beam.sdk.extensions.sql.meta.Table;\n import org.apache.beam.sdk.options.PipelineOptions;\n import org.apache.beam.sdk.schemas.Schema;\n-import org.apache.beam.sdk.schemas.utils.AvroUtils;\n+import org.apache.beam.sdk.schemas.io.SchemaIO;\n import org.apache.beam.sdk.transforms.PTransform;\n import org.apache.beam.sdk.values.PBegin;\n import org.apache.beam.sdk.values.PCollection;\n-import org.apache.beam.sdk.values.PDone;\n+import org.apache.beam.sdk.values.POutput;\n import org.apache.beam.sdk.values.Row;\n+@Internal\n+@Experimental\n+/**\n+ * A generalized {@link Table} for IOs to create IO readers and writers.\n+ */\n+public class SchemaIOTableWrapper extends BaseBeamTable implements Serializable {\n+  protected final SchemaIO schemaIO;\n \n-/** {@link ParquetTable} is a {@link BeamSqlTable}. */\n-public class ParquetTable extends SchemaBaseBeamTable implements Serializable {\n-  private final String filePattern;\n+  private SchemaIOTableWrapper(SchemaIO schemaIO) {\n+    this.schemaIO = schemaIO;\n+  }\n \n-  public ParquetTable(Schema beamSchema, String filePattern) {\n-    super(beamSchema);\n-    this.filePattern = filePattern;\n+  static SchemaIOTableWrapper fromSchemaIO(SchemaIO schemaIO) {\n+    return new SchemaIOTableWrapper(schemaIO);\n   }\n \n   @Override\n-  public PCollection<Row> buildIOReader(PBegin begin) {\n-    PTransform<PCollection<GenericRecord>, PCollection<Row>> readConverter =\n-        GenericRecordReadConverter.builder().beamSchema(schema).build();\n+  public PCollection.IsBounded isBounded() {\n+    return PCollection.IsBounded.UNBOUNDED;\n+  }\n \n-    return begin\n-        .apply(\"ParquetIORead\", ParquetIO.read(AvroUtils.toAvroSchema(schema)).from(filePattern))\n-        .apply(\"GenericRecordToRow\", readConverter);\n+  @Override\n+  public Schema getSchema() {\n+    return schemaIO.schema();\n   }\n \n   @Override\n-  public PDone buildIOWriter(PCollection<Row> input) {\n-    throw new UnsupportedOperationException(\"Writing to a Parquet file is not supported\");\n+  public PCollection<Row> buildIOReader(PBegin begin) {\n+    PTransform<PBegin, PCollection<Row>> readerTransform = schemaIO.buildReader();\n+    return begin.apply(readerTransform);\n   }\n \n   @Override\n-  public PCollection.IsBounded isBounded() {\n-    return PCollection.IsBounded.BOUNDED;\n+  public POutput buildIOWriter(PCollection<Row> input) {\n+    PTransform<PCollection<Row>, POutput> writerTransform = schemaIO.buildWriter();\n+    return input.apply(writerTransform);\n   }\n \n   @Override\n   public BeamTableStatistics getTableStatistics(PipelineOptions options) {\n-    return BeamTableStatistics.BOUNDED_UNKNOWN;\n+    return BeamTableStatistics.UNBOUNDED_UNKNOWN;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "60394123a7b9fd1a44b8c9c4860a489d0f911eda"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTg5NjU3MA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            @Internal\n          \n          \n            \n            @Experimental\n          \n          \n            \n            public class AvroTableProvider extends SchemaCapableIOTableProviderWrapper {\n          \n          \n            \n            @AutoService(TableProvider.class)\n          \n          \n            \n            public class AvroTableProvider extends SchemaCapableIOTableProviderWrapper {\n          \n      \n    \n    \n  \n\nWe can keep these annotations the same as they were, since this class should work exactly the same as it used to from the user perspective.", "url": "https://github.com/apache/beam/pull/12202#discussion_r451896570", "createdAt": "2020-07-09T00:26:56Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/avro/AvroTableProvider.java", "diffHunk": "@@ -38,15 +42,10 @@\n  * LOCATION '/tmp/persons.avro'\n  * }</pre>\n  */\n-@AutoService(TableProvider.class)\n-public class AvroTableProvider extends InMemoryMetaTableProvider {\n-  @Override\n-  public String getTableType() {\n-    return \"avro\";\n-  }\n-\n-  @Override\n-  public BeamSqlTable buildBeamSqlTable(Table table) {\n-    return new AvroTable(table.getName(), table.getSchema(), table.getLocation());\n+@Internal\n+@Experimental\n+public class AvroTableProvider extends SchemaCapableIOTableProviderWrapper {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "60394123a7b9fd1a44b8c9c4860a489d0f911eda"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTg5NzEwMw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            @Internal\n          \n          \n            \n            @Experimental\n          \n          \n            \n            public class ParquetTableProvider extends SchemaCapableIOTableProviderWrapper {\n          \n          \n            \n            @AutoService(TableProvider.class)\n          \n          \n            \n            public class ParquetTableProvider extends SchemaCapableIOTableProviderWrapper {\n          \n      \n    \n    \n  \n\nHere as well", "url": "https://github.com/apache/beam/pull/12202#discussion_r451897103", "createdAt": "2020-07-09T00:29:00Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/parquet/ParquetTableProvider.java", "diffHunk": "@@ -38,15 +42,10 @@\n  * LOCATION '/home/admin/users.parquet'\n  * }</pre>\n  */\n-@AutoService(TableProvider.class)\n-public class ParquetTableProvider extends InMemoryMetaTableProvider {\n-  @Override\n-  public String getTableType() {\n-    return \"parquet\";\n-  }\n-\n-  @Override\n-  public BeamSqlTable buildBeamSqlTable(Table table) {\n-    return new ParquetTable(table.getSchema(), table.getLocation());\n+@Internal\n+@Experimental\n+public class ParquetTableProvider extends SchemaCapableIOTableProviderWrapper {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "60394123a7b9fd1a44b8c9c4860a489d0f911eda"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTg5ODM3Ng==", "bodyText": "Can you make this class package-private? Users may be more tempted to use it now that it's outside of the SQL extensions.\nThis could be a generally useful transform, we may want to move it outside of the parquet package and make it public... but let's not do that now.", "url": "https://github.com/apache/beam/pull/12202#discussion_r451898376", "createdAt": "2020-07-09T00:33:54Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/io/parquet/src/main/java/org/apache/beam/sdk/io/parquet/GenericRecordReadConverter.java", "diffHunk": "@@ -15,7 +15,7 @@\n  * See the License for the specific language governing permissions and\n  * limitations under the License.\n  */\n-package org.apache.beam.sdk.extensions.sql.meta.provider.parquet;\n+package org.apache.beam.sdk.io.parquet;\n \n import com.google.auto.value.AutoValue;\n import java.io.Serializable;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "60394123a7b9fd1a44b8c9c4860a489d0f911eda"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTg5OTkwNQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n             * An implementation of {@link SchemaCapableIOProvider} for reading and writing JSON payloads with\n          \n          \n            \n             * {@link AvroIO}.\n          \n          \n            \n             * An implementation of {@link SchemaCapableIOProvider} for reading and writing avro files with\n          \n          \n            \n             * {@link AvroIO}.", "url": "https://github.com/apache/beam/pull/12202#discussion_r451899905", "createdAt": "2020-07-09T00:39:49Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/io/AvroSchemaCapableIOProvider.java", "diffHunk": "@@ -0,0 +1,117 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io;\n+\n+import com.google.auto.service.AutoService;\n+import java.io.Serializable;\n+import org.apache.avro.generic.GenericRecord;\n+import org.apache.beam.sdk.annotations.Internal;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.schemas.io.SchemaCapableIOProvider;\n+import org.apache.beam.sdk.schemas.io.SchemaIO;\n+import org.apache.beam.sdk.schemas.transforms.Convert;\n+import org.apache.beam.sdk.schemas.utils.AvroUtils;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.apache.beam.sdk.values.POutput;\n+import org.apache.beam.sdk.values.Row;\n+\n+/**\n+ * An implementation of {@link SchemaCapableIOProvider} for reading and writing JSON payloads with\n+ * {@link AvroIO}.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "60394123a7b9fd1a44b8c9c4860a489d0f911eda"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTkwMDMzOA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n             * An implementation of {@link SchemaCapableIOProvider} for reading and writing JSON payloads with\n          \n          \n            \n             * {@link ParquetIO}.\n          \n          \n            \n             * An implementation of {@link SchemaCapableIOProvider} for reading and writing parquet files with\n          \n          \n            \n             * {@link ParquetIO}.", "url": "https://github.com/apache/beam/pull/12202#discussion_r451900338", "createdAt": "2020-07-09T00:41:27Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/io/parquet/src/main/java/org/apache/beam/sdk/io/parquet/ParquetSchemaCapableIOProvider.java", "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.parquet;\n+\n+import com.google.auto.service.AutoService;\n+import java.io.Serializable;\n+import org.apache.avro.generic.GenericRecord;\n+import org.apache.beam.sdk.annotations.Internal;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.schemas.io.SchemaCapableIOProvider;\n+import org.apache.beam.sdk.schemas.io.SchemaIO;\n+import org.apache.beam.sdk.schemas.utils.AvroUtils;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.POutput;\n+import org.apache.beam.sdk.values.Row;\n+\n+/**\n+ * An implementation of {@link SchemaCapableIOProvider} for reading and writing JSON payloads with\n+ * {@link ParquetIO}.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "60394123a7b9fd1a44b8c9c4860a489d0f911eda"}, "originalPosition": 36}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c5a10511799f1e23f7ac095ca35c65985ac07811", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/c5a10511799f1e23f7ac095ca35c65985ac07811", "committedDate": "2020-07-14T19:19:31Z", "message": "Merge branch 'SchemaCapableIOTableProviderWrappers' of https://github.com/sclukas77/beam into SchemaCapableIOTableProviderWrappers"}, "afterCommit": {"oid": "803cb161e7482c2b705e82c736a533f48acea983", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/803cb161e7482c2b705e82c736a533f48acea983", "committedDate": "2020-07-14T20:39:00Z", "message": "Resolved merge conflicts"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUxMDAwMTE3", "url": "https://github.com/apache/beam/pull/12202#pullrequestreview-451000117", "createdAt": "2020-07-17T23:18:15Z", "commit": {"oid": "d36671af68a40926bf0a3d2bdddd43579bcbc690"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QyMzoxODoxNlrOGzjdkg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xOFQwMDo0MTowM1rOGzkYWA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjcxMTU3MA==", "bodyText": "Table should be BeamSqlTable here.\nTable is actually a class for config, I think we should rename it to something like TableDefinition later... It is very confusing to me.", "url": "https://github.com/apache/beam/pull/12202#discussion_r456711570", "createdAt": "2020-07-17T23:18:16Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/SchemaCapableIOTableProviderWrapper.java", "diffHunk": "@@ -0,0 +1,132 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.meta.provider;\n+\n+import static org.apache.beam.sdk.util.RowJsonUtils.newObjectMapperWith;\n+\n+import com.alibaba.fastjson.JSONObject;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import java.io.Serializable;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.annotations.Internal;\n+import org.apache.beam.sdk.extensions.sql.impl.BeamTableStatistics;\n+import org.apache.beam.sdk.extensions.sql.meta.BaseBeamTable;\n+import org.apache.beam.sdk.extensions.sql.meta.BeamSqlTable;\n+import org.apache.beam.sdk.extensions.sql.meta.Table;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.schemas.io.InvalidConfigurationException;\n+import org.apache.beam.sdk.schemas.io.InvalidSchemaException;\n+import org.apache.beam.sdk.schemas.io.SchemaIO;\n+import org.apache.beam.sdk.schemas.io.SchemaIOProvider;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.util.RowJson;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.POutput;\n+import org.apache.beam.sdk.values.Row;\n+\n+/**\n+ * A general {@link TableProvider} for IOs for consumption by Beam SQL.\n+ *\n+ * <p>Can create child classes for IOs to pass {@link #getSchemaIOProvider()} that is specific to\n+ * the IO.\n+ */\n+@Internal\n+@Experimental\n+public abstract class SchemaCapableIOTableProviderWrapper extends InMemoryMetaTableProvider\n+    implements Serializable {\n+  public abstract SchemaIOProvider getSchemaIOProvider();\n+\n+  @Override\n+  public String getTableType() {\n+    return getSchemaIOProvider().identifier();\n+  }\n+\n+  @Override\n+  public BeamSqlTable buildBeamSqlTable(Table tableDefinition) {\n+    JSONObject tableProperties = tableDefinition.getProperties();\n+\n+    try {\n+      RowJson.RowJsonDeserializer deserializer =\n+          RowJson.RowJsonDeserializer.forSchema(getSchemaIOProvider().configurationSchema())\n+              .withNullBehavior(RowJson.RowJsonDeserializer.NullBehavior.ACCEPT_MISSING_OR_NULL);\n+\n+      Row configurationRow =\n+          newObjectMapperWith(deserializer).readValue(tableProperties.toString(), Row.class);\n+\n+      SchemaIO schemaIO =\n+          getSchemaIOProvider()\n+              .from(tableDefinition.getLocation(), configurationRow, tableDefinition.getSchema());\n+\n+      return new SchemaIOTableWrapper(schemaIO);\n+    } catch (InvalidConfigurationException | InvalidSchemaException e) {\n+      throw new InvalidTableException(e.getMessage());\n+    } catch (JsonProcessingException e) {\n+      throw new AssertionError(\n+          \"Failed to re-parse TBLPROPERTIES JSON \" + tableProperties.toString());\n+    }\n+  }\n+\n+  private BeamTableStatistics getTableStatistics(PipelineOptions options) {\n+    if (isBounded().equals(PCollection.IsBounded.BOUNDED)) {\n+      return BeamTableStatistics.BOUNDED_UNKNOWN;\n+    }\n+    return BeamTableStatistics.UNBOUNDED_UNKNOWN;\n+  }\n+\n+  private PCollection.IsBounded isBounded() {\n+    return getSchemaIOProvider().isBounded();\n+  }\n+\n+  /** A generalized {@link Table} for IOs to create IO readers and writers. */", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d36671af68a40926bf0a3d2bdddd43579bcbc690"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjcxNDkzOA==", "bodyText": "Please add a TODO with JIRA link here such that people know this override is only a temporary solution, and we can remove it after the issue tracked by that JIRA is fixed. Like\n// TODO[BEAM-?????]: remove this override after TableProvider problem is fixed\n\nAnd we should do the same thing for all classes that extends SchemaCapableIOTableProviderWrapper", "url": "https://github.com/apache/beam/pull/12202#discussion_r456714938", "createdAt": "2020-07-17T23:34:22Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/pubsub/PubsubJsonTableProvider.java", "diffHunk": "@@ -17,63 +17,32 @@\n  */\n package org.apache.beam.sdk.extensions.sql.meta.provider.pubsub;\n \n-import static org.apache.beam.sdk.util.RowJsonUtils.newObjectMapperWith;\n-\n-import com.alibaba.fastjson.JSONObject;\n-import com.fasterxml.jackson.core.JsonProcessingException;\n import com.google.auto.service.AutoService;\n import org.apache.beam.sdk.annotations.Experimental;\n import org.apache.beam.sdk.annotations.Internal;\n-import org.apache.beam.sdk.extensions.sql.meta.BeamSqlTable;\n-import org.apache.beam.sdk.extensions.sql.meta.Table;\n-import org.apache.beam.sdk.extensions.sql.meta.provider.InMemoryMetaTableProvider;\n-import org.apache.beam.sdk.extensions.sql.meta.provider.InvalidTableException;\n+import org.apache.beam.sdk.extensions.sql.meta.provider.SchemaCapableIOTableProviderWrapper;\n import org.apache.beam.sdk.extensions.sql.meta.provider.TableProvider;\n import org.apache.beam.sdk.io.gcp.pubsub.PubsubIO;\n import org.apache.beam.sdk.io.gcp.pubsub.PubsubSchemaCapableIOProvider;\n-import org.apache.beam.sdk.schemas.io.InvalidConfigurationException;\n-import org.apache.beam.sdk.schemas.io.InvalidSchemaException;\n-import org.apache.beam.sdk.schemas.io.SchemaIO;\n-import org.apache.beam.sdk.util.RowJson.RowJsonDeserializer;\n-import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.sdk.schemas.io.SchemaIOProvider;\n \n /**\n- * {@link TableProvider} for {@link PubsubIOJsonTable} which wraps {@link PubsubIO} for consumption\n- * by Beam SQL.\n+ * {@link TableProvider} for {@link PubsubIO} for consumption by Beam SQL.\n+ *\n+ * <p>Passes the {@link PubsubSchemaCapableIOProvider} to the generalized table provider wrapper,\n+ * {@link SchemaCapableIOTableProviderWrapper}, for Pubsub specific behavior.\n  */\n @Internal\n @Experimental\n @AutoService(TableProvider.class)\n-public class PubsubJsonTableProvider extends InMemoryMetaTableProvider {\n-\n+public class PubsubJsonTableProvider extends SchemaCapableIOTableProviderWrapper {\n   @Override\n-  public String getTableType() {\n-    return \"pubsub\";\n+  public SchemaIOProvider getSchemaIOProvider() {\n+    return new PubsubSchemaCapableIOProvider();\n   }\n \n   @Override\n-  public BeamSqlTable buildBeamSqlTable(Table tableDefinition) {\n-    JSONObject tableProperties = tableDefinition.getProperties();\n-    PubsubSchemaCapableIOProvider ioProvider = new PubsubSchemaCapableIOProvider();\n-\n-    try {\n-      RowJsonDeserializer deserializer =\n-          RowJsonDeserializer.forSchema(ioProvider.configurationSchema())\n-              .withNullBehavior(RowJsonDeserializer.NullBehavior.ACCEPT_MISSING_OR_NULL);\n-\n-      Row configurationRow =\n-          newObjectMapperWith(deserializer).readValue(tableProperties.toString(), Row.class);\n-\n-      SchemaIO pubsubSchemaIO =\n-          ioProvider.from(\n-              tableDefinition.getLocation(), configurationRow, tableDefinition.getSchema());\n-\n-      return PubsubIOJsonTable.fromSchemaIO(pubsubSchemaIO);\n-    } catch (InvalidConfigurationException | InvalidSchemaException e) {\n-      throw new InvalidTableException(e.getMessage());\n-    } catch (JsonProcessingException e) {\n-      throw new AssertionError(\n-          \"Failed to re-parse TBLPROPERTIES JSON \" + tableProperties.toString());\n-    }\n+  public String getTableType() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d36671af68a40926bf0a3d2bdddd43579bcbc690"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjcxNTkxOQ==", "bodyText": "We can make this class a static inner class by passing another parameter PCollection.IsBounded isBounded to the constructor and save it. This way we can also remove the 2 helper functions above (getTableStatistics and isBounded).", "url": "https://github.com/apache/beam/pull/12202#discussion_r456715919", "createdAt": "2020-07-17T23:39:35Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/SchemaCapableIOTableProviderWrapper.java", "diffHunk": "@@ -0,0 +1,132 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.meta.provider;\n+\n+import static org.apache.beam.sdk.util.RowJsonUtils.newObjectMapperWith;\n+\n+import com.alibaba.fastjson.JSONObject;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import java.io.Serializable;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.annotations.Internal;\n+import org.apache.beam.sdk.extensions.sql.impl.BeamTableStatistics;\n+import org.apache.beam.sdk.extensions.sql.meta.BaseBeamTable;\n+import org.apache.beam.sdk.extensions.sql.meta.BeamSqlTable;\n+import org.apache.beam.sdk.extensions.sql.meta.Table;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.schemas.io.InvalidConfigurationException;\n+import org.apache.beam.sdk.schemas.io.InvalidSchemaException;\n+import org.apache.beam.sdk.schemas.io.SchemaIO;\n+import org.apache.beam.sdk.schemas.io.SchemaIOProvider;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.util.RowJson;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.POutput;\n+import org.apache.beam.sdk.values.Row;\n+\n+/**\n+ * A general {@link TableProvider} for IOs for consumption by Beam SQL.\n+ *\n+ * <p>Can create child classes for IOs to pass {@link #getSchemaIOProvider()} that is specific to\n+ * the IO.\n+ */\n+@Internal\n+@Experimental\n+public abstract class SchemaCapableIOTableProviderWrapper extends InMemoryMetaTableProvider\n+    implements Serializable {\n+  public abstract SchemaIOProvider getSchemaIOProvider();\n+\n+  @Override\n+  public String getTableType() {\n+    return getSchemaIOProvider().identifier();\n+  }\n+\n+  @Override\n+  public BeamSqlTable buildBeamSqlTable(Table tableDefinition) {\n+    JSONObject tableProperties = tableDefinition.getProperties();\n+\n+    try {\n+      RowJson.RowJsonDeserializer deserializer =\n+          RowJson.RowJsonDeserializer.forSchema(getSchemaIOProvider().configurationSchema())\n+              .withNullBehavior(RowJson.RowJsonDeserializer.NullBehavior.ACCEPT_MISSING_OR_NULL);\n+\n+      Row configurationRow =\n+          newObjectMapperWith(deserializer).readValue(tableProperties.toString(), Row.class);\n+\n+      SchemaIO schemaIO =\n+          getSchemaIOProvider()\n+              .from(tableDefinition.getLocation(), configurationRow, tableDefinition.getSchema());\n+\n+      return new SchemaIOTableWrapper(schemaIO);\n+    } catch (InvalidConfigurationException | InvalidSchemaException e) {\n+      throw new InvalidTableException(e.getMessage());\n+    } catch (JsonProcessingException e) {\n+      throw new AssertionError(\n+          \"Failed to re-parse TBLPROPERTIES JSON \" + tableProperties.toString());\n+    }\n+  }\n+\n+  private BeamTableStatistics getTableStatistics(PipelineOptions options) {\n+    if (isBounded().equals(PCollection.IsBounded.BOUNDED)) {\n+      return BeamTableStatistics.BOUNDED_UNKNOWN;\n+    }\n+    return BeamTableStatistics.UNBOUNDED_UNKNOWN;\n+  }\n+\n+  private PCollection.IsBounded isBounded() {\n+    return getSchemaIOProvider().isBounded();\n+  }\n+\n+  /** A generalized {@link Table} for IOs to create IO readers and writers. */\n+  private class SchemaIOTableWrapper extends BaseBeamTable {\n+    protected final SchemaIO schemaIO;\n+\n+    private SchemaIOTableWrapper(SchemaIO schemaIO) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d36671af68a40926bf0a3d2bdddd43579bcbc690"}, "originalPosition": 101}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjcxNjQ1Ng==", "bodyText": "This line of comment belongs better as getSchemaIOProvider() method comment. Like:\n// Subclasses should provide the schemaIOProvider that is specific to its IO.\npublic abstract SchemaIOProvider getSchemaIOProvider();", "url": "https://github.com/apache/beam/pull/12202#discussion_r456716456", "createdAt": "2020-07-17T23:42:24Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/SchemaCapableIOTableProviderWrapper.java", "diffHunk": "@@ -0,0 +1,132 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.meta.provider;\n+\n+import static org.apache.beam.sdk.util.RowJsonUtils.newObjectMapperWith;\n+\n+import com.alibaba.fastjson.JSONObject;\n+import com.fasterxml.jackson.core.JsonProcessingException;\n+import java.io.Serializable;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.annotations.Internal;\n+import org.apache.beam.sdk.extensions.sql.impl.BeamTableStatistics;\n+import org.apache.beam.sdk.extensions.sql.meta.BaseBeamTable;\n+import org.apache.beam.sdk.extensions.sql.meta.BeamSqlTable;\n+import org.apache.beam.sdk.extensions.sql.meta.Table;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.schemas.io.InvalidConfigurationException;\n+import org.apache.beam.sdk.schemas.io.InvalidSchemaException;\n+import org.apache.beam.sdk.schemas.io.SchemaIO;\n+import org.apache.beam.sdk.schemas.io.SchemaIOProvider;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.util.RowJson;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.POutput;\n+import org.apache.beam.sdk.values.Row;\n+\n+/**\n+ * A general {@link TableProvider} for IOs for consumption by Beam SQL.\n+ *\n+ * <p>Can create child classes for IOs to pass {@link #getSchemaIOProvider()} that is specific to", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d36671af68a40926bf0a3d2bdddd43579bcbc690"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjcyMDcyNw==", "bodyText": "Duplicate comment here.", "url": "https://github.com/apache/beam/pull/12202#discussion_r456720727", "createdAt": "2020-07-18T00:04:11Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/parquet/ParquetTableProvider.java", "diffHunk": "@@ -18,13 +18,20 @@\n package org.apache.beam.sdk.extensions.sql.meta.provider.parquet;\n \n import com.google.auto.service.AutoService;\n-import org.apache.beam.sdk.extensions.sql.meta.BeamSqlTable;\n-import org.apache.beam.sdk.extensions.sql.meta.Table;\n-import org.apache.beam.sdk.extensions.sql.meta.provider.InMemoryMetaTableProvider;\n+import org.apache.beam.sdk.extensions.sql.meta.provider.SchemaCapableIOTableProviderWrapper;\n import org.apache.beam.sdk.extensions.sql.meta.provider.TableProvider;\n+import org.apache.beam.sdk.io.parquet.ParquetIO;\n+import org.apache.beam.sdk.io.parquet.ParquetSchemaCapableIOProvider;\n+import org.apache.beam.sdk.schemas.io.SchemaIOProvider;\n \n /**\n- * {@link TableProvider} for {@link ParquetTable}.\n+ * {@link TableProvider} for {@link ParquetIO} for consumption by Beam SQL.\n+ *\n+ * <p>Passes the {@link ParquetSchemaCapableIOProvider} to the generalized table provider wrapper,\n+ * {@link SchemaCapableIOTableProviderWrapper}, for Parquet specific behavior.\n+ *\n+ * <p>Passes the {@link ParquetSchemaCapableIOProvider} to the generalized table provider wrapper,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d36671af68a40926bf0a3d2bdddd43579bcbc690"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjcyMTYyOA==", "bodyText": "@Internal not necessary here. Please check in other places as well.", "url": "https://github.com/apache/beam/pull/12202#discussion_r456721628", "createdAt": "2020-07-18T00:09:23Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/io/parquet/src/main/java/org/apache/beam/sdk/io/parquet/ParquetSchemaCapableIOProvider.java", "diffHunk": "@@ -0,0 +1,113 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.parquet;\n+\n+import com.google.auto.service.AutoService;\n+import java.io.Serializable;\n+import org.apache.avro.generic.GenericRecord;\n+import org.apache.beam.sdk.annotations.Internal;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.schemas.io.SchemaIO;\n+import org.apache.beam.sdk.schemas.io.SchemaIOProvider;\n+import org.apache.beam.sdk.schemas.utils.AvroUtils;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.POutput;\n+import org.apache.beam.sdk.values.Row;\n+\n+/**\n+ * An implementation of {@link SchemaIOProvider} for reading and writing parquet files with {@link\n+ * ParquetIO}.\n+ */\n+@Internal\n+@AutoService(SchemaIOProvider.class)\n+public class ParquetSchemaCapableIOProvider implements SchemaIOProvider {\n+  /** Returns an id that uniquely represents this IO. */\n+  @Override\n+  public String identifier() {\n+    return \"parquet\";\n+  }\n+\n+  /**\n+   * Returns the expected schema of the configuration object. Note this is distinct from the schema\n+   * of the data source itself. No configuration expected for parquet.\n+   */\n+  @Override\n+  public Schema configurationSchema() {\n+    return Schema.builder().build();\n+  }\n+\n+  /**\n+   * Produce a SchemaIO given a String representing the data's location, the schema of the data that\n+   * resides there, and some IO-specific configuration object.\n+   */\n+  @Override\n+  public ParquetSchemaIO from(String location, Row configuration, Schema dataSchema) {\n+    return new ParquetSchemaIO(location, dataSchema);\n+  }\n+\n+  @Override\n+  public boolean requiresDataSchema() {\n+    return true;\n+  }\n+\n+  @Override\n+  public PCollection.IsBounded isBounded() {\n+    return PCollection.IsBounded.BOUNDED;\n+  }\n+\n+  /** An abstraction to create schema aware IOs. */\n+  @Internal", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d36671af68a40926bf0a3d2bdddd43579bcbc690"}, "originalPosition": 76}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjcyMzQ2NA==", "bodyText": "This file is moved to the core module, I believe you want to move it to the io module?", "url": "https://github.com/apache/beam/pull/12202#discussion_r456723464", "createdAt": "2020-07-18T00:20:23Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/io/GenericRecordWriteConverter.java", "diffHunk": "@@ -15,7 +15,7 @@\n  * See the License for the specific language governing permissions and\n  * limitations under the License.\n  */\n-package org.apache.beam.sdk.extensions.sql.meta.provider.avro;\n+package org.apache.beam.sdk.io;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d36671af68a40926bf0a3d2bdddd43579bcbc690"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjcyNjYxNg==", "bodyText": "This PR changes the behavior of this line, from setting the second parameter using table name to null. How will this affect the behavior of AvroIO?", "url": "https://github.com/apache/beam/pull/12202#discussion_r456726616", "createdAt": "2020-07-18T00:41:03Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/io/AvroSchemaCapableIOProvider.java", "diffHunk": "@@ -0,0 +1,127 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io;\n+\n+import com.google.auto.service.AutoService;\n+import java.io.Serializable;\n+import org.apache.avro.generic.GenericRecord;\n+import org.apache.beam.sdk.annotations.Internal;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.schemas.io.SchemaIO;\n+import org.apache.beam.sdk.schemas.io.SchemaIOProvider;\n+import org.apache.beam.sdk.schemas.transforms.Convert;\n+import org.apache.beam.sdk.schemas.utils.AvroUtils;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PDone;\n+import org.apache.beam.sdk.values.POutput;\n+import org.apache.beam.sdk.values.Row;\n+\n+/**\n+ * An implementation of {@link SchemaIOProvider} for reading and writing Avro files with {@link\n+ * AvroIO}.\n+ */\n+@Internal\n+@AutoService(SchemaIOProvider.class)\n+public class AvroSchemaCapableIOProvider implements SchemaIOProvider {\n+  /** Returns an id that uniquely represents this IO. */\n+  @Override\n+  public String identifier() {\n+    return \"avro\";\n+  }\n+\n+  /**\n+   * Returns the expected schema of the configuration object. Note this is distinct from the schema\n+   * of the data source itself. No configuration expected for Avro.\n+   */\n+  @Override\n+  public Schema configurationSchema() {\n+    return Schema.builder().build();\n+  }\n+\n+  /**\n+   * Produce a SchemaIO given a String representing the data's location, the schema of the data that\n+   * resides there, and some IO-specific configuration object.\n+   */\n+  @Override\n+  public AvroSchemaIO from(String location, Row configuration, Schema dataSchema) {\n+    return new AvroSchemaIO(location, dataSchema);\n+  }\n+\n+  @Override\n+  public boolean requiresDataSchema() {\n+    return true;\n+  }\n+\n+  @Override\n+  public PCollection.IsBounded isBounded() {\n+    return PCollection.IsBounded.BOUNDED;\n+  }\n+\n+  /** An abstraction to create schema aware IOs. */\n+  @Internal\n+  private static class AvroSchemaIO implements SchemaIO, Serializable {\n+    protected final Schema dataSchema;\n+    protected final String location;\n+\n+    private AvroSchemaIO(String location, Schema dataSchema) {\n+      this.dataSchema = dataSchema;\n+      this.location = location;\n+    }\n+\n+    @Override\n+    public Schema schema() {\n+      return dataSchema;\n+    }\n+\n+    @Override\n+    public PTransform<PBegin, PCollection<Row>> buildReader() {\n+      return new PTransform<PBegin, PCollection<Row>>() {\n+        @Override\n+        public PCollection<Row> expand(PBegin begin) {\n+          return begin\n+              .apply(\n+                  \"AvroIORead\",\n+                  AvroIO.readGenericRecords(AvroUtils.toAvroSchema(dataSchema, null, null))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d36671af68a40926bf0a3d2bdddd43579bcbc690"}, "originalPosition": 101}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "90855dff7ce526f96332a74a9487f7240822ee06", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/90855dff7ce526f96332a74a9487f7240822ee06", "committedDate": "2020-07-20T20:18:01Z", "message": "Added TODO comments"}, "afterCommit": {"oid": "3df7054a2e7a81049a51ddf6a1d183dd99917c17", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/3df7054a2e7a81049a51ddf6a1d183dd99917c17", "committedDate": "2020-07-20T20:47:57Z", "message": "Added TODO comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUyNTk0OTc1", "url": "https://github.com/apache/beam/pull/12202#pullrequestreview-452594975", "createdAt": "2020-07-21T15:48:41Z", "commit": {"oid": "3df7054a2e7a81049a51ddf6a1d183dd99917c17"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQxNTo0ODo0MlrOG0-c_Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQxNTo0ODo0MlrOG0-c_Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODIwMjM2NQ==", "bodyText": "could you remove the \"Capable\" from all of these class names now that we've switched to SchemaIOProvider?", "url": "https://github.com/apache/beam/pull/12202#discussion_r458202365", "createdAt": "2020-07-21T15:48:42Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/io/parquet/src/main/java/org/apache/beam/sdk/io/parquet/ParquetSchemaCapableIOProvider.java", "diffHunk": "@@ -0,0 +1,112 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.parquet;\n+\n+import com.google.auto.service.AutoService;\n+import java.io.Serializable;\n+import org.apache.avro.generic.GenericRecord;\n+import org.apache.beam.sdk.annotations.Internal;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.schemas.io.SchemaIO;\n+import org.apache.beam.sdk.schemas.io.SchemaIOProvider;\n+import org.apache.beam.sdk.schemas.utils.AvroUtils;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.POutput;\n+import org.apache.beam.sdk.values.Row;\n+\n+/**\n+ * An implementation of {@link SchemaIOProvider} for reading and writing parquet files with {@link\n+ * ParquetIO}.\n+ */\n+@Internal\n+@AutoService(SchemaIOProvider.class)\n+public class ParquetSchemaCapableIOProvider implements SchemaIOProvider {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3df7054a2e7a81049a51ddf6a1d183dd99917c17"}, "originalPosition": 40}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUzMDUwODQz", "url": "https://github.com/apache/beam/pull/12202#pullrequestreview-453050843", "createdAt": "2020-07-22T07:12:35Z", "commit": {"oid": "7336db169937854d4b49fde1d7c26ab2cedf9050"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2045d930e0fb60e4e7234117658131b499847cf8", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/2045d930e0fb60e4e7234117658131b499847cf8", "committedDate": "2020-07-22T15:57:15Z", "message": "Added SchemaIOTableProviderWrapper, used for PubsubJsonTableProvider"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6c2aed710320a0c918feb3c8c0e9f6b7e5c6c073", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/6c2aed710320a0c918feb3c8c0e9f6b7e5c6c073", "committedDate": "2020-07-22T17:14:42Z", "message": "Implemented SchemaIO and SchemaIOProvider for Avro"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bd915c7af479620a94d823b9219112885f7c80b4", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/bd915c7af479620a94d823b9219112885f7c80b4", "committedDate": "2020-07-22T17:16:29Z", "message": "Implemented SchemaIO and SchemaIOProvider for Parquet"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "7336db169937854d4b49fde1d7c26ab2cedf9050", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/7336db169937854d4b49fde1d7c26ab2cedf9050", "committedDate": "2020-07-21T18:08:04Z", "message": "Removed \"Capable\" from SchemaCapableIOProvider names"}, "afterCommit": {"oid": "bd915c7af479620a94d823b9219112885f7c80b4", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/bd915c7af479620a94d823b9219112885f7c80b4", "committedDate": "2020-07-22T17:16:29Z", "message": "Implemented SchemaIO and SchemaIOProvider for Parquet"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUzNjAyNDY2", "url": "https://github.com/apache/beam/pull/12202#pullrequestreview-453602466", "createdAt": "2020-07-22T19:02:52Z", "commit": {"oid": "bd915c7af479620a94d823b9219112885f7c80b4"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4181, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}