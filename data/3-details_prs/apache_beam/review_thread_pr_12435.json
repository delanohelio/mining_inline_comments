{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDYwMjQ3NzQx", "number": 12435, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQxOTo0NDo0OVrOEV9-LA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQxOTo1NToyOFrOEV-Meg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxNDcwODkyOnYy", "diffSide": "RIGHT", "path": ".test-infra/jenkins/job_LoadTests_ParDo_Python.groovy", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQxOTo0NDo0OVrOG9Bz-g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMFQwNzo0Mjo1OVrOG-ERsQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjY0NjAxMA==", "bodyText": "Are you planning to investigate this now, soon, or in the future? If it isn't something you'll be looking into immediately and there is some additional context related to the timeouts that you've found while testing it would be helpful to create a Jira issue and link it here instead of a TODO for yourself.", "url": "https://github.com/apache/beam/pull/12435#discussion_r466646010", "createdAt": "2020-08-06T19:44:49Z", "author": {"login": "tysonjh"}, "path": ".test-infra/jenkins/job_LoadTests_ParDo_Python.groovy", "diffHunk": "@@ -151,3 +151,35 @@ CronJobBuilder.cronJob('beam_LoadTests_Python_ParDo_Dataflow_Batch', 'H 13 * * *\n   ]\n   batchLoadTestJob(delegate, CommonTestProperties.TriggeringContext.POST_COMMIT)\n }\n+\n+def streamingLoadTestJob = { scope, triggeringContext ->\n+  scope.description('Runs Python ParDo load tests on Dataflow runner in streaming mode')\n+  commonJobProperties.setTopLevelMainJobProperties(scope, 'master', 120)\n+\n+  def datasetName = loadTestsBuilder.getBigQueryDataset('load_test', triggeringContext)\n+  for (testConfiguration in loadTestConfigurations(\"streaming\", datasetName)) {\n+    // Skipping case 2 in streaming because it timeouts. To be checked TODO: kkucharc", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7f811d9f80dc08c27763023d9c1904a977639689"}, "originalPosition": 100}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NzczNDk2MQ==", "bodyText": "It makes sense. I saw several times TODOs with username and I thought this is convention where developers takes responsibility for this TODO. I changed it to issue.", "url": "https://github.com/apache/beam/pull/12435#discussion_r467734961", "createdAt": "2020-08-10T07:42:59Z", "author": {"login": "kkucharc"}, "path": ".test-infra/jenkins/job_LoadTests_ParDo_Python.groovy", "diffHunk": "@@ -151,3 +151,35 @@ CronJobBuilder.cronJob('beam_LoadTests_Python_ParDo_Dataflow_Batch', 'H 13 * * *\n   ]\n   batchLoadTestJob(delegate, CommonTestProperties.TriggeringContext.POST_COMMIT)\n }\n+\n+def streamingLoadTestJob = { scope, triggeringContext ->\n+  scope.description('Runs Python ParDo load tests on Dataflow runner in streaming mode')\n+  commonJobProperties.setTopLevelMainJobProperties(scope, 'master', 120)\n+\n+  def datasetName = loadTestsBuilder.getBigQueryDataset('load_test', triggeringContext)\n+  for (testConfiguration in loadTestConfigurations(\"streaming\", datasetName)) {\n+    // Skipping case 2 in streaming because it timeouts. To be checked TODO: kkucharc", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjY0NjAxMA=="}, "originalCommit": {"oid": "7f811d9f80dc08c27763023d9c1904a977639689"}, "originalPosition": 100}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxNDcyNDc1OnYy", "diffSide": "RIGHT", "path": ".test-infra/jenkins/job_LoadTests_ParDo_Python.groovy", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQxOTo0OToyMFrOG9B9YA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxNzo0NDo1OVrOHE15ZA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjY0ODQxNg==", "bodyText": "This should be a property in the testConfiguration instead of relying on title implicitly? That would also eliminate adding a 'streaming' property below as well.\nIn fact, doing this may also allow refactoring 'batchLoadTestJob' to a more generic 'loadTestJob' for reuse in both Streaming/Batch cases. It may unnecessarily complicate things, I'll leave it up to your judgement.", "url": "https://github.com/apache/beam/pull/12435#discussion_r466648416", "createdAt": "2020-08-06T19:49:20Z", "author": {"login": "tysonjh"}, "path": ".test-infra/jenkins/job_LoadTests_ParDo_Python.groovy", "diffHunk": "@@ -151,3 +151,35 @@ CronJobBuilder.cronJob('beam_LoadTests_Python_ParDo_Dataflow_Batch', 'H 13 * * *\n   ]\n   batchLoadTestJob(delegate, CommonTestProperties.TriggeringContext.POST_COMMIT)\n }\n+\n+def streamingLoadTestJob = { scope, triggeringContext ->\n+  scope.description('Runs Python ParDo load tests on Dataflow runner in streaming mode')\n+  commonJobProperties.setTopLevelMainJobProperties(scope, 'master', 120)\n+\n+  def datasetName = loadTestsBuilder.getBigQueryDataset('load_test', triggeringContext)\n+  for (testConfiguration in loadTestConfigurations(\"streaming\", datasetName)) {\n+    // Skipping case 2 in streaming because it timeouts. To be checked TODO: kkucharc\n+    if(testConfiguration.title != \"ParDo Python Load test: 2GB 100 byte records 200 times\") {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7f811d9f80dc08c27763023d9c1904a977639689"}, "originalPosition": 101}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODgwNzc2OQ==", "bodyText": "I am totally for refactoring those LoadTestJob methods into one. Thank you for suggestion.\nAs it comes to excluding the test, I am usually more for implicit pointing to the test that should be excluded than by pointing ex. index of array (maybe because that index can change in case of adding new test cases).", "url": "https://github.com/apache/beam/pull/12435#discussion_r468807769", "createdAt": "2020-08-11T19:15:00Z", "author": {"login": "kkucharc"}, "path": ".test-infra/jenkins/job_LoadTests_ParDo_Python.groovy", "diffHunk": "@@ -151,3 +151,35 @@ CronJobBuilder.cronJob('beam_LoadTests_Python_ParDo_Dataflow_Batch', 'H 13 * * *\n   ]\n   batchLoadTestJob(delegate, CommonTestProperties.TriggeringContext.POST_COMMIT)\n }\n+\n+def streamingLoadTestJob = { scope, triggeringContext ->\n+  scope.description('Runs Python ParDo load tests on Dataflow runner in streaming mode')\n+  commonJobProperties.setTopLevelMainJobProperties(scope, 'master', 120)\n+\n+  def datasetName = loadTestsBuilder.getBigQueryDataset('load_test', triggeringContext)\n+  for (testConfiguration in loadTestConfigurations(\"streaming\", datasetName)) {\n+    // Skipping case 2 in streaming because it timeouts. To be checked TODO: kkucharc\n+    if(testConfiguration.title != \"ParDo Python Load test: 2GB 100 byte records 200 times\") {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjY0ODQxNg=="}, "originalCommit": {"oid": "7f811d9f80dc08c27763023d9c1904a977639689"}, "originalPosition": 101}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDgzOTM5Ng==", "bodyText": "Hm, good point. I just reviewed @kamilwu PR#12612 and was a bit uneasy that it used indices for ignoring tests but didn't make a comment. Maybe it is worth updating that PR follow this approach instead for the reasons you mention and uniformity.", "url": "https://github.com/apache/beam/pull/12435#discussion_r474839396", "createdAt": "2020-08-21T17:44:59Z", "author": {"login": "tysonjh"}, "path": ".test-infra/jenkins/job_LoadTests_ParDo_Python.groovy", "diffHunk": "@@ -151,3 +151,35 @@ CronJobBuilder.cronJob('beam_LoadTests_Python_ParDo_Dataflow_Batch', 'H 13 * * *\n   ]\n   batchLoadTestJob(delegate, CommonTestProperties.TriggeringContext.POST_COMMIT)\n }\n+\n+def streamingLoadTestJob = { scope, triggeringContext ->\n+  scope.description('Runs Python ParDo load tests on Dataflow runner in streaming mode')\n+  commonJobProperties.setTopLevelMainJobProperties(scope, 'master', 120)\n+\n+  def datasetName = loadTestsBuilder.getBigQueryDataset('load_test', triggeringContext)\n+  for (testConfiguration in loadTestConfigurations(\"streaming\", datasetName)) {\n+    // Skipping case 2 in streaming because it timeouts. To be checked TODO: kkucharc\n+    if(testConfiguration.title != \"ParDo Python Load test: 2GB 100 byte records 200 times\") {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjY0ODQxNg=="}, "originalCommit": {"oid": "7f811d9f80dc08c27763023d9c1904a977639689"}, "originalPosition": 101}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkxNDc0NTU0OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/testing/load_tests/pardo_test.py", "isResolved": false, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQxOTo1NToyOFrOG9CJvg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxMjowNToyM1rOHJAWDA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjY1MTU4Mg==", "bodyText": "Why only for the PortableRunner now?", "url": "https://github.com/apache/beam/pull/12435#discussion_r466651582", "createdAt": "2020-08-06T19:55:28Z", "author": {"login": "tysonjh"}, "path": "sdks/python/apache_beam/testing/load_tests/pardo_test.py", "diffHunk": "@@ -125,7 +125,9 @@ def process(self, element, state=state_param):\n             state.add(1)\n         yield element\n \n-    if self.get_option_or_default('streaming', False):\n+    if self.get_option_or_default(\n+        'streaming',\n+        False) and self.pipeline.get_option('runner') == \"PortableRunner\":", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7f811d9f80dc08c27763023d9c1904a977639689"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODQ2NDcwOA==", "bodyText": "The PortableRunner is supposed to use StatefulLoadGenerator to enable streaming.\nTo be honest I assumed that if we are comparing core operations, we should be using the same source method -  SyntheticSources.\nOn the other hand maybe StatefulLoadGenerator should be part of SyntheticSources. WDYT @tysonjh ?", "url": "https://github.com/apache/beam/pull/12435#discussion_r468464708", "createdAt": "2020-08-11T09:56:55Z", "author": {"login": "kkucharc"}, "path": "sdks/python/apache_beam/testing/load_tests/pardo_test.py", "diffHunk": "@@ -125,7 +125,9 @@ def process(self, element, state=state_param):\n             state.add(1)\n         yield element\n \n-    if self.get_option_or_default('streaming', False):\n+    if self.get_option_or_default(\n+        'streaming',\n+        False) and self.pipeline.get_option('runner') == \"PortableRunner\":", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjY1MTU4Mg=="}, "originalCommit": {"oid": "7f811d9f80dc08c27763023d9c1904a977639689"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODc0OTM1Ng==", "bodyText": "Right, I remember you mentioned there was some issue with the SyntheticSource that Max ran into. Ideally Synthetic source would work for all standard uses but I'm not familiar with the details. How big of a change would it be to fix SyntheticSource?\nI'm OK with moving forward with this change, creating a Jira issue for tracking the SyntheticSource improvement, and noting it here as a TODO.", "url": "https://github.com/apache/beam/pull/12435#discussion_r468749356", "createdAt": "2020-08-11T17:34:13Z", "author": {"login": "tysonjh"}, "path": "sdks/python/apache_beam/testing/load_tests/pardo_test.py", "diffHunk": "@@ -125,7 +125,9 @@ def process(self, element, state=state_param):\n             state.add(1)\n         yield element\n \n-    if self.get_option_or_default('streaming', False):\n+    if self.get_option_or_default(\n+        'streaming',\n+        False) and self.pipeline.get_option('runner') == \"PortableRunner\":", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjY1MTU4Mg=="}, "originalCommit": {"oid": "7f811d9f80dc08c27763023d9c1904a977639689"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjQ4NTg3MQ==", "bodyText": "Actually, StatefulLoadGenerator is no longer required to enable streaming for Flink (please do note I'm using Flink instead of PortableRunner. PortableRunner can run pipelines on any engine that supports portability, Flink included). SyntheticSource executes as SDF (Splittable DoFn). Since Python SDK supports streaming SDF (https://issues.apache.org/jira/browse/BEAM-3742), SyntheticSource should work on Flink.\n@mxm We'd love to hear your opinion. Should streaming ParDo tests for Flink still use StatefulLoadGenerator?", "url": "https://github.com/apache/beam/pull/12435#discussion_r476485871", "createdAt": "2020-08-25T14:19:04Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/testing/load_tests/pardo_test.py", "diffHunk": "@@ -125,7 +125,9 @@ def process(self, element, state=state_param):\n             state.add(1)\n         yield element\n \n-    if self.get_option_or_default('streaming', False):\n+    if self.get_option_or_default(\n+        'streaming',\n+        False) and self.pipeline.get_option('runner') == \"PortableRunner\":", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjY1MTU4Mg=="}, "originalCommit": {"oid": "7f811d9f80dc08c27763023d9c1904a977639689"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTAzMDc4Mw==", "bodyText": "It's definitely not ideal to have two different sources here. Ideally, we would just use SyntheticSource for all tests. If we can replicate the behavior of StatefulLoadGenerator with SyntheticSource, it would be great to remove the former.", "url": "https://github.com/apache/beam/pull/12435#discussion_r479030783", "createdAt": "2020-08-28T09:37:42Z", "author": {"login": "mxm"}, "path": "sdks/python/apache_beam/testing/load_tests/pardo_test.py", "diffHunk": "@@ -125,7 +125,9 @@ def process(self, element, state=state_param):\n             state.add(1)\n         yield element\n \n-    if self.get_option_or_default('streaming', False):\n+    if self.get_option_or_default(\n+        'streaming',\n+        False) and self.pipeline.get_option('runner') == \"PortableRunner\":", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjY1MTU4Mg=="}, "originalCommit": {"oid": "7f811d9f80dc08c27763023d9c1904a977639689"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTIwNDg3Ng==", "bodyText": "I did some more tests in streaming on Flink and it turned out that SyntheticSource is slower than StatefulLoadGenerator. I think it's because SyntheticSource is not able to use the benefits of multiple workers (only one task manager generates data).\nThat being said, I think we should keep two different sources for now. As for the if statement above, in my opinion, a new switch (for example, --use_stateful_load_generator) be a good idea.", "url": "https://github.com/apache/beam/pull/12435#discussion_r479204876", "createdAt": "2020-08-28T12:05:23Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/testing/load_tests/pardo_test.py", "diffHunk": "@@ -125,7 +125,9 @@ def process(self, element, state=state_param):\n             state.add(1)\n         yield element\n \n-    if self.get_option_or_default('streaming', False):\n+    if self.get_option_or_default(\n+        'streaming',\n+        False) and self.pipeline.get_option('runner') == \"PortableRunner\":", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjY1MTU4Mg=="}, "originalCommit": {"oid": "7f811d9f80dc08c27763023d9c1904a977639689"}, "originalPosition": 7}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 768, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}