{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzY5MzAzODQx", "number": 10731, "reviewThreads": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMFQxODo1MzoyM1rODekTPg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMFQxODo1OTo0MVrODekbPg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMzMzc4NjIyOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/interactive/interactive_beam.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMFQxODo1MzoyM1rOFnxlaw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNFQwMDo1NDoxMlrOFpolpQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzI1MTE3OQ==", "bodyText": "doc string above says \"The PCollections given must belong to the same pipeline and be watched\". But even if they are not watched, they will be auto-watched. Should we update the doc string?", "url": "https://github.com/apache/beam/pull/10731#discussion_r377251179", "createdAt": "2020-02-10T18:53:23Z", "author": {"login": "aaltay"}, "path": "sdks/python/apache_beam/runners/interactive/interactive_beam.py", "diffHunk": "@@ -82,7 +89,100 @@ def run_pipeline(self):\n   ie.current_env().watch(watchable)\n \n \n-def visualize(pcoll):\n-  \"\"\"Visualizes a PCollection.\"\"\"\n-  # TODO(BEAM-7926)\n-  pass\n+def show(*pcolls):\n+  \"\"\"Visualizes given PCollections in an interactive exploratory way if used\n+  within a notebook, or prints a heading sampled data if used within an ipython\n+  shell. Noop if used in a non-interactive environment.\n+\n+  Ad hoc builds a pipeline fragment including only transforms that are\n+  necessary to produce data for given PCollections pcolls, runs the pipeline\n+  fragment to compute data for those pcolls and then visualizes the data.\n+\n+  The function is always blocking. If used within a notebook, the data\n+  visualized might be dynamically updated before the function returns as more\n+  and more data could getting processed and emitted when the pipeline fragment\n+  is being executed. If used within an ipython shell, there will be no dynamic\n+  plotting but a static plotting in the end of pipeline fragment execution.\n+\n+  The PCollections given must belong to the same pipeline and be watched by\n+  Interactive Beam (PCollections defined in __main__ are automatically watched).\n+\n+    For example::\n+\n+      p = beam.Pipeline(InteractiveRunner())\n+      init = p | 'Init' >> beam.Create(range(1000))\n+      square = init | 'Square' >> beam.Map(lambda x: x * x)\n+      cube = init | 'Cube' >> beam.Map(lambda x: x ** 3)\n+\n+      # Below builds a pipeline fragment from the defined pipeline `p` that\n+      # contains only applied transforms of `Init` and `Square`. Then the\n+      # interactive runner runs the pipeline fragment implicitly to compute data\n+      # represented by PCollection `square` and visualizes it.\n+      show(square)\n+\n+      # This is equivalent to `show(square)` because `square` depends on `init`\n+      # and `init` is included in the pipeline fragment and computed anyway.\n+      show(init, square)\n+\n+      # Below is similar to running `p.run()`. It computes data for both\n+      # PCollection `square` and PCollection `cube`, then visualizes them.\n+      show(square, cube)\n+  \"\"\"\n+  assert len(pcolls) > 0, (\n+      'Need at least 1 PCollection to show data visualization.')\n+  for pcoll in pcolls:\n+    assert isinstance(pcoll, beam.pvalue.PCollection), (\n+        '{} is not an apache_beam.pvalue.PCollection.'.format(pcoll))\n+  user_pipeline = pcolls[0].pipeline\n+  for pcoll in pcolls:\n+    assert pcoll.pipeline is user_pipeline, (\n+        '{} belongs to a different user-defined pipeline ({}) than that of'\n+        ' other PCollections ({}).'.format(\n+            pcoll, pcoll.pipeline, user_pipeline))\n+  runner = user_pipeline.runner\n+  if isinstance(runner, ir.InteractiveRunner):\n+    runner = runner._underlying_runner\n+\n+  # Make sure that all PCollections to be shown are watched. If a PCollection\n+  # has not been watched, make up a variable name for that PCollection and watch\n+  # it. No validation is needed here because the watch logic can handle\n+  # arbitrary variables.\n+  watched_pcollections = set()\n+  for watching in ie.current_env().watching():\n+    for key, val in watching:\n+      if hasattr(val, '__class__') and isinstance(val, beam.pvalue.PCollection):\n+        watched_pcollections.add(val)\n+  for pcoll in pcolls:\n+    if pcoll not in watched_pcollections:\n+      watch({re.sub(r'[\\[\\]\\(\\)]', '_', str(pcoll)): pcoll})", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a735ac102def4f6da23e0bfe19a2591b494a45d7"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTIwMDkzMw==", "bodyText": "Removed the must be watched statement from the docstrings.", "url": "https://github.com/apache/beam/pull/10731#discussion_r379200933", "createdAt": "2020-02-14T00:54:12Z", "author": {"login": "KevinGG"}, "path": "sdks/python/apache_beam/runners/interactive/interactive_beam.py", "diffHunk": "@@ -82,7 +89,100 @@ def run_pipeline(self):\n   ie.current_env().watch(watchable)\n \n \n-def visualize(pcoll):\n-  \"\"\"Visualizes a PCollection.\"\"\"\n-  # TODO(BEAM-7926)\n-  pass\n+def show(*pcolls):\n+  \"\"\"Visualizes given PCollections in an interactive exploratory way if used\n+  within a notebook, or prints a heading sampled data if used within an ipython\n+  shell. Noop if used in a non-interactive environment.\n+\n+  Ad hoc builds a pipeline fragment including only transforms that are\n+  necessary to produce data for given PCollections pcolls, runs the pipeline\n+  fragment to compute data for those pcolls and then visualizes the data.\n+\n+  The function is always blocking. If used within a notebook, the data\n+  visualized might be dynamically updated before the function returns as more\n+  and more data could getting processed and emitted when the pipeline fragment\n+  is being executed. If used within an ipython shell, there will be no dynamic\n+  plotting but a static plotting in the end of pipeline fragment execution.\n+\n+  The PCollections given must belong to the same pipeline and be watched by\n+  Interactive Beam (PCollections defined in __main__ are automatically watched).\n+\n+    For example::\n+\n+      p = beam.Pipeline(InteractiveRunner())\n+      init = p | 'Init' >> beam.Create(range(1000))\n+      square = init | 'Square' >> beam.Map(lambda x: x * x)\n+      cube = init | 'Cube' >> beam.Map(lambda x: x ** 3)\n+\n+      # Below builds a pipeline fragment from the defined pipeline `p` that\n+      # contains only applied transforms of `Init` and `Square`. Then the\n+      # interactive runner runs the pipeline fragment implicitly to compute data\n+      # represented by PCollection `square` and visualizes it.\n+      show(square)\n+\n+      # This is equivalent to `show(square)` because `square` depends on `init`\n+      # and `init` is included in the pipeline fragment and computed anyway.\n+      show(init, square)\n+\n+      # Below is similar to running `p.run()`. It computes data for both\n+      # PCollection `square` and PCollection `cube`, then visualizes them.\n+      show(square, cube)\n+  \"\"\"\n+  assert len(pcolls) > 0, (\n+      'Need at least 1 PCollection to show data visualization.')\n+  for pcoll in pcolls:\n+    assert isinstance(pcoll, beam.pvalue.PCollection), (\n+        '{} is not an apache_beam.pvalue.PCollection.'.format(pcoll))\n+  user_pipeline = pcolls[0].pipeline\n+  for pcoll in pcolls:\n+    assert pcoll.pipeline is user_pipeline, (\n+        '{} belongs to a different user-defined pipeline ({}) than that of'\n+        ' other PCollections ({}).'.format(\n+            pcoll, pcoll.pipeline, user_pipeline))\n+  runner = user_pipeline.runner\n+  if isinstance(runner, ir.InteractiveRunner):\n+    runner = runner._underlying_runner\n+\n+  # Make sure that all PCollections to be shown are watched. If a PCollection\n+  # has not been watched, make up a variable name for that PCollection and watch\n+  # it. No validation is needed here because the watch logic can handle\n+  # arbitrary variables.\n+  watched_pcollections = set()\n+  for watching in ie.current_env().watching():\n+    for key, val in watching:\n+      if hasattr(val, '__class__') and isinstance(val, beam.pvalue.PCollection):\n+        watched_pcollections.add(val)\n+  for pcoll in pcolls:\n+    if pcoll not in watched_pcollections:\n+      watch({re.sub(r'[\\[\\]\\(\\)]', '_', str(pcoll)): pcoll})", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzI1MTE3OQ=="}, "originalCommit": {"oid": "a735ac102def4f6da23e0bfe19a2591b494a45d7"}, "originalPosition": 88}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMzMzc5MTUyOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/interactive/interactive_beam.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMFQxODo1NDo1OVrOFnxo3Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNFQwMDo1Njo0NFrOFpoocA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzI1MjA2MQ==", "bodyText": "What is dynamic_plotting_interval ? Is it a 1 second update?", "url": "https://github.com/apache/beam/pull/10731#discussion_r377252061", "createdAt": "2020-02-10T18:54:59Z", "author": {"login": "aaltay"}, "path": "sdks/python/apache_beam/runners/interactive/interactive_beam.py", "diffHunk": "@@ -82,7 +89,100 @@ def run_pipeline(self):\n   ie.current_env().watch(watchable)\n \n \n-def visualize(pcoll):\n-  \"\"\"Visualizes a PCollection.\"\"\"\n-  # TODO(BEAM-7926)\n-  pass\n+def show(*pcolls):\n+  \"\"\"Visualizes given PCollections in an interactive exploratory way if used\n+  within a notebook, or prints a heading sampled data if used within an ipython\n+  shell. Noop if used in a non-interactive environment.\n+\n+  Ad hoc builds a pipeline fragment including only transforms that are\n+  necessary to produce data for given PCollections pcolls, runs the pipeline\n+  fragment to compute data for those pcolls and then visualizes the data.\n+\n+  The function is always blocking. If used within a notebook, the data\n+  visualized might be dynamically updated before the function returns as more\n+  and more data could getting processed and emitted when the pipeline fragment\n+  is being executed. If used within an ipython shell, there will be no dynamic\n+  plotting but a static plotting in the end of pipeline fragment execution.\n+\n+  The PCollections given must belong to the same pipeline and be watched by\n+  Interactive Beam (PCollections defined in __main__ are automatically watched).\n+\n+    For example::\n+\n+      p = beam.Pipeline(InteractiveRunner())\n+      init = p | 'Init' >> beam.Create(range(1000))\n+      square = init | 'Square' >> beam.Map(lambda x: x * x)\n+      cube = init | 'Cube' >> beam.Map(lambda x: x ** 3)\n+\n+      # Below builds a pipeline fragment from the defined pipeline `p` that\n+      # contains only applied transforms of `Init` and `Square`. Then the\n+      # interactive runner runs the pipeline fragment implicitly to compute data\n+      # represented by PCollection `square` and visualizes it.\n+      show(square)\n+\n+      # This is equivalent to `show(square)` because `square` depends on `init`\n+      # and `init` is included in the pipeline fragment and computed anyway.\n+      show(init, square)\n+\n+      # Below is similar to running `p.run()`. It computes data for both\n+      # PCollection `square` and PCollection `cube`, then visualizes them.\n+      show(square, cube)\n+  \"\"\"\n+  assert len(pcolls) > 0, (\n+      'Need at least 1 PCollection to show data visualization.')\n+  for pcoll in pcolls:\n+    assert isinstance(pcoll, beam.pvalue.PCollection), (\n+        '{} is not an apache_beam.pvalue.PCollection.'.format(pcoll))\n+  user_pipeline = pcolls[0].pipeline\n+  for pcoll in pcolls:\n+    assert pcoll.pipeline is user_pipeline, (\n+        '{} belongs to a different user-defined pipeline ({}) than that of'\n+        ' other PCollections ({}).'.format(\n+            pcoll, pcoll.pipeline, user_pipeline))\n+  runner = user_pipeline.runner\n+  if isinstance(runner, ir.InteractiveRunner):\n+    runner = runner._underlying_runner\n+\n+  # Make sure that all PCollections to be shown are watched. If a PCollection\n+  # has not been watched, make up a variable name for that PCollection and watch\n+  # it. No validation is needed here because the watch logic can handle\n+  # arbitrary variables.\n+  watched_pcollections = set()\n+  for watching in ie.current_env().watching():\n+    for key, val in watching:\n+      if hasattr(val, '__class__') and isinstance(val, beam.pvalue.PCollection):\n+        watched_pcollections.add(val)\n+  for pcoll in pcolls:\n+    if pcoll not in watched_pcollections:\n+      watch({re.sub(r'[\\[\\]\\(\\)]', '_', str(pcoll)): pcoll})\n+\n+  # Attempt to run background caching job since we have the reference to the\n+  # user-defined pipeline.\n+  bcj.attempt_to_run_background_caching_job(runner, user_pipeline)\n+\n+  # Build a pipeline fragment for the PCollections and run it.\n+  result = pf.PipelineFragment(list(pcolls)).run()\n+  ie.current_env().set_pipeline_result(\n+      user_pipeline,\n+      result,\n+      is_main_job=True)\n+\n+  # If in notebook, dynamic plotting as computation goes.\n+  if ie.current_env().is_in_notebook:\n+    for pcoll in pcolls:\n+      visualize(pcoll, dynamic_plotting_interval=1)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a735ac102def4f6da23e0bfe19a2591b494a45d7"}, "originalPosition": 104}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTIwMTY0OA==", "bodyText": "Yes, its unit is second. The underlying implementation uses a datetime.timedelta. This is to simplify the visualize interface and its usages.", "url": "https://github.com/apache/beam/pull/10731#discussion_r379201648", "createdAt": "2020-02-14T00:56:44Z", "author": {"login": "KevinGG"}, "path": "sdks/python/apache_beam/runners/interactive/interactive_beam.py", "diffHunk": "@@ -82,7 +89,100 @@ def run_pipeline(self):\n   ie.current_env().watch(watchable)\n \n \n-def visualize(pcoll):\n-  \"\"\"Visualizes a PCollection.\"\"\"\n-  # TODO(BEAM-7926)\n-  pass\n+def show(*pcolls):\n+  \"\"\"Visualizes given PCollections in an interactive exploratory way if used\n+  within a notebook, or prints a heading sampled data if used within an ipython\n+  shell. Noop if used in a non-interactive environment.\n+\n+  Ad hoc builds a pipeline fragment including only transforms that are\n+  necessary to produce data for given PCollections pcolls, runs the pipeline\n+  fragment to compute data for those pcolls and then visualizes the data.\n+\n+  The function is always blocking. If used within a notebook, the data\n+  visualized might be dynamically updated before the function returns as more\n+  and more data could getting processed and emitted when the pipeline fragment\n+  is being executed. If used within an ipython shell, there will be no dynamic\n+  plotting but a static plotting in the end of pipeline fragment execution.\n+\n+  The PCollections given must belong to the same pipeline and be watched by\n+  Interactive Beam (PCollections defined in __main__ are automatically watched).\n+\n+    For example::\n+\n+      p = beam.Pipeline(InteractiveRunner())\n+      init = p | 'Init' >> beam.Create(range(1000))\n+      square = init | 'Square' >> beam.Map(lambda x: x * x)\n+      cube = init | 'Cube' >> beam.Map(lambda x: x ** 3)\n+\n+      # Below builds a pipeline fragment from the defined pipeline `p` that\n+      # contains only applied transforms of `Init` and `Square`. Then the\n+      # interactive runner runs the pipeline fragment implicitly to compute data\n+      # represented by PCollection `square` and visualizes it.\n+      show(square)\n+\n+      # This is equivalent to `show(square)` because `square` depends on `init`\n+      # and `init` is included in the pipeline fragment and computed anyway.\n+      show(init, square)\n+\n+      # Below is similar to running `p.run()`. It computes data for both\n+      # PCollection `square` and PCollection `cube`, then visualizes them.\n+      show(square, cube)\n+  \"\"\"\n+  assert len(pcolls) > 0, (\n+      'Need at least 1 PCollection to show data visualization.')\n+  for pcoll in pcolls:\n+    assert isinstance(pcoll, beam.pvalue.PCollection), (\n+        '{} is not an apache_beam.pvalue.PCollection.'.format(pcoll))\n+  user_pipeline = pcolls[0].pipeline\n+  for pcoll in pcolls:\n+    assert pcoll.pipeline is user_pipeline, (\n+        '{} belongs to a different user-defined pipeline ({}) than that of'\n+        ' other PCollections ({}).'.format(\n+            pcoll, pcoll.pipeline, user_pipeline))\n+  runner = user_pipeline.runner\n+  if isinstance(runner, ir.InteractiveRunner):\n+    runner = runner._underlying_runner\n+\n+  # Make sure that all PCollections to be shown are watched. If a PCollection\n+  # has not been watched, make up a variable name for that PCollection and watch\n+  # it. No validation is needed here because the watch logic can handle\n+  # arbitrary variables.\n+  watched_pcollections = set()\n+  for watching in ie.current_env().watching():\n+    for key, val in watching:\n+      if hasattr(val, '__class__') and isinstance(val, beam.pvalue.PCollection):\n+        watched_pcollections.add(val)\n+  for pcoll in pcolls:\n+    if pcoll not in watched_pcollections:\n+      watch({re.sub(r'[\\[\\]\\(\\)]', '_', str(pcoll)): pcoll})\n+\n+  # Attempt to run background caching job since we have the reference to the\n+  # user-defined pipeline.\n+  bcj.attempt_to_run_background_caching_job(runner, user_pipeline)\n+\n+  # Build a pipeline fragment for the PCollections and run it.\n+  result = pf.PipelineFragment(list(pcolls)).run()\n+  ie.current_env().set_pipeline_result(\n+      user_pipeline,\n+      result,\n+      is_main_job=True)\n+\n+  # If in notebook, dynamic plotting as computation goes.\n+  if ie.current_env().is_in_notebook:\n+    for pcoll in pcolls:\n+      visualize(pcoll, dynamic_plotting_interval=1)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzI1MjA2MQ=="}, "originalCommit": {"oid": "a735ac102def4f6da23e0bfe19a2591b494a45d7"}, "originalPosition": 104}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMzMzc5Nzk4OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/interactive/interactive_beam_test.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMFQxODo1Njo1NlrOFnxs8w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNFQwMDo1NzowOVrOFpoozQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzI1MzEwNw==", "bodyText": "This test will break if anything changes related to this arbitrary naming. Maybe just check that it exists.", "url": "https://github.com/apache/beam/pull/10731#discussion_r377253107", "createdAt": "2020-02-10T18:56:56Z", "author": {"login": "aaltay"}, "path": "sdks/python/apache_beam/runners/interactive/interactive_beam_test.py", "diffHunk": "@@ -67,6 +77,31 @@ def test_watch_class_instance(self):\n     test_env.watch(self)\n     self.assertEqual(ie.current_env().watching(), test_env.watching())\n \n+  def test_show_always_watch_given_pcolls(self):\n+    p = beam.Pipeline(ir.InteractiveRunner())\n+    # pylint: disable=range-builtin-not-iterating\n+    pcoll = p | 'Create' >> beam.Create(range(10))\n+    # The pcoll is not watched since watch(locals()) is not explicitly called.\n+    self.assertFalse(\n+        pcoll in _get_watched_pcollections_with_variable_names())\n+    # The call of show watches pcoll.\n+    ib.show(pcoll)\n+    self.assertTrue(\n+        pcoll in _get_watched_pcollections_with_variable_names())\n+    # The name of pcoll is made up by show.\n+    self.assertEqual(\n+        'PCollection_Create/Map_decode_.None_',", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a735ac102def4f6da23e0bfe19a2591b494a45d7"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTIwMTc0MQ==", "bodyText": "Removed the str assertion. Kept the existence check.", "url": "https://github.com/apache/beam/pull/10731#discussion_r379201741", "createdAt": "2020-02-14T00:57:09Z", "author": {"login": "KevinGG"}, "path": "sdks/python/apache_beam/runners/interactive/interactive_beam_test.py", "diffHunk": "@@ -67,6 +77,31 @@ def test_watch_class_instance(self):\n     test_env.watch(self)\n     self.assertEqual(ie.current_env().watching(), test_env.watching())\n \n+  def test_show_always_watch_given_pcolls(self):\n+    p = beam.Pipeline(ir.InteractiveRunner())\n+    # pylint: disable=range-builtin-not-iterating\n+    pcoll = p | 'Create' >> beam.Create(range(10))\n+    # The pcoll is not watched since watch(locals()) is not explicitly called.\n+    self.assertFalse(\n+        pcoll in _get_watched_pcollections_with_variable_names())\n+    # The call of show watches pcoll.\n+    ib.show(pcoll)\n+    self.assertTrue(\n+        pcoll in _get_watched_pcollections_with_variable_names())\n+    # The name of pcoll is made up by show.\n+    self.assertEqual(\n+        'PCollection_Create/Map_decode_.None_',", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzI1MzEwNw=="}, "originalCommit": {"oid": "a735ac102def4f6da23e0bfe19a2591b494a45d7"}, "originalPosition": 45}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMzMzgwMjY0OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/interactive/pipeline_fragment.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMFQxODo1ODoyM1rOFnxv_A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNFQwMDo1ODo0M1rOFpoqOg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzI1Mzg4NA==", "bodyText": "Use blocking instead of blocking_run? (Since that is what we use in other places.)", "url": "https://github.com/apache/beam/pull/10731#discussion_r377253884", "createdAt": "2020-02-10T18:58:23Z", "author": {"login": "aaltay"}, "path": "sdks/python/apache_beam/runners/interactive/pipeline_fragment.py", "diffHunk": "@@ -100,17 +100,23 @@ def deduce_fragment(self):\n         self._runner_pipeline.runner,\n         self._options)\n \n-  def run(self, display_pipeline_graph=False, use_cache=True):\n+  def run(self,\n+          display_pipeline_graph=False,\n+          use_cache=True,\n+          blocking_run=False):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a735ac102def4f6da23e0bfe19a2591b494a45d7"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTIwMjEwNg==", "bodyText": "Renamed blocking_run to blocking.\nRenamed all try-finally preserve-and-reset variables with preserved_ prefix.", "url": "https://github.com/apache/beam/pull/10731#discussion_r379202106", "createdAt": "2020-02-14T00:58:43Z", "author": {"login": "KevinGG"}, "path": "sdks/python/apache_beam/runners/interactive/pipeline_fragment.py", "diffHunk": "@@ -100,17 +100,23 @@ def deduce_fragment(self):\n         self._runner_pipeline.runner,\n         self._options)\n \n-  def run(self, display_pipeline_graph=False, use_cache=True):\n+  def run(self,\n+          display_pipeline_graph=False,\n+          use_cache=True,\n+          blocking_run=False):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzI1Mzg4NA=="}, "originalCommit": {"oid": "a735ac102def4f6da23e0bfe19a2591b494a45d7"}, "originalPosition": 8}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMzMzgwNjcwOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/interactive/interactive_beam.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xMFQxODo1OTo0MVrOFnxyuQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0xNFQwMTowMToyMlrOFpotCw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzI1NDU4NQ==", "bodyText": "You renamed pin to build_pipeline_instrument in another place. Do you want to switch these to background_caching_job if you are trying to be more explicit in general?", "url": "https://github.com/apache/beam/pull/10731#discussion_r377254585", "createdAt": "2020-02-10T18:59:41Z", "author": {"login": "aaltay"}, "path": "sdks/python/apache_beam/runners/interactive/interactive_beam.py", "diffHunk": "@@ -82,7 +89,100 @@ def run_pipeline(self):\n   ie.current_env().watch(watchable)\n \n \n-def visualize(pcoll):\n-  \"\"\"Visualizes a PCollection.\"\"\"\n-  # TODO(BEAM-7926)\n-  pass\n+def show(*pcolls):\n+  \"\"\"Visualizes given PCollections in an interactive exploratory way if used\n+  within a notebook, or prints a heading sampled data if used within an ipython\n+  shell. Noop if used in a non-interactive environment.\n+\n+  Ad hoc builds a pipeline fragment including only transforms that are\n+  necessary to produce data for given PCollections pcolls, runs the pipeline\n+  fragment to compute data for those pcolls and then visualizes the data.\n+\n+  The function is always blocking. If used within a notebook, the data\n+  visualized might be dynamically updated before the function returns as more\n+  and more data could getting processed and emitted when the pipeline fragment\n+  is being executed. If used within an ipython shell, there will be no dynamic\n+  plotting but a static plotting in the end of pipeline fragment execution.\n+\n+  The PCollections given must belong to the same pipeline and be watched by\n+  Interactive Beam (PCollections defined in __main__ are automatically watched).\n+\n+    For example::\n+\n+      p = beam.Pipeline(InteractiveRunner())\n+      init = p | 'Init' >> beam.Create(range(1000))\n+      square = init | 'Square' >> beam.Map(lambda x: x * x)\n+      cube = init | 'Cube' >> beam.Map(lambda x: x ** 3)\n+\n+      # Below builds a pipeline fragment from the defined pipeline `p` that\n+      # contains only applied transforms of `Init` and `Square`. Then the\n+      # interactive runner runs the pipeline fragment implicitly to compute data\n+      # represented by PCollection `square` and visualizes it.\n+      show(square)\n+\n+      # This is equivalent to `show(square)` because `square` depends on `init`\n+      # and `init` is included in the pipeline fragment and computed anyway.\n+      show(init, square)\n+\n+      # Below is similar to running `p.run()`. It computes data for both\n+      # PCollection `square` and PCollection `cube`, then visualizes them.\n+      show(square, cube)\n+  \"\"\"\n+  assert len(pcolls) > 0, (\n+      'Need at least 1 PCollection to show data visualization.')\n+  for pcoll in pcolls:\n+    assert isinstance(pcoll, beam.pvalue.PCollection), (\n+        '{} is not an apache_beam.pvalue.PCollection.'.format(pcoll))\n+  user_pipeline = pcolls[0].pipeline\n+  for pcoll in pcolls:\n+    assert pcoll.pipeline is user_pipeline, (\n+        '{} belongs to a different user-defined pipeline ({}) than that of'\n+        ' other PCollections ({}).'.format(\n+            pcoll, pcoll.pipeline, user_pipeline))\n+  runner = user_pipeline.runner\n+  if isinstance(runner, ir.InteractiveRunner):\n+    runner = runner._underlying_runner\n+\n+  # Make sure that all PCollections to be shown are watched. If a PCollection\n+  # has not been watched, make up a variable name for that PCollection and watch\n+  # it. No validation is needed here because the watch logic can handle\n+  # arbitrary variables.\n+  watched_pcollections = set()\n+  for watching in ie.current_env().watching():\n+    for key, val in watching:\n+      if hasattr(val, '__class__') and isinstance(val, beam.pvalue.PCollection):\n+        watched_pcollections.add(val)\n+  for pcoll in pcolls:\n+    if pcoll not in watched_pcollections:\n+      watch({re.sub(r'[\\[\\]\\(\\)]', '_', str(pcoll)): pcoll})\n+\n+  # Attempt to run background caching job since we have the reference to the\n+  # user-defined pipeline.\n+  bcj.attempt_to_run_background_caching_job(runner, user_pipeline)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a735ac102def4f6da23e0bfe19a2591b494a45d7"}, "originalPosition": 92}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3OTIwMjgyNw==", "bodyText": "This is to discern instances from modules.\nFor example, given a background_caching_job, it feels more like an instance of BackgroundCachingJob.\nFor pipeline_instrument, when importing the module, we normally rename it to instr or inst.\nBecause pipeline_instrument = instr.build_pipeline_instrument(...).\nThe abbreviation is to avoid name conflicts.", "url": "https://github.com/apache/beam/pull/10731#discussion_r379202827", "createdAt": "2020-02-14T01:01:22Z", "author": {"login": "KevinGG"}, "path": "sdks/python/apache_beam/runners/interactive/interactive_beam.py", "diffHunk": "@@ -82,7 +89,100 @@ def run_pipeline(self):\n   ie.current_env().watch(watchable)\n \n \n-def visualize(pcoll):\n-  \"\"\"Visualizes a PCollection.\"\"\"\n-  # TODO(BEAM-7926)\n-  pass\n+def show(*pcolls):\n+  \"\"\"Visualizes given PCollections in an interactive exploratory way if used\n+  within a notebook, or prints a heading sampled data if used within an ipython\n+  shell. Noop if used in a non-interactive environment.\n+\n+  Ad hoc builds a pipeline fragment including only transforms that are\n+  necessary to produce data for given PCollections pcolls, runs the pipeline\n+  fragment to compute data for those pcolls and then visualizes the data.\n+\n+  The function is always blocking. If used within a notebook, the data\n+  visualized might be dynamically updated before the function returns as more\n+  and more data could getting processed and emitted when the pipeline fragment\n+  is being executed. If used within an ipython shell, there will be no dynamic\n+  plotting but a static plotting in the end of pipeline fragment execution.\n+\n+  The PCollections given must belong to the same pipeline and be watched by\n+  Interactive Beam (PCollections defined in __main__ are automatically watched).\n+\n+    For example::\n+\n+      p = beam.Pipeline(InteractiveRunner())\n+      init = p | 'Init' >> beam.Create(range(1000))\n+      square = init | 'Square' >> beam.Map(lambda x: x * x)\n+      cube = init | 'Cube' >> beam.Map(lambda x: x ** 3)\n+\n+      # Below builds a pipeline fragment from the defined pipeline `p` that\n+      # contains only applied transforms of `Init` and `Square`. Then the\n+      # interactive runner runs the pipeline fragment implicitly to compute data\n+      # represented by PCollection `square` and visualizes it.\n+      show(square)\n+\n+      # This is equivalent to `show(square)` because `square` depends on `init`\n+      # and `init` is included in the pipeline fragment and computed anyway.\n+      show(init, square)\n+\n+      # Below is similar to running `p.run()`. It computes data for both\n+      # PCollection `square` and PCollection `cube`, then visualizes them.\n+      show(square, cube)\n+  \"\"\"\n+  assert len(pcolls) > 0, (\n+      'Need at least 1 PCollection to show data visualization.')\n+  for pcoll in pcolls:\n+    assert isinstance(pcoll, beam.pvalue.PCollection), (\n+        '{} is not an apache_beam.pvalue.PCollection.'.format(pcoll))\n+  user_pipeline = pcolls[0].pipeline\n+  for pcoll in pcolls:\n+    assert pcoll.pipeline is user_pipeline, (\n+        '{} belongs to a different user-defined pipeline ({}) than that of'\n+        ' other PCollections ({}).'.format(\n+            pcoll, pcoll.pipeline, user_pipeline))\n+  runner = user_pipeline.runner\n+  if isinstance(runner, ir.InteractiveRunner):\n+    runner = runner._underlying_runner\n+\n+  # Make sure that all PCollections to be shown are watched. If a PCollection\n+  # has not been watched, make up a variable name for that PCollection and watch\n+  # it. No validation is needed here because the watch logic can handle\n+  # arbitrary variables.\n+  watched_pcollections = set()\n+  for watching in ie.current_env().watching():\n+    for key, val in watching:\n+      if hasattr(val, '__class__') and isinstance(val, beam.pvalue.PCollection):\n+        watched_pcollections.add(val)\n+  for pcoll in pcolls:\n+    if pcoll not in watched_pcollections:\n+      watch({re.sub(r'[\\[\\]\\(\\)]', '_', str(pcoll)): pcoll})\n+\n+  # Attempt to run background caching job since we have the reference to the\n+  # user-defined pipeline.\n+  bcj.attempt_to_run_background_caching_job(runner, user_pipeline)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NzI1NDU4NQ=="}, "originalCommit": {"oid": "a735ac102def4f6da23e0bfe19a2591b494a45d7"}, "originalPosition": 92}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2098, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}