{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQ1MTU5MDA0", "number": 12188, "title": "[BEAM-10411] Adds an example that use Python cross-language Kafka transforms.", "bodyText": "Please add a meaningful description for your change here\n\nThank you for your contribution! Follow this checklist to help us incorporate your contribution quickly and easily:\n\n Choose reviewer(s) and mention them in a comment (R: @username).\n Format the pull request title like [BEAM-XXX] Fixes bug in ApproximateQuantiles, where you replace BEAM-XXX with the appropriate JIRA issue, if applicable. This will automatically link the pull request to the issue.\n Update CHANGES.md with noteworthy changes.\n If this contribution is large, please file an Apache Individual Contributor License Agreement.\n\nSee the Contributor Guide for more tips on how to make review process smoother.\nPost-Commit Tests Status (on master branch)\n\n\n\nLang\nSDK\nDataflow\nFlink\nSamza\nSpark\nTwister2\n\n\n\n\nGo\n\n---\n\n---\n\n---\n\n\nJava\n\n\n\n\n\n\n\n\nPython\n\n\n\n---\n\n---\n\n\nXLang\n---\n---\n\n---\n\n---\n\n\n\nPre-Commit Tests Status (on master branch)\n\n\n\n---\nJava\nPython\nGo\nWebsite\n\n\n\n\nNon-portable\n\n\n\n\n\n\nPortable\n---\n\n---\n---\n\n\n\nSee .test-infra/jenkins/README for trigger phrase, status and link of all Jenkins jobs.", "createdAt": "2020-07-07T05:19:13Z", "url": "https://github.com/apache/beam/pull/12188", "merged": true, "mergeCommit": {"oid": "6761a5bff9e2d28dad056f3fd4fa381c828238e1"}, "closed": true, "closedAt": "2020-07-21T20:59:45Z", "author": {"login": "chamikaramj"}, "timelineItems": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcyfA2igBqjM1MTg2ODQ1Njc=", "endCursor": "Y3Vyc29yOnYyOpPPAAABc3L5PuAFqTQ1MjcxMzczMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "3fa27e3c6d695a42b50a4152d134d1965091bff9", "author": {"user": {"login": "chamikaramj", "name": "Chamikara Jayalath"}}, "url": "https://github.com/apache/beam/commit/3fa27e3c6d695a42b50a4152d134d1965091bff9", "committedDate": "2020-07-07T05:17:44Z", "message": "Adds an example that use Python cross-language Kafka transforms."}, "afterCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6", "author": {"user": {"login": "chamikaramj", "name": "Chamikara Jayalath"}}, "url": "https://github.com/apache/beam/commit/c01d0f0d0cea545632809131a8dc5a1adeaa9db6", "committedDate": "2020-07-07T05:30:07Z", "message": "Adds an example that use Python cross-language Kafka transforms."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ0OTM5Mjc0", "url": "https://github.com/apache/beam/pull/12188#pullrequestreview-444939274", "createdAt": "2020-07-08T16:32:25Z", "commit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOFQxNjozMjoyNVrOGuwIsg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOFQxNjo1MzoxMVrOGuw6ow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTY3NjMzOA==", "bodyText": "Is there any reason not to use the shorter version?\npipeline_options = PipelineOptions(\n    pipeline_args,\n    save_main_session=True,\n    streaming=True)", "url": "https://github.com/apache/beam/pull/12188#discussion_r451676338", "createdAt": "2020-07-08T16:32:25Z", "author": {"login": "davidcavazos"}, "path": "sdks/python/apache_beam/examples/kafkataxi/kafka_taxi.py", "diffHunk": "@@ -0,0 +1,87 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"An example that writes to and reads from Kafka.\n+\n+ This example reads from the PubSub NYC Taxi stream described in\n+ https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon, writes to a\n+ given Kafka topic and reads back from the same Kafka topic.\n+ \"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import argparse\n+import logging\n+import typing\n+\n+import apache_beam as beam\n+from apache_beam.io.kafka import ReadFromKafka\n+from apache_beam.io.kafka import WriteToKafka\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.options.pipeline_options import SetupOptions\n+from apache_beam.options.pipeline_options import StandardOptions\n+\n+\n+def run(argv=None):\n+  \"\"\"Main entry point; defines and runs the wordcount pipeline.\"\"\"\n+  parser = argparse.ArgumentParser()\n+  parser.add_argument(\n+      '--bootstrap_servers',\n+      dest='bootstrap_servers',\n+      required=True,\n+      help='Bootstrap servers for the Kafka cluster. Should be accessible by '\n+      'the runner')\n+  parser.add_argument(\n+      '--topic',\n+      dest='topic',\n+      default='kafka_taxirides_realtime',\n+      help='Kafka topic to write to and read from')\n+  known_args, pipeline_args = parser.parse_known_args(argv)\n+\n+  pipeline_options = PipelineOptions(pipeline_args)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTY3ODc3Mg==", "bodyText": "Why not use with statement?\nwith beam.Pipeline(options=pipeline_options) as pipeline:\n  _ = (\n      pipeline\n      | beam.io.ReadFromPubsub(...\n      ...\n  )\n\n  _ = (\n      pipeline\n      | ReadFromKafka(...\n      ...\n  )", "url": "https://github.com/apache/beam/pull/12188#discussion_r451678772", "createdAt": "2020-07-08T16:36:28Z", "author": {"login": "davidcavazos"}, "path": "sdks/python/apache_beam/examples/kafkataxi/kafka_taxi.py", "diffHunk": "@@ -0,0 +1,87 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"An example that writes to and reads from Kafka.\n+\n+ This example reads from the PubSub NYC Taxi stream described in\n+ https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon, writes to a\n+ given Kafka topic and reads back from the same Kafka topic.\n+ \"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import argparse\n+import logging\n+import typing\n+\n+import apache_beam as beam\n+from apache_beam.io.kafka import ReadFromKafka\n+from apache_beam.io.kafka import WriteToKafka\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.options.pipeline_options import SetupOptions\n+from apache_beam.options.pipeline_options import StandardOptions\n+\n+\n+def run(argv=None):\n+  \"\"\"Main entry point; defines and runs the wordcount pipeline.\"\"\"\n+  parser = argparse.ArgumentParser()\n+  parser.add_argument(\n+      '--bootstrap_servers',\n+      dest='bootstrap_servers',\n+      required=True,\n+      help='Bootstrap servers for the Kafka cluster. Should be accessible by '\n+      'the runner')\n+  parser.add_argument(\n+      '--topic',\n+      dest='topic',\n+      default='kafka_taxirides_realtime',\n+      help='Kafka topic to write to and read from')\n+  known_args, pipeline_args = parser.parse_known_args(argv)\n+\n+  pipeline_options = PipelineOptions(pipeline_args)\n+  pipeline_options.view_as(SetupOptions).save_main_session = True\n+  pipeline_options.view_as(StandardOptions).streaming = True\n+\n+  pipeline = beam.Pipeline(options=pipeline_options)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTY4MjI1Ng==", "bodyText": "In general, for Python samples, we usually have the run function accept the actual values the function needs to run instead of argv, and we let __main__ use argparse to parse the arguments.\nThis allows users to more easily import the sample \"as a library\" and run the sample from within a script. It also makes it easier to test.\nIt's also a good idea to show a commented example of how those arguments would look like. Ideally, if they copy-paste the contents of the run function and uncomment those examples, it should run, although some inputs might need tweaking like a project ID or something like that.\ndef run(bootstrap_servers, topic, pipeline_args):\n  # bootstrap_servers = '...'\n  # topic = 'kafka_taxirides_realtime'\n  # pipeline_args = ['--project', 'my-project', ...]\n  ...\n\nif __name__ == '__main__':\n  import argparse\n\n  parser = argparse.ArgumentParser()\n  ...\n  args, pipeline_args = parser.parse_known_args()\n\n  run(args.bootstrap_servers, args.topic, pipeline_args)", "url": "https://github.com/apache/beam/pull/12188#discussion_r451682256", "createdAt": "2020-07-08T16:42:09Z", "author": {"login": "davidcavazos"}, "path": "sdks/python/apache_beam/examples/kafkataxi/kafka_taxi.py", "diffHunk": "@@ -0,0 +1,87 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"An example that writes to and reads from Kafka.\n+\n+ This example reads from the PubSub NYC Taxi stream described in\n+ https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon, writes to a\n+ given Kafka topic and reads back from the same Kafka topic.\n+ \"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import argparse\n+import logging\n+import typing\n+\n+import apache_beam as beam\n+from apache_beam.io.kafka import ReadFromKafka\n+from apache_beam.io.kafka import WriteToKafka\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.options.pipeline_options import SetupOptions\n+from apache_beam.options.pipeline_options import StandardOptions\n+\n+\n+def run(argv=None):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTY4NjI5Ng==", "bodyText": "Can we make this into either a constant or another command line argument with a default value? It's also a good idea to mention the units, are these seconds or minutes?", "url": "https://github.com/apache/beam/pull/12188#discussion_r451686296", "createdAt": "2020-07-08T16:48:42Z", "author": {"login": "davidcavazos"}, "path": "sdks/python/apache_beam/examples/kafkataxi/kafka_taxi.py", "diffHunk": "@@ -0,0 +1,87 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"An example that writes to and reads from Kafka.\n+\n+ This example reads from the PubSub NYC Taxi stream described in\n+ https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon, writes to a\n+ given Kafka topic and reads back from the same Kafka topic.\n+ \"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import argparse\n+import logging\n+import typing\n+\n+import apache_beam as beam\n+from apache_beam.io.kafka import ReadFromKafka\n+from apache_beam.io.kafka import WriteToKafka\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.options.pipeline_options import SetupOptions\n+from apache_beam.options.pipeline_options import StandardOptions\n+\n+\n+def run(argv=None):\n+  \"\"\"Main entry point; defines and runs the wordcount pipeline.\"\"\"\n+  parser = argparse.ArgumentParser()\n+  parser.add_argument(\n+      '--bootstrap_servers',\n+      dest='bootstrap_servers',\n+      required=True,\n+      help='Bootstrap servers for the Kafka cluster. Should be accessible by '\n+      'the runner')\n+  parser.add_argument(\n+      '--topic',\n+      dest='topic',\n+      default='kafka_taxirides_realtime',\n+      help='Kafka topic to write to and read from')\n+  known_args, pipeline_args = parser.parse_known_args(argv)\n+\n+  pipeline_options = PipelineOptions(pipeline_args)\n+  pipeline_options.view_as(SetupOptions).save_main_session = True\n+  pipeline_options.view_as(StandardOptions).streaming = True\n+\n+  pipeline = beam.Pipeline(options=pipeline_options)\n+  bootstrap_servers = known_args.bootstrap_servers\n+  _ = (\n+      pipeline\n+      | beam.io.ReadFromPubSub(\n+          topic='projects/pubsub-public-data/topics/taxirides-realtime').\n+      with_output_types(bytes)\n+      | beam.Map(lambda x: (b'', x)).with_output_types(\n+          typing.Tuple[bytes, bytes])\n+      | beam.WindowInto(beam.window.FixedWindows(15))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTY4NzMzNg==", "bodyText": "I know this is how Kafka calls them, but reading this name is not very intuitive of what it means. Maybe rename to something like --kafka_servers? What do you think?", "url": "https://github.com/apache/beam/pull/12188#discussion_r451687336", "createdAt": "2020-07-08T16:50:21Z", "author": {"login": "davidcavazos"}, "path": "sdks/python/apache_beam/examples/kafkataxi/kafka_taxi.py", "diffHunk": "@@ -0,0 +1,87 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"An example that writes to and reads from Kafka.\n+\n+ This example reads from the PubSub NYC Taxi stream described in\n+ https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon, writes to a\n+ given Kafka topic and reads back from the same Kafka topic.\n+ \"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import argparse\n+import logging\n+import typing\n+\n+import apache_beam as beam\n+from apache_beam.io.kafka import ReadFromKafka\n+from apache_beam.io.kafka import WriteToKafka\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.options.pipeline_options import SetupOptions\n+from apache_beam.options.pipeline_options import StandardOptions\n+\n+\n+def run(argv=None):\n+  \"\"\"Main entry point; defines and runs the wordcount pipeline.\"\"\"\n+  parser = argparse.ArgumentParser()\n+  parser.add_argument(\n+      '--bootstrap_servers',", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTY4ODQxOQ==", "bodyText": "Why are we adding an empty bytes key? Is it required by another transform? A comment would be nice.", "url": "https://github.com/apache/beam/pull/12188#discussion_r451688419", "createdAt": "2020-07-08T16:52:00Z", "author": {"login": "davidcavazos"}, "path": "sdks/python/apache_beam/examples/kafkataxi/kafka_taxi.py", "diffHunk": "@@ -0,0 +1,87 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"An example that writes to and reads from Kafka.\n+\n+ This example reads from the PubSub NYC Taxi stream described in\n+ https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon, writes to a\n+ given Kafka topic and reads back from the same Kafka topic.\n+ \"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import argparse\n+import logging\n+import typing\n+\n+import apache_beam as beam\n+from apache_beam.io.kafka import ReadFromKafka\n+from apache_beam.io.kafka import WriteToKafka\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.options.pipeline_options import SetupOptions\n+from apache_beam.options.pipeline_options import StandardOptions\n+\n+\n+def run(argv=None):\n+  \"\"\"Main entry point; defines and runs the wordcount pipeline.\"\"\"\n+  parser = argparse.ArgumentParser()\n+  parser.add_argument(\n+      '--bootstrap_servers',\n+      dest='bootstrap_servers',\n+      required=True,\n+      help='Bootstrap servers for the Kafka cluster. Should be accessible by '\n+      'the runner')\n+  parser.add_argument(\n+      '--topic',\n+      dest='topic',\n+      default='kafka_taxirides_realtime',\n+      help='Kafka topic to write to and read from')\n+  known_args, pipeline_args = parser.parse_known_args(argv)\n+\n+  pipeline_options = PipelineOptions(pipeline_args)\n+  pipeline_options.view_as(SetupOptions).save_main_session = True\n+  pipeline_options.view_as(StandardOptions).streaming = True\n+\n+  pipeline = beam.Pipeline(options=pipeline_options)\n+  bootstrap_servers = known_args.bootstrap_servers\n+  _ = (\n+      pipeline\n+      | beam.io.ReadFromPubSub(\n+          topic='projects/pubsub-public-data/topics/taxirides-realtime').\n+      with_output_types(bytes)\n+      | beam.Map(lambda x: (b'', x)).with_output_types(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTY4OTEyMw==", "bodyText": "Why are we getting rid of all the elements?\nBy running this, do we see the elements via the Kafka transform or should we print the elements?", "url": "https://github.com/apache/beam/pull/12188#discussion_r451689123", "createdAt": "2020-07-08T16:53:11Z", "author": {"login": "davidcavazos"}, "path": "sdks/python/apache_beam/examples/kafkataxi/kafka_taxi.py", "diffHunk": "@@ -0,0 +1,87 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"An example that writes to and reads from Kafka.\n+\n+ This example reads from the PubSub NYC Taxi stream described in\n+ https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon, writes to a\n+ given Kafka topic and reads back from the same Kafka topic.\n+ \"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import argparse\n+import logging\n+import typing\n+\n+import apache_beam as beam\n+from apache_beam.io.kafka import ReadFromKafka\n+from apache_beam.io.kafka import WriteToKafka\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.options.pipeline_options import SetupOptions\n+from apache_beam.options.pipeline_options import StandardOptions\n+\n+\n+def run(argv=None):\n+  \"\"\"Main entry point; defines and runs the wordcount pipeline.\"\"\"\n+  parser = argparse.ArgumentParser()\n+  parser.add_argument(\n+      '--bootstrap_servers',\n+      dest='bootstrap_servers',\n+      required=True,\n+      help='Bootstrap servers for the Kafka cluster. Should be accessible by '\n+      'the runner')\n+  parser.add_argument(\n+      '--topic',\n+      dest='topic',\n+      default='kafka_taxirides_realtime',\n+      help='Kafka topic to write to and read from')\n+  known_args, pipeline_args = parser.parse_known_args(argv)\n+\n+  pipeline_options = PipelineOptions(pipeline_args)\n+  pipeline_options.view_as(SetupOptions).save_main_session = True\n+  pipeline_options.view_as(StandardOptions).streaming = True\n+\n+  pipeline = beam.Pipeline(options=pipeline_options)\n+  bootstrap_servers = known_args.bootstrap_servers\n+  _ = (\n+      pipeline\n+      | beam.io.ReadFromPubSub(\n+          topic='projects/pubsub-public-data/topics/taxirides-realtime').\n+      with_output_types(bytes)\n+      | beam.Map(lambda x: (b'', x)).with_output_types(\n+          typing.Tuple[bytes, bytes])\n+      | beam.WindowInto(beam.window.FixedWindows(15))\n+      | WriteToKafka(\n+          producer_config={'bootstrap.servers': bootstrap_servers},\n+          topic=known_args.topic))\n+\n+  _ = (\n+      pipeline\n+      | ReadFromKafka(\n+          consumer_config={'bootstrap.servers': bootstrap_servers},\n+          topics=[known_args.topic])\n+      | beam.FlatMap(lambda x: []))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 80}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ1MTE3NDU3", "url": "https://github.com/apache/beam/pull/12188#pullrequestreview-445117457", "createdAt": "2020-07-08T20:48:10Z", "commit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "state": "COMMENTED", "comments": {"totalCount": 17, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOFQyMDo0ODoxMFrOGu4rmQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOFQyMTozMjoyNlrOGu5-RQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTgxNjM0NQ==", "bodyText": "Can we link to https://adoptopenjdk.net/?variant=openjdk11&jvmVariant=openj9 for installing Java?", "url": "https://github.com/apache/beam/pull/12188#discussion_r451816345", "createdAt": "2020-07-08T20:48:10Z", "author": {"login": "davidcavazos"}, "path": "sdks/python/apache_beam/examples/kafkataxi/README.md", "diffHunk": "@@ -0,0 +1,164 @@\n+<!--\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+-->\n+\n+# Python KafkaIO Example\n+\n+This example reads from the PubSub NYC Taxi stream described\n+[here](https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon), writes\n+to a given Kafka topic and reads back from the same Kafka topic. This example\n+uses cross-language transforms available in\n+[kafka.py](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/kafka.py).\n+Transforms are implemented in Java and are available\n+[here](https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java).\n+\n+## Prerequisites\n+\n+Install Java in your system and make sure that `java` command is available in ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTgxNzE3MQ==", "bodyText": "Can we get rid of the initial > and the \"output\"? It makes it trickier to copy-paste the command.\njava --version", "url": "https://github.com/apache/beam/pull/12188#discussion_r451817171", "createdAt": "2020-07-08T20:49:53Z", "author": {"login": "davidcavazos"}, "path": "sdks/python/apache_beam/examples/kafkataxi/README.md", "diffHunk": "@@ -0,0 +1,164 @@\n+<!--\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+-->\n+\n+# Python KafkaIO Example\n+\n+This example reads from the PubSub NYC Taxi stream described\n+[here](https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon), writes\n+to a given Kafka topic and reads back from the same Kafka topic. This example\n+uses cross-language transforms available in\n+[kafka.py](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/kafka.py).\n+Transforms are implemented in Java and are available\n+[here](https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java).\n+\n+## Prerequisites\n+\n+Install Java in your system and make sure that `java` command is available in \n+the environment.\n+\n+```sh\n+>java --version", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTgxNzU3OA==", "bodyText": "Can we link to http://kafka.apache.org/quickstart ?", "url": "https://github.com/apache/beam/pull/12188#discussion_r451817578", "createdAt": "2020-07-08T20:50:39Z", "author": {"login": "davidcavazos"}, "path": "sdks/python/apache_beam/examples/kafkataxi/README.md", "diffHunk": "@@ -0,0 +1,164 @@\n+<!--\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+-->\n+\n+# Python KafkaIO Example\n+\n+This example reads from the PubSub NYC Taxi stream described\n+[here](https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon), writes\n+to a given Kafka topic and reads back from the same Kafka topic. This example\n+uses cross-language transforms available in\n+[kafka.py](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/kafka.py).\n+Transforms are implemented in Java and are available\n+[here](https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java).\n+\n+## Prerequisites\n+\n+Install Java in your system and make sure that `java` command is available in \n+the environment.\n+\n+```sh\n+>java --version\n+> <Should print information regarding the installed Java version>\n+```\n+\n+## Setup the Kafka cluster\n+\n+This example requires users to setup a Kafka cluster that the Beam runner\n+executing the pipeline has access to. There are few options.\n+\n+* For local runners that execute the pipelines in a single computer (for ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTgxODIzMw==", "bodyText": "Do we need anything besides java like maven or gradle?", "url": "https://github.com/apache/beam/pull/12188#discussion_r451818233", "createdAt": "2020-07-08T20:51:56Z", "author": {"login": "davidcavazos"}, "path": "sdks/python/apache_beam/examples/kafkataxi/README.md", "diffHunk": "@@ -0,0 +1,164 @@\n+<!--\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+-->\n+\n+# Python KafkaIO Example\n+\n+This example reads from the PubSub NYC Taxi stream described\n+[here](https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon), writes\n+to a given Kafka topic and reads back from the same Kafka topic. This example\n+uses cross-language transforms available in\n+[kafka.py](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/kafka.py).\n+Transforms are implemented in Java and are available\n+[here](https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java).\n+\n+## Prerequisites\n+\n+Install Java in your system and make sure that `java` command is available in \n+the environment.\n+\n+```sh\n+>java --version\n+> <Should print information regarding the installed Java version>\n+```", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTgyMDgzOQ==", "bodyText": "Can we get rid of the > as well?\nFor this command example, we could assume it's running locally. Someone not familiar with IP addresses might not know what KAFKA_ADDRESS means. We could mention that if you're running it in a distributed environment you'll need to replace the address with its public IP address.\nexport BOOTSTRAP_SERVER=127.0.0.1:9092\n\n[edit]: after looking below, it looks like this guide's instructions are only written in Dataflow. If that's the case, running Kafka locally won't work since Dataflow needs to reach the Kafka address. Should we take out any mention of running it locally and just assume users will run it in a distributed environment?", "url": "https://github.com/apache/beam/pull/12188#discussion_r451820839", "createdAt": "2020-07-08T20:57:12Z", "author": {"login": "davidcavazos"}, "path": "sdks/python/apache_beam/examples/kafkataxi/README.md", "diffHunk": "@@ -0,0 +1,164 @@\n+<!--\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+-->\n+\n+# Python KafkaIO Example\n+\n+This example reads from the PubSub NYC Taxi stream described\n+[here](https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon), writes\n+to a given Kafka topic and reads back from the same Kafka topic. This example\n+uses cross-language transforms available in\n+[kafka.py](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/kafka.py).\n+Transforms are implemented in Java and are available\n+[here](https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java).\n+\n+## Prerequisites\n+\n+Install Java in your system and make sure that `java` command is available in \n+the environment.\n+\n+```sh\n+>java --version\n+> <Should print information regarding the installed Java version>\n+```\n+\n+## Setup the Kafka cluster\n+\n+This example requires users to setup a Kafka cluster that the Beam runner\n+executing the pipeline has access to. There are few options.\n+\n+* For local runners that execute the pipelines in a single computer (for \n+example, portable DirectRunner or Spark/Flink runners in local mode), you can \n+setup a local Kafka cluster running in the same computer.\n+* For Dataflow or portable Spark/Flink in distributed mode, you can setup a Kafka \n+cluster in GCE. See \n+[here](https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/dataflow/flex-templates/kafka_to_bigquery) \n+for step by step instructions for this.\n+\n+Let's assume that that IP address of the node running the Kafka cluster to be \n+`KAFKA_ADDRESS` and the port to be `9092`.\n+\n+```sh\n+> export BOOTSTRAP_SERVER=KAFKA_ADDRESS:9092", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTgyNDUxMQ==", "bodyText": "Typo on link? (short name)[url] -> [url](short name)", "url": "https://github.com/apache/beam/pull/12188#discussion_r451824511", "createdAt": "2020-07-08T21:04:38Z", "author": {"login": "davidcavazos"}, "path": "sdks/python/apache_beam/examples/kafkataxi/README.md", "diffHunk": "@@ -0,0 +1,164 @@\n+<!--\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+-->\n+\n+# Python KafkaIO Example\n+\n+This example reads from the PubSub NYC Taxi stream described\n+[here](https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon), writes\n+to a given Kafka topic and reads back from the same Kafka topic. This example\n+uses cross-language transforms available in\n+[kafka.py](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/kafka.py).\n+Transforms are implemented in Java and are available\n+[here](https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java).\n+\n+## Prerequisites\n+\n+Install Java in your system and make sure that `java` command is available in \n+the environment.\n+\n+```sh\n+>java --version\n+> <Should print information regarding the installed Java version>\n+```\n+\n+## Setup the Kafka cluster\n+\n+This example requires users to setup a Kafka cluster that the Beam runner\n+executing the pipeline has access to. There are few options.\n+\n+* For local runners that execute the pipelines in a single computer (for \n+example, portable DirectRunner or Spark/Flink runners in local mode), you can \n+setup a local Kafka cluster running in the same computer.\n+* For Dataflow or portable Spark/Flink in distributed mode, you can setup a Kafka \n+cluster in GCE. See \n+[here](https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/dataflow/flex-templates/kafka_to_bigquery) \n+for step by step instructions for this.\n+\n+Let's assume that that IP address of the node running the Kafka cluster to be \n+`KAFKA_ADDRESS` and the port to be `9092`.\n+\n+```sh\n+> export BOOTSTRAP_SERVER=KAFKA_ADDRESS:9092\n+```\n+\n+## Running the example on latest released Beam version\n+\n+Perform Beam runner specific setup. Note that cross-language transforms require \n+portable implementations of Spark/Flink/Direct runners. Dataflow requires\n+(runner V2)[https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#dataflow-runner-v2]", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTgyNTA2Ng==", "bodyText": "Can we remove the > from here as well?\nIn general, we can assume users will run these commands in their working directory of choice, so I would say we can safely omit the export WORK_DIRECTORY and cd $WORK_DIRECTORY instructions.", "url": "https://github.com/apache/beam/pull/12188#discussion_r451825066", "createdAt": "2020-07-08T21:05:47Z", "author": {"login": "davidcavazos"}, "path": "sdks/python/apache_beam/examples/kafkataxi/README.md", "diffHunk": "@@ -0,0 +1,164 @@\n+<!--\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+-->\n+\n+# Python KafkaIO Example\n+\n+This example reads from the PubSub NYC Taxi stream described\n+[here](https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon), writes\n+to a given Kafka topic and reads back from the same Kafka topic. This example\n+uses cross-language transforms available in\n+[kafka.py](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/kafka.py).\n+Transforms are implemented in Java and are available\n+[here](https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java).\n+\n+## Prerequisites\n+\n+Install Java in your system and make sure that `java` command is available in \n+the environment.\n+\n+```sh\n+>java --version\n+> <Should print information regarding the installed Java version>\n+```\n+\n+## Setup the Kafka cluster\n+\n+This example requires users to setup a Kafka cluster that the Beam runner\n+executing the pipeline has access to. There are few options.\n+\n+* For local runners that execute the pipelines in a single computer (for \n+example, portable DirectRunner or Spark/Flink runners in local mode), you can \n+setup a local Kafka cluster running in the same computer.\n+* For Dataflow or portable Spark/Flink in distributed mode, you can setup a Kafka \n+cluster in GCE. See \n+[here](https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/dataflow/flex-templates/kafka_to_bigquery) \n+for step by step instructions for this.\n+\n+Let's assume that that IP address of the node running the Kafka cluster to be \n+`KAFKA_ADDRESS` and the port to be `9092`.\n+\n+```sh\n+> export BOOTSTRAP_SERVER=KAFKA_ADDRESS:9092\n+```\n+\n+## Running the example on latest released Beam version\n+\n+Perform Beam runner specific setup. Note that cross-language transforms require \n+portable implementations of Spark/Flink/Direct runners. Dataflow requires\n+(runner V2)[https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#dataflow-runner-v2]\n+and Beam 2.22.0 or later. See\n+[here](https://beam.apache.org/documentation/runners/dataflow/) for \n+instructions for setting up Dataflow.\n+\n+Setup a virtual environment for running Beam Python programs. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for prerequisites. \n+Dataflow requires the `gcp` tag. Assuming your work directory to be\n+`/path/to/work`.\n+\n+```sh\n+> export WORK_DIRECTORY=/path/to/work", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTgyOTEzMQ==", "bodyText": "As of Python 3, the recommended way to create virtual environments is through venv which already comes preinstalled with Python.\nI would also use the more \"standard\" name env for the virtualenv, it's more familiar and a good assumption for most tools.\nIn zsh using pip install -e .[gcp] gets interpreted a little bit different, so it's actually a good idea to surround the .[gcp] in quotes.\nAlso, is there any reason to install -e '.[gcp]' instead of -U 'apache-beam[gcp]'?\npython -m venv env\nsource env/bin/activate\npip install -e '.[gcp]'", "url": "https://github.com/apache/beam/pull/12188#discussion_r451829131", "createdAt": "2020-07-08T21:14:16Z", "author": {"login": "davidcavazos"}, "path": "sdks/python/apache_beam/examples/kafkataxi/README.md", "diffHunk": "@@ -0,0 +1,164 @@\n+<!--\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+-->\n+\n+# Python KafkaIO Example\n+\n+This example reads from the PubSub NYC Taxi stream described\n+[here](https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon), writes\n+to a given Kafka topic and reads back from the same Kafka topic. This example\n+uses cross-language transforms available in\n+[kafka.py](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/kafka.py).\n+Transforms are implemented in Java and are available\n+[here](https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java).\n+\n+## Prerequisites\n+\n+Install Java in your system and make sure that `java` command is available in \n+the environment.\n+\n+```sh\n+>java --version\n+> <Should print information regarding the installed Java version>\n+```\n+\n+## Setup the Kafka cluster\n+\n+This example requires users to setup a Kafka cluster that the Beam runner\n+executing the pipeline has access to. There are few options.\n+\n+* For local runners that execute the pipelines in a single computer (for \n+example, portable DirectRunner or Spark/Flink runners in local mode), you can \n+setup a local Kafka cluster running in the same computer.\n+* For Dataflow or portable Spark/Flink in distributed mode, you can setup a Kafka \n+cluster in GCE. See \n+[here](https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/dataflow/flex-templates/kafka_to_bigquery) \n+for step by step instructions for this.\n+\n+Let's assume that that IP address of the node running the Kafka cluster to be \n+`KAFKA_ADDRESS` and the port to be `9092`.\n+\n+```sh\n+> export BOOTSTRAP_SERVER=KAFKA_ADDRESS:9092\n+```\n+\n+## Running the example on latest released Beam version\n+\n+Perform Beam runner specific setup. Note that cross-language transforms require \n+portable implementations of Spark/Flink/Direct runners. Dataflow requires\n+(runner V2)[https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#dataflow-runner-v2]\n+and Beam 2.22.0 or later. See\n+[here](https://beam.apache.org/documentation/runners/dataflow/) for \n+instructions for setting up Dataflow.\n+\n+Setup a virtual environment for running Beam Python programs. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for prerequisites. \n+Dataflow requires the `gcp` tag. Assuming your work directory to be\n+`/path/to/work`.\n+\n+```sh\n+> export WORK_DIRECTORY=/path/to/work\n+> cd $WORK_DIRECTORY\n+> mkdir kafka_env\n+> virtualenv kafka_env", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTgzNDI3Nw==", "bodyText": "Can we get rid of the > from here as well?\nI would highly suggest breaking this command into separate lines for readability.\nIt would also be a good idea to set variables beforehand so that once they set those variables, they can copy-paste the rest of the command.\nI would link to the Dataflow regional endpoints docs for more information about the --region.\nPROJECT=\"$(gcloud config get-value project)\"\nTEMP_LOCATION=\"gs://MY-BUCKET/temp\"\nREGION=\"us-central1\"\nJOB_NAME=\"kafka_taxi-`date +%Y%m%d-%H%M%S`\"\nBOOTSTRAP_SERVER=\"123.45.67.89:123\"\n\npython -m apache_beam.examples.kafkataxi.kafka_taxi \\\n  --runner \"DataflowRunner\" \\\n  --project \"$PROJECT\" \\\n  --temp_location \"$TEMP_LOCATION\" \\\n  --region \"$REGION\" \\\n  --num_workers 1 \\\n  --job_name \"$JOB_NAME\" \\\n  --bootstrap_servers \"$BOOTSTRAP_SERVER\" \\\n  --experiments \"use_runner_v2\"", "url": "https://github.com/apache/beam/pull/12188#discussion_r451834277", "createdAt": "2020-07-08T21:25:43Z", "author": {"login": "davidcavazos"}, "path": "sdks/python/apache_beam/examples/kafkataxi/README.md", "diffHunk": "@@ -0,0 +1,164 @@\n+<!--\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+-->\n+\n+# Python KafkaIO Example\n+\n+This example reads from the PubSub NYC Taxi stream described\n+[here](https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon), writes\n+to a given Kafka topic and reads back from the same Kafka topic. This example\n+uses cross-language transforms available in\n+[kafka.py](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/kafka.py).\n+Transforms are implemented in Java and are available\n+[here](https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java).\n+\n+## Prerequisites\n+\n+Install Java in your system and make sure that `java` command is available in \n+the environment.\n+\n+```sh\n+>java --version\n+> <Should print information regarding the installed Java version>\n+```\n+\n+## Setup the Kafka cluster\n+\n+This example requires users to setup a Kafka cluster that the Beam runner\n+executing the pipeline has access to. There are few options.\n+\n+* For local runners that execute the pipelines in a single computer (for \n+example, portable DirectRunner or Spark/Flink runners in local mode), you can \n+setup a local Kafka cluster running in the same computer.\n+* For Dataflow or portable Spark/Flink in distributed mode, you can setup a Kafka \n+cluster in GCE. See \n+[here](https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/dataflow/flex-templates/kafka_to_bigquery) \n+for step by step instructions for this.\n+\n+Let's assume that that IP address of the node running the Kafka cluster to be \n+`KAFKA_ADDRESS` and the port to be `9092`.\n+\n+```sh\n+> export BOOTSTRAP_SERVER=KAFKA_ADDRESS:9092\n+```\n+\n+## Running the example on latest released Beam version\n+\n+Perform Beam runner specific setup. Note that cross-language transforms require \n+portable implementations of Spark/Flink/Direct runners. Dataflow requires\n+(runner V2)[https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#dataflow-runner-v2]\n+and Beam 2.22.0 or later. See\n+[here](https://beam.apache.org/documentation/runners/dataflow/) for \n+instructions for setting up Dataflow.\n+\n+Setup a virtual environment for running Beam Python programs. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for prerequisites. \n+Dataflow requires the `gcp` tag. Assuming your work directory to be\n+`/path/to/work`.\n+\n+```sh\n+> export WORK_DIRECTORY=/path/to/work\n+> cd $WORK_DIRECTORY\n+> mkdir kafka_env\n+> virtualenv kafka_env\n+> . kafka_env/bin/activate\n+> pip install -e .[gcp]\n+```\n+\n+Run the Beam pipeline. You can either use the default Kafka topic name or \n+specify a Kafka topic name. Following command assumes Dataflow. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for instructions on \n+running Beam Python programs on other runners. Note that you have to fill in \n+information mentioned within angle brackets (`<` and `>`).\n+\n+Note that this exemple is not available in Beam versions before 2.24.0 hence\n+you'll have to either get the example program from Beam or follow steps\n+provided in the section *Running the Example from a Beam Git Clone*.\n+\n+```sh\n+>  python -m apache_beam.examples.kafkataxi.kafka_taxi --runner DataflowRunner --temp_location <GCS temp location> --project <GCP project>  --region <region> \\", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTgzNTM1NQ==", "bodyText": "I would put an (Optional) note at the beginning of the header to be explicit that it's safe to skip this section if they're not interested in running from a git clone.\n## *(Optional)* Running the Example from a Beam Git Clone", "url": "https://github.com/apache/beam/pull/12188#discussion_r451835355", "createdAt": "2020-07-08T21:27:47Z", "author": {"login": "davidcavazos"}, "path": "sdks/python/apache_beam/examples/kafkataxi/README.md", "diffHunk": "@@ -0,0 +1,164 @@\n+<!--\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+-->\n+\n+# Python KafkaIO Example\n+\n+This example reads from the PubSub NYC Taxi stream described\n+[here](https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon), writes\n+to a given Kafka topic and reads back from the same Kafka topic. This example\n+uses cross-language transforms available in\n+[kafka.py](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/kafka.py).\n+Transforms are implemented in Java and are available\n+[here](https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java).\n+\n+## Prerequisites\n+\n+Install Java in your system and make sure that `java` command is available in \n+the environment.\n+\n+```sh\n+>java --version\n+> <Should print information regarding the installed Java version>\n+```\n+\n+## Setup the Kafka cluster\n+\n+This example requires users to setup a Kafka cluster that the Beam runner\n+executing the pipeline has access to. There are few options.\n+\n+* For local runners that execute the pipelines in a single computer (for \n+example, portable DirectRunner or Spark/Flink runners in local mode), you can \n+setup a local Kafka cluster running in the same computer.\n+* For Dataflow or portable Spark/Flink in distributed mode, you can setup a Kafka \n+cluster in GCE. See \n+[here](https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/dataflow/flex-templates/kafka_to_bigquery) \n+for step by step instructions for this.\n+\n+Let's assume that that IP address of the node running the Kafka cluster to be \n+`KAFKA_ADDRESS` and the port to be `9092`.\n+\n+```sh\n+> export BOOTSTRAP_SERVER=KAFKA_ADDRESS:9092\n+```\n+\n+## Running the example on latest released Beam version\n+\n+Perform Beam runner specific setup. Note that cross-language transforms require \n+portable implementations of Spark/Flink/Direct runners. Dataflow requires\n+(runner V2)[https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#dataflow-runner-v2]\n+and Beam 2.22.0 or later. See\n+[here](https://beam.apache.org/documentation/runners/dataflow/) for \n+instructions for setting up Dataflow.\n+\n+Setup a virtual environment for running Beam Python programs. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for prerequisites. \n+Dataflow requires the `gcp` tag. Assuming your work directory to be\n+`/path/to/work`.\n+\n+```sh\n+> export WORK_DIRECTORY=/path/to/work\n+> cd $WORK_DIRECTORY\n+> mkdir kafka_env\n+> virtualenv kafka_env\n+> . kafka_env/bin/activate\n+> pip install -e .[gcp]\n+```\n+\n+Run the Beam pipeline. You can either use the default Kafka topic name or \n+specify a Kafka topic name. Following command assumes Dataflow. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for instructions on \n+running Beam Python programs on other runners. Note that you have to fill in \n+information mentioned within angle brackets (`<` and `>`).\n+\n+Note that this exemple is not available in Beam versions before 2.24.0 hence\n+you'll have to either get the example program from Beam or follow steps\n+provided in the section *Running the Example from a Beam Git Clone*.\n+\n+```sh\n+>  python -m apache_beam.examples.kafkataxi.kafka_taxi --runner DataflowRunner --temp_location <GCS temp location> --project <GCP project>  --region <region> \\\n+   --num_workers 1 --job_name <job name> --bootstrap_servers $BOOTSTRAP_SERVER --experiments=use_runner_v2\n+```\n+\n+## Running the Example from a Beam Git Clone", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTgzNjA4Nw==", "bodyText": "Can we get rid of the > from these as well?\nI think it's also safe to skip the WORK_DIRECTORY step.", "url": "https://github.com/apache/beam/pull/12188#discussion_r451836087", "createdAt": "2020-07-08T21:29:30Z", "author": {"login": "davidcavazos"}, "path": "sdks/python/apache_beam/examples/kafkataxi/README.md", "diffHunk": "@@ -0,0 +1,164 @@\n+<!--\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+-->\n+\n+# Python KafkaIO Example\n+\n+This example reads from the PubSub NYC Taxi stream described\n+[here](https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon), writes\n+to a given Kafka topic and reads back from the same Kafka topic. This example\n+uses cross-language transforms available in\n+[kafka.py](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/kafka.py).\n+Transforms are implemented in Java and are available\n+[here](https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java).\n+\n+## Prerequisites\n+\n+Install Java in your system and make sure that `java` command is available in \n+the environment.\n+\n+```sh\n+>java --version\n+> <Should print information regarding the installed Java version>\n+```\n+\n+## Setup the Kafka cluster\n+\n+This example requires users to setup a Kafka cluster that the Beam runner\n+executing the pipeline has access to. There are few options.\n+\n+* For local runners that execute the pipelines in a single computer (for \n+example, portable DirectRunner or Spark/Flink runners in local mode), you can \n+setup a local Kafka cluster running in the same computer.\n+* For Dataflow or portable Spark/Flink in distributed mode, you can setup a Kafka \n+cluster in GCE. See \n+[here](https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/dataflow/flex-templates/kafka_to_bigquery) \n+for step by step instructions for this.\n+\n+Let's assume that that IP address of the node running the Kafka cluster to be \n+`KAFKA_ADDRESS` and the port to be `9092`.\n+\n+```sh\n+> export BOOTSTRAP_SERVER=KAFKA_ADDRESS:9092\n+```\n+\n+## Running the example on latest released Beam version\n+\n+Perform Beam runner specific setup. Note that cross-language transforms require \n+portable implementations of Spark/Flink/Direct runners. Dataflow requires\n+(runner V2)[https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#dataflow-runner-v2]\n+and Beam 2.22.0 or later. See\n+[here](https://beam.apache.org/documentation/runners/dataflow/) for \n+instructions for setting up Dataflow.\n+\n+Setup a virtual environment for running Beam Python programs. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for prerequisites. \n+Dataflow requires the `gcp` tag. Assuming your work directory to be\n+`/path/to/work`.\n+\n+```sh\n+> export WORK_DIRECTORY=/path/to/work\n+> cd $WORK_DIRECTORY\n+> mkdir kafka_env\n+> virtualenv kafka_env\n+> . kafka_env/bin/activate\n+> pip install -e .[gcp]\n+```\n+\n+Run the Beam pipeline. You can either use the default Kafka topic name or \n+specify a Kafka topic name. Following command assumes Dataflow. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for instructions on \n+running Beam Python programs on other runners. Note that you have to fill in \n+information mentioned within angle brackets (`<` and `>`).\n+\n+Note that this exemple is not available in Beam versions before 2.24.0 hence\n+you'll have to either get the example program from Beam or follow steps\n+provided in the section *Running the Example from a Beam Git Clone*.\n+\n+```sh\n+>  python -m apache_beam.examples.kafkataxi.kafka_taxi --runner DataflowRunner --temp_location <GCS temp location> --project <GCP project>  --region <region> \\\n+   --num_workers 1 --job_name <job name> --bootstrap_servers $BOOTSTRAP_SERVER --experiments=use_runner_v2\n+```\n+\n+## Running the Example from a Beam Git Clone\n+\n+Running this example from a Beam Git clone requires some additional steps.\n+\n+Checkout a clone of the Beam Git repo. See \n+[here](https://beam.apache.org/contribute/) for prerequisites.\n+\n+Assume your Github username to be `GITHUB_USERNAME`.\n+\n+```sh\n+> cd $WORK_DIRECTORY", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 108}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTgzNjIxMA==", "bodyText": "Can we get rid of the > from these as well?", "url": "https://github.com/apache/beam/pull/12188#discussion_r451836210", "createdAt": "2020-07-08T21:29:45Z", "author": {"login": "davidcavazos"}, "path": "sdks/python/apache_beam/examples/kafkataxi/README.md", "diffHunk": "@@ -0,0 +1,164 @@\n+<!--\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+-->\n+\n+# Python KafkaIO Example\n+\n+This example reads from the PubSub NYC Taxi stream described\n+[here](https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon), writes\n+to a given Kafka topic and reads back from the same Kafka topic. This example\n+uses cross-language transforms available in\n+[kafka.py](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/kafka.py).\n+Transforms are implemented in Java and are available\n+[here](https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java).\n+\n+## Prerequisites\n+\n+Install Java in your system and make sure that `java` command is available in \n+the environment.\n+\n+```sh\n+>java --version\n+> <Should print information regarding the installed Java version>\n+```\n+\n+## Setup the Kafka cluster\n+\n+This example requires users to setup a Kafka cluster that the Beam runner\n+executing the pipeline has access to. There are few options.\n+\n+* For local runners that execute the pipelines in a single computer (for \n+example, portable DirectRunner or Spark/Flink runners in local mode), you can \n+setup a local Kafka cluster running in the same computer.\n+* For Dataflow or portable Spark/Flink in distributed mode, you can setup a Kafka \n+cluster in GCE. See \n+[here](https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/dataflow/flex-templates/kafka_to_bigquery) \n+for step by step instructions for this.\n+\n+Let's assume that that IP address of the node running the Kafka cluster to be \n+`KAFKA_ADDRESS` and the port to be `9092`.\n+\n+```sh\n+> export BOOTSTRAP_SERVER=KAFKA_ADDRESS:9092\n+```\n+\n+## Running the example on latest released Beam version\n+\n+Perform Beam runner specific setup. Note that cross-language transforms require \n+portable implementations of Spark/Flink/Direct runners. Dataflow requires\n+(runner V2)[https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#dataflow-runner-v2]\n+and Beam 2.22.0 or later. See\n+[here](https://beam.apache.org/documentation/runners/dataflow/) for \n+instructions for setting up Dataflow.\n+\n+Setup a virtual environment for running Beam Python programs. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for prerequisites. \n+Dataflow requires the `gcp` tag. Assuming your work directory to be\n+`/path/to/work`.\n+\n+```sh\n+> export WORK_DIRECTORY=/path/to/work\n+> cd $WORK_DIRECTORY\n+> mkdir kafka_env\n+> virtualenv kafka_env\n+> . kafka_env/bin/activate\n+> pip install -e .[gcp]\n+```\n+\n+Run the Beam pipeline. You can either use the default Kafka topic name or \n+specify a Kafka topic name. Following command assumes Dataflow. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for instructions on \n+running Beam Python programs on other runners. Note that you have to fill in \n+information mentioned within angle brackets (`<` and `>`).\n+\n+Note that this exemple is not available in Beam versions before 2.24.0 hence\n+you'll have to either get the example program from Beam or follow steps\n+provided in the section *Running the Example from a Beam Git Clone*.\n+\n+```sh\n+>  python -m apache_beam.examples.kafkataxi.kafka_taxi --runner DataflowRunner --temp_location <GCS temp location> --project <GCP project>  --region <region> \\\n+   --num_workers 1 --job_name <job name> --bootstrap_servers $BOOTSTRAP_SERVER --experiments=use_runner_v2\n+```\n+\n+## Running the Example from a Beam Git Clone\n+\n+Running this example from a Beam Git clone requires some additional steps.\n+\n+Checkout a clone of the Beam Git repo. See \n+[here](https://beam.apache.org/contribute/) for prerequisites.\n+\n+Assume your Github username to be `GITHUB_USERNAME`.\n+\n+```sh\n+> cd $WORK_DIRECTORY\n+> git clone git@github.com:${GITHUB_USERNAME}/beam\n+> cd beam\n+```\n+\n+Build IO expansion service jar.\n+\n+```sh\n+> ./gradlew :sdks:java:io:expansion-service:build", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTgzNjI5MQ==", "bodyText": "Can we get rid of the > from these as well?", "url": "https://github.com/apache/beam/pull/12188#discussion_r451836291", "createdAt": "2020-07-08T21:29:56Z", "author": {"login": "davidcavazos"}, "path": "sdks/python/apache_beam/examples/kafkataxi/README.md", "diffHunk": "@@ -0,0 +1,164 @@\n+<!--\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+-->\n+\n+# Python KafkaIO Example\n+\n+This example reads from the PubSub NYC Taxi stream described\n+[here](https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon), writes\n+to a given Kafka topic and reads back from the same Kafka topic. This example\n+uses cross-language transforms available in\n+[kafka.py](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/kafka.py).\n+Transforms are implemented in Java and are available\n+[here](https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java).\n+\n+## Prerequisites\n+\n+Install Java in your system and make sure that `java` command is available in \n+the environment.\n+\n+```sh\n+>java --version\n+> <Should print information regarding the installed Java version>\n+```\n+\n+## Setup the Kafka cluster\n+\n+This example requires users to setup a Kafka cluster that the Beam runner\n+executing the pipeline has access to. There are few options.\n+\n+* For local runners that execute the pipelines in a single computer (for \n+example, portable DirectRunner or Spark/Flink runners in local mode), you can \n+setup a local Kafka cluster running in the same computer.\n+* For Dataflow or portable Spark/Flink in distributed mode, you can setup a Kafka \n+cluster in GCE. See \n+[here](https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/dataflow/flex-templates/kafka_to_bigquery) \n+for step by step instructions for this.\n+\n+Let's assume that that IP address of the node running the Kafka cluster to be \n+`KAFKA_ADDRESS` and the port to be `9092`.\n+\n+```sh\n+> export BOOTSTRAP_SERVER=KAFKA_ADDRESS:9092\n+```\n+\n+## Running the example on latest released Beam version\n+\n+Perform Beam runner specific setup. Note that cross-language transforms require \n+portable implementations of Spark/Flink/Direct runners. Dataflow requires\n+(runner V2)[https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#dataflow-runner-v2]\n+and Beam 2.22.0 or later. See\n+[here](https://beam.apache.org/documentation/runners/dataflow/) for \n+instructions for setting up Dataflow.\n+\n+Setup a virtual environment for running Beam Python programs. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for prerequisites. \n+Dataflow requires the `gcp` tag. Assuming your work directory to be\n+`/path/to/work`.\n+\n+```sh\n+> export WORK_DIRECTORY=/path/to/work\n+> cd $WORK_DIRECTORY\n+> mkdir kafka_env\n+> virtualenv kafka_env\n+> . kafka_env/bin/activate\n+> pip install -e .[gcp]\n+```\n+\n+Run the Beam pipeline. You can either use the default Kafka topic name or \n+specify a Kafka topic name. Following command assumes Dataflow. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for instructions on \n+running Beam Python programs on other runners. Note that you have to fill in \n+information mentioned within angle brackets (`<` and `>`).\n+\n+Note that this exemple is not available in Beam versions before 2.24.0 hence\n+you'll have to either get the example program from Beam or follow steps\n+provided in the section *Running the Example from a Beam Git Clone*.\n+\n+```sh\n+>  python -m apache_beam.examples.kafkataxi.kafka_taxi --runner DataflowRunner --temp_location <GCS temp location> --project <GCP project>  --region <region> \\\n+   --num_workers 1 --job_name <job name> --bootstrap_servers $BOOTSTRAP_SERVER --experiments=use_runner_v2\n+```\n+\n+## Running the Example from a Beam Git Clone\n+\n+Running this example from a Beam Git clone requires some additional steps.\n+\n+Checkout a clone of the Beam Git repo. See \n+[here](https://beam.apache.org/contribute/) for prerequisites.\n+\n+Assume your Github username to be `GITHUB_USERNAME`.\n+\n+```sh\n+> cd $WORK_DIRECTORY\n+> git clone git@github.com:${GITHUB_USERNAME}/beam\n+> cd beam\n+```\n+\n+Build IO expansion service jar.\n+\n+```sh\n+> ./gradlew :sdks:java:io:expansion-service:build\n+```\n+\n+Push a java SDK Harness container to Docker Hub. See \n+[here](https://beam.apache.org/documentation/runtime/environments/) for \n+prerequisites and additional information. Note that you have to fill in \n+information mentioned within angle brackets (`<` and `>`). Assume your Docker\n+repository root to be `<Docker repository root>`.\n+\n+```sh\n+> export DOCKER_ROOT=<Docker repository root>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 126}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTgzNjU1Ng==", "bodyText": "Same as the previous section", "url": "https://github.com/apache/beam/pull/12188#discussion_r451836556", "createdAt": "2020-07-08T21:30:30Z", "author": {"login": "davidcavazos"}, "path": "sdks/python/apache_beam/examples/kafkataxi/README.md", "diffHunk": "@@ -0,0 +1,164 @@\n+<!--\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+-->\n+\n+# Python KafkaIO Example\n+\n+This example reads from the PubSub NYC Taxi stream described\n+[here](https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon), writes\n+to a given Kafka topic and reads back from the same Kafka topic. This example\n+uses cross-language transforms available in\n+[kafka.py](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/kafka.py).\n+Transforms are implemented in Java and are available\n+[here](https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java).\n+\n+## Prerequisites\n+\n+Install Java in your system and make sure that `java` command is available in \n+the environment.\n+\n+```sh\n+>java --version\n+> <Should print information regarding the installed Java version>\n+```\n+\n+## Setup the Kafka cluster\n+\n+This example requires users to setup a Kafka cluster that the Beam runner\n+executing the pipeline has access to. There are few options.\n+\n+* For local runners that execute the pipelines in a single computer (for \n+example, portable DirectRunner or Spark/Flink runners in local mode), you can \n+setup a local Kafka cluster running in the same computer.\n+* For Dataflow or portable Spark/Flink in distributed mode, you can setup a Kafka \n+cluster in GCE. See \n+[here](https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/dataflow/flex-templates/kafka_to_bigquery) \n+for step by step instructions for this.\n+\n+Let's assume that that IP address of the node running the Kafka cluster to be \n+`KAFKA_ADDRESS` and the port to be `9092`.\n+\n+```sh\n+> export BOOTSTRAP_SERVER=KAFKA_ADDRESS:9092\n+```\n+\n+## Running the example on latest released Beam version\n+\n+Perform Beam runner specific setup. Note that cross-language transforms require \n+portable implementations of Spark/Flink/Direct runners. Dataflow requires\n+(runner V2)[https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#dataflow-runner-v2]\n+and Beam 2.22.0 or later. See\n+[here](https://beam.apache.org/documentation/runners/dataflow/) for \n+instructions for setting up Dataflow.\n+\n+Setup a virtual environment for running Beam Python programs. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for prerequisites. \n+Dataflow requires the `gcp` tag. Assuming your work directory to be\n+`/path/to/work`.\n+\n+```sh\n+> export WORK_DIRECTORY=/path/to/work\n+> cd $WORK_DIRECTORY\n+> mkdir kafka_env\n+> virtualenv kafka_env\n+> . kafka_env/bin/activate\n+> pip install -e .[gcp]\n+```\n+\n+Run the Beam pipeline. You can either use the default Kafka topic name or \n+specify a Kafka topic name. Following command assumes Dataflow. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for instructions on \n+running Beam Python programs on other runners. Note that you have to fill in \n+information mentioned within angle brackets (`<` and `>`).\n+\n+Note that this exemple is not available in Beam versions before 2.24.0 hence\n+you'll have to either get the example program from Beam or follow steps\n+provided in the section *Running the Example from a Beam Git Clone*.\n+\n+```sh\n+>  python -m apache_beam.examples.kafkataxi.kafka_taxi --runner DataflowRunner --temp_location <GCS temp location> --project <GCP project>  --region <region> \\\n+   --num_workers 1 --job_name <job name> --bootstrap_servers $BOOTSTRAP_SERVER --experiments=use_runner_v2\n+```\n+\n+## Running the Example from a Beam Git Clone\n+\n+Running this example from a Beam Git clone requires some additional steps.\n+\n+Checkout a clone of the Beam Git repo. See \n+[here](https://beam.apache.org/contribute/) for prerequisites.\n+\n+Assume your Github username to be `GITHUB_USERNAME`.\n+\n+```sh\n+> cd $WORK_DIRECTORY\n+> git clone git@github.com:${GITHUB_USERNAME}/beam\n+> cd beam\n+```\n+\n+Build IO expansion service jar.\n+\n+```sh\n+> ./gradlew :sdks:java:io:expansion-service:build\n+```\n+\n+Push a java SDK Harness container to Docker Hub. See \n+[here](https://beam.apache.org/documentation/runtime/environments/) for \n+prerequisites and additional information. Note that you have to fill in \n+information mentioned within angle brackets (`<` and `>`). Assume your Docker\n+repository root to be `<Docker repository root>`.\n+\n+```sh\n+> export DOCKER_ROOT=<Docker repository root>\n+> ./gradlew :sdks:java:container:docker -Pdocker-repository-root=$DOCKER_ROOT -Pdocker-tag=latest\n+> docker push $DOCKER_ROOT/beam_java_sdk:latest\n+```\n+\n+For portable Flink/Spark in local mode, instead of above command just build the\n+Java SDK harness container locally using the default values for repository root\n+and the docker tag.\n+\n+Activate your Python virtual environment.  This example uses `virtualenv`. See \n+[here](https://cwiki.apache.org/confluence/display/BEAM/Python+Tips) for\n+instructions regarding setting up other types of Python virtual environments.\n+\n+```sh\n+> cd $WORK_DIRECTORY", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 140}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTgzNjg3MA==", "bodyText": "Can we get rid of the > from these as well?\nI would also surround the .[gcp,test] in single quotes for zsh users.", "url": "https://github.com/apache/beam/pull/12188#discussion_r451836870", "createdAt": "2020-07-08T21:31:08Z", "author": {"login": "davidcavazos"}, "path": "sdks/python/apache_beam/examples/kafkataxi/README.md", "diffHunk": "@@ -0,0 +1,164 @@\n+<!--\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+-->\n+\n+# Python KafkaIO Example\n+\n+This example reads from the PubSub NYC Taxi stream described\n+[here](https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon), writes\n+to a given Kafka topic and reads back from the same Kafka topic. This example\n+uses cross-language transforms available in\n+[kafka.py](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/kafka.py).\n+Transforms are implemented in Java and are available\n+[here](https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java).\n+\n+## Prerequisites\n+\n+Install Java in your system and make sure that `java` command is available in \n+the environment.\n+\n+```sh\n+>java --version\n+> <Should print information regarding the installed Java version>\n+```\n+\n+## Setup the Kafka cluster\n+\n+This example requires users to setup a Kafka cluster that the Beam runner\n+executing the pipeline has access to. There are few options.\n+\n+* For local runners that execute the pipelines in a single computer (for \n+example, portable DirectRunner or Spark/Flink runners in local mode), you can \n+setup a local Kafka cluster running in the same computer.\n+* For Dataflow or portable Spark/Flink in distributed mode, you can setup a Kafka \n+cluster in GCE. See \n+[here](https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/dataflow/flex-templates/kafka_to_bigquery) \n+for step by step instructions for this.\n+\n+Let's assume that that IP address of the node running the Kafka cluster to be \n+`KAFKA_ADDRESS` and the port to be `9092`.\n+\n+```sh\n+> export BOOTSTRAP_SERVER=KAFKA_ADDRESS:9092\n+```\n+\n+## Running the example on latest released Beam version\n+\n+Perform Beam runner specific setup. Note that cross-language transforms require \n+portable implementations of Spark/Flink/Direct runners. Dataflow requires\n+(runner V2)[https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#dataflow-runner-v2]\n+and Beam 2.22.0 or later. See\n+[here](https://beam.apache.org/documentation/runners/dataflow/) for \n+instructions for setting up Dataflow.\n+\n+Setup a virtual environment for running Beam Python programs. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for prerequisites. \n+Dataflow requires the `gcp` tag. Assuming your work directory to be\n+`/path/to/work`.\n+\n+```sh\n+> export WORK_DIRECTORY=/path/to/work\n+> cd $WORK_DIRECTORY\n+> mkdir kafka_env\n+> virtualenv kafka_env\n+> . kafka_env/bin/activate\n+> pip install -e .[gcp]\n+```\n+\n+Run the Beam pipeline. You can either use the default Kafka topic name or \n+specify a Kafka topic name. Following command assumes Dataflow. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for instructions on \n+running Beam Python programs on other runners. Note that you have to fill in \n+information mentioned within angle brackets (`<` and `>`).\n+\n+Note that this exemple is not available in Beam versions before 2.24.0 hence\n+you'll have to either get the example program from Beam or follow steps\n+provided in the section *Running the Example from a Beam Git Clone*.\n+\n+```sh\n+>  python -m apache_beam.examples.kafkataxi.kafka_taxi --runner DataflowRunner --temp_location <GCS temp location> --project <GCP project>  --region <region> \\\n+   --num_workers 1 --job_name <job name> --bootstrap_servers $BOOTSTRAP_SERVER --experiments=use_runner_v2\n+```\n+\n+## Running the Example from a Beam Git Clone\n+\n+Running this example from a Beam Git clone requires some additional steps.\n+\n+Checkout a clone of the Beam Git repo. See \n+[here](https://beam.apache.org/contribute/) for prerequisites.\n+\n+Assume your Github username to be `GITHUB_USERNAME`.\n+\n+```sh\n+> cd $WORK_DIRECTORY\n+> git clone git@github.com:${GITHUB_USERNAME}/beam\n+> cd beam\n+```\n+\n+Build IO expansion service jar.\n+\n+```sh\n+> ./gradlew :sdks:java:io:expansion-service:build\n+```\n+\n+Push a java SDK Harness container to Docker Hub. See \n+[here](https://beam.apache.org/documentation/runtime/environments/) for \n+prerequisites and additional information. Note that you have to fill in \n+information mentioned within angle brackets (`<` and `>`). Assume your Docker\n+repository root to be `<Docker repository root>`.\n+\n+```sh\n+> export DOCKER_ROOT=<Docker repository root>\n+> ./gradlew :sdks:java:container:docker -Pdocker-repository-root=$DOCKER_ROOT -Pdocker-tag=latest\n+> docker push $DOCKER_ROOT/beam_java_sdk:latest\n+```\n+\n+For portable Flink/Spark in local mode, instead of above command just build the\n+Java SDK harness container locally using the default values for repository root\n+and the docker tag.\n+\n+Activate your Python virtual environment.  This example uses `virtualenv`. See \n+[here](https://cwiki.apache.org/confluence/display/BEAM/Python+Tips) for\n+instructions regarding setting up other types of Python virtual environments.\n+\n+```sh\n+> cd $WORK_DIRECTORY\n+> mkdir kafka_env\n+> virtualenv kafka_env\n+> . kafka_env/bin/activate\n+```\n+\n+Install Beam and dependencies and build a Beam distribution.\n+\n+```sh\n+> cd beam/sdks/python", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 149}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTgzNzAxOQ==", "bodyText": "Same as the previous section", "url": "https://github.com/apache/beam/pull/12188#discussion_r451837019", "createdAt": "2020-07-08T21:31:25Z", "author": {"login": "davidcavazos"}, "path": "sdks/python/apache_beam/examples/kafkataxi/README.md", "diffHunk": "@@ -0,0 +1,164 @@\n+<!--\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+-->\n+\n+# Python KafkaIO Example\n+\n+This example reads from the PubSub NYC Taxi stream described\n+[here](https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon), writes\n+to a given Kafka topic and reads back from the same Kafka topic. This example\n+uses cross-language transforms available in\n+[kafka.py](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/kafka.py).\n+Transforms are implemented in Java and are available\n+[here](https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java).\n+\n+## Prerequisites\n+\n+Install Java in your system and make sure that `java` command is available in \n+the environment.\n+\n+```sh\n+>java --version\n+> <Should print information regarding the installed Java version>\n+```\n+\n+## Setup the Kafka cluster\n+\n+This example requires users to setup a Kafka cluster that the Beam runner\n+executing the pipeline has access to. There are few options.\n+\n+* For local runners that execute the pipelines in a single computer (for \n+example, portable DirectRunner or Spark/Flink runners in local mode), you can \n+setup a local Kafka cluster running in the same computer.\n+* For Dataflow or portable Spark/Flink in distributed mode, you can setup a Kafka \n+cluster in GCE. See \n+[here](https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/dataflow/flex-templates/kafka_to_bigquery) \n+for step by step instructions for this.\n+\n+Let's assume that that IP address of the node running the Kafka cluster to be \n+`KAFKA_ADDRESS` and the port to be `9092`.\n+\n+```sh\n+> export BOOTSTRAP_SERVER=KAFKA_ADDRESS:9092\n+```\n+\n+## Running the example on latest released Beam version\n+\n+Perform Beam runner specific setup. Note that cross-language transforms require \n+portable implementations of Spark/Flink/Direct runners. Dataflow requires\n+(runner V2)[https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#dataflow-runner-v2]\n+and Beam 2.22.0 or later. See\n+[here](https://beam.apache.org/documentation/runners/dataflow/) for \n+instructions for setting up Dataflow.\n+\n+Setup a virtual environment for running Beam Python programs. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for prerequisites. \n+Dataflow requires the `gcp` tag. Assuming your work directory to be\n+`/path/to/work`.\n+\n+```sh\n+> export WORK_DIRECTORY=/path/to/work\n+> cd $WORK_DIRECTORY\n+> mkdir kafka_env\n+> virtualenv kafka_env\n+> . kafka_env/bin/activate\n+> pip install -e .[gcp]\n+```\n+\n+Run the Beam pipeline. You can either use the default Kafka topic name or \n+specify a Kafka topic name. Following command assumes Dataflow. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for instructions on \n+running Beam Python programs on other runners. Note that you have to fill in \n+information mentioned within angle brackets (`<` and `>`).\n+\n+Note that this exemple is not available in Beam versions before 2.24.0 hence\n+you'll have to either get the example program from Beam or follow steps\n+provided in the section *Running the Example from a Beam Git Clone*.\n+\n+```sh\n+>  python -m apache_beam.examples.kafkataxi.kafka_taxi --runner DataflowRunner --temp_location <GCS temp location> --project <GCP project>  --region <region> \\\n+   --num_workers 1 --job_name <job name> --bootstrap_servers $BOOTSTRAP_SERVER --experiments=use_runner_v2\n+```\n+\n+## Running the Example from a Beam Git Clone\n+\n+Running this example from a Beam Git clone requires some additional steps.\n+\n+Checkout a clone of the Beam Git repo. See \n+[here](https://beam.apache.org/contribute/) for prerequisites.\n+\n+Assume your Github username to be `GITHUB_USERNAME`.\n+\n+```sh\n+> cd $WORK_DIRECTORY\n+> git clone git@github.com:${GITHUB_USERNAME}/beam\n+> cd beam\n+```\n+\n+Build IO expansion service jar.\n+\n+```sh\n+> ./gradlew :sdks:java:io:expansion-service:build\n+```\n+\n+Push a java SDK Harness container to Docker Hub. See \n+[here](https://beam.apache.org/documentation/runtime/environments/) for \n+prerequisites and additional information. Note that you have to fill in \n+information mentioned within angle brackets (`<` and `>`). Assume your Docker\n+repository root to be `<Docker repository root>`.\n+\n+```sh\n+> export DOCKER_ROOT=<Docker repository root>\n+> ./gradlew :sdks:java:container:docker -Pdocker-repository-root=$DOCKER_ROOT -Pdocker-tag=latest\n+> docker push $DOCKER_ROOT/beam_java_sdk:latest\n+```\n+\n+For portable Flink/Spark in local mode, instead of above command just build the\n+Java SDK harness container locally using the default values for repository root\n+and the docker tag.\n+\n+Activate your Python virtual environment.  This example uses `virtualenv`. See \n+[here](https://cwiki.apache.org/confluence/display/BEAM/Python+Tips) for\n+instructions regarding setting up other types of Python virtual environments.\n+\n+```sh\n+> cd $WORK_DIRECTORY\n+> mkdir kafka_env\n+> virtualenv kafka_env\n+> . kafka_env/bin/activate\n+```\n+\n+Install Beam and dependencies and build a Beam distribution.\n+\n+```sh\n+> cd beam/sdks/python\n+> pip install -r build-requirements.txt\n+> pip install -e .[gcp,test]\n+> python setup.py sdist\n+```\n+\n+Run the Beam pipeline. You can either use the default Kafka topic name or specify \n+a Kafka topic name. Following command assumes Dataflow. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for instructions on \n+running Beam Python programs on other runners.\n+\n+```sh\n+>  python -m apache_beam.examples.kafkataxi.kafka_taxi --runner DataflowRunner --temp_location <GCS temp location> --project <GCP project>  --region <region> \\", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 161}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTgzNzUwOQ==", "bodyText": "Can we link to the Docker installation page here? Users might not have docker installed.", "url": "https://github.com/apache/beam/pull/12188#discussion_r451837509", "createdAt": "2020-07-08T21:32:26Z", "author": {"login": "davidcavazos"}, "path": "sdks/python/apache_beam/examples/kafkataxi/README.md", "diffHunk": "@@ -0,0 +1,164 @@\n+<!--\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+-->\n+\n+# Python KafkaIO Example\n+\n+This example reads from the PubSub NYC Taxi stream described\n+[here](https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon), writes\n+to a given Kafka topic and reads back from the same Kafka topic. This example\n+uses cross-language transforms available in\n+[kafka.py](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/kafka.py).\n+Transforms are implemented in Java and are available\n+[here](https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java).\n+\n+## Prerequisites\n+\n+Install Java in your system and make sure that `java` command is available in \n+the environment.\n+\n+```sh\n+>java --version\n+> <Should print information regarding the installed Java version>\n+```\n+\n+## Setup the Kafka cluster\n+\n+This example requires users to setup a Kafka cluster that the Beam runner\n+executing the pipeline has access to. There are few options.\n+\n+* For local runners that execute the pipelines in a single computer (for \n+example, portable DirectRunner or Spark/Flink runners in local mode), you can \n+setup a local Kafka cluster running in the same computer.\n+* For Dataflow or portable Spark/Flink in distributed mode, you can setup a Kafka \n+cluster in GCE. See \n+[here](https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/dataflow/flex-templates/kafka_to_bigquery) \n+for step by step instructions for this.\n+\n+Let's assume that that IP address of the node running the Kafka cluster to be \n+`KAFKA_ADDRESS` and the port to be `9092`.\n+\n+```sh\n+> export BOOTSTRAP_SERVER=KAFKA_ADDRESS:9092\n+```\n+\n+## Running the example on latest released Beam version\n+\n+Perform Beam runner specific setup. Note that cross-language transforms require \n+portable implementations of Spark/Flink/Direct runners. Dataflow requires\n+(runner V2)[https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#dataflow-runner-v2]\n+and Beam 2.22.0 or later. See\n+[here](https://beam.apache.org/documentation/runners/dataflow/) for \n+instructions for setting up Dataflow.\n+\n+Setup a virtual environment for running Beam Python programs. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for prerequisites. \n+Dataflow requires the `gcp` tag. Assuming your work directory to be\n+`/path/to/work`.\n+\n+```sh\n+> export WORK_DIRECTORY=/path/to/work\n+> cd $WORK_DIRECTORY\n+> mkdir kafka_env\n+> virtualenv kafka_env\n+> . kafka_env/bin/activate\n+> pip install -e .[gcp]\n+```\n+\n+Run the Beam pipeline. You can either use the default Kafka topic name or \n+specify a Kafka topic name. Following command assumes Dataflow. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for instructions on \n+running Beam Python programs on other runners. Note that you have to fill in \n+information mentioned within angle brackets (`<` and `>`).\n+\n+Note that this exemple is not available in Beam versions before 2.24.0 hence\n+you'll have to either get the example program from Beam or follow steps\n+provided in the section *Running the Example from a Beam Git Clone*.\n+\n+```sh\n+>  python -m apache_beam.examples.kafkataxi.kafka_taxi --runner DataflowRunner --temp_location <GCS temp location> --project <GCP project>  --region <region> \\\n+   --num_workers 1 --job_name <job name> --bootstrap_servers $BOOTSTRAP_SERVER --experiments=use_runner_v2\n+```\n+\n+## Running the Example from a Beam Git Clone\n+\n+Running this example from a Beam Git clone requires some additional steps.\n+\n+Checkout a clone of the Beam Git repo. See \n+[here](https://beam.apache.org/contribute/) for prerequisites.\n+\n+Assume your Github username to be `GITHUB_USERNAME`.\n+\n+```sh\n+> cd $WORK_DIRECTORY\n+> git clone git@github.com:${GITHUB_USERNAME}/beam\n+> cd beam\n+```\n+\n+Build IO expansion service jar.\n+\n+```sh\n+> ./gradlew :sdks:java:io:expansion-service:build\n+```\n+\n+Push a java SDK Harness container to Docker Hub. See ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 119}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "801d033455b0d6db731305af14456956ef52a146", "author": {"user": {"login": "chamikaramj", "name": "Chamikara Jayalath"}}, "url": "https://github.com/apache/beam/commit/801d033455b0d6db731305af14456956ef52a146", "committedDate": "2020-07-17T08:45:39Z", "message": "Adds an example that use Python cross-language Kafka transforms."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6c791812068c42ef262ea8bb4afb18d92e0b3163", "author": {"user": {"login": "chamikaramj", "name": "Chamikara Jayalath"}}, "url": "https://github.com/apache/beam/commit/6c791812068c42ef262ea8bb4afb18d92e0b3163", "committedDate": "2020-07-17T08:45:39Z", "message": "Address reviewer comments"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6", "author": {"user": {"login": "chamikaramj", "name": "Chamikara Jayalath"}}, "url": "https://github.com/apache/beam/commit/c01d0f0d0cea545632809131a8dc5a1adeaa9db6", "committedDate": "2020-07-07T05:30:07Z", "message": "Adds an example that use Python cross-language Kafka transforms."}, "afterCommit": {"oid": "6c791812068c42ef262ea8bb4afb18d92e0b3163", "author": {"user": {"login": "chamikaramj", "name": "Chamikara Jayalath"}}, "url": "https://github.com/apache/beam/commit/6c791812068c42ef262ea8bb4afb18d92e0b3163", "committedDate": "2020-07-17T08:45:39Z", "message": "Address reviewer comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2MDM0Mzg1", "url": "https://github.com/apache/beam/pull/12188#pullrequestreview-446034385", "createdAt": "2020-07-09T23:33:31Z", "commit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "state": "COMMENTED", "comments": {"totalCount": 24, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOVQyMzozMzozMVrOGvlKMw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xN1QwODoyMTozNFrOGzJ_IA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjU0NTA3NQ==", "bodyText": "Added the same link as Beam quick-start and updated text.", "url": "https://github.com/apache/beam/pull/12188#discussion_r452545075", "createdAt": "2020-07-09T23:33:31Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/examples/kafkataxi/README.md", "diffHunk": "@@ -0,0 +1,164 @@\n+<!--\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+-->\n+\n+# Python KafkaIO Example\n+\n+This example reads from the PubSub NYC Taxi stream described\n+[here](https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon), writes\n+to a given Kafka topic and reads back from the same Kafka topic. This example\n+uses cross-language transforms available in\n+[kafka.py](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/kafka.py).\n+Transforms are implemented in Java and are available\n+[here](https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java).\n+\n+## Prerequisites\n+\n+Install Java in your system and make sure that `java` command is available in ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTgxNjM0NQ=="}, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjU0NjA0MQ==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/12188#discussion_r452546041", "createdAt": "2020-07-09T23:36:22Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/examples/kafkataxi/README.md", "diffHunk": "@@ -0,0 +1,164 @@\n+<!--\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+-->\n+\n+# Python KafkaIO Example\n+\n+This example reads from the PubSub NYC Taxi stream described\n+[here](https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon), writes\n+to a given Kafka topic and reads back from the same Kafka topic. This example\n+uses cross-language transforms available in\n+[kafka.py](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/kafka.py).\n+Transforms are implemented in Java and are available\n+[here](https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java).\n+\n+## Prerequisites\n+\n+Install Java in your system and make sure that `java` command is available in \n+the environment.\n+\n+```sh\n+>java --version", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTgxNzE3MQ=="}, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjU0NjIyMQ==", "bodyText": "No (also Beam comes with a Gradle script when cloning).", "url": "https://github.com/apache/beam/pull/12188#discussion_r452546221", "createdAt": "2020-07-09T23:36:59Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/examples/kafkataxi/README.md", "diffHunk": "@@ -0,0 +1,164 @@\n+<!--\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+-->\n+\n+# Python KafkaIO Example\n+\n+This example reads from the PubSub NYC Taxi stream described\n+[here](https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon), writes\n+to a given Kafka topic and reads back from the same Kafka topic. This example\n+uses cross-language transforms available in\n+[kafka.py](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/kafka.py).\n+Transforms are implemented in Java and are available\n+[here](https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java).\n+\n+## Prerequisites\n+\n+Install Java in your system and make sure that `java` command is available in \n+the environment.\n+\n+```sh\n+>java --version\n+> <Should print information regarding the installed Java version>\n+```", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTgxODIzMw=="}, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjU0NjUzNA==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/12188#discussion_r452546534", "createdAt": "2020-07-09T23:37:59Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/examples/kafkataxi/README.md", "diffHunk": "@@ -0,0 +1,164 @@\n+<!--\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+-->\n+\n+# Python KafkaIO Example\n+\n+This example reads from the PubSub NYC Taxi stream described\n+[here](https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon), writes\n+to a given Kafka topic and reads back from the same Kafka topic. This example\n+uses cross-language transforms available in\n+[kafka.py](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/kafka.py).\n+Transforms are implemented in Java and are available\n+[here](https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java).\n+\n+## Prerequisites\n+\n+Install Java in your system and make sure that `java` command is available in \n+the environment.\n+\n+```sh\n+>java --version\n+> <Should print information regarding the installed Java version>\n+```\n+\n+## Setup the Kafka cluster\n+\n+This example requires users to setup a Kafka cluster that the Beam runner\n+executing the pipeline has access to. There are few options.\n+\n+* For local runners that execute the pipelines in a single computer (for ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTgxNzU3OA=="}, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjU0ODI5NQ==", "bodyText": "Yes, this is geared towards distributed runners though users would be able to run the example with Flink/Spark in local mode as well. I think it's good to not mention local Kafka cluster so that it's not confusing and gives the impression that distributed runners will work with this. Updated.", "url": "https://github.com/apache/beam/pull/12188#discussion_r452548295", "createdAt": "2020-07-09T23:44:06Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/examples/kafkataxi/README.md", "diffHunk": "@@ -0,0 +1,164 @@\n+<!--\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+-->\n+\n+# Python KafkaIO Example\n+\n+This example reads from the PubSub NYC Taxi stream described\n+[here](https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon), writes\n+to a given Kafka topic and reads back from the same Kafka topic. This example\n+uses cross-language transforms available in\n+[kafka.py](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/kafka.py).\n+Transforms are implemented in Java and are available\n+[here](https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java).\n+\n+## Prerequisites\n+\n+Install Java in your system and make sure that `java` command is available in \n+the environment.\n+\n+```sh\n+>java --version\n+> <Should print information regarding the installed Java version>\n+```\n+\n+## Setup the Kafka cluster\n+\n+This example requires users to setup a Kafka cluster that the Beam runner\n+executing the pipeline has access to. There are few options.\n+\n+* For local runners that execute the pipelines in a single computer (for \n+example, portable DirectRunner or Spark/Flink runners in local mode), you can \n+setup a local Kafka cluster running in the same computer.\n+* For Dataflow or portable Spark/Flink in distributed mode, you can setup a Kafka \n+cluster in GCE. See \n+[here](https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/dataflow/flex-templates/kafka_to_bigquery) \n+for step by step instructions for this.\n+\n+Let's assume that that IP address of the node running the Kafka cluster to be \n+`KAFKA_ADDRESS` and the port to be `9092`.\n+\n+```sh\n+> export BOOTSTRAP_SERVER=KAFKA_ADDRESS:9092", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTgyMDgzOQ=="}, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjU0OTE3OA==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/12188#discussion_r452549178", "createdAt": "2020-07-09T23:46:59Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/examples/kafkataxi/README.md", "diffHunk": "@@ -0,0 +1,164 @@\n+<!--\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+-->\n+\n+# Python KafkaIO Example\n+\n+This example reads from the PubSub NYC Taxi stream described\n+[here](https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon), writes\n+to a given Kafka topic and reads back from the same Kafka topic. This example\n+uses cross-language transforms available in\n+[kafka.py](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/kafka.py).\n+Transforms are implemented in Java and are available\n+[here](https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java).\n+\n+## Prerequisites\n+\n+Install Java in your system and make sure that `java` command is available in \n+the environment.\n+\n+```sh\n+>java --version\n+> <Should print information regarding the installed Java version>\n+```\n+\n+## Setup the Kafka cluster\n+\n+This example requires users to setup a Kafka cluster that the Beam runner\n+executing the pipeline has access to. There are few options.\n+\n+* For local runners that execute the pipelines in a single computer (for \n+example, portable DirectRunner or Spark/Flink runners in local mode), you can \n+setup a local Kafka cluster running in the same computer.\n+* For Dataflow or portable Spark/Flink in distributed mode, you can setup a Kafka \n+cluster in GCE. See \n+[here](https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/dataflow/flex-templates/kafka_to_bigquery) \n+for step by step instructions for this.\n+\n+Let's assume that that IP address of the node running the Kafka cluster to be \n+`KAFKA_ADDRESS` and the port to be `9092`.\n+\n+```sh\n+> export BOOTSTRAP_SERVER=KAFKA_ADDRESS:9092\n+```\n+\n+## Running the example on latest released Beam version\n+\n+Perform Beam runner specific setup. Note that cross-language transforms require \n+portable implementations of Spark/Flink/Direct runners. Dataflow requires\n+(runner V2)[https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#dataflow-runner-v2]", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTgyNDUxMQ=="}, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MjU0OTUyNg==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/12188#discussion_r452549526", "createdAt": "2020-07-09T23:48:08Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/examples/kafkataxi/README.md", "diffHunk": "@@ -0,0 +1,164 @@\n+<!--\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+-->\n+\n+# Python KafkaIO Example\n+\n+This example reads from the PubSub NYC Taxi stream described\n+[here](https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon), writes\n+to a given Kafka topic and reads back from the same Kafka topic. This example\n+uses cross-language transforms available in\n+[kafka.py](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/kafka.py).\n+Transforms are implemented in Java and are available\n+[here](https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java).\n+\n+## Prerequisites\n+\n+Install Java in your system and make sure that `java` command is available in \n+the environment.\n+\n+```sh\n+>java --version\n+> <Should print information regarding the installed Java version>\n+```\n+\n+## Setup the Kafka cluster\n+\n+This example requires users to setup a Kafka cluster that the Beam runner\n+executing the pipeline has access to. There are few options.\n+\n+* For local runners that execute the pipelines in a single computer (for \n+example, portable DirectRunner or Spark/Flink runners in local mode), you can \n+setup a local Kafka cluster running in the same computer.\n+* For Dataflow or portable Spark/Flink in distributed mode, you can setup a Kafka \n+cluster in GCE. See \n+[here](https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/dataflow/flex-templates/kafka_to_bigquery) \n+for step by step instructions for this.\n+\n+Let's assume that that IP address of the node running the Kafka cluster to be \n+`KAFKA_ADDRESS` and the port to be `9092`.\n+\n+```sh\n+> export BOOTSTRAP_SERVER=KAFKA_ADDRESS:9092\n+```\n+\n+## Running the example on latest released Beam version\n+\n+Perform Beam runner specific setup. Note that cross-language transforms require \n+portable implementations of Spark/Flink/Direct runners. Dataflow requires\n+(runner V2)[https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#dataflow-runner-v2]\n+and Beam 2.22.0 or later. See\n+[here](https://beam.apache.org/documentation/runners/dataflow/) for \n+instructions for setting up Dataflow.\n+\n+Setup a virtual environment for running Beam Python programs. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for prerequisites. \n+Dataflow requires the `gcp` tag. Assuming your work directory to be\n+`/path/to/work`.\n+\n+```sh\n+> export WORK_DIRECTORY=/path/to/work", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTgyNTA2Ng=="}, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzExMjMyNQ==", "bodyText": "Done. Though I noticed that we mention virtualenv both in Beam contribution guide and Python quickstart.", "url": "https://github.com/apache/beam/pull/12188#discussion_r453112325", "createdAt": "2020-07-10T22:58:03Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/examples/kafkataxi/README.md", "diffHunk": "@@ -0,0 +1,164 @@\n+<!--\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+-->\n+\n+# Python KafkaIO Example\n+\n+This example reads from the PubSub NYC Taxi stream described\n+[here](https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon), writes\n+to a given Kafka topic and reads back from the same Kafka topic. This example\n+uses cross-language transforms available in\n+[kafka.py](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/kafka.py).\n+Transforms are implemented in Java and are available\n+[here](https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java).\n+\n+## Prerequisites\n+\n+Install Java in your system and make sure that `java` command is available in \n+the environment.\n+\n+```sh\n+>java --version\n+> <Should print information regarding the installed Java version>\n+```\n+\n+## Setup the Kafka cluster\n+\n+This example requires users to setup a Kafka cluster that the Beam runner\n+executing the pipeline has access to. There are few options.\n+\n+* For local runners that execute the pipelines in a single computer (for \n+example, portable DirectRunner or Spark/Flink runners in local mode), you can \n+setup a local Kafka cluster running in the same computer.\n+* For Dataflow or portable Spark/Flink in distributed mode, you can setup a Kafka \n+cluster in GCE. See \n+[here](https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/dataflow/flex-templates/kafka_to_bigquery) \n+for step by step instructions for this.\n+\n+Let's assume that that IP address of the node running the Kafka cluster to be \n+`KAFKA_ADDRESS` and the port to be `9092`.\n+\n+```sh\n+> export BOOTSTRAP_SERVER=KAFKA_ADDRESS:9092\n+```\n+\n+## Running the example on latest released Beam version\n+\n+Perform Beam runner specific setup. Note that cross-language transforms require \n+portable implementations of Spark/Flink/Direct runners. Dataflow requires\n+(runner V2)[https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#dataflow-runner-v2]\n+and Beam 2.22.0 or later. See\n+[here](https://beam.apache.org/documentation/runners/dataflow/) for \n+instructions for setting up Dataflow.\n+\n+Setup a virtual environment for running Beam Python programs. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for prerequisites. \n+Dataflow requires the `gcp` tag. Assuming your work directory to be\n+`/path/to/work`.\n+\n+```sh\n+> export WORK_DIRECTORY=/path/to/work\n+> cd $WORK_DIRECTORY\n+> mkdir kafka_env\n+> virtualenv kafka_env", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTgyOTEzMQ=="}, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjA2NjEyNw==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/12188#discussion_r456066127", "createdAt": "2020-07-16T20:43:13Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/examples/kafkataxi/README.md", "diffHunk": "@@ -0,0 +1,164 @@\n+<!--\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+-->\n+\n+# Python KafkaIO Example\n+\n+This example reads from the PubSub NYC Taxi stream described\n+[here](https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon), writes\n+to a given Kafka topic and reads back from the same Kafka topic. This example\n+uses cross-language transforms available in\n+[kafka.py](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/kafka.py).\n+Transforms are implemented in Java and are available\n+[here](https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java).\n+\n+## Prerequisites\n+\n+Install Java in your system and make sure that `java` command is available in \n+the environment.\n+\n+```sh\n+>java --version\n+> <Should print information regarding the installed Java version>\n+```\n+\n+## Setup the Kafka cluster\n+\n+This example requires users to setup a Kafka cluster that the Beam runner\n+executing the pipeline has access to. There are few options.\n+\n+* For local runners that execute the pipelines in a single computer (for \n+example, portable DirectRunner or Spark/Flink runners in local mode), you can \n+setup a local Kafka cluster running in the same computer.\n+* For Dataflow or portable Spark/Flink in distributed mode, you can setup a Kafka \n+cluster in GCE. See \n+[here](https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/dataflow/flex-templates/kafka_to_bigquery) \n+for step by step instructions for this.\n+\n+Let's assume that that IP address of the node running the Kafka cluster to be \n+`KAFKA_ADDRESS` and the port to be `9092`.\n+\n+```sh\n+> export BOOTSTRAP_SERVER=KAFKA_ADDRESS:9092\n+```\n+\n+## Running the example on latest released Beam version\n+\n+Perform Beam runner specific setup. Note that cross-language transforms require \n+portable implementations of Spark/Flink/Direct runners. Dataflow requires\n+(runner V2)[https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#dataflow-runner-v2]\n+and Beam 2.22.0 or later. See\n+[here](https://beam.apache.org/documentation/runners/dataflow/) for \n+instructions for setting up Dataflow.\n+\n+Setup a virtual environment for running Beam Python programs. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for prerequisites. \n+Dataflow requires the `gcp` tag. Assuming your work directory to be\n+`/path/to/work`.\n+\n+```sh\n+> export WORK_DIRECTORY=/path/to/work\n+> cd $WORK_DIRECTORY\n+> mkdir kafka_env\n+> virtualenv kafka_env\n+> . kafka_env/bin/activate\n+> pip install -e .[gcp]\n+```\n+\n+Run the Beam pipeline. You can either use the default Kafka topic name or \n+specify a Kafka topic name. Following command assumes Dataflow. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for instructions on \n+running Beam Python programs on other runners. Note that you have to fill in \n+information mentioned within angle brackets (`<` and `>`).\n+\n+Note that this exemple is not available in Beam versions before 2.24.0 hence\n+you'll have to either get the example program from Beam or follow steps\n+provided in the section *Running the Example from a Beam Git Clone*.\n+\n+```sh\n+>  python -m apache_beam.examples.kafkataxi.kafka_taxi --runner DataflowRunner --temp_location <GCS temp location> --project <GCP project>  --region <region> \\", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTgzNDI3Nw=="}, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjA2NjQ4OA==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/12188#discussion_r456066488", "createdAt": "2020-07-16T20:43:47Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/examples/kafkataxi/README.md", "diffHunk": "@@ -0,0 +1,164 @@\n+<!--\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+-->\n+\n+# Python KafkaIO Example\n+\n+This example reads from the PubSub NYC Taxi stream described\n+[here](https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon), writes\n+to a given Kafka topic and reads back from the same Kafka topic. This example\n+uses cross-language transforms available in\n+[kafka.py](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/kafka.py).\n+Transforms are implemented in Java and are available\n+[here](https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java).\n+\n+## Prerequisites\n+\n+Install Java in your system and make sure that `java` command is available in \n+the environment.\n+\n+```sh\n+>java --version\n+> <Should print information regarding the installed Java version>\n+```\n+\n+## Setup the Kafka cluster\n+\n+This example requires users to setup a Kafka cluster that the Beam runner\n+executing the pipeline has access to. There are few options.\n+\n+* For local runners that execute the pipelines in a single computer (for \n+example, portable DirectRunner or Spark/Flink runners in local mode), you can \n+setup a local Kafka cluster running in the same computer.\n+* For Dataflow or portable Spark/Flink in distributed mode, you can setup a Kafka \n+cluster in GCE. See \n+[here](https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/dataflow/flex-templates/kafka_to_bigquery) \n+for step by step instructions for this.\n+\n+Let's assume that that IP address of the node running the Kafka cluster to be \n+`KAFKA_ADDRESS` and the port to be `9092`.\n+\n+```sh\n+> export BOOTSTRAP_SERVER=KAFKA_ADDRESS:9092\n+```\n+\n+## Running the example on latest released Beam version\n+\n+Perform Beam runner specific setup. Note that cross-language transforms require \n+portable implementations of Spark/Flink/Direct runners. Dataflow requires\n+(runner V2)[https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#dataflow-runner-v2]\n+and Beam 2.22.0 or later. See\n+[here](https://beam.apache.org/documentation/runners/dataflow/) for \n+instructions for setting up Dataflow.\n+\n+Setup a virtual environment for running Beam Python programs. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for prerequisites. \n+Dataflow requires the `gcp` tag. Assuming your work directory to be\n+`/path/to/work`.\n+\n+```sh\n+> export WORK_DIRECTORY=/path/to/work\n+> cd $WORK_DIRECTORY\n+> mkdir kafka_env\n+> virtualenv kafka_env\n+> . kafka_env/bin/activate\n+> pip install -e .[gcp]\n+```\n+\n+Run the Beam pipeline. You can either use the default Kafka topic name or \n+specify a Kafka topic name. Following command assumes Dataflow. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for instructions on \n+running Beam Python programs on other runners. Note that you have to fill in \n+information mentioned within angle brackets (`<` and `>`).\n+\n+Note that this exemple is not available in Beam versions before 2.24.0 hence\n+you'll have to either get the example program from Beam or follow steps\n+provided in the section *Running the Example from a Beam Git Clone*.\n+\n+```sh\n+>  python -m apache_beam.examples.kafkataxi.kafka_taxi --runner DataflowRunner --temp_location <GCS temp location> --project <GCP project>  --region <region> \\\n+   --num_workers 1 --job_name <job name> --bootstrap_servers $BOOTSTRAP_SERVER --experiments=use_runner_v2\n+```\n+\n+## Running the Example from a Beam Git Clone", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTgzNTM1NQ=="}, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjA2OTMzOA==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/12188#discussion_r456069338", "createdAt": "2020-07-16T20:49:35Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/examples/kafkataxi/README.md", "diffHunk": "@@ -0,0 +1,164 @@\n+<!--\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+-->\n+\n+# Python KafkaIO Example\n+\n+This example reads from the PubSub NYC Taxi stream described\n+[here](https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon), writes\n+to a given Kafka topic and reads back from the same Kafka topic. This example\n+uses cross-language transforms available in\n+[kafka.py](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/kafka.py).\n+Transforms are implemented in Java and are available\n+[here](https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java).\n+\n+## Prerequisites\n+\n+Install Java in your system and make sure that `java` command is available in \n+the environment.\n+\n+```sh\n+>java --version\n+> <Should print information regarding the installed Java version>\n+```\n+\n+## Setup the Kafka cluster\n+\n+This example requires users to setup a Kafka cluster that the Beam runner\n+executing the pipeline has access to. There are few options.\n+\n+* For local runners that execute the pipelines in a single computer (for \n+example, portable DirectRunner or Spark/Flink runners in local mode), you can \n+setup a local Kafka cluster running in the same computer.\n+* For Dataflow or portable Spark/Flink in distributed mode, you can setup a Kafka \n+cluster in GCE. See \n+[here](https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/dataflow/flex-templates/kafka_to_bigquery) \n+for step by step instructions for this.\n+\n+Let's assume that that IP address of the node running the Kafka cluster to be \n+`KAFKA_ADDRESS` and the port to be `9092`.\n+\n+```sh\n+> export BOOTSTRAP_SERVER=KAFKA_ADDRESS:9092\n+```\n+\n+## Running the example on latest released Beam version\n+\n+Perform Beam runner specific setup. Note that cross-language transforms require \n+portable implementations of Spark/Flink/Direct runners. Dataflow requires\n+(runner V2)[https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#dataflow-runner-v2]\n+and Beam 2.22.0 or later. See\n+[here](https://beam.apache.org/documentation/runners/dataflow/) for \n+instructions for setting up Dataflow.\n+\n+Setup a virtual environment for running Beam Python programs. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for prerequisites. \n+Dataflow requires the `gcp` tag. Assuming your work directory to be\n+`/path/to/work`.\n+\n+```sh\n+> export WORK_DIRECTORY=/path/to/work\n+> cd $WORK_DIRECTORY\n+> mkdir kafka_env\n+> virtualenv kafka_env\n+> . kafka_env/bin/activate\n+> pip install -e .[gcp]\n+```\n+\n+Run the Beam pipeline. You can either use the default Kafka topic name or \n+specify a Kafka topic name. Following command assumes Dataflow. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for instructions on \n+running Beam Python programs on other runners. Note that you have to fill in \n+information mentioned within angle brackets (`<` and `>`).\n+\n+Note that this exemple is not available in Beam versions before 2.24.0 hence\n+you'll have to either get the example program from Beam or follow steps\n+provided in the section *Running the Example from a Beam Git Clone*.\n+\n+```sh\n+>  python -m apache_beam.examples.kafkataxi.kafka_taxi --runner DataflowRunner --temp_location <GCS temp location> --project <GCP project>  --region <region> \\\n+   --num_workers 1 --job_name <job name> --bootstrap_servers $BOOTSTRAP_SERVER --experiments=use_runner_v2\n+```\n+\n+## Running the Example from a Beam Git Clone\n+\n+Running this example from a Beam Git clone requires some additional steps.\n+\n+Checkout a clone of the Beam Git repo. See \n+[here](https://beam.apache.org/contribute/) for prerequisites.\n+\n+Assume your Github username to be `GITHUB_USERNAME`.\n+\n+```sh\n+> cd $WORK_DIRECTORY", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTgzNjA4Nw=="}, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 108}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjEzODUxMQ==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/12188#discussion_r456138511", "createdAt": "2020-07-16T23:44:34Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/examples/kafkataxi/README.md", "diffHunk": "@@ -0,0 +1,164 @@\n+<!--\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+-->\n+\n+# Python KafkaIO Example\n+\n+This example reads from the PubSub NYC Taxi stream described\n+[here](https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon), writes\n+to a given Kafka topic and reads back from the same Kafka topic. This example\n+uses cross-language transforms available in\n+[kafka.py](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/kafka.py).\n+Transforms are implemented in Java and are available\n+[here](https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java).\n+\n+## Prerequisites\n+\n+Install Java in your system and make sure that `java` command is available in \n+the environment.\n+\n+```sh\n+>java --version\n+> <Should print information regarding the installed Java version>\n+```\n+\n+## Setup the Kafka cluster\n+\n+This example requires users to setup a Kafka cluster that the Beam runner\n+executing the pipeline has access to. There are few options.\n+\n+* For local runners that execute the pipelines in a single computer (for \n+example, portable DirectRunner or Spark/Flink runners in local mode), you can \n+setup a local Kafka cluster running in the same computer.\n+* For Dataflow or portable Spark/Flink in distributed mode, you can setup a Kafka \n+cluster in GCE. See \n+[here](https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/dataflow/flex-templates/kafka_to_bigquery) \n+for step by step instructions for this.\n+\n+Let's assume that that IP address of the node running the Kafka cluster to be \n+`KAFKA_ADDRESS` and the port to be `9092`.\n+\n+```sh\n+> export BOOTSTRAP_SERVER=KAFKA_ADDRESS:9092\n+```\n+\n+## Running the example on latest released Beam version\n+\n+Perform Beam runner specific setup. Note that cross-language transforms require \n+portable implementations of Spark/Flink/Direct runners. Dataflow requires\n+(runner V2)[https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#dataflow-runner-v2]\n+and Beam 2.22.0 or later. See\n+[here](https://beam.apache.org/documentation/runners/dataflow/) for \n+instructions for setting up Dataflow.\n+\n+Setup a virtual environment for running Beam Python programs. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for prerequisites. \n+Dataflow requires the `gcp` tag. Assuming your work directory to be\n+`/path/to/work`.\n+\n+```sh\n+> export WORK_DIRECTORY=/path/to/work\n+> cd $WORK_DIRECTORY\n+> mkdir kafka_env\n+> virtualenv kafka_env\n+> . kafka_env/bin/activate\n+> pip install -e .[gcp]\n+```\n+\n+Run the Beam pipeline. You can either use the default Kafka topic name or \n+specify a Kafka topic name. Following command assumes Dataflow. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for instructions on \n+running Beam Python programs on other runners. Note that you have to fill in \n+information mentioned within angle brackets (`<` and `>`).\n+\n+Note that this exemple is not available in Beam versions before 2.24.0 hence\n+you'll have to either get the example program from Beam or follow steps\n+provided in the section *Running the Example from a Beam Git Clone*.\n+\n+```sh\n+>  python -m apache_beam.examples.kafkataxi.kafka_taxi --runner DataflowRunner --temp_location <GCS temp location> --project <GCP project>  --region <region> \\\n+   --num_workers 1 --job_name <job name> --bootstrap_servers $BOOTSTRAP_SERVER --experiments=use_runner_v2\n+```\n+\n+## Running the Example from a Beam Git Clone\n+\n+Running this example from a Beam Git clone requires some additional steps.\n+\n+Checkout a clone of the Beam Git repo. See \n+[here](https://beam.apache.org/contribute/) for prerequisites.\n+\n+Assume your Github username to be `GITHUB_USERNAME`.\n+\n+```sh\n+> cd $WORK_DIRECTORY\n+> git clone git@github.com:${GITHUB_USERNAME}/beam\n+> cd beam\n+```\n+\n+Build IO expansion service jar.\n+\n+```sh\n+> ./gradlew :sdks:java:io:expansion-service:build", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTgzNjIxMA=="}, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjEzODk1NQ==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/12188#discussion_r456138955", "createdAt": "2020-07-16T23:45:56Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/examples/kafkataxi/README.md", "diffHunk": "@@ -0,0 +1,164 @@\n+<!--\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+-->\n+\n+# Python KafkaIO Example\n+\n+This example reads from the PubSub NYC Taxi stream described\n+[here](https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon), writes\n+to a given Kafka topic and reads back from the same Kafka topic. This example\n+uses cross-language transforms available in\n+[kafka.py](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/kafka.py).\n+Transforms are implemented in Java and are available\n+[here](https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java).\n+\n+## Prerequisites\n+\n+Install Java in your system and make sure that `java` command is available in \n+the environment.\n+\n+```sh\n+>java --version\n+> <Should print information regarding the installed Java version>\n+```\n+\n+## Setup the Kafka cluster\n+\n+This example requires users to setup a Kafka cluster that the Beam runner\n+executing the pipeline has access to. There are few options.\n+\n+* For local runners that execute the pipelines in a single computer (for \n+example, portable DirectRunner or Spark/Flink runners in local mode), you can \n+setup a local Kafka cluster running in the same computer.\n+* For Dataflow or portable Spark/Flink in distributed mode, you can setup a Kafka \n+cluster in GCE. See \n+[here](https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/dataflow/flex-templates/kafka_to_bigquery) \n+for step by step instructions for this.\n+\n+Let's assume that that IP address of the node running the Kafka cluster to be \n+`KAFKA_ADDRESS` and the port to be `9092`.\n+\n+```sh\n+> export BOOTSTRAP_SERVER=KAFKA_ADDRESS:9092\n+```\n+\n+## Running the example on latest released Beam version\n+\n+Perform Beam runner specific setup. Note that cross-language transforms require \n+portable implementations of Spark/Flink/Direct runners. Dataflow requires\n+(runner V2)[https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#dataflow-runner-v2]\n+and Beam 2.22.0 or later. See\n+[here](https://beam.apache.org/documentation/runners/dataflow/) for \n+instructions for setting up Dataflow.\n+\n+Setup a virtual environment for running Beam Python programs. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for prerequisites. \n+Dataflow requires the `gcp` tag. Assuming your work directory to be\n+`/path/to/work`.\n+\n+```sh\n+> export WORK_DIRECTORY=/path/to/work\n+> cd $WORK_DIRECTORY\n+> mkdir kafka_env\n+> virtualenv kafka_env\n+> . kafka_env/bin/activate\n+> pip install -e .[gcp]\n+```\n+\n+Run the Beam pipeline. You can either use the default Kafka topic name or \n+specify a Kafka topic name. Following command assumes Dataflow. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for instructions on \n+running Beam Python programs on other runners. Note that you have to fill in \n+information mentioned within angle brackets (`<` and `>`).\n+\n+Note that this exemple is not available in Beam versions before 2.24.0 hence\n+you'll have to either get the example program from Beam or follow steps\n+provided in the section *Running the Example from a Beam Git Clone*.\n+\n+```sh\n+>  python -m apache_beam.examples.kafkataxi.kafka_taxi --runner DataflowRunner --temp_location <GCS temp location> --project <GCP project>  --region <region> \\\n+   --num_workers 1 --job_name <job name> --bootstrap_servers $BOOTSTRAP_SERVER --experiments=use_runner_v2\n+```\n+\n+## Running the Example from a Beam Git Clone\n+\n+Running this example from a Beam Git clone requires some additional steps.\n+\n+Checkout a clone of the Beam Git repo. See \n+[here](https://beam.apache.org/contribute/) for prerequisites.\n+\n+Assume your Github username to be `GITHUB_USERNAME`.\n+\n+```sh\n+> cd $WORK_DIRECTORY\n+> git clone git@github.com:${GITHUB_USERNAME}/beam\n+> cd beam\n+```\n+\n+Build IO expansion service jar.\n+\n+```sh\n+> ./gradlew :sdks:java:io:expansion-service:build\n+```\n+\n+Push a java SDK Harness container to Docker Hub. See ", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTgzNzUwOQ=="}, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 119}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjEzOTAxNQ==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/12188#discussion_r456139015", "createdAt": "2020-07-16T23:46:08Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/examples/kafkataxi/README.md", "diffHunk": "@@ -0,0 +1,164 @@\n+<!--\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+-->\n+\n+# Python KafkaIO Example\n+\n+This example reads from the PubSub NYC Taxi stream described\n+[here](https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon), writes\n+to a given Kafka topic and reads back from the same Kafka topic. This example\n+uses cross-language transforms available in\n+[kafka.py](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/kafka.py).\n+Transforms are implemented in Java and are available\n+[here](https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java).\n+\n+## Prerequisites\n+\n+Install Java in your system and make sure that `java` command is available in \n+the environment.\n+\n+```sh\n+>java --version\n+> <Should print information regarding the installed Java version>\n+```\n+\n+## Setup the Kafka cluster\n+\n+This example requires users to setup a Kafka cluster that the Beam runner\n+executing the pipeline has access to. There are few options.\n+\n+* For local runners that execute the pipelines in a single computer (for \n+example, portable DirectRunner or Spark/Flink runners in local mode), you can \n+setup a local Kafka cluster running in the same computer.\n+* For Dataflow or portable Spark/Flink in distributed mode, you can setup a Kafka \n+cluster in GCE. See \n+[here](https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/dataflow/flex-templates/kafka_to_bigquery) \n+for step by step instructions for this.\n+\n+Let's assume that that IP address of the node running the Kafka cluster to be \n+`KAFKA_ADDRESS` and the port to be `9092`.\n+\n+```sh\n+> export BOOTSTRAP_SERVER=KAFKA_ADDRESS:9092\n+```\n+\n+## Running the example on latest released Beam version\n+\n+Perform Beam runner specific setup. Note that cross-language transforms require \n+portable implementations of Spark/Flink/Direct runners. Dataflow requires\n+(runner V2)[https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#dataflow-runner-v2]\n+and Beam 2.22.0 or later. See\n+[here](https://beam.apache.org/documentation/runners/dataflow/) for \n+instructions for setting up Dataflow.\n+\n+Setup a virtual environment for running Beam Python programs. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for prerequisites. \n+Dataflow requires the `gcp` tag. Assuming your work directory to be\n+`/path/to/work`.\n+\n+```sh\n+> export WORK_DIRECTORY=/path/to/work\n+> cd $WORK_DIRECTORY\n+> mkdir kafka_env\n+> virtualenv kafka_env\n+> . kafka_env/bin/activate\n+> pip install -e .[gcp]\n+```\n+\n+Run the Beam pipeline. You can either use the default Kafka topic name or \n+specify a Kafka topic name. Following command assumes Dataflow. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for instructions on \n+running Beam Python programs on other runners. Note that you have to fill in \n+information mentioned within angle brackets (`<` and `>`).\n+\n+Note that this exemple is not available in Beam versions before 2.24.0 hence\n+you'll have to either get the example program from Beam or follow steps\n+provided in the section *Running the Example from a Beam Git Clone*.\n+\n+```sh\n+>  python -m apache_beam.examples.kafkataxi.kafka_taxi --runner DataflowRunner --temp_location <GCS temp location> --project <GCP project>  --region <region> \\\n+   --num_workers 1 --job_name <job name> --bootstrap_servers $BOOTSTRAP_SERVER --experiments=use_runner_v2\n+```\n+\n+## Running the Example from a Beam Git Clone\n+\n+Running this example from a Beam Git clone requires some additional steps.\n+\n+Checkout a clone of the Beam Git repo. See \n+[here](https://beam.apache.org/contribute/) for prerequisites.\n+\n+Assume your Github username to be `GITHUB_USERNAME`.\n+\n+```sh\n+> cd $WORK_DIRECTORY\n+> git clone git@github.com:${GITHUB_USERNAME}/beam\n+> cd beam\n+```\n+\n+Build IO expansion service jar.\n+\n+```sh\n+> ./gradlew :sdks:java:io:expansion-service:build\n+```\n+\n+Push a java SDK Harness container to Docker Hub. See \n+[here](https://beam.apache.org/documentation/runtime/environments/) for \n+prerequisites and additional information. Note that you have to fill in \n+information mentioned within angle brackets (`<` and `>`). Assume your Docker\n+repository root to be `<Docker repository root>`.\n+\n+```sh\n+> export DOCKER_ROOT=<Docker repository root>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTgzNjI5MQ=="}, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 126}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjEzOTA4OA==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/12188#discussion_r456139088", "createdAt": "2020-07-16T23:46:23Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/examples/kafkataxi/README.md", "diffHunk": "@@ -0,0 +1,164 @@\n+<!--\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+-->\n+\n+# Python KafkaIO Example\n+\n+This example reads from the PubSub NYC Taxi stream described\n+[here](https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon), writes\n+to a given Kafka topic and reads back from the same Kafka topic. This example\n+uses cross-language transforms available in\n+[kafka.py](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/kafka.py).\n+Transforms are implemented in Java and are available\n+[here](https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java).\n+\n+## Prerequisites\n+\n+Install Java in your system and make sure that `java` command is available in \n+the environment.\n+\n+```sh\n+>java --version\n+> <Should print information regarding the installed Java version>\n+```\n+\n+## Setup the Kafka cluster\n+\n+This example requires users to setup a Kafka cluster that the Beam runner\n+executing the pipeline has access to. There are few options.\n+\n+* For local runners that execute the pipelines in a single computer (for \n+example, portable DirectRunner or Spark/Flink runners in local mode), you can \n+setup a local Kafka cluster running in the same computer.\n+* For Dataflow or portable Spark/Flink in distributed mode, you can setup a Kafka \n+cluster in GCE. See \n+[here](https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/dataflow/flex-templates/kafka_to_bigquery) \n+for step by step instructions for this.\n+\n+Let's assume that that IP address of the node running the Kafka cluster to be \n+`KAFKA_ADDRESS` and the port to be `9092`.\n+\n+```sh\n+> export BOOTSTRAP_SERVER=KAFKA_ADDRESS:9092\n+```\n+\n+## Running the example on latest released Beam version\n+\n+Perform Beam runner specific setup. Note that cross-language transforms require \n+portable implementations of Spark/Flink/Direct runners. Dataflow requires\n+(runner V2)[https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#dataflow-runner-v2]\n+and Beam 2.22.0 or later. See\n+[here](https://beam.apache.org/documentation/runners/dataflow/) for \n+instructions for setting up Dataflow.\n+\n+Setup a virtual environment for running Beam Python programs. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for prerequisites. \n+Dataflow requires the `gcp` tag. Assuming your work directory to be\n+`/path/to/work`.\n+\n+```sh\n+> export WORK_DIRECTORY=/path/to/work\n+> cd $WORK_DIRECTORY\n+> mkdir kafka_env\n+> virtualenv kafka_env\n+> . kafka_env/bin/activate\n+> pip install -e .[gcp]\n+```\n+\n+Run the Beam pipeline. You can either use the default Kafka topic name or \n+specify a Kafka topic name. Following command assumes Dataflow. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for instructions on \n+running Beam Python programs on other runners. Note that you have to fill in \n+information mentioned within angle brackets (`<` and `>`).\n+\n+Note that this exemple is not available in Beam versions before 2.24.0 hence\n+you'll have to either get the example program from Beam or follow steps\n+provided in the section *Running the Example from a Beam Git Clone*.\n+\n+```sh\n+>  python -m apache_beam.examples.kafkataxi.kafka_taxi --runner DataflowRunner --temp_location <GCS temp location> --project <GCP project>  --region <region> \\\n+   --num_workers 1 --job_name <job name> --bootstrap_servers $BOOTSTRAP_SERVER --experiments=use_runner_v2\n+```\n+\n+## Running the Example from a Beam Git Clone\n+\n+Running this example from a Beam Git clone requires some additional steps.\n+\n+Checkout a clone of the Beam Git repo. See \n+[here](https://beam.apache.org/contribute/) for prerequisites.\n+\n+Assume your Github username to be `GITHUB_USERNAME`.\n+\n+```sh\n+> cd $WORK_DIRECTORY\n+> git clone git@github.com:${GITHUB_USERNAME}/beam\n+> cd beam\n+```\n+\n+Build IO expansion service jar.\n+\n+```sh\n+> ./gradlew :sdks:java:io:expansion-service:build\n+```\n+\n+Push a java SDK Harness container to Docker Hub. See \n+[here](https://beam.apache.org/documentation/runtime/environments/) for \n+prerequisites and additional information. Note that you have to fill in \n+information mentioned within angle brackets (`<` and `>`). Assume your Docker\n+repository root to be `<Docker repository root>`.\n+\n+```sh\n+> export DOCKER_ROOT=<Docker repository root>\n+> ./gradlew :sdks:java:container:docker -Pdocker-repository-root=$DOCKER_ROOT -Pdocker-tag=latest\n+> docker push $DOCKER_ROOT/beam_java_sdk:latest\n+```\n+\n+For portable Flink/Spark in local mode, instead of above command just build the\n+Java SDK harness container locally using the default values for repository root\n+and the docker tag.\n+\n+Activate your Python virtual environment.  This example uses `virtualenv`. See \n+[here](https://cwiki.apache.org/confluence/display/BEAM/Python+Tips) for\n+instructions regarding setting up other types of Python virtual environments.\n+\n+```sh\n+> cd $WORK_DIRECTORY", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTgzNjU1Ng=="}, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 140}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjEzOTQwMQ==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/12188#discussion_r456139401", "createdAt": "2020-07-16T23:47:29Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/examples/kafkataxi/README.md", "diffHunk": "@@ -0,0 +1,164 @@\n+<!--\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+-->\n+\n+# Python KafkaIO Example\n+\n+This example reads from the PubSub NYC Taxi stream described\n+[here](https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon), writes\n+to a given Kafka topic and reads back from the same Kafka topic. This example\n+uses cross-language transforms available in\n+[kafka.py](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/kafka.py).\n+Transforms are implemented in Java and are available\n+[here](https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java).\n+\n+## Prerequisites\n+\n+Install Java in your system and make sure that `java` command is available in \n+the environment.\n+\n+```sh\n+>java --version\n+> <Should print information regarding the installed Java version>\n+```\n+\n+## Setup the Kafka cluster\n+\n+This example requires users to setup a Kafka cluster that the Beam runner\n+executing the pipeline has access to. There are few options.\n+\n+* For local runners that execute the pipelines in a single computer (for \n+example, portable DirectRunner or Spark/Flink runners in local mode), you can \n+setup a local Kafka cluster running in the same computer.\n+* For Dataflow or portable Spark/Flink in distributed mode, you can setup a Kafka \n+cluster in GCE. See \n+[here](https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/dataflow/flex-templates/kafka_to_bigquery) \n+for step by step instructions for this.\n+\n+Let's assume that that IP address of the node running the Kafka cluster to be \n+`KAFKA_ADDRESS` and the port to be `9092`.\n+\n+```sh\n+> export BOOTSTRAP_SERVER=KAFKA_ADDRESS:9092\n+```\n+\n+## Running the example on latest released Beam version\n+\n+Perform Beam runner specific setup. Note that cross-language transforms require \n+portable implementations of Spark/Flink/Direct runners. Dataflow requires\n+(runner V2)[https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#dataflow-runner-v2]\n+and Beam 2.22.0 or later. See\n+[here](https://beam.apache.org/documentation/runners/dataflow/) for \n+instructions for setting up Dataflow.\n+\n+Setup a virtual environment for running Beam Python programs. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for prerequisites. \n+Dataflow requires the `gcp` tag. Assuming your work directory to be\n+`/path/to/work`.\n+\n+```sh\n+> export WORK_DIRECTORY=/path/to/work\n+> cd $WORK_DIRECTORY\n+> mkdir kafka_env\n+> virtualenv kafka_env\n+> . kafka_env/bin/activate\n+> pip install -e .[gcp]\n+```\n+\n+Run the Beam pipeline. You can either use the default Kafka topic name or \n+specify a Kafka topic name. Following command assumes Dataflow. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for instructions on \n+running Beam Python programs on other runners. Note that you have to fill in \n+information mentioned within angle brackets (`<` and `>`).\n+\n+Note that this exemple is not available in Beam versions before 2.24.0 hence\n+you'll have to either get the example program from Beam or follow steps\n+provided in the section *Running the Example from a Beam Git Clone*.\n+\n+```sh\n+>  python -m apache_beam.examples.kafkataxi.kafka_taxi --runner DataflowRunner --temp_location <GCS temp location> --project <GCP project>  --region <region> \\\n+   --num_workers 1 --job_name <job name> --bootstrap_servers $BOOTSTRAP_SERVER --experiments=use_runner_v2\n+```\n+\n+## Running the Example from a Beam Git Clone\n+\n+Running this example from a Beam Git clone requires some additional steps.\n+\n+Checkout a clone of the Beam Git repo. See \n+[here](https://beam.apache.org/contribute/) for prerequisites.\n+\n+Assume your Github username to be `GITHUB_USERNAME`.\n+\n+```sh\n+> cd $WORK_DIRECTORY\n+> git clone git@github.com:${GITHUB_USERNAME}/beam\n+> cd beam\n+```\n+\n+Build IO expansion service jar.\n+\n+```sh\n+> ./gradlew :sdks:java:io:expansion-service:build\n+```\n+\n+Push a java SDK Harness container to Docker Hub. See \n+[here](https://beam.apache.org/documentation/runtime/environments/) for \n+prerequisites and additional information. Note that you have to fill in \n+information mentioned within angle brackets (`<` and `>`). Assume your Docker\n+repository root to be `<Docker repository root>`.\n+\n+```sh\n+> export DOCKER_ROOT=<Docker repository root>\n+> ./gradlew :sdks:java:container:docker -Pdocker-repository-root=$DOCKER_ROOT -Pdocker-tag=latest\n+> docker push $DOCKER_ROOT/beam_java_sdk:latest\n+```\n+\n+For portable Flink/Spark in local mode, instead of above command just build the\n+Java SDK harness container locally using the default values for repository root\n+and the docker tag.\n+\n+Activate your Python virtual environment.  This example uses `virtualenv`. See \n+[here](https://cwiki.apache.org/confluence/display/BEAM/Python+Tips) for\n+instructions regarding setting up other types of Python virtual environments.\n+\n+```sh\n+> cd $WORK_DIRECTORY\n+> mkdir kafka_env\n+> virtualenv kafka_env\n+> . kafka_env/bin/activate\n+```\n+\n+Install Beam and dependencies and build a Beam distribution.\n+\n+```sh\n+> cd beam/sdks/python", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTgzNjg3MA=="}, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 149}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjE0MDA5Ng==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/12188#discussion_r456140096", "createdAt": "2020-07-16T23:49:45Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/examples/kafkataxi/README.md", "diffHunk": "@@ -0,0 +1,164 @@\n+<!--\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+-->\n+\n+# Python KafkaIO Example\n+\n+This example reads from the PubSub NYC Taxi stream described\n+[here](https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon), writes\n+to a given Kafka topic and reads back from the same Kafka topic. This example\n+uses cross-language transforms available in\n+[kafka.py](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/kafka.py).\n+Transforms are implemented in Java and are available\n+[here](https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java).\n+\n+## Prerequisites\n+\n+Install Java in your system and make sure that `java` command is available in \n+the environment.\n+\n+```sh\n+>java --version\n+> <Should print information regarding the installed Java version>\n+```\n+\n+## Setup the Kafka cluster\n+\n+This example requires users to setup a Kafka cluster that the Beam runner\n+executing the pipeline has access to. There are few options.\n+\n+* For local runners that execute the pipelines in a single computer (for \n+example, portable DirectRunner or Spark/Flink runners in local mode), you can \n+setup a local Kafka cluster running in the same computer.\n+* For Dataflow or portable Spark/Flink in distributed mode, you can setup a Kafka \n+cluster in GCE. See \n+[here](https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/dataflow/flex-templates/kafka_to_bigquery) \n+for step by step instructions for this.\n+\n+Let's assume that that IP address of the node running the Kafka cluster to be \n+`KAFKA_ADDRESS` and the port to be `9092`.\n+\n+```sh\n+> export BOOTSTRAP_SERVER=KAFKA_ADDRESS:9092\n+```\n+\n+## Running the example on latest released Beam version\n+\n+Perform Beam runner specific setup. Note that cross-language transforms require \n+portable implementations of Spark/Flink/Direct runners. Dataflow requires\n+(runner V2)[https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#dataflow-runner-v2]\n+and Beam 2.22.0 or later. See\n+[here](https://beam.apache.org/documentation/runners/dataflow/) for \n+instructions for setting up Dataflow.\n+\n+Setup a virtual environment for running Beam Python programs. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for prerequisites. \n+Dataflow requires the `gcp` tag. Assuming your work directory to be\n+`/path/to/work`.\n+\n+```sh\n+> export WORK_DIRECTORY=/path/to/work\n+> cd $WORK_DIRECTORY\n+> mkdir kafka_env\n+> virtualenv kafka_env\n+> . kafka_env/bin/activate\n+> pip install -e .[gcp]\n+```\n+\n+Run the Beam pipeline. You can either use the default Kafka topic name or \n+specify a Kafka topic name. Following command assumes Dataflow. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for instructions on \n+running Beam Python programs on other runners. Note that you have to fill in \n+information mentioned within angle brackets (`<` and `>`).\n+\n+Note that this exemple is not available in Beam versions before 2.24.0 hence\n+you'll have to either get the example program from Beam or follow steps\n+provided in the section *Running the Example from a Beam Git Clone*.\n+\n+```sh\n+>  python -m apache_beam.examples.kafkataxi.kafka_taxi --runner DataflowRunner --temp_location <GCS temp location> --project <GCP project>  --region <region> \\\n+   --num_workers 1 --job_name <job name> --bootstrap_servers $BOOTSTRAP_SERVER --experiments=use_runner_v2\n+```\n+\n+## Running the Example from a Beam Git Clone\n+\n+Running this example from a Beam Git clone requires some additional steps.\n+\n+Checkout a clone of the Beam Git repo. See \n+[here](https://beam.apache.org/contribute/) for prerequisites.\n+\n+Assume your Github username to be `GITHUB_USERNAME`.\n+\n+```sh\n+> cd $WORK_DIRECTORY\n+> git clone git@github.com:${GITHUB_USERNAME}/beam\n+> cd beam\n+```\n+\n+Build IO expansion service jar.\n+\n+```sh\n+> ./gradlew :sdks:java:io:expansion-service:build\n+```\n+\n+Push a java SDK Harness container to Docker Hub. See \n+[here](https://beam.apache.org/documentation/runtime/environments/) for \n+prerequisites and additional information. Note that you have to fill in \n+information mentioned within angle brackets (`<` and `>`). Assume your Docker\n+repository root to be `<Docker repository root>`.\n+\n+```sh\n+> export DOCKER_ROOT=<Docker repository root>\n+> ./gradlew :sdks:java:container:docker -Pdocker-repository-root=$DOCKER_ROOT -Pdocker-tag=latest\n+> docker push $DOCKER_ROOT/beam_java_sdk:latest\n+```\n+\n+For portable Flink/Spark in local mode, instead of above command just build the\n+Java SDK harness container locally using the default values for repository root\n+and the docker tag.\n+\n+Activate your Python virtual environment.  This example uses `virtualenv`. See \n+[here](https://cwiki.apache.org/confluence/display/BEAM/Python+Tips) for\n+instructions regarding setting up other types of Python virtual environments.\n+\n+```sh\n+> cd $WORK_DIRECTORY\n+> mkdir kafka_env\n+> virtualenv kafka_env\n+> . kafka_env/bin/activate\n+```\n+\n+Install Beam and dependencies and build a Beam distribution.\n+\n+```sh\n+> cd beam/sdks/python\n+> pip install -r build-requirements.txt\n+> pip install -e .[gcp,test]\n+> python setup.py sdist\n+```\n+\n+Run the Beam pipeline. You can either use the default Kafka topic name or specify \n+a Kafka topic name. Following command assumes Dataflow. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for instructions on \n+running Beam Python programs on other runners.\n+\n+```sh\n+>  python -m apache_beam.examples.kafkataxi.kafka_taxi --runner DataflowRunner --temp_location <GCS temp location> --project <GCP project>  --region <region> \\", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTgzNzAxOQ=="}, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 161}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjIzMTQ3Mg==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/12188#discussion_r456231472", "createdAt": "2020-07-17T05:48:38Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/examples/kafkataxi/kafka_taxi.py", "diffHunk": "@@ -0,0 +1,87 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"An example that writes to and reads from Kafka.\n+\n+ This example reads from the PubSub NYC Taxi stream described in\n+ https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon, writes to a\n+ given Kafka topic and reads back from the same Kafka topic.\n+ \"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import argparse\n+import logging\n+import typing\n+\n+import apache_beam as beam\n+from apache_beam.io.kafka import ReadFromKafka\n+from apache_beam.io.kafka import WriteToKafka\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.options.pipeline_options import SetupOptions\n+from apache_beam.options.pipeline_options import StandardOptions\n+\n+\n+def run(argv=None):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTY4MjI1Ng=="}, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjIzMTY2MA==", "bodyText": "I think it's better to keep this as 'bootstrap_servers' since that's well known for any Kafka users.", "url": "https://github.com/apache/beam/pull/12188#discussion_r456231660", "createdAt": "2020-07-17T05:49:11Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/examples/kafkataxi/kafka_taxi.py", "diffHunk": "@@ -0,0 +1,87 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"An example that writes to and reads from Kafka.\n+\n+ This example reads from the PubSub NYC Taxi stream described in\n+ https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon, writes to a\n+ given Kafka topic and reads back from the same Kafka topic.\n+ \"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import argparse\n+import logging\n+import typing\n+\n+import apache_beam as beam\n+from apache_beam.io.kafka import ReadFromKafka\n+from apache_beam.io.kafka import WriteToKafka\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.options.pipeline_options import SetupOptions\n+from apache_beam.options.pipeline_options import StandardOptions\n+\n+\n+def run(argv=None):\n+  \"\"\"Main entry point; defines and runs the wordcount pipeline.\"\"\"\n+  parser = argparse.ArgumentParser()\n+  parser.add_argument(\n+      '--bootstrap_servers',", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTY4NzMzNg=="}, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjIzMjA4Ng==", "bodyText": "Are you sure this works ? I don't see such keyword arguments.", "url": "https://github.com/apache/beam/pull/12188#discussion_r456232086", "createdAt": "2020-07-17T05:50:42Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/examples/kafkataxi/kafka_taxi.py", "diffHunk": "@@ -0,0 +1,87 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"An example that writes to and reads from Kafka.\n+\n+ This example reads from the PubSub NYC Taxi stream described in\n+ https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon, writes to a\n+ given Kafka topic and reads back from the same Kafka topic.\n+ \"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import argparse\n+import logging\n+import typing\n+\n+import apache_beam as beam\n+from apache_beam.io.kafka import ReadFromKafka\n+from apache_beam.io.kafka import WriteToKafka\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.options.pipeline_options import SetupOptions\n+from apache_beam.options.pipeline_options import StandardOptions\n+\n+\n+def run(argv=None):\n+  \"\"\"Main entry point; defines and runs the wordcount pipeline.\"\"\"\n+  parser = argparse.ArgumentParser()\n+  parser.add_argument(\n+      '--bootstrap_servers',\n+      dest='bootstrap_servers',\n+      required=True,\n+      help='Bootstrap servers for the Kafka cluster. Should be accessible by '\n+      'the runner')\n+  parser.add_argument(\n+      '--topic',\n+      dest='topic',\n+      default='kafka_taxirides_realtime',\n+      help='Kafka topic to write to and read from')\n+  known_args, pipeline_args = parser.parse_known_args(argv)\n+\n+  pipeline_options = PipelineOptions(pipeline_args)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTY3NjMzOA=="}, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjIzMjIyOQ==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/12188#discussion_r456232229", "createdAt": "2020-07-17T05:51:11Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/examples/kafkataxi/kafka_taxi.py", "diffHunk": "@@ -0,0 +1,87 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"An example that writes to and reads from Kafka.\n+\n+ This example reads from the PubSub NYC Taxi stream described in\n+ https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon, writes to a\n+ given Kafka topic and reads back from the same Kafka topic.\n+ \"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import argparse\n+import logging\n+import typing\n+\n+import apache_beam as beam\n+from apache_beam.io.kafka import ReadFromKafka\n+from apache_beam.io.kafka import WriteToKafka\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.options.pipeline_options import SetupOptions\n+from apache_beam.options.pipeline_options import StandardOptions\n+\n+\n+def run(argv=None):\n+  \"\"\"Main entry point; defines and runs the wordcount pipeline.\"\"\"\n+  parser = argparse.ArgumentParser()\n+  parser.add_argument(\n+      '--bootstrap_servers',\n+      dest='bootstrap_servers',\n+      required=True,\n+      help='Bootstrap servers for the Kafka cluster. Should be accessible by '\n+      'the runner')\n+  parser.add_argument(\n+      '--topic',\n+      dest='topic',\n+      default='kafka_taxirides_realtime',\n+      help='Kafka topic to write to and read from')\n+  known_args, pipeline_args = parser.parse_known_args(argv)\n+\n+  pipeline_options = PipelineOptions(pipeline_args)\n+  pipeline_options.view_as(SetupOptions).save_main_session = True\n+  pipeline_options.view_as(StandardOptions).streaming = True\n+\n+  pipeline = beam.Pipeline(options=pipeline_options)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTY3ODc3Mg=="}, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjIzNTQ4NA==", "bodyText": "Moved to a parameter. Don't think this will be useful as a command line argument. Added a comment with the unit.", "url": "https://github.com/apache/beam/pull/12188#discussion_r456235484", "createdAt": "2020-07-17T06:02:04Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/examples/kafkataxi/kafka_taxi.py", "diffHunk": "@@ -0,0 +1,87 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"An example that writes to and reads from Kafka.\n+\n+ This example reads from the PubSub NYC Taxi stream described in\n+ https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon, writes to a\n+ given Kafka topic and reads back from the same Kafka topic.\n+ \"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import argparse\n+import logging\n+import typing\n+\n+import apache_beam as beam\n+from apache_beam.io.kafka import ReadFromKafka\n+from apache_beam.io.kafka import WriteToKafka\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.options.pipeline_options import SetupOptions\n+from apache_beam.options.pipeline_options import StandardOptions\n+\n+\n+def run(argv=None):\n+  \"\"\"Main entry point; defines and runs the wordcount pipeline.\"\"\"\n+  parser = argparse.ArgumentParser()\n+  parser.add_argument(\n+      '--bootstrap_servers',\n+      dest='bootstrap_servers',\n+      required=True,\n+      help='Bootstrap servers for the Kafka cluster. Should be accessible by '\n+      'the runner')\n+  parser.add_argument(\n+      '--topic',\n+      dest='topic',\n+      default='kafka_taxirides_realtime',\n+      help='Kafka topic to write to and read from')\n+  known_args, pipeline_args = parser.parse_known_args(argv)\n+\n+  pipeline_options = PipelineOptions(pipeline_args)\n+  pipeline_options.view_as(SetupOptions).save_main_session = True\n+  pipeline_options.view_as(StandardOptions).streaming = True\n+\n+  pipeline = beam.Pipeline(options=pipeline_options)\n+  bootstrap_servers = known_args.bootstrap_servers\n+  _ = (\n+      pipeline\n+      | beam.io.ReadFromPubSub(\n+          topic='projects/pubsub-public-data/topics/taxirides-realtime').\n+      with_output_types(bytes)\n+      | beam.Map(lambda x: (b'', x)).with_output_types(\n+          typing.Tuple[bytes, bytes])\n+      | beam.WindowInto(beam.window.FixedWindows(15))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTY4NjI5Ng=="}, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjIzNTg3Mg==", "bodyText": "It's required by the Kafka write transform added a comment.", "url": "https://github.com/apache/beam/pull/12188#discussion_r456235872", "createdAt": "2020-07-17T06:03:20Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/examples/kafkataxi/kafka_taxi.py", "diffHunk": "@@ -0,0 +1,87 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"An example that writes to and reads from Kafka.\n+\n+ This example reads from the PubSub NYC Taxi stream described in\n+ https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon, writes to a\n+ given Kafka topic and reads back from the same Kafka topic.\n+ \"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import argparse\n+import logging\n+import typing\n+\n+import apache_beam as beam\n+from apache_beam.io.kafka import ReadFromKafka\n+from apache_beam.io.kafka import WriteToKafka\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.options.pipeline_options import SetupOptions\n+from apache_beam.options.pipeline_options import StandardOptions\n+\n+\n+def run(argv=None):\n+  \"\"\"Main entry point; defines and runs the wordcount pipeline.\"\"\"\n+  parser = argparse.ArgumentParser()\n+  parser.add_argument(\n+      '--bootstrap_servers',\n+      dest='bootstrap_servers',\n+      required=True,\n+      help='Bootstrap servers for the Kafka cluster. Should be accessible by '\n+      'the runner')\n+  parser.add_argument(\n+      '--topic',\n+      dest='topic',\n+      default='kafka_taxirides_realtime',\n+      help='Kafka topic to write to and read from')\n+  known_args, pipeline_args = parser.parse_known_args(argv)\n+\n+  pipeline_options = PipelineOptions(pipeline_args)\n+  pipeline_options.view_as(SetupOptions).save_main_session = True\n+  pipeline_options.view_as(StandardOptions).streaming = True\n+\n+  pipeline = beam.Pipeline(options=pipeline_options)\n+  bootstrap_servers = known_args.bootstrap_servers\n+  _ = (\n+      pipeline\n+      | beam.io.ReadFromPubSub(\n+          topic='projects/pubsub-public-data/topics/taxirides-realtime').\n+      with_output_types(bytes)\n+      | beam.Map(lambda x: (b'', x)).with_output_types(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTY4ODQxOQ=="}, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NjI5NDE3Ng==", "bodyText": "Updated to parse and print elements.", "url": "https://github.com/apache/beam/pull/12188#discussion_r456294176", "createdAt": "2020-07-17T08:21:34Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/examples/kafkataxi/kafka_taxi.py", "diffHunk": "@@ -0,0 +1,87 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"An example that writes to and reads from Kafka.\n+\n+ This example reads from the PubSub NYC Taxi stream described in\n+ https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon, writes to a\n+ given Kafka topic and reads back from the same Kafka topic.\n+ \"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import argparse\n+import logging\n+import typing\n+\n+import apache_beam as beam\n+from apache_beam.io.kafka import ReadFromKafka\n+from apache_beam.io.kafka import WriteToKafka\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.options.pipeline_options import SetupOptions\n+from apache_beam.options.pipeline_options import StandardOptions\n+\n+\n+def run(argv=None):\n+  \"\"\"Main entry point; defines and runs the wordcount pipeline.\"\"\"\n+  parser = argparse.ArgumentParser()\n+  parser.add_argument(\n+      '--bootstrap_servers',\n+      dest='bootstrap_servers',\n+      required=True,\n+      help='Bootstrap servers for the Kafka cluster. Should be accessible by '\n+      'the runner')\n+  parser.add_argument(\n+      '--topic',\n+      dest='topic',\n+      default='kafka_taxirides_realtime',\n+      help='Kafka topic to write to and read from')\n+  known_args, pipeline_args = parser.parse_known_args(argv)\n+\n+  pipeline_options = PipelineOptions(pipeline_args)\n+  pipeline_options.view_as(SetupOptions).save_main_session = True\n+  pipeline_options.view_as(StandardOptions).streaming = True\n+\n+  pipeline = beam.Pipeline(options=pipeline_options)\n+  bootstrap_servers = known_args.bootstrap_servers\n+  _ = (\n+      pipeline\n+      | beam.io.ReadFromPubSub(\n+          topic='projects/pubsub-public-data/topics/taxirides-realtime').\n+      with_output_types(bytes)\n+      | beam.Map(lambda x: (b'', x)).with_output_types(\n+          typing.Tuple[bytes, bytes])\n+      | beam.WindowInto(beam.window.FixedWindows(15))\n+      | WriteToKafka(\n+          producer_config={'bootstrap.servers': bootstrap_servers},\n+          topic=known_args.topic))\n+\n+  _ = (\n+      pipeline\n+      | ReadFromKafka(\n+          consumer_config={'bootstrap.servers': bootstrap_servers},\n+          topics=[known_args.topic])\n+      | beam.FlatMap(lambda x: []))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTY4OTEyMw=="}, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 80}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUyMDAxNDUy", "url": "https://github.com/apache/beam/pull/12188#pullrequestreview-452001452", "createdAt": "2020-07-20T22:25:38Z", "commit": {"oid": "6c791812068c42ef262ea8bb4afb18d92e0b3163"}, "state": "APPROVED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMFQyMjoyNTozOFrOG0hZBA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMFQyMjo0NjowMlrOG0h2LQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzcyNjIxMg==", "bodyText": "Is there any reason to link to the proprietary version instead of the open source version? If there are no incompatibilities, I would suggest using the open source version.", "url": "https://github.com/apache/beam/pull/12188#discussion_r457726212", "createdAt": "2020-07-20T22:25:38Z", "author": {"login": "davidcavazos"}, "path": "sdks/python/apache_beam/examples/kafkataxi/README.md", "diffHunk": "@@ -0,0 +1,190 @@\n+<!--\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+-->\n+\n+# Python KafkaIO Example\n+\n+This example reads from the Google Cloud Pub/Sub NYC Taxi stream described\n+[here](https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon), writes\n+to a given Kafka topic, and reads back from the same Kafka topic. This example\n+uses cross-language transforms available in\n+[kafka.py](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/kafka.py).\n+Transforms are implemented in Java and are available\n+[here](https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java).\n+\n+## Prerequisites\n+\n+Install [Java Development kit (JDK) version 8](https://www.oracle.com/java/technologies/javase-downloads.html)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c791812068c42ef262ea8bb4afb18d92e0b3163"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzcyNzg2NA==", "bodyText": "Nit: can we make this a quote block with an information sign?\n> \u2139\ufe0f Note that this ...", "url": "https://github.com/apache/beam/pull/12188#discussion_r457727864", "createdAt": "2020-07-20T22:30:11Z", "author": {"login": "davidcavazos"}, "path": "sdks/python/apache_beam/examples/kafkataxi/README.md", "diffHunk": "@@ -0,0 +1,190 @@\n+<!--\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+-->\n+\n+# Python KafkaIO Example\n+\n+This example reads from the Google Cloud Pub/Sub NYC Taxi stream described\n+[here](https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon), writes\n+to a given Kafka topic, and reads back from the same Kafka topic. This example\n+uses cross-language transforms available in\n+[kafka.py](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/kafka.py).\n+Transforms are implemented in Java and are available\n+[here](https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java).\n+\n+## Prerequisites\n+\n+Install [Java Development kit (JDK) version 8](https://www.oracle.com/java/technologies/javase-downloads.html)\n+in your system and make sure that `JAVA_HOME` environment variable points to\n+your JDK installation. Make sure that `java` command is available in \n+the environment.\n+\n+```sh\n+java --version\n+<Should print information regarding the installed Java version>\n+```\n+\n+## Setup the Kafka cluster\n+\n+This example requires users to setup a Kafka cluster that the Beam runner\n+executing the pipeline has access to.\n+\n+See [here]((https://kafka.apache.org/quickstart)) for general instructions on\n+setting up a Kafka cluster. One option is to setup the Kafka cluster in\n+[GCE](https://cloud.google.com/compute). See\n+[here](https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/dataflow/flex-templates/kafka_to_bigquery)\n+for step by step instructions on  setting up a single node Kafka cluster in GCE.\n+When using Dataflow consider starting the Kafka cluster in the region where\n+Dataflow pipeline will be running. See\n+[here](https://cloud.google.com/dataflow/docs/concepts/regional-endpoints) \n+for more details regarding the selecting a GCP region for Dataflow.\n+\n+Let's assume that that IP address of one of the [bootstrap servers](https://kafka.apache.org/quickstart)\n+of the Kafka cluster to be  `123.45.67.89:123` and the port to be `9092`.\n+\n+```sh\n+export BOOTSTRAP_SERVER=\"123.45.67.89:123:9092\"\n+```\n+\n+## Running the example on latest released Beam version\n+\n+Perform Beam runner specific setup. Note that cross-language transforms require \n+portable implementations of Spark/Flink/Direct runners. Dataflow requires\n+[runner V2](https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#dataflow-runner-v2).\n+See [here](https://beam.apache.org/documentation/runners/dataflow/) for \n+instructions for setting up Dataflow.\n+\n+Setup a virtual environment for running Beam Python programs. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for prerequisites. \n+Dataflow requires the `gcp` tag when installing Beam.\n+\n+```sh\n+python -m venv env\n+source env/bin/activate\n+pip install -e 'apache-beam[gcp]'\n+```\n+\n+Run the Beam pipeline. You can either use the default Kafka topic name or \n+specify a Kafka topic name. Following command assumes Dataflow. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for instructions on \n+running Beam Python programs on other runners.\n+\n+Note that this exemple is not available in Beam versions before 2.24.0 hence", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c791812068c42ef262ea8bb4afb18d92e0b3163"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzcyODM2Mg==", "bodyText": "Typo: extra export", "url": "https://github.com/apache/beam/pull/12188#discussion_r457728362", "createdAt": "2020-07-20T22:31:30Z", "author": {"login": "davidcavazos"}, "path": "sdks/python/apache_beam/examples/kafkataxi/README.md", "diffHunk": "@@ -0,0 +1,190 @@\n+<!--\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+-->\n+\n+# Python KafkaIO Example\n+\n+This example reads from the Google Cloud Pub/Sub NYC Taxi stream described\n+[here](https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon), writes\n+to a given Kafka topic, and reads back from the same Kafka topic. This example\n+uses cross-language transforms available in\n+[kafka.py](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/kafka.py).\n+Transforms are implemented in Java and are available\n+[here](https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java).\n+\n+## Prerequisites\n+\n+Install [Java Development kit (JDK) version 8](https://www.oracle.com/java/technologies/javase-downloads.html)\n+in your system and make sure that `JAVA_HOME` environment variable points to\n+your JDK installation. Make sure that `java` command is available in \n+the environment.\n+\n+```sh\n+java --version\n+<Should print information regarding the installed Java version>\n+```\n+\n+## Setup the Kafka cluster\n+\n+This example requires users to setup a Kafka cluster that the Beam runner\n+executing the pipeline has access to.\n+\n+See [here]((https://kafka.apache.org/quickstart)) for general instructions on\n+setting up a Kafka cluster. One option is to setup the Kafka cluster in\n+[GCE](https://cloud.google.com/compute). See\n+[here](https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/dataflow/flex-templates/kafka_to_bigquery)\n+for step by step instructions on  setting up a single node Kafka cluster in GCE.\n+When using Dataflow consider starting the Kafka cluster in the region where\n+Dataflow pipeline will be running. See\n+[here](https://cloud.google.com/dataflow/docs/concepts/regional-endpoints) \n+for more details regarding the selecting a GCP region for Dataflow.\n+\n+Let's assume that that IP address of one of the [bootstrap servers](https://kafka.apache.org/quickstart)\n+of the Kafka cluster to be  `123.45.67.89:123` and the port to be `9092`.\n+\n+```sh\n+export BOOTSTRAP_SERVER=\"123.45.67.89:123:9092\"\n+```\n+\n+## Running the example on latest released Beam version\n+\n+Perform Beam runner specific setup. Note that cross-language transforms require \n+portable implementations of Spark/Flink/Direct runners. Dataflow requires\n+[runner V2](https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#dataflow-runner-v2).\n+See [here](https://beam.apache.org/documentation/runners/dataflow/) for \n+instructions for setting up Dataflow.\n+\n+Setup a virtual environment for running Beam Python programs. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for prerequisites. \n+Dataflow requires the `gcp` tag when installing Beam.\n+\n+```sh\n+python -m venv env\n+source env/bin/activate\n+pip install -e 'apache-beam[gcp]'\n+```\n+\n+Run the Beam pipeline. You can either use the default Kafka topic name or \n+specify a Kafka topic name. Following command assumes Dataflow. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for instructions on \n+running Beam Python programs on other runners.\n+\n+Note that this exemple is not available in Beam versions before 2.24.0 hence\n+you'll have to either get the example program from Beam or follow steps\n+provided in the section *Running the Example from a Beam Git Clone*.\n+\n+```sh\n+export PROJECT=\"$(gcloud config get-value project)\"\n+export TEMP_LOCATION=\"gs://MY-BUCKET/temp\"\n+export REGION=\"us-central1\" \n+export JOB_NAME=\"kafka-taxi-`date +%Y%m%d-%H%M%S`\"\n+export NUM_WORKERS=\"5\"\n+\n+python -m apache_beam.examples.kafkataxi.kafka_taxi \\\n+  --runner DataflowRunner \\\n+  --temp_location $TEMP_LOCATION \\\n+  --project $PROJECT \\\n+  --region $REGION \\\n+  --num_workers $NUM_WORKERS \\\n+  --job_name $JOB_NAME \\\n+  --bootstrap_servers $BOOTSTRAP_SERVER \\\n+  --experiments=use_runner_v2\n+```\n+\n+## *(Optional)*  Running the Example from a Beam Git Clone\n+\n+Running this example from a Beam Git clone requires some additional steps.\n+\n+Checkout a clone of the Beam Git repo. See \n+[here](https://beam.apache.org/contribute/) for prerequisites.\n+\n+Assume your Github username to be `GITHUB_USERNAME`.\n+\n+```sh\n+git clone git@github.com:${GITHUB_USERNAME}/beam\n+cd beam\n+```\n+\n+Build IO expansion service jar.\n+\n+```sh\n+./gradlew :sdks:java:io:expansion-service:build\n+```\n+\n+Push a java SDK Harness container to [Docker](https://www.docker.com/get-started)\n+Hub. See \n+[here](https://beam.apache.org/documentation/runtime/environments/) for \n+prerequisites and additional information.\n+\n+```sh\n+export DOCKER_ROOT=\"Your Docker Repository Root\"\n+./gradlew :sdks:java:container:docker -Pdocker-repository-root=$DOCKER_ROOT -Pdocker-tag=latest\n+docker push $DOCKER_ROOT/beam_java_sdk:latest\n+```\n+\n+For portable Flink/Spark in local mode, instead of above command just build the\n+Java SDK harness container locally using the default values for repository root\n+and the docker tag.\n+\n+Activate your Python virtual environment.  This example uses `venv`. See \n+[here](https://cwiki.apache.org/confluence/display/BEAM/Python+Tips) for\n+instructions regarding setting up other types of Python virtual environments.\n+\n+```sh\n+cd ..  # Creating the virtual environment in the top level work directory.\n+python -m venv env\n+source env/bin/activate\n+```\n+\n+Install Beam and dependencies and build a Beam distribution.\n+\n+```sh\n+cd beam/sdks/python\n+pip install -r build-requirements.txt\n+pip install -e '.[gcp]'\n+python setup.py sdist\n+```\n+\n+Run the Beam pipeline. You can either use the default Kafka topic name or specify \n+a Kafka topic name. Following command assumes Dataflow. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for instructions on \n+running Beam Python programs on other runners.\n+\n+See [here](https://cloud.google.com/dataflow/docs/concepts/regional-endpoints) \n+for more details regarding the selecting a GCP region for Dataflow.\n+\n+```sh\n+export PROJECT=\"$(gcloud config get-value project)\"\n+export TEMP_LOCATION=\"gs://MY-BUCKET/temp\"\n+export REGION=\"us-central1\" \n+export JOB_NAME=\"kafka-taxi-`date +%Y%m%d-%H%M%S`\"\n+export export NUM_WORKERS=\"5\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c791812068c42ef262ea8bb4afb18d92e0b3163"}, "originalPosition": 176}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzcyODY1Mg==", "bodyText": "Nit: for consistency with the README it would be nice to use the same \"123.45.67.89:123:9092\" example :)", "url": "https://github.com/apache/beam/pull/12188#discussion_r457728652", "createdAt": "2020-07-20T22:32:30Z", "author": {"login": "davidcavazos"}, "path": "sdks/python/apache_beam/examples/kafkataxi/kafka_taxi.py", "diffHunk": "@@ -0,0 +1,105 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"An example that writes to and reads from Kafka.\n+\n+ This example reads from the PubSub NYC Taxi stream described in\n+ https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon, writes to a\n+ given Kafka topic and reads back from the same Kafka topic.\n+ \"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import logging\n+import typing\n+\n+import apache_beam as beam\n+from apache_beam.io.kafka import ReadFromKafka\n+from apache_beam.io.kafka import WriteToKafka\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.options.pipeline_options import SetupOptions\n+from apache_beam.options.pipeline_options import StandardOptions\n+\n+\n+def run(bootstrap_servers, topic, pipeline_args):\n+  # bootstrap_servers = '...'", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c791812068c42ef262ea8bb4afb18d92e0b3163"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzcyOTM4Mw==", "bodyText": "Nit: it would read nicer if every parameter was in its own line, it would only add 2 extra lines\n# pipeline_args = ['--project', 'my-project',\n#                  '--runner', 'DataflowRunner',\n# ...", "url": "https://github.com/apache/beam/pull/12188#discussion_r457729383", "createdAt": "2020-07-20T22:34:17Z", "author": {"login": "davidcavazos"}, "path": "sdks/python/apache_beam/examples/kafkataxi/kafka_taxi.py", "diffHunk": "@@ -0,0 +1,105 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"An example that writes to and reads from Kafka.\n+\n+ This example reads from the PubSub NYC Taxi stream described in\n+ https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon, writes to a\n+ given Kafka topic and reads back from the same Kafka topic.\n+ \"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import logging\n+import typing\n+\n+import apache_beam as beam\n+from apache_beam.io.kafka import ReadFromKafka\n+from apache_beam.io.kafka import WriteToKafka\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.options.pipeline_options import SetupOptions\n+from apache_beam.options.pipeline_options import StandardOptions\n+\n+\n+def run(bootstrap_servers, topic, pipeline_args):\n+  # bootstrap_servers = '...'\n+  # topic = 'kafka_taxirides_realtime'\n+  # pipeline_args = ['--project', 'my-project', '--runner', 'DataflowRunner',", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c791812068c42ef262ea8bb4afb18d92e0b3163"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMjAzNQ==", "bodyText": "It would be nice to use the kwargs version, it's shorter and easier to read/write.", "url": "https://github.com/apache/beam/pull/12188#discussion_r457732035", "createdAt": "2020-07-20T22:41:33Z", "author": {"login": "davidcavazos"}, "path": "sdks/python/apache_beam/examples/kafkataxi/kafka_taxi.py", "diffHunk": "@@ -0,0 +1,105 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"An example that writes to and reads from Kafka.\n+\n+ This example reads from the PubSub NYC Taxi stream described in\n+ https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon, writes to a\n+ given Kafka topic and reads back from the same Kafka topic.\n+ \"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import logging\n+import typing\n+\n+import apache_beam as beam\n+from apache_beam.io.kafka import ReadFromKafka\n+from apache_beam.io.kafka import WriteToKafka\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.options.pipeline_options import SetupOptions\n+from apache_beam.options.pipeline_options import StandardOptions\n+\n+\n+def run(bootstrap_servers, topic, pipeline_args):\n+  # bootstrap_servers = '...'\n+  # topic = 'kafka_taxirides_realtime'\n+  # pipeline_args = ['--project', 'my-project', '--runner', 'DataflowRunner',\n+  #                  '--temp_location', 'my-temp-location',\n+  #                  '--region', 'my-region', '--num_workers',\n+  #                  'my-num-workers', '--experiments', 'use_runner_v2']\n+\n+  pipeline_options = PipelineOptions(pipeline_args)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c791812068c42ef262ea8bb4afb18d92e0b3163"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMzU0NA==", "bodyText": "When using the with statement, this line is no longer necessary, it's run by the __exit__ method of Pipeline.", "url": "https://github.com/apache/beam/pull/12188#discussion_r457733544", "createdAt": "2020-07-20T22:45:39Z", "author": {"login": "davidcavazos"}, "path": "sdks/python/apache_beam/examples/kafkataxi/kafka_taxi.py", "diffHunk": "@@ -0,0 +1,105 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"An example that writes to and reads from Kafka.\n+\n+ This example reads from the PubSub NYC Taxi stream described in\n+ https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon, writes to a\n+ given Kafka topic and reads back from the same Kafka topic.\n+ \"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import logging\n+import typing\n+\n+import apache_beam as beam\n+from apache_beam.io.kafka import ReadFromKafka\n+from apache_beam.io.kafka import WriteToKafka\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.options.pipeline_options import SetupOptions\n+from apache_beam.options.pipeline_options import StandardOptions\n+\n+\n+def run(bootstrap_servers, topic, pipeline_args):\n+  # bootstrap_servers = '...'\n+  # topic = 'kafka_taxirides_realtime'\n+  # pipeline_args = ['--project', 'my-project', '--runner', 'DataflowRunner',\n+  #                  '--temp_location', 'my-temp-location',\n+  #                  '--region', 'my-region', '--num_workers',\n+  #                  'my-num-workers', '--experiments', 'use_runner_v2']\n+\n+  pipeline_options = PipelineOptions(pipeline_args)\n+  pipeline_options.view_as(SetupOptions).save_main_session = True\n+  pipeline_options.view_as(StandardOptions).streaming = True\n+  window_size = 15  # size of the Window in seconds.\n+\n+  def log_ride(ride_bytes):\n+    # Converting bytes record from Kafka to a dictionary.\n+    import ast\n+    ride = ast.literal_eval(ride_bytes.decode(\"UTF-8\"))\n+    logging.info(\n+        'Found ride at latitude %r and longitude %r with %r '\n+        'passengers',\n+        ride['latitude'],\n+        ride['longitude'],\n+        ride['passenger_count'])\n+\n+  with beam.Pipeline(options=pipeline_options) as pipeline:\n+    _ = (\n+        pipeline\n+        | beam.io.ReadFromPubSub(\n+            topic='projects/pubsub-public-data/topics/taxirides-realtime').\n+        with_output_types(bytes)\n+        | beam.Map(lambda x: (b'', x)).with_output_types(\n+            typing.Tuple[bytes, bytes])  # Kafka write transforms expects KVs.\n+        | beam.WindowInto(beam.window.FixedWindows(window_size))\n+        | WriteToKafka(\n+            producer_config={'bootstrap.servers': bootstrap_servers},\n+            topic=topic))\n+\n+    _ = (\n+        pipeline\n+        | ReadFromKafka(\n+            consumer_config={'bootstrap.servers': bootstrap_servers},\n+            topics=[topic])\n+        | beam.FlatMap(lambda kv: log_ride(kv[1])))\n+\n+    pipeline.run().wait_until_finish()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6c791812068c42ef262ea8bb4afb18d92e0b3163"}, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMzY3Nw==", "bodyText": "Got it, sounds good to me.", "url": "https://github.com/apache/beam/pull/12188#discussion_r457733677", "createdAt": "2020-07-20T22:46:02Z", "author": {"login": "davidcavazos"}, "path": "sdks/python/apache_beam/examples/kafkataxi/kafka_taxi.py", "diffHunk": "@@ -0,0 +1,87 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"An example that writes to and reads from Kafka.\n+\n+ This example reads from the PubSub NYC Taxi stream described in\n+ https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon, writes to a\n+ given Kafka topic and reads back from the same Kafka topic.\n+ \"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import argparse\n+import logging\n+import typing\n+\n+import apache_beam as beam\n+from apache_beam.io.kafka import ReadFromKafka\n+from apache_beam.io.kafka import WriteToKafka\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.options.pipeline_options import SetupOptions\n+from apache_beam.options.pipeline_options import StandardOptions\n+\n+\n+def run(argv=None):\n+  \"\"\"Main entry point; defines and runs the wordcount pipeline.\"\"\"\n+  parser = argparse.ArgumentParser()\n+  parser.add_argument(\n+      '--bootstrap_servers',", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTY4NzMzNg=="}, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 45}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1d781ff7d8649090a9fd51a114e7382b85fc8f80", "author": {"user": {"login": "chamikaramj", "name": "Chamikara Jayalath"}}, "url": "https://github.com/apache/beam/commit/1d781ff7d8649090a9fd51a114e7382b85fc8f80", "committedDate": "2020-07-21T20:01:23Z", "message": "Addresses reviewer comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUyNzEzNzMx", "url": "https://github.com/apache/beam/pull/12188#pullrequestreview-452713731", "createdAt": "2020-07-21T18:16:17Z", "commit": {"oid": "6c791812068c42ef262ea8bb4afb18d92e0b3163"}, "state": "COMMENTED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQxODoxNjoxN1rOG1EM4g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQyMDowMjo1OFrOG1HwNw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODI5NjU0Ng==", "bodyText": "I'm using the same link as Beam quickstart: https://beam.apache.org/get-started/quickstart-java/", "url": "https://github.com/apache/beam/pull/12188#discussion_r458296546", "createdAt": "2020-07-21T18:16:17Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/examples/kafkataxi/README.md", "diffHunk": "@@ -0,0 +1,190 @@\n+<!--\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+-->\n+\n+# Python KafkaIO Example\n+\n+This example reads from the Google Cloud Pub/Sub NYC Taxi stream described\n+[here](https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon), writes\n+to a given Kafka topic, and reads back from the same Kafka topic. This example\n+uses cross-language transforms available in\n+[kafka.py](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/kafka.py).\n+Transforms are implemented in Java and are available\n+[here](https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java).\n+\n+## Prerequisites\n+\n+Install [Java Development kit (JDK) version 8](https://www.oracle.com/java/technologies/javase-downloads.html)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzcyNjIxMg=="}, "originalCommit": {"oid": "6c791812068c42ef262ea8bb4afb18d92e0b3163"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODI5NzUzOQ==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/12188#discussion_r458297539", "createdAt": "2020-07-21T18:17:57Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/examples/kafkataxi/README.md", "diffHunk": "@@ -0,0 +1,190 @@\n+<!--\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+-->\n+\n+# Python KafkaIO Example\n+\n+This example reads from the Google Cloud Pub/Sub NYC Taxi stream described\n+[here](https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon), writes\n+to a given Kafka topic, and reads back from the same Kafka topic. This example\n+uses cross-language transforms available in\n+[kafka.py](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/kafka.py).\n+Transforms are implemented in Java and are available\n+[here](https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java).\n+\n+## Prerequisites\n+\n+Install [Java Development kit (JDK) version 8](https://www.oracle.com/java/technologies/javase-downloads.html)\n+in your system and make sure that `JAVA_HOME` environment variable points to\n+your JDK installation. Make sure that `java` command is available in \n+the environment.\n+\n+```sh\n+java --version\n+<Should print information regarding the installed Java version>\n+```\n+\n+## Setup the Kafka cluster\n+\n+This example requires users to setup a Kafka cluster that the Beam runner\n+executing the pipeline has access to.\n+\n+See [here]((https://kafka.apache.org/quickstart)) for general instructions on\n+setting up a Kafka cluster. One option is to setup the Kafka cluster in\n+[GCE](https://cloud.google.com/compute). See\n+[here](https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/dataflow/flex-templates/kafka_to_bigquery)\n+for step by step instructions on  setting up a single node Kafka cluster in GCE.\n+When using Dataflow consider starting the Kafka cluster in the region where\n+Dataflow pipeline will be running. See\n+[here](https://cloud.google.com/dataflow/docs/concepts/regional-endpoints) \n+for more details regarding the selecting a GCP region for Dataflow.\n+\n+Let's assume that that IP address of one of the [bootstrap servers](https://kafka.apache.org/quickstart)\n+of the Kafka cluster to be  `123.45.67.89:123` and the port to be `9092`.\n+\n+```sh\n+export BOOTSTRAP_SERVER=\"123.45.67.89:123:9092\"\n+```\n+\n+## Running the example on latest released Beam version\n+\n+Perform Beam runner specific setup. Note that cross-language transforms require \n+portable implementations of Spark/Flink/Direct runners. Dataflow requires\n+[runner V2](https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#dataflow-runner-v2).\n+See [here](https://beam.apache.org/documentation/runners/dataflow/) for \n+instructions for setting up Dataflow.\n+\n+Setup a virtual environment for running Beam Python programs. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for prerequisites. \n+Dataflow requires the `gcp` tag when installing Beam.\n+\n+```sh\n+python -m venv env\n+source env/bin/activate\n+pip install -e 'apache-beam[gcp]'\n+```\n+\n+Run the Beam pipeline. You can either use the default Kafka topic name or \n+specify a Kafka topic name. Following command assumes Dataflow. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for instructions on \n+running Beam Python programs on other runners.\n+\n+Note that this exemple is not available in Beam versions before 2.24.0 hence", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzcyNzg2NA=="}, "originalCommit": {"oid": "6c791812068c42ef262ea8bb4afb18d92e0b3163"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODI5Nzc1Mg==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/12188#discussion_r458297752", "createdAt": "2020-07-21T18:18:19Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/examples/kafkataxi/README.md", "diffHunk": "@@ -0,0 +1,190 @@\n+<!--\n+    Licensed to the Apache Software Foundation (ASF) under one\n+    or more contributor license agreements.  See the NOTICE file\n+    distributed with this work for additional information\n+    regarding copyright ownership.  The ASF licenses this file\n+    to you under the Apache License, Version 2.0 (the\n+    \"License\"); you may not use this file except in compliance\n+    with the License.  You may obtain a copy of the License at\n+\n+      http://www.apache.org/licenses/LICENSE-2.0\n+\n+    Unless required by applicable law or agreed to in writing,\n+    software distributed under the License is distributed on an\n+    \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+    KIND, either express or implied.  See the License for the\n+    specific language governing permissions and limitations\n+    under the License.\n+-->\n+\n+# Python KafkaIO Example\n+\n+This example reads from the Google Cloud Pub/Sub NYC Taxi stream described\n+[here](https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon), writes\n+to a given Kafka topic, and reads back from the same Kafka topic. This example\n+uses cross-language transforms available in\n+[kafka.py](https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/kafka.py).\n+Transforms are implemented in Java and are available\n+[here](https://github.com/apache/beam/blob/master/sdks/java/io/kafka/src/main/java/org/apache/beam/sdk/io/kafka/KafkaIO.java).\n+\n+## Prerequisites\n+\n+Install [Java Development kit (JDK) version 8](https://www.oracle.com/java/technologies/javase-downloads.html)\n+in your system and make sure that `JAVA_HOME` environment variable points to\n+your JDK installation. Make sure that `java` command is available in \n+the environment.\n+\n+```sh\n+java --version\n+<Should print information regarding the installed Java version>\n+```\n+\n+## Setup the Kafka cluster\n+\n+This example requires users to setup a Kafka cluster that the Beam runner\n+executing the pipeline has access to.\n+\n+See [here]((https://kafka.apache.org/quickstart)) for general instructions on\n+setting up a Kafka cluster. One option is to setup the Kafka cluster in\n+[GCE](https://cloud.google.com/compute). See\n+[here](https://github.com/GoogleCloudPlatform/java-docs-samples/tree/master/dataflow/flex-templates/kafka_to_bigquery)\n+for step by step instructions on  setting up a single node Kafka cluster in GCE.\n+When using Dataflow consider starting the Kafka cluster in the region where\n+Dataflow pipeline will be running. See\n+[here](https://cloud.google.com/dataflow/docs/concepts/regional-endpoints) \n+for more details regarding the selecting a GCP region for Dataflow.\n+\n+Let's assume that that IP address of one of the [bootstrap servers](https://kafka.apache.org/quickstart)\n+of the Kafka cluster to be  `123.45.67.89:123` and the port to be `9092`.\n+\n+```sh\n+export BOOTSTRAP_SERVER=\"123.45.67.89:123:9092\"\n+```\n+\n+## Running the example on latest released Beam version\n+\n+Perform Beam runner specific setup. Note that cross-language transforms require \n+portable implementations of Spark/Flink/Direct runners. Dataflow requires\n+[runner V2](https://cloud.google.com/dataflow/docs/guides/deploying-a-pipeline#dataflow-runner-v2).\n+See [here](https://beam.apache.org/documentation/runners/dataflow/) for \n+instructions for setting up Dataflow.\n+\n+Setup a virtual environment for running Beam Python programs. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for prerequisites. \n+Dataflow requires the `gcp` tag when installing Beam.\n+\n+```sh\n+python -m venv env\n+source env/bin/activate\n+pip install -e 'apache-beam[gcp]'\n+```\n+\n+Run the Beam pipeline. You can either use the default Kafka topic name or \n+specify a Kafka topic name. Following command assumes Dataflow. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for instructions on \n+running Beam Python programs on other runners.\n+\n+Note that this exemple is not available in Beam versions before 2.24.0 hence\n+you'll have to either get the example program from Beam or follow steps\n+provided in the section *Running the Example from a Beam Git Clone*.\n+\n+```sh\n+export PROJECT=\"$(gcloud config get-value project)\"\n+export TEMP_LOCATION=\"gs://MY-BUCKET/temp\"\n+export REGION=\"us-central1\" \n+export JOB_NAME=\"kafka-taxi-`date +%Y%m%d-%H%M%S`\"\n+export NUM_WORKERS=\"5\"\n+\n+python -m apache_beam.examples.kafkataxi.kafka_taxi \\\n+  --runner DataflowRunner \\\n+  --temp_location $TEMP_LOCATION \\\n+  --project $PROJECT \\\n+  --region $REGION \\\n+  --num_workers $NUM_WORKERS \\\n+  --job_name $JOB_NAME \\\n+  --bootstrap_servers $BOOTSTRAP_SERVER \\\n+  --experiments=use_runner_v2\n+```\n+\n+## *(Optional)*  Running the Example from a Beam Git Clone\n+\n+Running this example from a Beam Git clone requires some additional steps.\n+\n+Checkout a clone of the Beam Git repo. See \n+[here](https://beam.apache.org/contribute/) for prerequisites.\n+\n+Assume your Github username to be `GITHUB_USERNAME`.\n+\n+```sh\n+git clone git@github.com:${GITHUB_USERNAME}/beam\n+cd beam\n+```\n+\n+Build IO expansion service jar.\n+\n+```sh\n+./gradlew :sdks:java:io:expansion-service:build\n+```\n+\n+Push a java SDK Harness container to [Docker](https://www.docker.com/get-started)\n+Hub. See \n+[here](https://beam.apache.org/documentation/runtime/environments/) for \n+prerequisites and additional information.\n+\n+```sh\n+export DOCKER_ROOT=\"Your Docker Repository Root\"\n+./gradlew :sdks:java:container:docker -Pdocker-repository-root=$DOCKER_ROOT -Pdocker-tag=latest\n+docker push $DOCKER_ROOT/beam_java_sdk:latest\n+```\n+\n+For portable Flink/Spark in local mode, instead of above command just build the\n+Java SDK harness container locally using the default values for repository root\n+and the docker tag.\n+\n+Activate your Python virtual environment.  This example uses `venv`. See \n+[here](https://cwiki.apache.org/confluence/display/BEAM/Python+Tips) for\n+instructions regarding setting up other types of Python virtual environments.\n+\n+```sh\n+cd ..  # Creating the virtual environment in the top level work directory.\n+python -m venv env\n+source env/bin/activate\n+```\n+\n+Install Beam and dependencies and build a Beam distribution.\n+\n+```sh\n+cd beam/sdks/python\n+pip install -r build-requirements.txt\n+pip install -e '.[gcp]'\n+python setup.py sdist\n+```\n+\n+Run the Beam pipeline. You can either use the default Kafka topic name or specify \n+a Kafka topic name. Following command assumes Dataflow. See \n+[here](https://beam.apache.org/get-started/quickstart-py/) for instructions on \n+running Beam Python programs on other runners.\n+\n+See [here](https://cloud.google.com/dataflow/docs/concepts/regional-endpoints) \n+for more details regarding the selecting a GCP region for Dataflow.\n+\n+```sh\n+export PROJECT=\"$(gcloud config get-value project)\"\n+export TEMP_LOCATION=\"gs://MY-BUCKET/temp\"\n+export REGION=\"us-central1\" \n+export JOB_NAME=\"kafka-taxi-`date +%Y%m%d-%H%M%S`\"\n+export export NUM_WORKERS=\"5\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzcyODM2Mg=="}, "originalCommit": {"oid": "6c791812068c42ef262ea8bb4afb18d92e0b3163"}, "originalPosition": 176}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODI5ODI4OQ==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/12188#discussion_r458298289", "createdAt": "2020-07-21T18:18:58Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/examples/kafkataxi/kafka_taxi.py", "diffHunk": "@@ -0,0 +1,105 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"An example that writes to and reads from Kafka.\n+\n+ This example reads from the PubSub NYC Taxi stream described in\n+ https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon, writes to a\n+ given Kafka topic and reads back from the same Kafka topic.\n+ \"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import logging\n+import typing\n+\n+import apache_beam as beam\n+from apache_beam.io.kafka import ReadFromKafka\n+from apache_beam.io.kafka import WriteToKafka\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.options.pipeline_options import SetupOptions\n+from apache_beam.options.pipeline_options import StandardOptions\n+\n+\n+def run(bootstrap_servers, topic, pipeline_args):\n+  # bootstrap_servers = '...'", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzcyODY1Mg=="}, "originalCommit": {"oid": "6c791812068c42ef262ea8bb4afb18d92e0b3163"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODI5ODc2Mg==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/12188#discussion_r458298762", "createdAt": "2020-07-21T18:19:51Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/examples/kafkataxi/kafka_taxi.py", "diffHunk": "@@ -0,0 +1,105 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"An example that writes to and reads from Kafka.\n+\n+ This example reads from the PubSub NYC Taxi stream described in\n+ https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon, writes to a\n+ given Kafka topic and reads back from the same Kafka topic.\n+ \"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import logging\n+import typing\n+\n+import apache_beam as beam\n+from apache_beam.io.kafka import ReadFromKafka\n+from apache_beam.io.kafka import WriteToKafka\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.options.pipeline_options import SetupOptions\n+from apache_beam.options.pipeline_options import StandardOptions\n+\n+\n+def run(bootstrap_servers, topic, pipeline_args):\n+  # bootstrap_servers = '...'\n+  # topic = 'kafka_taxirides_realtime'\n+  # pipeline_args = ['--project', 'my-project', '--runner', 'DataflowRunner',", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzcyOTM4Mw=="}, "originalCommit": {"oid": "6c791812068c42ef262ea8bb4afb18d92e0b3163"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODI5OTI4NA==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/12188#discussion_r458299284", "createdAt": "2020-07-21T18:20:45Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/examples/kafkataxi/kafka_taxi.py", "diffHunk": "@@ -0,0 +1,105 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"An example that writes to and reads from Kafka.\n+\n+ This example reads from the PubSub NYC Taxi stream described in\n+ https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon, writes to a\n+ given Kafka topic and reads back from the same Kafka topic.\n+ \"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import logging\n+import typing\n+\n+import apache_beam as beam\n+from apache_beam.io.kafka import ReadFromKafka\n+from apache_beam.io.kafka import WriteToKafka\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.options.pipeline_options import SetupOptions\n+from apache_beam.options.pipeline_options import StandardOptions\n+\n+\n+def run(bootstrap_servers, topic, pipeline_args):\n+  # bootstrap_servers = '...'\n+  # topic = 'kafka_taxirides_realtime'\n+  # pipeline_args = ['--project', 'my-project', '--runner', 'DataflowRunner',\n+  #                  '--temp_location', 'my-temp-location',\n+  #                  '--region', 'my-region', '--num_workers',\n+  #                  'my-num-workers', '--experiments', 'use_runner_v2']\n+\n+  pipeline_options = PipelineOptions(pipeline_args)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMjAzNQ=="}, "originalCommit": {"oid": "6c791812068c42ef262ea8bb4afb18d92e0b3163"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODI5OTQ2MA==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/12188#discussion_r458299460", "createdAt": "2020-07-21T18:21:05Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/examples/kafkataxi/kafka_taxi.py", "diffHunk": "@@ -0,0 +1,105 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"An example that writes to and reads from Kafka.\n+\n+ This example reads from the PubSub NYC Taxi stream described in\n+ https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon, writes to a\n+ given Kafka topic and reads back from the same Kafka topic.\n+ \"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import logging\n+import typing\n+\n+import apache_beam as beam\n+from apache_beam.io.kafka import ReadFromKafka\n+from apache_beam.io.kafka import WriteToKafka\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.options.pipeline_options import SetupOptions\n+from apache_beam.options.pipeline_options import StandardOptions\n+\n+\n+def run(bootstrap_servers, topic, pipeline_args):\n+  # bootstrap_servers = '...'\n+  # topic = 'kafka_taxirides_realtime'\n+  # pipeline_args = ['--project', 'my-project', '--runner', 'DataflowRunner',\n+  #                  '--temp_location', 'my-temp-location',\n+  #                  '--region', 'my-region', '--num_workers',\n+  #                  'my-num-workers', '--experiments', 'use_runner_v2']\n+\n+  pipeline_options = PipelineOptions(pipeline_args)\n+  pipeline_options.view_as(SetupOptions).save_main_session = True\n+  pipeline_options.view_as(StandardOptions).streaming = True\n+  window_size = 15  # size of the Window in seconds.\n+\n+  def log_ride(ride_bytes):\n+    # Converting bytes record from Kafka to a dictionary.\n+    import ast\n+    ride = ast.literal_eval(ride_bytes.decode(\"UTF-8\"))\n+    logging.info(\n+        'Found ride at latitude %r and longitude %r with %r '\n+        'passengers',\n+        ride['latitude'],\n+        ride['longitude'],\n+        ride['passenger_count'])\n+\n+  with beam.Pipeline(options=pipeline_options) as pipeline:\n+    _ = (\n+        pipeline\n+        | beam.io.ReadFromPubSub(\n+            topic='projects/pubsub-public-data/topics/taxirides-realtime').\n+        with_output_types(bytes)\n+        | beam.Map(lambda x: (b'', x)).with_output_types(\n+            typing.Tuple[bytes, bytes])  # Kafka write transforms expects KVs.\n+        | beam.WindowInto(beam.window.FixedWindows(window_size))\n+        | WriteToKafka(\n+            producer_config={'bootstrap.servers': bootstrap_servers},\n+            topic=topic))\n+\n+    _ = (\n+        pipeline\n+        | ReadFromKafka(\n+            consumer_config={'bootstrap.servers': bootstrap_servers},\n+            topics=[topic])\n+        | beam.FlatMap(lambda kv: log_ride(kv[1])))\n+\n+    pipeline.run().wait_until_finish()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzczMzU0NA=="}, "originalCommit": {"oid": "6c791812068c42ef262ea8bb4afb18d92e0b3163"}, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODM1NDc0Mw==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/12188#discussion_r458354743", "createdAt": "2020-07-21T20:02:58Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/examples/kafkataxi/kafka_taxi.py", "diffHunk": "@@ -0,0 +1,87 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"An example that writes to and reads from Kafka.\n+\n+ This example reads from the PubSub NYC Taxi stream described in\n+ https://github.com/googlecodelabs/cloud-dataflow-nyc-taxi-tycoon, writes to a\n+ given Kafka topic and reads back from the same Kafka topic.\n+ \"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import argparse\n+import logging\n+import typing\n+\n+import apache_beam as beam\n+from apache_beam.io.kafka import ReadFromKafka\n+from apache_beam.io.kafka import WriteToKafka\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.options.pipeline_options import SetupOptions\n+from apache_beam.options.pipeline_options import StandardOptions\n+\n+\n+def run(argv=None):\n+  \"\"\"Main entry point; defines and runs the wordcount pipeline.\"\"\"\n+  parser = argparse.ArgumentParser()\n+  parser.add_argument(\n+      '--bootstrap_servers',\n+      dest='bootstrap_servers',\n+      required=True,\n+      help='Bootstrap servers for the Kafka cluster. Should be accessible by '\n+      'the runner')\n+  parser.add_argument(\n+      '--topic',\n+      dest='topic',\n+      default='kafka_taxirides_realtime',\n+      help='Kafka topic to write to and read from')\n+  known_args, pipeline_args = parser.parse_known_args(argv)\n+\n+  pipeline_options = PipelineOptions(pipeline_args)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTY3NjMzOA=="}, "originalCommit": {"oid": "c01d0f0d0cea545632809131a8dc5a1adeaa9db6"}, "originalPosition": 57}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3394, "cost": 1, "resetAt": "2021-10-28T16:48:13Z"}}}