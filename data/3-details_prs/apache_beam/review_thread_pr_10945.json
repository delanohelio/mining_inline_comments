{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzc4NzkyOTE3", "number": 10945, "reviewThreads": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQwNTo0MTozM1rODi8uWQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQxMTowOToxMFrODmopCQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM3OTczMDgxOnYy", "diffSide": "RIGHT", "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkExecutionEnvironments.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQwNTo0MTozM1rOFue2TQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yNlQwNTo0MTozM1rOFue2TQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NDI4NDIzNw==", "bodyText": "It has sets the default managed memory size to 128MB for MiniCluster in https://issues.apache.org/jira/browse/FLINK-15763. Have set it to a large value when the master host is [local]. Appreciate for any suggestions on a better way to address this issue.", "url": "https://github.com/apache/beam/pull/10945#discussion_r384284237", "createdAt": "2020-02-26T05:41:33Z", "author": {"login": "sunjincheng121"}, "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkExecutionEnvironments.java", "diffHunk": "@@ -67,6 +69,7 @@ static ExecutionEnvironment createBatchExecutionEnvironment(\n \n     // depending on the master, create the right environment.\n     if (\"[local]\".equals(flinkMasterHostPort)) {\n+      flinkConfiguration.set(TaskManagerOptions.MANAGED_MEMORY_SIZE, MemorySize.parse(\"2048m\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "156c43747f81ee6b539af054769f54155ff039c4"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM4ODAyNjMwOnYy", "diffSide": "LEFT", "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkExecutionEnvironments.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yOFQwOTowMToxN1rOFvtx0g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQxNToyMjo1OFrOFztQDw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTU3NzQyNg==", "bodyText": "This cannot be removed yet. The feature is only present in 1.8.", "url": "https://github.com/apache/beam/pull/10945#discussion_r385577426", "createdAt": "2020-02-28T09:01:17Z", "author": {"login": "mxm"}, "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkExecutionEnvironments.java", "diffHunk": "@@ -311,78 +302,4 @@ private static void applyLatencyTrackingInterval(\n     long latencyTrackingInterval = options.getLatencyTrackingInterval();\n     config.setLatencyTrackingInterval(latencyTrackingInterval);\n   }\n-\n-  /**\n-   * Remote stream environment that supports job execution with restore from savepoint.\n-   *\n-   * <p>This class can be removed once Flink provides this functionality.\n-   *\n-   * <p>TODO: https://issues.apache.org/jira/browse/BEAM-5396\n-   */\n-  private static class BeamFlinkRemoteStreamEnvironment extends RemoteStreamEnvironment {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "82b781c3f39ffe684ca93bde7c8520244cdfe4a3"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NjAwMjg0MA==", "bodyText": "BeamFlinkRemoteStreamEnvironment has not been removed. Actually it has been moved to runner 1.7. The reason is that in 1.10 we don't need it any more. What do you think?", "url": "https://github.com/apache/beam/pull/10945#discussion_r386002840", "createdAt": "2020-02-29T05:20:11Z", "author": {"login": "sunjincheng121"}, "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkExecutionEnvironments.java", "diffHunk": "@@ -311,78 +302,4 @@ private static void applyLatencyTrackingInterval(\n     long latencyTrackingInterval = options.getLatencyTrackingInterval();\n     config.setLatencyTrackingInterval(latencyTrackingInterval);\n   }\n-\n-  /**\n-   * Remote stream environment that supports job execution with restore from savepoint.\n-   *\n-   * <p>This class can be removed once Flink provides this functionality.\n-   *\n-   * <p>TODO: https://issues.apache.org/jira/browse/BEAM-5396\n-   */\n-  private static class BeamFlinkRemoteStreamEnvironment extends RemoteStreamEnvironment {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTU3NzQyNg=="}, "originalCommit": {"oid": "82b781c3f39ffe684ca93bde7c8520244cdfe4a3"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc2MzA4Nw==", "bodyText": "I didn't see that. In this case \ud83d\udc4d", "url": "https://github.com/apache/beam/pull/10945#discussion_r389763087", "createdAt": "2020-03-09T15:22:58Z", "author": {"login": "mxm"}, "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkExecutionEnvironments.java", "diffHunk": "@@ -311,78 +302,4 @@ private static void applyLatencyTrackingInterval(\n     long latencyTrackingInterval = options.getLatencyTrackingInterval();\n     config.setLatencyTrackingInterval(latencyTrackingInterval);\n   }\n-\n-  /**\n-   * Remote stream environment that supports job execution with restore from savepoint.\n-   *\n-   * <p>This class can be removed once Flink provides this functionality.\n-   *\n-   * <p>TODO: https://issues.apache.org/jira/browse/BEAM-5396\n-   */\n-  private static class BeamFlinkRemoteStreamEnvironment extends RemoteStreamEnvironment {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTU3NzQyNg=="}, "originalCommit": {"oid": "82b781c3f39ffe684ca93bde7c8520244cdfe4a3"}, "originalPosition": 56}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjM4ODAzMzQyOnYy", "diffSide": "RIGHT", "path": "runners/flink/1.10/src/test/java/org/apache/beam/runners/flink/FlinkSubmissionTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yOFQwOTowNDoxMlrOFvt2Yg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0yOFQwOTowNDoxMlrOFvt2Yg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4NTU3ODU5NA==", "bodyText": "No need to copy everything because of one change package name. We can load JobStatus dynamically.", "url": "https://github.com/apache/beam/pull/10945#discussion_r385578594", "createdAt": "2020-02-28T09:04:12Z", "author": {"login": "mxm"}, "path": "runners/flink/1.10/src/test/java/org/apache/beam/runners/flink/FlinkSubmissionTest.java", "diffHunk": "@@ -0,0 +1,256 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.flink;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.is;\n+\n+import java.io.File;\n+import java.lang.reflect.Field;\n+import java.lang.reflect.Modifier;\n+import java.nio.file.Files;\n+import java.security.Permission;\n+import java.util.Collection;\n+import java.util.Map;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.beam.runners.core.construction.resources.PipelineResources;\n+import org.apache.beam.sdk.Pipeline;\n+import org.apache.beam.sdk.io.GenerateSequence;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.options.PipelineOptionsFactory;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Charsets;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Iterables;\n+import org.apache.flink.api.common.JobStatus;\n+import org.apache.flink.client.cli.CliFrontend;\n+import org.apache.flink.configuration.ConfigConstants;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.configuration.JobManagerOptions;\n+import org.apache.flink.configuration.RestOptions;\n+import org.apache.flink.runtime.client.JobStatusMessage;\n+import org.apache.flink.runtime.minicluster.MiniClusterConfiguration;\n+import org.apache.flink.runtime.minicluster.RpcServiceSharing;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+import org.junit.rules.Timeout;\n+\n+/**\n+ * End-to-end submission test of Beam jobs on a Flink cluster.\n+ *\n+ * <p>This test is copied to 1.10 is becauses the package name of JobStatus has changed in Flink\n+ * 1.10, please refer to", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "82b781c3f39ffe684ca93bde7c8520244cdfe4a3"}, "originalPosition": 61}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQxNTMxMzIwOnYy", "diffSide": "RIGHT", "path": "runners/flink/1.10/src/test/java/org/apache/beam/runners/flink/FlinkExecutionEnvironmentsTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQxNToyMDowNFrOFztIDg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQxNToyMDowNFrOFztIDg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc2MTAzOA==", "bodyText": "We could avoid duplication of this file and just have a check method which branches depending on whether we have 1.10 or a version below.", "url": "https://github.com/apache/beam/pull/10945#discussion_r389761038", "createdAt": "2020-03-09T15:20:04Z", "author": {"login": "mxm"}, "path": "runners/flink/1.10/src/test/java/org/apache/beam/runners/flink/FlinkExecutionEnvironmentsTest.java", "diffHunk": "@@ -0,0 +1,533 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.flink;\n+\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.instanceOf;\n+import static org.hamcrest.core.Is.is;\n+import static org.junit.Assert.assertEquals;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.nio.file.Files;\n+import java.util.Collections;\n+import org.apache.beam.sdk.options.PipelineOptionsFactory;\n+import org.apache.flink.api.java.ExecutionEnvironment;\n+import org.apache.flink.api.java.LocalEnvironment;\n+import org.apache.flink.api.java.RemoteEnvironment;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.configuration.RestOptions;\n+import org.apache.flink.runtime.jobgraph.SavepointConfigOptions;\n+import org.apache.flink.streaming.api.environment.LocalStreamEnvironment;\n+import org.apache.flink.streaming.api.environment.RemoteStreamEnvironment;\n+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.ExpectedException;\n+import org.junit.rules.TemporaryFolder;\n+import org.powermock.reflect.Whitebox;\n+\n+/**\n+ * Tests for {@link FlinkExecutionEnvironments}.\n+ *\n+ * <p>This test is copied to 1.10 is becauses the field host, port, etc have been removed from\n+ * RemoteEnvironment in Flink 1.10, please refer to\n+ * https://github.com/apache/flink/commit/057c036784242c674ea6091549cdbc98688827a6 for more details.\n+ */\n+public class FlinkExecutionEnvironmentsTest {\n+\n+  @Rule public TemporaryFolder temporaryFolder = new TemporaryFolder();\n+  @Rule public ExpectedException expectedException = ExpectedException.none();\n+\n+  @Test\n+  public void shouldSetParallelismBatch() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(TestFlinkRunner.class);\n+    options.setParallelism(42);\n+\n+    ExecutionEnvironment bev =\n+        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    assertThat(options.getParallelism(), is(42));\n+    assertThat(bev.getParallelism(), is(42));\n+  }\n+\n+  @Test\n+  public void shouldSetParallelismStreaming() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(TestFlinkRunner.class);\n+    options.setParallelism(42);\n+\n+    StreamExecutionEnvironment sev =\n+        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    assertThat(options.getParallelism(), is(42));\n+    assertThat(sev.getParallelism(), is(42));\n+  }\n+\n+  @Test\n+  public void shouldSetMaxParallelismStreaming() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(TestFlinkRunner.class);\n+    options.setMaxParallelism(42);\n+\n+    StreamExecutionEnvironment sev =\n+        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    assertThat(options.getMaxParallelism(), is(42));\n+    assertThat(sev.getMaxParallelism(), is(42));\n+  }\n+\n+  @Test\n+  public void shouldInferParallelismFromEnvironmentBatch() throws IOException {\n+    String flinkConfDir = extractFlinkConfig();\n+\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(TestFlinkRunner.class);\n+    options.setFlinkMaster(\"host:80\");\n+\n+    ExecutionEnvironment bev =\n+        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+            options, Collections.emptyList(), flinkConfDir);\n+\n+    assertThat(options.getParallelism(), is(23));\n+    assertThat(bev.getParallelism(), is(23));\n+  }\n+\n+  @Test\n+  public void shouldInferParallelismFromEnvironmentStreaming() throws IOException {\n+    String confDir = extractFlinkConfig();\n+\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(TestFlinkRunner.class);\n+    options.setFlinkMaster(\"host:80\");\n+\n+    StreamExecutionEnvironment sev =\n+        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n+            options, Collections.emptyList(), confDir);\n+\n+    assertThat(options.getParallelism(), is(23));\n+    assertThat(sev.getParallelism(), is(23));\n+  }\n+\n+  @Test\n+  public void shouldFallbackToDefaultParallelismBatch() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(TestFlinkRunner.class);\n+    options.setFlinkMaster(\"host:80\");\n+\n+    ExecutionEnvironment bev =\n+        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    assertThat(options.getParallelism(), is(1));\n+    assertThat(bev.getParallelism(), is(1));\n+  }\n+\n+  @Test\n+  public void shouldFallbackToDefaultParallelismStreaming() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(TestFlinkRunner.class);\n+    options.setFlinkMaster(\"host:80\");\n+\n+    StreamExecutionEnvironment sev =\n+        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    assertThat(options.getParallelism(), is(1));\n+    assertThat(sev.getParallelism(), is(1));\n+  }\n+\n+  @Test\n+  public void useDefaultParallelismFromContextBatch() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(TestFlinkRunner.class);\n+\n+    ExecutionEnvironment bev =\n+        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    assertThat(bev, instanceOf(LocalEnvironment.class));\n+    assertThat(options.getParallelism(), is(LocalStreamEnvironment.getDefaultLocalParallelism()));\n+    assertThat(bev.getParallelism(), is(LocalStreamEnvironment.getDefaultLocalParallelism()));\n+  }\n+\n+  @Test\n+  public void useDefaultParallelismFromContextStreaming() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(TestFlinkRunner.class);\n+\n+    StreamExecutionEnvironment sev =\n+        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    assertThat(sev, instanceOf(LocalStreamEnvironment.class));\n+    assertThat(options.getParallelism(), is(LocalStreamEnvironment.getDefaultLocalParallelism()));\n+    assertThat(sev.getParallelism(), is(LocalStreamEnvironment.getDefaultLocalParallelism()));\n+  }\n+\n+  @Test\n+  public void shouldParsePortForRemoteEnvironmentBatch() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+    options.setFlinkMaster(\"host:1234\");\n+\n+    ExecutionEnvironment bev =\n+        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    assertThat(bev, instanceOf(RemoteEnvironment.class));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getString(RestOptions.ADDRESS),\n+        is(\"host\"));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getInteger(RestOptions.PORT),\n+        is(1234));\n+  }\n+\n+  @Test\n+  public void shouldParsePortForRemoteEnvironmentStreaming() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+    options.setFlinkMaster(\"host:1234\");\n+\n+    StreamExecutionEnvironment sev =\n+        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    assertThat(sev, instanceOf(RemoteStreamEnvironment.class));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(sev, \"configuration\"))\n+            .getString(RestOptions.ADDRESS),\n+        is(\"host\"));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(sev, \"configuration\"))\n+            .getInteger(RestOptions.PORT),\n+        is(1234));\n+  }\n+\n+  @Test\n+  public void shouldAllowPortOmissionForRemoteEnvironmentBatch() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+    options.setFlinkMaster(\"host\");\n+\n+    ExecutionEnvironment bev =\n+        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    assertThat(bev, instanceOf(RemoteEnvironment.class));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getString(RestOptions.ADDRESS),\n+        is(\"host\"));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getInteger(RestOptions.PORT),\n+        is(RestOptions.PORT.defaultValue()));\n+  }\n+\n+  @Test\n+  public void shouldAllowPortOmissionForRemoteEnvironmentStreaming() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+    options.setFlinkMaster(\"host\");\n+\n+    StreamExecutionEnvironment sev =\n+        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    assertThat(sev, instanceOf(RemoteStreamEnvironment.class));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(sev, \"configuration\"))\n+            .getString(RestOptions.ADDRESS),\n+        is(\"host\"));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(sev, \"configuration\"))\n+            .getInteger(RestOptions.PORT),\n+        is(RestOptions.PORT.defaultValue()));\n+  }\n+\n+  @Test\n+  public void shouldTreatAutoAndEmptyHostTheSameBatch() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+\n+    ExecutionEnvironment sev =\n+        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    options.setFlinkMaster(\"[auto]\");\n+\n+    ExecutionEnvironment sev2 =\n+        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    assertEquals(sev.getClass(), sev2.getClass());\n+  }\n+\n+  @Test\n+  public void shouldTreatAutoAndEmptyHostTheSameStreaming() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+\n+    StreamExecutionEnvironment sev =\n+        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    options.setFlinkMaster(\"[auto]\");\n+\n+    StreamExecutionEnvironment sev2 =\n+        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n+            options, Collections.emptyList());\n+\n+    assertEquals(sev.getClass(), sev2.getClass());\n+  }\n+\n+  @Test\n+  public void shouldDetectMalformedPortBatch() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+    options.setFlinkMaster(\"host:p0rt\");\n+\n+    expectedException.expect(IllegalArgumentException.class);\n+    expectedException.expectMessage(\"Unparseable port number\");\n+\n+    FlinkExecutionEnvironments.createBatchExecutionEnvironment(options, Collections.emptyList());\n+  }\n+\n+  @Test\n+  public void shouldDetectMalformedPortStreaming() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+    options.setFlinkMaster(\"host:p0rt\");\n+\n+    expectedException.expect(IllegalArgumentException.class);\n+    expectedException.expectMessage(\"Unparseable port number\");\n+\n+    FlinkExecutionEnvironments.createStreamExecutionEnvironment(options, Collections.emptyList());\n+  }\n+\n+  @Test\n+  public void shouldSupportIPv4Batch() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+\n+    options.setFlinkMaster(\"192.168.1.1:1234\");\n+    ExecutionEnvironment bev =\n+        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+            options, Collections.emptyList());\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getString(RestOptions.ADDRESS),\n+        is(\"192.168.1.1\"));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getInteger(RestOptions.PORT),\n+        is(1234));\n+\n+    options.setFlinkMaster(\"192.168.1.1\");\n+    bev =\n+        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+            options, Collections.emptyList());\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getString(RestOptions.ADDRESS),\n+        is(\"192.168.1.1\"));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getInteger(RestOptions.PORT),\n+        is(RestOptions.PORT.defaultValue()));\n+  }\n+\n+  @Test\n+  public void shouldSupportIPv4Streaming() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+\n+    options.setFlinkMaster(\"192.168.1.1:1234\");\n+    ExecutionEnvironment bev =\n+        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+            options, Collections.emptyList());\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getString(RestOptions.ADDRESS),\n+        is(\"192.168.1.1\"));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getInteger(RestOptions.PORT),\n+        is(1234));\n+\n+    options.setFlinkMaster(\"192.168.1.1\");\n+    bev =\n+        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+            options, Collections.emptyList());\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getString(RestOptions.ADDRESS),\n+        is(\"192.168.1.1\"));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getInteger(RestOptions.PORT),\n+        is(RestOptions.PORT.defaultValue()));\n+  }\n+\n+  @Test\n+  public void shouldSupportIPv6Batch() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+\n+    options.setFlinkMaster(\"[FE80:CD00:0000:0CDE:1257:0000:211E:729C]:1234\");\n+    ExecutionEnvironment bev =\n+        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+            options, Collections.emptyList());\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getString(RestOptions.ADDRESS),\n+        is(\"fe80:cd00:0:cde:1257:0:211e:729c\"));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getInteger(RestOptions.PORT),\n+        is(1234));\n+\n+    options.setFlinkMaster(\"FE80:CD00:0000:0CDE:1257:0000:211E:729C\");\n+    bev =\n+        FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+            options, Collections.emptyList());\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getString(RestOptions.ADDRESS),\n+        is(\"fe80:cd00:0:cde:1257:0:211e:729c\"));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(bev, \"configuration\"))\n+            .getInteger(RestOptions.PORT),\n+        is(RestOptions.PORT.defaultValue()));\n+  }\n+\n+  @Test\n+  public void shouldSupportIPv6Streaming() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+\n+    options.setFlinkMaster(\"[FE80:CD00:0000:0CDE:1257:0000:211E:729C]:1234\");\n+    StreamExecutionEnvironment sev =\n+        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n+            options, Collections.emptyList());\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(sev, \"configuration\"))\n+            .getString(RestOptions.ADDRESS),\n+        is(\"fe80:cd00:0:cde:1257:0:211e:729c\"));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(sev, \"configuration\"))\n+            .getInteger(RestOptions.PORT),\n+        is(1234));\n+\n+    options.setFlinkMaster(\"FE80:CD00:0000:0CDE:1257:0000:211E:729C\");\n+    sev =\n+        FlinkExecutionEnvironments.createStreamExecutionEnvironment(\n+            options, Collections.emptyList());\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(sev, \"configuration\"))\n+            .getString(RestOptions.ADDRESS),\n+        is(\"fe80:cd00:0:cde:1257:0:211e:729c\"));\n+    assertThat(\n+        ((Configuration) Whitebox.getInternalState(sev, \"configuration\"))\n+            .getInteger(RestOptions.PORT),\n+        is(RestOptions.PORT.defaultValue()));\n+  }\n+\n+  @Test\n+  public void shouldRemoveHttpProtocolFromHostBatch() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(FlinkRunner.class);\n+\n+    for (String flinkMaster :\n+        new String[] {\n+          \"http://host:1234\", \" http://host:1234\", \"https://host:1234\", \" https://host:1234\"\n+        }) {\n+      options.setFlinkMaster(flinkMaster);\n+      ExecutionEnvironment sev =\n+          FlinkExecutionEnvironments.createBatchExecutionEnvironment(\n+              options, Collections.emptyList());\n+      assertThat(\n+          ((Configuration) Whitebox.getInternalState(sev, \"configuration\"))\n+              .getString(RestOptions.ADDRESS),\n+          is(\"host\"));\n+      assertThat(\n+          ((Configuration) Whitebox.getInternalState(sev, \"configuration\"))\n+              .getInteger(RestOptions.PORT),\n+          is(1234));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d87a6db4e71b753693058ac8010c04b8f78ab2e"}, "originalPosition": 480}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQxNTMxNzU3OnYy", "diffSide": "RIGHT", "path": "runners/flink/1.10/src/test/java/org/apache/beam/runners/flink/FlinkPipelineExecutionEnvironmentTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQxNToyMDo1OVrOFztKtQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQxNToyMDo1OVrOFztKtQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTc2MTcxNw==", "bodyText": "We could avoid duplicating this file if we had a Flink 1.10 dependent branching here.", "url": "https://github.com/apache/beam/pull/10945#discussion_r389761717", "createdAt": "2020-03-09T15:20:59Z", "author": {"login": "mxm"}, "path": "runners/flink/1.10/src/test/java/org/apache/beam/runners/flink/FlinkPipelineExecutionEnvironmentTest.java", "diffHunk": "@@ -0,0 +1,441 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.flink;\n+\n+import static org.apache.beam.sdk.testing.RegexMatcher.matches;\n+import static org.hamcrest.CoreMatchers.containsString;\n+import static org.hamcrest.CoreMatchers.instanceOf;\n+import static org.hamcrest.CoreMatchers.is;\n+import static org.hamcrest.CoreMatchers.not;\n+import static org.hamcrest.CoreMatchers.startsWith;\n+import static org.hamcrest.MatcherAssert.assertThat;\n+import static org.hamcrest.Matchers.hasItem;\n+import static org.hamcrest.core.Every.everyItem;\n+import static org.junit.Assert.assertThrows;\n+import static org.junit.Assert.fail;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.File;\n+import java.io.IOException;\n+import java.io.PrintStream;\n+import java.io.Serializable;\n+import java.net.MalformedURLException;\n+import java.net.URL;\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import org.apache.beam.runners.core.construction.PTransformMatchers;\n+import org.apache.beam.runners.core.construction.PTransformTranslation;\n+import org.apache.beam.runners.core.construction.resources.PipelineResources;\n+import org.apache.beam.sdk.Pipeline;\n+import org.apache.beam.sdk.io.GenerateSequence;\n+import org.apache.beam.sdk.io.TextIO;\n+import org.apache.beam.sdk.options.PipelineOptionsFactory;\n+import org.apache.beam.sdk.runners.PTransformOverride;\n+import org.apache.beam.sdk.runners.PTransformOverrideFactory;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.windowing.FixedWindows;\n+import org.apache.beam.sdk.transforms.windowing.Window;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Charsets;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.flink.api.java.ExecutionEnvironment;\n+import org.apache.flink.api.java.RemoteEnvironment;\n+import org.apache.flink.client.cli.ExecutionConfigAccessor;\n+import org.apache.flink.configuration.Configuration;\n+import org.apache.flink.streaming.api.environment.RemoteStreamEnvironment;\n+import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;\n+import org.hamcrest.BaseMatcher;\n+import org.hamcrest.Description;\n+import org.hamcrest.Matchers;\n+import org.joda.time.Duration;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.JUnit4;\n+import org.mockito.ArgumentCaptor;\n+import org.mockito.Mockito;\n+import org.powermock.reflect.Whitebox;\n+\n+/**\n+ * Tests for {@link FlinkPipelineExecutionEnvironment}.\n+ *\n+ * <p>This test is copied to 1.10 is becauses the field jarFiles has been removed from\n+ * RemoteEnvironment in Flink 1.10, please refer to\n+ * https://github.com/apache/flink/commit/057c036784242c674ea6091549cdbc98688827a6 for more details.\n+ */\n+@RunWith(JUnit4.class)\n+public class FlinkPipelineExecutionEnvironmentTest implements Serializable {\n+\n+  @Rule public transient TemporaryFolder tmpFolder = new TemporaryFolder();\n+\n+  @Test\n+  public void shouldRecognizeAndTranslateStreamingPipeline() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(TestFlinkRunner.class);\n+    options.setFlinkMaster(\"[auto]\");\n+\n+    FlinkPipelineExecutionEnvironment flinkEnv = new FlinkPipelineExecutionEnvironment(options);\n+    Pipeline pipeline = Pipeline.create();\n+\n+    pipeline\n+        .apply(GenerateSequence.from(0).withRate(1, Duration.standardSeconds(1)))\n+        .apply(\n+            ParDo.of(\n+                new DoFn<Long, String>() {\n+\n+                  @ProcessElement\n+                  public void processElement(ProcessContext c) throws Exception {\n+                    c.output(Long.toString(c.element()));\n+                  }\n+                }))\n+        .apply(Window.into(FixedWindows.of(Duration.standardHours(1))))\n+        .apply(TextIO.write().withNumShards(1).withWindowedWrites().to(\"/dummy/path\"));\n+\n+    flinkEnv.translate(pipeline);\n+\n+    // no exception should be thrown\n+  }\n+\n+  @Test\n+  public void shouldPrepareFilesToStageWhenFlinkMasterIsSetExplicitly() throws IOException {\n+    FlinkPipelineOptions options = testPreparingResourcesToStage(\"localhost:8081\", true, false);\n+\n+    assertThat(options.getFilesToStage().size(), is(2));\n+    assertThat(options.getFilesToStage().get(0), matches(\".*\\\\.jar\"));\n+  }\n+\n+  @Test\n+  public void shouldFailWhenFileDoesNotExistAndFlinkMasterIsSetExplicitly() {\n+    assertThrows(\n+        \"To-be-staged file does not exist: \",\n+        IllegalStateException.class,\n+        () -> testPreparingResourcesToStage(\"localhost:8081\", true, true));\n+  }\n+\n+  @Test\n+  public void shouldNotPrepareFilesToStageWhenFlinkMasterIsSetToAuto() throws IOException {\n+    FlinkPipelineOptions options = testPreparingResourcesToStage(\"[auto]\");\n+\n+    assertThat(options.getFilesToStage().size(), is(2));\n+    assertThat(options.getFilesToStage(), everyItem(not(matches(\".*\\\\.jar\"))));\n+  }\n+\n+  @Test\n+  public void shouldNotPrepareFilesToStagewhenFlinkMasterIsSetToCollection() throws IOException {\n+    FlinkPipelineOptions options = testPreparingResourcesToStage(\"[collection]\");\n+\n+    assertThat(options.getFilesToStage().size(), is(2));\n+    assertThat(options.getFilesToStage(), everyItem(not(matches(\".*\\\\.jar\"))));\n+  }\n+\n+  @Test\n+  public void shouldNotPrepareFilesToStageWhenFlinkMasterIsSetToLocal() throws IOException {\n+    FlinkPipelineOptions options = testPreparingResourcesToStage(\"[local]\");\n+\n+    assertThat(options.getFilesToStage().size(), is(2));\n+    assertThat(options.getFilesToStage(), everyItem(not(matches(\".*\\\\.jar\"))));\n+  }\n+\n+  @Test\n+  public void shouldUseDefaultTempLocationIfNoneSet() {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(TestFlinkRunner.class);\n+    options.setFlinkMaster(\"clusterAddress\");\n+\n+    FlinkPipelineExecutionEnvironment flinkEnv = new FlinkPipelineExecutionEnvironment(options);\n+\n+    Pipeline pipeline = Pipeline.create(options);\n+    flinkEnv.translate(pipeline);\n+\n+    String defaultTmpDir = System.getProperty(\"java.io.tmpdir\");\n+\n+    assertThat(options.getFilesToStage(), hasItem(startsWith(defaultTmpDir)));\n+  }\n+\n+  @Test\n+  public void shouldUsePreparedFilesOnRemoteEnvironment() throws Exception {\n+    FlinkPipelineOptions options = PipelineOptionsFactory.as(FlinkPipelineOptions.class);\n+    options.setRunner(TestFlinkRunner.class);\n+    options.setFlinkMaster(\"clusterAddress\");\n+\n+    FlinkPipelineExecutionEnvironment flinkEnv = new FlinkPipelineExecutionEnvironment(options);\n+\n+    Pipeline pipeline = Pipeline.create(options);\n+    flinkEnv.translate(pipeline);\n+\n+    ExecutionEnvironment executionEnvironment = flinkEnv.getBatchExecutionEnvironment();\n+    assertThat(executionEnvironment, instanceOf(RemoteEnvironment.class));\n+\n+    ExecutionConfigAccessor accesor =\n+        ExecutionConfigAccessor.fromConfiguration(\n+            (Configuration) Whitebox.getInternalState(executionEnvironment, \"configuration\"));\n+    List<URL> jarFiles = accesor.getJars();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d87a6db4e71b753693058ac8010c04b8f78ab2e"}, "originalPosition": 190}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQxODM3NTE5OnYy", "diffSide": "RIGHT", "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkExecutionEnvironments.java", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQxMTowNjoyM1rOF0KWow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQxNzowMDoxM1rOF1AMYg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDIzOTkwNw==", "bodyText": "I have the feeling this won't be reliable enough. Why not instead taskmanager.memory.managed.fraction?", "url": "https://github.com/apache/beam/pull/10945#discussion_r390239907", "createdAt": "2020-03-10T11:06:23Z", "author": {"login": "mxm"}, "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkExecutionEnvironments.java", "diffHunk": "@@ -77,6 +67,7 @@ static ExecutionEnvironment createBatchExecutionEnvironment(\n \n     // depending on the master, create the right environment.\n     if (\"[local]\".equals(flinkMasterHostPort)) {\n+      flinkConfiguration.setString(\"taskmanager.memory.managed.size\", \"2048m\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f513ad3ba814fb4ef9f52bbf935d5cdc11f96ff"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDI4NzYwNQ==", "bodyText": "It will set the taskmanager.memory.managed.size as 128MB for MiniCluster if it's not set. I think set taskmanager.memory.managed.fraction\" doesn't take effect here. Thoughts? :)", "url": "https://github.com/apache/beam/pull/10945#discussion_r390287605", "createdAt": "2020-03-10T12:47:27Z", "author": {"login": "sunjincheng121"}, "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkExecutionEnvironments.java", "diffHunk": "@@ -77,6 +67,7 @@ static ExecutionEnvironment createBatchExecutionEnvironment(\n \n     // depending on the master, create the right environment.\n     if (\"[local]\".equals(flinkMasterHostPort)) {\n+      flinkConfiguration.setString(\"taskmanager.memory.managed.size\", \"2048m\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDIzOTkwNw=="}, "originalCommit": {"oid": "1f513ad3ba814fb4ef9f52bbf935d5cdc11f96ff"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDMyODYwNg==", "bodyText": "I'm hesitant with this default because it will always pre-allocate 2GB of memory which won't be used most of the time, except for the one large record test case you mentioned.\nWe could set I'd go for something like https://github.com/apache/flink/blob/42a56f4c75693773e21fa2dea45df640c2d7f9da/flink-runtime/src/main/java/org/apache/flink/runtime/clusterframework/TaskExecutorProcessUtils.java#L287 based on the memory available.\nActually, that is what the Flink 1.8 code used to do: https://github.com/apache/flink/blob/60d9b96456f142f8d18d5882016840a00159403e/flink-runtime/src/main/java/org/apache/flink/runtime/taskexecutor/TaskManagerServices.java#L296\nSo let's just check the free memory and use a fraction for memory managed memory by default. What do you think?", "url": "https://github.com/apache/beam/pull/10945#discussion_r390328606", "createdAt": "2020-03-10T13:53:55Z", "author": {"login": "mxm"}, "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkExecutionEnvironments.java", "diffHunk": "@@ -77,6 +67,7 @@ static ExecutionEnvironment createBatchExecutionEnvironment(\n \n     // depending on the master, create the right environment.\n     if (\"[local]\".equals(flinkMasterHostPort)) {\n+      flinkConfiguration.setString(\"taskmanager.memory.managed.size\", \"2048m\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDIzOTkwNw=="}, "originalCommit": {"oid": "1f513ad3ba814fb4ef9f52bbf935d5cdc11f96ff"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDc0NzUxMQ==", "bodyText": "Thanks @mxm, Sounds good to me ;)", "url": "https://github.com/apache/beam/pull/10945#discussion_r390747511", "createdAt": "2020-03-11T05:03:15Z", "author": {"login": "sunjincheng121"}, "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkExecutionEnvironments.java", "diffHunk": "@@ -77,6 +67,7 @@ static ExecutionEnvironment createBatchExecutionEnvironment(\n \n     // depending on the master, create the right environment.\n     if (\"[local]\".equals(flinkMasterHostPort)) {\n+      flinkConfiguration.setString(\"taskmanager.memory.managed.size\", \"2048m\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDIzOTkwNw=="}, "originalCommit": {"oid": "1f513ad3ba814fb4ef9f52bbf935d5cdc11f96ff"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTEyMjAxOA==", "bodyText": "Cool, thanks for the changes.", "url": "https://github.com/apache/beam/pull/10945#discussion_r391122018", "createdAt": "2020-03-11T17:00:13Z", "author": {"login": "mxm"}, "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkExecutionEnvironments.java", "diffHunk": "@@ -77,6 +67,7 @@ static ExecutionEnvironment createBatchExecutionEnvironment(\n \n     // depending on the master, create the right environment.\n     if (\"[local]\".equals(flinkMasterHostPort)) {\n+      flinkConfiguration.setString(\"taskmanager.memory.managed.size\", \"2048m\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDIzOTkwNw=="}, "originalCommit": {"oid": "1f513ad3ba814fb4ef9f52bbf935d5cdc11f96ff"}, "originalPosition": 40}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQxODM3OTczOnYy", "diffSide": "RIGHT", "path": "runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkExecutionEnvironmentsTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQxMTowNzo1OFrOF0KZZg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQxMTowNzo1OFrOF0KZZg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDI0MDYxNA==", "bodyText": "We shouldn't be catching throwable here.\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                } catch (Throwable t) {\n          \n          \n            \n                } catch (FieldNotFoundException e) {", "url": "https://github.com/apache/beam/pull/10945#discussion_r390240614", "createdAt": "2020-03-10T11:07:58Z", "author": {"login": "mxm"}, "path": "runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkExecutionEnvironmentsTest.java", "diffHunk": "@@ -438,8 +424,34 @@ public void shouldSetSavepointRestoreForRemoteStreaming() {\n             options, Collections.emptyList());\n     // subject to change with https://issues.apache.org/jira/browse/FLINK-11048\n     assertThat(sev, instanceOf(RemoteStreamEnvironment.class));\n-    assertThat(\n-        Whitebox.getInternalState(sev, \"restoreSettings\"),\n-        is(SavepointRestoreSettings.forPath(path)));\n+    assertThat(getSavepointPath(sev), is(path));\n+  }\n+\n+  private void checkHostAndPort(Object env, String expectedHost, int expectedPort) {\n+    try {\n+      assertThat(Whitebox.getInternalState(env, \"host\"), is(expectedHost));\n+      assertThat(Whitebox.getInternalState(env, \"port\"), is(expectedPort));\n+    } catch (Throwable t) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f513ad3ba814fb4ef9f52bbf935d5cdc11f96ff"}, "originalPosition": 167}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQxODM4MDQ5OnYy", "diffSide": "RIGHT", "path": "runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkExecutionEnvironmentsTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQxMTowODoxMlrOF0KZ1Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQxMTowODoxMlrOF0KZ1Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDI0MDcyNQ==", "bodyText": "We shouldn't be catching throwable here.\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                } catch (Throwable t) {\n          \n          \n            \n                } catch (FieldNotFoundException e) {", "url": "https://github.com/apache/beam/pull/10945#discussion_r390240725", "createdAt": "2020-03-10T11:08:12Z", "author": {"login": "mxm"}, "path": "runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkExecutionEnvironmentsTest.java", "diffHunk": "@@ -438,8 +424,34 @@ public void shouldSetSavepointRestoreForRemoteStreaming() {\n             options, Collections.emptyList());\n     // subject to change with https://issues.apache.org/jira/browse/FLINK-11048\n     assertThat(sev, instanceOf(RemoteStreamEnvironment.class));\n-    assertThat(\n-        Whitebox.getInternalState(sev, \"restoreSettings\"),\n-        is(SavepointRestoreSettings.forPath(path)));\n+    assertThat(getSavepointPath(sev), is(path));\n+  }\n+\n+  private void checkHostAndPort(Object env, String expectedHost, int expectedPort) {\n+    try {\n+      assertThat(Whitebox.getInternalState(env, \"host\"), is(expectedHost));\n+      assertThat(Whitebox.getInternalState(env, \"port\"), is(expectedPort));\n+    } catch (Throwable t) {\n+      // for flink 1.10+\n+      String host =\n+          ((Configuration) Whitebox.getInternalState(env, \"configuration\"))\n+              .getString(RestOptions.ADDRESS);\n+      int port =\n+          ((Configuration) Whitebox.getInternalState(env, \"configuration\"))\n+              .getInteger(RestOptions.PORT);\n+      assertThat(\n+          new InetSocketAddress(host, port), is(new InetSocketAddress(expectedHost, expectedPort)));\n+    }\n+  }\n+\n+  private String getSavepointPath(Object env) {\n+    try {\n+      return ((SavepointRestoreSettings) Whitebox.getInternalState(env, \"restoreSettings\"))\n+          .getRestorePath();\n+    } catch (Throwable t) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f513ad3ba814fb4ef9f52bbf935d5cdc11f96ff"}, "originalPosition": 184}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQxODM4MzQ1OnYy", "diffSide": "RIGHT", "path": "runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkPipelineExecutionEnvironmentTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQxMTowOToxMFrOF0KbpA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQxMTowOToxMFrOF0KbpA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDI0MTE4OA==", "bodyText": "We shouldn't be catching throwable here.\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                } catch (Throwable t) {\n          \n          \n            \n                } catch (FieldNotFoundException e) {", "url": "https://github.com/apache/beam/pull/10945#discussion_r390241188", "createdAt": "2020-03-10T11:09:10Z", "author": {"login": "mxm"}, "path": "runners/flink/src/test/java/org/apache/beam/runners/flink/FlinkPipelineExecutionEnvironmentTest.java", "diffHunk": "@@ -418,4 +426,20 @@ private FlinkPipelineOptions setPipelineOptions(\n             })\n         .collect(Collectors.toList());\n   }\n+\n+  private List<URL> getJars(Object env) throws Exception {\n+    try {\n+      return (List<URL>) Whitebox.getInternalState(env, \"jarFiles\");\n+    } catch (Throwable t) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1f513ad3ba814fb4ef9f52bbf935d5cdc11f96ff"}, "originalPosition": 133}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1890, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}