{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg1NDYyODE0", "number": 11075, "title": "[BEAM-9421] Website section that describes getting predictions using AI Platform Prediciton", "bodyText": "Thank you for your contribution! Follow this checklist to help us incorporate your contribution quickly and easily:\n\n Choose reviewer(s) and mention them in a comment (R: @username).\n Format the pull request title like [BEAM-XXX] Fixes bug in ApproximateQuantiles, where you replace BEAM-XXX with the appropriate JIRA issue, if applicable. This will automatically link the pull request to the issue.\n Update CHANGES.md with noteworthy changes.\n If this contribution is large, please file an Apache Individual Contributor License Agreement.\n\nSee the Contributor Guide for more tips on how to make review process smoother.\nPost-Commit Tests Status (on master branch)\n\n\n\nLang\nSDK\nApex\nDataflow\nFlink\nGearpump\nSamza\nSpark\n\n\n\n\nGo\n\n---\n---\n\n---\n---\n\n\n\nJava\n\n\n\n\n\n\n\n\n\nPython\n\n---\n\n\n---\n---\n\n\n\nXLang\n---\n---\n---\n\n---\n---\n\n\n\n\nPre-Commit Tests Status (on master branch)\n\n\n\n---\nJava\nPython\nGo\nWebsite\n\n\n\n\nNon-portable\n\n\n\n\n\n\nPortable\n---\n\n---\n---\n\n\n\nSee .test-infra/jenkins/README for trigger phrase, status and link of all Jenkins jobs.", "createdAt": "2020-03-09T09:04:36Z", "url": "https://github.com/apache/beam/pull/11075", "merged": true, "mergeCommit": {"oid": "e9837feb508db7c2a2c1b2d1c8da1135caca3ecb"}, "closed": true, "closedAt": "2020-06-01T09:56:03Z", "author": {"login": "kamilwu"}, "timelineItems": {"totalCount": 23, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcMp__1gFqTM3Mjk0MTQ5NA==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcm8zUrABqjMzOTIyNzkyOTU=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzcyOTQxNDk0", "url": "https://github.com/apache/beam/pull/11075#pullrequestreview-372941494", "createdAt": "2020-03-11T16:48:24Z", "commit": {"oid": "ddfb70210752480f4f38282f888be12489c3b588"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQxNjo0ODoyNFrOF0_tHg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQxNjo0ODoyNFrOF0_tHg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTExNDAxNA==", "bodyText": "We can create tracking Jira for this and add reference.", "url": "https://github.com/apache/beam/pull/11075#discussion_r391114014", "createdAt": "2020-03-11T16:48:24Z", "author": {"login": "Ardagan"}, "path": "website/src/documentation/patterns/ai-platform.md", "diffHunk": "@@ -0,0 +1,87 @@\n+---\n+layout: section\n+title: \"AI Platform integration patterns\"\n+section_menu: section-menu/documentation.html\n+permalink: /documentation/patterns/ai-platform/\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+# AI Platform integration patterns\n+\n+This page describes common patterns in pipelines with Google AI Platform transforms.\n+\n+<nav class=\"language-switcher\">\n+  <strong>Adapt for:</strong>\n+  <ul>\n+    <li data-type=\"language-java\">Java SDK</li>\n+    <li data-type=\"language-py\" class=\"active\">Python SDK</li>\n+  </ul>\n+</nav>\n+\n+## Getting predictions\n+\n+This section shows how to use your cloud-hosted machine learning model to make predictions about new data using Google Cloud AI Platform Prediction within Beam's pipeline.\n+ \n+We are going to use [tfx_bsl](https://github.com/tensorflow/tfx-bsl) library which provides `RunInference` Beam's PTransform. `RunInference` is a PTransform able to perform two types of inference. In this section we are going to consider one of them that uses a service endpoint. When using a service endpoint, the transform takes a PCollection of type `tf.train.Example` and, for each element, sends a request to Google Cloud AI Platform Prediction service. The transform produces a PCollection of type `PredictLog` which contains predictions.\n+\n+Before we get started, we have to deploy a machine learning model to the cloud. The cloud service manages the infrastructure needed to handle prediction requests in both efficient and scalable way. Only Tensorflow models are supported. For more information, see [Exporting a SavedModel for prediction](https://cloud.google.com/ai-platform/prediction/docs/exporting-savedmodel-for-prediction).\n+\n+Let's show an example of a pipeline that reads input instances from the file, converts JSON objects to `tf.train.Example` objects and sends data to the service. The content of a file can look like this:\n+\n+```\n+{\"input\": \"the quick brown\"}\n+{\"input\": \"la bruja le\"}\n+``` \n+\n+Here is the code:\n+\n+{:.language-java}\n+```java\n+// Getting predictions is not available for Java.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ddfb70210752480f4f38282f888be12489c3b588"}, "originalPosition": 52}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzczMDE1MDM0", "url": "https://github.com/apache/beam/pull/11075#pullrequestreview-373015034", "createdAt": "2020-03-11T18:21:29Z", "commit": {"oid": "ddfb70210752480f4f38282f888be12489c3b588"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzczMTg0MjMw", "url": "https://github.com/apache/beam/pull/11075#pullrequestreview-373184230", "createdAt": "2020-03-11T23:04:28Z", "commit": {"oid": "ddfb70210752480f4f38282f888be12489c3b588"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc0NjkwNDU3", "url": "https://github.com/apache/beam/pull/11075#pullrequestreview-374690457", "createdAt": "2020-03-14T02:25:22Z", "commit": {"oid": "a3b1bb3c731e814be1c9314f0ef872a7bfae78c9"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNFQwMjoyNToyMlrOF2XQxQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xNFQwMjo0Njo0NVrOF2XWSQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjU0ODU0OQ==", "bodyText": "\"one of them can use a service endpoint\", just out of curiosity, what is the other type of inference", "url": "https://github.com/apache/beam/pull/11075#discussion_r392548549", "createdAt": "2020-03-14T02:25:22Z", "author": {"login": "wenchenglu"}, "path": "website/src/documentation/patterns/ai-platform.md", "diffHunk": "@@ -0,0 +1,87 @@\n+---\n+layout: section\n+title: \"AI Platform integration patterns\"\n+section_menu: section-menu/documentation.html\n+permalink: /documentation/patterns/ai-platform/\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+# AI Platform integration patterns\n+\n+This page describes common patterns in pipelines with Google AI Platform transforms.\n+\n+<nav class=\"language-switcher\">\n+  <strong>Adapt for:</strong>\n+  <ul>\n+    <li data-type=\"language-java\">Java SDK</li>\n+    <li data-type=\"language-py\" class=\"active\">Python SDK</li>\n+  </ul>\n+</nav>\n+\n+## Getting predictions\n+\n+This section shows how to use a cloud-hosted machine learning model to make predictions about new data using Google Cloud AI Platform Prediction within Beam's pipeline.\n+ \n+[tfx_bsl](https://github.com/tensorflow/tfx-bsl) is a library that provides `RunInference` Beam's PTransform. `RunInference` is a PTransform able to perform two types of inference. One of them can use a service endpoint. When using a service endpoint, the transform takes a PCollection of type `tf.train.Example` and, for each element, sends a request to Google Cloud AI Platform Prediction service. The transform produces a PCollection of type `PredictLog` which contains predictions.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3b1bb3c731e814be1c9314f0ef872a7bfae78c9"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjU0OTA5Nw==", "bodyText": "Does that mean users will need to separately deploy a model first? will it be a better user experience if some initial setup stage for Beam can call AI Platform prediction public API to deploy model and get the service endpoint?\nAlso, for batch inference scenario, model deployment is a one-off job, users then need to un-deploy models to avoid unnecessary charges. Should they do that separately, or is there a BEAM final stage we could plug in a API call to delete that model deployment?", "url": "https://github.com/apache/beam/pull/11075#discussion_r392549097", "createdAt": "2020-03-14T02:33:46Z", "author": {"login": "wenchenglu"}, "path": "website/src/documentation/patterns/ai-platform.md", "diffHunk": "@@ -0,0 +1,87 @@\n+---\n+layout: section\n+title: \"AI Platform integration patterns\"\n+section_menu: section-menu/documentation.html\n+permalink: /documentation/patterns/ai-platform/\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+# AI Platform integration patterns\n+\n+This page describes common patterns in pipelines with Google AI Platform transforms.\n+\n+<nav class=\"language-switcher\">\n+  <strong>Adapt for:</strong>\n+  <ul>\n+    <li data-type=\"language-java\">Java SDK</li>\n+    <li data-type=\"language-py\" class=\"active\">Python SDK</li>\n+  </ul>\n+</nav>\n+\n+## Getting predictions\n+\n+This section shows how to use a cloud-hosted machine learning model to make predictions about new data using Google Cloud AI Platform Prediction within Beam's pipeline.\n+ \n+[tfx_bsl](https://github.com/tensorflow/tfx-bsl) is a library that provides `RunInference` Beam's PTransform. `RunInference` is a PTransform able to perform two types of inference. One of them can use a service endpoint. When using a service endpoint, the transform takes a PCollection of type `tf.train.Example` and, for each element, sends a request to Google Cloud AI Platform Prediction service. The transform produces a PCollection of type `PredictLog` which contains predictions.\n+\n+Before getting started, deploy a machine learning model to the cloud. The cloud service manages the infrastructure needed to handle prediction requests in both efficient and scalable way. Only Tensorflow models are supported. For more information, see [Exporting a SavedModel for prediction](https://cloud.google.com/ai-platform/prediction/docs/exporting-savedmodel-for-prediction).", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3b1bb3c731e814be1c9314f0ef872a7bfae78c9"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjU0OTM4Mw==", "bodyText": "is this a single inference input item? or a set of items? FYI, I think AI Platform Prediction supports both. For the latter one, a single HTTP request will embed multiple input items, which might provide better throughput once AI Platform Prediction enables batching mode in their model server.", "url": "https://github.com/apache/beam/pull/11075#discussion_r392549383", "createdAt": "2020-03-14T02:38:19Z", "author": {"login": "wenchenglu"}, "path": "website/src/documentation/patterns/ai-platform.md", "diffHunk": "@@ -0,0 +1,87 @@\n+---\n+layout: section\n+title: \"AI Platform integration patterns\"\n+section_menu: section-menu/documentation.html\n+permalink: /documentation/patterns/ai-platform/\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+# AI Platform integration patterns\n+\n+This page describes common patterns in pipelines with Google AI Platform transforms.\n+\n+<nav class=\"language-switcher\">\n+  <strong>Adapt for:</strong>\n+  <ul>\n+    <li data-type=\"language-java\">Java SDK</li>\n+    <li data-type=\"language-py\" class=\"active\">Python SDK</li>\n+  </ul>\n+</nav>\n+\n+## Getting predictions\n+\n+This section shows how to use a cloud-hosted machine learning model to make predictions about new data using Google Cloud AI Platform Prediction within Beam's pipeline.\n+ \n+[tfx_bsl](https://github.com/tensorflow/tfx-bsl) is a library that provides `RunInference` Beam's PTransform. `RunInference` is a PTransform able to perform two types of inference. One of them can use a service endpoint. When using a service endpoint, the transform takes a PCollection of type `tf.train.Example` and, for each element, sends a request to Google Cloud AI Platform Prediction service. The transform produces a PCollection of type `PredictLog` which contains predictions.\n+\n+Before getting started, deploy a machine learning model to the cloud. The cloud service manages the infrastructure needed to handle prediction requests in both efficient and scalable way. Only Tensorflow models are supported. For more information, see [Exporting a SavedModel for prediction](https://cloud.google.com/ai-platform/prediction/docs/exporting-savedmodel-for-prediction).\n+\n+Once a machine learning model is deployed, prepare a list of instances to get predictions for. \n+\n+Here is an example of a pipeline that reads input instances from the file, converts JSON objects to `tf.train.Example` objects and sends data to the service. The content of a file can look like this:\n+\n+```\n+{\"input\": \"the quick brown\"}\n+{\"input\": \"la bruja le\"}\n+``` \n+\n+The example creates `tf.train.BytesList` instances, thus it expects byte-like strings as input, but other data types, like `tf.train.FloatList` and `tf.train.Int64List`, are also supported by the transform. To send binary data, make sure that the name of an input ends in `_bytes`.\n+\n+Here is the code:\n+\n+{:.language-java}\n+```java\n+// Getting predictions is not yet available for Java. [BEAM-9501]\n+```\n+\n+{:.language-py}\n+```py\n+import json\n+\n+import apache_beam as beam\n+\n+import tensorflow as tf\n+from tfx_bsl.beam.run_inference import RunInference\n+from tfx_bsl.proto import model_spec_pb2\n+\n+def convert_json_to_tf_example(json_obj):\n+  dict_ = json.loads(json_obj)\n+  for name, text in dict_.items():\n+      value = tf.train.Feature(bytes_list=tf.train.BytesList(\n+        value=[text.encode('utf-8')]))\n+      feature = {name: value}\n+      return tf.train.Example(features=tf.train.Features(feature=feature))\n+\n+with beam.Pipeline() as p:\n+     _ = (p\n+         | beam.io.ReadFromText('gs://my-bucket/samples.json')", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3b1bb3c731e814be1c9314f0ef872a7bfae78c9"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjU0OTk2MQ==", "bodyText": "Is RunInference a HTTP call? is there a plan to support gRPC in the future?", "url": "https://github.com/apache/beam/pull/11075#discussion_r392549961", "createdAt": "2020-03-14T02:46:45Z", "author": {"login": "wenchenglu"}, "path": "website/src/documentation/patterns/ai-platform.md", "diffHunk": "@@ -0,0 +1,87 @@\n+---\n+layout: section\n+title: \"AI Platform integration patterns\"\n+section_menu: section-menu/documentation.html\n+permalink: /documentation/patterns/ai-platform/\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+# AI Platform integration patterns\n+\n+This page describes common patterns in pipelines with Google AI Platform transforms.\n+\n+<nav class=\"language-switcher\">\n+  <strong>Adapt for:</strong>\n+  <ul>\n+    <li data-type=\"language-java\">Java SDK</li>\n+    <li data-type=\"language-py\" class=\"active\">Python SDK</li>\n+  </ul>\n+</nav>\n+\n+## Getting predictions\n+\n+This section shows how to use a cloud-hosted machine learning model to make predictions about new data using Google Cloud AI Platform Prediction within Beam's pipeline.\n+ \n+[tfx_bsl](https://github.com/tensorflow/tfx-bsl) is a library that provides `RunInference` Beam's PTransform. `RunInference` is a PTransform able to perform two types of inference. One of them can use a service endpoint. When using a service endpoint, the transform takes a PCollection of type `tf.train.Example` and, for each element, sends a request to Google Cloud AI Platform Prediction service. The transform produces a PCollection of type `PredictLog` which contains predictions.\n+\n+Before getting started, deploy a machine learning model to the cloud. The cloud service manages the infrastructure needed to handle prediction requests in both efficient and scalable way. Only Tensorflow models are supported. For more information, see [Exporting a SavedModel for prediction](https://cloud.google.com/ai-platform/prediction/docs/exporting-savedmodel-for-prediction).\n+\n+Once a machine learning model is deployed, prepare a list of instances to get predictions for. \n+\n+Here is an example of a pipeline that reads input instances from the file, converts JSON objects to `tf.train.Example` objects and sends data to the service. The content of a file can look like this:\n+\n+```\n+{\"input\": \"the quick brown\"}\n+{\"input\": \"la bruja le\"}\n+``` \n+\n+The example creates `tf.train.BytesList` instances, thus it expects byte-like strings as input, but other data types, like `tf.train.FloatList` and `tf.train.Int64List`, are also supported by the transform. To send binary data, make sure that the name of an input ends in `_bytes`.\n+\n+Here is the code:\n+\n+{:.language-java}\n+```java\n+// Getting predictions is not yet available for Java. [BEAM-9501]\n+```\n+\n+{:.language-py}\n+```py\n+import json\n+\n+import apache_beam as beam\n+\n+import tensorflow as tf\n+from tfx_bsl.beam.run_inference import RunInference\n+from tfx_bsl.proto import model_spec_pb2\n+\n+def convert_json_to_tf_example(json_obj):\n+  dict_ = json.loads(json_obj)\n+  for name, text in dict_.items():\n+      value = tf.train.Feature(bytes_list=tf.train.BytesList(\n+        value=[text.encode('utf-8')]))\n+      feature = {name: value}\n+      return tf.train.Example(features=tf.train.Features(feature=feature))\n+\n+with beam.Pipeline() as p:\n+     _ = (p\n+         | beam.io.ReadFromText('gs://my-bucket/samples.json')\n+         | beam.Map(convert_json_to_tf_example)\n+         | RunInference(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3b1bb3c731e814be1c9314f0ef872a7bfae78c9"}, "originalPosition": 81}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc1NjYxNzU3", "url": "https://github.com/apache/beam/pull/11075#pullrequestreview-375661757", "createdAt": "2020-03-17T00:12:32Z", "commit": {"oid": "a3b1bb3c731e814be1c9314f0ef872a7bfae78c9"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xN1QwMDoxMjozMlrOF3J6Ug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xN1QwMDoxMjozMlrOF3J6Ug==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MzM3ODM4Ng==", "bodyText": "I think it would be good to list all possible input formats and output formats here or somewhere else for reference. And for the last sentence, do you mean that we need to change l74 to something like:\nfeature={name+'_bytes', value} for sending binary data to endpoint?", "url": "https://github.com/apache/beam/pull/11075#discussion_r393378386", "createdAt": "2020-03-17T00:12:32Z", "author": {"login": "limingxi"}, "path": "website/src/documentation/patterns/ai-platform.md", "diffHunk": "@@ -0,0 +1,87 @@\n+---\n+layout: section\n+title: \"AI Platform integration patterns\"\n+section_menu: section-menu/documentation.html\n+permalink: /documentation/patterns/ai-platform/\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+# AI Platform integration patterns\n+\n+This page describes common patterns in pipelines with Google AI Platform transforms.\n+\n+<nav class=\"language-switcher\">\n+  <strong>Adapt for:</strong>\n+  <ul>\n+    <li data-type=\"language-java\">Java SDK</li>\n+    <li data-type=\"language-py\" class=\"active\">Python SDK</li>\n+  </ul>\n+</nav>\n+\n+## Getting predictions\n+\n+This section shows how to use a cloud-hosted machine learning model to make predictions about new data using Google Cloud AI Platform Prediction within Beam's pipeline.\n+ \n+[tfx_bsl](https://github.com/tensorflow/tfx-bsl) is a library that provides `RunInference` Beam's PTransform. `RunInference` is a PTransform able to perform two types of inference. One of them can use a service endpoint. When using a service endpoint, the transform takes a PCollection of type `tf.train.Example` and, for each element, sends a request to Google Cloud AI Platform Prediction service. The transform produces a PCollection of type `PredictLog` which contains predictions.\n+\n+Before getting started, deploy a machine learning model to the cloud. The cloud service manages the infrastructure needed to handle prediction requests in both efficient and scalable way. Only Tensorflow models are supported. For more information, see [Exporting a SavedModel for prediction](https://cloud.google.com/ai-platform/prediction/docs/exporting-savedmodel-for-prediction).\n+\n+Once a machine learning model is deployed, prepare a list of instances to get predictions for. \n+\n+Here is an example of a pipeline that reads input instances from the file, converts JSON objects to `tf.train.Example` objects and sends data to the service. The content of a file can look like this:\n+\n+```\n+{\"input\": \"the quick brown\"}\n+{\"input\": \"la bruja le\"}\n+``` \n+\n+The example creates `tf.train.BytesList` instances, thus it expects byte-like strings as input, but other data types, like `tf.train.FloatList` and `tf.train.Int64List`, are also supported by the transform. To send binary data, make sure that the name of an input ends in `_bytes`.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3b1bb3c731e814be1c9314f0ef872a7bfae78c9"}, "originalPosition": 50}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc2MTUyMDYz", "url": "https://github.com/apache/beam/pull/11075#pullrequestreview-376152063", "createdAt": "2020-03-17T15:36:28Z", "commit": {"oid": "a3b1bb3c731e814be1c9314f0ef872a7bfae78c9"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xN1QxNTozNjoyOFrOF3h1tw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xN1QxNTo1Mjo1MFrOF3inXw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mzc3MDQyMw==", "bodyText": "Is AI Platform the \"cloud-hosted machine learning model\"?\nI think we can remove the last part (\"within Beam's pipeline\").", "url": "https://github.com/apache/beam/pull/11075#discussion_r393770423", "createdAt": "2020-03-17T15:36:28Z", "author": {"login": "soyrice"}, "path": "website/src/documentation/patterns/ai-platform.md", "diffHunk": "@@ -0,0 +1,87 @@\n+---\n+layout: section\n+title: \"AI Platform integration patterns\"\n+section_menu: section-menu/documentation.html\n+permalink: /documentation/patterns/ai-platform/\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+# AI Platform integration patterns\n+\n+This page describes common patterns in pipelines with Google AI Platform transforms.\n+\n+<nav class=\"language-switcher\">\n+  <strong>Adapt for:</strong>\n+  <ul>\n+    <li data-type=\"language-java\">Java SDK</li>\n+    <li data-type=\"language-py\" class=\"active\">Python SDK</li>\n+  </ul>\n+</nav>\n+\n+## Getting predictions\n+\n+This section shows how to use a cloud-hosted machine learning model to make predictions about new data using Google Cloud AI Platform Prediction within Beam's pipeline.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3b1bb3c731e814be1c9314f0ef872a7bfae78c9"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mzc3MzAzOQ==", "bodyText": "To avoid the phrase \"Beam's PTransform\", I'd recommend something like \"is a library with a Beam PTransform called RunInterface\".", "url": "https://github.com/apache/beam/pull/11075#discussion_r393773039", "createdAt": "2020-03-17T15:39:48Z", "author": {"login": "soyrice"}, "path": "website/src/documentation/patterns/ai-platform.md", "diffHunk": "@@ -0,0 +1,87 @@\n+---\n+layout: section\n+title: \"AI Platform integration patterns\"\n+section_menu: section-menu/documentation.html\n+permalink: /documentation/patterns/ai-platform/\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+# AI Platform integration patterns\n+\n+This page describes common patterns in pipelines with Google AI Platform transforms.\n+\n+<nav class=\"language-switcher\">\n+  <strong>Adapt for:</strong>\n+  <ul>\n+    <li data-type=\"language-java\">Java SDK</li>\n+    <li data-type=\"language-py\" class=\"active\">Python SDK</li>\n+  </ul>\n+</nav>\n+\n+## Getting predictions\n+\n+This section shows how to use a cloud-hosted machine learning model to make predictions about new data using Google Cloud AI Platform Prediction within Beam's pipeline.\n+ \n+[tfx_bsl](https://github.com/tensorflow/tfx-bsl) is a library that provides `RunInference` Beam's PTransform. `RunInference` is a PTransform able to perform two types of inference. One of them can use a service endpoint. When using a service endpoint, the transform takes a PCollection of type `tf.train.Example` and, for each element, sends a request to Google Cloud AI Platform Prediction service. The transform produces a PCollection of type `PredictLog` which contains predictions.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3b1bb3c731e814be1c9314f0ef872a7bfae78c9"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mzc3NDIxMg==", "bodyText": "\"able to perform two types of inference\"\nI only see one type of inference discussed in this paragraph. If we're only addressing one type of inference here, then we don't need to mention that there's another type. A reader might expect there to be information on both types of inference.", "url": "https://github.com/apache/beam/pull/11075#discussion_r393774212", "createdAt": "2020-03-17T15:41:24Z", "author": {"login": "soyrice"}, "path": "website/src/documentation/patterns/ai-platform.md", "diffHunk": "@@ -0,0 +1,87 @@\n+---\n+layout: section\n+title: \"AI Platform integration patterns\"\n+section_menu: section-menu/documentation.html\n+permalink: /documentation/patterns/ai-platform/\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+# AI Platform integration patterns\n+\n+This page describes common patterns in pipelines with Google AI Platform transforms.\n+\n+<nav class=\"language-switcher\">\n+  <strong>Adapt for:</strong>\n+  <ul>\n+    <li data-type=\"language-java\">Java SDK</li>\n+    <li data-type=\"language-py\" class=\"active\">Python SDK</li>\n+  </ul>\n+</nav>\n+\n+## Getting predictions\n+\n+This section shows how to use a cloud-hosted machine learning model to make predictions about new data using Google Cloud AI Platform Prediction within Beam's pipeline.\n+ \n+[tfx_bsl](https://github.com/tensorflow/tfx-bsl) is a library that provides `RunInference` Beam's PTransform. `RunInference` is a PTransform able to perform two types of inference. One of them can use a service endpoint. When using a service endpoint, the transform takes a PCollection of type `tf.train.Example` and, for each element, sends a request to Google Cloud AI Platform Prediction service. The transform produces a PCollection of type `PredictLog` which contains predictions.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3b1bb3c731e814be1c9314f0ef872a7bfae78c9"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mzc3NDg5OA==", "bodyText": "Add a comma before \"which\" in \"which contains predictions\"", "url": "https://github.com/apache/beam/pull/11075#discussion_r393774898", "createdAt": "2020-03-17T15:42:13Z", "author": {"login": "soyrice"}, "path": "website/src/documentation/patterns/ai-platform.md", "diffHunk": "@@ -0,0 +1,87 @@\n+---\n+layout: section\n+title: \"AI Platform integration patterns\"\n+section_menu: section-menu/documentation.html\n+permalink: /documentation/patterns/ai-platform/\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+# AI Platform integration patterns\n+\n+This page describes common patterns in pipelines with Google AI Platform transforms.\n+\n+<nav class=\"language-switcher\">\n+  <strong>Adapt for:</strong>\n+  <ul>\n+    <li data-type=\"language-java\">Java SDK</li>\n+    <li data-type=\"language-py\" class=\"active\">Python SDK</li>\n+  </ul>\n+</nav>\n+\n+## Getting predictions\n+\n+This section shows how to use a cloud-hosted machine learning model to make predictions about new data using Google Cloud AI Platform Prediction within Beam's pipeline.\n+ \n+[tfx_bsl](https://github.com/tensorflow/tfx-bsl) is a library that provides `RunInference` Beam's PTransform. `RunInference` is a PTransform able to perform two types of inference. One of them can use a service endpoint. When using a service endpoint, the transform takes a PCollection of type `tf.train.Example` and, for each element, sends a request to Google Cloud AI Platform Prediction service. The transform produces a PCollection of type `PredictLog` which contains predictions.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3b1bb3c731e814be1c9314f0ef872a7bfae78c9"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mzc3NTY1Ng==", "bodyText": "\"One of them can use a service endpoint.\"\nFirst state the inference you can do with the transform, then describe how to do it.", "url": "https://github.com/apache/beam/pull/11075#discussion_r393775656", "createdAt": "2020-03-17T15:43:04Z", "author": {"login": "soyrice"}, "path": "website/src/documentation/patterns/ai-platform.md", "diffHunk": "@@ -0,0 +1,87 @@\n+---\n+layout: section\n+title: \"AI Platform integration patterns\"\n+section_menu: section-menu/documentation.html\n+permalink: /documentation/patterns/ai-platform/\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+# AI Platform integration patterns\n+\n+This page describes common patterns in pipelines with Google AI Platform transforms.\n+\n+<nav class=\"language-switcher\">\n+  <strong>Adapt for:</strong>\n+  <ul>\n+    <li data-type=\"language-java\">Java SDK</li>\n+    <li data-type=\"language-py\" class=\"active\">Python SDK</li>\n+  </ul>\n+</nav>\n+\n+## Getting predictions\n+\n+This section shows how to use a cloud-hosted machine learning model to make predictions about new data using Google Cloud AI Platform Prediction within Beam's pipeline.\n+ \n+[tfx_bsl](https://github.com/tensorflow/tfx-bsl) is a library that provides `RunInference` Beam's PTransform. `RunInference` is a PTransform able to perform two types of inference. One of them can use a service endpoint. When using a service endpoint, the transform takes a PCollection of type `tf.train.Example` and, for each element, sends a request to Google Cloud AI Platform Prediction service. The transform produces a PCollection of type `PredictLog` which contains predictions.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3b1bb3c731e814be1c9314f0ef872a7bfae78c9"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mzc3NzMwNw==", "bodyText": "If only TensorFlow models are supported, we should say \"deploy a TensorFlow model to the cloud.\"\nAlso, does the cloud service to which you deploy the model have to be AI Platform? If so, we should say \"deploy a TensorFlow model to AI Platform.\"", "url": "https://github.com/apache/beam/pull/11075#discussion_r393777307", "createdAt": "2020-03-17T15:45:12Z", "author": {"login": "soyrice"}, "path": "website/src/documentation/patterns/ai-platform.md", "diffHunk": "@@ -0,0 +1,87 @@\n+---\n+layout: section\n+title: \"AI Platform integration patterns\"\n+section_menu: section-menu/documentation.html\n+permalink: /documentation/patterns/ai-platform/\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+# AI Platform integration patterns\n+\n+This page describes common patterns in pipelines with Google AI Platform transforms.\n+\n+<nav class=\"language-switcher\">\n+  <strong>Adapt for:</strong>\n+  <ul>\n+    <li data-type=\"language-java\">Java SDK</li>\n+    <li data-type=\"language-py\" class=\"active\">Python SDK</li>\n+  </ul>\n+</nav>\n+\n+## Getting predictions\n+\n+This section shows how to use a cloud-hosted machine learning model to make predictions about new data using Google Cloud AI Platform Prediction within Beam's pipeline.\n+ \n+[tfx_bsl](https://github.com/tensorflow/tfx-bsl) is a library that provides `RunInference` Beam's PTransform. `RunInference` is a PTransform able to perform two types of inference. One of them can use a service endpoint. When using a service endpoint, the transform takes a PCollection of type `tf.train.Example` and, for each element, sends a request to Google Cloud AI Platform Prediction service. The transform produces a PCollection of type `PredictLog` which contains predictions.\n+\n+Before getting started, deploy a machine learning model to the cloud. The cloud service manages the infrastructure needed to handle prediction requests in both efficient and scalable way. Only Tensorflow models are supported. For more information, see [Exporting a SavedModel for prediction](https://cloud.google.com/ai-platform/prediction/docs/exporting-savedmodel-for-prediction).", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3b1bb3c731e814be1c9314f0ef872a7bfae78c9"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mzc3ODEyNw==", "bodyText": "\"and sends data to the service\"\n\"the service\" is \"AI Platform\", right? We should state this explicitly.", "url": "https://github.com/apache/beam/pull/11075#discussion_r393778127", "createdAt": "2020-03-17T15:46:16Z", "author": {"login": "soyrice"}, "path": "website/src/documentation/patterns/ai-platform.md", "diffHunk": "@@ -0,0 +1,87 @@\n+---\n+layout: section\n+title: \"AI Platform integration patterns\"\n+section_menu: section-menu/documentation.html\n+permalink: /documentation/patterns/ai-platform/\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+# AI Platform integration patterns\n+\n+This page describes common patterns in pipelines with Google AI Platform transforms.\n+\n+<nav class=\"language-switcher\">\n+  <strong>Adapt for:</strong>\n+  <ul>\n+    <li data-type=\"language-java\">Java SDK</li>\n+    <li data-type=\"language-py\" class=\"active\">Python SDK</li>\n+  </ul>\n+</nav>\n+\n+## Getting predictions\n+\n+This section shows how to use a cloud-hosted machine learning model to make predictions about new data using Google Cloud AI Platform Prediction within Beam's pipeline.\n+ \n+[tfx_bsl](https://github.com/tensorflow/tfx-bsl) is a library that provides `RunInference` Beam's PTransform. `RunInference` is a PTransform able to perform two types of inference. One of them can use a service endpoint. When using a service endpoint, the transform takes a PCollection of type `tf.train.Example` and, for each element, sends a request to Google Cloud AI Platform Prediction service. The transform produces a PCollection of type `PredictLog` which contains predictions.\n+\n+Before getting started, deploy a machine learning model to the cloud. The cloud service manages the infrastructure needed to handle prediction requests in both efficient and scalable way. Only Tensorflow models are supported. For more information, see [Exporting a SavedModel for prediction](https://cloud.google.com/ai-platform/prediction/docs/exporting-savedmodel-for-prediction).\n+\n+Once a machine learning model is deployed, prepare a list of instances to get predictions for. \n+\n+Here is an example of a pipeline that reads input instances from the file, converts JSON objects to `tf.train.Example` objects and sends data to the service. The content of a file can look like this:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3b1bb3c731e814be1c9314f0ef872a7bfae78c9"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mzc3ODk2Nw==", "bodyText": "The first sentence of this paragraph is long and hard to follow. Consider splitting in up into two (or even three) shorter sentences.", "url": "https://github.com/apache/beam/pull/11075#discussion_r393778967", "createdAt": "2020-03-17T15:47:24Z", "author": {"login": "soyrice"}, "path": "website/src/documentation/patterns/ai-platform.md", "diffHunk": "@@ -0,0 +1,87 @@\n+---\n+layout: section\n+title: \"AI Platform integration patterns\"\n+section_menu: section-menu/documentation.html\n+permalink: /documentation/patterns/ai-platform/\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+# AI Platform integration patterns\n+\n+This page describes common patterns in pipelines with Google AI Platform transforms.\n+\n+<nav class=\"language-switcher\">\n+  <strong>Adapt for:</strong>\n+  <ul>\n+    <li data-type=\"language-java\">Java SDK</li>\n+    <li data-type=\"language-py\" class=\"active\">Python SDK</li>\n+  </ul>\n+</nav>\n+\n+## Getting predictions\n+\n+This section shows how to use a cloud-hosted machine learning model to make predictions about new data using Google Cloud AI Platform Prediction within Beam's pipeline.\n+ \n+[tfx_bsl](https://github.com/tensorflow/tfx-bsl) is a library that provides `RunInference` Beam's PTransform. `RunInference` is a PTransform able to perform two types of inference. One of them can use a service endpoint. When using a service endpoint, the transform takes a PCollection of type `tf.train.Example` and, for each element, sends a request to Google Cloud AI Platform Prediction service. The transform produces a PCollection of type `PredictLog` which contains predictions.\n+\n+Before getting started, deploy a machine learning model to the cloud. The cloud service manages the infrastructure needed to handle prediction requests in both efficient and scalable way. Only Tensorflow models are supported. For more information, see [Exporting a SavedModel for prediction](https://cloud.google.com/ai-platform/prediction/docs/exporting-savedmodel-for-prediction).\n+\n+Once a machine learning model is deployed, prepare a list of instances to get predictions for. \n+\n+Here is an example of a pipeline that reads input instances from the file, converts JSON objects to `tf.train.Example` objects and sends data to the service. The content of a file can look like this:\n+\n+```\n+{\"input\": \"the quick brown\"}\n+{\"input\": \"la bruja le\"}\n+``` \n+\n+The example creates `tf.train.BytesList` instances, thus it expects byte-like strings as input, but other data types, like `tf.train.FloatList` and `tf.train.Int64List`, are also supported by the transform. To send binary data, make sure that the name of an input ends in `_bytes`.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3b1bb3c731e814be1c9314f0ef872a7bfae78c9"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5Mzc4MzEzNQ==", "bodyText": "Use the full service name here: \"Patterns for using the Google Cloud AI Platform Prediction\"\nMake sure the the service name is consistent throughout the pattern. I noticed that sometimes it's \"Google Cloud AI Platform Prediction service\", \"Google Cloud AI Platform Prediction\", etc.\nI'd recommend using the full service name (\"Google Cloud AI Platform Prediction\") the first time its mentioned. Then, refer to the service with the shorthand \"AI Platform Prediction\". This way, you can use some shorthand but there's no ambiguity about the name of service.", "url": "https://github.com/apache/beam/pull/11075#discussion_r393783135", "createdAt": "2020-03-17T15:52:50Z", "author": {"login": "soyrice"}, "path": "website/src/documentation/patterns/overview.md", "diffHunk": "@@ -38,6 +38,9 @@ Pipeline patterns demonstrate common Beam use cases. Pipeline patterns are based\n **Custom window patterns** - Patterns for windowing functions\n * [Using data to dynamically set session window gaps]({{ site.baseurl }}/documentation/patterns/custom-windows/#using-data-to-dynamically-set-session-window-gaps)\n \n+**AI Platform integration patterns** - Patterns for Google AI Platform transforms", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3b1bb3c731e814be1c9314f0ef872a7bfae78c9"}, "originalPosition": 4}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a3b1bb3c731e814be1c9314f0ef872a7bfae78c9", "author": {"user": {"login": "kamilwu", "name": "Kamil Wasilewski"}}, "url": "https://github.com/apache/beam/commit/a3b1bb3c731e814be1c9314f0ef872a7bfae78c9", "committedDate": "2020-03-13T15:39:59Z", "message": "fix: add jira reference to Java part"}, "afterCommit": {"oid": "7d174eb913dea3e1294811a1282b572ec2aecfc6", "author": {"user": {"login": "kamilwu", "name": "Kamil Wasilewski"}}, "url": "https://github.com/apache/beam/commit/7d174eb913dea3e1294811a1282b572ec2aecfc6", "committedDate": "2020-03-19T14:27:00Z", "message": "fix: additional fixes after review"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc3ODE4NDU4", "url": "https://github.com/apache/beam/pull/11075#pullrequestreview-377818458", "createdAt": "2020-03-19T15:14:32Z", "commit": {"oid": "7d174eb913dea3e1294811a1282b572ec2aecfc6"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxNToxNDozM1rOF4zMHg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xOVQxNToxNDozM1rOF4zMHg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTEwMzI2Mg==", "bodyText": "\"for every bunch of elements, sends a request to AI Platform Prediction.\"\nI assume this refers to batching data to AI Platform. Is there away to configure how many elements are in the batch? I think the previous version of this paragraph stated that one request is sent per element.", "url": "https://github.com/apache/beam/pull/11075#discussion_r395103262", "createdAt": "2020-03-19T15:14:33Z", "author": {"login": "soyrice"}, "path": "website/src/documentation/patterns/ai-platform.md", "diffHunk": "@@ -0,0 +1,87 @@\n+---\n+layout: section\n+title: \"AI Platform integration patterns\"\n+section_menu: section-menu/documentation.html\n+permalink: /documentation/patterns/ai-platform/\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+# AI Platform integration patterns\n+\n+This page describes common patterns in pipelines with Google Cloud AI Platform transforms.\n+\n+<nav class=\"language-switcher\">\n+  <strong>Adapt for:</strong>\n+  <ul>\n+    <li data-type=\"language-java\">Java SDK</li>\n+    <li data-type=\"language-py\" class=\"active\">Python SDK</li>\n+  </ul>\n+</nav>\n+\n+## Getting predictions\n+\n+This section shows how to use [Google Cloud AI Platform Prediction](https://cloud.google.com/ai-platform/prediction/docs/overview) to make predictions about new data from a cloud-hosted machine learning model.\n+ \n+[tfx_bsl](https://github.com/tensorflow/tfx-bsl) is a library with a Beam PTransform called `RunInference`. `RunInference` is able to perform an inference that can use a service endpoint. When using a service endpoint, the transform takes a PCollection of type `tf.train.Example` and, for every bunch of elements, sends a request to AI Platform Prediction. The transform produces a PCollection of type `PredictLog`, which contains predictions.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7d174eb913dea3e1294811a1282b572ec2aecfc6"}, "originalPosition": 37}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA3MDc1MzIz", "url": "https://github.com/apache/beam/pull/11075#pullrequestreview-407075323", "createdAt": "2020-05-07T00:29:28Z", "commit": {"oid": "265063fc04ca7f6ab71b3ca864d6ad4cb09d9f6f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QwMDoyOToyOFrOGRqIlA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QwMDoyOToyOFrOGRqIlA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTE2OTMwMA==", "bodyText": "s/PredictLog/PredictionLog", "url": "https://github.com/apache/beam/pull/11075#discussion_r421169300", "createdAt": "2020-05-07T00:29:28Z", "author": {"login": "rose-rong-liu"}, "path": "website/src/documentation/patterns/ai-platform.md", "diffHunk": "@@ -0,0 +1,90 @@\n+---\n+layout: section\n+title: \"AI Platform integration patterns\"\n+section_menu: section-menu/documentation.html\n+permalink: /documentation/patterns/ai-platform/\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+# AI Platform integration patterns\n+\n+This page describes common patterns in pipelines with Google Cloud AI Platform transforms.\n+\n+<nav class=\"language-switcher\">\n+  <strong>Adapt for:</strong>\n+  <ul>\n+    <li data-type=\"language-java\">Java SDK</li>\n+    <li data-type=\"language-py\" class=\"active\">Python SDK</li>\n+  </ul>\n+</nav>\n+\n+## Getting predictions\n+\n+This section shows how to use [Google Cloud AI Platform Prediction](https://cloud.google.com/ai-platform/prediction/docs/overview) to make predictions about new data from a cloud-hosted machine learning model.\n+ \n+[tfx_bsl](https://github.com/tensorflow/tfx-bsl) is a library with a Beam PTransform called `RunInference`. `RunInference` is able to perform an inference that can use an external service endpoint for receiving data. When using a service endpoint, the transform takes a PCollection of type `tf.train.Example` and, for every batch of elements, sends a request to AI Platform Prediction. The size of a batch may vary. For more details on how Beam finds the best batch size, refer to a docstring for [BatchElements](https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.util.html?highlight=batchelements#apache_beam.transforms.util.BatchElements).\n+ \n+ The transform produces a PCollection of type `PredictLog`, which contains predictions. ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "265063fc04ca7f6ab71b3ca864d6ad4cb09d9f6f"}, "originalPosition": 39}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA3MDc1NzUy", "url": "https://github.com/apache/beam/pull/11075#pullrequestreview-407075752", "createdAt": "2020-05-07T00:30:47Z", "commit": {"oid": "265063fc04ca7f6ab71b3ca864d6ad4cb09d9f6f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QwMDozMDo0N1rOGRqKTg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QwMDozMDo0N1rOGRqKTg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTE2OTc0Mg==", "bodyText": "Is there extra space?", "url": "https://github.com/apache/beam/pull/11075#discussion_r421169742", "createdAt": "2020-05-07T00:30:47Z", "author": {"login": "rose-rong-liu"}, "path": "website/src/documentation/patterns/ai-platform.md", "diffHunk": "@@ -0,0 +1,90 @@\n+---\n+layout: section\n+title: \"AI Platform integration patterns\"\n+section_menu: section-menu/documentation.html\n+permalink: /documentation/patterns/ai-platform/\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+# AI Platform integration patterns\n+\n+This page describes common patterns in pipelines with Google Cloud AI Platform transforms.\n+\n+<nav class=\"language-switcher\">\n+  <strong>Adapt for:</strong>\n+  <ul>\n+    <li data-type=\"language-java\">Java SDK</li>\n+    <li data-type=\"language-py\" class=\"active\">Python SDK</li>\n+  </ul>\n+</nav>\n+\n+## Getting predictions\n+\n+This section shows how to use [Google Cloud AI Platform Prediction](https://cloud.google.com/ai-platform/prediction/docs/overview) to make predictions about new data from a cloud-hosted machine learning model.\n+ \n+[tfx_bsl](https://github.com/tensorflow/tfx-bsl) is a library with a Beam PTransform called `RunInference`. `RunInference` is able to perform an inference that can use an external service endpoint for receiving data. When using a service endpoint, the transform takes a PCollection of type `tf.train.Example` and, for every batch of elements, sends a request to AI Platform Prediction. The size of a batch may vary. For more details on how Beam finds the best batch size, refer to a docstring for [BatchElements](https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.util.html?highlight=batchelements#apache_beam.transforms.util.BatchElements).\n+ \n+ The transform produces a PCollection of type `PredictLog`, which contains predictions. \n+\n+Before getting started, deploy a TensorFlow model to AI Platform Prediction. The cloud service manages the infrastructure needed to handle prediction requests in both efficient and scalable way. Do note that only TensorFlow models are supported by the transform. For more information, see [Exporting a SavedModel for prediction](https://cloud.google.com/ai-platform/prediction/docs/exporting-savedmodel-for-prediction).\n+\n+Once a machine learning model is deployed, prepare a list of instances to get predictions for. To send binary data, make sure that the name of an input ends in `_bytes`. This will base64-encode data before sending a request.\n+\n+### Example\n+Here is an example of a pipeline that reads input instances from the file, converts JSON objects to `tf.train.Example` objects and sends data to AI Platform Prediction. The content of a file can look like this:\n+\n+```\n+{\"input\": \"the quick brown\"}\n+{\"input\": \"la bruja le\"}\n+``` \n+\n+The example creates `tf.train.BytesList` instances, thus it expects byte-like strings as input. However, other data types, like `tf.train.FloatList` and `tf.train.Int64List`, are also supported by the transform.\n+\n+Here is the code:\n+\n+{:.language-java}\n+```java\n+// Getting predictions is not yet available for Java. [BEAM-9501]\n+```\n+\n+{:.language-py}\n+```py\n+import json\n+\n+import apache_beam as beam\n+\n+import tensorflow as tf\n+from tfx_bsl.beam.run_inference import RunInference\n+from tfx_bsl.proto import model_spec_pb2\n+\n+def convert_json_to_tf_example(json_obj):\n+  dict_ = json.loads(json_obj)\n+  for name, text in dict_.items():\n+      value = tf.train.Feature(bytes_list=tf.train.BytesList(\n+        value=[text.encode('utf-8')]))\n+      feature = {name: value}\n+      return tf.train.Example(features=tf.train.Features(feature=feature))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "265063fc04ca7f6ab71b3ca864d6ad4cb09d9f6f"}, "originalPosition": 78}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA3MDc2MTg2", "url": "https://github.com/apache/beam/pull/11075#pullrequestreview-407076186", "createdAt": "2020-05-07T00:32:10Z", "commit": {"oid": "265063fc04ca7f6ab71b3ca864d6ad4cb09d9f6f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QwMDozMjoxMFrOGRqL4A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QwMDozMjoxMFrOGRqL4A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTE3MDE0NA==", "bodyText": "ModelEndpointSpec will be changed to AIPlatformPredictionModelSpec in next release of tfx_bsl.", "url": "https://github.com/apache/beam/pull/11075#discussion_r421170144", "createdAt": "2020-05-07T00:32:10Z", "author": {"login": "rose-rong-liu"}, "path": "website/src/documentation/patterns/ai-platform.md", "diffHunk": "@@ -0,0 +1,90 @@\n+---\n+layout: section\n+title: \"AI Platform integration patterns\"\n+section_menu: section-menu/documentation.html\n+permalink: /documentation/patterns/ai-platform/\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+# AI Platform integration patterns\n+\n+This page describes common patterns in pipelines with Google Cloud AI Platform transforms.\n+\n+<nav class=\"language-switcher\">\n+  <strong>Adapt for:</strong>\n+  <ul>\n+    <li data-type=\"language-java\">Java SDK</li>\n+    <li data-type=\"language-py\" class=\"active\">Python SDK</li>\n+  </ul>\n+</nav>\n+\n+## Getting predictions\n+\n+This section shows how to use [Google Cloud AI Platform Prediction](https://cloud.google.com/ai-platform/prediction/docs/overview) to make predictions about new data from a cloud-hosted machine learning model.\n+ \n+[tfx_bsl](https://github.com/tensorflow/tfx-bsl) is a library with a Beam PTransform called `RunInference`. `RunInference` is able to perform an inference that can use an external service endpoint for receiving data. When using a service endpoint, the transform takes a PCollection of type `tf.train.Example` and, for every batch of elements, sends a request to AI Platform Prediction. The size of a batch may vary. For more details on how Beam finds the best batch size, refer to a docstring for [BatchElements](https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.util.html?highlight=batchelements#apache_beam.transforms.util.BatchElements).\n+ \n+ The transform produces a PCollection of type `PredictLog`, which contains predictions. \n+\n+Before getting started, deploy a TensorFlow model to AI Platform Prediction. The cloud service manages the infrastructure needed to handle prediction requests in both efficient and scalable way. Do note that only TensorFlow models are supported by the transform. For more information, see [Exporting a SavedModel for prediction](https://cloud.google.com/ai-platform/prediction/docs/exporting-savedmodel-for-prediction).\n+\n+Once a machine learning model is deployed, prepare a list of instances to get predictions for. To send binary data, make sure that the name of an input ends in `_bytes`. This will base64-encode data before sending a request.\n+\n+### Example\n+Here is an example of a pipeline that reads input instances from the file, converts JSON objects to `tf.train.Example` objects and sends data to AI Platform Prediction. The content of a file can look like this:\n+\n+```\n+{\"input\": \"the quick brown\"}\n+{\"input\": \"la bruja le\"}\n+``` \n+\n+The example creates `tf.train.BytesList` instances, thus it expects byte-like strings as input. However, other data types, like `tf.train.FloatList` and `tf.train.Int64List`, are also supported by the transform.\n+\n+Here is the code:\n+\n+{:.language-java}\n+```java\n+// Getting predictions is not yet available for Java. [BEAM-9501]\n+```\n+\n+{:.language-py}\n+```py\n+import json\n+\n+import apache_beam as beam\n+\n+import tensorflow as tf\n+from tfx_bsl.beam.run_inference import RunInference\n+from tfx_bsl.proto import model_spec_pb2\n+\n+def convert_json_to_tf_example(json_obj):\n+  dict_ = json.loads(json_obj)\n+  for name, text in dict_.items():\n+      value = tf.train.Feature(bytes_list=tf.train.BytesList(\n+        value=[text.encode('utf-8')]))\n+      feature = {name: value}\n+      return tf.train.Example(features=tf.train.Features(feature=feature))\n+\n+with beam.Pipeline() as p:\n+     _ = (p\n+         | beam.io.ReadFromText('gs://my-bucket/samples.json')\n+         | beam.Map(convert_json_to_tf_example)\n+         | RunInference(\n+             model_spec_pb2.InferenceEndpoint(\n+                 model_endpoint_spec=model_spec_pb2.ModelEndpointSpec(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "265063fc04ca7f6ab71b3ca864d6ad4cb09d9f6f"}, "originalPosition": 86}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "265063fc04ca7f6ab71b3ca864d6ad4cb09d9f6f", "author": {"user": {"login": "kamilwu", "name": "Kamil Wasilewski"}}, "url": "https://github.com/apache/beam/commit/265063fc04ca7f6ab71b3ca864d6ad4cb09d9f6f", "committedDate": "2020-03-20T13:59:51Z", "message": "fix: add a link to pydoc"}, "afterCommit": {"oid": "c8a2246f3541b5e979a40b7b402cad8727729777", "author": {"user": {"login": "kamilwu", "name": "Kamil Wasilewski"}}, "url": "https://github.com/apache/beam/commit/c8a2246f3541b5e979a40b7b402cad8727729777", "committedDate": "2020-05-07T11:54:10Z", "message": "fix: addressing comments"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c8a2246f3541b5e979a40b7b402cad8727729777", "author": {"user": {"login": "kamilwu", "name": "Kamil Wasilewski"}}, "url": "https://github.com/apache/beam/commit/c8a2246f3541b5e979a40b7b402cad8727729777", "committedDate": "2020-05-07T11:54:10Z", "message": "fix: addressing comments"}, "afterCommit": {"oid": "d2fcdf025eb95de69f110daab3d58e7d18fd0c80", "author": {"user": {"login": "kamilwu", "name": "Kamil Wasilewski"}}, "url": "https://github.com/apache/beam/commit/d2fcdf025eb95de69f110daab3d58e7d18fd0c80", "committedDate": "2020-05-18T13:49:41Z", "message": "[BEAM-9421] Website section that describes getting predictions using AI Platform Prediction"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d2fcdf025eb95de69f110daab3d58e7d18fd0c80", "author": {"user": {"login": "kamilwu", "name": "Kamil Wasilewski"}}, "url": "https://github.com/apache/beam/commit/d2fcdf025eb95de69f110daab3d58e7d18fd0c80", "committedDate": "2020-05-18T13:49:41Z", "message": "[BEAM-9421] Website section that describes getting predictions using AI Platform Prediction"}, "afterCommit": {"oid": "2889af47ac3462c9c35b891c1452e0de70d64a25", "author": {"user": {"login": "kamilwu", "name": "Kamil Wasilewski"}}, "url": "https://github.com/apache/beam/commit/2889af47ac3462c9c35b891c1452e0de70d64a25", "committedDate": "2020-05-18T14:17:33Z", "message": "[BEAM-9421] Website section that describes getting predictions using AI Platform Prediction"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDEzODU1NjI3", "url": "https://github.com/apache/beam/pull/11075#pullrequestreview-413855627", "createdAt": "2020-05-18T18:54:52Z", "commit": {"oid": "2889af47ac3462c9c35b891c1452e0de70d64a25"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQxODo1NDo1MlrOGXDpSg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQxODo1NDo1MlrOGXDpSg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjgzMDE1NA==", "bodyText": "From the implementation side, it does not limit to tensorflow model, right? As cloud serves other model formats with the same predict API. Or is this for branding purpose?", "url": "https://github.com/apache/beam/pull/11075#discussion_r426830154", "createdAt": "2020-05-18T18:54:52Z", "author": {"login": "rose-rong-liu"}, "path": "website/www/site/content/en/documentation/patterns/ai-platform.md", "diffHunk": "@@ -0,0 +1,79 @@\n+---\n+title: \"AI Platform integration patterns\"\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+# AI Platform integration patterns\n+\n+This page describes common patterns in pipelines with Google Cloud AI Platform transforms.\n+\n+{{< language-switcher java py >}}\n+\n+## Getting predictions\n+\n+This section shows how to use [Google Cloud AI Platform Prediction](https://cloud.google.com/ai-platform/prediction/docs/overview) to make predictions about new data from a cloud-hosted machine learning model.\n+ \n+[tfx_bsl](https://github.com/tensorflow/tfx-bsl) is a library with a Beam PTransform called `RunInference`. `RunInference` is able to perform an inference that can use an external service endpoint for receiving data. When using a service endpoint, the transform takes a PCollection of type `tf.train.Example` and, for every batch of elements, sends a request to AI Platform Prediction. The size of a batch may vary. For more details on how Beam finds the best batch size, refer to a docstring for [BatchElements](https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.util.html?highlight=batchelements#apache_beam.transforms.util.BatchElements).\n+ \n+ The transform produces a PCollection of type `PredictionLog`, which contains predictions.\n+\n+Before getting started, deploy a TensorFlow model to AI Platform Prediction. The cloud service manages the infrastructure needed to handle prediction requests in both efficient and scalable way. Do note that only TensorFlow models are supported by the transform. For more information, see [Exporting a SavedModel for prediction](https://cloud.google.com/ai-platform/prediction/docs/exporting-savedmodel-for-prediction).", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2889af47ac3462c9c35b891c1452e0de70d64a25"}, "originalPosition": 32}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDEzOTMzNzg2", "url": "https://github.com/apache/beam/pull/11075#pullrequestreview-413933786", "createdAt": "2020-05-18T20:57:34Z", "commit": {"oid": "2889af47ac3462c9c35b891c1452e0de70d64a25"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQyMDo1NzozNFrOGXHQJg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQyMDo1OToxN1rOGXHTHQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjg4OTI1NA==", "bodyText": "tf.train.Example -> tf.train.Example or tf.train.SequenceExample", "url": "https://github.com/apache/beam/pull/11075#discussion_r426889254", "createdAt": "2020-05-18T20:57:34Z", "author": {"login": "aaltay"}, "path": "website/www/site/content/en/documentation/patterns/ai-platform.md", "diffHunk": "@@ -0,0 +1,79 @@\n+---\n+title: \"AI Platform integration patterns\"\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+# AI Platform integration patterns\n+\n+This page describes common patterns in pipelines with Google Cloud AI Platform transforms.\n+\n+{{< language-switcher java py >}}\n+\n+## Getting predictions\n+\n+This section shows how to use [Google Cloud AI Platform Prediction](https://cloud.google.com/ai-platform/prediction/docs/overview) to make predictions about new data from a cloud-hosted machine learning model.\n+ \n+[tfx_bsl](https://github.com/tensorflow/tfx-bsl) is a library with a Beam PTransform called `RunInference`. `RunInference` is able to perform an inference that can use an external service endpoint for receiving data. When using a service endpoint, the transform takes a PCollection of type `tf.train.Example` and, for every batch of elements, sends a request to AI Platform Prediction. The size of a batch may vary. For more details on how Beam finds the best batch size, refer to a docstring for [BatchElements](https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.util.html?highlight=batchelements#apache_beam.transforms.util.BatchElements).", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2889af47ac3462c9c35b891c1452e0de70d64a25"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjg4OTUxOQ==", "bodyText": "The size of a batch may vary. -> The size of a batch is automatically computed.", "url": "https://github.com/apache/beam/pull/11075#discussion_r426889519", "createdAt": "2020-05-18T20:58:04Z", "author": {"login": "aaltay"}, "path": "website/www/site/content/en/documentation/patterns/ai-platform.md", "diffHunk": "@@ -0,0 +1,79 @@\n+---\n+title: \"AI Platform integration patterns\"\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+# AI Platform integration patterns\n+\n+This page describes common patterns in pipelines with Google Cloud AI Platform transforms.\n+\n+{{< language-switcher java py >}}\n+\n+## Getting predictions\n+\n+This section shows how to use [Google Cloud AI Platform Prediction](https://cloud.google.com/ai-platform/prediction/docs/overview) to make predictions about new data from a cloud-hosted machine learning model.\n+ \n+[tfx_bsl](https://github.com/tensorflow/tfx-bsl) is a library with a Beam PTransform called `RunInference`. `RunInference` is able to perform an inference that can use an external service endpoint for receiving data. When using a service endpoint, the transform takes a PCollection of type `tf.train.Example` and, for every batch of elements, sends a request to AI Platform Prediction. The size of a batch may vary. For more details on how Beam finds the best batch size, refer to a docstring for [BatchElements](https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.util.html?highlight=batchelements#apache_beam.transforms.util.BatchElements).", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2889af47ac3462c9c35b891c1452e0de70d64a25"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjg4OTgwNg==", "bodyText": "Is this still applicable?\n/cc @rose-rong-liu", "url": "https://github.com/apache/beam/pull/11075#discussion_r426889806", "createdAt": "2020-05-18T20:58:48Z", "author": {"login": "aaltay"}, "path": "website/www/site/content/en/documentation/patterns/ai-platform.md", "diffHunk": "@@ -0,0 +1,79 @@\n+---\n+title: \"AI Platform integration patterns\"\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+# AI Platform integration patterns\n+\n+This page describes common patterns in pipelines with Google Cloud AI Platform transforms.\n+\n+{{< language-switcher java py >}}\n+\n+## Getting predictions\n+\n+This section shows how to use [Google Cloud AI Platform Prediction](https://cloud.google.com/ai-platform/prediction/docs/overview) to make predictions about new data from a cloud-hosted machine learning model.\n+ \n+[tfx_bsl](https://github.com/tensorflow/tfx-bsl) is a library with a Beam PTransform called `RunInference`. `RunInference` is able to perform an inference that can use an external service endpoint for receiving data. When using a service endpoint, the transform takes a PCollection of type `tf.train.Example` and, for every batch of elements, sends a request to AI Platform Prediction. The size of a batch may vary. For more details on how Beam finds the best batch size, refer to a docstring for [BatchElements](https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.util.html?highlight=batchelements#apache_beam.transforms.util.BatchElements).\n+ \n+ The transform produces a PCollection of type `PredictionLog`, which contains predictions.\n+\n+Before getting started, deploy a TensorFlow model to AI Platform Prediction. The cloud service manages the infrastructure needed to handle prediction requests in both efficient and scalable way. Do note that only TensorFlow models are supported by the transform. For more information, see [Exporting a SavedModel for prediction](https://cloud.google.com/ai-platform/prediction/docs/exporting-savedmodel-for-prediction).\n+\n+Once a machine learning model is deployed, prepare a list of instances to get predictions for. To send binary data, make sure that the name of an input ends in `_bytes`. This will base64-encode data before sending a request.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2889af47ac3462c9c35b891c1452e0de70d64a25"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjg5MDAxMw==", "bodyText": "remove the underscore. dict_ -> dict", "url": "https://github.com/apache/beam/pull/11075#discussion_r426890013", "createdAt": "2020-05-18T20:59:17Z", "author": {"login": "aaltay"}, "path": "website/www/site/content/en/documentation/patterns/ai-platform.md", "diffHunk": "@@ -0,0 +1,79 @@\n+---\n+title: \"AI Platform integration patterns\"\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+# AI Platform integration patterns\n+\n+This page describes common patterns in pipelines with Google Cloud AI Platform transforms.\n+\n+{{< language-switcher java py >}}\n+\n+## Getting predictions\n+\n+This section shows how to use [Google Cloud AI Platform Prediction](https://cloud.google.com/ai-platform/prediction/docs/overview) to make predictions about new data from a cloud-hosted machine learning model.\n+ \n+[tfx_bsl](https://github.com/tensorflow/tfx-bsl) is a library with a Beam PTransform called `RunInference`. `RunInference` is able to perform an inference that can use an external service endpoint for receiving data. When using a service endpoint, the transform takes a PCollection of type `tf.train.Example` and, for every batch of elements, sends a request to AI Platform Prediction. The size of a batch may vary. For more details on how Beam finds the best batch size, refer to a docstring for [BatchElements](https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.util.html?highlight=batchelements#apache_beam.transforms.util.BatchElements).\n+ \n+ The transform produces a PCollection of type `PredictionLog`, which contains predictions.\n+\n+Before getting started, deploy a TensorFlow model to AI Platform Prediction. The cloud service manages the infrastructure needed to handle prediction requests in both efficient and scalable way. Do note that only TensorFlow models are supported by the transform. For more information, see [Exporting a SavedModel for prediction](https://cloud.google.com/ai-platform/prediction/docs/exporting-savedmodel-for-prediction).\n+\n+Once a machine learning model is deployed, prepare a list of instances to get predictions for. To send binary data, make sure that the name of an input ends in `_bytes`. This will base64-encode data before sending a request.\n+\n+### Example\n+Here is an example of a pipeline that reads input instances from the file, converts JSON objects to `tf.train.Example` objects and sends data to AI Platform Prediction. The content of a file can look like this:\n+\n+```\n+{\"input\": \"the quick brown\"}\n+{\"input\": \"la bruja le\"}\n+``` \n+\n+The example creates `tf.train.BytesList` instances, thus it expects byte-like strings as input. However, other data types, like `tf.train.FloatList` and `tf.train.Int64List`, are also supported by the transform.\n+\n+Here is the code:\n+\n+{{< highlight java >}}\n+// Getting predictions is not yet available for Java. [BEAM-9501]\n+{{< /highlight >}}\n+\n+{{< highlight py >}}\n+import json\n+\n+import apache_beam as beam\n+\n+import tensorflow as tf\n+from tfx_bsl.beam.run_inference import RunInference\n+from tfx_bsl.proto import model_spec_pb2\n+\n+def convert_json_to_tf_example(json_obj):\n+  dict_ = json.loads(json_obj)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2889af47ac3462c9c35b891c1452e0de70d64a25"}, "originalPosition": 62}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIwMjk4OTM2", "url": "https://github.com/apache/beam/pull/11075#pullrequestreview-420298936", "createdAt": "2020-05-28T16:41:24Z", "commit": {"oid": "cdb44f79106b6e512c758c63c08d44932afa50d2"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "5a8039c1d1d6528902b83dd93b4a934532eecaff", "author": {"user": {"login": "kamilwu", "name": "Kamil Wasilewski"}}, "url": "https://github.com/apache/beam/commit/5a8039c1d1d6528902b83dd93b4a934532eecaff", "committedDate": "2020-05-29T09:50:36Z", "message": "fix: add a note about sequence example"}, "afterCommit": {"oid": "9bb3dd4f45f993466cb9d78dc1cb76c8ab6d1ba0", "author": {"user": {"login": "kamilwu", "name": "Kamil Wasilewski"}}, "url": "https://github.com/apache/beam/commit/9bb3dd4f45f993466cb9d78dc1cb76c8ab6d1ba0", "committedDate": "2020-05-29T09:51:46Z", "message": "fix: add a note about sequence example"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8228baf9f2751a85ca4b545c4bba4aab45182d15", "author": {"user": {"login": "kamilwu", "name": "Kamil Wasilewski"}}, "url": "https://github.com/apache/beam/commit/8228baf9f2751a85ca4b545c4bba4aab45182d15", "committedDate": "2020-06-01T09:19:09Z", "message": "[BEAM-9421] Website section that describes getting predictions using AI Platform Prediction"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "520dd0a0abf5063e3638a9956ed62dd4a3adff24", "author": {"user": {"login": "kamilwu", "name": "Kamil Wasilewski"}}, "url": "https://github.com/apache/beam/commit/520dd0a0abf5063e3638a9956ed62dd4a3adff24", "committedDate": "2020-06-01T09:19:13Z", "message": "fix: addressing comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "583e2179649b04f56d1422d5ebfacc2688ee9a4e", "author": {"user": {"login": "kamilwu", "name": "Kamil Wasilewski"}}, "url": "https://github.com/apache/beam/commit/583e2179649b04f56d1422d5ebfacc2688ee9a4e", "committedDate": "2020-06-01T09:19:13Z", "message": "fix: add a note about sequence example"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8e8c3a1db3b4dbf979277aa4113dfb102af87036", "author": {"user": {"login": "kamilwu", "name": "Kamil Wasilewski"}}, "url": "https://github.com/apache/beam/commit/8e8c3a1db3b4dbf979277aa4113dfb102af87036", "committedDate": "2020-06-01T09:25:17Z", "message": "fix: python snippet first"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9bb3dd4f45f993466cb9d78dc1cb76c8ab6d1ba0", "author": {"user": {"login": "kamilwu", "name": "Kamil Wasilewski"}}, "url": "https://github.com/apache/beam/commit/9bb3dd4f45f993466cb9d78dc1cb76c8ab6d1ba0", "committedDate": "2020-05-29T09:51:46Z", "message": "fix: add a note about sequence example"}, "afterCommit": {"oid": "8e8c3a1db3b4dbf979277aa4113dfb102af87036", "author": {"user": {"login": "kamilwu", "name": "Kamil Wasilewski"}}, "url": "https://github.com/apache/beam/commit/8e8c3a1db3b4dbf979277aa4113dfb102af87036", "committedDate": "2020-06-01T09:25:17Z", "message": "fix: python snippet first"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3105, "cost": 1, "resetAt": "2021-10-28T16:48:13Z"}}}