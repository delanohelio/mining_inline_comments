{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTA3NzQzMDAx", "number": 13160, "title": "[BEAM-11078] Add splittable DoFn documentation to programming guide", "bodyText": "Thank you for your contribution! Follow this checklist to help us incorporate your contribution quickly and easily:\n\n Choose reviewer(s) and mention them in a comment (R: @username).\n Format the pull request title like [BEAM-XXX] Fixes bug in ApproximateQuantiles, where you replace BEAM-XXX with the appropriate JIRA issue, if applicable. This will automatically link the pull request to the issue.\n Update CHANGES.md with noteworthy changes.\n If this contribution is large, please file an Apache Individual Contributor License Agreement.\n\nSee the Contributor Guide for more tips on how to make review process smoother.\nPost-Commit Tests Status (on master branch)\n\n\n\nLang\nSDK\nDataflow\nFlink\nSamza\nSpark\nTwister2\n\n\n\n\nGo\n\n---\n\n---\n\n---\n\n\nJava\n\n\n\n\n\n\n\n\nPython\n\n\n\n---\n\n---\n\n\nXLang\n\n---\n\n---\n\n---\n\n\n\nPre-Commit Tests Status (on master branch)\n\n\n\n---\nJava\nPython\nGo\nWebsite\nWhitespace\nTypescript\n\n\n\n\nNon-portable\n\n \n\n\n\n\n\n\nPortable\n---\n\n---\n---\n---\n---\n\n\n\nSee .test-infra/jenkins/README for trigger phrase, status and link of all Jenkins jobs.\nGitHub Actions Tests Status (on master branch)\n\n\n\nSee CI.md for more information about GitHub Actions CI.", "createdAt": "2020-10-21T17:47:06Z", "url": "https://github.com/apache/beam/pull/13160", "merged": true, "mergeCommit": {"oid": "a99c81c15c03ed642b9ed90f4a0eea14e1b316b9"}, "closed": true, "closedAt": "2020-10-23T01:37:12Z", "author": {"login": "lukecwik"}, "timelineItems": {"totalCount": 20, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdUf9d7gH2gAyNTA3NzQzMDAxOmZhNTNhMGRkNjFhZWRkODQ4YTBkNmE1ZTAyMjdhZjc2YjIxNzhmZmI=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdVJi68AH2gAyNTA3NzQzMDAxOmFjOGY3NzNiMDk2NTY1Y2NmNGViOTVmYjk0ZTZlOWI1Y2U5NDdkMTQ=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "fa53a0dd61aedd848a0d6a5e0227af76b2178ffb", "author": {"user": {"login": "lukecwik", "name": "Lukasz Cwik"}}, "url": "https://github.com/apache/beam/commit/fa53a0dd61aedd848a0d6a5e0227af76b2178ffb", "committedDate": "2020-10-20T21:49:55Z", "message": "[BEAM-11078, BEAM-2081] Convert to markdown, no changes of content from http://doc/1kpn0RxqZaoacUPVSMYhhnfmlo8fGT-p50fEblaFr2HE"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a5f39677388fa263aefe2742b9d76c95c4b68a26", "author": {"user": {"login": "lukecwik", "name": "Lukasz Cwik"}}, "url": "https://github.com/apache/beam/commit/a5f39677388fa263aefe2742b9d76c95c4b68a26", "committedDate": "2020-10-20T23:04:54Z", "message": "Fill in placeholders for missing py snippets.\nMake website renderable."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "30f46307dfacd8642b5dbae3b430ed229c564d50", "author": {"user": {"login": "lukecwik", "name": "Lukasz Cwik"}}, "url": "https://github.com/apache/beam/commit/30f46307dfacd8642b5dbae3b430ed229c564d50", "committedDate": "2020-10-21T16:11:13Z", "message": "edit heading"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "beb01b11ed41349fdeed221e84021793196049c5", "author": {"user": {"login": "lukecwik", "name": "Lukasz Cwik"}}, "url": "https://github.com/apache/beam/commit/beb01b11ed41349fdeed221e84021793196049c5", "committedDate": "2020-10-21T16:18:42Z", "message": "Update section menu"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "521de77446da09cd7abb7ccdc45f279f6a0a222b", "author": {"user": {"login": "lukecwik", "name": "Lukasz Cwik"}}, "url": "https://github.com/apache/beam/commit/521de77446da09cd7abb7ccdc45f279f6a0a222b", "committedDate": "2020-10-21T17:44:23Z", "message": "Fill in Python code snippets, make minor Java/Go code snippet changes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e5a6622ae410e4bd7c22193ce0579372ccb33c05", "author": {"user": {"login": "lukecwik", "name": "Lukasz Cwik"}}, "url": "https://github.com/apache/beam/commit/e5a6622ae410e4bd7c22193ce0579372ccb33c05", "committedDate": "2020-10-21T18:10:40Z", "message": "Fix lint issues in snippets"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bb81848f03998f830d1728daea8406015955de31", "author": {"user": {"login": "lukecwik", "name": "Lukasz Cwik"}}, "url": "https://github.com/apache/beam/commit/bb81848f03998f830d1728daea8406015955de31", "committedDate": "2020-10-21T18:15:35Z", "message": "Fix Java snippets"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e25d66a22134e2316e336b9582b2f146dd81c34f", "author": {"user": {"login": "lukecwik", "name": "Lukasz Cwik"}}, "url": "https://github.com/apache/beam/commit/e25d66a22134e2316e336b9582b2f146dd81c34f", "committedDate": "2020-10-21T18:21:15Z", "message": "fix whitespace lint issues in website"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e38f86acced96b71079c6ad3273abf9313b192b7", "author": {"user": {"login": "lukecwik", "name": "Lukasz Cwik"}}, "url": "https://github.com/apache/beam/commit/e38f86acced96b71079c6ad3273abf9313b192b7", "committedDate": "2020-10-21T18:23:42Z", "message": "More python snippet lint fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c2d0fcd65e3fa29793ef1998f9dec719aad61347", "author": {"user": {"login": "lukecwik", "name": "Lukasz Cwik"}}, "url": "https://github.com/apache/beam/commit/c2d0fcd65e3fa29793ef1998f9dec719aad61347", "committedDate": "2020-10-21T18:28:01Z", "message": "Fix Java snippets spotless error"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5294ea19a2bba517ac5544e58e29b957d9536e60", "author": {"user": {"login": "lukecwik", "name": "Lukasz Cwik"}}, "url": "https://github.com/apache/beam/commit/5294ea19a2bba517ac5544e58e29b957d9536e60", "committedDate": "2020-10-21T19:50:26Z", "message": "Add image to SDF high level overview"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cde1bf1761920deded30475f92c782848bf64244", "author": {"user": {"login": "lukecwik", "name": "Lukasz Cwik"}}, "url": "https://github.com/apache/beam/commit/cde1bf1761920deded30475f92c782848bf64244", "committedDate": "2020-10-21T19:50:26Z", "message": "Remove current status link to be re-added back once capability matrix is updated"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e3bfc75014c2966f979dda6b0de6de648819f949", "author": {"user": {"login": "lukecwik", "name": "Lukasz Cwik"}}, "url": "https://github.com/apache/beam/commit/e3bfc75014c2966f979dda6b0de6de648819f949", "committedDate": "2020-10-21T19:46:52Z", "message": "Remove current status link to be re-added back once capability matrix is updated"}, "afterCommit": {"oid": "cde1bf1761920deded30475f92c782848bf64244", "author": {"user": {"login": "lukecwik", "name": "Lukasz Cwik"}}, "url": "https://github.com/apache/beam/commit/cde1bf1761920deded30475f92c782848bf64244", "committedDate": "2020-10-21T19:50:26Z", "message": "Remove current status link to be re-added back once capability matrix is updated"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "626366b189b7dee572bd92fdefc7b11b6f7b2d51", "author": {"user": {"login": "lukecwik", "name": "Lukasz Cwik"}}, "url": "https://github.com/apache/beam/commit/626366b189b7dee572bd92fdefc7b11b6f7b2d51", "committedDate": "2020-10-21T21:03:32Z", "message": "Update Java snippets to satisfy spotbugs"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE0MzA2NDIw", "url": "https://github.com/apache/beam/pull/13160#pullrequestreview-514306420", "createdAt": "2020-10-22T01:56:10Z", "commit": {"oid": "626366b189b7dee572bd92fdefc7b11b6f7b2d51"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQwMTo1NjoxMFrOHmNxkg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQwNDowMDo1MlrOHmPw4A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTgzMzYxOA==", "bodyText": "Note that rest.Size() is a convenience function added to offsetrange.Restriction specifically, it's not part of the SDF API. It might be better to replace it with rest.End - rest.Start to avoid the expectation that all restrictions will have a size method.", "url": "https://github.com/apache/beam/pull/13160#discussion_r509833618", "createdAt": "2020-10-22T01:56:10Z", "author": {"login": "youngoli"}, "path": "website/www/site/content/en/documentation/programming-guide.md", "diffHunk": "@@ -5143,3 +5143,282 @@ perUser.apply(ParDo.of(new DoFn<KV<String, ValueT>, OutputT>() {\n   }\n }));\n {{< /highlight >}}\n+\n+## 12 Splittable DoFns {#splittable-dofns}\n+\n+Splittable DoFns (SDFs) enable users to create modular components containing I/Os (and some advanced\n+[non I/O use cases](https://s.apache.org/splittable-do-fn#heading=h.5cep9s8k4fxv)). Having modular\n+I/O components that can be connected to each other simplify typical patterns that users want.\n+For example, a popular use case is to read filenames from a message queue followed by parsing those\n+files. Traditionally users were required to either write a single I/O connector that contained the\n+logic for the message queue and the file reader (increased complexity) or choose to reuse a message\n+queue I/O followed by a regular DoFn that read the file (decreased performance). With splittable DoFns,\n+we bring the richness of Apache Beam\u2019s I/O APIs to DoFns enabling modularity while maintaining the\n+performance of traditional I/O connectors.\n+\n+### 12.1 Splittable DoFn basics {#splittable-dofn-basics}\n+\n+At a high level, a splittable DoFn is responsible for processing element and restriction pairs. A\n+restriction represents a subset of work that would have been necessary to have been done when\n+processing the element.\n+\n+Executing a splittable DoFn follows the following steps:\n+\n+1. Each element is paired with a restriction (e.g. filename is paired with offset range representing the whole file).\n+2. Each element and restriction pair is split (e.g. offset ranges are broken up into smaller pieces).\n+3. The runner redistributes the element and restriction pairs to several workers.\n+4. Element and restriction pairs are processed in parallel (e.g. the file is read).\n+\n+![Diagram of steps that a splittable DoFn is composed of](/images/sdf_high_level_overview.svg)\n+\n+Within the last step, the element and restriction pair can pause its own processing and/or be split into\n+further element and restriction pairs. This last step is what enables I/O-like capabilities for DoFns.\n+\n+\n+#### 12.1.1 A basic splittable DoFn {#a-basic-splittable-dofn}\n+\n+A basic splittable DoFn is composed of three parts: a restriction, a restriction provider, and a\n+restriction tracker. The restriction is used to represent a subset of work for a given element.\n+The restriction provider lets SDF authors override default implementations for splitting, sizing,\n+watermark estimation, and so forth. In [Java](https://github.com/apache/beam/blob/f4c2734261396858e388ebef2eef50e7d48231a8/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/DoFn.java#L92)\n+and [Go](https://github.com/apache/beam/blob/0f466e6bcd4ac8677c2bd9ecc8e6af3836b7f3b8/sdks/go/pkg/beam/pardo.go#L226),\n+this is the DoFn. [Python](https://github.com/apache/beam/blob/f4c2734261396858e388ebef2eef50e7d48231a8/sdks/python/apache_beam/transforms/core.py#L213)\n+has a dedicated RestrictionProvider type. The restriction tracker is responsible for tracking\n+what subset of the restriction has been completed during processing.\n+\n+To define a splittable DoFn, you must choose whether the splittable DoFn is bounded (default) or\n+unbounded and define a way to initialize an initial restriction for an element.\n+\n+{{< highlight java >}}\n+{{< code_sample \"examples/java/src/main/java/org/apache/beam/examples/snippets/Snippets.java\" SDF_BasicExample >}}\n+{{< /highlight >}}\n+\n+{{< highlight py >}}\n+{{< code_sample \"sdks/python/apache_beam/examples/snippets/snippets.py\" SDF_BasicExample >}}\n+{{< /highlight >}}\n+\n+{{< highlight go >}}\n+func (fn *splittableDoFn) CreateInitialRestriction(filename string) offsetrange.Restriction {\n+\treturn offsetrange.Restriction{\n+\t\tStart: 0,\n+\t\tEnd:   getFileLength(filename),\n+\t}\n+}\n+\n+func (fn *splittableDoFn) CreateTracker(rest offsetrange.Restriction) *sdf.LockRTracker {\n+\treturn sdf.NewLockRTracker(offsetrange.NewTracker(rest))\n+}\n+\n+func (fn *splittableDoFn) ProcessElement(rt *sdf.LockRTracker, filename string, emit func(int)) error {\n+            file, err := os.Open(filename)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\toffset, err := seekToNextRecordBoundaryInFile(file, rt.GetRestriction().(offsetrange.Restriction).Start)\n+\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tfor rt.TryClaim(offset) {\n+\t\trecord, newOffset := readNextRecord(file)\n+\t\temit(record)\n+\t\toffset = newOffset\n+\t}\n+\treturn nil\n+}\n+{{< /highlight >}}\n+\n+At this point, we have a splittable DoFn that supports [runner-initiated splits](#runner-initiated-split)\n+enabling dynamic work rebalancing. To increase the rate at which initial parallelization of work occurs\n+or for those runners that do not support runner-initiated splitting, we recommend providing\n+a set of initial splits:\n+\n+{{< highlight java >}}\n+{{< code_sample \"examples/java/src/main/java/org/apache/beam/examples/snippets/Snippets.java\" SDF_BasicExampleWithSplitting >}}\n+{{< /highlight >}}\n+\n+{{< highlight py >}}\n+{{< code_sample \"sdks/python/apache_beam/examples/snippets/snippets.py\" SDF_BasicExampleWithSplitting >}}\n+{{< /highlight >}}\n+\n+{{< highlight go >}}\n+func (fn *splittableDoFn) SplitRestriction(filename string, rest offsetrange.Restriction) (splits []offsetrange.Restriction) {\n+\tsize := 64 * (1 << 20)\n+\ti := rest.Start\n+\tfor i < rest.End - size {\n+\t\t// Compute and output 64 MiB size ranges to process in parallel\n+\t\tend := i + size\n+     \t\tsplits = append(splits, offsetrange.Restriction{i, end})\n+\t\ti = end\n+\t}\n+\t// Output the last range\n+\tsplits = append(splits, offsetrange.Restriction{i, rest.End})\n+\treturn splits\n+}\n+{{< /highlight >}}\n+\n+### 12.2 Sizing and progress {#sizing-and-progress}\n+\n+Sizing and progress are used during execution of a splittable DoFn to inform runners so that they may\n+perform intelligent decisions about which restrictions to split and how to parallelize work.\n+\n+Before processing an element and restriction, an initial size may be used by a runner to choose\n+how and who processes the restrictions attempting to improve initial balancing and parallelization\n+of work. During the processing of an element and restriction, sizing and progress are used to choose\n+which restrictions to split and who should process them.\n+\n+By default, we use the restriction tracker\u2019s estimate for work remaining falling back to assuming\n+that all restrictions have an equal cost. To override the default, SDF authors can provide the\n+appropriate method within the restriction provider.\n+\n+{{< highlight java >}}\n+{{< code_sample \"examples/java/src/main/java/org/apache/beam/examples/snippets/Snippets.java\" SDF_GetSize >}}\n+{{< /highlight >}}\n+\n+{{< highlight py >}}\n+{{< code_sample \"sdks/python/apache_beam/examples/snippets/snippets.py\" SDF_GetSize >}}\n+{{< /highlight >}}\n+\n+{{< highlight go >}}\n+func (fn *splittableDoFn) RestrictionSize(filename string, rest offsetrange.Restriction) float64 {\n+\tweight := float64(1)\n+\tif strings.Contains(filename, \u201cexpensiveRecords\u201d) {\n+\t\tweight = 2\n+\t}\n+\treturn weight * rest.Size()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "626366b189b7dee572bd92fdefc7b11b6f7b2d51"}, "originalPosition": 146}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTg2NjIwOA==", "bodyText": "Typo: \"As a splittable DoFn pr an element...\"", "url": "https://github.com/apache/beam/pull/13160#discussion_r509866208", "createdAt": "2020-10-22T04:00:52Z", "author": {"login": "youngoli"}, "path": "website/www/site/content/en/documentation/programming-guide.md", "diffHunk": "@@ -5143,3 +5143,282 @@ perUser.apply(ParDo.of(new DoFn<KV<String, ValueT>, OutputT>() {\n   }\n }));\n {{< /highlight >}}\n+\n+## 12 Splittable DoFns {#splittable-dofns}\n+\n+Splittable DoFns (SDFs) enable users to create modular components containing I/Os (and some advanced\n+[non I/O use cases](https://s.apache.org/splittable-do-fn#heading=h.5cep9s8k4fxv)). Having modular\n+I/O components that can be connected to each other simplify typical patterns that users want.\n+For example, a popular use case is to read filenames from a message queue followed by parsing those\n+files. Traditionally users were required to either write a single I/O connector that contained the\n+logic for the message queue and the file reader (increased complexity) or choose to reuse a message\n+queue I/O followed by a regular DoFn that read the file (decreased performance). With splittable DoFns,\n+we bring the richness of Apache Beam\u2019s I/O APIs to DoFns enabling modularity while maintaining the\n+performance of traditional I/O connectors.\n+\n+### 12.1 Splittable DoFn basics {#splittable-dofn-basics}\n+\n+At a high level, a splittable DoFn is responsible for processing element and restriction pairs. A\n+restriction represents a subset of work that would have been necessary to have been done when\n+processing the element.\n+\n+Executing a splittable DoFn follows the following steps:\n+\n+1. Each element is paired with a restriction (e.g. filename is paired with offset range representing the whole file).\n+2. Each element and restriction pair is split (e.g. offset ranges are broken up into smaller pieces).\n+3. The runner redistributes the element and restriction pairs to several workers.\n+4. Element and restriction pairs are processed in parallel (e.g. the file is read).\n+\n+![Diagram of steps that a splittable DoFn is composed of](/images/sdf_high_level_overview.svg)\n+\n+Within the last step, the element and restriction pair can pause its own processing and/or be split into\n+further element and restriction pairs. This last step is what enables I/O-like capabilities for DoFns.\n+\n+\n+#### 12.1.1 A basic splittable DoFn {#a-basic-splittable-dofn}\n+\n+A basic splittable DoFn is composed of three parts: a restriction, a restriction provider, and a\n+restriction tracker. The restriction is used to represent a subset of work for a given element.\n+The restriction provider lets SDF authors override default implementations for splitting, sizing,\n+watermark estimation, and so forth. In [Java](https://github.com/apache/beam/blob/f4c2734261396858e388ebef2eef50e7d48231a8/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/DoFn.java#L92)\n+and [Go](https://github.com/apache/beam/blob/0f466e6bcd4ac8677c2bd9ecc8e6af3836b7f3b8/sdks/go/pkg/beam/pardo.go#L226),\n+this is the DoFn. [Python](https://github.com/apache/beam/blob/f4c2734261396858e388ebef2eef50e7d48231a8/sdks/python/apache_beam/transforms/core.py#L213)\n+has a dedicated RestrictionProvider type. The restriction tracker is responsible for tracking\n+what subset of the restriction has been completed during processing.\n+\n+To define a splittable DoFn, you must choose whether the splittable DoFn is bounded (default) or\n+unbounded and define a way to initialize an initial restriction for an element.\n+\n+{{< highlight java >}}\n+{{< code_sample \"examples/java/src/main/java/org/apache/beam/examples/snippets/Snippets.java\" SDF_BasicExample >}}\n+{{< /highlight >}}\n+\n+{{< highlight py >}}\n+{{< code_sample \"sdks/python/apache_beam/examples/snippets/snippets.py\" SDF_BasicExample >}}\n+{{< /highlight >}}\n+\n+{{< highlight go >}}\n+func (fn *splittableDoFn) CreateInitialRestriction(filename string) offsetrange.Restriction {\n+\treturn offsetrange.Restriction{\n+\t\tStart: 0,\n+\t\tEnd:   getFileLength(filename),\n+\t}\n+}\n+\n+func (fn *splittableDoFn) CreateTracker(rest offsetrange.Restriction) *sdf.LockRTracker {\n+\treturn sdf.NewLockRTracker(offsetrange.NewTracker(rest))\n+}\n+\n+func (fn *splittableDoFn) ProcessElement(rt *sdf.LockRTracker, filename string, emit func(int)) error {\n+            file, err := os.Open(filename)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\toffset, err := seekToNextRecordBoundaryInFile(file, rt.GetRestriction().(offsetrange.Restriction).Start)\n+\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tfor rt.TryClaim(offset) {\n+\t\trecord, newOffset := readNextRecord(file)\n+\t\temit(record)\n+\t\toffset = newOffset\n+\t}\n+\treturn nil\n+}\n+{{< /highlight >}}\n+\n+At this point, we have a splittable DoFn that supports [runner-initiated splits](#runner-initiated-split)\n+enabling dynamic work rebalancing. To increase the rate at which initial parallelization of work occurs\n+or for those runners that do not support runner-initiated splitting, we recommend providing\n+a set of initial splits:\n+\n+{{< highlight java >}}\n+{{< code_sample \"examples/java/src/main/java/org/apache/beam/examples/snippets/Snippets.java\" SDF_BasicExampleWithSplitting >}}\n+{{< /highlight >}}\n+\n+{{< highlight py >}}\n+{{< code_sample \"sdks/python/apache_beam/examples/snippets/snippets.py\" SDF_BasicExampleWithSplitting >}}\n+{{< /highlight >}}\n+\n+{{< highlight go >}}\n+func (fn *splittableDoFn) SplitRestriction(filename string, rest offsetrange.Restriction) (splits []offsetrange.Restriction) {\n+\tsize := 64 * (1 << 20)\n+\ti := rest.Start\n+\tfor i < rest.End - size {\n+\t\t// Compute and output 64 MiB size ranges to process in parallel\n+\t\tend := i + size\n+     \t\tsplits = append(splits, offsetrange.Restriction{i, end})\n+\t\ti = end\n+\t}\n+\t// Output the last range\n+\tsplits = append(splits, offsetrange.Restriction{i, rest.End})\n+\treturn splits\n+}\n+{{< /highlight >}}\n+\n+### 12.2 Sizing and progress {#sizing-and-progress}\n+\n+Sizing and progress are used during execution of a splittable DoFn to inform runners so that they may\n+perform intelligent decisions about which restrictions to split and how to parallelize work.\n+\n+Before processing an element and restriction, an initial size may be used by a runner to choose\n+how and who processes the restrictions attempting to improve initial balancing and parallelization\n+of work. During the processing of an element and restriction, sizing and progress are used to choose\n+which restrictions to split and who should process them.\n+\n+By default, we use the restriction tracker\u2019s estimate for work remaining falling back to assuming\n+that all restrictions have an equal cost. To override the default, SDF authors can provide the\n+appropriate method within the restriction provider.\n+\n+{{< highlight java >}}\n+{{< code_sample \"examples/java/src/main/java/org/apache/beam/examples/snippets/Snippets.java\" SDF_GetSize >}}\n+{{< /highlight >}}\n+\n+{{< highlight py >}}\n+{{< code_sample \"sdks/python/apache_beam/examples/snippets/snippets.py\" SDF_GetSize >}}\n+{{< /highlight >}}\n+\n+{{< highlight go >}}\n+func (fn *splittableDoFn) RestrictionSize(filename string, rest offsetrange.Restriction) float64 {\n+\tweight := float64(1)\n+\tif strings.Contains(filename, \u201cexpensiveRecords\u201d) {\n+\t\tweight = 2\n+\t}\n+\treturn weight * rest.Size()\n+}\n+{{< /highlight >}}\n+\n+### 12.3 User initiated checkpoint {#user-initiated-checkpoint}\n+\n+Some I/Os cannot produce all of the data necessary to complete a restriction within the lifetime of a\n+single bundle. This typically happens with unbounded restrictions, but can also happen with bounded\n+restrictions. For example, there could be more data that needs to be ingested but is not available yet.\n+Another cause of this scenario is the source system throttling your data.\n+\n+Your splittable DoFn can signal to you that you are not done processing the current restriction. This\n+signal can suggest a time to resume at. While the runner tries to honor the resume time, this is not\n+guaranteed. This allows execution to continue on a restriction that has available work improving\n+resource utilization.\n+\n+{{< highlight java >}}\n+{{< code_sample \"examples/java/src/main/java/org/apache/beam/examples/snippets/Snippets.java\" SDF_UserInitiatedCheckpoint >}}\n+{{< /highlight >}}\n+\n+{{< highlight py >}}\n+{{< code_sample \"sdks/python/apache_beam/examples/snippets/snippets.py\" SDF_UserInitiatedCheckpoint >}}\n+{{< /highlight >}}\n+\n+### 12.4 Runner-initiated split {#runner-initiated-split}\n+\n+A runner at any time may attempt to split a restriction while it is being processed. This allows the\n+runner to either pause processing of the restriction so that other work may be done (common for\n+unbounded restrictions to limit the amount of output and/or improve latency) or split the restriction\n+into two pieces, increasing the available parallelism within the system. It is important to author a\n+splittable DoFn with this in mind since the end of the restriction may change. Thus when writing the\n+processing loop, it is important to use the result from trying to claim a piece of the restriction\n+instead of assuming one can process till the end.\n+\n+{{< highlight java >}}\n+{{< code_sample \"examples/java/src/main/java/org/apache/beam/examples/snippets/Snippets.java\" SDF_BadTryClaimLoop >}}\n+{{< /highlight >}}\n+\n+{{< highlight py >}}\n+{{< code_sample \"sdks/python/apache_beam/examples/snippets/snippets.py\" SDF_BadTryClaimLoop >}}\n+{{< /highlight >}}\n+\n+{{< highlight go >}}\n+func (fn *badTryClaimLoop) ProcessElement(rt *sdf.LockRTracker, filename string, emit func(int)) error {\n+            file, err := os.Open(filename)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\toffset, err := seekToNextRecordBoundaryInFile(file, rt.GetRestriction().(offsetrange.Restriction).Start)\n+\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// The restriction tracker can be modified by another thread in parallel\n+\t// so storing state locally is ill advised.\n+\tend = rt.GetRestriction().(offsetrange.Restriction).End\n+\tfor offset < end {\n+\t\t// Only after successfully claiming should we produce any output and/or\n+\t\t// perform side effects.\n+    \trt.TryClaim(offset)\n+\t\trecord, newOffset := readNextRecord(file)\n+\t\temit(record)\n+\t\toffset = newOffset\n+\t}\n+\treturn nil\n+}\n+{{< /highlight >}}\n+\n+### 12.5 Watermark estimation {#watermark-estimation}\n+\n+The default watermark estimator does not produce a watermark estimate. Therefore, the output watermark\n+is solely computed by the minimum of upstream watermarks.\n+\n+As a splittable DoFn pr an element and restriction pair, it can advance the output watermark by specifying", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "626366b189b7dee572bd92fdefc7b11b6f7b2d51"}, "originalPosition": 220}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE0OTM3MjU0", "url": "https://github.com/apache/beam/pull/13160#pullrequestreview-514937254", "createdAt": "2020-10-22T16:59:00Z", "commit": {"oid": "626366b189b7dee572bd92fdefc7b11b6f7b2d51"}, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQxNjo1OTowMFrOHmrV-A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQxNzo0NTo0MFrOHmtEsg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDMxODA3Mg==", "bodyText": "The class DoFn should be in code font when it's within the text. I see that this is inconsistently applied in the programming guide, but let's make the changes in at least this section. https://developers.google.com/style/code-in-text", "url": "https://github.com/apache/beam/pull/13160#discussion_r510318072", "createdAt": "2020-10-22T16:59:00Z", "author": {"login": "rosetn"}, "path": "website/www/site/content/en/documentation/programming-guide.md", "diffHunk": "@@ -5143,3 +5143,282 @@ perUser.apply(ParDo.of(new DoFn<KV<String, ValueT>, OutputT>() {\n   }\n }));\n {{< /highlight >}}\n+\n+## 12 Splittable DoFns {#splittable-dofns}\n+\n+Splittable DoFns (SDFs) enable users to create modular components containing I/Os (and some advanced\n+[non I/O use cases](https://s.apache.org/splittable-do-fn#heading=h.5cep9s8k4fxv)). Having modular\n+I/O components that can be connected to each other simplify typical patterns that users want.\n+For example, a popular use case is to read filenames from a message queue followed by parsing those\n+files. Traditionally users were required to either write a single I/O connector that contained the\n+logic for the message queue and the file reader (increased complexity) or choose to reuse a message\n+queue I/O followed by a regular DoFn that read the file (decreased performance). With splittable DoFns,\n+we bring the richness of Apache Beam\u2019s I/O APIs to DoFns enabling modularity while maintaining the\n+performance of traditional I/O connectors.\n+\n+### 12.1 Splittable DoFn basics {#splittable-dofn-basics}\n+\n+At a high level, a splittable DoFn is responsible for processing element and restriction pairs. A\n+restriction represents a subset of work that would have been necessary to have been done when\n+processing the element.\n+\n+Executing a splittable DoFn follows the following steps:\n+\n+1. Each element is paired with a restriction (e.g. filename is paired with offset range representing the whole file).\n+2. Each element and restriction pair is split (e.g. offset ranges are broken up into smaller pieces).\n+3. The runner redistributes the element and restriction pairs to several workers.\n+4. Element and restriction pairs are processed in parallel (e.g. the file is read).\n+\n+![Diagram of steps that a splittable DoFn is composed of](/images/sdf_high_level_overview.svg)\n+\n+Within the last step, the element and restriction pair can pause its own processing and/or be split into\n+further element and restriction pairs. This last step is what enables I/O-like capabilities for DoFns.\n+\n+\n+#### 12.1.1 A basic splittable DoFn {#a-basic-splittable-dofn}\n+\n+A basic splittable DoFn is composed of three parts: a restriction, a restriction provider, and a", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "626366b189b7dee572bd92fdefc7b11b6f7b2d51"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDMyMTYyMw==", "bodyText": "Missing period\n12. Splittable DoFns {#splittable-dofns}", "url": "https://github.com/apache/beam/pull/13160#discussion_r510321623", "createdAt": "2020-10-22T17:04:50Z", "author": {"login": "rosetn"}, "path": "website/www/site/content/en/documentation/programming-guide.md", "diffHunk": "@@ -5143,3 +5143,282 @@ perUser.apply(ParDo.of(new DoFn<KV<String, ValueT>, OutputT>() {\n   }\n }));\n {{< /highlight >}}\n+\n+## 12 Splittable DoFns {#splittable-dofns}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "626366b189b7dee572bd92fdefc7b11b6f7b2d51"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDMyMzcyNg==", "bodyText": "Add comma\nTraditionally, users", "url": "https://github.com/apache/beam/pull/13160#discussion_r510323726", "createdAt": "2020-10-22T17:08:17Z", "author": {"login": "rosetn"}, "path": "website/www/site/content/en/documentation/programming-guide.md", "diffHunk": "@@ -5143,3 +5143,282 @@ perUser.apply(ParDo.of(new DoFn<KV<String, ValueT>, OutputT>() {\n   }\n }));\n {{< /highlight >}}\n+\n+## 12 Splittable DoFns {#splittable-dofns}\n+\n+Splittable DoFns (SDFs) enable users to create modular components containing I/Os (and some advanced\n+[non I/O use cases](https://s.apache.org/splittable-do-fn#heading=h.5cep9s8k4fxv)). Having modular\n+I/O components that can be connected to each other simplify typical patterns that users want.\n+For example, a popular use case is to read filenames from a message queue followed by parsing those\n+files. Traditionally users were required to either write a single I/O connector that contained the", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "626366b189b7dee572bd92fdefc7b11b6f7b2d51"}, "originalPosition": 11}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDM0NDk3MA==", "bodyText": "Can you add more explanation to the \"Checkpoint/split\" bubble in the diagram on this list?", "url": "https://github.com/apache/beam/pull/13160#discussion_r510344970", "createdAt": "2020-10-22T17:43:24Z", "author": {"login": "rosetn"}, "path": "website/www/site/content/en/documentation/programming-guide.md", "diffHunk": "@@ -5143,3 +5143,282 @@ perUser.apply(ParDo.of(new DoFn<KV<String, ValueT>, OutputT>() {\n   }\n }));\n {{< /highlight >}}\n+\n+## 12 Splittable DoFns {#splittable-dofns}\n+\n+Splittable DoFns (SDFs) enable users to create modular components containing I/Os (and some advanced\n+[non I/O use cases](https://s.apache.org/splittable-do-fn#heading=h.5cep9s8k4fxv)). Having modular\n+I/O components that can be connected to each other simplify typical patterns that users want.\n+For example, a popular use case is to read filenames from a message queue followed by parsing those\n+files. Traditionally users were required to either write a single I/O connector that contained the\n+logic for the message queue and the file reader (increased complexity) or choose to reuse a message\n+queue I/O followed by a regular DoFn that read the file (decreased performance). With splittable DoFns,\n+we bring the richness of Apache Beam\u2019s I/O APIs to DoFns enabling modularity while maintaining the\n+performance of traditional I/O connectors.\n+\n+### 12.1 Splittable DoFn basics {#splittable-dofn-basics}\n+\n+At a high level, a splittable DoFn is responsible for processing element and restriction pairs. A\n+restriction represents a subset of work that would have been necessary to have been done when\n+processing the element.\n+\n+Executing a splittable DoFn follows the following steps:\n+\n+1. Each element is paired with a restriction (e.g. filename is paired with offset range representing the whole file).\n+2. Each element and restriction pair is split (e.g. offset ranges are broken up into smaller pieces).\n+3. The runner redistributes the element and restriction pairs to several workers.\n+4. Element and restriction pairs are processed in parallel (e.g. the file is read).", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "626366b189b7dee572bd92fdefc7b11b6f7b2d51"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDM0NTM4OQ==", "bodyText": "You can leave \"SDF\" in normal font", "url": "https://github.com/apache/beam/pull/13160#discussion_r510345389", "createdAt": "2020-10-22T17:44:02Z", "author": {"login": "rosetn"}, "path": "website/www/site/content/en/documentation/programming-guide.md", "diffHunk": "@@ -5143,3 +5143,282 @@ perUser.apply(ParDo.of(new DoFn<KV<String, ValueT>, OutputT>() {\n   }\n }));\n {{< /highlight >}}\n+\n+## 12 Splittable DoFns {#splittable-dofns}\n+\n+Splittable DoFns (SDFs) enable users to create modular components containing I/Os (and some advanced\n+[non I/O use cases](https://s.apache.org/splittable-do-fn#heading=h.5cep9s8k4fxv)). Having modular\n+I/O components that can be connected to each other simplify typical patterns that users want.\n+For example, a popular use case is to read filenames from a message queue followed by parsing those\n+files. Traditionally users were required to either write a single I/O connector that contained the\n+logic for the message queue and the file reader (increased complexity) or choose to reuse a message\n+queue I/O followed by a regular DoFn that read the file (decreased performance). With splittable DoFns,\n+we bring the richness of Apache Beam\u2019s I/O APIs to DoFns enabling modularity while maintaining the\n+performance of traditional I/O connectors.\n+\n+### 12.1 Splittable DoFn basics {#splittable-dofn-basics}\n+\n+At a high level, a splittable DoFn is responsible for processing element and restriction pairs. A\n+restriction represents a subset of work that would have been necessary to have been done when\n+processing the element.\n+\n+Executing a splittable DoFn follows the following steps:\n+\n+1. Each element is paired with a restriction (e.g. filename is paired with offset range representing the whole file).\n+2. Each element and restriction pair is split (e.g. offset ranges are broken up into smaller pieces).\n+3. The runner redistributes the element and restriction pairs to several workers.\n+4. Element and restriction pairs are processed in parallel (e.g. the file is read).\n+\n+![Diagram of steps that a splittable DoFn is composed of](/images/sdf_high_level_overview.svg)\n+\n+Within the last step, the element and restriction pair can pause its own processing and/or be split into\n+further element and restriction pairs. This last step is what enables I/O-like capabilities for DoFns.\n+\n+\n+#### 12.1.1 A basic splittable DoFn {#a-basic-splittable-dofn}\n+\n+A basic splittable DoFn is composed of three parts: a restriction, a restriction provider, and a", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDMxODA3Mg=="}, "originalCommit": {"oid": "626366b189b7dee572bd92fdefc7b11b6f7b2d51"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDM0NTg5Mg==", "bodyText": "User-initiated", "url": "https://github.com/apache/beam/pull/13160#discussion_r510345892", "createdAt": "2020-10-22T17:44:51Z", "author": {"login": "rosetn"}, "path": "website/www/site/content/en/documentation/programming-guide.md", "diffHunk": "@@ -5143,3 +5143,282 @@ perUser.apply(ParDo.of(new DoFn<KV<String, ValueT>, OutputT>() {\n   }\n }));\n {{< /highlight >}}\n+\n+## 12 Splittable DoFns {#splittable-dofns}\n+\n+Splittable DoFns (SDFs) enable users to create modular components containing I/Os (and some advanced\n+[non I/O use cases](https://s.apache.org/splittable-do-fn#heading=h.5cep9s8k4fxv)). Having modular\n+I/O components that can be connected to each other simplify typical patterns that users want.\n+For example, a popular use case is to read filenames from a message queue followed by parsing those\n+files. Traditionally users were required to either write a single I/O connector that contained the\n+logic for the message queue and the file reader (increased complexity) or choose to reuse a message\n+queue I/O followed by a regular DoFn that read the file (decreased performance). With splittable DoFns,\n+we bring the richness of Apache Beam\u2019s I/O APIs to DoFns enabling modularity while maintaining the\n+performance of traditional I/O connectors.\n+\n+### 12.1 Splittable DoFn basics {#splittable-dofn-basics}\n+\n+At a high level, a splittable DoFn is responsible for processing element and restriction pairs. A\n+restriction represents a subset of work that would have been necessary to have been done when\n+processing the element.\n+\n+Executing a splittable DoFn follows the following steps:\n+\n+1. Each element is paired with a restriction (e.g. filename is paired with offset range representing the whole file).\n+2. Each element and restriction pair is split (e.g. offset ranges are broken up into smaller pieces).\n+3. The runner redistributes the element and restriction pairs to several workers.\n+4. Element and restriction pairs are processed in parallel (e.g. the file is read).\n+\n+![Diagram of steps that a splittable DoFn is composed of](/images/sdf_high_level_overview.svg)\n+\n+Within the last step, the element and restriction pair can pause its own processing and/or be split into\n+further element and restriction pairs. This last step is what enables I/O-like capabilities for DoFns.\n+\n+\n+#### 12.1.1 A basic splittable DoFn {#a-basic-splittable-dofn}\n+\n+A basic splittable DoFn is composed of three parts: a restriction, a restriction provider, and a\n+restriction tracker. The restriction is used to represent a subset of work for a given element.\n+The restriction provider lets SDF authors override default implementations for splitting, sizing,\n+watermark estimation, and so forth. In [Java](https://github.com/apache/beam/blob/f4c2734261396858e388ebef2eef50e7d48231a8/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/DoFn.java#L92)\n+and [Go](https://github.com/apache/beam/blob/0f466e6bcd4ac8677c2bd9ecc8e6af3836b7f3b8/sdks/go/pkg/beam/pardo.go#L226),\n+this is the DoFn. [Python](https://github.com/apache/beam/blob/f4c2734261396858e388ebef2eef50e7d48231a8/sdks/python/apache_beam/transforms/core.py#L213)\n+has a dedicated RestrictionProvider type. The restriction tracker is responsible for tracking\n+what subset of the restriction has been completed during processing.\n+\n+To define a splittable DoFn, you must choose whether the splittable DoFn is bounded (default) or\n+unbounded and define a way to initialize an initial restriction for an element.\n+\n+{{< highlight java >}}\n+{{< code_sample \"examples/java/src/main/java/org/apache/beam/examples/snippets/Snippets.java\" SDF_BasicExample >}}\n+{{< /highlight >}}\n+\n+{{< highlight py >}}\n+{{< code_sample \"sdks/python/apache_beam/examples/snippets/snippets.py\" SDF_BasicExample >}}\n+{{< /highlight >}}\n+\n+{{< highlight go >}}\n+func (fn *splittableDoFn) CreateInitialRestriction(filename string) offsetrange.Restriction {\n+\treturn offsetrange.Restriction{\n+\t\tStart: 0,\n+\t\tEnd:   getFileLength(filename),\n+\t}\n+}\n+\n+func (fn *splittableDoFn) CreateTracker(rest offsetrange.Restriction) *sdf.LockRTracker {\n+\treturn sdf.NewLockRTracker(offsetrange.NewTracker(rest))\n+}\n+\n+func (fn *splittableDoFn) ProcessElement(rt *sdf.LockRTracker, filename string, emit func(int)) error {\n+            file, err := os.Open(filename)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\toffset, err := seekToNextRecordBoundaryInFile(file, rt.GetRestriction().(offsetrange.Restriction).Start)\n+\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tfor rt.TryClaim(offset) {\n+\t\trecord, newOffset := readNextRecord(file)\n+\t\temit(record)\n+\t\toffset = newOffset\n+\t}\n+\treturn nil\n+}\n+{{< /highlight >}}\n+\n+At this point, we have a splittable DoFn that supports [runner-initiated splits](#runner-initiated-split)\n+enabling dynamic work rebalancing. To increase the rate at which initial parallelization of work occurs\n+or for those runners that do not support runner-initiated splitting, we recommend providing\n+a set of initial splits:\n+\n+{{< highlight java >}}\n+{{< code_sample \"examples/java/src/main/java/org/apache/beam/examples/snippets/Snippets.java\" SDF_BasicExampleWithSplitting >}}\n+{{< /highlight >}}\n+\n+{{< highlight py >}}\n+{{< code_sample \"sdks/python/apache_beam/examples/snippets/snippets.py\" SDF_BasicExampleWithSplitting >}}\n+{{< /highlight >}}\n+\n+{{< highlight go >}}\n+func (fn *splittableDoFn) SplitRestriction(filename string, rest offsetrange.Restriction) (splits []offsetrange.Restriction) {\n+\tsize := 64 * (1 << 20)\n+\ti := rest.Start\n+\tfor i < rest.End - size {\n+\t\t// Compute and output 64 MiB size ranges to process in parallel\n+\t\tend := i + size\n+     \t\tsplits = append(splits, offsetrange.Restriction{i, end})\n+\t\ti = end\n+\t}\n+\t// Output the last range\n+\tsplits = append(splits, offsetrange.Restriction{i, rest.End})\n+\treturn splits\n+}\n+{{< /highlight >}}\n+\n+### 12.2 Sizing and progress {#sizing-and-progress}\n+\n+Sizing and progress are used during execution of a splittable DoFn to inform runners so that they may\n+perform intelligent decisions about which restrictions to split and how to parallelize work.\n+\n+Before processing an element and restriction, an initial size may be used by a runner to choose\n+how and who processes the restrictions attempting to improve initial balancing and parallelization\n+of work. During the processing of an element and restriction, sizing and progress are used to choose\n+which restrictions to split and who should process them.\n+\n+By default, we use the restriction tracker\u2019s estimate for work remaining falling back to assuming\n+that all restrictions have an equal cost. To override the default, SDF authors can provide the\n+appropriate method within the restriction provider.\n+\n+{{< highlight java >}}\n+{{< code_sample \"examples/java/src/main/java/org/apache/beam/examples/snippets/Snippets.java\" SDF_GetSize >}}\n+{{< /highlight >}}\n+\n+{{< highlight py >}}\n+{{< code_sample \"sdks/python/apache_beam/examples/snippets/snippets.py\" SDF_GetSize >}}\n+{{< /highlight >}}\n+\n+{{< highlight go >}}\n+func (fn *splittableDoFn) RestrictionSize(filename string, rest offsetrange.Restriction) float64 {\n+\tweight := float64(1)\n+\tif strings.Contains(filename, \u201cexpensiveRecords\u201d) {\n+\t\tweight = 2\n+\t}\n+\treturn weight * rest.Size()\n+}\n+{{< /highlight >}}\n+\n+### 12.3 User initiated checkpoint {#user-initiated-checkpoint}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "626366b189b7dee572bd92fdefc7b11b6f7b2d51"}, "originalPosition": 150}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDM0NjQxOA==", "bodyText": "Also add them for each header. This stopped in the last two sections, but we can keep it consistent with the rest of the programming guide here.", "url": "https://github.com/apache/beam/pull/13160#discussion_r510346418", "createdAt": "2020-10-22T17:45:40Z", "author": {"login": "rosetn"}, "path": "website/www/site/content/en/documentation/programming-guide.md", "diffHunk": "@@ -5143,3 +5143,282 @@ perUser.apply(ParDo.of(new DoFn<KV<String, ValueT>, OutputT>() {\n   }\n }));\n {{< /highlight >}}\n+\n+## 12 Splittable DoFns {#splittable-dofns}", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDMyMTYyMw=="}, "originalCommit": {"oid": "626366b189b7dee572bd92fdefc7b11b6f7b2d51"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE1MDA5NDkw", "url": "https://github.com/apache/beam/pull/13160#pullrequestreview-515009490", "createdAt": "2020-10-22T18:31:34Z", "commit": {"oid": "626366b189b7dee572bd92fdefc7b11b6f7b2d51"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQxODozMTozNVrOHmutNg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQxODozMTozNVrOHmutNg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDM3MzE3NA==", "bodyText": "Consider pointing out that with only the above example code, the restrictions don't currently do anything extra WRT the same DoFn without the restriction handling. It's a non-splittable-dofn with vestigial extras.  (there's probably a much better way to phrase this).", "url": "https://github.com/apache/beam/pull/13160#discussion_r510373174", "createdAt": "2020-10-22T18:31:35Z", "author": {"login": "lostluck"}, "path": "website/www/site/content/en/documentation/programming-guide.md", "diffHunk": "@@ -5143,3 +5143,282 @@ perUser.apply(ParDo.of(new DoFn<KV<String, ValueT>, OutputT>() {\n   }\n }));\n {{< /highlight >}}\n+\n+## 12 Splittable DoFns {#splittable-dofns}\n+\n+Splittable DoFns (SDFs) enable users to create modular components containing I/Os (and some advanced\n+[non I/O use cases](https://s.apache.org/splittable-do-fn#heading=h.5cep9s8k4fxv)). Having modular\n+I/O components that can be connected to each other simplify typical patterns that users want.\n+For example, a popular use case is to read filenames from a message queue followed by parsing those\n+files. Traditionally users were required to either write a single I/O connector that contained the\n+logic for the message queue and the file reader (increased complexity) or choose to reuse a message\n+queue I/O followed by a regular DoFn that read the file (decreased performance). With splittable DoFns,\n+we bring the richness of Apache Beam\u2019s I/O APIs to DoFns enabling modularity while maintaining the\n+performance of traditional I/O connectors.\n+\n+### 12.1 Splittable DoFn basics {#splittable-dofn-basics}\n+\n+At a high level, a splittable DoFn is responsible for processing element and restriction pairs. A\n+restriction represents a subset of work that would have been necessary to have been done when\n+processing the element.\n+\n+Executing a splittable DoFn follows the following steps:\n+\n+1. Each element is paired with a restriction (e.g. filename is paired with offset range representing the whole file).\n+2. Each element and restriction pair is split (e.g. offset ranges are broken up into smaller pieces).\n+3. The runner redistributes the element and restriction pairs to several workers.\n+4. Element and restriction pairs are processed in parallel (e.g. the file is read).\n+\n+![Diagram of steps that a splittable DoFn is composed of](/images/sdf_high_level_overview.svg)\n+\n+Within the last step, the element and restriction pair can pause its own processing and/or be split into\n+further element and restriction pairs. This last step is what enables I/O-like capabilities for DoFns.\n+\n+\n+#### 12.1.1 A basic splittable DoFn {#a-basic-splittable-dofn}\n+\n+A basic splittable DoFn is composed of three parts: a restriction, a restriction provider, and a\n+restriction tracker. The restriction is used to represent a subset of work for a given element.\n+The restriction provider lets SDF authors override default implementations for splitting, sizing,\n+watermark estimation, and so forth. In [Java](https://github.com/apache/beam/blob/f4c2734261396858e388ebef2eef50e7d48231a8/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/DoFn.java#L92)\n+and [Go](https://github.com/apache/beam/blob/0f466e6bcd4ac8677c2bd9ecc8e6af3836b7f3b8/sdks/go/pkg/beam/pardo.go#L226),\n+this is the DoFn. [Python](https://github.com/apache/beam/blob/f4c2734261396858e388ebef2eef50e7d48231a8/sdks/python/apache_beam/transforms/core.py#L213)\n+has a dedicated RestrictionProvider type. The restriction tracker is responsible for tracking\n+what subset of the restriction has been completed during processing.\n+\n+To define a splittable DoFn, you must choose whether the splittable DoFn is bounded (default) or\n+unbounded and define a way to initialize an initial restriction for an element.\n+\n+{{< highlight java >}}\n+{{< code_sample \"examples/java/src/main/java/org/apache/beam/examples/snippets/Snippets.java\" SDF_BasicExample >}}\n+{{< /highlight >}}\n+\n+{{< highlight py >}}\n+{{< code_sample \"sdks/python/apache_beam/examples/snippets/snippets.py\" SDF_BasicExample >}}\n+{{< /highlight >}}\n+\n+{{< highlight go >}}\n+func (fn *splittableDoFn) CreateInitialRestriction(filename string) offsetrange.Restriction {\n+\treturn offsetrange.Restriction{\n+\t\tStart: 0,\n+\t\tEnd:   getFileLength(filename),\n+\t}\n+}\n+\n+func (fn *splittableDoFn) CreateTracker(rest offsetrange.Restriction) *sdf.LockRTracker {\n+\treturn sdf.NewLockRTracker(offsetrange.NewTracker(rest))\n+}\n+\n+func (fn *splittableDoFn) ProcessElement(rt *sdf.LockRTracker, filename string, emit func(int)) error {\n+            file, err := os.Open(filename)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\toffset, err := seekToNextRecordBoundaryInFile(file, rt.GetRestriction().(offsetrange.Restriction).Start)\n+\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tfor rt.TryClaim(offset) {\n+\t\trecord, newOffset := readNextRecord(file)\n+\t\temit(record)\n+\t\toffset = newOffset\n+\t}\n+\treturn nil\n+}\n+{{< /highlight >}}\n+\n+At this point, we have a splittable DoFn that supports [runner-initiated splits](#runner-initiated-split)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "626366b189b7dee572bd92fdefc7b11b6f7b2d51"}, "originalPosition": 89}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bf59970c4297e1721bc4eb5d93e09c5e2569b87c", "author": {"user": {"login": "lukecwik", "name": "Lukasz Cwik"}}, "url": "https://github.com/apache/beam/commit/bf59970c4297e1721bc4eb5d93e09c5e2569b87c", "committedDate": "2020-10-22T19:20:12Z", "message": "Address PR comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE1MTU2NzM5", "url": "https://github.com/apache/beam/pull/13160#pullrequestreview-515156739", "createdAt": "2020-10-22T22:13:09Z", "commit": {"oid": "bf59970c4297e1721bc4eb5d93e09c5e2569b87c"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQyMjoxMzoxMFrOHm1tXA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQyMjoxMzoxMFrOHm1tXA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDQ4NzkwMA==", "bodyText": "Let's make these \"an SDF\"", "url": "https://github.com/apache/beam/pull/13160#discussion_r510487900", "createdAt": "2020-10-22T22:13:10Z", "author": {"login": "rosetn"}, "path": "website/www/site/content/en/documentation/programming-guide.md", "diffHunk": "@@ -5143,3 +5143,281 @@ perUser.apply(ParDo.of(new DoFn<KV<String, ValueT>, OutputT>() {\n   }\n }));\n {{< /highlight >}}\n+\n+## 12. Splittable `DoFns` {#splittable-dofns}\n+\n+A Splittable `DoFn` (SDF) enables users to create modular components containing I/Os (and some advanced\n+[non I/O use cases](https://s.apache.org/splittable-do-fn#heading=h.5cep9s8k4fxv)). Having modular\n+I/O components that can be connected to each other simplify typical patterns that users want.\n+For example, a popular use case is to read filenames from a message queue followed by parsing those\n+files. Traditionally, users were required to either write a single I/O connector that contained the\n+logic for the message queue and the file reader (increased complexity) or choose to reuse a message\n+queue I/O followed by a regular `DoFn` that read the file (decreased performance). With SDF,\n+we bring the richness of Apache Beam\u2019s I/O APIs to a `DoFn` enabling modularity while maintaining the\n+performance of traditional I/O connectors.\n+\n+### 12.1. SDF basics {#sdf-basics}\n+\n+At a high level, a SDF is responsible for processing element and restriction pairs. A", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bf59970c4297e1721bc4eb5d93e09c5e2569b87c"}, "originalPosition": 19}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ac8f773b096565ccf4eb95fb94e6e9b5ce947d14", "author": {"user": {"login": "lukecwik", "name": "Lukasz Cwik"}}, "url": "https://github.com/apache/beam/commit/ac8f773b096565ccf4eb95fb94e6e9b5ce947d14", "committedDate": "2020-10-22T22:16:56Z", "message": "Replace 'a SDF' with 'an SDF'"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2158, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}