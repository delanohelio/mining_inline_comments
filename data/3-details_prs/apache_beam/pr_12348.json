{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDU1NDYyMzAx", "number": 12348, "title": "[BEAM-10240] Support ZetaSQL DATETIME functions in BeamSQL", "bodyText": "This PR adds support of all ZetaSQL DATETIME functions to BeamSQL:\n\nCURRENT_DATETIME\nEXTRACT\nDATETIME\nDATETIME_ADD\nDATETIME_SUB\nDATETIME_DIFF\nDATETIME_TRUNC\nFORMAT_DATETIME\nPARSE_DATETIME\n\nDATE_FROM_DATETIME(), TIME_FROM_DATETIME(), TIMESTAMP_FROM_DATETIME() and EXTRACT_DATETIME_FROM_TIMESTAMP are also supported.\nr: @apilloud @robinyqiu\n\nThank you for your contribution! Follow this checklist to help us incorporate your contribution quickly and easily:\n\n Choose reviewer(s) and mention them in a comment (R: @username).\n Format the pull request title like [BEAM-XXX] Fixes bug in ApproximateQuantiles, where you replace BEAM-XXX with the appropriate JIRA issue, if applicable. This will automatically link the pull request to the issue.\n Update CHANGES.md with noteworthy changes.\n If this contribution is large, please file an Apache Individual Contributor License Agreement.\n\nSee the Contributor Guide for more tips on how to make review process smoother.\nPost-Commit Tests Status (on master branch)\n\n\n\nLang\nSDK\nDataflow\nFlink\nSamza\nSpark\nTwister2\n\n\n\n\nGo\n\n---\n\n---\n\n---\n\n\nJava\n\n\n\n\n\n\n\n\nPython\n\n\n\n---\n\n---\n\n\nXLang\n\n---\n\n---\n\n---\n\n\n\nPre-Commit Tests Status (on master branch)\n\n\n\n---\nJava\nPython\nGo\nWebsite\n\n\n\n\nNon-portable\n\n\n\n\n\n\nPortable\n---\n\n---\n---\n\n\n\nSee .test-infra/jenkins/README for trigger phrase, status and link of all Jenkins jobs.", "createdAt": "2020-07-23T03:36:33Z", "url": "https://github.com/apache/beam/pull/12348", "merged": true, "mergeCommit": {"oid": "e3e2989b6c10361a752a0463efbdb152d690a451"}, "closed": true, "closedAt": "2020-08-06T18:20:42Z", "author": {"login": "ZijieSong946"}, "timelineItems": {"totalCount": 23, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc3m81_AH2gAyNDU1NDYyMzAxOmUyZTViNDc0MGRhZTRlNjk4OGNhNTlmNzJmMTYwZWMwYjA4M2ZhNGY=", "endCursor": "Y3Vyc29yOnYyOpPPAAABc8S1SZAH2gAyNDU1NDYyMzAxOjM3ZTkyMGIxOWM5YTQxYjk4MDE1NmQwZTc2ZjRiNTg2NjczNTcyNDA=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "e2e5b4740dae4e6988ca59f72f160ec0b083fa4f", "author": {"user": {"login": "ZijieSong946", "name": "Zijie Song"}}, "url": "https://github.com/apache/beam/commit/e2e5b4740dae4e6988ca59f72f160ec0b083fa4f", "committedDate": "2020-07-23T03:34:46Z", "message": "DateTime functions update."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1d377702e2c1b7bdada4325bf1f51cad85aed38d", "author": {"user": {"login": "ZijieSong946", "name": "Zijie Song"}}, "url": "https://github.com/apache/beam/commit/1d377702e2c1b7bdada4325bf1f51cad85aed38d", "committedDate": "2020-07-27T05:23:04Z", "message": "Draft version."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "121b0b6dc80a5e3eb5eb190a9bd92c0d54ae95ab", "author": {"user": {"login": "ZijieSong946", "name": "Zijie Song"}}, "url": "https://github.com/apache/beam/commit/121b0b6dc80a5e3eb5eb190a9bd92c0d54ae95ab", "committedDate": "2020-07-27T23:12:42Z", "message": "Draft version."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d", "author": {"user": {"login": "ZijieSong946", "name": "Zijie Song"}}, "url": "https://github.com/apache/beam/commit/2d28bf0299f8a2e920311da06c3c936d311c605d", "committedDate": "2020-07-28T20:36:43Z", "message": "Beam tests passed for DateTime type."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU3MDE2NTIw", "url": "https://github.com/apache/beam/pull/12348#pullrequestreview-457016520", "createdAt": "2020-07-28T21:12:04Z", "commit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d"}, "state": "COMMENTED", "comments": {"totalCount": 13, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQyMToxMjowNFrOG4fD_w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQyMzoyMToyM1rOG4jFFQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTg4MjM2Nw==", "bodyText": "This should be a constant (make static and use upper-case name like DATETIME_SCHEMA)", "url": "https://github.com/apache/beam/pull/12348#discussion_r461882367", "createdAt": "2020-07-28T21:12:04Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/logicaltypes/DateTime.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.schemas.logicaltypes;\n+\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.values.Row;\n+\n+/**\n+ * A datetime without a time-zone.\n+ *\n+ * <p>It cannot represent an instant on the time-line without additional information such as an\n+ * offset or time-zone.\n+ *\n+ * <p>Its input type is a {@link LocalDateTime}, and base type is a {@link Row} containing Date\n+ * field and Time field. Date field is a Long that represents incrementing count of days where day 0\n+ * is 1970-01-01 (ISO). Time field is a Long that represents a count of time in nanoseconds.\n+ */\n+public class DateTime implements Schema.LogicalType<LocalDateTime, Row> {\n+  private final Schema schema =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTg4NDM2Ng==", "bodyText": "\"Date\" and \"Time\" are also used below. We should make them constants as well.", "url": "https://github.com/apache/beam/pull/12348#discussion_r461884366", "createdAt": "2020-07-28T21:16:01Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/logicaltypes/DateTime.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.schemas.logicaltypes;\n+\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.values.Row;\n+\n+/**\n+ * A datetime without a time-zone.\n+ *\n+ * <p>It cannot represent an instant on the time-line without additional information such as an\n+ * offset or time-zone.\n+ *\n+ * <p>Its input type is a {@link LocalDateTime}, and base type is a {@link Row} containing Date\n+ * field and Time field. Date field is a Long that represents incrementing count of days where day 0\n+ * is 1970-01-01 (ISO). Time field is a Long that represents a count of time in nanoseconds.\n+ */\n+public class DateTime implements Schema.LogicalType<LocalDateTime, Row> {\n+  private final Schema schema =\n+      Schema.builder().addInt64Field(\"Date\").addInt64Field(\"Time\").build();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTg4NTM2Mw==", "bodyText": "I would mention these 2 longs are the same as the base types of Date and Time.", "url": "https://github.com/apache/beam/pull/12348#discussion_r461885363", "createdAt": "2020-07-28T21:18:03Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/logicaltypes/DateTime.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.schemas.logicaltypes;\n+\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.values.Row;\n+\n+/**\n+ * A datetime without a time-zone.\n+ *\n+ * <p>It cannot represent an instant on the time-line without additional information such as an\n+ * offset or time-zone.\n+ *\n+ * <p>Its input type is a {@link LocalDateTime}, and base type is a {@link Row} containing Date\n+ * field and Time field. Date field is a Long that represents incrementing count of days where day 0\n+ * is 1970-01-01 (ISO). Time field is a Long that represents a count of time in nanoseconds.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTkyNjkxMg==", "bodyText": "CalciteSQL does not have a DATETIME type. I think we don't need to mention CalciteSQL here.", "url": "https://github.com/apache/beam/pull/12348#discussion_r461926912", "createdAt": "2020-07-28T22:22:12Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/logicaltypes/SqlTypes.java", "diffHunk": "@@ -31,4 +33,7 @@ private SqlTypes() {}\n \n   /** Beam LogicalType corresponding to ZetaSQL/CalciteSQL TIME type. */\n   public static final LogicalType<LocalTime, Long> TIME = new Time();\n+\n+  /** Beam LogicalType corresponding to ZetaSQL/CalciteSQL DATETIME type. */", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTkzMDI2MQ==", "bodyText": "Could you implement the support for this and add a test as well?", "url": "https://github.com/apache/beam/pull/12348#discussion_r461930261", "createdAt": "2020-07-28T22:31:05Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/SupportedZetaSqlBuiltinFunctions.java", "diffHunk": "@@ -258,23 +257,23 @@\n \n           // Signatures specific to extracting the DATE date part from a DATETIME or a\n           // TIMESTAMP.\n-          // FunctionSignatureId.FN_EXTRACT_DATE_FROM_DATETIME, // $extract_date\n+          FunctionSignatureId.FN_EXTRACT_DATE_FROM_DATETIME, // $extract_date\n           FunctionSignatureId.FN_EXTRACT_DATE_FROM_TIMESTAMP, // $extract_date\n \n           // Signatures specific to extracting the TIME date part from a DATETIME or a\n           // TIMESTAMP.\n-          // FunctionSignatureId.FN_EXTRACT_TIME_FROM_DATETIME, // $extract_time\n+          FunctionSignatureId.FN_EXTRACT_TIME_FROM_DATETIME, // $extract_time\n           FunctionSignatureId.FN_EXTRACT_TIME_FROM_TIMESTAMP, // $extract_time\n \n           // Signature specific to extracting the DATETIME date part from a TIMESTAMP.\n           // FunctionSignatureId.FN_EXTRACT_DATETIME_FROM_TIMESTAMP, // $extract_datetime", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTkzODQ2NQ==", "bodyText": "Internally we have a Value.createDatetimeValue() method that takes a Java LocalDateTime. I think that is what we want here. But we don't have it now because it has not been open-sourced to ZetaSQL.\n(This is not a comment, but a note to ourselves.)", "url": "https://github.com/apache/beam/pull/12348#discussion_r461938465", "createdAt": "2020-07-28T22:52:44Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/ZetaSqlBeamTranslationUtils.java", "diffHunk": "@@ -184,6 +188,19 @@ private static Value beamLogicalObjectToZetaSqlValue(Object object, String ident\n       } else { // input type\n         return Value.createTimeValue(CivilTimeEncoder.encodePacked64TimeNanos((LocalTime) object));\n       }\n+    } else if (SqlTypes.DATETIME.getIdentifier().equals(identifier)) {\n+      // DateTime value\n+      LocalDateTime datetime;\n+      if (object instanceof Row) { // base type\n+        datetime =\n+            LocalDateTime.of(\n+                LocalDate.ofEpochDay(((Row) object).getValue(\"Date\")),\n+                LocalTime.ofNanoOfDay(((Row) object).getValue(\"Time\")));\n+      } else { // input type\n+        datetime = (LocalDateTime) object;\n+      }\n+      return Value.createDatetimeValue(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk0MTQyNw==", "bodyText": "You don't need to create a list here. I think there is another overload of this function that takes a single operand.", "url": "https://github.com/apache/beam/pull/12348#discussion_r461941427", "createdAt": "2020-07-28T23:01:01Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/translation/ExpressionConverter.java", "diffHunk": "@@ -850,6 +852,38 @@ private RexNode convertSimpleValueToRexNode(TypeKind kind, Value value) {\n         // TODO: Doing micro to mills truncation, need to throw exception.\n         ret = rexBuilder().makeLiteral(convertTimeValueToTimeString(value), timeType, false);\n         break;\n+      case TYPE_DATETIME:\n+        // Cannot simply call makeTimestampWithLocalTimeZoneLiteral() for ZetaSQL DATETIME type\n+        // because later it will be unparsed to the string representation of timestamp (e.g. \"SELECT\n+        // DATETIME '2008-12-25 15:30:00'\" will be unparsed to \"SELECT TIMESTAMP '2008-12-25\n+        // 15:30:00:000000'\"). So we create a wrapper function here such that we can later recognize\n+        // it and customize its unparsing in BeamBigQuerySqlDialect.\n+        LocalDateTime dateTime =\n+            CivilTimeEncoder.decodePacked96DatetimeNanosAsJavaTime(value.getDatetimeValue());\n+        TimestampString tsString =\n+            new TimestampString(\n+                    dateTime.getYear(),\n+                    dateTime.getMonthValue(),\n+                    dateTime.getDayOfMonth(),\n+                    dateTime.getHour(),\n+                    dateTime.getMinute(),\n+                    dateTime.getSecond())\n+                .withNanos(dateTime.getNano());\n+\n+        ret =\n+            rexBuilder()\n+                .makeCall(\n+                    SqlOperators.createZetaSqlFunction(\n+                        BeamBigQuerySqlDialect.DATETIME_LITERAL_FUNCTION,\n+                        ZetaSqlCalciteTranslationUtils.toCalciteTypeName(kind)),\n+                    ImmutableList.of(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk0MzIzOQ==", "bodyText": "Could you make a convertDateTimeValueToTimeString helper method in DateTimeUtils like we did for Date and Time?", "url": "https://github.com/apache/beam/pull/12348#discussion_r461943239", "createdAt": "2020-07-28T23:06:34Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/translation/ExpressionConverter.java", "diffHunk": "@@ -850,6 +852,38 @@ private RexNode convertSimpleValueToRexNode(TypeKind kind, Value value) {\n         // TODO: Doing micro to mills truncation, need to throw exception.\n         ret = rexBuilder().makeLiteral(convertTimeValueToTimeString(value), timeType, false);\n         break;\n+      case TYPE_DATETIME:\n+        // Cannot simply call makeTimestampWithLocalTimeZoneLiteral() for ZetaSQL DATETIME type\n+        // because later it will be unparsed to the string representation of timestamp (e.g. \"SELECT\n+        // DATETIME '2008-12-25 15:30:00'\" will be unparsed to \"SELECT TIMESTAMP '2008-12-25\n+        // 15:30:00:000000'\"). So we create a wrapper function here such that we can later recognize\n+        // it and customize its unparsing in BeamBigQuerySqlDialect.\n+        LocalDateTime dateTime =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk0NTM2NA==", "bodyText": "Could you please rename all WTH with WITH by the way? Thanks!", "url": "https://github.com/apache/beam/pull/12348#discussion_r461945364", "createdAt": "2020-07-28T23:12:54Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/zetasql/src/test/java/org/apache/beam/sdk/extensions/sql/zetasql/TestInput.java", "diffHunk": "@@ -260,12 +261,24 @@\n \n   private static final Schema TABLE_WTH_NUMERIC_SCHEMA =\n       Schema.builder().addDecimalField(\"numeric_field\").addStringField(\"str_field\").build();\n+\n   public static final TestBoundedTable TABLE_WITH_NUMERIC =\n       TestBoundedTable.of(TABLE_WTH_NUMERIC_SCHEMA)\n           .addRows(ZetaSqlTypesUtils.bigDecimalAsNumeric(\"123.4567\"), \"str1\")\n           .addRows(ZetaSqlTypesUtils.bigDecimalAsNumeric(\"765.4321\"), \"str2\")\n           .addRows(ZetaSqlTypesUtils.bigDecimalAsNumeric(\"-555.5555\"), \"str3\");\n \n+  private static final Schema TABLE_WTH_DATETIME_SCHEMA =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk0NTk3Ng==", "bodyText": "else if to be consistent?", "url": "https://github.com/apache/beam/pull/12348#discussion_r461945976", "createdAt": "2020-07-28T23:14:47Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/bigquery/BeamBigQuerySqlDialect.java", "diffHunk": "@@ -166,6 +168,12 @@ public void unparseCall(\n         break;\n       case OTHER_FUNCTION:\n         String funName = call.getOperator().getName();\n+        if (DATETIME_LITERAL_FUNCTION.equals(funName)) {\n+          // self-designed function dealing with the unparsing of ZetaSQL DATETIME literal, to\n+          // differentiate it from ZetaSQL TIMESTAMP literal\n+          unparseDateTimeLiteralWrapperFunction(writer, call, leftPrec, rightPrec);\n+          break;\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk0NzA0OQ==", "bodyText": "I would recommend using replace (replace TIMESTAMP with DATETIME) here instead of substring. I think that's more readable.", "url": "https://github.com/apache/beam/pull/12348#discussion_r461947049", "createdAt": "2020-07-28T23:17:59Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/bigquery/BeamBigQuerySqlDialect.java", "diffHunk": "@@ -253,6 +261,12 @@ private void unparseTrim(SqlWriter writer, SqlCall call, int leftPrec, int right\n     writer.endFunCall(trimFrame);\n   }\n \n+  private void unparseDateTimeLiteralWrapperFunction(\n+      SqlWriter writer, SqlCall call, int leftPrec, int rightPrec) {\n+    writer.literal(\"DATETIME\");\n+    writer.literal(call.operand(0).toString().substring(DATETIME_LITERAL_OFFSET));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk0NzUxNA==", "bodyText": "Use DATETIME with micro-second component to be more generic (same below)?", "url": "https://github.com/apache/beam/pull/12348#discussion_r461947514", "createdAt": "2020-07-28T23:19:26Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/zetasql/src/test/java/org/apache/beam/sdk/extensions/sql/zetasql/ZetaSqlTimeFunctionsTest.java", "diffHunk": "@@ -218,6 +219,22 @@ public void testDateFromTimestamp() {\n     pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n   }\n \n+  @Test\n+  public void testDateFromDateTime() {\n+    String sql = \"SELECT DATE(DATETIME '2008-12-25 15:30:00')\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk0ODE4MQ==", "bodyText": "Choose time component here to format as well?", "url": "https://github.com/apache/beam/pull/12348#discussion_r461948181", "createdAt": "2020-07-28T23:21:23Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/zetasql/src/test/java/org/apache/beam/sdk/extensions/sql/zetasql/ZetaSqlTimeFunctionsTest.java", "diffHunk": "@@ -753,13 +786,415 @@ public void testParseTime() {\n   /////////////////////////////////////////////////////////////////////////////\n \n   @Test\n-  @Ignore(\"Does not support Datetime literal.\")\n-  public void testDatetimeLiteral() {\n-    String sql = \"SELECT DATETIME '2018-01-01 05:30:00.334'\";\n+  public void testDateTimeLiteral() {\n+    String sql = \"SELECT DATETIME '2008-12-25 15:30:00'\";\n+\n     ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n-    thrown.expect(RuntimeException.class);\n-    thrown.expectMessage(\"Unsupported ResolvedLiteral type: DATETIME\");\n-    zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(\n+                    Schema.builder().addLogicalTypeField(\"f_datetime\", SqlTypes.DATETIME).build())\n+                .addValues(LocalDateTime.of(2008, 12, 25, 15, 30, 0))\n+                .build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testDateTimeColumn() {\n+    String sql = \"SELECT FORMAT_DATETIME('%b-%d-%Y', datetime_field) FROM table_with_datetime\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d"}, "originalPosition": 94}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "156bce1ba903d08a36aa5ce6925413cbb56d1f04", "author": {"user": {"login": "ZijieSong946", "name": "Zijie Song"}}, "url": "https://github.com/apache/beam/commit/156bce1ba903d08a36aa5ce6925413cbb56d1f04", "committedDate": "2020-07-29T20:08:45Z", "message": "Improvements done."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a180cf2573ae9a35fe0c58167cdf5bcb4a33da2d", "author": {"user": {"login": "ZijieSong946", "name": "Zijie Song"}}, "url": "https://github.com/apache/beam/commit/a180cf2573ae9a35fe0c58167cdf5bcb4a33da2d", "committedDate": "2020-07-29T20:14:26Z", "message": "CheckStyle fixed."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU3ODcyMzQ5", "url": "https://github.com/apache/beam/pull/12348#pullrequestreview-457872349", "createdAt": "2020-07-29T20:29:07Z", "commit": {"oid": "a180cf2573ae9a35fe0c58167cdf5bcb4a33da2d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMDoyOTowN1rOG5I9cg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMDoyOTowN1rOG5I9cg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU2ODgxOA==", "bodyText": "This empty line is accidentally removed. Could you add it back? Thanks!", "url": "https://github.com/apache/beam/pull/12348#discussion_r462568818", "createdAt": "2020-07-29T20:29:07Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/SupportedZetaSqlBuiltinFunctions.java", "diffHunk": "@@ -258,23 +257,22 @@\n \n           // Signatures specific to extracting the DATE date part from a DATETIME or a\n           // TIMESTAMP.\n-          // FunctionSignatureId.FN_EXTRACT_DATE_FROM_DATETIME, // $extract_date\n+          FunctionSignatureId.FN_EXTRACT_DATE_FROM_DATETIME, // $extract_date\n           FunctionSignatureId.FN_EXTRACT_DATE_FROM_TIMESTAMP, // $extract_date\n \n           // Signatures specific to extracting the TIME date part from a DATETIME or a\n           // TIMESTAMP.\n-          // FunctionSignatureId.FN_EXTRACT_TIME_FROM_DATETIME, // $extract_time\n+          FunctionSignatureId.FN_EXTRACT_TIME_FROM_DATETIME, // $extract_time\n           FunctionSignatureId.FN_EXTRACT_TIME_FROM_TIMESTAMP, // $extract_time\n \n           // Signature specific to extracting the DATETIME date part from a TIMESTAMP.\n-          // FunctionSignatureId.FN_EXTRACT_DATETIME_FROM_TIMESTAMP, // $extract_datetime\n-", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a180cf2573ae9a35fe0c58167cdf5bcb4a33da2d"}, "originalPosition": 72}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7ddc59f321996449c1544a2fa90473ce3802af46", "author": {"user": {"login": "ZijieSong946", "name": "Zijie Song"}}, "url": "https://github.com/apache/beam/commit/7ddc59f321996449c1544a2fa90473ce3802af46", "committedDate": "2020-07-29T20:32:10Z", "message": "Empty line added."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f7fcb6bdc71d1ea6335aaab0fb4fbb363ff02e3a", "author": {"user": {"login": "ZijieSong946", "name": "Zijie Song"}}, "url": "https://github.com/apache/beam/commit/f7fcb6bdc71d1ea6335aaab0fb4fbb363ff02e3a", "committedDate": "2020-07-29T20:33:59Z", "message": "Empty line added."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "db928fd8ea88d09d0d0457efd253b56072da9672", "author": {"user": {"login": "ZijieSong946", "name": "Zijie Song"}}, "url": "https://github.com/apache/beam/commit/db928fd8ea88d09d0d0457efd253b56072da9672", "committedDate": "2020-07-29T20:37:55Z", "message": "SpotlessCheck fixed."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU3ODgxNjAz", "url": "https://github.com/apache/beam/pull/12348#pullrequestreview-457881603", "createdAt": "2020-07-29T20:42:41Z", "commit": {"oid": "f7fcb6bdc71d1ea6335aaab0fb4fbb363ff02e3a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMDo0Mjo0MVrOG5JZ7A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMDo0Mjo0MVrOG5JZ7A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU3NjEwOA==", "bodyText": "Could you also add micro-second component here and below?", "url": "https://github.com/apache/beam/pull/12348#discussion_r462576108", "createdAt": "2020-07-29T20:42:41Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/zetasql/src/test/java/org/apache/beam/sdk/extensions/sql/zetasql/ZetaSqlTimeFunctionsTest.java", "diffHunk": "@@ -753,13 +786,416 @@ public void testParseTime() {\n   /////////////////////////////////////////////////////////////////////////////\n \n   @Test\n-  @Ignore(\"Does not support Datetime literal.\")\n-  public void testDatetimeLiteral() {\n-    String sql = \"SELECT DATETIME '2018-01-01 05:30:00.334'\";\n+  public void testDateTimeLiteral() {\n+    String sql = \"SELECT DATETIME '2008-12-25 15:30:00.123456'\";\n+\n     ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n-    thrown.expect(RuntimeException.class);\n-    thrown.expectMessage(\"Unsupported ResolvedLiteral type: DATETIME\");\n-    zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(\n+                    Schema.builder().addLogicalTypeField(\"f_datetime\", SqlTypes.DATETIME).build())\n+                .addValues(LocalDateTime.of(2008, 12, 25, 15, 30, 0).withNano(123456000))\n+                .build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testDateTimeColumn() {\n+    String sql = \"SELECT FORMAT_DATETIME('%D %T', datetime_field) FROM table_with_datetime\";\n+\n+    ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(Schema.builder().addStringField(\"f_datetime_str\").build())\n+                .addValues(\"12/25/08 15:30:00\")\n+                .build(),\n+            Row.withSchema(Schema.builder().addStringField(\"f_datetime_str\").build())\n+                .addValues(\"10/06/12 11:45:00\")\n+                .build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testGroupByDateTime() {\n+    String sql = \"SELECT datetime_field, COUNT(*) FROM table_with_datetime GROUP BY datetime_field\";\n+\n+    ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    final Schema schema =\n+        Schema.builder()\n+            .addLogicalTypeField(\"datetime_field\", SqlTypes.DATETIME)\n+            .addInt64Field(\"count\")\n+            .build();\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(schema).addValues(LocalDateTime.of(2008, 12, 25, 15, 30, 0), 1L).build(),\n+            Row.withSchema(schema).addValues(LocalDateTime.of(2012, 10, 6, 11, 45, 0), 1L).build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testAggregateOnDateTime() {\n+    String sql = \"SELECT MAX(datetime_field) FROM table_with_datetime GROUP BY str_field\";\n+\n+    ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(\n+                    Schema.builder()\n+                        .addLogicalTypeField(\"datetime_field\", SqlTypes.DATETIME)\n+                        .build())\n+                .addValues(LocalDateTime.of(2012, 10, 6, 11, 45, 0))\n+                .build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  // TODO[BEAM-9166]: Add a test for CURRENT_DATETIME function (\"SELECT CURRENT_DATETIME()\")\n+\n+  @Test\n+  public void testExtractFromDateTime() {\n+    String sql =\n+        \"SELECT \"\n+            + \"EXTRACT(YEAR FROM DATETIME '2008-12-25 15:30:00') as year, \"\n+            + \"EXTRACT(QUARTER FROM DATETIME '2008-12-25 15:30:00') as quarter, \"\n+            + \"EXTRACT(MONTH FROM DATETIME '2008-12-25 15:30:00') as month, \"\n+            // TODO[BEAM-9178]: Add tests for DATETIME_TRUNC and EXTRACT with \"week with weekday\"\n+            //  date parts once they are supported\n+            // + \"EXTRACT(WEEK FROM DATETIME '2008-12-25 15:30:00') as week, \"\n+            + \"EXTRACT(DAY FROM DATETIME '2008-12-25 15:30:00') as day, \"\n+            + \"EXTRACT(DAYOFWEEK FROM DATETIME '2008-12-25 15:30:00') as dayofweek, \"\n+            + \"EXTRACT(DAYOFYEAR FROM DATETIME '2008-12-25 15:30:00') as dayofyear, \"\n+            + \"EXTRACT(HOUR FROM DATETIME '2008-12-25 15:30:00.123456') as hour, \"\n+            + \"EXTRACT(MINUTE FROM DATETIME '2008-12-25 15:30:00.123456') as minute, \"\n+            + \"EXTRACT(SECOND FROM DATETIME '2008-12-25 15:30:00.123456') as second, \"\n+            + \"EXTRACT(MILLISECOND FROM DATETIME '2008-12-25 15:30:00.123456') as millisecond, \"\n+            + \"EXTRACT(MICROSECOND FROM DATETIME '2008-12-25 15:30:00.123456') as microsecond, \"\n+            + \"EXTRACT(DATE FROM DATETIME '2008-12-25 15:30:00.123456') as date, \"\n+            + \"EXTRACT(TIME FROM DATETIME '2008-12-25 15:30:00.123456') as time \";\n+\n+    ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    final Schema schema =\n+        Schema.builder()\n+            .addInt64Field(\"year\")\n+            .addInt64Field(\"quarter\")\n+            .addInt64Field(\"month\")\n+            // .addInt64Field(\"week\")\n+            .addInt64Field(\"day\")\n+            .addInt64Field(\"dayofweek\")\n+            .addInt64Field(\"dayofyear\")\n+            .addInt64Field(\"hour\")\n+            .addInt64Field(\"minute\")\n+            .addInt64Field(\"second\")\n+            .addInt64Field(\"millisecond\")\n+            .addInt64Field(\"microsecond\")\n+            .addLogicalTypeField(\"date\", SqlTypes.DATE)\n+            .addLogicalTypeField(\"time\", SqlTypes.TIME)\n+            .build();\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(schema)\n+                .addValues(\n+                    2008L,\n+                    4L,\n+                    12L,\n+                    // 52L,\n+                    25L,\n+                    5L,\n+                    360L,\n+                    15L,\n+                    30L,\n+                    0L,\n+                    123L,\n+                    123456L,\n+                    LocalDate.of(2008, 12, 25),\n+                    LocalTime.of(15, 30, 0, 123456000))\n+                .build());\n+\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testDateTimeFromDateAndTime() {\n+    String sql = \"SELECT DATETIME(DATE '2008-12-25', TIME '15:30:00.123456')\";\n+\n+    ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(\n+                    Schema.builder().addLogicalTypeField(\"f_datetime\", SqlTypes.DATETIME).build())\n+                .addValues(LocalDateTime.of(2008, 12, 25, 15, 30, 0).withNano(123456000))\n+                .build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testDateTimeFromDate() {\n+    String sql = \"SELECT DATETIME(DATE '2008-12-25')\";\n+\n+    ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(\n+                    Schema.builder().addLogicalTypeField(\"f_datetime\", SqlTypes.DATETIME).build())\n+                .addValues(LocalDateTime.of(2008, 12, 25, 0, 0, 0))\n+                .build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testDateTimeFromYearMonthDayHourMinuteSecond() {\n+    String sql = \"SELECT DATETIME(2008, 12, 25, 15, 30, 0)\";\n+\n+    ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(\n+                    Schema.builder().addLogicalTypeField(\"f_datetime\", SqlTypes.DATETIME).build())\n+                .addValues(LocalDateTime.of(2008, 12, 25, 15, 30, 0))\n+                .build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testDateTimeFromTimestamp() {\n+    String sql = \"SELECT DATETIME(TIMESTAMP '2008-12-25 15:30:00+08', 'America/Los_Angeles')\";\n+\n+    ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(\n+                    Schema.builder().addLogicalTypeField(\"f_datetime\", SqlTypes.DATETIME).build())\n+                .addValues(LocalDateTime.of(2008, 12, 24, 23, 30, 0))\n+                .build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testDateTimeAdd() {\n+    String sql =\n+        \"SELECT \"\n+            + \"DATETIME_ADD(DATETIME '2008-12-25 15:30:00', INTERVAL 10 MICROSECOND), \"\n+            + \"DATETIME_ADD(DATETIME '2008-12-25 15:30:00', INTERVAL 10 MILLISECOND), \"\n+            + \"DATETIME_ADD(DATETIME '2008-12-25 15:30:00', INTERVAL 10 SECOND), \"\n+            + \"DATETIME_ADD(DATETIME '2008-12-25 15:30:00', INTERVAL 10 MINUTE), \"\n+            + \"DATETIME_ADD(DATETIME '2008-12-25 15:30:00', INTERVAL 10 HOUR), \"\n+            + \"DATETIME_ADD(DATETIME '2008-12-25 15:30:00', INTERVAL 10 DAY), \"\n+            + \"DATETIME_ADD(DATETIME '2008-12-25 15:30:00', INTERVAL 10 MONTH), \"\n+            + \"DATETIME_ADD(DATETIME '2008-12-25 15:30:00', INTERVAL 10 QUARTER), \"\n+            + \"DATETIME_ADD(DATETIME '2008-12-25 15:30:00', INTERVAL 10 YEAR) \";\n+\n+    ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(\n+                    Schema.builder()\n+                        .addLogicalTypeField(\"f_time1\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time2\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time3\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time4\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time5\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time6\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time7\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time8\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time9\", SqlTypes.DATETIME)\n+                        .build())\n+                .addValues(\n+                    LocalDateTime.of(2008, 12, 25, 15, 30, 0).withNano(10000),\n+                    LocalDateTime.of(2008, 12, 25, 15, 30, 0).withNano(10000000),\n+                    LocalDateTime.of(2008, 12, 25, 15, 30, 10),\n+                    LocalDateTime.of(2008, 12, 25, 15, 40, 0),\n+                    LocalDateTime.of(2008, 12, 26, 1, 30, 0),\n+                    LocalDateTime.of(2009, 1, 4, 15, 30, 0),\n+                    LocalDateTime.of(2009, 10, 25, 15, 30, 0),\n+                    LocalDateTime.of(2011, 6, 25, 15, 30, 0),\n+                    LocalDateTime.of(2018, 12, 25, 15, 30, 0))\n+                .build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testDateTimeAddWithParameter() {\n+    String sql = \"SELECT DATETIME_ADD(@p0, INTERVAL @p1 HOUR)\";\n+\n+    LocalDateTime datetime = LocalDateTime.of(2008, 12, 25, 15, 30, 00).withNano(123456000);\n+    ImmutableMap<String, Value> params =\n+        ImmutableMap.of(\n+            \"p0\",\n+                Value.createDatetimeValue(\n+                    CivilTimeEncoder.encodePacked64DatetimeSeconds(datetime), datetime.getNano()),\n+            \"p1\", Value.createInt64Value(3L));\n+\n+    ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql, params);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(\n+                    Schema.builder().addLogicalTypeField(\"f_datetime\", SqlTypes.DATETIME).build())\n+                .addValues(LocalDateTime.of(2008, 12, 25, 18, 30, 00).withNano(123456000))\n+                .build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testDateTimeSub() {\n+    String sql =\n+        \"SELECT \"\n+            + \"DATETIME_SUB(DATETIME '2008-12-25 15:30:00', INTERVAL 10 MICROSECOND), \"\n+            + \"DATETIME_SUB(DATETIME '2008-12-25 15:30:00', INTERVAL 10 MILLISECOND), \"\n+            + \"DATETIME_SUB(DATETIME '2008-12-25 15:30:00', INTERVAL 10 SECOND), \"\n+            + \"DATETIME_SUB(DATETIME '2008-12-25 15:30:00', INTERVAL 10 MINUTE), \"\n+            + \"DATETIME_SUB(DATETIME '2008-12-25 15:30:00', INTERVAL 10 HOUR), \"\n+            + \"DATETIME_SUB(DATETIME '2008-12-25 15:30:00', INTERVAL 10 DAY), \"\n+            + \"DATETIME_SUB(DATETIME '2008-12-25 15:30:00', INTERVAL 10 MONTH), \"\n+            + \"DATETIME_SUB(DATETIME '2008-12-25 15:30:00', INTERVAL 10 QUARTER), \"\n+            + \"DATETIME_SUB(DATETIME '2008-12-25 15:30:00', INTERVAL 10 YEAR) \";\n+\n+    ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(\n+                    Schema.builder()\n+                        .addLogicalTypeField(\"f_time1\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time2\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time3\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time4\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time5\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time6\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time7\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time8\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time9\", SqlTypes.DATETIME)\n+                        .build())\n+                .addValues(\n+                    LocalDateTime.of(2008, 12, 25, 15, 29, 59).withNano(999990000),\n+                    LocalDateTime.of(2008, 12, 25, 15, 29, 59).withNano(990000000),\n+                    LocalDateTime.of(2008, 12, 25, 15, 29, 50),\n+                    LocalDateTime.of(2008, 12, 25, 15, 20, 0),\n+                    LocalDateTime.of(2008, 12, 25, 5, 30, 0),\n+                    LocalDateTime.of(2008, 12, 15, 15, 30, 0),\n+                    LocalDateTime.of(2008, 2, 25, 15, 30, 0),\n+                    LocalDateTime.of(2006, 6, 25, 15, 30, 0),\n+                    LocalDateTime.of(1998, 12, 25, 15, 30, 0))\n+                .build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testDateTimeDiff() {\n+    String sql =\n+        \"SELECT DATETIME_DIFF(DATETIME '2008-12-25 15:30:00', DATETIME '2008-10-25 15:30:00', DAY)\";\n+\n+    ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(Schema.builder().addInt64Field(\"f_datetime_diff\").build())\n+                .addValues(61L)\n+                .build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testDateTimeDiffNegativeResult() {\n+    String sql =\n+        \"SELECT DATETIME_DIFF(DATETIME '2008-10-25 15:30:00', DATETIME '2008-12-25 15:30:00', DAY)\";\n+\n+    ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(Schema.builder().addInt64Field(\"f_datetime_diff\").build())\n+                .addValues(-61L)\n+                .build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testDateTimeTrunc() {\n+    String sql = \"SELECT DATETIME_TRUNC(DATETIME '2008-12-25 15:30:00', HOUR)\";\n+\n+    ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(\n+                    Schema.builder()\n+                        .addLogicalTypeField(\"f_datetime_trunc\", SqlTypes.DATETIME)\n+                        .build())\n+                .addValues(LocalDateTime.of(2008, 12, 25, 15, 0, 0))\n+                .build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testFormatDateTime() {\n+    String sql = \"SELECT FORMAT_DATETIME('%D %T', DATETIME '2008-12-25 15:30:00')\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f7fcb6bdc71d1ea6335aaab0fb4fbb363ff02e3a"}, "originalPosition": 457}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU3ODgyMjIy", "url": "https://github.com/apache/beam/pull/12348#pullrequestreview-457882222", "createdAt": "2020-07-29T20:43:31Z", "commit": {"oid": "db928fd8ea88d09d0d0457efd253b56072da9672"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMDo0MzozMVrOG5JbwA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMDo0MzozMVrOG5JbwA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU3NjU3Ng==", "bodyText": "I would add micro-second components for column as well.", "url": "https://github.com/apache/beam/pull/12348#discussion_r462576576", "createdAt": "2020-07-29T20:43:31Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/zetasql/src/test/java/org/apache/beam/sdk/extensions/sql/zetasql/TestInput.java", "diffHunk": "@@ -225,47 +226,59 @@\n   public static final TestBoundedTable TABLE_EMPTY =\n       TestBoundedTable.of(Schema.builder().addInt64Field(\"ColId\").addStringField(\"Value\").build());\n \n-  private static final Schema TABLE_WTH_MAP_SCHEMA =\n+  private static final Schema TABLE_WITH_MAP_SCHEMA =\n       Schema.builder()\n           .addMapField(\"map_field\", FieldType.STRING, FieldType.STRING)\n           .addRowField(\"row_field\", structSchema)\n           .build();\n   public static final TestBoundedTable TABLE_WITH_MAP =\n-      TestBoundedTable.of(TABLE_WTH_MAP_SCHEMA)\n+      TestBoundedTable.of(TABLE_WITH_MAP_SCHEMA)\n           .addRows(\n               ImmutableMap.of(\"MAP_KEY_1\", \"MAP_VALUE_1\"),\n               Row.withSchema(structSchema).addValues(1L, \"data1\").build());\n \n-  private static final Schema TABLE_WTH_DATE_SCHEMA =\n+  private static final Schema TABLE_WITH_DATE_SCHEMA =\n       Schema.builder()\n           .addLogicalTypeField(\"date_field\", SqlTypes.DATE)\n           .addStringField(\"str_field\")\n           .build();\n \n   public static final TestBoundedTable TABLE_WITH_DATE =\n-      TestBoundedTable.of(TABLE_WTH_DATE_SCHEMA)\n+      TestBoundedTable.of(TABLE_WITH_DATE_SCHEMA)\n           .addRows(LocalDate.of(2008, 12, 25), \"s\")\n           .addRows(LocalDate.of(2020, 4, 7), \"s\");\n \n-  private static final Schema TABLE_WTH_TIME_SCHEMA =\n+  private static final Schema TABLE_WITH_TIME_SCHEMA =\n       Schema.builder()\n           .addLogicalTypeField(\"time_field\", SqlTypes.TIME)\n           .addStringField(\"str_field\")\n           .build();\n \n   public static final TestBoundedTable TABLE_WITH_TIME =\n-      TestBoundedTable.of(TABLE_WTH_TIME_SCHEMA)\n+      TestBoundedTable.of(TABLE_WITH_TIME_SCHEMA)\n           .addRows(LocalTime.of(15, 30, 0), \"s\")\n           .addRows(LocalTime.of(23, 35, 59), \"s\");\n \n-  private static final Schema TABLE_WTH_NUMERIC_SCHEMA =\n+  private static final Schema TABLE_WITH_NUMERIC_SCHEMA =\n       Schema.builder().addDecimalField(\"numeric_field\").addStringField(\"str_field\").build();\n+\n   public static final TestBoundedTable TABLE_WITH_NUMERIC =\n-      TestBoundedTable.of(TABLE_WTH_NUMERIC_SCHEMA)\n+      TestBoundedTable.of(TABLE_WITH_NUMERIC_SCHEMA)\n           .addRows(ZetaSqlTypesUtils.bigDecimalAsNumeric(\"123.4567\"), \"str1\")\n           .addRows(ZetaSqlTypesUtils.bigDecimalAsNumeric(\"765.4321\"), \"str2\")\n           .addRows(ZetaSqlTypesUtils.bigDecimalAsNumeric(\"-555.5555\"), \"str3\");\n \n+  private static final Schema TABLE_WITH_DATETIME_SCHEMA =\n+      Schema.builder()\n+          .addLogicalTypeField(\"datetime_field\", SqlTypes.DATETIME)\n+          .addStringField(\"str_field\")\n+          .build();\n+\n+  public static final TestBoundedTable TABLE_WITH_DATETIME =\n+      TestBoundedTable.of(TABLE_WITH_DATETIME_SCHEMA)\n+          .addRows(LocalDateTime.of(2008, 12, 25, 15, 30, 0), \"s\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db928fd8ea88d09d0d0457efd253b56072da9672"}, "originalPosition": 70}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "32544594dc65ad092032b366533daa2277fb8c73", "author": {"user": {"login": "ZijieSong946", "name": "Zijie Song"}}, "url": "https://github.com/apache/beam/commit/32544594dc65ad092032b366533daa2277fb8c73", "committedDate": "2020-07-29T21:04:22Z", "message": "Improvements done."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9da6738f63fcb336a0210d411cf34b6e0f6a8730", "author": {"user": {"login": "ZijieSong946", "name": "Zijie Song"}}, "url": "https://github.com/apache/beam/commit/9da6738f63fcb336a0210d411cf34b6e0f6a8730", "committedDate": "2020-08-04T03:53:12Z", "message": "Beam testcases and logic added."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDYxMDQyNzA4", "url": "https://github.com/apache/beam/pull/12348#pullrequestreview-461042708", "createdAt": "2020-08-04T17:57:19Z", "commit": {"oid": "9da6738f63fcb336a0210d411cf34b6e0f6a8730"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQxNzo1NzoyMFrOG7rW1g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQxODo0NToyMlrOG7s92A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTIyOTUyNg==", "bodyText": "Now these fields are all public, I think it makes sense to give them more precise names, like \"DATE_FIELD_NAME\" and \"TIME_FIELD_NAME\"?", "url": "https://github.com/apache/beam/pull/12348#discussion_r465229526", "createdAt": "2020-08-04T17:57:20Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/logicaltypes/DateTime.java", "diffHunk": "@@ -0,0 +1,83 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.schemas.logicaltypes;\n+\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.values.Row;\n+\n+/**\n+ * A datetime without a time-zone.\n+ *\n+ * <p>It cannot represent an instant on the time-line without additional information such as an\n+ * offset or time-zone.\n+ *\n+ * <p>Its input type is a {@link LocalDateTime}, and base type is a {@link Row} containing Date\n+ * field and Time field. Date field is the same as the base type of {@link Date}, which is a Long\n+ * that represents incrementing count of days where day 0 is 1970-01-01 (ISO). Time field is the\n+ * same as the base type of {@link Time}, which is a Long that represents a count of time in\n+ * nanoseconds.\n+ */\n+public class DateTime implements Schema.LogicalType<LocalDateTime, Row> {\n+  public static final String DATE_FIELD = \"Date\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9da6738f63fcb336a0210d411cf34b6e0f6a8730"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTIzMDc0MA==", "bodyText": "Let's not use the name \"datetime\" here. I think it should be \"timestamp_with_local_time_zone\"? See other column names above, they all use the Calcite name.", "url": "https://github.com/apache/beam/pull/12348#discussion_r465230740", "createdAt": "2020-08-04T17:59:28Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/impl/schema/BeamSqlRowCoderTest.java", "diffHunk": "@@ -51,6 +52,7 @@ public void encodeAndDecode() throws Exception {\n             .add(\"col_string_varchar\", SqlTypeName.VARCHAR)\n             .add(\"col_time\", SqlTypeName.TIME)\n             .add(\"col_date\", SqlTypeName.DATE)\n+            .add(\"col_datetime\", SqlTypeName.TIMESTAMP_WITH_LOCAL_TIME_ZONE)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9da6738f63fcb336a0210d411cf34b6e0f6a8730"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTI1NDQyMw==", "bodyText": "Add some tests on \"nullableDateTimeField\" as well, like above?", "url": "https://github.com/apache/beam/pull/12348#discussion_r465254423", "createdAt": "2020-08-04T18:42:32Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/BeamComplexTypeTest.java", "diffHunk": "@@ -412,32 +398,141 @@ public void testNullDatetimeFields() {\n             .addNullableField(\"year_with_null\", FieldType.INT64)\n             .addField(\"mm\", FieldType.INT64)\n             .addNullableField(\"month_with_null\", FieldType.INT64)\n+            .build();\n+\n+    PAssert.that(outputRow)\n+        .containsInAnyOrder(\n+            Row.withSchema(outputRowSchema).addValues(2019L, null, 06L, null).build());\n+\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(2));\n+  }\n+\n+  @Test\n+  public void testNullSqlLogicalTypeDateFields() {\n+    Schema dateTimeFieldSchema =\n+        Schema.builder()\n+            .addField(\"dateTypeField\", FieldType.logicalType(SqlTypes.DATE))\n+            .addNullableField(\"nullableDateTypeField\", FieldType.logicalType(SqlTypes.DATE))\n+            .build();\n+\n+    Row dateRow =\n+        Row.withSchema(dateTimeFieldSchema).addValues(LocalDate.of(2019, 6, 27), null).build();\n+\n+    PCollection<Row> outputRow =\n+        pipeline\n+            .apply(Create.of(dateRow))\n+            .setRowSchema(dateTimeFieldSchema)\n+            .apply(\n+                SqlTransform.query(\n+                    \"select EXTRACT(DAY from dateTypeField) as dd, \"\n+                        + \" EXTRACT(DAY from nullableDateTypeField) as day_with_null, \"\n+                        + \" dateTypeField + interval '1' day as date_with_day_added, \"\n+                        + \" nullableDateTypeField + interval '1' day as day_added_with_null \"\n+                        + \" from PCOLLECTION\"));\n+\n+    Schema outputRowSchema =\n+        Schema.builder()\n+            .addField(\"dd\", FieldType.INT64)\n+            .addNullableField(\"day_with_null\", FieldType.INT64)\n+            .addField(\"date_with_day_added\", FieldType.logicalType(SqlTypes.DATE))\n+            .addNullableField(\"day_added_with_null\", FieldType.logicalType(SqlTypes.DATE))\n+            .build();\n+\n+    PAssert.that(outputRow)\n+        .containsInAnyOrder(\n+            Row.withSchema(outputRowSchema)\n+                .addValues(27L, null, LocalDate.of(2019, 6, 28), null)\n+                .build());\n+\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(2));\n+  }\n+\n+  @Test\n+  public void testNullSqlLogicalTypeTimeFields() {\n+    Schema dateTimeFieldSchema =\n+        Schema.builder()\n+            .addField(\"timeTypeField\", FieldType.logicalType(SqlTypes.TIME))\n+            .addNullableField(\"nullableTimeTypeField\", FieldType.logicalType(SqlTypes.TIME))\n+            .build();\n+\n+    Row timeRow =\n+        Row.withSchema(dateTimeFieldSchema).addValues(LocalTime.of(1, 0, 0), null).build();\n+\n+    PCollection<Row> outputRow =\n+        pipeline\n+            .apply(Create.of(timeRow))\n+            .setRowSchema(dateTimeFieldSchema)\n+            .apply(\n+                SqlTransform.query(\n+                    \"select timeTypeField + interval '1' hour as time_with_hour_added, \"\n+                        + \" nullableTimeTypeField + interval '1' hour as hour_added_with_null, \"\n+                        + \" timeTypeField - INTERVAL '60' SECOND as time_with_seconds_added, \"\n+                        + \" nullableTimeTypeField - INTERVAL '60' SECOND as seconds_added_with_null \"\n+                        + \" from PCOLLECTION\"));\n+\n+    Schema outputRowSchema =\n+        Schema.builder()\n             .addField(\"time_with_hour_added\", FieldType.logicalType(SqlTypes.TIME))\n             .addNullableField(\"hour_added_with_null\", FieldType.logicalType(SqlTypes.TIME))\n             .addField(\"time_with_seconds_added\", FieldType.logicalType(SqlTypes.TIME))\n             .addNullableField(\"seconds_added_with_null\", FieldType.logicalType(SqlTypes.TIME))\n+            .build();\n+\n+    PAssert.that(outputRow)\n+        .containsInAnyOrder(\n+            Row.withSchema(outputRowSchema)\n+                .addValues(LocalTime.of(2, 0, 0), null, LocalTime.of(0, 59, 0), null)\n+                .build());\n+\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(2));\n+  }\n+\n+  @Test\n+  public void testSqlLogicalTypeDatetimeFields() {\n+    Schema dateTimeFieldSchema =\n+        Schema.builder()\n+            .addField(\"dateTimeField\", FieldType.logicalType(SqlTypes.DATETIME))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9da6738f63fcb336a0210d411cf34b6e0f6a8730"}, "originalPosition": 140}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTI1NTg5Ng==", "bodyText": "Thanks for splitting these tests. Now its much easier to read.\nCould you remove the \"Null\" from this test name (and above)? I think all tests have a non-null field and a nullable field now.", "url": "https://github.com/apache/beam/pull/12348#discussion_r465255896", "createdAt": "2020-08-04T18:45:22Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/BeamComplexTypeTest.java", "diffHunk": "@@ -412,32 +398,141 @@ public void testNullDatetimeFields() {\n             .addNullableField(\"year_with_null\", FieldType.INT64)\n             .addField(\"mm\", FieldType.INT64)\n             .addNullableField(\"month_with_null\", FieldType.INT64)\n+            .build();\n+\n+    PAssert.that(outputRow)\n+        .containsInAnyOrder(\n+            Row.withSchema(outputRowSchema).addValues(2019L, null, 06L, null).build());\n+\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(2));\n+  }\n+\n+  @Test\n+  public void testNullSqlLogicalTypeDateFields() {\n+    Schema dateTimeFieldSchema =\n+        Schema.builder()\n+            .addField(\"dateTypeField\", FieldType.logicalType(SqlTypes.DATE))\n+            .addNullableField(\"nullableDateTypeField\", FieldType.logicalType(SqlTypes.DATE))\n+            .build();\n+\n+    Row dateRow =\n+        Row.withSchema(dateTimeFieldSchema).addValues(LocalDate.of(2019, 6, 27), null).build();\n+\n+    PCollection<Row> outputRow =\n+        pipeline\n+            .apply(Create.of(dateRow))\n+            .setRowSchema(dateTimeFieldSchema)\n+            .apply(\n+                SqlTransform.query(\n+                    \"select EXTRACT(DAY from dateTypeField) as dd, \"\n+                        + \" EXTRACT(DAY from nullableDateTypeField) as day_with_null, \"\n+                        + \" dateTypeField + interval '1' day as date_with_day_added, \"\n+                        + \" nullableDateTypeField + interval '1' day as day_added_with_null \"\n+                        + \" from PCOLLECTION\"));\n+\n+    Schema outputRowSchema =\n+        Schema.builder()\n+            .addField(\"dd\", FieldType.INT64)\n+            .addNullableField(\"day_with_null\", FieldType.INT64)\n+            .addField(\"date_with_day_added\", FieldType.logicalType(SqlTypes.DATE))\n+            .addNullableField(\"day_added_with_null\", FieldType.logicalType(SqlTypes.DATE))\n+            .build();\n+\n+    PAssert.that(outputRow)\n+        .containsInAnyOrder(\n+            Row.withSchema(outputRowSchema)\n+                .addValues(27L, null, LocalDate.of(2019, 6, 28), null)\n+                .build());\n+\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(2));\n+  }\n+\n+  @Test\n+  public void testNullSqlLogicalTypeTimeFields() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9da6738f63fcb336a0210d411cf34b6e0f6a8730"}, "originalPosition": 97}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3f8502c8139821d281b766ce7ee8392b465fa856", "author": {"user": {"login": "ZijieSong946", "name": "Zijie Song"}}, "url": "https://github.com/apache/beam/commit/3f8502c8139821d281b766ce7ee8392b465fa856", "committedDate": "2020-08-04T20:42:22Z", "message": "Improvements done. Bug related to null timezone remains."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDYxMjA1NjIw", "url": "https://github.com/apache/beam/pull/12348#pullrequestreview-461205620", "createdAt": "2020-08-04T22:03:26Z", "commit": {"oid": "3f8502c8139821d281b766ce7ee8392b465fa856"}, "state": "APPROVED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQyMjowMzoyNlrOG7zDzA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQyMjo1MjowN1rOG70K7Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM1NTcyNA==", "bodyText": "Instead of getValue(), use getInt64() as we expect this to always be Int64.\nnit:getInt64(DATE_FIELD_INDEX) is probably a better choice than getInt64(DATE_FIELD_NAME) if there is a fixed schema.", "url": "https://github.com/apache/beam/pull/12348#discussion_r465355724", "createdAt": "2020-08-04T22:03:26Z", "author": {"login": "apilloud"}, "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/logicaltypes/DateTime.java", "diffHunk": "@@ -0,0 +1,83 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.schemas.logicaltypes;\n+\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.values.Row;\n+\n+/**\n+ * A datetime without a time-zone.\n+ *\n+ * <p>It cannot represent an instant on the time-line without additional information such as an\n+ * offset or time-zone.\n+ *\n+ * <p>Its input type is a {@link LocalDateTime}, and base type is a {@link Row} containing Date\n+ * field and Time field. Date field is the same as the base type of {@link Date}, which is a Long\n+ * that represents incrementing count of days where day 0 is 1970-01-01 (ISO). Time field is the\n+ * same as the base type of {@link Time}, which is a Long that represents a count of time in\n+ * nanoseconds.\n+ */\n+public class DateTime implements Schema.LogicalType<LocalDateTime, Row> {\n+  public static final String DATE_FIELD_NAME = \"Date\";\n+  public static final String TIME_FIELD_NAME = \"Time\";\n+  public static final Schema DATETIME_SCHEMA =\n+      Schema.builder().addInt64Field(DATE_FIELD_NAME).addInt64Field(TIME_FIELD_NAME).build();\n+\n+  @Override\n+  public String getIdentifier() {\n+    return \"beam:logical_type:datetime:v1\";\n+  }\n+\n+  // unused\n+  @Override\n+  public Schema.FieldType getArgumentType() {\n+    return Schema.FieldType.STRING;\n+  }\n+\n+  // unused\n+  @Override\n+  public String getArgument() {\n+    return \"\";\n+  }\n+\n+  @Override\n+  public Schema.FieldType getBaseType() {\n+    return Schema.FieldType.row(DATETIME_SCHEMA);\n+  }\n+\n+  @Override\n+  public Row toBaseType(LocalDateTime input) {\n+    return input == null\n+        ? null\n+        : Row.withSchema(DATETIME_SCHEMA)\n+            .addValues(input.toLocalDate().toEpochDay(), input.toLocalTime().toNanoOfDay())\n+            .build();\n+  }\n+\n+  @Override\n+  public LocalDateTime toInputType(Row base) {\n+    return base == null\n+        ? null\n+        : LocalDateTime.of(\n+            LocalDate.ofEpochDay(base.getValue(DATE_FIELD_NAME)),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f8502c8139821d281b766ce7ee8392b465fa856"}, "originalPosition": 80}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM1OTgxNA==", "bodyText": "getInt64 returns a Long, so I believe that will allow you to remove the castIfNecessary?", "url": "https://github.com/apache/beam/pull/12348#discussion_r465359814", "createdAt": "2020-08-04T22:13:05Z", "author": {"login": "apilloud"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamCalcRel.java", "diffHunk": "@@ -442,6 +455,20 @@ private static Expression value(Expression value, Schema.FieldType type) {\n               value, Expressions.divide(value, Expressions.constant(NANOS_PER_MILLISECOND)));\n         } else if (SqlTypes.DATE.getIdentifier().equals(logicalId)) {\n           return value;\n+        } else if (SqlTypes.DATETIME.getIdentifier().equals(logicalId)) {\n+          Expression dateValue =\n+              Expressions.call(value, \"getValue\", Expressions.constant(DateTime.DATE_FIELD_NAME));\n+          Expression timeValue =\n+              Expressions.call(value, \"getValue\", Expressions.constant(DateTime.TIME_FIELD_NAME));\n+          Expression returnValue =\n+              Expressions.add(\n+                  Expressions.multiply(\n+                      Types.castIfNecessary(long.class, dateValue),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f8502c8139821d281b766ce7ee8392b465fa856"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM3MDM4Ng==", "bodyText": "I'm not a fan of using replace here. I believe the operand(0) will be a SqlTimestampLiteral? If so, you can call toFormattedString instead: https://github.com/apache/calcite/blob/52a57078ba081b24b9d086ed363c715485d1a519/core/src/main/java/org/apache/calcite/sql/SqlTimestampLiteral.java#L54", "url": "https://github.com/apache/beam/pull/12348#discussion_r465370386", "createdAt": "2020-08-04T22:42:06Z", "author": {"login": "apilloud"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/bigquery/BeamBigQuerySqlDialect.java", "diffHunk": "@@ -253,6 +259,11 @@ private void unparseTrim(SqlWriter writer, SqlCall call, int leftPrec, int right\n     writer.endFunCall(trimFrame);\n   }\n \n+  private void unparseDateTimeLiteralWrapperFunction(\n+      SqlWriter writer, SqlCall call, int leftPrec, int rightPrec) {\n+    writer.literal(call.operand(0).toString().replace(\"TIMESTAMP\", \"DATETIME\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f8502c8139821d281b766ce7ee8392b465fa856"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM3MzkzMw==", "bodyText": "Instead of wrapping with a function here, it looks like you can do the same thing by creating a class overloading SqlTimestampLiteral.toString() and wrapping it in BeamSqlUnparseContext? This would reduce the complexity at the Rel layer.\n\n  \n    \n      beam/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/bigquery/BeamSqlUnparseContext.java\n    \n    \n         Line 70\n      in\n      6fdde4f\n    \n    \n    \n    \n\n        \n          \n           if (rex.getKind().equals(SqlKind.LITERAL)) {", "url": "https://github.com/apache/beam/pull/12348#discussion_r465373933", "createdAt": "2020-08-04T22:52:07Z", "author": {"login": "apilloud"}, "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/translation/ExpressionConverter.java", "diffHunk": "@@ -850,6 +848,25 @@ private RexNode convertSimpleValueToRexNode(TypeKind kind, Value value) {\n         // TODO: Doing micro to mills truncation, need to throw exception.\n         ret = rexBuilder().makeLiteral(convertTimeValueToTimeString(value), timeType, false);\n         break;\n+      case TYPE_DATETIME:\n+        // Cannot simply call makeTimestampWithLocalTimeZoneLiteral() for ZetaSQL DATETIME type\n+        // because later it will be unparsed to the string representation of timestamp (e.g. \"SELECT\n+        // DATETIME '2008-12-25 15:30:00'\" will be unparsed to \"SELECT TIMESTAMP '2008-12-25\n+        // 15:30:00:000000'\"). So we create a wrapper function here such that we can later recognize\n+        // it and customize its unparsing in BeamBigQuerySqlDialect.\n+        ret =\n+            rexBuilder()\n+                .makeCall(\n+                    SqlOperators.createZetaSqlFunction(\n+                        BeamBigQuerySqlDialect.DATETIME_LITERAL_FUNCTION,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f8502c8139821d281b766ce7ee8392b465fa856"}, "originalPosition": 69}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fb366047ee9e2f00cbcff98364a728c212a2f470", "author": {"user": {"login": "ZijieSong946", "name": "Zijie Song"}}, "url": "https://github.com/apache/beam/commit/fb366047ee9e2f00cbcff98364a728c212a2f470", "committedDate": "2020-08-05T05:49:27Z", "message": "CalciteSql tests passed. Improments dones. Wrapper func not updated yet."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b3defda19b42dda4e8e99c13e6b17e03d6baed46", "author": {"user": {"login": "ZijieSong946", "name": "Zijie Song"}}, "url": "https://github.com/apache/beam/commit/b3defda19b42dda4e8e99c13e6b17e03d6baed46", "committedDate": "2020-08-05T05:55:50Z", "message": "CheckStyle fixed."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDYxOTI1NzEw", "url": "https://github.com/apache/beam/pull/12348#pullrequestreview-461925710", "createdAt": "2020-08-05T18:38:13Z", "commit": {"oid": "b3defda19b42dda4e8e99c13e6b17e03d6baed46"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4c6c7ca0095e0d0117cee3bad93217a8a947d11f", "author": {"user": {"login": "ZijieSong946", "name": "Zijie Song"}}, "url": "https://github.com/apache/beam/commit/4c6c7ca0095e0d0117cee3bad93217a8a947d11f", "committedDate": "2020-08-06T06:34:04Z", "message": "Override function not works."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "37e920b19c9a41b980156d0e76f4b58667357240", "author": {"user": {"login": "ZijieSong946", "name": "Zijie Song"}}, "url": "https://github.com/apache/beam/commit/37e920b19c9a41b980156d0e76f4b58667357240", "committedDate": "2020-08-06T16:58:02Z", "message": "Wrapper function updated."}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3890, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}