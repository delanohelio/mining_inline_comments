{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDI0MzE3MjQ1", "number": 11847, "title": "[BEAM-10125] adding cross-language KafkaIO integration test", "bodyText": "Thank you for your contribution! Follow this checklist to help us incorporate your contribution quickly and easily:\n\n Choose reviewer(s) and mention them in a comment (R: @username).\n Format the pull request title like [BEAM-XXX] Fixes bug in ApproximateQuantiles, where you replace BEAM-XXX with the appropriate JIRA issue, if applicable. This will automatically link the pull request to the issue.\n Update CHANGES.md with noteworthy changes.\n If this contribution is large, please file an Apache Individual Contributor License Agreement.\n\nSee the Contributor Guide for more tips on how to make review process smoother.\nPost-Commit Tests Status (on master branch)\n\n\n\nLang\nSDK\nApex\nDataflow\nFlink\nGearpump\nSamza\nSpark\n\n\n\n\nGo\n\n---\n---\n\n---\n---\n\n\n\nJava\n\n\n\n\n\n\n\n\n\nPython\n\n---\n\n\n---\n---\n\n\n\nXLang\n---\n---\n---\n\n---\n---\n\n\n\n\nPre-Commit Tests Status (on master branch)\n\n\n\n---\nJava\nPython\nGo\nWebsite\n\n\n\n\nNon-portable\n\n\n\n\n\n\nPortable\n---\n\n---\n---\n\n\n\nSee .test-infra/jenkins/README for trigger phrase, status and link of all Jenkins jobs.", "createdAt": "2020-05-28T08:01:14Z", "url": "https://github.com/apache/beam/pull/11847", "merged": true, "mergeCommit": {"oid": "858fe4e51cceba33bb94245f55d0652c7159d8b9"}, "closed": true, "closedAt": "2020-05-29T18:34:36Z", "author": {"login": "ihji"}, "timelineItems": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABclzlhEgFqTQyMDQ0MzI2OA==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcl5PxpABqjMzODU0MDAzNDI=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIwNDQzMjY4", "url": "https://github.com/apache/beam/pull/11847#pullrequestreview-420443268", "createdAt": "2020-05-28T19:52:04Z", "commit": {"oid": "492adc0fadf110d087d63590e2b655b53543be8c"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQxOTo1MjowNFrOGcERPQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQyMDowNzoxOFrOGcE7CQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjA4MzI2MQ==", "bodyText": "Is this only for internal testing ?\nExternally, kafkaio.py should automatically startup an expansion service as long as we are in a release or a Beam repo clone.", "url": "https://github.com/apache/beam/pull/11847#discussion_r432083261", "createdAt": "2020-05-28T19:52:04Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/io/external/xlang_kafkaio_it_test.py", "diffHunk": "@@ -0,0 +1,145 @@\n+\"\"\"Integration test for Python cross-language pipelines for Java KafkaIO.\"\"\"\n+\n+from __future__ import absolute_import\n+\n+import contextlib\n+import logging\n+import os\n+import socket\n+import subprocess\n+import time\n+import typing\n+import unittest\n+\n+import grpc\n+\n+import apache_beam as beam\n+from apache_beam.io.external.kafka import ReadFromKafka\n+from apache_beam.io.external.kafka import WriteToKafka\n+from apache_beam.metrics import Metrics\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.testing.test_pipeline import TestPipeline\n+\n+\n+class CrossLanguageKafkaIO(object):\n+  def __init__(self, bootstrap_servers, topic, expansion_service=None):\n+    self.bootstrap_servers = bootstrap_servers\n+    self.topic = topic\n+    self.expansion_service = expansion_service or (\n+        'localhost:%s' % os.environ.get('EXPANSION_PORT'))\n+    self.sum_counter = Metrics.counter('source', 'elements_sum')\n+\n+  def build_write_pipeline(self, pipeline):\n+    _ = (\n+        pipeline\n+        | 'Impulse' >> beam.Impulse()\n+        | 'Generate' >> beam.FlatMap(lambda x: range(1000)) # pylint: disable=range-builtin-not-iterating\n+        | 'Reshuffle' >> beam.Reshuffle()\n+        | 'MakeKV' >> beam.Map(lambda x:\n+                               (b'', str(x).encode())).with_output_types(\n+                                   typing.Tuple[bytes, bytes])\n+        | 'WriteToKafka' >> WriteToKafka(\n+            producer_config={'bootstrap.servers': self.bootstrap_servers},\n+            topic=self.topic,\n+            expansion_service=self.expansion_service))\n+\n+  def build_read_pipeline(self, pipeline):\n+    _ = (\n+        pipeline\n+        | 'ReadFromKafka' >> ReadFromKafka(\n+            consumer_config={\n+                'bootstrap.servers': self.bootstrap_servers,\n+                'auto.offset.reset': 'earliest'\n+            },\n+            topics=[self.topic],\n+            expansion_service=self.expansion_service)\n+        | 'Windowing' >> beam.WindowInto(\n+            beam.window.FixedWindows(300),\n+            trigger=beam.transforms.trigger.AfterProcessingTime(60),\n+            accumulation_mode=beam.transforms.trigger.AccumulationMode.\n+            DISCARDING)\n+        | 'DecodingValue' >> beam.Map(lambda elem: int(elem[1].decode()))\n+        | 'CombineGlobally' >> beam.CombineGlobally(sum).without_defaults()\n+        | 'SetSumCounter' >> beam.Map(self.sum_counter.inc))\n+\n+  def run_xlang_kafkaio(self, pipeline):\n+    self.build_write_pipeline(pipeline)\n+    self.build_read_pipeline(pipeline)\n+    pipeline.run(False)\n+\n+\n+@unittest.skipUnless(\n+    os.environ.get('LOCAL_KAFKA_JAR'),\n+    \"LOCAL_KAFKA_JAR environment var is not provided.\")\n+@unittest.skipUnless(\n+    os.environ.get('EXPANSION_JAR'),\n+    \"EXPANSION_JAR environment var is not provided.\")\n+class CrossLanguageKafkaIOTest(unittest.TestCase):\n+  def get_open_port(self):\n+    s = None\n+    try:\n+      s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n+    except:  # pylint: disable=bare-except\n+      # Above call will fail for nodes that only support IPv6.\n+      s = socket.socket(socket.AF_INET6, socket.SOCK_STREAM)\n+    s.bind(('localhost', 0))\n+    s.listen(1)\n+    port = s.getsockname()[1]\n+    s.close()\n+    return port\n+\n+  @contextlib.contextmanager\n+  def local_services(self, expansion_service_jar_file, local_kafka_jar_file):\n+    expansion_service_port = str(self.get_open_port())\n+    kafka_port = str(self.get_open_port())\n+    zookeeper_port = str(self.get_open_port())\n+\n+    expansion_server = None\n+    kafka_server = None\n+    try:\n+      expansion_server = subprocess.Popen(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "492adc0fadf110d087d63590e2b655b53543be8c"}, "originalPosition": 100}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjA4NTc0OA==", "bodyText": "Can we update this test to not startup an expansion service and use the default expansion service setup for external tests ?", "url": "https://github.com/apache/beam/pull/11847#discussion_r432085748", "createdAt": "2020-05-28T19:55:11Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/io/external/xlang_kafkaio_it_test.py", "diffHunk": "@@ -0,0 +1,145 @@\n+\"\"\"Integration test for Python cross-language pipelines for Java KafkaIO.\"\"\"\n+\n+from __future__ import absolute_import\n+\n+import contextlib\n+import logging\n+import os\n+import socket\n+import subprocess\n+import time\n+import typing\n+import unittest\n+\n+import grpc\n+\n+import apache_beam as beam\n+from apache_beam.io.external.kafka import ReadFromKafka\n+from apache_beam.io.external.kafka import WriteToKafka\n+from apache_beam.metrics import Metrics\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.testing.test_pipeline import TestPipeline\n+\n+\n+class CrossLanguageKafkaIO(object):\n+  def __init__(self, bootstrap_servers, topic, expansion_service=None):\n+    self.bootstrap_servers = bootstrap_servers\n+    self.topic = topic\n+    self.expansion_service = expansion_service or (\n+        'localhost:%s' % os.environ.get('EXPANSION_PORT'))\n+    self.sum_counter = Metrics.counter('source', 'elements_sum')\n+\n+  def build_write_pipeline(self, pipeline):\n+    _ = (\n+        pipeline\n+        | 'Impulse' >> beam.Impulse()\n+        | 'Generate' >> beam.FlatMap(lambda x: range(1000)) # pylint: disable=range-builtin-not-iterating\n+        | 'Reshuffle' >> beam.Reshuffle()\n+        | 'MakeKV' >> beam.Map(lambda x:\n+                               (b'', str(x).encode())).with_output_types(\n+                                   typing.Tuple[bytes, bytes])\n+        | 'WriteToKafka' >> WriteToKafka(\n+            producer_config={'bootstrap.servers': self.bootstrap_servers},\n+            topic=self.topic,\n+            expansion_service=self.expansion_service))\n+\n+  def build_read_pipeline(self, pipeline):\n+    _ = (\n+        pipeline\n+        | 'ReadFromKafka' >> ReadFromKafka(\n+            consumer_config={\n+                'bootstrap.servers': self.bootstrap_servers,\n+                'auto.offset.reset': 'earliest'\n+            },\n+            topics=[self.topic],\n+            expansion_service=self.expansion_service)\n+        | 'Windowing' >> beam.WindowInto(\n+            beam.window.FixedWindows(300),\n+            trigger=beam.transforms.trigger.AfterProcessingTime(60),\n+            accumulation_mode=beam.transforms.trigger.AccumulationMode.\n+            DISCARDING)\n+        | 'DecodingValue' >> beam.Map(lambda elem: int(elem[1].decode()))\n+        | 'CombineGlobally' >> beam.CombineGlobally(sum).without_defaults()\n+        | 'SetSumCounter' >> beam.Map(self.sum_counter.inc))\n+\n+  def run_xlang_kafkaio(self, pipeline):\n+    self.build_write_pipeline(pipeline)\n+    self.build_read_pipeline(pipeline)\n+    pipeline.run(False)\n+\n+\n+@unittest.skipUnless(\n+    os.environ.get('LOCAL_KAFKA_JAR'),\n+    \"LOCAL_KAFKA_JAR environment var is not provided.\")\n+@unittest.skipUnless(\n+    os.environ.get('EXPANSION_JAR'),\n+    \"EXPANSION_JAR environment var is not provided.\")\n+class CrossLanguageKafkaIOTest(unittest.TestCase):\n+  def get_open_port(self):\n+    s = None\n+    try:\n+      s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n+    except:  # pylint: disable=bare-except\n+      # Above call will fail for nodes that only support IPv6.\n+      s = socket.socket(socket.AF_INET6, socket.SOCK_STREAM)\n+    s.bind(('localhost', 0))\n+    s.listen(1)\n+    port = s.getsockname()[1]\n+    s.close()\n+    return port\n+\n+  @contextlib.contextmanager\n+  def local_services(self, expansion_service_jar_file, local_kafka_jar_file):\n+    expansion_service_port = str(self.get_open_port())\n+    kafka_port = str(self.get_open_port())\n+    zookeeper_port = str(self.get_open_port())\n+\n+    expansion_server = None\n+    kafka_server = None\n+    try:\n+      expansion_server = subprocess.Popen(\n+          ['java', '-jar', expansion_service_jar_file, expansion_service_port])\n+      kafka_server = subprocess.Popen(\n+          ['java', '-jar', local_kafka_jar_file, kafka_port, zookeeper_port])\n+      time.sleep(3)\n+      channel_creds = grpc.local_channel_credentials()\n+      with grpc.secure_channel('localhost:%s' % expansion_service_port,\n+                               channel_creds) as channel:\n+        grpc.channel_ready_future(channel).result()\n+\n+      yield expansion_service_port, kafka_port\n+    finally:\n+      if expansion_server:\n+        expansion_server.kill()\n+      if kafka_server:\n+        kafka_server.kill()\n+\n+  def get_options(self):\n+    options = PipelineOptions([\n+        '--runner',\n+        'FlinkRunner',\n+        '--parallelism',\n+        '2',\n+        '--experiment',\n+        'beam_fn_api'\n+    ])\n+    return options\n+\n+  def test_kafkaio_write(self):\n+    local_kafka_jar = os.environ.get('LOCAL_KAFKA_JAR')\n+    expansion_service_jar = os.environ.get('EXPANSION_JAR')\n+    with self.local_services(expansion_service_jar,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "492adc0fadf110d087d63590e2b655b53543be8c"}, "originalPosition": 131}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjA5Mzk2MQ==", "bodyText": "Is this for external testing (given that internally we have a setup for starting Kafka cluster) ? Or is this required for this test for some reason ?", "url": "https://github.com/apache/beam/pull/11847#discussion_r432093961", "createdAt": "2020-05-28T20:07:18Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/io/external/xlang_kafkaio_it_test.py", "diffHunk": "@@ -0,0 +1,145 @@\n+\"\"\"Integration test for Python cross-language pipelines for Java KafkaIO.\"\"\"\n+\n+from __future__ import absolute_import\n+\n+import contextlib\n+import logging\n+import os\n+import socket\n+import subprocess\n+import time\n+import typing\n+import unittest\n+\n+import grpc\n+\n+import apache_beam as beam\n+from apache_beam.io.external.kafka import ReadFromKafka\n+from apache_beam.io.external.kafka import WriteToKafka\n+from apache_beam.metrics import Metrics\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.testing.test_pipeline import TestPipeline\n+\n+\n+class CrossLanguageKafkaIO(object):\n+  def __init__(self, bootstrap_servers, topic, expansion_service=None):\n+    self.bootstrap_servers = bootstrap_servers\n+    self.topic = topic\n+    self.expansion_service = expansion_service or (\n+        'localhost:%s' % os.environ.get('EXPANSION_PORT'))\n+    self.sum_counter = Metrics.counter('source', 'elements_sum')\n+\n+  def build_write_pipeline(self, pipeline):\n+    _ = (\n+        pipeline\n+        | 'Impulse' >> beam.Impulse()\n+        | 'Generate' >> beam.FlatMap(lambda x: range(1000)) # pylint: disable=range-builtin-not-iterating\n+        | 'Reshuffle' >> beam.Reshuffle()\n+        | 'MakeKV' >> beam.Map(lambda x:\n+                               (b'', str(x).encode())).with_output_types(\n+                                   typing.Tuple[bytes, bytes])\n+        | 'WriteToKafka' >> WriteToKafka(\n+            producer_config={'bootstrap.servers': self.bootstrap_servers},\n+            topic=self.topic,\n+            expansion_service=self.expansion_service))\n+\n+  def build_read_pipeline(self, pipeline):\n+    _ = (\n+        pipeline\n+        | 'ReadFromKafka' >> ReadFromKafka(\n+            consumer_config={\n+                'bootstrap.servers': self.bootstrap_servers,\n+                'auto.offset.reset': 'earliest'\n+            },\n+            topics=[self.topic],\n+            expansion_service=self.expansion_service)\n+        | 'Windowing' >> beam.WindowInto(\n+            beam.window.FixedWindows(300),\n+            trigger=beam.transforms.trigger.AfterProcessingTime(60),\n+            accumulation_mode=beam.transforms.trigger.AccumulationMode.\n+            DISCARDING)\n+        | 'DecodingValue' >> beam.Map(lambda elem: int(elem[1].decode()))\n+        | 'CombineGlobally' >> beam.CombineGlobally(sum).without_defaults()\n+        | 'SetSumCounter' >> beam.Map(self.sum_counter.inc))\n+\n+  def run_xlang_kafkaio(self, pipeline):\n+    self.build_write_pipeline(pipeline)\n+    self.build_read_pipeline(pipeline)\n+    pipeline.run(False)\n+\n+\n+@unittest.skipUnless(\n+    os.environ.get('LOCAL_KAFKA_JAR'),\n+    \"LOCAL_KAFKA_JAR environment var is not provided.\")\n+@unittest.skipUnless(\n+    os.environ.get('EXPANSION_JAR'),\n+    \"EXPANSION_JAR environment var is not provided.\")\n+class CrossLanguageKafkaIOTest(unittest.TestCase):\n+  def get_open_port(self):\n+    s = None\n+    try:\n+      s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n+    except:  # pylint: disable=bare-except\n+      # Above call will fail for nodes that only support IPv6.\n+      s = socket.socket(socket.AF_INET6, socket.SOCK_STREAM)\n+    s.bind(('localhost', 0))\n+    s.listen(1)\n+    port = s.getsockname()[1]\n+    s.close()\n+    return port\n+\n+  @contextlib.contextmanager\n+  def local_services(self, expansion_service_jar_file, local_kafka_jar_file):\n+    expansion_service_port = str(self.get_open_port())\n+    kafka_port = str(self.get_open_port())\n+    zookeeper_port = str(self.get_open_port())\n+\n+    expansion_server = None\n+    kafka_server = None\n+    try:\n+      expansion_server = subprocess.Popen(\n+          ['java', '-jar', expansion_service_jar_file, expansion_service_port])\n+      kafka_server = subprocess.Popen(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "492adc0fadf110d087d63590e2b655b53543be8c"}, "originalPosition": 102}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9e5dd68bb951cf8c7faaf15d4e5852b0fe6963d2", "author": {"user": {"login": "ihji", "name": "Heejong Lee"}}, "url": "https://github.com/apache/beam/commit/9e5dd68bb951cf8c7faaf15d4e5852b0fe6963d2", "committedDate": "2020-05-29T02:28:07Z", "message": "[BEAM-10125] adding cross-language KafkaIO integration test"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "3f6533202dcefca8742f49da60f3109bab403798", "author": {"user": {"login": "ihji", "name": "Heejong Lee"}}, "url": "https://github.com/apache/beam/commit/3f6533202dcefca8742f49da60f3109bab403798", "committedDate": "2020-05-28T23:44:12Z", "message": "fix formatting"}, "afterCommit": {"oid": "9e5dd68bb951cf8c7faaf15d4e5852b0fe6963d2", "author": {"user": {"login": "ihji", "name": "Heejong Lee"}}, "url": "https://github.com/apache/beam/commit/9e5dd68bb951cf8c7faaf15d4e5852b0fe6963d2", "committedDate": "2020-05-29T02:28:07Z", "message": "[BEAM-10125] adding cross-language KafkaIO integration test"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4411, "cost": 1, "resetAt": "2021-10-28T16:48:13Z"}}}