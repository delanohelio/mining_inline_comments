{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzg1ODQwMDgx", "number": 11086, "reviewThreads": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQwMzoxNTozOFrODpvX4Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQxNjoyODo1OVrOEFHsLw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1MDk0MzY5OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/bigquery_read_it_test.py", "isResolved": false, "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yMFQwMzoxNTozOFrOF5Grag==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQxODowMDoyN1rOGGFShQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQyMjU3MA==", "bodyText": "How intuitive will this behavior be to users? should't the output be consistent?\nIf we decide to keep it, how will this be documented?", "url": "https://github.com/apache/beam/pull/11086#discussion_r395422570", "createdAt": "2020-03-20T03:15:38Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/io/gcp/bigquery_read_it_test.py", "diffHunk": "@@ -236,11 +251,12 @@ def create_table(cls, table_name):\n     cls.bigquery_client.insert_rows(\n         cls.project, cls.dataset_id, table_name, table_data)\n \n-  def get_expected_data(self):\n+  def get_expected_data(self, native=True):\n+    byts = b'\\xab\\xac'\n     expected_row = {\n         'float': 0.33,\n         'numeric': Decimal('10'),\n-        'bytes': base64.b64encode(b'\\xab\\xac'),\n+        'bytes': base64.b64encode(byts) if native else byts,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "950abf9d6d95f94c6284958b13248a7ab21702dc"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTkxMDg1NQ==", "bodyText": "The behavior will be different for different transforms. Users will need to explicitly change the transform in their code. We can make them aware of the new transform, and its typing differences in release notes, and possibly in Pydoc for the new transform as well. Thoughts?", "url": "https://github.com/apache/beam/pull/11086#discussion_r395910855", "createdAt": "2020-03-20T22:08:12Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/bigquery_read_it_test.py", "diffHunk": "@@ -236,11 +251,12 @@ def create_table(cls, table_name):\n     cls.bigquery_client.insert_rows(\n         cls.project, cls.dataset_id, table_name, table_data)\n \n-  def get_expected_data(self):\n+  def get_expected_data(self, native=True):\n+    byts = b'\\xab\\xac'\n     expected_row = {\n         'float': 0.33,\n         'numeric': Decimal('10'),\n-        'bytes': base64.b64encode(b'\\xab\\xac'),\n+        'bytes': base64.b64encode(byts) if native else byts,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQyMjU3MA=="}, "originalCommit": {"oid": "950abf9d6d95f94c6284958b13248a7ab21702dc"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5ODIzMjEwOA==", "bodyText": "Bytes treatment should be called out in IO doc, we do mention it: \n  \n    \n      beam/sdks/python/apache_beam/io/gcp/bigquery.py\n    \n    \n         Line 227\n      in\n      8bc2880\n    \n    \n    \n    \n\n        \n          \n           BigQuery IO requires values of BYTES datatype to be encoded using base64 \n        \n    \n  \n\n.\nb64encoding may be unnecessary, and less efficient. I think the reason native IO encodes bytes with b64 is because that was the behavior in Java SDK. We can argue that's not necessary. However I am concerned about the consistency of the UX here. Different UX for two transforms means the transforms will not be interchangeable, and users might overlook this.  This might also cause friction in cross-language pipelines.", "url": "https://github.com/apache/beam/pull/11086#discussion_r398232108", "createdAt": "2020-03-25T23:29:36Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/io/gcp/bigquery_read_it_test.py", "diffHunk": "@@ -236,11 +251,12 @@ def create_table(cls, table_name):\n     cls.bigquery_client.insert_rows(\n         cls.project, cls.dataset_id, table_name, table_data)\n \n-  def get_expected_data(self):\n+  def get_expected_data(self, native=True):\n+    byts = b'\\xab\\xac'\n     expected_row = {\n         'float': 0.33,\n         'numeric': Decimal('10'),\n-        'bytes': base64.b64encode(b'\\xab\\xac'),\n+        'bytes': base64.b64encode(byts) if native else byts,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQyMjU3MA=="}, "originalCommit": {"oid": "950abf9d6d95f94c6284958b13248a7ab21702dc"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzMzODQzMg==", "bodyText": "I think that's reasonable. But I'd think that after slight confusion, users would figure out the differences.\nAnother option is to provide a parameter to the transform to have backwards-compatible types at a performance cost.\n@chamikaramj @tvalentyn  wdyt?", "url": "https://github.com/apache/beam/pull/11086#discussion_r403338432", "createdAt": "2020-04-03T21:12:36Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/bigquery_read_it_test.py", "diffHunk": "@@ -236,11 +251,12 @@ def create_table(cls, table_name):\n     cls.bigquery_client.insert_rows(\n         cls.project, cls.dataset_id, table_name, table_data)\n \n-  def get_expected_data(self):\n+  def get_expected_data(self, native=True):\n+    byts = b'\\xab\\xac'\n     expected_row = {\n         'float': 0.33,\n         'numeric': Decimal('10'),\n-        'bytes': base64.b64encode(b'\\xab\\xac'),\n+        'bytes': base64.b64encode(byts) if native else byts,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQyMjU3MA=="}, "originalCommit": {"oid": "950abf9d6d95f94c6284958b13248a7ab21702dc"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDIxODEyMA==", "bodyText": "Having a parameter for backwards-compatibility would make sense to me, but will defer to @chamikaramj  on this. Since new transform comes with a new name, whoever will be using it, will have to read the API, so will be aware of the issue. But that would mean we add a knob, potentially indefinitely.", "url": "https://github.com/apache/beam/pull/11086#discussion_r404218120", "createdAt": "2020-04-06T16:17:11Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/io/gcp/bigquery_read_it_test.py", "diffHunk": "@@ -236,11 +251,12 @@ def create_table(cls, table_name):\n     cls.bigquery_client.insert_rows(\n         cls.project, cls.dataset_id, table_name, table_data)\n \n-  def get_expected_data(self):\n+  def get_expected_data(self, native=True):\n+    byts = b'\\xab\\xac'\n     expected_row = {\n         'float': 0.33,\n         'numeric': Decimal('10'),\n-        'bytes': base64.b64encode(b'\\xab\\xac'),\n+        'bytes': base64.b64encode(byts) if native else byts,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQyMjU3MA=="}, "originalCommit": {"oid": "950abf9d6d95f94c6284958b13248a7ab21702dc"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNTAxNDg2MA==", "bodyText": "So the proposal right now is: To have a parameter for backwards compatibility in the transform, but by default return Avro-returned types. We will need to have clear Pydoc on _ReadFromBigQuery, and on CHANGES.md.\n@chamikaramj thoughts?", "url": "https://github.com/apache/beam/pull/11086#discussion_r405014860", "createdAt": "2020-04-07T18:14:25Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/bigquery_read_it_test.py", "diffHunk": "@@ -236,11 +251,12 @@ def create_table(cls, table_name):\n     cls.bigquery_client.insert_rows(\n         cls.project, cls.dataset_id, table_name, table_data)\n \n-  def get_expected_data(self):\n+  def get_expected_data(self, native=True):\n+    byts = b'\\xab\\xac'\n     expected_row = {\n         'float': 0.33,\n         'numeric': Decimal('10'),\n-        'bytes': base64.b64encode(b'\\xab\\xac'),\n+        'bytes': base64.b64encode(byts) if native else byts,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQyMjU3MA=="}, "originalCommit": {"oid": "950abf9d6d95f94c6284958b13248a7ab21702dc"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjkzMTIzOQ==", "bodyText": "@chamikaramj @tvalentyn @kamilwu - added a backward compatibility flag. Can you review?", "url": "https://github.com/apache/beam/pull/11086#discussion_r406931239", "createdAt": "2020-04-10T20:32:56Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/bigquery_read_it_test.py", "diffHunk": "@@ -236,11 +251,12 @@ def create_table(cls, table_name):\n     cls.bigquery_client.insert_rows(\n         cls.project, cls.dataset_id, table_name, table_data)\n \n-  def get_expected_data(self):\n+  def get_expected_data(self, native=True):\n+    byts = b'\\xab\\xac'\n     expected_row = {\n         'float': 0.33,\n         'numeric': Decimal('10'),\n-        'bytes': base64.b64encode(b'\\xab\\xac'),\n+        'bytes': base64.b64encode(byts) if native else byts,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQyMjU3MA=="}, "originalCommit": {"oid": "950abf9d6d95f94c6284958b13248a7ab21702dc"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjkzMTQ3Mg==", "bodyText": "If the changes are reasonable, I'll add to release notes", "url": "https://github.com/apache/beam/pull/11086#discussion_r406931472", "createdAt": "2020-04-10T20:33:26Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/bigquery_read_it_test.py", "diffHunk": "@@ -236,11 +251,12 @@ def create_table(cls, table_name):\n     cls.bigquery_client.insert_rows(\n         cls.project, cls.dataset_id, table_name, table_data)\n \n-  def get_expected_data(self):\n+  def get_expected_data(self, native=True):\n+    byts = b'\\xab\\xac'\n     expected_row = {\n         'float': 0.33,\n         'numeric': Decimal('10'),\n-        'bytes': base64.b64encode(b'\\xab\\xac'),\n+        'bytes': base64.b64encode(byts) if native else byts,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQyMjU3MA=="}, "originalCommit": {"oid": "950abf9d6d95f94c6284958b13248a7ab21702dc"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTAzMTMwMQ==", "bodyText": "I think having a single \"backwards compatibility\" parameter can be confusing and error prone. We might still be backwards incompatible in some unknown ways. I think it's better to document exact differences between the transforms and give clear documentation/guidelines for anyone who is upgrading.", "url": "https://github.com/apache/beam/pull/11086#discussion_r409031301", "createdAt": "2020-04-15T18:00:27Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/io/gcp/bigquery_read_it_test.py", "diffHunk": "@@ -236,11 +251,12 @@ def create_table(cls, table_name):\n     cls.bigquery_client.insert_rows(\n         cls.project, cls.dataset_id, table_name, table_data)\n \n-  def get_expected_data(self):\n+  def get_expected_data(self, native=True):\n+    byts = b'\\xab\\xac'\n     expected_row = {\n         'float': 0.33,\n         'numeric': Decimal('10'),\n-        'bytes': base64.b64encode(b'\\xab\\xac'),\n+        'bytes': base64.b64encode(byts) if native else byts,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NTQyMjU3MA=="}, "originalCommit": {"oid": "950abf9d6d95f94c6284958b13248a7ab21702dc"}, "originalPosition": 40}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1ODc1NzkzOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yM1QxNzo0MzoyOFrOF6Q0Tw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wN1QxMDozNjozM1rOGB9b8A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjYzNzI2Mw==", "bodyText": "Does it mean that coder is no longer needed for _CustomBigQuerySource?", "url": "https://github.com/apache/beam/pull/11086#discussion_r396637263", "createdAt": "2020-03-23T17:43:28Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -663,14 +662,10 @@ def split(self, desired_bundle_size, start_position=None, stop_position=None):\n         self._setup_temporary_dataset(bq)\n         self.table_reference = self._execute_query(bq)\n \n-      schema, metadata_list = self._export_files(bq)\n+      unused_schema, metadata_list = self._export_files(bq)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "950abf9d6d95f94c6284958b13248a7ab21702dc"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMzMzNzk2OQ==", "bodyText": "You're correct!", "url": "https://github.com/apache/beam/pull/11086#discussion_r403337969", "createdAt": "2020-04-03T21:11:20Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -663,14 +662,10 @@ def split(self, desired_bundle_size, start_position=None, stop_position=None):\n         self._setup_temporary_dataset(bq)\n         self.table_reference = self._execute_query(bq)\n \n-      schema, metadata_list = self._export_files(bq)\n+      unused_schema, metadata_list = self._export_files(bq)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjYzNzI2Mw=="}, "originalCommit": {"oid": "950abf9d6d95f94c6284958b13248a7ab21702dc"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDAwMDE1Mw==", "bodyText": "This is great! That would mean that we can safely remove _JsonToDictCoder. Do you think you can do this as a part of this PR?", "url": "https://github.com/apache/beam/pull/11086#discussion_r404000153", "createdAt": "2020-04-06T10:52:25Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -663,14 +662,10 @@ def split(self, desired_bundle_size, start_position=None, stop_position=None):\n         self._setup_temporary_dataset(bq)\n         self.table_reference = self._execute_query(bq)\n \n-      schema, metadata_list = self._export_files(bq)\n+      unused_schema, metadata_list = self._export_files(bq)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjYzNzI2Mw=="}, "originalCommit": {"oid": "950abf9d6d95f94c6284958b13248a7ab21702dc"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDQ4MzExMA==", "bodyText": "We may do that, but if we end up keeping a backwards compatibility flag, we'll need to keep the coder as-is.", "url": "https://github.com/apache/beam/pull/11086#discussion_r404483110", "createdAt": "2020-04-07T01:26:23Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -663,14 +662,10 @@ def split(self, desired_bundle_size, start_position=None, stop_position=None):\n         self._setup_temporary_dataset(bq)\n         self.table_reference = self._execute_query(bq)\n \n-      schema, metadata_list = self._export_files(bq)\n+      unused_schema, metadata_list = self._export_files(bq)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjYzNzI2Mw=="}, "originalCommit": {"oid": "950abf9d6d95f94c6284958b13248a7ab21702dc"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDcwODMzNg==", "bodyText": "I see. Then let's wait for the decision.", "url": "https://github.com/apache/beam/pull/11086#discussion_r404708336", "createdAt": "2020-04-07T10:36:33Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -663,14 +662,10 @@ def split(self, desired_bundle_size, start_position=None, stop_position=None):\n         self._setup_temporary_dataset(bq)\n         self.table_reference = self._execute_query(bq)\n \n-      schema, metadata_list = self._export_files(bq)\n+      unused_schema, metadata_list = self._export_files(bq)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjYzNzI2Mw=="}, "originalCommit": {"oid": "950abf9d6d95f94c6284958b13248a7ab21702dc"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ1ODc2NzM1OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/bigquery_read_it_test.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yM1QxNzo0NTo0MFrOF6Q59g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQxODowMzo0OVrOGUSrfQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjYzODcxMA==", "bodyText": "We can combine this condition with the one below:\nif isinstance(v, datetime.time) or isinstance(v, datetime.date):", "url": "https://github.com/apache/beam/pull/11086#discussion_r396638710", "createdAt": "2020-03-23T17:45:40Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/bigquery_read_it_test.py", "diffHunk": "@@ -69,6 +70,20 @@ def wrapped(self):\n   return inner\n \n \n+def datetime_to_utc(element):\n+  for k, v in element.items():\n+    if isinstance(v, datetime.time):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "950abf9d6d95f94c6284958b13248a7ab21702dc"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzkzMDc0OQ==", "bodyText": "or isinstance(v, (datetime.time, datetime.date))", "url": "https://github.com/apache/beam/pull/11086#discussion_r423930749", "createdAt": "2020-05-12T18:03:49Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/io/gcp/bigquery_read_it_test.py", "diffHunk": "@@ -69,6 +70,20 @@ def wrapped(self):\n   return inner\n \n \n+def datetime_to_utc(element):\n+  for k, v in element.items():\n+    if isinstance(v, datetime.time):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5NjYzODcxMA=="}, "originalCommit": {"oid": "950abf9d6d95f94c6284958b13248a7ab21702dc"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNTc2OTUzOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQyMjoyNjoyM1rOGEHXbQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQxNzo0MzoxOFrOGGEqgg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjk2ODE3Mw==", "bodyText": "Can we use a bool as a default value instead of None?\nCan we use rename this flag to something that describes the course of action, for example: use_json_data_representation=False - you can come up with a better name.", "url": "https://github.com/apache/beam/pull/11086#discussion_r406968173", "createdAt": "2020-04-10T22:26:23Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -609,7 +611,8 @@ def __init__(\n       coder=None,\n       use_standard_sql=False,\n       flatten_results=True,\n-      kms_key=None):\n+      kms_key=None,\n+      backwards_compatible_data_format=None):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "80138416bcd10b84b3a473d83738c52d970f91f5"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTAyMTA1OA==", "bodyText": "Done.\nI've called it use_json_exports - does that help?", "url": "https://github.com/apache/beam/pull/11086#discussion_r409021058", "createdAt": "2020-04-15T17:43:18Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -609,7 +611,8 @@ def __init__(\n       coder=None,\n       use_standard_sql=False,\n       flatten_results=True,\n-      kms_key=None):\n+      kms_key=None,\n+      backwards_compatible_data_format=None):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjk2ODE3Mw=="}, "originalCommit": {"oid": "80138416bcd10b84b3a473d83738c52d970f91f5"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyNTc3ODkyOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xMFQyMjozMjoyMFrOGEHdDQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQxNzo0MzozNlrOGGErQg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjk2OTYxMw==", "bodyText": "Do all BQ types have a native python type?\nWhat are JSON-types?", "url": "https://github.com/apache/beam/pull/11086#discussion_r406969613", "createdAt": "2020-04-10T22:32:20Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -1570,6 +1584,10 @@ class _ReadFromBigQuery(PTransform):\n       bucket where the extracted table should be written as a string or\n       a :class:`~apache_beam.options.value_provider.ValueProvider`. If\n       :data:`None`, then the temp_location parameter is used.\n+    backwards_compatible_data_format (bool): By default, this transform reads\n+      data in native Python types that come from Avro-exports of BigQuery. By\n+      setting this flag to True, the transform will return JSON-types, like\n+      the older BigQuerySource.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "80138416bcd10b84b3a473d83738c52d970f91f5"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTAyMTI1MA==", "bodyText": "I've added a link to https://cloud.google.com/bigquery/docs/loading-data-cloud-storage-avro#avro_conversions for details on the conversions. I've also rephrased the doc. LMK what you think.", "url": "https://github.com/apache/beam/pull/11086#discussion_r409021250", "createdAt": "2020-04-15T17:43:36Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -1570,6 +1584,10 @@ class _ReadFromBigQuery(PTransform):\n       bucket where the extracted table should be written as a string or\n       a :class:`~apache_beam.options.value_provider.ValueProvider`. If\n       :data:`None`, then the temp_location parameter is used.\n+    backwards_compatible_data_format (bool): By default, this transform reads\n+      data in native Python types that come from Avro-exports of BigQuery. By\n+      setting this flag to True, the transform will return JSON-types, like\n+      the older BigQuerySource.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNjk2OTYxMw=="}, "originalCommit": {"oid": "80138416bcd10b84b3a473d83738c52d970f91f5"}, "originalPosition": 69}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzOTQxOTUwOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQxNzo0NTozMFrOGGEv1Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQxNjoxMDo0MFrOGjJpLQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTAyMjQyMQ==", "bodyText": "Let's document subtle differences between the two types (and two transforms ?) in doc comments of _ReadFromBigQuery so that users who upgrade/change the BigQuery read transforms have clear guidelines for updating their pipelines.", "url": "https://github.com/apache/beam/pull/11086#discussion_r409022421", "createdAt": "2020-04-15T17:45:30Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -732,11 +748,20 @@ def _export_files(self, bq):\n       bigquery.TableSchema instance, a list of FileMetadata instances\n     \"\"\"\n     job_id = uuid.uuid4().hex\n-    job_ref = bq.perform_extract_job([self.gcs_location],\n-                                     job_id,\n-                                     self.table_reference,\n-                                     bigquery_tools.FileFormat.JSON,\n-                                     include_header=False)\n+    if self.use_json_exports:\n+      job_ref = bq.perform_extract_job([self.gcs_location],\n+                                       job_id,\n+                                       self.table_reference,\n+                                       bigquery_tools.FileFormat.JSON,\n+                                       include_header=False)\n+    else:\n+      job_ref = bq.perform_extract_job([self.gcs_location],", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0864dbdd00e47152b6d904d1d9b1ad8400c81f52"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTUxMTM0MQ==", "bodyText": "Is this resolved?", "url": "https://github.com/apache/beam/pull/11086#discussion_r439511341", "createdAt": "2020-06-12T16:10:40Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -732,11 +748,20 @@ def _export_files(self, bq):\n       bigquery.TableSchema instance, a list of FileMetadata instances\n     \"\"\"\n     job_id = uuid.uuid4().hex\n-    job_ref = bq.perform_extract_job([self.gcs_location],\n-                                     job_id,\n-                                     self.table_reference,\n-                                     bigquery_tools.FileFormat.JSON,\n-                                     include_header=False)\n+    if self.use_json_exports:\n+      job_ref = bq.perform_extract_job([self.gcs_location],\n+                                       job_id,\n+                                       self.table_reference,\n+                                       bigquery_tools.FileFormat.JSON,\n+                                       include_header=False)\n+    else:\n+      job_ref = bq.perform_extract_job([self.gcs_location],", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTAyMjQyMQ=="}, "originalCommit": {"oid": "0864dbdd00e47152b6d904d1d9b1ad8400c81f52"}, "originalPosition": 82}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzOTQzNDM4OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQxNzo0OTo0MFrOGGE5Wg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQxNzo0OTo0MFrOGGE5Wg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTAyNDg1OA==", "bodyText": "Probably cleaner to use the \"param_name=value\" format here for keyword arguments and not specify anything when we just want the default.", "url": "https://github.com/apache/beam/pull/11086#discussion_r409024858", "createdAt": "2020-04-15T17:49:40Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -669,6 +681,13 @@ def estimate_size(self):\n       # no access to the query that we're running.\n       return None\n \n+  def _create_source(self, path, schema):\n+    if not self.use_json_exports:\n+      return create_avro_source(path, 0, True, use_fastavro=True)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0864dbdd00e47152b6d904d1d9b1ad8400c81f52"}, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzOTQzNTAwOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQxNzo0OTo1MFrOGGE5xg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQxNzo0OTo1MFrOGGE5xg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTAyNDk2Ng==", "bodyText": "Ditto.", "url": "https://github.com/apache/beam/pull/11086#discussion_r409024966", "createdAt": "2020-04-15T17:49:50Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -669,6 +681,13 @@ def estimate_size(self):\n       # no access to the query that we're running.\n       return None\n \n+  def _create_source(self, path, schema):\n+    if not self.use_json_exports:\n+      return create_avro_source(path, 0, True, use_fastavro=True)\n+    else:\n+      return TextSource(\n+          path, 0, CompressionTypes.UNCOMPRESSED, True, self.coder(schema))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0864dbdd00e47152b6d904d1d9b1ad8400c81f52"}, "originalPosition": 44}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzOTQ0MDUzOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "isResolved": false, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQxNzo1MToxNlrOGGE9Cg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQxOTo1MjozMFrOGZAoPA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTAyNTgwMg==", "bodyText": "Is there a reason to continue supporting JSON for the new transform (once we get our current performance issues) ? Probably we should document why users may choose JSON over Avro if we want to support both.", "url": "https://github.com/apache/beam/pull/11086#discussion_r409025802", "createdAt": "2020-04-15T17:51:16Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -610,7 +611,8 @@ def __init__(\n       coder=None,\n       use_standard_sql=False,\n       flatten_results=True,\n-      kms_key=None):\n+      kms_key=None,\n+      use_json_exports=False):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0864dbdd00e47152b6d904d1d9b1ad8400c81f52"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTA5MDEwMQ==", "bodyText": "not supporting JSON would increase the amount of changes that users need to make to migrate to the new source, as the data output types would change. I don't think this would be ideal. Wouldn't it be better to allow users to migrate to the new source without having to change the rest of their pipeline?", "url": "https://github.com/apache/beam/pull/11086#discussion_r409090101", "createdAt": "2020-04-15T19:42:53Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -610,7 +611,8 @@ def __init__(\n       coder=None,\n       use_standard_sql=False,\n       flatten_results=True,\n-      kms_key=None):\n+      kms_key=None,\n+      use_json_exports=False):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTAyNTgwMg=="}, "originalCommit": {"oid": "0864dbdd00e47152b6d904d1d9b1ad8400c81f52"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzkzNDI2OA==", "bodyText": "Assuming Avro is a superior format, I think we should drop support for json (but not right away). My preference would be to have this choice be orthogonal to the choice of types (and having the bytes default to be base64 encoded feels really wrong) so do think having a backwards compatibility parameter is preferable. (If it's just the date and bytes types, I would split this into two parameters: use_base64_encoded_bytes and datedtime_type.)", "url": "https://github.com/apache/beam/pull/11086#discussion_r423934268", "createdAt": "2020-05-12T18:09:40Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -610,7 +611,8 @@ def __init__(\n       coder=None,\n       use_standard_sql=False,\n       flatten_results=True,\n-      kms_key=None):\n+      kms_key=None,\n+      use_json_exports=False):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTAyNTgwMg=="}, "originalCommit": {"oid": "0864dbdd00e47152b6d904d1d9b1ad8400c81f52"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDA4OTcwMw==", "bodyText": "\"having the bytes default to be base64 encoded feels really wrong\" .\n\nI think we changed bytes to be base64-encoded several years back, because Java SDK used that representation: https://github.com/apache/beam/blob/master/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryIO.java#L181-L182", "url": "https://github.com/apache/beam/pull/11086#discussion_r424089703", "createdAt": "2020-05-12T23:25:46Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -610,7 +611,8 @@ def __init__(\n       coder=None,\n       use_standard_sql=False,\n       flatten_results=True,\n-      kms_key=None):\n+      kms_key=None,\n+      use_json_exports=False):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTAyNTgwMg=="}, "originalCommit": {"oid": "0864dbdd00e47152b6d904d1d9b1ad8400c81f52"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDA5MjA3Ng==", "bodyText": "Yes, the joys of matching what was done in Java years ago for the Dataflow service API.", "url": "https://github.com/apache/beam/pull/11086#discussion_r424092076", "createdAt": "2020-05-12T23:33:28Z", "author": {"login": "lukecwik"}, "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -610,7 +611,8 @@ def __init__(\n       coder=None,\n       use_standard_sql=False,\n       flatten_results=True,\n-      kms_key=None):\n+      kms_key=None,\n+      use_json_exports=False):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTAyNTgwMg=="}, "originalCommit": {"oid": "0864dbdd00e47152b6d904d1d9b1ad8400c81f52"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODg3Nzg4NA==", "bodyText": "Restarting this discussion after some rebasing and preparing...\nI think I'd prefer to allow users to choose the export file format. This is what we do for writing to BQ in Java and Python. Allowing users to choose output type for specific column types would add overhead of (if avro and json_format_bytes: formatbytes; if avro and json_datetime_format: formatdatetime; if not avro and not json_format_bytes: formatbytes; ...).\nWe can discourage users from using JSON (AVRO is already the default) - and eventually stop supporting it if that makes sense. Thoughts?", "url": "https://github.com/apache/beam/pull/11086#discussion_r428877884", "createdAt": "2020-05-21T19:52:30Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -610,7 +611,8 @@ def __init__(\n       coder=None,\n       use_standard_sql=False,\n       flatten_results=True,\n-      kms_key=None):\n+      kms_key=None,\n+      use_json_exports=False):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTAyNTgwMg=="}, "originalCommit": {"oid": "0864dbdd00e47152b6d904d1d9b1ad8400c81f52"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYwNDc1MjA5OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wMVQxNjowNjo1MFrOGPN6mQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQxNjowOToyOFrOGjJl1g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODYwOTgxNw==", "bodyText": "Typo in From", "url": "https://github.com/apache/beam/pull/11086#discussion_r418609817", "createdAt": "2020-05-01T16:06:50Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -45,8 +45,8 @@\n may use some caching techniques to share the side inputs between calls in order\n to avoid excessive reading:::\n \n-  main_table = pipeline | 'VeryBig' >> beam.io.Read(beam.io.BigQuerySource()\n-  side_table = pipeline | 'NotBig' >> beam.io.Read(beam.io.BigQuerySource()\n+  main_table = pipeline | 'VeryBig' >> beam.io.ReadFroBigQuery(...)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e1aa4b68dd69221752d8a50a8dec4d6976e23333"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTUxMDQ4Ng==", "bodyText": "Ping on this", "url": "https://github.com/apache/beam/pull/11086#discussion_r439510486", "createdAt": "2020-06-12T16:09:28Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -45,8 +45,8 @@\n may use some caching techniques to share the side inputs between calls in order\n to avoid excessive reading:::\n \n-  main_table = pipeline | 'VeryBig' >> beam.io.Read(beam.io.BigQuerySource()\n-  side_table = pipeline | 'NotBig' >> beam.io.Read(beam.io.BigQuerySource()\n+  main_table = pipeline | 'VeryBig' >> beam.io.ReadFroBigQuery(...)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODYwOTgxNw=="}, "originalCommit": {"oid": "e1aa4b68dd69221752d8a50a8dec4d6976e23333"}, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYwNDc4NjA1OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wMVQxNjoxOTozNVrOGPOQYQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQxNjoxMDoyNFrOGjJoUg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODYxNTM5Mw==", "bodyText": "Can we add some guidance when to use which?", "url": "https://github.com/apache/beam/pull/11086#discussion_r418615393", "createdAt": "2020-05-01T16:19:35Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -78,6 +72,12 @@\n or a table. Pipeline construction will fail with a validation error if neither\n or both are specified.\n \n+When reading from BigQuery using `BigQuerySource`, bytes are returned as", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e1aa4b68dd69221752d8a50a8dec4d6976e23333"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTUxMTEyMg==", "bodyText": "Ping on this - do we need to guide users in any way which transform they should use? Is some of them experimental or to be deprecated?", "url": "https://github.com/apache/beam/pull/11086#discussion_r439511122", "createdAt": "2020-06-12T16:10:24Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -78,6 +72,12 @@\n or a table. Pipeline construction will fail with a validation error if neither\n or both are specified.\n \n+When reading from BigQuery using `BigQuerySource`, bytes are returned as", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODYxNTM5Mw=="}, "originalCommit": {"oid": "e1aa4b68dd69221752d8a50a8dec4d6976e23333"}, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY5MTM2Nzk5OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/big_query_query_to_table_it_test.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQyMDo0NDoyOVrOGcGDOw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQyMTowMDoyMlrOGhcSxw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjExMjQ0Mw==", "bodyText": "Looks like we run this test internally using this name. Since this test now changes to  use_beam_bq_sink, please check that  maintain reasonable internal test coverage for the native sink, or use a new test name for new behavior.", "url": "https://github.com/apache/beam/pull/11086#discussion_r432112443", "createdAt": "2020-05-28T20:44:29Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/io/gcp/big_query_query_to_table_it_test.py", "diffHunk": "@@ -254,11 +256,36 @@ def test_big_query_new_types(self):\n         'output_schema': NEW_TYPES_OUTPUT_SCHEMA,\n         'use_standard_sql': False,\n         'wait_until_finish_duration': WAIT_UNTIL_FINISH_DURATION_MS,\n+        'use_json_exports': True,\n         'on_success_matcher': all_of(*pipeline_verifiers)\n     }\n     options = self.test_pipeline.get_full_options_as_args(**extra_opts)\n     big_query_query_to_table_pipeline.run_bq_pipeline(options)\n \n+  @attr('IT')\n+  def test_big_query_new_types(self):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "58dd68604e568637cab28bdbecbb72d44502f7b4"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzcxOTc1MQ==", "bodyText": "Thanks for pointing that out. I've renamed the test cases to keep coverage for the feature on the same test.", "url": "https://github.com/apache/beam/pull/11086#discussion_r437719751", "createdAt": "2020-06-09T21:00:22Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/big_query_query_to_table_it_test.py", "diffHunk": "@@ -254,11 +256,36 @@ def test_big_query_new_types(self):\n         'output_schema': NEW_TYPES_OUTPUT_SCHEMA,\n         'use_standard_sql': False,\n         'wait_until_finish_duration': WAIT_UNTIL_FINISH_DURATION_MS,\n+        'use_json_exports': True,\n         'on_success_matcher': all_of(*pipeline_verifiers)\n     }\n     options = self.test_pipeline.get_full_options_as_args(**extra_opts)\n     big_query_query_to_table_pipeline.run_bq_pipeline(options)\n \n+  @attr('IT')\n+  def test_big_query_new_types(self):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjExMjQ0Mw=="}, "originalCommit": {"oid": "58dd68604e568637cab28bdbecbb72d44502f7b4"}, "originalPosition": 40}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczODAzOTUwOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQxNjoyNzozNlrOGjKTVg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQxODo1NzowOFrOGjOlCQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTUyMjEzNA==", "bodyText": "nit: exports", "url": "https://github.com/apache/beam/pull/11086#discussion_r439522134", "createdAt": "2020-06-12T16:27:36Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -78,6 +72,12 @@\n or a table. Pipeline construction will fail with a validation error if neither\n or both are specified.\n \n+When reading from BigQuery using `BigQuerySource`, bytes are returned as\n+base64-encoded bytes. When reading via `ReadFromBigQuery`, bytes are returned\n+as bytes without base64 encoding. This is due to the fact that ReadFromBigQuery\n+uses Avro expors by default. To get base64-encoded bytes, you can use the flag", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5566f44a5a9027d3bdaa384c2ebce86284fded48"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTU5MjIwMQ==", "bodyText": "done", "url": "https://github.com/apache/beam/pull/11086#discussion_r439592201", "createdAt": "2020-06-12T18:57:08Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -78,6 +72,12 @@\n or a table. Pipeline construction will fail with a validation error if neither\n or both are specified.\n \n+When reading from BigQuery using `BigQuerySource`, bytes are returned as\n+base64-encoded bytes. When reading via `ReadFromBigQuery`, bytes are returned\n+as bytes without base64 encoding. This is due to the fact that ReadFromBigQuery\n+uses Avro expors by default. To get base64-encoded bytes, you can use the flag", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTUyMjEzNA=="}, "originalCommit": {"oid": "5566f44a5a9027d3bdaa384c2ebce86284fded48"}, "originalPosition": 35}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczODA0MzM1OnYy", "diffSide": "RIGHT", "path": "CHANGES.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQxNjoyODo1OVrOGjKV0w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMlQxODo1NzoxOFrOGjOlaQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTUyMjc3MQ==", "bodyText": "To confirm - there is no changes in behavior for old sync, right?", "url": "https://github.com/apache/beam/pull/11086#discussion_r439522771", "createdAt": "2020-06-12T16:28:59Z", "author": {"login": "tvalentyn"}, "path": "CHANGES.md", "diffHunk": "@@ -58,6 +58,10 @@\n \n * Support for X source added (Java/Python) ([BEAM-X](https://issues.apache.org/jira/browse/BEAM-X)).\n * Support for reading from Snowflake added (Java) ([BEAM-9722](https://issues.apache.org/jira/browse/BEAM-9722)).\n+* A new transform to read from BigQuery has been added: `apache_beam.io.gcp.bigquery.ReadFromBigQuery`. This transform", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5566f44a5a9027d3bdaa384c2ebce86284fded48"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTU5MjI5Nw==", "bodyText": "that's correct.", "url": "https://github.com/apache/beam/pull/11086#discussion_r439592297", "createdAt": "2020-06-12T18:57:18Z", "author": {"login": "pabloem"}, "path": "CHANGES.md", "diffHunk": "@@ -58,6 +58,10 @@\n \n * Support for X source added (Java/Python) ([BEAM-X](https://issues.apache.org/jira/browse/BEAM-X)).\n * Support for reading from Snowflake added (Java) ([BEAM-9722](https://issues.apache.org/jira/browse/BEAM-9722)).\n+* A new transform to read from BigQuery has been added: `apache_beam.io.gcp.bigquery.ReadFromBigQuery`. This transform", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTUyMjc3MQ=="}, "originalCommit": {"oid": "5566f44a5a9027d3bdaa384c2ebce86284fded48"}, "originalPosition": 4}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1831, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}