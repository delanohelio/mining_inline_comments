{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE2MTE0MzY2", "number": 11661, "title": "[BEAM-7774] Remove perfkit benchmarking tool from python performance \u2026", "bodyText": "Remove Perfkit benchmarking tool from python performance test and publish the metrics to influx, display on grafana.\nPlease add a meaningful description for your change here\n\nThank you for your contribution! Follow this checklist to help us incorporate your contribution quickly and easily:\n\n Choose reviewer(s) and mention them in a comment (R: @username).\n Format the pull request title like [BEAM-XXX] Fixes bug in ApproximateQuantiles, where you replace BEAM-XXX with the appropriate JIRA issue, if applicable. This will automatically link the pull request to the issue.\n Update CHANGES.md with noteworthy changes.\n If this contribution is large, please file an Apache Individual Contributor License Agreement.\n\nSee the Contributor Guide for more tips on how to make review process smoother.\nPost-Commit Tests Status (on master branch)\n\n\n\nLang\nSDK\nApex\nDataflow\nFlink\nGearpump\nSamza\nSpark\n\n\n\n\nGo\n\n---\n---\n\n---\n---\n\n\n\nJava\n\n\n\n\n\n\n\n\n\nPython\n\n---\n\n\n---\n---\n\n\n\nXLang\n---\n---\n---\n\n---\n---\n\n\n\n\nPre-Commit Tests Status (on master branch)\n\n\n\n---\nJava\nPython\nGo\nWebsite\n\n\n\n\nNon-portable\n\n\n\n\n\n\nPortable\n---\n\n---\n---\n\n\n\nSee .test-infra/jenkins/README for trigger phrase, status and link of all Jenkins jobs.", "createdAt": "2020-05-11T13:43:33Z", "url": "https://github.com/apache/beam/pull/11661", "merged": true, "mergeCommit": {"oid": "19931023224768341c45af1b5bd81835ea6c7edc"}, "closed": true, "closedAt": "2020-06-03T08:12:45Z", "author": {"login": "piotr-szuberski"}, "timelineItems": {"totalCount": 27, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcgRxBBgBqjMzMjM2MjMxODU=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcnW2_JABqjMzOTgzMTI0MDM=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f24beef37004a29ee3b44bcdb93da7d3798e9f0c", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/f24beef37004a29ee3b44bcdb93da7d3798e9f0c", "committedDate": "2020-05-11T13:40:18Z", "message": "[BEAM-7774] Remove perfkit benchmarking tool from python performance tests"}, "afterCommit": {"oid": "a9d345c1304e5f7eec93a3859ad4f62094eceeb6", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/a9d345c1304e5f7eec93a3859ad4f62094eceeb6", "committedDate": "2020-05-11T15:52:29Z", "message": "[BEAM-7774] Remove perfkit benchmarking tool from python performance tests"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a9d345c1304e5f7eec93a3859ad4f62094eceeb6", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/a9d345c1304e5f7eec93a3859ad4f62094eceeb6", "committedDate": "2020-05-11T15:52:29Z", "message": "[BEAM-7774] Remove perfkit benchmarking tool from python performance tests"}, "afterCommit": {"oid": "9c49645656afcb9efdb3927ff2e09769dc9f525c", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/9c49645656afcb9efdb3927ff2e09769dc9f525c", "committedDate": "2020-05-11T16:04:02Z", "message": "[BEAM-7774] Remove perfkit benchmarking tool from python performance tests"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9c49645656afcb9efdb3927ff2e09769dc9f525c", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/9c49645656afcb9efdb3927ff2e09769dc9f525c", "committedDate": "2020-05-11T16:04:02Z", "message": "[BEAM-7774] Remove perfkit benchmarking tool from python performance tests"}, "afterCommit": {"oid": "6eeab88fa2ba3403c88c175d3a1570748d62d994", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/6eeab88fa2ba3403c88c175d3a1570748d62d994", "committedDate": "2020-05-11T16:07:13Z", "message": "[BEAM-7774] Remove perfkit benchmarking tool from python performance tests"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "6eeab88fa2ba3403c88c175d3a1570748d62d994", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/6eeab88fa2ba3403c88c175d3a1570748d62d994", "committedDate": "2020-05-11T16:07:13Z", "message": "[BEAM-7774] Remove perfkit benchmarking tool from python performance tests"}, "afterCommit": {"oid": "b1a3c51effd3250308bc4c96ec31140933e19268", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/b1a3c51effd3250308bc4c96ec31140933e19268", "committedDate": "2020-05-11T16:10:13Z", "message": "[BEAM-7774] Remove perfkit benchmarking tool from python performance tests"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b1a3c51effd3250308bc4c96ec31140933e19268", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/b1a3c51effd3250308bc4c96ec31140933e19268", "committedDate": "2020-05-11T16:10:13Z", "message": "[BEAM-7774] Remove perfkit benchmarking tool from python performance tests"}, "afterCommit": {"oid": "9ec9f6620fb0bd38e309931dc335494f9d7b7178", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/9ec9f6620fb0bd38e309931dc335494f9d7b7178", "committedDate": "2020-05-19T13:05:00Z", "message": "[BEAM-7774] Remove perfkit benchmarking tool from python performance tests"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9ec9f6620fb0bd38e309931dc335494f9d7b7178", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/9ec9f6620fb0bd38e309931dc335494f9d7b7178", "committedDate": "2020-05-19T13:05:00Z", "message": "[BEAM-7774] Remove perfkit benchmarking tool from python performance tests"}, "afterCommit": {"oid": "414239cd30aa62ff3db1bfe29c0cac6fdaeeb8ba", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/414239cd30aa62ff3db1bfe29c0cac6fdaeeb8ba", "committedDate": "2020-05-19T13:59:36Z", "message": "[BEAM-7774] Remove perfkit benchmarking tool from python performance tests"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "414239cd30aa62ff3db1bfe29c0cac6fdaeeb8ba", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/414239cd30aa62ff3db1bfe29c0cac6fdaeeb8ba", "committedDate": "2020-05-19T13:59:36Z", "message": "[BEAM-7774] Remove perfkit benchmarking tool from python performance tests"}, "afterCommit": {"oid": "90f5745b47e84bff0bf8c87123046d44c85d0deb", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/90f5745b47e84bff0bf8c87123046d44c85d0deb", "committedDate": "2020-05-19T14:11:22Z", "message": "[BEAM-7774] Remove perfkit benchmarking tool from python performance tests"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "90f5745b47e84bff0bf8c87123046d44c85d0deb", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/90f5745b47e84bff0bf8c87123046d44c85d0deb", "committedDate": "2020-05-19T14:11:22Z", "message": "[BEAM-7774] Remove perfkit benchmarking tool from python performance tests"}, "afterCommit": {"oid": "ae329623f561e2ac95972f336e751068abae0674", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/ae329623f561e2ac95972f336e751068abae0674", "committedDate": "2020-05-19T14:47:18Z", "message": "[BEAM-7774] Remove perfkit benchmarking tool from python performance tests"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ae329623f561e2ac95972f336e751068abae0674", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/ae329623f561e2ac95972f336e751068abae0674", "committedDate": "2020-05-19T14:47:18Z", "message": "[BEAM-7774] Remove perfkit benchmarking tool from python performance tests"}, "afterCommit": {"oid": "ca6200110135814a90bfcdf9f24e53d01f83ea0e", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/ca6200110135814a90bfcdf9f24e53d01f83ea0e", "committedDate": "2020-05-19T15:06:18Z", "message": "[BEAM-7774] Remove perfkit benchmarking tool from python performance tests"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE0NjEzNDE5", "url": "https://github.com/apache/beam/pull/11661#pullrequestreview-414613419", "createdAt": "2020-05-19T16:19:50Z", "commit": {"oid": "ca6200110135814a90bfcdf9f24e53d01f83ea0e"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQxNjoxOTo1MFrOGXoTAQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQxOToyMjowOFrOGXvNaQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzQzMDY1Nw==", "bodyText": "Can we import this from common.gradle?", "url": "https://github.com/apache/beam/pull/11661#discussion_r427430657", "createdAt": "2020-05-19T16:19:50Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/test-suites/dataflow/py2/build.gradle", "diffHunk": "@@ -205,3 +205,20 @@ task chicagoTaxiExample {\n     }\n   }\n }\n+\n+task runPerformanceTest {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca6200110135814a90bfcdf9f24e53d01f83ea0e"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzUxNzk1MA==", "bodyText": "I don't think there is significant value to run across all Python version. We can keep Py 27 and Py37 for now, and then switch to one of \"high-priority\"[1] versions once we introduce that concept. cc: @lazylynx\n[1] https://lists.apache.org/thread.html/re621331e10896ac65f487c1a83cc4a91152e2fd6d7e363c115b1857f%40%3Cdev.beam.apache.org%3E", "url": "https://github.com/apache/beam/pull/11661#discussion_r427517950", "createdAt": "2020-05-19T18:37:35Z", "author": {"login": "tvalentyn"}, "path": ".test-infra/jenkins/job_PerformanceTests_Python.groovy", "diffHunk": "@@ -58,117 +26,59 @@ def dataflowPipelineArgs = [\n     temp_location   : 'gs://temp-storage-for-end-to-end-tests/temp-it',\n ]\n \n-\n-// Configurations of each Jenkins job.\n-def testConfigurations = [\n-    new PerformanceTestConfigurations(\n-        jobName           : 'beam_PerformanceTests_WordCountIT_Py27',\n-        jobDescription    : 'Python SDK Performance Test - Run WordCountIT in Py27 with 1Gb files',\n-        jobTriggerPhrase  : 'Run Python27 WordCountIT Performance Test',\n-        resultTable       : 'beam_performance.wordcount_py27_pkb_results',\n-        test              : 'apache_beam.examples.wordcount_it_test:WordCountIT.test_wordcount_it',\n-        itModule          : ':sdks:python:test-suites:dataflow:py2',\n-        extraPipelineArgs : dataflowPipelineArgs + [\n-            input: 'gs://apache-beam-samples/input_small_files/ascii_sort_1MB_input.0000*', // 1Gb\n-            output: 'gs://temp-storage-for-end-to-end-tests/py-it-cloud/output',\n-            expect_checksum: 'ea0ca2e5ee4ea5f218790f28d0b9fe7d09d8d710',\n-            num_workers: '10',\n-            autoscaling_algorithm: 'NONE',  // Disable autoscale the worker pool.\n-        ],\n-    ),\n-    new PerformanceTestConfigurations(\n-        jobName           : 'beam_PerformanceTests_WordCountIT_Py35',\n-        jobDescription    : 'Python SDK Performance Test - Run WordCountIT in Py35 with 1Gb files',\n-        jobTriggerPhrase  : 'Run Python35 WordCountIT Performance Test',\n-        resultTable       : 'beam_performance.wordcount_py35_pkb_results',\n-        test              : 'apache_beam.examples.wordcount_it_test:WordCountIT.test_wordcount_it',\n-        itModule          : ':sdks:python:test-suites:dataflow:py35',\n-        extraPipelineArgs : dataflowPipelineArgs + [\n-            input: 'gs://apache-beam-samples/input_small_files/ascii_sort_1MB_input.0000*', // 1Gb\n-            output: 'gs://temp-storage-for-end-to-end-tests/py-it-cloud/output',\n-            expect_checksum: 'ea0ca2e5ee4ea5f218790f28d0b9fe7d09d8d710',\n-            num_workers: '10',\n-            autoscaling_algorithm: 'NONE',  // Disable autoscale the worker pool.\n-        ],\n-    ),\n-    new PerformanceTestConfigurations(\n-        jobName           : 'beam_PerformanceTests_WordCountIT_Py36',\n-        jobDescription    : 'Python SDK Performance Test - Run WordCountIT in Py36 with 1Gb files',\n-        jobTriggerPhrase  : 'Run Python36 WordCountIT Performance Test',\n-        resultTable       : 'beam_performance.wordcount_py36_pkb_results',\n-        test              : 'apache_beam.examples.wordcount_it_test:WordCountIT.test_wordcount_it',\n-        itModule          : ':sdks:python:test-suites:dataflow:py36',\n-        extraPipelineArgs : dataflowPipelineArgs + [\n-            input: 'gs://apache-beam-samples/input_small_files/ascii_sort_1MB_input.0000*', // 1Gb\n-            output: 'gs://temp-storage-for-end-to-end-tests/py-it-cloud/output',\n-            expect_checksum: 'ea0ca2e5ee4ea5f218790f28d0b9fe7d09d8d710',\n-            num_workers: '10',\n-            autoscaling_algorithm: 'NONE',  // Disable autoscale the worker pool.\n-        ],\n-    ),\n-    new PerformanceTestConfigurations(\n-        jobName           : 'beam_PerformanceTests_WordCountIT_Py37',\n-        jobDescription    : 'Python SDK Performance Test - Run WordCountIT in Py37 with 1Gb files',\n-        jobTriggerPhrase  : 'Run Python37 WordCountIT Performance Test',\n-        resultTable       : 'beam_performance.wordcount_py37_pkb_results',\n-        test              : 'apache_beam.examples.wordcount_it_test:WordCountIT.test_wordcount_it',\n-        itModule          : ':sdks:python:test-suites:dataflow:py37',\n-        extraPipelineArgs : dataflowPipelineArgs + [\n-            input: 'gs://apache-beam-samples/input_small_files/ascii_sort_1MB_input.0000*', // 1Gb\n-            output: 'gs://temp-storage-for-end-to-end-tests/py-it-cloud/output',\n-            expect_checksum: 'ea0ca2e5ee4ea5f218790f28d0b9fe7d09d8d710',\n-            num_workers: '10',\n-            autoscaling_algorithm: 'NONE',  // Disable autoscale the worker pool.\n-        ],\n-    ),\n-]\n-\n+testConfigurations = []\n+pythonVersions = ['27', '35', '36', '37']", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca6200110135814a90bfcdf9f24e53d01f83ea0e"}, "originalPosition": 109}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzUxODQzNA==", "bodyText": "Where do we configure the dashboards for these tests? Do we need to configure python version bit in the dashboard configuration as well?", "url": "https://github.com/apache/beam/pull/11661#discussion_r427518434", "createdAt": "2020-05-19T18:38:23Z", "author": {"login": "tvalentyn"}, "path": ".test-infra/jenkins/job_PerformanceTests_Python.groovy", "diffHunk": "@@ -58,117 +26,59 @@ def dataflowPipelineArgs = [\n     temp_location   : 'gs://temp-storage-for-end-to-end-tests/temp-it',\n ]\n \n-\n-// Configurations of each Jenkins job.\n-def testConfigurations = [\n-    new PerformanceTestConfigurations(\n-        jobName           : 'beam_PerformanceTests_WordCountIT_Py27',\n-        jobDescription    : 'Python SDK Performance Test - Run WordCountIT in Py27 with 1Gb files',\n-        jobTriggerPhrase  : 'Run Python27 WordCountIT Performance Test',\n-        resultTable       : 'beam_performance.wordcount_py27_pkb_results',\n-        test              : 'apache_beam.examples.wordcount_it_test:WordCountIT.test_wordcount_it',\n-        itModule          : ':sdks:python:test-suites:dataflow:py2',\n-        extraPipelineArgs : dataflowPipelineArgs + [\n-            input: 'gs://apache-beam-samples/input_small_files/ascii_sort_1MB_input.0000*', // 1Gb\n-            output: 'gs://temp-storage-for-end-to-end-tests/py-it-cloud/output',\n-            expect_checksum: 'ea0ca2e5ee4ea5f218790f28d0b9fe7d09d8d710',\n-            num_workers: '10',\n-            autoscaling_algorithm: 'NONE',  // Disable autoscale the worker pool.\n-        ],\n-    ),\n-    new PerformanceTestConfigurations(\n-        jobName           : 'beam_PerformanceTests_WordCountIT_Py35',\n-        jobDescription    : 'Python SDK Performance Test - Run WordCountIT in Py35 with 1Gb files',\n-        jobTriggerPhrase  : 'Run Python35 WordCountIT Performance Test',\n-        resultTable       : 'beam_performance.wordcount_py35_pkb_results',\n-        test              : 'apache_beam.examples.wordcount_it_test:WordCountIT.test_wordcount_it',\n-        itModule          : ':sdks:python:test-suites:dataflow:py35',\n-        extraPipelineArgs : dataflowPipelineArgs + [\n-            input: 'gs://apache-beam-samples/input_small_files/ascii_sort_1MB_input.0000*', // 1Gb\n-            output: 'gs://temp-storage-for-end-to-end-tests/py-it-cloud/output',\n-            expect_checksum: 'ea0ca2e5ee4ea5f218790f28d0b9fe7d09d8d710',\n-            num_workers: '10',\n-            autoscaling_algorithm: 'NONE',  // Disable autoscale the worker pool.\n-        ],\n-    ),\n-    new PerformanceTestConfigurations(\n-        jobName           : 'beam_PerformanceTests_WordCountIT_Py36',\n-        jobDescription    : 'Python SDK Performance Test - Run WordCountIT in Py36 with 1Gb files',\n-        jobTriggerPhrase  : 'Run Python36 WordCountIT Performance Test',\n-        resultTable       : 'beam_performance.wordcount_py36_pkb_results',\n-        test              : 'apache_beam.examples.wordcount_it_test:WordCountIT.test_wordcount_it',\n-        itModule          : ':sdks:python:test-suites:dataflow:py36',\n-        extraPipelineArgs : dataflowPipelineArgs + [\n-            input: 'gs://apache-beam-samples/input_small_files/ascii_sort_1MB_input.0000*', // 1Gb\n-            output: 'gs://temp-storage-for-end-to-end-tests/py-it-cloud/output',\n-            expect_checksum: 'ea0ca2e5ee4ea5f218790f28d0b9fe7d09d8d710',\n-            num_workers: '10',\n-            autoscaling_algorithm: 'NONE',  // Disable autoscale the worker pool.\n-        ],\n-    ),\n-    new PerformanceTestConfigurations(\n-        jobName           : 'beam_PerformanceTests_WordCountIT_Py37',\n-        jobDescription    : 'Python SDK Performance Test - Run WordCountIT in Py37 with 1Gb files',\n-        jobTriggerPhrase  : 'Run Python37 WordCountIT Performance Test',\n-        resultTable       : 'beam_performance.wordcount_py37_pkb_results',\n-        test              : 'apache_beam.examples.wordcount_it_test:WordCountIT.test_wordcount_it',\n-        itModule          : ':sdks:python:test-suites:dataflow:py37',\n-        extraPipelineArgs : dataflowPipelineArgs + [\n-            input: 'gs://apache-beam-samples/input_small_files/ascii_sort_1MB_input.0000*', // 1Gb\n-            output: 'gs://temp-storage-for-end-to-end-tests/py-it-cloud/output',\n-            expect_checksum: 'ea0ca2e5ee4ea5f218790f28d0b9fe7d09d8d710',\n-            num_workers: '10',\n-            autoscaling_algorithm: 'NONE',  // Disable autoscale the worker pool.\n-        ],\n-    ),\n-]\n-\n+testConfigurations = []\n+pythonVersions = ['27', '35', '36', '37']\n+\n+for (pythonVersion in pythonVersions) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca6200110135814a90bfcdf9f24e53d01f83ea0e"}, "originalPosition": 111}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzUxOTE5MA==", "bodyText": "fyi, @lazylynx - I think this stanza would be useful to configure low priority jobs.", "url": "https://github.com/apache/beam/pull/11661#discussion_r427519190", "createdAt": "2020-05-19T18:39:41Z", "author": {"login": "tvalentyn"}, "path": ".test-infra/jenkins/job_PerformanceTests_Python.groovy", "diffHunk": "@@ -58,117 +26,59 @@ def dataflowPipelineArgs = [\n     temp_location   : 'gs://temp-storage-for-end-to-end-tests/temp-it',\n ]\n \n-\n-// Configurations of each Jenkins job.\n-def testConfigurations = [\n-    new PerformanceTestConfigurations(\n-        jobName           : 'beam_PerformanceTests_WordCountIT_Py27',\n-        jobDescription    : 'Python SDK Performance Test - Run WordCountIT in Py27 with 1Gb files',\n-        jobTriggerPhrase  : 'Run Python27 WordCountIT Performance Test',\n-        resultTable       : 'beam_performance.wordcount_py27_pkb_results',\n-        test              : 'apache_beam.examples.wordcount_it_test:WordCountIT.test_wordcount_it',\n-        itModule          : ':sdks:python:test-suites:dataflow:py2',\n-        extraPipelineArgs : dataflowPipelineArgs + [\n-            input: 'gs://apache-beam-samples/input_small_files/ascii_sort_1MB_input.0000*', // 1Gb\n-            output: 'gs://temp-storage-for-end-to-end-tests/py-it-cloud/output',\n-            expect_checksum: 'ea0ca2e5ee4ea5f218790f28d0b9fe7d09d8d710',\n-            num_workers: '10',\n-            autoscaling_algorithm: 'NONE',  // Disable autoscale the worker pool.\n-        ],\n-    ),\n-    new PerformanceTestConfigurations(\n-        jobName           : 'beam_PerformanceTests_WordCountIT_Py35',\n-        jobDescription    : 'Python SDK Performance Test - Run WordCountIT in Py35 with 1Gb files',\n-        jobTriggerPhrase  : 'Run Python35 WordCountIT Performance Test',\n-        resultTable       : 'beam_performance.wordcount_py35_pkb_results',\n-        test              : 'apache_beam.examples.wordcount_it_test:WordCountIT.test_wordcount_it',\n-        itModule          : ':sdks:python:test-suites:dataflow:py35',\n-        extraPipelineArgs : dataflowPipelineArgs + [\n-            input: 'gs://apache-beam-samples/input_small_files/ascii_sort_1MB_input.0000*', // 1Gb\n-            output: 'gs://temp-storage-for-end-to-end-tests/py-it-cloud/output',\n-            expect_checksum: 'ea0ca2e5ee4ea5f218790f28d0b9fe7d09d8d710',\n-            num_workers: '10',\n-            autoscaling_algorithm: 'NONE',  // Disable autoscale the worker pool.\n-        ],\n-    ),\n-    new PerformanceTestConfigurations(\n-        jobName           : 'beam_PerformanceTests_WordCountIT_Py36',\n-        jobDescription    : 'Python SDK Performance Test - Run WordCountIT in Py36 with 1Gb files',\n-        jobTriggerPhrase  : 'Run Python36 WordCountIT Performance Test',\n-        resultTable       : 'beam_performance.wordcount_py36_pkb_results',\n-        test              : 'apache_beam.examples.wordcount_it_test:WordCountIT.test_wordcount_it',\n-        itModule          : ':sdks:python:test-suites:dataflow:py36',\n-        extraPipelineArgs : dataflowPipelineArgs + [\n-            input: 'gs://apache-beam-samples/input_small_files/ascii_sort_1MB_input.0000*', // 1Gb\n-            output: 'gs://temp-storage-for-end-to-end-tests/py-it-cloud/output',\n-            expect_checksum: 'ea0ca2e5ee4ea5f218790f28d0b9fe7d09d8d710',\n-            num_workers: '10',\n-            autoscaling_algorithm: 'NONE',  // Disable autoscale the worker pool.\n-        ],\n-    ),\n-    new PerformanceTestConfigurations(\n-        jobName           : 'beam_PerformanceTests_WordCountIT_Py37',\n-        jobDescription    : 'Python SDK Performance Test - Run WordCountIT in Py37 with 1Gb files',\n-        jobTriggerPhrase  : 'Run Python37 WordCountIT Performance Test',\n-        resultTable       : 'beam_performance.wordcount_py37_pkb_results',\n-        test              : 'apache_beam.examples.wordcount_it_test:WordCountIT.test_wordcount_it',\n-        itModule          : ':sdks:python:test-suites:dataflow:py37',\n-        extraPipelineArgs : dataflowPipelineArgs + [\n-            input: 'gs://apache-beam-samples/input_small_files/ascii_sort_1MB_input.0000*', // 1Gb\n-            output: 'gs://temp-storage-for-end-to-end-tests/py-it-cloud/output',\n-            expect_checksum: 'ea0ca2e5ee4ea5f218790f28d0b9fe7d09d8d710',\n-            num_workers: '10',\n-            autoscaling_algorithm: 'NONE',  // Disable autoscale the worker pool.\n-        ],\n-    ),\n-]\n-\n+testConfigurations = []\n+pythonVersions = ['27', '35', '36', '37']\n+\n+for (pythonVersion in pythonVersions) {\n+    def taskVersion = pythonVersion == '27' ? '2' : pythonVersion\n+    testConfigurations.add([\n+            jobName           : \"beam_PerformanceTests_WordCountIT_Py${pythonVersion}\",\n+            jobDescription    : \"Python SDK Performance Test - Run WordCountIT in Py${pythonVersion} with 1Gb files\",\n+            jobTriggerPhrase  : \"Run Python${pythonVersion} WordCountIT Performance Test\",\n+            test              : \"apache_beam.examples.wordcount_it_test:WordCountIT.test_wordcount_it\",\n+            gradleTaskName    : \":sdks:python:test-suites:dataflow:py${taskVersion}:runPerformanceTest\",\n+            pipelineOptions   : dataflowPipelineArgs + [\n+                    runner               : 'TestDataflowRunner',\n+                    publish_to_big_query : true,\n+                    metrics_dataset      : 'beam_performance',\n+                    metrics_table        : \"wordcount_py${pythonVersion}_pkb_results\",\n+                    input                : \"gs://apache-beam-samples/input_small_files/ascii_sort_1MB_input.0000*\", // 1Gb\n+                    output               : \"gs://temp-storage-for-end-to-end-tests/py-it-cloud/output\",\n+                    expect_checksum      : \"ea0ca2e5ee4ea5f218790f28d0b9fe7d09d8d710\",\n+                    num_workers          : '10',\n+                    autoscaling_algorithm: \"NONE\",  // Disable autoscale the worker pool.\n+            ]\n+    ])\n+}\n \n for (testConfig in testConfigurations) {\n   createPythonPerformanceTestJob(testConfig)\n }\n \n-\n-private void createPythonPerformanceTestJob(PerformanceTestConfigurations testConfig) {\n-  // This job runs the Beam Python performance tests on PerfKit Benchmarker.\n+private void createPythonPerformanceTestJob(Map testConfig) {\n+  // This job runs the Beam Python performance tests\n   job(testConfig.jobName) {\n     // Set default Beam job properties.\n     commonJobProperties.setTopLevelMainJobProperties(delegate)\n \n     // Run job in postcommit, don't trigger every push.\n-    commonJobProperties.setAutoJob(\n-        delegate,\n-        testConfig.buildSchedule)\n+    commonJobProperties.setAutoJob(delegate, 'H */6 * * *')", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca6200110135814a90bfcdf9f24e53d01f83ea0e"}, "originalPosition": 150}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzU0MTExOA==", "bodyText": "Please make sure these tests export the xml logs that can be inspected in Jenkins in case of test failure:\nRelevant bits are:\n\n\n  \n    \n      beam/.test-infra/jenkins/job_PostCommit_Python37.groovy\n    \n    \n         Line 32\n      in\n      03d99df\n    \n    \n    \n    \n\n        \n          \n           publishers { \n        \n    \n  \n\n\n\n  \n    \n      beam/sdks/python/scripts/run_integration_test.sh\n    \n    \n         Line 276\n      in\n      03d99df\n    \n    \n    \n    \n\n        \n          \n           --with-xunitmp --xunitmp-file=$XUNIT_FILE \\ \n        \n    \n  \n\n\n\ncc: @udim who may have additional feedback on this. Udi, would it make sense to use pytest here instead of nose?", "url": "https://github.com/apache/beam/pull/11661#discussion_r427541118", "createdAt": "2020-05-19T19:17:09Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/test-suites/dataflow/common.gradle", "diffHunk": "@@ -109,4 +109,21 @@ task validatesRunnerStreamingTests {\n       args '-c', \". ${envdir}/bin/activate && ${runScriptsDir}/run_integration_test.sh $cmdArgs\"\n     }\n   }\n-}\n\\ No newline at end of file\n+}\n+\n+task runPerformanceTest {\n+    dependsOn 'installGcpTest'\n+    dependsOn ':sdks:python:sdist'\n+\n+    def test = project.findProperty('test')\n+    def testOpts = project.findProperty('test-pipeline-options')\n+    testOpts += \" --sdk_location=${files(configurations.distTarBall.files).singleFile}\"\n+\n+  doLast {\n+    exec {\n+      workingDir \"${project.rootDir}/sdks/python\"\n+      executable 'sh'\n+      args '-c', \". ${envdir}/bin/activate && ${envdir}/bin/python setup.py nosetests --tests=${test}  --test-pipeline-options=\\\"${testOpts}\\\" --ignore-files \\'.*py3\\\\d?\\\\.py\\$\\'\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca6200110135814a90bfcdf9f24e53d01f83ea0e"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzU0MzkxMw==", "bodyText": "Do we need to pass --ignore-files given that we control which tests to run?", "url": "https://github.com/apache/beam/pull/11661#discussion_r427543913", "createdAt": "2020-05-19T19:22:08Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/test-suites/dataflow/common.gradle", "diffHunk": "@@ -109,4 +109,21 @@ task validatesRunnerStreamingTests {\n       args '-c', \". ${envdir}/bin/activate && ${runScriptsDir}/run_integration_test.sh $cmdArgs\"\n     }\n   }\n-}\n\\ No newline at end of file\n+}\n+\n+task runPerformanceTest {\n+    dependsOn 'installGcpTest'\n+    dependsOn ':sdks:python:sdist'\n+\n+    def test = project.findProperty('test')\n+    def testOpts = project.findProperty('test-pipeline-options')\n+    testOpts += \" --sdk_location=${files(configurations.distTarBall.files).singleFile}\"\n+\n+  doLast {\n+    exec {\n+      workingDir \"${project.rootDir}/sdks/python\"\n+      executable 'sh'\n+      args '-c', \". ${envdir}/bin/activate && ${envdir}/bin/python setup.py nosetests --tests=${test}  --test-pipeline-options=\\\"${testOpts}\\\" --ignore-files \\'.*py3\\\\d?\\\\.py\\$\\'\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ca6200110135814a90bfcdf9f24e53d01f83ea0e"}, "originalPosition": 20}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE4NTMxNDMx", "url": "https://github.com/apache/beam/pull/11661#pullrequestreview-418531431", "createdAt": "2020-05-26T17:42:56Z", "commit": {"oid": "1516e9728ba502fdd9304fc1657b639a855c25a0"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxNzo0Mjo1NlrOGapSlQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxNzo0Mjo1NlrOGapSlQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDU5MjY2MQ==", "bodyText": "Sounds like this code can be reused across other performance tests, is there a module shared across perf tests that we can move it to? cc: @kamilwu", "url": "https://github.com/apache/beam/pull/11661#discussion_r430592661", "createdAt": "2020-05-26T17:42:56Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/examples/wordcount_it_test.py", "diffHunk": "@@ -104,18 +107,33 @@ def _run_wordcount_it(self, run_wordcount, **opts):\n     run_time = end_time - start_time\n \n     if publish_to_bq:\n-      bq_publisher = BigQueryMetricsPublisher(\n-          project_name=test_pipeline.get_option('project'),\n-          table=test_pipeline.get_option('metrics_table'),\n-          dataset=test_pipeline.get_option('metrics_dataset'),\n-      )\n-      result = Metric(\n-          submit_timestamp=time.time(),\n-          metric_id=uuid.uuid4().hex,\n-          value=run_time,\n-          label='Python performance test',\n-      )\n-      bq_publisher.publish([result.as_dict()])\n+      self._publish_metrics(test_pipeline, run_time)\n+\n+  def _publish_metrics(self, pipeline, metric_value):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1516e9728ba502fdd9304fc1657b639a855c25a0"}, "originalPosition": 35}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE4NTM3NDgz", "url": "https://github.com/apache/beam/pull/11661#pullrequestreview-418537483", "createdAt": "2020-05-26T17:51:14Z", "commit": {"oid": "1516e9728ba502fdd9304fc1657b639a855c25a0"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxNzo1MToxNFrOGaplsQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yNlQxNzo1MToxNFrOGaplsQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDU5NzU1Mw==", "bodyText": "@kamilwu , could you please review the dashboard config?\nSome questions:\nIs there a way to visualize the dashboard on an in-progress PR?\nIs it possible to reduce duplication in the configs? We can do it in a separate change. For example: most settings for Python 2.7, and 3.7 are similar.  Have we considered  auto-generating  the final config from a smaller set of settings?", "url": "https://github.com/apache/beam/pull/11661#discussion_r430597553", "createdAt": "2020-05-26T17:51:14Z", "author": {"login": "tvalentyn"}, "path": ".test-infra/metrics/grafana/dashboards/perftests_metrics/Python_Performance_Tests.json", "diffHunk": "@@ -0,0 +1,297 @@\n+{", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1516e9728ba502fdd9304fc1657b639a855c25a0"}, "originalPosition": 1}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE5NDQ4MzMx", "url": "https://github.com/apache/beam/pull/11661#pullrequestreview-419448331", "createdAt": "2020-05-27T17:23:03Z", "commit": {"oid": "f84ff0d04a3abbf0568f5fab0ecdbd6eb2133c55"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxNzoyMzowM1rOGbVUfQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yN1QxNzozMToxOFrOGbVoeQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTMxNDA0NQ==", "bodyText": "Good catch.\nRe:\n\nApart from that, we can also consider another question: is having those .json files version-controlled profitable? Diffs are often very large, so the standard review process does not apply here.\n\nI agree that those files are hard to review - I was thinking that perhaps we can autogenerate the final configs from a much smaller config that just captures the minimal necessary information (name of the benchmark to display,  table/row name in the database that has the datapoints). The idea is that final configs are not edited manually. It would make sense for the visualization tool to provide a capability to generate the dashboard based on a common template + required minimal config. Is that what Scripted Dashboards is? The webpage page says this feature is deprecated.", "url": "https://github.com/apache/beam/pull/11661#discussion_r431314045", "createdAt": "2020-05-27T17:23:03Z", "author": {"login": "tvalentyn"}, "path": ".test-infra/metrics/grafana/dashboards/perftests_metrics/Python_Performance_Tests.json", "diffHunk": "@@ -0,0 +1,297 @@\n+{", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMDU5NzU1Mw=="}, "originalCommit": {"oid": "1516e9728ba502fdd9304fc1657b639a855c25a0"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMTMxOTE2MQ==", "bodyText": "I think the metric name should be 'Runtime', or something like that, not the test suite name.\nAlso, it may be more common to pass (Key,Value) pairs instead of (Value, Key)", "url": "https://github.com/apache/beam/pull/11661#discussion_r431319161", "createdAt": "2020-05-27T17:31:18Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/examples/wordcount_it_test.py", "diffHunk": "@@ -84,11 +87,45 @@ def _run_wordcount_it(self, run_wordcount, **opts):\n     # Register clean up before pipeline execution\n     self.addCleanup(delete_files, [test_output + '*'])\n \n+    publish_to_bq = bool(\n+        test_pipeline.get_option('publish_to_big_query') or False)\n+\n+    # Start measure time for performance test\n+    start_time = time.time()\n+\n     # Get pipeline options from command argument: --test-pipeline-options,\n     # and start pipeline job by calling pipeline main function.\n     run_wordcount(\n         test_pipeline.get_full_options_as_args(**extra_opts),\n-        save_main_session=False)\n+        save_main_session=False,\n+    )\n+\n+    end_time = time.time()\n+    run_time = end_time - start_time\n+\n+    if publish_to_bq:\n+      self._publish_metrics(test_pipeline, run_time)\n+\n+  def _publish_metrics(self, pipeline, metric_value):\n+    influx_options = InfluxDBMetricsPublisherOptions(\n+        pipeline.get_option('influx_measurement'),\n+        pipeline.get_option('influx_db_name'),\n+        pipeline.get_option('influx_hostname'),\n+        os.getenv('INFLUXDB_USER'),\n+        os.getenv('INFLUXDB_USER_PASSWORD'),\n+    )\n+    metric_reader = MetricsReader(\n+        project_name=pipeline.get_option('project'),\n+        bq_table=pipeline.get_option('metrics_table'),\n+        bq_dataset=pipeline.get_option('metrics_dataset'),\n+        publish_to_bq=True,\n+        influxdb_options=influx_options,\n+    )\n+\n+    metric_reader.publish_values((\n+        metric_value,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f84ff0d04a3abbf0568f5fab0ecdbd6eb2133c55"}, "originalPosition": 58}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDIwNDcwNTU3", "url": "https://github.com/apache/beam/pull/11661#pullrequestreview-420470557", "createdAt": "2020-05-28T20:33:46Z", "commit": {"oid": "3ee636005a74c112286b7c66663ed5cb82ceeddd"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQyMDozMzo0N1rOGcFu8w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOFQyMDozMzo0N1rOGcFu8w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjEwNzI1MQ==", "bodyText": "Seeing this query now - yes, I wound just keep the metric 'runtime', since we already know it is wordcount_py27_results, and it would be simpler that pipeline does not need to know the name of the suite. In the future we might add different metrics like 'cost' or total cputime consumed by other workers as opposed to runtime.", "url": "https://github.com/apache/beam/pull/11661#discussion_r432107251", "createdAt": "2020-05-28T20:33:47Z", "author": {"login": "tvalentyn"}, "path": ".test-infra/metrics/grafana/dashboards/perftests_metrics/Python_Performance_Tests.json", "diffHunk": "@@ -77,7 +77,7 @@\n           ],\n           \"orderByTime\": \"ASC\",\n           \"policy\": \"default\",\n-          \"query\": \"SELECT mean(\\\"value\\\") FROM \\\"wordcount_py27_results\\\" WHERE metric = 'Python performance test' AND $timeFilter GROUP BY time($__interval),  \\\"metric\\\"\",\n+          \"query\": \"SELECT mean(\\\"value\\\") FROM \\\"wordcount_py27_results\\\" WHERE metric = 'wordcount_it_runtime' AND $timeFilter GROUP BY time($__interval),  \\\"metric\\\"\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ee636005a74c112286b7c66663ed5cb82ceeddd"}, "originalPosition": 5}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "3ee636005a74c112286b7c66663ed5cb82ceeddd", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/3ee636005a74c112286b7c66663ed5cb82ceeddd", "committedDate": "2020-05-28T19:12:51Z", "message": "[BEAM-10102] Change metric label and the order of tuple in publisher"}, "afterCommit": {"oid": "a1a1c659197dcbee3cc2d2995904e8c4c6ae1927", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/a1a1c659197dcbee3cc2d2995904e8c4c6ae1927", "committedDate": "2020-05-29T10:57:33Z", "message": "[BEAM-7774] Add python wordcount performance test grafana dashboard"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "90e3dcd68d460e2464e4a1b972b181460d8cbf2c", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/90e3dcd68d460e2464e4a1b972b181460d8cbf2c", "committedDate": "2020-05-29T15:16:10Z", "message": "[BEAM-7774] Move duplicated code from py2 and py37 suites to common.gradle"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a1a1c659197dcbee3cc2d2995904e8c4c6ae1927", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/a1a1c659197dcbee3cc2d2995904e8c4c6ae1927", "committedDate": "2020-05-29T10:57:33Z", "message": "[BEAM-7774] Add python wordcount performance test grafana dashboard"}, "afterCommit": {"oid": "927aad2d21473ceaf53214413c1bee2d45da9256", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/927aad2d21473ceaf53214413c1bee2d45da9256", "committedDate": "2020-05-29T15:19:23Z", "message": "[BEAM-7774] Add python wordcount performance test grafana dashboard"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "db8c8e81a64d6419409245946de5c68bb05d5705", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/db8c8e81a64d6419409245946de5c68bb05d5705", "committedDate": "2020-06-01T10:26:10Z", "message": "[BEAM-7774] Update jenkins jobs readme - remove python 35 and 36 wordcount it performance tests"}, "afterCommit": {"oid": "2097cd074e2b1ca9f52dbaaa965b9aaad29c0d21", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/2097cd074e2b1ca9f52dbaaa965b9aaad29c0d21", "committedDate": "2020-06-01T10:27:39Z", "message": "[BEAM-7774] Update jenkins jobs readme - remove python 35 and 36 wordcount it performance tests"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "2097cd074e2b1ca9f52dbaaa965b9aaad29c0d21", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/2097cd074e2b1ca9f52dbaaa965b9aaad29c0d21", "committedDate": "2020-06-01T10:27:39Z", "message": "[BEAM-7774] Update jenkins jobs readme - remove python 35 and 36 wordcount it performance tests"}, "afterCommit": {"oid": "d5e277aa60af4092dcf90515b2c9d56fdf05e7cc", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/d5e277aa60af4092dcf90515b2c9d56fdf05e7cc", "committedDate": "2020-06-01T13:45:42Z", "message": "[BEAM-7774] Update jenkins jobs readme - remove python 35 and 36 wordcount it performance tests"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d5e277aa60af4092dcf90515b2c9d56fdf05e7cc", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/d5e277aa60af4092dcf90515b2c9d56fdf05e7cc", "committedDate": "2020-06-01T13:45:42Z", "message": "[BEAM-7774] Update jenkins jobs readme - remove python 35 and 36 wordcount it performance tests"}, "afterCommit": {"oid": "684261e4175db136723c9bed5cee2f293469e465", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/684261e4175db136723c9bed5cee2f293469e465", "committedDate": "2020-06-01T15:25:02Z", "message": "[BEAM-7774] Update jenkins jobs readme - remove python 35 and 36 wordcount it performance tests"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "684261e4175db136723c9bed5cee2f293469e465", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/684261e4175db136723c9bed5cee2f293469e465", "committedDate": "2020-06-01T15:25:02Z", "message": "[BEAM-7774] Update jenkins jobs readme - remove python 35 and 36 wordcount it performance tests"}, "afterCommit": {"oid": "21d8edd484cadf888d75b02ebc8efd98b4ca641b", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/21d8edd484cadf888d75b02ebc8efd98b4ca641b", "committedDate": "2020-06-02T08:22:07Z", "message": "[BEAM-7774] Add use influx credentials to the jenkins job"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "21d8edd484cadf888d75b02ebc8efd98b4ca641b", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/21d8edd484cadf888d75b02ebc8efd98b4ca641b", "committedDate": "2020-06-02T08:22:07Z", "message": "[BEAM-7774] Add use influx credentials to the jenkins job"}, "afterCommit": {"oid": "aedef64a6f6ba87e6d7221c33758b0826e95a40c", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/aedef64a6f6ba87e6d7221c33758b0826e95a40c", "committedDate": "2020-06-02T09:02:41Z", "message": "[BEAM-7774] Update jenkins jobs readme - remove python 35 and 36 wordcount it performance tests"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "bcafe274a4599f88fa00808b52ea4d11baa1c855", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/bcafe274a4599f88fa00808b52ea4d11baa1c855", "committedDate": "2020-06-02T11:15:15Z", "message": "[BEAM-7774] Correct given parameters to publish methods"}, "afterCommit": {"oid": "92694b9f7f392f00c2f91a18579c0af27f734ede", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/92694b9f7f392f00c2f91a18579c0af27f734ede", "committedDate": "2020-06-02T12:26:51Z", "message": "[BEAM-7774] Update jenkins jobs readme - remove python 35 and 36 wordcount it performance tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cf93a2841ef5821f4654312f7ecb7b841af1bf7a", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/cf93a2841ef5821f4654312f7ecb7b841af1bf7a", "committedDate": "2020-06-02T14:33:44Z", "message": "[BEAM-7774] Remove Perfkit Benchmarking tool from python wordcount performance tests jobs"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "92694b9f7f392f00c2f91a18579c0af27f734ede", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/92694b9f7f392f00c2f91a18579c0af27f734ede", "committedDate": "2020-06-02T12:26:51Z", "message": "[BEAM-7774] Update jenkins jobs readme - remove python 35 and 36 wordcount it performance tests"}, "afterCommit": {"oid": "6ef8e2a27d8b780119e6ef2fdf8cc4d90bb765e2", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/6ef8e2a27d8b780119e6ef2fdf8cc4d90bb765e2", "committedDate": "2020-06-02T14:33:59Z", "message": "[BEAM-7774] Add python wordcount performance test grafana dashboard"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "56e853e72d82eac9567a8ceebdcad8eec12ad107", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/56e853e72d82eac9567a8ceebdcad8eec12ad107", "committedDate": "2020-06-02T15:46:51Z", "message": "[BEAM-7774] Add python wordcount performance test grafana dashboard"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "6ef8e2a27d8b780119e6ef2fdf8cc4d90bb765e2", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/6ef8e2a27d8b780119e6ef2fdf8cc4d90bb765e2", "committedDate": "2020-06-02T14:33:59Z", "message": "[BEAM-7774] Add python wordcount performance test grafana dashboard"}, "afterCommit": {"oid": "56e853e72d82eac9567a8ceebdcad8eec12ad107", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/56e853e72d82eac9567a8ceebdcad8eec12ad107", "committedDate": "2020-06-02T15:46:51Z", "message": "[BEAM-7774] Add python wordcount performance test grafana dashboard"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4937, "cost": 1, "resetAt": "2021-10-28T16:48:13Z"}}}