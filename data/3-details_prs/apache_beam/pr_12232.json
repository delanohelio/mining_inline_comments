{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQ3ODc2MjYw", "number": 12232, "title": "[Beam-9543] Support Match Recognition in Beam SQL", "bodyText": "Changes since the last PR:\n\nSolved serialization issues and coder issues.\nUsed Java Regex library to support pattern matching without back-reference (quantifiers not supported for now).\nPassed a simple test case (more test cases to be added soon).\nFixed code style.\n\n\nThank you for your contribution! Follow this checklist to help us incorporate your contribution quickly and easily:\n\n Choose reviewer(s) and mention them in a comment (R: @username).\n Format the pull request title like [BEAM-XXX] Fixes bug in ApproximateQuantiles, where you replace BEAM-XXX with the appropriate JIRA issue, if applicable. This will automatically link the pull request to the issue.\n Update CHANGES.md with noteworthy changes.\n If this contribution is large, please file an Apache Individual Contributor License Agreement.\n\nSee the Contributor Guide for more tips on how to make review process smoother.\nPost-Commit Tests Status (on master branch)\n\n\n\nLang\nSDK\nDataflow\nFlink\nSamza\nSpark\nTwister2\n\n\n\n\nGo\n\n---\n\n---\n\n---\n\n\nJava\n\n\n\n\n\n\n\n\nPython\n\n\n\n---\n\n---\n\n\nXLang\n---\n---\n\n---\n\n---\n\n\n\nPre-Commit Tests Status (on master branch)\n\n\n\n---\nJava\nPython\nGo\nWebsite\n\n\n\n\nNon-portable\n\n\n\n\n\n\nPortable\n---\n\n---\n---\n\n\n\nSee .test-infra/jenkins/README for trigger phrase, status and link of all Jenkins jobs.", "createdAt": "2020-07-12T09:38:54Z", "url": "https://github.com/apache/beam/pull/12232", "merged": true, "mergeCommit": {"oid": "583366789d9bb2531240596ebc0e6d3dcb9f5a15"}, "closed": true, "closedAt": "2020-08-03T17:29:47Z", "author": {"login": "Mark-Zeng"}, "timelineItems": {"totalCount": 30, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc0JwhGgFqTQ0Njg2MzM3NQ==", "endCursor": "Y3Vyc29yOnYyOpPPAAABc7VeNYgFqTQ2MDIwODI2OA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2ODYzMzc1", "url": "https://github.com/apache/beam/pull/12232#pullrequestreview-446863375", "createdAt": "2020-07-12T09:52:17Z", "commit": {"oid": "1727e170ef88ed8150a7fd30f6f9254ef1031548"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMlQwOTo1MjoxN1rOGwS6WA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMlQwOTo1MjoxN1rOGwS6WA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzI5NDY4MA==", "bodyText": "In my last PR (#12073), Rui suggested there is a row comparator available for use. I found it a private class in BeamSortRel. I just wonder if I could copy the code from there (maybe also and a reference?). What is the correct way of doing it?", "url": "https://github.com/apache/beam/pull/12232#discussion_r453294680", "createdAt": "2020-07-12T09:52:17Z", "author": {"login": "Mark-Zeng"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java", "diffHunk": "@@ -0,0 +1,380 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.rel;\n+\n+import static org.apache.beam.vendor.calcite.v1_20_0.com.google.common.base.Preconditions.checkArgument;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.beam.sdk.coders.KvCoder;\n+import org.apache.beam.sdk.coders.RowCoder;\n+import org.apache.beam.sdk.extensions.sql.impl.SqlConversionException;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.CEPPattern;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.CEPUtil;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.OrderKey;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.BeamCostModel;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.NodeStats;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.GroupByKey;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionList;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptCluster;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptPlanner;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelTraitSet;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelFieldCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.Match;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.metadata.RelMetadataQuery;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.type.RelDataType;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexCall;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexVariable;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/** {@link BeamRelNode} to replace a {@link Match} node. */\n+public class BeamMatchRel extends Match implements BeamRelNode {\n+\n+  public static final Logger LOG = LoggerFactory.getLogger(BeamMatchRel.class);\n+\n+  public BeamMatchRel(\n+      RelOptCluster cluster,\n+      RelTraitSet traitSet,\n+      RelNode input,\n+      RelDataType rowType,\n+      RexNode pattern,\n+      boolean strictStart,\n+      boolean strictEnd,\n+      Map<String, RexNode> patternDefinitions,\n+      Map<String, RexNode> measures,\n+      RexNode after,\n+      Map<String, ? extends SortedSet<String>> subsets,\n+      boolean allRows,\n+      List<RexNode> partitionKeys,\n+      RelCollation orderKeys,\n+      RexNode interval) {\n+\n+    super(\n+        cluster,\n+        traitSet,\n+        input,\n+        rowType,\n+        pattern,\n+        strictStart,\n+        strictEnd,\n+        patternDefinitions,\n+        measures,\n+        after,\n+        subsets,\n+        allRows,\n+        partitionKeys,\n+        orderKeys,\n+        interval);\n+  }\n+\n+  @Override\n+  public BeamCostModel beamComputeSelfCost(RelOptPlanner planner, RelMetadataQuery mq) {\n+    return BeamCostModel.FACTORY.makeTinyCost(); // return constant costModel for now\n+  }\n+\n+  @Override\n+  public NodeStats estimateNodeStats(RelMetadataQuery mq) {\n+    // a simple way of getting some estimate data\n+    // to be examined further\n+    NodeStats inputEstimate = BeamSqlRelUtils.getNodeStats(input, mq);\n+    double numRows = inputEstimate.getRowCount();\n+    double winSize = inputEstimate.getWindow();\n+    double rate = inputEstimate.getRate();\n+\n+    return NodeStats.create(numRows, rate, winSize).multiply(0.5);\n+  }\n+\n+  @Override\n+  public PTransform<PCollectionList<Row>, PCollection<Row>> buildPTransform() {\n+\n+    return new MatchTransform(partitionKeys, orderKeys, pattern, patternDefinitions);\n+  }\n+\n+  private static class MatchTransform extends PTransform<PCollectionList<Row>, PCollection<Row>> {\n+\n+    private final List<RexNode> parKeys;\n+    private final RelCollation orderKeys;\n+    private final RexNode pattern;\n+    private final Map<String, RexNode> patternDefs;\n+\n+    public MatchTransform(\n+        List<RexNode> parKeys,\n+        RelCollation orderKeys,\n+        RexNode pattern,\n+        Map<String, RexNode> patternDefs) {\n+      this.parKeys = parKeys;\n+      this.orderKeys = orderKeys;\n+      this.pattern = pattern;\n+      this.patternDefs = patternDefs;\n+    }\n+\n+    @Override\n+    public PCollection<Row> expand(PCollectionList<Row> pinput) {\n+      checkArgument(\n+          pinput.size() == 1,\n+          \"Wrong number of inputs for %s: %s\",\n+          BeamMatchRel.class.getSimpleName(),\n+          pinput);\n+      PCollection<Row> upstream = pinput.get(0);\n+\n+      Schema collectionSchema = upstream.getSchema();\n+\n+      Schema.Builder schemaBuilder = new Schema.Builder();\n+      for (RexNode i : parKeys) {\n+        RexVariable varNode = (RexVariable) i;\n+        int index = Integer.parseInt(varNode.getName().substring(1)); // get rid of `$`\n+        schemaBuilder.addField(collectionSchema.getField(index));\n+      }\n+      Schema mySchema = schemaBuilder.build();\n+\n+      // partition according to the partition keys\n+      PCollection<KV<Row, Row>> keyedUpstream = upstream.apply(ParDo.of(new MapKeys(mySchema)));\n+\n+      // group by keys\n+      PCollection<KV<Row, Iterable<Row>>> groupedUpstream =\n+          keyedUpstream\n+              .setCoder(KvCoder.of(RowCoder.of(mySchema), RowCoder.of(collectionSchema)))\n+              .apply(GroupByKey.create());\n+\n+      // sort within each keyed partition\n+      PCollection<KV<Row, Iterable<Row>>> orderedUpstream =\n+          groupedUpstream.apply(ParDo.of(new SortPerKey(collectionSchema, orderKeys)));\n+\n+      // apply the pattern match in each partition\n+      ArrayList<CEPPattern> cepPattern =\n+          CEPUtil.getCEPPatternFromPattern(collectionSchema, (RexCall) pattern, patternDefs);\n+      String regexPattern = CEPUtil.getRegexFromPattern((RexCall) pattern);\n+      PCollection<KV<Row, Iterable<Row>>> matchedUpstream =\n+          orderedUpstream.apply(ParDo.of(new MatchPattern(cepPattern, regexPattern)));\n+\n+      // apply the ParDo for the measures clause\n+      // for now, output the all rows of each pattern matched (for testing purpose)\n+      PCollection<Row> outStream =\n+          matchedUpstream.apply(ParDo.of(new Measure())).setRowSchema(collectionSchema);\n+\n+      return outStream;\n+    }\n+\n+    private static class Measure extends DoFn<KV<Row, Iterable<Row>>, Row> {\n+\n+      @ProcessElement\n+      public void processElement(@Element KV<Row, Iterable<Row>> keyRows, OutputReceiver<Row> out) {\n+        for (Row i : keyRows.getValue()) {\n+          out.output(i);\n+        }\n+      }\n+    }\n+\n+    // TODO: support both ALL ROWS PER MATCH and ONE ROW PER MATCH.\n+    // support only one row per match for now.\n+    private static class MatchPattern extends DoFn<KV<Row, Iterable<Row>>, KV<Row, Iterable<Row>>> {\n+\n+      private final ArrayList<CEPPattern> pattern;\n+      private final String regexPattern;\n+\n+      MatchPattern(ArrayList<CEPPattern> pattern, String regexPattern) {\n+        this.pattern = pattern;\n+        this.regexPattern = regexPattern;\n+      }\n+\n+      @ProcessElement\n+      public void processElement(\n+          @Element KV<Row, Iterable<Row>> keyRows, OutputReceiver<KV<Row, Iterable<Row>>> out) {\n+        ArrayList<Row> rows = new ArrayList<>();\n+        StringBuilder patternString = new StringBuilder();\n+        for (Row i : keyRows.getValue()) {\n+          rows.add(i);\n+          // check pattern of row i\n+          String patternOfRow = \" \"; // a row with no matched pattern is marked by a space\n+          for (int j = 0; j < pattern.size(); ++j) {\n+            CEPPattern tryPattern = pattern.get(j);\n+            if (tryPattern.evalRow(i)) {\n+              patternOfRow = tryPattern.toString();\n+            }\n+          }\n+          patternString.append(patternOfRow);\n+        }\n+\n+        Pattern p = Pattern.compile(regexPattern);\n+        Matcher m = p.matcher(patternString.toString());\n+        // if the pattern is (A B+ C),\n+        // it should return a List three rows matching A B C respectively\n+        if (m.matches()) {\n+          out.output(KV.of(keyRows.getKey(), rows.subList(m.start(), m.end())));\n+        }\n+      }\n+    }\n+\n+    private static class SortPerKey extends DoFn<KV<Row, Iterable<Row>>, KV<Row, Iterable<Row>>> {\n+\n+      private final Schema cSchema;\n+      private final ArrayList<OrderKey> orderKeys;\n+\n+      public SortPerKey(Schema cSchema, RelCollation orderKeys) {\n+        this.cSchema = cSchema;\n+\n+        List<RelFieldCollation> revOrderKeys = orderKeys.getFieldCollations();\n+        Collections.reverse(revOrderKeys);\n+        ArrayList<OrderKey> revOrderKeysList = new ArrayList<>();\n+        for (RelFieldCollation i : revOrderKeys) {\n+          int fIndex = i.getFieldIndex();\n+          RelFieldCollation.Direction dir = i.getDirection();\n+          if (dir == RelFieldCollation.Direction.ASCENDING) {\n+            revOrderKeysList.add(new OrderKey(fIndex, false));\n+          } else {\n+            revOrderKeysList.add(new OrderKey(fIndex, true));\n+          }\n+        }\n+\n+        this.orderKeys = revOrderKeysList;\n+      }\n+\n+      @ProcessElement\n+      public void processElement(\n+          @Element KV<Row, Iterable<Row>> keyRows, OutputReceiver<KV<Row, Iterable<Row>>> out) {\n+        ArrayList<Row> rows = new ArrayList<Row>();\n+        for (Row i : keyRows.getValue()) {\n+          rows.add(i);\n+        }\n+        for (OrderKey i : orderKeys) {\n+          int fIndex = i.getIndex();\n+          boolean dir = i.getDir();\n+          rows.sort(new SortComparator(fIndex, dir));\n+        }\n+        // TODO: Change the comparator to the row comparator:\n+        // https://github.com/apache/beam/blob/master/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamSortRel.java#L373\n+\n+        out.output(KV.of(keyRows.getKey(), rows));\n+      }\n+\n+      private class SortComparator implements Comparator<Row> {\n+\n+        private final int fIndex;\n+        private final int inv;\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1727e170ef88ed8150a7fd30f6f9254ef1031548"}, "originalPosition": 286}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ3NjYwMDQz", "url": "https://github.com/apache/beam/pull/12232#pullrequestreview-447660043", "createdAt": "2020-07-13T22:40:14Z", "commit": {"oid": "1727e170ef88ed8150a7fd30f6f9254ef1031548"}, "state": "COMMENTED", "comments": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QyMjo0MDoxNVrOGw9NzQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QyMzowNDo1MVrOGw9u2Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk4Nzc4OQ==", "bodyText": "This seems a unused class?", "url": "https://github.com/apache/beam/pull/12232#discussion_r453987789", "createdAt": "2020-07-13T22:40:15Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/cep/CEPOperand.java", "diffHunk": "@@ -0,0 +1,20 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.cep;\n+\n+public class CEPOperand {}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1727e170ef88ed8150a7fd30f6f9254ef1031548"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk4OTIwMg==", "bodyText": "To make sure I understand this example.\nDoes PATTERN(A B C) means it should produce rows, in which each three rows are a set, and in each set, names should be a, b, c and also in this order?", "url": "https://github.com/apache/beam/pull/12232#discussion_r453989202", "createdAt": "2020-07-13T22:44:14Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRelTest.java", "diffHunk": "@@ -0,0 +1,75 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.rel;\n+\n+import static org.apache.beam.sdk.extensions.sql.impl.rel.BaseRelTest.compilePipeline;\n+import static org.apache.beam.sdk.extensions.sql.impl.rel.BaseRelTest.registerTable;\n+\n+import org.apache.beam.sdk.extensions.sql.TestUtils;\n+import org.apache.beam.sdk.extensions.sql.meta.provider.test.TestBoundedTable;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.testing.PAssert;\n+import org.apache.beam.sdk.testing.TestPipeline;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.Row;\n+import org.junit.Rule;\n+import org.junit.Test;\n+\n+public class BeamMatchRelTest {\n+\n+  @Rule public final TestPipeline pipeline = TestPipeline.create();\n+\n+  @Test\n+  public void matchLogicalPlanTest() {\n+    Schema schemaType =\n+        Schema.builder()\n+            .addInt32Field(\"id\")\n+            .addStringField(\"name\")\n+            .addInt32Field(\"proctime\")\n+            .build();\n+\n+    registerTable(\n+        \"TestTable\", TestBoundedTable.of(schemaType).addRows(1, \"a\", 1, 1, \"b\", 2, 1, \"c\", 3));\n+\n+    String sql =\n+        \"SELECT * \"\n+            + \"FROM TestTable \"\n+            + \"MATCH_RECOGNIZE (\"\n+            + \"PARTITION BY id \"\n+            + \"ORDER BY proctime \"\n+            + \"PATTERN (A B C) \"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1727e170ef88ed8150a7fd30f6f9254ef1031548"}, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk4OTM4OQ==", "bodyText": "For all new classes, please add javadoc to explain these classes (i.e. /** */). Adding comments are usual good idea to improve your code's readability.", "url": "https://github.com/apache/beam/pull/12232#discussion_r453989389", "createdAt": "2020-07-13T22:44:44Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rule/BeamMatchRule.java", "diffHunk": "@@ -0,0 +1,56 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.rule;\n+\n+import org.apache.beam.sdk.extensions.sql.impl.rel.BeamLogicalConvention;\n+import org.apache.beam.sdk.extensions.sql.impl.rel.BeamMatchRel;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.Convention;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.convert.ConverterRule;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.Match;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.logical.LogicalMatch;\n+\n+public class BeamMatchRule extends ConverterRule {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1727e170ef88ed8150a7fd30f6f9254ef1031548"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk4OTgzNA==", "bodyText": "In fact what you are doing is ok. This is minor.", "url": "https://github.com/apache/beam/pull/12232#discussion_r453989834", "createdAt": "2020-07-13T22:45:54Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java", "diffHunk": "@@ -0,0 +1,380 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.rel;\n+\n+import static org.apache.beam.vendor.calcite.v1_20_0.com.google.common.base.Preconditions.checkArgument;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.beam.sdk.coders.KvCoder;\n+import org.apache.beam.sdk.coders.RowCoder;\n+import org.apache.beam.sdk.extensions.sql.impl.SqlConversionException;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.CEPPattern;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.CEPUtil;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.OrderKey;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.BeamCostModel;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.NodeStats;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.GroupByKey;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionList;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptCluster;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptPlanner;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelTraitSet;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelFieldCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.Match;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.metadata.RelMetadataQuery;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.type.RelDataType;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexCall;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexVariable;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/** {@link BeamRelNode} to replace a {@link Match} node. */\n+public class BeamMatchRel extends Match implements BeamRelNode {\n+\n+  public static final Logger LOG = LoggerFactory.getLogger(BeamMatchRel.class);\n+\n+  public BeamMatchRel(\n+      RelOptCluster cluster,\n+      RelTraitSet traitSet,\n+      RelNode input,\n+      RelDataType rowType,\n+      RexNode pattern,\n+      boolean strictStart,\n+      boolean strictEnd,\n+      Map<String, RexNode> patternDefinitions,\n+      Map<String, RexNode> measures,\n+      RexNode after,\n+      Map<String, ? extends SortedSet<String>> subsets,\n+      boolean allRows,\n+      List<RexNode> partitionKeys,\n+      RelCollation orderKeys,\n+      RexNode interval) {\n+\n+    super(\n+        cluster,\n+        traitSet,\n+        input,\n+        rowType,\n+        pattern,\n+        strictStart,\n+        strictEnd,\n+        patternDefinitions,\n+        measures,\n+        after,\n+        subsets,\n+        allRows,\n+        partitionKeys,\n+        orderKeys,\n+        interval);\n+  }\n+\n+  @Override\n+  public BeamCostModel beamComputeSelfCost(RelOptPlanner planner, RelMetadataQuery mq) {\n+    return BeamCostModel.FACTORY.makeTinyCost(); // return constant costModel for now\n+  }\n+\n+  @Override\n+  public NodeStats estimateNodeStats(RelMetadataQuery mq) {\n+    // a simple way of getting some estimate data\n+    // to be examined further\n+    NodeStats inputEstimate = BeamSqlRelUtils.getNodeStats(input, mq);\n+    double numRows = inputEstimate.getRowCount();\n+    double winSize = inputEstimate.getWindow();\n+    double rate = inputEstimate.getRate();\n+\n+    return NodeStats.create(numRows, rate, winSize).multiply(0.5);\n+  }\n+\n+  @Override\n+  public PTransform<PCollectionList<Row>, PCollection<Row>> buildPTransform() {\n+\n+    return new MatchTransform(partitionKeys, orderKeys, pattern, patternDefinitions);\n+  }\n+\n+  private static class MatchTransform extends PTransform<PCollectionList<Row>, PCollection<Row>> {\n+\n+    private final List<RexNode> parKeys;\n+    private final RelCollation orderKeys;\n+    private final RexNode pattern;\n+    private final Map<String, RexNode> patternDefs;\n+\n+    public MatchTransform(\n+        List<RexNode> parKeys,\n+        RelCollation orderKeys,\n+        RexNode pattern,\n+        Map<String, RexNode> patternDefs) {\n+      this.parKeys = parKeys;\n+      this.orderKeys = orderKeys;\n+      this.pattern = pattern;\n+      this.patternDefs = patternDefs;\n+    }\n+\n+    @Override\n+    public PCollection<Row> expand(PCollectionList<Row> pinput) {\n+      checkArgument(\n+          pinput.size() == 1,\n+          \"Wrong number of inputs for %s: %s\",\n+          BeamMatchRel.class.getSimpleName(),\n+          pinput);\n+      PCollection<Row> upstream = pinput.get(0);\n+\n+      Schema collectionSchema = upstream.getSchema();\n+\n+      Schema.Builder schemaBuilder = new Schema.Builder();\n+      for (RexNode i : parKeys) {\n+        RexVariable varNode = (RexVariable) i;\n+        int index = Integer.parseInt(varNode.getName().substring(1)); // get rid of `$`\n+        schemaBuilder.addField(collectionSchema.getField(index));\n+      }\n+      Schema mySchema = schemaBuilder.build();\n+\n+      // partition according to the partition keys\n+      PCollection<KV<Row, Row>> keyedUpstream = upstream.apply(ParDo.of(new MapKeys(mySchema)));\n+\n+      // group by keys\n+      PCollection<KV<Row, Iterable<Row>>> groupedUpstream =\n+          keyedUpstream\n+              .setCoder(KvCoder.of(RowCoder.of(mySchema), RowCoder.of(collectionSchema)))\n+              .apply(GroupByKey.create());\n+\n+      // sort within each keyed partition\n+      PCollection<KV<Row, Iterable<Row>>> orderedUpstream =\n+          groupedUpstream.apply(ParDo.of(new SortPerKey(collectionSchema, orderKeys)));\n+\n+      // apply the pattern match in each partition\n+      ArrayList<CEPPattern> cepPattern =\n+          CEPUtil.getCEPPatternFromPattern(collectionSchema, (RexCall) pattern, patternDefs);\n+      String regexPattern = CEPUtil.getRegexFromPattern((RexCall) pattern);\n+      PCollection<KV<Row, Iterable<Row>>> matchedUpstream =\n+          orderedUpstream.apply(ParDo.of(new MatchPattern(cepPattern, regexPattern)));\n+\n+      // apply the ParDo for the measures clause\n+      // for now, output the all rows of each pattern matched (for testing purpose)\n+      PCollection<Row> outStream =\n+          matchedUpstream.apply(ParDo.of(new Measure())).setRowSchema(collectionSchema);\n+\n+      return outStream;\n+    }\n+\n+    private static class Measure extends DoFn<KV<Row, Iterable<Row>>, Row> {\n+\n+      @ProcessElement\n+      public void processElement(@Element KV<Row, Iterable<Row>> keyRows, OutputReceiver<Row> out) {\n+        for (Row i : keyRows.getValue()) {\n+          out.output(i);\n+        }\n+      }\n+    }\n+\n+    // TODO: support both ALL ROWS PER MATCH and ONE ROW PER MATCH.\n+    // support only one row per match for now.\n+    private static class MatchPattern extends DoFn<KV<Row, Iterable<Row>>, KV<Row, Iterable<Row>>> {\n+\n+      private final ArrayList<CEPPattern> pattern;\n+      private final String regexPattern;\n+\n+      MatchPattern(ArrayList<CEPPattern> pattern, String regexPattern) {\n+        this.pattern = pattern;\n+        this.regexPattern = regexPattern;\n+      }\n+\n+      @ProcessElement\n+      public void processElement(\n+          @Element KV<Row, Iterable<Row>> keyRows, OutputReceiver<KV<Row, Iterable<Row>>> out) {\n+        ArrayList<Row> rows = new ArrayList<>();\n+        StringBuilder patternString = new StringBuilder();\n+        for (Row i : keyRows.getValue()) {\n+          rows.add(i);\n+          // check pattern of row i\n+          String patternOfRow = \" \"; // a row with no matched pattern is marked by a space\n+          for (int j = 0; j < pattern.size(); ++j) {\n+            CEPPattern tryPattern = pattern.get(j);\n+            if (tryPattern.evalRow(i)) {\n+              patternOfRow = tryPattern.toString();\n+            }\n+          }\n+          patternString.append(patternOfRow);\n+        }\n+\n+        Pattern p = Pattern.compile(regexPattern);\n+        Matcher m = p.matcher(patternString.toString());\n+        // if the pattern is (A B+ C),\n+        // it should return a List three rows matching A B C respectively\n+        if (m.matches()) {\n+          out.output(KV.of(keyRows.getKey(), rows.subList(m.start(), m.end())));\n+        }\n+      }\n+    }\n+\n+    private static class SortPerKey extends DoFn<KV<Row, Iterable<Row>>, KV<Row, Iterable<Row>>> {\n+\n+      private final Schema cSchema;\n+      private final ArrayList<OrderKey> orderKeys;\n+\n+      public SortPerKey(Schema cSchema, RelCollation orderKeys) {\n+        this.cSchema = cSchema;\n+\n+        List<RelFieldCollation> revOrderKeys = orderKeys.getFieldCollations();\n+        Collections.reverse(revOrderKeys);\n+        ArrayList<OrderKey> revOrderKeysList = new ArrayList<>();\n+        for (RelFieldCollation i : revOrderKeys) {\n+          int fIndex = i.getFieldIndex();\n+          RelFieldCollation.Direction dir = i.getDirection();\n+          if (dir == RelFieldCollation.Direction.ASCENDING) {\n+            revOrderKeysList.add(new OrderKey(fIndex, false));\n+          } else {\n+            revOrderKeysList.add(new OrderKey(fIndex, true));\n+          }\n+        }\n+\n+        this.orderKeys = revOrderKeysList;\n+      }\n+\n+      @ProcessElement\n+      public void processElement(\n+          @Element KV<Row, Iterable<Row>> keyRows, OutputReceiver<KV<Row, Iterable<Row>>> out) {\n+        ArrayList<Row> rows = new ArrayList<Row>();\n+        for (Row i : keyRows.getValue()) {\n+          rows.add(i);\n+        }\n+        for (OrderKey i : orderKeys) {\n+          int fIndex = i.getIndex();\n+          boolean dir = i.getDir();\n+          rows.sort(new SortComparator(fIndex, dir));\n+        }\n+        // TODO: Change the comparator to the row comparator:\n+        // https://github.com/apache/beam/blob/master/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamSortRel.java#L373\n+\n+        out.output(KV.of(keyRows.getKey(), rows));\n+      }\n+\n+      private class SortComparator implements Comparator<Row> {\n+\n+        private final int fIndex;\n+        private final int inv;\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzI5NDY4MA=="}, "originalCommit": {"oid": "1727e170ef88ed8150a7fd30f6f9254ef1031548"}, "originalPosition": 286}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk5MTEzMQ==", "bodyText": "Nit: upstreamSchema might be a better variable name.", "url": "https://github.com/apache/beam/pull/12232#discussion_r453991131", "createdAt": "2020-07-13T22:49:42Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java", "diffHunk": "@@ -0,0 +1,380 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.rel;\n+\n+import static org.apache.beam.vendor.calcite.v1_20_0.com.google.common.base.Preconditions.checkArgument;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.beam.sdk.coders.KvCoder;\n+import org.apache.beam.sdk.coders.RowCoder;\n+import org.apache.beam.sdk.extensions.sql.impl.SqlConversionException;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.CEPPattern;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.CEPUtil;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.OrderKey;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.BeamCostModel;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.NodeStats;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.GroupByKey;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionList;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptCluster;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptPlanner;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelTraitSet;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelFieldCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.Match;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.metadata.RelMetadataQuery;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.type.RelDataType;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexCall;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexVariable;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/** {@link BeamRelNode} to replace a {@link Match} node. */\n+public class BeamMatchRel extends Match implements BeamRelNode {\n+\n+  public static final Logger LOG = LoggerFactory.getLogger(BeamMatchRel.class);\n+\n+  public BeamMatchRel(\n+      RelOptCluster cluster,\n+      RelTraitSet traitSet,\n+      RelNode input,\n+      RelDataType rowType,\n+      RexNode pattern,\n+      boolean strictStart,\n+      boolean strictEnd,\n+      Map<String, RexNode> patternDefinitions,\n+      Map<String, RexNode> measures,\n+      RexNode after,\n+      Map<String, ? extends SortedSet<String>> subsets,\n+      boolean allRows,\n+      List<RexNode> partitionKeys,\n+      RelCollation orderKeys,\n+      RexNode interval) {\n+\n+    super(\n+        cluster,\n+        traitSet,\n+        input,\n+        rowType,\n+        pattern,\n+        strictStart,\n+        strictEnd,\n+        patternDefinitions,\n+        measures,\n+        after,\n+        subsets,\n+        allRows,\n+        partitionKeys,\n+        orderKeys,\n+        interval);\n+  }\n+\n+  @Override\n+  public BeamCostModel beamComputeSelfCost(RelOptPlanner planner, RelMetadataQuery mq) {\n+    return BeamCostModel.FACTORY.makeTinyCost(); // return constant costModel for now\n+  }\n+\n+  @Override\n+  public NodeStats estimateNodeStats(RelMetadataQuery mq) {\n+    // a simple way of getting some estimate data\n+    // to be examined further\n+    NodeStats inputEstimate = BeamSqlRelUtils.getNodeStats(input, mq);\n+    double numRows = inputEstimate.getRowCount();\n+    double winSize = inputEstimate.getWindow();\n+    double rate = inputEstimate.getRate();\n+\n+    return NodeStats.create(numRows, rate, winSize).multiply(0.5);\n+  }\n+\n+  @Override\n+  public PTransform<PCollectionList<Row>, PCollection<Row>> buildPTransform() {\n+\n+    return new MatchTransform(partitionKeys, orderKeys, pattern, patternDefinitions);\n+  }\n+\n+  private static class MatchTransform extends PTransform<PCollectionList<Row>, PCollection<Row>> {\n+\n+    private final List<RexNode> parKeys;\n+    private final RelCollation orderKeys;\n+    private final RexNode pattern;\n+    private final Map<String, RexNode> patternDefs;\n+\n+    public MatchTransform(\n+        List<RexNode> parKeys,\n+        RelCollation orderKeys,\n+        RexNode pattern,\n+        Map<String, RexNode> patternDefs) {\n+      this.parKeys = parKeys;\n+      this.orderKeys = orderKeys;\n+      this.pattern = pattern;\n+      this.patternDefs = patternDefs;\n+    }\n+\n+    @Override\n+    public PCollection<Row> expand(PCollectionList<Row> pinput) {\n+      checkArgument(\n+          pinput.size() == 1,\n+          \"Wrong number of inputs for %s: %s\",\n+          BeamMatchRel.class.getSimpleName(),\n+          pinput);\n+      PCollection<Row> upstream = pinput.get(0);\n+\n+      Schema collectionSchema = upstream.getSchema();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1727e170ef88ed8150a7fd30f6f9254ef1031548"}, "originalPosition": 152}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk5MjI1Nw==", "bodyText": "Ah so is collectionSchema's field name the same as varNode's name (including that $)?\nSee Schema.getName API: https://github.com/apache/beam/blob/master/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/Schema.java#L1270", "url": "https://github.com/apache/beam/pull/12232#discussion_r453992257", "createdAt": "2020-07-13T22:53:05Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java", "diffHunk": "@@ -0,0 +1,380 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.rel;\n+\n+import static org.apache.beam.vendor.calcite.v1_20_0.com.google.common.base.Preconditions.checkArgument;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.beam.sdk.coders.KvCoder;\n+import org.apache.beam.sdk.coders.RowCoder;\n+import org.apache.beam.sdk.extensions.sql.impl.SqlConversionException;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.CEPPattern;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.CEPUtil;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.OrderKey;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.BeamCostModel;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.NodeStats;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.GroupByKey;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionList;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptCluster;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptPlanner;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelTraitSet;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelFieldCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.Match;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.metadata.RelMetadataQuery;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.type.RelDataType;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexCall;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexVariable;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/** {@link BeamRelNode} to replace a {@link Match} node. */\n+public class BeamMatchRel extends Match implements BeamRelNode {\n+\n+  public static final Logger LOG = LoggerFactory.getLogger(BeamMatchRel.class);\n+\n+  public BeamMatchRel(\n+      RelOptCluster cluster,\n+      RelTraitSet traitSet,\n+      RelNode input,\n+      RelDataType rowType,\n+      RexNode pattern,\n+      boolean strictStart,\n+      boolean strictEnd,\n+      Map<String, RexNode> patternDefinitions,\n+      Map<String, RexNode> measures,\n+      RexNode after,\n+      Map<String, ? extends SortedSet<String>> subsets,\n+      boolean allRows,\n+      List<RexNode> partitionKeys,\n+      RelCollation orderKeys,\n+      RexNode interval) {\n+\n+    super(\n+        cluster,\n+        traitSet,\n+        input,\n+        rowType,\n+        pattern,\n+        strictStart,\n+        strictEnd,\n+        patternDefinitions,\n+        measures,\n+        after,\n+        subsets,\n+        allRows,\n+        partitionKeys,\n+        orderKeys,\n+        interval);\n+  }\n+\n+  @Override\n+  public BeamCostModel beamComputeSelfCost(RelOptPlanner planner, RelMetadataQuery mq) {\n+    return BeamCostModel.FACTORY.makeTinyCost(); // return constant costModel for now\n+  }\n+\n+  @Override\n+  public NodeStats estimateNodeStats(RelMetadataQuery mq) {\n+    // a simple way of getting some estimate data\n+    // to be examined further\n+    NodeStats inputEstimate = BeamSqlRelUtils.getNodeStats(input, mq);\n+    double numRows = inputEstimate.getRowCount();\n+    double winSize = inputEstimate.getWindow();\n+    double rate = inputEstimate.getRate();\n+\n+    return NodeStats.create(numRows, rate, winSize).multiply(0.5);\n+  }\n+\n+  @Override\n+  public PTransform<PCollectionList<Row>, PCollection<Row>> buildPTransform() {\n+\n+    return new MatchTransform(partitionKeys, orderKeys, pattern, patternDefinitions);\n+  }\n+\n+  private static class MatchTransform extends PTransform<PCollectionList<Row>, PCollection<Row>> {\n+\n+    private final List<RexNode> parKeys;\n+    private final RelCollation orderKeys;\n+    private final RexNode pattern;\n+    private final Map<String, RexNode> patternDefs;\n+\n+    public MatchTransform(\n+        List<RexNode> parKeys,\n+        RelCollation orderKeys,\n+        RexNode pattern,\n+        Map<String, RexNode> patternDefs) {\n+      this.parKeys = parKeys;\n+      this.orderKeys = orderKeys;\n+      this.pattern = pattern;\n+      this.patternDefs = patternDefs;\n+    }\n+\n+    @Override\n+    public PCollection<Row> expand(PCollectionList<Row> pinput) {\n+      checkArgument(\n+          pinput.size() == 1,\n+          \"Wrong number of inputs for %s: %s\",\n+          BeamMatchRel.class.getSimpleName(),\n+          pinput);\n+      PCollection<Row> upstream = pinput.get(0);\n+\n+      Schema collectionSchema = upstream.getSchema();\n+\n+      Schema.Builder schemaBuilder = new Schema.Builder();\n+      for (RexNode i : parKeys) {\n+        RexVariable varNode = (RexVariable) i;\n+        int index = Integer.parseInt(varNode.getName().substring(1)); // get rid of `$`\n+        schemaBuilder.addField(collectionSchema.getField(index));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1727e170ef88ed8150a7fd30f6f9254ef1031548"}, "originalPosition": 158}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk5MjQyNA==", "bodyText": "Nit: name it PartitionKeySchema might be more readable.", "url": "https://github.com/apache/beam/pull/12232#discussion_r453992424", "createdAt": "2020-07-13T22:53:36Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java", "diffHunk": "@@ -0,0 +1,380 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.rel;\n+\n+import static org.apache.beam.vendor.calcite.v1_20_0.com.google.common.base.Preconditions.checkArgument;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.beam.sdk.coders.KvCoder;\n+import org.apache.beam.sdk.coders.RowCoder;\n+import org.apache.beam.sdk.extensions.sql.impl.SqlConversionException;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.CEPPattern;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.CEPUtil;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.OrderKey;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.BeamCostModel;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.NodeStats;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.GroupByKey;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionList;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptCluster;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptPlanner;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelTraitSet;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelFieldCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.Match;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.metadata.RelMetadataQuery;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.type.RelDataType;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexCall;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexVariable;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/** {@link BeamRelNode} to replace a {@link Match} node. */\n+public class BeamMatchRel extends Match implements BeamRelNode {\n+\n+  public static final Logger LOG = LoggerFactory.getLogger(BeamMatchRel.class);\n+\n+  public BeamMatchRel(\n+      RelOptCluster cluster,\n+      RelTraitSet traitSet,\n+      RelNode input,\n+      RelDataType rowType,\n+      RexNode pattern,\n+      boolean strictStart,\n+      boolean strictEnd,\n+      Map<String, RexNode> patternDefinitions,\n+      Map<String, RexNode> measures,\n+      RexNode after,\n+      Map<String, ? extends SortedSet<String>> subsets,\n+      boolean allRows,\n+      List<RexNode> partitionKeys,\n+      RelCollation orderKeys,\n+      RexNode interval) {\n+\n+    super(\n+        cluster,\n+        traitSet,\n+        input,\n+        rowType,\n+        pattern,\n+        strictStart,\n+        strictEnd,\n+        patternDefinitions,\n+        measures,\n+        after,\n+        subsets,\n+        allRows,\n+        partitionKeys,\n+        orderKeys,\n+        interval);\n+  }\n+\n+  @Override\n+  public BeamCostModel beamComputeSelfCost(RelOptPlanner planner, RelMetadataQuery mq) {\n+    return BeamCostModel.FACTORY.makeTinyCost(); // return constant costModel for now\n+  }\n+\n+  @Override\n+  public NodeStats estimateNodeStats(RelMetadataQuery mq) {\n+    // a simple way of getting some estimate data\n+    // to be examined further\n+    NodeStats inputEstimate = BeamSqlRelUtils.getNodeStats(input, mq);\n+    double numRows = inputEstimate.getRowCount();\n+    double winSize = inputEstimate.getWindow();\n+    double rate = inputEstimate.getRate();\n+\n+    return NodeStats.create(numRows, rate, winSize).multiply(0.5);\n+  }\n+\n+  @Override\n+  public PTransform<PCollectionList<Row>, PCollection<Row>> buildPTransform() {\n+\n+    return new MatchTransform(partitionKeys, orderKeys, pattern, patternDefinitions);\n+  }\n+\n+  private static class MatchTransform extends PTransform<PCollectionList<Row>, PCollection<Row>> {\n+\n+    private final List<RexNode> parKeys;\n+    private final RelCollation orderKeys;\n+    private final RexNode pattern;\n+    private final Map<String, RexNode> patternDefs;\n+\n+    public MatchTransform(\n+        List<RexNode> parKeys,\n+        RelCollation orderKeys,\n+        RexNode pattern,\n+        Map<String, RexNode> patternDefs) {\n+      this.parKeys = parKeys;\n+      this.orderKeys = orderKeys;\n+      this.pattern = pattern;\n+      this.patternDefs = patternDefs;\n+    }\n+\n+    @Override\n+    public PCollection<Row> expand(PCollectionList<Row> pinput) {\n+      checkArgument(\n+          pinput.size() == 1,\n+          \"Wrong number of inputs for %s: %s\",\n+          BeamMatchRel.class.getSimpleName(),\n+          pinput);\n+      PCollection<Row> upstream = pinput.get(0);\n+\n+      Schema collectionSchema = upstream.getSchema();\n+\n+      Schema.Builder schemaBuilder = new Schema.Builder();\n+      for (RexNode i : parKeys) {\n+        RexVariable varNode = (RexVariable) i;\n+        int index = Integer.parseInt(varNode.getName().substring(1)); // get rid of `$`\n+        schemaBuilder.addField(collectionSchema.getField(index));\n+      }\n+      Schema mySchema = schemaBuilder.build();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1727e170ef88ed8150a7fd30f6f9254ef1031548"}, "originalPosition": 160}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk5Mzc5OQ==", "bodyText": "In fact, there is also a NullDirection to consider (Null first/Null last): https://github.com/apache/calcite/blob/master/core/src/main/java/org/apache/calcite/rel/RelFieldCollation.java#L185\nIt is ok to not handle it for now, but please leave a TODO comment (i.e. // TODO: handle NullDirection)", "url": "https://github.com/apache/beam/pull/12232#discussion_r453993799", "createdAt": "2020-07-13T22:57:36Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java", "diffHunk": "@@ -0,0 +1,380 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.rel;\n+\n+import static org.apache.beam.vendor.calcite.v1_20_0.com.google.common.base.Preconditions.checkArgument;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.beam.sdk.coders.KvCoder;\n+import org.apache.beam.sdk.coders.RowCoder;\n+import org.apache.beam.sdk.extensions.sql.impl.SqlConversionException;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.CEPPattern;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.CEPUtil;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.OrderKey;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.BeamCostModel;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.NodeStats;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.GroupByKey;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionList;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptCluster;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptPlanner;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelTraitSet;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelFieldCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.Match;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.metadata.RelMetadataQuery;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.type.RelDataType;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexCall;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexVariable;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/** {@link BeamRelNode} to replace a {@link Match} node. */\n+public class BeamMatchRel extends Match implements BeamRelNode {\n+\n+  public static final Logger LOG = LoggerFactory.getLogger(BeamMatchRel.class);\n+\n+  public BeamMatchRel(\n+      RelOptCluster cluster,\n+      RelTraitSet traitSet,\n+      RelNode input,\n+      RelDataType rowType,\n+      RexNode pattern,\n+      boolean strictStart,\n+      boolean strictEnd,\n+      Map<String, RexNode> patternDefinitions,\n+      Map<String, RexNode> measures,\n+      RexNode after,\n+      Map<String, ? extends SortedSet<String>> subsets,\n+      boolean allRows,\n+      List<RexNode> partitionKeys,\n+      RelCollation orderKeys,\n+      RexNode interval) {\n+\n+    super(\n+        cluster,\n+        traitSet,\n+        input,\n+        rowType,\n+        pattern,\n+        strictStart,\n+        strictEnd,\n+        patternDefinitions,\n+        measures,\n+        after,\n+        subsets,\n+        allRows,\n+        partitionKeys,\n+        orderKeys,\n+        interval);\n+  }\n+\n+  @Override\n+  public BeamCostModel beamComputeSelfCost(RelOptPlanner planner, RelMetadataQuery mq) {\n+    return BeamCostModel.FACTORY.makeTinyCost(); // return constant costModel for now\n+  }\n+\n+  @Override\n+  public NodeStats estimateNodeStats(RelMetadataQuery mq) {\n+    // a simple way of getting some estimate data\n+    // to be examined further\n+    NodeStats inputEstimate = BeamSqlRelUtils.getNodeStats(input, mq);\n+    double numRows = inputEstimate.getRowCount();\n+    double winSize = inputEstimate.getWindow();\n+    double rate = inputEstimate.getRate();\n+\n+    return NodeStats.create(numRows, rate, winSize).multiply(0.5);\n+  }\n+\n+  @Override\n+  public PTransform<PCollectionList<Row>, PCollection<Row>> buildPTransform() {\n+\n+    return new MatchTransform(partitionKeys, orderKeys, pattern, patternDefinitions);\n+  }\n+\n+  private static class MatchTransform extends PTransform<PCollectionList<Row>, PCollection<Row>> {\n+\n+    private final List<RexNode> parKeys;\n+    private final RelCollation orderKeys;\n+    private final RexNode pattern;\n+    private final Map<String, RexNode> patternDefs;\n+\n+    public MatchTransform(\n+        List<RexNode> parKeys,\n+        RelCollation orderKeys,\n+        RexNode pattern,\n+        Map<String, RexNode> patternDefs) {\n+      this.parKeys = parKeys;\n+      this.orderKeys = orderKeys;\n+      this.pattern = pattern;\n+      this.patternDefs = patternDefs;\n+    }\n+\n+    @Override\n+    public PCollection<Row> expand(PCollectionList<Row> pinput) {\n+      checkArgument(\n+          pinput.size() == 1,\n+          \"Wrong number of inputs for %s: %s\",\n+          BeamMatchRel.class.getSimpleName(),\n+          pinput);\n+      PCollection<Row> upstream = pinput.get(0);\n+\n+      Schema collectionSchema = upstream.getSchema();\n+\n+      Schema.Builder schemaBuilder = new Schema.Builder();\n+      for (RexNode i : parKeys) {\n+        RexVariable varNode = (RexVariable) i;\n+        int index = Integer.parseInt(varNode.getName().substring(1)); // get rid of `$`\n+        schemaBuilder.addField(collectionSchema.getField(index));\n+      }\n+      Schema mySchema = schemaBuilder.build();\n+\n+      // partition according to the partition keys\n+      PCollection<KV<Row, Row>> keyedUpstream = upstream.apply(ParDo.of(new MapKeys(mySchema)));\n+\n+      // group by keys\n+      PCollection<KV<Row, Iterable<Row>>> groupedUpstream =\n+          keyedUpstream\n+              .setCoder(KvCoder.of(RowCoder.of(mySchema), RowCoder.of(collectionSchema)))\n+              .apply(GroupByKey.create());\n+\n+      // sort within each keyed partition\n+      PCollection<KV<Row, Iterable<Row>>> orderedUpstream =\n+          groupedUpstream.apply(ParDo.of(new SortPerKey(collectionSchema, orderKeys)));\n+\n+      // apply the pattern match in each partition\n+      ArrayList<CEPPattern> cepPattern =\n+          CEPUtil.getCEPPatternFromPattern(collectionSchema, (RexCall) pattern, patternDefs);\n+      String regexPattern = CEPUtil.getRegexFromPattern((RexCall) pattern);\n+      PCollection<KV<Row, Iterable<Row>>> matchedUpstream =\n+          orderedUpstream.apply(ParDo.of(new MatchPattern(cepPattern, regexPattern)));\n+\n+      // apply the ParDo for the measures clause\n+      // for now, output the all rows of each pattern matched (for testing purpose)\n+      PCollection<Row> outStream =\n+          matchedUpstream.apply(ParDo.of(new Measure())).setRowSchema(collectionSchema);\n+\n+      return outStream;\n+    }\n+\n+    private static class Measure extends DoFn<KV<Row, Iterable<Row>>, Row> {\n+\n+      @ProcessElement\n+      public void processElement(@Element KV<Row, Iterable<Row>> keyRows, OutputReceiver<Row> out) {\n+        for (Row i : keyRows.getValue()) {\n+          out.output(i);\n+        }\n+      }\n+    }\n+\n+    // TODO: support both ALL ROWS PER MATCH and ONE ROW PER MATCH.\n+    // support only one row per match for now.\n+    private static class MatchPattern extends DoFn<KV<Row, Iterable<Row>>, KV<Row, Iterable<Row>>> {\n+\n+      private final ArrayList<CEPPattern> pattern;\n+      private final String regexPattern;\n+\n+      MatchPattern(ArrayList<CEPPattern> pattern, String regexPattern) {\n+        this.pattern = pattern;\n+        this.regexPattern = regexPattern;\n+      }\n+\n+      @ProcessElement\n+      public void processElement(\n+          @Element KV<Row, Iterable<Row>> keyRows, OutputReceiver<KV<Row, Iterable<Row>>> out) {\n+        ArrayList<Row> rows = new ArrayList<>();\n+        StringBuilder patternString = new StringBuilder();\n+        for (Row i : keyRows.getValue()) {\n+          rows.add(i);\n+          // check pattern of row i\n+          String patternOfRow = \" \"; // a row with no matched pattern is marked by a space\n+          for (int j = 0; j < pattern.size(); ++j) {\n+            CEPPattern tryPattern = pattern.get(j);\n+            if (tryPattern.evalRow(i)) {\n+              patternOfRow = tryPattern.toString();\n+            }\n+          }\n+          patternString.append(patternOfRow);\n+        }\n+\n+        Pattern p = Pattern.compile(regexPattern);\n+        Matcher m = p.matcher(patternString.toString());\n+        // if the pattern is (A B+ C),\n+        // it should return a List three rows matching A B C respectively\n+        if (m.matches()) {\n+          out.output(KV.of(keyRows.getKey(), rows.subList(m.start(), m.end())));\n+        }\n+      }\n+    }\n+\n+    private static class SortPerKey extends DoFn<KV<Row, Iterable<Row>>, KV<Row, Iterable<Row>>> {\n+\n+      private final Schema cSchema;\n+      private final ArrayList<OrderKey> orderKeys;\n+\n+      public SortPerKey(Schema cSchema, RelCollation orderKeys) {\n+        this.cSchema = cSchema;\n+\n+        List<RelFieldCollation> revOrderKeys = orderKeys.getFieldCollations();\n+        Collections.reverse(revOrderKeys);\n+        ArrayList<OrderKey> revOrderKeysList = new ArrayList<>();\n+        for (RelFieldCollation i : revOrderKeys) {\n+          int fIndex = i.getFieldIndex();\n+          RelFieldCollation.Direction dir = i.getDirection();\n+          if (dir == RelFieldCollation.Direction.ASCENDING) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1727e170ef88ed8150a7fd30f6f9254ef1031548"}, "originalPosition": 254}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk5NDcxNA==", "bodyText": "I think you got to make Pattern p as a variable to compile once?", "url": "https://github.com/apache/beam/pull/12232#discussion_r453994714", "createdAt": "2020-07-13T23:00:14Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java", "diffHunk": "@@ -0,0 +1,380 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.rel;\n+\n+import static org.apache.beam.vendor.calcite.v1_20_0.com.google.common.base.Preconditions.checkArgument;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.beam.sdk.coders.KvCoder;\n+import org.apache.beam.sdk.coders.RowCoder;\n+import org.apache.beam.sdk.extensions.sql.impl.SqlConversionException;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.CEPPattern;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.CEPUtil;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.OrderKey;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.BeamCostModel;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.NodeStats;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.GroupByKey;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionList;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptCluster;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptPlanner;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelTraitSet;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelFieldCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.Match;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.metadata.RelMetadataQuery;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.type.RelDataType;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexCall;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexVariable;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/** {@link BeamRelNode} to replace a {@link Match} node. */\n+public class BeamMatchRel extends Match implements BeamRelNode {\n+\n+  public static final Logger LOG = LoggerFactory.getLogger(BeamMatchRel.class);\n+\n+  public BeamMatchRel(\n+      RelOptCluster cluster,\n+      RelTraitSet traitSet,\n+      RelNode input,\n+      RelDataType rowType,\n+      RexNode pattern,\n+      boolean strictStart,\n+      boolean strictEnd,\n+      Map<String, RexNode> patternDefinitions,\n+      Map<String, RexNode> measures,\n+      RexNode after,\n+      Map<String, ? extends SortedSet<String>> subsets,\n+      boolean allRows,\n+      List<RexNode> partitionKeys,\n+      RelCollation orderKeys,\n+      RexNode interval) {\n+\n+    super(\n+        cluster,\n+        traitSet,\n+        input,\n+        rowType,\n+        pattern,\n+        strictStart,\n+        strictEnd,\n+        patternDefinitions,\n+        measures,\n+        after,\n+        subsets,\n+        allRows,\n+        partitionKeys,\n+        orderKeys,\n+        interval);\n+  }\n+\n+  @Override\n+  public BeamCostModel beamComputeSelfCost(RelOptPlanner planner, RelMetadataQuery mq) {\n+    return BeamCostModel.FACTORY.makeTinyCost(); // return constant costModel for now\n+  }\n+\n+  @Override\n+  public NodeStats estimateNodeStats(RelMetadataQuery mq) {\n+    // a simple way of getting some estimate data\n+    // to be examined further\n+    NodeStats inputEstimate = BeamSqlRelUtils.getNodeStats(input, mq);\n+    double numRows = inputEstimate.getRowCount();\n+    double winSize = inputEstimate.getWindow();\n+    double rate = inputEstimate.getRate();\n+\n+    return NodeStats.create(numRows, rate, winSize).multiply(0.5);\n+  }\n+\n+  @Override\n+  public PTransform<PCollectionList<Row>, PCollection<Row>> buildPTransform() {\n+\n+    return new MatchTransform(partitionKeys, orderKeys, pattern, patternDefinitions);\n+  }\n+\n+  private static class MatchTransform extends PTransform<PCollectionList<Row>, PCollection<Row>> {\n+\n+    private final List<RexNode> parKeys;\n+    private final RelCollation orderKeys;\n+    private final RexNode pattern;\n+    private final Map<String, RexNode> patternDefs;\n+\n+    public MatchTransform(\n+        List<RexNode> parKeys,\n+        RelCollation orderKeys,\n+        RexNode pattern,\n+        Map<String, RexNode> patternDefs) {\n+      this.parKeys = parKeys;\n+      this.orderKeys = orderKeys;\n+      this.pattern = pattern;\n+      this.patternDefs = patternDefs;\n+    }\n+\n+    @Override\n+    public PCollection<Row> expand(PCollectionList<Row> pinput) {\n+      checkArgument(\n+          pinput.size() == 1,\n+          \"Wrong number of inputs for %s: %s\",\n+          BeamMatchRel.class.getSimpleName(),\n+          pinput);\n+      PCollection<Row> upstream = pinput.get(0);\n+\n+      Schema collectionSchema = upstream.getSchema();\n+\n+      Schema.Builder schemaBuilder = new Schema.Builder();\n+      for (RexNode i : parKeys) {\n+        RexVariable varNode = (RexVariable) i;\n+        int index = Integer.parseInt(varNode.getName().substring(1)); // get rid of `$`\n+        schemaBuilder.addField(collectionSchema.getField(index));\n+      }\n+      Schema mySchema = schemaBuilder.build();\n+\n+      // partition according to the partition keys\n+      PCollection<KV<Row, Row>> keyedUpstream = upstream.apply(ParDo.of(new MapKeys(mySchema)));\n+\n+      // group by keys\n+      PCollection<KV<Row, Iterable<Row>>> groupedUpstream =\n+          keyedUpstream\n+              .setCoder(KvCoder.of(RowCoder.of(mySchema), RowCoder.of(collectionSchema)))\n+              .apply(GroupByKey.create());\n+\n+      // sort within each keyed partition\n+      PCollection<KV<Row, Iterable<Row>>> orderedUpstream =\n+          groupedUpstream.apply(ParDo.of(new SortPerKey(collectionSchema, orderKeys)));\n+\n+      // apply the pattern match in each partition\n+      ArrayList<CEPPattern> cepPattern =\n+          CEPUtil.getCEPPatternFromPattern(collectionSchema, (RexCall) pattern, patternDefs);\n+      String regexPattern = CEPUtil.getRegexFromPattern((RexCall) pattern);\n+      PCollection<KV<Row, Iterable<Row>>> matchedUpstream =\n+          orderedUpstream.apply(ParDo.of(new MatchPattern(cepPattern, regexPattern)));\n+\n+      // apply the ParDo for the measures clause\n+      // for now, output the all rows of each pattern matched (for testing purpose)\n+      PCollection<Row> outStream =\n+          matchedUpstream.apply(ParDo.of(new Measure())).setRowSchema(collectionSchema);\n+\n+      return outStream;\n+    }\n+\n+    private static class Measure extends DoFn<KV<Row, Iterable<Row>>, Row> {\n+\n+      @ProcessElement\n+      public void processElement(@Element KV<Row, Iterable<Row>> keyRows, OutputReceiver<Row> out) {\n+        for (Row i : keyRows.getValue()) {\n+          out.output(i);\n+        }\n+      }\n+    }\n+\n+    // TODO: support both ALL ROWS PER MATCH and ONE ROW PER MATCH.\n+    // support only one row per match for now.\n+    private static class MatchPattern extends DoFn<KV<Row, Iterable<Row>>, KV<Row, Iterable<Row>>> {\n+\n+      private final ArrayList<CEPPattern> pattern;\n+      private final String regexPattern;\n+\n+      MatchPattern(ArrayList<CEPPattern> pattern, String regexPattern) {\n+        this.pattern = pattern;\n+        this.regexPattern = regexPattern;\n+      }\n+\n+      @ProcessElement\n+      public void processElement(\n+          @Element KV<Row, Iterable<Row>> keyRows, OutputReceiver<KV<Row, Iterable<Row>>> out) {\n+        ArrayList<Row> rows = new ArrayList<>();\n+        StringBuilder patternString = new StringBuilder();\n+        for (Row i : keyRows.getValue()) {\n+          rows.add(i);\n+          // check pattern of row i\n+          String patternOfRow = \" \"; // a row with no matched pattern is marked by a space\n+          for (int j = 0; j < pattern.size(); ++j) {\n+            CEPPattern tryPattern = pattern.get(j);\n+            if (tryPattern.evalRow(i)) {\n+              patternOfRow = tryPattern.toString();\n+            }\n+          }\n+          patternString.append(patternOfRow);\n+        }\n+\n+        Pattern p = Pattern.compile(regexPattern);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1727e170ef88ed8150a7fd30f6f9254ef1031548"}, "originalPosition": 230}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk5NTQ0Ng==", "bodyText": "Is it possible to reuse https://github.com/apache/beam/blob/master/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/Schema.java#L413?", "url": "https://github.com/apache/beam/pull/12232#discussion_r453995446", "createdAt": "2020-07-13T23:02:28Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/cep/CEPTypeName.java", "diffHunk": "@@ -0,0 +1,33 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.cep;\n+\n+import java.io.Serializable;\n+\n+public enum CEPTypeName implements Serializable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1727e170ef88ed8150a7fd30f6f9254ef1031548"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk5NjI0OQ==", "bodyText": "It is ok though if you still want to use a separate enum for CEP types, since it is a standalone library.\nJust curious, is there a type that is not covered by https://github.com/apache/beam/blob/master/sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/Schema.java#L413?", "url": "https://github.com/apache/beam/pull/12232#discussion_r453996249", "createdAt": "2020-07-13T23:04:51Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/cep/CEPTypeName.java", "diffHunk": "@@ -0,0 +1,33 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.cep;\n+\n+import java.io.Serializable;\n+\n+public enum CEPTypeName implements Serializable {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk5NTQ0Ng=="}, "originalCommit": {"oid": "1727e170ef88ed8150a7fd30f6f9254ef1031548"}, "originalPosition": 22}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ3NjcwNTI0", "url": "https://github.com/apache/beam/pull/12232#pullrequestreview-447670524", "createdAt": "2020-07-13T23:06:30Z", "commit": {"oid": "1727e170ef88ed8150a7fd30f6f9254ef1031548"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QyMzowNjozMFrOGw9xAw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QyMzowNjozMFrOGw9xAw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzk5NjgwMw==", "bodyText": "This will rely on an assumption that Fusion will fuse operators here so the sorted result will be preserved for the next match transform. In most of the runners (if not all) this should be true.", "url": "https://github.com/apache/beam/pull/12232#discussion_r453996803", "createdAt": "2020-07-13T23:06:30Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java", "diffHunk": "@@ -0,0 +1,380 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.rel;\n+\n+import static org.apache.beam.vendor.calcite.v1_20_0.com.google.common.base.Preconditions.checkArgument;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.Comparator;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.beam.sdk.coders.KvCoder;\n+import org.apache.beam.sdk.coders.RowCoder;\n+import org.apache.beam.sdk.extensions.sql.impl.SqlConversionException;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.CEPPattern;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.CEPUtil;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.OrderKey;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.BeamCostModel;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.NodeStats;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.GroupByKey;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionList;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptCluster;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptPlanner;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelTraitSet;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelFieldCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.Match;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.metadata.RelMetadataQuery;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.type.RelDataType;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexCall;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexVariable;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/** {@link BeamRelNode} to replace a {@link Match} node. */\n+public class BeamMatchRel extends Match implements BeamRelNode {\n+\n+  public static final Logger LOG = LoggerFactory.getLogger(BeamMatchRel.class);\n+\n+  public BeamMatchRel(\n+      RelOptCluster cluster,\n+      RelTraitSet traitSet,\n+      RelNode input,\n+      RelDataType rowType,\n+      RexNode pattern,\n+      boolean strictStart,\n+      boolean strictEnd,\n+      Map<String, RexNode> patternDefinitions,\n+      Map<String, RexNode> measures,\n+      RexNode after,\n+      Map<String, ? extends SortedSet<String>> subsets,\n+      boolean allRows,\n+      List<RexNode> partitionKeys,\n+      RelCollation orderKeys,\n+      RexNode interval) {\n+\n+    super(\n+        cluster,\n+        traitSet,\n+        input,\n+        rowType,\n+        pattern,\n+        strictStart,\n+        strictEnd,\n+        patternDefinitions,\n+        measures,\n+        after,\n+        subsets,\n+        allRows,\n+        partitionKeys,\n+        orderKeys,\n+        interval);\n+  }\n+\n+  @Override\n+  public BeamCostModel beamComputeSelfCost(RelOptPlanner planner, RelMetadataQuery mq) {\n+    return BeamCostModel.FACTORY.makeTinyCost(); // return constant costModel for now\n+  }\n+\n+  @Override\n+  public NodeStats estimateNodeStats(RelMetadataQuery mq) {\n+    // a simple way of getting some estimate data\n+    // to be examined further\n+    NodeStats inputEstimate = BeamSqlRelUtils.getNodeStats(input, mq);\n+    double numRows = inputEstimate.getRowCount();\n+    double winSize = inputEstimate.getWindow();\n+    double rate = inputEstimate.getRate();\n+\n+    return NodeStats.create(numRows, rate, winSize).multiply(0.5);\n+  }\n+\n+  @Override\n+  public PTransform<PCollectionList<Row>, PCollection<Row>> buildPTransform() {\n+\n+    return new MatchTransform(partitionKeys, orderKeys, pattern, patternDefinitions);\n+  }\n+\n+  private static class MatchTransform extends PTransform<PCollectionList<Row>, PCollection<Row>> {\n+\n+    private final List<RexNode> parKeys;\n+    private final RelCollation orderKeys;\n+    private final RexNode pattern;\n+    private final Map<String, RexNode> patternDefs;\n+\n+    public MatchTransform(\n+        List<RexNode> parKeys,\n+        RelCollation orderKeys,\n+        RexNode pattern,\n+        Map<String, RexNode> patternDefs) {\n+      this.parKeys = parKeys;\n+      this.orderKeys = orderKeys;\n+      this.pattern = pattern;\n+      this.patternDefs = patternDefs;\n+    }\n+\n+    @Override\n+    public PCollection<Row> expand(PCollectionList<Row> pinput) {\n+      checkArgument(\n+          pinput.size() == 1,\n+          \"Wrong number of inputs for %s: %s\",\n+          BeamMatchRel.class.getSimpleName(),\n+          pinput);\n+      PCollection<Row> upstream = pinput.get(0);\n+\n+      Schema collectionSchema = upstream.getSchema();\n+\n+      Schema.Builder schemaBuilder = new Schema.Builder();\n+      for (RexNode i : parKeys) {\n+        RexVariable varNode = (RexVariable) i;\n+        int index = Integer.parseInt(varNode.getName().substring(1)); // get rid of `$`\n+        schemaBuilder.addField(collectionSchema.getField(index));\n+      }\n+      Schema mySchema = schemaBuilder.build();\n+\n+      // partition according to the partition keys\n+      PCollection<KV<Row, Row>> keyedUpstream = upstream.apply(ParDo.of(new MapKeys(mySchema)));\n+\n+      // group by keys\n+      PCollection<KV<Row, Iterable<Row>>> groupedUpstream =\n+          keyedUpstream\n+              .setCoder(KvCoder.of(RowCoder.of(mySchema), RowCoder.of(collectionSchema)))\n+              .apply(GroupByKey.create());\n+\n+      // sort within each keyed partition\n+      PCollection<KV<Row, Iterable<Row>>> orderedUpstream =\n+          groupedUpstream.apply(ParDo.of(new SortPerKey(collectionSchema, orderKeys)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1727e170ef88ed8150a7fd30f6f9254ef1031548"}, "originalPosition": 173}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUyMTYyNzg3", "url": "https://github.com/apache/beam/pull/12232#pullrequestreview-452162787", "createdAt": "2020-07-21T06:34:18Z", "commit": {"oid": "e4652aedd6a3c1a9914d0ffe28b5f46bbb2bae38"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQwNjozNDoxOVrOG0qB5g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQwNjozNDoxOVrOG0qB5g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzg2Nzc1MA==", "bodyText": "I realized this should be a while loop. And for regex implementation, the default after match strategy is \"skip past last row\". I will change it to a while loop in my next commit.", "url": "https://github.com/apache/beam/pull/12232#discussion_r457867750", "createdAt": "2020-07-21T06:34:19Z", "author": {"login": "Mark-Zeng"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRel.java", "diffHunk": "@@ -0,0 +1,338 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.rel;\n+\n+import static org.apache.beam.sdk.extensions.sql.impl.cep.CEPUtil.makeOrderKeysFromCollation;\n+import static org.apache.beam.vendor.calcite.v1_20_0.com.google.common.base.Preconditions.checkArgument;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.SortedSet;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.beam.sdk.coders.KvCoder;\n+import org.apache.beam.sdk.coders.RowCoder;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.CEPPattern;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.CEPUtil;\n+import org.apache.beam.sdk.extensions.sql.impl.cep.OrderKey;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.BeamCostModel;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.NodeStats;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.GroupByKey;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionList;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptCluster;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptPlanner;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelTraitSet;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.Match;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.metadata.RelMetadataQuery;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.type.RelDataType;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexVariable;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * {@code BeamRelNode} to replace a {@code Match} node.\n+ *\n+ * <p>The {@code BeamMatchRel} is the Beam implementation of {@code MATCH_RECOGNIZE} in SQL.\n+ *\n+ * <p>For now, the underline implementation is based on java.util.regex.\n+ */\n+public class BeamMatchRel extends Match implements BeamRelNode {\n+\n+  public static final Logger LOG = LoggerFactory.getLogger(BeamMatchRel.class);\n+\n+  public BeamMatchRel(\n+      RelOptCluster cluster,\n+      RelTraitSet traitSet,\n+      RelNode input,\n+      RelDataType rowType,\n+      RexNode pattern,\n+      boolean strictStart,\n+      boolean strictEnd,\n+      Map<String, RexNode> patternDefinitions,\n+      Map<String, RexNode> measures,\n+      RexNode after,\n+      Map<String, ? extends SortedSet<String>> subsets,\n+      boolean allRows,\n+      List<RexNode> partitionKeys,\n+      RelCollation orderKeys,\n+      RexNode interval) {\n+\n+    super(\n+        cluster,\n+        traitSet,\n+        input,\n+        rowType,\n+        pattern,\n+        strictStart,\n+        strictEnd,\n+        patternDefinitions,\n+        measures,\n+        after,\n+        subsets,\n+        allRows,\n+        partitionKeys,\n+        orderKeys,\n+        interval);\n+  }\n+\n+  @Override\n+  public BeamCostModel beamComputeSelfCost(RelOptPlanner planner, RelMetadataQuery mq) {\n+    return BeamCostModel.FACTORY.makeTinyCost(); // return constant costModel for now\n+  }\n+\n+  @Override\n+  public NodeStats estimateNodeStats(RelMetadataQuery mq) {\n+    // a simple way of getting some estimate data\n+    // to be examined further\n+    NodeStats inputEstimate = BeamSqlRelUtils.getNodeStats(input, mq);\n+    double numRows = inputEstimate.getRowCount();\n+    double winSize = inputEstimate.getWindow();\n+    double rate = inputEstimate.getRate();\n+\n+    return NodeStats.create(numRows, rate, winSize).multiply(0.5);\n+  }\n+\n+  @Override\n+  public PTransform<PCollectionList<Row>, PCollection<Row>> buildPTransform() {\n+\n+    return new MatchTransform(partitionKeys, orderKeys, pattern, patternDefinitions);\n+  }\n+\n+  private static class MatchTransform extends PTransform<PCollectionList<Row>, PCollection<Row>> {\n+\n+    private final List<RexNode> parKeys;\n+    private final RelCollation orderKeys;\n+    private final RexNode pattern;\n+    private final Map<String, RexNode> patternDefs;\n+\n+    public MatchTransform(\n+        List<RexNode> parKeys,\n+        RelCollation orderKeys,\n+        RexNode pattern,\n+        Map<String, RexNode> patternDefs) {\n+      this.parKeys = parKeys;\n+      this.orderKeys = orderKeys;\n+      this.pattern = pattern;\n+      this.patternDefs = patternDefs;\n+    }\n+\n+    @Override\n+    public PCollection<Row> expand(PCollectionList<Row> pinput) {\n+      checkArgument(\n+          pinput.size() == 1,\n+          \"Wrong number of inputs for %s: %s\",\n+          BeamMatchRel.class.getSimpleName(),\n+          pinput);\n+      PCollection<Row> upstream = pinput.get(0);\n+\n+      Schema upstreamSchema = upstream.getSchema();\n+\n+      Schema.Builder schemaBuilder = new Schema.Builder();\n+      for (RexNode i : parKeys) {\n+        RexVariable varNode = (RexVariable) i;\n+        int index = Integer.parseInt(varNode.getName().substring(1)); // get rid of `$`\n+        schemaBuilder.addField(upstreamSchema.getField(index));\n+      }\n+      Schema partitionKeySchema = schemaBuilder.build();\n+\n+      // partition according to the partition keys\n+      PCollection<KV<Row, Row>> keyedUpstream =\n+          upstream.apply(ParDo.of(new MapKeys(partitionKeySchema)));\n+\n+      // group by keys\n+      PCollection<KV<Row, Iterable<Row>>> groupedUpstream =\n+          keyedUpstream\n+              .setCoder(KvCoder.of(RowCoder.of(partitionKeySchema), RowCoder.of(upstreamSchema)))\n+              .apply(GroupByKey.create());\n+\n+      // sort within each keyed partition\n+      ArrayList<OrderKey> orderKeyList = makeOrderKeysFromCollation(orderKeys);\n+      // This will rely on an assumption that Fusion will fuse\n+      // operators here so the sorted result will be preserved\n+      // for the next match transform.\n+      // In most of the runners (if not all) this should be true.\n+      PCollection<KV<Row, Iterable<Row>>> orderedUpstream =\n+          groupedUpstream.apply(ParDo.of(new SortPerKey(upstreamSchema, orderKeyList)));\n+\n+      // apply the pattern match in each partition\n+      ArrayList<CEPPattern> cepPattern =\n+          CEPUtil.getCEPPatternFromPattern(upstreamSchema, pattern, patternDefs);\n+      String regexPattern = CEPUtil.getRegexFromPattern(pattern);\n+      PCollection<KV<Row, Iterable<Row>>> matchedUpstream =\n+          orderedUpstream.apply(ParDo.of(new MatchPattern(cepPattern, regexPattern)));\n+\n+      // apply the ParDo for the measures clause\n+      // for now, output all rows of each pattern matched (for testing purpose)\n+      // TODO: add ONE ROW PER MATCH and MEASURES implementation.\n+      PCollection<Row> outStream =\n+          matchedUpstream.apply(ParDo.of(new Measure())).setRowSchema(upstreamSchema);\n+\n+      return outStream;\n+    }\n+\n+    private static class Measure extends DoFn<KV<Row, Iterable<Row>>, Row> {\n+\n+      @ProcessElement\n+      public void processElement(@Element KV<Row, Iterable<Row>> keyRows, OutputReceiver<Row> out) {\n+        for (Row i : keyRows.getValue()) {\n+          out.output(i);\n+        }\n+      }\n+    }\n+\n+    // TODO: support both ALL ROWS PER MATCH and ONE ROW PER MATCH.\n+    // support only one row per match for now.\n+    private static class MatchPattern extends DoFn<KV<Row, Iterable<Row>>, KV<Row, Iterable<Row>>> {\n+\n+      private final ArrayList<CEPPattern> pattern;\n+      private final String regexPattern;\n+\n+      MatchPattern(ArrayList<CEPPattern> pattern, String regexPattern) {\n+        this.pattern = pattern;\n+        this.regexPattern = regexPattern;\n+      }\n+\n+      @ProcessElement\n+      public void processElement(\n+          @Element KV<Row, Iterable<Row>> keyRows, OutputReceiver<KV<Row, Iterable<Row>>> out) {\n+        ArrayList<Row> rows = new ArrayList<>();\n+        StringBuilder patternString = new StringBuilder();\n+        for (Row i : keyRows.getValue()) {\n+          rows.add(i);\n+          // check pattern of row i\n+          String patternOfRow = \" \"; // a row with no matched pattern is marked by a space\n+          for (int j = 0; j < pattern.size(); ++j) {\n+            CEPPattern tryPattern = pattern.get(j);\n+            if (tryPattern.evalRow(i)) {\n+              patternOfRow = tryPattern.getPatternVar();\n+            }\n+          }\n+          patternString.append(patternOfRow);\n+        }\n+\n+        Pattern p = Pattern.compile(regexPattern);\n+        Matcher m = p.matcher(patternString.toString());\n+        // if the pattern is (A B+ C),\n+        // it should return a List three rows matching A B C respectively\n+        if (m.matches()) {\n+          out.output(KV.of(keyRows.getKey(), rows.subList(m.start(), m.end())));\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4652aedd6a3c1a9914d0ffe28b5f46bbb2bae38"}, "originalPosition": 245}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU1MjQ0OTAy", "url": "https://github.com/apache/beam/pull/12232#pullrequestreview-455244902", "createdAt": "2020-07-25T00:42:35Z", "commit": {"oid": "e4652aedd6a3c1a9914d0ffe28b5f46bbb2bae38"}, "state": "APPROVED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNVQwMDo0MjozNVrOG3BBzw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNVQwMDo1NDoxMlrOG3BITg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM0MTcxMQ==", "bodyText": "Is it correct to not handle other classes?\nIf so can you add an exception in the last else?", "url": "https://github.com/apache/beam/pull/12232#discussion_r460341711", "createdAt": "2020-07-25T00:42:35Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/cep/CEPCall.java", "diffHunk": "@@ -0,0 +1,72 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.cep;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexCall;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexLiteral;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexPatternFieldRef;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.sql.SqlOperator;\n+\n+/**\n+ * A {@code CEPCall} instance represents an operation (node) that contains an operator and a list of\n+ * operands. It has the similar functionality as Calcite's {@code RexCall}.\n+ */\n+public class CEPCall extends CEPOperation {\n+\n+  private final CEPOperator operator;\n+  private final List<CEPOperation> operands;\n+\n+  private CEPCall(CEPOperator operator, List<CEPOperation> operands) {\n+    this.operator = operator;\n+    this.operands = operands;\n+  }\n+\n+  public CEPOperator getOperator() {\n+    return operator;\n+  }\n+\n+  public List<CEPOperation> getOperands() {\n+    return operands;\n+  }\n+\n+  public static CEPCall of(RexCall operation) {\n+    SqlOperator call = operation.getOperator();\n+    CEPOperator myOp = CEPOperator.of(call);\n+\n+    ArrayList<CEPOperation> operandsList = new ArrayList<>();\n+    for (RexNode i : operation.getOperands()) {\n+      if (i.getClass() == RexCall.class) {\n+        CEPCall callToAdd = CEPCall.of((RexCall) i);\n+        operandsList.add(callToAdd);\n+      } else if (i.getClass() == RexLiteral.class) {\n+        RexLiteral lit = (RexLiteral) i;\n+        CEPLiteral litToAdd = CEPLiteral.of(lit);\n+        operandsList.add(litToAdd);\n+      } else if (i.getClass() == RexPatternFieldRef.class) {\n+        RexPatternFieldRef fieldRef = (RexPatternFieldRef) i;\n+        CEPFieldRef fieldRefToAdd = CEPFieldRef.of(fieldRef);\n+        operandsList.add(fieldRefToAdd);\n+      }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4652aedd6a3c1a9914d0ffe28b5f46bbb2bae38"}, "originalPosition": 67}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM0MTg2OA==", "bodyText": "nit: no need add literal here.", "url": "https://github.com/apache/beam/pull/12232#discussion_r460341868", "createdAt": "2020-07-25T00:43:45Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/cep/CEPLiteral.java", "diffHunk": "@@ -0,0 +1,196 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.cep;\n+\n+import java.math.BigDecimal;\n+import org.apache.beam.sdk.extensions.sql.impl.SqlConversionException;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexLiteral;\n+import org.joda.time.ReadableDateTime;\n+\n+/**\n+ * {@code CEPLiteral} represents a literal node. It corresponds to {@code RexLiteral} in Calcite.\n+ */\n+public class CEPLiteral extends CEPOperation {\n+\n+  private final Schema.TypeName typeName;\n+\n+  private CEPLiteral(Schema.TypeName typeName) {\n+    this.typeName = typeName;\n+  }\n+\n+  // TODO: deal with other types (byte, short...)\n+  public static CEPLiteral of(RexLiteral lit) {\n+    switch (lit.getTypeName()) {\n+      case INTEGER:\n+        return of(lit.getValueAs(Integer.class));\n+      case BIGINT:\n+        return of(lit.getValueAs(Long.class));\n+      case DECIMAL:\n+        return of(lit.getValueAs(BigDecimal.class));\n+      case FLOAT:\n+        return of(lit.getValueAs(Float.class));\n+      case DOUBLE:\n+        return of(lit.getValueAs(Double.class));\n+      case BOOLEAN:\n+        return of(lit.getValueAs(Boolean.class));\n+      case DATE:\n+        return of(lit.getValueAs(ReadableDateTime.class));\n+      case CHAR:\n+      case VARCHAR:\n+        return of(lit.getValueAs(String.class));\n+      default:\n+        throw new SqlConversionException(\n+            \"sql literal type not supported: \" + lit.getTypeName().toString());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4652aedd6a3c1a9914d0ffe28b5f46bbb2bae38"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM0MzM3NA==", "bodyText": "This reverse seems not useful.", "url": "https://github.com/apache/beam/pull/12232#discussion_r460343374", "createdAt": "2020-07-25T00:54:12Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/cep/CEPUtil.java", "diffHunk": "@@ -0,0 +1,155 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.cep;\n+\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelFieldCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexCall;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexLiteral;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.sql.SqlKind;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.sql.SqlOperator;\n+\n+/**\n+ * Some utility methods for transforming Calcite's constructs into our own Beam constructs (for\n+ * serialization purpose).\n+ */\n+public class CEPUtil {\n+\n+  private static Quantifier getQuantifier(int start, int end, boolean isReluctant) {\n+    Quantifier quantToAdd;\n+    if (!isReluctant) {\n+      if (start == end) {\n+        quantToAdd = new Quantifier(\"{ \" + start + \" }\");\n+      } else {\n+        if (end == -1) {\n+          if (start == 0) {\n+            quantToAdd = Quantifier.ASTERISK;\n+          } else if (start == 1) {\n+            quantToAdd = Quantifier.PLUS;\n+          } else {\n+            quantToAdd = new Quantifier(\"{ \" + start + \" }\");\n+          }\n+        } else {\n+          if (start == 0 && end == 1) {\n+            quantToAdd = Quantifier.QMARK;\n+          } else if (start == -1) {\n+            quantToAdd = new Quantifier(\"{ , \" + end + \" }\");\n+          } else {\n+            quantToAdd = new Quantifier(\"{ \" + start + \" , }\");\n+          }\n+        }\n+      }\n+    } else {\n+      if (start == end) {\n+        quantToAdd = new Quantifier(\"{ \" + start + \" }?\");\n+      } else {\n+        if (end == -1) {\n+          if (start == 0) {\n+            quantToAdd = Quantifier.ASTERISK_RELUCTANT;\n+          } else if (start == 1) {\n+            quantToAdd = Quantifier.PLUS_RELUCTANT;\n+          } else {\n+            quantToAdd = new Quantifier(\"{ \" + start + \" }?\");\n+          }\n+        } else {\n+          if (start == 0 && end == 1) {\n+            quantToAdd = Quantifier.QMARK_RELUCTANT;\n+          } else if (start == -1) {\n+            quantToAdd = new Quantifier(\"{ , \" + end + \" }?\");\n+          } else {\n+            quantToAdd = new Quantifier(\"{ \" + start + \" , }?\");\n+          }\n+        }\n+      }\n+    }\n+\n+    return quantToAdd;\n+  }\n+\n+  /** Construct a list of {@code CEPPattern}s from a {@code RexNode}. */\n+  public static ArrayList<CEPPattern> getCEPPatternFromPattern(\n+      Schema upStreamSchema, RexNode call, Map<String, RexNode> patternDefs) {\n+    ArrayList<CEPPattern> patternList = new ArrayList<>();\n+    if (call.getClass() == RexLiteral.class) {\n+      String p = ((RexLiteral) call).getValueAs(String.class);\n+      RexNode pd = patternDefs.get(p);\n+      patternList.add(CEPPattern.of(upStreamSchema, p, (RexCall) pd, Quantifier.NONE));\n+    } else {\n+      RexCall patCall = (RexCall) call;\n+      SqlOperator operator = patCall.getOperator();\n+      List<RexNode> operands = patCall.getOperands();\n+\n+      // check if if the node has quantifier\n+      if (operator.getKind() == SqlKind.PATTERN_QUANTIFIER) {\n+        String p = ((RexLiteral) operands.get(0)).getValueAs(String.class);\n+        RexNode pd = patternDefs.get(p);\n+        int start = ((RexLiteral) operands.get(1)).getValueAs(Integer.class);\n+        int end = ((RexLiteral) operands.get(2)).getValueAs(Integer.class);\n+        boolean isReluctant = ((RexLiteral) operands.get(3)).getValueAs(Boolean.class);\n+\n+        patternList.add(\n+            CEPPattern.of(upStreamSchema, p, (RexCall) pd, getQuantifier(start, end, isReluctant)));\n+      } else {\n+        for (RexNode i : operands) {\n+          patternList.addAll(getCEPPatternFromPattern(upStreamSchema, i, patternDefs));\n+        }\n+      }\n+    }\n+    return patternList;\n+  }\n+\n+  /** Recursively construct a regular expression from a {@code RexNode}. */\n+  public static String getRegexFromPattern(RexNode call) {\n+    if (call.getClass() == RexLiteral.class) {\n+      return ((RexLiteral) call).getValueAs(String.class);\n+    } else {\n+      RexCall opr = (RexCall) call;\n+      SqlOperator operator = opr.getOperator();\n+      List<RexNode> operands = opr.getOperands();\n+      if (operator.getKind() == SqlKind.PATTERN_QUANTIFIER) {\n+        String p = ((RexLiteral) operands.get(0)).getValueAs(String.class);\n+        int start = ((RexLiteral) operands.get(1)).getValueAs(Integer.class);\n+        int end = ((RexLiteral) operands.get(2)).getValueAs(Integer.class);\n+        boolean isReluctant = ((RexLiteral) operands.get(3)).getValueAs(Boolean.class);\n+        Quantifier quantifier = getQuantifier(start, end, isReluctant);\n+        return p + quantifier.toString();\n+      }\n+      return getRegexFromPattern(opr.getOperands().get(0))\n+          + getRegexFromPattern(opr.getOperands().get(1));\n+    }\n+  }\n+\n+  /** Transform a list of keys in Calcite to {@code ORDER BY} to {@code OrderKey}s. */\n+  public static ArrayList<OrderKey> makeOrderKeysFromCollation(RelCollation orderKeys) {\n+    List<RelFieldCollation> revOrderKeys = orderKeys.getFieldCollations();\n+    Collections.reverse(revOrderKeys);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4652aedd6a3c1a9914d0ffe28b5f46bbb2bae38"}, "originalPosition": 146}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU5Njc0MDMx", "url": "https://github.com/apache/beam/pull/12232#pullrequestreview-459674031", "createdAt": "2020-08-02T19:47:34Z", "commit": {"oid": "f79922b3b4c1d3b2a88cea091ebb6257806b23aa"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMlQxOTo0NzozNFrOG6naow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wMlQxOTo1MDoyN1rOG6nbwg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDExNjM4Nw==", "bodyText": "You can either remove this commented test, or leave it with @ignore(\"the reason to ignore this test\").", "url": "https://github.com/apache/beam/pull/12232#discussion_r464116387", "createdAt": "2020-08-02T19:47:34Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamMatchRelTest.java", "diffHunk": "@@ -0,0 +1,234 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.rel;\n+\n+import static org.apache.beam.sdk.extensions.sql.impl.rel.BaseRelTest.compilePipeline;\n+import static org.apache.beam.sdk.extensions.sql.impl.rel.BaseRelTest.registerTable;\n+\n+import org.apache.beam.sdk.extensions.sql.TestUtils;\n+import org.apache.beam.sdk.extensions.sql.meta.provider.test.TestBoundedTable;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.testing.PAssert;\n+import org.apache.beam.sdk.testing.TestPipeline;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.Row;\n+import org.junit.Rule;\n+import org.junit.Test;\n+\n+/** Test for {@code BeamMatchRel}. */\n+public class BeamMatchRelTest {\n+\n+  @Rule public final TestPipeline pipeline = TestPipeline.create();\n+\n+  @Test\n+  public void matchLogicalPlanTest() {\n+    Schema schemaType =\n+        Schema.builder()\n+            .addInt32Field(\"id\")\n+            .addStringField(\"name\")\n+            .addInt32Field(\"proctime\")\n+            .build();\n+\n+    registerTable(\n+        \"TestTable\", TestBoundedTable.of(schemaType).addRows(1, \"a\", 1, 1, \"b\", 2, 1, \"c\", 3));\n+\n+    String sql =\n+        \"SELECT * \"\n+            + \"FROM TestTable \"\n+            + \"MATCH_RECOGNIZE (\"\n+            + \"PARTITION BY id \"\n+            + \"ORDER BY proctime \"\n+            + \"ALL ROWS PER MATCH \"\n+            + \"PATTERN (A B C) \"\n+            + \"DEFINE \"\n+            + \"A AS name = 'a', \"\n+            + \"B AS name = 'b', \"\n+            + \"C AS name = 'c' \"\n+            + \") AS T\";\n+\n+    PCollection<Row> result = compilePipeline(sql, pipeline);\n+\n+    PAssert.that(result)\n+        .containsInAnyOrder(\n+            TestUtils.RowsBuilder.of(\n+                    Schema.FieldType.INT32, \"id\",\n+                    Schema.FieldType.STRING, \"name\",\n+                    Schema.FieldType.INT32, \"proctime\")\n+                .addRows(1, \"a\", 1, 1, \"b\", 2, 1, \"c\", 3)\n+                .getRows());\n+\n+    pipeline.run().waitUntilFinish();\n+  }\n+\n+  @Test\n+  public void matchQuantifierTest() {\n+    Schema schemaType =\n+        Schema.builder()\n+            .addInt32Field(\"id\")\n+            .addStringField(\"name\")\n+            .addInt32Field(\"proctime\")\n+            .build();\n+\n+    registerTable(\n+        \"TestTable\",\n+        TestBoundedTable.of(schemaType).addRows(1, \"a\", 1, 1, \"a\", 2, 1, \"b\", 3, 1, \"c\", 4));\n+\n+    String sql =\n+        \"SELECT * \"\n+            + \"FROM TestTable \"\n+            + \"MATCH_RECOGNIZE (\"\n+            + \"PARTITION BY id \"\n+            + \"ORDER BY proctime \"\n+            + \"ALL ROWS PER MATCH \"\n+            + \"PATTERN (A+ B C) \"\n+            + \"DEFINE \"\n+            + \"A AS name = 'a', \"\n+            + \"B AS name = 'b', \"\n+            + \"C AS name = 'c' \"\n+            + \") AS T\";\n+\n+    PCollection<Row> result = compilePipeline(sql, pipeline);\n+\n+    PAssert.that(result)\n+        .containsInAnyOrder(\n+            TestUtils.RowsBuilder.of(\n+                    Schema.FieldType.INT32, \"id\",\n+                    Schema.FieldType.STRING, \"name\",\n+                    Schema.FieldType.INT32, \"proctime\")\n+                .addRows(1, \"a\", 1, 1, \"a\", 2, 1, \"b\", 3, 1, \"c\", 4)\n+                .getRows());\n+\n+    pipeline.run().waitUntilFinish();\n+  }\n+\n+  @Test\n+  public void matchMeasuresTest() {\n+    Schema schemaType =\n+        Schema.builder()\n+            .addInt32Field(\"id\")\n+            .addStringField(\"name\")\n+            .addInt32Field(\"proctime\")\n+            .build();\n+\n+    registerTable(\n+        \"TestTable\",\n+        TestBoundedTable.of(schemaType)\n+            .addRows(\n+                1, \"a\", 1, 1, \"a\", 2, 1, \"b\", 3, 1, \"c\", 4, 1, \"b\", 8, 1, \"a\", 7, 1, \"c\", 9, 2, \"a\",\n+                6, 2, \"b\", 10, 2, \"c\", 11, 5, \"a\", 0));\n+\n+    String sql =\n+        \"SELECT * \"\n+            + \"FROM TestTable \"\n+            + \"MATCH_RECOGNIZE (\"\n+            + \"PARTITION BY id \"\n+            + \"ORDER BY proctime \"\n+            + \"MEASURES \"\n+            + \"LAST (A.proctime) AS atime, \"\n+            + \"B.proctime AS btime, \"\n+            + \"C.proctime AS ctime \"\n+            + \"PATTERN (A+ B C) \"\n+            + \"DEFINE \"\n+            + \"A AS name = 'a', \"\n+            + \"B AS name = 'b', \"\n+            + \"C AS name = 'c' \"\n+            + \") AS T\";\n+\n+    PCollection<Row> result = compilePipeline(sql, pipeline);\n+\n+    PAssert.that(result)\n+        .containsInAnyOrder(\n+            TestUtils.RowsBuilder.of(\n+                    Schema.FieldType.INT32, \"id\",\n+                    Schema.FieldType.INT32, \"T.atime\",\n+                    Schema.FieldType.INT32, \"T.btime\",\n+                    Schema.FieldType.INT32, \"T.ctime\")\n+                .addRows(1, 2, 3, 4, 1, 7, 8, 9, 2, 6, 10, 11)\n+                .getRows());\n+\n+    pipeline.run().waitUntilFinish();\n+  }\n+\n+  /*", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f79922b3b4c1d3b2a88cea091ebb6257806b23aa"}, "originalPosition": 167}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDExNjY3NA==", "bodyText": "Please print the RexNode so people can see which RexNode is not supported.\n \"the RexNode is not recognized: \" + i", "url": "https://github.com/apache/beam/pull/12232#discussion_r464116674", "createdAt": "2020-08-02T19:50:27Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/cep/CEPCall.java", "diffHunk": "@@ -0,0 +1,72 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.cep;\n+\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexCall;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexLiteral;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexPatternFieldRef;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.sql.SqlOperator;\n+\n+/**\n+ * A {@code CEPCall} instance represents an operation (node) that contains an operator and a list of\n+ * operands. It has the similar functionality as Calcite's {@code RexCall}.\n+ */\n+public class CEPCall extends CEPOperation {\n+\n+  private final CEPOperator operator;\n+  private final List<CEPOperation> operands;\n+\n+  private CEPCall(CEPOperator operator, List<CEPOperation> operands) {\n+    this.operator = operator;\n+    this.operands = operands;\n+  }\n+\n+  public CEPOperator getOperator() {\n+    return operator;\n+  }\n+\n+  public List<CEPOperation> getOperands() {\n+    return operands;\n+  }\n+\n+  public static CEPCall of(RexCall operation) {\n+    SqlOperator call = operation.getOperator();\n+    CEPOperator myOp = CEPOperator.of(call);\n+\n+    ArrayList<CEPOperation> operandsList = new ArrayList<>();\n+    for (RexNode i : operation.getOperands()) {\n+      if (i.getClass() == RexCall.class) {\n+        CEPCall callToAdd = CEPCall.of((RexCall) i);\n+        operandsList.add(callToAdd);\n+      } else if (i.getClass() == RexLiteral.class) {\n+        RexLiteral lit = (RexLiteral) i;\n+        CEPLiteral litToAdd = CEPLiteral.of(lit);\n+        operandsList.add(litToAdd);\n+      } else if (i.getClass() == RexPatternFieldRef.class) {\n+        RexPatternFieldRef fieldRef = (RexPatternFieldRef) i;\n+        CEPFieldRef fieldRefToAdd = CEPFieldRef.of(fieldRef);\n+        operandsList.add(fieldRefToAdd);\n+      }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM0MTcxMQ=="}, "originalCommit": {"oid": "e4652aedd6a3c1a9914d0ffe28b5f46bbb2bae38"}, "originalPosition": 67}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4e56953a135e40bbb3415d05ec6d14bbab947927", "author": {"user": {"login": "Mark-Zeng", "name": "Qihang"}}, "url": "https://github.com/apache/beam/commit/4e56953a135e40bbb3415d05ec6d14bbab947927", "committedDate": "2020-08-03T10:40:12Z", "message": "[BEAM-9543] built the basis for Match_Recog"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "72232fcdf157ab0a09d72d57603d1f348774a116", "author": {"user": {"login": "Mark-Zeng", "name": "Qihang"}}, "url": "https://github.com/apache/beam/commit/72232fcdf157ab0a09d72d57603d1f348774a116", "committedDate": "2020-08-03T10:40:12Z", "message": "[BEAM-9543] built the basis for Match_Recog"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "064ada7257970bcb1d35530be1b88cb3830f242b", "author": {"user": {"login": "Mark-Zeng", "name": "Qihang"}}, "url": "https://github.com/apache/beam/commit/064ada7257970bcb1d35530be1b88cb3830f242b", "committedDate": "2020-08-03T10:40:12Z", "message": "[BEAM-9543] implemented `partition by`"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9cd1a82bec7b2f7c44aacfbd72f5f775bb58b650", "author": {"user": {"login": "Mark-Zeng", "name": "Qihang"}}, "url": "https://github.com/apache/beam/commit/9cd1a82bec7b2f7c44aacfbd72f5f775bb58b650", "committedDate": "2020-08-03T10:40:12Z", "message": "[BEAM-9543] implemented `order by`"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c07b8a89e6c54f699590d5b9e8242cb92de3c505", "author": {"user": {"login": "Mark-Zeng", "name": "Qihang"}}, "url": "https://github.com/apache/beam/commit/c07b8a89e6c54f699590d5b9e8242cb92de3c505", "committedDate": "2020-08-03T10:40:12Z", "message": "[BEAM-9543] fixed `order by` coder issue"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cdb7e9f120a21506a800f6f6840fb315c4b6524b", "author": {"user": {"login": "Mark-Zeng", "name": "Qihang"}}, "url": "https://github.com/apache/beam/commit/cdb7e9f120a21506a800f6f6840fb315c4b6524b", "committedDate": "2020-08-03T10:40:12Z", "message": "[BEAM-9543] fixed `order by` coder issue"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cc63e557faf36656c330f305b3924016fdad2151", "author": {"user": {"login": "Mark-Zeng", "name": "Qihang"}}, "url": "https://github.com/apache/beam/commit/cc63e557faf36656c330f305b3924016fdad2151", "committedDate": "2020-08-03T10:40:12Z", "message": "[BEAM-9543] applied regex pattern match"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b2b189dfdea88baf34849a17b203058f29212b00", "author": {"user": {"login": "Mark-Zeng", "name": "Qihang"}}, "url": "https://github.com/apache/beam/commit/b2b189dfdea88baf34849a17b203058f29212b00", "committedDate": "2020-08-03T10:40:12Z", "message": "[BEAM-9543] applied regex pattern match"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "08abbab35e1ee71fe3c9b2b92aa049b945a92763", "author": {"user": {"login": "Mark-Zeng", "name": "Qihang"}}, "url": "https://github.com/apache/beam/commit/08abbab35e1ee71fe3c9b2b92aa049b945a92763", "committedDate": "2020-08-03T10:40:12Z", "message": "[BEAM-9543] fixed sortKey serialization problem"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "03a33c6ea20b4bde3541d3acba742903cc03b24e", "author": {"user": {"login": "Mark-Zeng", "name": "Qihang"}}, "url": "https://github.com/apache/beam/commit/03a33c6ea20b4bde3541d3acba742903cc03b24e", "committedDate": "2020-08-03T10:40:12Z", "message": "[BEAM-9543] fixed sortKey serialization problem"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ec7c929c340ba38615145908249be24778ffc436", "author": {"user": {"login": "Mark-Zeng", "name": "Qihang"}}, "url": "https://github.com/apache/beam/commit/ec7c929c340ba38615145908249be24778ffc436", "committedDate": "2020-08-03T10:40:12Z", "message": "[BEAM-9543] fixed serialization problem"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f52d96fc33382fc9e46d3249a2600e2af9f67326", "author": {"user": {"login": "Mark-Zeng", "name": "Qihang"}}, "url": "https://github.com/apache/beam/commit/f52d96fc33382fc9e46d3249a2600e2af9f67326", "committedDate": "2020-08-03T10:40:12Z", "message": "[BEAM-9543] recognized simple pattern"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8d6ffcc213e30999fc495c119b68da4f62fad258", "author": {"user": {"login": "Mark-Zeng", "name": "Qihang"}}, "url": "https://github.com/apache/beam/commit/8d6ffcc213e30999fc495c119b68da4f62fad258", "committedDate": "2020-08-03T10:40:12Z", "message": "[BEAM-9543] recognized simple pattern"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a7d111f896f5f8e14f6211d01811a618b905ec32", "author": {"user": {"login": "Mark-Zeng", "name": "Qihang"}}, "url": "https://github.com/apache/beam/commit/a7d111f896f5f8e14f6211d01811a618b905ec32", "committedDate": "2020-08-03T10:40:12Z", "message": "[BEAM-9543] fixed code style"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f529b876a2c2e43d012c71b3a83ebd55eb16f4ff", "author": {"user": {"login": "Mark-Zeng", "name": "Qihang"}}, "url": "https://github.com/apache/beam/commit/f529b876a2c2e43d012c71b3a83ebd55eb16f4ff", "committedDate": "2020-08-03T10:40:12Z", "message": "[BEAM-9543] supported regex quantifier"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0bf24db5e75c0db715c6954b11afac357c49d7f6", "author": {"user": {"login": "Mark-Zeng", "name": "Qihang"}}, "url": "https://github.com/apache/beam/commit/0bf24db5e75c0db715c6954b11afac357c49d7f6", "committedDate": "2020-08-03T10:40:12Z", "message": "[BEAM-9543] added javadoc"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "422cbe2b87a6f69b8efda0f6ec88baa973bd26c4", "author": {"user": {"login": "Mark-Zeng", "name": "Qihang"}}, "url": "https://github.com/apache/beam/commit/422cbe2b87a6f69b8efda0f6ec88baa973bd26c4", "committedDate": "2020-08-03T10:40:12Z", "message": "[BEAM-9543] removed CEPTypeName.java"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "adc2354752ef48237020f3fa84d00ab65c2ead74", "author": {"user": {"login": "Mark-Zeng", "name": "Qihang"}}, "url": "https://github.com/apache/beam/commit/adc2354752ef48237020f3fa84d00ab65c2ead74", "committedDate": "2020-08-03T10:40:12Z", "message": "[BEAM-9543] added Measures implementation (unfinished)"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ebc41a263dc07b305c190f0ded1ec86e90099ee7", "author": {"user": {"login": "Mark-Zeng", "name": "Qihang"}}, "url": "https://github.com/apache/beam/commit/ebc41a263dc07b305c190f0ded1ec86e90099ee7", "committedDate": "2020-08-03T10:40:13Z", "message": "[BEAM-9543] added Measures implementation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "87935746647611aa139d664ebed10c8e638bb024", "author": {"user": {"login": "Mark-Zeng", "name": "Qihang"}}, "url": "https://github.com/apache/beam/commit/87935746647611aa139d664ebed10c8e638bb024", "committedDate": "2020-08-03T10:40:13Z", "message": "[BEAM-9543] added Measures implementation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "040d1f41db568a00b1fef898bddfa690be21015e", "author": {"user": {"login": "Mark-Zeng", "name": "Qihang"}}, "url": "https://github.com/apache/beam/commit/040d1f41db568a00b1fef898bddfa690be21015e", "committedDate": "2020-08-03T10:40:13Z", "message": "[BEAM-9543] fixed minor issues"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "799491bbe96fdcefd6ca1cc0f974c202159c8a91", "author": {"user": {"login": "Mark-Zeng", "name": "Qihang"}}, "url": "https://github.com/apache/beam/commit/799491bbe96fdcefd6ca1cc0f974c202159c8a91", "committedDate": "2020-08-03T10:40:13Z", "message": "[BEAM-9543] fixed minor style issues"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f79922b3b4c1d3b2a88cea091ebb6257806b23aa", "author": {"user": {"login": "Mark-Zeng", "name": "Qihang"}}, "url": "https://github.com/apache/beam/commit/f79922b3b4c1d3b2a88cea091ebb6257806b23aa", "committedDate": "2020-08-01T14:31:15Z", "message": "[BEAM-9543] fixed minor issues"}, "afterCommit": {"oid": "799491bbe96fdcefd6ca1cc0f974c202159c8a91", "author": {"user": {"login": "Mark-Zeng", "name": "Qihang"}}, "url": "https://github.com/apache/beam/commit/799491bbe96fdcefd6ca1cc0f974c202159c8a91", "committedDate": "2020-08-03T10:40:13Z", "message": "[BEAM-9543] fixed minor style issues"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDYwMjA4MjY4", "url": "https://github.com/apache/beam/pull/12232#pullrequestreview-460208268", "createdAt": "2020-08-03T17:28:37Z", "commit": {"oid": "799491bbe96fdcefd6ca1cc0f974c202159c8a91"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4061, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}