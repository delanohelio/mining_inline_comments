{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTA4NzExNjk4", "number": 13175, "reviewThreads": {"totalCount": 17, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxODo1NjoxNlrOEy9RIQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yN1QyMTozNToyNVrOFTyMyw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxODY4MDY1OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/transforms/stats.py", "isResolved": true, "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxODo1NjoxNlrOHp5ChA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0xMlQwMzoyNjozM1rOIkVYAw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY4ODE5Ng==", "bodyText": "Are there downsides to just making this a dependency?", "url": "https://github.com/apache/beam/pull/13175#discussion_r513688196", "createdAt": "2020-10-28T18:56:16Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -61,30 +58,34 @@\n K = typing.TypeVar('K')\n V = typing.TypeVar('V')\n \n+try:\n+  import mmh3  # pylint: disable=import-error\n \n-def _get_default_hash_fn():\n-  \"\"\"Returns either murmurhash or md5 based on installation.\"\"\"\n-  try:\n-    import mmh3  # pylint: disable=import-error\n+  def _mmh3_hash(value):\n+    # mmh3.hash64 returns two 64-bit unsigned integers\n+    return mmh3.hash64(value, seed=0, signed=False)[0]\n+\n+  _default_hash_fn = _mmh3_hash\n+  _default_hash_fn_type = 'mmh3'\n+except ImportError:\n \n-    def _mmh3_hash(value):\n-      # mmh3.hash64 returns two 64-bit unsigned integers\n-      return mmh3.hash64(value, seed=0, signed=False)[0]\n+  def _md5_hash(value):\n+    # md5 is a 128-bit hash, so we truncate the hexdigest (string of 32\n+    # hexadecimal digits) to 16 digits and convert to int to get the 64-bit\n+    # integer fingerprint.\n+    return int(hashlib.md5(value).hexdigest()[:16], 16)\n \n-    return _mmh3_hash\n+  _default_hash_fn = _md5_hash\n+  _default_hash_fn_type = 'md5'\n \n-  except ImportError:\n+\n+def _get_default_hash_fn():\n+  \"\"\"Returns either murmurhash or md5 based on installation.\"\"\"\n+  if _default_hash_fn_type == 'md5':\n     logging.warning(\n         'Couldn\\'t find murmurhash. Install mmh3 for a faster implementation of'", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDM2Mzk5NQ==", "bodyText": "Not sure if it's still maintained, last release happened 3 years ago. I'm not aware of any other downsides, wdyt?\nhttps://github.com/hajimes/mmh3", "url": "https://github.com/apache/beam/pull/13175#discussion_r514363995", "createdAt": "2020-10-29T15:45:37Z", "author": {"login": "iindyk"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -61,30 +58,34 @@\n K = typing.TypeVar('K')\n V = typing.TypeVar('V')\n \n+try:\n+  import mmh3  # pylint: disable=import-error\n \n-def _get_default_hash_fn():\n-  \"\"\"Returns either murmurhash or md5 based on installation.\"\"\"\n-  try:\n-    import mmh3  # pylint: disable=import-error\n+  def _mmh3_hash(value):\n+    # mmh3.hash64 returns two 64-bit unsigned integers\n+    return mmh3.hash64(value, seed=0, signed=False)[0]\n+\n+  _default_hash_fn = _mmh3_hash\n+  _default_hash_fn_type = 'mmh3'\n+except ImportError:\n \n-    def _mmh3_hash(value):\n-      # mmh3.hash64 returns two 64-bit unsigned integers\n-      return mmh3.hash64(value, seed=0, signed=False)[0]\n+  def _md5_hash(value):\n+    # md5 is a 128-bit hash, so we truncate the hexdigest (string of 32\n+    # hexadecimal digits) to 16 digits and convert to int to get the 64-bit\n+    # integer fingerprint.\n+    return int(hashlib.md5(value).hexdigest()[:16], 16)\n \n-    return _mmh3_hash\n+  _default_hash_fn = _md5_hash\n+  _default_hash_fn_type = 'md5'\n \n-  except ImportError:\n+\n+def _get_default_hash_fn():\n+  \"\"\"Returns either murmurhash or md5 based on installation.\"\"\"\n+  if _default_hash_fn_type == 'md5':\n     logging.warning(\n         'Couldn\\'t find murmurhash. Install mmh3 for a faster implementation of'", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY4ODE5Ng=="}, "originalCommit": {"oid": "2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDg2MTM3MQ==", "bodyText": "One downside is that mmh3 has only source release, and does not release wheel files. Installing mmh3 requires certain c++ compiler/headers dependencies be present on the machine. It appears that the project is no longer maintained. I tried to contact the maintainer and did not receive a response... Note that sklearn has also implemented a python wrapper for murmurhash: https://scikit-learn.org/stable/modules/generated/sklearn.utils.murmurhash3_32.html. We could likewise incorporate murmurhash into Beam codebase, make a (maintainable) fork of mmh3 and release wheel files, use sklearn's implementation, or try to explore a different library for our hashing needs.", "url": "https://github.com/apache/beam/pull/13175#discussion_r564861371", "createdAt": "2021-01-26T21:57:14Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -61,30 +58,34 @@\n K = typing.TypeVar('K')\n V = typing.TypeVar('V')\n \n+try:\n+  import mmh3  # pylint: disable=import-error\n \n-def _get_default_hash_fn():\n-  \"\"\"Returns either murmurhash or md5 based on installation.\"\"\"\n-  try:\n-    import mmh3  # pylint: disable=import-error\n+  def _mmh3_hash(value):\n+    # mmh3.hash64 returns two 64-bit unsigned integers\n+    return mmh3.hash64(value, seed=0, signed=False)[0]\n+\n+  _default_hash_fn = _mmh3_hash\n+  _default_hash_fn_type = 'mmh3'\n+except ImportError:\n \n-    def _mmh3_hash(value):\n-      # mmh3.hash64 returns two 64-bit unsigned integers\n-      return mmh3.hash64(value, seed=0, signed=False)[0]\n+  def _md5_hash(value):\n+    # md5 is a 128-bit hash, so we truncate the hexdigest (string of 32\n+    # hexadecimal digits) to 16 digits and convert to int to get the 64-bit\n+    # integer fingerprint.\n+    return int(hashlib.md5(value).hexdigest()[:16], 16)\n \n-    return _mmh3_hash\n+  _default_hash_fn = _md5_hash\n+  _default_hash_fn_type = 'md5'\n \n-  except ImportError:\n+\n+def _get_default_hash_fn():\n+  \"\"\"Returns either murmurhash or md5 based on installation.\"\"\"\n+  if _default_hash_fn_type == 'md5':\n     logging.warning(\n         'Couldn\\'t find murmurhash. Install mmh3 for a faster implementation of'", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY4ODE5Ng=="}, "originalCommit": {"oid": "2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDg2MzE2MA==", "bodyText": "Looks like there is already a binary version: https://pypi.org/project/mmh3-binary/, with a somewhat recent release (Apr 2020, but only 3.6 wheels: https://pypi.org/project/mmh3-binary/#files).", "url": "https://github.com/apache/beam/pull/13175#discussion_r564863160", "createdAt": "2021-01-26T22:00:07Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -61,30 +58,34 @@\n K = typing.TypeVar('K')\n V = typing.TypeVar('V')\n \n+try:\n+  import mmh3  # pylint: disable=import-error\n \n-def _get_default_hash_fn():\n-  \"\"\"Returns either murmurhash or md5 based on installation.\"\"\"\n-  try:\n-    import mmh3  # pylint: disable=import-error\n+  def _mmh3_hash(value):\n+    # mmh3.hash64 returns two 64-bit unsigned integers\n+    return mmh3.hash64(value, seed=0, signed=False)[0]\n+\n+  _default_hash_fn = _mmh3_hash\n+  _default_hash_fn_type = 'mmh3'\n+except ImportError:\n \n-    def _mmh3_hash(value):\n-      # mmh3.hash64 returns two 64-bit unsigned integers\n-      return mmh3.hash64(value, seed=0, signed=False)[0]\n+  def _md5_hash(value):\n+    # md5 is a 128-bit hash, so we truncate the hexdigest (string of 32\n+    # hexadecimal digits) to 16 digits and convert to int to get the 64-bit\n+    # integer fingerprint.\n+    return int(hashlib.md5(value).hexdigest()[:16], 16)\n \n-    return _mmh3_hash\n+  _default_hash_fn = _md5_hash\n+  _default_hash_fn_type = 'md5'\n \n-  except ImportError:\n+\n+def _get_default_hash_fn():\n+  \"\"\"Returns either murmurhash or md5 based on installation.\"\"\"\n+  if _default_hash_fn_type == 'md5':\n     logging.warning(\n         'Couldn\\'t find murmurhash. Install mmh3 for a faster implementation of'", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY4ODE5Ng=="}, "originalCommit": {"oid": "2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDcyMDM0Mw==", "bodyText": "Should I make it a dependency then?", "url": "https://github.com/apache/beam/pull/13175#discussion_r570720343", "createdAt": "2021-02-05T04:55:43Z", "author": {"login": "iindyk"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -61,30 +58,34 @@\n K = typing.TypeVar('K')\n V = typing.TypeVar('V')\n \n+try:\n+  import mmh3  # pylint: disable=import-error\n \n-def _get_default_hash_fn():\n-  \"\"\"Returns either murmurhash or md5 based on installation.\"\"\"\n-  try:\n-    import mmh3  # pylint: disable=import-error\n+  def _mmh3_hash(value):\n+    # mmh3.hash64 returns two 64-bit unsigned integers\n+    return mmh3.hash64(value, seed=0, signed=False)[0]\n+\n+  _default_hash_fn = _mmh3_hash\n+  _default_hash_fn_type = 'mmh3'\n+except ImportError:\n \n-    def _mmh3_hash(value):\n-      # mmh3.hash64 returns two 64-bit unsigned integers\n-      return mmh3.hash64(value, seed=0, signed=False)[0]\n+  def _md5_hash(value):\n+    # md5 is a 128-bit hash, so we truncate the hexdigest (string of 32\n+    # hexadecimal digits) to 16 digits and convert to int to get the 64-bit\n+    # integer fingerprint.\n+    return int(hashlib.md5(value).hexdigest()[:16], 16)\n \n-    return _mmh3_hash\n+  _default_hash_fn = _md5_hash\n+  _default_hash_fn_type = 'md5'\n \n-  except ImportError:\n+\n+def _get_default_hash_fn():\n+  \"\"\"Returns either murmurhash or md5 based on installation.\"\"\"\n+  if _default_hash_fn_type == 'md5':\n     logging.warning(\n         'Couldn\\'t find murmurhash. Install mmh3 for a faster implementation of'", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY4ODE5Ng=="}, "originalCommit": {"oid": "2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3NDE3NTgyNQ==", "bodyText": "I wouldn't make it a dependency until it releases wheels.", "url": "https://github.com/apache/beam/pull/13175#discussion_r574175825", "createdAt": "2021-02-11T00:12:00Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -61,30 +58,34 @@\n K = typing.TypeVar('K')\n V = typing.TypeVar('V')\n \n+try:\n+  import mmh3  # pylint: disable=import-error\n \n-def _get_default_hash_fn():\n-  \"\"\"Returns either murmurhash or md5 based on installation.\"\"\"\n-  try:\n-    import mmh3  # pylint: disable=import-error\n+  def _mmh3_hash(value):\n+    # mmh3.hash64 returns two 64-bit unsigned integers\n+    return mmh3.hash64(value, seed=0, signed=False)[0]\n+\n+  _default_hash_fn = _mmh3_hash\n+  _default_hash_fn_type = 'mmh3'\n+except ImportError:\n \n-    def _mmh3_hash(value):\n-      # mmh3.hash64 returns two 64-bit unsigned integers\n-      return mmh3.hash64(value, seed=0, signed=False)[0]\n+  def _md5_hash(value):\n+    # md5 is a 128-bit hash, so we truncate the hexdigest (string of 32\n+    # hexadecimal digits) to 16 digits and convert to int to get the 64-bit\n+    # integer fingerprint.\n+    return int(hashlib.md5(value).hexdigest()[:16], 16)\n \n-    return _mmh3_hash\n+  _default_hash_fn = _md5_hash\n+  _default_hash_fn_type = 'md5'\n \n-  except ImportError:\n+\n+def _get_default_hash_fn():\n+  \"\"\"Returns either murmurhash or md5 based on installation.\"\"\"\n+  if _default_hash_fn_type == 'md5':\n     logging.warning(\n         'Couldn\\'t find murmurhash. Install mmh3 for a faster implementation of'", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY4ODE5Ng=="}, "originalCommit": {"oid": "2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3NDk2OTg1OQ==", "bodyText": "sg", "url": "https://github.com/apache/beam/pull/13175#discussion_r574969859", "createdAt": "2021-02-12T03:26:33Z", "author": {"login": "iindyk"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -61,30 +58,34 @@\n K = typing.TypeVar('K')\n V = typing.TypeVar('V')\n \n+try:\n+  import mmh3  # pylint: disable=import-error\n \n-def _get_default_hash_fn():\n-  \"\"\"Returns either murmurhash or md5 based on installation.\"\"\"\n-  try:\n-    import mmh3  # pylint: disable=import-error\n+  def _mmh3_hash(value):\n+    # mmh3.hash64 returns two 64-bit unsigned integers\n+    return mmh3.hash64(value, seed=0, signed=False)[0]\n+\n+  _default_hash_fn = _mmh3_hash\n+  _default_hash_fn_type = 'mmh3'\n+except ImportError:\n \n-    def _mmh3_hash(value):\n-      # mmh3.hash64 returns two 64-bit unsigned integers\n-      return mmh3.hash64(value, seed=0, signed=False)[0]\n+  def _md5_hash(value):\n+    # md5 is a 128-bit hash, so we truncate the hexdigest (string of 32\n+    # hexadecimal digits) to 16 digits and convert to int to get the 64-bit\n+    # integer fingerprint.\n+    return int(hashlib.md5(value).hexdigest()[:16], 16)\n \n-    return _mmh3_hash\n+  _default_hash_fn = _md5_hash\n+  _default_hash_fn_type = 'md5'\n \n-  except ImportError:\n+\n+def _get_default_hash_fn():\n+  \"\"\"Returns either murmurhash or md5 based on installation.\"\"\"\n+  if _default_hash_fn_type == 'md5':\n     logging.warning(\n         'Couldn\\'t find murmurhash. Install mmh3 for a faster implementation of'", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY4ODE5Ng=="}, "originalCommit": {"oid": "2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671"}, "originalPosition": 54}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxODY5MDMwOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/transforms/stats.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxODo1ODo1OVrOHp5IxA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOVQxNTo0NTo0M1rOHqiStg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY4OTc5Ng==", "bodyText": "Nit: it'd be easier to read if reverse and key is None rather than having the extra negation in there.", "url": "https://github.com/apache/beam/pull/13175#discussion_r513689796", "createdAt": "2020-10-28T18:58:59Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -368,82 +383,129 @@ class PerKey(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate\n+        multiple elements at a time more efficiently.\n     \"\"\"\n-    def __init__(self, num_quantiles, key=None, reverse=False, weighted=False):\n+    def __init__(\n+        self,\n+        num_quantiles,\n+        key=None,\n+        reverse=False,\n+        weighted=False,\n+        batch_input=False):\n       self._num_quantiles = num_quantiles\n       self._key = key\n       self._reverse = reverse\n       self._weighted = weighted\n+      self._batch_input = batch_input\n \n     def expand(self, pcoll):\n       return pcoll | CombinePerKey(\n           ApproximateQuantilesCombineFn.create(\n               num_quantiles=self._num_quantiles,\n               key=self._key,\n               reverse=self._reverse,\n-              weighted=self._weighted))\n+              weighted=self._weighted,\n+              batch_input=self._batch_input))\n \n     def display_data(self):\n       return ApproximateQuantiles._display_data(\n           num_quantiles=self._num_quantiles,\n           key=self._key,\n           reverse=self._reverse,\n-          weighted=self._weighted)\n+          weighted=self._weighted,\n+          batch_input=self._batch_input)\n+\n+\n+class _QuantileSpec(object):\n+  \"\"\"Quantiles computation specifications.\"\"\"\n+  def __init__(self, buffer_size, num_buffers, weighted, key, reverse):\n+    # type: (int, int, bool, Any, bool) -> None\n+    self.buffer_size = buffer_size\n+    self.num_buffers = num_buffers\n+    self.weighted = weighted\n+    self.key = key\n+    self.reverse = reverse\n+\n+    # Used to sort tuples of values and weights.\n+    self.weighted_key = None if key is None else (lambda x: key(x[0]))\n+\n+    # Used to compare values.\n+    if key is None and not reverse:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671"}, "originalPosition": 187}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDM2NDA4Ng==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/13175#discussion_r514364086", "createdAt": "2020-10-29T15:45:43Z", "author": {"login": "iindyk"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -368,82 +383,129 @@ class PerKey(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate\n+        multiple elements at a time more efficiently.\n     \"\"\"\n-    def __init__(self, num_quantiles, key=None, reverse=False, weighted=False):\n+    def __init__(\n+        self,\n+        num_quantiles,\n+        key=None,\n+        reverse=False,\n+        weighted=False,\n+        batch_input=False):\n       self._num_quantiles = num_quantiles\n       self._key = key\n       self._reverse = reverse\n       self._weighted = weighted\n+      self._batch_input = batch_input\n \n     def expand(self, pcoll):\n       return pcoll | CombinePerKey(\n           ApproximateQuantilesCombineFn.create(\n               num_quantiles=self._num_quantiles,\n               key=self._key,\n               reverse=self._reverse,\n-              weighted=self._weighted))\n+              weighted=self._weighted,\n+              batch_input=self._batch_input))\n \n     def display_data(self):\n       return ApproximateQuantiles._display_data(\n           num_quantiles=self._num_quantiles,\n           key=self._key,\n           reverse=self._reverse,\n-          weighted=self._weighted)\n+          weighted=self._weighted,\n+          batch_input=self._batch_input)\n+\n+\n+class _QuantileSpec(object):\n+  \"\"\"Quantiles computation specifications.\"\"\"\n+  def __init__(self, buffer_size, num_buffers, weighted, key, reverse):\n+    # type: (int, int, bool, Any, bool) -> None\n+    self.buffer_size = buffer_size\n+    self.num_buffers = num_buffers\n+    self.weighted = weighted\n+    self.key = key\n+    self.reverse = reverse\n+\n+    # Used to sort tuples of values and weights.\n+    self.weighted_key = None if key is None else (lambda x: key(x[0]))\n+\n+    # Used to compare values.\n+    if key is None and not reverse:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY4OTc5Ng=="}, "originalCommit": {"oid": "2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671"}, "originalPosition": 187}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxODY5NDEzOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/transforms/stats.py", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxOTowMDowMFrOHp5LDw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQwMDo1ODo1OFrOHw1uhQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY5MDM4Mw==", "bodyText": "I'm curious if it's faster to always have weights (by default 1) than introducing this indirection everywhere.", "url": "https://github.com/apache/beam/pull/13175#discussion_r513690383", "createdAt": "2020-10-28T19:00:00Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -368,82 +383,129 @@ class PerKey(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate\n+        multiple elements at a time more efficiently.\n     \"\"\"\n-    def __init__(self, num_quantiles, key=None, reverse=False, weighted=False):\n+    def __init__(\n+        self,\n+        num_quantiles,\n+        key=None,\n+        reverse=False,\n+        weighted=False,\n+        batch_input=False):\n       self._num_quantiles = num_quantiles\n       self._key = key\n       self._reverse = reverse\n       self._weighted = weighted\n+      self._batch_input = batch_input\n \n     def expand(self, pcoll):\n       return pcoll | CombinePerKey(\n           ApproximateQuantilesCombineFn.create(\n               num_quantiles=self._num_quantiles,\n               key=self._key,\n               reverse=self._reverse,\n-              weighted=self._weighted))\n+              weighted=self._weighted,\n+              batch_input=self._batch_input))\n \n     def display_data(self):\n       return ApproximateQuantiles._display_data(\n           num_quantiles=self._num_quantiles,\n           key=self._key,\n           reverse=self._reverse,\n-          weighted=self._weighted)\n+          weighted=self._weighted,\n+          batch_input=self._batch_input)\n+\n+\n+class _QuantileSpec(object):\n+  \"\"\"Quantiles computation specifications.\"\"\"\n+  def __init__(self, buffer_size, num_buffers, weighted, key, reverse):\n+    # type: (int, int, bool, Any, bool) -> None\n+    self.buffer_size = buffer_size\n+    self.num_buffers = num_buffers\n+    self.weighted = weighted\n+    self.key = key\n+    self.reverse = reverse\n+\n+    # Used to sort tuples of values and weights.\n+    self.weighted_key = None if key is None else (lambda x: key(x[0]))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671"}, "originalPosition": 184}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDM2NDE4OA==", "bodyText": "It's not, unfortunately. It's about 30% slower in add_input (for batched inputs) and slightly more than that in merge_accumulators.", "url": "https://github.com/apache/beam/pull/13175#discussion_r514364188", "createdAt": "2020-10-29T15:45:51Z", "author": {"login": "iindyk"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -368,82 +383,129 @@ class PerKey(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate\n+        multiple elements at a time more efficiently.\n     \"\"\"\n-    def __init__(self, num_quantiles, key=None, reverse=False, weighted=False):\n+    def __init__(\n+        self,\n+        num_quantiles,\n+        key=None,\n+        reverse=False,\n+        weighted=False,\n+        batch_input=False):\n       self._num_quantiles = num_quantiles\n       self._key = key\n       self._reverse = reverse\n       self._weighted = weighted\n+      self._batch_input = batch_input\n \n     def expand(self, pcoll):\n       return pcoll | CombinePerKey(\n           ApproximateQuantilesCombineFn.create(\n               num_quantiles=self._num_quantiles,\n               key=self._key,\n               reverse=self._reverse,\n-              weighted=self._weighted))\n+              weighted=self._weighted,\n+              batch_input=self._batch_input))\n \n     def display_data(self):\n       return ApproximateQuantiles._display_data(\n           num_quantiles=self._num_quantiles,\n           key=self._key,\n           reverse=self._reverse,\n-          weighted=self._weighted)\n+          weighted=self._weighted,\n+          batch_input=self._batch_input)\n+\n+\n+class _QuantileSpec(object):\n+  \"\"\"Quantiles computation specifications.\"\"\"\n+  def __init__(self, buffer_size, num_buffers, weighted, key, reverse):\n+    # type: (int, int, bool, Any, bool) -> None\n+    self.buffer_size = buffer_size\n+    self.num_buffers = num_buffers\n+    self.weighted = weighted\n+    self.key = key\n+    self.reverse = reverse\n+\n+    # Used to sort tuples of values and weights.\n+    self.weighted_key = None if key is None else (lambda x: key(x[0]))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY5MDM4Mw=="}, "originalCommit": {"oid": "2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671"}, "originalPosition": 184}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDM2NTkyOQ==", "bodyText": "And would also increase memory usage by elements_in_buffers * weight_type_size, which may be significant relative to the current memory usage.", "url": "https://github.com/apache/beam/pull/13175#discussion_r514365929", "createdAt": "2020-10-29T15:48:06Z", "author": {"login": "iindyk"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -368,82 +383,129 @@ class PerKey(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate\n+        multiple elements at a time more efficiently.\n     \"\"\"\n-    def __init__(self, num_quantiles, key=None, reverse=False, weighted=False):\n+    def __init__(\n+        self,\n+        num_quantiles,\n+        key=None,\n+        reverse=False,\n+        weighted=False,\n+        batch_input=False):\n       self._num_quantiles = num_quantiles\n       self._key = key\n       self._reverse = reverse\n       self._weighted = weighted\n+      self._batch_input = batch_input\n \n     def expand(self, pcoll):\n       return pcoll | CombinePerKey(\n           ApproximateQuantilesCombineFn.create(\n               num_quantiles=self._num_quantiles,\n               key=self._key,\n               reverse=self._reverse,\n-              weighted=self._weighted))\n+              weighted=self._weighted,\n+              batch_input=self._batch_input))\n \n     def display_data(self):\n       return ApproximateQuantiles._display_data(\n           num_quantiles=self._num_quantiles,\n           key=self._key,\n           reverse=self._reverse,\n-          weighted=self._weighted)\n+          weighted=self._weighted,\n+          batch_input=self._batch_input)\n+\n+\n+class _QuantileSpec(object):\n+  \"\"\"Quantiles computation specifications.\"\"\"\n+  def __init__(self, buffer_size, num_buffers, weighted, key, reverse):\n+    # type: (int, int, bool, Any, bool) -> None\n+    self.buffer_size = buffer_size\n+    self.num_buffers = num_buffers\n+    self.weighted = weighted\n+    self.key = key\n+    self.reverse = reverse\n+\n+    # Used to sort tuples of values and weights.\n+    self.weighted_key = None if key is None else (lambda x: key(x[0]))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY5MDM4Mw=="}, "originalCommit": {"oid": "2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671"}, "originalPosition": 184}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDk3Mzk1Nw==", "bodyText": "Ah, OK. Thanks for the info.", "url": "https://github.com/apache/beam/pull/13175#discussion_r520973957", "createdAt": "2020-11-11T00:58:58Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -368,82 +383,129 @@ class PerKey(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate\n+        multiple elements at a time more efficiently.\n     \"\"\"\n-    def __init__(self, num_quantiles, key=None, reverse=False, weighted=False):\n+    def __init__(\n+        self,\n+        num_quantiles,\n+        key=None,\n+        reverse=False,\n+        weighted=False,\n+        batch_input=False):\n       self._num_quantiles = num_quantiles\n       self._key = key\n       self._reverse = reverse\n       self._weighted = weighted\n+      self._batch_input = batch_input\n \n     def expand(self, pcoll):\n       return pcoll | CombinePerKey(\n           ApproximateQuantilesCombineFn.create(\n               num_quantiles=self._num_quantiles,\n               key=self._key,\n               reverse=self._reverse,\n-              weighted=self._weighted))\n+              weighted=self._weighted,\n+              batch_input=self._batch_input))\n \n     def display_data(self):\n       return ApproximateQuantiles._display_data(\n           num_quantiles=self._num_quantiles,\n           key=self._key,\n           reverse=self._reverse,\n-          weighted=self._weighted)\n+          weighted=self._weighted,\n+          batch_input=self._batch_input)\n+\n+\n+class _QuantileSpec(object):\n+  \"\"\"Quantiles computation specifications.\"\"\"\n+  def __init__(self, buffer_size, num_buffers, weighted, key, reverse):\n+    # type: (int, int, bool, Any, bool) -> None\n+    self.buffer_size = buffer_size\n+    self.num_buffers = num_buffers\n+    self.weighted = weighted\n+    self.key = key\n+    self.reverse = reverse\n+\n+    # Used to sort tuples of values and weights.\n+    self.weighted_key = None if key is None else (lambda x: key(x[0]))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY5MDM4Mw=="}, "originalCommit": {"oid": "2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671"}, "originalPosition": 184}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxODY5NzIyOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/transforms/stats.py", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxOTowMDo1MFrOHp5M9w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQxNTozMDoxM1rOHxSGrw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY5MDg3MQ==", "bodyText": "Can we doubly inherit to keep the type checking?", "url": "https://github.com/apache/beam/pull/13175#discussion_r513690871", "createdAt": "2020-10-28T19:00:50Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -368,82 +383,129 @@ class PerKey(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate\n+        multiple elements at a time more efficiently.\n     \"\"\"\n-    def __init__(self, num_quantiles, key=None, reverse=False, weighted=False):\n+    def __init__(\n+        self,\n+        num_quantiles,\n+        key=None,\n+        reverse=False,\n+        weighted=False,\n+        batch_input=False):\n       self._num_quantiles = num_quantiles\n       self._key = key\n       self._reverse = reverse\n       self._weighted = weighted\n+      self._batch_input = batch_input\n \n     def expand(self, pcoll):\n       return pcoll | CombinePerKey(\n           ApproximateQuantilesCombineFn.create(\n               num_quantiles=self._num_quantiles,\n               key=self._key,\n               reverse=self._reverse,\n-              weighted=self._weighted))\n+              weighted=self._weighted,\n+              batch_input=self._batch_input))\n \n     def display_data(self):\n       return ApproximateQuantiles._display_data(\n           num_quantiles=self._num_quantiles,\n           key=self._key,\n           reverse=self._reverse,\n-          weighted=self._weighted)\n+          weighted=self._weighted,\n+          batch_input=self._batch_input)\n+\n+\n+class _QuantileSpec(object):\n+  \"\"\"Quantiles computation specifications.\"\"\"\n+  def __init__(self, buffer_size, num_buffers, weighted, key, reverse):\n+    # type: (int, int, bool, Any, bool) -> None\n+    self.buffer_size = buffer_size\n+    self.num_buffers = num_buffers\n+    self.weighted = weighted\n+    self.key = key\n+    self.reverse = reverse\n+\n+    # Used to sort tuples of values and weights.\n+    self.weighted_key = None if key is None else (lambda x: key(x[0]))\n+\n+    # Used to compare values.\n+    if key is None and not reverse:\n+      self.less_than = lambda a, b: a < b\n+    elif key is None:\n+      self.less_than = lambda a, b: a > b\n+    elif not reverse:\n+      self.less_than = lambda a, b: key(a) < key(b)\n+    else:\n+      self.less_than = lambda a, b: key(a) > key(b)\n+\n+  def get_argsort_key(self, elements):\n+    # type: (List) -> Any\n+\n+    \"\"\"Returns a key for sorting indices of elements by element's value.\"\"\"\n+    if self.key is None:\n+      return elements.__getitem__\n+    else:\n+      return lambda idx: self.key(elements[idx])\n+\n+  def __reduce__(self):\n+    return (\n+        self.__class__,\n+        (\n+            self.buffer_size,\n+            self.num_buffers,\n+            self.weighted,\n+            self.key,\n+            self.reverse))\n \n \n-class _QuantileBuffer(Generic[T]):\n+class _QuantileBuffer(object):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671"}, "originalPosition": 217}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDM2NjAxMw==", "bodyText": "Is there a good way to make this inheritance work with Cython?\nIt doesn't compile with inheritance from a non-extension type.", "url": "https://github.com/apache/beam/pull/13175#discussion_r514366013", "createdAt": "2020-10-29T15:48:14Z", "author": {"login": "iindyk"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -368,82 +383,129 @@ class PerKey(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate\n+        multiple elements at a time more efficiently.\n     \"\"\"\n-    def __init__(self, num_quantiles, key=None, reverse=False, weighted=False):\n+    def __init__(\n+        self,\n+        num_quantiles,\n+        key=None,\n+        reverse=False,\n+        weighted=False,\n+        batch_input=False):\n       self._num_quantiles = num_quantiles\n       self._key = key\n       self._reverse = reverse\n       self._weighted = weighted\n+      self._batch_input = batch_input\n \n     def expand(self, pcoll):\n       return pcoll | CombinePerKey(\n           ApproximateQuantilesCombineFn.create(\n               num_quantiles=self._num_quantiles,\n               key=self._key,\n               reverse=self._reverse,\n-              weighted=self._weighted))\n+              weighted=self._weighted,\n+              batch_input=self._batch_input))\n \n     def display_data(self):\n       return ApproximateQuantiles._display_data(\n           num_quantiles=self._num_quantiles,\n           key=self._key,\n           reverse=self._reverse,\n-          weighted=self._weighted)\n+          weighted=self._weighted,\n+          batch_input=self._batch_input)\n+\n+\n+class _QuantileSpec(object):\n+  \"\"\"Quantiles computation specifications.\"\"\"\n+  def __init__(self, buffer_size, num_buffers, weighted, key, reverse):\n+    # type: (int, int, bool, Any, bool) -> None\n+    self.buffer_size = buffer_size\n+    self.num_buffers = num_buffers\n+    self.weighted = weighted\n+    self.key = key\n+    self.reverse = reverse\n+\n+    # Used to sort tuples of values and weights.\n+    self.weighted_key = None if key is None else (lambda x: key(x[0]))\n+\n+    # Used to compare values.\n+    if key is None and not reverse:\n+      self.less_than = lambda a, b: a < b\n+    elif key is None:\n+      self.less_than = lambda a, b: a > b\n+    elif not reverse:\n+      self.less_than = lambda a, b: key(a) < key(b)\n+    else:\n+      self.less_than = lambda a, b: key(a) > key(b)\n+\n+  def get_argsort_key(self, elements):\n+    # type: (List) -> Any\n+\n+    \"\"\"Returns a key for sorting indices of elements by element's value.\"\"\"\n+    if self.key is None:\n+      return elements.__getitem__\n+    else:\n+      return lambda idx: self.key(elements[idx])\n+\n+  def __reduce__(self):\n+    return (\n+        self.__class__,\n+        (\n+            self.buffer_size,\n+            self.num_buffers,\n+            self.weighted,\n+            self.key,\n+            self.reverse))\n \n \n-class _QuantileBuffer(Generic[T]):\n+class _QuantileBuffer(object):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY5MDg3MQ=="}, "originalCommit": {"oid": "2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671"}, "originalPosition": 217}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDk3NDM5Mw==", "bodyText": "You should be able to inherit rom both object and Generic[T].", "url": "https://github.com/apache/beam/pull/13175#discussion_r520974393", "createdAt": "2020-11-11T00:59:34Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -368,82 +383,129 @@ class PerKey(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate\n+        multiple elements at a time more efficiently.\n     \"\"\"\n-    def __init__(self, num_quantiles, key=None, reverse=False, weighted=False):\n+    def __init__(\n+        self,\n+        num_quantiles,\n+        key=None,\n+        reverse=False,\n+        weighted=False,\n+        batch_input=False):\n       self._num_quantiles = num_quantiles\n       self._key = key\n       self._reverse = reverse\n       self._weighted = weighted\n+      self._batch_input = batch_input\n \n     def expand(self, pcoll):\n       return pcoll | CombinePerKey(\n           ApproximateQuantilesCombineFn.create(\n               num_quantiles=self._num_quantiles,\n               key=self._key,\n               reverse=self._reverse,\n-              weighted=self._weighted))\n+              weighted=self._weighted,\n+              batch_input=self._batch_input))\n \n     def display_data(self):\n       return ApproximateQuantiles._display_data(\n           num_quantiles=self._num_quantiles,\n           key=self._key,\n           reverse=self._reverse,\n-          weighted=self._weighted)\n+          weighted=self._weighted,\n+          batch_input=self._batch_input)\n+\n+\n+class _QuantileSpec(object):\n+  \"\"\"Quantiles computation specifications.\"\"\"\n+  def __init__(self, buffer_size, num_buffers, weighted, key, reverse):\n+    # type: (int, int, bool, Any, bool) -> None\n+    self.buffer_size = buffer_size\n+    self.num_buffers = num_buffers\n+    self.weighted = weighted\n+    self.key = key\n+    self.reverse = reverse\n+\n+    # Used to sort tuples of values and weights.\n+    self.weighted_key = None if key is None else (lambda x: key(x[0]))\n+\n+    # Used to compare values.\n+    if key is None and not reverse:\n+      self.less_than = lambda a, b: a < b\n+    elif key is None:\n+      self.less_than = lambda a, b: a > b\n+    elif not reverse:\n+      self.less_than = lambda a, b: key(a) < key(b)\n+    else:\n+      self.less_than = lambda a, b: key(a) > key(b)\n+\n+  def get_argsort_key(self, elements):\n+    # type: (List) -> Any\n+\n+    \"\"\"Returns a key for sorting indices of elements by element's value.\"\"\"\n+    if self.key is None:\n+      return elements.__getitem__\n+    else:\n+      return lambda idx: self.key(elements[idx])\n+\n+  def __reduce__(self):\n+    return (\n+        self.__class__,\n+        (\n+            self.buffer_size,\n+            self.num_buffers,\n+            self.weighted,\n+            self.key,\n+            self.reverse))\n \n \n-class _QuantileBuffer(Generic[T]):\n+class _QuantileBuffer(object):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY5MDg3MQ=="}, "originalCommit": {"oid": "2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671"}, "originalPosition": 217}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTQzODg5NQ==", "bodyText": "when inherit _QuantileBuffer(object, Generic[T]), without Cython I get\nTypeError: Cannot create a consistent method resolution order (MRO) for bases object, Generic\n\nWhen I do _QuantileBuffer(Generic[T], object), then it works for Python, but with Cythonization I get\nFirst base of '_QuantileBuffer' is not an extension type.\n\nand\nOnly one extension type base class allowed.\n\nAm I missing something?", "url": "https://github.com/apache/beam/pull/13175#discussion_r521438895", "createdAt": "2020-11-11T15:30:13Z", "author": {"login": "iindyk"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -368,82 +383,129 @@ class PerKey(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate\n+        multiple elements at a time more efficiently.\n     \"\"\"\n-    def __init__(self, num_quantiles, key=None, reverse=False, weighted=False):\n+    def __init__(\n+        self,\n+        num_quantiles,\n+        key=None,\n+        reverse=False,\n+        weighted=False,\n+        batch_input=False):\n       self._num_quantiles = num_quantiles\n       self._key = key\n       self._reverse = reverse\n       self._weighted = weighted\n+      self._batch_input = batch_input\n \n     def expand(self, pcoll):\n       return pcoll | CombinePerKey(\n           ApproximateQuantilesCombineFn.create(\n               num_quantiles=self._num_quantiles,\n               key=self._key,\n               reverse=self._reverse,\n-              weighted=self._weighted))\n+              weighted=self._weighted,\n+              batch_input=self._batch_input))\n \n     def display_data(self):\n       return ApproximateQuantiles._display_data(\n           num_quantiles=self._num_quantiles,\n           key=self._key,\n           reverse=self._reverse,\n-          weighted=self._weighted)\n+          weighted=self._weighted,\n+          batch_input=self._batch_input)\n+\n+\n+class _QuantileSpec(object):\n+  \"\"\"Quantiles computation specifications.\"\"\"\n+  def __init__(self, buffer_size, num_buffers, weighted, key, reverse):\n+    # type: (int, int, bool, Any, bool) -> None\n+    self.buffer_size = buffer_size\n+    self.num_buffers = num_buffers\n+    self.weighted = weighted\n+    self.key = key\n+    self.reverse = reverse\n+\n+    # Used to sort tuples of values and weights.\n+    self.weighted_key = None if key is None else (lambda x: key(x[0]))\n+\n+    # Used to compare values.\n+    if key is None and not reverse:\n+      self.less_than = lambda a, b: a < b\n+    elif key is None:\n+      self.less_than = lambda a, b: a > b\n+    elif not reverse:\n+      self.less_than = lambda a, b: key(a) < key(b)\n+    else:\n+      self.less_than = lambda a, b: key(a) > key(b)\n+\n+  def get_argsort_key(self, elements):\n+    # type: (List) -> Any\n+\n+    \"\"\"Returns a key for sorting indices of elements by element's value.\"\"\"\n+    if self.key is None:\n+      return elements.__getitem__\n+    else:\n+      return lambda idx: self.key(elements[idx])\n+\n+  def __reduce__(self):\n+    return (\n+        self.__class__,\n+        (\n+            self.buffer_size,\n+            self.num_buffers,\n+            self.weighted,\n+            self.key,\n+            self.reverse))\n \n \n-class _QuantileBuffer(Generic[T]):\n+class _QuantileBuffer(object):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY5MDg3MQ=="}, "originalCommit": {"oid": "2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671"}, "originalPosition": 217}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxODcxNjQxOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/transforms/stats.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxOTowNTo0OFrOHp5Ydg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOVQxNTo0ODoyN1rOHqia2w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY5MzgxNA==", "bodyText": "This will break if it's called twice. Instead put the call to zip here.", "url": "https://github.com/apache/beam/pull/13175#discussion_r513693814", "createdAt": "2020-10-28T19:05:48Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -368,82 +383,129 @@ class PerKey(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate\n+        multiple elements at a time more efficiently.\n     \"\"\"\n-    def __init__(self, num_quantiles, key=None, reverse=False, weighted=False):\n+    def __init__(\n+        self,\n+        num_quantiles,\n+        key=None,\n+        reverse=False,\n+        weighted=False,\n+        batch_input=False):\n       self._num_quantiles = num_quantiles\n       self._key = key\n       self._reverse = reverse\n       self._weighted = weighted\n+      self._batch_input = batch_input\n \n     def expand(self, pcoll):\n       return pcoll | CombinePerKey(\n           ApproximateQuantilesCombineFn.create(\n               num_quantiles=self._num_quantiles,\n               key=self._key,\n               reverse=self._reverse,\n-              weighted=self._weighted))\n+              weighted=self._weighted,\n+              batch_input=self._batch_input))\n \n     def display_data(self):\n       return ApproximateQuantiles._display_data(\n           num_quantiles=self._num_quantiles,\n           key=self._key,\n           reverse=self._reverse,\n-          weighted=self._weighted)\n+          weighted=self._weighted,\n+          batch_input=self._batch_input)\n+\n+\n+class _QuantileSpec(object):\n+  \"\"\"Quantiles computation specifications.\"\"\"\n+  def __init__(self, buffer_size, num_buffers, weighted, key, reverse):\n+    # type: (int, int, bool, Any, bool) -> None\n+    self.buffer_size = buffer_size\n+    self.num_buffers = num_buffers\n+    self.weighted = weighted\n+    self.key = key\n+    self.reverse = reverse\n+\n+    # Used to sort tuples of values and weights.\n+    self.weighted_key = None if key is None else (lambda x: key(x[0]))\n+\n+    # Used to compare values.\n+    if key is None and not reverse:\n+      self.less_than = lambda a, b: a < b\n+    elif key is None:\n+      self.less_than = lambda a, b: a > b\n+    elif not reverse:\n+      self.less_than = lambda a, b: key(a) < key(b)\n+    else:\n+      self.less_than = lambda a, b: key(a) > key(b)\n+\n+  def get_argsort_key(self, elements):\n+    # type: (List) -> Any\n+\n+    \"\"\"Returns a key for sorting indices of elements by element's value.\"\"\"\n+    if self.key is None:\n+      return elements.__getitem__\n+    else:\n+      return lambda idx: self.key(elements[idx])\n+\n+  def __reduce__(self):\n+    return (\n+        self.__class__,\n+        (\n+            self.buffer_size,\n+            self.num_buffers,\n+            self.weighted,\n+            self.key,\n+            self.reverse))\n \n \n-class _QuantileBuffer(Generic[T]):\n+class _QuantileBuffer(object):\n   \"\"\"A single buffer in the sense of the referenced algorithm.\n   (see http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.6.6513&rep=rep1\n   &type=pdf and ApproximateQuantilesCombineFn for further information)\"\"\"\n-  def __init__(self, elements, weighted, level=0, weight=1):\n-    # type: (Sequence[T], bool, int, int) -> None\n-    # In case of weighted quantiles, elements are tuples of values and weights.\n+  def __init__(\n+      self, elements, weights, weighted, level=0, min_val=None, max_val=None):\n+    # type: (List, List, bool, int, Any, Any) -> None\n     self.elements = elements\n-    self.weighted = weighted\n+    self.weights = weights\n     self.level = level\n-    self.weight = weight\n-\n-  def __lt__(self, other):\n-    if self.weighted:\n-      return [element[0] for element in self.elements\n-              ] < [element[0] for element in other.elements]\n+    if min_val is None or max_val is None:\n+      # Buffer is always initialized with sorted elements.\n+      self.min_val = elements[0]\n+      self.max_val = elements[-1]\n     else:\n-      return self.elements < other.elements\n-\n-  def sized_iterator(self):\n-    class QuantileBufferIterator(object):\n-      def __init__(self, elem, weighted, weight):\n-        self._iter = iter(elem)\n-        self.weighted = weighted\n-        self.weight = weight\n-\n-      def __iter__(self):\n-        return self\n+      # Note that collapsed buffer may not contain min and max in the list of\n+      # elements.\n+      self.min_val = min_val\n+      self.max_val = max_val\n+    self._iter = zip(\n+        self.elements,\n+        self.weights if weighted else itertools.repeat(self.weights[0]))\n \n-      def __next__(self):\n-        if self.weighted:\n-          return next(self._iter)\n-        else:\n-          value = next(self._iter)\n-          return (value, self.weight)\n+  def __iter__(self):\n+    return self._iter", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671"}, "originalPosition": 268}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDM2NjE3MQ==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/13175#discussion_r514366171", "createdAt": "2020-10-29T15:48:27Z", "author": {"login": "iindyk"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -368,82 +383,129 @@ class PerKey(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate\n+        multiple elements at a time more efficiently.\n     \"\"\"\n-    def __init__(self, num_quantiles, key=None, reverse=False, weighted=False):\n+    def __init__(\n+        self,\n+        num_quantiles,\n+        key=None,\n+        reverse=False,\n+        weighted=False,\n+        batch_input=False):\n       self._num_quantiles = num_quantiles\n       self._key = key\n       self._reverse = reverse\n       self._weighted = weighted\n+      self._batch_input = batch_input\n \n     def expand(self, pcoll):\n       return pcoll | CombinePerKey(\n           ApproximateQuantilesCombineFn.create(\n               num_quantiles=self._num_quantiles,\n               key=self._key,\n               reverse=self._reverse,\n-              weighted=self._weighted))\n+              weighted=self._weighted,\n+              batch_input=self._batch_input))\n \n     def display_data(self):\n       return ApproximateQuantiles._display_data(\n           num_quantiles=self._num_quantiles,\n           key=self._key,\n           reverse=self._reverse,\n-          weighted=self._weighted)\n+          weighted=self._weighted,\n+          batch_input=self._batch_input)\n+\n+\n+class _QuantileSpec(object):\n+  \"\"\"Quantiles computation specifications.\"\"\"\n+  def __init__(self, buffer_size, num_buffers, weighted, key, reverse):\n+    # type: (int, int, bool, Any, bool) -> None\n+    self.buffer_size = buffer_size\n+    self.num_buffers = num_buffers\n+    self.weighted = weighted\n+    self.key = key\n+    self.reverse = reverse\n+\n+    # Used to sort tuples of values and weights.\n+    self.weighted_key = None if key is None else (lambda x: key(x[0]))\n+\n+    # Used to compare values.\n+    if key is None and not reverse:\n+      self.less_than = lambda a, b: a < b\n+    elif key is None:\n+      self.less_than = lambda a, b: a > b\n+    elif not reverse:\n+      self.less_than = lambda a, b: key(a) < key(b)\n+    else:\n+      self.less_than = lambda a, b: key(a) > key(b)\n+\n+  def get_argsort_key(self, elements):\n+    # type: (List) -> Any\n+\n+    \"\"\"Returns a key for sorting indices of elements by element's value.\"\"\"\n+    if self.key is None:\n+      return elements.__getitem__\n+    else:\n+      return lambda idx: self.key(elements[idx])\n+\n+  def __reduce__(self):\n+    return (\n+        self.__class__,\n+        (\n+            self.buffer_size,\n+            self.num_buffers,\n+            self.weighted,\n+            self.key,\n+            self.reverse))\n \n \n-class _QuantileBuffer(Generic[T]):\n+class _QuantileBuffer(object):\n   \"\"\"A single buffer in the sense of the referenced algorithm.\n   (see http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.6.6513&rep=rep1\n   &type=pdf and ApproximateQuantilesCombineFn for further information)\"\"\"\n-  def __init__(self, elements, weighted, level=0, weight=1):\n-    # type: (Sequence[T], bool, int, int) -> None\n-    # In case of weighted quantiles, elements are tuples of values and weights.\n+  def __init__(\n+      self, elements, weights, weighted, level=0, min_val=None, max_val=None):\n+    # type: (List, List, bool, int, Any, Any) -> None\n     self.elements = elements\n-    self.weighted = weighted\n+    self.weights = weights\n     self.level = level\n-    self.weight = weight\n-\n-  def __lt__(self, other):\n-    if self.weighted:\n-      return [element[0] for element in self.elements\n-              ] < [element[0] for element in other.elements]\n+    if min_val is None or max_val is None:\n+      # Buffer is always initialized with sorted elements.\n+      self.min_val = elements[0]\n+      self.max_val = elements[-1]\n     else:\n-      return self.elements < other.elements\n-\n-  def sized_iterator(self):\n-    class QuantileBufferIterator(object):\n-      def __init__(self, elem, weighted, weight):\n-        self._iter = iter(elem)\n-        self.weighted = weighted\n-        self.weight = weight\n-\n-      def __iter__(self):\n-        return self\n+      # Note that collapsed buffer may not contain min and max in the list of\n+      # elements.\n+      self.min_val = min_val\n+      self.max_val = max_val\n+    self._iter = zip(\n+        self.elements,\n+        self.weights if weighted else itertools.repeat(self.weights[0]))\n \n-      def __next__(self):\n-        if self.weighted:\n-          return next(self._iter)\n-        else:\n-          value = next(self._iter)\n-          return (value, self.weight)\n+  def __iter__(self):\n+    return self._iter", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY5MzgxNA=="}, "originalCommit": {"oid": "2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671"}, "originalPosition": 268}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxODcxOTAwOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/transforms/stats.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxOTowNjozM1rOHp5aDQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOVQxNTo0ODozM1rOHqibMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY5NDIyMQ==", "bodyText": "Python 2 support no longer needed.", "url": "https://github.com/apache/beam/pull/13175#discussion_r513694221", "createdAt": "2020-10-28T19:06:33Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -368,82 +383,129 @@ class PerKey(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate\n+        multiple elements at a time more efficiently.\n     \"\"\"\n-    def __init__(self, num_quantiles, key=None, reverse=False, weighted=False):\n+    def __init__(\n+        self,\n+        num_quantiles,\n+        key=None,\n+        reverse=False,\n+        weighted=False,\n+        batch_input=False):\n       self._num_quantiles = num_quantiles\n       self._key = key\n       self._reverse = reverse\n       self._weighted = weighted\n+      self._batch_input = batch_input\n \n     def expand(self, pcoll):\n       return pcoll | CombinePerKey(\n           ApproximateQuantilesCombineFn.create(\n               num_quantiles=self._num_quantiles,\n               key=self._key,\n               reverse=self._reverse,\n-              weighted=self._weighted))\n+              weighted=self._weighted,\n+              batch_input=self._batch_input))\n \n     def display_data(self):\n       return ApproximateQuantiles._display_data(\n           num_quantiles=self._num_quantiles,\n           key=self._key,\n           reverse=self._reverse,\n-          weighted=self._weighted)\n+          weighted=self._weighted,\n+          batch_input=self._batch_input)\n+\n+\n+class _QuantileSpec(object):\n+  \"\"\"Quantiles computation specifications.\"\"\"\n+  def __init__(self, buffer_size, num_buffers, weighted, key, reverse):\n+    # type: (int, int, bool, Any, bool) -> None\n+    self.buffer_size = buffer_size\n+    self.num_buffers = num_buffers\n+    self.weighted = weighted\n+    self.key = key\n+    self.reverse = reverse\n+\n+    # Used to sort tuples of values and weights.\n+    self.weighted_key = None if key is None else (lambda x: key(x[0]))\n+\n+    # Used to compare values.\n+    if key is None and not reverse:\n+      self.less_than = lambda a, b: a < b\n+    elif key is None:\n+      self.less_than = lambda a, b: a > b\n+    elif not reverse:\n+      self.less_than = lambda a, b: key(a) < key(b)\n+    else:\n+      self.less_than = lambda a, b: key(a) > key(b)\n+\n+  def get_argsort_key(self, elements):\n+    # type: (List) -> Any\n+\n+    \"\"\"Returns a key for sorting indices of elements by element's value.\"\"\"\n+    if self.key is None:\n+      return elements.__getitem__\n+    else:\n+      return lambda idx: self.key(elements[idx])\n+\n+  def __reduce__(self):\n+    return (\n+        self.__class__,\n+        (\n+            self.buffer_size,\n+            self.num_buffers,\n+            self.weighted,\n+            self.key,\n+            self.reverse))\n \n \n-class _QuantileBuffer(Generic[T]):\n+class _QuantileBuffer(object):\n   \"\"\"A single buffer in the sense of the referenced algorithm.\n   (see http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.6.6513&rep=rep1\n   &type=pdf and ApproximateQuantilesCombineFn for further information)\"\"\"\n-  def __init__(self, elements, weighted, level=0, weight=1):\n-    # type: (Sequence[T], bool, int, int) -> None\n-    # In case of weighted quantiles, elements are tuples of values and weights.\n+  def __init__(\n+      self, elements, weights, weighted, level=0, min_val=None, max_val=None):\n+    # type: (List, List, bool, int, Any, Any) -> None\n     self.elements = elements\n-    self.weighted = weighted\n+    self.weights = weights\n     self.level = level\n-    self.weight = weight\n-\n-  def __lt__(self, other):\n-    if self.weighted:\n-      return [element[0] for element in self.elements\n-              ] < [element[0] for element in other.elements]\n+    if min_val is None or max_val is None:\n+      # Buffer is always initialized with sorted elements.\n+      self.min_val = elements[0]\n+      self.max_val = elements[-1]\n     else:\n-      return self.elements < other.elements\n-\n-  def sized_iterator(self):\n-    class QuantileBufferIterator(object):\n-      def __init__(self, elem, weighted, weight):\n-        self._iter = iter(elem)\n-        self.weighted = weighted\n-        self.weight = weight\n-\n-      def __iter__(self):\n-        return self\n+      # Note that collapsed buffer may not contain min and max in the list of\n+      # elements.\n+      self.min_val = min_val\n+      self.max_val = max_val\n+    self._iter = zip(\n+        self.elements,\n+        self.weights if weighted else itertools.repeat(self.weights[0]))\n \n-      def __next__(self):\n-        if self.weighted:\n-          return next(self._iter)\n-        else:\n-          value = next(self._iter)\n-          return (value, self.weight)\n+  def __iter__(self):\n+    return self._iter\n \n-      next = __next__  # For Python 2\n+  def __next__(self):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671"}, "originalPosition": 271}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDM2NjI1Nw==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/13175#discussion_r514366257", "createdAt": "2020-10-29T15:48:33Z", "author": {"login": "iindyk"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -368,82 +383,129 @@ class PerKey(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate\n+        multiple elements at a time more efficiently.\n     \"\"\"\n-    def __init__(self, num_quantiles, key=None, reverse=False, weighted=False):\n+    def __init__(\n+        self,\n+        num_quantiles,\n+        key=None,\n+        reverse=False,\n+        weighted=False,\n+        batch_input=False):\n       self._num_quantiles = num_quantiles\n       self._key = key\n       self._reverse = reverse\n       self._weighted = weighted\n+      self._batch_input = batch_input\n \n     def expand(self, pcoll):\n       return pcoll | CombinePerKey(\n           ApproximateQuantilesCombineFn.create(\n               num_quantiles=self._num_quantiles,\n               key=self._key,\n               reverse=self._reverse,\n-              weighted=self._weighted))\n+              weighted=self._weighted,\n+              batch_input=self._batch_input))\n \n     def display_data(self):\n       return ApproximateQuantiles._display_data(\n           num_quantiles=self._num_quantiles,\n           key=self._key,\n           reverse=self._reverse,\n-          weighted=self._weighted)\n+          weighted=self._weighted,\n+          batch_input=self._batch_input)\n+\n+\n+class _QuantileSpec(object):\n+  \"\"\"Quantiles computation specifications.\"\"\"\n+  def __init__(self, buffer_size, num_buffers, weighted, key, reverse):\n+    # type: (int, int, bool, Any, bool) -> None\n+    self.buffer_size = buffer_size\n+    self.num_buffers = num_buffers\n+    self.weighted = weighted\n+    self.key = key\n+    self.reverse = reverse\n+\n+    # Used to sort tuples of values and weights.\n+    self.weighted_key = None if key is None else (lambda x: key(x[0]))\n+\n+    # Used to compare values.\n+    if key is None and not reverse:\n+      self.less_than = lambda a, b: a < b\n+    elif key is None:\n+      self.less_than = lambda a, b: a > b\n+    elif not reverse:\n+      self.less_than = lambda a, b: key(a) < key(b)\n+    else:\n+      self.less_than = lambda a, b: key(a) > key(b)\n+\n+  def get_argsort_key(self, elements):\n+    # type: (List) -> Any\n+\n+    \"\"\"Returns a key for sorting indices of elements by element's value.\"\"\"\n+    if self.key is None:\n+      return elements.__getitem__\n+    else:\n+      return lambda idx: self.key(elements[idx])\n+\n+  def __reduce__(self):\n+    return (\n+        self.__class__,\n+        (\n+            self.buffer_size,\n+            self.num_buffers,\n+            self.weighted,\n+            self.key,\n+            self.reverse))\n \n \n-class _QuantileBuffer(Generic[T]):\n+class _QuantileBuffer(object):\n   \"\"\"A single buffer in the sense of the referenced algorithm.\n   (see http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.6.6513&rep=rep1\n   &type=pdf and ApproximateQuantilesCombineFn for further information)\"\"\"\n-  def __init__(self, elements, weighted, level=0, weight=1):\n-    # type: (Sequence[T], bool, int, int) -> None\n-    # In case of weighted quantiles, elements are tuples of values and weights.\n+  def __init__(\n+      self, elements, weights, weighted, level=0, min_val=None, max_val=None):\n+    # type: (List, List, bool, int, Any, Any) -> None\n     self.elements = elements\n-    self.weighted = weighted\n+    self.weights = weights\n     self.level = level\n-    self.weight = weight\n-\n-  def __lt__(self, other):\n-    if self.weighted:\n-      return [element[0] for element in self.elements\n-              ] < [element[0] for element in other.elements]\n+    if min_val is None or max_val is None:\n+      # Buffer is always initialized with sorted elements.\n+      self.min_val = elements[0]\n+      self.max_val = elements[-1]\n     else:\n-      return self.elements < other.elements\n-\n-  def sized_iterator(self):\n-    class QuantileBufferIterator(object):\n-      def __init__(self, elem, weighted, weight):\n-        self._iter = iter(elem)\n-        self.weighted = weighted\n-        self.weight = weight\n-\n-      def __iter__(self):\n-        return self\n+      # Note that collapsed buffer may not contain min and max in the list of\n+      # elements.\n+      self.min_val = min_val\n+      self.max_val = max_val\n+    self._iter = zip(\n+        self.elements,\n+        self.weights if weighted else itertools.repeat(self.weights[0]))\n \n-      def __next__(self):\n-        if self.weighted:\n-          return next(self._iter)\n-        else:\n-          value = next(self._iter)\n-          return (value, self.weight)\n+  def __iter__(self):\n+    return self._iter\n \n-      next = __next__  # For Python 2\n+  def __next__(self):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY5NDIyMQ=="}, "originalCommit": {"oid": "2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671"}, "originalPosition": 271}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxODcxOTczOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/transforms/stats.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxOTowNjo0N1rOHp5ahQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxOTowNjo0N1rOHp5ahQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY5NDM0MQ==", "bodyText": "Same.", "url": "https://github.com/apache/beam/pull/13175#discussion_r513694341", "createdAt": "2020-10-28T19:06:47Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -368,82 +383,129 @@ class PerKey(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate\n+        multiple elements at a time more efficiently.\n     \"\"\"\n-    def __init__(self, num_quantiles, key=None, reverse=False, weighted=False):\n+    def __init__(\n+        self,\n+        num_quantiles,\n+        key=None,\n+        reverse=False,\n+        weighted=False,\n+        batch_input=False):\n       self._num_quantiles = num_quantiles\n       self._key = key\n       self._reverse = reverse\n       self._weighted = weighted\n+      self._batch_input = batch_input\n \n     def expand(self, pcoll):\n       return pcoll | CombinePerKey(\n           ApproximateQuantilesCombineFn.create(\n               num_quantiles=self._num_quantiles,\n               key=self._key,\n               reverse=self._reverse,\n-              weighted=self._weighted))\n+              weighted=self._weighted,\n+              batch_input=self._batch_input))\n \n     def display_data(self):\n       return ApproximateQuantiles._display_data(\n           num_quantiles=self._num_quantiles,\n           key=self._key,\n           reverse=self._reverse,\n-          weighted=self._weighted)\n+          weighted=self._weighted,\n+          batch_input=self._batch_input)\n+\n+\n+class _QuantileSpec(object):\n+  \"\"\"Quantiles computation specifications.\"\"\"\n+  def __init__(self, buffer_size, num_buffers, weighted, key, reverse):\n+    # type: (int, int, bool, Any, bool) -> None\n+    self.buffer_size = buffer_size\n+    self.num_buffers = num_buffers\n+    self.weighted = weighted\n+    self.key = key\n+    self.reverse = reverse\n+\n+    # Used to sort tuples of values and weights.\n+    self.weighted_key = None if key is None else (lambda x: key(x[0]))\n+\n+    # Used to compare values.\n+    if key is None and not reverse:\n+      self.less_than = lambda a, b: a < b\n+    elif key is None:\n+      self.less_than = lambda a, b: a > b\n+    elif not reverse:\n+      self.less_than = lambda a, b: key(a) < key(b)\n+    else:\n+      self.less_than = lambda a, b: key(a) > key(b)\n+\n+  def get_argsort_key(self, elements):\n+    # type: (List) -> Any\n+\n+    \"\"\"Returns a key for sorting indices of elements by element's value.\"\"\"\n+    if self.key is None:\n+      return elements.__getitem__\n+    else:\n+      return lambda idx: self.key(elements[idx])\n+\n+  def __reduce__(self):\n+    return (\n+        self.__class__,\n+        (\n+            self.buffer_size,\n+            self.num_buffers,\n+            self.weighted,\n+            self.key,\n+            self.reverse))\n \n \n-class _QuantileBuffer(Generic[T]):\n+class _QuantileBuffer(object):\n   \"\"\"A single buffer in the sense of the referenced algorithm.\n   (see http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.6.6513&rep=rep1\n   &type=pdf and ApproximateQuantilesCombineFn for further information)\"\"\"\n-  def __init__(self, elements, weighted, level=0, weight=1):\n-    # type: (Sequence[T], bool, int, int) -> None\n-    # In case of weighted quantiles, elements are tuples of values and weights.\n+  def __init__(\n+      self, elements, weights, weighted, level=0, min_val=None, max_val=None):\n+    # type: (List, List, bool, int, Any, Any) -> None\n     self.elements = elements\n-    self.weighted = weighted\n+    self.weights = weights\n     self.level = level\n-    self.weight = weight\n-\n-  def __lt__(self, other):\n-    if self.weighted:\n-      return [element[0] for element in self.elements\n-              ] < [element[0] for element in other.elements]\n+    if min_val is None or max_val is None:\n+      # Buffer is always initialized with sorted elements.\n+      self.min_val = elements[0]\n+      self.max_val = elements[-1]\n     else:\n-      return self.elements < other.elements\n-\n-  def sized_iterator(self):\n-    class QuantileBufferIterator(object):\n-      def __init__(self, elem, weighted, weight):\n-        self._iter = iter(elem)\n-        self.weighted = weighted\n-        self.weight = weight\n-\n-      def __iter__(self):\n-        return self\n+      # Note that collapsed buffer may not contain min and max in the list of\n+      # elements.\n+      self.min_val = min_val\n+      self.max_val = max_val\n+    self._iter = zip(\n+        self.elements,\n+        self.weights if weighted else itertools.repeat(self.weights[0]))\n \n-      def __next__(self):\n-        if self.weighted:\n-          return next(self._iter)\n-        else:\n-          value = next(self._iter)\n-          return (value, self.weight)\n+  def __iter__(self):\n+    return self._iter\n \n-      next = __next__  # For Python 2\n+  def __next__(self):\n+    return next(self._iter)\n \n-    return QuantileBufferIterator(self.elements, self.weighted, self.weight)\n+  def __lt__(self, other):\n+    return self.level < other.level\n \n \n-class _QuantileState(Generic[T]):\n+class _QuantileState(object):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671"}, "originalPosition": 280}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI2NjA0ODY5OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/transforms/stats.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQwMDo1ODoxNlrOHw1syA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQxNToyMzozMVrOHxR0EQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDk3MzUxMg==", "bodyText": "Go ahead and put a trailing comma on this one too.", "url": "https://github.com/apache/beam/pull/13175#discussion_r520973512", "createdAt": "2020-11-11T00:58:16Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -299,15 +300,17 @@ class ApproximateQuantiles(object):\n     out: [0, 2, 5, 7, 100]\n   \"\"\"\n   @staticmethod\n-  def _display_data(num_quantiles, key, reverse, weighted):\n+  def _display_data(num_quantiles, key, reverse, weighted, batch_input):\n     return {\n         'num_quantiles': DisplayDataItem(num_quantiles, label='Quantile Count'),\n         'key': DisplayDataItem(\n             key.__name__\n             if hasattr(key, '__name__') else key.__class__.__name__,\n             label='Record Comparer Key'),\n         'reverse': DisplayDataItem(str(reverse), label='Is Reversed'),\n-        'weighted': DisplayDataItem(str(weighted), label='Is Weighted')\n+        'weighted': DisplayDataItem(str(weighted), label='Is Weighted'),\n+        'batch_input': DisplayDataItem(\n+            str(batch_input), label='Is Input Batched')", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0f36b7d5baca732684e678ed7a5cb6cea381ab59"}, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTQzNDEyOQ==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/13175#discussion_r521434129", "createdAt": "2020-11-11T15:23:31Z", "author": {"login": "iindyk"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -299,15 +300,17 @@ class ApproximateQuantiles(object):\n     out: [0, 2, 5, 7, 100]\n   \"\"\"\n   @staticmethod\n-  def _display_data(num_quantiles, key, reverse, weighted):\n+  def _display_data(num_quantiles, key, reverse, weighted, batch_input):\n     return {\n         'num_quantiles': DisplayDataItem(num_quantiles, label='Quantile Count'),\n         'key': DisplayDataItem(\n             key.__name__\n             if hasattr(key, '__name__') else key.__class__.__name__,\n             label='Record Comparer Key'),\n         'reverse': DisplayDataItem(str(reverse), label='Is Reversed'),\n-        'weighted': DisplayDataItem(str(weighted), label='Is Weighted')\n+        'weighted': DisplayDataItem(str(weighted), label='Is Weighted'),\n+        'batch_input': DisplayDataItem(\n+            str(batch_input), label='Is Input Batched')", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDk3MzUxMg=="}, "originalCommit": {"oid": "0f36b7d5baca732684e678ed7a5cb6cea381ab59"}, "originalPosition": 84}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU0NTM2MDI3OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/transforms/stats.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yM1QwMToxMzoyNVrOIY6bDw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wNVQwNDozOToyMFrOIgRueA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Mjk5MzkzNQ==", "bodyText": "Re: line 766: could you please clarify what is N in the docstring\nAlso, can you please note that the algorithm referenced in the paper is generalized to compute weighted quantiles.", "url": "https://github.com/apache/beam/pull/13175#discussion_r562993935", "createdAt": "2021-01-23T01:13:25Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -501,6 +781,8 @@ class ApproximateQuantilesCombineFn(CombineFn, Generic[T]):\n     weighted: (optional) if set to True, the combiner produces weighted\n       quantiles. The input elements are then expected to be tuples of input\n       values with the corresponding weight.\n+    batch_input: (optional) if set to True, inputs are expected to be batches of", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8fff438793b622ac6ae2493d9fb24a581edc4264"}, "originalPosition": 541}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDcxNTc2OA==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/13175#discussion_r570715768", "createdAt": "2021-02-05T04:39:20Z", "author": {"login": "iindyk"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -501,6 +781,8 @@ class ApproximateQuantilesCombineFn(CombineFn, Generic[T]):\n     weighted: (optional) if set to True, the combiner produces weighted\n       quantiles. The input elements are then expected to be tuples of input\n       values with the corresponding weight.\n+    batch_input: (optional) if set to True, inputs are expected to be batches of", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Mjk5MzkzNQ=="}, "originalCommit": {"oid": "8fff438793b622ac6ae2493d9fb24a581edc4264"}, "originalPosition": 541}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU0ODU2ODk3OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/transforms/stats.py", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNVQwMjowOToyN1rOIZU5Ew==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wOVQyMDozMjo0N1rOIiqUyQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzQyNzYwMw==", "bodyText": "Can you please comment on the structure of a 'batch' here? in particular for the weighted case. Consider also adding an example to line 295.\n\n\nLooking at the tests, it seems that for weighted case with batches, we expect users to provide  elements and weights as separate lists. From API/usability standpoint, what is the rationale on providing weights as a separate list in as opposed to augmenting the weight to the element in a tuple, which is how elements are represented for non-batched case?", "url": "https://github.com/apache/beam/pull/13175#discussion_r563427603", "createdAt": "2021-01-25T02:09:27Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -327,27 +330,39 @@ class Globally(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8fff438793b622ac6ae2493d9fb24a581edc4264"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDg2NTgxNA==", "bodyText": "wording suggestion: s/batch_input/input_batched  or inputs_batched, since the parameter refers to the input rather than the result (like in case of reverse).", "url": "https://github.com/apache/beam/pull/13175#discussion_r564865814", "createdAt": "2021-01-26T22:05:16Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -327,27 +330,39 @@ class Globally(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzQyNzYwMw=="}, "originalCommit": {"oid": "8fff438793b622ac6ae2493d9fb24a581edc4264"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDcxNjA0Mg==", "bodyText": "Done, also added examples.\nI think tuple (element, weight) generalizes the same way to (elements, weights) as it does to [(element1, weight1), ...], so I don't see any strong advantage of either from usability perspective (for instance, TFT's quantiles take them as separate tensors), but there's a benefit in taking (elements, weights) from code simplicity perspective - it allows weighted and unweighted cases to have a lot of code in common.", "url": "https://github.com/apache/beam/pull/13175#discussion_r570716042", "createdAt": "2021-02-05T04:40:14Z", "author": {"login": "iindyk"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -327,27 +330,39 @@ class Globally(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzQyNzYwMw=="}, "originalCommit": {"oid": "8fff438793b622ac6ae2493d9fb24a581edc4264"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzIxNTk0NQ==", "bodyText": "SG, thank you.", "url": "https://github.com/apache/beam/pull/13175#discussion_r573215945", "createdAt": "2021-02-09T20:32:47Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -327,27 +330,39 @@ class Globally(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzQyNzYwMw=="}, "originalCommit": {"oid": "8fff438793b622ac6ae2493d9fb24a581edc4264"}, "originalPosition": 93}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU1NzkxNTg0OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/transforms/stats.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNlQyMjoyNToxNlrOIatSdQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wNVQwNDo0MDoyOFrOIgRvxg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDg3NTg5Mw==", "bodyText": "Please comment that in non-weighted case weights stores a single element - the weight of the buffer in the sense of the algorithm. In the generalized (weighted) case, it stores weights of individual elements.", "url": "https://github.com/apache/beam/pull/13175#discussion_r564875893", "createdAt": "2021-01-26T22:25:16Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -368,82 +383,126 @@ class PerKey(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate\n+        multiple elements at a time more efficiently.\n     \"\"\"\n-    def __init__(self, num_quantiles, key=None, reverse=False, weighted=False):\n+    def __init__(\n+        self,\n+        num_quantiles,\n+        key=None,\n+        reverse=False,\n+        weighted=False,\n+        batch_input=False):\n       self._num_quantiles = num_quantiles\n       self._key = key\n       self._reverse = reverse\n       self._weighted = weighted\n+      self._batch_input = batch_input\n \n     def expand(self, pcoll):\n       return pcoll | CombinePerKey(\n           ApproximateQuantilesCombineFn.create(\n               num_quantiles=self._num_quantiles,\n               key=self._key,\n               reverse=self._reverse,\n-              weighted=self._weighted))\n+              weighted=self._weighted,\n+              batch_input=self._batch_input))\n \n     def display_data(self):\n       return ApproximateQuantiles._display_data(\n           num_quantiles=self._num_quantiles,\n           key=self._key,\n           reverse=self._reverse,\n-          weighted=self._weighted)\n+          weighted=self._weighted,\n+          batch_input=self._batch_input)\n+\n+\n+class _QuantileSpec(object):\n+  \"\"\"Quantiles computation specifications.\"\"\"\n+  def __init__(self, buffer_size, num_buffers, weighted, key, reverse):\n+    # type: (int, int, bool, Any, bool) -> None\n+    self.buffer_size = buffer_size\n+    self.num_buffers = num_buffers\n+    self.weighted = weighted\n+    self.key = key\n+    self.reverse = reverse\n+\n+    # Used to sort tuples of values and weights.\n+    self.weighted_key = None if key is None else (lambda x: key(x[0]))\n+\n+    # Used to compare values.\n+    if reverse and key is None:\n+      self.less_than = lambda a, b: a > b\n+    elif reverse:\n+      self.less_than = lambda a, b: key(a) > key(b)\n+    elif key is None:\n+      self.less_than = lambda a, b: a < b\n+    else:\n+      self.less_than = lambda a, b: key(a) < key(b)\n+\n+  def get_argsort_key(self, elements):\n+    # type: (List) -> Any\n+\n+    \"\"\"Returns a key for sorting indices of elements by element's value.\"\"\"\n+    if self.key is None:\n+      return elements.__getitem__\n+    else:\n+      return lambda idx: self.key(elements[idx])\n+\n+  def __reduce__(self):\n+    return (\n+        self.__class__,\n+        (\n+            self.buffer_size,\n+            self.num_buffers,\n+            self.weighted,\n+            self.key,\n+            self.reverse))\n \n \n-class _QuantileBuffer(Generic[T]):\n+class _QuantileBuffer(object):\n   \"\"\"A single buffer in the sense of the referenced algorithm.\n   (see http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.6.6513&rep=rep1\n   &type=pdf and ApproximateQuantilesCombineFn for further information)\"\"\"\n-  def __init__(self, elements, weighted, level=0, weight=1):\n-    # type: (Sequence[T], bool, int, int) -> None\n-    # In case of weighted quantiles, elements are tuples of values and weights.\n+  def __init__(\n+      self, elements, weights, weighted, level=0, min_val=None, max_val=None):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8fff438793b622ac6ae2493d9fb24a581edc4264"}, "originalPosition": 225}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDcxNjEwMg==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/13175#discussion_r570716102", "createdAt": "2021-02-05T04:40:28Z", "author": {"login": "iindyk"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -368,82 +383,126 @@ class PerKey(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate\n+        multiple elements at a time more efficiently.\n     \"\"\"\n-    def __init__(self, num_quantiles, key=None, reverse=False, weighted=False):\n+    def __init__(\n+        self,\n+        num_quantiles,\n+        key=None,\n+        reverse=False,\n+        weighted=False,\n+        batch_input=False):\n       self._num_quantiles = num_quantiles\n       self._key = key\n       self._reverse = reverse\n       self._weighted = weighted\n+      self._batch_input = batch_input\n \n     def expand(self, pcoll):\n       return pcoll | CombinePerKey(\n           ApproximateQuantilesCombineFn.create(\n               num_quantiles=self._num_quantiles,\n               key=self._key,\n               reverse=self._reverse,\n-              weighted=self._weighted))\n+              weighted=self._weighted,\n+              batch_input=self._batch_input))\n \n     def display_data(self):\n       return ApproximateQuantiles._display_data(\n           num_quantiles=self._num_quantiles,\n           key=self._key,\n           reverse=self._reverse,\n-          weighted=self._weighted)\n+          weighted=self._weighted,\n+          batch_input=self._batch_input)\n+\n+\n+class _QuantileSpec(object):\n+  \"\"\"Quantiles computation specifications.\"\"\"\n+  def __init__(self, buffer_size, num_buffers, weighted, key, reverse):\n+    # type: (int, int, bool, Any, bool) -> None\n+    self.buffer_size = buffer_size\n+    self.num_buffers = num_buffers\n+    self.weighted = weighted\n+    self.key = key\n+    self.reverse = reverse\n+\n+    # Used to sort tuples of values and weights.\n+    self.weighted_key = None if key is None else (lambda x: key(x[0]))\n+\n+    # Used to compare values.\n+    if reverse and key is None:\n+      self.less_than = lambda a, b: a > b\n+    elif reverse:\n+      self.less_than = lambda a, b: key(a) > key(b)\n+    elif key is None:\n+      self.less_than = lambda a, b: a < b\n+    else:\n+      self.less_than = lambda a, b: key(a) < key(b)\n+\n+  def get_argsort_key(self, elements):\n+    # type: (List) -> Any\n+\n+    \"\"\"Returns a key for sorting indices of elements by element's value.\"\"\"\n+    if self.key is None:\n+      return elements.__getitem__\n+    else:\n+      return lambda idx: self.key(elements[idx])\n+\n+  def __reduce__(self):\n+    return (\n+        self.__class__,\n+        (\n+            self.buffer_size,\n+            self.num_buffers,\n+            self.weighted,\n+            self.key,\n+            self.reverse))\n \n \n-class _QuantileBuffer(Generic[T]):\n+class _QuantileBuffer(object):\n   \"\"\"A single buffer in the sense of the referenced algorithm.\n   (see http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.6.6513&rep=rep1\n   &type=pdf and ApproximateQuantilesCombineFn for further information)\"\"\"\n-  def __init__(self, elements, weighted, level=0, weight=1):\n-    # type: (Sequence[T], bool, int, int) -> None\n-    # In case of weighted quantiles, elements are tuples of values and weights.\n+  def __init__(\n+      self, elements, weights, weighted, level=0, min_val=None, max_val=None):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDg3NTg5Mw=="}, "originalCommit": {"oid": "8fff438793b622ac6ae2493d9fb24a581edc4264"}, "originalPosition": 225}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU1Nzk5NTc5OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/transforms/stats.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yNlQyMjo0OTo1NVrOIauDQw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wNVQwNDo1Mzo0M1rOIgR-Nw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDg4ODM4Nw==", "bodyText": "For my education, why was this required? Is there some internal state that gets in the way of pickling? Also, could you please add a comment?", "url": "https://github.com/apache/beam/pull/13175#discussion_r564888387", "createdAt": "2021-01-26T22:49:55Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -452,15 +511,236 @@ def __init__(self, buffer_size, num_buffers, unbuffered_elements, buffers):\n     # into new, full buffers and then take them into account when computing the\n     # final output.\n     self.unbuffered_elements = unbuffered_elements\n+    self.unbuffered_weights = unbuffered_weights\n+\n+  def __reduce__(self):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8fff438793b622ac6ae2493d9fb24a581edc4264"}, "originalPosition": 305}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDcxOTc5OQ==", "bodyText": "When Cythonization is enabled pickling fails without it. I can lookup the error description, if interested. Added a comment.", "url": "https://github.com/apache/beam/pull/13175#discussion_r570719799", "createdAt": "2021-02-05T04:53:43Z", "author": {"login": "iindyk"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -452,15 +511,236 @@ def __init__(self, buffer_size, num_buffers, unbuffered_elements, buffers):\n     # into new, full buffers and then take them into account when computing the\n     # final output.\n     self.unbuffered_elements = unbuffered_elements\n+    self.unbuffered_weights = unbuffered_weights\n+\n+  def __reduce__(self):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDg4ODM4Nw=="}, "originalCommit": {"oid": "8fff438793b622ac6ae2493d9fb24a581edc4264"}, "originalPosition": 305}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU1ODk5Mzk2OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/transforms/stats.py", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yN1QwNTozNDo1NlrOIa3R0g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0xOVQwMzowNTowM1rOIoE2UA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTAzOTU3MA==", "bodyText": "Nit: self.add_input = self._add_inputs may be easier to read.", "url": "https://github.com/apache/beam/pull/13175#discussion_r565039570", "createdAt": "2021-01-27T05:34:56Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -523,29 +805,25 @@ def __init__(\n       num_buffers,  # type: int\n       key=None,\n       reverse=False,\n-      weighted=False):\n-    def _comparator(a, b):\n-      if key:\n-        a, b = key(a), key(b)\n-\n-      retval = int(a > b) - int(a < b)\n-\n-      if reverse:\n-        return -retval\n-\n-      return retval\n-\n-    self._comparator = _comparator\n-\n+      weighted=False,\n+      batch_input=False):\n     self._num_quantiles = num_quantiles\n-    self._buffer_size = buffer_size\n-    self._num_buffers = num_buffers\n-    if weighted:\n-      self._key = (lambda x: x[0]) if key is None else (lambda x: key(x[0]))\n-    else:\n-      self._key = key\n-    self._reverse = reverse\n-    self._weighted = weighted\n+    self._spec = _QuantileSpec(buffer_size, num_buffers, weighted, key, reverse)\n+    self._batch_input = batch_input\n+    if self._batch_input:\n+      setattr(self, 'add_input', self._add_inputs)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8fff438793b622ac6ae2493d9fb24a581edc4264"}, "originalPosition": 587}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDcxNjEzNg==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/13175#discussion_r570716136", "createdAt": "2021-02-05T04:40:39Z", "author": {"login": "iindyk"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -523,29 +805,25 @@ def __init__(\n       num_buffers,  # type: int\n       key=None,\n       reverse=False,\n-      weighted=False):\n-    def _comparator(a, b):\n-      if key:\n-        a, b = key(a), key(b)\n-\n-      retval = int(a > b) - int(a < b)\n-\n-      if reverse:\n-        return -retval\n-\n-      return retval\n-\n-    self._comparator = _comparator\n-\n+      weighted=False,\n+      batch_input=False):\n     self._num_quantiles = num_quantiles\n-    self._buffer_size = buffer_size\n-    self._num_buffers = num_buffers\n-    if weighted:\n-      self._key = (lambda x: x[0]) if key is None else (lambda x: key(x[0]))\n-    else:\n-      self._key = key\n-    self._reverse = reverse\n-    self._weighted = weighted\n+    self._spec = _QuantileSpec(buffer_size, num_buffers, weighted, key, reverse)\n+    self._batch_input = batch_input\n+    if self._batch_input:\n+      setattr(self, 'add_input', self._add_inputs)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTAzOTU3MA=="}, "originalCommit": {"oid": "8fff438793b622ac6ae2493d9fb24a581edc4264"}, "originalPosition": 587}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3NDk3MjcwMQ==", "bodyText": "Just realized that the direct assignment causes a lint error:\n03:29:45 apache_beam/transforms/stats.py:837: error: Cannot assign to a method  [assignment]\n\nchanged back to setattr", "url": "https://github.com/apache/beam/pull/13175#discussion_r574972701", "createdAt": "2021-02-12T03:39:21Z", "author": {"login": "iindyk"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -523,29 +805,25 @@ def __init__(\n       num_buffers,  # type: int\n       key=None,\n       reverse=False,\n-      weighted=False):\n-    def _comparator(a, b):\n-      if key:\n-        a, b = key(a), key(b)\n-\n-      retval = int(a > b) - int(a < b)\n-\n-      if reverse:\n-        return -retval\n-\n-      return retval\n-\n-    self._comparator = _comparator\n-\n+      weighted=False,\n+      batch_input=False):\n     self._num_quantiles = num_quantiles\n-    self._buffer_size = buffer_size\n-    self._num_buffers = num_buffers\n-    if weighted:\n-      self._key = (lambda x: x[0]) if key is None else (lambda x: key(x[0]))\n-    else:\n-      self._key = key\n-    self._reverse = reverse\n-    self._weighted = weighted\n+    self._spec = _QuantileSpec(buffer_size, num_buffers, weighted, key, reverse)\n+    self._batch_input = batch_input\n+    if self._batch_input:\n+      setattr(self, 'add_input', self._add_inputs)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTAzOTU3MA=="}, "originalCommit": {"oid": "8fff438793b622ac6ae2493d9fb24a581edc4264"}, "originalPosition": 587}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3ODg5MzM5Mg==", "bodyText": "Thanks. Looks like this is python/mypy#2427.", "url": "https://github.com/apache/beam/pull/13175#discussion_r578893392", "createdAt": "2021-02-19T03:05:03Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -523,29 +805,25 @@ def __init__(\n       num_buffers,  # type: int\n       key=None,\n       reverse=False,\n-      weighted=False):\n-    def _comparator(a, b):\n-      if key:\n-        a, b = key(a), key(b)\n-\n-      retval = int(a > b) - int(a < b)\n-\n-      if reverse:\n-        return -retval\n-\n-      return retval\n-\n-    self._comparator = _comparator\n-\n+      weighted=False,\n+      batch_input=False):\n     self._num_quantiles = num_quantiles\n-    self._buffer_size = buffer_size\n-    self._num_buffers = num_buffers\n-    if weighted:\n-      self._key = (lambda x: x[0]) if key is None else (lambda x: key(x[0]))\n-    else:\n-      self._key = key\n-    self._reverse = reverse\n-    self._weighted = weighted\n+    self._spec = _QuantileSpec(buffer_size, num_buffers, weighted, key, reverse)\n+    self._batch_input = batch_input\n+    if self._batch_input:\n+      setattr(self, 'add_input', self._add_inputs)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTAzOTU3MA=="}, "originalCommit": {"oid": "8fff438793b622ac6ae2493d9fb24a581edc4264"}, "originalPosition": 587}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU2MjgzODQ1OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/transforms/stats.py", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yN1QyMToxOTo0MFrOIbb_Mw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0xMlQwMzoyNzoxMlrOIkVYjQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTY0MTAxMQ==", "bodyText": "I am not sure how k, b are computed here (see line 872) - it seems that b follows the experimental evaluation suggested in sect. 4.3 of the paper, which corresponds to a 'Munro-Paterson algorithm', while the experimental evaluation for the 'new' algorithm is covered in 4.5. Looking at the Table1, the 'new' algorithm has lower values of k, b, perhaps it is worth to reexamine this logic.", "url": "https://github.com/apache/beam/pull/13175#discussion_r565641011", "createdAt": "2021-01-27T21:19:40Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -582,6 +861,8 @@ def create(\n       weighted: (optional) if set to True, the combiner produces weighted\n         quantiles. The input elements are then expected to be tuples of values\n         with the corresponding weight.\n+      batch_input: (optional) if set to True, inputs are expected to be batches\n+        of elements.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8fff438793b622ac6ae2493d9fb24a581edc4264"}, "originalPosition": 618}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDcxNjMxMg==", "bodyText": "Yes, here the logic of the Munro-Paterson algorithm is used. Switching to the calculation from 4.5 would allow to reduce size of the (full) accumulator. But it's probably out of the scope of this PR, should I leave a TODO?", "url": "https://github.com/apache/beam/pull/13175#discussion_r570716312", "createdAt": "2021-02-05T04:41:17Z", "author": {"login": "iindyk"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -582,6 +861,8 @@ def create(\n       weighted: (optional) if set to True, the combiner produces weighted\n         quantiles. The input elements are then expected to be tuples of values\n         with the corresponding weight.\n+      batch_input: (optional) if set to True, inputs are expected to be batches\n+        of elements.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTY0MTAxMQ=="}, "originalCommit": {"oid": "8fff438793b622ac6ae2493d9fb24a581edc4264"}, "originalPosition": 618}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzIyMDYwOA==", "bodyText": "Agree that this is out of scope, SGTM to add a note in case someone happens to read through this..\nAFAICT this is not critical, and these numbers numbers are tied to MAX_ELEMENTS, which is somewhat arbitrary and not exposed to in the user. Perhaps if we decide to expose MAX_ELEMENTS as a transform param, we'd have to take a closer look at this.", "url": "https://github.com/apache/beam/pull/13175#discussion_r573220608", "createdAt": "2021-02-09T20:38:17Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -582,6 +861,8 @@ def create(\n       weighted: (optional) if set to True, the combiner produces weighted\n         quantiles. The input elements are then expected to be tuples of values\n         with the corresponding weight.\n+      batch_input: (optional) if set to True, inputs are expected to be batches\n+        of elements.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTY0MTAxMQ=="}, "originalCommit": {"oid": "8fff438793b622ac6ae2493d9fb24a581edc4264"}, "originalPosition": 618}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3NDk2OTk5Nw==", "bodyText": "Added a note.", "url": "https://github.com/apache/beam/pull/13175#discussion_r574969997", "createdAt": "2021-02-12T03:27:12Z", "author": {"login": "iindyk"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -582,6 +861,8 @@ def create(\n       weighted: (optional) if set to True, the combiner produces weighted\n         quantiles. The input elements are then expected to be tuples of values\n         with the corresponding weight.\n+      batch_input: (optional) if set to True, inputs are expected to be batches\n+        of elements.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTY0MTAxMQ=="}, "originalCommit": {"oid": "8fff438793b622ac6ae2493d9fb24a581edc4264"}, "originalPosition": 618}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU2Mjg3NjA5OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/transforms/stats.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yN1QyMToyOToxM1rOIbcWIg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0wNVQwNDo0MToyM1rOIgRwtA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTY0Njg4Mg==", "bodyText": "Would this hint work here ?\n# type: (List) -> Callable[[int], Any]", "url": "https://github.com/apache/beam/pull/13175#discussion_r565646882", "createdAt": "2021-01-27T21:29:13Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -368,82 +383,126 @@ class PerKey(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate\n+        multiple elements at a time more efficiently.\n     \"\"\"\n-    def __init__(self, num_quantiles, key=None, reverse=False, weighted=False):\n+    def __init__(\n+        self,\n+        num_quantiles,\n+        key=None,\n+        reverse=False,\n+        weighted=False,\n+        batch_input=False):\n       self._num_quantiles = num_quantiles\n       self._key = key\n       self._reverse = reverse\n       self._weighted = weighted\n+      self._batch_input = batch_input\n \n     def expand(self, pcoll):\n       return pcoll | CombinePerKey(\n           ApproximateQuantilesCombineFn.create(\n               num_quantiles=self._num_quantiles,\n               key=self._key,\n               reverse=self._reverse,\n-              weighted=self._weighted))\n+              weighted=self._weighted,\n+              batch_input=self._batch_input))\n \n     def display_data(self):\n       return ApproximateQuantiles._display_data(\n           num_quantiles=self._num_quantiles,\n           key=self._key,\n           reverse=self._reverse,\n-          weighted=self._weighted)\n+          weighted=self._weighted,\n+          batch_input=self._batch_input)\n+\n+\n+class _QuantileSpec(object):\n+  \"\"\"Quantiles computation specifications.\"\"\"\n+  def __init__(self, buffer_size, num_buffers, weighted, key, reverse):\n+    # type: (int, int, bool, Any, bool) -> None\n+    self.buffer_size = buffer_size\n+    self.num_buffers = num_buffers\n+    self.weighted = weighted\n+    self.key = key\n+    self.reverse = reverse\n+\n+    # Used to sort tuples of values and weights.\n+    self.weighted_key = None if key is None else (lambda x: key(x[0]))\n+\n+    # Used to compare values.\n+    if reverse and key is None:\n+      self.less_than = lambda a, b: a > b\n+    elif reverse:\n+      self.less_than = lambda a, b: key(a) > key(b)\n+    elif key is None:\n+      self.less_than = lambda a, b: a < b\n+    else:\n+      self.less_than = lambda a, b: key(a) < key(b)\n+\n+  def get_argsort_key(self, elements):\n+    # type: (List) -> Any", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8fff438793b622ac6ae2493d9fb24a581edc4264"}, "originalPosition": 197}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDcxNjM0MA==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/13175#discussion_r570716340", "createdAt": "2021-02-05T04:41:23Z", "author": {"login": "iindyk"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -368,82 +383,126 @@ class PerKey(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate\n+        multiple elements at a time more efficiently.\n     \"\"\"\n-    def __init__(self, num_quantiles, key=None, reverse=False, weighted=False):\n+    def __init__(\n+        self,\n+        num_quantiles,\n+        key=None,\n+        reverse=False,\n+        weighted=False,\n+        batch_input=False):\n       self._num_quantiles = num_quantiles\n       self._key = key\n       self._reverse = reverse\n       self._weighted = weighted\n+      self._batch_input = batch_input\n \n     def expand(self, pcoll):\n       return pcoll | CombinePerKey(\n           ApproximateQuantilesCombineFn.create(\n               num_quantiles=self._num_quantiles,\n               key=self._key,\n               reverse=self._reverse,\n-              weighted=self._weighted))\n+              weighted=self._weighted,\n+              batch_input=self._batch_input))\n \n     def display_data(self):\n       return ApproximateQuantiles._display_data(\n           num_quantiles=self._num_quantiles,\n           key=self._key,\n           reverse=self._reverse,\n-          weighted=self._weighted)\n+          weighted=self._weighted,\n+          batch_input=self._batch_input)\n+\n+\n+class _QuantileSpec(object):\n+  \"\"\"Quantiles computation specifications.\"\"\"\n+  def __init__(self, buffer_size, num_buffers, weighted, key, reverse):\n+    # type: (int, int, bool, Any, bool) -> None\n+    self.buffer_size = buffer_size\n+    self.num_buffers = num_buffers\n+    self.weighted = weighted\n+    self.key = key\n+    self.reverse = reverse\n+\n+    # Used to sort tuples of values and weights.\n+    self.weighted_key = None if key is None else (lambda x: key(x[0]))\n+\n+    # Used to compare values.\n+    if reverse and key is None:\n+      self.less_than = lambda a, b: a > b\n+    elif reverse:\n+      self.less_than = lambda a, b: key(a) > key(b)\n+    elif key is None:\n+      self.less_than = lambda a, b: a < b\n+    else:\n+      self.less_than = lambda a, b: key(a) < key(b)\n+\n+  def get_argsort_key(self, elements):\n+    # type: (List) -> Any", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTY0Njg4Mg=="}, "originalCommit": {"oid": "8fff438793b622ac6ae2493d9fb24a581edc4264"}, "originalPosition": 197}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU2Mjg4NDk0OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/transforms/stats.py", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yN1QyMTozMTo0NlrOIbcb0Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0xMlQwMzoyNzozNlrOIkVY3w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTY0ODMzNw==", "bodyText": "would it make sense to make _collapse, _interpolate, _offset be methods of _QuantileState class ? Would that impact cythonization/performance?", "url": "https://github.com/apache/beam/pull/13175#discussion_r565648337", "createdAt": "2021-01-27T21:31:46Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -636,132 +895,33 @@ def _offset(self, new_weight):\n       self._offset_jitter = 2 - self._offset_jitter\n       return (new_weight + self._offset_jitter) / 2\n \n-  def _collapse(self, buffers):\n-    # type: (Iterable[_QuantileBuffer[T]]) -> _QuantileBuffer[T]\n-    new_level = 0\n-    new_weight = 0\n-    for buffer_elem in buffers:\n-      # As presented in the paper, there should always be at least two\n-      # buffers of the same (minimal) level to collapse, but it is possible\n-      # to violate this condition when combining buffers from independently\n-      # computed shards.  If they differ we take the max.\n-      new_level = max([new_level, buffer_elem.level + 1])\n-      new_weight = new_weight + buffer_elem.weight\n-    if self._weighted:\n-      step = new_weight / (self._buffer_size - 1)\n-      offset = new_weight / (2 * self._buffer_size)\n-    else:\n-      step = new_weight\n-      offset = self._offset(new_weight)\n-    new_elements = self._interpolate(buffers, self._buffer_size, step, offset)\n-    return _QuantileBuffer(new_elements, self._weighted, new_level, new_weight)\n-\n-  def _collapse_if_needed(self, qs):\n-    # type: (_QuantileState) -> None\n-    while len(qs.buffers) > self._num_buffers:\n-      to_collapse = []\n-      to_collapse.append(heapq.heappop(qs.buffers))\n-      to_collapse.append(heapq.heappop(qs.buffers))\n-      min_level = to_collapse[1].level\n-\n-      while len(qs.buffers) > 0 and qs.buffers[0].level == min_level:\n-        to_collapse.append(heapq.heappop(qs.buffers))\n-\n-      heapq.heappush(qs.buffers, self._collapse(to_collapse))\n-\n-  def _interpolate(self, i_buffers, count, step, offset):\n-    \"\"\"\n-    Emulates taking the ordered union of all elements in buffers, repeated\n-    according to their weight, and picking out the (k * step + offset)-th\n-    elements of this list for `0 <= k < count`.\n-    \"\"\"\n-\n-    iterators = []\n-    new_elements = []\n-    compare_key = self._key\n-    if self._key and not self._weighted:\n-      compare_key = lambda x: self._key(x[0])\n-    for buffer_elem in i_buffers:\n-      iterators.append(buffer_elem.sized_iterator())\n-\n-    # Python 3 `heapq.merge` support key comparison and returns an iterator and\n-    # does not pull the data into memory all at once. Python 2 does not\n-    # support comparison on its `heapq.merge` api, so we use the itertools\n-    # which takes the `key` function for comparison and creates an iterator\n-    # from it.\n-    if sys.version_info[0] < 3:\n-      sorted_elem = iter(\n-          sorted(\n-              itertools.chain.from_iterable(iterators),\n-              key=compare_key,\n-              reverse=self._reverse))\n-    else:\n-      sorted_elem = heapq.merge(\n-          *iterators, key=compare_key, reverse=self._reverse)\n-\n-    weighted_element = next(sorted_elem)\n-    current = weighted_element[1]\n-    j = 0\n-    previous = 0\n-    while j < count:\n-      target = j * step + offset\n-      j = j + 1\n-      try:\n-        while current <= target:\n-          weighted_element = next(sorted_elem)\n-          current = current + weighted_element[1]\n-      except StopIteration:\n-        pass\n-      if self._weighted:\n-        new_elements.append((weighted_element[0], current - previous))\n-        previous = current\n-      else:\n-        new_elements.append(weighted_element[0])\n-    return new_elements\n-\n   # TODO(BEAM-7746): Signature incompatible with supertype\n   def create_accumulator(self):  # type: ignore[override]\n-    # type: () -> _QuantileState[T]\n+    # type: () -> _QuantileState\n     self._qs = _QuantileState(\n-        buffer_size=self._buffer_size,\n-        num_buffers=self._num_buffers,\n         unbuffered_elements=[],\n-        buffers=[])\n+        unbuffered_weights=[],\n+        buffers=[],\n+        spec=self._spec)\n     return self._qs\n \n   def add_input(self, quantile_state, element):\n     \"\"\"\n     Add a new element to the collection being summarized by quantile state.\n     \"\"\"\n-    value = element[0] if self._weighted else element\n-    if quantile_state.is_empty():\n-      quantile_state.min_val = quantile_state.max_val = value\n-    elif self._comparator(value, quantile_state.min_val) < 0:\n-      quantile_state.min_val = value\n-    elif self._comparator(value, quantile_state.max_val) > 0:\n-      quantile_state.max_val = value\n-    self._add_unbuffered(quantile_state, elements=[element])\n+    quantile_state.add_unbuffered([element], self._offset)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8fff438793b622ac6ae2493d9fb24a581edc4264"}, "originalPosition": 768}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDcxNjQ3Ng==", "bodyText": "I don't think that this may cause any problems with cythonization or performance. They will be static methods though, so the only difference is the namespace and neither of them deals with _QuantileState objects. But I don't have any strong preference, WDYT?", "url": "https://github.com/apache/beam/pull/13175#discussion_r570716476", "createdAt": "2021-02-05T04:42:00Z", "author": {"login": "iindyk"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -636,132 +895,33 @@ def _offset(self, new_weight):\n       self._offset_jitter = 2 - self._offset_jitter\n       return (new_weight + self._offset_jitter) / 2\n \n-  def _collapse(self, buffers):\n-    # type: (Iterable[_QuantileBuffer[T]]) -> _QuantileBuffer[T]\n-    new_level = 0\n-    new_weight = 0\n-    for buffer_elem in buffers:\n-      # As presented in the paper, there should always be at least two\n-      # buffers of the same (minimal) level to collapse, but it is possible\n-      # to violate this condition when combining buffers from independently\n-      # computed shards.  If they differ we take the max.\n-      new_level = max([new_level, buffer_elem.level + 1])\n-      new_weight = new_weight + buffer_elem.weight\n-    if self._weighted:\n-      step = new_weight / (self._buffer_size - 1)\n-      offset = new_weight / (2 * self._buffer_size)\n-    else:\n-      step = new_weight\n-      offset = self._offset(new_weight)\n-    new_elements = self._interpolate(buffers, self._buffer_size, step, offset)\n-    return _QuantileBuffer(new_elements, self._weighted, new_level, new_weight)\n-\n-  def _collapse_if_needed(self, qs):\n-    # type: (_QuantileState) -> None\n-    while len(qs.buffers) > self._num_buffers:\n-      to_collapse = []\n-      to_collapse.append(heapq.heappop(qs.buffers))\n-      to_collapse.append(heapq.heappop(qs.buffers))\n-      min_level = to_collapse[1].level\n-\n-      while len(qs.buffers) > 0 and qs.buffers[0].level == min_level:\n-        to_collapse.append(heapq.heappop(qs.buffers))\n-\n-      heapq.heappush(qs.buffers, self._collapse(to_collapse))\n-\n-  def _interpolate(self, i_buffers, count, step, offset):\n-    \"\"\"\n-    Emulates taking the ordered union of all elements in buffers, repeated\n-    according to their weight, and picking out the (k * step + offset)-th\n-    elements of this list for `0 <= k < count`.\n-    \"\"\"\n-\n-    iterators = []\n-    new_elements = []\n-    compare_key = self._key\n-    if self._key and not self._weighted:\n-      compare_key = lambda x: self._key(x[0])\n-    for buffer_elem in i_buffers:\n-      iterators.append(buffer_elem.sized_iterator())\n-\n-    # Python 3 `heapq.merge` support key comparison and returns an iterator and\n-    # does not pull the data into memory all at once. Python 2 does not\n-    # support comparison on its `heapq.merge` api, so we use the itertools\n-    # which takes the `key` function for comparison and creates an iterator\n-    # from it.\n-    if sys.version_info[0] < 3:\n-      sorted_elem = iter(\n-          sorted(\n-              itertools.chain.from_iterable(iterators),\n-              key=compare_key,\n-              reverse=self._reverse))\n-    else:\n-      sorted_elem = heapq.merge(\n-          *iterators, key=compare_key, reverse=self._reverse)\n-\n-    weighted_element = next(sorted_elem)\n-    current = weighted_element[1]\n-    j = 0\n-    previous = 0\n-    while j < count:\n-      target = j * step + offset\n-      j = j + 1\n-      try:\n-        while current <= target:\n-          weighted_element = next(sorted_elem)\n-          current = current + weighted_element[1]\n-      except StopIteration:\n-        pass\n-      if self._weighted:\n-        new_elements.append((weighted_element[0], current - previous))\n-        previous = current\n-      else:\n-        new_elements.append(weighted_element[0])\n-    return new_elements\n-\n   # TODO(BEAM-7746): Signature incompatible with supertype\n   def create_accumulator(self):  # type: ignore[override]\n-    # type: () -> _QuantileState[T]\n+    # type: () -> _QuantileState\n     self._qs = _QuantileState(\n-        buffer_size=self._buffer_size,\n-        num_buffers=self._num_buffers,\n         unbuffered_elements=[],\n-        buffers=[])\n+        unbuffered_weights=[],\n+        buffers=[],\n+        spec=self._spec)\n     return self._qs\n \n   def add_input(self, quantile_state, element):\n     \"\"\"\n     Add a new element to the collection being summarized by quantile state.\n     \"\"\"\n-    value = element[0] if self._weighted else element\n-    if quantile_state.is_empty():\n-      quantile_state.min_val = quantile_state.max_val = value\n-    elif self._comparator(value, quantile_state.min_val) < 0:\n-      quantile_state.min_val = value\n-    elif self._comparator(value, quantile_state.max_val) > 0:\n-      quantile_state.max_val = value\n-    self._add_unbuffered(quantile_state, elements=[element])\n+    quantile_state.add_unbuffered([element], self._offset)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTY0ODMzNw=="}, "originalCommit": {"oid": "8fff438793b622ac6ae2493d9fb24a581edc4264"}, "originalPosition": 768}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzIzNDM3Mw==", "bodyText": "There is no big difference if they are static, but I thought that if they were instance methods you perhaps you wouldn't have to pass spec or offset_fn. No strong opinion, feel free to leave as is.", "url": "https://github.com/apache/beam/pull/13175#discussion_r573234373", "createdAt": "2021-02-09T20:56:33Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -636,132 +895,33 @@ def _offset(self, new_weight):\n       self._offset_jitter = 2 - self._offset_jitter\n       return (new_weight + self._offset_jitter) / 2\n \n-  def _collapse(self, buffers):\n-    # type: (Iterable[_QuantileBuffer[T]]) -> _QuantileBuffer[T]\n-    new_level = 0\n-    new_weight = 0\n-    for buffer_elem in buffers:\n-      # As presented in the paper, there should always be at least two\n-      # buffers of the same (minimal) level to collapse, but it is possible\n-      # to violate this condition when combining buffers from independently\n-      # computed shards.  If they differ we take the max.\n-      new_level = max([new_level, buffer_elem.level + 1])\n-      new_weight = new_weight + buffer_elem.weight\n-    if self._weighted:\n-      step = new_weight / (self._buffer_size - 1)\n-      offset = new_weight / (2 * self._buffer_size)\n-    else:\n-      step = new_weight\n-      offset = self._offset(new_weight)\n-    new_elements = self._interpolate(buffers, self._buffer_size, step, offset)\n-    return _QuantileBuffer(new_elements, self._weighted, new_level, new_weight)\n-\n-  def _collapse_if_needed(self, qs):\n-    # type: (_QuantileState) -> None\n-    while len(qs.buffers) > self._num_buffers:\n-      to_collapse = []\n-      to_collapse.append(heapq.heappop(qs.buffers))\n-      to_collapse.append(heapq.heappop(qs.buffers))\n-      min_level = to_collapse[1].level\n-\n-      while len(qs.buffers) > 0 and qs.buffers[0].level == min_level:\n-        to_collapse.append(heapq.heappop(qs.buffers))\n-\n-      heapq.heappush(qs.buffers, self._collapse(to_collapse))\n-\n-  def _interpolate(self, i_buffers, count, step, offset):\n-    \"\"\"\n-    Emulates taking the ordered union of all elements in buffers, repeated\n-    according to their weight, and picking out the (k * step + offset)-th\n-    elements of this list for `0 <= k < count`.\n-    \"\"\"\n-\n-    iterators = []\n-    new_elements = []\n-    compare_key = self._key\n-    if self._key and not self._weighted:\n-      compare_key = lambda x: self._key(x[0])\n-    for buffer_elem in i_buffers:\n-      iterators.append(buffer_elem.sized_iterator())\n-\n-    # Python 3 `heapq.merge` support key comparison and returns an iterator and\n-    # does not pull the data into memory all at once. Python 2 does not\n-    # support comparison on its `heapq.merge` api, so we use the itertools\n-    # which takes the `key` function for comparison and creates an iterator\n-    # from it.\n-    if sys.version_info[0] < 3:\n-      sorted_elem = iter(\n-          sorted(\n-              itertools.chain.from_iterable(iterators),\n-              key=compare_key,\n-              reverse=self._reverse))\n-    else:\n-      sorted_elem = heapq.merge(\n-          *iterators, key=compare_key, reverse=self._reverse)\n-\n-    weighted_element = next(sorted_elem)\n-    current = weighted_element[1]\n-    j = 0\n-    previous = 0\n-    while j < count:\n-      target = j * step + offset\n-      j = j + 1\n-      try:\n-        while current <= target:\n-          weighted_element = next(sorted_elem)\n-          current = current + weighted_element[1]\n-      except StopIteration:\n-        pass\n-      if self._weighted:\n-        new_elements.append((weighted_element[0], current - previous))\n-        previous = current\n-      else:\n-        new_elements.append(weighted_element[0])\n-    return new_elements\n-\n   # TODO(BEAM-7746): Signature incompatible with supertype\n   def create_accumulator(self):  # type: ignore[override]\n-    # type: () -> _QuantileState[T]\n+    # type: () -> _QuantileState\n     self._qs = _QuantileState(\n-        buffer_size=self._buffer_size,\n-        num_buffers=self._num_buffers,\n         unbuffered_elements=[],\n-        buffers=[])\n+        unbuffered_weights=[],\n+        buffers=[],\n+        spec=self._spec)\n     return self._qs\n \n   def add_input(self, quantile_state, element):\n     \"\"\"\n     Add a new element to the collection being summarized by quantile state.\n     \"\"\"\n-    value = element[0] if self._weighted else element\n-    if quantile_state.is_empty():\n-      quantile_state.min_val = quantile_state.max_val = value\n-    elif self._comparator(value, quantile_state.min_val) < 0:\n-      quantile_state.min_val = value\n-    elif self._comparator(value, quantile_state.max_val) > 0:\n-      quantile_state.max_val = value\n-    self._add_unbuffered(quantile_state, elements=[element])\n+    quantile_state.add_unbuffered([element], self._offset)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTY0ODMzNw=="}, "originalCommit": {"oid": "8fff438793b622ac6ae2493d9fb24a581edc4264"}, "originalPosition": 768}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3NDk3MDA3OQ==", "bodyText": "sg", "url": "https://github.com/apache/beam/pull/13175#discussion_r574970079", "createdAt": "2021-02-12T03:27:36Z", "author": {"login": "iindyk"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -636,132 +895,33 @@ def _offset(self, new_weight):\n       self._offset_jitter = 2 - self._offset_jitter\n       return (new_weight + self._offset_jitter) / 2\n \n-  def _collapse(self, buffers):\n-    # type: (Iterable[_QuantileBuffer[T]]) -> _QuantileBuffer[T]\n-    new_level = 0\n-    new_weight = 0\n-    for buffer_elem in buffers:\n-      # As presented in the paper, there should always be at least two\n-      # buffers of the same (minimal) level to collapse, but it is possible\n-      # to violate this condition when combining buffers from independently\n-      # computed shards.  If they differ we take the max.\n-      new_level = max([new_level, buffer_elem.level + 1])\n-      new_weight = new_weight + buffer_elem.weight\n-    if self._weighted:\n-      step = new_weight / (self._buffer_size - 1)\n-      offset = new_weight / (2 * self._buffer_size)\n-    else:\n-      step = new_weight\n-      offset = self._offset(new_weight)\n-    new_elements = self._interpolate(buffers, self._buffer_size, step, offset)\n-    return _QuantileBuffer(new_elements, self._weighted, new_level, new_weight)\n-\n-  def _collapse_if_needed(self, qs):\n-    # type: (_QuantileState) -> None\n-    while len(qs.buffers) > self._num_buffers:\n-      to_collapse = []\n-      to_collapse.append(heapq.heappop(qs.buffers))\n-      to_collapse.append(heapq.heappop(qs.buffers))\n-      min_level = to_collapse[1].level\n-\n-      while len(qs.buffers) > 0 and qs.buffers[0].level == min_level:\n-        to_collapse.append(heapq.heappop(qs.buffers))\n-\n-      heapq.heappush(qs.buffers, self._collapse(to_collapse))\n-\n-  def _interpolate(self, i_buffers, count, step, offset):\n-    \"\"\"\n-    Emulates taking the ordered union of all elements in buffers, repeated\n-    according to their weight, and picking out the (k * step + offset)-th\n-    elements of this list for `0 <= k < count`.\n-    \"\"\"\n-\n-    iterators = []\n-    new_elements = []\n-    compare_key = self._key\n-    if self._key and not self._weighted:\n-      compare_key = lambda x: self._key(x[0])\n-    for buffer_elem in i_buffers:\n-      iterators.append(buffer_elem.sized_iterator())\n-\n-    # Python 3 `heapq.merge` support key comparison and returns an iterator and\n-    # does not pull the data into memory all at once. Python 2 does not\n-    # support comparison on its `heapq.merge` api, so we use the itertools\n-    # which takes the `key` function for comparison and creates an iterator\n-    # from it.\n-    if sys.version_info[0] < 3:\n-      sorted_elem = iter(\n-          sorted(\n-              itertools.chain.from_iterable(iterators),\n-              key=compare_key,\n-              reverse=self._reverse))\n-    else:\n-      sorted_elem = heapq.merge(\n-          *iterators, key=compare_key, reverse=self._reverse)\n-\n-    weighted_element = next(sorted_elem)\n-    current = weighted_element[1]\n-    j = 0\n-    previous = 0\n-    while j < count:\n-      target = j * step + offset\n-      j = j + 1\n-      try:\n-        while current <= target:\n-          weighted_element = next(sorted_elem)\n-          current = current + weighted_element[1]\n-      except StopIteration:\n-        pass\n-      if self._weighted:\n-        new_elements.append((weighted_element[0], current - previous))\n-        previous = current\n-      else:\n-        new_elements.append(weighted_element[0])\n-    return new_elements\n-\n   # TODO(BEAM-7746): Signature incompatible with supertype\n   def create_accumulator(self):  # type: ignore[override]\n-    # type: () -> _QuantileState[T]\n+    # type: () -> _QuantileState\n     self._qs = _QuantileState(\n-        buffer_size=self._buffer_size,\n-        num_buffers=self._num_buffers,\n         unbuffered_elements=[],\n-        buffers=[])\n+        unbuffered_weights=[],\n+        buffers=[],\n+        spec=self._spec)\n     return self._qs\n \n   def add_input(self, quantile_state, element):\n     \"\"\"\n     Add a new element to the collection being summarized by quantile state.\n     \"\"\"\n-    value = element[0] if self._weighted else element\n-    if quantile_state.is_empty():\n-      quantile_state.min_val = quantile_state.max_val = value\n-    elif self._comparator(value, quantile_state.min_val) < 0:\n-      quantile_state.min_val = value\n-    elif self._comparator(value, quantile_state.max_val) > 0:\n-      quantile_state.max_val = value\n-    self._add_unbuffered(quantile_state, elements=[element])\n+    quantile_state.add_unbuffered([element], self._offset)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTY0ODMzNw=="}, "originalCommit": {"oid": "8fff438793b622ac6ae2493d9fb24a581edc4264"}, "originalPosition": 768}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzU2Mjg5NzM5OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/transforms/stats_test.py", "isResolved": false, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yN1QyMTozNToyNVrOIbcjnQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMi0xOVQwMzowNzoxOVrOIoE6qg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTY1MDMzMw==", "bodyText": "I have some concerns about test coverage of  ApproximateQuantiles.\n\nDo any of the tests exercise merging of accumulators?\nDo any of the tests exercise collapsing of multiple buffers, including buffers with same & different weights?", "url": "https://github.com/apache/beam/pull/13175#discussion_r565650333", "createdAt": "2021-01-27T21:35:25Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/transforms/stats_test.py", "diffHunk": "@@ -482,13 +482,74 @@ def test_alternate_quantiles(self):\n           equal_to([[\"ccccc\", \"aaa\", \"b\"]]),\n           label='checkWithKeyAndReversed')\n \n+  def test_batched_quantiles(self):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8fff438793b622ac6ae2493d9fb24a581edc4264"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTY1Mjg5NA==", "bodyText": "We should have codecov working again, but somehow retesting didn't trigger it. I think if you add commits to this branch or repush it, codecov will run and may give some signals re: test coverage.", "url": "https://github.com/apache/beam/pull/13175#discussion_r565652894", "createdAt": "2021-01-27T21:39:42Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/transforms/stats_test.py", "diffHunk": "@@ -482,13 +482,74 @@ def test_alternate_quantiles(self):\n           equal_to([[\"ccccc\", \"aaa\", \"b\"]]),\n           label='checkWithKeyAndReversed')\n \n+  def test_batched_quantiles(self):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTY1MDMzMw=="}, "originalCommit": {"oid": "8fff438793b622ac6ae2493d9fb24a581edc4264"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MDcxNjY3OQ==", "bodyText": "I think the tests use DirectRunner, so probably no.\nThe approximation will be properly tested only if either the number of inputs will be large with default settings, or max_num_elements and epsilon will be set to extremely low and large values, respectively. I tested approximation with large number of inputs and FlumeCppRunner during development, but it took some time to complete, so it's probably not suitable for continuous testing. It might make sense for me to initialize the CombineFn with the extreme values and test add_input, merge_accumulators and extract_output directly, WDYT?", "url": "https://github.com/apache/beam/pull/13175#discussion_r570716679", "createdAt": "2021-02-05T04:42:46Z", "author": {"login": "iindyk"}, "path": "sdks/python/apache_beam/transforms/stats_test.py", "diffHunk": "@@ -482,13 +482,74 @@ def test_alternate_quantiles(self):\n           equal_to([[\"ccccc\", \"aaa\", \"b\"]]),\n           label='checkWithKeyAndReversed')\n \n+  def test_batched_quantiles(self):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTY1MDMzMw=="}, "originalCommit": {"oid": "8fff438793b622ac6ae2493d9fb24a581edc4264"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3MzIzNTY0NA==", "bodyText": "Given that a typo that creeps in might not be discovered until the code runs on a sufficiently large input, I'd be more comfortable merging this if we added targeted unit tests just for methods in question, exercising the logic that is not exercised in direct runner test due to small size/undeterminism.", "url": "https://github.com/apache/beam/pull/13175#discussion_r573235644", "createdAt": "2021-02-09T20:58:42Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/transforms/stats_test.py", "diffHunk": "@@ -482,13 +482,74 @@ def test_alternate_quantiles(self):\n           equal_to([[\"ccccc\", \"aaa\", \"b\"]]),\n           label='checkWithKeyAndReversed')\n \n+  def test_batched_quantiles(self):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTY1MDMzMw=="}, "originalCommit": {"oid": "8fff438793b622ac6ae2493d9fb24a581edc4264"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3NDk3MDc2Mg==", "bodyText": "Makes sense. I added a test that creates a combinefn with extremely small max_num_elements and manually split the data to a bunch of accumulators which are then merged. Also, the small max_num_elements will ensure that buffer collapsing and interpolation is exercised.", "url": "https://github.com/apache/beam/pull/13175#discussion_r574970762", "createdAt": "2021-02-12T03:30:28Z", "author": {"login": "iindyk"}, "path": "sdks/python/apache_beam/transforms/stats_test.py", "diffHunk": "@@ -482,13 +482,74 @@ def test_alternate_quantiles(self):\n           equal_to([[\"ccccc\", \"aaa\", \"b\"]]),\n           label='checkWithKeyAndReversed')\n \n+  def test_batched_quantiles(self):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTY1MDMzMw=="}, "originalCommit": {"oid": "8fff438793b622ac6ae2493d9fb24a581edc4264"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU3ODg5NDUwNg==", "bodyText": "Thank you, much appreciated!", "url": "https://github.com/apache/beam/pull/13175#discussion_r578894506", "createdAt": "2021-02-19T03:07:19Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/transforms/stats_test.py", "diffHunk": "@@ -482,13 +482,74 @@ def test_alternate_quantiles(self):\n           equal_to([[\"ccccc\", \"aaa\", \"b\"]]),\n           label='checkWithKeyAndReversed')\n \n+  def test_batched_quantiles(self):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTY1MDMzMw=="}, "originalCommit": {"oid": "8fff438793b622ac6ae2493d9fb24a581edc4264"}, "originalPosition": 4}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2836, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}