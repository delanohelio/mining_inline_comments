{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTIxMTkwODI4", "number": 13350, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNlQxODozMjo0OFrOE5nz1A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNlQxODozNTo1NVrOE5n4Hg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI4ODU2NTMyOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/mongodbio.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNlQxODozMjo0OFrOH0MFyQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QyMjoxMjowNFrOH1NloQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQ4NjA4OQ==", "bodyText": "The split function will likely be called recursively for dynamic rebalancing, so for a range with start_pos and end_pos, it can be further split upon backend request, so it might not be reasonable to always use the total collection size divided by desired_chunk_size to calculate the bucket count. Is it possible to only get the buckets within the give _id range? and we can probably use an average document size times the number of documents to calculate the size of the range being split.", "url": "https://github.com/apache/beam/pull/13350#discussion_r524486089", "createdAt": "2020-11-16T18:32:48Z", "author": {"login": "y1chi"}, "path": "sdks/python/apache_beam/io/mongodbio.py", "diffHunk": "@@ -241,6 +275,27 @@ def _get_split_keys(self, desired_chunk_size_in_mb, start_pos, end_pos):\n               max={'_id': end_pos},\n               maxChunkSize=desired_chunk_size_in_mb)['splitKeys'])\n \n+  def _get_buckets(self, desired_chunk_size, start_pos, end_pos):\n+    if start_pos >= end_pos:\n+      # single document not splittable\n+      return []\n+    size = self.estimate_size()\n+    bucket_count = size // desired_chunk_size", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "94a85339c7008aa7676bc2d9872705309744220c"}, "originalPosition": 175}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU1OTIwMQ==", "bodyText": "Thanks, @y1chi!\nI will look closer how it works in Java sdk and will try to filter by _id ranges.", "url": "https://github.com/apache/beam/pull/13350#discussion_r525559201", "createdAt": "2020-11-17T22:12:04Z", "author": {"login": "nikie"}, "path": "sdks/python/apache_beam/io/mongodbio.py", "diffHunk": "@@ -241,6 +275,27 @@ def _get_split_keys(self, desired_chunk_size_in_mb, start_pos, end_pos):\n               max={'_id': end_pos},\n               maxChunkSize=desired_chunk_size_in_mb)['splitKeys'])\n \n+  def _get_buckets(self, desired_chunk_size, start_pos, end_pos):\n+    if start_pos >= end_pos:\n+      # single document not splittable\n+      return []\n+    size = self.estimate_size()\n+    bucket_count = size // desired_chunk_size", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQ4NjA4OQ=="}, "originalCommit": {"oid": "94a85339c7008aa7676bc2d9872705309744220c"}, "originalPosition": 175}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI4ODU3NjMwOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/mongodbio.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNlQxODozNTo1NVrOH0MM3g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMlQxOTozMjoxMVrOH36jpw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQ4NzkwMg==", "bodyText": "the return buckets should guarantee the _id range is start_pos and end_pos otherwise same document could be read multiple times.", "url": "https://github.com/apache/beam/pull/13350#discussion_r524487902", "createdAt": "2020-11-16T18:35:55Z", "author": {"login": "y1chi"}, "path": "sdks/python/apache_beam/io/mongodbio.py", "diffHunk": "@@ -241,6 +275,27 @@ def _get_split_keys(self, desired_chunk_size_in_mb, start_pos, end_pos):\n               max={'_id': end_pos},\n               maxChunkSize=desired_chunk_size_in_mb)['splitKeys'])\n \n+  def _get_buckets(self, desired_chunk_size, start_pos, end_pos):\n+    if start_pos >= end_pos:\n+      # single document not splittable\n+      return []\n+    size = self.estimate_size()\n+    bucket_count = size // desired_chunk_size\n+    if size % desired_chunk_size != 0:\n+      bucket_count += 1\n+    with beam.io.mongodbio.MongoClient(self.uri, **self.spec) as client:\n+      buckets = list(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "94a85339c7008aa7676bc2d9872705309744220c"}, "originalPosition": 179}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODM5MzEyNw==", "bodyText": "Fixed - return buckets cover all the requested range.", "url": "https://github.com/apache/beam/pull/13350#discussion_r528393127", "createdAt": "2020-11-22T19:32:11Z", "author": {"login": "nikie"}, "path": "sdks/python/apache_beam/io/mongodbio.py", "diffHunk": "@@ -241,6 +275,27 @@ def _get_split_keys(self, desired_chunk_size_in_mb, start_pos, end_pos):\n               max={'_id': end_pos},\n               maxChunkSize=desired_chunk_size_in_mb)['splitKeys'])\n \n+  def _get_buckets(self, desired_chunk_size, start_pos, end_pos):\n+    if start_pos >= end_pos:\n+      # single document not splittable\n+      return []\n+    size = self.estimate_size()\n+    bucket_count = size // desired_chunk_size\n+    if size % desired_chunk_size != 0:\n+      bucket_count += 1\n+    with beam.io.mongodbio.MongoClient(self.uri, **self.spec) as client:\n+      buckets = list(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQ4NzkwMg=="}, "originalCommit": {"oid": "94a85339c7008aa7676bc2d9872705309744220c"}, "originalPosition": 179}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2813, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}