{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDUwMzg3ODk0", "number": 12280, "title": "Improving BQ IO documentation", "bodyText": "Please add a meaningful description for your change here\n\nThank you for your contribution! Follow this checklist to help us incorporate your contribution quickly and easily:\n\n Choose reviewer(s) and mention them in a comment (R: @username).\n Format the pull request title like [BEAM-XXX] Fixes bug in ApproximateQuantiles, where you replace BEAM-XXX with the appropriate JIRA issue, if applicable. This will automatically link the pull request to the issue.\n Update CHANGES.md with noteworthy changes.\n If this contribution is large, please file an Apache Individual Contributor License Agreement.\n\nSee the Contributor Guide for more tips on how to make review process smoother.\nPost-Commit Tests Status (on master branch)\n\n\n\nLang\nSDK\nDataflow\nFlink\nSamza\nSpark\nTwister2\n\n\n\n\nGo\n\n---\n\n---\n\n---\n\n\nJava\n\n\n\n\n\n\n\n\nPython\n\n\n\n---\n\n---\n\n\nXLang\n\n---\n\n---\n\n---\n\n\n\nPre-Commit Tests Status (on master branch)\n\n\n\n---\nJava\nPython\nGo\nWebsite\n\n\n\n\nNon-portable\n\n\n\n\n\n\nPortable\n---\n\n---\n---\n\n\n\nSee .test-infra/jenkins/README for trigger phrase, status and link of all Jenkins jobs.", "createdAt": "2020-07-16T17:56:53Z", "url": "https://github.com/apache/beam/pull/12280", "merged": true, "mergeCommit": {"oid": "19f12201f3970f19eb0180f8a46c2b920b8d5bce"}, "closed": true, "closedAt": "2020-07-23T03:59:01Z", "author": {"login": "pabloem"}, "timelineItems": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc1jFhxgH2gAyNDUwMzg3ODk0OmI5Mzc3MmE1MjUyODhkMjhjZGViMThjMWU1ZTg2NGZlOTg1ZjMyN2Q=", "endCursor": "Y3Vyc29yOnYyOpPPAAABc3iC1TgH2gAyNDUwMzg3ODk0OjQyZTgyOTI0YzQ3YTYyZTdiMDU1Nzk5Y2Q5NWRiZDc2N2Q0OTc3ZmE=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "b93772a525288d28cdeb18c1e5e864fe985f327d", "author": {"user": {"login": "pabloem", "name": "Pablo"}}, "url": "https://github.com/apache/beam/commit/b93772a525288d28cdeb18c1e5e864fe985f327d", "committedDate": "2020-07-16T17:56:47Z", "message": "Improving BQ IO documentation"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUzNzA1MTEy", "url": "https://github.com/apache/beam/pull/12280#pullrequestreview-453705112", "createdAt": "2020-07-22T21:39:52Z", "commit": {"oid": "b93772a525288d28cdeb18c1e5e864fe985f327d"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMTozOTo1MlrOG11NkA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMTozOTo1MlrOG11NkA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA5OTUzNg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            This is due to the fact that ReadFromBigQuery uses Avro expors by default.\n          \n          \n            \n            This is due to the fact that ReadFromBigQuery uses Avro exports by default.", "url": "https://github.com/apache/beam/pull/12280#discussion_r459099536", "createdAt": "2020-07-22T21:39:52Z", "author": {"login": "udim"}, "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -65,18 +65,19 @@\n table. If specified, the result obtained by executing the specified query will\n be used as the data of the input transform.::\n \n-  query_results = pipeline | beam.io.Read(beam.io.BigQuerySource(\n-      query='SELECT year, mean_temp FROM samples.weather_stations'))\n+  query_results = pipeline | beam.io.gcp.bigquery.ReadFromBigQuery(\n+      query='SELECT year, mean_temp FROM samples.weather_stations')\n \n When creating a BigQuery input transform, users should provide either a query\n or a table. Pipeline construction will fail with a validation error if neither\n or both are specified.\n \n-When reading from BigQuery using `BigQuerySource`, bytes are returned as\n-base64-encoded bytes. When reading via `ReadFromBigQuery`, bytes are returned\n-as bytes without base64 encoding. This is due to the fact that ReadFromBigQuery\n-uses Avro expors by default. To get base64-encoded bytes, you can use the flag\n-`use_json_exports` to export data as JSON, and receive base64-encoded bytes.\n+When reading via `ReadFromBigQuery`, bytes are returned decoded as bytes.\n+This is due to the fact that ReadFromBigQuery uses Avro expors by default.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b93772a525288d28cdeb18c1e5e864fe985f327d"}, "originalPosition": 19}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "42e82924c47a62e7b055799cd95dbd767d4977fa", "author": {"user": {"login": "pabloem", "name": "Pablo"}}, "url": "https://github.com/apache/beam/commit/42e82924c47a62e7b055799cd95dbd767d4977fa", "committedDate": "2020-07-22T21:51:47Z", "message": "Update sdks/python/apache_beam/io/gcp/bigquery.py\n\nCo-authored-by: Udi Meiri <udim@users.noreply.github.com>"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4138, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}