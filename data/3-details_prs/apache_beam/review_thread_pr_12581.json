{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDY3NzY0NjM5", "number": 12581, "reviewThreads": {"totalCount": 29, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQxODowNjoxM1rOEYkFHw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQwMzoxNjozOFrOEaSXFw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk0MTkyNDE1OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/azure/testingFiles/in.txt", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQxODowNjoxM1rOHA96oQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQxODowNjoxM1rOHA96oQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDc3NjQ4MQ==", "bodyText": "you can move this to src/test/resources", "url": "https://github.com/apache/beam/pull/12581#discussion_r470776481", "createdAt": "2020-08-14T18:06:13Z", "author": {"login": "pabloem"}, "path": "sdks/java/io/azure/testingFiles/in.txt", "diffHunk": "@@ -0,0 +1,23 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a4471727d5bba7d22bc9525324e4deec104f0ab8"}, "originalPosition": 17}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk0MjY2NjQxOnYy", "diffSide": "RIGHT", "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzfsResourceId.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQyMjozNToyOVrOHBE__g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QyMzoxNzowMVrOHB971w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg5MjU0Mg==", "bodyText": "is it possible to have blob == null and also container == null so that it's an account?", "url": "https://github.com/apache/beam/pull/12581#discussion_r470892542", "createdAt": "2020-08-14T22:35:29Z", "author": {"login": "pabloem"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzfsResourceId.java", "diffHunk": "@@ -105,6 +129,17 @@ boolean isWildcard() {\n     return GLOB_PREFIX.matcher(blob).matches();\n   }\n \n+  String getBlobNonWildcardPrefix() {\n+    Matcher m = GLOB_PREFIX.matcher(getBlob());\n+    checkArgument(\n+        m.matches(), String.format(\"Glob expression: [%s] is not expandable.\", getBlob()));\n+    return m.group(\"PREFIX\");\n+  }\n+\n+  public boolean isContainer() {\n+    return blob == null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "58325cb61a8b8f226b0f8d88131ea7b2337d529d"}, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTczODY1OQ==", "bodyText": "(it seems like it's not possible, so feel free to ignore the comment if that's correct)", "url": "https://github.com/apache/beam/pull/12581#discussion_r471738659", "createdAt": "2020-08-17T19:51:00Z", "author": {"login": "pabloem"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzfsResourceId.java", "diffHunk": "@@ -105,6 +129,17 @@ boolean isWildcard() {\n     return GLOB_PREFIX.matcher(blob).matches();\n   }\n \n+  String getBlobNonWildcardPrefix() {\n+    Matcher m = GLOB_PREFIX.matcher(getBlob());\n+    checkArgument(\n+        m.matches(), String.format(\"Glob expression: [%s] is not expandable.\", getBlob()));\n+    return m.group(\"PREFIX\");\n+  }\n+\n+  public boolean isContainer() {\n+    return blob == null;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg5MjU0Mg=="}, "originalCommit": {"oid": "58325cb61a8b8f226b0f8d88131ea7b2337d529d"}, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTgyNTM2Nw==", "bodyText": "It says in the javadoc for ResourceId.java that a resource id represents a file-like resource, so AzfsResourceId does not support resource id's without a container.", "url": "https://github.com/apache/beam/pull/12581#discussion_r471825367", "createdAt": "2020-08-17T23:17:01Z", "author": {"login": "ettirapp"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzfsResourceId.java", "diffHunk": "@@ -105,6 +129,17 @@ boolean isWildcard() {\n     return GLOB_PREFIX.matcher(blob).matches();\n   }\n \n+  String getBlobNonWildcardPrefix() {\n+    Matcher m = GLOB_PREFIX.matcher(getBlob());\n+    checkArgument(\n+        m.matches(), String.format(\"Glob expression: [%s] is not expandable.\", getBlob()));\n+    return m.group(\"PREFIX\");\n+  }\n+\n+  public boolean isContainer() {\n+    return blob == null;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg5MjU0Mg=="}, "originalCommit": {"oid": "58325cb61a8b8f226b0f8d88131ea7b2337d529d"}, "originalPosition": 102}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk0NDk1NTQ3OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzfsResourceId.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNlQyMzo1MzoyM1rOHBWR7A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNlQyMzo1MzoyM1rOHBWR7A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTE3NTY2MA==", "bodyText": "I think you can return Long directly and the caller should check whether it's null.", "url": "https://github.com/apache/beam/pull/12581#discussion_r471175660", "createdAt": "2020-08-16T23:53:23Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzfsResourceId.java", "diffHunk": "@@ -93,6 +101,22 @@ public String getScheme() {\n     return SCHEME;\n   }\n \n+  Optional<Long> getSize() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 71}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk0NTEwMDczOnYy", "diffSide": "LEFT", "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzfsResourceId.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QwMTo1NzowNlrOHBXeAA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQwMzoyNjoxOVrOHCvnlQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTE5NTEzNg==", "bodyText": "Is this resolved now?", "url": "https://github.com/apache/beam/pull/12581#discussion_r471195136", "createdAt": "2020-08-17T01:57:06Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzfsResourceId.java", "diffHunk": "@@ -156,8 +190,6 @@ public int hashCode() {\n   @Override\n   public ResourceId resolve(String other, ResolveOptions resolveOptions) {\n     checkState(isDirectory(), \"Expected this resource to be a directory, but was [%s]\", toString());\n-    // TODO: check if resolve options are an illegal name in any way, see:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 120}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjYzOTM4MQ==", "bodyText": "I decided that it makes most sense to check that a filename is valid in the create method of the AzureBlobStoreFileSystem, where a new file is created.  In the create method, the getBlobOutputStream() method will throw a BlobStorageException if a filename is invalid.", "url": "https://github.com/apache/beam/pull/12581#discussion_r472639381", "createdAt": "2020-08-19T03:26:19Z", "author": {"login": "ettirapp"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzfsResourceId.java", "diffHunk": "@@ -156,8 +190,6 @@ public int hashCode() {\n   @Override\n   public ResourceId resolve(String other, ResolveOptions resolveOptions) {\n     checkState(isDirectory(), \"Expected this resource to be a directory, but was [%s]\", toString());\n-    // TODO: check if resolve options are an illegal name in any way, see:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTE5NTEzNg=="}, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 120}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk0Nzc2MjQxOnYy", "diffSide": "RIGHT", "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxNjozNjo0MVrOHBwPbA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxOTowOToyMlrOHB3blw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTYwMTAwNA==", "bodyText": "How do we pick up the number 8640000  here? If it should be a constant, we can make it as static final.", "url": "https://github.com/apache/beam/pull/12581#discussion_r471601004", "createdAt": "2020-08-17T16:36:41Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "diffHunk": "@@ -17,67 +17,438 @@\n  */\n package org.apache.beam.sdk.io.azure.blobstore;\n \n+import static java.nio.channels.Channels.newChannel;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobItem;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.BlobStorageException;\n+import com.azure.storage.blob.models.ListBlobsOptions;\n+import com.microsoft.azure.storage.CloudStorageAccount;\n+import com.microsoft.azure.storage.SharedAccessAccountPolicy;\n+import java.io.FileNotFoundException;\n import java.io.IOException;\n+import java.io.OutputStream;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.time.Duration;\n+import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Date;\n+import java.util.Iterator;\n import java.util.List;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n import org.apache.beam.sdk.io.FileSystem;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreClientBuilderFactory;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n import org.apache.beam.sdk.io.fs.CreateOptions;\n import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.util.InstanceBuilder;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Supplier;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Suppliers;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableSet;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n class AzureBlobStoreFileSystem extends FileSystem<AzfsResourceId> {\n \n+  private static final Logger LOG = LoggerFactory.getLogger(AzureBlobStoreFileSystem.class);\n+\n+  private static final ImmutableSet<String> NON_READ_SEEK_EFFICIENT_ENCODINGS =\n+      ImmutableSet.of(\"gzip\");\n+\n+  private Supplier<BlobServiceClient> client;\n+  private final BlobstoreOptions options;\n+\n+  AzureBlobStoreFileSystem(BlobstoreOptions options) {\n+    this.options = checkNotNull(options, \"options\");\n+\n+    BlobServiceClientBuilder builder =\n+        InstanceBuilder.ofType(BlobstoreClientBuilderFactory.class)\n+            .fromClass(options.getBlobstoreClientFactoryClass())\n+            .build()\n+            .createBuilder(options);\n+\n+    // The Supplier is to make sure we don't call .build() unless we are actually using Azure.\n+    client = Suppliers.memoize(builder::buildClient);\n+  }\n+\n+  @VisibleForTesting\n+  void setClient(BlobServiceClient client) {\n+    this.client = Suppliers.ofInstance(client);\n+  }\n+\n+  @VisibleForTesting\n+  BlobServiceClient getClient() {\n+    return client.get();\n+  }\n+\n   @Override\n   protected String getScheme() {\n-    return \"azfs\";\n+    return AzfsResourceId.SCHEME;\n   }\n \n   @Override\n-  protected List<MatchResult> match(List<String> specs) throws IOException {\n-    // TODO\n-    return null;\n+  protected List<MatchResult> match(List<String> specs) {\n+    List<AzfsResourceId> paths =\n+        specs.stream().map(AzfsResourceId::fromUri).collect(Collectors.toList());\n+    List<AzfsResourceId> globs = new ArrayList<>();\n+    List<AzfsResourceId> nonGlobs = new ArrayList<>();\n+    List<Boolean> isGlobBooleans = new ArrayList<>();\n+\n+    for (AzfsResourceId path : paths) {\n+      if (path.isWildcard()) {\n+        globs.add(path);\n+        isGlobBooleans.add(true);\n+      } else {\n+        nonGlobs.add(path);\n+        isGlobBooleans.add(false);\n+      }\n+    }\n+\n+    Iterator<MatchResult> globMatches = matchGlobPaths(globs).iterator();\n+    Iterator<MatchResult> nonGlobMatches = matchNonGlobPaths(nonGlobs).iterator();\n+\n+    ImmutableList.Builder<MatchResult> matchResults = ImmutableList.builder();\n+    for (Boolean isGlob : isGlobBooleans) {\n+      if (isGlob) {\n+        checkState(globMatches.hasNext(), \"Expect globMatches has next.\");\n+        matchResults.add(globMatches.next());\n+      } else {\n+        checkState(nonGlobMatches.hasNext(), \"Expect nonGlobMatches has next.\");\n+        matchResults.add(nonGlobMatches.next());\n+      }\n+    }\n+    checkState(!globMatches.hasNext(), \"Expect no more elements in globMatches.\");\n+    checkState(!nonGlobMatches.hasNext(), \"Expect no more elements in nonGlobMatches.\");\n+\n+    return matchResults.build();\n+  }\n+\n+  /**\n+   * Expands glob expressions to regular expressions.\n+   *\n+   * @param globExp the glob expression to expand\n+   * @return a string with the regular expression this glob expands to\n+   */\n+  @VisibleForTesting\n+  static String wildcardToRegexp(String globExp) {\n+    StringBuilder dst = new StringBuilder();\n+    char[] src = globExp.replace(\"**/*\", \"**\").toCharArray();\n+    int i = 0;\n+    while (i < src.length) {\n+      char c = src[i++];\n+      switch (c) {\n+        case '*':\n+          // One char lookahead for **\n+          if (i < src.length && src[i] == '*') {\n+            dst.append(\".*\");\n+            ++i;\n+          } else {\n+            dst.append(\"[^/]*\");\n+          }\n+          break;\n+        case '?':\n+          dst.append(\"[^/]\");\n+          break;\n+        case '.':\n+        case '+':\n+        case '{':\n+        case '}':\n+        case '(':\n+        case ')':\n+        case '|':\n+        case '^':\n+        case '$':\n+          // These need to be escaped in regular expressions\n+          dst.append('\\\\').append(c);\n+          break;\n+        case '\\\\':\n+          i = doubleSlashes(dst, src, i);\n+          break;\n+        default:\n+          dst.append(c);\n+          break;\n+      }\n+    }\n+    return dst.toString();\n+  }\n+\n+  private static int doubleSlashes(StringBuilder dst, char[] src, int i) {\n+    // Emit the next character without special interpretation\n+    dst.append(\"\\\\\\\\\");\n+    if ((i - 1) != src.length) {\n+      dst.append(src[i]);\n+      i++;\n+    } else {\n+      // A backslash at the very end is treated like an escaped backslash\n+      dst.append('\\\\');\n+    }\n+    return i;\n+  }\n+\n+  private List<MatchResult> matchGlobPaths(List<AzfsResourceId> globs) {\n+    return FluentIterable.from(globs).transform(this::expand).toList();\n+  }\n+\n+  /** Expands a pattern into {@link MatchResult}. */\n+  @VisibleForTesting\n+  MatchResult expand(AzfsResourceId azfsPattern) {\n+\n+    checkArgument(azfsPattern.isWildcard(), \"is Wildcard\");\n+    String blobPrefix = azfsPattern.getBlobNonWildcardPrefix();\n+    Pattern wildcardAsRegexp = Pattern.compile(wildcardToRegexp(azfsPattern.getBlob()));\n+\n+    LOG.debug(\n+        \"matching files in container {}, prefix {} against pattern {}\",\n+        azfsPattern.getContainer(),\n+        blobPrefix,\n+        wildcardAsRegexp.toString());\n+\n+    ListBlobsOptions listOptions = new ListBlobsOptions().setPrefix(blobPrefix);\n+    Duration timeout = Duration.ZERO.plusMinutes(1);\n+\n+    String account = azfsPattern.getAccount();\n+    String container = azfsPattern.getContainer();\n+    BlobContainerClient blobContainerClient = client.get().getBlobContainerClient(container);\n+    PagedIterable<BlobItem> blobs = blobContainerClient.listBlobs(listOptions, timeout);\n+    List<MatchResult.Metadata> results = new ArrayList<>();\n+\n+    blobs.forEach(\n+        blob -> {\n+          String name = blob.getName();\n+          if (wildcardAsRegexp.matcher(name).matches() && !name.endsWith(\"/\")) {\n+            LOG.debug(\"Matched object: {}\", name);\n+\n+            BlobProperties properties = blobContainerClient.getBlobClient(name).getProperties();\n+            AzfsResourceId rid =\n+                AzfsResourceId.fromComponents(account, container, name)\n+                    .withSize(properties.getBlobSize())\n+                    .withLastModified(Date.from(properties.getLastModified().toInstant()));\n+\n+            results.add(toMetadata(rid, properties.getContentEncoding()));\n+          }\n+        });\n+\n+    return MatchResult.create(MatchResult.Status.OK, results);\n+  }\n+\n+  private MatchResult.Metadata toMetadata(AzfsResourceId path, String contentEncoding) {\n+\n+    checkArgument(path.getSize().isPresent(), \"path has size\");\n+    boolean isReadSeekEfficient = !NON_READ_SEEK_EFFICIENT_ENCODINGS.contains(contentEncoding);\n+\n+    return MatchResult.Metadata.builder()\n+        .setIsReadSeekEfficient(isReadSeekEfficient)\n+        .setResourceId(path)\n+        .setSizeBytes(path.getSize().get())\n+        .setLastModifiedMillis(path.getLastModified().transform(Date::getTime).or(0L))\n+        .build();\n+  }\n+\n+  /**\n+   * Returns {@link MatchResult MatchResults} for the given {@link AzfsResourceId paths}.\n+   *\n+   * <p>The number of returned {@link MatchResult MatchResults} equals to the number of given {@link\n+   * AzfsResourceId paths}. Each {@link MatchResult} contains one {@link MatchResult.Metadata}.\n+   */\n+  @VisibleForTesting\n+  private Iterable<MatchResult> matchNonGlobPaths(List<AzfsResourceId> paths) {\n+    ImmutableList.Builder<MatchResult> toReturn = ImmutableList.builder();\n+    for (AzfsResourceId path : paths) {\n+      toReturn.add(toMatchResult(path));\n+    }\n+    return toReturn.build();\n+  }\n+\n+  private MatchResult toMatchResult(AzfsResourceId path) {\n+    BlobClient blobClient =\n+        client.get().getBlobContainerClient(path.getContainer()).getBlobClient(path.getBlob());\n+    BlobProperties blobProperties;\n+\n+    try {\n+      blobProperties = blobClient.getProperties();\n+    } catch (BlobStorageException e) {\n+      if (e.getStatusCode() == 404) {\n+        return MatchResult.create(MatchResult.Status.NOT_FOUND, new FileNotFoundException());\n+      }\n+      return MatchResult.create(MatchResult.Status.ERROR, new IOException(e));\n+    }\n+\n+    return MatchResult.create(\n+        MatchResult.Status.OK,\n+        ImmutableList.of(\n+            toMetadata(\n+                path.withSize(blobProperties.getBlobSize())\n+                    .withLastModified(Date.from(blobProperties.getLastModified().toInstant())),\n+                blobProperties.getContentEncoding())));\n   }\n \n   @Override\n   protected WritableByteChannel create(AzfsResourceId resourceId, CreateOptions createOptions)\n       throws IOException {\n-    // TODO\n-    return null;\n+    BlobContainerClient blobContainerClient =\n+        client.get().getBlobContainerClient(resourceId.getContainer());\n+    if (!blobContainerClient.exists()) {\n+      throw new UnsupportedOperationException(\"create does not create containers.\");\n+    }\n+\n+    BlobClient blobClient = blobContainerClient.getBlobClient(resourceId.getBlob());\n+    // The getBlobOutputStream method overwrites existing blobs,\n+    // so throw an error in this case to prevent data loss\n+    if (blobClient.exists()) {\n+      throw new IOException(\"This filename is already in use.\");\n+    }\n+\n+    OutputStream outputStream;\n+    try {\n+      outputStream = blobClient.getBlockBlobClient().getBlobOutputStream();\n+    } catch (BlobStorageException e) {\n+      throw (IOException) e.getCause();\n+    }\n+    return newChannel(outputStream);\n   }\n \n   @Override\n   protected ReadableByteChannel open(AzfsResourceId resourceId) throws IOException {\n-    // TODO\n-    return null;\n+    BlobClient blobClient =\n+        client\n+            .get()\n+            .getBlobContainerClient(resourceId.getContainer())\n+            .getBlobClient(resourceId.getBlob());\n+    if (!blobClient.exists()) {\n+      throw new FileNotFoundException(\"The requested file doesn't exist.\");\n+    }\n+    return new AzureReadableSeekableByteChannel(blobClient);\n   }\n \n   @Override\n   protected void copy(List<AzfsResourceId> srcPaths, List<AzfsResourceId> destPaths)\n       throws IOException {\n-    // TODO\n+    checkArgument(\n+        srcPaths.size() == destPaths.size(),\n+        \"sizes of source paths and destination paths do not match\");\n+\n+    Iterator<AzfsResourceId> sourcePathsIterator = srcPaths.iterator();\n+    Iterator<AzfsResourceId> destinationPathsIterator = destPaths.iterator();\n+    while (sourcePathsIterator.hasNext()) {\n+      final AzfsResourceId sourcePath = sourcePathsIterator.next();\n+      final AzfsResourceId destinationPath = destinationPathsIterator.next();\n+      copy(sourcePath, destinationPath);\n+    }\n   }\n \n   @VisibleForTesting\n   void copy(AzfsResourceId sourcePath, AzfsResourceId destinationPath) throws IOException {\n-    // TODO\n+    checkArgument(\n+        sourcePath.getBlob() != null && destinationPath.getBlob() != null,\n+        \"This method is intended to copy file-like resources, not directories.\");\n+\n+    // get source blob client\n+    BlobClient srcBlobClient =\n+        client\n+            .get()\n+            .getBlobContainerClient(sourcePath.getContainer())\n+            .getBlobClient(sourcePath.getBlob());\n+    if (!srcBlobClient.exists()) {\n+      throw new FileNotFoundException(\"The copy source does not exist.\");\n+    }\n+\n+    // get destination blob client\n+    BlobContainerClient destBlobContainerClient =\n+        client.get().getBlobContainerClient(destinationPath.getContainer());\n+    if (!destBlobContainerClient.exists()) {\n+      client.get().createBlobContainer(destinationPath.getContainer());\n+    }\n+    BlobClient destBlobClient = destBlobContainerClient.getBlobClient(destinationPath.getBlob());\n+\n+    destBlobClient.copyFromUrl(srcBlobClient.getBlobUrl() + generateSasToken());\n+  }\n+\n+  @VisibleForTesting\n+  String generateSasToken() throws IOException {\n+    SharedAccessAccountPolicy sharedAccessAccountPolicy = new SharedAccessAccountPolicy();\n+    long date = new Date().getTime();\n+    long expiryDate = new Date(date + 8640000).getTime();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 377}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTcxODgwNw==", "bodyText": "This is a typo, I meant 86400000. 86,400,000 millis = 1 day.  I can make it a final constant.", "url": "https://github.com/apache/beam/pull/12581#discussion_r471718807", "createdAt": "2020-08-17T19:09:22Z", "author": {"login": "ettirapp"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "diffHunk": "@@ -17,67 +17,438 @@\n  */\n package org.apache.beam.sdk.io.azure.blobstore;\n \n+import static java.nio.channels.Channels.newChannel;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobItem;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.BlobStorageException;\n+import com.azure.storage.blob.models.ListBlobsOptions;\n+import com.microsoft.azure.storage.CloudStorageAccount;\n+import com.microsoft.azure.storage.SharedAccessAccountPolicy;\n+import java.io.FileNotFoundException;\n import java.io.IOException;\n+import java.io.OutputStream;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.time.Duration;\n+import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Date;\n+import java.util.Iterator;\n import java.util.List;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n import org.apache.beam.sdk.io.FileSystem;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreClientBuilderFactory;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n import org.apache.beam.sdk.io.fs.CreateOptions;\n import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.util.InstanceBuilder;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Supplier;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Suppliers;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableSet;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n class AzureBlobStoreFileSystem extends FileSystem<AzfsResourceId> {\n \n+  private static final Logger LOG = LoggerFactory.getLogger(AzureBlobStoreFileSystem.class);\n+\n+  private static final ImmutableSet<String> NON_READ_SEEK_EFFICIENT_ENCODINGS =\n+      ImmutableSet.of(\"gzip\");\n+\n+  private Supplier<BlobServiceClient> client;\n+  private final BlobstoreOptions options;\n+\n+  AzureBlobStoreFileSystem(BlobstoreOptions options) {\n+    this.options = checkNotNull(options, \"options\");\n+\n+    BlobServiceClientBuilder builder =\n+        InstanceBuilder.ofType(BlobstoreClientBuilderFactory.class)\n+            .fromClass(options.getBlobstoreClientFactoryClass())\n+            .build()\n+            .createBuilder(options);\n+\n+    // The Supplier is to make sure we don't call .build() unless we are actually using Azure.\n+    client = Suppliers.memoize(builder::buildClient);\n+  }\n+\n+  @VisibleForTesting\n+  void setClient(BlobServiceClient client) {\n+    this.client = Suppliers.ofInstance(client);\n+  }\n+\n+  @VisibleForTesting\n+  BlobServiceClient getClient() {\n+    return client.get();\n+  }\n+\n   @Override\n   protected String getScheme() {\n-    return \"azfs\";\n+    return AzfsResourceId.SCHEME;\n   }\n \n   @Override\n-  protected List<MatchResult> match(List<String> specs) throws IOException {\n-    // TODO\n-    return null;\n+  protected List<MatchResult> match(List<String> specs) {\n+    List<AzfsResourceId> paths =\n+        specs.stream().map(AzfsResourceId::fromUri).collect(Collectors.toList());\n+    List<AzfsResourceId> globs = new ArrayList<>();\n+    List<AzfsResourceId> nonGlobs = new ArrayList<>();\n+    List<Boolean> isGlobBooleans = new ArrayList<>();\n+\n+    for (AzfsResourceId path : paths) {\n+      if (path.isWildcard()) {\n+        globs.add(path);\n+        isGlobBooleans.add(true);\n+      } else {\n+        nonGlobs.add(path);\n+        isGlobBooleans.add(false);\n+      }\n+    }\n+\n+    Iterator<MatchResult> globMatches = matchGlobPaths(globs).iterator();\n+    Iterator<MatchResult> nonGlobMatches = matchNonGlobPaths(nonGlobs).iterator();\n+\n+    ImmutableList.Builder<MatchResult> matchResults = ImmutableList.builder();\n+    for (Boolean isGlob : isGlobBooleans) {\n+      if (isGlob) {\n+        checkState(globMatches.hasNext(), \"Expect globMatches has next.\");\n+        matchResults.add(globMatches.next());\n+      } else {\n+        checkState(nonGlobMatches.hasNext(), \"Expect nonGlobMatches has next.\");\n+        matchResults.add(nonGlobMatches.next());\n+      }\n+    }\n+    checkState(!globMatches.hasNext(), \"Expect no more elements in globMatches.\");\n+    checkState(!nonGlobMatches.hasNext(), \"Expect no more elements in nonGlobMatches.\");\n+\n+    return matchResults.build();\n+  }\n+\n+  /**\n+   * Expands glob expressions to regular expressions.\n+   *\n+   * @param globExp the glob expression to expand\n+   * @return a string with the regular expression this glob expands to\n+   */\n+  @VisibleForTesting\n+  static String wildcardToRegexp(String globExp) {\n+    StringBuilder dst = new StringBuilder();\n+    char[] src = globExp.replace(\"**/*\", \"**\").toCharArray();\n+    int i = 0;\n+    while (i < src.length) {\n+      char c = src[i++];\n+      switch (c) {\n+        case '*':\n+          // One char lookahead for **\n+          if (i < src.length && src[i] == '*') {\n+            dst.append(\".*\");\n+            ++i;\n+          } else {\n+            dst.append(\"[^/]*\");\n+          }\n+          break;\n+        case '?':\n+          dst.append(\"[^/]\");\n+          break;\n+        case '.':\n+        case '+':\n+        case '{':\n+        case '}':\n+        case '(':\n+        case ')':\n+        case '|':\n+        case '^':\n+        case '$':\n+          // These need to be escaped in regular expressions\n+          dst.append('\\\\').append(c);\n+          break;\n+        case '\\\\':\n+          i = doubleSlashes(dst, src, i);\n+          break;\n+        default:\n+          dst.append(c);\n+          break;\n+      }\n+    }\n+    return dst.toString();\n+  }\n+\n+  private static int doubleSlashes(StringBuilder dst, char[] src, int i) {\n+    // Emit the next character without special interpretation\n+    dst.append(\"\\\\\\\\\");\n+    if ((i - 1) != src.length) {\n+      dst.append(src[i]);\n+      i++;\n+    } else {\n+      // A backslash at the very end is treated like an escaped backslash\n+      dst.append('\\\\');\n+    }\n+    return i;\n+  }\n+\n+  private List<MatchResult> matchGlobPaths(List<AzfsResourceId> globs) {\n+    return FluentIterable.from(globs).transform(this::expand).toList();\n+  }\n+\n+  /** Expands a pattern into {@link MatchResult}. */\n+  @VisibleForTesting\n+  MatchResult expand(AzfsResourceId azfsPattern) {\n+\n+    checkArgument(azfsPattern.isWildcard(), \"is Wildcard\");\n+    String blobPrefix = azfsPattern.getBlobNonWildcardPrefix();\n+    Pattern wildcardAsRegexp = Pattern.compile(wildcardToRegexp(azfsPattern.getBlob()));\n+\n+    LOG.debug(\n+        \"matching files in container {}, prefix {} against pattern {}\",\n+        azfsPattern.getContainer(),\n+        blobPrefix,\n+        wildcardAsRegexp.toString());\n+\n+    ListBlobsOptions listOptions = new ListBlobsOptions().setPrefix(blobPrefix);\n+    Duration timeout = Duration.ZERO.plusMinutes(1);\n+\n+    String account = azfsPattern.getAccount();\n+    String container = azfsPattern.getContainer();\n+    BlobContainerClient blobContainerClient = client.get().getBlobContainerClient(container);\n+    PagedIterable<BlobItem> blobs = blobContainerClient.listBlobs(listOptions, timeout);\n+    List<MatchResult.Metadata> results = new ArrayList<>();\n+\n+    blobs.forEach(\n+        blob -> {\n+          String name = blob.getName();\n+          if (wildcardAsRegexp.matcher(name).matches() && !name.endsWith(\"/\")) {\n+            LOG.debug(\"Matched object: {}\", name);\n+\n+            BlobProperties properties = blobContainerClient.getBlobClient(name).getProperties();\n+            AzfsResourceId rid =\n+                AzfsResourceId.fromComponents(account, container, name)\n+                    .withSize(properties.getBlobSize())\n+                    .withLastModified(Date.from(properties.getLastModified().toInstant()));\n+\n+            results.add(toMetadata(rid, properties.getContentEncoding()));\n+          }\n+        });\n+\n+    return MatchResult.create(MatchResult.Status.OK, results);\n+  }\n+\n+  private MatchResult.Metadata toMetadata(AzfsResourceId path, String contentEncoding) {\n+\n+    checkArgument(path.getSize().isPresent(), \"path has size\");\n+    boolean isReadSeekEfficient = !NON_READ_SEEK_EFFICIENT_ENCODINGS.contains(contentEncoding);\n+\n+    return MatchResult.Metadata.builder()\n+        .setIsReadSeekEfficient(isReadSeekEfficient)\n+        .setResourceId(path)\n+        .setSizeBytes(path.getSize().get())\n+        .setLastModifiedMillis(path.getLastModified().transform(Date::getTime).or(0L))\n+        .build();\n+  }\n+\n+  /**\n+   * Returns {@link MatchResult MatchResults} for the given {@link AzfsResourceId paths}.\n+   *\n+   * <p>The number of returned {@link MatchResult MatchResults} equals to the number of given {@link\n+   * AzfsResourceId paths}. Each {@link MatchResult} contains one {@link MatchResult.Metadata}.\n+   */\n+  @VisibleForTesting\n+  private Iterable<MatchResult> matchNonGlobPaths(List<AzfsResourceId> paths) {\n+    ImmutableList.Builder<MatchResult> toReturn = ImmutableList.builder();\n+    for (AzfsResourceId path : paths) {\n+      toReturn.add(toMatchResult(path));\n+    }\n+    return toReturn.build();\n+  }\n+\n+  private MatchResult toMatchResult(AzfsResourceId path) {\n+    BlobClient blobClient =\n+        client.get().getBlobContainerClient(path.getContainer()).getBlobClient(path.getBlob());\n+    BlobProperties blobProperties;\n+\n+    try {\n+      blobProperties = blobClient.getProperties();\n+    } catch (BlobStorageException e) {\n+      if (e.getStatusCode() == 404) {\n+        return MatchResult.create(MatchResult.Status.NOT_FOUND, new FileNotFoundException());\n+      }\n+      return MatchResult.create(MatchResult.Status.ERROR, new IOException(e));\n+    }\n+\n+    return MatchResult.create(\n+        MatchResult.Status.OK,\n+        ImmutableList.of(\n+            toMetadata(\n+                path.withSize(blobProperties.getBlobSize())\n+                    .withLastModified(Date.from(blobProperties.getLastModified().toInstant())),\n+                blobProperties.getContentEncoding())));\n   }\n \n   @Override\n   protected WritableByteChannel create(AzfsResourceId resourceId, CreateOptions createOptions)\n       throws IOException {\n-    // TODO\n-    return null;\n+    BlobContainerClient blobContainerClient =\n+        client.get().getBlobContainerClient(resourceId.getContainer());\n+    if (!blobContainerClient.exists()) {\n+      throw new UnsupportedOperationException(\"create does not create containers.\");\n+    }\n+\n+    BlobClient blobClient = blobContainerClient.getBlobClient(resourceId.getBlob());\n+    // The getBlobOutputStream method overwrites existing blobs,\n+    // so throw an error in this case to prevent data loss\n+    if (blobClient.exists()) {\n+      throw new IOException(\"This filename is already in use.\");\n+    }\n+\n+    OutputStream outputStream;\n+    try {\n+      outputStream = blobClient.getBlockBlobClient().getBlobOutputStream();\n+    } catch (BlobStorageException e) {\n+      throw (IOException) e.getCause();\n+    }\n+    return newChannel(outputStream);\n   }\n \n   @Override\n   protected ReadableByteChannel open(AzfsResourceId resourceId) throws IOException {\n-    // TODO\n-    return null;\n+    BlobClient blobClient =\n+        client\n+            .get()\n+            .getBlobContainerClient(resourceId.getContainer())\n+            .getBlobClient(resourceId.getBlob());\n+    if (!blobClient.exists()) {\n+      throw new FileNotFoundException(\"The requested file doesn't exist.\");\n+    }\n+    return new AzureReadableSeekableByteChannel(blobClient);\n   }\n \n   @Override\n   protected void copy(List<AzfsResourceId> srcPaths, List<AzfsResourceId> destPaths)\n       throws IOException {\n-    // TODO\n+    checkArgument(\n+        srcPaths.size() == destPaths.size(),\n+        \"sizes of source paths and destination paths do not match\");\n+\n+    Iterator<AzfsResourceId> sourcePathsIterator = srcPaths.iterator();\n+    Iterator<AzfsResourceId> destinationPathsIterator = destPaths.iterator();\n+    while (sourcePathsIterator.hasNext()) {\n+      final AzfsResourceId sourcePath = sourcePathsIterator.next();\n+      final AzfsResourceId destinationPath = destinationPathsIterator.next();\n+      copy(sourcePath, destinationPath);\n+    }\n   }\n \n   @VisibleForTesting\n   void copy(AzfsResourceId sourcePath, AzfsResourceId destinationPath) throws IOException {\n-    // TODO\n+    checkArgument(\n+        sourcePath.getBlob() != null && destinationPath.getBlob() != null,\n+        \"This method is intended to copy file-like resources, not directories.\");\n+\n+    // get source blob client\n+    BlobClient srcBlobClient =\n+        client\n+            .get()\n+            .getBlobContainerClient(sourcePath.getContainer())\n+            .getBlobClient(sourcePath.getBlob());\n+    if (!srcBlobClient.exists()) {\n+      throw new FileNotFoundException(\"The copy source does not exist.\");\n+    }\n+\n+    // get destination blob client\n+    BlobContainerClient destBlobContainerClient =\n+        client.get().getBlobContainerClient(destinationPath.getContainer());\n+    if (!destBlobContainerClient.exists()) {\n+      client.get().createBlobContainer(destinationPath.getContainer());\n+    }\n+    BlobClient destBlobClient = destBlobContainerClient.getBlobClient(destinationPath.getBlob());\n+\n+    destBlobClient.copyFromUrl(srcBlobClient.getBlobUrl() + generateSasToken());\n+  }\n+\n+  @VisibleForTesting\n+  String generateSasToken() throws IOException {\n+    SharedAccessAccountPolicy sharedAccessAccountPolicy = new SharedAccessAccountPolicy();\n+    long date = new Date().getTime();\n+    long expiryDate = new Date(date + 8640000).getTime();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTYwMTAwNA=="}, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 377}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk0Nzc5NDM3OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxNjo0NToyM1rOHBwi8A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxNjo0NToyM1rOHBwi8A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTYwNjAwMA==", "bodyText": "Please have a class-level javadoc to explain what the class is for.", "url": "https://github.com/apache/beam/pull/12581#discussion_r471606000", "createdAt": "2020-08-17T16:45:23Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "diffHunk": "@@ -17,67 +17,438 @@\n  */\n package org.apache.beam.sdk.io.azure.blobstore;\n \n+import static java.nio.channels.Channels.newChannel;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobItem;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.BlobStorageException;\n+import com.azure.storage.blob.models.ListBlobsOptions;\n+import com.microsoft.azure.storage.CloudStorageAccount;\n+import com.microsoft.azure.storage.SharedAccessAccountPolicy;\n+import java.io.FileNotFoundException;\n import java.io.IOException;\n+import java.io.OutputStream;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.time.Duration;\n+import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Date;\n+import java.util.Iterator;\n import java.util.List;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n import org.apache.beam.sdk.io.FileSystem;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreClientBuilderFactory;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n import org.apache.beam.sdk.io.fs.CreateOptions;\n import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.util.InstanceBuilder;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Supplier;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Suppliers;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableSet;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n class AzureBlobStoreFileSystem extends FileSystem<AzfsResourceId> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 48}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk0Nzk0NTk5OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxNzoxNjowMFrOHByGkw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxNzoxNjowMFrOHByGkw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTYzMTUwNw==", "bodyText": "Can you elaborate more on the error msg? Like the pattern should be wildcard?", "url": "https://github.com/apache/beam/pull/12581#discussion_r471631507", "createdAt": "2020-08-17T17:16:00Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "diffHunk": "@@ -17,67 +17,438 @@\n  */\n package org.apache.beam.sdk.io.azure.blobstore;\n \n+import static java.nio.channels.Channels.newChannel;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobItem;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.BlobStorageException;\n+import com.azure.storage.blob.models.ListBlobsOptions;\n+import com.microsoft.azure.storage.CloudStorageAccount;\n+import com.microsoft.azure.storage.SharedAccessAccountPolicy;\n+import java.io.FileNotFoundException;\n import java.io.IOException;\n+import java.io.OutputStream;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.time.Duration;\n+import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Date;\n+import java.util.Iterator;\n import java.util.List;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n import org.apache.beam.sdk.io.FileSystem;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreClientBuilderFactory;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n import org.apache.beam.sdk.io.fs.CreateOptions;\n import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.util.InstanceBuilder;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Supplier;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Suppliers;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableSet;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n class AzureBlobStoreFileSystem extends FileSystem<AzfsResourceId> {\n \n+  private static final Logger LOG = LoggerFactory.getLogger(AzureBlobStoreFileSystem.class);\n+\n+  private static final ImmutableSet<String> NON_READ_SEEK_EFFICIENT_ENCODINGS =\n+      ImmutableSet.of(\"gzip\");\n+\n+  private Supplier<BlobServiceClient> client;\n+  private final BlobstoreOptions options;\n+\n+  AzureBlobStoreFileSystem(BlobstoreOptions options) {\n+    this.options = checkNotNull(options, \"options\");\n+\n+    BlobServiceClientBuilder builder =\n+        InstanceBuilder.ofType(BlobstoreClientBuilderFactory.class)\n+            .fromClass(options.getBlobstoreClientFactoryClass())\n+            .build()\n+            .createBuilder(options);\n+\n+    // The Supplier is to make sure we don't call .build() unless we are actually using Azure.\n+    client = Suppliers.memoize(builder::buildClient);\n+  }\n+\n+  @VisibleForTesting\n+  void setClient(BlobServiceClient client) {\n+    this.client = Suppliers.ofInstance(client);\n+  }\n+\n+  @VisibleForTesting\n+  BlobServiceClient getClient() {\n+    return client.get();\n+  }\n+\n   @Override\n   protected String getScheme() {\n-    return \"azfs\";\n+    return AzfsResourceId.SCHEME;\n   }\n \n   @Override\n-  protected List<MatchResult> match(List<String> specs) throws IOException {\n-    // TODO\n-    return null;\n+  protected List<MatchResult> match(List<String> specs) {\n+    List<AzfsResourceId> paths =\n+        specs.stream().map(AzfsResourceId::fromUri).collect(Collectors.toList());\n+    List<AzfsResourceId> globs = new ArrayList<>();\n+    List<AzfsResourceId> nonGlobs = new ArrayList<>();\n+    List<Boolean> isGlobBooleans = new ArrayList<>();\n+\n+    for (AzfsResourceId path : paths) {\n+      if (path.isWildcard()) {\n+        globs.add(path);\n+        isGlobBooleans.add(true);\n+      } else {\n+        nonGlobs.add(path);\n+        isGlobBooleans.add(false);\n+      }\n+    }\n+\n+    Iterator<MatchResult> globMatches = matchGlobPaths(globs).iterator();\n+    Iterator<MatchResult> nonGlobMatches = matchNonGlobPaths(nonGlobs).iterator();\n+\n+    ImmutableList.Builder<MatchResult> matchResults = ImmutableList.builder();\n+    for (Boolean isGlob : isGlobBooleans) {\n+      if (isGlob) {\n+        checkState(globMatches.hasNext(), \"Expect globMatches has next.\");\n+        matchResults.add(globMatches.next());\n+      } else {\n+        checkState(nonGlobMatches.hasNext(), \"Expect nonGlobMatches has next.\");\n+        matchResults.add(nonGlobMatches.next());\n+      }\n+    }\n+    checkState(!globMatches.hasNext(), \"Expect no more elements in globMatches.\");\n+    checkState(!nonGlobMatches.hasNext(), \"Expect no more elements in nonGlobMatches.\");\n+\n+    return matchResults.build();\n+  }\n+\n+  /**\n+   * Expands glob expressions to regular expressions.\n+   *\n+   * @param globExp the glob expression to expand\n+   * @return a string with the regular expression this glob expands to\n+   */\n+  @VisibleForTesting\n+  static String wildcardToRegexp(String globExp) {\n+    StringBuilder dst = new StringBuilder();\n+    char[] src = globExp.replace(\"**/*\", \"**\").toCharArray();\n+    int i = 0;\n+    while (i < src.length) {\n+      char c = src[i++];\n+      switch (c) {\n+        case '*':\n+          // One char lookahead for **\n+          if (i < src.length && src[i] == '*') {\n+            dst.append(\".*\");\n+            ++i;\n+          } else {\n+            dst.append(\"[^/]*\");\n+          }\n+          break;\n+        case '?':\n+          dst.append(\"[^/]\");\n+          break;\n+        case '.':\n+        case '+':\n+        case '{':\n+        case '}':\n+        case '(':\n+        case ')':\n+        case '|':\n+        case '^':\n+        case '$':\n+          // These need to be escaped in regular expressions\n+          dst.append('\\\\').append(c);\n+          break;\n+        case '\\\\':\n+          i = doubleSlashes(dst, src, i);\n+          break;\n+        default:\n+          dst.append(c);\n+          break;\n+      }\n+    }\n+    return dst.toString();\n+  }\n+\n+  private static int doubleSlashes(StringBuilder dst, char[] src, int i) {\n+    // Emit the next character without special interpretation\n+    dst.append(\"\\\\\\\\\");\n+    if ((i - 1) != src.length) {\n+      dst.append(src[i]);\n+      i++;\n+    } else {\n+      // A backslash at the very end is treated like an escaped backslash\n+      dst.append('\\\\');\n+    }\n+    return i;\n+  }\n+\n+  private List<MatchResult> matchGlobPaths(List<AzfsResourceId> globs) {\n+    return FluentIterable.from(globs).transform(this::expand).toList();\n+  }\n+\n+  /** Expands a pattern into {@link MatchResult}. */\n+  @VisibleForTesting\n+  MatchResult expand(AzfsResourceId azfsPattern) {\n+\n+    checkArgument(azfsPattern.isWildcard(), \"is Wildcard\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 197}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk0Nzk4MzM0OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxNzoyMToxNlrOHBygFQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxNzoyMToxNlrOHBygFQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTYzODAzNw==", "bodyText": "Duration.ofMinutes(1)", "url": "https://github.com/apache/beam/pull/12581#discussion_r471638037", "createdAt": "2020-08-17T17:21:16Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "diffHunk": "@@ -17,67 +17,438 @@\n  */\n package org.apache.beam.sdk.io.azure.blobstore;\n \n+import static java.nio.channels.Channels.newChannel;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobItem;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.BlobStorageException;\n+import com.azure.storage.blob.models.ListBlobsOptions;\n+import com.microsoft.azure.storage.CloudStorageAccount;\n+import com.microsoft.azure.storage.SharedAccessAccountPolicy;\n+import java.io.FileNotFoundException;\n import java.io.IOException;\n+import java.io.OutputStream;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.time.Duration;\n+import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Date;\n+import java.util.Iterator;\n import java.util.List;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n import org.apache.beam.sdk.io.FileSystem;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreClientBuilderFactory;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n import org.apache.beam.sdk.io.fs.CreateOptions;\n import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.util.InstanceBuilder;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Supplier;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Suppliers;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableSet;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n class AzureBlobStoreFileSystem extends FileSystem<AzfsResourceId> {\n \n+  private static final Logger LOG = LoggerFactory.getLogger(AzureBlobStoreFileSystem.class);\n+\n+  private static final ImmutableSet<String> NON_READ_SEEK_EFFICIENT_ENCODINGS =\n+      ImmutableSet.of(\"gzip\");\n+\n+  private Supplier<BlobServiceClient> client;\n+  private final BlobstoreOptions options;\n+\n+  AzureBlobStoreFileSystem(BlobstoreOptions options) {\n+    this.options = checkNotNull(options, \"options\");\n+\n+    BlobServiceClientBuilder builder =\n+        InstanceBuilder.ofType(BlobstoreClientBuilderFactory.class)\n+            .fromClass(options.getBlobstoreClientFactoryClass())\n+            .build()\n+            .createBuilder(options);\n+\n+    // The Supplier is to make sure we don't call .build() unless we are actually using Azure.\n+    client = Suppliers.memoize(builder::buildClient);\n+  }\n+\n+  @VisibleForTesting\n+  void setClient(BlobServiceClient client) {\n+    this.client = Suppliers.ofInstance(client);\n+  }\n+\n+  @VisibleForTesting\n+  BlobServiceClient getClient() {\n+    return client.get();\n+  }\n+\n   @Override\n   protected String getScheme() {\n-    return \"azfs\";\n+    return AzfsResourceId.SCHEME;\n   }\n \n   @Override\n-  protected List<MatchResult> match(List<String> specs) throws IOException {\n-    // TODO\n-    return null;\n+  protected List<MatchResult> match(List<String> specs) {\n+    List<AzfsResourceId> paths =\n+        specs.stream().map(AzfsResourceId::fromUri).collect(Collectors.toList());\n+    List<AzfsResourceId> globs = new ArrayList<>();\n+    List<AzfsResourceId> nonGlobs = new ArrayList<>();\n+    List<Boolean> isGlobBooleans = new ArrayList<>();\n+\n+    for (AzfsResourceId path : paths) {\n+      if (path.isWildcard()) {\n+        globs.add(path);\n+        isGlobBooleans.add(true);\n+      } else {\n+        nonGlobs.add(path);\n+        isGlobBooleans.add(false);\n+      }\n+    }\n+\n+    Iterator<MatchResult> globMatches = matchGlobPaths(globs).iterator();\n+    Iterator<MatchResult> nonGlobMatches = matchNonGlobPaths(nonGlobs).iterator();\n+\n+    ImmutableList.Builder<MatchResult> matchResults = ImmutableList.builder();\n+    for (Boolean isGlob : isGlobBooleans) {\n+      if (isGlob) {\n+        checkState(globMatches.hasNext(), \"Expect globMatches has next.\");\n+        matchResults.add(globMatches.next());\n+      } else {\n+        checkState(nonGlobMatches.hasNext(), \"Expect nonGlobMatches has next.\");\n+        matchResults.add(nonGlobMatches.next());\n+      }\n+    }\n+    checkState(!globMatches.hasNext(), \"Expect no more elements in globMatches.\");\n+    checkState(!nonGlobMatches.hasNext(), \"Expect no more elements in nonGlobMatches.\");\n+\n+    return matchResults.build();\n+  }\n+\n+  /**\n+   * Expands glob expressions to regular expressions.\n+   *\n+   * @param globExp the glob expression to expand\n+   * @return a string with the regular expression this glob expands to\n+   */\n+  @VisibleForTesting\n+  static String wildcardToRegexp(String globExp) {\n+    StringBuilder dst = new StringBuilder();\n+    char[] src = globExp.replace(\"**/*\", \"**\").toCharArray();\n+    int i = 0;\n+    while (i < src.length) {\n+      char c = src[i++];\n+      switch (c) {\n+        case '*':\n+          // One char lookahead for **\n+          if (i < src.length && src[i] == '*') {\n+            dst.append(\".*\");\n+            ++i;\n+          } else {\n+            dst.append(\"[^/]*\");\n+          }\n+          break;\n+        case '?':\n+          dst.append(\"[^/]\");\n+          break;\n+        case '.':\n+        case '+':\n+        case '{':\n+        case '}':\n+        case '(':\n+        case ')':\n+        case '|':\n+        case '^':\n+        case '$':\n+          // These need to be escaped in regular expressions\n+          dst.append('\\\\').append(c);\n+          break;\n+        case '\\\\':\n+          i = doubleSlashes(dst, src, i);\n+          break;\n+        default:\n+          dst.append(c);\n+          break;\n+      }\n+    }\n+    return dst.toString();\n+  }\n+\n+  private static int doubleSlashes(StringBuilder dst, char[] src, int i) {\n+    // Emit the next character without special interpretation\n+    dst.append(\"\\\\\\\\\");\n+    if ((i - 1) != src.length) {\n+      dst.append(src[i]);\n+      i++;\n+    } else {\n+      // A backslash at the very end is treated like an escaped backslash\n+      dst.append('\\\\');\n+    }\n+    return i;\n+  }\n+\n+  private List<MatchResult> matchGlobPaths(List<AzfsResourceId> globs) {\n+    return FluentIterable.from(globs).transform(this::expand).toList();\n+  }\n+\n+  /** Expands a pattern into {@link MatchResult}. */\n+  @VisibleForTesting\n+  MatchResult expand(AzfsResourceId azfsPattern) {\n+\n+    checkArgument(azfsPattern.isWildcard(), \"is Wildcard\");\n+    String blobPrefix = azfsPattern.getBlobNonWildcardPrefix();\n+    Pattern wildcardAsRegexp = Pattern.compile(wildcardToRegexp(azfsPattern.getBlob()));\n+\n+    LOG.debug(\n+        \"matching files in container {}, prefix {} against pattern {}\",\n+        azfsPattern.getContainer(),\n+        blobPrefix,\n+        wildcardAsRegexp.toString());\n+\n+    ListBlobsOptions listOptions = new ListBlobsOptions().setPrefix(blobPrefix);\n+    Duration timeout = Duration.ZERO.plusMinutes(1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 208}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk0ODAxMjgyOnYy", "diffSide": "RIGHT", "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxNzoyNToyOVrOHBy0Ng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxNzoyNToyOVrOHBy0Ng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY0MzE5MA==", "bodyText": "Please make the error message specific.", "url": "https://github.com/apache/beam/pull/12581#discussion_r471643190", "createdAt": "2020-08-17T17:25:29Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "diffHunk": "@@ -17,67 +17,438 @@\n  */\n package org.apache.beam.sdk.io.azure.blobstore;\n \n+import static java.nio.channels.Channels.newChannel;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobItem;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.BlobStorageException;\n+import com.azure.storage.blob.models.ListBlobsOptions;\n+import com.microsoft.azure.storage.CloudStorageAccount;\n+import com.microsoft.azure.storage.SharedAccessAccountPolicy;\n+import java.io.FileNotFoundException;\n import java.io.IOException;\n+import java.io.OutputStream;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.time.Duration;\n+import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Date;\n+import java.util.Iterator;\n import java.util.List;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n import org.apache.beam.sdk.io.FileSystem;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreClientBuilderFactory;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n import org.apache.beam.sdk.io.fs.CreateOptions;\n import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.util.InstanceBuilder;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Supplier;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Suppliers;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableSet;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n class AzureBlobStoreFileSystem extends FileSystem<AzfsResourceId> {\n \n+  private static final Logger LOG = LoggerFactory.getLogger(AzureBlobStoreFileSystem.class);\n+\n+  private static final ImmutableSet<String> NON_READ_SEEK_EFFICIENT_ENCODINGS =\n+      ImmutableSet.of(\"gzip\");\n+\n+  private Supplier<BlobServiceClient> client;\n+  private final BlobstoreOptions options;\n+\n+  AzureBlobStoreFileSystem(BlobstoreOptions options) {\n+    this.options = checkNotNull(options, \"options\");\n+\n+    BlobServiceClientBuilder builder =\n+        InstanceBuilder.ofType(BlobstoreClientBuilderFactory.class)\n+            .fromClass(options.getBlobstoreClientFactoryClass())\n+            .build()\n+            .createBuilder(options);\n+\n+    // The Supplier is to make sure we don't call .build() unless we are actually using Azure.\n+    client = Suppliers.memoize(builder::buildClient);\n+  }\n+\n+  @VisibleForTesting\n+  void setClient(BlobServiceClient client) {\n+    this.client = Suppliers.ofInstance(client);\n+  }\n+\n+  @VisibleForTesting\n+  BlobServiceClient getClient() {\n+    return client.get();\n+  }\n+\n   @Override\n   protected String getScheme() {\n-    return \"azfs\";\n+    return AzfsResourceId.SCHEME;\n   }\n \n   @Override\n-  protected List<MatchResult> match(List<String> specs) throws IOException {\n-    // TODO\n-    return null;\n+  protected List<MatchResult> match(List<String> specs) {\n+    List<AzfsResourceId> paths =\n+        specs.stream().map(AzfsResourceId::fromUri).collect(Collectors.toList());\n+    List<AzfsResourceId> globs = new ArrayList<>();\n+    List<AzfsResourceId> nonGlobs = new ArrayList<>();\n+    List<Boolean> isGlobBooleans = new ArrayList<>();\n+\n+    for (AzfsResourceId path : paths) {\n+      if (path.isWildcard()) {\n+        globs.add(path);\n+        isGlobBooleans.add(true);\n+      } else {\n+        nonGlobs.add(path);\n+        isGlobBooleans.add(false);\n+      }\n+    }\n+\n+    Iterator<MatchResult> globMatches = matchGlobPaths(globs).iterator();\n+    Iterator<MatchResult> nonGlobMatches = matchNonGlobPaths(nonGlobs).iterator();\n+\n+    ImmutableList.Builder<MatchResult> matchResults = ImmutableList.builder();\n+    for (Boolean isGlob : isGlobBooleans) {\n+      if (isGlob) {\n+        checkState(globMatches.hasNext(), \"Expect globMatches has next.\");\n+        matchResults.add(globMatches.next());\n+      } else {\n+        checkState(nonGlobMatches.hasNext(), \"Expect nonGlobMatches has next.\");\n+        matchResults.add(nonGlobMatches.next());\n+      }\n+    }\n+    checkState(!globMatches.hasNext(), \"Expect no more elements in globMatches.\");\n+    checkState(!nonGlobMatches.hasNext(), \"Expect no more elements in nonGlobMatches.\");\n+\n+    return matchResults.build();\n+  }\n+\n+  /**\n+   * Expands glob expressions to regular expressions.\n+   *\n+   * @param globExp the glob expression to expand\n+   * @return a string with the regular expression this glob expands to\n+   */\n+  @VisibleForTesting\n+  static String wildcardToRegexp(String globExp) {\n+    StringBuilder dst = new StringBuilder();\n+    char[] src = globExp.replace(\"**/*\", \"**\").toCharArray();\n+    int i = 0;\n+    while (i < src.length) {\n+      char c = src[i++];\n+      switch (c) {\n+        case '*':\n+          // One char lookahead for **\n+          if (i < src.length && src[i] == '*') {\n+            dst.append(\".*\");\n+            ++i;\n+          } else {\n+            dst.append(\"[^/]*\");\n+          }\n+          break;\n+        case '?':\n+          dst.append(\"[^/]\");\n+          break;\n+        case '.':\n+        case '+':\n+        case '{':\n+        case '}':\n+        case '(':\n+        case ')':\n+        case '|':\n+        case '^':\n+        case '$':\n+          // These need to be escaped in regular expressions\n+          dst.append('\\\\').append(c);\n+          break;\n+        case '\\\\':\n+          i = doubleSlashes(dst, src, i);\n+          break;\n+        default:\n+          dst.append(c);\n+          break;\n+      }\n+    }\n+    return dst.toString();\n+  }\n+\n+  private static int doubleSlashes(StringBuilder dst, char[] src, int i) {\n+    // Emit the next character without special interpretation\n+    dst.append(\"\\\\\\\\\");\n+    if ((i - 1) != src.length) {\n+      dst.append(src[i]);\n+      i++;\n+    } else {\n+      // A backslash at the very end is treated like an escaped backslash\n+      dst.append('\\\\');\n+    }\n+    return i;\n+  }\n+\n+  private List<MatchResult> matchGlobPaths(List<AzfsResourceId> globs) {\n+    return FluentIterable.from(globs).transform(this::expand).toList();\n+  }\n+\n+  /** Expands a pattern into {@link MatchResult}. */\n+  @VisibleForTesting\n+  MatchResult expand(AzfsResourceId azfsPattern) {\n+\n+    checkArgument(azfsPattern.isWildcard(), \"is Wildcard\");\n+    String blobPrefix = azfsPattern.getBlobNonWildcardPrefix();\n+    Pattern wildcardAsRegexp = Pattern.compile(wildcardToRegexp(azfsPattern.getBlob()));\n+\n+    LOG.debug(\n+        \"matching files in container {}, prefix {} against pattern {}\",\n+        azfsPattern.getContainer(),\n+        blobPrefix,\n+        wildcardAsRegexp.toString());\n+\n+    ListBlobsOptions listOptions = new ListBlobsOptions().setPrefix(blobPrefix);\n+    Duration timeout = Duration.ZERO.plusMinutes(1);\n+\n+    String account = azfsPattern.getAccount();\n+    String container = azfsPattern.getContainer();\n+    BlobContainerClient blobContainerClient = client.get().getBlobContainerClient(container);\n+    PagedIterable<BlobItem> blobs = blobContainerClient.listBlobs(listOptions, timeout);\n+    List<MatchResult.Metadata> results = new ArrayList<>();\n+\n+    blobs.forEach(\n+        blob -> {\n+          String name = blob.getName();\n+          if (wildcardAsRegexp.matcher(name).matches() && !name.endsWith(\"/\")) {\n+            LOG.debug(\"Matched object: {}\", name);\n+\n+            BlobProperties properties = blobContainerClient.getBlobClient(name).getProperties();\n+            AzfsResourceId rid =\n+                AzfsResourceId.fromComponents(account, container, name)\n+                    .withSize(properties.getBlobSize())\n+                    .withLastModified(Date.from(properties.getLastModified().toInstant()));\n+\n+            results.add(toMetadata(rid, properties.getContentEncoding()));\n+          }\n+        });\n+\n+    return MatchResult.create(MatchResult.Status.OK, results);\n+  }\n+\n+  private MatchResult.Metadata toMetadata(AzfsResourceId path, String contentEncoding) {\n+\n+    checkArgument(path.getSize().isPresent(), \"path has size\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 237}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk0ODA1OTA3OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxNzozNDo0MlrOHBzS9A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxOTowMDo0NFrOHB3KCA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY1MTA2MA==", "bodyText": "Why is it an UnsupportedOperationException ? Under what kind of condition the blobContainerClient.exists() will be false?", "url": "https://github.com/apache/beam/pull/12581#discussion_r471651060", "createdAt": "2020-08-17T17:34:42Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "diffHunk": "@@ -17,67 +17,438 @@\n  */\n package org.apache.beam.sdk.io.azure.blobstore;\n \n+import static java.nio.channels.Channels.newChannel;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobItem;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.BlobStorageException;\n+import com.azure.storage.blob.models.ListBlobsOptions;\n+import com.microsoft.azure.storage.CloudStorageAccount;\n+import com.microsoft.azure.storage.SharedAccessAccountPolicy;\n+import java.io.FileNotFoundException;\n import java.io.IOException;\n+import java.io.OutputStream;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.time.Duration;\n+import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Date;\n+import java.util.Iterator;\n import java.util.List;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n import org.apache.beam.sdk.io.FileSystem;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreClientBuilderFactory;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n import org.apache.beam.sdk.io.fs.CreateOptions;\n import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.util.InstanceBuilder;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Supplier;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Suppliers;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableSet;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n class AzureBlobStoreFileSystem extends FileSystem<AzfsResourceId> {\n \n+  private static final Logger LOG = LoggerFactory.getLogger(AzureBlobStoreFileSystem.class);\n+\n+  private static final ImmutableSet<String> NON_READ_SEEK_EFFICIENT_ENCODINGS =\n+      ImmutableSet.of(\"gzip\");\n+\n+  private Supplier<BlobServiceClient> client;\n+  private final BlobstoreOptions options;\n+\n+  AzureBlobStoreFileSystem(BlobstoreOptions options) {\n+    this.options = checkNotNull(options, \"options\");\n+\n+    BlobServiceClientBuilder builder =\n+        InstanceBuilder.ofType(BlobstoreClientBuilderFactory.class)\n+            .fromClass(options.getBlobstoreClientFactoryClass())\n+            .build()\n+            .createBuilder(options);\n+\n+    // The Supplier is to make sure we don't call .build() unless we are actually using Azure.\n+    client = Suppliers.memoize(builder::buildClient);\n+  }\n+\n+  @VisibleForTesting\n+  void setClient(BlobServiceClient client) {\n+    this.client = Suppliers.ofInstance(client);\n+  }\n+\n+  @VisibleForTesting\n+  BlobServiceClient getClient() {\n+    return client.get();\n+  }\n+\n   @Override\n   protected String getScheme() {\n-    return \"azfs\";\n+    return AzfsResourceId.SCHEME;\n   }\n \n   @Override\n-  protected List<MatchResult> match(List<String> specs) throws IOException {\n-    // TODO\n-    return null;\n+  protected List<MatchResult> match(List<String> specs) {\n+    List<AzfsResourceId> paths =\n+        specs.stream().map(AzfsResourceId::fromUri).collect(Collectors.toList());\n+    List<AzfsResourceId> globs = new ArrayList<>();\n+    List<AzfsResourceId> nonGlobs = new ArrayList<>();\n+    List<Boolean> isGlobBooleans = new ArrayList<>();\n+\n+    for (AzfsResourceId path : paths) {\n+      if (path.isWildcard()) {\n+        globs.add(path);\n+        isGlobBooleans.add(true);\n+      } else {\n+        nonGlobs.add(path);\n+        isGlobBooleans.add(false);\n+      }\n+    }\n+\n+    Iterator<MatchResult> globMatches = matchGlobPaths(globs).iterator();\n+    Iterator<MatchResult> nonGlobMatches = matchNonGlobPaths(nonGlobs).iterator();\n+\n+    ImmutableList.Builder<MatchResult> matchResults = ImmutableList.builder();\n+    for (Boolean isGlob : isGlobBooleans) {\n+      if (isGlob) {\n+        checkState(globMatches.hasNext(), \"Expect globMatches has next.\");\n+        matchResults.add(globMatches.next());\n+      } else {\n+        checkState(nonGlobMatches.hasNext(), \"Expect nonGlobMatches has next.\");\n+        matchResults.add(nonGlobMatches.next());\n+      }\n+    }\n+    checkState(!globMatches.hasNext(), \"Expect no more elements in globMatches.\");\n+    checkState(!nonGlobMatches.hasNext(), \"Expect no more elements in nonGlobMatches.\");\n+\n+    return matchResults.build();\n+  }\n+\n+  /**\n+   * Expands glob expressions to regular expressions.\n+   *\n+   * @param globExp the glob expression to expand\n+   * @return a string with the regular expression this glob expands to\n+   */\n+  @VisibleForTesting\n+  static String wildcardToRegexp(String globExp) {\n+    StringBuilder dst = new StringBuilder();\n+    char[] src = globExp.replace(\"**/*\", \"**\").toCharArray();\n+    int i = 0;\n+    while (i < src.length) {\n+      char c = src[i++];\n+      switch (c) {\n+        case '*':\n+          // One char lookahead for **\n+          if (i < src.length && src[i] == '*') {\n+            dst.append(\".*\");\n+            ++i;\n+          } else {\n+            dst.append(\"[^/]*\");\n+          }\n+          break;\n+        case '?':\n+          dst.append(\"[^/]\");\n+          break;\n+        case '.':\n+        case '+':\n+        case '{':\n+        case '}':\n+        case '(':\n+        case ')':\n+        case '|':\n+        case '^':\n+        case '$':\n+          // These need to be escaped in regular expressions\n+          dst.append('\\\\').append(c);\n+          break;\n+        case '\\\\':\n+          i = doubleSlashes(dst, src, i);\n+          break;\n+        default:\n+          dst.append(c);\n+          break;\n+      }\n+    }\n+    return dst.toString();\n+  }\n+\n+  private static int doubleSlashes(StringBuilder dst, char[] src, int i) {\n+    // Emit the next character without special interpretation\n+    dst.append(\"\\\\\\\\\");\n+    if ((i - 1) != src.length) {\n+      dst.append(src[i]);\n+      i++;\n+    } else {\n+      // A backslash at the very end is treated like an escaped backslash\n+      dst.append('\\\\');\n+    }\n+    return i;\n+  }\n+\n+  private List<MatchResult> matchGlobPaths(List<AzfsResourceId> globs) {\n+    return FluentIterable.from(globs).transform(this::expand).toList();\n+  }\n+\n+  /** Expands a pattern into {@link MatchResult}. */\n+  @VisibleForTesting\n+  MatchResult expand(AzfsResourceId azfsPattern) {\n+\n+    checkArgument(azfsPattern.isWildcard(), \"is Wildcard\");\n+    String blobPrefix = azfsPattern.getBlobNonWildcardPrefix();\n+    Pattern wildcardAsRegexp = Pattern.compile(wildcardToRegexp(azfsPattern.getBlob()));\n+\n+    LOG.debug(\n+        \"matching files in container {}, prefix {} against pattern {}\",\n+        azfsPattern.getContainer(),\n+        blobPrefix,\n+        wildcardAsRegexp.toString());\n+\n+    ListBlobsOptions listOptions = new ListBlobsOptions().setPrefix(blobPrefix);\n+    Duration timeout = Duration.ZERO.plusMinutes(1);\n+\n+    String account = azfsPattern.getAccount();\n+    String container = azfsPattern.getContainer();\n+    BlobContainerClient blobContainerClient = client.get().getBlobContainerClient(container);\n+    PagedIterable<BlobItem> blobs = blobContainerClient.listBlobs(listOptions, timeout);\n+    List<MatchResult.Metadata> results = new ArrayList<>();\n+\n+    blobs.forEach(\n+        blob -> {\n+          String name = blob.getName();\n+          if (wildcardAsRegexp.matcher(name).matches() && !name.endsWith(\"/\")) {\n+            LOG.debug(\"Matched object: {}\", name);\n+\n+            BlobProperties properties = blobContainerClient.getBlobClient(name).getProperties();\n+            AzfsResourceId rid =\n+                AzfsResourceId.fromComponents(account, container, name)\n+                    .withSize(properties.getBlobSize())\n+                    .withLastModified(Date.from(properties.getLastModified().toInstant()));\n+\n+            results.add(toMetadata(rid, properties.getContentEncoding()));\n+          }\n+        });\n+\n+    return MatchResult.create(MatchResult.Status.OK, results);\n+  }\n+\n+  private MatchResult.Metadata toMetadata(AzfsResourceId path, String contentEncoding) {\n+\n+    checkArgument(path.getSize().isPresent(), \"path has size\");\n+    boolean isReadSeekEfficient = !NON_READ_SEEK_EFFICIENT_ENCODINGS.contains(contentEncoding);\n+\n+    return MatchResult.Metadata.builder()\n+        .setIsReadSeekEfficient(isReadSeekEfficient)\n+        .setResourceId(path)\n+        .setSizeBytes(path.getSize().get())\n+        .setLastModifiedMillis(path.getLastModified().transform(Date::getTime).or(0L))\n+        .build();\n+  }\n+\n+  /**\n+   * Returns {@link MatchResult MatchResults} for the given {@link AzfsResourceId paths}.\n+   *\n+   * <p>The number of returned {@link MatchResult MatchResults} equals to the number of given {@link\n+   * AzfsResourceId paths}. Each {@link MatchResult} contains one {@link MatchResult.Metadata}.\n+   */\n+  @VisibleForTesting\n+  private Iterable<MatchResult> matchNonGlobPaths(List<AzfsResourceId> paths) {\n+    ImmutableList.Builder<MatchResult> toReturn = ImmutableList.builder();\n+    for (AzfsResourceId path : paths) {\n+      toReturn.add(toMatchResult(path));\n+    }\n+    return toReturn.build();\n+  }\n+\n+  private MatchResult toMatchResult(AzfsResourceId path) {\n+    BlobClient blobClient =\n+        client.get().getBlobContainerClient(path.getContainer()).getBlobClient(path.getBlob());\n+    BlobProperties blobProperties;\n+\n+    try {\n+      blobProperties = blobClient.getProperties();\n+    } catch (BlobStorageException e) {\n+      if (e.getStatusCode() == 404) {\n+        return MatchResult.create(MatchResult.Status.NOT_FOUND, new FileNotFoundException());\n+      }\n+      return MatchResult.create(MatchResult.Status.ERROR, new IOException(e));\n+    }\n+\n+    return MatchResult.create(\n+        MatchResult.Status.OK,\n+        ImmutableList.of(\n+            toMetadata(\n+                path.withSize(blobProperties.getBlobSize())\n+                    .withLastModified(Date.from(blobProperties.getLastModified().toInstant())),\n+                blobProperties.getContentEncoding())));\n   }\n \n   @Override\n   protected WritableByteChannel create(AzfsResourceId resourceId, CreateOptions createOptions)\n       throws IOException {\n-    // TODO\n-    return null;\n+    BlobContainerClient blobContainerClient =\n+        client.get().getBlobContainerClient(resourceId.getContainer());\n+    if (!blobContainerClient.exists()) {\n+      throw new UnsupportedOperationException(\"create does not create containers.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 294}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTcxNDMxMg==", "bodyText": "The operation is unsupported because the user is trying to create a file in a container that doesn't exist, and I made a design decision that the create method does not recursively create containers, it only creates files within containers that already exist.  I can change this to a FileNotFoundException stating that the container doesn't exist if that is more intuitive.", "url": "https://github.com/apache/beam/pull/12581#discussion_r471714312", "createdAt": "2020-08-17T19:00:44Z", "author": {"login": "ettirapp"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "diffHunk": "@@ -17,67 +17,438 @@\n  */\n package org.apache.beam.sdk.io.azure.blobstore;\n \n+import static java.nio.channels.Channels.newChannel;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobItem;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.BlobStorageException;\n+import com.azure.storage.blob.models.ListBlobsOptions;\n+import com.microsoft.azure.storage.CloudStorageAccount;\n+import com.microsoft.azure.storage.SharedAccessAccountPolicy;\n+import java.io.FileNotFoundException;\n import java.io.IOException;\n+import java.io.OutputStream;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.time.Duration;\n+import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Date;\n+import java.util.Iterator;\n import java.util.List;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n import org.apache.beam.sdk.io.FileSystem;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreClientBuilderFactory;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n import org.apache.beam.sdk.io.fs.CreateOptions;\n import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.util.InstanceBuilder;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Supplier;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Suppliers;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableSet;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n class AzureBlobStoreFileSystem extends FileSystem<AzfsResourceId> {\n \n+  private static final Logger LOG = LoggerFactory.getLogger(AzureBlobStoreFileSystem.class);\n+\n+  private static final ImmutableSet<String> NON_READ_SEEK_EFFICIENT_ENCODINGS =\n+      ImmutableSet.of(\"gzip\");\n+\n+  private Supplier<BlobServiceClient> client;\n+  private final BlobstoreOptions options;\n+\n+  AzureBlobStoreFileSystem(BlobstoreOptions options) {\n+    this.options = checkNotNull(options, \"options\");\n+\n+    BlobServiceClientBuilder builder =\n+        InstanceBuilder.ofType(BlobstoreClientBuilderFactory.class)\n+            .fromClass(options.getBlobstoreClientFactoryClass())\n+            .build()\n+            .createBuilder(options);\n+\n+    // The Supplier is to make sure we don't call .build() unless we are actually using Azure.\n+    client = Suppliers.memoize(builder::buildClient);\n+  }\n+\n+  @VisibleForTesting\n+  void setClient(BlobServiceClient client) {\n+    this.client = Suppliers.ofInstance(client);\n+  }\n+\n+  @VisibleForTesting\n+  BlobServiceClient getClient() {\n+    return client.get();\n+  }\n+\n   @Override\n   protected String getScheme() {\n-    return \"azfs\";\n+    return AzfsResourceId.SCHEME;\n   }\n \n   @Override\n-  protected List<MatchResult> match(List<String> specs) throws IOException {\n-    // TODO\n-    return null;\n+  protected List<MatchResult> match(List<String> specs) {\n+    List<AzfsResourceId> paths =\n+        specs.stream().map(AzfsResourceId::fromUri).collect(Collectors.toList());\n+    List<AzfsResourceId> globs = new ArrayList<>();\n+    List<AzfsResourceId> nonGlobs = new ArrayList<>();\n+    List<Boolean> isGlobBooleans = new ArrayList<>();\n+\n+    for (AzfsResourceId path : paths) {\n+      if (path.isWildcard()) {\n+        globs.add(path);\n+        isGlobBooleans.add(true);\n+      } else {\n+        nonGlobs.add(path);\n+        isGlobBooleans.add(false);\n+      }\n+    }\n+\n+    Iterator<MatchResult> globMatches = matchGlobPaths(globs).iterator();\n+    Iterator<MatchResult> nonGlobMatches = matchNonGlobPaths(nonGlobs).iterator();\n+\n+    ImmutableList.Builder<MatchResult> matchResults = ImmutableList.builder();\n+    for (Boolean isGlob : isGlobBooleans) {\n+      if (isGlob) {\n+        checkState(globMatches.hasNext(), \"Expect globMatches has next.\");\n+        matchResults.add(globMatches.next());\n+      } else {\n+        checkState(nonGlobMatches.hasNext(), \"Expect nonGlobMatches has next.\");\n+        matchResults.add(nonGlobMatches.next());\n+      }\n+    }\n+    checkState(!globMatches.hasNext(), \"Expect no more elements in globMatches.\");\n+    checkState(!nonGlobMatches.hasNext(), \"Expect no more elements in nonGlobMatches.\");\n+\n+    return matchResults.build();\n+  }\n+\n+  /**\n+   * Expands glob expressions to regular expressions.\n+   *\n+   * @param globExp the glob expression to expand\n+   * @return a string with the regular expression this glob expands to\n+   */\n+  @VisibleForTesting\n+  static String wildcardToRegexp(String globExp) {\n+    StringBuilder dst = new StringBuilder();\n+    char[] src = globExp.replace(\"**/*\", \"**\").toCharArray();\n+    int i = 0;\n+    while (i < src.length) {\n+      char c = src[i++];\n+      switch (c) {\n+        case '*':\n+          // One char lookahead for **\n+          if (i < src.length && src[i] == '*') {\n+            dst.append(\".*\");\n+            ++i;\n+          } else {\n+            dst.append(\"[^/]*\");\n+          }\n+          break;\n+        case '?':\n+          dst.append(\"[^/]\");\n+          break;\n+        case '.':\n+        case '+':\n+        case '{':\n+        case '}':\n+        case '(':\n+        case ')':\n+        case '|':\n+        case '^':\n+        case '$':\n+          // These need to be escaped in regular expressions\n+          dst.append('\\\\').append(c);\n+          break;\n+        case '\\\\':\n+          i = doubleSlashes(dst, src, i);\n+          break;\n+        default:\n+          dst.append(c);\n+          break;\n+      }\n+    }\n+    return dst.toString();\n+  }\n+\n+  private static int doubleSlashes(StringBuilder dst, char[] src, int i) {\n+    // Emit the next character without special interpretation\n+    dst.append(\"\\\\\\\\\");\n+    if ((i - 1) != src.length) {\n+      dst.append(src[i]);\n+      i++;\n+    } else {\n+      // A backslash at the very end is treated like an escaped backslash\n+      dst.append('\\\\');\n+    }\n+    return i;\n+  }\n+\n+  private List<MatchResult> matchGlobPaths(List<AzfsResourceId> globs) {\n+    return FluentIterable.from(globs).transform(this::expand).toList();\n+  }\n+\n+  /** Expands a pattern into {@link MatchResult}. */\n+  @VisibleForTesting\n+  MatchResult expand(AzfsResourceId azfsPattern) {\n+\n+    checkArgument(azfsPattern.isWildcard(), \"is Wildcard\");\n+    String blobPrefix = azfsPattern.getBlobNonWildcardPrefix();\n+    Pattern wildcardAsRegexp = Pattern.compile(wildcardToRegexp(azfsPattern.getBlob()));\n+\n+    LOG.debug(\n+        \"matching files in container {}, prefix {} against pattern {}\",\n+        azfsPattern.getContainer(),\n+        blobPrefix,\n+        wildcardAsRegexp.toString());\n+\n+    ListBlobsOptions listOptions = new ListBlobsOptions().setPrefix(blobPrefix);\n+    Duration timeout = Duration.ZERO.plusMinutes(1);\n+\n+    String account = azfsPattern.getAccount();\n+    String container = azfsPattern.getContainer();\n+    BlobContainerClient blobContainerClient = client.get().getBlobContainerClient(container);\n+    PagedIterable<BlobItem> blobs = blobContainerClient.listBlobs(listOptions, timeout);\n+    List<MatchResult.Metadata> results = new ArrayList<>();\n+\n+    blobs.forEach(\n+        blob -> {\n+          String name = blob.getName();\n+          if (wildcardAsRegexp.matcher(name).matches() && !name.endsWith(\"/\")) {\n+            LOG.debug(\"Matched object: {}\", name);\n+\n+            BlobProperties properties = blobContainerClient.getBlobClient(name).getProperties();\n+            AzfsResourceId rid =\n+                AzfsResourceId.fromComponents(account, container, name)\n+                    .withSize(properties.getBlobSize())\n+                    .withLastModified(Date.from(properties.getLastModified().toInstant()));\n+\n+            results.add(toMetadata(rid, properties.getContentEncoding()));\n+          }\n+        });\n+\n+    return MatchResult.create(MatchResult.Status.OK, results);\n+  }\n+\n+  private MatchResult.Metadata toMetadata(AzfsResourceId path, String contentEncoding) {\n+\n+    checkArgument(path.getSize().isPresent(), \"path has size\");\n+    boolean isReadSeekEfficient = !NON_READ_SEEK_EFFICIENT_ENCODINGS.contains(contentEncoding);\n+\n+    return MatchResult.Metadata.builder()\n+        .setIsReadSeekEfficient(isReadSeekEfficient)\n+        .setResourceId(path)\n+        .setSizeBytes(path.getSize().get())\n+        .setLastModifiedMillis(path.getLastModified().transform(Date::getTime).or(0L))\n+        .build();\n+  }\n+\n+  /**\n+   * Returns {@link MatchResult MatchResults} for the given {@link AzfsResourceId paths}.\n+   *\n+   * <p>The number of returned {@link MatchResult MatchResults} equals to the number of given {@link\n+   * AzfsResourceId paths}. Each {@link MatchResult} contains one {@link MatchResult.Metadata}.\n+   */\n+  @VisibleForTesting\n+  private Iterable<MatchResult> matchNonGlobPaths(List<AzfsResourceId> paths) {\n+    ImmutableList.Builder<MatchResult> toReturn = ImmutableList.builder();\n+    for (AzfsResourceId path : paths) {\n+      toReturn.add(toMatchResult(path));\n+    }\n+    return toReturn.build();\n+  }\n+\n+  private MatchResult toMatchResult(AzfsResourceId path) {\n+    BlobClient blobClient =\n+        client.get().getBlobContainerClient(path.getContainer()).getBlobClient(path.getBlob());\n+    BlobProperties blobProperties;\n+\n+    try {\n+      blobProperties = blobClient.getProperties();\n+    } catch (BlobStorageException e) {\n+      if (e.getStatusCode() == 404) {\n+        return MatchResult.create(MatchResult.Status.NOT_FOUND, new FileNotFoundException());\n+      }\n+      return MatchResult.create(MatchResult.Status.ERROR, new IOException(e));\n+    }\n+\n+    return MatchResult.create(\n+        MatchResult.Status.OK,\n+        ImmutableList.of(\n+            toMetadata(\n+                path.withSize(blobProperties.getBlobSize())\n+                    .withLastModified(Date.from(blobProperties.getLastModified().toInstant())),\n+                blobProperties.getContentEncoding())));\n   }\n \n   @Override\n   protected WritableByteChannel create(AzfsResourceId resourceId, CreateOptions createOptions)\n       throws IOException {\n-    // TODO\n-    return null;\n+    BlobContainerClient blobContainerClient =\n+        client.get().getBlobContainerClient(resourceId.getContainer());\n+    if (!blobContainerClient.exists()) {\n+      throw new UnsupportedOperationException(\"create does not create containers.\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY1MTA2MA=="}, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 294}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk0ODA2MTk4OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxNzozNTozNVrOHBzUww==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQwMzo1MjozOFrOHCwlZw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY1MTUyMw==", "bodyText": "I see that this code is duplicated in other filesystems. Would you be willing to move this to something like FileSystemUtils.java to live right next to FileSystem.java and remove the duplicated code from other places? (this can be done as part of a follow-up PR, but can you file a JIRA ticket to track it?)", "url": "https://github.com/apache/beam/pull/12581#discussion_r471651523", "createdAt": "2020-08-17T17:35:35Z", "author": {"login": "pabloem"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "diffHunk": "@@ -17,67 +17,438 @@\n  */\n package org.apache.beam.sdk.io.azure.blobstore;\n \n+import static java.nio.channels.Channels.newChannel;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobItem;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.BlobStorageException;\n+import com.azure.storage.blob.models.ListBlobsOptions;\n+import com.microsoft.azure.storage.CloudStorageAccount;\n+import com.microsoft.azure.storage.SharedAccessAccountPolicy;\n+import java.io.FileNotFoundException;\n import java.io.IOException;\n+import java.io.OutputStream;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.time.Duration;\n+import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Date;\n+import java.util.Iterator;\n import java.util.List;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n import org.apache.beam.sdk.io.FileSystem;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreClientBuilderFactory;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n import org.apache.beam.sdk.io.fs.CreateOptions;\n import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.util.InstanceBuilder;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Supplier;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Suppliers;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableSet;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n class AzureBlobStoreFileSystem extends FileSystem<AzfsResourceId> {\n \n+  private static final Logger LOG = LoggerFactory.getLogger(AzureBlobStoreFileSystem.class);\n+\n+  private static final ImmutableSet<String> NON_READ_SEEK_EFFICIENT_ENCODINGS =\n+      ImmutableSet.of(\"gzip\");\n+\n+  private Supplier<BlobServiceClient> client;\n+  private final BlobstoreOptions options;\n+\n+  AzureBlobStoreFileSystem(BlobstoreOptions options) {\n+    this.options = checkNotNull(options, \"options\");\n+\n+    BlobServiceClientBuilder builder =\n+        InstanceBuilder.ofType(BlobstoreClientBuilderFactory.class)\n+            .fromClass(options.getBlobstoreClientFactoryClass())\n+            .build()\n+            .createBuilder(options);\n+\n+    // The Supplier is to make sure we don't call .build() unless we are actually using Azure.\n+    client = Suppliers.memoize(builder::buildClient);\n+  }\n+\n+  @VisibleForTesting\n+  void setClient(BlobServiceClient client) {\n+    this.client = Suppliers.ofInstance(client);\n+  }\n+\n+  @VisibleForTesting\n+  BlobServiceClient getClient() {\n+    return client.get();\n+  }\n+\n   @Override\n   protected String getScheme() {\n-    return \"azfs\";\n+    return AzfsResourceId.SCHEME;\n   }\n \n   @Override\n-  protected List<MatchResult> match(List<String> specs) throws IOException {\n-    // TODO\n-    return null;\n+  protected List<MatchResult> match(List<String> specs) {\n+    List<AzfsResourceId> paths =\n+        specs.stream().map(AzfsResourceId::fromUri).collect(Collectors.toList());\n+    List<AzfsResourceId> globs = new ArrayList<>();\n+    List<AzfsResourceId> nonGlobs = new ArrayList<>();\n+    List<Boolean> isGlobBooleans = new ArrayList<>();\n+\n+    for (AzfsResourceId path : paths) {\n+      if (path.isWildcard()) {\n+        globs.add(path);\n+        isGlobBooleans.add(true);\n+      } else {\n+        nonGlobs.add(path);\n+        isGlobBooleans.add(false);\n+      }\n+    }\n+\n+    Iterator<MatchResult> globMatches = matchGlobPaths(globs).iterator();\n+    Iterator<MatchResult> nonGlobMatches = matchNonGlobPaths(nonGlobs).iterator();\n+\n+    ImmutableList.Builder<MatchResult> matchResults = ImmutableList.builder();\n+    for (Boolean isGlob : isGlobBooleans) {\n+      if (isGlob) {\n+        checkState(globMatches.hasNext(), \"Expect globMatches has next.\");\n+        matchResults.add(globMatches.next());\n+      } else {\n+        checkState(nonGlobMatches.hasNext(), \"Expect nonGlobMatches has next.\");\n+        matchResults.add(nonGlobMatches.next());\n+      }\n+    }\n+    checkState(!globMatches.hasNext(), \"Expect no more elements in globMatches.\");\n+    checkState(!nonGlobMatches.hasNext(), \"Expect no more elements in nonGlobMatches.\");\n+\n+    return matchResults.build();\n+  }\n+\n+  /**\n+   * Expands glob expressions to regular expressions.\n+   *\n+   * @param globExp the glob expression to expand\n+   * @return a string with the regular expression this glob expands to\n+   */\n+  @VisibleForTesting\n+  static String wildcardToRegexp(String globExp) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 134}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjY1NTIwNw==", "bodyText": "Sure, I filed a ticket at https://issues.apache.org/jira/browse/BEAM-10758.", "url": "https://github.com/apache/beam/pull/12581#discussion_r472655207", "createdAt": "2020-08-19T03:52:38Z", "author": {"login": "ettirapp"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "diffHunk": "@@ -17,67 +17,438 @@\n  */\n package org.apache.beam.sdk.io.azure.blobstore;\n \n+import static java.nio.channels.Channels.newChannel;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobItem;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.BlobStorageException;\n+import com.azure.storage.blob.models.ListBlobsOptions;\n+import com.microsoft.azure.storage.CloudStorageAccount;\n+import com.microsoft.azure.storage.SharedAccessAccountPolicy;\n+import java.io.FileNotFoundException;\n import java.io.IOException;\n+import java.io.OutputStream;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.time.Duration;\n+import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Date;\n+import java.util.Iterator;\n import java.util.List;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n import org.apache.beam.sdk.io.FileSystem;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreClientBuilderFactory;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n import org.apache.beam.sdk.io.fs.CreateOptions;\n import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.util.InstanceBuilder;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Supplier;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Suppliers;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableSet;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n class AzureBlobStoreFileSystem extends FileSystem<AzfsResourceId> {\n \n+  private static final Logger LOG = LoggerFactory.getLogger(AzureBlobStoreFileSystem.class);\n+\n+  private static final ImmutableSet<String> NON_READ_SEEK_EFFICIENT_ENCODINGS =\n+      ImmutableSet.of(\"gzip\");\n+\n+  private Supplier<BlobServiceClient> client;\n+  private final BlobstoreOptions options;\n+\n+  AzureBlobStoreFileSystem(BlobstoreOptions options) {\n+    this.options = checkNotNull(options, \"options\");\n+\n+    BlobServiceClientBuilder builder =\n+        InstanceBuilder.ofType(BlobstoreClientBuilderFactory.class)\n+            .fromClass(options.getBlobstoreClientFactoryClass())\n+            .build()\n+            .createBuilder(options);\n+\n+    // The Supplier is to make sure we don't call .build() unless we are actually using Azure.\n+    client = Suppliers.memoize(builder::buildClient);\n+  }\n+\n+  @VisibleForTesting\n+  void setClient(BlobServiceClient client) {\n+    this.client = Suppliers.ofInstance(client);\n+  }\n+\n+  @VisibleForTesting\n+  BlobServiceClient getClient() {\n+    return client.get();\n+  }\n+\n   @Override\n   protected String getScheme() {\n-    return \"azfs\";\n+    return AzfsResourceId.SCHEME;\n   }\n \n   @Override\n-  protected List<MatchResult> match(List<String> specs) throws IOException {\n-    // TODO\n-    return null;\n+  protected List<MatchResult> match(List<String> specs) {\n+    List<AzfsResourceId> paths =\n+        specs.stream().map(AzfsResourceId::fromUri).collect(Collectors.toList());\n+    List<AzfsResourceId> globs = new ArrayList<>();\n+    List<AzfsResourceId> nonGlobs = new ArrayList<>();\n+    List<Boolean> isGlobBooleans = new ArrayList<>();\n+\n+    for (AzfsResourceId path : paths) {\n+      if (path.isWildcard()) {\n+        globs.add(path);\n+        isGlobBooleans.add(true);\n+      } else {\n+        nonGlobs.add(path);\n+        isGlobBooleans.add(false);\n+      }\n+    }\n+\n+    Iterator<MatchResult> globMatches = matchGlobPaths(globs).iterator();\n+    Iterator<MatchResult> nonGlobMatches = matchNonGlobPaths(nonGlobs).iterator();\n+\n+    ImmutableList.Builder<MatchResult> matchResults = ImmutableList.builder();\n+    for (Boolean isGlob : isGlobBooleans) {\n+      if (isGlob) {\n+        checkState(globMatches.hasNext(), \"Expect globMatches has next.\");\n+        matchResults.add(globMatches.next());\n+      } else {\n+        checkState(nonGlobMatches.hasNext(), \"Expect nonGlobMatches has next.\");\n+        matchResults.add(nonGlobMatches.next());\n+      }\n+    }\n+    checkState(!globMatches.hasNext(), \"Expect no more elements in globMatches.\");\n+    checkState(!nonGlobMatches.hasNext(), \"Expect no more elements in nonGlobMatches.\");\n+\n+    return matchResults.build();\n+  }\n+\n+  /**\n+   * Expands glob expressions to regular expressions.\n+   *\n+   * @param globExp the glob expression to expand\n+   * @return a string with the regular expression this glob expands to\n+   */\n+  @VisibleForTesting\n+  static String wildcardToRegexp(String globExp) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY1MTUyMw=="}, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 134}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk0ODA3Nzk0OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxNzo0MDoyOVrOHBzesQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxNzo0MDoyOVrOHBzesQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY1NDA2NQ==", "bodyText": "it's not that important, but name here contains only the blob name, right? Can you include the container and account in the log?", "url": "https://github.com/apache/beam/pull/12581#discussion_r471654065", "createdAt": "2020-08-17T17:40:29Z", "author": {"login": "pabloem"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "diffHunk": "@@ -17,67 +17,438 @@\n  */\n package org.apache.beam.sdk.io.azure.blobstore;\n \n+import static java.nio.channels.Channels.newChannel;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobItem;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.BlobStorageException;\n+import com.azure.storage.blob.models.ListBlobsOptions;\n+import com.microsoft.azure.storage.CloudStorageAccount;\n+import com.microsoft.azure.storage.SharedAccessAccountPolicy;\n+import java.io.FileNotFoundException;\n import java.io.IOException;\n+import java.io.OutputStream;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.time.Duration;\n+import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Date;\n+import java.util.Iterator;\n import java.util.List;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n import org.apache.beam.sdk.io.FileSystem;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreClientBuilderFactory;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n import org.apache.beam.sdk.io.fs.CreateOptions;\n import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.util.InstanceBuilder;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Supplier;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Suppliers;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableSet;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n class AzureBlobStoreFileSystem extends FileSystem<AzfsResourceId> {\n \n+  private static final Logger LOG = LoggerFactory.getLogger(AzureBlobStoreFileSystem.class);\n+\n+  private static final ImmutableSet<String> NON_READ_SEEK_EFFICIENT_ENCODINGS =\n+      ImmutableSet.of(\"gzip\");\n+\n+  private Supplier<BlobServiceClient> client;\n+  private final BlobstoreOptions options;\n+\n+  AzureBlobStoreFileSystem(BlobstoreOptions options) {\n+    this.options = checkNotNull(options, \"options\");\n+\n+    BlobServiceClientBuilder builder =\n+        InstanceBuilder.ofType(BlobstoreClientBuilderFactory.class)\n+            .fromClass(options.getBlobstoreClientFactoryClass())\n+            .build()\n+            .createBuilder(options);\n+\n+    // The Supplier is to make sure we don't call .build() unless we are actually using Azure.\n+    client = Suppliers.memoize(builder::buildClient);\n+  }\n+\n+  @VisibleForTesting\n+  void setClient(BlobServiceClient client) {\n+    this.client = Suppliers.ofInstance(client);\n+  }\n+\n+  @VisibleForTesting\n+  BlobServiceClient getClient() {\n+    return client.get();\n+  }\n+\n   @Override\n   protected String getScheme() {\n-    return \"azfs\";\n+    return AzfsResourceId.SCHEME;\n   }\n \n   @Override\n-  protected List<MatchResult> match(List<String> specs) throws IOException {\n-    // TODO\n-    return null;\n+  protected List<MatchResult> match(List<String> specs) {\n+    List<AzfsResourceId> paths =\n+        specs.stream().map(AzfsResourceId::fromUri).collect(Collectors.toList());\n+    List<AzfsResourceId> globs = new ArrayList<>();\n+    List<AzfsResourceId> nonGlobs = new ArrayList<>();\n+    List<Boolean> isGlobBooleans = new ArrayList<>();\n+\n+    for (AzfsResourceId path : paths) {\n+      if (path.isWildcard()) {\n+        globs.add(path);\n+        isGlobBooleans.add(true);\n+      } else {\n+        nonGlobs.add(path);\n+        isGlobBooleans.add(false);\n+      }\n+    }\n+\n+    Iterator<MatchResult> globMatches = matchGlobPaths(globs).iterator();\n+    Iterator<MatchResult> nonGlobMatches = matchNonGlobPaths(nonGlobs).iterator();\n+\n+    ImmutableList.Builder<MatchResult> matchResults = ImmutableList.builder();\n+    for (Boolean isGlob : isGlobBooleans) {\n+      if (isGlob) {\n+        checkState(globMatches.hasNext(), \"Expect globMatches has next.\");\n+        matchResults.add(globMatches.next());\n+      } else {\n+        checkState(nonGlobMatches.hasNext(), \"Expect nonGlobMatches has next.\");\n+        matchResults.add(nonGlobMatches.next());\n+      }\n+    }\n+    checkState(!globMatches.hasNext(), \"Expect no more elements in globMatches.\");\n+    checkState(!nonGlobMatches.hasNext(), \"Expect no more elements in nonGlobMatches.\");\n+\n+    return matchResults.build();\n+  }\n+\n+  /**\n+   * Expands glob expressions to regular expressions.\n+   *\n+   * @param globExp the glob expression to expand\n+   * @return a string with the regular expression this glob expands to\n+   */\n+  @VisibleForTesting\n+  static String wildcardToRegexp(String globExp) {\n+    StringBuilder dst = new StringBuilder();\n+    char[] src = globExp.replace(\"**/*\", \"**\").toCharArray();\n+    int i = 0;\n+    while (i < src.length) {\n+      char c = src[i++];\n+      switch (c) {\n+        case '*':\n+          // One char lookahead for **\n+          if (i < src.length && src[i] == '*') {\n+            dst.append(\".*\");\n+            ++i;\n+          } else {\n+            dst.append(\"[^/]*\");\n+          }\n+          break;\n+        case '?':\n+          dst.append(\"[^/]\");\n+          break;\n+        case '.':\n+        case '+':\n+        case '{':\n+        case '}':\n+        case '(':\n+        case ')':\n+        case '|':\n+        case '^':\n+        case '$':\n+          // These need to be escaped in regular expressions\n+          dst.append('\\\\').append(c);\n+          break;\n+        case '\\\\':\n+          i = doubleSlashes(dst, src, i);\n+          break;\n+        default:\n+          dst.append(c);\n+          break;\n+      }\n+    }\n+    return dst.toString();\n+  }\n+\n+  private static int doubleSlashes(StringBuilder dst, char[] src, int i) {\n+    // Emit the next character without special interpretation\n+    dst.append(\"\\\\\\\\\");\n+    if ((i - 1) != src.length) {\n+      dst.append(src[i]);\n+      i++;\n+    } else {\n+      // A backslash at the very end is treated like an escaped backslash\n+      dst.append('\\\\');\n+    }\n+    return i;\n+  }\n+\n+  private List<MatchResult> matchGlobPaths(List<AzfsResourceId> globs) {\n+    return FluentIterable.from(globs).transform(this::expand).toList();\n+  }\n+\n+  /** Expands a pattern into {@link MatchResult}. */\n+  @VisibleForTesting\n+  MatchResult expand(AzfsResourceId azfsPattern) {\n+\n+    checkArgument(azfsPattern.isWildcard(), \"is Wildcard\");\n+    String blobPrefix = azfsPattern.getBlobNonWildcardPrefix();\n+    Pattern wildcardAsRegexp = Pattern.compile(wildcardToRegexp(azfsPattern.getBlob()));\n+\n+    LOG.debug(\n+        \"matching files in container {}, prefix {} against pattern {}\",\n+        azfsPattern.getContainer(),\n+        blobPrefix,\n+        wildcardAsRegexp.toString());\n+\n+    ListBlobsOptions listOptions = new ListBlobsOptions().setPrefix(blobPrefix);\n+    Duration timeout = Duration.ZERO.plusMinutes(1);\n+\n+    String account = azfsPattern.getAccount();\n+    String container = azfsPattern.getContainer();\n+    BlobContainerClient blobContainerClient = client.get().getBlobContainerClient(container);\n+    PagedIterable<BlobItem> blobs = blobContainerClient.listBlobs(listOptions, timeout);\n+    List<MatchResult.Metadata> results = new ArrayList<>();\n+\n+    blobs.forEach(\n+        blob -> {\n+          String name = blob.getName();\n+          if (wildcardAsRegexp.matcher(name).matches() && !name.endsWith(\"/\")) {\n+            LOG.debug(\"Matched object: {}\", name);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 220}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk0ODA5NjY1OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxNzo0NjoxMFrOHBzpyg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQxNjo1MjozMlrOHDQh2w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY1NjkwNg==", "bodyText": "What happens if there are no matches whatsoever? I guess results would be empty and that's it?", "url": "https://github.com/apache/beam/pull/12581#discussion_r471656906", "createdAt": "2020-08-17T17:46:10Z", "author": {"login": "pabloem"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "diffHunk": "@@ -17,67 +17,438 @@\n  */\n package org.apache.beam.sdk.io.azure.blobstore;\n \n+import static java.nio.channels.Channels.newChannel;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobItem;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.BlobStorageException;\n+import com.azure.storage.blob.models.ListBlobsOptions;\n+import com.microsoft.azure.storage.CloudStorageAccount;\n+import com.microsoft.azure.storage.SharedAccessAccountPolicy;\n+import java.io.FileNotFoundException;\n import java.io.IOException;\n+import java.io.OutputStream;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.time.Duration;\n+import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Date;\n+import java.util.Iterator;\n import java.util.List;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n import org.apache.beam.sdk.io.FileSystem;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreClientBuilderFactory;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n import org.apache.beam.sdk.io.fs.CreateOptions;\n import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.util.InstanceBuilder;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Supplier;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Suppliers;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableSet;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n class AzureBlobStoreFileSystem extends FileSystem<AzfsResourceId> {\n \n+  private static final Logger LOG = LoggerFactory.getLogger(AzureBlobStoreFileSystem.class);\n+\n+  private static final ImmutableSet<String> NON_READ_SEEK_EFFICIENT_ENCODINGS =\n+      ImmutableSet.of(\"gzip\");\n+\n+  private Supplier<BlobServiceClient> client;\n+  private final BlobstoreOptions options;\n+\n+  AzureBlobStoreFileSystem(BlobstoreOptions options) {\n+    this.options = checkNotNull(options, \"options\");\n+\n+    BlobServiceClientBuilder builder =\n+        InstanceBuilder.ofType(BlobstoreClientBuilderFactory.class)\n+            .fromClass(options.getBlobstoreClientFactoryClass())\n+            .build()\n+            .createBuilder(options);\n+\n+    // The Supplier is to make sure we don't call .build() unless we are actually using Azure.\n+    client = Suppliers.memoize(builder::buildClient);\n+  }\n+\n+  @VisibleForTesting\n+  void setClient(BlobServiceClient client) {\n+    this.client = Suppliers.ofInstance(client);\n+  }\n+\n+  @VisibleForTesting\n+  BlobServiceClient getClient() {\n+    return client.get();\n+  }\n+\n   @Override\n   protected String getScheme() {\n-    return \"azfs\";\n+    return AzfsResourceId.SCHEME;\n   }\n \n   @Override\n-  protected List<MatchResult> match(List<String> specs) throws IOException {\n-    // TODO\n-    return null;\n+  protected List<MatchResult> match(List<String> specs) {\n+    List<AzfsResourceId> paths =\n+        specs.stream().map(AzfsResourceId::fromUri).collect(Collectors.toList());\n+    List<AzfsResourceId> globs = new ArrayList<>();\n+    List<AzfsResourceId> nonGlobs = new ArrayList<>();\n+    List<Boolean> isGlobBooleans = new ArrayList<>();\n+\n+    for (AzfsResourceId path : paths) {\n+      if (path.isWildcard()) {\n+        globs.add(path);\n+        isGlobBooleans.add(true);\n+      } else {\n+        nonGlobs.add(path);\n+        isGlobBooleans.add(false);\n+      }\n+    }\n+\n+    Iterator<MatchResult> globMatches = matchGlobPaths(globs).iterator();\n+    Iterator<MatchResult> nonGlobMatches = matchNonGlobPaths(nonGlobs).iterator();\n+\n+    ImmutableList.Builder<MatchResult> matchResults = ImmutableList.builder();\n+    for (Boolean isGlob : isGlobBooleans) {\n+      if (isGlob) {\n+        checkState(globMatches.hasNext(), \"Expect globMatches has next.\");\n+        matchResults.add(globMatches.next());\n+      } else {\n+        checkState(nonGlobMatches.hasNext(), \"Expect nonGlobMatches has next.\");\n+        matchResults.add(nonGlobMatches.next());\n+      }\n+    }\n+    checkState(!globMatches.hasNext(), \"Expect no more elements in globMatches.\");\n+    checkState(!nonGlobMatches.hasNext(), \"Expect no more elements in nonGlobMatches.\");\n+\n+    return matchResults.build();\n+  }\n+\n+  /**\n+   * Expands glob expressions to regular expressions.\n+   *\n+   * @param globExp the glob expression to expand\n+   * @return a string with the regular expression this glob expands to\n+   */\n+  @VisibleForTesting\n+  static String wildcardToRegexp(String globExp) {\n+    StringBuilder dst = new StringBuilder();\n+    char[] src = globExp.replace(\"**/*\", \"**\").toCharArray();\n+    int i = 0;\n+    while (i < src.length) {\n+      char c = src[i++];\n+      switch (c) {\n+        case '*':\n+          // One char lookahead for **\n+          if (i < src.length && src[i] == '*') {\n+            dst.append(\".*\");\n+            ++i;\n+          } else {\n+            dst.append(\"[^/]*\");\n+          }\n+          break;\n+        case '?':\n+          dst.append(\"[^/]\");\n+          break;\n+        case '.':\n+        case '+':\n+        case '{':\n+        case '}':\n+        case '(':\n+        case ')':\n+        case '|':\n+        case '^':\n+        case '$':\n+          // These need to be escaped in regular expressions\n+          dst.append('\\\\').append(c);\n+          break;\n+        case '\\\\':\n+          i = doubleSlashes(dst, src, i);\n+          break;\n+        default:\n+          dst.append(c);\n+          break;\n+      }\n+    }\n+    return dst.toString();\n+  }\n+\n+  private static int doubleSlashes(StringBuilder dst, char[] src, int i) {\n+    // Emit the next character without special interpretation\n+    dst.append(\"\\\\\\\\\");\n+    if ((i - 1) != src.length) {\n+      dst.append(src[i]);\n+      i++;\n+    } else {\n+      // A backslash at the very end is treated like an escaped backslash\n+      dst.append('\\\\');\n+    }\n+    return i;\n+  }\n+\n+  private List<MatchResult> matchGlobPaths(List<AzfsResourceId> globs) {\n+    return FluentIterable.from(globs).transform(this::expand).toList();\n+  }\n+\n+  /** Expands a pattern into {@link MatchResult}. */\n+  @VisibleForTesting\n+  MatchResult expand(AzfsResourceId azfsPattern) {\n+\n+    checkArgument(azfsPattern.isWildcard(), \"is Wildcard\");\n+    String blobPrefix = azfsPattern.getBlobNonWildcardPrefix();\n+    Pattern wildcardAsRegexp = Pattern.compile(wildcardToRegexp(azfsPattern.getBlob()));\n+\n+    LOG.debug(\n+        \"matching files in container {}, prefix {} against pattern {}\",\n+        azfsPattern.getContainer(),\n+        blobPrefix,\n+        wildcardAsRegexp.toString());\n+\n+    ListBlobsOptions listOptions = new ListBlobsOptions().setPrefix(blobPrefix);\n+    Duration timeout = Duration.ZERO.plusMinutes(1);\n+\n+    String account = azfsPattern.getAccount();\n+    String container = azfsPattern.getContainer();\n+    BlobContainerClient blobContainerClient = client.get().getBlobContainerClient(container);\n+    PagedIterable<BlobItem> blobs = blobContainerClient.listBlobs(listOptions, timeout);\n+    List<MatchResult.Metadata> results = new ArrayList<>();\n+\n+    blobs.forEach(\n+        blob -> {\n+          String name = blob.getName();\n+          if (wildcardAsRegexp.matcher(name).matches() && !name.endsWith(\"/\")) {\n+            LOG.debug(\"Matched object: {}\", name);\n+\n+            BlobProperties properties = blobContainerClient.getBlobClient(name).getProperties();\n+            AzfsResourceId rid =\n+                AzfsResourceId.fromComponents(account, container, name)\n+                    .withSize(properties.getBlobSize())\n+                    .withLastModified(Date.from(properties.getLastModified().toInstant()));\n+\n+            results.add(toMetadata(rid, properties.getContentEncoding()));\n+          }\n+        });\n+\n+    return MatchResult.create(MatchResult.Status.OK, results);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 232}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjY3Mzg2NA==", "bodyText": "I looked into this and it seems that it depends on the EmptyMatchTreatment used in the Filesystems::match call.  See https://github.com/apache/beam/blob/master/sdks/java/core/src/main/java/org/apache/beam/sdk/io/fs/EmptyMatchTreatment.java.  So in the case where there are no matches, I can either return MatchResult.create(MatchResult.Status.OK, results) or MatchResult.create(MatchResult.Status.NOT_FOUND, new FileNotFoundException()), and these two options will be treated in the same way at https://github.com/apache/beam/blob/master/sdks/java/core/src/main/java/org/apache/beam/sdk/io/FileSystems.java#L159-L160.  So I can leave the code as is, unless the second option is more readable.", "url": "https://github.com/apache/beam/pull/12581#discussion_r472673864", "createdAt": "2020-08-19T04:22:52Z", "author": {"login": "ettirapp"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "diffHunk": "@@ -17,67 +17,438 @@\n  */\n package org.apache.beam.sdk.io.azure.blobstore;\n \n+import static java.nio.channels.Channels.newChannel;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobItem;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.BlobStorageException;\n+import com.azure.storage.blob.models.ListBlobsOptions;\n+import com.microsoft.azure.storage.CloudStorageAccount;\n+import com.microsoft.azure.storage.SharedAccessAccountPolicy;\n+import java.io.FileNotFoundException;\n import java.io.IOException;\n+import java.io.OutputStream;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.time.Duration;\n+import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Date;\n+import java.util.Iterator;\n import java.util.List;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n import org.apache.beam.sdk.io.FileSystem;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreClientBuilderFactory;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n import org.apache.beam.sdk.io.fs.CreateOptions;\n import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.util.InstanceBuilder;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Supplier;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Suppliers;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableSet;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n class AzureBlobStoreFileSystem extends FileSystem<AzfsResourceId> {\n \n+  private static final Logger LOG = LoggerFactory.getLogger(AzureBlobStoreFileSystem.class);\n+\n+  private static final ImmutableSet<String> NON_READ_SEEK_EFFICIENT_ENCODINGS =\n+      ImmutableSet.of(\"gzip\");\n+\n+  private Supplier<BlobServiceClient> client;\n+  private final BlobstoreOptions options;\n+\n+  AzureBlobStoreFileSystem(BlobstoreOptions options) {\n+    this.options = checkNotNull(options, \"options\");\n+\n+    BlobServiceClientBuilder builder =\n+        InstanceBuilder.ofType(BlobstoreClientBuilderFactory.class)\n+            .fromClass(options.getBlobstoreClientFactoryClass())\n+            .build()\n+            .createBuilder(options);\n+\n+    // The Supplier is to make sure we don't call .build() unless we are actually using Azure.\n+    client = Suppliers.memoize(builder::buildClient);\n+  }\n+\n+  @VisibleForTesting\n+  void setClient(BlobServiceClient client) {\n+    this.client = Suppliers.ofInstance(client);\n+  }\n+\n+  @VisibleForTesting\n+  BlobServiceClient getClient() {\n+    return client.get();\n+  }\n+\n   @Override\n   protected String getScheme() {\n-    return \"azfs\";\n+    return AzfsResourceId.SCHEME;\n   }\n \n   @Override\n-  protected List<MatchResult> match(List<String> specs) throws IOException {\n-    // TODO\n-    return null;\n+  protected List<MatchResult> match(List<String> specs) {\n+    List<AzfsResourceId> paths =\n+        specs.stream().map(AzfsResourceId::fromUri).collect(Collectors.toList());\n+    List<AzfsResourceId> globs = new ArrayList<>();\n+    List<AzfsResourceId> nonGlobs = new ArrayList<>();\n+    List<Boolean> isGlobBooleans = new ArrayList<>();\n+\n+    for (AzfsResourceId path : paths) {\n+      if (path.isWildcard()) {\n+        globs.add(path);\n+        isGlobBooleans.add(true);\n+      } else {\n+        nonGlobs.add(path);\n+        isGlobBooleans.add(false);\n+      }\n+    }\n+\n+    Iterator<MatchResult> globMatches = matchGlobPaths(globs).iterator();\n+    Iterator<MatchResult> nonGlobMatches = matchNonGlobPaths(nonGlobs).iterator();\n+\n+    ImmutableList.Builder<MatchResult> matchResults = ImmutableList.builder();\n+    for (Boolean isGlob : isGlobBooleans) {\n+      if (isGlob) {\n+        checkState(globMatches.hasNext(), \"Expect globMatches has next.\");\n+        matchResults.add(globMatches.next());\n+      } else {\n+        checkState(nonGlobMatches.hasNext(), \"Expect nonGlobMatches has next.\");\n+        matchResults.add(nonGlobMatches.next());\n+      }\n+    }\n+    checkState(!globMatches.hasNext(), \"Expect no more elements in globMatches.\");\n+    checkState(!nonGlobMatches.hasNext(), \"Expect no more elements in nonGlobMatches.\");\n+\n+    return matchResults.build();\n+  }\n+\n+  /**\n+   * Expands glob expressions to regular expressions.\n+   *\n+   * @param globExp the glob expression to expand\n+   * @return a string with the regular expression this glob expands to\n+   */\n+  @VisibleForTesting\n+  static String wildcardToRegexp(String globExp) {\n+    StringBuilder dst = new StringBuilder();\n+    char[] src = globExp.replace(\"**/*\", \"**\").toCharArray();\n+    int i = 0;\n+    while (i < src.length) {\n+      char c = src[i++];\n+      switch (c) {\n+        case '*':\n+          // One char lookahead for **\n+          if (i < src.length && src[i] == '*') {\n+            dst.append(\".*\");\n+            ++i;\n+          } else {\n+            dst.append(\"[^/]*\");\n+          }\n+          break;\n+        case '?':\n+          dst.append(\"[^/]\");\n+          break;\n+        case '.':\n+        case '+':\n+        case '{':\n+        case '}':\n+        case '(':\n+        case ')':\n+        case '|':\n+        case '^':\n+        case '$':\n+          // These need to be escaped in regular expressions\n+          dst.append('\\\\').append(c);\n+          break;\n+        case '\\\\':\n+          i = doubleSlashes(dst, src, i);\n+          break;\n+        default:\n+          dst.append(c);\n+          break;\n+      }\n+    }\n+    return dst.toString();\n+  }\n+\n+  private static int doubleSlashes(StringBuilder dst, char[] src, int i) {\n+    // Emit the next character without special interpretation\n+    dst.append(\"\\\\\\\\\");\n+    if ((i - 1) != src.length) {\n+      dst.append(src[i]);\n+      i++;\n+    } else {\n+      // A backslash at the very end is treated like an escaped backslash\n+      dst.append('\\\\');\n+    }\n+    return i;\n+  }\n+\n+  private List<MatchResult> matchGlobPaths(List<AzfsResourceId> globs) {\n+    return FluentIterable.from(globs).transform(this::expand).toList();\n+  }\n+\n+  /** Expands a pattern into {@link MatchResult}. */\n+  @VisibleForTesting\n+  MatchResult expand(AzfsResourceId azfsPattern) {\n+\n+    checkArgument(azfsPattern.isWildcard(), \"is Wildcard\");\n+    String blobPrefix = azfsPattern.getBlobNonWildcardPrefix();\n+    Pattern wildcardAsRegexp = Pattern.compile(wildcardToRegexp(azfsPattern.getBlob()));\n+\n+    LOG.debug(\n+        \"matching files in container {}, prefix {} against pattern {}\",\n+        azfsPattern.getContainer(),\n+        blobPrefix,\n+        wildcardAsRegexp.toString());\n+\n+    ListBlobsOptions listOptions = new ListBlobsOptions().setPrefix(blobPrefix);\n+    Duration timeout = Duration.ZERO.plusMinutes(1);\n+\n+    String account = azfsPattern.getAccount();\n+    String container = azfsPattern.getContainer();\n+    BlobContainerClient blobContainerClient = client.get().getBlobContainerClient(container);\n+    PagedIterable<BlobItem> blobs = blobContainerClient.listBlobs(listOptions, timeout);\n+    List<MatchResult.Metadata> results = new ArrayList<>();\n+\n+    blobs.forEach(\n+        blob -> {\n+          String name = blob.getName();\n+          if (wildcardAsRegexp.matcher(name).matches() && !name.endsWith(\"/\")) {\n+            LOG.debug(\"Matched object: {}\", name);\n+\n+            BlobProperties properties = blobContainerClient.getBlobClient(name).getProperties();\n+            AzfsResourceId rid =\n+                AzfsResourceId.fromComponents(account, container, name)\n+                    .withSize(properties.getBlobSize())\n+                    .withLastModified(Date.from(properties.getLastModified().toInstant()));\n+\n+            results.add(toMetadata(rid, properties.getContentEncoding()));\n+          }\n+        });\n+\n+    return MatchResult.create(MatchResult.Status.OK, results);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY1NjkwNg=="}, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 232}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzE3ODU4Nw==", "bodyText": "perfect. thanks!", "url": "https://github.com/apache/beam/pull/12581#discussion_r473178587", "createdAt": "2020-08-19T16:52:32Z", "author": {"login": "pabloem"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "diffHunk": "@@ -17,67 +17,438 @@\n  */\n package org.apache.beam.sdk.io.azure.blobstore;\n \n+import static java.nio.channels.Channels.newChannel;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobItem;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.BlobStorageException;\n+import com.azure.storage.blob.models.ListBlobsOptions;\n+import com.microsoft.azure.storage.CloudStorageAccount;\n+import com.microsoft.azure.storage.SharedAccessAccountPolicy;\n+import java.io.FileNotFoundException;\n import java.io.IOException;\n+import java.io.OutputStream;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.time.Duration;\n+import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Date;\n+import java.util.Iterator;\n import java.util.List;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n import org.apache.beam.sdk.io.FileSystem;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreClientBuilderFactory;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n import org.apache.beam.sdk.io.fs.CreateOptions;\n import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.util.InstanceBuilder;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Supplier;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Suppliers;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableSet;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n class AzureBlobStoreFileSystem extends FileSystem<AzfsResourceId> {\n \n+  private static final Logger LOG = LoggerFactory.getLogger(AzureBlobStoreFileSystem.class);\n+\n+  private static final ImmutableSet<String> NON_READ_SEEK_EFFICIENT_ENCODINGS =\n+      ImmutableSet.of(\"gzip\");\n+\n+  private Supplier<BlobServiceClient> client;\n+  private final BlobstoreOptions options;\n+\n+  AzureBlobStoreFileSystem(BlobstoreOptions options) {\n+    this.options = checkNotNull(options, \"options\");\n+\n+    BlobServiceClientBuilder builder =\n+        InstanceBuilder.ofType(BlobstoreClientBuilderFactory.class)\n+            .fromClass(options.getBlobstoreClientFactoryClass())\n+            .build()\n+            .createBuilder(options);\n+\n+    // The Supplier is to make sure we don't call .build() unless we are actually using Azure.\n+    client = Suppliers.memoize(builder::buildClient);\n+  }\n+\n+  @VisibleForTesting\n+  void setClient(BlobServiceClient client) {\n+    this.client = Suppliers.ofInstance(client);\n+  }\n+\n+  @VisibleForTesting\n+  BlobServiceClient getClient() {\n+    return client.get();\n+  }\n+\n   @Override\n   protected String getScheme() {\n-    return \"azfs\";\n+    return AzfsResourceId.SCHEME;\n   }\n \n   @Override\n-  protected List<MatchResult> match(List<String> specs) throws IOException {\n-    // TODO\n-    return null;\n+  protected List<MatchResult> match(List<String> specs) {\n+    List<AzfsResourceId> paths =\n+        specs.stream().map(AzfsResourceId::fromUri).collect(Collectors.toList());\n+    List<AzfsResourceId> globs = new ArrayList<>();\n+    List<AzfsResourceId> nonGlobs = new ArrayList<>();\n+    List<Boolean> isGlobBooleans = new ArrayList<>();\n+\n+    for (AzfsResourceId path : paths) {\n+      if (path.isWildcard()) {\n+        globs.add(path);\n+        isGlobBooleans.add(true);\n+      } else {\n+        nonGlobs.add(path);\n+        isGlobBooleans.add(false);\n+      }\n+    }\n+\n+    Iterator<MatchResult> globMatches = matchGlobPaths(globs).iterator();\n+    Iterator<MatchResult> nonGlobMatches = matchNonGlobPaths(nonGlobs).iterator();\n+\n+    ImmutableList.Builder<MatchResult> matchResults = ImmutableList.builder();\n+    for (Boolean isGlob : isGlobBooleans) {\n+      if (isGlob) {\n+        checkState(globMatches.hasNext(), \"Expect globMatches has next.\");\n+        matchResults.add(globMatches.next());\n+      } else {\n+        checkState(nonGlobMatches.hasNext(), \"Expect nonGlobMatches has next.\");\n+        matchResults.add(nonGlobMatches.next());\n+      }\n+    }\n+    checkState(!globMatches.hasNext(), \"Expect no more elements in globMatches.\");\n+    checkState(!nonGlobMatches.hasNext(), \"Expect no more elements in nonGlobMatches.\");\n+\n+    return matchResults.build();\n+  }\n+\n+  /**\n+   * Expands glob expressions to regular expressions.\n+   *\n+   * @param globExp the glob expression to expand\n+   * @return a string with the regular expression this glob expands to\n+   */\n+  @VisibleForTesting\n+  static String wildcardToRegexp(String globExp) {\n+    StringBuilder dst = new StringBuilder();\n+    char[] src = globExp.replace(\"**/*\", \"**\").toCharArray();\n+    int i = 0;\n+    while (i < src.length) {\n+      char c = src[i++];\n+      switch (c) {\n+        case '*':\n+          // One char lookahead for **\n+          if (i < src.length && src[i] == '*') {\n+            dst.append(\".*\");\n+            ++i;\n+          } else {\n+            dst.append(\"[^/]*\");\n+          }\n+          break;\n+        case '?':\n+          dst.append(\"[^/]\");\n+          break;\n+        case '.':\n+        case '+':\n+        case '{':\n+        case '}':\n+        case '(':\n+        case ')':\n+        case '|':\n+        case '^':\n+        case '$':\n+          // These need to be escaped in regular expressions\n+          dst.append('\\\\').append(c);\n+          break;\n+        case '\\\\':\n+          i = doubleSlashes(dst, src, i);\n+          break;\n+        default:\n+          dst.append(c);\n+          break;\n+      }\n+    }\n+    return dst.toString();\n+  }\n+\n+  private static int doubleSlashes(StringBuilder dst, char[] src, int i) {\n+    // Emit the next character without special interpretation\n+    dst.append(\"\\\\\\\\\");\n+    if ((i - 1) != src.length) {\n+      dst.append(src[i]);\n+      i++;\n+    } else {\n+      // A backslash at the very end is treated like an escaped backslash\n+      dst.append('\\\\');\n+    }\n+    return i;\n+  }\n+\n+  private List<MatchResult> matchGlobPaths(List<AzfsResourceId> globs) {\n+    return FluentIterable.from(globs).transform(this::expand).toList();\n+  }\n+\n+  /** Expands a pattern into {@link MatchResult}. */\n+  @VisibleForTesting\n+  MatchResult expand(AzfsResourceId azfsPattern) {\n+\n+    checkArgument(azfsPattern.isWildcard(), \"is Wildcard\");\n+    String blobPrefix = azfsPattern.getBlobNonWildcardPrefix();\n+    Pattern wildcardAsRegexp = Pattern.compile(wildcardToRegexp(azfsPattern.getBlob()));\n+\n+    LOG.debug(\n+        \"matching files in container {}, prefix {} against pattern {}\",\n+        azfsPattern.getContainer(),\n+        blobPrefix,\n+        wildcardAsRegexp.toString());\n+\n+    ListBlobsOptions listOptions = new ListBlobsOptions().setPrefix(blobPrefix);\n+    Duration timeout = Duration.ZERO.plusMinutes(1);\n+\n+    String account = azfsPattern.getAccount();\n+    String container = azfsPattern.getContainer();\n+    BlobContainerClient blobContainerClient = client.get().getBlobContainerClient(container);\n+    PagedIterable<BlobItem> blobs = blobContainerClient.listBlobs(listOptions, timeout);\n+    List<MatchResult.Metadata> results = new ArrayList<>();\n+\n+    blobs.forEach(\n+        blob -> {\n+          String name = blob.getName();\n+          if (wildcardAsRegexp.matcher(name).matches() && !name.endsWith(\"/\")) {\n+            LOG.debug(\"Matched object: {}\", name);\n+\n+            BlobProperties properties = blobContainerClient.getBlobClient(name).getProperties();\n+            AzfsResourceId rid =\n+                AzfsResourceId.fromComponents(account, container, name)\n+                    .withSize(properties.getBlobSize())\n+                    .withLastModified(Date.from(properties.getLastModified().toInstant()));\n+\n+            results.add(toMetadata(rid, properties.getContentEncoding()));\n+          }\n+        });\n+\n+    return MatchResult.create(MatchResult.Status.OK, results);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY1NjkwNg=="}, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 232}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk0ODEwMjc1OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxNzo0NzozNlrOHBztPg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQwMzozNToyNFrOHCv8tg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY1Nzc5MA==", "bodyText": "Can we make the constant string racwdlup  and co  as static final attribute of the class?", "url": "https://github.com/apache/beam/pull/12581#discussion_r471657790", "createdAt": "2020-08-17T17:47:36Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "diffHunk": "@@ -17,67 +17,438 @@\n  */\n package org.apache.beam.sdk.io.azure.blobstore;\n \n+import static java.nio.channels.Channels.newChannel;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobItem;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.BlobStorageException;\n+import com.azure.storage.blob.models.ListBlobsOptions;\n+import com.microsoft.azure.storage.CloudStorageAccount;\n+import com.microsoft.azure.storage.SharedAccessAccountPolicy;\n+import java.io.FileNotFoundException;\n import java.io.IOException;\n+import java.io.OutputStream;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.time.Duration;\n+import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Date;\n+import java.util.Iterator;\n import java.util.List;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n import org.apache.beam.sdk.io.FileSystem;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreClientBuilderFactory;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n import org.apache.beam.sdk.io.fs.CreateOptions;\n import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.util.InstanceBuilder;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Supplier;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Suppliers;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableSet;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n class AzureBlobStoreFileSystem extends FileSystem<AzfsResourceId> {\n \n+  private static final Logger LOG = LoggerFactory.getLogger(AzureBlobStoreFileSystem.class);\n+\n+  private static final ImmutableSet<String> NON_READ_SEEK_EFFICIENT_ENCODINGS =\n+      ImmutableSet.of(\"gzip\");\n+\n+  private Supplier<BlobServiceClient> client;\n+  private final BlobstoreOptions options;\n+\n+  AzureBlobStoreFileSystem(BlobstoreOptions options) {\n+    this.options = checkNotNull(options, \"options\");\n+\n+    BlobServiceClientBuilder builder =\n+        InstanceBuilder.ofType(BlobstoreClientBuilderFactory.class)\n+            .fromClass(options.getBlobstoreClientFactoryClass())\n+            .build()\n+            .createBuilder(options);\n+\n+    // The Supplier is to make sure we don't call .build() unless we are actually using Azure.\n+    client = Suppliers.memoize(builder::buildClient);\n+  }\n+\n+  @VisibleForTesting\n+  void setClient(BlobServiceClient client) {\n+    this.client = Suppliers.ofInstance(client);\n+  }\n+\n+  @VisibleForTesting\n+  BlobServiceClient getClient() {\n+    return client.get();\n+  }\n+\n   @Override\n   protected String getScheme() {\n-    return \"azfs\";\n+    return AzfsResourceId.SCHEME;\n   }\n \n   @Override\n-  protected List<MatchResult> match(List<String> specs) throws IOException {\n-    // TODO\n-    return null;\n+  protected List<MatchResult> match(List<String> specs) {\n+    List<AzfsResourceId> paths =\n+        specs.stream().map(AzfsResourceId::fromUri).collect(Collectors.toList());\n+    List<AzfsResourceId> globs = new ArrayList<>();\n+    List<AzfsResourceId> nonGlobs = new ArrayList<>();\n+    List<Boolean> isGlobBooleans = new ArrayList<>();\n+\n+    for (AzfsResourceId path : paths) {\n+      if (path.isWildcard()) {\n+        globs.add(path);\n+        isGlobBooleans.add(true);\n+      } else {\n+        nonGlobs.add(path);\n+        isGlobBooleans.add(false);\n+      }\n+    }\n+\n+    Iterator<MatchResult> globMatches = matchGlobPaths(globs).iterator();\n+    Iterator<MatchResult> nonGlobMatches = matchNonGlobPaths(nonGlobs).iterator();\n+\n+    ImmutableList.Builder<MatchResult> matchResults = ImmutableList.builder();\n+    for (Boolean isGlob : isGlobBooleans) {\n+      if (isGlob) {\n+        checkState(globMatches.hasNext(), \"Expect globMatches has next.\");\n+        matchResults.add(globMatches.next());\n+      } else {\n+        checkState(nonGlobMatches.hasNext(), \"Expect nonGlobMatches has next.\");\n+        matchResults.add(nonGlobMatches.next());\n+      }\n+    }\n+    checkState(!globMatches.hasNext(), \"Expect no more elements in globMatches.\");\n+    checkState(!nonGlobMatches.hasNext(), \"Expect no more elements in nonGlobMatches.\");\n+\n+    return matchResults.build();\n+  }\n+\n+  /**\n+   * Expands glob expressions to regular expressions.\n+   *\n+   * @param globExp the glob expression to expand\n+   * @return a string with the regular expression this glob expands to\n+   */\n+  @VisibleForTesting\n+  static String wildcardToRegexp(String globExp) {\n+    StringBuilder dst = new StringBuilder();\n+    char[] src = globExp.replace(\"**/*\", \"**\").toCharArray();\n+    int i = 0;\n+    while (i < src.length) {\n+      char c = src[i++];\n+      switch (c) {\n+        case '*':\n+          // One char lookahead for **\n+          if (i < src.length && src[i] == '*') {\n+            dst.append(\".*\");\n+            ++i;\n+          } else {\n+            dst.append(\"[^/]*\");\n+          }\n+          break;\n+        case '?':\n+          dst.append(\"[^/]\");\n+          break;\n+        case '.':\n+        case '+':\n+        case '{':\n+        case '}':\n+        case '(':\n+        case ')':\n+        case '|':\n+        case '^':\n+        case '$':\n+          // These need to be escaped in regular expressions\n+          dst.append('\\\\').append(c);\n+          break;\n+        case '\\\\':\n+          i = doubleSlashes(dst, src, i);\n+          break;\n+        default:\n+          dst.append(c);\n+          break;\n+      }\n+    }\n+    return dst.toString();\n+  }\n+\n+  private static int doubleSlashes(StringBuilder dst, char[] src, int i) {\n+    // Emit the next character without special interpretation\n+    dst.append(\"\\\\\\\\\");\n+    if ((i - 1) != src.length) {\n+      dst.append(src[i]);\n+      i++;\n+    } else {\n+      // A backslash at the very end is treated like an escaped backslash\n+      dst.append('\\\\');\n+    }\n+    return i;\n+  }\n+\n+  private List<MatchResult> matchGlobPaths(List<AzfsResourceId> globs) {\n+    return FluentIterable.from(globs).transform(this::expand).toList();\n+  }\n+\n+  /** Expands a pattern into {@link MatchResult}. */\n+  @VisibleForTesting\n+  MatchResult expand(AzfsResourceId azfsPattern) {\n+\n+    checkArgument(azfsPattern.isWildcard(), \"is Wildcard\");\n+    String blobPrefix = azfsPattern.getBlobNonWildcardPrefix();\n+    Pattern wildcardAsRegexp = Pattern.compile(wildcardToRegexp(azfsPattern.getBlob()));\n+\n+    LOG.debug(\n+        \"matching files in container {}, prefix {} against pattern {}\",\n+        azfsPattern.getContainer(),\n+        blobPrefix,\n+        wildcardAsRegexp.toString());\n+\n+    ListBlobsOptions listOptions = new ListBlobsOptions().setPrefix(blobPrefix);\n+    Duration timeout = Duration.ZERO.plusMinutes(1);\n+\n+    String account = azfsPattern.getAccount();\n+    String container = azfsPattern.getContainer();\n+    BlobContainerClient blobContainerClient = client.get().getBlobContainerClient(container);\n+    PagedIterable<BlobItem> blobs = blobContainerClient.listBlobs(listOptions, timeout);\n+    List<MatchResult.Metadata> results = new ArrayList<>();\n+\n+    blobs.forEach(\n+        blob -> {\n+          String name = blob.getName();\n+          if (wildcardAsRegexp.matcher(name).matches() && !name.endsWith(\"/\")) {\n+            LOG.debug(\"Matched object: {}\", name);\n+\n+            BlobProperties properties = blobContainerClient.getBlobClient(name).getProperties();\n+            AzfsResourceId rid =\n+                AzfsResourceId.fromComponents(account, container, name)\n+                    .withSize(properties.getBlobSize())\n+                    .withLastModified(Date.from(properties.getLastModified().toInstant()));\n+\n+            results.add(toMetadata(rid, properties.getContentEncoding()));\n+          }\n+        });\n+\n+    return MatchResult.create(MatchResult.Status.OK, results);\n+  }\n+\n+  private MatchResult.Metadata toMetadata(AzfsResourceId path, String contentEncoding) {\n+\n+    checkArgument(path.getSize().isPresent(), \"path has size\");\n+    boolean isReadSeekEfficient = !NON_READ_SEEK_EFFICIENT_ENCODINGS.contains(contentEncoding);\n+\n+    return MatchResult.Metadata.builder()\n+        .setIsReadSeekEfficient(isReadSeekEfficient)\n+        .setResourceId(path)\n+        .setSizeBytes(path.getSize().get())\n+        .setLastModifiedMillis(path.getLastModified().transform(Date::getTime).or(0L))\n+        .build();\n+  }\n+\n+  /**\n+   * Returns {@link MatchResult MatchResults} for the given {@link AzfsResourceId paths}.\n+   *\n+   * <p>The number of returned {@link MatchResult MatchResults} equals to the number of given {@link\n+   * AzfsResourceId paths}. Each {@link MatchResult} contains one {@link MatchResult.Metadata}.\n+   */\n+  @VisibleForTesting\n+  private Iterable<MatchResult> matchNonGlobPaths(List<AzfsResourceId> paths) {\n+    ImmutableList.Builder<MatchResult> toReturn = ImmutableList.builder();\n+    for (AzfsResourceId path : paths) {\n+      toReturn.add(toMatchResult(path));\n+    }\n+    return toReturn.build();\n+  }\n+\n+  private MatchResult toMatchResult(AzfsResourceId path) {\n+    BlobClient blobClient =\n+        client.get().getBlobContainerClient(path.getContainer()).getBlobClient(path.getBlob());\n+    BlobProperties blobProperties;\n+\n+    try {\n+      blobProperties = blobClient.getProperties();\n+    } catch (BlobStorageException e) {\n+      if (e.getStatusCode() == 404) {\n+        return MatchResult.create(MatchResult.Status.NOT_FOUND, new FileNotFoundException());\n+      }\n+      return MatchResult.create(MatchResult.Status.ERROR, new IOException(e));\n+    }\n+\n+    return MatchResult.create(\n+        MatchResult.Status.OK,\n+        ImmutableList.of(\n+            toMetadata(\n+                path.withSize(blobProperties.getBlobSize())\n+                    .withLastModified(Date.from(blobProperties.getLastModified().toInstant())),\n+                blobProperties.getContentEncoding())));\n   }\n \n   @Override\n   protected WritableByteChannel create(AzfsResourceId resourceId, CreateOptions createOptions)\n       throws IOException {\n-    // TODO\n-    return null;\n+    BlobContainerClient blobContainerClient =\n+        client.get().getBlobContainerClient(resourceId.getContainer());\n+    if (!blobContainerClient.exists()) {\n+      throw new UnsupportedOperationException(\"create does not create containers.\");\n+    }\n+\n+    BlobClient blobClient = blobContainerClient.getBlobClient(resourceId.getBlob());\n+    // The getBlobOutputStream method overwrites existing blobs,\n+    // so throw an error in this case to prevent data loss\n+    if (blobClient.exists()) {\n+      throw new IOException(\"This filename is already in use.\");\n+    }\n+\n+    OutputStream outputStream;\n+    try {\n+      outputStream = blobClient.getBlockBlobClient().getBlobOutputStream();\n+    } catch (BlobStorageException e) {\n+      throw (IOException) e.getCause();\n+    }\n+    return newChannel(outputStream);\n   }\n \n   @Override\n   protected ReadableByteChannel open(AzfsResourceId resourceId) throws IOException {\n-    // TODO\n-    return null;\n+    BlobClient blobClient =\n+        client\n+            .get()\n+            .getBlobContainerClient(resourceId.getContainer())\n+            .getBlobClient(resourceId.getBlob());\n+    if (!blobClient.exists()) {\n+      throw new FileNotFoundException(\"The requested file doesn't exist.\");\n+    }\n+    return new AzureReadableSeekableByteChannel(blobClient);\n   }\n \n   @Override\n   protected void copy(List<AzfsResourceId> srcPaths, List<AzfsResourceId> destPaths)\n       throws IOException {\n-    // TODO\n+    checkArgument(\n+        srcPaths.size() == destPaths.size(),\n+        \"sizes of source paths and destination paths do not match\");\n+\n+    Iterator<AzfsResourceId> sourcePathsIterator = srcPaths.iterator();\n+    Iterator<AzfsResourceId> destinationPathsIterator = destPaths.iterator();\n+    while (sourcePathsIterator.hasNext()) {\n+      final AzfsResourceId sourcePath = sourcePathsIterator.next();\n+      final AzfsResourceId destinationPath = destinationPathsIterator.next();\n+      copy(sourcePath, destinationPath);\n+    }\n   }\n \n   @VisibleForTesting\n   void copy(AzfsResourceId sourcePath, AzfsResourceId destinationPath) throws IOException {\n-    // TODO\n+    checkArgument(\n+        sourcePath.getBlob() != null && destinationPath.getBlob() != null,\n+        \"This method is intended to copy file-like resources, not directories.\");\n+\n+    // get source blob client\n+    BlobClient srcBlobClient =\n+        client\n+            .get()\n+            .getBlobContainerClient(sourcePath.getContainer())\n+            .getBlobClient(sourcePath.getBlob());\n+    if (!srcBlobClient.exists()) {\n+      throw new FileNotFoundException(\"The copy source does not exist.\");\n+    }\n+\n+    // get destination blob client\n+    BlobContainerClient destBlobContainerClient =\n+        client.get().getBlobContainerClient(destinationPath.getContainer());\n+    if (!destBlobContainerClient.exists()) {\n+      client.get().createBlobContainer(destinationPath.getContainer());\n+    }\n+    BlobClient destBlobClient = destBlobContainerClient.getBlobClient(destinationPath.getBlob());\n+\n+    destBlobClient.copyFromUrl(srcBlobClient.getBlobUrl() + generateSasToken());\n+  }\n+\n+  @VisibleForTesting\n+  String generateSasToken() throws IOException {\n+    SharedAccessAccountPolicy sharedAccessAccountPolicy = new SharedAccessAccountPolicy();\n+    long date = new Date().getTime();\n+    long expiryDate = new Date(date + 8640000).getTime();\n+\n+    sharedAccessAccountPolicy.setPermissionsFromString(\"racwdlup\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 379}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjY0NDc5MA==", "bodyText": "Sure, done.", "url": "https://github.com/apache/beam/pull/12581#discussion_r472644790", "createdAt": "2020-08-19T03:35:24Z", "author": {"login": "ettirapp"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "diffHunk": "@@ -17,67 +17,438 @@\n  */\n package org.apache.beam.sdk.io.azure.blobstore;\n \n+import static java.nio.channels.Channels.newChannel;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobItem;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.BlobStorageException;\n+import com.azure.storage.blob.models.ListBlobsOptions;\n+import com.microsoft.azure.storage.CloudStorageAccount;\n+import com.microsoft.azure.storage.SharedAccessAccountPolicy;\n+import java.io.FileNotFoundException;\n import java.io.IOException;\n+import java.io.OutputStream;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.time.Duration;\n+import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Date;\n+import java.util.Iterator;\n import java.util.List;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n import org.apache.beam.sdk.io.FileSystem;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreClientBuilderFactory;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n import org.apache.beam.sdk.io.fs.CreateOptions;\n import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.util.InstanceBuilder;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Supplier;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Suppliers;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableSet;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n class AzureBlobStoreFileSystem extends FileSystem<AzfsResourceId> {\n \n+  private static final Logger LOG = LoggerFactory.getLogger(AzureBlobStoreFileSystem.class);\n+\n+  private static final ImmutableSet<String> NON_READ_SEEK_EFFICIENT_ENCODINGS =\n+      ImmutableSet.of(\"gzip\");\n+\n+  private Supplier<BlobServiceClient> client;\n+  private final BlobstoreOptions options;\n+\n+  AzureBlobStoreFileSystem(BlobstoreOptions options) {\n+    this.options = checkNotNull(options, \"options\");\n+\n+    BlobServiceClientBuilder builder =\n+        InstanceBuilder.ofType(BlobstoreClientBuilderFactory.class)\n+            .fromClass(options.getBlobstoreClientFactoryClass())\n+            .build()\n+            .createBuilder(options);\n+\n+    // The Supplier is to make sure we don't call .build() unless we are actually using Azure.\n+    client = Suppliers.memoize(builder::buildClient);\n+  }\n+\n+  @VisibleForTesting\n+  void setClient(BlobServiceClient client) {\n+    this.client = Suppliers.ofInstance(client);\n+  }\n+\n+  @VisibleForTesting\n+  BlobServiceClient getClient() {\n+    return client.get();\n+  }\n+\n   @Override\n   protected String getScheme() {\n-    return \"azfs\";\n+    return AzfsResourceId.SCHEME;\n   }\n \n   @Override\n-  protected List<MatchResult> match(List<String> specs) throws IOException {\n-    // TODO\n-    return null;\n+  protected List<MatchResult> match(List<String> specs) {\n+    List<AzfsResourceId> paths =\n+        specs.stream().map(AzfsResourceId::fromUri).collect(Collectors.toList());\n+    List<AzfsResourceId> globs = new ArrayList<>();\n+    List<AzfsResourceId> nonGlobs = new ArrayList<>();\n+    List<Boolean> isGlobBooleans = new ArrayList<>();\n+\n+    for (AzfsResourceId path : paths) {\n+      if (path.isWildcard()) {\n+        globs.add(path);\n+        isGlobBooleans.add(true);\n+      } else {\n+        nonGlobs.add(path);\n+        isGlobBooleans.add(false);\n+      }\n+    }\n+\n+    Iterator<MatchResult> globMatches = matchGlobPaths(globs).iterator();\n+    Iterator<MatchResult> nonGlobMatches = matchNonGlobPaths(nonGlobs).iterator();\n+\n+    ImmutableList.Builder<MatchResult> matchResults = ImmutableList.builder();\n+    for (Boolean isGlob : isGlobBooleans) {\n+      if (isGlob) {\n+        checkState(globMatches.hasNext(), \"Expect globMatches has next.\");\n+        matchResults.add(globMatches.next());\n+      } else {\n+        checkState(nonGlobMatches.hasNext(), \"Expect nonGlobMatches has next.\");\n+        matchResults.add(nonGlobMatches.next());\n+      }\n+    }\n+    checkState(!globMatches.hasNext(), \"Expect no more elements in globMatches.\");\n+    checkState(!nonGlobMatches.hasNext(), \"Expect no more elements in nonGlobMatches.\");\n+\n+    return matchResults.build();\n+  }\n+\n+  /**\n+   * Expands glob expressions to regular expressions.\n+   *\n+   * @param globExp the glob expression to expand\n+   * @return a string with the regular expression this glob expands to\n+   */\n+  @VisibleForTesting\n+  static String wildcardToRegexp(String globExp) {\n+    StringBuilder dst = new StringBuilder();\n+    char[] src = globExp.replace(\"**/*\", \"**\").toCharArray();\n+    int i = 0;\n+    while (i < src.length) {\n+      char c = src[i++];\n+      switch (c) {\n+        case '*':\n+          // One char lookahead for **\n+          if (i < src.length && src[i] == '*') {\n+            dst.append(\".*\");\n+            ++i;\n+          } else {\n+            dst.append(\"[^/]*\");\n+          }\n+          break;\n+        case '?':\n+          dst.append(\"[^/]\");\n+          break;\n+        case '.':\n+        case '+':\n+        case '{':\n+        case '}':\n+        case '(':\n+        case ')':\n+        case '|':\n+        case '^':\n+        case '$':\n+          // These need to be escaped in regular expressions\n+          dst.append('\\\\').append(c);\n+          break;\n+        case '\\\\':\n+          i = doubleSlashes(dst, src, i);\n+          break;\n+        default:\n+          dst.append(c);\n+          break;\n+      }\n+    }\n+    return dst.toString();\n+  }\n+\n+  private static int doubleSlashes(StringBuilder dst, char[] src, int i) {\n+    // Emit the next character without special interpretation\n+    dst.append(\"\\\\\\\\\");\n+    if ((i - 1) != src.length) {\n+      dst.append(src[i]);\n+      i++;\n+    } else {\n+      // A backslash at the very end is treated like an escaped backslash\n+      dst.append('\\\\');\n+    }\n+    return i;\n+  }\n+\n+  private List<MatchResult> matchGlobPaths(List<AzfsResourceId> globs) {\n+    return FluentIterable.from(globs).transform(this::expand).toList();\n+  }\n+\n+  /** Expands a pattern into {@link MatchResult}. */\n+  @VisibleForTesting\n+  MatchResult expand(AzfsResourceId azfsPattern) {\n+\n+    checkArgument(azfsPattern.isWildcard(), \"is Wildcard\");\n+    String blobPrefix = azfsPattern.getBlobNonWildcardPrefix();\n+    Pattern wildcardAsRegexp = Pattern.compile(wildcardToRegexp(azfsPattern.getBlob()));\n+\n+    LOG.debug(\n+        \"matching files in container {}, prefix {} against pattern {}\",\n+        azfsPattern.getContainer(),\n+        blobPrefix,\n+        wildcardAsRegexp.toString());\n+\n+    ListBlobsOptions listOptions = new ListBlobsOptions().setPrefix(blobPrefix);\n+    Duration timeout = Duration.ZERO.plusMinutes(1);\n+\n+    String account = azfsPattern.getAccount();\n+    String container = azfsPattern.getContainer();\n+    BlobContainerClient blobContainerClient = client.get().getBlobContainerClient(container);\n+    PagedIterable<BlobItem> blobs = blobContainerClient.listBlobs(listOptions, timeout);\n+    List<MatchResult.Metadata> results = new ArrayList<>();\n+\n+    blobs.forEach(\n+        blob -> {\n+          String name = blob.getName();\n+          if (wildcardAsRegexp.matcher(name).matches() && !name.endsWith(\"/\")) {\n+            LOG.debug(\"Matched object: {}\", name);\n+\n+            BlobProperties properties = blobContainerClient.getBlobClient(name).getProperties();\n+            AzfsResourceId rid =\n+                AzfsResourceId.fromComponents(account, container, name)\n+                    .withSize(properties.getBlobSize())\n+                    .withLastModified(Date.from(properties.getLastModified().toInstant()));\n+\n+            results.add(toMetadata(rid, properties.getContentEncoding()));\n+          }\n+        });\n+\n+    return MatchResult.create(MatchResult.Status.OK, results);\n+  }\n+\n+  private MatchResult.Metadata toMetadata(AzfsResourceId path, String contentEncoding) {\n+\n+    checkArgument(path.getSize().isPresent(), \"path has size\");\n+    boolean isReadSeekEfficient = !NON_READ_SEEK_EFFICIENT_ENCODINGS.contains(contentEncoding);\n+\n+    return MatchResult.Metadata.builder()\n+        .setIsReadSeekEfficient(isReadSeekEfficient)\n+        .setResourceId(path)\n+        .setSizeBytes(path.getSize().get())\n+        .setLastModifiedMillis(path.getLastModified().transform(Date::getTime).or(0L))\n+        .build();\n+  }\n+\n+  /**\n+   * Returns {@link MatchResult MatchResults} for the given {@link AzfsResourceId paths}.\n+   *\n+   * <p>The number of returned {@link MatchResult MatchResults} equals to the number of given {@link\n+   * AzfsResourceId paths}. Each {@link MatchResult} contains one {@link MatchResult.Metadata}.\n+   */\n+  @VisibleForTesting\n+  private Iterable<MatchResult> matchNonGlobPaths(List<AzfsResourceId> paths) {\n+    ImmutableList.Builder<MatchResult> toReturn = ImmutableList.builder();\n+    for (AzfsResourceId path : paths) {\n+      toReturn.add(toMatchResult(path));\n+    }\n+    return toReturn.build();\n+  }\n+\n+  private MatchResult toMatchResult(AzfsResourceId path) {\n+    BlobClient blobClient =\n+        client.get().getBlobContainerClient(path.getContainer()).getBlobClient(path.getBlob());\n+    BlobProperties blobProperties;\n+\n+    try {\n+      blobProperties = blobClient.getProperties();\n+    } catch (BlobStorageException e) {\n+      if (e.getStatusCode() == 404) {\n+        return MatchResult.create(MatchResult.Status.NOT_FOUND, new FileNotFoundException());\n+      }\n+      return MatchResult.create(MatchResult.Status.ERROR, new IOException(e));\n+    }\n+\n+    return MatchResult.create(\n+        MatchResult.Status.OK,\n+        ImmutableList.of(\n+            toMetadata(\n+                path.withSize(blobProperties.getBlobSize())\n+                    .withLastModified(Date.from(blobProperties.getLastModified().toInstant())),\n+                blobProperties.getContentEncoding())));\n   }\n \n   @Override\n   protected WritableByteChannel create(AzfsResourceId resourceId, CreateOptions createOptions)\n       throws IOException {\n-    // TODO\n-    return null;\n+    BlobContainerClient blobContainerClient =\n+        client.get().getBlobContainerClient(resourceId.getContainer());\n+    if (!blobContainerClient.exists()) {\n+      throw new UnsupportedOperationException(\"create does not create containers.\");\n+    }\n+\n+    BlobClient blobClient = blobContainerClient.getBlobClient(resourceId.getBlob());\n+    // The getBlobOutputStream method overwrites existing blobs,\n+    // so throw an error in this case to prevent data loss\n+    if (blobClient.exists()) {\n+      throw new IOException(\"This filename is already in use.\");\n+    }\n+\n+    OutputStream outputStream;\n+    try {\n+      outputStream = blobClient.getBlockBlobClient().getBlobOutputStream();\n+    } catch (BlobStorageException e) {\n+      throw (IOException) e.getCause();\n+    }\n+    return newChannel(outputStream);\n   }\n \n   @Override\n   protected ReadableByteChannel open(AzfsResourceId resourceId) throws IOException {\n-    // TODO\n-    return null;\n+    BlobClient blobClient =\n+        client\n+            .get()\n+            .getBlobContainerClient(resourceId.getContainer())\n+            .getBlobClient(resourceId.getBlob());\n+    if (!blobClient.exists()) {\n+      throw new FileNotFoundException(\"The requested file doesn't exist.\");\n+    }\n+    return new AzureReadableSeekableByteChannel(blobClient);\n   }\n \n   @Override\n   protected void copy(List<AzfsResourceId> srcPaths, List<AzfsResourceId> destPaths)\n       throws IOException {\n-    // TODO\n+    checkArgument(\n+        srcPaths.size() == destPaths.size(),\n+        \"sizes of source paths and destination paths do not match\");\n+\n+    Iterator<AzfsResourceId> sourcePathsIterator = srcPaths.iterator();\n+    Iterator<AzfsResourceId> destinationPathsIterator = destPaths.iterator();\n+    while (sourcePathsIterator.hasNext()) {\n+      final AzfsResourceId sourcePath = sourcePathsIterator.next();\n+      final AzfsResourceId destinationPath = destinationPathsIterator.next();\n+      copy(sourcePath, destinationPath);\n+    }\n   }\n \n   @VisibleForTesting\n   void copy(AzfsResourceId sourcePath, AzfsResourceId destinationPath) throws IOException {\n-    // TODO\n+    checkArgument(\n+        sourcePath.getBlob() != null && destinationPath.getBlob() != null,\n+        \"This method is intended to copy file-like resources, not directories.\");\n+\n+    // get source blob client\n+    BlobClient srcBlobClient =\n+        client\n+            .get()\n+            .getBlobContainerClient(sourcePath.getContainer())\n+            .getBlobClient(sourcePath.getBlob());\n+    if (!srcBlobClient.exists()) {\n+      throw new FileNotFoundException(\"The copy source does not exist.\");\n+    }\n+\n+    // get destination blob client\n+    BlobContainerClient destBlobContainerClient =\n+        client.get().getBlobContainerClient(destinationPath.getContainer());\n+    if (!destBlobContainerClient.exists()) {\n+      client.get().createBlobContainer(destinationPath.getContainer());\n+    }\n+    BlobClient destBlobClient = destBlobContainerClient.getBlobClient(destinationPath.getBlob());\n+\n+    destBlobClient.copyFromUrl(srcBlobClient.getBlobUrl() + generateSasToken());\n+  }\n+\n+  @VisibleForTesting\n+  String generateSasToken() throws IOException {\n+    SharedAccessAccountPolicy sharedAccessAccountPolicy = new SharedAccessAccountPolicy();\n+    long date = new Date().getTime();\n+    long expiryDate = new Date(date + 8640000).getTime();\n+\n+    sharedAccessAccountPolicy.setPermissionsFromString(\"racwdlup\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY1Nzc5MA=="}, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 379}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk0ODEwOTAwOnYy", "diffSide": "RIGHT", "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxNzo0OToxNFrOHBzw6A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxNzo0OToxNFrOHBzw6A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY1ODcyOA==", "bodyText": "Please make the comment as the javadoc.", "url": "https://github.com/apache/beam/pull/12581#discussion_r471658728", "createdAt": "2020-08-17T17:49:14Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "diffHunk": "@@ -17,67 +17,438 @@\n  */\n package org.apache.beam.sdk.io.azure.blobstore;\n \n+import static java.nio.channels.Channels.newChannel;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobItem;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.BlobStorageException;\n+import com.azure.storage.blob.models.ListBlobsOptions;\n+import com.microsoft.azure.storage.CloudStorageAccount;\n+import com.microsoft.azure.storage.SharedAccessAccountPolicy;\n+import java.io.FileNotFoundException;\n import java.io.IOException;\n+import java.io.OutputStream;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.time.Duration;\n+import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Date;\n+import java.util.Iterator;\n import java.util.List;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n import org.apache.beam.sdk.io.FileSystem;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreClientBuilderFactory;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n import org.apache.beam.sdk.io.fs.CreateOptions;\n import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.util.InstanceBuilder;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Supplier;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Suppliers;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableSet;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n class AzureBlobStoreFileSystem extends FileSystem<AzfsResourceId> {\n \n+  private static final Logger LOG = LoggerFactory.getLogger(AzureBlobStoreFileSystem.class);\n+\n+  private static final ImmutableSet<String> NON_READ_SEEK_EFFICIENT_ENCODINGS =\n+      ImmutableSet.of(\"gzip\");\n+\n+  private Supplier<BlobServiceClient> client;\n+  private final BlobstoreOptions options;\n+\n+  AzureBlobStoreFileSystem(BlobstoreOptions options) {\n+    this.options = checkNotNull(options, \"options\");\n+\n+    BlobServiceClientBuilder builder =\n+        InstanceBuilder.ofType(BlobstoreClientBuilderFactory.class)\n+            .fromClass(options.getBlobstoreClientFactoryClass())\n+            .build()\n+            .createBuilder(options);\n+\n+    // The Supplier is to make sure we don't call .build() unless we are actually using Azure.\n+    client = Suppliers.memoize(builder::buildClient);\n+  }\n+\n+  @VisibleForTesting\n+  void setClient(BlobServiceClient client) {\n+    this.client = Suppliers.ofInstance(client);\n+  }\n+\n+  @VisibleForTesting\n+  BlobServiceClient getClient() {\n+    return client.get();\n+  }\n+\n   @Override\n   protected String getScheme() {\n-    return \"azfs\";\n+    return AzfsResourceId.SCHEME;\n   }\n \n   @Override\n-  protected List<MatchResult> match(List<String> specs) throws IOException {\n-    // TODO\n-    return null;\n+  protected List<MatchResult> match(List<String> specs) {\n+    List<AzfsResourceId> paths =\n+        specs.stream().map(AzfsResourceId::fromUri).collect(Collectors.toList());\n+    List<AzfsResourceId> globs = new ArrayList<>();\n+    List<AzfsResourceId> nonGlobs = new ArrayList<>();\n+    List<Boolean> isGlobBooleans = new ArrayList<>();\n+\n+    for (AzfsResourceId path : paths) {\n+      if (path.isWildcard()) {\n+        globs.add(path);\n+        isGlobBooleans.add(true);\n+      } else {\n+        nonGlobs.add(path);\n+        isGlobBooleans.add(false);\n+      }\n+    }\n+\n+    Iterator<MatchResult> globMatches = matchGlobPaths(globs).iterator();\n+    Iterator<MatchResult> nonGlobMatches = matchNonGlobPaths(nonGlobs).iterator();\n+\n+    ImmutableList.Builder<MatchResult> matchResults = ImmutableList.builder();\n+    for (Boolean isGlob : isGlobBooleans) {\n+      if (isGlob) {\n+        checkState(globMatches.hasNext(), \"Expect globMatches has next.\");\n+        matchResults.add(globMatches.next());\n+      } else {\n+        checkState(nonGlobMatches.hasNext(), \"Expect nonGlobMatches has next.\");\n+        matchResults.add(nonGlobMatches.next());\n+      }\n+    }\n+    checkState(!globMatches.hasNext(), \"Expect no more elements in globMatches.\");\n+    checkState(!nonGlobMatches.hasNext(), \"Expect no more elements in nonGlobMatches.\");\n+\n+    return matchResults.build();\n+  }\n+\n+  /**\n+   * Expands glob expressions to regular expressions.\n+   *\n+   * @param globExp the glob expression to expand\n+   * @return a string with the regular expression this glob expands to\n+   */\n+  @VisibleForTesting\n+  static String wildcardToRegexp(String globExp) {\n+    StringBuilder dst = new StringBuilder();\n+    char[] src = globExp.replace(\"**/*\", \"**\").toCharArray();\n+    int i = 0;\n+    while (i < src.length) {\n+      char c = src[i++];\n+      switch (c) {\n+        case '*':\n+          // One char lookahead for **\n+          if (i < src.length && src[i] == '*') {\n+            dst.append(\".*\");\n+            ++i;\n+          } else {\n+            dst.append(\"[^/]*\");\n+          }\n+          break;\n+        case '?':\n+          dst.append(\"[^/]\");\n+          break;\n+        case '.':\n+        case '+':\n+        case '{':\n+        case '}':\n+        case '(':\n+        case ')':\n+        case '|':\n+        case '^':\n+        case '$':\n+          // These need to be escaped in regular expressions\n+          dst.append('\\\\').append(c);\n+          break;\n+        case '\\\\':\n+          i = doubleSlashes(dst, src, i);\n+          break;\n+        default:\n+          dst.append(c);\n+          break;\n+      }\n+    }\n+    return dst.toString();\n+  }\n+\n+  private static int doubleSlashes(StringBuilder dst, char[] src, int i) {\n+    // Emit the next character without special interpretation\n+    dst.append(\"\\\\\\\\\");\n+    if ((i - 1) != src.length) {\n+      dst.append(src[i]);\n+      i++;\n+    } else {\n+      // A backslash at the very end is treated like an escaped backslash\n+      dst.append('\\\\');\n+    }\n+    return i;\n+  }\n+\n+  private List<MatchResult> matchGlobPaths(List<AzfsResourceId> globs) {\n+    return FluentIterable.from(globs).transform(this::expand).toList();\n+  }\n+\n+  /** Expands a pattern into {@link MatchResult}. */\n+  @VisibleForTesting\n+  MatchResult expand(AzfsResourceId azfsPattern) {\n+\n+    checkArgument(azfsPattern.isWildcard(), \"is Wildcard\");\n+    String blobPrefix = azfsPattern.getBlobNonWildcardPrefix();\n+    Pattern wildcardAsRegexp = Pattern.compile(wildcardToRegexp(azfsPattern.getBlob()));\n+\n+    LOG.debug(\n+        \"matching files in container {}, prefix {} against pattern {}\",\n+        azfsPattern.getContainer(),\n+        blobPrefix,\n+        wildcardAsRegexp.toString());\n+\n+    ListBlobsOptions listOptions = new ListBlobsOptions().setPrefix(blobPrefix);\n+    Duration timeout = Duration.ZERO.plusMinutes(1);\n+\n+    String account = azfsPattern.getAccount();\n+    String container = azfsPattern.getContainer();\n+    BlobContainerClient blobContainerClient = client.get().getBlobContainerClient(container);\n+    PagedIterable<BlobItem> blobs = blobContainerClient.listBlobs(listOptions, timeout);\n+    List<MatchResult.Metadata> results = new ArrayList<>();\n+\n+    blobs.forEach(\n+        blob -> {\n+          String name = blob.getName();\n+          if (wildcardAsRegexp.matcher(name).matches() && !name.endsWith(\"/\")) {\n+            LOG.debug(\"Matched object: {}\", name);\n+\n+            BlobProperties properties = blobContainerClient.getBlobClient(name).getProperties();\n+            AzfsResourceId rid =\n+                AzfsResourceId.fromComponents(account, container, name)\n+                    .withSize(properties.getBlobSize())\n+                    .withLastModified(Date.from(properties.getLastModified().toInstant()));\n+\n+            results.add(toMetadata(rid, properties.getContentEncoding()));\n+          }\n+        });\n+\n+    return MatchResult.create(MatchResult.Status.OK, results);\n+  }\n+\n+  private MatchResult.Metadata toMetadata(AzfsResourceId path, String contentEncoding) {\n+\n+    checkArgument(path.getSize().isPresent(), \"path has size\");\n+    boolean isReadSeekEfficient = !NON_READ_SEEK_EFFICIENT_ENCODINGS.contains(contentEncoding);\n+\n+    return MatchResult.Metadata.builder()\n+        .setIsReadSeekEfficient(isReadSeekEfficient)\n+        .setResourceId(path)\n+        .setSizeBytes(path.getSize().get())\n+        .setLastModifiedMillis(path.getLastModified().transform(Date::getTime).or(0L))\n+        .build();\n+  }\n+\n+  /**\n+   * Returns {@link MatchResult MatchResults} for the given {@link AzfsResourceId paths}.\n+   *\n+   * <p>The number of returned {@link MatchResult MatchResults} equals to the number of given {@link\n+   * AzfsResourceId paths}. Each {@link MatchResult} contains one {@link MatchResult.Metadata}.\n+   */\n+  @VisibleForTesting\n+  private Iterable<MatchResult> matchNonGlobPaths(List<AzfsResourceId> paths) {\n+    ImmutableList.Builder<MatchResult> toReturn = ImmutableList.builder();\n+    for (AzfsResourceId path : paths) {\n+      toReturn.add(toMatchResult(path));\n+    }\n+    return toReturn.build();\n+  }\n+\n+  private MatchResult toMatchResult(AzfsResourceId path) {\n+    BlobClient blobClient =\n+        client.get().getBlobContainerClient(path.getContainer()).getBlobClient(path.getBlob());\n+    BlobProperties blobProperties;\n+\n+    try {\n+      blobProperties = blobClient.getProperties();\n+    } catch (BlobStorageException e) {\n+      if (e.getStatusCode() == 404) {\n+        return MatchResult.create(MatchResult.Status.NOT_FOUND, new FileNotFoundException());\n+      }\n+      return MatchResult.create(MatchResult.Status.ERROR, new IOException(e));\n+    }\n+\n+    return MatchResult.create(\n+        MatchResult.Status.OK,\n+        ImmutableList.of(\n+            toMetadata(\n+                path.withSize(blobProperties.getBlobSize())\n+                    .withLastModified(Date.from(blobProperties.getLastModified().toInstant())),\n+                blobProperties.getContentEncoding())));\n   }\n \n   @Override\n   protected WritableByteChannel create(AzfsResourceId resourceId, CreateOptions createOptions)\n       throws IOException {\n-    // TODO\n-    return null;\n+    BlobContainerClient blobContainerClient =\n+        client.get().getBlobContainerClient(resourceId.getContainer());\n+    if (!blobContainerClient.exists()) {\n+      throw new UnsupportedOperationException(\"create does not create containers.\");\n+    }\n+\n+    BlobClient blobClient = blobContainerClient.getBlobClient(resourceId.getBlob());\n+    // The getBlobOutputStream method overwrites existing blobs,\n+    // so throw an error in this case to prevent data loss\n+    if (blobClient.exists()) {\n+      throw new IOException(\"This filename is already in use.\");\n+    }\n+\n+    OutputStream outputStream;\n+    try {\n+      outputStream = blobClient.getBlockBlobClient().getBlobOutputStream();\n+    } catch (BlobStorageException e) {\n+      throw (IOException) e.getCause();\n+    }\n+    return newChannel(outputStream);\n   }\n \n   @Override\n   protected ReadableByteChannel open(AzfsResourceId resourceId) throws IOException {\n-    // TODO\n-    return null;\n+    BlobClient blobClient =\n+        client\n+            .get()\n+            .getBlobContainerClient(resourceId.getContainer())\n+            .getBlobClient(resourceId.getBlob());\n+    if (!blobClient.exists()) {\n+      throw new FileNotFoundException(\"The requested file doesn't exist.\");\n+    }\n+    return new AzureReadableSeekableByteChannel(blobClient);\n   }\n \n   @Override\n   protected void copy(List<AzfsResourceId> srcPaths, List<AzfsResourceId> destPaths)\n       throws IOException {\n-    // TODO\n+    checkArgument(\n+        srcPaths.size() == destPaths.size(),\n+        \"sizes of source paths and destination paths do not match\");\n+\n+    Iterator<AzfsResourceId> sourcePathsIterator = srcPaths.iterator();\n+    Iterator<AzfsResourceId> destinationPathsIterator = destPaths.iterator();\n+    while (sourcePathsIterator.hasNext()) {\n+      final AzfsResourceId sourcePath = sourcePathsIterator.next();\n+      final AzfsResourceId destinationPath = destinationPathsIterator.next();\n+      copy(sourcePath, destinationPath);\n+    }\n   }\n \n   @VisibleForTesting\n   void copy(AzfsResourceId sourcePath, AzfsResourceId destinationPath) throws IOException {\n-    // TODO\n+    checkArgument(\n+        sourcePath.getBlob() != null && destinationPath.getBlob() != null,\n+        \"This method is intended to copy file-like resources, not directories.\");\n+\n+    // get source blob client\n+    BlobClient srcBlobClient =\n+        client\n+            .get()\n+            .getBlobContainerClient(sourcePath.getContainer())\n+            .getBlobClient(sourcePath.getBlob());\n+    if (!srcBlobClient.exists()) {\n+      throw new FileNotFoundException(\"The copy source does not exist.\");\n+    }\n+\n+    // get destination blob client\n+    BlobContainerClient destBlobContainerClient =\n+        client.get().getBlobContainerClient(destinationPath.getContainer());\n+    if (!destBlobContainerClient.exists()) {\n+      client.get().createBlobContainer(destinationPath.getContainer());\n+    }\n+    BlobClient destBlobClient = destBlobContainerClient.getBlobClient(destinationPath.getBlob());\n+\n+    destBlobClient.copyFromUrl(srcBlobClient.getBlobUrl() + generateSasToken());\n+  }\n+\n+  @VisibleForTesting\n+  String generateSasToken() throws IOException {\n+    SharedAccessAccountPolicy sharedAccessAccountPolicy = new SharedAccessAccountPolicy();\n+    long date = new Date().getTime();\n+    long expiryDate = new Date(date + 8640000).getTime();\n+\n+    sharedAccessAccountPolicy.setPermissionsFromString(\"racwdlup\");\n+    sharedAccessAccountPolicy.setSharedAccessStartTime(new Date(date));\n+    sharedAccessAccountPolicy.setSharedAccessExpiryTime(new Date(expiryDate));\n+    sharedAccessAccountPolicy.setResourceTypeFromString(\n+        \"co\"); // container, object, add s for service\n+    sharedAccessAccountPolicy.setServiceFromString(\"b\"); // blob, add \"fqt\" for file, queue, table\n+\n+    String storageConnectionString = options.getAzureConnectionString();\n+    try {\n+      CloudStorageAccount storageAccount = CloudStorageAccount.parse(storageConnectionString);\n+      return \"?\" + storageAccount.generateSharedAccessSignature(sharedAccessAccountPolicy);\n+    } catch (Exception e) {\n+      throw (IOException) e.getCause();\n+    }\n   }\n \n   @Override\n   protected void rename(List<AzfsResourceId> srcResourceIds, List<AzfsResourceId> destResourceIds)\n       throws IOException {\n-    // TODO\n+    copy(srcResourceIds, destResourceIds);\n+    delete(srcResourceIds);\n   }\n \n+  // This method with delete a virtual folder or a blob", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 403}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk0ODExMzU2OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxNzo1MDoxOVrOHBzzjw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxNzo1MDoxOVrOHBzzjw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY1OTQwNw==", "bodyText": "For line 133 and 134 Can you add something like \"Internal error encountered in AzureBlobStoreFileSystem: Expect no more elements in ...\" ?", "url": "https://github.com/apache/beam/pull/12581#discussion_r471659407", "createdAt": "2020-08-17T17:50:19Z", "author": {"login": "pabloem"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "diffHunk": "@@ -17,67 +17,438 @@\n  */\n package org.apache.beam.sdk.io.azure.blobstore;\n \n+import static java.nio.channels.Channels.newChannel;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobItem;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.BlobStorageException;\n+import com.azure.storage.blob.models.ListBlobsOptions;\n+import com.microsoft.azure.storage.CloudStorageAccount;\n+import com.microsoft.azure.storage.SharedAccessAccountPolicy;\n+import java.io.FileNotFoundException;\n import java.io.IOException;\n+import java.io.OutputStream;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.time.Duration;\n+import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Date;\n+import java.util.Iterator;\n import java.util.List;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n import org.apache.beam.sdk.io.FileSystem;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreClientBuilderFactory;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n import org.apache.beam.sdk.io.fs.CreateOptions;\n import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.util.InstanceBuilder;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Supplier;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Suppliers;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableSet;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n class AzureBlobStoreFileSystem extends FileSystem<AzfsResourceId> {\n \n+  private static final Logger LOG = LoggerFactory.getLogger(AzureBlobStoreFileSystem.class);\n+\n+  private static final ImmutableSet<String> NON_READ_SEEK_EFFICIENT_ENCODINGS =\n+      ImmutableSet.of(\"gzip\");\n+\n+  private Supplier<BlobServiceClient> client;\n+  private final BlobstoreOptions options;\n+\n+  AzureBlobStoreFileSystem(BlobstoreOptions options) {\n+    this.options = checkNotNull(options, \"options\");\n+\n+    BlobServiceClientBuilder builder =\n+        InstanceBuilder.ofType(BlobstoreClientBuilderFactory.class)\n+            .fromClass(options.getBlobstoreClientFactoryClass())\n+            .build()\n+            .createBuilder(options);\n+\n+    // The Supplier is to make sure we don't call .build() unless we are actually using Azure.\n+    client = Suppliers.memoize(builder::buildClient);\n+  }\n+\n+  @VisibleForTesting\n+  void setClient(BlobServiceClient client) {\n+    this.client = Suppliers.ofInstance(client);\n+  }\n+\n+  @VisibleForTesting\n+  BlobServiceClient getClient() {\n+    return client.get();\n+  }\n+\n   @Override\n   protected String getScheme() {\n-    return \"azfs\";\n+    return AzfsResourceId.SCHEME;\n   }\n \n   @Override\n-  protected List<MatchResult> match(List<String> specs) throws IOException {\n-    // TODO\n-    return null;\n+  protected List<MatchResult> match(List<String> specs) {\n+    List<AzfsResourceId> paths =\n+        specs.stream().map(AzfsResourceId::fromUri).collect(Collectors.toList());\n+    List<AzfsResourceId> globs = new ArrayList<>();\n+    List<AzfsResourceId> nonGlobs = new ArrayList<>();\n+    List<Boolean> isGlobBooleans = new ArrayList<>();\n+\n+    for (AzfsResourceId path : paths) {\n+      if (path.isWildcard()) {\n+        globs.add(path);\n+        isGlobBooleans.add(true);\n+      } else {\n+        nonGlobs.add(path);\n+        isGlobBooleans.add(false);\n+      }\n+    }\n+\n+    Iterator<MatchResult> globMatches = matchGlobPaths(globs).iterator();\n+    Iterator<MatchResult> nonGlobMatches = matchNonGlobPaths(nonGlobs).iterator();\n+\n+    ImmutableList.Builder<MatchResult> matchResults = ImmutableList.builder();\n+    for (Boolean isGlob : isGlobBooleans) {\n+      if (isGlob) {\n+        checkState(globMatches.hasNext(), \"Expect globMatches has next.\");\n+        matchResults.add(globMatches.next());\n+      } else {\n+        checkState(nonGlobMatches.hasNext(), \"Expect nonGlobMatches has next.\");\n+        matchResults.add(nonGlobMatches.next());\n+      }\n+    }\n+    checkState(!globMatches.hasNext(), \"Expect no more elements in globMatches.\");\n+    checkState(!nonGlobMatches.hasNext(), \"Expect no more elements in nonGlobMatches.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 122}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk0ODEyMzg0OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxNzo1MzowM1rOHBz5yQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQyMTozMzo1MVrOHDaopQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY2MTAwMQ==", "bodyText": "Should this be i-1? or should it actually be i+1? I understand this code comes from elsewhere (thus it's a good idea to standardize and make it a utility) - can you add a unit test with a file pattern containing a backslash at the end to see what happens?", "url": "https://github.com/apache/beam/pull/12581#discussion_r471661001", "createdAt": "2020-08-17T17:53:03Z", "author": {"login": "pabloem"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "diffHunk": "@@ -17,67 +17,438 @@\n  */\n package org.apache.beam.sdk.io.azure.blobstore;\n \n+import static java.nio.channels.Channels.newChannel;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobItem;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.BlobStorageException;\n+import com.azure.storage.blob.models.ListBlobsOptions;\n+import com.microsoft.azure.storage.CloudStorageAccount;\n+import com.microsoft.azure.storage.SharedAccessAccountPolicy;\n+import java.io.FileNotFoundException;\n import java.io.IOException;\n+import java.io.OutputStream;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.time.Duration;\n+import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Date;\n+import java.util.Iterator;\n import java.util.List;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n import org.apache.beam.sdk.io.FileSystem;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreClientBuilderFactory;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n import org.apache.beam.sdk.io.fs.CreateOptions;\n import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.util.InstanceBuilder;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Supplier;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Suppliers;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableSet;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n class AzureBlobStoreFileSystem extends FileSystem<AzfsResourceId> {\n \n+  private static final Logger LOG = LoggerFactory.getLogger(AzureBlobStoreFileSystem.class);\n+\n+  private static final ImmutableSet<String> NON_READ_SEEK_EFFICIENT_ENCODINGS =\n+      ImmutableSet.of(\"gzip\");\n+\n+  private Supplier<BlobServiceClient> client;\n+  private final BlobstoreOptions options;\n+\n+  AzureBlobStoreFileSystem(BlobstoreOptions options) {\n+    this.options = checkNotNull(options, \"options\");\n+\n+    BlobServiceClientBuilder builder =\n+        InstanceBuilder.ofType(BlobstoreClientBuilderFactory.class)\n+            .fromClass(options.getBlobstoreClientFactoryClass())\n+            .build()\n+            .createBuilder(options);\n+\n+    // The Supplier is to make sure we don't call .build() unless we are actually using Azure.\n+    client = Suppliers.memoize(builder::buildClient);\n+  }\n+\n+  @VisibleForTesting\n+  void setClient(BlobServiceClient client) {\n+    this.client = Suppliers.ofInstance(client);\n+  }\n+\n+  @VisibleForTesting\n+  BlobServiceClient getClient() {\n+    return client.get();\n+  }\n+\n   @Override\n   protected String getScheme() {\n-    return \"azfs\";\n+    return AzfsResourceId.SCHEME;\n   }\n \n   @Override\n-  protected List<MatchResult> match(List<String> specs) throws IOException {\n-    // TODO\n-    return null;\n+  protected List<MatchResult> match(List<String> specs) {\n+    List<AzfsResourceId> paths =\n+        specs.stream().map(AzfsResourceId::fromUri).collect(Collectors.toList());\n+    List<AzfsResourceId> globs = new ArrayList<>();\n+    List<AzfsResourceId> nonGlobs = new ArrayList<>();\n+    List<Boolean> isGlobBooleans = new ArrayList<>();\n+\n+    for (AzfsResourceId path : paths) {\n+      if (path.isWildcard()) {\n+        globs.add(path);\n+        isGlobBooleans.add(true);\n+      } else {\n+        nonGlobs.add(path);\n+        isGlobBooleans.add(false);\n+      }\n+    }\n+\n+    Iterator<MatchResult> globMatches = matchGlobPaths(globs).iterator();\n+    Iterator<MatchResult> nonGlobMatches = matchNonGlobPaths(nonGlobs).iterator();\n+\n+    ImmutableList.Builder<MatchResult> matchResults = ImmutableList.builder();\n+    for (Boolean isGlob : isGlobBooleans) {\n+      if (isGlob) {\n+        checkState(globMatches.hasNext(), \"Expect globMatches has next.\");\n+        matchResults.add(globMatches.next());\n+      } else {\n+        checkState(nonGlobMatches.hasNext(), \"Expect nonGlobMatches has next.\");\n+        matchResults.add(nonGlobMatches.next());\n+      }\n+    }\n+    checkState(!globMatches.hasNext(), \"Expect no more elements in globMatches.\");\n+    checkState(!nonGlobMatches.hasNext(), \"Expect no more elements in nonGlobMatches.\");\n+\n+    return matchResults.build();\n+  }\n+\n+  /**\n+   * Expands glob expressions to regular expressions.\n+   *\n+   * @param globExp the glob expression to expand\n+   * @return a string with the regular expression this glob expands to\n+   */\n+  @VisibleForTesting\n+  static String wildcardToRegexp(String globExp) {\n+    StringBuilder dst = new StringBuilder();\n+    char[] src = globExp.replace(\"**/*\", \"**\").toCharArray();\n+    int i = 0;\n+    while (i < src.length) {\n+      char c = src[i++];\n+      switch (c) {\n+        case '*':\n+          // One char lookahead for **\n+          if (i < src.length && src[i] == '*') {\n+            dst.append(\".*\");\n+            ++i;\n+          } else {\n+            dst.append(\"[^/]*\");\n+          }\n+          break;\n+        case '?':\n+          dst.append(\"[^/]\");\n+          break;\n+        case '.':\n+        case '+':\n+        case '{':\n+        case '}':\n+        case '(':\n+        case ')':\n+        case '|':\n+        case '^':\n+        case '$':\n+          // These need to be escaped in regular expressions\n+          dst.append('\\\\').append(c);\n+          break;\n+        case '\\\\':\n+          i = doubleSlashes(dst, src, i);\n+          break;\n+        default:\n+          dst.append(c);\n+          break;\n+      }\n+    }\n+    return dst.toString();\n+  }\n+\n+  private static int doubleSlashes(StringBuilder dst, char[] src, int i) {\n+    // Emit the next character without special interpretation\n+    dst.append(\"\\\\\\\\\");\n+    if ((i - 1) != src.length) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 179}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzM0NDE2NQ==", "bodyText": "As we discussed, there seems to be an error in this method, but we will resolve it in a follow-up PR.", "url": "https://github.com/apache/beam/pull/12581#discussion_r473344165", "createdAt": "2020-08-19T21:33:51Z", "author": {"login": "ettirapp"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "diffHunk": "@@ -17,67 +17,438 @@\n  */\n package org.apache.beam.sdk.io.azure.blobstore;\n \n+import static java.nio.channels.Channels.newChannel;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobItem;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.BlobStorageException;\n+import com.azure.storage.blob.models.ListBlobsOptions;\n+import com.microsoft.azure.storage.CloudStorageAccount;\n+import com.microsoft.azure.storage.SharedAccessAccountPolicy;\n+import java.io.FileNotFoundException;\n import java.io.IOException;\n+import java.io.OutputStream;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.time.Duration;\n+import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Date;\n+import java.util.Iterator;\n import java.util.List;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n import org.apache.beam.sdk.io.FileSystem;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreClientBuilderFactory;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n import org.apache.beam.sdk.io.fs.CreateOptions;\n import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.util.InstanceBuilder;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Supplier;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Suppliers;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableSet;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n class AzureBlobStoreFileSystem extends FileSystem<AzfsResourceId> {\n \n+  private static final Logger LOG = LoggerFactory.getLogger(AzureBlobStoreFileSystem.class);\n+\n+  private static final ImmutableSet<String> NON_READ_SEEK_EFFICIENT_ENCODINGS =\n+      ImmutableSet.of(\"gzip\");\n+\n+  private Supplier<BlobServiceClient> client;\n+  private final BlobstoreOptions options;\n+\n+  AzureBlobStoreFileSystem(BlobstoreOptions options) {\n+    this.options = checkNotNull(options, \"options\");\n+\n+    BlobServiceClientBuilder builder =\n+        InstanceBuilder.ofType(BlobstoreClientBuilderFactory.class)\n+            .fromClass(options.getBlobstoreClientFactoryClass())\n+            .build()\n+            .createBuilder(options);\n+\n+    // The Supplier is to make sure we don't call .build() unless we are actually using Azure.\n+    client = Suppliers.memoize(builder::buildClient);\n+  }\n+\n+  @VisibleForTesting\n+  void setClient(BlobServiceClient client) {\n+    this.client = Suppliers.ofInstance(client);\n+  }\n+\n+  @VisibleForTesting\n+  BlobServiceClient getClient() {\n+    return client.get();\n+  }\n+\n   @Override\n   protected String getScheme() {\n-    return \"azfs\";\n+    return AzfsResourceId.SCHEME;\n   }\n \n   @Override\n-  protected List<MatchResult> match(List<String> specs) throws IOException {\n-    // TODO\n-    return null;\n+  protected List<MatchResult> match(List<String> specs) {\n+    List<AzfsResourceId> paths =\n+        specs.stream().map(AzfsResourceId::fromUri).collect(Collectors.toList());\n+    List<AzfsResourceId> globs = new ArrayList<>();\n+    List<AzfsResourceId> nonGlobs = new ArrayList<>();\n+    List<Boolean> isGlobBooleans = new ArrayList<>();\n+\n+    for (AzfsResourceId path : paths) {\n+      if (path.isWildcard()) {\n+        globs.add(path);\n+        isGlobBooleans.add(true);\n+      } else {\n+        nonGlobs.add(path);\n+        isGlobBooleans.add(false);\n+      }\n+    }\n+\n+    Iterator<MatchResult> globMatches = matchGlobPaths(globs).iterator();\n+    Iterator<MatchResult> nonGlobMatches = matchNonGlobPaths(nonGlobs).iterator();\n+\n+    ImmutableList.Builder<MatchResult> matchResults = ImmutableList.builder();\n+    for (Boolean isGlob : isGlobBooleans) {\n+      if (isGlob) {\n+        checkState(globMatches.hasNext(), \"Expect globMatches has next.\");\n+        matchResults.add(globMatches.next());\n+      } else {\n+        checkState(nonGlobMatches.hasNext(), \"Expect nonGlobMatches has next.\");\n+        matchResults.add(nonGlobMatches.next());\n+      }\n+    }\n+    checkState(!globMatches.hasNext(), \"Expect no more elements in globMatches.\");\n+    checkState(!nonGlobMatches.hasNext(), \"Expect no more elements in nonGlobMatches.\");\n+\n+    return matchResults.build();\n+  }\n+\n+  /**\n+   * Expands glob expressions to regular expressions.\n+   *\n+   * @param globExp the glob expression to expand\n+   * @return a string with the regular expression this glob expands to\n+   */\n+  @VisibleForTesting\n+  static String wildcardToRegexp(String globExp) {\n+    StringBuilder dst = new StringBuilder();\n+    char[] src = globExp.replace(\"**/*\", \"**\").toCharArray();\n+    int i = 0;\n+    while (i < src.length) {\n+      char c = src[i++];\n+      switch (c) {\n+        case '*':\n+          // One char lookahead for **\n+          if (i < src.length && src[i] == '*') {\n+            dst.append(\".*\");\n+            ++i;\n+          } else {\n+            dst.append(\"[^/]*\");\n+          }\n+          break;\n+        case '?':\n+          dst.append(\"[^/]\");\n+          break;\n+        case '.':\n+        case '+':\n+        case '{':\n+        case '}':\n+        case '(':\n+        case ')':\n+        case '|':\n+        case '^':\n+        case '$':\n+          // These need to be escaped in regular expressions\n+          dst.append('\\\\').append(c);\n+          break;\n+        case '\\\\':\n+          i = doubleSlashes(dst, src, i);\n+          break;\n+        default:\n+          dst.append(c);\n+          break;\n+      }\n+    }\n+    return dst.toString();\n+  }\n+\n+  private static int doubleSlashes(StringBuilder dst, char[] src, int i) {\n+    // Emit the next character without special interpretation\n+    dst.append(\"\\\\\\\\\");\n+    if ((i - 1) != src.length) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY2MTAwMQ=="}, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 179}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk0ODE0MTY5OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxNzo1Nzo1MVrOHB0ESQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxNzo1Nzo1MVrOHB0ESQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY2MzY4OQ==", "bodyText": "Can you LOG.info the fact that a container is being created?", "url": "https://github.com/apache/beam/pull/12581#discussion_r471663689", "createdAt": "2020-08-17T17:57:51Z", "author": {"login": "pabloem"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "diffHunk": "@@ -17,67 +17,438 @@\n  */\n package org.apache.beam.sdk.io.azure.blobstore;\n \n+import static java.nio.channels.Channels.newChannel;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobItem;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.BlobStorageException;\n+import com.azure.storage.blob.models.ListBlobsOptions;\n+import com.microsoft.azure.storage.CloudStorageAccount;\n+import com.microsoft.azure.storage.SharedAccessAccountPolicy;\n+import java.io.FileNotFoundException;\n import java.io.IOException;\n+import java.io.OutputStream;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.time.Duration;\n+import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Date;\n+import java.util.Iterator;\n import java.util.List;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n import org.apache.beam.sdk.io.FileSystem;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreClientBuilderFactory;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n import org.apache.beam.sdk.io.fs.CreateOptions;\n import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.util.InstanceBuilder;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Supplier;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Suppliers;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableSet;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n class AzureBlobStoreFileSystem extends FileSystem<AzfsResourceId> {\n \n+  private static final Logger LOG = LoggerFactory.getLogger(AzureBlobStoreFileSystem.class);\n+\n+  private static final ImmutableSet<String> NON_READ_SEEK_EFFICIENT_ENCODINGS =\n+      ImmutableSet.of(\"gzip\");\n+\n+  private Supplier<BlobServiceClient> client;\n+  private final BlobstoreOptions options;\n+\n+  AzureBlobStoreFileSystem(BlobstoreOptions options) {\n+    this.options = checkNotNull(options, \"options\");\n+\n+    BlobServiceClientBuilder builder =\n+        InstanceBuilder.ofType(BlobstoreClientBuilderFactory.class)\n+            .fromClass(options.getBlobstoreClientFactoryClass())\n+            .build()\n+            .createBuilder(options);\n+\n+    // The Supplier is to make sure we don't call .build() unless we are actually using Azure.\n+    client = Suppliers.memoize(builder::buildClient);\n+  }\n+\n+  @VisibleForTesting\n+  void setClient(BlobServiceClient client) {\n+    this.client = Suppliers.ofInstance(client);\n+  }\n+\n+  @VisibleForTesting\n+  BlobServiceClient getClient() {\n+    return client.get();\n+  }\n+\n   @Override\n   protected String getScheme() {\n-    return \"azfs\";\n+    return AzfsResourceId.SCHEME;\n   }\n \n   @Override\n-  protected List<MatchResult> match(List<String> specs) throws IOException {\n-    // TODO\n-    return null;\n+  protected List<MatchResult> match(List<String> specs) {\n+    List<AzfsResourceId> paths =\n+        specs.stream().map(AzfsResourceId::fromUri).collect(Collectors.toList());\n+    List<AzfsResourceId> globs = new ArrayList<>();\n+    List<AzfsResourceId> nonGlobs = new ArrayList<>();\n+    List<Boolean> isGlobBooleans = new ArrayList<>();\n+\n+    for (AzfsResourceId path : paths) {\n+      if (path.isWildcard()) {\n+        globs.add(path);\n+        isGlobBooleans.add(true);\n+      } else {\n+        nonGlobs.add(path);\n+        isGlobBooleans.add(false);\n+      }\n+    }\n+\n+    Iterator<MatchResult> globMatches = matchGlobPaths(globs).iterator();\n+    Iterator<MatchResult> nonGlobMatches = matchNonGlobPaths(nonGlobs).iterator();\n+\n+    ImmutableList.Builder<MatchResult> matchResults = ImmutableList.builder();\n+    for (Boolean isGlob : isGlobBooleans) {\n+      if (isGlob) {\n+        checkState(globMatches.hasNext(), \"Expect globMatches has next.\");\n+        matchResults.add(globMatches.next());\n+      } else {\n+        checkState(nonGlobMatches.hasNext(), \"Expect nonGlobMatches has next.\");\n+        matchResults.add(nonGlobMatches.next());\n+      }\n+    }\n+    checkState(!globMatches.hasNext(), \"Expect no more elements in globMatches.\");\n+    checkState(!nonGlobMatches.hasNext(), \"Expect no more elements in nonGlobMatches.\");\n+\n+    return matchResults.build();\n+  }\n+\n+  /**\n+   * Expands glob expressions to regular expressions.\n+   *\n+   * @param globExp the glob expression to expand\n+   * @return a string with the regular expression this glob expands to\n+   */\n+  @VisibleForTesting\n+  static String wildcardToRegexp(String globExp) {\n+    StringBuilder dst = new StringBuilder();\n+    char[] src = globExp.replace(\"**/*\", \"**\").toCharArray();\n+    int i = 0;\n+    while (i < src.length) {\n+      char c = src[i++];\n+      switch (c) {\n+        case '*':\n+          // One char lookahead for **\n+          if (i < src.length && src[i] == '*') {\n+            dst.append(\".*\");\n+            ++i;\n+          } else {\n+            dst.append(\"[^/]*\");\n+          }\n+          break;\n+        case '?':\n+          dst.append(\"[^/]\");\n+          break;\n+        case '.':\n+        case '+':\n+        case '{':\n+        case '}':\n+        case '(':\n+        case ')':\n+        case '|':\n+        case '^':\n+        case '$':\n+          // These need to be escaped in regular expressions\n+          dst.append('\\\\').append(c);\n+          break;\n+        case '\\\\':\n+          i = doubleSlashes(dst, src, i);\n+          break;\n+        default:\n+          dst.append(c);\n+          break;\n+      }\n+    }\n+    return dst.toString();\n+  }\n+\n+  private static int doubleSlashes(StringBuilder dst, char[] src, int i) {\n+    // Emit the next character without special interpretation\n+    dst.append(\"\\\\\\\\\");\n+    if ((i - 1) != src.length) {\n+      dst.append(src[i]);\n+      i++;\n+    } else {\n+      // A backslash at the very end is treated like an escaped backslash\n+      dst.append('\\\\');\n+    }\n+    return i;\n+  }\n+\n+  private List<MatchResult> matchGlobPaths(List<AzfsResourceId> globs) {\n+    return FluentIterable.from(globs).transform(this::expand).toList();\n+  }\n+\n+  /** Expands a pattern into {@link MatchResult}. */\n+  @VisibleForTesting\n+  MatchResult expand(AzfsResourceId azfsPattern) {\n+\n+    checkArgument(azfsPattern.isWildcard(), \"is Wildcard\");\n+    String blobPrefix = azfsPattern.getBlobNonWildcardPrefix();\n+    Pattern wildcardAsRegexp = Pattern.compile(wildcardToRegexp(azfsPattern.getBlob()));\n+\n+    LOG.debug(\n+        \"matching files in container {}, prefix {} against pattern {}\",\n+        azfsPattern.getContainer(),\n+        blobPrefix,\n+        wildcardAsRegexp.toString());\n+\n+    ListBlobsOptions listOptions = new ListBlobsOptions().setPrefix(blobPrefix);\n+    Duration timeout = Duration.ZERO.plusMinutes(1);\n+\n+    String account = azfsPattern.getAccount();\n+    String container = azfsPattern.getContainer();\n+    BlobContainerClient blobContainerClient = client.get().getBlobContainerClient(container);\n+    PagedIterable<BlobItem> blobs = blobContainerClient.listBlobs(listOptions, timeout);\n+    List<MatchResult.Metadata> results = new ArrayList<>();\n+\n+    blobs.forEach(\n+        blob -> {\n+          String name = blob.getName();\n+          if (wildcardAsRegexp.matcher(name).matches() && !name.endsWith(\"/\")) {\n+            LOG.debug(\"Matched object: {}\", name);\n+\n+            BlobProperties properties = blobContainerClient.getBlobClient(name).getProperties();\n+            AzfsResourceId rid =\n+                AzfsResourceId.fromComponents(account, container, name)\n+                    .withSize(properties.getBlobSize())\n+                    .withLastModified(Date.from(properties.getLastModified().toInstant()));\n+\n+            results.add(toMetadata(rid, properties.getContentEncoding()));\n+          }\n+        });\n+\n+    return MatchResult.create(MatchResult.Status.OK, results);\n+  }\n+\n+  private MatchResult.Metadata toMetadata(AzfsResourceId path, String contentEncoding) {\n+\n+    checkArgument(path.getSize().isPresent(), \"path has size\");\n+    boolean isReadSeekEfficient = !NON_READ_SEEK_EFFICIENT_ENCODINGS.contains(contentEncoding);\n+\n+    return MatchResult.Metadata.builder()\n+        .setIsReadSeekEfficient(isReadSeekEfficient)\n+        .setResourceId(path)\n+        .setSizeBytes(path.getSize().get())\n+        .setLastModifiedMillis(path.getLastModified().transform(Date::getTime).or(0L))\n+        .build();\n+  }\n+\n+  /**\n+   * Returns {@link MatchResult MatchResults} for the given {@link AzfsResourceId paths}.\n+   *\n+   * <p>The number of returned {@link MatchResult MatchResults} equals to the number of given {@link\n+   * AzfsResourceId paths}. Each {@link MatchResult} contains one {@link MatchResult.Metadata}.\n+   */\n+  @VisibleForTesting\n+  private Iterable<MatchResult> matchNonGlobPaths(List<AzfsResourceId> paths) {\n+    ImmutableList.Builder<MatchResult> toReturn = ImmutableList.builder();\n+    for (AzfsResourceId path : paths) {\n+      toReturn.add(toMatchResult(path));\n+    }\n+    return toReturn.build();\n+  }\n+\n+  private MatchResult toMatchResult(AzfsResourceId path) {\n+    BlobClient blobClient =\n+        client.get().getBlobContainerClient(path.getContainer()).getBlobClient(path.getBlob());\n+    BlobProperties blobProperties;\n+\n+    try {\n+      blobProperties = blobClient.getProperties();\n+    } catch (BlobStorageException e) {\n+      if (e.getStatusCode() == 404) {\n+        return MatchResult.create(MatchResult.Status.NOT_FOUND, new FileNotFoundException());\n+      }\n+      return MatchResult.create(MatchResult.Status.ERROR, new IOException(e));\n+    }\n+\n+    return MatchResult.create(\n+        MatchResult.Status.OK,\n+        ImmutableList.of(\n+            toMetadata(\n+                path.withSize(blobProperties.getBlobSize())\n+                    .withLastModified(Date.from(blobProperties.getLastModified().toInstant())),\n+                blobProperties.getContentEncoding())));\n   }\n \n   @Override\n   protected WritableByteChannel create(AzfsResourceId resourceId, CreateOptions createOptions)\n       throws IOException {\n-    // TODO\n-    return null;\n+    BlobContainerClient blobContainerClient =\n+        client.get().getBlobContainerClient(resourceId.getContainer());\n+    if (!blobContainerClient.exists()) {\n+      throw new UnsupportedOperationException(\"create does not create containers.\");\n+    }\n+\n+    BlobClient blobClient = blobContainerClient.getBlobClient(resourceId.getBlob());\n+    // The getBlobOutputStream method overwrites existing blobs,\n+    // so throw an error in this case to prevent data loss\n+    if (blobClient.exists()) {\n+      throw new IOException(\"This filename is already in use.\");\n+    }\n+\n+    OutputStream outputStream;\n+    try {\n+      outputStream = blobClient.getBlockBlobClient().getBlobOutputStream();\n+    } catch (BlobStorageException e) {\n+      throw (IOException) e.getCause();\n+    }\n+    return newChannel(outputStream);\n   }\n \n   @Override\n   protected ReadableByteChannel open(AzfsResourceId resourceId) throws IOException {\n-    // TODO\n-    return null;\n+    BlobClient blobClient =\n+        client\n+            .get()\n+            .getBlobContainerClient(resourceId.getContainer())\n+            .getBlobClient(resourceId.getBlob());\n+    if (!blobClient.exists()) {\n+      throw new FileNotFoundException(\"The requested file doesn't exist.\");\n+    }\n+    return new AzureReadableSeekableByteChannel(blobClient);\n   }\n \n   @Override\n   protected void copy(List<AzfsResourceId> srcPaths, List<AzfsResourceId> destPaths)\n       throws IOException {\n-    // TODO\n+    checkArgument(\n+        srcPaths.size() == destPaths.size(),\n+        \"sizes of source paths and destination paths do not match\");\n+\n+    Iterator<AzfsResourceId> sourcePathsIterator = srcPaths.iterator();\n+    Iterator<AzfsResourceId> destinationPathsIterator = destPaths.iterator();\n+    while (sourcePathsIterator.hasNext()) {\n+      final AzfsResourceId sourcePath = sourcePathsIterator.next();\n+      final AzfsResourceId destinationPath = destinationPathsIterator.next();\n+      copy(sourcePath, destinationPath);\n+    }\n   }\n \n   @VisibleForTesting\n   void copy(AzfsResourceId sourcePath, AzfsResourceId destinationPath) throws IOException {\n-    // TODO\n+    checkArgument(\n+        sourcePath.getBlob() != null && destinationPath.getBlob() != null,\n+        \"This method is intended to copy file-like resources, not directories.\");\n+\n+    // get source blob client\n+    BlobClient srcBlobClient =\n+        client\n+            .get()\n+            .getBlobContainerClient(sourcePath.getContainer())\n+            .getBlobClient(sourcePath.getBlob());\n+    if (!srcBlobClient.exists()) {\n+      throw new FileNotFoundException(\"The copy source does not exist.\");\n+    }\n+\n+    // get destination blob client\n+    BlobContainerClient destBlobContainerClient =\n+        client.get().getBlobContainerClient(destinationPath.getContainer());\n+    if (!destBlobContainerClient.exists()) {\n+      client.get().createBlobContainer(destinationPath.getContainer());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 366}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk0ODE1MDM4OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxODowMDoyNFrOHB0JxA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxOTo1MjowNlrOHB4q7A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY2NTA5Mg==", "bodyText": "remove this line", "url": "https://github.com/apache/beam/pull/12581#discussion_r471665092", "createdAt": "2020-08-17T18:00:24Z", "author": {"login": "pabloem"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "diffHunk": "@@ -17,67 +17,438 @@\n  */\n package org.apache.beam.sdk.io.azure.blobstore;\n \n+import static java.nio.channels.Channels.newChannel;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobItem;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.BlobStorageException;\n+import com.azure.storage.blob.models.ListBlobsOptions;\n+import com.microsoft.azure.storage.CloudStorageAccount;\n+import com.microsoft.azure.storage.SharedAccessAccountPolicy;\n+import java.io.FileNotFoundException;\n import java.io.IOException;\n+import java.io.OutputStream;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.time.Duration;\n+import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Date;\n+import java.util.Iterator;\n import java.util.List;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n import org.apache.beam.sdk.io.FileSystem;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreClientBuilderFactory;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n import org.apache.beam.sdk.io.fs.CreateOptions;\n import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.util.InstanceBuilder;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Supplier;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Suppliers;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableSet;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n class AzureBlobStoreFileSystem extends FileSystem<AzfsResourceId> {\n \n+  private static final Logger LOG = LoggerFactory.getLogger(AzureBlobStoreFileSystem.class);\n+\n+  private static final ImmutableSet<String> NON_READ_SEEK_EFFICIENT_ENCODINGS =\n+      ImmutableSet.of(\"gzip\");\n+\n+  private Supplier<BlobServiceClient> client;\n+  private final BlobstoreOptions options;\n+\n+  AzureBlobStoreFileSystem(BlobstoreOptions options) {\n+    this.options = checkNotNull(options, \"options\");\n+\n+    BlobServiceClientBuilder builder =\n+        InstanceBuilder.ofType(BlobstoreClientBuilderFactory.class)\n+            .fromClass(options.getBlobstoreClientFactoryClass())\n+            .build()\n+            .createBuilder(options);\n+\n+    // The Supplier is to make sure we don't call .build() unless we are actually using Azure.\n+    client = Suppliers.memoize(builder::buildClient);\n+  }\n+\n+  @VisibleForTesting\n+  void setClient(BlobServiceClient client) {\n+    this.client = Suppliers.ofInstance(client);\n+  }\n+\n+  @VisibleForTesting\n+  BlobServiceClient getClient() {\n+    return client.get();\n+  }\n+\n   @Override\n   protected String getScheme() {\n-    return \"azfs\";\n+    return AzfsResourceId.SCHEME;\n   }\n \n   @Override\n-  protected List<MatchResult> match(List<String> specs) throws IOException {\n-    // TODO\n-    return null;\n+  protected List<MatchResult> match(List<String> specs) {\n+    List<AzfsResourceId> paths =\n+        specs.stream().map(AzfsResourceId::fromUri).collect(Collectors.toList());\n+    List<AzfsResourceId> globs = new ArrayList<>();\n+    List<AzfsResourceId> nonGlobs = new ArrayList<>();\n+    List<Boolean> isGlobBooleans = new ArrayList<>();\n+\n+    for (AzfsResourceId path : paths) {\n+      if (path.isWildcard()) {\n+        globs.add(path);\n+        isGlobBooleans.add(true);\n+      } else {\n+        nonGlobs.add(path);\n+        isGlobBooleans.add(false);\n+      }\n+    }\n+\n+    Iterator<MatchResult> globMatches = matchGlobPaths(globs).iterator();\n+    Iterator<MatchResult> nonGlobMatches = matchNonGlobPaths(nonGlobs).iterator();\n+\n+    ImmutableList.Builder<MatchResult> matchResults = ImmutableList.builder();\n+    for (Boolean isGlob : isGlobBooleans) {\n+      if (isGlob) {\n+        checkState(globMatches.hasNext(), \"Expect globMatches has next.\");\n+        matchResults.add(globMatches.next());\n+      } else {\n+        checkState(nonGlobMatches.hasNext(), \"Expect nonGlobMatches has next.\");\n+        matchResults.add(nonGlobMatches.next());\n+      }\n+    }\n+    checkState(!globMatches.hasNext(), \"Expect no more elements in globMatches.\");\n+    checkState(!nonGlobMatches.hasNext(), \"Expect no more elements in nonGlobMatches.\");\n+\n+    return matchResults.build();\n+  }\n+\n+  /**\n+   * Expands glob expressions to regular expressions.\n+   *\n+   * @param globExp the glob expression to expand\n+   * @return a string with the regular expression this glob expands to\n+   */\n+  @VisibleForTesting\n+  static String wildcardToRegexp(String globExp) {\n+    StringBuilder dst = new StringBuilder();\n+    char[] src = globExp.replace(\"**/*\", \"**\").toCharArray();\n+    int i = 0;\n+    while (i < src.length) {\n+      char c = src[i++];\n+      switch (c) {\n+        case '*':\n+          // One char lookahead for **\n+          if (i < src.length && src[i] == '*') {\n+            dst.append(\".*\");\n+            ++i;\n+          } else {\n+            dst.append(\"[^/]*\");\n+          }\n+          break;\n+        case '?':\n+          dst.append(\"[^/]\");\n+          break;\n+        case '.':\n+        case '+':\n+        case '{':\n+        case '}':\n+        case '(':\n+        case ')':\n+        case '|':\n+        case '^':\n+        case '$':\n+          // These need to be escaped in regular expressions\n+          dst.append('\\\\').append(c);\n+          break;\n+        case '\\\\':\n+          i = doubleSlashes(dst, src, i);\n+          break;\n+        default:\n+          dst.append(c);\n+          break;\n+      }\n+    }\n+    return dst.toString();\n+  }\n+\n+  private static int doubleSlashes(StringBuilder dst, char[] src, int i) {\n+    // Emit the next character without special interpretation\n+    dst.append(\"\\\\\\\\\");\n+    if ((i - 1) != src.length) {\n+      dst.append(src[i]);\n+      i++;\n+    } else {\n+      // A backslash at the very end is treated like an escaped backslash\n+      dst.append('\\\\');\n+    }\n+    return i;\n+  }\n+\n+  private List<MatchResult> matchGlobPaths(List<AzfsResourceId> globs) {\n+    return FluentIterable.from(globs).transform(this::expand).toList();\n+  }\n+\n+  /** Expands a pattern into {@link MatchResult}. */\n+  @VisibleForTesting\n+  MatchResult expand(AzfsResourceId azfsPattern) {\n+\n+    checkArgument(azfsPattern.isWildcard(), \"is Wildcard\");\n+    String blobPrefix = azfsPattern.getBlobNonWildcardPrefix();\n+    Pattern wildcardAsRegexp = Pattern.compile(wildcardToRegexp(azfsPattern.getBlob()));\n+\n+    LOG.debug(\n+        \"matching files in container {}, prefix {} against pattern {}\",\n+        azfsPattern.getContainer(),\n+        blobPrefix,\n+        wildcardAsRegexp.toString());\n+\n+    ListBlobsOptions listOptions = new ListBlobsOptions().setPrefix(blobPrefix);\n+    Duration timeout = Duration.ZERO.plusMinutes(1);\n+\n+    String account = azfsPattern.getAccount();\n+    String container = azfsPattern.getContainer();\n+    BlobContainerClient blobContainerClient = client.get().getBlobContainerClient(container);\n+    PagedIterable<BlobItem> blobs = blobContainerClient.listBlobs(listOptions, timeout);\n+    List<MatchResult.Metadata> results = new ArrayList<>();\n+\n+    blobs.forEach(\n+        blob -> {\n+          String name = blob.getName();\n+          if (wildcardAsRegexp.matcher(name).matches() && !name.endsWith(\"/\")) {\n+            LOG.debug(\"Matched object: {}\", name);\n+\n+            BlobProperties properties = blobContainerClient.getBlobClient(name).getProperties();\n+            AzfsResourceId rid =\n+                AzfsResourceId.fromComponents(account, container, name)\n+                    .withSize(properties.getBlobSize())\n+                    .withLastModified(Date.from(properties.getLastModified().toInstant()));\n+\n+            results.add(toMetadata(rid, properties.getContentEncoding()));\n+          }\n+        });\n+\n+    return MatchResult.create(MatchResult.Status.OK, results);\n+  }\n+\n+  private MatchResult.Metadata toMetadata(AzfsResourceId path, String contentEncoding) {\n+\n+    checkArgument(path.getSize().isPresent(), \"path has size\");\n+    boolean isReadSeekEfficient = !NON_READ_SEEK_EFFICIENT_ENCODINGS.contains(contentEncoding);\n+\n+    return MatchResult.Metadata.builder()\n+        .setIsReadSeekEfficient(isReadSeekEfficient)\n+        .setResourceId(path)\n+        .setSizeBytes(path.getSize().get())\n+        .setLastModifiedMillis(path.getLastModified().transform(Date::getTime).or(0L))\n+        .build();\n+  }\n+\n+  /**\n+   * Returns {@link MatchResult MatchResults} for the given {@link AzfsResourceId paths}.\n+   *\n+   * <p>The number of returned {@link MatchResult MatchResults} equals to the number of given {@link\n+   * AzfsResourceId paths}. Each {@link MatchResult} contains one {@link MatchResult.Metadata}.\n+   */\n+  @VisibleForTesting\n+  private Iterable<MatchResult> matchNonGlobPaths(List<AzfsResourceId> paths) {\n+    ImmutableList.Builder<MatchResult> toReturn = ImmutableList.builder();\n+    for (AzfsResourceId path : paths) {\n+      toReturn.add(toMatchResult(path));\n+    }\n+    return toReturn.build();\n+  }\n+\n+  private MatchResult toMatchResult(AzfsResourceId path) {\n+    BlobClient blobClient =\n+        client.get().getBlobContainerClient(path.getContainer()).getBlobClient(path.getBlob());\n+    BlobProperties blobProperties;\n+\n+    try {\n+      blobProperties = blobClient.getProperties();\n+    } catch (BlobStorageException e) {\n+      if (e.getStatusCode() == 404) {\n+        return MatchResult.create(MatchResult.Status.NOT_FOUND, new FileNotFoundException());\n+      }\n+      return MatchResult.create(MatchResult.Status.ERROR, new IOException(e));\n+    }\n+\n+    return MatchResult.create(\n+        MatchResult.Status.OK,\n+        ImmutableList.of(\n+            toMetadata(\n+                path.withSize(blobProperties.getBlobSize())\n+                    .withLastModified(Date.from(blobProperties.getLastModified().toInstant())),\n+                blobProperties.getContentEncoding())));\n   }\n \n   @Override\n   protected WritableByteChannel create(AzfsResourceId resourceId, CreateOptions createOptions)\n       throws IOException {\n-    // TODO\n-    return null;\n+    BlobContainerClient blobContainerClient =\n+        client.get().getBlobContainerClient(resourceId.getContainer());\n+    if (!blobContainerClient.exists()) {\n+      throw new UnsupportedOperationException(\"create does not create containers.\");\n+    }\n+\n+    BlobClient blobClient = blobContainerClient.getBlobClient(resourceId.getBlob());\n+    // The getBlobOutputStream method overwrites existing blobs,\n+    // so throw an error in this case to prevent data loss\n+    if (blobClient.exists()) {\n+      throw new IOException(\"This filename is already in use.\");\n+    }\n+\n+    OutputStream outputStream;\n+    try {\n+      outputStream = blobClient.getBlockBlobClient().getBlobOutputStream();\n+    } catch (BlobStorageException e) {\n+      throw (IOException) e.getCause();\n+    }\n+    return newChannel(outputStream);\n   }\n \n   @Override\n   protected ReadableByteChannel open(AzfsResourceId resourceId) throws IOException {\n-    // TODO\n-    return null;\n+    BlobClient blobClient =\n+        client\n+            .get()\n+            .getBlobContainerClient(resourceId.getContainer())\n+            .getBlobClient(resourceId.getBlob());\n+    if (!blobClient.exists()) {\n+      throw new FileNotFoundException(\"The requested file doesn't exist.\");\n+    }\n+    return new AzureReadableSeekableByteChannel(blobClient);\n   }\n \n   @Override\n   protected void copy(List<AzfsResourceId> srcPaths, List<AzfsResourceId> destPaths)\n       throws IOException {\n-    // TODO\n+    checkArgument(\n+        srcPaths.size() == destPaths.size(),\n+        \"sizes of source paths and destination paths do not match\");\n+\n+    Iterator<AzfsResourceId> sourcePathsIterator = srcPaths.iterator();\n+    Iterator<AzfsResourceId> destinationPathsIterator = destPaths.iterator();\n+    while (sourcePathsIterator.hasNext()) {\n+      final AzfsResourceId sourcePath = sourcePathsIterator.next();\n+      final AzfsResourceId destinationPath = destinationPathsIterator.next();\n+      copy(sourcePath, destinationPath);\n+    }\n   }\n \n   @VisibleForTesting\n   void copy(AzfsResourceId sourcePath, AzfsResourceId destinationPath) throws IOException {\n-    // TODO\n+    checkArgument(\n+        sourcePath.getBlob() != null && destinationPath.getBlob() != null,\n+        \"This method is intended to copy file-like resources, not directories.\");\n+\n+    // get source blob client\n+    BlobClient srcBlobClient =\n+        client\n+            .get()\n+            .getBlobContainerClient(sourcePath.getContainer())\n+            .getBlobClient(sourcePath.getBlob());\n+    if (!srcBlobClient.exists()) {\n+      throw new FileNotFoundException(\"The copy source does not exist.\");\n+    }\n+\n+    // get destination blob client\n+    BlobContainerClient destBlobContainerClient =\n+        client.get().getBlobContainerClient(destinationPath.getContainer());\n+    if (!destBlobContainerClient.exists()) {\n+      client.get().createBlobContainer(destinationPath.getContainer());\n+    }\n+    BlobClient destBlobClient = destBlobContainerClient.getBlobClient(destinationPath.getBlob());\n+\n+    destBlobClient.copyFromUrl(srcBlobClient.getBlobUrl() + generateSasToken());\n+  }\n+\n+  @VisibleForTesting\n+  String generateSasToken() throws IOException {\n+    SharedAccessAccountPolicy sharedAccessAccountPolicy = new SharedAccessAccountPolicy();\n+    long date = new Date().getTime();\n+    long expiryDate = new Date(date + 8640000).getTime();\n+\n+    sharedAccessAccountPolicy.setPermissionsFromString(\"racwdlup\");\n+    sharedAccessAccountPolicy.setSharedAccessStartTime(new Date(date));\n+    sharedAccessAccountPolicy.setSharedAccessExpiryTime(new Date(expiryDate));\n+    sharedAccessAccountPolicy.setResourceTypeFromString(\n+        \"co\"); // container, object, add s for service\n+    sharedAccessAccountPolicy.setServiceFromString(\"b\"); // blob, add \"fqt\" for file, queue, table\n+\n+    String storageConnectionString = options.getAzureConnectionString();\n+    try {\n+      CloudStorageAccount storageAccount = CloudStorageAccount.parse(storageConnectionString);\n+      return \"?\" + storageAccount.generateSharedAccessSignature(sharedAccessAccountPolicy);\n+    } catch (Exception e) {\n+      throw (IOException) e.getCause();\n+    }\n   }\n \n   @Override\n   protected void rename(List<AzfsResourceId> srcResourceIds, List<AzfsResourceId> destResourceIds)\n       throws IOException {\n-    // TODO\n+    copy(srcResourceIds, destResourceIds);\n+    delete(srcResourceIds);\n   }\n \n+  // This method with delete a virtual folder or a blob\n   @Override\n   protected void delete(Collection<AzfsResourceId> resourceIds) throws IOException {\n-    // TODO\n+    for (AzfsResourceId resourceId : resourceIds) {\n+      if (resourceId.getBlob() == null) {\n+        throw new IOException(\"delete does not delete containers.\");\n+      }\n+\n+      BlobContainerClient container =\n+          client.get().getBlobContainerClient(resourceId.getContainer());\n+\n+      // deleting a blob that is not a directory\n+      if (!resourceId.isDirectory()) {\n+        BlobClient blob = container.getBlobClient(resourceId.getBlob());\n+        if (!blob.exists()) {\n+          throw new FileNotFoundException(\"The resource to delete does not exist.\");\n+        }\n+        blob.delete();\n+      }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 423}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTczOTExNg==", "bodyText": "(meaning the empty 427 line)", "url": "https://github.com/apache/beam/pull/12581#discussion_r471739116", "createdAt": "2020-08-17T19:52:06Z", "author": {"login": "pabloem"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "diffHunk": "@@ -17,67 +17,438 @@\n  */\n package org.apache.beam.sdk.io.azure.blobstore;\n \n+import static java.nio.channels.Channels.newChannel;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.BlobServiceClientBuilder;\n+import com.azure.storage.blob.models.BlobItem;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.BlobStorageException;\n+import com.azure.storage.blob.models.ListBlobsOptions;\n+import com.microsoft.azure.storage.CloudStorageAccount;\n+import com.microsoft.azure.storage.SharedAccessAccountPolicy;\n+import java.io.FileNotFoundException;\n import java.io.IOException;\n+import java.io.OutputStream;\n import java.nio.channels.ReadableByteChannel;\n import java.nio.channels.WritableByteChannel;\n+import java.time.Duration;\n+import java.util.ArrayList;\n import java.util.Collection;\n+import java.util.Date;\n+import java.util.Iterator;\n import java.util.List;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n import org.apache.beam.sdk.io.FileSystem;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreClientBuilderFactory;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n import org.apache.beam.sdk.io.fs.CreateOptions;\n import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.util.InstanceBuilder;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.annotations.VisibleForTesting;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Supplier;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Suppliers;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableSet;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n \n class AzureBlobStoreFileSystem extends FileSystem<AzfsResourceId> {\n \n+  private static final Logger LOG = LoggerFactory.getLogger(AzureBlobStoreFileSystem.class);\n+\n+  private static final ImmutableSet<String> NON_READ_SEEK_EFFICIENT_ENCODINGS =\n+      ImmutableSet.of(\"gzip\");\n+\n+  private Supplier<BlobServiceClient> client;\n+  private final BlobstoreOptions options;\n+\n+  AzureBlobStoreFileSystem(BlobstoreOptions options) {\n+    this.options = checkNotNull(options, \"options\");\n+\n+    BlobServiceClientBuilder builder =\n+        InstanceBuilder.ofType(BlobstoreClientBuilderFactory.class)\n+            .fromClass(options.getBlobstoreClientFactoryClass())\n+            .build()\n+            .createBuilder(options);\n+\n+    // The Supplier is to make sure we don't call .build() unless we are actually using Azure.\n+    client = Suppliers.memoize(builder::buildClient);\n+  }\n+\n+  @VisibleForTesting\n+  void setClient(BlobServiceClient client) {\n+    this.client = Suppliers.ofInstance(client);\n+  }\n+\n+  @VisibleForTesting\n+  BlobServiceClient getClient() {\n+    return client.get();\n+  }\n+\n   @Override\n   protected String getScheme() {\n-    return \"azfs\";\n+    return AzfsResourceId.SCHEME;\n   }\n \n   @Override\n-  protected List<MatchResult> match(List<String> specs) throws IOException {\n-    // TODO\n-    return null;\n+  protected List<MatchResult> match(List<String> specs) {\n+    List<AzfsResourceId> paths =\n+        specs.stream().map(AzfsResourceId::fromUri).collect(Collectors.toList());\n+    List<AzfsResourceId> globs = new ArrayList<>();\n+    List<AzfsResourceId> nonGlobs = new ArrayList<>();\n+    List<Boolean> isGlobBooleans = new ArrayList<>();\n+\n+    for (AzfsResourceId path : paths) {\n+      if (path.isWildcard()) {\n+        globs.add(path);\n+        isGlobBooleans.add(true);\n+      } else {\n+        nonGlobs.add(path);\n+        isGlobBooleans.add(false);\n+      }\n+    }\n+\n+    Iterator<MatchResult> globMatches = matchGlobPaths(globs).iterator();\n+    Iterator<MatchResult> nonGlobMatches = matchNonGlobPaths(nonGlobs).iterator();\n+\n+    ImmutableList.Builder<MatchResult> matchResults = ImmutableList.builder();\n+    for (Boolean isGlob : isGlobBooleans) {\n+      if (isGlob) {\n+        checkState(globMatches.hasNext(), \"Expect globMatches has next.\");\n+        matchResults.add(globMatches.next());\n+      } else {\n+        checkState(nonGlobMatches.hasNext(), \"Expect nonGlobMatches has next.\");\n+        matchResults.add(nonGlobMatches.next());\n+      }\n+    }\n+    checkState(!globMatches.hasNext(), \"Expect no more elements in globMatches.\");\n+    checkState(!nonGlobMatches.hasNext(), \"Expect no more elements in nonGlobMatches.\");\n+\n+    return matchResults.build();\n+  }\n+\n+  /**\n+   * Expands glob expressions to regular expressions.\n+   *\n+   * @param globExp the glob expression to expand\n+   * @return a string with the regular expression this glob expands to\n+   */\n+  @VisibleForTesting\n+  static String wildcardToRegexp(String globExp) {\n+    StringBuilder dst = new StringBuilder();\n+    char[] src = globExp.replace(\"**/*\", \"**\").toCharArray();\n+    int i = 0;\n+    while (i < src.length) {\n+      char c = src[i++];\n+      switch (c) {\n+        case '*':\n+          // One char lookahead for **\n+          if (i < src.length && src[i] == '*') {\n+            dst.append(\".*\");\n+            ++i;\n+          } else {\n+            dst.append(\"[^/]*\");\n+          }\n+          break;\n+        case '?':\n+          dst.append(\"[^/]\");\n+          break;\n+        case '.':\n+        case '+':\n+        case '{':\n+        case '}':\n+        case '(':\n+        case ')':\n+        case '|':\n+        case '^':\n+        case '$':\n+          // These need to be escaped in regular expressions\n+          dst.append('\\\\').append(c);\n+          break;\n+        case '\\\\':\n+          i = doubleSlashes(dst, src, i);\n+          break;\n+        default:\n+          dst.append(c);\n+          break;\n+      }\n+    }\n+    return dst.toString();\n+  }\n+\n+  private static int doubleSlashes(StringBuilder dst, char[] src, int i) {\n+    // Emit the next character without special interpretation\n+    dst.append(\"\\\\\\\\\");\n+    if ((i - 1) != src.length) {\n+      dst.append(src[i]);\n+      i++;\n+    } else {\n+      // A backslash at the very end is treated like an escaped backslash\n+      dst.append('\\\\');\n+    }\n+    return i;\n+  }\n+\n+  private List<MatchResult> matchGlobPaths(List<AzfsResourceId> globs) {\n+    return FluentIterable.from(globs).transform(this::expand).toList();\n+  }\n+\n+  /** Expands a pattern into {@link MatchResult}. */\n+  @VisibleForTesting\n+  MatchResult expand(AzfsResourceId azfsPattern) {\n+\n+    checkArgument(azfsPattern.isWildcard(), \"is Wildcard\");\n+    String blobPrefix = azfsPattern.getBlobNonWildcardPrefix();\n+    Pattern wildcardAsRegexp = Pattern.compile(wildcardToRegexp(azfsPattern.getBlob()));\n+\n+    LOG.debug(\n+        \"matching files in container {}, prefix {} against pattern {}\",\n+        azfsPattern.getContainer(),\n+        blobPrefix,\n+        wildcardAsRegexp.toString());\n+\n+    ListBlobsOptions listOptions = new ListBlobsOptions().setPrefix(blobPrefix);\n+    Duration timeout = Duration.ZERO.plusMinutes(1);\n+\n+    String account = azfsPattern.getAccount();\n+    String container = azfsPattern.getContainer();\n+    BlobContainerClient blobContainerClient = client.get().getBlobContainerClient(container);\n+    PagedIterable<BlobItem> blobs = blobContainerClient.listBlobs(listOptions, timeout);\n+    List<MatchResult.Metadata> results = new ArrayList<>();\n+\n+    blobs.forEach(\n+        blob -> {\n+          String name = blob.getName();\n+          if (wildcardAsRegexp.matcher(name).matches() && !name.endsWith(\"/\")) {\n+            LOG.debug(\"Matched object: {}\", name);\n+\n+            BlobProperties properties = blobContainerClient.getBlobClient(name).getProperties();\n+            AzfsResourceId rid =\n+                AzfsResourceId.fromComponents(account, container, name)\n+                    .withSize(properties.getBlobSize())\n+                    .withLastModified(Date.from(properties.getLastModified().toInstant()));\n+\n+            results.add(toMetadata(rid, properties.getContentEncoding()));\n+          }\n+        });\n+\n+    return MatchResult.create(MatchResult.Status.OK, results);\n+  }\n+\n+  private MatchResult.Metadata toMetadata(AzfsResourceId path, String contentEncoding) {\n+\n+    checkArgument(path.getSize().isPresent(), \"path has size\");\n+    boolean isReadSeekEfficient = !NON_READ_SEEK_EFFICIENT_ENCODINGS.contains(contentEncoding);\n+\n+    return MatchResult.Metadata.builder()\n+        .setIsReadSeekEfficient(isReadSeekEfficient)\n+        .setResourceId(path)\n+        .setSizeBytes(path.getSize().get())\n+        .setLastModifiedMillis(path.getLastModified().transform(Date::getTime).or(0L))\n+        .build();\n+  }\n+\n+  /**\n+   * Returns {@link MatchResult MatchResults} for the given {@link AzfsResourceId paths}.\n+   *\n+   * <p>The number of returned {@link MatchResult MatchResults} equals to the number of given {@link\n+   * AzfsResourceId paths}. Each {@link MatchResult} contains one {@link MatchResult.Metadata}.\n+   */\n+  @VisibleForTesting\n+  private Iterable<MatchResult> matchNonGlobPaths(List<AzfsResourceId> paths) {\n+    ImmutableList.Builder<MatchResult> toReturn = ImmutableList.builder();\n+    for (AzfsResourceId path : paths) {\n+      toReturn.add(toMatchResult(path));\n+    }\n+    return toReturn.build();\n+  }\n+\n+  private MatchResult toMatchResult(AzfsResourceId path) {\n+    BlobClient blobClient =\n+        client.get().getBlobContainerClient(path.getContainer()).getBlobClient(path.getBlob());\n+    BlobProperties blobProperties;\n+\n+    try {\n+      blobProperties = blobClient.getProperties();\n+    } catch (BlobStorageException e) {\n+      if (e.getStatusCode() == 404) {\n+        return MatchResult.create(MatchResult.Status.NOT_FOUND, new FileNotFoundException());\n+      }\n+      return MatchResult.create(MatchResult.Status.ERROR, new IOException(e));\n+    }\n+\n+    return MatchResult.create(\n+        MatchResult.Status.OK,\n+        ImmutableList.of(\n+            toMetadata(\n+                path.withSize(blobProperties.getBlobSize())\n+                    .withLastModified(Date.from(blobProperties.getLastModified().toInstant())),\n+                blobProperties.getContentEncoding())));\n   }\n \n   @Override\n   protected WritableByteChannel create(AzfsResourceId resourceId, CreateOptions createOptions)\n       throws IOException {\n-    // TODO\n-    return null;\n+    BlobContainerClient blobContainerClient =\n+        client.get().getBlobContainerClient(resourceId.getContainer());\n+    if (!blobContainerClient.exists()) {\n+      throw new UnsupportedOperationException(\"create does not create containers.\");\n+    }\n+\n+    BlobClient blobClient = blobContainerClient.getBlobClient(resourceId.getBlob());\n+    // The getBlobOutputStream method overwrites existing blobs,\n+    // so throw an error in this case to prevent data loss\n+    if (blobClient.exists()) {\n+      throw new IOException(\"This filename is already in use.\");\n+    }\n+\n+    OutputStream outputStream;\n+    try {\n+      outputStream = blobClient.getBlockBlobClient().getBlobOutputStream();\n+    } catch (BlobStorageException e) {\n+      throw (IOException) e.getCause();\n+    }\n+    return newChannel(outputStream);\n   }\n \n   @Override\n   protected ReadableByteChannel open(AzfsResourceId resourceId) throws IOException {\n-    // TODO\n-    return null;\n+    BlobClient blobClient =\n+        client\n+            .get()\n+            .getBlobContainerClient(resourceId.getContainer())\n+            .getBlobClient(resourceId.getBlob());\n+    if (!blobClient.exists()) {\n+      throw new FileNotFoundException(\"The requested file doesn't exist.\");\n+    }\n+    return new AzureReadableSeekableByteChannel(blobClient);\n   }\n \n   @Override\n   protected void copy(List<AzfsResourceId> srcPaths, List<AzfsResourceId> destPaths)\n       throws IOException {\n-    // TODO\n+    checkArgument(\n+        srcPaths.size() == destPaths.size(),\n+        \"sizes of source paths and destination paths do not match\");\n+\n+    Iterator<AzfsResourceId> sourcePathsIterator = srcPaths.iterator();\n+    Iterator<AzfsResourceId> destinationPathsIterator = destPaths.iterator();\n+    while (sourcePathsIterator.hasNext()) {\n+      final AzfsResourceId sourcePath = sourcePathsIterator.next();\n+      final AzfsResourceId destinationPath = destinationPathsIterator.next();\n+      copy(sourcePath, destinationPath);\n+    }\n   }\n \n   @VisibleForTesting\n   void copy(AzfsResourceId sourcePath, AzfsResourceId destinationPath) throws IOException {\n-    // TODO\n+    checkArgument(\n+        sourcePath.getBlob() != null && destinationPath.getBlob() != null,\n+        \"This method is intended to copy file-like resources, not directories.\");\n+\n+    // get source blob client\n+    BlobClient srcBlobClient =\n+        client\n+            .get()\n+            .getBlobContainerClient(sourcePath.getContainer())\n+            .getBlobClient(sourcePath.getBlob());\n+    if (!srcBlobClient.exists()) {\n+      throw new FileNotFoundException(\"The copy source does not exist.\");\n+    }\n+\n+    // get destination blob client\n+    BlobContainerClient destBlobContainerClient =\n+        client.get().getBlobContainerClient(destinationPath.getContainer());\n+    if (!destBlobContainerClient.exists()) {\n+      client.get().createBlobContainer(destinationPath.getContainer());\n+    }\n+    BlobClient destBlobClient = destBlobContainerClient.getBlobClient(destinationPath.getBlob());\n+\n+    destBlobClient.copyFromUrl(srcBlobClient.getBlobUrl() + generateSasToken());\n+  }\n+\n+  @VisibleForTesting\n+  String generateSasToken() throws IOException {\n+    SharedAccessAccountPolicy sharedAccessAccountPolicy = new SharedAccessAccountPolicy();\n+    long date = new Date().getTime();\n+    long expiryDate = new Date(date + 8640000).getTime();\n+\n+    sharedAccessAccountPolicy.setPermissionsFromString(\"racwdlup\");\n+    sharedAccessAccountPolicy.setSharedAccessStartTime(new Date(date));\n+    sharedAccessAccountPolicy.setSharedAccessExpiryTime(new Date(expiryDate));\n+    sharedAccessAccountPolicy.setResourceTypeFromString(\n+        \"co\"); // container, object, add s for service\n+    sharedAccessAccountPolicy.setServiceFromString(\"b\"); // blob, add \"fqt\" for file, queue, table\n+\n+    String storageConnectionString = options.getAzureConnectionString();\n+    try {\n+      CloudStorageAccount storageAccount = CloudStorageAccount.parse(storageConnectionString);\n+      return \"?\" + storageAccount.generateSharedAccessSignature(sharedAccessAccountPolicy);\n+    } catch (Exception e) {\n+      throw (IOException) e.getCause();\n+    }\n   }\n \n   @Override\n   protected void rename(List<AzfsResourceId> srcResourceIds, List<AzfsResourceId> destResourceIds)\n       throws IOException {\n-    // TODO\n+    copy(srcResourceIds, destResourceIds);\n+    delete(srcResourceIds);\n   }\n \n+  // This method with delete a virtual folder or a blob\n   @Override\n   protected void delete(Collection<AzfsResourceId> resourceIds) throws IOException {\n-    // TODO\n+    for (AzfsResourceId resourceId : resourceIds) {\n+      if (resourceId.getBlob() == null) {\n+        throw new IOException(\"delete does not delete containers.\");\n+      }\n+\n+      BlobContainerClient container =\n+          client.get().getBlobContainerClient(resourceId.getContainer());\n+\n+      // deleting a blob that is not a directory\n+      if (!resourceId.isDirectory()) {\n+        BlobClient blob = container.getBlobClient(resourceId.getBlob());\n+        if (!blob.exists()) {\n+          throw new FileNotFoundException(\"The resource to delete does not exist.\");\n+        }\n+        blob.delete();\n+      }\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY2NTA5Mg=="}, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 423}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk0ODE2NzQwOnYy", "diffSide": "RIGHT", "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/options/AzureOptions.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxODowNTozMFrOHB0UGQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQwNDoyNzo1OVrOHCx6PQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY2NzczNw==", "bodyText": "It seems like you have already separated the Azure options and Blob options.", "url": "https://github.com/apache/beam/pull/12581#discussion_r471667737", "createdAt": "2020-08-17T18:05:30Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/options/AzureOptions.java", "diffHunk": "@@ -0,0 +1,86 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.azure.options;\n+\n+import com.azure.core.credential.TokenCredential;\n+import com.azure.core.util.Configuration;\n+import com.azure.identity.DefaultAzureCredentialBuilder;\n+import org.apache.beam.sdk.options.Default;\n+import org.apache.beam.sdk.options.DefaultValueFactory;\n+import org.apache.beam.sdk.options.Description;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+\n+public interface AzureOptions extends PipelineOptions {\n+\n+  // TODO: Add any other azure options that users should be able to configure\n+  // TODO: Confirm that Azure options are in this file, Blobstore options in BlobstoreOptions", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjY3NjkyNQ==", "bodyText": "I have decided to delete AzureOptions, as per our conversation.", "url": "https://github.com/apache/beam/pull/12581#discussion_r472676925", "createdAt": "2020-08-19T04:27:59Z", "author": {"login": "ettirapp"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/options/AzureOptions.java", "diffHunk": "@@ -0,0 +1,86 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.azure.options;\n+\n+import com.azure.core.credential.TokenCredential;\n+import com.azure.core.util.Configuration;\n+import com.azure.identity.DefaultAzureCredentialBuilder;\n+import org.apache.beam.sdk.options.Default;\n+import org.apache.beam.sdk.options.DefaultValueFactory;\n+import org.apache.beam.sdk.options.Description;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+\n+public interface AzureOptions extends PipelineOptions {\n+\n+  // TODO: Add any other azure options that users should be able to configure\n+  // TODO: Confirm that Azure options are in this file, Blobstore options in BlobstoreOptions", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY2NzczNw=="}, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk0ODE4OTMwOnYy", "diffSide": "RIGHT", "path": "sdks/java/io/azure/src/test/java/org/apache/beam/sdk/io/azure/blobstore/AzfsTestUtils.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxODoxMDoxN1rOHB0gLA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQwNDozMToyMVrOHCyCQQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY3MDgyOA==", "bodyText": "It assumes that the running env has AZURE_STORAGE_CONNECTION_STRING, which should be false for most of time.", "url": "https://github.com/apache/beam/pull/12581#discussion_r471670828", "createdAt": "2020-08-17T18:10:17Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/azure/src/test/java/org/apache/beam/sdk/io/azure/blobstore/AzfsTestUtils.java", "diffHunk": "@@ -0,0 +1,42 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.azure.blobstore;\n+\n+import com.azure.storage.blob.BlobServiceClient;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n+import org.apache.beam.sdk.options.PipelineOptionsFactory;\n+import org.mockito.Mockito;\n+\n+class AzfsTestUtils {\n+  static BlobstoreOptions azfsOptions() {\n+    BlobstoreOptions options = PipelineOptionsFactory.as(BlobstoreOptions.class);\n+    options.setAzureConnectionString(System.getenv(\"AZURE_STORAGE_CONNECTION_STRING\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjY3ODk3Nw==", "bodyText": "I had been running these tests as integration tests with my Azure account. Since Beam does not have an Azure account as of now, I will convert these tests to unit tests and I will move integration tests to a separate file.", "url": "https://github.com/apache/beam/pull/12581#discussion_r472678977", "createdAt": "2020-08-19T04:31:21Z", "author": {"login": "ettirapp"}, "path": "sdks/java/io/azure/src/test/java/org/apache/beam/sdk/io/azure/blobstore/AzfsTestUtils.java", "diffHunk": "@@ -0,0 +1,42 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.azure.blobstore;\n+\n+import com.azure.storage.blob.BlobServiceClient;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n+import org.apache.beam.sdk.options.PipelineOptionsFactory;\n+import org.mockito.Mockito;\n+\n+class AzfsTestUtils {\n+  static BlobstoreOptions azfsOptions() {\n+    BlobstoreOptions options = PipelineOptionsFactory.as(BlobstoreOptions.class);\n+    options.setAzureConnectionString(System.getenv(\"AZURE_STORAGE_CONNECTION_STRING\"));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY3MDgyOA=="}, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk0ODE5OTc2OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/azure/src/test/java/org/apache/beam/sdk/io/azure/blobstore/AzfsTestUtils.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxODoxMzo0MFrOHB0mug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQwNDozMDowMlrOHCx_JQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY3MjUwNg==", "bodyText": "Is it used anywhere?", "url": "https://github.com/apache/beam/pull/12581#discussion_r471672506", "createdAt": "2020-08-17T18:13:40Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/azure/src/test/java/org/apache/beam/sdk/io/azure/blobstore/AzfsTestUtils.java", "diffHunk": "@@ -0,0 +1,42 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.azure.blobstore;\n+\n+import com.azure.storage.blob.BlobServiceClient;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n+import org.apache.beam.sdk.options.PipelineOptionsFactory;\n+import org.mockito.Mockito;\n+\n+class AzfsTestUtils {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjY3ODE4MQ==", "bodyText": "I deleted this file for now.  I was going to use it in my unit tests, but I decided to build mocks in AzureBlobStoreFileSystemTest for now, and I will move them to a TestUtils file if the filesystem test code becomes over-complicated as is.", "url": "https://github.com/apache/beam/pull/12581#discussion_r472678181", "createdAt": "2020-08-19T04:30:02Z", "author": {"login": "ettirapp"}, "path": "sdks/java/io/azure/src/test/java/org/apache/beam/sdk/io/azure/blobstore/AzfsTestUtils.java", "diffHunk": "@@ -0,0 +1,42 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.azure.blobstore;\n+\n+import com.azure.storage.blob.BlobServiceClient;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n+import org.apache.beam.sdk.options.PipelineOptionsFactory;\n+import org.mockito.Mockito;\n+\n+class AzfsTestUtils {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY3MjUwNg=="}, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk0ODU3NTE3OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/options/AzureOptions.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxOTo0NDoxM1rOHB4cJQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQxNjozMTozNFrOHDPqvA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTczNTMzMw==", "bodyText": "These configuration-related variables seem to be non-serializable. I think we need to implement the special Json serializer before moving forward with adding these changes. We can remove these changes from this PR (and rely purely on a String-type connectionString) and add them in a follow-up PR, or get the Json serializer in this PR. What do you think?", "url": "https://github.com/apache/beam/pull/12581#discussion_r471735333", "createdAt": "2020-08-17T19:44:13Z", "author": {"login": "pabloem"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/options/AzureOptions.java", "diffHunk": "@@ -0,0 +1,86 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.azure.options;\n+\n+import com.azure.core.credential.TokenCredential;\n+import com.azure.core.util.Configuration;\n+import com.azure.identity.DefaultAzureCredentialBuilder;\n+import org.apache.beam.sdk.options.Default;\n+import org.apache.beam.sdk.options.DefaultValueFactory;\n+import org.apache.beam.sdk.options.Description;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+\n+public interface AzureOptions extends PipelineOptions {\n+\n+  // TODO: Add any other azure options that users should be able to configure\n+  // TODO: Confirm that Azure options are in this file, Blobstore options in BlobstoreOptions\n+\n+  /** The Azure service endpoint used by the Azure client. */\n+  @Description(\"Azure service endpoint used by the Azure client\")\n+  String getAzureServiceEndpoint();\n+\n+  void setAzureServiceEndpoint(String value);\n+\n+  /**\n+   * The credential instance that should be used to authenticate against Azure services. The option\n+   * value must contain a \"@type\" field and an Azure credentials provider class as the field value.\n+   */\n+  @Description(\n+      \"The credential instance that should be used to authenticate \"\n+          + \"against Azure services. The option value must contain \\\"@type\\\" field \"\n+          + \"and an Azure credentials provider class name as the field value.\")\n+  @Default.InstanceFactory(AzureUserCredentialsFactory.class)\n+  TokenCredential getAzureCredentialsProvider();\n+\n+  void setAzureCredentialsProvider(TokenCredential value);\n+\n+  /** Attempts to load Azure credentials. */\n+  class AzureUserCredentialsFactory implements DefaultValueFactory<TokenCredential> {\n+\n+    @Override\n+    public TokenCredential create(PipelineOptions options) {\n+      return new DefaultAzureCredentialBuilder().build();\n+    }\n+  }\n+\n+  /** The client configuration instance that should be used to configure Azure service clients. */\n+  @Description(\n+      \"The client configuration instance that should be used to configure Azure service clients\")\n+  @Default.InstanceFactory(ConfigurationFactory.class)\n+  Configuration getClientConfiguration();\n+\n+  void setClientConfiguration(Configuration configuration);\n+\n+  /** The client configuration instance that should be used to configure Azure service clients. */\n+  @Description(\n+      \"The client configuration instance that should be used to configure Azure http client configuration parameters.\"\n+          + \"Mentioned parameters are the available parameters that can be set. Set only those that need custom changes.\")\n+  @Default.InstanceFactory(ConfigurationFactory.class)\n+  Configuration getAzureHttpConfiguration();\n+\n+  void setAzureHttpConfiguration(Configuration configuration);\n+\n+  /** Default Azure client configuration. */\n+  class ConfigurationFactory implements DefaultValueFactory<Configuration> {\n+\n+    @Override\n+    public Configuration create(PipelineOptions options) {\n+      return new Configuration();\n+    }\n+  }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzE2NDQ3Ng==", "bodyText": "I was planning to implement a module similar to AwsModule to serialize the non-serializable variables.  I can include it in this PR, I'll work on it today.", "url": "https://github.com/apache/beam/pull/12581#discussion_r473164476", "createdAt": "2020-08-19T16:31:34Z", "author": {"login": "ettirapp"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/options/AzureOptions.java", "diffHunk": "@@ -0,0 +1,86 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.azure.options;\n+\n+import com.azure.core.credential.TokenCredential;\n+import com.azure.core.util.Configuration;\n+import com.azure.identity.DefaultAzureCredentialBuilder;\n+import org.apache.beam.sdk.options.Default;\n+import org.apache.beam.sdk.options.DefaultValueFactory;\n+import org.apache.beam.sdk.options.Description;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+\n+public interface AzureOptions extends PipelineOptions {\n+\n+  // TODO: Add any other azure options that users should be able to configure\n+  // TODO: Confirm that Azure options are in this file, Blobstore options in BlobstoreOptions\n+\n+  /** The Azure service endpoint used by the Azure client. */\n+  @Description(\"Azure service endpoint used by the Azure client\")\n+  String getAzureServiceEndpoint();\n+\n+  void setAzureServiceEndpoint(String value);\n+\n+  /**\n+   * The credential instance that should be used to authenticate against Azure services. The option\n+   * value must contain a \"@type\" field and an Azure credentials provider class as the field value.\n+   */\n+  @Description(\n+      \"The credential instance that should be used to authenticate \"\n+          + \"against Azure services. The option value must contain \\\"@type\\\" field \"\n+          + \"and an Azure credentials provider class name as the field value.\")\n+  @Default.InstanceFactory(AzureUserCredentialsFactory.class)\n+  TokenCredential getAzureCredentialsProvider();\n+\n+  void setAzureCredentialsProvider(TokenCredential value);\n+\n+  /** Attempts to load Azure credentials. */\n+  class AzureUserCredentialsFactory implements DefaultValueFactory<TokenCredential> {\n+\n+    @Override\n+    public TokenCredential create(PipelineOptions options) {\n+      return new DefaultAzureCredentialBuilder().build();\n+    }\n+  }\n+\n+  /** The client configuration instance that should be used to configure Azure service clients. */\n+  @Description(\n+      \"The client configuration instance that should be used to configure Azure service clients\")\n+  @Default.InstanceFactory(ConfigurationFactory.class)\n+  Configuration getClientConfiguration();\n+\n+  void setClientConfiguration(Configuration configuration);\n+\n+  /** The client configuration instance that should be used to configure Azure service clients. */\n+  @Description(\n+      \"The client configuration instance that should be used to configure Azure http client configuration parameters.\"\n+          + \"Mentioned parameters are the available parameters that can be set. Set only those that need custom changes.\")\n+  @Default.InstanceFactory(ConfigurationFactory.class)\n+  Configuration getAzureHttpConfiguration();\n+\n+  void setAzureHttpConfiguration(Configuration configuration);\n+\n+  /** Default Azure client configuration. */\n+  class ConfigurationFactory implements DefaultValueFactory<Configuration> {\n+\n+    @Override\n+    public Configuration create(PipelineOptions options) {\n+      return new Configuration();\n+    }\n+  }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTczNTMzMw=="}, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 85}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk0ODU4MDY3OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/options/package-info.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxOTo0NTo1M1rOHB4fZA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxOTo0NTo1M1rOHB4fZA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTczNjE2NA==", "bodyText": "this comment is more related to the options classes, but you can add this annotation to AzureOptions and BlobstoreOptions, so that we will be able to move options around. As discussed in person, when in doubt about where to put an option, err on the side of caution, and put them in BlobstoreOptions.", "url": "https://github.com/apache/beam/pull/12581#discussion_r471736164", "createdAt": "2020-08-17T19:45:53Z", "author": {"login": "pabloem"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/options/package-info.java", "diffHunk": "@@ -0,0 +1,23 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+/** Defines IO connectors for Microsoft Azure Blobstore. */\n+@Experimental(Kind.FILESYSTEM)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f456095e9b54d3256dd1148c217156fb6826950b"}, "originalPosition": 19}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk1MzM0NjMzOnYy", "diffSide": "RIGHT", "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQyMDo0NToxMVrOHCmB-g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQyMDo0NToxMVrOHCmB-g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjQ4MjI5OA==", "bodyText": "Constants usually have uppercase names, like so:\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              private static final int expiryTime = 86400000;\n          \n          \n            \n              private static final int DEFAULT_EXPIRY_TIME = 86400000;", "url": "https://github.com/apache/beam/pull/12581#discussion_r472482298", "createdAt": "2020-08-18T20:45:11Z", "author": {"login": "pabloem"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystem.java", "diffHunk": "@@ -68,6 +68,8 @@\n   private static final ImmutableSet<String> NON_READ_SEEK_EFFICIENT_ENCODINGS =\n       ImmutableSet.of(\"gzip\");\n \n+  private static final int expiryTime = 86400000;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5fb8001b8a1aac042f8a3046dc9342611b9a0484"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk1NzU0MTc4OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureReadableSeekableByteChannel.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQxNjoyMzowNFrOHDPG4w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQxNjoyNzozOVrOHDPatw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzE1NTI5OQ==", "bodyText": "I recommend you remove all the LOG.info lines from this class. Because there may be 100s or 1000s of AzureReadableSeekableByteChannel objects in a Beam pipeline, this logging may overwhelm the logging system", "url": "https://github.com/apache/beam/pull/12581#discussion_r473155299", "createdAt": "2020-08-19T16:23:04Z", "author": {"login": "pabloem"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureReadableSeekableByteChannel.java", "diffHunk": "@@ -44,23 +50,22 @@ public int read(ByteBuffer dst) throws IOException {\n     if (closed) {\n       throw new ClosedChannelException();\n     }\n-    if (!dst.hasRemaining()) {\n-      return 0;\n-    }\n \n     int read = 0;\n     if (dst.hasArray()) {\n       // Stores up to dst.remaining() bytes into dst.array() starting at dst.position().\n       // But dst can have an offset with its backing array, hence the + dst.arrayOffset().\n       read = inputStream.read(dst.array(), dst.position() + dst.arrayOffset(), dst.remaining());\n+      LOG.info(\"PArray: \" + StandardCharsets.UTF_8.decode(dst).toString());\n     } else {\n       byte[] myarray = new byte[dst.remaining()];\n       read = inputStream.read(myarray, 0, myarray.length);\n       dst.put(myarray);\n+      LOG.info(\"Array: \" + Arrays.toString(myarray));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9aea1b2a4846e156ceeeb880d798fd1896d14045"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzE2MDM3NQ==", "bodyText": "Got it, will do.", "url": "https://github.com/apache/beam/pull/12581#discussion_r473160375", "createdAt": "2020-08-19T16:27:39Z", "author": {"login": "ettirapp"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/blobstore/AzureReadableSeekableByteChannel.java", "diffHunk": "@@ -44,23 +50,22 @@ public int read(ByteBuffer dst) throws IOException {\n     if (closed) {\n       throw new ClosedChannelException();\n     }\n-    if (!dst.hasRemaining()) {\n-      return 0;\n-    }\n \n     int read = 0;\n     if (dst.hasArray()) {\n       // Stores up to dst.remaining() bytes into dst.array() starting at dst.position().\n       // But dst can have an offset with its backing array, hence the + dst.arrayOffset().\n       read = inputStream.read(dst.array(), dst.position() + dst.arrayOffset(), dst.remaining());\n+      LOG.info(\"PArray: \" + StandardCharsets.UTF_8.decode(dst).toString());\n     } else {\n       byte[] myarray = new byte[dst.remaining()];\n       read = inputStream.read(myarray, 0, myarray.length);\n       dst.put(myarray);\n+      LOG.info(\"Array: \" + Arrays.toString(myarray));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzE1NTI5OQ=="}, "originalCommit": {"oid": "9aea1b2a4846e156ceeeb880d798fd1896d14045"}, "originalPosition": 43}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk1Nzc2NTYxOnYy", "diffSide": "RIGHT", "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/options/BlobstoreOptions.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQxNzoxMDoxM1rOHDRbIA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQxNzoxMzo0NFrOHDRitw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzE5MzI0OA==", "bodyText": "The Environment Configuration property is failing to serialize, and thus it's preventing me from running the pipeline on DirectRunner. We can work around this by writing a custom JSON serializer (like in S3). But maybe we can remove environmentConfiguration for now and add it on a later change?", "url": "https://github.com/apache/beam/pull/12581#discussion_r473193248", "createdAt": "2020-08-19T17:10:13Z", "author": {"login": "pabloem"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/options/BlobstoreOptions.java", "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.azure.options;\n+\n+import com.azure.core.credential.TokenCredential;\n+import com.azure.core.http.HttpClient;\n+import com.azure.core.http.HttpPipeline;\n+import com.azure.core.http.policy.HttpPipelinePolicy;\n+import com.azure.core.util.Configuration;\n+import com.azure.identity.DefaultAzureCredentialBuilder;\n+import com.azure.storage.blob.models.CustomerProvidedKey;\n+import com.azure.storage.common.StorageSharedKeyCredential;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.annotations.Experimental.Kind;\n+import org.apache.beam.sdk.io.azure.blobstore.DefaultBlobstoreClientBuilderFactory;\n+import org.apache.beam.sdk.options.Default;\n+import org.apache.beam.sdk.options.DefaultValueFactory;\n+import org.apache.beam.sdk.options.Description;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.checkerframework.checker.nullness.qual.Nullable;\n+\n+// TODO: Tag each option with @Default or @Nullable\n+\n+@Experimental(Kind.FILESYSTEM)\n+/** Options used to configure Microsoft Azure Blob Storage. */\n+public interface BlobstoreOptions extends PipelineOptions {\n+\n+  @Description(\n+      \"Factory class that should be created and used to create a builder of Azure Blobstore client.\"\n+          + \"Override the default value if you need a Azure client with custom properties.\")\n+  @Default.Class(DefaultBlobstoreClientBuilderFactory.class)\n+  Class<? extends BlobstoreClientBuilderFactory> getBlobstoreClientFactoryClass();\n+\n+  void setBlobstoreClientFactoryClass(\n+      Class<? extends BlobstoreClientBuilderFactory> blobstoreClientFactoryClass);\n+\n+  @Description(\"Adds a pipeline policy to apply on each request sent to the blob service client.\")\n+  @Nullable\n+  HttpPipelinePolicy getPipelinePolicy();\n+\n+  void setPipelinePolicy(HttpPipelinePolicy pipelinePolicy);\n+\n+  /** The client configuration instance that should be used to configure Azure service clients. */\n+  @Description(\n+      \"The configuration instance used to retrieve environment configuration values \"\n+          + \"when building an Azure Blobstore client. Set only those that need custom changes.\")\n+  @Default.InstanceFactory(BlobstoreOptions.ConfigurationFactory.class)\n+  @Nullable\n+  Configuration getEnvironmentConfiguration();\n+\n+  void setEnvironmentConfiguration(Configuration configuration);\n+\n+  /** Default Azure client configuration. */\n+  class ConfigurationFactory implements DefaultValueFactory<Configuration> {\n+\n+    @Override\n+    public Configuration create(PipelineOptions options) {\n+      return new Configuration();\n+    }\n+  }\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aab24bfc50fd379a2a013ebe0ef52ef047756a48"}, "originalPosition": 76}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzE5NTE5MQ==", "bodyText": "Sure, I'll remove it", "url": "https://github.com/apache/beam/pull/12581#discussion_r473195191", "createdAt": "2020-08-19T17:13:44Z", "author": {"login": "ettirapp"}, "path": "sdks/java/io/azure/src/main/java/org/apache/beam/sdk/io/azure/options/BlobstoreOptions.java", "diffHunk": "@@ -0,0 +1,154 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.azure.options;\n+\n+import com.azure.core.credential.TokenCredential;\n+import com.azure.core.http.HttpClient;\n+import com.azure.core.http.HttpPipeline;\n+import com.azure.core.http.policy.HttpPipelinePolicy;\n+import com.azure.core.util.Configuration;\n+import com.azure.identity.DefaultAzureCredentialBuilder;\n+import com.azure.storage.blob.models.CustomerProvidedKey;\n+import com.azure.storage.common.StorageSharedKeyCredential;\n+import org.apache.beam.sdk.annotations.Experimental;\n+import org.apache.beam.sdk.annotations.Experimental.Kind;\n+import org.apache.beam.sdk.io.azure.blobstore.DefaultBlobstoreClientBuilderFactory;\n+import org.apache.beam.sdk.options.Default;\n+import org.apache.beam.sdk.options.DefaultValueFactory;\n+import org.apache.beam.sdk.options.Description;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.checkerframework.checker.nullness.qual.Nullable;\n+\n+// TODO: Tag each option with @Default or @Nullable\n+\n+@Experimental(Kind.FILESYSTEM)\n+/** Options used to configure Microsoft Azure Blob Storage. */\n+public interface BlobstoreOptions extends PipelineOptions {\n+\n+  @Description(\n+      \"Factory class that should be created and used to create a builder of Azure Blobstore client.\"\n+          + \"Override the default value if you need a Azure client with custom properties.\")\n+  @Default.Class(DefaultBlobstoreClientBuilderFactory.class)\n+  Class<? extends BlobstoreClientBuilderFactory> getBlobstoreClientFactoryClass();\n+\n+  void setBlobstoreClientFactoryClass(\n+      Class<? extends BlobstoreClientBuilderFactory> blobstoreClientFactoryClass);\n+\n+  @Description(\"Adds a pipeline policy to apply on each request sent to the blob service client.\")\n+  @Nullable\n+  HttpPipelinePolicy getPipelinePolicy();\n+\n+  void setPipelinePolicy(HttpPipelinePolicy pipelinePolicy);\n+\n+  /** The client configuration instance that should be used to configure Azure service clients. */\n+  @Description(\n+      \"The configuration instance used to retrieve environment configuration values \"\n+          + \"when building an Azure Blobstore client. Set only those that need custom changes.\")\n+  @Default.InstanceFactory(BlobstoreOptions.ConfigurationFactory.class)\n+  @Nullable\n+  Configuration getEnvironmentConfiguration();\n+\n+  void setEnvironmentConfiguration(Configuration configuration);\n+\n+  /** Default Azure client configuration. */\n+  class ConfigurationFactory implements DefaultValueFactory<Configuration> {\n+\n+    @Override\n+    public Configuration create(PipelineOptions options) {\n+      return new Configuration();\n+    }\n+  }\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzE5MzI0OA=="}, "originalCommit": {"oid": "aab24bfc50fd379a2a013ebe0ef52ef047756a48"}, "originalPosition": 76}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk1OTM1NDE2OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/azure/src/test/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystemTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQwMDowMToyMFrOHDhWwQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQwMDowODowMVrOHDhoow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzQ1NDI3Mw==", "bodyText": "Please file a JIRA issue to track this.", "url": "https://github.com/apache/beam/pull/12581#discussion_r473454273", "createdAt": "2020-08-20T00:01:20Z", "author": {"login": "pabloem"}, "path": "sdks/java/io/azure/src/test/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystemTest.java", "diffHunk": "@@ -0,0 +1,352 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.azure.blobstore;\n+\n+import static java.util.UUID.randomUUID;\n+import static org.apache.beam.sdk.io.fs.CreateOptions.StandardCreateOptions.builder;\n+import static org.hamcrest.Matchers.contains;\n+import static org.junit.Assert.assertArrayEquals;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertThat;\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.ArgumentMatchers.anyString;\n+import static org.mockito.Mockito.doAnswer;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.models.BlobItem;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.ListBlobsOptions;\n+import com.azure.storage.blob.specialized.BlobInputStream;\n+import com.azure.storage.blob.specialized.BlobOutputStream;\n+import com.azure.storage.blob.specialized.BlockBlobClient;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.ReadableByteChannel;\n+import java.nio.channels.WritableByteChannel;\n+import java.time.Duration;\n+import java.time.OffsetDateTime;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n+import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.options.PipelineOptionsFactory;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.junit.Before;\n+import org.junit.Ignore;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.JUnit4;\n+import org.mockito.Mockito;\n+\n+@RunWith(JUnit4.class)\n+@SuppressWarnings(\"CannotMockFinalClass\") // Mockito 2 and above can mock final classes\n+public class AzureBlobStoreFileSystemTest {\n+\n+  private static AzureBlobStoreFileSystem azureBlobStoreFileSystem;\n+  BlobstoreOptions options = PipelineOptionsFactory.as(BlobstoreOptions.class);\n+  BlobstoreOptions spyOptions = Mockito.spy(options);\n+  BlobServiceClient mockedServiceClient = Mockito.mock(BlobServiceClient.class);\n+  BlobContainerClient mockedContainerClient = Mockito.mock(BlobContainerClient.class);\n+  BlobClient mockedBlobClient = Mockito.mock(BlobClient.class);\n+  BlockBlobClient mockedBlockBlob = Mockito.mock(BlockBlobClient.class);\n+  BlobProperties mockedProperties = Mockito.mock(BlobProperties.class);\n+  PagedIterable<BlobItem> mockedPagedIterable = Mockito.mock(PagedIterable.class);\n+  BlobOutputStream mockedOutputStream = Mockito.mock(BlobOutputStream.class);\n+  BlobItem mockedBlobItem = Mockito.mock(BlobItem.class);\n+  BlobInputStream mockedInputStream = Mockito.mock(BlobInputStream.class);\n+\n+  @Before\n+  public void beforeClass() {\n+    azureBlobStoreFileSystem = new AzureBlobStoreFileSystem(spyOptions);\n+    azureBlobStoreFileSystem.setClient(mockedServiceClient);\n+\n+    boolean[] containerCreated = {false};\n+    when(mockedServiceClient.createBlobContainer(anyString()))\n+        .thenAnswer(\n+            (invocation) -> {\n+              containerCreated[0] = true;\n+              return mockedContainerClient;\n+            });\n+    when(mockedContainerClient.exists()).thenAnswer((invocation) -> containerCreated[0]);\n+    boolean[] blobCreated = {false};\n+    doAnswer(\n+            invocation -> {\n+              blobCreated[0] = true;\n+              return null;\n+            })\n+        .when(mockedBlobClient)\n+        .uploadFromFile(anyString());\n+    when(mockedBlobClient.exists()).thenAnswer((invocation) -> blobCreated[0]);\n+    when(azureBlobStoreFileSystem.getClient().getBlobContainerClient(anyString()))\n+        .thenReturn(mockedContainerClient);\n+    when(mockedContainerClient.getBlobClient(anyString())).thenReturn(mockedBlobClient);\n+    when(mockedBlobClient.getBlockBlobClient()).thenReturn(mockedBlockBlob);\n+    when(mockedBlobClient.getProperties()).thenReturn(mockedProperties);\n+    when(mockedProperties.getBlobSize()).thenReturn(Long.valueOf(1));\n+    when(mockedProperties.getLastModified()).thenReturn(OffsetDateTime.now());\n+    when(mockedContainerClient.listBlobs(any(ListBlobsOptions.class), any(Duration.class)))\n+        .thenReturn(mockedPagedIterable);\n+    when(mockedContainerClient.listBlobsByHierarchy(any(String.class)))\n+        .thenReturn(mockedPagedIterable);\n+    when(mockedBlockBlob.getBlobOutputStream())\n+        .thenAnswer(\n+            (i) -> {\n+              blobCreated[0] = true;\n+              return mockedOutputStream;\n+            });\n+    when(mockedBlobItem.getName()).thenReturn(\"name\");\n+    when(spyOptions.getSasToken()).thenReturn(\"sas-token\");\n+    when(mockedBlobClient.openInputStream()).thenReturn(mockedInputStream);\n+  }\n+\n+  @Test\n+  public void testGetScheme() {\n+    assertEquals(\"azfs\", azureBlobStoreFileSystem.getScheme());\n+  }\n+\n+  @Test\n+  public void testGlobTranslation() {\n+    assertEquals(\"foo\", AzureBlobStoreFileSystem.wildcardToRegexp(\"foo\"));\n+    assertEquals(\"fo[^/]*o\", AzureBlobStoreFileSystem.wildcardToRegexp(\"fo*o\"));\n+    assertEquals(\"f[^/]*o\\\\.[^/]\", AzureBlobStoreFileSystem.wildcardToRegexp(\"f*o.?\"));\n+    assertEquals(\"foo-[0-9][^/]*\", AzureBlobStoreFileSystem.wildcardToRegexp(\"foo-[0-9]*\"));\n+    assertEquals(\"foo-[0-9].*\", AzureBlobStoreFileSystem.wildcardToRegexp(\"foo-[0-9]**\"));\n+    assertEquals(\".*foo\", AzureBlobStoreFileSystem.wildcardToRegexp(\"**/*foo\"));\n+    assertEquals(\".*foo\", AzureBlobStoreFileSystem.wildcardToRegexp(\"**foo\"));\n+    assertEquals(\"foo/[^/]*\", AzureBlobStoreFileSystem.wildcardToRegexp(\"foo/*\"));\n+    assertEquals(\"foo[^/]*\", AzureBlobStoreFileSystem.wildcardToRegexp(\"foo*\"));\n+    assertEquals(\"foo/[^/]*/[^/]*/[^/]*\", AzureBlobStoreFileSystem.wildcardToRegexp(\"foo/*/*/*\"));\n+    assertEquals(\"foo/[^/]*/.*\", AzureBlobStoreFileSystem.wildcardToRegexp(\"foo/*/**\"));\n+    assertEquals(\"foo.*baz\", AzureBlobStoreFileSystem.wildcardToRegexp(\"foo**baz\"));\n+  }\n+\n+  @Test\n+  @SuppressWarnings(\"CheckReturnValue\")\n+  public void testCopy() throws IOException {\n+    List<AzfsResourceId> src =\n+        new ArrayList<>(\n+            Arrays.asList(AzfsResourceId.fromComponents(\"account\", \"container\", \"from\")));\n+    List<AzfsResourceId> dest =\n+        new ArrayList<>(Arrays.asList(AzfsResourceId.fromComponents(\"account\", \"container\", \"to\")));\n+    when(mockedBlobClient.exists()).thenReturn(true);\n+    azureBlobStoreFileSystem.copy(src, dest);\n+    verify(mockedBlobClient, times(1)).copyFromUrl(any(String.class));\n+  }\n+\n+  @Test\n+  public void testWriteAndRead() throws IOException {\n+    azureBlobStoreFileSystem.getClient().createBlobContainer(\"testcontainer\");\n+\n+    byte[] writtenArray = new byte[] {0};\n+    ByteBuffer bb = ByteBuffer.allocate(writtenArray.length);\n+    bb.put(writtenArray);\n+\n+    // First create an object and write data to it\n+    AzfsResourceId path = AzfsResourceId.fromUri(\"azfs://account/testcontainer/foo/bar.txt\");\n+    WritableByteChannel writableByteChannel =\n+        azureBlobStoreFileSystem.create(path, builder().setMimeType(\"application/text\").build());\n+    writableByteChannel.write(bb);\n+    writableByteChannel.close();\n+\n+    // Now read the same object\n+    ByteBuffer bb2 = ByteBuffer.allocate(writtenArray.length);\n+    ReadableByteChannel open = azureBlobStoreFileSystem.open(path);\n+    open.read(bb2);\n+\n+    // And compare the content with the one that was written\n+    byte[] readArray = bb2.array();\n+    assertArrayEquals(readArray, writtenArray);\n+    open.close();\n+  }\n+\n+  @Test\n+  @Ignore\n+  public void testGlobExpansion() throws IOException {\n+    // TODO: Write this test with mocks - see GcsFileSystemTest", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4bc1857b7fab3c8383e4d80d7284333a7165857d"}, "originalPosition": 188}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzQ1ODg1MQ==", "bodyText": "Done: https://issues.apache.org/jira/browse/BEAM-10772", "url": "https://github.com/apache/beam/pull/12581#discussion_r473458851", "createdAt": "2020-08-20T00:08:01Z", "author": {"login": "ettirapp"}, "path": "sdks/java/io/azure/src/test/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystemTest.java", "diffHunk": "@@ -0,0 +1,352 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.azure.blobstore;\n+\n+import static java.util.UUID.randomUUID;\n+import static org.apache.beam.sdk.io.fs.CreateOptions.StandardCreateOptions.builder;\n+import static org.hamcrest.Matchers.contains;\n+import static org.junit.Assert.assertArrayEquals;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertThat;\n+import static org.mockito.ArgumentMatchers.any;\n+import static org.mockito.ArgumentMatchers.anyString;\n+import static org.mockito.Mockito.doAnswer;\n+import static org.mockito.Mockito.times;\n+import static org.mockito.Mockito.verify;\n+import static org.mockito.Mockito.when;\n+\n+import com.azure.core.http.rest.PagedIterable;\n+import com.azure.storage.blob.BlobClient;\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import com.azure.storage.blob.models.BlobItem;\n+import com.azure.storage.blob.models.BlobProperties;\n+import com.azure.storage.blob.models.ListBlobsOptions;\n+import com.azure.storage.blob.specialized.BlobInputStream;\n+import com.azure.storage.blob.specialized.BlobOutputStream;\n+import com.azure.storage.blob.specialized.BlockBlobClient;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.ReadableByteChannel;\n+import java.nio.channels.WritableByteChannel;\n+import java.time.Duration;\n+import java.time.OffsetDateTime;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n+import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.options.PipelineOptionsFactory;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.junit.Before;\n+import org.junit.Ignore;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.JUnit4;\n+import org.mockito.Mockito;\n+\n+@RunWith(JUnit4.class)\n+@SuppressWarnings(\"CannotMockFinalClass\") // Mockito 2 and above can mock final classes\n+public class AzureBlobStoreFileSystemTest {\n+\n+  private static AzureBlobStoreFileSystem azureBlobStoreFileSystem;\n+  BlobstoreOptions options = PipelineOptionsFactory.as(BlobstoreOptions.class);\n+  BlobstoreOptions spyOptions = Mockito.spy(options);\n+  BlobServiceClient mockedServiceClient = Mockito.mock(BlobServiceClient.class);\n+  BlobContainerClient mockedContainerClient = Mockito.mock(BlobContainerClient.class);\n+  BlobClient mockedBlobClient = Mockito.mock(BlobClient.class);\n+  BlockBlobClient mockedBlockBlob = Mockito.mock(BlockBlobClient.class);\n+  BlobProperties mockedProperties = Mockito.mock(BlobProperties.class);\n+  PagedIterable<BlobItem> mockedPagedIterable = Mockito.mock(PagedIterable.class);\n+  BlobOutputStream mockedOutputStream = Mockito.mock(BlobOutputStream.class);\n+  BlobItem mockedBlobItem = Mockito.mock(BlobItem.class);\n+  BlobInputStream mockedInputStream = Mockito.mock(BlobInputStream.class);\n+\n+  @Before\n+  public void beforeClass() {\n+    azureBlobStoreFileSystem = new AzureBlobStoreFileSystem(spyOptions);\n+    azureBlobStoreFileSystem.setClient(mockedServiceClient);\n+\n+    boolean[] containerCreated = {false};\n+    when(mockedServiceClient.createBlobContainer(anyString()))\n+        .thenAnswer(\n+            (invocation) -> {\n+              containerCreated[0] = true;\n+              return mockedContainerClient;\n+            });\n+    when(mockedContainerClient.exists()).thenAnswer((invocation) -> containerCreated[0]);\n+    boolean[] blobCreated = {false};\n+    doAnswer(\n+            invocation -> {\n+              blobCreated[0] = true;\n+              return null;\n+            })\n+        .when(mockedBlobClient)\n+        .uploadFromFile(anyString());\n+    when(mockedBlobClient.exists()).thenAnswer((invocation) -> blobCreated[0]);\n+    when(azureBlobStoreFileSystem.getClient().getBlobContainerClient(anyString()))\n+        .thenReturn(mockedContainerClient);\n+    when(mockedContainerClient.getBlobClient(anyString())).thenReturn(mockedBlobClient);\n+    when(mockedBlobClient.getBlockBlobClient()).thenReturn(mockedBlockBlob);\n+    when(mockedBlobClient.getProperties()).thenReturn(mockedProperties);\n+    when(mockedProperties.getBlobSize()).thenReturn(Long.valueOf(1));\n+    when(mockedProperties.getLastModified()).thenReturn(OffsetDateTime.now());\n+    when(mockedContainerClient.listBlobs(any(ListBlobsOptions.class), any(Duration.class)))\n+        .thenReturn(mockedPagedIterable);\n+    when(mockedContainerClient.listBlobsByHierarchy(any(String.class)))\n+        .thenReturn(mockedPagedIterable);\n+    when(mockedBlockBlob.getBlobOutputStream())\n+        .thenAnswer(\n+            (i) -> {\n+              blobCreated[0] = true;\n+              return mockedOutputStream;\n+            });\n+    when(mockedBlobItem.getName()).thenReturn(\"name\");\n+    when(spyOptions.getSasToken()).thenReturn(\"sas-token\");\n+    when(mockedBlobClient.openInputStream()).thenReturn(mockedInputStream);\n+  }\n+\n+  @Test\n+  public void testGetScheme() {\n+    assertEquals(\"azfs\", azureBlobStoreFileSystem.getScheme());\n+  }\n+\n+  @Test\n+  public void testGlobTranslation() {\n+    assertEquals(\"foo\", AzureBlobStoreFileSystem.wildcardToRegexp(\"foo\"));\n+    assertEquals(\"fo[^/]*o\", AzureBlobStoreFileSystem.wildcardToRegexp(\"fo*o\"));\n+    assertEquals(\"f[^/]*o\\\\.[^/]\", AzureBlobStoreFileSystem.wildcardToRegexp(\"f*o.?\"));\n+    assertEquals(\"foo-[0-9][^/]*\", AzureBlobStoreFileSystem.wildcardToRegexp(\"foo-[0-9]*\"));\n+    assertEquals(\"foo-[0-9].*\", AzureBlobStoreFileSystem.wildcardToRegexp(\"foo-[0-9]**\"));\n+    assertEquals(\".*foo\", AzureBlobStoreFileSystem.wildcardToRegexp(\"**/*foo\"));\n+    assertEquals(\".*foo\", AzureBlobStoreFileSystem.wildcardToRegexp(\"**foo\"));\n+    assertEquals(\"foo/[^/]*\", AzureBlobStoreFileSystem.wildcardToRegexp(\"foo/*\"));\n+    assertEquals(\"foo[^/]*\", AzureBlobStoreFileSystem.wildcardToRegexp(\"foo*\"));\n+    assertEquals(\"foo/[^/]*/[^/]*/[^/]*\", AzureBlobStoreFileSystem.wildcardToRegexp(\"foo/*/*/*\"));\n+    assertEquals(\"foo/[^/]*/.*\", AzureBlobStoreFileSystem.wildcardToRegexp(\"foo/*/**\"));\n+    assertEquals(\"foo.*baz\", AzureBlobStoreFileSystem.wildcardToRegexp(\"foo**baz\"));\n+  }\n+\n+  @Test\n+  @SuppressWarnings(\"CheckReturnValue\")\n+  public void testCopy() throws IOException {\n+    List<AzfsResourceId> src =\n+        new ArrayList<>(\n+            Arrays.asList(AzfsResourceId.fromComponents(\"account\", \"container\", \"from\")));\n+    List<AzfsResourceId> dest =\n+        new ArrayList<>(Arrays.asList(AzfsResourceId.fromComponents(\"account\", \"container\", \"to\")));\n+    when(mockedBlobClient.exists()).thenReturn(true);\n+    azureBlobStoreFileSystem.copy(src, dest);\n+    verify(mockedBlobClient, times(1)).copyFromUrl(any(String.class));\n+  }\n+\n+  @Test\n+  public void testWriteAndRead() throws IOException {\n+    azureBlobStoreFileSystem.getClient().createBlobContainer(\"testcontainer\");\n+\n+    byte[] writtenArray = new byte[] {0};\n+    ByteBuffer bb = ByteBuffer.allocate(writtenArray.length);\n+    bb.put(writtenArray);\n+\n+    // First create an object and write data to it\n+    AzfsResourceId path = AzfsResourceId.fromUri(\"azfs://account/testcontainer/foo/bar.txt\");\n+    WritableByteChannel writableByteChannel =\n+        azureBlobStoreFileSystem.create(path, builder().setMimeType(\"application/text\").build());\n+    writableByteChannel.write(bb);\n+    writableByteChannel.close();\n+\n+    // Now read the same object\n+    ByteBuffer bb2 = ByteBuffer.allocate(writtenArray.length);\n+    ReadableByteChannel open = azureBlobStoreFileSystem.open(path);\n+    open.read(bb2);\n+\n+    // And compare the content with the one that was written\n+    byte[] readArray = bb2.array();\n+    assertArrayEquals(readArray, writtenArray);\n+    open.close();\n+  }\n+\n+  @Test\n+  @Ignore\n+  public void testGlobExpansion() throws IOException {\n+    // TODO: Write this test with mocks - see GcsFileSystemTest", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzQ1NDI3Mw=="}, "originalCommit": {"oid": "4bc1857b7fab3c8383e4d80d7284333a7165857d"}, "originalPosition": 188}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk1OTk5MjU1OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/azure/src/test/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystemIT.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQwMzoxNjozOFrOHDn_ng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQwNTo1OTo1NVrOHDr2ng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzU2MzAzOA==", "bodyText": "I don't think this test suite is necessary for IT since test cases here should be covered by the unit tests already. I would image the IT we want is a a pipeline reading from azure file system and writing to azure file system. @pabloem what do you think?", "url": "https://github.com/apache/beam/pull/12581#discussion_r473563038", "createdAt": "2020-08-20T03:16:38Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/azure/src/test/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystemIT.java", "diffHunk": "@@ -0,0 +1,353 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.azure.blobstore;\n+\n+import static java.util.UUID.randomUUID;\n+import static org.apache.beam.sdk.io.fs.CreateOptions.StandardCreateOptions.builder;\n+import static org.hamcrest.Matchers.contains;\n+import static org.junit.Assert.assertArrayEquals;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertThat;\n+import static org.junit.Assert.assertThrows;\n+import static org.junit.Assert.assertTrue;\n+\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import java.io.File;\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.ReadableByteChannel;\n+import java.nio.channels.WritableByteChannel;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n+import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.options.PipelineOptionsFactory;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.commons.io.FileUtils;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.JUnit4;\n+\n+@RunWith(JUnit4.class)\n+public class AzureBlobStoreFileSystemIT {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4bc1857b7fab3c8383e4d80d7284333a7165857d"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzU2NDg1Mw==", "bodyText": "Yes, the integration tests are a work in progress.  I put these tests here in case I ended up needing any of them later, but I can move them out of this PR since they aren't being used now.  Thanks for reviewing everything!", "url": "https://github.com/apache/beam/pull/12581#discussion_r473564853", "createdAt": "2020-08-20T03:24:12Z", "author": {"login": "ettirapp"}, "path": "sdks/java/io/azure/src/test/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystemIT.java", "diffHunk": "@@ -0,0 +1,353 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.azure.blobstore;\n+\n+import static java.util.UUID.randomUUID;\n+import static org.apache.beam.sdk.io.fs.CreateOptions.StandardCreateOptions.builder;\n+import static org.hamcrest.Matchers.contains;\n+import static org.junit.Assert.assertArrayEquals;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertThat;\n+import static org.junit.Assert.assertThrows;\n+import static org.junit.Assert.assertTrue;\n+\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import java.io.File;\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.ReadableByteChannel;\n+import java.nio.channels.WritableByteChannel;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n+import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.options.PipelineOptionsFactory;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.commons.io.FileUtils;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.JUnit4;\n+\n+@RunWith(JUnit4.class)\n+public class AzureBlobStoreFileSystemIT {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzU2MzAzOA=="}, "originalCommit": {"oid": "4bc1857b7fab3c8383e4d80d7284333a7165857d"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzYyNjI3MA==", "bodyText": "I agree. We only need a configuration in a build.gradle file that runs WordCount from an azfs:// file.", "url": "https://github.com/apache/beam/pull/12581#discussion_r473626270", "createdAt": "2020-08-20T05:59:55Z", "author": {"login": "pabloem"}, "path": "sdks/java/io/azure/src/test/java/org/apache/beam/sdk/io/azure/blobstore/AzureBlobStoreFileSystemIT.java", "diffHunk": "@@ -0,0 +1,353 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.azure.blobstore;\n+\n+import static java.util.UUID.randomUUID;\n+import static org.apache.beam.sdk.io.fs.CreateOptions.StandardCreateOptions.builder;\n+import static org.hamcrest.Matchers.contains;\n+import static org.junit.Assert.assertArrayEquals;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertThat;\n+import static org.junit.Assert.assertThrows;\n+import static org.junit.Assert.assertTrue;\n+\n+import com.azure.storage.blob.BlobContainerClient;\n+import com.azure.storage.blob.BlobServiceClient;\n+import java.io.File;\n+import java.io.FileNotFoundException;\n+import java.io.IOException;\n+import java.nio.ByteBuffer;\n+import java.nio.channels.ReadableByteChannel;\n+import java.nio.channels.WritableByteChannel;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.List;\n+import org.apache.beam.sdk.io.azure.options.BlobstoreOptions;\n+import org.apache.beam.sdk.io.fs.MatchResult;\n+import org.apache.beam.sdk.options.PipelineOptionsFactory;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.FluentIterable;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.commons.io.FileUtils;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.JUnit4;\n+\n+@RunWith(JUnit4.class)\n+public class AzureBlobStoreFileSystemIT {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzU2MzAzOA=="}, "originalCommit": {"oid": "4bc1857b7fab3c8383e4d80d7284333a7165857d"}, "originalPosition": 53}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 703, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}