{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDk1ODY1MzY0", "number": 12982, "title": "[BEAM-9547] Dataframe covariance and correlation.", "bodyText": "This implements correlation, covariance, and standard deviation for series and dataframes.\nIt is split up into three commits. The first is the math-heavy one that implements the distributed algorithm, the second uses it everywhere, and the third adds an apply method to scalars to simplify things.\n\nThank you for your contribution! Follow this checklist to help us incorporate your contribution quickly and easily:\n\n Choose reviewer(s) and mention them in a comment (R: @username).\n Format the pull request title like [BEAM-XXX] Fixes bug in ApproximateQuantiles, where you replace BEAM-XXX with the appropriate JIRA issue, if applicable. This will automatically link the pull request to the issue.\n Update CHANGES.md with noteworthy changes.\n If this contribution is large, please file an Apache Individual Contributor License Agreement.\n\nSee the Contributor Guide for more tips on how to make review process smoother.\nPost-Commit Tests Status (on master branch)\n\n\n\nLang\nSDK\nDataflow\nFlink\nSamza\nSpark\nTwister2\n\n\n\n\nGo\n\n---\n\n---\n\n---\n\n\nJava\n\n\n\n\n\n\n\n\nPython\n\n\n\n---\n\n---\n\n\nXLang\n\n---\n\n---\n\n---\n\n\n\nPre-Commit Tests Status (on master branch)\n\n\n\n---\nJava\nPython\nGo\nWebsite\nWhitespace\nTypescript\n\n\n\n\nNon-portable\n\n \n\n\n\n\n\n\nPortable\n---\n\n---\n---\n---\n---\n\n\n\nSee .test-infra/jenkins/README for trigger phrase, status and link of all Jenkins jobs.\nGitHub Actions Tests Status (on master branch)\n\n\n\nSee CI.md for more information about GitHub Actions CI.", "createdAt": "2020-10-01T00:02:25Z", "url": "https://github.com/apache/beam/pull/12982", "merged": true, "mergeCommit": {"oid": "0c62087de5e8dd3075f6604508fc54fb3ee4b705"}, "closed": true, "closedAt": "2020-10-12T16:51:21Z", "author": {"login": "robertwb"}, "timelineItems": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdQVXn7AFqTUwNDI2ODMyNg==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdQ_G34gBqjM4NjIxMTcyMDQ=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA0MjY4MzI2", "url": "https://github.com/apache/beam/pull/12982#pullrequestreview-504268326", "createdAt": "2020-10-07T21:08:00Z", "commit": {"oid": "322b4ce3a4c2909e673704aebbe0aa964efaf417"}, "state": "APPROVED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QyMTowODowMFrOHeFlTw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QyMzoxMDo0OVrOHeIpRQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTMxMDc5OQ==", "bodyText": "nit: consider defining a variable for delta to make this easier to relate to the formula in https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Parallel_algorithm", "url": "https://github.com/apache/beam/pull/12982#discussion_r501310799", "createdAt": "2020-10-07T21:08:00Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/frames.py", "diffHunk": "@@ -34,6 +36,124 @@ def __array__(self, dtype=None):\n \n   between = frame_base._elementwise_method('between')\n \n+  @frame_base.args_to_kwargs(pd.Series)\n+  @frame_base.populate_defaults(pd.Series)\n+  def std(self, axis, skipna, level, ddof, **kwargs):\n+    if level is not None:\n+      raise NotImplementedError(\"per-level aggregation\")\n+    if skipna:\n+      self = self.dropna()\n+\n+    # See the online, numerically stable formulae at\n+    # https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance\n+    def compute_moments(x):\n+      n = len(x)\n+      m = x.std(ddof=0)**2 * n\n+      s = x.sum()\n+      return pd.DataFrame(dict(m=[m], s=[s], n=[n]))\n+\n+    def combine_moments(data):\n+      m = s = n = 0.0\n+      for datum in data.itertuples():\n+        if datum.n == 0:\n+          continue\n+        elif n == 0:\n+          m, s, n = datum.m, datum.s, datum.n\n+        else:\n+          m += datum.m + (s / n - datum.s / datum.n)**2 * n * datum.n / (", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "322b4ce3a4c2909e673704aebbe0aa964efaf417"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTMxNTMyNA==", "bodyText": "Can this link directly to https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Parallel_algorithm and/or https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Welford's_online_algorithm?", "url": "https://github.com/apache/beam/pull/12982#discussion_r501315324", "createdAt": "2020-10-07T21:17:20Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/frames.py", "diffHunk": "@@ -34,6 +36,124 @@ def __array__(self, dtype=None):\n \n   between = frame_base._elementwise_method('between')\n \n+  @frame_base.args_to_kwargs(pd.Series)\n+  @frame_base.populate_defaults(pd.Series)\n+  def std(self, axis, skipna, level, ddof, **kwargs):\n+    if level is not None:\n+      raise NotImplementedError(\"per-level aggregation\")\n+    if skipna:\n+      self = self.dropna()\n+\n+    # See the online, numerically stable formulae at\n+    # https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "322b4ce3a4c2909e673704aebbe0aa964efaf417"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTMyMTgzNA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                          other: df.corr(other, method=method, DataFrame=min_periods)[\n          \n          \n            \n                          other: df.corr(other, method=method, min_periods=min_periods)[", "url": "https://github.com/apache/beam/pull/12982#discussion_r501321834", "createdAt": "2020-10-07T21:31:27Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/frames.py", "diffHunk": "@@ -34,6 +36,124 @@ def __array__(self, dtype=None):\n \n   between = frame_base._elementwise_method('between')\n \n+  @frame_base.args_to_kwargs(pd.Series)\n+  @frame_base.populate_defaults(pd.Series)\n+  def std(self, axis, skipna, level, ddof, **kwargs):\n+    if level is not None:\n+      raise NotImplementedError(\"per-level aggregation\")\n+    if skipna:\n+      self = self.dropna()\n+\n+    # See the online, numerically stable formulae at\n+    # https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance\n+    def compute_moments(x):\n+      n = len(x)\n+      m = x.std(ddof=0)**2 * n\n+      s = x.sum()\n+      return pd.DataFrame(dict(m=[m], s=[s], n=[n]))\n+\n+    def combine_moments(data):\n+      m = s = n = 0.0\n+      for datum in data.itertuples():\n+        if datum.n == 0:\n+          continue\n+        elif n == 0:\n+          m, s, n = datum.m, datum.s, datum.n\n+        else:\n+          m += datum.m + (s / n - datum.s / datum.n)**2 * n * datum.n / (\n+              n + datum.n)\n+          s += datum.s\n+          n += datum.n\n+      if n <= ddof:\n+        return float('nan')\n+      else:\n+        return math.sqrt(m / (n - ddof))\n+\n+    moments = expressions.ComputedExpression(\n+        'compute_moments',\n+        compute_moments, [self._expr],\n+        requires_partition_by=partitionings.Nothing())\n+    with expressions.allow_non_parallel_operations(True):\n+      return frame_base.DeferredFrame.wrap(\n+          expressions.ComputedExpression(\n+              'combine_moments',\n+              combine_moments, [moments],\n+              requires_partition_by=partitionings.Singleton()))\n+\n+  @frame_base.args_to_kwargs(pd.Series)\n+  @frame_base.populate_defaults(pd.Series)\n+  def corr(self, other, method, min_periods):\n+    if method == 'pearson':  # Note that this is the default.\n+      x = self.dropna()\n+      y = other.dropna()\n+\n+      # Do this first to filter to the entries that are present on both sides.\n+      def join(x, y):\n+        return pd.concat([x, y], axis=1, join='inner').rename(\n+            lambda c: 'xy'[c], axis=1)\n+\n+      # Use the formulae from\n+      # https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Covariance\n+      def compute_co_moments(x, y):\n+        n = len(x)\n+        if n <= 1:\n+          c = 0\n+        else:\n+          c = x.corr(y) * x.std() * y.std() * (n - 1)\n+        sx = x.sum()\n+        sy = y.sum()\n+        return pd.DataFrame(dict(c=[c], sx=[sx], sy=[sy], n=[n]))\n+\n+      def combine_co_moments(data, std_x, std_y):\n+        c = sx = sy = n = 0.0\n+        for datum in data.itertuples():\n+          if datum.n == 0:\n+            continue\n+          elif n == 0:\n+            c, sx, sy, n = datum.c, datum.sx, datum.sy, datum.n\n+          else:\n+            c += (\n+                datum.c + (sx / n - datum.sx / datum.n) *\n+                (sy / n - datum.sy / datum.n) * n * datum.n / (n + datum.n))\n+            sx += datum.sx\n+            sy += datum.sy\n+            n += datum.n\n+        if n < max(2, min_periods or 0):\n+          return float('nan')\n+        else:\n+          return c / (n - 1) / std_x / std_y\n+\n+      joined = frame_base.DeferredFrame.wrap(\n+          expressions.ComputedExpression(\n+              'join',\n+              join, [x._expr, y._expr],\n+              requires_partition_by=partitionings.Index()))\n+      std_x = joined.x.std()\n+      std_y = joined.y.std()\n+\n+      moments = expressions.ComputedExpression(\n+          'compute_co_moments',\n+          compute_co_moments, [joined.x._expr, joined.y._expr])\n+\n+      with expressions.allow_non_parallel_operations(True):\n+        return frame_base.DeferredFrame.wrap(\n+            expressions.ComputedExpression(\n+                'comnine_co_moments',\n+                combine_co_moments, [moments, std_x._expr, std_y._expr],\n+                requires_partition_by=partitionings.Singleton()))\n+\n+    else:\n+      # The rank-based correlations are not obviously parallelizable, though\n+      # perhaps an approximation could be done with a knowledge of quantiles\n+      # and custom partitioning.\n+      return frame_base.DeferredFrame.wrap(\n+          expressions.ComputedExpression(\n+              'corr',\n+              lambda df,\n+              other: df.corr(other, method=method, DataFrame=min_periods)[", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "322b4ce3a4c2909e673704aebbe0aa964efaf417"}, "originalPosition": 127}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTMzNTI3MA==", "bodyText": "It would help to be more specific here, I spent a while trying to find references. It looks like combine_co_moments  is the formula for combining covariance from two sets hidden at the bottom of the Online Covariance section.\nThe other critical piece is the translation between co-moment and pearson correlation coefficient. Is there something we can reference for that? It seems to follow from the last definition here. IIUC the co-moment is the numerator in that definition, and that fits with your code.", "url": "https://github.com/apache/beam/pull/12982#discussion_r501335270", "createdAt": "2020-10-07T22:02:17Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/frames.py", "diffHunk": "@@ -34,6 +36,124 @@ def __array__(self, dtype=None):\n \n   between = frame_base._elementwise_method('between')\n \n+  @frame_base.args_to_kwargs(pd.Series)\n+  @frame_base.populate_defaults(pd.Series)\n+  def std(self, axis, skipna, level, ddof, **kwargs):\n+    if level is not None:\n+      raise NotImplementedError(\"per-level aggregation\")\n+    if skipna:\n+      self = self.dropna()\n+\n+    # See the online, numerically stable formulae at\n+    # https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance\n+    def compute_moments(x):\n+      n = len(x)\n+      m = x.std(ddof=0)**2 * n\n+      s = x.sum()\n+      return pd.DataFrame(dict(m=[m], s=[s], n=[n]))\n+\n+    def combine_moments(data):\n+      m = s = n = 0.0\n+      for datum in data.itertuples():\n+        if datum.n == 0:\n+          continue\n+        elif n == 0:\n+          m, s, n = datum.m, datum.s, datum.n\n+        else:\n+          m += datum.m + (s / n - datum.s / datum.n)**2 * n * datum.n / (\n+              n + datum.n)\n+          s += datum.s\n+          n += datum.n\n+      if n <= ddof:\n+        return float('nan')\n+      else:\n+        return math.sqrt(m / (n - ddof))\n+\n+    moments = expressions.ComputedExpression(\n+        'compute_moments',\n+        compute_moments, [self._expr],\n+        requires_partition_by=partitionings.Nothing())\n+    with expressions.allow_non_parallel_operations(True):\n+      return frame_base.DeferredFrame.wrap(\n+          expressions.ComputedExpression(\n+              'combine_moments',\n+              combine_moments, [moments],\n+              requires_partition_by=partitionings.Singleton()))\n+\n+  @frame_base.args_to_kwargs(pd.Series)\n+  @frame_base.populate_defaults(pd.Series)\n+  def corr(self, other, method, min_periods):\n+    if method == 'pearson':  # Note that this is the default.\n+      x = self.dropna()\n+      y = other.dropna()\n+\n+      # Do this first to filter to the entries that are present on both sides.\n+      def join(x, y):\n+        return pd.concat([x, y], axis=1, join='inner').rename(\n+            lambda c: 'xy'[c], axis=1)\n+\n+      # Use the formulae from", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "322b4ce3a4c2909e673704aebbe0aa964efaf417"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTM0ODUxNA==", "bodyText": "Nevermind looks like you corrected this later", "url": "https://github.com/apache/beam/pull/12982#discussion_r501348514", "createdAt": "2020-10-07T22:35:30Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/frames.py", "diffHunk": "@@ -34,6 +36,124 @@ def __array__(self, dtype=None):\n \n   between = frame_base._elementwise_method('between')\n \n+  @frame_base.args_to_kwargs(pd.Series)\n+  @frame_base.populate_defaults(pd.Series)\n+  def std(self, axis, skipna, level, ddof, **kwargs):\n+    if level is not None:\n+      raise NotImplementedError(\"per-level aggregation\")\n+    if skipna:\n+      self = self.dropna()\n+\n+    # See the online, numerically stable formulae at\n+    # https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance\n+    def compute_moments(x):\n+      n = len(x)\n+      m = x.std(ddof=0)**2 * n\n+      s = x.sum()\n+      return pd.DataFrame(dict(m=[m], s=[s], n=[n]))\n+\n+    def combine_moments(data):\n+      m = s = n = 0.0\n+      for datum in data.itertuples():\n+        if datum.n == 0:\n+          continue\n+        elif n == 0:\n+          m, s, n = datum.m, datum.s, datum.n\n+        else:\n+          m += datum.m + (s / n - datum.s / datum.n)**2 * n * datum.n / (\n+              n + datum.n)\n+          s += datum.s\n+          n += datum.n\n+      if n <= ddof:\n+        return float('nan')\n+      else:\n+        return math.sqrt(m / (n - ddof))\n+\n+    moments = expressions.ComputedExpression(\n+        'compute_moments',\n+        compute_moments, [self._expr],\n+        requires_partition_by=partitionings.Nothing())\n+    with expressions.allow_non_parallel_operations(True):\n+      return frame_base.DeferredFrame.wrap(\n+          expressions.ComputedExpression(\n+              'combine_moments',\n+              combine_moments, [moments],\n+              requires_partition_by=partitionings.Singleton()))\n+\n+  @frame_base.args_to_kwargs(pd.Series)\n+  @frame_base.populate_defaults(pd.Series)\n+  def corr(self, other, method, min_periods):\n+    if method == 'pearson':  # Note that this is the default.\n+      x = self.dropna()\n+      y = other.dropna()\n+\n+      # Do this first to filter to the entries that are present on both sides.\n+      def join(x, y):\n+        return pd.concat([x, y], axis=1, join='inner').rename(\n+            lambda c: 'xy'[c], axis=1)\n+\n+      # Use the formulae from\n+      # https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Covariance\n+      def compute_co_moments(x, y):\n+        n = len(x)\n+        if n <= 1:\n+          c = 0\n+        else:\n+          c = x.corr(y) * x.std() * y.std() * (n - 1)\n+        sx = x.sum()\n+        sy = y.sum()\n+        return pd.DataFrame(dict(c=[c], sx=[sx], sy=[sy], n=[n]))\n+\n+      def combine_co_moments(data, std_x, std_y):\n+        c = sx = sy = n = 0.0\n+        for datum in data.itertuples():\n+          if datum.n == 0:\n+            continue\n+          elif n == 0:\n+            c, sx, sy, n = datum.c, datum.sx, datum.sy, datum.n\n+          else:\n+            c += (\n+                datum.c + (sx / n - datum.sx / datum.n) *\n+                (sy / n - datum.sy / datum.n) * n * datum.n / (n + datum.n))\n+            sx += datum.sx\n+            sy += datum.sy\n+            n += datum.n\n+        if n < max(2, min_periods or 0):\n+          return float('nan')\n+        else:\n+          return c / (n - 1) / std_x / std_y\n+\n+      joined = frame_base.DeferredFrame.wrap(\n+          expressions.ComputedExpression(\n+              'join',\n+              join, [x._expr, y._expr],\n+              requires_partition_by=partitionings.Index()))\n+      std_x = joined.x.std()\n+      std_y = joined.y.std()\n+\n+      moments = expressions.ComputedExpression(\n+          'compute_co_moments',\n+          compute_co_moments, [joined.x._expr, joined.y._expr])\n+\n+      with expressions.allow_non_parallel_operations(True):\n+        return frame_base.DeferredFrame.wrap(\n+            expressions.ComputedExpression(\n+                'comnine_co_moments',\n+                combine_co_moments, [moments, std_x._expr, std_y._expr],\n+                requires_partition_by=partitionings.Singleton()))\n+\n+    else:\n+      # The rank-based correlations are not obviously parallelizable, though\n+      # perhaps an approximation could be done with a knowledge of quantiles\n+      # and custom partitioning.\n+      return frame_base.DeferredFrame.wrap(\n+          expressions.ComputedExpression(\n+              'corr',\n+              lambda df,\n+              other: df.corr(other, method=method, DataFrame=min_periods)[", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTMyMTgzNA=="}, "originalCommit": {"oid": "322b4ce3a4c2909e673704aebbe0aa964efaf417"}, "originalPosition": 127}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTM1MTAwNw==", "bodyText": "nit: this could become x.cov(y) * (n-1) which makes this more easily relatable to the wiki link", "url": "https://github.com/apache/beam/pull/12982#discussion_r501351007", "createdAt": "2020-10-07T22:42:12Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/frames.py", "diffHunk": "@@ -150,8 +115,72 @@ def combine_co_moments(data, std_x, std_y):\n           expressions.ComputedExpression(\n               'corr',\n               lambda df,\n-              other: df.corr(other, method=method, DataFrame=min_periods)[\n-                  self._expr, other._expr],\n+              other: df.corr(other, method=method, min_periods=min_periods),\n+              [self._expr, other._expr],\n+              requires_partition_by=partitionings.Singleton()))\n+\n+  def _corr_aligned(self, other, method, min_periods):\n+    std_x = self.std()\n+    std_y = other.std()\n+    cov = self._cov_aligned(other, min_periods)\n+    with expressions.allow_non_parallel_operations(True):\n+      return frame_base.DeferredFrame.wrap(\n+          expressions.ComputedExpression(\n+              'normalize',\n+              lambda cov,\n+              std_x,\n+              std_y: cov / (std_x * std_y),\n+              [cov._expr, std_x._expr, std_y._expr],\n+              requires_partition_by=partitionings.Singleton()))\n+\n+  @frame_base.args_to_kwargs(pd.Series)\n+  @frame_base.populate_defaults(pd.Series)\n+  def cov(self, other, min_periods, ddof):\n+    x, y = self.dropna().align(other.dropna(), 'inner')\n+    return x._cov_aligned(y, min_periods, ddof)\n+\n+  def _cov_aligned(self, other, min_periods, ddof=1):\n+    # Use the formulae from\n+    # https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Covariance\n+    def compute_co_moments(x, y):\n+      n = len(x)\n+      if n <= 1:\n+        c = 0\n+      else:\n+        c = x.corr(y) * x.std() * y.std() * (n - 1)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f6ef962ad62f77bda8782b82498e3770bac45fa4"}, "originalPosition": 147}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTM1Mzk5MQ==", "bodyText": "Should this also check against ddof like std?", "url": "https://github.com/apache/beam/pull/12982#discussion_r501353991", "createdAt": "2020-10-07T22:49:56Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/frames.py", "diffHunk": "@@ -150,8 +115,72 @@ def combine_co_moments(data, std_x, std_y):\n           expressions.ComputedExpression(\n               'corr',\n               lambda df,\n-              other: df.corr(other, method=method, DataFrame=min_periods)[\n-                  self._expr, other._expr],\n+              other: df.corr(other, method=method, min_periods=min_periods),\n+              [self._expr, other._expr],\n+              requires_partition_by=partitionings.Singleton()))\n+\n+  def _corr_aligned(self, other, method, min_periods):\n+    std_x = self.std()\n+    std_y = other.std()\n+    cov = self._cov_aligned(other, min_periods)\n+    with expressions.allow_non_parallel_operations(True):\n+      return frame_base.DeferredFrame.wrap(\n+          expressions.ComputedExpression(\n+              'normalize',\n+              lambda cov,\n+              std_x,\n+              std_y: cov / (std_x * std_y),\n+              [cov._expr, std_x._expr, std_y._expr],\n+              requires_partition_by=partitionings.Singleton()))\n+\n+  @frame_base.args_to_kwargs(pd.Series)\n+  @frame_base.populate_defaults(pd.Series)\n+  def cov(self, other, min_periods, ddof):\n+    x, y = self.dropna().align(other.dropna(), 'inner')\n+    return x._cov_aligned(y, min_periods, ddof)\n+\n+  def _cov_aligned(self, other, min_periods, ddof=1):\n+    # Use the formulae from\n+    # https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Covariance\n+    def compute_co_moments(x, y):\n+      n = len(x)\n+      if n <= 1:\n+        c = 0\n+      else:\n+        c = x.corr(y) * x.std() * y.std() * (n - 1)\n+      sx = x.sum()\n+      sy = y.sum()\n+      return pd.DataFrame(dict(c=[c], sx=[sx], sy=[sy], n=[n]))\n+\n+    def combine_co_moments(data):\n+      c = sx = sy = n = 0.0\n+      for datum in data.itertuples():\n+        if datum.n == 0:\n+          continue\n+        elif n == 0:\n+          c, sx, sy, n = datum.c, datum.sx, datum.sy, datum.n\n+        else:\n+          c += (\n+              datum.c + (sx / n - datum.sx / datum.n) *\n+              (sy / n - datum.sy / datum.n) * n * datum.n / (n + datum.n))\n+          sx += datum.sx\n+          sy += datum.sy\n+          n += datum.n\n+      if n < max(2, min_periods or 0):\n+        return float('nan')", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f6ef962ad62f77bda8782b82498e3770bac45fa4"}, "originalPosition": 167}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTM2MDk2NQ==", "bodyText": "Why revert this?", "url": "https://github.com/apache/beam/pull/12982#discussion_r501360965", "createdAt": "2020-10-07T23:10:49Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/frames_test.py", "diffHunk": "@@ -36,7 +36,7 @@ def _run_test(self, func, *args):\n             expressions.ConstantExpression(arg, arg[0:0])) for arg in args\n     ]\n     expected = func(*args)\n-    actual = expressions.PartitioningSession({}).evaluate(\n+    actual = expressions.Session({}).evaluate(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bfa633a581f5efc5097c50f68dd0dac0d91d4449"}, "originalPosition": 5}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8c0ac9b45a4e8f928cc78a3263004b4d6adf9901", "author": {"user": {"login": "robertwb", "name": "Robert Bradshaw"}}, "url": "https://github.com/apache/beam/commit/8c0ac9b45a4e8f928cc78a3263004b4d6adf9901", "committedDate": "2020-10-09T16:20:33Z", "message": "reviewer comments"}, "afterCommit": {"oid": "e5b9a39c78efe8cafcbd6efa084fc27e94308d2d", "author": {"user": {"login": "robertwb", "name": "Robert Bradshaw"}}, "url": "https://github.com/apache/beam/commit/e5b9a39c78efe8cafcbd6efa084fc27e94308d2d", "committedDate": "2020-10-09T18:48:28Z", "message": "Scalar apply method."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "766039917cc43424a1a6f6232caa46e7a19c84b1", "author": {"user": {"login": "robertwb", "name": "Robert Bradshaw"}}, "url": "https://github.com/apache/beam/commit/766039917cc43424a1a6f6232caa46e7a19c84b1", "committedDate": "2020-10-09T23:51:24Z", "message": "[BEAM-9547] Implement covariance and correlation."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c4c61423f4eb2d44067c05c63a7e0def2d16b5c3", "author": {"user": {"login": "robertwb", "name": "Robert Bradshaw"}}, "url": "https://github.com/apache/beam/commit/c4c61423f4eb2d44067c05c63a7e0def2d16b5c3", "committedDate": "2020-10-09T23:51:24Z", "message": "[BEAM-9547] Dataframe covariance and correlation."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "83c90581b226cc1c6ece1aec7ba3c48a3c1a7053", "author": {"user": {"login": "robertwb", "name": "Robert Bradshaw"}}, "url": "https://github.com/apache/beam/commit/83c90581b226cc1c6ece1aec7ba3c48a3c1a7053", "committedDate": "2020-10-09T23:51:24Z", "message": "Scalar apply method."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e5b9a39c78efe8cafcbd6efa084fc27e94308d2d", "author": {"user": {"login": "robertwb", "name": "Robert Bradshaw"}}, "url": "https://github.com/apache/beam/commit/e5b9a39c78efe8cafcbd6efa084fc27e94308d2d", "committedDate": "2020-10-09T18:48:28Z", "message": "Scalar apply method."}, "afterCommit": {"oid": "83c90581b226cc1c6ece1aec7ba3c48a3c1a7053", "author": {"user": {"login": "robertwb", "name": "Robert Bradshaw"}}, "url": "https://github.com/apache/beam/commit/83c90581b226cc1c6ece1aec7ba3c48a3c1a7053", "committedDate": "2020-10-09T23:51:24Z", "message": "Scalar apply method."}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2206, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}