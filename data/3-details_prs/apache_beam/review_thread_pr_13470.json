{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTMxNDc4NDQx", "number": 13470, "reviewThreads": {"totalCount": 20, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQyMzowMDoxOFrOFBA86A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQwMToxMjoyMVrOFF4l8Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM2NjA4NDg4OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/OffsetByteRangeTracker.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQyMzowMDoxOFrOH_lU5g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQwNDozNToyNlrOIC1IDg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQzMzg5NA==", "bodyText": "If lastClaimed == Long.MAX_VALUE, you will get overflow here.", "url": "https://github.com/apache/beam/pull/13470#discussion_r536433894", "createdAt": "2020-12-04T23:00:18Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/OffsetByteRangeTracker.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.proto.ComputeMessageStatsResponse;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker.HasProgress;\n+import org.apache.beam.sdk.transforms.splittabledofn.SplitResult;\n+\n+public class OffsetByteRangeTracker extends RestrictionTracker<OffsetRange, OffsetByteProgress>\n+    implements HasProgress {\n+  private final TopicBacklogReader backlogReader;\n+  private OffsetRange range;\n+  private @Nullable Long lastClaimed;\n+  private long byteCount = 0;\n+\n+  public OffsetByteRangeTracker(OffsetRange range, TopicBacklogReader backlogReader) {\n+    checkArgument(range.getTo() == Long.MAX_VALUE);\n+    this.backlogReader = backlogReader;\n+    this.range = range;\n+  }\n+\n+  @Override\n+  public IsBounded isBounded() {\n+    return IsBounded.UNBOUNDED;\n+  }\n+\n+  @Override\n+  public boolean tryClaim(OffsetByteProgress position) {\n+    long toClaim = position.lastOffset().value();\n+    checkArgument(\n+        lastClaimed == null || toClaim > lastClaimed,\n+        \"Trying to claim offset %s while last attempted was %s\",\n+        position.lastOffset().value(),\n+        lastClaimed);\n+    checkArgument(\n+        toClaim >= range.getFrom(),\n+        \"Trying to claim offset %s before start of the range %s\",\n+        toClaim,\n+        range);\n+    // split() has already been called, truncating this range. No more offsets may be claimed.\n+    if (range.getTo() != Long.MAX_VALUE) {\n+      boolean isRangeEmpty = range.getTo() == range.getFrom();\n+      boolean isValidClosedRange = nextOffset() == range.getTo();\n+      checkState(\n+          isRangeEmpty || isValidClosedRange,\n+          \"Violated class precondition: offset range improperly split. Please report a beam bug.\");\n+      return false;\n+    }\n+    lastClaimed = toClaim;\n+    byteCount += position.batchBytes();\n+    return true;\n+  }\n+\n+  @Override\n+  public OffsetRange currentRestriction() {\n+    return range;\n+  }\n+\n+  private long nextOffset() {\n+    return lastClaimed == null ? currentRestriction().getFrom() : lastClaimed + 1;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4ba623c7fb6cc3935558a861444583496a413cf"}, "originalPosition": 83}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTgzODQ3OA==", "bodyText": "Correct. This doesn't currently handle MAX_VALUE offsets, as there is no reason one would be produced. I've added a \"checkState\" to ensure this doesn't overflow.", "url": "https://github.com/apache/beam/pull/13470#discussion_r539838478", "createdAt": "2020-12-10T04:35:26Z", "author": {"login": "dpcollins-google"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/OffsetByteRangeTracker.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.proto.ComputeMessageStatsResponse;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker.HasProgress;\n+import org.apache.beam.sdk.transforms.splittabledofn.SplitResult;\n+\n+public class OffsetByteRangeTracker extends RestrictionTracker<OffsetRange, OffsetByteProgress>\n+    implements HasProgress {\n+  private final TopicBacklogReader backlogReader;\n+  private OffsetRange range;\n+  private @Nullable Long lastClaimed;\n+  private long byteCount = 0;\n+\n+  public OffsetByteRangeTracker(OffsetRange range, TopicBacklogReader backlogReader) {\n+    checkArgument(range.getTo() == Long.MAX_VALUE);\n+    this.backlogReader = backlogReader;\n+    this.range = range;\n+  }\n+\n+  @Override\n+  public IsBounded isBounded() {\n+    return IsBounded.UNBOUNDED;\n+  }\n+\n+  @Override\n+  public boolean tryClaim(OffsetByteProgress position) {\n+    long toClaim = position.lastOffset().value();\n+    checkArgument(\n+        lastClaimed == null || toClaim > lastClaimed,\n+        \"Trying to claim offset %s while last attempted was %s\",\n+        position.lastOffset().value(),\n+        lastClaimed);\n+    checkArgument(\n+        toClaim >= range.getFrom(),\n+        \"Trying to claim offset %s before start of the range %s\",\n+        toClaim,\n+        range);\n+    // split() has already been called, truncating this range. No more offsets may be claimed.\n+    if (range.getTo() != Long.MAX_VALUE) {\n+      boolean isRangeEmpty = range.getTo() == range.getFrom();\n+      boolean isValidClosedRange = nextOffset() == range.getTo();\n+      checkState(\n+          isRangeEmpty || isValidClosedRange,\n+          \"Violated class precondition: offset range improperly split. Please report a beam bug.\");\n+      return false;\n+    }\n+    lastClaimed = toClaim;\n+    byteCount += position.batchBytes();\n+    return true;\n+  }\n+\n+  @Override\n+  public OffsetRange currentRestriction() {\n+    return range;\n+  }\n+\n+  private long nextOffset() {\n+    return lastClaimed == null ? currentRestriction().getFrom() : lastClaimed + 1;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQzMzg5NA=="}, "originalCommit": {"oid": "e4ba623c7fb6cc3935558a861444583496a413cf"}, "originalPosition": 83}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM2NjA5MjM4OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/OffsetByteRangeTracker.java", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQyMzowMjo1MlrOH_lYtA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQxOTozODoxN1rOIGct8w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQzNDg2OA==", "bodyText": "If something goes wrong before we reaching to checkDone, we will have resource leak on backlogReader.", "url": "https://github.com/apache/beam/pull/13470#discussion_r536434868", "createdAt": "2020-12-04T23:02:52Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/OffsetByteRangeTracker.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.proto.ComputeMessageStatsResponse;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker.HasProgress;\n+import org.apache.beam.sdk.transforms.splittabledofn.SplitResult;\n+\n+public class OffsetByteRangeTracker extends RestrictionTracker<OffsetRange, OffsetByteProgress>\n+    implements HasProgress {\n+  private final TopicBacklogReader backlogReader;\n+  private OffsetRange range;\n+  private @Nullable Long lastClaimed;\n+  private long byteCount = 0;\n+\n+  public OffsetByteRangeTracker(OffsetRange range, TopicBacklogReader backlogReader) {\n+    checkArgument(range.getTo() == Long.MAX_VALUE);\n+    this.backlogReader = backlogReader;\n+    this.range = range;\n+  }\n+\n+  @Override\n+  public IsBounded isBounded() {\n+    return IsBounded.UNBOUNDED;\n+  }\n+\n+  @Override\n+  public boolean tryClaim(OffsetByteProgress position) {\n+    long toClaim = position.lastOffset().value();\n+    checkArgument(\n+        lastClaimed == null || toClaim > lastClaimed,\n+        \"Trying to claim offset %s while last attempted was %s\",\n+        position.lastOffset().value(),\n+        lastClaimed);\n+    checkArgument(\n+        toClaim >= range.getFrom(),\n+        \"Trying to claim offset %s before start of the range %s\",\n+        toClaim,\n+        range);\n+    // split() has already been called, truncating this range. No more offsets may be claimed.\n+    if (range.getTo() != Long.MAX_VALUE) {\n+      boolean isRangeEmpty = range.getTo() == range.getFrom();\n+      boolean isValidClosedRange = nextOffset() == range.getTo();\n+      checkState(\n+          isRangeEmpty || isValidClosedRange,\n+          \"Violated class precondition: offset range improperly split. Please report a beam bug.\");\n+      return false;\n+    }\n+    lastClaimed = toClaim;\n+    byteCount += position.batchBytes();\n+    return true;\n+  }\n+\n+  @Override\n+  public OffsetRange currentRestriction() {\n+    return range;\n+  }\n+\n+  private long nextOffset() {\n+    return lastClaimed == null ? currentRestriction().getFrom() : lastClaimed + 1;\n+  }\n+\n+  @Override\n+  public @Nullable SplitResult<OffsetRange> trySplit(double fractionOfRemainder) {\n+    // Cannot split a bounded range. This should already be completely claimed.\n+    if (range.getTo() != Long.MAX_VALUE) return null;\n+    range = new OffsetRange(currentRestriction().getFrom(), nextOffset());\n+    return SplitResult.of(this.range, new OffsetRange(nextOffset(), Long.MAX_VALUE));\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"unboxing.of.nullable\")\n+  public void checkDone() throws IllegalStateException {\n+    backlogReader.close();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4ba623c7fb6cc3935558a861444583496a413cf"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTUwNjI3NQ==", "bodyText": "Good to know, but it doesn't look like OffsetByteRangeTracker has any lifecycle methods? Where would you suggest this object is cleaned up?", "url": "https://github.com/apache/beam/pull/13470#discussion_r539506275", "createdAt": "2020-12-09T17:33:55Z", "author": {"login": "dpcollins-google"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/OffsetByteRangeTracker.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.proto.ComputeMessageStatsResponse;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker.HasProgress;\n+import org.apache.beam.sdk.transforms.splittabledofn.SplitResult;\n+\n+public class OffsetByteRangeTracker extends RestrictionTracker<OffsetRange, OffsetByteProgress>\n+    implements HasProgress {\n+  private final TopicBacklogReader backlogReader;\n+  private OffsetRange range;\n+  private @Nullable Long lastClaimed;\n+  private long byteCount = 0;\n+\n+  public OffsetByteRangeTracker(OffsetRange range, TopicBacklogReader backlogReader) {\n+    checkArgument(range.getTo() == Long.MAX_VALUE);\n+    this.backlogReader = backlogReader;\n+    this.range = range;\n+  }\n+\n+  @Override\n+  public IsBounded isBounded() {\n+    return IsBounded.UNBOUNDED;\n+  }\n+\n+  @Override\n+  public boolean tryClaim(OffsetByteProgress position) {\n+    long toClaim = position.lastOffset().value();\n+    checkArgument(\n+        lastClaimed == null || toClaim > lastClaimed,\n+        \"Trying to claim offset %s while last attempted was %s\",\n+        position.lastOffset().value(),\n+        lastClaimed);\n+    checkArgument(\n+        toClaim >= range.getFrom(),\n+        \"Trying to claim offset %s before start of the range %s\",\n+        toClaim,\n+        range);\n+    // split() has already been called, truncating this range. No more offsets may be claimed.\n+    if (range.getTo() != Long.MAX_VALUE) {\n+      boolean isRangeEmpty = range.getTo() == range.getFrom();\n+      boolean isValidClosedRange = nextOffset() == range.getTo();\n+      checkState(\n+          isRangeEmpty || isValidClosedRange,\n+          \"Violated class precondition: offset range improperly split. Please report a beam bug.\");\n+      return false;\n+    }\n+    lastClaimed = toClaim;\n+    byteCount += position.batchBytes();\n+    return true;\n+  }\n+\n+  @Override\n+  public OffsetRange currentRestriction() {\n+    return range;\n+  }\n+\n+  private long nextOffset() {\n+    return lastClaimed == null ? currentRestriction().getFrom() : lastClaimed + 1;\n+  }\n+\n+  @Override\n+  public @Nullable SplitResult<OffsetRange> trySplit(double fractionOfRemainder) {\n+    // Cannot split a bounded range. This should already be completely claimed.\n+    if (range.getTo() != Long.MAX_VALUE) return null;\n+    range = new OffsetRange(currentRestriction().getFrom(), nextOffset());\n+    return SplitResult.of(this.range, new OffsetRange(nextOffset(), Long.MAX_VALUE));\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"unboxing.of.nullable\")\n+  public void checkDone() throws IllegalStateException {\n+    backlogReader.close();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQzNDg2OA=="}, "originalCommit": {"oid": "e4ba623c7fb6cc3935558a861444583496a413cf"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTcwNTI5OA==", "bodyText": "You can override Java Object finalize() function to close the reader when GC happens.", "url": "https://github.com/apache/beam/pull/13470#discussion_r539705298", "createdAt": "2020-12-09T22:46:17Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/OffsetByteRangeTracker.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.proto.ComputeMessageStatsResponse;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker.HasProgress;\n+import org.apache.beam.sdk.transforms.splittabledofn.SplitResult;\n+\n+public class OffsetByteRangeTracker extends RestrictionTracker<OffsetRange, OffsetByteProgress>\n+    implements HasProgress {\n+  private final TopicBacklogReader backlogReader;\n+  private OffsetRange range;\n+  private @Nullable Long lastClaimed;\n+  private long byteCount = 0;\n+\n+  public OffsetByteRangeTracker(OffsetRange range, TopicBacklogReader backlogReader) {\n+    checkArgument(range.getTo() == Long.MAX_VALUE);\n+    this.backlogReader = backlogReader;\n+    this.range = range;\n+  }\n+\n+  @Override\n+  public IsBounded isBounded() {\n+    return IsBounded.UNBOUNDED;\n+  }\n+\n+  @Override\n+  public boolean tryClaim(OffsetByteProgress position) {\n+    long toClaim = position.lastOffset().value();\n+    checkArgument(\n+        lastClaimed == null || toClaim > lastClaimed,\n+        \"Trying to claim offset %s while last attempted was %s\",\n+        position.lastOffset().value(),\n+        lastClaimed);\n+    checkArgument(\n+        toClaim >= range.getFrom(),\n+        \"Trying to claim offset %s before start of the range %s\",\n+        toClaim,\n+        range);\n+    // split() has already been called, truncating this range. No more offsets may be claimed.\n+    if (range.getTo() != Long.MAX_VALUE) {\n+      boolean isRangeEmpty = range.getTo() == range.getFrom();\n+      boolean isValidClosedRange = nextOffset() == range.getTo();\n+      checkState(\n+          isRangeEmpty || isValidClosedRange,\n+          \"Violated class precondition: offset range improperly split. Please report a beam bug.\");\n+      return false;\n+    }\n+    lastClaimed = toClaim;\n+    byteCount += position.batchBytes();\n+    return true;\n+  }\n+\n+  @Override\n+  public OffsetRange currentRestriction() {\n+    return range;\n+  }\n+\n+  private long nextOffset() {\n+    return lastClaimed == null ? currentRestriction().getFrom() : lastClaimed + 1;\n+  }\n+\n+  @Override\n+  public @Nullable SplitResult<OffsetRange> trySplit(double fractionOfRemainder) {\n+    // Cannot split a bounded range. This should already be completely claimed.\n+    if (range.getTo() != Long.MAX_VALUE) return null;\n+    range = new OffsetRange(currentRestriction().getFrom(), nextOffset());\n+    return SplitResult.of(this.range, new OffsetRange(nextOffset(), Long.MAX_VALUE));\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"unboxing.of.nullable\")\n+  public void checkDone() throws IllegalStateException {\n+    backlogReader.close();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQzNDg2OA=="}, "originalCommit": {"oid": "e4ba623c7fb6cc3935558a861444583496a413cf"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTg0MDk4MQ==", "bodyText": "You know finalize() is deprecated yes? https://docs.oracle.com/en/java/javase/11/docs/api/java.base/java/lang/Object.html#finalize() It seems like a model deficiency that this object doesn't have a cleanup function (i.e. implementing autocloseable) But I've added this.", "url": "https://github.com/apache/beam/pull/13470#discussion_r539840981", "createdAt": "2020-12-10T04:43:07Z", "author": {"login": "dpcollins-google"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/OffsetByteRangeTracker.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.proto.ComputeMessageStatsResponse;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker.HasProgress;\n+import org.apache.beam.sdk.transforms.splittabledofn.SplitResult;\n+\n+public class OffsetByteRangeTracker extends RestrictionTracker<OffsetRange, OffsetByteProgress>\n+    implements HasProgress {\n+  private final TopicBacklogReader backlogReader;\n+  private OffsetRange range;\n+  private @Nullable Long lastClaimed;\n+  private long byteCount = 0;\n+\n+  public OffsetByteRangeTracker(OffsetRange range, TopicBacklogReader backlogReader) {\n+    checkArgument(range.getTo() == Long.MAX_VALUE);\n+    this.backlogReader = backlogReader;\n+    this.range = range;\n+  }\n+\n+  @Override\n+  public IsBounded isBounded() {\n+    return IsBounded.UNBOUNDED;\n+  }\n+\n+  @Override\n+  public boolean tryClaim(OffsetByteProgress position) {\n+    long toClaim = position.lastOffset().value();\n+    checkArgument(\n+        lastClaimed == null || toClaim > lastClaimed,\n+        \"Trying to claim offset %s while last attempted was %s\",\n+        position.lastOffset().value(),\n+        lastClaimed);\n+    checkArgument(\n+        toClaim >= range.getFrom(),\n+        \"Trying to claim offset %s before start of the range %s\",\n+        toClaim,\n+        range);\n+    // split() has already been called, truncating this range. No more offsets may be claimed.\n+    if (range.getTo() != Long.MAX_VALUE) {\n+      boolean isRangeEmpty = range.getTo() == range.getFrom();\n+      boolean isValidClosedRange = nextOffset() == range.getTo();\n+      checkState(\n+          isRangeEmpty || isValidClosedRange,\n+          \"Violated class precondition: offset range improperly split. Please report a beam bug.\");\n+      return false;\n+    }\n+    lastClaimed = toClaim;\n+    byteCount += position.batchBytes();\n+    return true;\n+  }\n+\n+  @Override\n+  public OffsetRange currentRestriction() {\n+    return range;\n+  }\n+\n+  private long nextOffset() {\n+    return lastClaimed == null ? currentRestriction().getFrom() : lastClaimed + 1;\n+  }\n+\n+  @Override\n+  public @Nullable SplitResult<OffsetRange> trySplit(double fractionOfRemainder) {\n+    // Cannot split a bounded range. This should already be completely claimed.\n+    if (range.getTo() != Long.MAX_VALUE) return null;\n+    range = new OffsetRange(currentRestriction().getFrom(), nextOffset());\n+    return SplitResult.of(this.range, new OffsetRange(nextOffset(), Long.MAX_VALUE));\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"unboxing.of.nullable\")\n+  public void checkDone() throws IllegalStateException {\n+    backlogReader.close();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQzNDg2OA=="}, "originalCommit": {"oid": "e4ba623c7fb6cc3935558a861444583496a413cf"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzYzMjg4Mw==", "bodyText": "You know finalize() is deprecated yes?\nI don't, but good to know.\n\nWe only have lifecycle management on DoFn, thus you should manage the resource of your objects.", "url": "https://github.com/apache/beam/pull/13470#discussion_r543632883", "createdAt": "2020-12-15T19:38:17Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/OffsetByteRangeTracker.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.proto.ComputeMessageStatsResponse;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker.HasProgress;\n+import org.apache.beam.sdk.transforms.splittabledofn.SplitResult;\n+\n+public class OffsetByteRangeTracker extends RestrictionTracker<OffsetRange, OffsetByteProgress>\n+    implements HasProgress {\n+  private final TopicBacklogReader backlogReader;\n+  private OffsetRange range;\n+  private @Nullable Long lastClaimed;\n+  private long byteCount = 0;\n+\n+  public OffsetByteRangeTracker(OffsetRange range, TopicBacklogReader backlogReader) {\n+    checkArgument(range.getTo() == Long.MAX_VALUE);\n+    this.backlogReader = backlogReader;\n+    this.range = range;\n+  }\n+\n+  @Override\n+  public IsBounded isBounded() {\n+    return IsBounded.UNBOUNDED;\n+  }\n+\n+  @Override\n+  public boolean tryClaim(OffsetByteProgress position) {\n+    long toClaim = position.lastOffset().value();\n+    checkArgument(\n+        lastClaimed == null || toClaim > lastClaimed,\n+        \"Trying to claim offset %s while last attempted was %s\",\n+        position.lastOffset().value(),\n+        lastClaimed);\n+    checkArgument(\n+        toClaim >= range.getFrom(),\n+        \"Trying to claim offset %s before start of the range %s\",\n+        toClaim,\n+        range);\n+    // split() has already been called, truncating this range. No more offsets may be claimed.\n+    if (range.getTo() != Long.MAX_VALUE) {\n+      boolean isRangeEmpty = range.getTo() == range.getFrom();\n+      boolean isValidClosedRange = nextOffset() == range.getTo();\n+      checkState(\n+          isRangeEmpty || isValidClosedRange,\n+          \"Violated class precondition: offset range improperly split. Please report a beam bug.\");\n+      return false;\n+    }\n+    lastClaimed = toClaim;\n+    byteCount += position.batchBytes();\n+    return true;\n+  }\n+\n+  @Override\n+  public OffsetRange currentRestriction() {\n+    return range;\n+  }\n+\n+  private long nextOffset() {\n+    return lastClaimed == null ? currentRestriction().getFrom() : lastClaimed + 1;\n+  }\n+\n+  @Override\n+  public @Nullable SplitResult<OffsetRange> trySplit(double fractionOfRemainder) {\n+    // Cannot split a bounded range. This should already be completely claimed.\n+    if (range.getTo() != Long.MAX_VALUE) return null;\n+    range = new OffsetRange(currentRestriction().getFrom(), nextOffset());\n+    return SplitResult.of(this.range, new OffsetRange(nextOffset(), Long.MAX_VALUE));\n+  }\n+\n+  @Override\n+  @SuppressWarnings(\"unboxing.of.nullable\")\n+  public void checkDone() throws IllegalStateException {\n+    backlogReader.close();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQzNDg2OA=="}, "originalCommit": {"oid": "e4ba623c7fb6cc3935558a861444583496a413cf"}, "originalPosition": 97}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM2NjEyMjU0OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/OffsetByteRangeTracker.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQyMzoxNDozM1rOH_lojQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQwNDozNDozOFrOIC1HDw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQzODkyNQ==", "bodyText": "Please add some javadoc to this tracker, especially about the assumption around range.getTo() == Long.MAX_VALUE and you ignore the fractionOfRemainder in trySplit", "url": "https://github.com/apache/beam/pull/13470#discussion_r536438925", "createdAt": "2020-12-04T23:14:33Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/OffsetByteRangeTracker.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.proto.ComputeMessageStatsResponse;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker.HasProgress;\n+import org.apache.beam.sdk.transforms.splittabledofn.SplitResult;\n+\n+public class OffsetByteRangeTracker extends RestrictionTracker<OffsetRange, OffsetByteProgress>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4ba623c7fb6cc3935558a861444583496a413cf"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTgzODIyMw==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/13470#discussion_r539838223", "createdAt": "2020-12-10T04:34:38Z", "author": {"login": "dpcollins-google"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/OffsetByteRangeTracker.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.proto.ComputeMessageStatsResponse;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker.HasProgress;\n+import org.apache.beam.sdk.transforms.splittabledofn.SplitResult;\n+\n+public class OffsetByteRangeTracker extends RestrictionTracker<OffsetRange, OffsetByteProgress>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQzODkyNQ=="}, "originalCommit": {"oid": "e4ba623c7fb6cc3935558a861444583496a413cf"}, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM2NjE0MjQ4OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PerPartitionSdf.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQyMzoyMzoxMVrOH_lzKg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQwNzo1MjoyMFrOIC70Eg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0MTY0Mg==", "bodyText": "I think you may also want to track watermark by implementing watermark related APIs: https://beam.apache.org/documentation/programming-guide/#watermark-estimation", "url": "https://github.com/apache/beam/pull/13470#discussion_r536441642", "createdAt": "2020-12-04T23:23:11Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PerPartitionSdf.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.Partition;\n+import com.google.cloud.pubsublite.internal.PullSubscriber;\n+import com.google.cloud.pubsublite.internal.wire.Committer;\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import com.google.common.flogger.GoogleLogger;\n+import com.google.protobuf.util.Timestamps;\n+import java.util.Collections;\n+import java.util.List;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.SerializableBiFunction;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.util.Sleeper;\n+import org.joda.time.Duration;\n+import org.joda.time.Instant;\n+\n+class PerPartitionSdf extends DoFn<Partition, SequencedMessage> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4ba623c7fb6cc3935558a861444583496a413cf"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTUxMTEyNQ==", "bodyText": "Pub/Sub Lite publish timestamps on a single partition will never go backwards (we haven't published this guarantee, but it is true of the system). If this is true, is the default behavior sufficient?", "url": "https://github.com/apache/beam/pull/13470#discussion_r539511125", "createdAt": "2020-12-09T17:38:35Z", "author": {"login": "dpcollins-google"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PerPartitionSdf.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.Partition;\n+import com.google.cloud.pubsublite.internal.PullSubscriber;\n+import com.google.cloud.pubsublite.internal.wire.Committer;\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import com.google.common.flogger.GoogleLogger;\n+import com.google.protobuf.util.Timestamps;\n+import java.util.Collections;\n+import java.util.List;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.SerializableBiFunction;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.util.Sleeper;\n+import org.joda.time.Duration;\n+import org.joda.time.Instant;\n+\n+class PerPartitionSdf extends DoFn<Partition, SequencedMessage> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0MTY0Mg=="}, "originalCommit": {"oid": "e4ba623c7fb6cc3935558a861444583496a413cf"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTcyMTU1OA==", "bodyText": "In that case, you may want to use MonotonicallyIncreasing one. What you need to do is to implement @ GetInitialWatermarkEstimatorState and  @NewWatermarkEstimator. And you want to use outputWithTimestamp to update the watermark estimator with the timestamp.", "url": "https://github.com/apache/beam/pull/13470#discussion_r539721558", "createdAt": "2020-12-09T23:20:08Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PerPartitionSdf.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.Partition;\n+import com.google.cloud.pubsublite.internal.PullSubscriber;\n+import com.google.cloud.pubsublite.internal.wire.Committer;\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import com.google.common.flogger.GoogleLogger;\n+import com.google.protobuf.util.Timestamps;\n+import java.util.Collections;\n+import java.util.List;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.SerializableBiFunction;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.util.Sleeper;\n+import org.joda.time.Duration;\n+import org.joda.time.Instant;\n+\n+class PerPartitionSdf extends DoFn<Partition, SequencedMessage> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0MTY0Mg=="}, "originalCommit": {"oid": "e4ba623c7fb6cc3935558a861444583496a413cf"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTk0ODA1MA==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/13470#discussion_r539948050", "createdAt": "2020-12-10T07:52:20Z", "author": {"login": "dpcollins-google"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PerPartitionSdf.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.Partition;\n+import com.google.cloud.pubsublite.internal.PullSubscriber;\n+import com.google.cloud.pubsublite.internal.wire.Committer;\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import com.google.common.flogger.GoogleLogger;\n+import com.google.protobuf.util.Timestamps;\n+import java.util.Collections;\n+import java.util.List;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.SerializableBiFunction;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.util.Sleeper;\n+import org.joda.time.Duration;\n+import org.joda.time.Instant;\n+\n+class PerPartitionSdf extends DoFn<Partition, SequencedMessage> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0MTY0Mg=="}, "originalCommit": {"oid": "e4ba623c7fb6cc3935558a861444583496a413cf"}, "originalPosition": 40}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM2NjE2OTkzOnYy", "diffSide": "RIGHT", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/OffsetByteRangeTracker.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQyMzozNToxN1rOH_mBxw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQwNDozNTo0MFrOIC1IZA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0NTM4Mw==", "bodyText": "Please file a JIRA and add a TODO here which talks about the improvement you are going to make.", "url": "https://github.com/apache/beam/pull/13470#discussion_r536445383", "createdAt": "2020-12-04T23:35:17Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/OffsetByteRangeTracker.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.proto.ComputeMessageStatsResponse;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker.HasProgress;\n+import org.apache.beam.sdk.transforms.splittabledofn.SplitResult;\n+\n+public class OffsetByteRangeTracker extends RestrictionTracker<OffsetRange, OffsetByteProgress>\n+    implements HasProgress {\n+  private final TopicBacklogReader backlogReader;\n+  private OffsetRange range;\n+  private @Nullable Long lastClaimed;\n+  private long byteCount = 0;\n+\n+  public OffsetByteRangeTracker(OffsetRange range, TopicBacklogReader backlogReader) {\n+    checkArgument(range.getTo() == Long.MAX_VALUE);\n+    this.backlogReader = backlogReader;\n+    this.range = range;\n+  }\n+\n+  @Override\n+  public IsBounded isBounded() {\n+    return IsBounded.UNBOUNDED;\n+  }\n+\n+  @Override\n+  public boolean tryClaim(OffsetByteProgress position) {\n+    long toClaim = position.lastOffset().value();\n+    checkArgument(\n+        lastClaimed == null || toClaim > lastClaimed,\n+        \"Trying to claim offset %s while last attempted was %s\",\n+        position.lastOffset().value(),\n+        lastClaimed);\n+    checkArgument(\n+        toClaim >= range.getFrom(),\n+        \"Trying to claim offset %s before start of the range %s\",\n+        toClaim,\n+        range);\n+    // split() has already been called, truncating this range. No more offsets may be claimed.\n+    if (range.getTo() != Long.MAX_VALUE) {\n+      boolean isRangeEmpty = range.getTo() == range.getFrom();\n+      boolean isValidClosedRange = nextOffset() == range.getTo();\n+      checkState(\n+          isRangeEmpty || isValidClosedRange,\n+          \"Violated class precondition: offset range improperly split. Please report a beam bug.\");\n+      return false;\n+    }\n+    lastClaimed = toClaim;\n+    byteCount += position.batchBytes();\n+    return true;\n+  }\n+\n+  @Override\n+  public OffsetRange currentRestriction() {\n+    return range;\n+  }\n+\n+  private long nextOffset() {\n+    return lastClaimed == null ? currentRestriction().getFrom() : lastClaimed + 1;\n+  }\n+\n+  @Override\n+  public @Nullable SplitResult<OffsetRange> trySplit(double fractionOfRemainder) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4ba623c7fb6cc3935558a861444583496a413cf"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTUxMTQ1OQ==", "bodyText": "Added a TODO, but since I already have this written a jira seems like overkill.", "url": "https://github.com/apache/beam/pull/13470#discussion_r539511459", "createdAt": "2020-12-09T17:39:05Z", "author": {"login": "dpcollins-google"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/OffsetByteRangeTracker.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.proto.ComputeMessageStatsResponse;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker.HasProgress;\n+import org.apache.beam.sdk.transforms.splittabledofn.SplitResult;\n+\n+public class OffsetByteRangeTracker extends RestrictionTracker<OffsetRange, OffsetByteProgress>\n+    implements HasProgress {\n+  private final TopicBacklogReader backlogReader;\n+  private OffsetRange range;\n+  private @Nullable Long lastClaimed;\n+  private long byteCount = 0;\n+\n+  public OffsetByteRangeTracker(OffsetRange range, TopicBacklogReader backlogReader) {\n+    checkArgument(range.getTo() == Long.MAX_VALUE);\n+    this.backlogReader = backlogReader;\n+    this.range = range;\n+  }\n+\n+  @Override\n+  public IsBounded isBounded() {\n+    return IsBounded.UNBOUNDED;\n+  }\n+\n+  @Override\n+  public boolean tryClaim(OffsetByteProgress position) {\n+    long toClaim = position.lastOffset().value();\n+    checkArgument(\n+        lastClaimed == null || toClaim > lastClaimed,\n+        \"Trying to claim offset %s while last attempted was %s\",\n+        position.lastOffset().value(),\n+        lastClaimed);\n+    checkArgument(\n+        toClaim >= range.getFrom(),\n+        \"Trying to claim offset %s before start of the range %s\",\n+        toClaim,\n+        range);\n+    // split() has already been called, truncating this range. No more offsets may be claimed.\n+    if (range.getTo() != Long.MAX_VALUE) {\n+      boolean isRangeEmpty = range.getTo() == range.getFrom();\n+      boolean isValidClosedRange = nextOffset() == range.getTo();\n+      checkState(\n+          isRangeEmpty || isValidClosedRange,\n+          \"Violated class precondition: offset range improperly split. Please report a beam bug.\");\n+      return false;\n+    }\n+    lastClaimed = toClaim;\n+    byteCount += position.batchBytes();\n+    return true;\n+  }\n+\n+  @Override\n+  public OffsetRange currentRestriction() {\n+    return range;\n+  }\n+\n+  private long nextOffset() {\n+    return lastClaimed == null ? currentRestriction().getFrom() : lastClaimed + 1;\n+  }\n+\n+  @Override\n+  public @Nullable SplitResult<OffsetRange> trySplit(double fractionOfRemainder) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0NTM4Mw=="}, "originalCommit": {"oid": "e4ba623c7fb6cc3935558a861444583496a413cf"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTgzODU2NA==", "bodyText": "Actually just merged this in here.", "url": "https://github.com/apache/beam/pull/13470#discussion_r539838564", "createdAt": "2020-12-10T04:35:40Z", "author": {"login": "dpcollins-google"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/OffsetByteRangeTracker.java", "diffHunk": "@@ -0,0 +1,119 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.proto.ComputeMessageStatsResponse;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker.HasProgress;\n+import org.apache.beam.sdk.transforms.splittabledofn.SplitResult;\n+\n+public class OffsetByteRangeTracker extends RestrictionTracker<OffsetRange, OffsetByteProgress>\n+    implements HasProgress {\n+  private final TopicBacklogReader backlogReader;\n+  private OffsetRange range;\n+  private @Nullable Long lastClaimed;\n+  private long byteCount = 0;\n+\n+  public OffsetByteRangeTracker(OffsetRange range, TopicBacklogReader backlogReader) {\n+    checkArgument(range.getTo() == Long.MAX_VALUE);\n+    this.backlogReader = backlogReader;\n+    this.range = range;\n+  }\n+\n+  @Override\n+  public IsBounded isBounded() {\n+    return IsBounded.UNBOUNDED;\n+  }\n+\n+  @Override\n+  public boolean tryClaim(OffsetByteProgress position) {\n+    long toClaim = position.lastOffset().value();\n+    checkArgument(\n+        lastClaimed == null || toClaim > lastClaimed,\n+        \"Trying to claim offset %s while last attempted was %s\",\n+        position.lastOffset().value(),\n+        lastClaimed);\n+    checkArgument(\n+        toClaim >= range.getFrom(),\n+        \"Trying to claim offset %s before start of the range %s\",\n+        toClaim,\n+        range);\n+    // split() has already been called, truncating this range. No more offsets may be claimed.\n+    if (range.getTo() != Long.MAX_VALUE) {\n+      boolean isRangeEmpty = range.getTo() == range.getFrom();\n+      boolean isValidClosedRange = nextOffset() == range.getTo();\n+      checkState(\n+          isRangeEmpty || isValidClosedRange,\n+          \"Violated class precondition: offset range improperly split. Please report a beam bug.\");\n+      return false;\n+    }\n+    lastClaimed = toClaim;\n+    byteCount += position.batchBytes();\n+    return true;\n+  }\n+\n+  @Override\n+  public OffsetRange currentRestriction() {\n+    return range;\n+  }\n+\n+  private long nextOffset() {\n+    return lastClaimed == null ? currentRestriction().getFrom() : lastClaimed + 1;\n+  }\n+\n+  @Override\n+  public @Nullable SplitResult<OffsetRange> trySplit(double fractionOfRemainder) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0NTM4Mw=="}, "originalCommit": {"oid": "e4ba623c7fb6cc3935558a861444583496a413cf"}, "originalPosition": 87}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM2NjE3ODkwOnYy", "diffSide": "RIGHT", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PerPartitionSdf.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQyMzozOToyNFrOH_mGeA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOVQxNzo0MDowNVrOIChNdg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0NjU4NA==", "bodyText": "I'm wondering how a partition can locate a read, I would image we at least need a topic. Is it plumped through by subscriberFactory  during construction time?", "url": "https://github.com/apache/beam/pull/13470#discussion_r536446584", "createdAt": "2020-12-04T23:39:24Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PerPartitionSdf.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.Partition;\n+import com.google.cloud.pubsublite.internal.PullSubscriber;\n+import com.google.cloud.pubsublite.internal.wire.Committer;\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import com.google.common.flogger.GoogleLogger;\n+import com.google.protobuf.util.Timestamps;\n+import java.util.Collections;\n+import java.util.List;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.SerializableBiFunction;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.util.Sleeper;\n+import org.joda.time.Duration;\n+import org.joda.time.Instant;\n+\n+class PerPartitionSdf extends DoFn<Partition, SequencedMessage> {\n+  private static final GoogleLogger logger = GoogleLogger.forEnclosingClass();\n+  private final Duration maxSleepTime;\n+  private final SerializableBiFunction<Partition, Offset, PullSubscriber<SequencedMessage>>\n+      subscriberFactory;\n+  private final SerializableFunction<Partition, Committer> committerFactory;\n+  private final SerializableSupplier<Sleeper> sleeperSupplier;\n+  private final SerializableFunction<Partition, InitialOffsetReader> offsetReaderFactory;\n+  private final SerializableBiFunction<\n+          Partition, OffsetRange, RestrictionTracker<OffsetRange, OffsetByteProgress>>\n+      trackerFactory;\n+\n+  Duration sleepTimeRemaining;\n+\n+  PerPartitionSdf(\n+      Duration maxSleepTime,\n+      SerializableBiFunction<Partition, Offset, PullSubscriber<SequencedMessage>> subscriberFactory,\n+      SerializableFunction<Partition, Committer> committerFactory,\n+      SerializableSupplier<Sleeper> sleeperSupplier,\n+      SerializableFunction<Partition, InitialOffsetReader> offsetReaderFactory,\n+      SerializableBiFunction<\n+              Partition, OffsetRange, RestrictionTracker<OffsetRange, OffsetByteProgress>>\n+          trackerFactory) {\n+    this.maxSleepTime = maxSleepTime;\n+    this.sleepTimeRemaining = maxSleepTime;\n+    this.subscriberFactory = subscriberFactory;\n+    this.committerFactory = committerFactory;\n+    this.sleeperSupplier = sleeperSupplier;\n+    this.offsetReaderFactory = offsetReaderFactory;\n+    this.trackerFactory = trackerFactory;\n+  }\n+\n+  private List<SequencedMessage> doPoll(PullSubscriber<SequencedMessage> subscriber)\n+      throws Exception {\n+    Sleeper sleeper = sleeperSupplier.get();\n+    while (sleepTimeRemaining.isLongerThan(Duration.ZERO)) {\n+      List<SequencedMessage> messages = subscriber.pull();\n+      if (!messages.isEmpty()) {\n+        return messages;\n+      }\n+      Duration sleepTime =\n+          Collections.min(ImmutableList.of(sleepTimeRemaining, Duration.millis(50)));\n+      sleepTimeRemaining = sleepTimeRemaining.minus(sleepTime);\n+      sleeper.sleep(sleepTime.getMillis());\n+    }\n+    return ImmutableList.of();\n+  }\n+\n+  @ProcessElement\n+  public ProcessContinuation processElement(\n+      RestrictionTracker<OffsetRange, OffsetByteProgress> tracker,\n+      @Element Partition partition,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4ba623c7fb6cc3935558a861444583496a413cf"}, "originalPosition": 91}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTUxMjE4Mg==", "bodyText": "Yes", "url": "https://github.com/apache/beam/pull/13470#discussion_r539512182", "createdAt": "2020-12-09T17:40:05Z", "author": {"login": "dpcollins-google"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PerPartitionSdf.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.Partition;\n+import com.google.cloud.pubsublite.internal.PullSubscriber;\n+import com.google.cloud.pubsublite.internal.wire.Committer;\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import com.google.common.flogger.GoogleLogger;\n+import com.google.protobuf.util.Timestamps;\n+import java.util.Collections;\n+import java.util.List;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.SerializableBiFunction;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.util.Sleeper;\n+import org.joda.time.Duration;\n+import org.joda.time.Instant;\n+\n+class PerPartitionSdf extends DoFn<Partition, SequencedMessage> {\n+  private static final GoogleLogger logger = GoogleLogger.forEnclosingClass();\n+  private final Duration maxSleepTime;\n+  private final SerializableBiFunction<Partition, Offset, PullSubscriber<SequencedMessage>>\n+      subscriberFactory;\n+  private final SerializableFunction<Partition, Committer> committerFactory;\n+  private final SerializableSupplier<Sleeper> sleeperSupplier;\n+  private final SerializableFunction<Partition, InitialOffsetReader> offsetReaderFactory;\n+  private final SerializableBiFunction<\n+          Partition, OffsetRange, RestrictionTracker<OffsetRange, OffsetByteProgress>>\n+      trackerFactory;\n+\n+  Duration sleepTimeRemaining;\n+\n+  PerPartitionSdf(\n+      Duration maxSleepTime,\n+      SerializableBiFunction<Partition, Offset, PullSubscriber<SequencedMessage>> subscriberFactory,\n+      SerializableFunction<Partition, Committer> committerFactory,\n+      SerializableSupplier<Sleeper> sleeperSupplier,\n+      SerializableFunction<Partition, InitialOffsetReader> offsetReaderFactory,\n+      SerializableBiFunction<\n+              Partition, OffsetRange, RestrictionTracker<OffsetRange, OffsetByteProgress>>\n+          trackerFactory) {\n+    this.maxSleepTime = maxSleepTime;\n+    this.sleepTimeRemaining = maxSleepTime;\n+    this.subscriberFactory = subscriberFactory;\n+    this.committerFactory = committerFactory;\n+    this.sleeperSupplier = sleeperSupplier;\n+    this.offsetReaderFactory = offsetReaderFactory;\n+    this.trackerFactory = trackerFactory;\n+  }\n+\n+  private List<SequencedMessage> doPoll(PullSubscriber<SequencedMessage> subscriber)\n+      throws Exception {\n+    Sleeper sleeper = sleeperSupplier.get();\n+    while (sleepTimeRemaining.isLongerThan(Duration.ZERO)) {\n+      List<SequencedMessage> messages = subscriber.pull();\n+      if (!messages.isEmpty()) {\n+        return messages;\n+      }\n+      Duration sleepTime =\n+          Collections.min(ImmutableList.of(sleepTimeRemaining, Duration.millis(50)));\n+      sleepTimeRemaining = sleepTimeRemaining.minus(sleepTime);\n+      sleeper.sleep(sleepTime.getMillis());\n+    }\n+    return ImmutableList.of();\n+  }\n+\n+  @ProcessElement\n+  public ProcessContinuation processElement(\n+      RestrictionTracker<OffsetRange, OffsetByteProgress> tracker,\n+      @Element Partition partition,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ0NjU4NA=="}, "originalCommit": {"oid": "e4ba623c7fb6cc3935558a861444583496a413cf"}, "originalPosition": 91}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM2NjIxNzcwOnYy", "diffSide": "RIGHT", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PubsubLiteIO.java", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQyMzo1Nzo0NFrOH_makg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQxOTo0MzoxMFrOIGc6OQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ1MTczMA==", "bodyText": "It seems like the PubsubLiteIO.read() is for reading one topic(subscription). Do we have a plan to have PubsubLiteIO expose readAll() API to read from multiple topics/subscriptions?", "url": "https://github.com/apache/beam/pull/13470#discussion_r536451730", "createdAt": "2020-12-04T23:57:44Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PubsubLiteIO.java", "diffHunk": "@@ -64,8 +64,8 @@ private PubsubLiteIO() {}\n    *     .build()), \"read\");\n    * }</pre>\n    */\n-  public static Read.Unbounded<SequencedMessage> read(SubscriberOptions options) {\n-    return Read.from(new PubsubLiteUnboundedSource(options));\n+  public static PTransform<PBegin, PCollection<SequencedMessage>> read(SubscriberOptions options) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4ba623c7fb6cc3935558a861444583496a413cf"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTUxNDk1MQ==", "bodyText": "I don't (it adds to the api surface for an uncommon case), but this can be implemented in userland by:\nPCollectionList list = PCollectionList.of();\nfor (SubscriptionPath subscription : subscriptions) {\n  list = list.and(p.apply(PubsubLiteIO.read(SubscriberOptions.newBuilder()\n      .setSubscriptionPath(subscriptionPath)\n      .build()), \"read\"));\n}\nreturn list.apply(Flatten.<SequencedMessage>pCollections())", "url": "https://github.com/apache/beam/pull/13470#discussion_r539514951", "createdAt": "2020-12-09T17:43:55Z", "author": {"login": "dpcollins-google"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PubsubLiteIO.java", "diffHunk": "@@ -64,8 +64,8 @@ private PubsubLiteIO() {}\n    *     .build()), \"read\");\n    * }</pre>\n    */\n-  public static Read.Unbounded<SequencedMessage> read(SubscriberOptions options) {\n-    return Read.from(new PubsubLiteUnboundedSource(options));\n+  public static PTransform<PBegin, PCollection<SequencedMessage>> read(SubscriberOptions options) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ1MTczMA=="}, "originalCommit": {"oid": "e4ba623c7fb6cc3935558a861444583496a413cf"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTczMjM4MQ==", "bodyText": "The main goal for us to build composite transform is to offer end users simple API to do complex work. I would say it's more convenient for pipeline authors to have readAll() API instead of writing more code by their own.", "url": "https://github.com/apache/beam/pull/13470#discussion_r539732381", "createdAt": "2020-12-09T23:43:30Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PubsubLiteIO.java", "diffHunk": "@@ -64,8 +64,8 @@ private PubsubLiteIO() {}\n    *     .build()), \"read\");\n    * }</pre>\n    */\n-  public static Read.Unbounded<SequencedMessage> read(SubscriberOptions options) {\n-    return Read.from(new PubsubLiteUnboundedSource(options));\n+  public static PTransform<PBegin, PCollection<SequencedMessage>> read(SubscriberOptions options) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ1MTczMA=="}, "originalCommit": {"oid": "e4ba623c7fb6cc3935558a861444583496a413cf"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTg0MTc4MQ==", "bodyText": "Yeah I don't agree. Reading from multiple subscriptions to process the same data is a niche use-case: especially given that we try to commit to not only never breaking API but the internal structure to prevent from breaking dataflow refreshing, I think we should keep the API surface as small as possible. Given how niche this is and how easy it is (5 LOC), I see no benefit in adding noise to the API surface of PubsubLiteIO.", "url": "https://github.com/apache/beam/pull/13470#discussion_r539841781", "createdAt": "2020-12-10T04:45:43Z", "author": {"login": "dpcollins-google"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PubsubLiteIO.java", "diffHunk": "@@ -64,8 +64,8 @@ private PubsubLiteIO() {}\n    *     .build()), \"read\");\n    * }</pre>\n    */\n-  public static Read.Unbounded<SequencedMessage> read(SubscriberOptions options) {\n-    return Read.from(new PubsubLiteUnboundedSource(options));\n+  public static PTransform<PBegin, PCollection<SequencedMessage>> read(SubscriberOptions options) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ1MTczMA=="}, "originalCommit": {"oid": "e4ba623c7fb6cc3935558a861444583496a413cf"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzYzNjAyNQ==", "bodyText": "I'll let you know when there is a FR on readAll", "url": "https://github.com/apache/beam/pull/13470#discussion_r543636025", "createdAt": "2020-12-15T19:43:10Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PubsubLiteIO.java", "diffHunk": "@@ -64,8 +64,8 @@ private PubsubLiteIO() {}\n    *     .build()), \"read\");\n    * }</pre>\n    */\n-  public static Read.Unbounded<SequencedMessage> read(SubscriberOptions options) {\n-    return Read.from(new PubsubLiteUnboundedSource(options));\n+  public static PTransform<PBegin, PCollection<SequencedMessage>> read(SubscriberOptions options) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ1MTczMA=="}, "originalCommit": {"oid": "e4ba623c7fb6cc3935558a861444583496a413cf"}, "originalPosition": 17}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM2NjIyNzU0OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/SubscribeTransform.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwMDowMjoxNVrOH_mfeQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQwNzo0MjozMVrOIC7gYA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ1Mjk4NQ==", "bodyText": "I'm thinking about whether it makes sense to have PerPartitionSdf to read from a SubscriberOptions or something that can locate a read(topic + partition + something else). It will also help us to enable readAll() API I mentioned above. Also the PerPartitionSdf will also be able to read from subscriptions/partitions that are created during pipeline execution time.\nOne major feature request for Kafka IO is to read from new added topics/partitions dynamically, which I think PubsubLiteIO might have the similar customer needs.", "url": "https://github.com/apache/beam/pull/13470#discussion_r536452985", "createdAt": "2020-12-05T00:02:15Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/SubscribeTransform.java", "diffHunk": "@@ -0,0 +1,85 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import static com.google.cloud.pubsublite.internal.ExtractStatus.toCanonical;\n+\n+import com.google.api.gax.rpc.ApiException;\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.Partition;\n+import com.google.cloud.pubsublite.internal.BufferingPullSubscriber;\n+import com.google.cloud.pubsublite.internal.PullSubscriber;\n+import com.google.cloud.pubsublite.proto.Cursor;\n+import com.google.cloud.pubsublite.proto.SeekRequest;\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.Reshuffle;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.util.Sleeper;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.joda.time.Duration;\n+\n+class SubscribeTransform extends PTransform<PBegin, PCollection<SequencedMessage>> {\n+  private static final Duration MAX_SLEEP_TIME = Duration.standardMinutes(1);\n+\n+  private final SubscriberOptions options;\n+\n+  SubscribeTransform(SubscriberOptions options) {\n+    this.options = options;\n+  }\n+\n+  private PullSubscriber<SequencedMessage> newPullSubscriber(Partition partition, Offset offset)\n+      throws ApiException {\n+    try {\n+      return new TranslatingPullSubscriber(\n+          new BufferingPullSubscriber(\n+              options.getSubscriberFactory(partition),\n+              options.flowControlSettings(),\n+              SeekRequest.newBuilder()\n+                  .setCursor(Cursor.newBuilder().setOffset(offset.value()))\n+                  .build()));\n+    } catch (Throwable t) {\n+      throw toCanonical(t).underlying;\n+    }\n+  }\n+\n+  private RestrictionTracker<OffsetRange, OffsetByteProgress> newRestrictionTracker(\n+      Partition partition, OffsetRange initial) {\n+    return new OffsetByteRangeTracker(initial, options.getBacklogReader(partition));\n+  }\n+\n+  @Override\n+  public PCollection<SequencedMessage> expand(PBegin input) {\n+    PCollection<Partition> partitions = Create.of(options.partitions()).expand(input);\n+    // Prevent fusion between Create and read.\n+    PCollection<Partition> shuffledPartitions = partitions.apply(Reshuffle.viaRandomKey());\n+    return shuffledPartitions.apply(\n+        ParDo.of(\n+            new PerPartitionSdf(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4ba623c7fb6cc3935558a861444583496a413cf"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTUxNjY1Mg==", "bodyText": "I disagree and thinks this adds complexity without a use case.\nNote that the feature requests I've seen are for adding <partitions> dynamically, not topics, which I will be modifying PubsubLiteIO to support shortly.", "url": "https://github.com/apache/beam/pull/13470#discussion_r539516652", "createdAt": "2020-12-09T17:46:21Z", "author": {"login": "dpcollins-google"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/SubscribeTransform.java", "diffHunk": "@@ -0,0 +1,85 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import static com.google.cloud.pubsublite.internal.ExtractStatus.toCanonical;\n+\n+import com.google.api.gax.rpc.ApiException;\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.Partition;\n+import com.google.cloud.pubsublite.internal.BufferingPullSubscriber;\n+import com.google.cloud.pubsublite.internal.PullSubscriber;\n+import com.google.cloud.pubsublite.proto.Cursor;\n+import com.google.cloud.pubsublite.proto.SeekRequest;\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.Reshuffle;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.util.Sleeper;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.joda.time.Duration;\n+\n+class SubscribeTransform extends PTransform<PBegin, PCollection<SequencedMessage>> {\n+  private static final Duration MAX_SLEEP_TIME = Duration.standardMinutes(1);\n+\n+  private final SubscriberOptions options;\n+\n+  SubscribeTransform(SubscriberOptions options) {\n+    this.options = options;\n+  }\n+\n+  private PullSubscriber<SequencedMessage> newPullSubscriber(Partition partition, Offset offset)\n+      throws ApiException {\n+    try {\n+      return new TranslatingPullSubscriber(\n+          new BufferingPullSubscriber(\n+              options.getSubscriberFactory(partition),\n+              options.flowControlSettings(),\n+              SeekRequest.newBuilder()\n+                  .setCursor(Cursor.newBuilder().setOffset(offset.value()))\n+                  .build()));\n+    } catch (Throwable t) {\n+      throw toCanonical(t).underlying;\n+    }\n+  }\n+\n+  private RestrictionTracker<OffsetRange, OffsetByteProgress> newRestrictionTracker(\n+      Partition partition, OffsetRange initial) {\n+    return new OffsetByteRangeTracker(initial, options.getBacklogReader(partition));\n+  }\n+\n+  @Override\n+  public PCollection<SequencedMessage> expand(PBegin input) {\n+    PCollection<Partition> partitions = Create.of(options.partitions()).expand(input);\n+    // Prevent fusion between Create and read.\n+    PCollection<Partition> shuffledPartitions = partitions.apply(Reshuffle.viaRandomKey());\n+    return shuffledPartitions.apply(\n+        ParDo.of(\n+            new PerPartitionSdf(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ1Mjk4NQ=="}, "originalCommit": {"oid": "e4ba623c7fb6cc3935558a861444583496a413cf"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTk0MzAwOA==", "bodyText": "I've added this, but don't think it is at all useful.", "url": "https://github.com/apache/beam/pull/13470#discussion_r539943008", "createdAt": "2020-12-10T07:42:31Z", "author": {"login": "dpcollins-google"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/SubscribeTransform.java", "diffHunk": "@@ -0,0 +1,85 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import static com.google.cloud.pubsublite.internal.ExtractStatus.toCanonical;\n+\n+import com.google.api.gax.rpc.ApiException;\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.Partition;\n+import com.google.cloud.pubsublite.internal.BufferingPullSubscriber;\n+import com.google.cloud.pubsublite.internal.PullSubscriber;\n+import com.google.cloud.pubsublite.proto.Cursor;\n+import com.google.cloud.pubsublite.proto.SeekRequest;\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.Reshuffle;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.util.Sleeper;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.joda.time.Duration;\n+\n+class SubscribeTransform extends PTransform<PBegin, PCollection<SequencedMessage>> {\n+  private static final Duration MAX_SLEEP_TIME = Duration.standardMinutes(1);\n+\n+  private final SubscriberOptions options;\n+\n+  SubscribeTransform(SubscriberOptions options) {\n+    this.options = options;\n+  }\n+\n+  private PullSubscriber<SequencedMessage> newPullSubscriber(Partition partition, Offset offset)\n+      throws ApiException {\n+    try {\n+      return new TranslatingPullSubscriber(\n+          new BufferingPullSubscriber(\n+              options.getSubscriberFactory(partition),\n+              options.flowControlSettings(),\n+              SeekRequest.newBuilder()\n+                  .setCursor(Cursor.newBuilder().setOffset(offset.value()))\n+                  .build()));\n+    } catch (Throwable t) {\n+      throw toCanonical(t).underlying;\n+    }\n+  }\n+\n+  private RestrictionTracker<OffsetRange, OffsetByteProgress> newRestrictionTracker(\n+      Partition partition, OffsetRange initial) {\n+    return new OffsetByteRangeTracker(initial, options.getBacklogReader(partition));\n+  }\n+\n+  @Override\n+  public PCollection<SequencedMessage> expand(PBegin input) {\n+    PCollection<Partition> partitions = Create.of(options.partitions()).expand(input);\n+    // Prevent fusion between Create and read.\n+    PCollection<Partition> shuffledPartitions = partitions.apply(Reshuffle.viaRandomKey());\n+    return shuffledPartitions.apply(\n+        ParDo.of(\n+            new PerPartitionSdf(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ1Mjk4NQ=="}, "originalCommit": {"oid": "e4ba623c7fb6cc3935558a861444583496a413cf"}, "originalPosition": 77}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM2NjI1MjIxOnYy", "diffSide": "RIGHT", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PerPartitionSdf.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwMDoxNDoyNFrOH_mryg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQwNzo0MTo1NFrOIC7e5g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ1NjEzOA==", "bodyText": "What'e the effect of committing offset? Are we able to read from that offset again if it's committed?", "url": "https://github.com/apache/beam/pull/13470#discussion_r536456138", "createdAt": "2020-12-05T00:14:24Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PerPartitionSdf.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.Partition;\n+import com.google.cloud.pubsublite.internal.PullSubscriber;\n+import com.google.cloud.pubsublite.internal.wire.Committer;\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import com.google.common.flogger.GoogleLogger;\n+import com.google.protobuf.util.Timestamps;\n+import java.util.Collections;\n+import java.util.List;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.SerializableBiFunction;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.util.Sleeper;\n+import org.joda.time.Duration;\n+import org.joda.time.Instant;\n+\n+class PerPartitionSdf extends DoFn<Partition, SequencedMessage> {\n+  private static final GoogleLogger logger = GoogleLogger.forEnclosingClass();\n+  private final Duration maxSleepTime;\n+  private final SerializableBiFunction<Partition, Offset, PullSubscriber<SequencedMessage>>\n+      subscriberFactory;\n+  private final SerializableFunction<Partition, Committer> committerFactory;\n+  private final SerializableSupplier<Sleeper> sleeperSupplier;\n+  private final SerializableFunction<Partition, InitialOffsetReader> offsetReaderFactory;\n+  private final SerializableBiFunction<\n+          Partition, OffsetRange, RestrictionTracker<OffsetRange, OffsetByteProgress>>\n+      trackerFactory;\n+\n+  Duration sleepTimeRemaining;\n+\n+  PerPartitionSdf(\n+      Duration maxSleepTime,\n+      SerializableBiFunction<Partition, Offset, PullSubscriber<SequencedMessage>> subscriberFactory,\n+      SerializableFunction<Partition, Committer> committerFactory,\n+      SerializableSupplier<Sleeper> sleeperSupplier,\n+      SerializableFunction<Partition, InitialOffsetReader> offsetReaderFactory,\n+      SerializableBiFunction<\n+              Partition, OffsetRange, RestrictionTracker<OffsetRange, OffsetByteProgress>>\n+          trackerFactory) {\n+    this.maxSleepTime = maxSleepTime;\n+    this.sleepTimeRemaining = maxSleepTime;\n+    this.subscriberFactory = subscriberFactory;\n+    this.committerFactory = committerFactory;\n+    this.sleeperSupplier = sleeperSupplier;\n+    this.offsetReaderFactory = offsetReaderFactory;\n+    this.trackerFactory = trackerFactory;\n+  }\n+\n+  private List<SequencedMessage> doPoll(PullSubscriber<SequencedMessage> subscriber)\n+      throws Exception {\n+    Sleeper sleeper = sleeperSupplier.get();\n+    while (sleepTimeRemaining.isLongerThan(Duration.ZERO)) {\n+      List<SequencedMessage> messages = subscriber.pull();\n+      if (!messages.isEmpty()) {\n+        return messages;\n+      }\n+      Duration sleepTime =\n+          Collections.min(ImmutableList.of(sleepTimeRemaining, Duration.millis(50)));\n+      sleepTimeRemaining = sleepTimeRemaining.minus(sleepTime);\n+      sleeper.sleep(sleepTime.getMillis());\n+    }\n+    return ImmutableList.of();\n+  }\n+\n+  @ProcessElement\n+  public ProcessContinuation processElement(\n+      RestrictionTracker<OffsetRange, OffsetByteProgress> tracker,\n+      @Element Partition partition,\n+      OutputReceiver<SequencedMessage> receiver)\n+      throws Exception {\n+    logger.atInfo().log(\"Starting processing for partition \" + partition);\n+    sleepTimeRemaining = maxSleepTime;\n+    Committer committer = committerFactory.apply(partition);\n+    committer.startAsync().awaitRunning();\n+    try (PullSubscriber<SequencedMessage> subscriber =\n+        subscriberFactory.apply(partition, Offset.of(tracker.currentRestriction().getFrom()))) {\n+      while (true) {\n+        List<SequencedMessage> messages = doPoll(subscriber);\n+        // We polled for as long as possible, yield to the runtime to allow it to reschedule us on\n+        // a new task.\n+        if (messages.isEmpty()) {\n+          logger.atInfo().log(\"Yielding due to timeout on partition \" + partition);\n+          return ProcessContinuation.resume();\n+        }\n+        Offset lastOffset = Offset.of(Iterables.getLast(messages).getCursor().getOffset());\n+        long byteSize = messages.stream().mapToLong(SequencedMessage::getSizeBytes).sum();\n+        if (tracker.tryClaim(OffsetByteProgress.of(lastOffset, byteSize))) {\n+          messages.forEach(\n+              message ->\n+                  receiver.outputWithTimestamp(\n+                      message, new Instant(Timestamps.toMillis(message.getPublishTime()))));\n+          committer.commitOffset(Offset.of(lastOffset.value() + 1)).get();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e4ba623c7fb6cc3935558a861444583496a413cf"}, "originalPosition": 115}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODgzMDE3Nw==", "bodyText": "It updates internal metrics and changes a stored integer value. It has no effect on where the current I/O reads from or what messages can be read.", "url": "https://github.com/apache/beam/pull/13470#discussion_r538830177", "createdAt": "2020-12-08T21:44:43Z", "author": {"login": "dpcollins-google"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PerPartitionSdf.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.Partition;\n+import com.google.cloud.pubsublite.internal.PullSubscriber;\n+import com.google.cloud.pubsublite.internal.wire.Committer;\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import com.google.common.flogger.GoogleLogger;\n+import com.google.protobuf.util.Timestamps;\n+import java.util.Collections;\n+import java.util.List;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.SerializableBiFunction;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.util.Sleeper;\n+import org.joda.time.Duration;\n+import org.joda.time.Instant;\n+\n+class PerPartitionSdf extends DoFn<Partition, SequencedMessage> {\n+  private static final GoogleLogger logger = GoogleLogger.forEnclosingClass();\n+  private final Duration maxSleepTime;\n+  private final SerializableBiFunction<Partition, Offset, PullSubscriber<SequencedMessage>>\n+      subscriberFactory;\n+  private final SerializableFunction<Partition, Committer> committerFactory;\n+  private final SerializableSupplier<Sleeper> sleeperSupplier;\n+  private final SerializableFunction<Partition, InitialOffsetReader> offsetReaderFactory;\n+  private final SerializableBiFunction<\n+          Partition, OffsetRange, RestrictionTracker<OffsetRange, OffsetByteProgress>>\n+      trackerFactory;\n+\n+  Duration sleepTimeRemaining;\n+\n+  PerPartitionSdf(\n+      Duration maxSleepTime,\n+      SerializableBiFunction<Partition, Offset, PullSubscriber<SequencedMessage>> subscriberFactory,\n+      SerializableFunction<Partition, Committer> committerFactory,\n+      SerializableSupplier<Sleeper> sleeperSupplier,\n+      SerializableFunction<Partition, InitialOffsetReader> offsetReaderFactory,\n+      SerializableBiFunction<\n+              Partition, OffsetRange, RestrictionTracker<OffsetRange, OffsetByteProgress>>\n+          trackerFactory) {\n+    this.maxSleepTime = maxSleepTime;\n+    this.sleepTimeRemaining = maxSleepTime;\n+    this.subscriberFactory = subscriberFactory;\n+    this.committerFactory = committerFactory;\n+    this.sleeperSupplier = sleeperSupplier;\n+    this.offsetReaderFactory = offsetReaderFactory;\n+    this.trackerFactory = trackerFactory;\n+  }\n+\n+  private List<SequencedMessage> doPoll(PullSubscriber<SequencedMessage> subscriber)\n+      throws Exception {\n+    Sleeper sleeper = sleeperSupplier.get();\n+    while (sleepTimeRemaining.isLongerThan(Duration.ZERO)) {\n+      List<SequencedMessage> messages = subscriber.pull();\n+      if (!messages.isEmpty()) {\n+        return messages;\n+      }\n+      Duration sleepTime =\n+          Collections.min(ImmutableList.of(sleepTimeRemaining, Duration.millis(50)));\n+      sleepTimeRemaining = sleepTimeRemaining.minus(sleepTime);\n+      sleeper.sleep(sleepTime.getMillis());\n+    }\n+    return ImmutableList.of();\n+  }\n+\n+  @ProcessElement\n+  public ProcessContinuation processElement(\n+      RestrictionTracker<OffsetRange, OffsetByteProgress> tracker,\n+      @Element Partition partition,\n+      OutputReceiver<SequencedMessage> receiver)\n+      throws Exception {\n+    logger.atInfo().log(\"Starting processing for partition \" + partition);\n+    sleepTimeRemaining = maxSleepTime;\n+    Committer committer = committerFactory.apply(partition);\n+    committer.startAsync().awaitRunning();\n+    try (PullSubscriber<SequencedMessage> subscriber =\n+        subscriberFactory.apply(partition, Offset.of(tracker.currentRestriction().getFrom()))) {\n+      while (true) {\n+        List<SequencedMessage> messages = doPoll(subscriber);\n+        // We polled for as long as possible, yield to the runtime to allow it to reschedule us on\n+        // a new task.\n+        if (messages.isEmpty()) {\n+          logger.atInfo().log(\"Yielding due to timeout on partition \" + partition);\n+          return ProcessContinuation.resume();\n+        }\n+        Offset lastOffset = Offset.of(Iterables.getLast(messages).getCursor().getOffset());\n+        long byteSize = messages.stream().mapToLong(SequencedMessage::getSizeBytes).sum();\n+        if (tracker.tryClaim(OffsetByteProgress.of(lastOffset, byteSize))) {\n+          messages.forEach(\n+              message ->\n+                  receiver.outputWithTimestamp(\n+                      message, new Instant(Timestamps.toMillis(message.getPublishTime()))));\n+          committer.commitOffset(Offset.of(lastOffset.value() + 1)).get();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ1NjEzOA=="}, "originalCommit": {"oid": "e4ba623c7fb6cc3935558a861444583496a413cf"}, "originalPosition": 115}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTUxODQxNg==", "bodyText": "This does actually affect where the I/O will start on clean restarts. Where this should be depends on how the beam model / dataflow handles drains for SDF pipelines. Do you have any information on this?", "url": "https://github.com/apache/beam/pull/13470#discussion_r539518416", "createdAt": "2020-12-09T17:48:56Z", "author": {"login": "dpcollins-google"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PerPartitionSdf.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.Partition;\n+import com.google.cloud.pubsublite.internal.PullSubscriber;\n+import com.google.cloud.pubsublite.internal.wire.Committer;\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import com.google.common.flogger.GoogleLogger;\n+import com.google.protobuf.util.Timestamps;\n+import java.util.Collections;\n+import java.util.List;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.SerializableBiFunction;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.util.Sleeper;\n+import org.joda.time.Duration;\n+import org.joda.time.Instant;\n+\n+class PerPartitionSdf extends DoFn<Partition, SequencedMessage> {\n+  private static final GoogleLogger logger = GoogleLogger.forEnclosingClass();\n+  private final Duration maxSleepTime;\n+  private final SerializableBiFunction<Partition, Offset, PullSubscriber<SequencedMessage>>\n+      subscriberFactory;\n+  private final SerializableFunction<Partition, Committer> committerFactory;\n+  private final SerializableSupplier<Sleeper> sleeperSupplier;\n+  private final SerializableFunction<Partition, InitialOffsetReader> offsetReaderFactory;\n+  private final SerializableBiFunction<\n+          Partition, OffsetRange, RestrictionTracker<OffsetRange, OffsetByteProgress>>\n+      trackerFactory;\n+\n+  Duration sleepTimeRemaining;\n+\n+  PerPartitionSdf(\n+      Duration maxSleepTime,\n+      SerializableBiFunction<Partition, Offset, PullSubscriber<SequencedMessage>> subscriberFactory,\n+      SerializableFunction<Partition, Committer> committerFactory,\n+      SerializableSupplier<Sleeper> sleeperSupplier,\n+      SerializableFunction<Partition, InitialOffsetReader> offsetReaderFactory,\n+      SerializableBiFunction<\n+              Partition, OffsetRange, RestrictionTracker<OffsetRange, OffsetByteProgress>>\n+          trackerFactory) {\n+    this.maxSleepTime = maxSleepTime;\n+    this.sleepTimeRemaining = maxSleepTime;\n+    this.subscriberFactory = subscriberFactory;\n+    this.committerFactory = committerFactory;\n+    this.sleeperSupplier = sleeperSupplier;\n+    this.offsetReaderFactory = offsetReaderFactory;\n+    this.trackerFactory = trackerFactory;\n+  }\n+\n+  private List<SequencedMessage> doPoll(PullSubscriber<SequencedMessage> subscriber)\n+      throws Exception {\n+    Sleeper sleeper = sleeperSupplier.get();\n+    while (sleepTimeRemaining.isLongerThan(Duration.ZERO)) {\n+      List<SequencedMessage> messages = subscriber.pull();\n+      if (!messages.isEmpty()) {\n+        return messages;\n+      }\n+      Duration sleepTime =\n+          Collections.min(ImmutableList.of(sleepTimeRemaining, Duration.millis(50)));\n+      sleepTimeRemaining = sleepTimeRemaining.minus(sleepTime);\n+      sleeper.sleep(sleepTime.getMillis());\n+    }\n+    return ImmutableList.of();\n+  }\n+\n+  @ProcessElement\n+  public ProcessContinuation processElement(\n+      RestrictionTracker<OffsetRange, OffsetByteProgress> tracker,\n+      @Element Partition partition,\n+      OutputReceiver<SequencedMessage> receiver)\n+      throws Exception {\n+    logger.atInfo().log(\"Starting processing for partition \" + partition);\n+    sleepTimeRemaining = maxSleepTime;\n+    Committer committer = committerFactory.apply(partition);\n+    committer.startAsync().awaitRunning();\n+    try (PullSubscriber<SequencedMessage> subscriber =\n+        subscriberFactory.apply(partition, Offset.of(tracker.currentRestriction().getFrom()))) {\n+      while (true) {\n+        List<SequencedMessage> messages = doPoll(subscriber);\n+        // We polled for as long as possible, yield to the runtime to allow it to reschedule us on\n+        // a new task.\n+        if (messages.isEmpty()) {\n+          logger.atInfo().log(\"Yielding due to timeout on partition \" + partition);\n+          return ProcessContinuation.resume();\n+        }\n+        Offset lastOffset = Offset.of(Iterables.getLast(messages).getCursor().getOffset());\n+        long byteSize = messages.stream().mapToLong(SequencedMessage::getSizeBytes).sum();\n+        if (tracker.tryClaim(OffsetByteProgress.of(lastOffset, byteSize))) {\n+          messages.forEach(\n+              message ->\n+                  receiver.outputWithTimestamp(\n+                      message, new Instant(Timestamps.toMillis(message.getPublishTime()))));\n+          committer.commitOffset(Offset.of(lastOffset.value() + 1)).get();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ1NjEzOA=="}, "originalCommit": {"oid": "e4ba623c7fb6cc3935558a861444583496a413cf"}, "originalPosition": 115}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTczNTk3MA==", "bodyText": "You can either use bundle finalization to commit offsets, which is best-effort. This is similar to how CheckpointMark of UnboundedSource works. Or you can do something similar to Kafka CommitOffset transform.", "url": "https://github.com/apache/beam/pull/13470#discussion_r539735970", "createdAt": "2020-12-09T23:51:06Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PerPartitionSdf.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.Partition;\n+import com.google.cloud.pubsublite.internal.PullSubscriber;\n+import com.google.cloud.pubsublite.internal.wire.Committer;\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import com.google.common.flogger.GoogleLogger;\n+import com.google.protobuf.util.Timestamps;\n+import java.util.Collections;\n+import java.util.List;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.SerializableBiFunction;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.util.Sleeper;\n+import org.joda.time.Duration;\n+import org.joda.time.Instant;\n+\n+class PerPartitionSdf extends DoFn<Partition, SequencedMessage> {\n+  private static final GoogleLogger logger = GoogleLogger.forEnclosingClass();\n+  private final Duration maxSleepTime;\n+  private final SerializableBiFunction<Partition, Offset, PullSubscriber<SequencedMessage>>\n+      subscriberFactory;\n+  private final SerializableFunction<Partition, Committer> committerFactory;\n+  private final SerializableSupplier<Sleeper> sleeperSupplier;\n+  private final SerializableFunction<Partition, InitialOffsetReader> offsetReaderFactory;\n+  private final SerializableBiFunction<\n+          Partition, OffsetRange, RestrictionTracker<OffsetRange, OffsetByteProgress>>\n+      trackerFactory;\n+\n+  Duration sleepTimeRemaining;\n+\n+  PerPartitionSdf(\n+      Duration maxSleepTime,\n+      SerializableBiFunction<Partition, Offset, PullSubscriber<SequencedMessage>> subscriberFactory,\n+      SerializableFunction<Partition, Committer> committerFactory,\n+      SerializableSupplier<Sleeper> sleeperSupplier,\n+      SerializableFunction<Partition, InitialOffsetReader> offsetReaderFactory,\n+      SerializableBiFunction<\n+              Partition, OffsetRange, RestrictionTracker<OffsetRange, OffsetByteProgress>>\n+          trackerFactory) {\n+    this.maxSleepTime = maxSleepTime;\n+    this.sleepTimeRemaining = maxSleepTime;\n+    this.subscriberFactory = subscriberFactory;\n+    this.committerFactory = committerFactory;\n+    this.sleeperSupplier = sleeperSupplier;\n+    this.offsetReaderFactory = offsetReaderFactory;\n+    this.trackerFactory = trackerFactory;\n+  }\n+\n+  private List<SequencedMessage> doPoll(PullSubscriber<SequencedMessage> subscriber)\n+      throws Exception {\n+    Sleeper sleeper = sleeperSupplier.get();\n+    while (sleepTimeRemaining.isLongerThan(Duration.ZERO)) {\n+      List<SequencedMessage> messages = subscriber.pull();\n+      if (!messages.isEmpty()) {\n+        return messages;\n+      }\n+      Duration sleepTime =\n+          Collections.min(ImmutableList.of(sleepTimeRemaining, Duration.millis(50)));\n+      sleepTimeRemaining = sleepTimeRemaining.minus(sleepTime);\n+      sleeper.sleep(sleepTime.getMillis());\n+    }\n+    return ImmutableList.of();\n+  }\n+\n+  @ProcessElement\n+  public ProcessContinuation processElement(\n+      RestrictionTracker<OffsetRange, OffsetByteProgress> tracker,\n+      @Element Partition partition,\n+      OutputReceiver<SequencedMessage> receiver)\n+      throws Exception {\n+    logger.atInfo().log(\"Starting processing for partition \" + partition);\n+    sleepTimeRemaining = maxSleepTime;\n+    Committer committer = committerFactory.apply(partition);\n+    committer.startAsync().awaitRunning();\n+    try (PullSubscriber<SequencedMessage> subscriber =\n+        subscriberFactory.apply(partition, Offset.of(tracker.currentRestriction().getFrom()))) {\n+      while (true) {\n+        List<SequencedMessage> messages = doPoll(subscriber);\n+        // We polled for as long as possible, yield to the runtime to allow it to reschedule us on\n+        // a new task.\n+        if (messages.isEmpty()) {\n+          logger.atInfo().log(\"Yielding due to timeout on partition \" + partition);\n+          return ProcessContinuation.resume();\n+        }\n+        Offset lastOffset = Offset.of(Iterables.getLast(messages).getCursor().getOffset());\n+        long byteSize = messages.stream().mapToLong(SequencedMessage::getSizeBytes).sum();\n+        if (tracker.tryClaim(OffsetByteProgress.of(lastOffset, byteSize))) {\n+          messages.forEach(\n+              message ->\n+                  receiver.outputWithTimestamp(\n+                      message, new Instant(Timestamps.toMillis(message.getPublishTime()))));\n+          committer.commitOffset(Offset.of(lastOffset.value() + 1)).get();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ1NjEzOA=="}, "originalCommit": {"oid": "e4ba623c7fb6cc3935558a861444583496a413cf"}, "originalPosition": 115}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTk0MjYzMA==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/13470#discussion_r539942630", "createdAt": "2020-12-10T07:41:54Z", "author": {"login": "dpcollins-google"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PerPartitionSdf.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.Partition;\n+import com.google.cloud.pubsublite.internal.PullSubscriber;\n+import com.google.cloud.pubsublite.internal.wire.Committer;\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import com.google.common.collect.ImmutableList;\n+import com.google.common.collect.Iterables;\n+import com.google.common.flogger.GoogleLogger;\n+import com.google.protobuf.util.Timestamps;\n+import java.util.Collections;\n+import java.util.List;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.SerializableBiFunction;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.util.Sleeper;\n+import org.joda.time.Duration;\n+import org.joda.time.Instant;\n+\n+class PerPartitionSdf extends DoFn<Partition, SequencedMessage> {\n+  private static final GoogleLogger logger = GoogleLogger.forEnclosingClass();\n+  private final Duration maxSleepTime;\n+  private final SerializableBiFunction<Partition, Offset, PullSubscriber<SequencedMessage>>\n+      subscriberFactory;\n+  private final SerializableFunction<Partition, Committer> committerFactory;\n+  private final SerializableSupplier<Sleeper> sleeperSupplier;\n+  private final SerializableFunction<Partition, InitialOffsetReader> offsetReaderFactory;\n+  private final SerializableBiFunction<\n+          Partition, OffsetRange, RestrictionTracker<OffsetRange, OffsetByteProgress>>\n+      trackerFactory;\n+\n+  Duration sleepTimeRemaining;\n+\n+  PerPartitionSdf(\n+      Duration maxSleepTime,\n+      SerializableBiFunction<Partition, Offset, PullSubscriber<SequencedMessage>> subscriberFactory,\n+      SerializableFunction<Partition, Committer> committerFactory,\n+      SerializableSupplier<Sleeper> sleeperSupplier,\n+      SerializableFunction<Partition, InitialOffsetReader> offsetReaderFactory,\n+      SerializableBiFunction<\n+              Partition, OffsetRange, RestrictionTracker<OffsetRange, OffsetByteProgress>>\n+          trackerFactory) {\n+    this.maxSleepTime = maxSleepTime;\n+    this.sleepTimeRemaining = maxSleepTime;\n+    this.subscriberFactory = subscriberFactory;\n+    this.committerFactory = committerFactory;\n+    this.sleeperSupplier = sleeperSupplier;\n+    this.offsetReaderFactory = offsetReaderFactory;\n+    this.trackerFactory = trackerFactory;\n+  }\n+\n+  private List<SequencedMessage> doPoll(PullSubscriber<SequencedMessage> subscriber)\n+      throws Exception {\n+    Sleeper sleeper = sleeperSupplier.get();\n+    while (sleepTimeRemaining.isLongerThan(Duration.ZERO)) {\n+      List<SequencedMessage> messages = subscriber.pull();\n+      if (!messages.isEmpty()) {\n+        return messages;\n+      }\n+      Duration sleepTime =\n+          Collections.min(ImmutableList.of(sleepTimeRemaining, Duration.millis(50)));\n+      sleepTimeRemaining = sleepTimeRemaining.minus(sleepTime);\n+      sleeper.sleep(sleepTime.getMillis());\n+    }\n+    return ImmutableList.of();\n+  }\n+\n+  @ProcessElement\n+  public ProcessContinuation processElement(\n+      RestrictionTracker<OffsetRange, OffsetByteProgress> tracker,\n+      @Element Partition partition,\n+      OutputReceiver<SequencedMessage> receiver)\n+      throws Exception {\n+    logger.atInfo().log(\"Starting processing for partition \" + partition);\n+    sleepTimeRemaining = maxSleepTime;\n+    Committer committer = committerFactory.apply(partition);\n+    committer.startAsync().awaitRunning();\n+    try (PullSubscriber<SequencedMessage> subscriber =\n+        subscriberFactory.apply(partition, Offset.of(tracker.currentRestriction().getFrom()))) {\n+      while (true) {\n+        List<SequencedMessage> messages = doPoll(subscriber);\n+        // We polled for as long as possible, yield to the runtime to allow it to reschedule us on\n+        // a new task.\n+        if (messages.isEmpty()) {\n+          logger.atInfo().log(\"Yielding due to timeout on partition \" + partition);\n+          return ProcessContinuation.resume();\n+        }\n+        Offset lastOffset = Offset.of(Iterables.getLast(messages).getCursor().getOffset());\n+        long byteSize = messages.stream().mapToLong(SequencedMessage::getSizeBytes).sum();\n+        if (tracker.tryClaim(OffsetByteProgress.of(lastOffset, byteSize))) {\n+          messages.forEach(\n+              message ->\n+                  receiver.outputWithTimestamp(\n+                      message, new Instant(Timestamps.toMillis(message.getPublishTime()))));\n+          committer.commitOffset(Offset.of(lastOffset.value() + 1)).get();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ1NjEzOA=="}, "originalCommit": {"oid": "e4ba623c7fb6cc3935558a861444583496a413cf"}, "originalPosition": 115}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQxNzAyMzYyOnYy", "diffSide": "RIGHT", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/OffsetByteRangeTracker.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQwMDoyODo1NlrOIGmHrw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQwMDoyODo1NlrOIGmHrw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mzc4NjkyNw==", "bodyText": "You also want to return null when fractionOfRemainder > 0.0", "url": "https://github.com/apache/beam/pull/13470#discussion_r543786927", "createdAt": "2020-12-16T00:28:56Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/OffsetByteRangeTracker.java", "diffHunk": "@@ -0,0 +1,172 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkNotNull;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkState;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.proto.ComputeMessageStatsResponse;\n+import java.util.concurrent.TimeUnit;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker.HasProgress;\n+import org.apache.beam.sdk.transforms.splittabledofn.SplitResult;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Stopwatch;\n+import org.joda.time.Duration;\n+\n+/**\n+ * OffsetByteRangeTracker is an unbounded restriction tracker for Pub/Sub lite partitions that\n+ * tracks offsets for checkpointing and bytes for progress.\n+ *\n+ * <p>Any valid instance of an OffsetByteRangeTracker tracks one of exactly two types of ranges: -\n+ * Unbounded ranges whose last offset is Long.MAX_VALUE - Completed ranges that are either empty\n+ * (From == To) or fully claimed (lastClaimed == To - 1)\n+ *\n+ * <p>Also prevents splitting until minTrackingTime has passed or minBytesReceived have been\n+ * received. IMPORTANT: minTrackingTime must be strictly smaller than the SDF read timeout when it\n+ * would return ProcessContinuation.resume().\n+ */\n+class OffsetByteRangeTracker extends RestrictionTracker<OffsetRange, OffsetByteProgress>\n+    implements HasProgress {\n+  private final TopicBacklogReader backlogReader;\n+  private final Duration minTrackingTime;\n+  private final long minBytesReceived;\n+  private final Stopwatch stopwatch;\n+  private OffsetRange range;\n+  private @Nullable Long lastClaimed;\n+  private long byteCount = 0;\n+\n+  public OffsetByteRangeTracker(\n+      OffsetRange range,\n+      TopicBacklogReader backlogReader,\n+      Stopwatch stopwatch,\n+      Duration minTrackingTime,\n+      long minBytesReceived) {\n+    checkArgument(range.getTo() == Long.MAX_VALUE);\n+    this.backlogReader = backlogReader;\n+    this.minTrackingTime = minTrackingTime;\n+    this.minBytesReceived = minBytesReceived;\n+    this.stopwatch = stopwatch.reset().start();\n+    this.range = range;\n+  }\n+\n+  @Override\n+  public void finalize() {\n+    this.backlogReader.close();\n+  }\n+\n+  @Override\n+  public IsBounded isBounded() {\n+    return IsBounded.UNBOUNDED;\n+  }\n+\n+  @Override\n+  public boolean tryClaim(OffsetByteProgress position) {\n+    long toClaim = position.lastOffset().value();\n+    checkArgument(\n+        lastClaimed == null || toClaim > lastClaimed,\n+        \"Trying to claim offset %s while last attempted was %s\",\n+        position.lastOffset().value(),\n+        lastClaimed);\n+    checkArgument(\n+        toClaim >= range.getFrom(),\n+        \"Trying to claim offset %s before start of the range %s\",\n+        toClaim,\n+        range);\n+    // split() has already been called, truncating this range. No more offsets may be claimed.\n+    if (range.getTo() != Long.MAX_VALUE) {\n+      boolean isRangeEmpty = range.getTo() == range.getFrom();\n+      boolean isValidClosedRange = nextOffset() == range.getTo();\n+      checkState(\n+          isRangeEmpty || isValidClosedRange,\n+          \"Violated class precondition: offset range improperly split. Please report a beam bug.\");\n+      return false;\n+    }\n+    lastClaimed = toClaim;\n+    byteCount += position.batchBytes();\n+    return true;\n+  }\n+\n+  @Override\n+  public OffsetRange currentRestriction() {\n+    return range;\n+  }\n+\n+  private long nextOffset() {\n+    checkState(lastClaimed == null || lastClaimed < Long.MAX_VALUE);\n+    return lastClaimed == null ? currentRestriction().getFrom() : lastClaimed + 1;\n+  }\n+\n+  /**\n+   * Whether the tracker has received enough data/been running for enough time that it can\n+   * checkpoint and be confident it can get sufficient throughput.\n+   */\n+  private boolean receivedEnough() {\n+    Duration duration = Duration.millis(stopwatch.elapsed(TimeUnit.MILLISECONDS));\n+    if (duration.isLongerThan(minTrackingTime)) {\n+      return true;\n+    }\n+    if (byteCount >= minBytesReceived) {\n+      return true;\n+    }\n+    return false;\n+  }\n+\n+  @Override\n+  public @Nullable SplitResult<OffsetRange> trySplit(double fractionOfRemainder) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "88a30211fe9046969e36f6934dd00f971836ac4b"}, "originalPosition": 134}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQxNzAzOTQ1OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PartitionProcessorFactory.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQwMDozNDozM1rOIGmQSA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQwMDozNDozM1rOIGmQSA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mzc4OTEyOA==", "bodyText": "SubscriptionPartitionFactory?", "url": "https://github.com/apache/beam/pull/13470#discussion_r543789128", "createdAt": "2020-12-16T00:34:33Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PartitionProcessorFactory.java", "diffHunk": "@@ -0,0 +1,33 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import java.io.Serializable;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.DoFn.OutputReceiver;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+\n+interface PartitionProcessorFactory extends Serializable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "88a30211fe9046969e36f6934dd00f971836ac4b"}, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQxNzA0MDU2OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PartitionProcessor.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQwMDozNDo1NVrOIGmQ4w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQwMDozNDo1NVrOIGmQ4w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mzc4OTI4Mw==", "bodyText": "SubscriptionPartitionProcessor?", "url": "https://github.com/apache/beam/pull/13470#discussion_r543789283", "createdAt": "2020-12-16T00:34:55Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PartitionProcessor.java", "diffHunk": "@@ -17,12 +17,12 @@\n  */\n package org.apache.beam.sdk.io.gcp.pubsublite;\n \n-import com.google.cloud.pubsublite.Offset;\n-import com.google.cloud.pubsublite.Partition;\n import com.google.cloud.pubsublite.internal.CheckedApiException;\n-import java.util.Map;\n+import org.apache.beam.sdk.transforms.DoFn.ProcessContinuation;\n+import org.joda.time.Duration;\n \n-/** An internal interface for finalizing offsets. */\n-interface OffsetFinalizer {\n-  void finalizeOffsets(Map<Partition, Offset> offsets) throws CheckedApiException;\n+interface PartitionProcessor extends AutoCloseable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "88a30211fe9046969e36f6934dd00f971836ac4b"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQxNzA0MTgxOnYy", "diffSide": "RIGHT", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PartitionProcessorImpl.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQwMDozNToyNlrOIGmRlg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQwMDozNToyNlrOIGmRlg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mzc4OTQ2Mg==", "bodyText": "SubscriptionPartitionProcessorImpl?", "url": "https://github.com/apache/beam/pull/13470#discussion_r543789462", "createdAt": "2020-12-16T00:35:26Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PartitionProcessorImpl.java", "diffHunk": "@@ -0,0 +1,143 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import com.google.api.core.ApiService.Listener;\n+import com.google.api.core.ApiService.State;\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.cloudpubsub.FlowControlSettings;\n+import com.google.cloud.pubsublite.internal.CheckedApiException;\n+import com.google.cloud.pubsublite.internal.ExtractStatus;\n+import com.google.cloud.pubsublite.internal.wire.Subscriber;\n+import com.google.cloud.pubsublite.proto.Cursor;\n+import com.google.cloud.pubsublite.proto.FlowControlRequest;\n+import com.google.cloud.pubsublite.proto.SeekRequest;\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import com.google.protobuf.util.Timestamps;\n+import java.util.List;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.TimeUnit;\n+import java.util.concurrent.TimeoutException;\n+import java.util.function.Consumer;\n+import java.util.function.Function;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.DoFn.OutputReceiver;\n+import org.apache.beam.sdk.transforms.DoFn.ProcessContinuation;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Iterables;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.util.concurrent.MoreExecutors;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.util.concurrent.SettableFuture;\n+import org.joda.time.Duration;\n+import org.joda.time.Instant;\n+\n+class PartitionProcessorImpl extends Listener implements PartitionProcessor {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "88a30211fe9046969e36f6934dd00f971836ac4b"}, "originalPosition": 48}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQxNzA0ODk0OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PerPartitionSdf.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQwMDozNzo1N1rOIGmVZw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQwMDozNzo1N1rOIGmVZw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mzc5MDQzOQ==", "bodyText": "PerSubscriptionPartitionSdf?", "url": "https://github.com/apache/beam/pull/13470#discussion_r543790439", "createdAt": "2020-12-16T00:37:57Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PerPartitionSdf.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.internal.wire.Committer;\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import java.util.Optional;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.SerializableBiFunction;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.transforms.splittabledofn.SplitResult;\n+import org.apache.beam.sdk.transforms.splittabledofn.WatermarkEstimators.MonotonicallyIncreasing;\n+import org.joda.time.Duration;\n+import org.joda.time.Instant;\n+\n+class PerPartitionSdf extends DoFn<SubscriptionPartition, SequencedMessage> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "88a30211fe9046969e36f6934dd00f971836ac4b"}, "originalPosition": 35}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQxNzA2NTQ3OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PerPartitionSdf.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQwMDo0Mzo1MlrOIGmeSQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQwMDo0Mzo1MlrOIGmeSQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mzc5MjcxMw==", "bodyText": "When you have got the result from processor.waitForCompletion(maxSleepTime), the tracker.currentRestriction().getTo() will be the lastClaimed you want.", "url": "https://github.com/apache/beam/pull/13470#discussion_r543792713", "createdAt": "2020-12-16T00:43:52Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PerPartitionSdf.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.internal.wire.Committer;\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import java.util.Optional;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.SerializableBiFunction;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.transforms.splittabledofn.SplitResult;\n+import org.apache.beam.sdk.transforms.splittabledofn.WatermarkEstimators.MonotonicallyIncreasing;\n+import org.joda.time.Duration;\n+import org.joda.time.Instant;\n+\n+class PerPartitionSdf extends DoFn<SubscriptionPartition, SequencedMessage> {\n+  private final Duration maxSleepTime;\n+  private final PartitionProcessorFactory processorFactory;\n+  private final SerializableFunction<SubscriptionPartition, InitialOffsetReader>\n+      offsetReaderFactory;\n+  private final SerializableBiFunction<\n+          SubscriptionPartition, OffsetRange, RestrictionTracker<OffsetRange, OffsetByteProgress>>\n+      trackerFactory;\n+  private final SerializableFunction<SubscriptionPartition, Committer> committerFactory;\n+\n+  PerPartitionSdf(\n+      Duration maxSleepTime,\n+      SerializableFunction<SubscriptionPartition, InitialOffsetReader> offsetReaderFactory,\n+      SerializableBiFunction<\n+              SubscriptionPartition,\n+              OffsetRange,\n+              RestrictionTracker<OffsetRange, OffsetByteProgress>>\n+          trackerFactory,\n+      PartitionProcessorFactory processorFactory,\n+      SerializableFunction<SubscriptionPartition, Committer> committerFactory) {\n+    this.maxSleepTime = maxSleepTime;\n+    this.processorFactory = processorFactory;\n+    this.offsetReaderFactory = offsetReaderFactory;\n+    this.trackerFactory = trackerFactory;\n+    this.committerFactory = committerFactory;\n+  }\n+\n+  private static final class WrappedTracker\n+      extends RestrictionTracker<OffsetRange, OffsetByteProgress> {\n+    private final RestrictionTracker<OffsetRange, OffsetByteProgress> underlying;\n+    Optional<Offset> lastClaimed;\n+\n+    WrappedTracker(RestrictionTracker<OffsetRange, OffsetByteProgress> underlying) {\n+      this.underlying = underlying;\n+      this.lastClaimed = Optional.empty();\n+    }\n+\n+    @Override\n+    public boolean tryClaim(OffsetByteProgress position) {\n+      boolean claimed = underlying.tryClaim(position);\n+      if (claimed) {\n+        lastClaimed = Optional.of(position.lastOffset());\n+      }\n+      return claimed;\n+    }\n+\n+    @Override\n+    public OffsetRange currentRestriction() {\n+      return underlying.currentRestriction();\n+    }\n+\n+    @Override\n+    public @Nullable SplitResult<OffsetRange> trySplit(double fractionOfRemainder) {\n+      return underlying.trySplit(fractionOfRemainder);\n+    }\n+\n+    @Override\n+    public void checkDone() throws IllegalStateException {\n+      underlying.checkDone();\n+    }\n+\n+    @Override\n+    public IsBounded isBounded() {\n+      return underlying.isBounded();\n+    }\n+  }\n+\n+  @GetInitialWatermarkEstimatorState\n+  Instant getInitialWatermarkState() {\n+    return Instant.EPOCH;\n+  }\n+\n+  @NewWatermarkEstimator\n+  MonotonicallyIncreasing newWatermarkEstimator(@WatermarkEstimatorState Instant state) {\n+    return new MonotonicallyIncreasing(state);\n+  }\n+\n+  @ProcessElement\n+  public ProcessContinuation processElement(\n+      RestrictionTracker<OffsetRange, OffsetByteProgress> tracker,\n+      @Element SubscriptionPartition subscriptionPartition,\n+      OutputReceiver<SequencedMessage> receiver,\n+      BundleFinalizer finalizer)\n+      throws Exception {\n+    WrappedTracker wrapped = new WrappedTracker(tracker);\n+    try (PartitionProcessor processor =\n+        processorFactory.newProcessor(subscriptionPartition, wrapped, receiver)) {\n+      processor.start();\n+      ProcessContinuation result = processor.waitForCompletion(maxSleepTime);\n+      wrapped.lastClaimed.ifPresent(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "88a30211fe9046969e36f6934dd00f971836ac4b"}, "originalPosition": 124}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQxNzA4OTMxOnYy", "diffSide": "RIGHT", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/SubscribeTransform.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQwMDo1Mjo0MVrOIGmrOQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQwMDo1Mjo0MVrOIGmrOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mzc5NjAyNQ==", "bodyText": "I don'y think inserting a Reshuffle is necessary.", "url": "https://github.com/apache/beam/pull/13470#discussion_r543796025", "createdAt": "2020-12-16T00:52:41Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/SubscribeTransform.java", "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import static com.google.cloud.pubsublite.internal.ExtractStatus.toCanonical;\n+import static com.google.cloud.pubsublite.internal.UncheckedApiPreconditions.checkArgument;\n+\n+import com.google.api.gax.rpc.ApiException;\n+import com.google.cloud.pubsublite.Partition;\n+import com.google.cloud.pubsublite.internal.wire.Committer;\n+import com.google.cloud.pubsublite.internal.wire.Subscriber;\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import java.util.List;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.apache.beam.sdk.transforms.DoFn.OutputReceiver;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.Reshuffle;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Stopwatch;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.math.LongMath;\n+import org.joda.time.Duration;\n+\n+class SubscribeTransform extends PTransform<PBegin, PCollection<SequencedMessage>> {\n+  private static final Duration MAX_SLEEP_TIME = Duration.standardMinutes(1);\n+\n+  private final SubscriberOptions options;\n+\n+  SubscribeTransform(SubscriberOptions options) {\n+    this.options = options;\n+  }\n+\n+  private void checkSubscription(SubscriptionPartition subscriptionPartition) throws ApiException {\n+    checkArgument(subscriptionPartition.subscription().equals(options.subscriptionPath()));\n+  }\n+\n+  private Subscriber newSubscriber(Partition partition, Consumer<List<SequencedMessage>> consumer) {\n+    try {\n+      return options\n+          .getSubscriberFactory(partition)\n+          .newSubscriber(\n+              messages ->\n+                  consumer.accept(\n+                      messages.stream()\n+                          .map(message -> message.toProto())\n+                          .collect(Collectors.toList())));\n+    } catch (Throwable t) {\n+      throw toCanonical(t).underlying;\n+    }\n+  }\n+\n+  private PartitionProcessor newPartitionProcessor(\n+      SubscriptionPartition subscriptionPartition,\n+      RestrictionTracker<OffsetRange, OffsetByteProgress> tracker,\n+      OutputReceiver<SequencedMessage> receiver)\n+      throws ApiException {\n+    checkSubscription(subscriptionPartition);\n+    return new PartitionProcessorImpl(\n+        tracker,\n+        receiver,\n+        consumer -> newSubscriber(subscriptionPartition.partition(), consumer),\n+        options.flowControlSettings());\n+  }\n+\n+  private RestrictionTracker<OffsetRange, OffsetByteProgress> newRestrictionTracker(\n+      SubscriptionPartition subscriptionPartition, OffsetRange initial) {\n+    checkSubscription(subscriptionPartition);\n+    return new OffsetByteRangeTracker(\n+        initial,\n+        options.getBacklogReader(subscriptionPartition.partition()),\n+        Stopwatch.createUnstarted(),\n+        MAX_SLEEP_TIME.multipliedBy(3).dividedBy(4),\n+        LongMath.saturatedMultiply(options.flowControlSettings().bytesOutstanding(), 10));\n+  }\n+\n+  private InitialOffsetReader newInitialOffsetReader(SubscriptionPartition subscriptionPartition) {\n+    checkSubscription(subscriptionPartition);\n+    return options.getInitialOffsetReader(subscriptionPartition.partition());\n+  }\n+\n+  private Committer newCommitter(SubscriptionPartition subscriptionPartition) {\n+    checkSubscription(subscriptionPartition);\n+    return options.getCommitter(subscriptionPartition.partition());\n+  }\n+\n+  @Override\n+  public PCollection<SequencedMessage> expand(PBegin input) {\n+    PCollection<SubscriptionPartition> partitions =\n+        Create.of(\n+                options.partitions().stream()\n+                    .map(\n+                        partition ->\n+                            SubscriptionPartition.of(options.subscriptionPath(), partition))\n+                    .collect(Collectors.toList()))\n+            .expand(input);\n+    // Prevent fusion between Create and read.\n+    PCollection<SubscriptionPartition> shuffledPartitions =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "88a30211fe9046969e36f6934dd00f971836ac4b"}, "originalPosition": 117}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQxNzEyMDIzOnYy", "diffSide": "RIGHT", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PerPartitionSdf.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQwMTowMzo1M1rOIGm7oQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQwMTowMzo1M1rOIGm7oQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzgwMDIyNQ==", "bodyText": "I'm curious why we need a trackerFactory here instead of returning your OffsetByteRangeTracker directly. Do you expect your SDF user to implement their own restriction tracker?", "url": "https://github.com/apache/beam/pull/13470#discussion_r543800225", "createdAt": "2020-12-16T01:03:53Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/PerPartitionSdf.java", "diffHunk": "@@ -0,0 +1,152 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import com.google.cloud.pubsublite.Offset;\n+import com.google.cloud.pubsublite.internal.wire.Committer;\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import java.util.Optional;\n+import javax.annotation.Nullable;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.SerializableBiFunction;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.transforms.splittabledofn.SplitResult;\n+import org.apache.beam.sdk.transforms.splittabledofn.WatermarkEstimators.MonotonicallyIncreasing;\n+import org.joda.time.Duration;\n+import org.joda.time.Instant;\n+\n+class PerPartitionSdf extends DoFn<SubscriptionPartition, SequencedMessage> {\n+  private final Duration maxSleepTime;\n+  private final PartitionProcessorFactory processorFactory;\n+  private final SerializableFunction<SubscriptionPartition, InitialOffsetReader>\n+      offsetReaderFactory;\n+  private final SerializableBiFunction<\n+          SubscriptionPartition, OffsetRange, RestrictionTracker<OffsetRange, OffsetByteProgress>>\n+      trackerFactory;\n+  private final SerializableFunction<SubscriptionPartition, Committer> committerFactory;\n+\n+  PerPartitionSdf(\n+      Duration maxSleepTime,\n+      SerializableFunction<SubscriptionPartition, InitialOffsetReader> offsetReaderFactory,\n+      SerializableBiFunction<\n+              SubscriptionPartition,\n+              OffsetRange,\n+              RestrictionTracker<OffsetRange, OffsetByteProgress>>\n+          trackerFactory,\n+      PartitionProcessorFactory processorFactory,\n+      SerializableFunction<SubscriptionPartition, Committer> committerFactory) {\n+    this.maxSleepTime = maxSleepTime;\n+    this.processorFactory = processorFactory;\n+    this.offsetReaderFactory = offsetReaderFactory;\n+    this.trackerFactory = trackerFactory;\n+    this.committerFactory = committerFactory;\n+  }\n+\n+  private static final class WrappedTracker\n+      extends RestrictionTracker<OffsetRange, OffsetByteProgress> {\n+    private final RestrictionTracker<OffsetRange, OffsetByteProgress> underlying;\n+    Optional<Offset> lastClaimed;\n+\n+    WrappedTracker(RestrictionTracker<OffsetRange, OffsetByteProgress> underlying) {\n+      this.underlying = underlying;\n+      this.lastClaimed = Optional.empty();\n+    }\n+\n+    @Override\n+    public boolean tryClaim(OffsetByteProgress position) {\n+      boolean claimed = underlying.tryClaim(position);\n+      if (claimed) {\n+        lastClaimed = Optional.of(position.lastOffset());\n+      }\n+      return claimed;\n+    }\n+\n+    @Override\n+    public OffsetRange currentRestriction() {\n+      return underlying.currentRestriction();\n+    }\n+\n+    @Override\n+    public @Nullable SplitResult<OffsetRange> trySplit(double fractionOfRemainder) {\n+      return underlying.trySplit(fractionOfRemainder);\n+    }\n+\n+    @Override\n+    public void checkDone() throws IllegalStateException {\n+      underlying.checkDone();\n+    }\n+\n+    @Override\n+    public IsBounded isBounded() {\n+      return underlying.isBounded();\n+    }\n+  }\n+\n+  @GetInitialWatermarkEstimatorState\n+  Instant getInitialWatermarkState() {\n+    return Instant.EPOCH;\n+  }\n+\n+  @NewWatermarkEstimator\n+  MonotonicallyIncreasing newWatermarkEstimator(@WatermarkEstimatorState Instant state) {\n+    return new MonotonicallyIncreasing(state);\n+  }\n+\n+  @ProcessElement\n+  public ProcessContinuation processElement(\n+      RestrictionTracker<OffsetRange, OffsetByteProgress> tracker,\n+      @Element SubscriptionPartition subscriptionPartition,\n+      OutputReceiver<SequencedMessage> receiver,\n+      BundleFinalizer finalizer)\n+      throws Exception {\n+    WrappedTracker wrapped = new WrappedTracker(tracker);\n+    try (PartitionProcessor processor =\n+        processorFactory.newProcessor(subscriptionPartition, wrapped, receiver)) {\n+      processor.start();\n+      ProcessContinuation result = processor.waitForCompletion(maxSleepTime);\n+      wrapped.lastClaimed.ifPresent(\n+          lastClaimedOffset ->\n+              finalizer.afterBundleCommit(\n+                  Instant.ofEpochMilli(Long.MAX_VALUE),\n+                  () -> {\n+                    Committer committer = committerFactory.apply(subscriptionPartition);\n+                    committer.startAsync().awaitRunning();\n+                    // Commit the next-to-deliver offset.\n+                    committer.commitOffset(Offset.of(lastClaimedOffset.value() + 1)).get();\n+                    committer.stopAsync().awaitTerminated();\n+                  }));\n+      return result;\n+    }\n+  }\n+\n+  @GetInitialRestriction\n+  public OffsetRange getInitialRestriction(@Element SubscriptionPartition subscriptionPartition) {\n+    try (InitialOffsetReader reader = offsetReaderFactory.apply(subscriptionPartition)) {\n+      Offset offset = reader.read();\n+      return new OffsetRange(offset.value(), Long.MAX_VALUE /* open interval */);\n+    }\n+  }\n+\n+  @NewTracker\n+  public RestrictionTracker<OffsetRange, OffsetByteProgress> newTracker(\n+      @Element SubscriptionPartition subscriptionPartition, @Restriction OffsetRange range) {\n+    return trackerFactory.apply(subscriptionPartition, range);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "88a30211fe9046969e36f6934dd00f971836ac4b"}, "originalPosition": 150}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQxNzEzMjYzOnYy", "diffSide": "RIGHT", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/SubscribeTransform.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQwMTowODoxMVrOIGnCXQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQwMTowODoxMVrOIGnCXQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzgwMTk0OQ==", "bodyText": "Can the PerPartitionSdf take the SubscriberOptions  as the constructor? Then the PerParittionSdf can construct  Committer, PartitionProcessor and InitialOffsetReader by itself, instead of asking the caller to do so?", "url": "https://github.com/apache/beam/pull/13470#discussion_r543801949", "createdAt": "2020-12-16T01:08:11Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/SubscribeTransform.java", "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import static com.google.cloud.pubsublite.internal.ExtractStatus.toCanonical;\n+import static com.google.cloud.pubsublite.internal.UncheckedApiPreconditions.checkArgument;\n+\n+import com.google.api.gax.rpc.ApiException;\n+import com.google.cloud.pubsublite.Partition;\n+import com.google.cloud.pubsublite.internal.wire.Committer;\n+import com.google.cloud.pubsublite.internal.wire.Subscriber;\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import java.util.List;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.apache.beam.sdk.transforms.DoFn.OutputReceiver;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.Reshuffle;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Stopwatch;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.math.LongMath;\n+import org.joda.time.Duration;\n+\n+class SubscribeTransform extends PTransform<PBegin, PCollection<SequencedMessage>> {\n+  private static final Duration MAX_SLEEP_TIME = Duration.standardMinutes(1);\n+\n+  private final SubscriberOptions options;\n+\n+  SubscribeTransform(SubscriberOptions options) {\n+    this.options = options;\n+  }\n+\n+  private void checkSubscription(SubscriptionPartition subscriptionPartition) throws ApiException {\n+    checkArgument(subscriptionPartition.subscription().equals(options.subscriptionPath()));\n+  }\n+\n+  private Subscriber newSubscriber(Partition partition, Consumer<List<SequencedMessage>> consumer) {\n+    try {\n+      return options\n+          .getSubscriberFactory(partition)\n+          .newSubscriber(\n+              messages ->\n+                  consumer.accept(\n+                      messages.stream()\n+                          .map(message -> message.toProto())\n+                          .collect(Collectors.toList())));\n+    } catch (Throwable t) {\n+      throw toCanonical(t).underlying;\n+    }\n+  }\n+\n+  private PartitionProcessor newPartitionProcessor(\n+      SubscriptionPartition subscriptionPartition,\n+      RestrictionTracker<OffsetRange, OffsetByteProgress> tracker,\n+      OutputReceiver<SequencedMessage> receiver)\n+      throws ApiException {\n+    checkSubscription(subscriptionPartition);\n+    return new PartitionProcessorImpl(\n+        tracker,\n+        receiver,\n+        consumer -> newSubscriber(subscriptionPartition.partition(), consumer),\n+        options.flowControlSettings());\n+  }\n+\n+  private RestrictionTracker<OffsetRange, OffsetByteProgress> newRestrictionTracker(\n+      SubscriptionPartition subscriptionPartition, OffsetRange initial) {\n+    checkSubscription(subscriptionPartition);\n+    return new OffsetByteRangeTracker(\n+        initial,\n+        options.getBacklogReader(subscriptionPartition.partition()),\n+        Stopwatch.createUnstarted(),\n+        MAX_SLEEP_TIME.multipliedBy(3).dividedBy(4),\n+        LongMath.saturatedMultiply(options.flowControlSettings().bytesOutstanding(), 10));\n+  }\n+\n+  private InitialOffsetReader newInitialOffsetReader(SubscriptionPartition subscriptionPartition) {\n+    checkSubscription(subscriptionPartition);\n+    return options.getInitialOffsetReader(subscriptionPartition.partition());\n+  }\n+\n+  private Committer newCommitter(SubscriptionPartition subscriptionPartition) {\n+    checkSubscription(subscriptionPartition);\n+    return options.getCommitter(subscriptionPartition.partition());\n+  }\n+\n+  @Override\n+  public PCollection<SequencedMessage> expand(PBegin input) {\n+    PCollection<SubscriptionPartition> partitions =\n+        Create.of(\n+                options.partitions().stream()\n+                    .map(\n+                        partition ->\n+                            SubscriptionPartition.of(options.subscriptionPath(), partition))\n+                    .collect(Collectors.toList()))\n+            .expand(input);\n+    // Prevent fusion between Create and read.\n+    PCollection<SubscriptionPartition> shuffledPartitions =\n+        partitions.apply(Reshuffle.viaRandomKey());\n+    return shuffledPartitions.apply(\n+        ParDo.of(\n+            new PerPartitionSdf(\n+                MAX_SLEEP_TIME,\n+                this::newInitialOffsetReader,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "88a30211fe9046969e36f6934dd00f971836ac4b"}, "originalPosition": 123}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQxNzEzNjg0OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/SubscriptionPartitionCoder.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQwMTowOTo0OVrOIGnEmw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQwMTowOTo0OVrOIGnEmw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzgwMjUyMw==", "bodyText": "Have you consider the x-lang usage, where you may want to use Schema to represent your element?", "url": "https://github.com/apache/beam/pull/13470#discussion_r543802523", "createdAt": "2020-12-16T01:09:49Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/SubscriptionPartitionCoder.java", "diffHunk": "@@ -0,0 +1,66 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import com.google.cloud.pubsublite.Partition;\n+import com.google.cloud.pubsublite.SubscriptionPath;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.OutputStream;\n+import org.apache.beam.sdk.coders.AtomicCoder;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.coders.CoderProvider;\n+import org.apache.beam.sdk.coders.CoderProviders;\n+import org.apache.beam.sdk.coders.DelegateCoder;\n+import org.apache.beam.sdk.coders.KvCoder;\n+import org.apache.beam.sdk.coders.StringUtf8Coder;\n+import org.apache.beam.sdk.coders.VarLongCoder;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.TypeDescriptor;\n+\n+public class SubscriptionPartitionCoder extends AtomicCoder<SubscriptionPartition> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "88a30211fe9046969e36f6934dd00f971836ac4b"}, "originalPosition": 36}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQxNzE0NDE3OnYy", "diffSide": "RIGHT", "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/SubscribeTransform.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQwMToxMjoyMVrOIGnIfQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNlQwMToxMjoyMVrOIGnIfQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MzgwMzUxNw==", "bodyText": "Why not put the whole logic into PubSubLiteIO?", "url": "https://github.com/apache/beam/pull/13470#discussion_r543803517", "createdAt": "2020-12-16T01:12:21Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsublite/SubscribeTransform.java", "diffHunk": "@@ -0,0 +1,128 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsublite;\n+\n+import static com.google.cloud.pubsublite.internal.ExtractStatus.toCanonical;\n+import static com.google.cloud.pubsublite.internal.UncheckedApiPreconditions.checkArgument;\n+\n+import com.google.api.gax.rpc.ApiException;\n+import com.google.cloud.pubsublite.Partition;\n+import com.google.cloud.pubsublite.internal.wire.Committer;\n+import com.google.cloud.pubsublite.internal.wire.Subscriber;\n+import com.google.cloud.pubsublite.proto.SequencedMessage;\n+import java.util.List;\n+import java.util.function.Consumer;\n+import java.util.stream.Collectors;\n+import org.apache.beam.sdk.io.range.OffsetRange;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.apache.beam.sdk.transforms.DoFn.OutputReceiver;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.transforms.Reshuffle;\n+import org.apache.beam.sdk.transforms.splittabledofn.RestrictionTracker;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Stopwatch;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.math.LongMath;\n+import org.joda.time.Duration;\n+\n+class SubscribeTransform extends PTransform<PBegin, PCollection<SequencedMessage>> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "88a30211fe9046969e36f6934dd00f971836ac4b"}, "originalPosition": 44}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2488, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}