{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDk1ODY1MzY0", "number": 12982, "reviewThreads": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QyMTowODowMFrOErW6VQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QyMzoxMDo0OVrOErY7eA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzODk5NjA1OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/frames.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QyMTowODowMFrOHeFlTw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOVQwNTozMjo0N1rOHe7uhw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTMxMDc5OQ==", "bodyText": "nit: consider defining a variable for delta to make this easier to relate to the formula in https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Parallel_algorithm", "url": "https://github.com/apache/beam/pull/12982#discussion_r501310799", "createdAt": "2020-10-07T21:08:00Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/frames.py", "diffHunk": "@@ -34,6 +36,124 @@ def __array__(self, dtype=None):\n \n   between = frame_base._elementwise_method('between')\n \n+  @frame_base.args_to_kwargs(pd.Series)\n+  @frame_base.populate_defaults(pd.Series)\n+  def std(self, axis, skipna, level, ddof, **kwargs):\n+    if level is not None:\n+      raise NotImplementedError(\"per-level aggregation\")\n+    if skipna:\n+      self = self.dropna()\n+\n+    # See the online, numerically stable formulae at\n+    # https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance\n+    def compute_moments(x):\n+      n = len(x)\n+      m = x.std(ddof=0)**2 * n\n+      s = x.sum()\n+      return pd.DataFrame(dict(m=[m], s=[s], n=[n]))\n+\n+    def combine_moments(data):\n+      m = s = n = 0.0\n+      for datum in data.itertuples():\n+        if datum.n == 0:\n+          continue\n+        elif n == 0:\n+          m, s, n = datum.m, datum.s, datum.n\n+        else:\n+          m += datum.m + (s / n - datum.s / datum.n)**2 * n * datum.n / (", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "322b4ce3a4c2909e673704aebbe0aa964efaf417"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjE5Nzg5NQ==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/12982#discussion_r502197895", "createdAt": "2020-10-09T05:32:47Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/frames.py", "diffHunk": "@@ -34,6 +36,124 @@ def __array__(self, dtype=None):\n \n   between = frame_base._elementwise_method('between')\n \n+  @frame_base.args_to_kwargs(pd.Series)\n+  @frame_base.populate_defaults(pd.Series)\n+  def std(self, axis, skipna, level, ddof, **kwargs):\n+    if level is not None:\n+      raise NotImplementedError(\"per-level aggregation\")\n+    if skipna:\n+      self = self.dropna()\n+\n+    # See the online, numerically stable formulae at\n+    # https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance\n+    def compute_moments(x):\n+      n = len(x)\n+      m = x.std(ddof=0)**2 * n\n+      s = x.sum()\n+      return pd.DataFrame(dict(m=[m], s=[s], n=[n]))\n+\n+    def combine_moments(data):\n+      m = s = n = 0.0\n+      for datum in data.itertuples():\n+        if datum.n == 0:\n+          continue\n+        elif n == 0:\n+          m, s, n = datum.m, datum.s, datum.n\n+        else:\n+          m += datum.m + (s / n - datum.s / datum.n)**2 * n * datum.n / (", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTMxMDc5OQ=="}, "originalCommit": {"oid": "322b4ce3a4c2909e673704aebbe0aa964efaf417"}, "originalPosition": 37}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzOTAyNDE3OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/frames.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QyMToxNzoyMFrOHeF2_A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOVQwNTozMDoxMVrOHe7r9g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTMxNTMyNA==", "bodyText": "Can this link directly to https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Parallel_algorithm and/or https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Welford's_online_algorithm?", "url": "https://github.com/apache/beam/pull/12982#discussion_r501315324", "createdAt": "2020-10-07T21:17:20Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/frames.py", "diffHunk": "@@ -34,6 +36,124 @@ def __array__(self, dtype=None):\n \n   between = frame_base._elementwise_method('between')\n \n+  @frame_base.args_to_kwargs(pd.Series)\n+  @frame_base.populate_defaults(pd.Series)\n+  def std(self, axis, skipna, level, ddof, **kwargs):\n+    if level is not None:\n+      raise NotImplementedError(\"per-level aggregation\")\n+    if skipna:\n+      self = self.dropna()\n+\n+    # See the online, numerically stable formulae at\n+    # https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "322b4ce3a4c2909e673704aebbe0aa964efaf417"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjE5NzIzOA==", "bodyText": "Done. Even if the subheading change, they're descriptive enough to identify what is meant.", "url": "https://github.com/apache/beam/pull/12982#discussion_r502197238", "createdAt": "2020-10-09T05:30:11Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/frames.py", "diffHunk": "@@ -34,6 +36,124 @@ def __array__(self, dtype=None):\n \n   between = frame_base._elementwise_method('between')\n \n+  @frame_base.args_to_kwargs(pd.Series)\n+  @frame_base.populate_defaults(pd.Series)\n+  def std(self, axis, skipna, level, ddof, **kwargs):\n+    if level is not None:\n+      raise NotImplementedError(\"per-level aggregation\")\n+    if skipna:\n+      self = self.dropna()\n+\n+    # See the online, numerically stable formulae at\n+    # https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTMxNTMyNA=="}, "originalCommit": {"oid": "322b4ce3a4c2909e673704aebbe0aa964efaf417"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzOTA2NjQ4OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/frames.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QyMTozMToyN1rOHeGQag==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QyMjozNTozMFrOHeH4og==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTMyMTgzNA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                          other: df.corr(other, method=method, DataFrame=min_periods)[\n          \n          \n            \n                          other: df.corr(other, method=method, min_periods=min_periods)[", "url": "https://github.com/apache/beam/pull/12982#discussion_r501321834", "createdAt": "2020-10-07T21:31:27Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/frames.py", "diffHunk": "@@ -34,6 +36,124 @@ def __array__(self, dtype=None):\n \n   between = frame_base._elementwise_method('between')\n \n+  @frame_base.args_to_kwargs(pd.Series)\n+  @frame_base.populate_defaults(pd.Series)\n+  def std(self, axis, skipna, level, ddof, **kwargs):\n+    if level is not None:\n+      raise NotImplementedError(\"per-level aggregation\")\n+    if skipna:\n+      self = self.dropna()\n+\n+    # See the online, numerically stable formulae at\n+    # https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance\n+    def compute_moments(x):\n+      n = len(x)\n+      m = x.std(ddof=0)**2 * n\n+      s = x.sum()\n+      return pd.DataFrame(dict(m=[m], s=[s], n=[n]))\n+\n+    def combine_moments(data):\n+      m = s = n = 0.0\n+      for datum in data.itertuples():\n+        if datum.n == 0:\n+          continue\n+        elif n == 0:\n+          m, s, n = datum.m, datum.s, datum.n\n+        else:\n+          m += datum.m + (s / n - datum.s / datum.n)**2 * n * datum.n / (\n+              n + datum.n)\n+          s += datum.s\n+          n += datum.n\n+      if n <= ddof:\n+        return float('nan')\n+      else:\n+        return math.sqrt(m / (n - ddof))\n+\n+    moments = expressions.ComputedExpression(\n+        'compute_moments',\n+        compute_moments, [self._expr],\n+        requires_partition_by=partitionings.Nothing())\n+    with expressions.allow_non_parallel_operations(True):\n+      return frame_base.DeferredFrame.wrap(\n+          expressions.ComputedExpression(\n+              'combine_moments',\n+              combine_moments, [moments],\n+              requires_partition_by=partitionings.Singleton()))\n+\n+  @frame_base.args_to_kwargs(pd.Series)\n+  @frame_base.populate_defaults(pd.Series)\n+  def corr(self, other, method, min_periods):\n+    if method == 'pearson':  # Note that this is the default.\n+      x = self.dropna()\n+      y = other.dropna()\n+\n+      # Do this first to filter to the entries that are present on both sides.\n+      def join(x, y):\n+        return pd.concat([x, y], axis=1, join='inner').rename(\n+            lambda c: 'xy'[c], axis=1)\n+\n+      # Use the formulae from\n+      # https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Covariance\n+      def compute_co_moments(x, y):\n+        n = len(x)\n+        if n <= 1:\n+          c = 0\n+        else:\n+          c = x.corr(y) * x.std() * y.std() * (n - 1)\n+        sx = x.sum()\n+        sy = y.sum()\n+        return pd.DataFrame(dict(c=[c], sx=[sx], sy=[sy], n=[n]))\n+\n+      def combine_co_moments(data, std_x, std_y):\n+        c = sx = sy = n = 0.0\n+        for datum in data.itertuples():\n+          if datum.n == 0:\n+            continue\n+          elif n == 0:\n+            c, sx, sy, n = datum.c, datum.sx, datum.sy, datum.n\n+          else:\n+            c += (\n+                datum.c + (sx / n - datum.sx / datum.n) *\n+                (sy / n - datum.sy / datum.n) * n * datum.n / (n + datum.n))\n+            sx += datum.sx\n+            sy += datum.sy\n+            n += datum.n\n+        if n < max(2, min_periods or 0):\n+          return float('nan')\n+        else:\n+          return c / (n - 1) / std_x / std_y\n+\n+      joined = frame_base.DeferredFrame.wrap(\n+          expressions.ComputedExpression(\n+              'join',\n+              join, [x._expr, y._expr],\n+              requires_partition_by=partitionings.Index()))\n+      std_x = joined.x.std()\n+      std_y = joined.y.std()\n+\n+      moments = expressions.ComputedExpression(\n+          'compute_co_moments',\n+          compute_co_moments, [joined.x._expr, joined.y._expr])\n+\n+      with expressions.allow_non_parallel_operations(True):\n+        return frame_base.DeferredFrame.wrap(\n+            expressions.ComputedExpression(\n+                'comnine_co_moments',\n+                combine_co_moments, [moments, std_x._expr, std_y._expr],\n+                requires_partition_by=partitionings.Singleton()))\n+\n+    else:\n+      # The rank-based correlations are not obviously parallelizable, though\n+      # perhaps an approximation could be done with a knowledge of quantiles\n+      # and custom partitioning.\n+      return frame_base.DeferredFrame.wrap(\n+          expressions.ComputedExpression(\n+              'corr',\n+              lambda df,\n+              other: df.corr(other, method=method, DataFrame=min_periods)[", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "322b4ce3a4c2909e673704aebbe0aa964efaf417"}, "originalPosition": 127}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTM0ODUxNA==", "bodyText": "Nevermind looks like you corrected this later", "url": "https://github.com/apache/beam/pull/12982#discussion_r501348514", "createdAt": "2020-10-07T22:35:30Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/frames.py", "diffHunk": "@@ -34,6 +36,124 @@ def __array__(self, dtype=None):\n \n   between = frame_base._elementwise_method('between')\n \n+  @frame_base.args_to_kwargs(pd.Series)\n+  @frame_base.populate_defaults(pd.Series)\n+  def std(self, axis, skipna, level, ddof, **kwargs):\n+    if level is not None:\n+      raise NotImplementedError(\"per-level aggregation\")\n+    if skipna:\n+      self = self.dropna()\n+\n+    # See the online, numerically stable formulae at\n+    # https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance\n+    def compute_moments(x):\n+      n = len(x)\n+      m = x.std(ddof=0)**2 * n\n+      s = x.sum()\n+      return pd.DataFrame(dict(m=[m], s=[s], n=[n]))\n+\n+    def combine_moments(data):\n+      m = s = n = 0.0\n+      for datum in data.itertuples():\n+        if datum.n == 0:\n+          continue\n+        elif n == 0:\n+          m, s, n = datum.m, datum.s, datum.n\n+        else:\n+          m += datum.m + (s / n - datum.s / datum.n)**2 * n * datum.n / (\n+              n + datum.n)\n+          s += datum.s\n+          n += datum.n\n+      if n <= ddof:\n+        return float('nan')\n+      else:\n+        return math.sqrt(m / (n - ddof))\n+\n+    moments = expressions.ComputedExpression(\n+        'compute_moments',\n+        compute_moments, [self._expr],\n+        requires_partition_by=partitionings.Nothing())\n+    with expressions.allow_non_parallel_operations(True):\n+      return frame_base.DeferredFrame.wrap(\n+          expressions.ComputedExpression(\n+              'combine_moments',\n+              combine_moments, [moments],\n+              requires_partition_by=partitionings.Singleton()))\n+\n+  @frame_base.args_to_kwargs(pd.Series)\n+  @frame_base.populate_defaults(pd.Series)\n+  def corr(self, other, method, min_periods):\n+    if method == 'pearson':  # Note that this is the default.\n+      x = self.dropna()\n+      y = other.dropna()\n+\n+      # Do this first to filter to the entries that are present on both sides.\n+      def join(x, y):\n+        return pd.concat([x, y], axis=1, join='inner').rename(\n+            lambda c: 'xy'[c], axis=1)\n+\n+      # Use the formulae from\n+      # https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Covariance\n+      def compute_co_moments(x, y):\n+        n = len(x)\n+        if n <= 1:\n+          c = 0\n+        else:\n+          c = x.corr(y) * x.std() * y.std() * (n - 1)\n+        sx = x.sum()\n+        sy = y.sum()\n+        return pd.DataFrame(dict(c=[c], sx=[sx], sy=[sy], n=[n]))\n+\n+      def combine_co_moments(data, std_x, std_y):\n+        c = sx = sy = n = 0.0\n+        for datum in data.itertuples():\n+          if datum.n == 0:\n+            continue\n+          elif n == 0:\n+            c, sx, sy, n = datum.c, datum.sx, datum.sy, datum.n\n+          else:\n+            c += (\n+                datum.c + (sx / n - datum.sx / datum.n) *\n+                (sy / n - datum.sy / datum.n) * n * datum.n / (n + datum.n))\n+            sx += datum.sx\n+            sy += datum.sy\n+            n += datum.n\n+        if n < max(2, min_periods or 0):\n+          return float('nan')\n+        else:\n+          return c / (n - 1) / std_x / std_y\n+\n+      joined = frame_base.DeferredFrame.wrap(\n+          expressions.ComputedExpression(\n+              'join',\n+              join, [x._expr, y._expr],\n+              requires_partition_by=partitionings.Index()))\n+      std_x = joined.x.std()\n+      std_y = joined.y.std()\n+\n+      moments = expressions.ComputedExpression(\n+          'compute_co_moments',\n+          compute_co_moments, [joined.x._expr, joined.y._expr])\n+\n+      with expressions.allow_non_parallel_operations(True):\n+        return frame_base.DeferredFrame.wrap(\n+            expressions.ComputedExpression(\n+                'comnine_co_moments',\n+                combine_co_moments, [moments, std_x._expr, std_y._expr],\n+                requires_partition_by=partitionings.Singleton()))\n+\n+    else:\n+      # The rank-based correlations are not obviously parallelizable, though\n+      # perhaps an approximation could be done with a knowledge of quantiles\n+      # and custom partitioning.\n+      return frame_base.DeferredFrame.wrap(\n+          expressions.ComputedExpression(\n+              'corr',\n+              lambda df,\n+              other: df.corr(other, method=method, DataFrame=min_periods)[", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTMyMTgzNA=="}, "originalCommit": {"oid": "322b4ce3a4c2909e673704aebbe0aa964efaf417"}, "originalPosition": 127}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzOTE1NTcyOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/frames.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QyMjowMjoxN1rOHeHE5g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QyMzoxNjoyN1rOHeIv_g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTMzNTI3MA==", "bodyText": "It would help to be more specific here, I spent a while trying to find references. It looks like combine_co_moments  is the formula for combining covariance from two sets hidden at the bottom of the Online Covariance section.\nThe other critical piece is the translation between co-moment and pearson correlation coefficient. Is there something we can reference for that? It seems to follow from the last definition here. IIUC the co-moment is the numerator in that definition, and that fits with your code.", "url": "https://github.com/apache/beam/pull/12982#discussion_r501335270", "createdAt": "2020-10-07T22:02:17Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/frames.py", "diffHunk": "@@ -34,6 +36,124 @@ def __array__(self, dtype=None):\n \n   between = frame_base._elementwise_method('between')\n \n+  @frame_base.args_to_kwargs(pd.Series)\n+  @frame_base.populate_defaults(pd.Series)\n+  def std(self, axis, skipna, level, ddof, **kwargs):\n+    if level is not None:\n+      raise NotImplementedError(\"per-level aggregation\")\n+    if skipna:\n+      self = self.dropna()\n+\n+    # See the online, numerically stable formulae at\n+    # https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance\n+    def compute_moments(x):\n+      n = len(x)\n+      m = x.std(ddof=0)**2 * n\n+      s = x.sum()\n+      return pd.DataFrame(dict(m=[m], s=[s], n=[n]))\n+\n+    def combine_moments(data):\n+      m = s = n = 0.0\n+      for datum in data.itertuples():\n+        if datum.n == 0:\n+          continue\n+        elif n == 0:\n+          m, s, n = datum.m, datum.s, datum.n\n+        else:\n+          m += datum.m + (s / n - datum.s / datum.n)**2 * n * datum.n / (\n+              n + datum.n)\n+          s += datum.s\n+          n += datum.n\n+      if n <= ddof:\n+        return float('nan')\n+      else:\n+        return math.sqrt(m / (n - ddof))\n+\n+    moments = expressions.ComputedExpression(\n+        'compute_moments',\n+        compute_moments, [self._expr],\n+        requires_partition_by=partitionings.Nothing())\n+    with expressions.allow_non_parallel_operations(True):\n+      return frame_base.DeferredFrame.wrap(\n+          expressions.ComputedExpression(\n+              'combine_moments',\n+              combine_moments, [moments],\n+              requires_partition_by=partitionings.Singleton()))\n+\n+  @frame_base.args_to_kwargs(pd.Series)\n+  @frame_base.populate_defaults(pd.Series)\n+  def corr(self, other, method, min_periods):\n+    if method == 'pearson':  # Note that this is the default.\n+      x = self.dropna()\n+      y = other.dropna()\n+\n+      # Do this first to filter to the entries that are present on both sides.\n+      def join(x, y):\n+        return pd.concat([x, y], axis=1, join='inner').rename(\n+            lambda c: 'xy'[c], axis=1)\n+\n+      # Use the formulae from", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "322b4ce3a4c2909e673704aebbe0aa964efaf417"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTM2MjY4Ng==", "bodyText": "I think the reference to pearson correlation coefficient is no longer necessary after this was moved to _cov_aligned, which can be understood just from https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Online. It would still be helpful to be more specific here though.", "url": "https://github.com/apache/beam/pull/12982#discussion_r501362686", "createdAt": "2020-10-07T23:16:27Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/frames.py", "diffHunk": "@@ -34,6 +36,124 @@ def __array__(self, dtype=None):\n \n   between = frame_base._elementwise_method('between')\n \n+  @frame_base.args_to_kwargs(pd.Series)\n+  @frame_base.populate_defaults(pd.Series)\n+  def std(self, axis, skipna, level, ddof, **kwargs):\n+    if level is not None:\n+      raise NotImplementedError(\"per-level aggregation\")\n+    if skipna:\n+      self = self.dropna()\n+\n+    # See the online, numerically stable formulae at\n+    # https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance\n+    def compute_moments(x):\n+      n = len(x)\n+      m = x.std(ddof=0)**2 * n\n+      s = x.sum()\n+      return pd.DataFrame(dict(m=[m], s=[s], n=[n]))\n+\n+    def combine_moments(data):\n+      m = s = n = 0.0\n+      for datum in data.itertuples():\n+        if datum.n == 0:\n+          continue\n+        elif n == 0:\n+          m, s, n = datum.m, datum.s, datum.n\n+        else:\n+          m += datum.m + (s / n - datum.s / datum.n)**2 * n * datum.n / (\n+              n + datum.n)\n+          s += datum.s\n+          n += datum.n\n+      if n <= ddof:\n+        return float('nan')\n+      else:\n+        return math.sqrt(m / (n - ddof))\n+\n+    moments = expressions.ComputedExpression(\n+        'compute_moments',\n+        compute_moments, [self._expr],\n+        requires_partition_by=partitionings.Nothing())\n+    with expressions.allow_non_parallel_operations(True):\n+      return frame_base.DeferredFrame.wrap(\n+          expressions.ComputedExpression(\n+              'combine_moments',\n+              combine_moments, [moments],\n+              requires_partition_by=partitionings.Singleton()))\n+\n+  @frame_base.args_to_kwargs(pd.Series)\n+  @frame_base.populate_defaults(pd.Series)\n+  def corr(self, other, method, min_periods):\n+    if method == 'pearson':  # Note that this is the default.\n+      x = self.dropna()\n+      y = other.dropna()\n+\n+      # Do this first to filter to the entries that are present on both sides.\n+      def join(x, y):\n+        return pd.concat([x, y], axis=1, join='inner').rename(\n+            lambda c: 'xy'[c], axis=1)\n+\n+      # Use the formulae from", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTMzNTI3MA=="}, "originalCommit": {"oid": "322b4ce3a4c2909e673704aebbe0aa964efaf417"}, "originalPosition": 69}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzOTI2MDQ0OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/frames.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QyMjo0MjoxMlrOHeICXw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOVQwNTozMjo1NlrOHe7usg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTM1MTAwNw==", "bodyText": "nit: this could become x.cov(y) * (n-1) which makes this more easily relatable to the wiki link", "url": "https://github.com/apache/beam/pull/12982#discussion_r501351007", "createdAt": "2020-10-07T22:42:12Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/frames.py", "diffHunk": "@@ -150,8 +115,72 @@ def combine_co_moments(data, std_x, std_y):\n           expressions.ComputedExpression(\n               'corr',\n               lambda df,\n-              other: df.corr(other, method=method, DataFrame=min_periods)[\n-                  self._expr, other._expr],\n+              other: df.corr(other, method=method, min_periods=min_periods),\n+              [self._expr, other._expr],\n+              requires_partition_by=partitionings.Singleton()))\n+\n+  def _corr_aligned(self, other, method, min_periods):\n+    std_x = self.std()\n+    std_y = other.std()\n+    cov = self._cov_aligned(other, min_periods)\n+    with expressions.allow_non_parallel_operations(True):\n+      return frame_base.DeferredFrame.wrap(\n+          expressions.ComputedExpression(\n+              'normalize',\n+              lambda cov,\n+              std_x,\n+              std_y: cov / (std_x * std_y),\n+              [cov._expr, std_x._expr, std_y._expr],\n+              requires_partition_by=partitionings.Singleton()))\n+\n+  @frame_base.args_to_kwargs(pd.Series)\n+  @frame_base.populate_defaults(pd.Series)\n+  def cov(self, other, min_periods, ddof):\n+    x, y = self.dropna().align(other.dropna(), 'inner')\n+    return x._cov_aligned(y, min_periods, ddof)\n+\n+  def _cov_aligned(self, other, min_periods, ddof=1):\n+    # Use the formulae from\n+    # https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Covariance\n+    def compute_co_moments(x, y):\n+      n = len(x)\n+      if n <= 1:\n+        c = 0\n+      else:\n+        c = x.corr(y) * x.std() * y.std() * (n - 1)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f6ef962ad62f77bda8782b82498e3770bac45fa4"}, "originalPosition": 147}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjE5NzkzOA==", "bodyText": "Good point. Done.", "url": "https://github.com/apache/beam/pull/12982#discussion_r502197938", "createdAt": "2020-10-09T05:32:56Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/frames.py", "diffHunk": "@@ -150,8 +115,72 @@ def combine_co_moments(data, std_x, std_y):\n           expressions.ComputedExpression(\n               'corr',\n               lambda df,\n-              other: df.corr(other, method=method, DataFrame=min_periods)[\n-                  self._expr, other._expr],\n+              other: df.corr(other, method=method, min_periods=min_periods),\n+              [self._expr, other._expr],\n+              requires_partition_by=partitionings.Singleton()))\n+\n+  def _corr_aligned(self, other, method, min_periods):\n+    std_x = self.std()\n+    std_y = other.std()\n+    cov = self._cov_aligned(other, min_periods)\n+    with expressions.allow_non_parallel_operations(True):\n+      return frame_base.DeferredFrame.wrap(\n+          expressions.ComputedExpression(\n+              'normalize',\n+              lambda cov,\n+              std_x,\n+              std_y: cov / (std_x * std_y),\n+              [cov._expr, std_x._expr, std_y._expr],\n+              requires_partition_by=partitionings.Singleton()))\n+\n+  @frame_base.args_to_kwargs(pd.Series)\n+  @frame_base.populate_defaults(pd.Series)\n+  def cov(self, other, min_periods, ddof):\n+    x, y = self.dropna().align(other.dropna(), 'inner')\n+    return x._cov_aligned(y, min_periods, ddof)\n+\n+  def _cov_aligned(self, other, min_periods, ddof=1):\n+    # Use the formulae from\n+    # https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Covariance\n+    def compute_co_moments(x, y):\n+      n = len(x)\n+      if n <= 1:\n+        c = 0\n+      else:\n+        c = x.corr(y) * x.std() * y.std() * (n - 1)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTM1MTAwNw=="}, "originalCommit": {"oid": "f6ef962ad62f77bda8782b82498e3770bac45fa4"}, "originalPosition": 147}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzOTI4MDI1OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/frames.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QyMjo0OTo1NlrOHeIOBw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOVQwNTozMzo1OVrOHe7vpw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTM1Mzk5MQ==", "bodyText": "Should this also check against ddof like std?", "url": "https://github.com/apache/beam/pull/12982#discussion_r501353991", "createdAt": "2020-10-07T22:49:56Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/frames.py", "diffHunk": "@@ -150,8 +115,72 @@ def combine_co_moments(data, std_x, std_y):\n           expressions.ComputedExpression(\n               'corr',\n               lambda df,\n-              other: df.corr(other, method=method, DataFrame=min_periods)[\n-                  self._expr, other._expr],\n+              other: df.corr(other, method=method, min_periods=min_periods),\n+              [self._expr, other._expr],\n+              requires_partition_by=partitionings.Singleton()))\n+\n+  def _corr_aligned(self, other, method, min_periods):\n+    std_x = self.std()\n+    std_y = other.std()\n+    cov = self._cov_aligned(other, min_periods)\n+    with expressions.allow_non_parallel_operations(True):\n+      return frame_base.DeferredFrame.wrap(\n+          expressions.ComputedExpression(\n+              'normalize',\n+              lambda cov,\n+              std_x,\n+              std_y: cov / (std_x * std_y),\n+              [cov._expr, std_x._expr, std_y._expr],\n+              requires_partition_by=partitionings.Singleton()))\n+\n+  @frame_base.args_to_kwargs(pd.Series)\n+  @frame_base.populate_defaults(pd.Series)\n+  def cov(self, other, min_periods, ddof):\n+    x, y = self.dropna().align(other.dropna(), 'inner')\n+    return x._cov_aligned(y, min_periods, ddof)\n+\n+  def _cov_aligned(self, other, min_periods, ddof=1):\n+    # Use the formulae from\n+    # https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Covariance\n+    def compute_co_moments(x, y):\n+      n = len(x)\n+      if n <= 1:\n+        c = 0\n+      else:\n+        c = x.corr(y) * x.std() * y.std() * (n - 1)\n+      sx = x.sum()\n+      sy = y.sum()\n+      return pd.DataFrame(dict(c=[c], sx=[sx], sy=[sy], n=[n]))\n+\n+    def combine_co_moments(data):\n+      c = sx = sy = n = 0.0\n+      for datum in data.itertuples():\n+        if datum.n == 0:\n+          continue\n+        elif n == 0:\n+          c, sx, sy, n = datum.c, datum.sx, datum.sy, datum.n\n+        else:\n+          c += (\n+              datum.c + (sx / n - datum.sx / datum.n) *\n+              (sy / n - datum.sy / datum.n) * n * datum.n / (n + datum.n))\n+          sx += datum.sx\n+          sy += datum.sy\n+          n += datum.n\n+      if n < max(2, min_periods or 0):\n+        return float('nan')", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f6ef962ad62f77bda8782b82498e3770bac45fa4"}, "originalPosition": 167}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjE5ODE4Mw==", "bodyText": "Yes. Done.", "url": "https://github.com/apache/beam/pull/12982#discussion_r502198183", "createdAt": "2020-10-09T05:33:59Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/frames.py", "diffHunk": "@@ -150,8 +115,72 @@ def combine_co_moments(data, std_x, std_y):\n           expressions.ComputedExpression(\n               'corr',\n               lambda df,\n-              other: df.corr(other, method=method, DataFrame=min_periods)[\n-                  self._expr, other._expr],\n+              other: df.corr(other, method=method, min_periods=min_periods),\n+              [self._expr, other._expr],\n+              requires_partition_by=partitionings.Singleton()))\n+\n+  def _corr_aligned(self, other, method, min_periods):\n+    std_x = self.std()\n+    std_y = other.std()\n+    cov = self._cov_aligned(other, min_periods)\n+    with expressions.allow_non_parallel_operations(True):\n+      return frame_base.DeferredFrame.wrap(\n+          expressions.ComputedExpression(\n+              'normalize',\n+              lambda cov,\n+              std_x,\n+              std_y: cov / (std_x * std_y),\n+              [cov._expr, std_x._expr, std_y._expr],\n+              requires_partition_by=partitionings.Singleton()))\n+\n+  @frame_base.args_to_kwargs(pd.Series)\n+  @frame_base.populate_defaults(pd.Series)\n+  def cov(self, other, min_periods, ddof):\n+    x, y = self.dropna().align(other.dropna(), 'inner')\n+    return x._cov_aligned(y, min_periods, ddof)\n+\n+  def _cov_aligned(self, other, min_periods, ddof=1):\n+    # Use the formulae from\n+    # https://en.wikipedia.org/wiki/Algorithms_for_calculating_variance#Covariance\n+    def compute_co_moments(x, y):\n+      n = len(x)\n+      if n <= 1:\n+        c = 0\n+      else:\n+        c = x.corr(y) * x.std() * y.std() * (n - 1)\n+      sx = x.sum()\n+      sy = y.sum()\n+      return pd.DataFrame(dict(c=[c], sx=[sx], sy=[sy], n=[n]))\n+\n+    def combine_co_moments(data):\n+      c = sx = sy = n = 0.0\n+      for datum in data.itertuples():\n+        if datum.n == 0:\n+          continue\n+        elif n == 0:\n+          c, sx, sy, n = datum.c, datum.sx, datum.sy, datum.n\n+        else:\n+          c += (\n+              datum.c + (sx / n - datum.sx / datum.n) *\n+              (sy / n - datum.sy / datum.n) * n * datum.n / (n + datum.n))\n+          sx += datum.sx\n+          sy += datum.sy\n+          n += datum.n\n+      if n < max(2, min_periods or 0):\n+        return float('nan')", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTM1Mzk5MQ=="}, "originalCommit": {"oid": "f6ef962ad62f77bda8782b82498e3770bac45fa4"}, "originalPosition": 167}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzOTMyNjY0OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/frames_test.py", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QyMzoxMDo0OVrOHeIpRQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wOVQwNTo0MDozMlrOHe72QQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTM2MDk2NQ==", "bodyText": "Why revert this?", "url": "https://github.com/apache/beam/pull/12982#discussion_r501360965", "createdAt": "2020-10-07T23:10:49Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/frames_test.py", "diffHunk": "@@ -36,7 +36,7 @@ def _run_test(self, func, *args):\n             expressions.ConstantExpression(arg, arg[0:0])) for arg in args\n     ]\n     expected = func(*args)\n-    actual = expressions.PartitioningSession({}).evaluate(\n+    actual = expressions.Session({}).evaluate(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bfa633a581f5efc5097c50f68dd0dac0d91d4449"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjE5ODMzOQ==", "bodyText": "Some of the other tests in this file were relying on the ordering.", "url": "https://github.com/apache/beam/pull/12982#discussion_r502198339", "createdAt": "2020-10-09T05:34:42Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/frames_test.py", "diffHunk": "@@ -36,7 +36,7 @@ def _run_test(self, func, *args):\n             expressions.ConstantExpression(arg, arg[0:0])) for arg in args\n     ]\n     expected = func(*args)\n-    actual = expressions.PartitioningSession({}).evaluate(\n+    actual = expressions.Session({}).evaluate(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTM2MDk2NQ=="}, "originalCommit": {"oid": "bfa633a581f5efc5097c50f68dd0dac0d91d4449"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMjE5OTg3Mw==", "bodyText": "I've made this an option, we can try to switch it in the future.", "url": "https://github.com/apache/beam/pull/12982#discussion_r502199873", "createdAt": "2020-10-09T05:40:32Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/frames_test.py", "diffHunk": "@@ -36,7 +36,7 @@ def _run_test(self, func, *args):\n             expressions.ConstantExpression(arg, arg[0:0])) for arg in args\n     ]\n     expected = func(*args)\n-    actual = expressions.PartitioningSession({}).evaluate(\n+    actual = expressions.Session({}).evaluate(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTM2MDk2NQ=="}, "originalCommit": {"oid": "bfa633a581f5efc5097c50f68dd0dac0d91d4449"}, "originalPosition": 5}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3072, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}