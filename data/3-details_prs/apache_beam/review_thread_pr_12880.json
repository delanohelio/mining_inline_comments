{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDg5ODExMzU2", "number": 12880, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMVQxNjoxMDoxN1rOElvT1g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMVQyMToyMjozOVrOEl2ASg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA4MDA3ODk0OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/dataflow/dataflow_runner.py", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMVQxNjoxMDoxN1rOHVYWFw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMVQxNjoxMDoxN1rOHVYWFw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjE4MTAxNQ==", "bodyText": "@CraigChambersG I was under the impression that this wasn't true and that Dataflow v2 handled this.", "url": "https://github.com/apache/beam/pull/12880#discussion_r492181015", "createdAt": "2020-09-21T16:10:17Z", "author": {"login": "lukecwik"}, "path": "sdks/python/apache_beam/runners/dataflow/dataflow_runner.py", "diffHunk": "@@ -430,6 +430,15 @@ def _check_for_unsupported_fnapi_features(self, pipeline_proto):\n                 components.coders[windowing_strategy.window_coder_id].spec.urn,\n                 windowing_strategy.window_fn.urn))\n \n+  def _adjust_types_for_dataflow(self, pipeline):\n+    # Dataflow runner requires a KV type for GBK inputs, hence we enforce that\n+    # here.\n+    pipeline.visit(self.group_by_key_input_visitor())\n+\n+    # Dataflow runner requires output type of the Flatten to be the same as the", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "23e6c0d74e364cf479721ea1d1bfacb9fcab1a53"}, "originalPosition": 9}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA4MTE2MTc2OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/dataflow/dataflow_runner.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMVQyMToxNzo1OFrOHViwcw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMVQyMjoyNjoxOVrOHVkiWw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjM1MTYwMw==", "bodyText": "Why do the type encodings not survive the round trip (pipeline -> proto -> pipeline)?", "url": "https://github.com/apache/beam/pull/12880#discussion_r492351603", "createdAt": "2020-09-21T21:17:58Z", "author": {"login": "lukecwik"}, "path": "sdks/python/apache_beam/runners/dataflow/dataflow_runner.py", "diffHunk": "@@ -488,12 +497,15 @@ def run_pipeline(self, pipeline, options):\n       # Cross language transform require using a pipeline object constructed\n       # from the full pipeline proto to make sure that expanded version of\n       # external transforms are reflected in the Pipeline job graph.\n+      # TODO(chamikara): remove following pipeline and pipeline proto recreation\n+      # after portable job submission path is fully in place.\n       from apache_beam import Pipeline\n       pipeline = Pipeline.from_runner_api(\n           self.proto_pipeline,\n           pipeline.runner,\n           options,\n           allow_proto_holders=True)\n+      self._adjust_types_for_dataflow(pipeline)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dfdda4e66a30834a203d70b78a7633e5c355e1fb"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjM4MDc2Mw==", "bodyText": "Verified that types are preserved in the pipeline->proto->pipeline roundtrip and removed this.", "url": "https://github.com/apache/beam/pull/12880#discussion_r492380763", "createdAt": "2020-09-21T22:26:19Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/runners/dataflow/dataflow_runner.py", "diffHunk": "@@ -488,12 +497,15 @@ def run_pipeline(self, pipeline, options):\n       # Cross language transform require using a pipeline object constructed\n       # from the full pipeline proto to make sure that expanded version of\n       # external transforms are reflected in the Pipeline job graph.\n+      # TODO(chamikara): remove following pipeline and pipeline proto recreation\n+      # after portable job submission path is fully in place.\n       from apache_beam import Pipeline\n       pipeline = Pipeline.from_runner_api(\n           self.proto_pipeline,\n           pipeline.runner,\n           options,\n           allow_proto_holders=True)\n+      self._adjust_types_for_dataflow(pipeline)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjM1MTYwMw=="}, "originalCommit": {"oid": "dfdda4e66a30834a203d70b78a7633e5c355e1fb"}, "originalPosition": 35}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA4MTE3NTc4OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/dataflow/dataflow_runner.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMVQyMToyMjozOVrOHVi47g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMVQyMjoyNToyMlrOHVkhFw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjM1Mzc3NA==", "bodyText": "_adjust_pipeline_for_dataflow_v2?", "url": "https://github.com/apache/beam/pull/12880#discussion_r492353774", "createdAt": "2020-09-21T21:22:39Z", "author": {"login": "lukecwik"}, "path": "sdks/python/apache_beam/runners/dataflow/dataflow_runner.py", "diffHunk": "@@ -430,6 +430,11 @@ def _check_for_unsupported_fnapi_features(self, pipeline_proto):\n                 components.coders[windowing_strategy.window_coder_id].spec.urn,\n                 windowing_strategy.window_fn.urn))\n \n+  def _adjust_types_for_dataflow(self, pipeline):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "dfdda4e66a30834a203d70b78a7633e5c355e1fb"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjM4MDQzOQ==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/12880#discussion_r492380439", "createdAt": "2020-09-21T22:25:22Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/runners/dataflow/dataflow_runner.py", "diffHunk": "@@ -430,6 +430,11 @@ def _check_for_unsupported_fnapi_features(self, pipeline_proto):\n                 components.coders[windowing_strategy.window_coder_id].spec.urn,\n                 windowing_strategy.window_fn.urn))\n \n+  def _adjust_types_for_dataflow(self, pipeline):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjM1Mzc3NA=="}, "originalCommit": {"oid": "dfdda4e66a30834a203d70b78a7633e5c355e1fb"}, "originalPosition": 4}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3166, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}