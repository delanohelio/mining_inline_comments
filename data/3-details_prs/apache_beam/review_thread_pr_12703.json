{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDc0ODkwNDc0", "number": 12703, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQyMDowOToyMlrOEfpJeA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxMzoxOTozMFrOEhPVWA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAxNjE1NDgwOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/interactive/recording_manager.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQyMDowOToyMlrOHMC-iw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQyMDo0ODoyOFrOHMGJdA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjM5MzczOQ==", "bodyText": "You can use attempt_to_cancel_background_caching_job(user_pipeline) https://github.com/apache/beam/blob/master/sdks/python/apache_beam/runners/interactive/background_caching_job.py#L220", "url": "https://github.com/apache/beam/pull/12703#discussion_r482393739", "createdAt": "2020-09-02T20:09:22Z", "author": {"login": "KevinGG"}, "path": "sdks/python/apache_beam/runners/interactive/recording_manager.py", "diffHunk": "@@ -258,16 +278,46 @@ def _watch(self, pcolls):\n         ie.current_env().watch(\n             {'anonymous_pcollection_{}'.format(id(pcoll)): pcoll})\n \n-  def clear(self, pcolls):\n+  def _clear(self, pipeline_instrument):\n     # type: (List[beam.pvalue.PCollection]) -> None\n \n-    \"\"\"Clears the cache of the given PCollections.\"\"\"\n+    \"\"\"Clears the recording of all non-source PCollections.\"\"\"\n \n     cache_manager = ie.current_env().get_cache_manager(self.user_pipeline)\n-    for pc in pcolls:\n-      cache_key = self._pipeline_instrument.cache_key(pc)\n+\n+    # Only clear the PCollections that aren't being populated from the\n+    # BackgroundCachingJob.\n+    all_cached = set(\n+        str(c.to_key()) for c in pipeline_instrument.cacheables.values())\n+    source_pcolls = getattr(cache_manager, 'capture_keys', set())\n+    to_clear = all_cached - source_pcolls\n+\n+    for cache_key in to_clear:\n       cache_manager.clear('full', cache_key)\n \n+  def cancel(self):\n+    # type: (None) -> None\n+\n+    \"\"\"Cancels the current background recording job.\"\"\"\n+\n+    bcj = ie.current_env().get_background_caching_job(self.user_pipeline)\n+    if bcj:\n+      bcj.cancel()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a4dcca4a0aea106e54e8d41ce841a174a54398fe"}, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjQ0NTY4NA==", "bodyText": "Great, thanks!", "url": "https://github.com/apache/beam/pull/12703#discussion_r482445684", "createdAt": "2020-09-02T20:48:28Z", "author": {"login": "rohdesamuel"}, "path": "sdks/python/apache_beam/runners/interactive/recording_manager.py", "diffHunk": "@@ -258,16 +278,46 @@ def _watch(self, pcolls):\n         ie.current_env().watch(\n             {'anonymous_pcollection_{}'.format(id(pcoll)): pcoll})\n \n-  def clear(self, pcolls):\n+  def _clear(self, pipeline_instrument):\n     # type: (List[beam.pvalue.PCollection]) -> None\n \n-    \"\"\"Clears the cache of the given PCollections.\"\"\"\n+    \"\"\"Clears the recording of all non-source PCollections.\"\"\"\n \n     cache_manager = ie.current_env().get_cache_manager(self.user_pipeline)\n-    for pc in pcolls:\n-      cache_key = self._pipeline_instrument.cache_key(pc)\n+\n+    # Only clear the PCollections that aren't being populated from the\n+    # BackgroundCachingJob.\n+    all_cached = set(\n+        str(c.to_key()) for c in pipeline_instrument.cacheables.values())\n+    source_pcolls = getattr(cache_manager, 'capture_keys', set())\n+    to_clear = all_cached - source_pcolls\n+\n+    for cache_key in to_clear:\n       cache_manager.clear('full', cache_key)\n \n+  def cancel(self):\n+    # type: (None) -> None\n+\n+    \"\"\"Cancels the current background recording job.\"\"\"\n+\n+    bcj = ie.current_env().get_background_caching_job(self.user_pipeline)\n+    if bcj:\n+      bcj.cancel()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjM5MzczOQ=="}, "originalCommit": {"oid": "a4dcca4a0aea106e54e8d41ce841a174a54398fe"}, "originalPosition": 103}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAxNjMwMjA0OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/interactive/recording_manager_test.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQyMDoyOToxN1rOHMElXQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQyMDo0OToxMlrOHMGNWA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjQyMDA2MQ==", "bodyText": "Are we still calling it BackgroundCachingJob?", "url": "https://github.com/apache/beam/pull/12703#discussion_r482420061", "createdAt": "2020-09-02T20:29:17Z", "author": {"login": "davidyan74"}, "path": "sdks/python/apache_beam/runners/interactive/recording_manager_test.py", "diffHunk": "@@ -288,18 +347,122 @@ def test_basic_wordcount(self):\n     # Create the recording objects. By calling `record` a new PipelineFragment\n     # is started to compute the given PCollections and cache to disk.\n     rm = RecordingManager(p)\n-    recording = rm.record([elems], max_n=3, max_duration_secs=500)\n-    stream = recording.stream(elems)\n-    recording.wait_until_finish()\n+    numbers_recording = rm.record([numbers], max_n=3, max_duration_secs=500)\n+    numbers_stream = numbers_recording.stream(numbers)\n+    numbers_recording.wait_until_finish()\n \n     # Once the pipeline fragment completes, we can read from the stream and know\n     # that all elements were written to cache.\n-    elems = list(stream.read())\n+    elems = list(numbers_stream.read())\n     expected_elems = [\n         WindowedValue(i, MIN_TIMESTAMP, [GlobalWindow()]) for i in range(3)\n     ]\n     self.assertListEqual(elems, expected_elems)\n \n+    # Make an extra recording and test the description.\n+    letters_recording = rm.record([letters], max_n=3, max_duration_secs=500)\n+    letters_recording.wait_until_finish()\n+\n+    self.assertEqual(\n+        rm.describe()['size'],\n+        numbers_recording.describe()['size'] +\n+        letters_recording.describe()['size'])\n+\n+    rm.cancel()\n+\n+  @unittest.skipIf(\n+      sys.version_info < (3, 6, 0),\n+      'This test requires at least Python 3.6 to work.')\n+  def test_cancel_stops_recording(self):\n+    # Add the TestStream so that it can be cached.\n+    ib.options.capturable_sources.add(TestStream)\n+\n+    p = beam.Pipeline(\n+        InteractiveRunner(), options=PipelineOptions(streaming=True))\n+    elems = (\n+        p\n+        | TestStream().advance_watermark_to(0).advance_processing_time(\n+            1).add_elements(list(range(10))).advance_processing_time(1))\n+    squares = elems | beam.Map(lambda x: x**2)\n+\n+    # Watch the local scope for Interactive Beam so that referenced PCollections\n+    # will be cached.\n+    ib.watch(locals())\n+\n+    # This is normally done in the interactive_utils when a transform is\n+    # applied but needs an IPython environment. So we manually run this here.\n+    ie.current_env().track_user_pipelines()\n+\n+    # Get the recording then the BackgroundCachingJob.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a4dcca4a0aea106e54e8d41ce841a174a54398fe"}, "originalPosition": 156}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjQ0NjY4MA==", "bodyText": "For the time being yes, but this will be changed later on.", "url": "https://github.com/apache/beam/pull/12703#discussion_r482446680", "createdAt": "2020-09-02T20:49:12Z", "author": {"login": "rohdesamuel"}, "path": "sdks/python/apache_beam/runners/interactive/recording_manager_test.py", "diffHunk": "@@ -288,18 +347,122 @@ def test_basic_wordcount(self):\n     # Create the recording objects. By calling `record` a new PipelineFragment\n     # is started to compute the given PCollections and cache to disk.\n     rm = RecordingManager(p)\n-    recording = rm.record([elems], max_n=3, max_duration_secs=500)\n-    stream = recording.stream(elems)\n-    recording.wait_until_finish()\n+    numbers_recording = rm.record([numbers], max_n=3, max_duration_secs=500)\n+    numbers_stream = numbers_recording.stream(numbers)\n+    numbers_recording.wait_until_finish()\n \n     # Once the pipeline fragment completes, we can read from the stream and know\n     # that all elements were written to cache.\n-    elems = list(stream.read())\n+    elems = list(numbers_stream.read())\n     expected_elems = [\n         WindowedValue(i, MIN_TIMESTAMP, [GlobalWindow()]) for i in range(3)\n     ]\n     self.assertListEqual(elems, expected_elems)\n \n+    # Make an extra recording and test the description.\n+    letters_recording = rm.record([letters], max_n=3, max_duration_secs=500)\n+    letters_recording.wait_until_finish()\n+\n+    self.assertEqual(\n+        rm.describe()['size'],\n+        numbers_recording.describe()['size'] +\n+        letters_recording.describe()['size'])\n+\n+    rm.cancel()\n+\n+  @unittest.skipIf(\n+      sys.version_info < (3, 6, 0),\n+      'This test requires at least Python 3.6 to work.')\n+  def test_cancel_stops_recording(self):\n+    # Add the TestStream so that it can be cached.\n+    ib.options.capturable_sources.add(TestStream)\n+\n+    p = beam.Pipeline(\n+        InteractiveRunner(), options=PipelineOptions(streaming=True))\n+    elems = (\n+        p\n+        | TestStream().advance_watermark_to(0).advance_processing_time(\n+            1).add_elements(list(range(10))).advance_processing_time(1))\n+    squares = elems | beam.Map(lambda x: x**2)\n+\n+    # Watch the local scope for Interactive Beam so that referenced PCollections\n+    # will be cached.\n+    ib.watch(locals())\n+\n+    # This is normally done in the interactive_utils when a transform is\n+    # applied but needs an IPython environment. So we manually run this here.\n+    ie.current_env().track_user_pipelines()\n+\n+    # Get the recording then the BackgroundCachingJob.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjQyMDA2MQ=="}, "originalCommit": {"oid": "a4dcca4a0aea106e54e8d41ce841a174a54398fe"}, "originalPosition": 156}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAxNzAyNzc0OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/interactive/recording_manager.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQyMjozMTowNlrOHMMLjA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxODoxNDoyOFrOHOoqRw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjU0NDUyNA==", "bodyText": "Generally doing this is not necessary. You can name the attribute self.cache_key, and users can access the attribute directly, unless there's a strong reason not to.", "url": "https://github.com/apache/beam/pull/12703#discussion_r482544524", "createdAt": "2020-09-02T22:31:06Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/runners/interactive/recording_manager.py", "diffHunk": "@@ -63,6 +63,12 @@ def var(self):\n     \"\"\"Returns the variable named that defined this PCollection.\"\"\"\n     return self._var\n \n+  def cache_key(self):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ab76559752bb27497d75fc44a614851d3b257ad6"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTEwODI5NQ==", "bodyText": "Gotcha, I turned this into a property. I wanted others to access the cache_key and var of the stream but without the ability for owners to modify the values.", "url": "https://github.com/apache/beam/pull/12703#discussion_r485108295", "createdAt": "2020-09-08T18:14:28Z", "author": {"login": "rohdesamuel"}, "path": "sdks/python/apache_beam/runners/interactive/recording_manager.py", "diffHunk": "@@ -63,6 +63,12 @@ def var(self):\n     \"\"\"Returns the variable named that defined this PCollection.\"\"\"\n     return self._var\n \n+  def cache_key(self):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjU0NDUyNA=="}, "originalCommit": {"oid": "ab76559752bb27497d75fc44a614851d3b257ad6"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAzMjg5Njg4OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/interactive/recording_manager.py", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxMzoxOTozMFrOHOcdsw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxNzoyOToyNVrOHOnL4A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDkwODQ2Nw==", "bodyText": "It's a little unsafe to use string representation as keys, no? Should CacheKey implement a hash method instead?", "url": "https://github.com/apache/beam/pull/12703#discussion_r484908467", "createdAt": "2020-09-08T13:19:30Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/runners/interactive/recording_manager.py", "diffHunk": "@@ -258,16 +278,44 @@ def _watch(self, pcolls):\n         ie.current_env().watch(\n             {'anonymous_pcollection_{}'.format(id(pcoll)): pcoll})\n \n-  def clear(self, pcolls):\n+  def _clear(self, pipeline_instrument):\n     # type: (List[beam.pvalue.PCollection]) -> None\n \n-    \"\"\"Clears the cache of the given PCollections.\"\"\"\n+    \"\"\"Clears the recording of all non-source PCollections.\"\"\"\n \n     cache_manager = ie.current_env().get_cache_manager(self.user_pipeline)\n-    for pc in pcolls:\n-      cache_key = self._pipeline_instrument.cache_key(pc)\n+\n+    # Only clear the PCollections that aren't being populated from the\n+    # BackgroundCachingJob.\n+    all_cached = set(\n+        str(c.to_key()) for c in pipeline_instrument.cacheables.values())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ab76559752bb27497d75fc44a614851d3b257ad6"}, "originalPosition": 89}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDkwOTg4NA==", "bodyText": "It seems that we're using the string representation everywhere, so it may represent a large change - and I see it;s a carefully written repr method, so it's not necessary for this PR.", "url": "https://github.com/apache/beam/pull/12703#discussion_r484909884", "createdAt": "2020-09-08T13:20:48Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/runners/interactive/recording_manager.py", "diffHunk": "@@ -258,16 +278,44 @@ def _watch(self, pcolls):\n         ie.current_env().watch(\n             {'anonymous_pcollection_{}'.format(id(pcoll)): pcoll})\n \n-  def clear(self, pcolls):\n+  def _clear(self, pipeline_instrument):\n     # type: (List[beam.pvalue.PCollection]) -> None\n \n-    \"\"\"Clears the cache of the given PCollections.\"\"\"\n+    \"\"\"Clears the recording of all non-source PCollections.\"\"\"\n \n     cache_manager = ie.current_env().get_cache_manager(self.user_pipeline)\n-    for pc in pcolls:\n-      cache_key = self._pipeline_instrument.cache_key(pc)\n+\n+    # Only clear the PCollections that aren't being populated from the\n+    # BackgroundCachingJob.\n+    all_cached = set(\n+        str(c.to_key()) for c in pipeline_instrument.cacheables.values())", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDkwODQ2Nw=="}, "originalCommit": {"oid": "ab76559752bb27497d75fc44a614851d3b257ad6"}, "originalPosition": 89}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA4NDEyOA==", "bodyText": "Gotcha, I can make a follow-up PR.", "url": "https://github.com/apache/beam/pull/12703#discussion_r485084128", "createdAt": "2020-09-08T17:29:25Z", "author": {"login": "rohdesamuel"}, "path": "sdks/python/apache_beam/runners/interactive/recording_manager.py", "diffHunk": "@@ -258,16 +278,44 @@ def _watch(self, pcolls):\n         ie.current_env().watch(\n             {'anonymous_pcollection_{}'.format(id(pcoll)): pcoll})\n \n-  def clear(self, pcolls):\n+  def _clear(self, pipeline_instrument):\n     # type: (List[beam.pvalue.PCollection]) -> None\n \n-    \"\"\"Clears the cache of the given PCollections.\"\"\"\n+    \"\"\"Clears the recording of all non-source PCollections.\"\"\"\n \n     cache_manager = ie.current_env().get_cache_manager(self.user_pipeline)\n-    for pc in pcolls:\n-      cache_key = self._pipeline_instrument.cache_key(pc)\n+\n+    # Only clear the PCollections that aren't being populated from the\n+    # BackgroundCachingJob.\n+    all_cached = set(\n+        str(c.to_key()) for c in pipeline_instrument.cacheables.values())", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDkwODQ2Nw=="}, "originalCommit": {"oid": "ab76559752bb27497d75fc44a614851d3b257ad6"}, "originalPosition": 89}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 366, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}