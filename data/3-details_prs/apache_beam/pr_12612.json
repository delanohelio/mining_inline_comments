{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDY5NTI1MDcx", "number": 12612, "title": "[BEAM-10675] Add Python GBK Load Tests for streaming on Dataflow ", "bodyText": "Add Python GBK Load Tests for streaming on Dataflow. Cases 1, 2, 4 and 5 are temporarily excluded because their execution time is too long.\n\nThank you for your contribution! Follow this checklist to help us incorporate your contribution quickly and easily:\n\n Choose reviewer(s) and mention them in a comment (R: @username).\n Format the pull request title like [BEAM-XXX] Fixes bug in ApproximateQuantiles, where you replace BEAM-XXX with the appropriate JIRA issue, if applicable. This will automatically link the pull request to the issue.\n Update CHANGES.md with noteworthy changes.\n If this contribution is large, please file an Apache Individual Contributor License Agreement.\n\nSee the Contributor Guide for more tips on how to make review process smoother.\nPost-Commit Tests Status (on master branch)\n\n\n\nLang\nSDK\nDataflow\nFlink\nSamza\nSpark\nTwister2\n\n\n\n\nGo\n\n---\n\n---\n\n---\n\n\nJava\n\n\n\n\n\n\n\n\nPython\n\n\n\n---\n\n---\n\n\nXLang\n\n---\n\n---\n\n---\n\n\n\nPre-Commit Tests Status (on master branch)\n\n\n\n---\nJava\nPython\nGo\nWebsite\n\n\n\n\nNon-portable\n\n \n\n\n\n\nPortable\n---\n\n---\n---\n\n\n\nSee .test-infra/jenkins/README for trigger phrase, status and link of all Jenkins jobs.\nGitHub Actions Tests Status (on master branch)\n\nSee CI.md for more information about GitHub Actions CI.", "createdAt": "2020-08-18T14:11:01Z", "url": "https://github.com/apache/beam/pull/12612", "merged": true, "mergeCommit": {"oid": "f675112bc6894a63b38f6a4ffd7eff985efaaa08"}, "closed": true, "closedAt": "2020-08-26T09:46:53Z", "author": {"login": "kamilwu"}, "timelineItems": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdAtbNagBqjM2NzQ1NTk1OTU=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdCd9dwAFqTQ3NDkyMDg5MQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e9c45101ca2d44b5b0c28d1d1e6e9ad647d0aa5d", "author": {"user": {"login": "kamilwu", "name": "Kamil Wasilewski"}}, "url": "https://github.com/apache/beam/commit/e9c45101ca2d44b5b0c28d1d1e6e9ad647d0aa5d", "committedDate": "2020-08-18T14:03:11Z", "message": "[BEAM-10675] Python GBK load test: add streaming job"}, "afterCommit": {"oid": "f67712b477f811e2fe61f5c816b58e1268db2e13", "author": {"user": {"login": "kamilwu", "name": "Kamil Wasilewski"}}, "url": "https://github.com/apache/beam/commit/f67712b477f811e2fe61f5c816b58e1268db2e13", "committedDate": "2020-08-20T10:02:13Z", "message": "[BEAM-10675] Python GBK load test: add streaming job"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDcyNjY0MjA3", "url": "https://github.com/apache/beam/pull/12612#pullrequestreview-472664207", "createdAt": "2020-08-21T17:25:26Z", "commit": {"oid": "f67712b477f811e2fe61f5c816b58e1268db2e13"}, "state": "APPROVED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxNzoyNToyNlrOHE1Vbg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxNzozNTowOVrOHE1ngA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDgzMDE5MA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    job_name             : 'load-tests-python-dataflow-${mode}-gbk-2-' + now,\n          \n          \n            \n                    job_name             : \"load-tests-python-dataflow-${mode}-gbk-2-${now}\",", "url": "https://github.com/apache/beam/pull/12612#discussion_r474830190", "createdAt": "2020-08-21T17:25:26Z", "author": {"login": "tysonjh"}, "path": ".test-infra/jenkins/job_LoadTests_GBK_Python.groovy", "diffHunk": "@@ -22,119 +22,138 @@ import InfluxDBCredentialsHelper\n \n def now = new Date().format(\"MMddHHmmss\", TimeZone.getTimeZone('UTC'))\n \n-def loadTestConfigurations = { datasetName ->\n+// TODO(BEAM-10774): Skipping some cases because they are too slow.\n+def STREAMING_TESTS_TO_SKIP = [1, 2, 4, 5]\n+\n+def loadTestConfigurations = { mode, datasetName ->\n   [\n     [\n       title          : 'GroupByKey Python Load test: 2GB of 10B records',\n       test           : 'apache_beam.testing.load_tests.group_by_key_test',\n       runner         : CommonTestProperties.Runner.DATAFLOW,\n       pipelineOptions: [\n-        job_name             : 'load-tests-python-dataflow-batch-gbk-1-' + now,\n+        job_name             : \"load-tests-python-dataflow-${mode}-gbk-1-${now}\",\n         project              : 'apache-beam-testing',\n         region               : 'us-central1',\n         temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n         publish_to_big_query : true,\n         metrics_dataset      : datasetName,\n-        metrics_table        : 'python_dataflow_batch_gbk_1',\n-        influx_measurement   : 'python_batch_gbk_1',\n+        metrics_table        : \"python_dataflow_${mode}_gbk_1\",\n+        influx_measurement   : \"python_${mode}_gbk_1\",\n         input_options        : '\\'{\"num_records\": 200000000,' +\n         '\"key_size\": 1,' +\n         '\"value_size\": 9}\\'',\n         iterations           : 1,\n         fanout               : 1,\n         num_workers          : 5,\n-        autoscaling_algorithm: \"NONE\"\n+        autoscaling_algorithm: 'NONE',\n       ]\n     ],\n     [\n       title          : 'GroupByKey Python Load test: 2GB of 100B records',\n       test           : 'apache_beam.testing.load_tests.group_by_key_test',\n       runner         : CommonTestProperties.Runner.DATAFLOW,\n       pipelineOptions: [\n-        job_name             : 'load-tests-python-dataflow-batch-gbk-2-' + now,\n+        job_name             : 'load-tests-python-dataflow-${mode}-gbk-2-' + now,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f67712b477f811e2fe61f5c816b58e1268db2e13"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDgzMzgwNg==", "bodyText": "Can you add a comment to explain what these settings are? It's unexpected to see that 'streaming: null' or 'enable_streaming_engine: null' somehow enables streaming, or why 'use_runner_v2' is required.", "url": "https://github.com/apache/beam/pull/12612#discussion_r474833806", "createdAt": "2020-08-21T17:33:10Z", "author": {"login": "tysonjh"}, "path": ".test-infra/jenkins/job_LoadTests_GBK_Python.groovy", "diffHunk": "@@ -22,119 +22,138 @@ import InfluxDBCredentialsHelper\n \n def now = new Date().format(\"MMddHHmmss\", TimeZone.getTimeZone('UTC'))\n \n-def loadTestConfigurations = { datasetName ->\n+// TODO(BEAM-10774): Skipping some cases because they are too slow.\n+def STREAMING_TESTS_TO_SKIP = [1, 2, 4, 5]\n+\n+def loadTestConfigurations = { mode, datasetName ->\n   [\n     [\n       title          : 'GroupByKey Python Load test: 2GB of 10B records',\n       test           : 'apache_beam.testing.load_tests.group_by_key_test',\n       runner         : CommonTestProperties.Runner.DATAFLOW,\n       pipelineOptions: [\n-        job_name             : 'load-tests-python-dataflow-batch-gbk-1-' + now,\n+        job_name             : \"load-tests-python-dataflow-${mode}-gbk-1-${now}\",\n         project              : 'apache-beam-testing',\n         region               : 'us-central1',\n         temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n         publish_to_big_query : true,\n         metrics_dataset      : datasetName,\n-        metrics_table        : 'python_dataflow_batch_gbk_1',\n-        influx_measurement   : 'python_batch_gbk_1',\n+        metrics_table        : \"python_dataflow_${mode}_gbk_1\",\n+        influx_measurement   : \"python_${mode}_gbk_1\",\n         input_options        : '\\'{\"num_records\": 200000000,' +\n         '\"key_size\": 1,' +\n         '\"value_size\": 9}\\'',\n         iterations           : 1,\n         fanout               : 1,\n         num_workers          : 5,\n-        autoscaling_algorithm: \"NONE\"\n+        autoscaling_algorithm: 'NONE',\n       ]\n     ],\n     [\n       title          : 'GroupByKey Python Load test: 2GB of 100B records',\n       test           : 'apache_beam.testing.load_tests.group_by_key_test',\n       runner         : CommonTestProperties.Runner.DATAFLOW,\n       pipelineOptions: [\n-        job_name             : 'load-tests-python-dataflow-batch-gbk-2-' + now,\n+        job_name             : 'load-tests-python-dataflow-${mode}-gbk-2-' + now,\n         project              : 'apache-beam-testing',\n         region               : 'us-central1',\n         temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n         publish_to_big_query : true,\n         metrics_dataset      : datasetName,\n-        metrics_table        : 'python_dataflow_batch_gbk_2',\n-        influx_measurement   : 'python_batch_gbk_2',\n+        metrics_table        : 'python_dataflow_${mode}_gbk_2',\n+        influx_measurement   : 'python_${mode}_gbk_2',\n         input_options        : '\\'{\"num_records\": 20000000,' +\n         '\"key_size\": 10,' +\n         '\"value_size\": 90}\\'',\n         iterations           : 1,\n         fanout               : 1,\n         num_workers          : 5,\n-        autoscaling_algorithm: \"NONE\"\n+        autoscaling_algorithm: 'NONE',\n       ]\n     ],\n     [\n       title          : 'GroupByKey Python Load test: 2GB of 100kB records',\n       test           : 'apache_beam.testing.load_tests.group_by_key_test',\n       runner         : CommonTestProperties.Runner.DATAFLOW,\n       pipelineOptions: [\n-        job_name             : 'load-tests-python-dataflow-batch-gbk-3-' + now,\n+        job_name             : \"load-tests-python-dataflow-${mode}-gbk-3-${now}\",\n         project              : 'apache-beam-testing',\n         region               : 'us-central1',\n         temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n         publish_to_big_query : true,\n         metrics_dataset      : datasetName,\n-        metrics_table        : 'python_dataflow_batch_gbk_3',\n-        influx_measurement   : 'python_batch_gbk_3',\n+        metrics_table        : \"python_dataflow_${mode}_gbk_3\",\n+        influx_measurement   : \"python_${mode}_gbk_3\",\n         input_options        : '\\'{\"num_records\": 20000,' +\n         '\"key_size\": 10000,' +\n         '\"value_size\": 90000}\\'',\n         iterations           : 1,\n         fanout               : 1,\n         num_workers          : 5,\n-        autoscaling_algorithm: \"NONE\"\n+        autoscaling_algorithm: 'NONE',\n       ]\n     ],\n     [\n       title          : 'GroupByKey Python Load test: fanout 4 times with 2GB 10-byte records total',\n       test           : 'apache_beam.testing.load_tests.group_by_key_test',\n       runner         : CommonTestProperties.Runner.DATAFLOW,\n       pipelineOptions: [\n-        job_name             : 'load-tests-python-dataflow-batch-gbk-4-' + now,\n+        job_name             : \"load-tests-python-dataflow-${mode}-gbk-4-${now}\",\n         project              : 'apache-beam-testing',\n         region               : 'us-central1',\n         temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n         publish_to_big_query : true,\n         metrics_dataset      : datasetName,\n-        metrics_table        : 'python_dataflow_batch_gbk_4',\n-        influx_measurement   : 'python_batch_gbk_4',\n+        metrics_table        : \"python_dataflow_${mode}_gbk_4\",\n+        influx_measurement   : \"python_${mode}_gbk_4\",\n         input_options        : '\\'{\"num_records\": 5000000,' +\n         '\"key_size\": 10,' +\n         '\"value_size\": 90}\\'',\n         iterations           : 1,\n         fanout               : 4,\n-        num_workers          : 5,\n-        autoscaling_algorithm: \"NONE\"\n+        num_workers          : 16,\n+        autoscaling_algorithm: 'NONE',\n       ]\n     ],\n     [\n       title          : 'GroupByKey Python Load test: fanout 8 times with 2GB 10-byte records total',\n       test           : 'apache_beam.testing.load_tests.group_by_key_test',\n       runner         : CommonTestProperties.Runner.DATAFLOW,\n       pipelineOptions: [\n-        job_name             : 'load-tests-python-dataflow-batch-gbk-5-' + now,\n+        job_name             : \"load-tests-python-dataflow-${mode}-gbk-5-${now}\",\n         project              : 'apache-beam-testing',\n         region               : 'us-central1',\n         temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n         publish_to_big_query : true,\n         metrics_dataset      : datasetName,\n-        metrics_table        : 'python_dataflow_batch_gbk_5',\n-        influx_measurement   : 'python_batch_gbk_5',\n+        metrics_table        : \"python_dataflow_${mode}_gbk_5\",\n+        influx_measurement   : \"python_${mode}_gbk_5\",\n         input_options        : '\\'{\"num_records\": 2500000,' +\n         '\"key_size\": 10,' +\n         '\"value_size\": 90}\\'',\n         iterations           : 1,\n         fanout               : 8,\n-        num_workers          : 5,\n-        autoscaling_algorithm: \"NONE\"\n+        num_workers          : 16,\n+        autoscaling_algorithm: 'NONE',\n       ]\n     ],\n-  ].each { test -> test.pipelineOptions.putAll(additionalPipelineArgs) }\n+  ]\n+  .each { test -> test.pipelineOptions.putAll(additionalPipelineArgs) }\n+  .each { test -> (mode != 'streaming') ?: addStreamingOptions(test) }\n+  .withIndex().collectMany { test, i ->\n+    mode == 'streaming' && STREAMING_TESTS_TO_SKIP.contains(i + 1) ? []: [test]\n+  }\n+}\n+\n+def addStreamingOptions(test) {\n+  test.pipelineOptions << [streaming: null, experiments: 'use_runner_v2',\n+    enable_streaming_engine: null ]\n+}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f67712b477f811e2fe61f5c816b58e1268db2e13"}, "originalPosition": 154}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDgzNDQ0Mw==", "bodyText": "Same here, please add a comment.", "url": "https://github.com/apache/beam/pull/12612#discussion_r474834443", "createdAt": "2020-08-21T17:34:28Z", "author": {"login": "tysonjh"}, "path": ".test-infra/jenkins/job_LoadTests_GBK_Python_reiterate.groovy", "diffHunk": "@@ -58,43 +58,47 @@ def loadTestConfigurations = { datasetName ->\n       pipelineOptions: [\n         project              : 'apache-beam-testing',\n         region               : 'us-central1',\n-        job_name             : 'load-tests-python-dataflow-batch-gbk-7-' + now,\n+        job_name             : \"load-tests-python-dataflow-${mode}-gbk-7-${now}\",\n         temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n         publish_to_big_query : true,\n         metrics_dataset      : datasetName,\n-        metrics_table        : 'python_dataflow_batch_gbk_7',\n-        influx_measurement   : 'python_batch_gbk_7',\n+        metrics_table        : \"python_dataflow_${mode}_gbk_7\",\n+        influx_measurement   : \"python_${mode}_gbk_7\",\n         input_options        : '\\'{\"num_records\": 20000000,' +\n         '\"key_size\": 10,' +\n         '\"value_size\": 90,' +\n         '\"num_hot_keys\": 10,' +\n         '\"hot_key_fraction\": 1}\\'',\n-        fanout               : 1,\n         iterations           : 4,\n+        fanout               : 1,\n         num_workers          : 5,\n-        autoscaling_algorithm: 'NONE'\n+        autoscaling_algorithm: 'NONE',\n       ]\n     ]\n-  ].each { test -> test.pipelineOptions.putAll(additionalPipelineArgs) }\n+  ]\n+  .each { test -> test.pipelineOptions.putAll(additionalPipelineArgs) }\n+  .each { test -> (mode != 'streaming') ?: addStreamingOptions(test) }\n }\n \n-def batchLoadTestJob = { scope, triggeringContext ->\n-  scope.description('Runs Python GBK reiterate load tests on Dataflow runner in batch mode')\n-  commonJobProperties.setTopLevelMainJobProperties(scope, 'master', 240)\n+def addStreamingOptions(test) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f67712b477f811e2fe61f5c816b58e1268db2e13"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDgzNDgxNg==", "bodyText": "What's the methodology for picking the time to trigger these? Is it documented anywhere?", "url": "https://github.com/apache/beam/pull/12612#discussion_r474834816", "createdAt": "2020-08-21T17:35:09Z", "author": {"login": "tysonjh"}, "path": ".test-infra/jenkins/job_LoadTests_GBK_Python_reiterate.groovy", "diffHunk": "@@ -58,43 +58,47 @@ def loadTestConfigurations = { datasetName ->\n       pipelineOptions: [\n         project              : 'apache-beam-testing',\n         region               : 'us-central1',\n-        job_name             : 'load-tests-python-dataflow-batch-gbk-7-' + now,\n+        job_name             : \"load-tests-python-dataflow-${mode}-gbk-7-${now}\",\n         temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n         publish_to_big_query : true,\n         metrics_dataset      : datasetName,\n-        metrics_table        : 'python_dataflow_batch_gbk_7',\n-        influx_measurement   : 'python_batch_gbk_7',\n+        metrics_table        : \"python_dataflow_${mode}_gbk_7\",\n+        influx_measurement   : \"python_${mode}_gbk_7\",\n         input_options        : '\\'{\"num_records\": 20000000,' +\n         '\"key_size\": 10,' +\n         '\"value_size\": 90,' +\n         '\"num_hot_keys\": 10,' +\n         '\"hot_key_fraction\": 1}\\'',\n-        fanout               : 1,\n         iterations           : 4,\n+        fanout               : 1,\n         num_workers          : 5,\n-        autoscaling_algorithm: 'NONE'\n+        autoscaling_algorithm: 'NONE',\n       ]\n     ]\n-  ].each { test -> test.pipelineOptions.putAll(additionalPipelineArgs) }\n+  ]\n+  .each { test -> test.pipelineOptions.putAll(additionalPipelineArgs) }\n+  .each { test -> (mode != 'streaming') ?: addStreamingOptions(test) }\n }\n \n-def batchLoadTestJob = { scope, triggeringContext ->\n-  scope.description('Runs Python GBK reiterate load tests on Dataflow runner in batch mode')\n-  commonJobProperties.setTopLevelMainJobProperties(scope, 'master', 240)\n+def addStreamingOptions(test) {\n+  test.pipelineOptions << [streaming: null, experiments: 'use_runner_v2',\n+    enable_streaming_engine: null ]\n+}\n \n+def loadTestJob = { scope, triggeringContext, mode ->\n   def datasetName = loadTestsBuilder.getBigQueryDataset('load_test', triggeringContext)\n-  for (testConfiguration in loadTestConfigurations(datasetName)) {\n-    loadTestsBuilder.loadTest(scope, testConfiguration.title, testConfiguration.runner, CommonTestProperties.SDK.PYTHON_37, testConfiguration.pipelineOptions, testConfiguration.test)\n-  }\n+  loadTestsBuilder.loadTests(scope, CommonTestProperties.SDK.PYTHON_37,\n+      loadTestConfigurations(mode, datasetName), 'GBK reiterate', mode)\n }\n \n-CronJobBuilder.cronJob('beam_LoadTests_Python_GBK_reiterate_Dataflow_Batch', 'H 14 * * *', this) {\n-  additionalPipelineArgs = [\n-    influx_db_name: InfluxDBCredentialsHelper.InfluxDBDatabaseName,\n-    influx_hostname: InfluxDBCredentialsHelper.InfluxDBHostname,\n-  ]\n-  batchLoadTestJob(delegate, CommonTestProperties.TriggeringContext.POST_COMMIT)\n-}\n+CronJobBuilder.cronJob('beam_LoadTests_Python_GBK_reiterate_Dataflow_Batch',\n+    'H 14 * * *', this) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f67712b477f811e2fe61f5c816b58e1268db2e13"}, "originalPosition": 93}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDcyNjc3NjI5", "url": "https://github.com/apache/beam/pull/12612#pullrequestreview-472677629", "createdAt": "2020-08-21T17:47:18Z", "commit": {"oid": "f67712b477f811e2fe61f5c816b58e1268db2e13"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxNzo0NzoxOFrOHE190A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxNzo0NzoxOFrOHE190A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDg0MDUyOA==", "bodyText": "@kkucharc made a good point here in PR#12435 about using indices for ignoring tests. I'm more inclined towards the approach @kkucharc is taking by excluding using the job_name.", "url": "https://github.com/apache/beam/pull/12612#discussion_r474840528", "createdAt": "2020-08-21T17:47:18Z", "author": {"login": "tysonjh"}, "path": ".test-infra/jenkins/job_LoadTests_GBK_Python.groovy", "diffHunk": "@@ -22,119 +22,138 @@ import InfluxDBCredentialsHelper\n \n def now = new Date().format(\"MMddHHmmss\", TimeZone.getTimeZone('UTC'))\n \n-def loadTestConfigurations = { datasetName ->\n+// TODO(BEAM-10774): Skipping some cases because they are too slow.\n+def STREAMING_TESTS_TO_SKIP = [1, 2, 4, 5]", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f67712b477f811e2fe61f5c816b58e1268db2e13"}, "originalPosition": 6}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7909cab3aaabf9f31cd06bf895d67309c0a31a1b", "author": {"user": {"login": "kamilwu", "name": "Kamil Wasilewski"}}, "url": "https://github.com/apache/beam/commit/7909cab3aaabf9f31cd06bf895d67309c0a31a1b", "committedDate": "2020-08-24T13:51:16Z", "message": "[BEAM-10675] Protect against None-valued metrics"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "88dd6b3972ac43844fbef4da9a7970889800a04f", "author": {"user": {"login": "kamilwu", "name": "Kamil Wasilewski"}}, "url": "https://github.com/apache/beam/commit/88dd6b3972ac43844fbef4da9a7970889800a04f", "committedDate": "2020-08-24T13:51:16Z", "message": "[BEAM-10675] Python GBK load test: fix a bug where KV pairs were not properly returned from Ungroup transform"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0e6735ba225039920d888f0a729841475ea48c7b", "author": {"user": {"login": "kamilwu", "name": "Kamil Wasilewski"}}, "url": "https://github.com/apache/beam/commit/0e6735ba225039920d888f0a729841475ea48c7b", "committedDate": "2020-08-24T13:51:16Z", "message": "[BEAM-10675] Python GBK load test: add streaming job"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "686122d512c70f4c18709e56497728f76ff529e7", "author": {"user": {"login": "kamilwu", "name": "Kamil Wasilewski"}}, "url": "https://github.com/apache/beam/commit/686122d512c70f4c18709e56497728f76ff529e7", "committedDate": "2020-08-24T13:51:16Z", "message": "fix: exclude test cases by job_name; add explanatory comments"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b1c9673a73492927a7c0c29a4cb104dba1a2d424", "author": {"user": {"login": "kamilwu", "name": "Kamil Wasilewski"}}, "url": "https://github.com/apache/beam/commit/b1c9673a73492927a7c0c29a4cb104dba1a2d424", "committedDate": "2020-08-24T09:54:19Z", "message": "fix: exclude test cases by job_name; add explanatory comments"}, "afterCommit": {"oid": "e6bbfe27007cb5b59cdb1df66bef1967f7f94ca2", "author": {"user": {"login": "kamilwu", "name": "Kamil Wasilewski"}}, "url": "https://github.com/apache/beam/commit/e6bbfe27007cb5b59cdb1df66bef1967f7f94ca2", "committedDate": "2020-08-24T15:34:19Z", "message": "fix: remove enable_streaming_engine option\n\nenable_streaming_engine is now being added automatically when running with 'use_runner_v2'"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "11a1a3b884c83cb6b5623105b252dc160ffa699a", "author": {"user": {"login": "kamilwu", "name": "Kamil Wasilewski"}}, "url": "https://github.com/apache/beam/commit/11a1a3b884c83cb6b5623105b252dc160ffa699a", "committedDate": "2020-08-24T15:35:02Z", "message": "fix: remove enable_streaming_engine option\n\nenable_streaming_engine is now being added automatically when running with 'use_runner_v2'"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e6bbfe27007cb5b59cdb1df66bef1967f7f94ca2", "author": {"user": {"login": "kamilwu", "name": "Kamil Wasilewski"}}, "url": "https://github.com/apache/beam/commit/e6bbfe27007cb5b59cdb1df66bef1967f7f94ca2", "committedDate": "2020-08-24T15:34:19Z", "message": "fix: remove enable_streaming_engine option\n\nenable_streaming_engine is now being added automatically when running with 'use_runner_v2'"}, "afterCommit": {"oid": "11a1a3b884c83cb6b5623105b252dc160ffa699a", "author": {"user": {"login": "kamilwu", "name": "Kamil Wasilewski"}}, "url": "https://github.com/apache/beam/commit/11a1a3b884c83cb6b5623105b252dc160ffa699a", "committedDate": "2020-08-24T15:35:02Z", "message": "fix: remove enable_streaming_engine option\n\nenable_streaming_engine is now being added automatically when running with 'use_runner_v2'"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDc0OTIwODkx", "url": "https://github.com/apache/beam/pull/12612#pullrequestreview-474920891", "createdAt": "2020-08-25T21:19:28Z", "commit": {"oid": "11a1a3b884c83cb6b5623105b252dc160ffa699a"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4748, "cost": 1, "resetAt": "2021-10-28T16:48:13Z"}}}