{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDg5ODM3NzM0", "number": 12882, "reviewThreads": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMFQwNzo0NTowNlrOElZw6Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QxNjowNDoxNVrOEmrFSw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA3NjU0ODg5OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/convert.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMFQwNzo0NTowNlrOHU40yA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMFQwNzo0NTowNlrOHU40yA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTY2NDU4NA==", "bodyText": "Put ()'s around (key, pc) for better formatting.", "url": "https://github.com/apache/beam/pull/12882#discussion_r491664584", "createdAt": "2020-09-20T07:45:06Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/convert.py", "diffHunk": "@@ -118,6 +119,15 @@ def extract_input(placeholder):\n              } | label >> transforms._DataframeExpressionsTransform(\n                  dict((ix, df._expr) for ix, df in enumerate(\n                      dataframes)))  # type: Dict[Any, pvalue.PCollection]\n+\n+  if not yield_dataframes:\n+    results = {\n+        key: pc | \"Unbatch '%s'\" % dataframes[key]._expr._id >>\n+        schemas.UnbatchPandas(dataframes[key]._expr.proxy())\n+        for key,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b93cb4d23bdabf1b82f6f378c34bc9677186ffc6"}, "originalPosition": 19}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA3NjU1MDY0OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/schemas.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMFQwNzo0ODowN1rOHU41iA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMVQyMDozMzowOFrOHVhZyQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTY2NDc3Ng==", "bodyText": "We should consider whether we want flattening here (e.g. with dotted attributes). Let's at least mark this paragraph as subject to change.", "url": "https://github.com/apache/beam/pull/12882#discussion_r491664776", "createdAt": "2020-09-20T07:48:07Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/schemas.py", "diffHunk": "@@ -15,25 +15,129 @@\n # limitations under the License.\n #\n \n-\"\"\"Utilities for relating schema-aware PCollections and dataframe transforms.\n+r\"\"\"Utilities for relating schema-aware PCollections and dataframe transforms.\n+\n+pandas dtype               Python typing\n+np.int{8,16,32,64}      <-----> np.int{8,16,32,64}*\n+pd.Int{8,16,32,64}Dtype <-----> Optional[np.int{8,16,32,64}]*\n+np.float{32,64}         <-----> Optional[np.float{32,64}]\n+                           \\--- np.float{32,64}\n+np.dtype('S')           <-----> bytes\n+Not supported           <------ Optional[bytes]\n+np.bool                 <-----> np.bool\n+\n+* int, float, bool are treated the same as np.int64, np.float64, np.bool\n+\n+Any unknown or unsupported types are trested as Any and shunted to\n+np.object:\n+\n+np.object               <-----> Any\n+\n+Strings and nullable Booleans are handled differently when using pandas 0.x vs.\n+1.x. pandas 0.x has no mapping for these types, so they are shunted lossily to\n+  np.object.\n+\n+pandas 0.x:\n+np.object         <------ Optional[bool]\n+                     \\--- Optional[str]\n+                      \\-- str\n+\n+pandas 1.x:\n+pd.BooleanDType() <-----> Optional[bool]\n+pd.StringDType()  <-----> Optional[str]\n+                     \\--- str\n+\n+Pandas does not support hierarchical data natively. All structured types", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b93cb4d23bdabf1b82f6f378c34bc9677186ffc6"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjMyOTQxNw==", "bodyText": "SG, I added a sentence indicating we might add better support for these types in the future.", "url": "https://github.com/apache/beam/pull/12882#discussion_r492329417", "createdAt": "2020-09-21T20:33:08Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/schemas.py", "diffHunk": "@@ -15,25 +15,129 @@\n # limitations under the License.\n #\n \n-\"\"\"Utilities for relating schema-aware PCollections and dataframe transforms.\n+r\"\"\"Utilities for relating schema-aware PCollections and dataframe transforms.\n+\n+pandas dtype               Python typing\n+np.int{8,16,32,64}      <-----> np.int{8,16,32,64}*\n+pd.Int{8,16,32,64}Dtype <-----> Optional[np.int{8,16,32,64}]*\n+np.float{32,64}         <-----> Optional[np.float{32,64}]\n+                           \\--- np.float{32,64}\n+np.dtype('S')           <-----> bytes\n+Not supported           <------ Optional[bytes]\n+np.bool                 <-----> np.bool\n+\n+* int, float, bool are treated the same as np.int64, np.float64, np.bool\n+\n+Any unknown or unsupported types are trested as Any and shunted to\n+np.object:\n+\n+np.object               <-----> Any\n+\n+Strings and nullable Booleans are handled differently when using pandas 0.x vs.\n+1.x. pandas 0.x has no mapping for these types, so they are shunted lossily to\n+  np.object.\n+\n+pandas 0.x:\n+np.object         <------ Optional[bool]\n+                     \\--- Optional[str]\n+                      \\-- str\n+\n+pandas 1.x:\n+pd.BooleanDType() <-----> Optional[bool]\n+pd.StringDType()  <-----> Optional[str]\n+                     \\--- str\n+\n+Pandas does not support hierarchical data natively. All structured types", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTY2NDc3Ng=="}, "originalCommit": {"oid": "b93cb4d23bdabf1b82f6f378c34bc9677186ffc6"}, "originalPosition": 37}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA3NjU1MTY3OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/schemas.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMFQwNzo0OTo0MVrOHU419w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMVQyMDozMjozNFrOHVhYwg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTY2NDg4Nw==", "bodyText": "This will break for betas, rcs, etc. Maybe just do int(pd.__version__.split('.')[0])", "url": "https://github.com/apache/beam/pull/12882#discussion_r491664887", "createdAt": "2020-09-20T07:49:41Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/schemas.py", "diffHunk": "@@ -15,25 +15,129 @@\n # limitations under the License.\n #\n \n-\"\"\"Utilities for relating schema-aware PCollections and dataframe transforms.\n+r\"\"\"Utilities for relating schema-aware PCollections and dataframe transforms.\n+\n+pandas dtype               Python typing\n+np.int{8,16,32,64}      <-----> np.int{8,16,32,64}*\n+pd.Int{8,16,32,64}Dtype <-----> Optional[np.int{8,16,32,64}]*\n+np.float{32,64}         <-----> Optional[np.float{32,64}]\n+                           \\--- np.float{32,64}\n+np.dtype('S')           <-----> bytes\n+Not supported           <------ Optional[bytes]\n+np.bool                 <-----> np.bool\n+\n+* int, float, bool are treated the same as np.int64, np.float64, np.bool\n+\n+Any unknown or unsupported types are trested as Any and shunted to\n+np.object:\n+\n+np.object               <-----> Any\n+\n+Strings and nullable Booleans are handled differently when using pandas 0.x vs.\n+1.x. pandas 0.x has no mapping for these types, so they are shunted lossily to\n+  np.object.\n+\n+pandas 0.x:\n+np.object         <------ Optional[bool]\n+                     \\--- Optional[str]\n+                      \\-- str\n+\n+pandas 1.x:\n+pd.BooleanDType() <-----> Optional[bool]\n+pd.StringDType()  <-----> Optional[str]\n+                     \\--- str\n+\n+Pandas does not support hierarchical data natively. All structured types\n+(Sequence, Mapping, nested NamedTuple types), will be shunted lossily to\n+np.object/Any.\n+\n+TODO: Mapping for date/time types\n+https://pandas.pydata.org/docs/user_guide/timeseries.html#overview\n+\n+timestamps and timedeltas in pandas always use nanosecond precision\n \"\"\"\n \n # pytype: skip-file\n \n from __future__ import absolute_import\n \n-import typing\n+from typing import Any\n+from typing import NamedTuple\n+from typing import Optional\n+from typing import TypeVar\n+from typing import Union\n \n+import numpy as np\n import pandas as pd\n \n import apache_beam as beam\n from apache_beam import typehints\n+from apache_beam.portability.api import schema_pb2\n from apache_beam.transforms.util import BatchElements\n+from apache_beam.typehints.native_type_compatibility import _match_is_optional\n from apache_beam.typehints.schemas import named_fields_from_element_type\n+from apache_beam.typehints.schemas import named_fields_to_schema\n+from apache_beam.typehints.schemas import named_tuple_from_schema\n+from apache_beam.typehints.schemas import named_tuple_to_schema\n+from apache_beam.utils import proto_utils\n+\n+__all__ = (\n+    'BatchRowsAsDataFrame',\n+    'generate_proxy',\n+    'UnbatchPandas',\n+    'element_type_from_proxy')\n+\n+T = TypeVar('T', bound=NamedTuple)\n+\n+PD_MAJOR, _, _ = map(int, pd.__version__.split('.'))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b93cb4d23bdabf1b82f6f378c34bc9677186ffc6"}, "originalPosition": 80}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjMyOTE1NA==", "bodyText": "Fixed, thanks", "url": "https://github.com/apache/beam/pull/12882#discussion_r492329154", "createdAt": "2020-09-21T20:32:34Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/schemas.py", "diffHunk": "@@ -15,25 +15,129 @@\n # limitations under the License.\n #\n \n-\"\"\"Utilities for relating schema-aware PCollections and dataframe transforms.\n+r\"\"\"Utilities for relating schema-aware PCollections and dataframe transforms.\n+\n+pandas dtype               Python typing\n+np.int{8,16,32,64}      <-----> np.int{8,16,32,64}*\n+pd.Int{8,16,32,64}Dtype <-----> Optional[np.int{8,16,32,64}]*\n+np.float{32,64}         <-----> Optional[np.float{32,64}]\n+                           \\--- np.float{32,64}\n+np.dtype('S')           <-----> bytes\n+Not supported           <------ Optional[bytes]\n+np.bool                 <-----> np.bool\n+\n+* int, float, bool are treated the same as np.int64, np.float64, np.bool\n+\n+Any unknown or unsupported types are trested as Any and shunted to\n+np.object:\n+\n+np.object               <-----> Any\n+\n+Strings and nullable Booleans are handled differently when using pandas 0.x vs.\n+1.x. pandas 0.x has no mapping for these types, so they are shunted lossily to\n+  np.object.\n+\n+pandas 0.x:\n+np.object         <------ Optional[bool]\n+                     \\--- Optional[str]\n+                      \\-- str\n+\n+pandas 1.x:\n+pd.BooleanDType() <-----> Optional[bool]\n+pd.StringDType()  <-----> Optional[str]\n+                     \\--- str\n+\n+Pandas does not support hierarchical data natively. All structured types\n+(Sequence, Mapping, nested NamedTuple types), will be shunted lossily to\n+np.object/Any.\n+\n+TODO: Mapping for date/time types\n+https://pandas.pydata.org/docs/user_guide/timeseries.html#overview\n+\n+timestamps and timedeltas in pandas always use nanosecond precision\n \"\"\"\n \n # pytype: skip-file\n \n from __future__ import absolute_import\n \n-import typing\n+from typing import Any\n+from typing import NamedTuple\n+from typing import Optional\n+from typing import TypeVar\n+from typing import Union\n \n+import numpy as np\n import pandas as pd\n \n import apache_beam as beam\n from apache_beam import typehints\n+from apache_beam.portability.api import schema_pb2\n from apache_beam.transforms.util import BatchElements\n+from apache_beam.typehints.native_type_compatibility import _match_is_optional\n from apache_beam.typehints.schemas import named_fields_from_element_type\n+from apache_beam.typehints.schemas import named_fields_to_schema\n+from apache_beam.typehints.schemas import named_tuple_from_schema\n+from apache_beam.typehints.schemas import named_tuple_to_schema\n+from apache_beam.utils import proto_utils\n+\n+__all__ = (\n+    'BatchRowsAsDataFrame',\n+    'generate_proxy',\n+    'UnbatchPandas',\n+    'element_type_from_proxy')\n+\n+T = TypeVar('T', bound=NamedTuple)\n+\n+PD_MAJOR, _, _ = map(int, pd.__version__.split('.'))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTY2NDg4Nw=="}, "originalCommit": {"oid": "b93cb4d23bdabf1b82f6f378c34bc9677186ffc6"}, "originalPosition": 80}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA3NjU1MjUwOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/schemas.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMFQwNzo1MDo1NlrOHU42Uw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMVQyMDozMjoyNlrOHVhYfQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTY2NDk3OQ==", "bodyText": "extra whitespace?", "url": "https://github.com/apache/beam/pull/12882#discussion_r491664979", "createdAt": "2020-09-20T07:50:56Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/schemas.py", "diffHunk": "@@ -55,17 +159,149 @@ def expand(self, pcoll):\n         lambda batch: pd.DataFrame.from_records(batch, columns=columns))\n \n \n-def _make_empty_series(name, typ):\n-  try:\n-    return pd.Series(name=name, dtype=typ)\n-  except TypeError:\n-    raise TypeError(\"Unable to convert type '%s' for field '%s'\" % (name, typ))\n+def _make_proxy_series(name, typehint):\n+  # Default to np.object. This is lossy, we won't be able to recover the type\n+  # at the output.\n+  dtype = BEAM_TO_PANDAS.get(typehint, np.object)\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b93cb4d23bdabf1b82f6f378c34bc9677186ffc6"}, "originalPosition": 147}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjMyOTA4NQ==", "bodyText": "Removed", "url": "https://github.com/apache/beam/pull/12882#discussion_r492329085", "createdAt": "2020-09-21T20:32:26Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/schemas.py", "diffHunk": "@@ -55,17 +159,149 @@ def expand(self, pcoll):\n         lambda batch: pd.DataFrame.from_records(batch, columns=columns))\n \n \n-def _make_empty_series(name, typ):\n-  try:\n-    return pd.Series(name=name, dtype=typ)\n-  except TypeError:\n-    raise TypeError(\"Unable to convert type '%s' for field '%s'\" % (name, typ))\n+def _make_proxy_series(name, typehint):\n+  # Default to np.object. This is lossy, we won't be able to recover the type\n+  # at the output.\n+  dtype = BEAM_TO_PANDAS.get(typehint, np.object)\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTY2NDk3OQ=="}, "originalCommit": {"oid": "b93cb4d23bdabf1b82f6f378c34bc9677186ffc6"}, "originalPosition": 147}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA3NjU1MzI2OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/schemas.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMFQwNzo1MjowMVrOHU42pg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMVQyMDozMjoxN1rOHVhYNg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTY2NTA2Mg==", "bodyText": "Is whitespace stripped at the beginning of a docstring? (Similarly below.)", "url": "https://github.com/apache/beam/pull/12882#discussion_r491665062", "createdAt": "2020-09-20T07:52:01Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/schemas.py", "diffHunk": "@@ -55,17 +159,149 @@ def expand(self, pcoll):\n         lambda batch: pd.DataFrame.from_records(batch, columns=columns))\n \n \n-def _make_empty_series(name, typ):\n-  try:\n-    return pd.Series(name=name, dtype=typ)\n-  except TypeError:\n-    raise TypeError(\"Unable to convert type '%s' for field '%s'\" % (name, typ))\n+def _make_proxy_series(name, typehint):\n+  # Default to np.object. This is lossy, we won't be able to recover the type\n+  # at the output.\n+  dtype = BEAM_TO_PANDAS.get(typehint, np.object)\n+\n+  return pd.Series(name=name, dtype=dtype)\n \n \n def generate_proxy(element_type):\n   # type: (type) -> pd.DataFrame\n-  return pd.DataFrame({\n-      name: _make_empty_series(name, typ)\n-      for name,\n-      typ in named_fields_from_element_type(element_type)\n-  })\n+\n+  \"\"\" Generate a proxy pandas object for the given PCollection element_type.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b93cb4d23bdabf1b82f6f378c34bc9677186ffc6"}, "originalPosition": 159}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjMyOTAxNA==", "bodyText": "Done", "url": "https://github.com/apache/beam/pull/12882#discussion_r492329014", "createdAt": "2020-09-21T20:32:17Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/schemas.py", "diffHunk": "@@ -55,17 +159,149 @@ def expand(self, pcoll):\n         lambda batch: pd.DataFrame.from_records(batch, columns=columns))\n \n \n-def _make_empty_series(name, typ):\n-  try:\n-    return pd.Series(name=name, dtype=typ)\n-  except TypeError:\n-    raise TypeError(\"Unable to convert type '%s' for field '%s'\" % (name, typ))\n+def _make_proxy_series(name, typehint):\n+  # Default to np.object. This is lossy, we won't be able to recover the type\n+  # at the output.\n+  dtype = BEAM_TO_PANDAS.get(typehint, np.object)\n+\n+  return pd.Series(name=name, dtype=dtype)\n \n \n def generate_proxy(element_type):\n   # type: (type) -> pd.DataFrame\n-  return pd.DataFrame({\n-      name: _make_empty_series(name, typ)\n-      for name,\n-      typ in named_fields_from_element_type(element_type)\n-  })\n+\n+  \"\"\" Generate a proxy pandas object for the given PCollection element_type.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTY2NTA2Mg=="}, "originalCommit": {"oid": "b93cb4d23bdabf1b82f6f378c34bc9677186ffc6"}, "originalPosition": 159}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA3NjU1NjMxOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/schemas.py", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMFQwNzo1NTo1NlrOHU43_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMlQwNDoxNToyOVrOHVpsjg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTY2NTQwNg==", "bodyText": "I was wondering about this as well--do we want to return the index iff it's a multi-index or it's named? Should we make whether to return the index another option?", "url": "https://github.com/apache/beam/pull/12882#discussion_r491665406", "createdAt": "2020-09-20T07:55:56Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/schemas.py", "diffHunk": "@@ -55,17 +159,149 @@ def expand(self, pcoll):\n         lambda batch: pd.DataFrame.from_records(batch, columns=columns))\n \n \n-def _make_empty_series(name, typ):\n-  try:\n-    return pd.Series(name=name, dtype=typ)\n-  except TypeError:\n-    raise TypeError(\"Unable to convert type '%s' for field '%s'\" % (name, typ))\n+def _make_proxy_series(name, typehint):\n+  # Default to np.object. This is lossy, we won't be able to recover the type\n+  # at the output.\n+  dtype = BEAM_TO_PANDAS.get(typehint, np.object)\n+\n+  return pd.Series(name=name, dtype=dtype)\n \n \n def generate_proxy(element_type):\n   # type: (type) -> pd.DataFrame\n-  return pd.DataFrame({\n-      name: _make_empty_series(name, typ)\n-      for name,\n-      typ in named_fields_from_element_type(element_type)\n-  })\n+\n+  \"\"\" Generate a proxy pandas object for the given PCollection element_type.\n+\n+  Currently only supports generating a DataFrame proxy from a schema-aware\n+  PCollection.\"\"\"\n+  fields = named_fields_from_element_type(element_type)\n+  return pd.DataFrame(\n+      {name: _make_proxy_series(name, typehint)\n+       for name, typehint in fields},\n+      columns=[name for name, _ in fields])\n+\n+\n+def element_type_from_proxy(proxy):\n+  # type: (pd.DataFrame) -> type\n+\n+  \"\"\" Generate an element_type for an element-wise PCollection from a proxy\n+  pandas object. Currently only supports converting the element_type for\n+  a schema-aware PCollection to a proxy DataFrame.\n+\n+  Currently only supports generating a DataFrame proxy from a schema-aware\n+  PCollection.\"\"\"\n+  indices = [] if proxy.index.names == (None, ) else [", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b93cb4d23bdabf1b82f6f378c34bc9677186ffc6"}, "originalPosition": 179}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjIxOTMxNw==", "bodyText": "I thought the MultiIndex or named case was important since otherwise we'll drop the grouped column(s) when unbatching the result of a grouped aggregation.\nIt raise some tricky issues though:\n\nIndex names are not required to be unique.\nIt looks like my assumption that all MultiIndexes are named is wrong. It's possible to create a MultiIndex with names=[None, None, 'foo'], which would break this badly.\nType information is not necessarily preserved in indexes. e.g. Int64Index doesn't support nulls like Series with Int64Dtype does. if one is added it's converted to a Float64Index with nans.\n\nMaybe including the index shouldn't be the default until we have a better handle on these edge cases.", "url": "https://github.com/apache/beam/pull/12882#discussion_r492219317", "createdAt": "2020-09-21T17:13:17Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/schemas.py", "diffHunk": "@@ -55,17 +159,149 @@ def expand(self, pcoll):\n         lambda batch: pd.DataFrame.from_records(batch, columns=columns))\n \n \n-def _make_empty_series(name, typ):\n-  try:\n-    return pd.Series(name=name, dtype=typ)\n-  except TypeError:\n-    raise TypeError(\"Unable to convert type '%s' for field '%s'\" % (name, typ))\n+def _make_proxy_series(name, typehint):\n+  # Default to np.object. This is lossy, we won't be able to recover the type\n+  # at the output.\n+  dtype = BEAM_TO_PANDAS.get(typehint, np.object)\n+\n+  return pd.Series(name=name, dtype=dtype)\n \n \n def generate_proxy(element_type):\n   # type: (type) -> pd.DataFrame\n-  return pd.DataFrame({\n-      name: _make_empty_series(name, typ)\n-      for name,\n-      typ in named_fields_from_element_type(element_type)\n-  })\n+\n+  \"\"\" Generate a proxy pandas object for the given PCollection element_type.\n+\n+  Currently only supports generating a DataFrame proxy from a schema-aware\n+  PCollection.\"\"\"\n+  fields = named_fields_from_element_type(element_type)\n+  return pd.DataFrame(\n+      {name: _make_proxy_series(name, typehint)\n+       for name, typehint in fields},\n+      columns=[name for name, _ in fields])\n+\n+\n+def element_type_from_proxy(proxy):\n+  # type: (pd.DataFrame) -> type\n+\n+  \"\"\" Generate an element_type for an element-wise PCollection from a proxy\n+  pandas object. Currently only supports converting the element_type for\n+  a schema-aware PCollection to a proxy DataFrame.\n+\n+  Currently only supports generating a DataFrame proxy from a schema-aware\n+  PCollection.\"\"\"\n+  indices = [] if proxy.index.names == (None, ) else [", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTY2NTQwNg=="}, "originalCommit": {"oid": "b93cb4d23bdabf1b82f6f378c34bc9677186ffc6"}, "originalPosition": 179}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjIxOTkzNg==", "bodyText": "We could log a warning if there's a named index in the result and include_indexes is False", "url": "https://github.com/apache/beam/pull/12882#discussion_r492219936", "createdAt": "2020-09-21T17:14:23Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/schemas.py", "diffHunk": "@@ -55,17 +159,149 @@ def expand(self, pcoll):\n         lambda batch: pd.DataFrame.from_records(batch, columns=columns))\n \n \n-def _make_empty_series(name, typ):\n-  try:\n-    return pd.Series(name=name, dtype=typ)\n-  except TypeError:\n-    raise TypeError(\"Unable to convert type '%s' for field '%s'\" % (name, typ))\n+def _make_proxy_series(name, typehint):\n+  # Default to np.object. This is lossy, we won't be able to recover the type\n+  # at the output.\n+  dtype = BEAM_TO_PANDAS.get(typehint, np.object)\n+\n+  return pd.Series(name=name, dtype=dtype)\n \n \n def generate_proxy(element_type):\n   # type: (type) -> pd.DataFrame\n-  return pd.DataFrame({\n-      name: _make_empty_series(name, typ)\n-      for name,\n-      typ in named_fields_from_element_type(element_type)\n-  })\n+\n+  \"\"\" Generate a proxy pandas object for the given PCollection element_type.\n+\n+  Currently only supports generating a DataFrame proxy from a schema-aware\n+  PCollection.\"\"\"\n+  fields = named_fields_from_element_type(element_type)\n+  return pd.DataFrame(\n+      {name: _make_proxy_series(name, typehint)\n+       for name, typehint in fields},\n+      columns=[name for name, _ in fields])\n+\n+\n+def element_type_from_proxy(proxy):\n+  # type: (pd.DataFrame) -> type\n+\n+  \"\"\" Generate an element_type for an element-wise PCollection from a proxy\n+  pandas object. Currently only supports converting the element_type for\n+  a schema-aware PCollection to a proxy DataFrame.\n+\n+  Currently only supports generating a DataFrame proxy from a schema-aware\n+  PCollection.\"\"\"\n+  indices = [] if proxy.index.names == (None, ) else [", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTY2NTQwNg=="}, "originalCommit": {"oid": "b93cb4d23bdabf1b82f6f378c34bc9677186ffc6"}, "originalPosition": 179}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjMzMDE4NA==", "bodyText": "I added an include_indexes option on DataframeTransform, to_pcollection, and UnbatchPandas. It raises an exception if used when index names are not unique or unnamed. PTAL", "url": "https://github.com/apache/beam/pull/12882#discussion_r492330184", "createdAt": "2020-09-21T20:34:44Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/schemas.py", "diffHunk": "@@ -55,17 +159,149 @@ def expand(self, pcoll):\n         lambda batch: pd.DataFrame.from_records(batch, columns=columns))\n \n \n-def _make_empty_series(name, typ):\n-  try:\n-    return pd.Series(name=name, dtype=typ)\n-  except TypeError:\n-    raise TypeError(\"Unable to convert type '%s' for field '%s'\" % (name, typ))\n+def _make_proxy_series(name, typehint):\n+  # Default to np.object. This is lossy, we won't be able to recover the type\n+  # at the output.\n+  dtype = BEAM_TO_PANDAS.get(typehint, np.object)\n+\n+  return pd.Series(name=name, dtype=dtype)\n \n \n def generate_proxy(element_type):\n   # type: (type) -> pd.DataFrame\n-  return pd.DataFrame({\n-      name: _make_empty_series(name, typ)\n-      for name,\n-      typ in named_fields_from_element_type(element_type)\n-  })\n+\n+  \"\"\" Generate a proxy pandas object for the given PCollection element_type.\n+\n+  Currently only supports generating a DataFrame proxy from a schema-aware\n+  PCollection.\"\"\"\n+  fields = named_fields_from_element_type(element_type)\n+  return pd.DataFrame(\n+      {name: _make_proxy_series(name, typehint)\n+       for name, typehint in fields},\n+      columns=[name for name, _ in fields])\n+\n+\n+def element_type_from_proxy(proxy):\n+  # type: (pd.DataFrame) -> type\n+\n+  \"\"\" Generate an element_type for an element-wise PCollection from a proxy\n+  pandas object. Currently only supports converting the element_type for\n+  a schema-aware PCollection to a proxy DataFrame.\n+\n+  Currently only supports generating a DataFrame proxy from a schema-aware\n+  PCollection.\"\"\"\n+  indices = [] if proxy.index.names == (None, ) else [", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTY2NTQwNg=="}, "originalCommit": {"oid": "b93cb4d23bdabf1b82f6f378c34bc9677186ffc6"}, "originalPosition": 179}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjQ2NTI5NA==", "bodyText": "+1 We should probably allow an explicit include_indexes=False to not raise an exception.", "url": "https://github.com/apache/beam/pull/12882#discussion_r492465294", "createdAt": "2020-09-22T04:15:29Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/schemas.py", "diffHunk": "@@ -55,17 +159,149 @@ def expand(self, pcoll):\n         lambda batch: pd.DataFrame.from_records(batch, columns=columns))\n \n \n-def _make_empty_series(name, typ):\n-  try:\n-    return pd.Series(name=name, dtype=typ)\n-  except TypeError:\n-    raise TypeError(\"Unable to convert type '%s' for field '%s'\" % (name, typ))\n+def _make_proxy_series(name, typehint):\n+  # Default to np.object. This is lossy, we won't be able to recover the type\n+  # at the output.\n+  dtype = BEAM_TO_PANDAS.get(typehint, np.object)\n+\n+  return pd.Series(name=name, dtype=dtype)\n \n \n def generate_proxy(element_type):\n   # type: (type) -> pd.DataFrame\n-  return pd.DataFrame({\n-      name: _make_empty_series(name, typ)\n-      for name,\n-      typ in named_fields_from_element_type(element_type)\n-  })\n+\n+  \"\"\" Generate a proxy pandas object for the given PCollection element_type.\n+\n+  Currently only supports generating a DataFrame proxy from a schema-aware\n+  PCollection.\"\"\"\n+  fields = named_fields_from_element_type(element_type)\n+  return pd.DataFrame(\n+      {name: _make_proxy_series(name, typehint)\n+       for name, typehint in fields},\n+      columns=[name for name, _ in fields])\n+\n+\n+def element_type_from_proxy(proxy):\n+  # type: (pd.DataFrame) -> type\n+\n+  \"\"\" Generate an element_type for an element-wise PCollection from a proxy\n+  pandas object. Currently only supports converting the element_type for\n+  a schema-aware PCollection to a proxy DataFrame.\n+\n+  Currently only supports generating a DataFrame proxy from a schema-aware\n+  PCollection.\"\"\"\n+  indices = [] if proxy.index.names == (None, ) else [", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTY2NTQwNg=="}, "originalCommit": {"oid": "b93cb4d23bdabf1b82f6f378c34bc9677186ffc6"}, "originalPosition": 179}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA3NjU2MDczOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/schemas.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMFQwODowMTo1MlrOHU45_A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yMVQyMDozMjowN1rOHVhX1w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTY2NTkxNg==", "bodyText": "Maybe ..._from_dataframe? (Proxy may not be a dataframe.)", "url": "https://github.com/apache/beam/pull/12882#discussion_r491665916", "createdAt": "2020-09-20T08:01:52Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/schemas.py", "diffHunk": "@@ -55,17 +159,149 @@ def expand(self, pcoll):\n         lambda batch: pd.DataFrame.from_records(batch, columns=columns))\n \n \n-def _make_empty_series(name, typ):\n-  try:\n-    return pd.Series(name=name, dtype=typ)\n-  except TypeError:\n-    raise TypeError(\"Unable to convert type '%s' for field '%s'\" % (name, typ))\n+def _make_proxy_series(name, typehint):\n+  # Default to np.object. This is lossy, we won't be able to recover the type\n+  # at the output.\n+  dtype = BEAM_TO_PANDAS.get(typehint, np.object)\n+\n+  return pd.Series(name=name, dtype=dtype)\n \n \n def generate_proxy(element_type):\n   # type: (type) -> pd.DataFrame\n-  return pd.DataFrame({\n-      name: _make_empty_series(name, typ)\n-      for name,\n-      typ in named_fields_from_element_type(element_type)\n-  })\n+\n+  \"\"\" Generate a proxy pandas object for the given PCollection element_type.\n+\n+  Currently only supports generating a DataFrame proxy from a schema-aware\n+  PCollection.\"\"\"\n+  fields = named_fields_from_element_type(element_type)\n+  return pd.DataFrame(\n+      {name: _make_proxy_series(name, typehint)\n+       for name, typehint in fields},\n+      columns=[name for name, _ in fields])\n+\n+\n+def element_type_from_proxy(proxy):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b93cb4d23bdabf1b82f6f378c34bc9677186ffc6"}, "originalPosition": 170}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MjMyODkxOQ==", "bodyText": "Done", "url": "https://github.com/apache/beam/pull/12882#discussion_r492328919", "createdAt": "2020-09-21T20:32:07Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/schemas.py", "diffHunk": "@@ -55,17 +159,149 @@ def expand(self, pcoll):\n         lambda batch: pd.DataFrame.from_records(batch, columns=columns))\n \n \n-def _make_empty_series(name, typ):\n-  try:\n-    return pd.Series(name=name, dtype=typ)\n-  except TypeError:\n-    raise TypeError(\"Unable to convert type '%s' for field '%s'\" % (name, typ))\n+def _make_proxy_series(name, typehint):\n+  # Default to np.object. This is lossy, we won't be able to recover the type\n+  # at the output.\n+  dtype = BEAM_TO_PANDAS.get(typehint, np.object)\n+\n+  return pd.Series(name=name, dtype=dtype)\n \n \n def generate_proxy(element_type):\n   # type: (type) -> pd.DataFrame\n-  return pd.DataFrame({\n-      name: _make_empty_series(name, typ)\n-      for name,\n-      typ in named_fields_from_element_type(element_type)\n-  })\n+\n+  \"\"\" Generate a proxy pandas object for the given PCollection element_type.\n+\n+  Currently only supports generating a DataFrame proxy from a schema-aware\n+  PCollection.\"\"\"\n+  fields = named_fields_from_element_type(element_type)\n+  return pd.DataFrame(\n+      {name: _make_proxy_series(name, typehint)\n+       for name, typehint in fields},\n+      columns=[name for name, _ in fields])\n+\n+\n+def element_type_from_proxy(proxy):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTY2NTkxNg=="}, "originalCommit": {"oid": "b93cb4d23bdabf1b82f6f378c34bc9677186ffc6"}, "originalPosition": 170}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA4OTg3MjExOnYy", "diffSide": "LEFT", "path": "build.gradle", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QxNjowNDoxNVrOHW10hA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QxNjowNDoxNVrOHW10hA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzcxMjUxNg==", "bodyText": "FYI @tvalentyn I just merged this PR including a commit to drop python 3.5 in the precommit", "url": "https://github.com/apache/beam/pull/12882#discussion_r493712516", "createdAt": "2020-09-23T16:04:15Z", "author": {"login": "TheNeuralBit"}, "path": "build.gradle", "diffHunk": "@@ -199,7 +199,6 @@ task goIntegrationTests() {\n \n task pythonPreCommit() {\n   dependsOn \":sdks:python:test-suites:tox:pycommon:preCommitPyCommon\"\n-  dependsOn \":sdks:python:test-suites:tox:py35:preCommitPy35\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c86da9504b5ae300ec3b680f54123827db2887f9"}, "originalPosition": 4}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3172, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}