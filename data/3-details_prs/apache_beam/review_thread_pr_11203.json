{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzkyNzI1MDYx", "number": 11203, "reviewThreads": {"totalCount": 18, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QxODozNzozNVrODsL17w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQwMjoyNDowMlrODs6-fw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ3NjU3OTY3OnYy", "diffSide": "RIGHT", "path": "model/job-management/src/main/proto/beam_artifact_api.proto", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QxODozNzozNVrOF89h0w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QxODozNzozNVrOF89h0w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTQ2Njk2Mw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            // A client calls the service with an ArtifactResponseWrapper that has the\n          \n          \n            \n            //\n          \n          \n            \n            // A client calls the service with an ArtifactResponseWrapper that has the", "url": "https://github.com/apache/beam/pull/11203#discussion_r399466963", "createdAt": "2020-03-27T18:37:35Z", "author": {"login": "lukecwik"}, "path": "model/job-management/src/main/proto/beam_artifact_api.proto", "diffHunk": "@@ -31,8 +31,77 @@ option java_outer_classname = \"ArtifactApi\";\n \n import \"beam_runner_api.proto\";\n \n-// A service to stage artifacts for use in a Job.\n+// A service to retrieve artifacts for use in a Job.\n+service ArtifactRetrievalService {\n+  // Resolves the given artifact reference into one or more simpler artifact\n+  // references (e.g. a Maven dependency into a (transitive) set of jars.\n+  // If no further simplification is possible, returns the original artifacts,\n+  // at which point, all artifacts must be gettable.\n+  rpc ResolveArtifact(ResolveArtifactRequest) returns (ResolveArtifactResponse);\n+\n+  // Retrieves the given artifact as a stream of bytes.\n+  rpc GetArtifact(GetArtifactRequest) returns (stream GetArtifactResponse);\n+}\n+\n+// A service that allows the client to act as an ArtifactRetrievalService,\n+// for a particular job with the server initiating requests and receiving\n+// responses.\n+// A client calls the service with an ArtifactResponseWrapper that has the", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "643c2cbbdb03b9b719946b137775a52278c34550"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ3NjU4MzI0OnYy", "diffSide": "RIGHT", "path": "model/job-management/src/main/proto/beam_artifact_api.proto", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QxODozODozNlrOF89j_Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QxODozODozNlrOF89j_Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTQ2NzUxNw==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              org.apache.beam.model.pipeline.v1.ArtifactInformation artifact = 2;\n          \n          \n            \n              org.apache.beam.model.pipeline.v1.ArtifactInformation artifact = 1;", "url": "https://github.com/apache/beam/pull/11203#discussion_r399467517", "createdAt": "2020-03-27T18:38:36Z", "author": {"login": "lukecwik"}, "path": "model/job-management/src/main/proto/beam_artifact_api.proto", "diffHunk": "@@ -31,8 +31,77 @@ option java_outer_classname = \"ArtifactApi\";\n \n import \"beam_runner_api.proto\";\n \n-// A service to stage artifacts for use in a Job.\n+// A service to retrieve artifacts for use in a Job.\n+service ArtifactRetrievalService {\n+  // Resolves the given artifact reference into one or more simpler artifact\n+  // references (e.g. a Maven dependency into a (transitive) set of jars.\n+  // If no further simplification is possible, returns the original artifacts,\n+  // at which point, all artifacts must be gettable.\n+  rpc ResolveArtifact(ResolveArtifactRequest) returns (ResolveArtifactResponse);\n+\n+  // Retrieves the given artifact as a stream of bytes.\n+  rpc GetArtifact(GetArtifactRequest) returns (stream GetArtifactResponse);\n+}\n+\n+// A service that allows the client to act as an ArtifactRetrievalService,\n+// for a particular job with the server initiating requests and receiving\n+// responses.\n+// A client calls the service with an ArtifactResponseWrapper that has the\n+// staging token set, and thereafter responds to the server's requests.\n service ArtifactStagingService {\n+  rpc ReverseArtifactRetrievalService(stream ArtifactResponseWrapper)\n+      returns (stream ArtifactRequestWrapper);\n+}\n+\n+// A request for artifact resolution.\n+message ResolveArtifactRequest {\n+  repeated org.apache.beam.model.pipeline.v1.ArtifactInformation artifacts = 1;\n+}\n+\n+// A response for artifact resolution.\n+message ResolveArtifactResponse {\n+  repeated org.apache.beam.model.pipeline.v1.ArtifactInformation replacements = 1;\n+}\n+\n+// A request to get an artifact.\n+message GetArtifactRequest {\n+  org.apache.beam.model.pipeline.v1.ArtifactInformation artifact = 2;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "643c2cbbdb03b9b719946b137775a52278c34550"}, "originalPosition": 39}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ3NjU5NTU3OnYy", "diffSide": "RIGHT", "path": "model/job-management/src/main/proto/beam_artifact_api.proto", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QxODo0MjoxM1rOF89rkQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QyMzozMzozM1rOF9EmhQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTQ2OTQ1Nw==", "bodyText": "Some documentation questions:\nIs this meant to completely replace the artifacts supplied in replacements?\nWhat if a user doesn't pass in all the original artifacts?\nIf something can't be \"resolved\" to something simpler, does it still appear in the output?", "url": "https://github.com/apache/beam/pull/11203#discussion_r399469457", "createdAt": "2020-03-27T18:42:13Z", "author": {"login": "lukecwik"}, "path": "model/job-management/src/main/proto/beam_artifact_api.proto", "diffHunk": "@@ -31,8 +31,77 @@ option java_outer_classname = \"ArtifactApi\";\n \n import \"beam_runner_api.proto\";\n \n-// A service to stage artifacts for use in a Job.\n+// A service to retrieve artifacts for use in a Job.\n+service ArtifactRetrievalService {\n+  // Resolves the given artifact reference into one or more simpler artifact\n+  // references (e.g. a Maven dependency into a (transitive) set of jars.\n+  // If no further simplification is possible, returns the original artifacts,\n+  // at which point, all artifacts must be gettable.\n+  rpc ResolveArtifact(ResolveArtifactRequest) returns (ResolveArtifactResponse);\n+\n+  // Retrieves the given artifact as a stream of bytes.\n+  rpc GetArtifact(GetArtifactRequest) returns (stream GetArtifactResponse);\n+}\n+\n+// A service that allows the client to act as an ArtifactRetrievalService,\n+// for a particular job with the server initiating requests and receiving\n+// responses.\n+// A client calls the service with an ArtifactResponseWrapper that has the\n+// staging token set, and thereafter responds to the server's requests.\n service ArtifactStagingService {\n+  rpc ReverseArtifactRetrievalService(stream ArtifactResponseWrapper)\n+      returns (stream ArtifactRequestWrapper);\n+}\n+\n+// A request for artifact resolution.\n+message ResolveArtifactRequest {\n+  repeated org.apache.beam.model.pipeline.v1.ArtifactInformation artifacts = 1;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "643c2cbbdb03b9b719946b137775a52278c34550"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU4MDgwNA==", "bodyText": "Yes, updated the documentation.", "url": "https://github.com/apache/beam/pull/11203#discussion_r399580804", "createdAt": "2020-03-27T23:24:29Z", "author": {"login": "robertwb"}, "path": "model/job-management/src/main/proto/beam_artifact_api.proto", "diffHunk": "@@ -31,8 +31,77 @@ option java_outer_classname = \"ArtifactApi\";\n \n import \"beam_runner_api.proto\";\n \n-// A service to stage artifacts for use in a Job.\n+// A service to retrieve artifacts for use in a Job.\n+service ArtifactRetrievalService {\n+  // Resolves the given artifact reference into one or more simpler artifact\n+  // references (e.g. a Maven dependency into a (transitive) set of jars.\n+  // If no further simplification is possible, returns the original artifacts,\n+  // at which point, all artifacts must be gettable.\n+  rpc ResolveArtifact(ResolveArtifactRequest) returns (ResolveArtifactResponse);\n+\n+  // Retrieves the given artifact as a stream of bytes.\n+  rpc GetArtifact(GetArtifactRequest) returns (stream GetArtifactResponse);\n+}\n+\n+// A service that allows the client to act as an ArtifactRetrievalService,\n+// for a particular job with the server initiating requests and receiving\n+// responses.\n+// A client calls the service with an ArtifactResponseWrapper that has the\n+// staging token set, and thereafter responds to the server's requests.\n service ArtifactStagingService {\n+  rpc ReverseArtifactRetrievalService(stream ArtifactResponseWrapper)\n+      returns (stream ArtifactRequestWrapper);\n+}\n+\n+// A request for artifact resolution.\n+message ResolveArtifactRequest {\n+  repeated org.apache.beam.model.pipeline.v1.ArtifactInformation artifacts = 1;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTQ2OTQ1Nw=="}, "originalCommit": {"oid": "643c2cbbdb03b9b719946b137775a52278c34550"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU4Mjg1Mw==", "bodyText": "The documentation has been expanded.", "url": "https://github.com/apache/beam/pull/11203#discussion_r399582853", "createdAt": "2020-03-27T23:33:33Z", "author": {"login": "robertwb"}, "path": "model/job-management/src/main/proto/beam_artifact_api.proto", "diffHunk": "@@ -31,8 +31,77 @@ option java_outer_classname = \"ArtifactApi\";\n \n import \"beam_runner_api.proto\";\n \n-// A service to stage artifacts for use in a Job.\n+// A service to retrieve artifacts for use in a Job.\n+service ArtifactRetrievalService {\n+  // Resolves the given artifact reference into one or more simpler artifact\n+  // references (e.g. a Maven dependency into a (transitive) set of jars.\n+  // If no further simplification is possible, returns the original artifacts,\n+  // at which point, all artifacts must be gettable.\n+  rpc ResolveArtifact(ResolveArtifactRequest) returns (ResolveArtifactResponse);\n+\n+  // Retrieves the given artifact as a stream of bytes.\n+  rpc GetArtifact(GetArtifactRequest) returns (stream GetArtifactResponse);\n+}\n+\n+// A service that allows the client to act as an ArtifactRetrievalService,\n+// for a particular job with the server initiating requests and receiving\n+// responses.\n+// A client calls the service with an ArtifactResponseWrapper that has the\n+// staging token set, and thereafter responds to the server's requests.\n service ArtifactStagingService {\n+  rpc ReverseArtifactRetrievalService(stream ArtifactResponseWrapper)\n+      returns (stream ArtifactRequestWrapper);\n+}\n+\n+// A request for artifact resolution.\n+message ResolveArtifactRequest {\n+  repeated org.apache.beam.model.pipeline.v1.ArtifactInformation artifacts = 1;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTQ2OTQ1Nw=="}, "originalCommit": {"oid": "643c2cbbdb03b9b719946b137775a52278c34550"}, "originalPosition": 29}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ3NjYzMzQ2OnYy", "diffSide": "RIGHT", "path": "model/job-management/src/main/proto/beam_artifact_api.proto", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QxODo1MzoxMlrOF8-Cpg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQwMDowNjoxMFrOF-ApIw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTQ3NTM2Ng==", "bodyText": "Why do you not want the resolving to happen as part of GetArtifact?", "url": "https://github.com/apache/beam/pull/11203#discussion_r399475366", "createdAt": "2020-03-27T18:53:12Z", "author": {"login": "lukecwik"}, "path": "model/job-management/src/main/proto/beam_artifact_api.proto", "diffHunk": "@@ -31,8 +31,77 @@ option java_outer_classname = \"ArtifactApi\";\n \n import \"beam_runner_api.proto\";\n \n-// A service to stage artifacts for use in a Job.\n+// A service to retrieve artifacts for use in a Job.\n+service ArtifactRetrievalService {\n+  // Resolves the given artifact reference into one or more simpler artifact\n+  // references (e.g. a Maven dependency into a (transitive) set of jars.\n+  // If no further simplification is possible, returns the original artifacts,\n+  // at which point, all artifacts must be gettable.\n+  rpc ResolveArtifact(ResolveArtifactRequest) returns (ResolveArtifactResponse);\n+\n+  // Retrieves the given artifact as a stream of bytes.\n+  rpc GetArtifact(GetArtifactRequest) returns (stream GetArtifactResponse);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "643c2cbbdb03b9b719946b137775a52278c34550"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDU2NjU2Mw==", "bodyText": "Resolution may expand a dependency into multiple distinct blobs. Also, it may be possible (likely?) that artifacts can be resolved into form the client can recognize (or at least deduplicate) obviating the need for a fetch.", "url": "https://github.com/apache/beam/pull/11203#discussion_r400566563", "createdAt": "2020-03-31T00:06:10Z", "author": {"login": "robertwb"}, "path": "model/job-management/src/main/proto/beam_artifact_api.proto", "diffHunk": "@@ -31,8 +31,77 @@ option java_outer_classname = \"ArtifactApi\";\n \n import \"beam_runner_api.proto\";\n \n-// A service to stage artifacts for use in a Job.\n+// A service to retrieve artifacts for use in a Job.\n+service ArtifactRetrievalService {\n+  // Resolves the given artifact reference into one or more simpler artifact\n+  // references (e.g. a Maven dependency into a (transitive) set of jars.\n+  // If no further simplification is possible, returns the original artifacts,\n+  // at which point, all artifacts must be gettable.\n+  rpc ResolveArtifact(ResolveArtifactRequest) returns (ResolveArtifactResponse);\n+\n+  // Retrieves the given artifact as a stream of bytes.\n+  rpc GetArtifact(GetArtifactRequest) returns (stream GetArtifactResponse);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTQ3NTM2Ng=="}, "originalCommit": {"oid": "643c2cbbdb03b9b719946b137775a52278c34550"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ3Njc4NDM0OnYy", "diffSide": "RIGHT", "path": "model/job-management/src/main/proto/beam_artifact_api.proto", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QxOTozOTo0NVrOF8_fnA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QyMzoyODo0OVrOF9EidQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTQ5OTE2NA==", "bodyText": "The style of this stream won't allow for parallel requests to be send to the client since there is no id mechanism to diffentiate the responses since every request will have to have wait for the is_last to be set before the next request is sent out. If you want to support parallel requests, you also need to have a place to provide errors outside of the gRPC status that can be returned since you'll want to identify which request had a problem.\nAlso, if there are any errors for a single request, the whole RPC needs to be terminated since there is no way to say which request failed.\nSince Java has typically a lot of jars, it is likely that we'll want to be able to parallelize this.", "url": "https://github.com/apache/beam/pull/11203#discussion_r399499164", "createdAt": "2020-03-27T19:39:45Z", "author": {"login": "lukecwik"}, "path": "model/job-management/src/main/proto/beam_artifact_api.proto", "diffHunk": "@@ -31,8 +31,77 @@ option java_outer_classname = \"ArtifactApi\";\n \n import \"beam_runner_api.proto\";\n \n-// A service to stage artifacts for use in a Job.\n+// A service to retrieve artifacts for use in a Job.\n+service ArtifactRetrievalService {\n+  // Resolves the given artifact reference into one or more simpler artifact\n+  // references (e.g. a Maven dependency into a (transitive) set of jars.\n+  // If no further simplification is possible, returns the original artifacts,\n+  // at which point, all artifacts must be gettable.\n+  rpc ResolveArtifact(ResolveArtifactRequest) returns (ResolveArtifactResponse);\n+\n+  // Retrieves the given artifact as a stream of bytes.\n+  rpc GetArtifact(GetArtifactRequest) returns (stream GetArtifactResponse);\n+}\n+\n+// A service that allows the client to act as an ArtifactRetrievalService,\n+// for a particular job with the server initiating requests and receiving\n+// responses.\n+// A client calls the service with an ArtifactResponseWrapper that has the\n+// staging token set, and thereafter responds to the server's requests.\n service ArtifactStagingService {\n+  rpc ReverseArtifactRetrievalService(stream ArtifactResponseWrapper)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "643c2cbbdb03b9b719946b137775a52278c34550"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU4MTgxMw==", "bodyText": "Good question. As discussed offline, multiple requests can be pushed before waiting for a response, so we should be able to fill the network buffer. Either the server or client can choose to parallelize on its backend store as needed.\nI added an error field to the resolve_artifacts field as a runner may attempt to opportunistically consolidate environments, and then fall back to doing each separately.", "url": "https://github.com/apache/beam/pull/11203#discussion_r399581813", "createdAt": "2020-03-27T23:28:49Z", "author": {"login": "robertwb"}, "path": "model/job-management/src/main/proto/beam_artifact_api.proto", "diffHunk": "@@ -31,8 +31,77 @@ option java_outer_classname = \"ArtifactApi\";\n \n import \"beam_runner_api.proto\";\n \n-// A service to stage artifacts for use in a Job.\n+// A service to retrieve artifacts for use in a Job.\n+service ArtifactRetrievalService {\n+  // Resolves the given artifact reference into one or more simpler artifact\n+  // references (e.g. a Maven dependency into a (transitive) set of jars.\n+  // If no further simplification is possible, returns the original artifacts,\n+  // at which point, all artifacts must be gettable.\n+  rpc ResolveArtifact(ResolveArtifactRequest) returns (ResolveArtifactResponse);\n+\n+  // Retrieves the given artifact as a stream of bytes.\n+  rpc GetArtifact(GetArtifactRequest) returns (stream GetArtifactResponse);\n+}\n+\n+// A service that allows the client to act as an ArtifactRetrievalService,\n+// for a particular job with the server initiating requests and receiving\n+// responses.\n+// A client calls the service with an ArtifactResponseWrapper that has the\n+// staging token set, and thereafter responds to the server's requests.\n service ArtifactStagingService {\n+  rpc ReverseArtifactRetrievalService(stream ArtifactResponseWrapper)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTQ5OTE2NA=="}, "originalCommit": {"oid": "643c2cbbdb03b9b719946b137775a52278c34550"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ3Njc5NzQ2OnYy", "diffSide": "RIGHT", "path": "model/job-management/src/main/proto/beam_artifact_api.proto", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QxOTo0NDoxNFrOF8_nzA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QxOTo0NDoxNFrOF8_nzA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTUwMTI2MA==", "bodyText": "I can see that your trying to set this up so that the staging service can make calls to the SDK so that this way it can get artifacts that are created by the expansion service.", "url": "https://github.com/apache/beam/pull/11203#discussion_r399501260", "createdAt": "2020-03-27T19:44:14Z", "author": {"login": "lukecwik"}, "path": "model/job-management/src/main/proto/beam_artifact_api.proto", "diffHunk": "@@ -31,8 +31,77 @@ option java_outer_classname = \"ArtifactApi\";\n \n import \"beam_runner_api.proto\";\n \n-// A service to stage artifacts for use in a Job.\n+// A service to retrieve artifacts for use in a Job.\n+service ArtifactRetrievalService {\n+  // Resolves the given artifact reference into one or more simpler artifact\n+  // references (e.g. a Maven dependency into a (transitive) set of jars.\n+  // If no further simplification is possible, returns the original artifacts,\n+  // at which point, all artifacts must be gettable.\n+  rpc ResolveArtifact(ResolveArtifactRequest) returns (ResolveArtifactResponse);\n+\n+  // Retrieves the given artifact as a stream of bytes.\n+  rpc GetArtifact(GetArtifactRequest) returns (stream GetArtifactResponse);\n+}\n+\n+// A service that allows the client to act as an ArtifactRetrievalService,\n+// for a particular job with the server initiating requests and receiving\n+// responses.\n+// A client calls the service with an ArtifactResponseWrapper that has the\n+// staging token set, and thereafter responds to the server's requests.\n service ArtifactStagingService {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "643c2cbbdb03b9b719946b137775a52278c34550"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ3NjgwMTI5OnYy", "diffSide": "RIGHT", "path": "model/job-management/src/main/proto/beam_artifact_api.proto", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QxOTo0NToyNlrOF8_qBg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QyMzozNToyOVrOF9EoMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTUwMTgzMA==", "bodyText": "What does simpler mean?, should the request contain a supported set of urns for types and roles?", "url": "https://github.com/apache/beam/pull/11203#discussion_r399501830", "createdAt": "2020-03-27T19:45:26Z", "author": {"login": "lukecwik"}, "path": "model/job-management/src/main/proto/beam_artifact_api.proto", "diffHunk": "@@ -31,8 +31,77 @@ option java_outer_classname = \"ArtifactApi\";\n \n import \"beam_runner_api.proto\";\n \n-// A service to stage artifacts for use in a Job.\n+// A service to retrieve artifacts for use in a Job.\n+service ArtifactRetrievalService {\n+  // Resolves the given artifact reference into one or more simpler artifact\n+  // references (e.g. a Maven dependency into a (transitive) set of jars.\n+  // If no further simplification is possible, returns the original artifacts,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "643c2cbbdb03b9b719946b137775a52278c34550"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU4MzI4MQ==", "bodyText": "Clarified in the docs.", "url": "https://github.com/apache/beam/pull/11203#discussion_r399583281", "createdAt": "2020-03-27T23:35:29Z", "author": {"login": "robertwb"}, "path": "model/job-management/src/main/proto/beam_artifact_api.proto", "diffHunk": "@@ -31,8 +31,77 @@ option java_outer_classname = \"ArtifactApi\";\n \n import \"beam_runner_api.proto\";\n \n-// A service to stage artifacts for use in a Job.\n+// A service to retrieve artifacts for use in a Job.\n+service ArtifactRetrievalService {\n+  // Resolves the given artifact reference into one or more simpler artifact\n+  // references (e.g. a Maven dependency into a (transitive) set of jars.\n+  // If no further simplification is possible, returns the original artifacts,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTUwMTgzMA=="}, "originalCommit": {"oid": "643c2cbbdb03b9b719946b137775a52278c34550"}, "originalPosition": 9}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4MzQyMjUxOnYy", "diffSide": "RIGHT", "path": "model/job-management/src/main/proto/beam_artifact_api.proto", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQyMDoxNzowNlrOF96khA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQwMjozMzoxNFrOF-DGvQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQ2NzA3Ng==", "bodyText": "Is this an ordered list, things that appear first are more preferred then things that appear later?\nIf so, we should make that clear.", "url": "https://github.com/apache/beam/pull/11203#discussion_r400467076", "createdAt": "2020-03-30T20:17:06Z", "author": {"login": "lukecwik"}, "path": "model/job-management/src/main/proto/beam_artifact_api.proto", "diffHunk": "@@ -31,8 +31,92 @@ option java_outer_classname = \"ArtifactApi\";\n \n import \"beam_runner_api.proto\";\n \n-// A service to stage artifacts for use in a Job.\n+// A service to retrieve artifacts for use in a Job.\n+service ArtifactRetrievalService {\n+  // Resolves the given artifact references into one or more replacement\n+  // artifact references (e.g. a Maven dependency into a (transitive) set\n+  // of jars.\n+  rpc ResolveArtifact(ResolveArtifactRequest) returns (ResolveArtifactResponse);\n+\n+  // Retrieves the given artifact as a stream of bytes.\n+  rpc GetArtifact(GetArtifactRequest) returns (stream GetArtifactResponse);\n+}\n+\n+// A service that allows the client to act as an ArtifactRetrievalService,\n+// for a particular job with the server initiating requests and receiving\n+// responses.\n+//\n+// A client calls the service with an ArtifactResponseWrapper that has the\n+// staging token set, and thereafter responds to the server's requests.\n service ArtifactStagingService {\n+  rpc ReverseArtifactRetrievalService(stream ArtifactResponseWrapper)\n+      returns (stream ArtifactRequestWrapper);\n+}\n+\n+// A request for artifact resolution.\n+message ResolveArtifactRequest {\n+  // A set of artifacts to (jointly) resolve.\n+  repeated org.apache.beam.model.pipeline.v1.ArtifactInformation artifacts = 1;\n+\n+  // A set of artifact type urns that are understood by the requester.\n+  // An attempt should be made to resolve the artifacts in terms of these URNs,\n+  // but other URNs may be used as well with the understanding that they must\n+  // be fetch-able as bytes via GetArtifact.\n+  repeated string preferred_urns = 2;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f10daf5ecc47d57a53e87e9a7bb8845a72f99b4c"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDU2NzQ4MQ==", "bodyText": "I was not intending for this to be an ordered list; I think the choice of artifact will governed more by the existing placement of the artifact.", "url": "https://github.com/apache/beam/pull/11203#discussion_r400567481", "createdAt": "2020-03-31T00:09:08Z", "author": {"login": "robertwb"}, "path": "model/job-management/src/main/proto/beam_artifact_api.proto", "diffHunk": "@@ -31,8 +31,92 @@ option java_outer_classname = \"ArtifactApi\";\n \n import \"beam_runner_api.proto\";\n \n-// A service to stage artifacts for use in a Job.\n+// A service to retrieve artifacts for use in a Job.\n+service ArtifactRetrievalService {\n+  // Resolves the given artifact references into one or more replacement\n+  // artifact references (e.g. a Maven dependency into a (transitive) set\n+  // of jars.\n+  rpc ResolveArtifact(ResolveArtifactRequest) returns (ResolveArtifactResponse);\n+\n+  // Retrieves the given artifact as a stream of bytes.\n+  rpc GetArtifact(GetArtifactRequest) returns (stream GetArtifactResponse);\n+}\n+\n+// A service that allows the client to act as an ArtifactRetrievalService,\n+// for a particular job with the server initiating requests and receiving\n+// responses.\n+//\n+// A client calls the service with an ArtifactResponseWrapper that has the\n+// staging token set, and thereafter responds to the server's requests.\n service ArtifactStagingService {\n+  rpc ReverseArtifactRetrievalService(stream ArtifactResponseWrapper)\n+      returns (stream ArtifactRequestWrapper);\n+}\n+\n+// A request for artifact resolution.\n+message ResolveArtifactRequest {\n+  // A set of artifacts to (jointly) resolve.\n+  repeated org.apache.beam.model.pipeline.v1.ArtifactInformation artifacts = 1;\n+\n+  // A set of artifact type urns that are understood by the requester.\n+  // An attempt should be made to resolve the artifacts in terms of these URNs,\n+  // but other URNs may be used as well with the understanding that they must\n+  // be fetch-able as bytes via GetArtifact.\n+  repeated string preferred_urns = 2;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQ2NzA3Ng=="}, "originalCommit": {"oid": "f10daf5ecc47d57a53e87e9a7bb8845a72f99b4c"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDYwNjkwOQ==", "bodyText": "We don't have to answer this question as part of this PR as it involves a much smaller subset so if you address the other parts then LGTM.\nImagine we added the deferred artifact, would resolving be allowed to return the deferred artifact again?\nWhat would Get do for a deferred artifact?", "url": "https://github.com/apache/beam/pull/11203#discussion_r400606909", "createdAt": "2020-03-31T02:33:14Z", "author": {"login": "lukecwik"}, "path": "model/job-management/src/main/proto/beam_artifact_api.proto", "diffHunk": "@@ -31,8 +31,92 @@ option java_outer_classname = \"ArtifactApi\";\n \n import \"beam_runner_api.proto\";\n \n-// A service to stage artifacts for use in a Job.\n+// A service to retrieve artifacts for use in a Job.\n+service ArtifactRetrievalService {\n+  // Resolves the given artifact references into one or more replacement\n+  // artifact references (e.g. a Maven dependency into a (transitive) set\n+  // of jars.\n+  rpc ResolveArtifact(ResolveArtifactRequest) returns (ResolveArtifactResponse);\n+\n+  // Retrieves the given artifact as a stream of bytes.\n+  rpc GetArtifact(GetArtifactRequest) returns (stream GetArtifactResponse);\n+}\n+\n+// A service that allows the client to act as an ArtifactRetrievalService,\n+// for a particular job with the server initiating requests and receiving\n+// responses.\n+//\n+// A client calls the service with an ArtifactResponseWrapper that has the\n+// staging token set, and thereafter responds to the server's requests.\n service ArtifactStagingService {\n+  rpc ReverseArtifactRetrievalService(stream ArtifactResponseWrapper)\n+      returns (stream ArtifactRequestWrapper);\n+}\n+\n+// A request for artifact resolution.\n+message ResolveArtifactRequest {\n+  // A set of artifacts to (jointly) resolve.\n+  repeated org.apache.beam.model.pipeline.v1.ArtifactInformation artifacts = 1;\n+\n+  // A set of artifact type urns that are understood by the requester.\n+  // An attempt should be made to resolve the artifacts in terms of these URNs,\n+  // but other URNs may be used as well with the understanding that they must\n+  // be fetch-able as bytes via GetArtifact.\n+  repeated string preferred_urns = 2;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQ2NzA3Ng=="}, "originalCommit": {"oid": "f10daf5ecc47d57a53e87e9a7bb8845a72f99b4c"}, "originalPosition": 36}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4MzQyNzgxOnYy", "diffSide": "RIGHT", "path": "model/job-management/src/main/proto/beam_artifact_api.proto", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQyMDoxODo0MFrOF96n_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQwMDowNjo1N1rOF-Ap8A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQ2Nzk2Ng==", "bodyText": "It is important to point out that the artifact information / ordering is important in both the request and the response since in Java this would represent the classpath. So artifacts should be passed in the expected order of usage and returned in an expected order of usage.", "url": "https://github.com/apache/beam/pull/11203#discussion_r400467966", "createdAt": "2020-03-30T20:18:40Z", "author": {"login": "lukecwik"}, "path": "model/job-management/src/main/proto/beam_artifact_api.proto", "diffHunk": "@@ -31,8 +31,92 @@ option java_outer_classname = \"ArtifactApi\";\n \n import \"beam_runner_api.proto\";\n \n-// A service to stage artifacts for use in a Job.\n+// A service to retrieve artifacts for use in a Job.\n+service ArtifactRetrievalService {\n+  // Resolves the given artifact references into one or more replacement\n+  // artifact references (e.g. a Maven dependency into a (transitive) set\n+  // of jars.\n+  rpc ResolveArtifact(ResolveArtifactRequest) returns (ResolveArtifactResponse);\n+\n+  // Retrieves the given artifact as a stream of bytes.\n+  rpc GetArtifact(GetArtifactRequest) returns (stream GetArtifactResponse);\n+}\n+\n+// A service that allows the client to act as an ArtifactRetrievalService,\n+// for a particular job with the server initiating requests and receiving\n+// responses.\n+//\n+// A client calls the service with an ArtifactResponseWrapper that has the\n+// staging token set, and thereafter responds to the server's requests.\n service ArtifactStagingService {\n+  rpc ReverseArtifactRetrievalService(stream ArtifactResponseWrapper)\n+      returns (stream ArtifactRequestWrapper);\n+}\n+\n+// A request for artifact resolution.\n+message ResolveArtifactRequest {\n+  // A set of artifacts to (jointly) resolve.\n+  repeated org.apache.beam.model.pipeline.v1.ArtifactInformation artifacts = 1;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f10daf5ecc47d57a53e87e9a7bb8845a72f99b4c"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDU2Njc2OA==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/11203#discussion_r400566768", "createdAt": "2020-03-31T00:06:57Z", "author": {"login": "robertwb"}, "path": "model/job-management/src/main/proto/beam_artifact_api.proto", "diffHunk": "@@ -31,8 +31,92 @@ option java_outer_classname = \"ArtifactApi\";\n \n import \"beam_runner_api.proto\";\n \n-// A service to stage artifacts for use in a Job.\n+// A service to retrieve artifacts for use in a Job.\n+service ArtifactRetrievalService {\n+  // Resolves the given artifact references into one or more replacement\n+  // artifact references (e.g. a Maven dependency into a (transitive) set\n+  // of jars.\n+  rpc ResolveArtifact(ResolveArtifactRequest) returns (ResolveArtifactResponse);\n+\n+  // Retrieves the given artifact as a stream of bytes.\n+  rpc GetArtifact(GetArtifactRequest) returns (stream GetArtifactResponse);\n+}\n+\n+// A service that allows the client to act as an ArtifactRetrievalService,\n+// for a particular job with the server initiating requests and receiving\n+// responses.\n+//\n+// A client calls the service with an ArtifactResponseWrapper that has the\n+// staging token set, and thereafter responds to the server's requests.\n service ArtifactStagingService {\n+  rpc ReverseArtifactRetrievalService(stream ArtifactResponseWrapper)\n+      returns (stream ArtifactRequestWrapper);\n+}\n+\n+// A request for artifact resolution.\n+message ResolveArtifactRequest {\n+  // A set of artifacts to (jointly) resolve.\n+  repeated org.apache.beam.model.pipeline.v1.ArtifactInformation artifacts = 1;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQ2Nzk2Ng=="}, "originalCommit": {"oid": "f10daf5ecc47d57a53e87e9a7bb8845a72f99b4c"}, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4MzQzMTEyOnYy", "diffSide": "RIGHT", "path": "model/job-management/src/main/proto/beam_artifact_api.proto", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQyMDoxOTo0MVrOF96qIA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQwMDoxODo1NFrOF-A3zA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQ2ODUxMg==", "bodyText": "I don't believe this error message will be actionable.\nA runner makes a request to resolve A -> B. If it doesn't understand what A is then an error during resolution won't really be actionable to the runner and I don't believe will be significantly better then terminating the whole streaming RPC with the failure. Lets say the runner could also try A -> C, then it should have listed in the preferred URNs B and C and the resolver would choose a valid combination.", "url": "https://github.com/apache/beam/pull/11203#discussion_r400468512", "createdAt": "2020-03-30T20:19:41Z", "author": {"login": "lukecwik"}, "path": "model/job-management/src/main/proto/beam_artifact_api.proto", "diffHunk": "@@ -31,8 +31,92 @@ option java_outer_classname = \"ArtifactApi\";\n \n import \"beam_runner_api.proto\";\n \n-// A service to stage artifacts for use in a Job.\n+// A service to retrieve artifacts for use in a Job.\n+service ArtifactRetrievalService {\n+  // Resolves the given artifact references into one or more replacement\n+  // artifact references (e.g. a Maven dependency into a (transitive) set\n+  // of jars.\n+  rpc ResolveArtifact(ResolveArtifactRequest) returns (ResolveArtifactResponse);\n+\n+  // Retrieves the given artifact as a stream of bytes.\n+  rpc GetArtifact(GetArtifactRequest) returns (stream GetArtifactResponse);\n+}\n+\n+// A service that allows the client to act as an ArtifactRetrievalService,\n+// for a particular job with the server initiating requests and receiving\n+// responses.\n+//\n+// A client calls the service with an ArtifactResponseWrapper that has the\n+// staging token set, and thereafter responds to the server's requests.\n service ArtifactStagingService {\n+  rpc ReverseArtifactRetrievalService(stream ArtifactResponseWrapper)\n+      returns (stream ArtifactRequestWrapper);\n+}\n+\n+// A request for artifact resolution.\n+message ResolveArtifactRequest {\n+  // A set of artifacts to (jointly) resolve.\n+  repeated org.apache.beam.model.pipeline.v1.ArtifactInformation artifacts = 1;\n+\n+  // A set of artifact type urns that are understood by the requester.\n+  // An attempt should be made to resolve the artifacts in terms of these URNs,\n+  // but other URNs may be used as well with the understanding that they must\n+  // be fetch-able as bytes via GetArtifact.\n+  repeated string preferred_urns = 2;\n+}\n+\n+// A response for artifact resolution.\n+message ResolveArtifactResponse {\n+  // A full set of replacements for the set of requested artifacts, preferably\n+  // in terms of the requested type URNs.  If there is no better resolution,\n+  // the original list is returned.\n+  repeated org.apache.beam.model.pipeline.v1.ArtifactInformation replacements = 1;\n+\n+  // (Optional) If set, used to indicate the artifacts are mutually inconsistent\n+  // (e.g. due to a diamond dependency problem) or could otherwise not be\n+  // resolved (e.g. due to invalid specifications).\n+  string error = 2;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f10daf5ecc47d57a53e87e9a7bb8845a72f99b4c"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDU3MDMxNg==", "bodyText": "This was intended to be used for the merging of environments. Suppose one environment requires A and another requires B. It may be possible to provide a set of artifacts that satisfy both (e.g. if they were maven dependencies), or possibly not (if there was a diamond dependency problem, or they were opaque).\nI am now realizing that this probably needs to be a separate protocol, which can be introduced at a future date.", "url": "https://github.com/apache/beam/pull/11203#discussion_r400570316", "createdAt": "2020-03-31T00:18:54Z", "author": {"login": "robertwb"}, "path": "model/job-management/src/main/proto/beam_artifact_api.proto", "diffHunk": "@@ -31,8 +31,92 @@ option java_outer_classname = \"ArtifactApi\";\n \n import \"beam_runner_api.proto\";\n \n-// A service to stage artifacts for use in a Job.\n+// A service to retrieve artifacts for use in a Job.\n+service ArtifactRetrievalService {\n+  // Resolves the given artifact references into one or more replacement\n+  // artifact references (e.g. a Maven dependency into a (transitive) set\n+  // of jars.\n+  rpc ResolveArtifact(ResolveArtifactRequest) returns (ResolveArtifactResponse);\n+\n+  // Retrieves the given artifact as a stream of bytes.\n+  rpc GetArtifact(GetArtifactRequest) returns (stream GetArtifactResponse);\n+}\n+\n+// A service that allows the client to act as an ArtifactRetrievalService,\n+// for a particular job with the server initiating requests and receiving\n+// responses.\n+//\n+// A client calls the service with an ArtifactResponseWrapper that has the\n+// staging token set, and thereafter responds to the server's requests.\n service ArtifactStagingService {\n+  rpc ReverseArtifactRetrievalService(stream ArtifactResponseWrapper)\n+      returns (stream ArtifactRequestWrapper);\n+}\n+\n+// A request for artifact resolution.\n+message ResolveArtifactRequest {\n+  // A set of artifacts to (jointly) resolve.\n+  repeated org.apache.beam.model.pipeline.v1.ArtifactInformation artifacts = 1;\n+\n+  // A set of artifact type urns that are understood by the requester.\n+  // An attempt should be made to resolve the artifacts in terms of these URNs,\n+  // but other URNs may be used as well with the understanding that they must\n+  // be fetch-able as bytes via GetArtifact.\n+  repeated string preferred_urns = 2;\n+}\n+\n+// A response for artifact resolution.\n+message ResolveArtifactResponse {\n+  // A full set of replacements for the set of requested artifacts, preferably\n+  // in terms of the requested type URNs.  If there is no better resolution,\n+  // the original list is returned.\n+  repeated org.apache.beam.model.pipeline.v1.ArtifactInformation replacements = 1;\n+\n+  // (Optional) If set, used to indicate the artifacts are mutually inconsistent\n+  // (e.g. due to a diamond dependency problem) or could otherwise not be\n+  // resolved (e.g. due to invalid specifications).\n+  string error = 2;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQ2ODUxMg=="}, "originalCommit": {"oid": "f10daf5ecc47d57a53e87e9a7bb8845a72f99b4c"}, "originalPosition": 49}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4MzQ0NjIzOnYy", "diffSide": "RIGHT", "path": "model/job-management/src/main/proto/beam_artifact_api.proto", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQyMDoyNDoxMlrOF96ztw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQwMjozMDowNFrOF-DDuw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQ3MDk2Nw==", "bodyText": "Should we have a resume_offset field?\nWhenever we need to stage a large amount of data, it seems as though the SDK would reconnect so a \"retry\" would be possible and should be able to pass in a point to resume from for a large stream.", "url": "https://github.com/apache/beam/pull/11203#discussion_r400470967", "createdAt": "2020-03-30T20:24:12Z", "author": {"login": "lukecwik"}, "path": "model/job-management/src/main/proto/beam_artifact_api.proto", "diffHunk": "@@ -31,8 +31,92 @@ option java_outer_classname = \"ArtifactApi\";\n \n import \"beam_runner_api.proto\";\n \n-// A service to stage artifacts for use in a Job.\n+// A service to retrieve artifacts for use in a Job.\n+service ArtifactRetrievalService {\n+  // Resolves the given artifact references into one or more replacement\n+  // artifact references (e.g. a Maven dependency into a (transitive) set\n+  // of jars.\n+  rpc ResolveArtifact(ResolveArtifactRequest) returns (ResolveArtifactResponse);\n+\n+  // Retrieves the given artifact as a stream of bytes.\n+  rpc GetArtifact(GetArtifactRequest) returns (stream GetArtifactResponse);\n+}\n+\n+// A service that allows the client to act as an ArtifactRetrievalService,\n+// for a particular job with the server initiating requests and receiving\n+// responses.\n+//\n+// A client calls the service with an ArtifactResponseWrapper that has the\n+// staging token set, and thereafter responds to the server's requests.\n service ArtifactStagingService {\n+  rpc ReverseArtifactRetrievalService(stream ArtifactResponseWrapper)\n+      returns (stream ArtifactRequestWrapper);\n+}\n+\n+// A request for artifact resolution.\n+message ResolveArtifactRequest {\n+  // A set of artifacts to (jointly) resolve.\n+  repeated org.apache.beam.model.pipeline.v1.ArtifactInformation artifacts = 1;\n+\n+  // A set of artifact type urns that are understood by the requester.\n+  // An attempt should be made to resolve the artifacts in terms of these URNs,\n+  // but other URNs may be used as well with the understanding that they must\n+  // be fetch-able as bytes via GetArtifact.\n+  repeated string preferred_urns = 2;\n+}\n+\n+// A response for artifact resolution.\n+message ResolveArtifactResponse {\n+  // A full set of replacements for the set of requested artifacts, preferably\n+  // in terms of the requested type URNs.  If there is no better resolution,\n+  // the original list is returned.\n+  repeated org.apache.beam.model.pipeline.v1.ArtifactInformation replacements = 1;\n+\n+  // (Optional) If set, used to indicate the artifacts are mutually inconsistent\n+  // (e.g. due to a diamond dependency problem) or could otherwise not be\n+  // resolved (e.g. due to invalid specifications).\n+  string error = 2;\n+}\n+\n+// A request to get an artifact.\n+message GetArtifactRequest {\n+  org.apache.beam.model.pipeline.v1.ArtifactInformation artifact = 1;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f10daf5ecc47d57a53e87e9a7bb8845a72f99b4c"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDU3MTYxNw==", "bodyText": "Let's not for now; this could be difficult to implement in practice (for non-seekable resources). We could add this capability in the future if needed.", "url": "https://github.com/apache/beam/pull/11203#discussion_r400571617", "createdAt": "2020-03-31T00:23:12Z", "author": {"login": "robertwb"}, "path": "model/job-management/src/main/proto/beam_artifact_api.proto", "diffHunk": "@@ -31,8 +31,92 @@ option java_outer_classname = \"ArtifactApi\";\n \n import \"beam_runner_api.proto\";\n \n-// A service to stage artifacts for use in a Job.\n+// A service to retrieve artifacts for use in a Job.\n+service ArtifactRetrievalService {\n+  // Resolves the given artifact references into one or more replacement\n+  // artifact references (e.g. a Maven dependency into a (transitive) set\n+  // of jars.\n+  rpc ResolveArtifact(ResolveArtifactRequest) returns (ResolveArtifactResponse);\n+\n+  // Retrieves the given artifact as a stream of bytes.\n+  rpc GetArtifact(GetArtifactRequest) returns (stream GetArtifactResponse);\n+}\n+\n+// A service that allows the client to act as an ArtifactRetrievalService,\n+// for a particular job with the server initiating requests and receiving\n+// responses.\n+//\n+// A client calls the service with an ArtifactResponseWrapper that has the\n+// staging token set, and thereafter responds to the server's requests.\n service ArtifactStagingService {\n+  rpc ReverseArtifactRetrievalService(stream ArtifactResponseWrapper)\n+      returns (stream ArtifactRequestWrapper);\n+}\n+\n+// A request for artifact resolution.\n+message ResolveArtifactRequest {\n+  // A set of artifacts to (jointly) resolve.\n+  repeated org.apache.beam.model.pipeline.v1.ArtifactInformation artifacts = 1;\n+\n+  // A set of artifact type urns that are understood by the requester.\n+  // An attempt should be made to resolve the artifacts in terms of these URNs,\n+  // but other URNs may be used as well with the understanding that they must\n+  // be fetch-able as bytes via GetArtifact.\n+  repeated string preferred_urns = 2;\n+}\n+\n+// A response for artifact resolution.\n+message ResolveArtifactResponse {\n+  // A full set of replacements for the set of requested artifacts, preferably\n+  // in terms of the requested type URNs.  If there is no better resolution,\n+  // the original list is returned.\n+  repeated org.apache.beam.model.pipeline.v1.ArtifactInformation replacements = 1;\n+\n+  // (Optional) If set, used to indicate the artifacts are mutually inconsistent\n+  // (e.g. due to a diamond dependency problem) or could otherwise not be\n+  // resolved (e.g. due to invalid specifications).\n+  string error = 2;\n+}\n+\n+// A request to get an artifact.\n+message GetArtifactRequest {\n+  org.apache.beam.model.pipeline.v1.ArtifactInformation artifact = 1;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQ3MDk2Nw=="}, "originalCommit": {"oid": "f10daf5ecc47d57a53e87e9a7bb8845a72f99b4c"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDYwNjEzOQ==", "bodyText": "I'm fine with adding it later, just pointing out that adding it later will require producing GetArtifactRequest V2 as adding the field would be backwards incompatible unless an actual resumed_offset was added to the response.", "url": "https://github.com/apache/beam/pull/11203#discussion_r400606139", "createdAt": "2020-03-31T02:30:04Z", "author": {"login": "lukecwik"}, "path": "model/job-management/src/main/proto/beam_artifact_api.proto", "diffHunk": "@@ -31,8 +31,92 @@ option java_outer_classname = \"ArtifactApi\";\n \n import \"beam_runner_api.proto\";\n \n-// A service to stage artifacts for use in a Job.\n+// A service to retrieve artifacts for use in a Job.\n+service ArtifactRetrievalService {\n+  // Resolves the given artifact references into one or more replacement\n+  // artifact references (e.g. a Maven dependency into a (transitive) set\n+  // of jars.\n+  rpc ResolveArtifact(ResolveArtifactRequest) returns (ResolveArtifactResponse);\n+\n+  // Retrieves the given artifact as a stream of bytes.\n+  rpc GetArtifact(GetArtifactRequest) returns (stream GetArtifactResponse);\n+}\n+\n+// A service that allows the client to act as an ArtifactRetrievalService,\n+// for a particular job with the server initiating requests and receiving\n+// responses.\n+//\n+// A client calls the service with an ArtifactResponseWrapper that has the\n+// staging token set, and thereafter responds to the server's requests.\n service ArtifactStagingService {\n+  rpc ReverseArtifactRetrievalService(stream ArtifactResponseWrapper)\n+      returns (stream ArtifactRequestWrapper);\n+}\n+\n+// A request for artifact resolution.\n+message ResolveArtifactRequest {\n+  // A set of artifacts to (jointly) resolve.\n+  repeated org.apache.beam.model.pipeline.v1.ArtifactInformation artifacts = 1;\n+\n+  // A set of artifact type urns that are understood by the requester.\n+  // An attempt should be made to resolve the artifacts in terms of these URNs,\n+  // but other URNs may be used as well with the understanding that they must\n+  // be fetch-able as bytes via GetArtifact.\n+  repeated string preferred_urns = 2;\n+}\n+\n+// A response for artifact resolution.\n+message ResolveArtifactResponse {\n+  // A full set of replacements for the set of requested artifacts, preferably\n+  // in terms of the requested type URNs.  If there is no better resolution,\n+  // the original list is returned.\n+  repeated org.apache.beam.model.pipeline.v1.ArtifactInformation replacements = 1;\n+\n+  // (Optional) If set, used to indicate the artifacts are mutually inconsistent\n+  // (e.g. due to a diamond dependency problem) or could otherwise not be\n+  // resolved (e.g. due to invalid specifications).\n+  string error = 2;\n+}\n+\n+// A request to get an artifact.\n+message GetArtifactRequest {\n+  org.apache.beam.model.pipeline.v1.ArtifactInformation artifact = 1;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQ3MDk2Nw=="}, "originalCommit": {"oid": "f10daf5ecc47d57a53e87e9a7bb8845a72f99b4c"}, "originalPosition": 54}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4MzQ3ODMxOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/portability/artifact_service.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQyMDozMzozMVrOF97H3w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQwMTowNzowN1rOF-BsrQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQ3NjEyNw==", "bodyText": "nit: FakeRetrievalService -> ForwardingRetrievalService\nor ProxyingRetrievalService", "url": "https://github.com/apache/beam/pull/11203#discussion_r400476127", "createdAt": "2020-03-30T20:33:31Z", "author": {"login": "lukecwik"}, "path": "sdks/python/apache_beam/runners/portability/artifact_service.py", "diffHunk": "@@ -263,3 +279,205 @@ def _open(self, path, mode='r'):\n       return filesystems.FileSystems.create(path)\n     else:\n       return filesystems.FileSystems.open(path)\n+\n+\n+# The dependency-aware artifact staging and retrieval services.\n+\n+\n+def _queue_iter(queue, end_token):\n+  while True:\n+    item = queue.get()\n+    if item is end_token:\n+      break\n+    yield item\n+\n+\n+class ArtifactRetrievalService(\n+    beam_artifact_api_pb2_grpc.ArtifactRetrievalServiceServicer):\n+\n+  _DEFAULT_CHUNK_SIZE = 2 << 20\n+\n+  def __init__(\n+      self,\n+      file_reader,  # type: Callable[[str], BinaryIO],\n+      chunk_size=None,\n+  ):\n+    self._file_reader = file_reader\n+    self._chunk_size = chunk_size or self._DEFAULT_CHUNK_SIZE\n+\n+  def ResolveArtifact(self, request, context=None):\n+    return beam_artifact_api_pb2.ResolveArtifactResponse(\n+        replacements=request.artifacts)\n+\n+  def GetArtifact(self, request, context=None):\n+    if request.artifact.type_urn == common_urns.artifact_types.FILE.urn:\n+      payload = proto_utils.parse_Bytes(\n+          request.artifact.type_payload,\n+          beam_runner_api_pb2.ArtifactFilePayload)\n+      read_handle = self._file_reader(payload.path)\n+    elif request.artifact.type_urn == common_urns.artifact_types.URL.urn:\n+      payload = proto_utils.parse_Bytes(\n+          request.artifact.type_payload, beam_runner_api_pb2.ArtifactUrlPayload)\n+      # TODO(Py3): Remove the unneeded contextlib wrapper.\n+      read_handle = contextlib.closing(urlopen(payload.path))\n+    elif request.artifact.type_urn == common_urns.artifact_types.EMBEDDED.urn:\n+      payload = proto_utils.parse_Bytes(\n+          request.artifact.type_payload,\n+          beam_runner_api_pb2.EmbeddedFilePayload)\n+      read_handle = BytesIO(payload.data)\n+    else:\n+      raise NotImplementedError(request.artifact.type_urn)\n+\n+    with read_handle as fin:\n+      while True:\n+        chunk = fin.read(self._chunk_size)\n+        if not chunk:\n+          break\n+        yield beam_artifact_api_pb2.GetArtifactResponse(data=chunk)\n+\n+\n+class ArtifactStagingService(\n+    beam_artifact_api_pb2_grpc.ArtifactStagingServiceServicer):\n+  def __init__(\n+      self,\n+      file_writer,  # type: Callable[[str, Optional[str]], Tuple[BinaryIO, str]]\n+    ):\n+    self._lock = threading.Lock()\n+    self._jobs_to_stage = {}\n+    self._file_writer = file_writer\n+\n+  def register_job(self, staging_token, dependencies):\n+    self._jobs_to_stage[staging_token] = list(dependencies), threading.Event()\n+\n+  def resolved_deps(self, staging_token, timeout=None):\n+    dependencies_list, event = self._jobs_to_stage[staging_token]\n+    try:\n+      if not event.wait(timeout):\n+        raise concurrent.futures.TimeoutError()\n+      return dependencies_list\n+    finally:\n+      del self._jobs_to_stage[staging_token]\n+\n+  def ReverseArtifactRetrievalService(self, responses, context=None):\n+    staging_token = next(responses).staging_token\n+    dependencies, event = self._jobs_to_stage[staging_token]\n+\n+    requests = queue.Queue()\n+\n+    class FakeRetrievalService(object):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f10daf5ecc47d57a53e87e9a7bb8845a72f99b4c"}, "originalPosition": 139}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDU4Mzg1Mw==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/11203#discussion_r400583853", "createdAt": "2020-03-31T01:07:07Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/runners/portability/artifact_service.py", "diffHunk": "@@ -263,3 +279,205 @@ def _open(self, path, mode='r'):\n       return filesystems.FileSystems.create(path)\n     else:\n       return filesystems.FileSystems.open(path)\n+\n+\n+# The dependency-aware artifact staging and retrieval services.\n+\n+\n+def _queue_iter(queue, end_token):\n+  while True:\n+    item = queue.get()\n+    if item is end_token:\n+      break\n+    yield item\n+\n+\n+class ArtifactRetrievalService(\n+    beam_artifact_api_pb2_grpc.ArtifactRetrievalServiceServicer):\n+\n+  _DEFAULT_CHUNK_SIZE = 2 << 20\n+\n+  def __init__(\n+      self,\n+      file_reader,  # type: Callable[[str], BinaryIO],\n+      chunk_size=None,\n+  ):\n+    self._file_reader = file_reader\n+    self._chunk_size = chunk_size or self._DEFAULT_CHUNK_SIZE\n+\n+  def ResolveArtifact(self, request, context=None):\n+    return beam_artifact_api_pb2.ResolveArtifactResponse(\n+        replacements=request.artifacts)\n+\n+  def GetArtifact(self, request, context=None):\n+    if request.artifact.type_urn == common_urns.artifact_types.FILE.urn:\n+      payload = proto_utils.parse_Bytes(\n+          request.artifact.type_payload,\n+          beam_runner_api_pb2.ArtifactFilePayload)\n+      read_handle = self._file_reader(payload.path)\n+    elif request.artifact.type_urn == common_urns.artifact_types.URL.urn:\n+      payload = proto_utils.parse_Bytes(\n+          request.artifact.type_payload, beam_runner_api_pb2.ArtifactUrlPayload)\n+      # TODO(Py3): Remove the unneeded contextlib wrapper.\n+      read_handle = contextlib.closing(urlopen(payload.path))\n+    elif request.artifact.type_urn == common_urns.artifact_types.EMBEDDED.urn:\n+      payload = proto_utils.parse_Bytes(\n+          request.artifact.type_payload,\n+          beam_runner_api_pb2.EmbeddedFilePayload)\n+      read_handle = BytesIO(payload.data)\n+    else:\n+      raise NotImplementedError(request.artifact.type_urn)\n+\n+    with read_handle as fin:\n+      while True:\n+        chunk = fin.read(self._chunk_size)\n+        if not chunk:\n+          break\n+        yield beam_artifact_api_pb2.GetArtifactResponse(data=chunk)\n+\n+\n+class ArtifactStagingService(\n+    beam_artifact_api_pb2_grpc.ArtifactStagingServiceServicer):\n+  def __init__(\n+      self,\n+      file_writer,  # type: Callable[[str, Optional[str]], Tuple[BinaryIO, str]]\n+    ):\n+    self._lock = threading.Lock()\n+    self._jobs_to_stage = {}\n+    self._file_writer = file_writer\n+\n+  def register_job(self, staging_token, dependencies):\n+    self._jobs_to_stage[staging_token] = list(dependencies), threading.Event()\n+\n+  def resolved_deps(self, staging_token, timeout=None):\n+    dependencies_list, event = self._jobs_to_stage[staging_token]\n+    try:\n+      if not event.wait(timeout):\n+        raise concurrent.futures.TimeoutError()\n+      return dependencies_list\n+    finally:\n+      del self._jobs_to_stage[staging_token]\n+\n+  def ReverseArtifactRetrievalService(self, responses, context=None):\n+    staging_token = next(responses).staging_token\n+    dependencies, event = self._jobs_to_stage[staging_token]\n+\n+    requests = queue.Queue()\n+\n+    class FakeRetrievalService(object):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQ3NjEyNw=="}, "originalCommit": {"oid": "f10daf5ecc47d57a53e87e9a7bb8845a72f99b4c"}, "originalPosition": 139}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4MzQ5MjMwOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/portability/artifact_service.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQyMDozNzozN1rOF97QrQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQwMTowODo0MlrOF-BuVQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQ3ODM4MQ==", "bodyText": "preferred_urns = FILE", "url": "https://github.com/apache/beam/pull/11203#discussion_r400478381", "createdAt": "2020-03-30T20:37:37Z", "author": {"login": "lukecwik"}, "path": "sdks/python/apache_beam/runners/portability/artifact_service.py", "diffHunk": "@@ -263,3 +279,205 @@ def _open(self, path, mode='r'):\n       return filesystems.FileSystems.create(path)\n     else:\n       return filesystems.FileSystems.open(path)\n+\n+\n+# The dependency-aware artifact staging and retrieval services.\n+\n+\n+def _queue_iter(queue, end_token):\n+  while True:\n+    item = queue.get()\n+    if item is end_token:\n+      break\n+    yield item\n+\n+\n+class ArtifactRetrievalService(\n+    beam_artifact_api_pb2_grpc.ArtifactRetrievalServiceServicer):\n+\n+  _DEFAULT_CHUNK_SIZE = 2 << 20\n+\n+  def __init__(\n+      self,\n+      file_reader,  # type: Callable[[str], BinaryIO],\n+      chunk_size=None,\n+  ):\n+    self._file_reader = file_reader\n+    self._chunk_size = chunk_size or self._DEFAULT_CHUNK_SIZE\n+\n+  def ResolveArtifact(self, request, context=None):\n+    return beam_artifact_api_pb2.ResolveArtifactResponse(\n+        replacements=request.artifacts)\n+\n+  def GetArtifact(self, request, context=None):\n+    if request.artifact.type_urn == common_urns.artifact_types.FILE.urn:\n+      payload = proto_utils.parse_Bytes(\n+          request.artifact.type_payload,\n+          beam_runner_api_pb2.ArtifactFilePayload)\n+      read_handle = self._file_reader(payload.path)\n+    elif request.artifact.type_urn == common_urns.artifact_types.URL.urn:\n+      payload = proto_utils.parse_Bytes(\n+          request.artifact.type_payload, beam_runner_api_pb2.ArtifactUrlPayload)\n+      # TODO(Py3): Remove the unneeded contextlib wrapper.\n+      read_handle = contextlib.closing(urlopen(payload.path))\n+    elif request.artifact.type_urn == common_urns.artifact_types.EMBEDDED.urn:\n+      payload = proto_utils.parse_Bytes(\n+          request.artifact.type_payload,\n+          beam_runner_api_pb2.EmbeddedFilePayload)\n+      read_handle = BytesIO(payload.data)\n+    else:\n+      raise NotImplementedError(request.artifact.type_urn)\n+\n+    with read_handle as fin:\n+      while True:\n+        chunk = fin.read(self._chunk_size)\n+        if not chunk:\n+          break\n+        yield beam_artifact_api_pb2.GetArtifactResponse(data=chunk)\n+\n+\n+class ArtifactStagingService(\n+    beam_artifact_api_pb2_grpc.ArtifactStagingServiceServicer):\n+  def __init__(\n+      self,\n+      file_writer,  # type: Callable[[str, Optional[str]], Tuple[BinaryIO, str]]\n+    ):\n+    self._lock = threading.Lock()\n+    self._jobs_to_stage = {}\n+    self._file_writer = file_writer\n+\n+  def register_job(self, staging_token, dependencies):\n+    self._jobs_to_stage[staging_token] = list(dependencies), threading.Event()\n+\n+  def resolved_deps(self, staging_token, timeout=None):\n+    dependencies_list, event = self._jobs_to_stage[staging_token]\n+    try:\n+      if not event.wait(timeout):\n+        raise concurrent.futures.TimeoutError()\n+      return dependencies_list\n+    finally:\n+      del self._jobs_to_stage[staging_token]\n+\n+  def ReverseArtifactRetrievalService(self, responses, context=None):\n+    staging_token = next(responses).staging_token\n+    dependencies, event = self._jobs_to_stage[staging_token]\n+\n+    requests = queue.Queue()\n+\n+    class FakeRetrievalService(object):\n+      def ResolveArtifacts(self, request):\n+        requests.put(\n+            beam_artifact_api_pb2.ArtifactRequestWrapper(\n+                resolve_artifact=request))\n+        return next(responses).resolve_artifact_response\n+\n+      def GetArtifact(self, request):\n+        requests.put(\n+            beam_artifact_api_pb2.ArtifactRequestWrapper(get_artifact=request))\n+        while True:\n+          response = next(responses)\n+          yield response.get_artifact_response\n+          if response.is_last:\n+            break\n+\n+    def resolve():\n+      file_deps = resolve_as_files(\n+          FakeRetrievalService(),\n+          lambda name: self._file_writer(os.path.join(staging_token, name)),\n+          dependencies)\n+      dependencies[:] = file_deps\n+      requests.put(None)\n+      event.set()\n+\n+    t = threading.Thread(target=resolve)\n+    t.daemon = True\n+    t.start()\n+\n+    return _queue_iter(requests, None)\n+\n+\n+def resolve_as_files(retrieval_service, file_writer, dependencies):\n+  \"\"\"Translates a set of dependencies into file-based dependencies.\"\"\"\n+  # Resolve until nothing changes.  This ensures that they can be fetched.\n+  resolution = retrieval_service.ResolveArtifacts(\n+      beam_artifact_api_pb2.ResolveArtifactRequest(\n+          artifacts=dependencies,\n+          # Anything fetchable will do.\n+          # TODO(robertwb): Take advantage of shared filesystems, urls.\n+          preferred_urns=[],", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f10daf5ecc47d57a53e87e9a7bb8845a72f99b4c"}, "originalPosition": 179}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDU4NDI3Nw==", "bodyText": "There is no preference here, it always fetches them.", "url": "https://github.com/apache/beam/pull/11203#discussion_r400584277", "createdAt": "2020-03-31T01:08:42Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/runners/portability/artifact_service.py", "diffHunk": "@@ -263,3 +279,205 @@ def _open(self, path, mode='r'):\n       return filesystems.FileSystems.create(path)\n     else:\n       return filesystems.FileSystems.open(path)\n+\n+\n+# The dependency-aware artifact staging and retrieval services.\n+\n+\n+def _queue_iter(queue, end_token):\n+  while True:\n+    item = queue.get()\n+    if item is end_token:\n+      break\n+    yield item\n+\n+\n+class ArtifactRetrievalService(\n+    beam_artifact_api_pb2_grpc.ArtifactRetrievalServiceServicer):\n+\n+  _DEFAULT_CHUNK_SIZE = 2 << 20\n+\n+  def __init__(\n+      self,\n+      file_reader,  # type: Callable[[str], BinaryIO],\n+      chunk_size=None,\n+  ):\n+    self._file_reader = file_reader\n+    self._chunk_size = chunk_size or self._DEFAULT_CHUNK_SIZE\n+\n+  def ResolveArtifact(self, request, context=None):\n+    return beam_artifact_api_pb2.ResolveArtifactResponse(\n+        replacements=request.artifacts)\n+\n+  def GetArtifact(self, request, context=None):\n+    if request.artifact.type_urn == common_urns.artifact_types.FILE.urn:\n+      payload = proto_utils.parse_Bytes(\n+          request.artifact.type_payload,\n+          beam_runner_api_pb2.ArtifactFilePayload)\n+      read_handle = self._file_reader(payload.path)\n+    elif request.artifact.type_urn == common_urns.artifact_types.URL.urn:\n+      payload = proto_utils.parse_Bytes(\n+          request.artifact.type_payload, beam_runner_api_pb2.ArtifactUrlPayload)\n+      # TODO(Py3): Remove the unneeded contextlib wrapper.\n+      read_handle = contextlib.closing(urlopen(payload.path))\n+    elif request.artifact.type_urn == common_urns.artifact_types.EMBEDDED.urn:\n+      payload = proto_utils.parse_Bytes(\n+          request.artifact.type_payload,\n+          beam_runner_api_pb2.EmbeddedFilePayload)\n+      read_handle = BytesIO(payload.data)\n+    else:\n+      raise NotImplementedError(request.artifact.type_urn)\n+\n+    with read_handle as fin:\n+      while True:\n+        chunk = fin.read(self._chunk_size)\n+        if not chunk:\n+          break\n+        yield beam_artifact_api_pb2.GetArtifactResponse(data=chunk)\n+\n+\n+class ArtifactStagingService(\n+    beam_artifact_api_pb2_grpc.ArtifactStagingServiceServicer):\n+  def __init__(\n+      self,\n+      file_writer,  # type: Callable[[str, Optional[str]], Tuple[BinaryIO, str]]\n+    ):\n+    self._lock = threading.Lock()\n+    self._jobs_to_stage = {}\n+    self._file_writer = file_writer\n+\n+  def register_job(self, staging_token, dependencies):\n+    self._jobs_to_stage[staging_token] = list(dependencies), threading.Event()\n+\n+  def resolved_deps(self, staging_token, timeout=None):\n+    dependencies_list, event = self._jobs_to_stage[staging_token]\n+    try:\n+      if not event.wait(timeout):\n+        raise concurrent.futures.TimeoutError()\n+      return dependencies_list\n+    finally:\n+      del self._jobs_to_stage[staging_token]\n+\n+  def ReverseArtifactRetrievalService(self, responses, context=None):\n+    staging_token = next(responses).staging_token\n+    dependencies, event = self._jobs_to_stage[staging_token]\n+\n+    requests = queue.Queue()\n+\n+    class FakeRetrievalService(object):\n+      def ResolveArtifacts(self, request):\n+        requests.put(\n+            beam_artifact_api_pb2.ArtifactRequestWrapper(\n+                resolve_artifact=request))\n+        return next(responses).resolve_artifact_response\n+\n+      def GetArtifact(self, request):\n+        requests.put(\n+            beam_artifact_api_pb2.ArtifactRequestWrapper(get_artifact=request))\n+        while True:\n+          response = next(responses)\n+          yield response.get_artifact_response\n+          if response.is_last:\n+            break\n+\n+    def resolve():\n+      file_deps = resolve_as_files(\n+          FakeRetrievalService(),\n+          lambda name: self._file_writer(os.path.join(staging_token, name)),\n+          dependencies)\n+      dependencies[:] = file_deps\n+      requests.put(None)\n+      event.set()\n+\n+    t = threading.Thread(target=resolve)\n+    t.daemon = True\n+    t.start()\n+\n+    return _queue_iter(requests, None)\n+\n+\n+def resolve_as_files(retrieval_service, file_writer, dependencies):\n+  \"\"\"Translates a set of dependencies into file-based dependencies.\"\"\"\n+  # Resolve until nothing changes.  This ensures that they can be fetched.\n+  resolution = retrieval_service.ResolveArtifacts(\n+      beam_artifact_api_pb2.ResolveArtifactRequest(\n+          artifacts=dependencies,\n+          # Anything fetchable will do.\n+          # TODO(robertwb): Take advantage of shared filesystems, urls.\n+          preferred_urns=[],", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQ3ODM4MQ=="}, "originalCommit": {"oid": "f10daf5ecc47d57a53e87e9a7bb8845a72f99b4c"}, "originalPosition": 179}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4MzUwODYwOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/portability/artifact_service.py", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQyMDo0MjoyM1rOF97axg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQwMjoyMDoxMlrOF-C5vg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQ4MDk2Ng==", "bodyText": "Any reason to not use the staging token to prevent collisions instead of relying on the sha256 of a proto which may not be unique (note that nobody populates the sha256 for the File type, I mentioned this on #11205)?", "url": "https://github.com/apache/beam/pull/11203#discussion_r400480966", "createdAt": "2020-03-30T20:42:23Z", "author": {"login": "lukecwik"}, "path": "sdks/python/apache_beam/runners/portability/artifact_service.py", "diffHunk": "@@ -263,3 +279,205 @@ def _open(self, path, mode='r'):\n       return filesystems.FileSystems.create(path)\n     else:\n       return filesystems.FileSystems.open(path)\n+\n+\n+# The dependency-aware artifact staging and retrieval services.\n+\n+\n+def _queue_iter(queue, end_token):\n+  while True:\n+    item = queue.get()\n+    if item is end_token:\n+      break\n+    yield item\n+\n+\n+class ArtifactRetrievalService(\n+    beam_artifact_api_pb2_grpc.ArtifactRetrievalServiceServicer):\n+\n+  _DEFAULT_CHUNK_SIZE = 2 << 20\n+\n+  def __init__(\n+      self,\n+      file_reader,  # type: Callable[[str], BinaryIO],\n+      chunk_size=None,\n+  ):\n+    self._file_reader = file_reader\n+    self._chunk_size = chunk_size or self._DEFAULT_CHUNK_SIZE\n+\n+  def ResolveArtifact(self, request, context=None):\n+    return beam_artifact_api_pb2.ResolveArtifactResponse(\n+        replacements=request.artifacts)\n+\n+  def GetArtifact(self, request, context=None):\n+    if request.artifact.type_urn == common_urns.artifact_types.FILE.urn:\n+      payload = proto_utils.parse_Bytes(\n+          request.artifact.type_payload,\n+          beam_runner_api_pb2.ArtifactFilePayload)\n+      read_handle = self._file_reader(payload.path)\n+    elif request.artifact.type_urn == common_urns.artifact_types.URL.urn:\n+      payload = proto_utils.parse_Bytes(\n+          request.artifact.type_payload, beam_runner_api_pb2.ArtifactUrlPayload)\n+      # TODO(Py3): Remove the unneeded contextlib wrapper.\n+      read_handle = contextlib.closing(urlopen(payload.path))\n+    elif request.artifact.type_urn == common_urns.artifact_types.EMBEDDED.urn:\n+      payload = proto_utils.parse_Bytes(\n+          request.artifact.type_payload,\n+          beam_runner_api_pb2.EmbeddedFilePayload)\n+      read_handle = BytesIO(payload.data)\n+    else:\n+      raise NotImplementedError(request.artifact.type_urn)\n+\n+    with read_handle as fin:\n+      while True:\n+        chunk = fin.read(self._chunk_size)\n+        if not chunk:\n+          break\n+        yield beam_artifact_api_pb2.GetArtifactResponse(data=chunk)\n+\n+\n+class ArtifactStagingService(\n+    beam_artifact_api_pb2_grpc.ArtifactStagingServiceServicer):\n+  def __init__(\n+      self,\n+      file_writer,  # type: Callable[[str, Optional[str]], Tuple[BinaryIO, str]]\n+    ):\n+    self._lock = threading.Lock()\n+    self._jobs_to_stage = {}\n+    self._file_writer = file_writer\n+\n+  def register_job(self, staging_token, dependencies):\n+    self._jobs_to_stage[staging_token] = list(dependencies), threading.Event()\n+\n+  def resolved_deps(self, staging_token, timeout=None):\n+    dependencies_list, event = self._jobs_to_stage[staging_token]\n+    try:\n+      if not event.wait(timeout):\n+        raise concurrent.futures.TimeoutError()\n+      return dependencies_list\n+    finally:\n+      del self._jobs_to_stage[staging_token]\n+\n+  def ReverseArtifactRetrievalService(self, responses, context=None):\n+    staging_token = next(responses).staging_token\n+    dependencies, event = self._jobs_to_stage[staging_token]\n+\n+    requests = queue.Queue()\n+\n+    class FakeRetrievalService(object):\n+      def ResolveArtifacts(self, request):\n+        requests.put(\n+            beam_artifact_api_pb2.ArtifactRequestWrapper(\n+                resolve_artifact=request))\n+        return next(responses).resolve_artifact_response\n+\n+      def GetArtifact(self, request):\n+        requests.put(\n+            beam_artifact_api_pb2.ArtifactRequestWrapper(get_artifact=request))\n+        while True:\n+          response = next(responses)\n+          yield response.get_artifact_response\n+          if response.is_last:\n+            break\n+\n+    def resolve():\n+      file_deps = resolve_as_files(\n+          FakeRetrievalService(),\n+          lambda name: self._file_writer(os.path.join(staging_token, name)),\n+          dependencies)\n+      dependencies[:] = file_deps\n+      requests.put(None)\n+      event.set()\n+\n+    t = threading.Thread(target=resolve)\n+    t.daemon = True\n+    t.start()\n+\n+    return _queue_iter(requests, None)\n+\n+\n+def resolve_as_files(retrieval_service, file_writer, dependencies):\n+  \"\"\"Translates a set of dependencies into file-based dependencies.\"\"\"\n+  # Resolve until nothing changes.  This ensures that they can be fetched.\n+  resolution = retrieval_service.ResolveArtifacts(\n+      beam_artifact_api_pb2.ResolveArtifactRequest(\n+          artifacts=dependencies,\n+          # Anything fetchable will do.\n+          # TODO(robertwb): Take advantage of shared filesystems, urls.\n+          preferred_urns=[],\n+      ))\n+  if resolution.error:\n+    raise RuntimeError(resolution)\n+  dependencies = resolution.replacements\n+\n+  # Fetch each of the dependencies, using file_writer to store them as\n+  # file-based artifacts.\n+  # TODO(robertwb): Consider parallelizing the actual writes.\n+  for dep in dependencies:\n+    if dep.role_urn == common_urns.artifact_roles.STAGING_TO.urn:\n+      base_name = os.path.basename(\n+          proto_utils.parse_Bytes(\n+              dep.role_payload,\n+              beam_runner_api_pb2.ArtifactStagingToRolePayload).staged_name)\n+    else:\n+      base_name = None\n+    unique_name = '-'.join(\n+        filter(\n+            None,\n+            [hashlib.sha256(dep.SerializeToString()).hexdigest(), base_name]))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f10daf5ecc47d57a53e87e9a7bb8845a72f99b4c"}, "originalPosition": 199}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDU4NTY3Ng==", "bodyText": "The full file path will already be prefixed by the staging token (line ~413 where this is called). This does make me wonder whether every artifact should have a name (even non-file based ones). Especially if roles become more specific (like classpath or pip package rather than just stage_to).", "url": "https://github.com/apache/beam/pull/11203#discussion_r400585676", "createdAt": "2020-03-31T01:13:20Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/runners/portability/artifact_service.py", "diffHunk": "@@ -263,3 +279,205 @@ def _open(self, path, mode='r'):\n       return filesystems.FileSystems.create(path)\n     else:\n       return filesystems.FileSystems.open(path)\n+\n+\n+# The dependency-aware artifact staging and retrieval services.\n+\n+\n+def _queue_iter(queue, end_token):\n+  while True:\n+    item = queue.get()\n+    if item is end_token:\n+      break\n+    yield item\n+\n+\n+class ArtifactRetrievalService(\n+    beam_artifact_api_pb2_grpc.ArtifactRetrievalServiceServicer):\n+\n+  _DEFAULT_CHUNK_SIZE = 2 << 20\n+\n+  def __init__(\n+      self,\n+      file_reader,  # type: Callable[[str], BinaryIO],\n+      chunk_size=None,\n+  ):\n+    self._file_reader = file_reader\n+    self._chunk_size = chunk_size or self._DEFAULT_CHUNK_SIZE\n+\n+  def ResolveArtifact(self, request, context=None):\n+    return beam_artifact_api_pb2.ResolveArtifactResponse(\n+        replacements=request.artifacts)\n+\n+  def GetArtifact(self, request, context=None):\n+    if request.artifact.type_urn == common_urns.artifact_types.FILE.urn:\n+      payload = proto_utils.parse_Bytes(\n+          request.artifact.type_payload,\n+          beam_runner_api_pb2.ArtifactFilePayload)\n+      read_handle = self._file_reader(payload.path)\n+    elif request.artifact.type_urn == common_urns.artifact_types.URL.urn:\n+      payload = proto_utils.parse_Bytes(\n+          request.artifact.type_payload, beam_runner_api_pb2.ArtifactUrlPayload)\n+      # TODO(Py3): Remove the unneeded contextlib wrapper.\n+      read_handle = contextlib.closing(urlopen(payload.path))\n+    elif request.artifact.type_urn == common_urns.artifact_types.EMBEDDED.urn:\n+      payload = proto_utils.parse_Bytes(\n+          request.artifact.type_payload,\n+          beam_runner_api_pb2.EmbeddedFilePayload)\n+      read_handle = BytesIO(payload.data)\n+    else:\n+      raise NotImplementedError(request.artifact.type_urn)\n+\n+    with read_handle as fin:\n+      while True:\n+        chunk = fin.read(self._chunk_size)\n+        if not chunk:\n+          break\n+        yield beam_artifact_api_pb2.GetArtifactResponse(data=chunk)\n+\n+\n+class ArtifactStagingService(\n+    beam_artifact_api_pb2_grpc.ArtifactStagingServiceServicer):\n+  def __init__(\n+      self,\n+      file_writer,  # type: Callable[[str, Optional[str]], Tuple[BinaryIO, str]]\n+    ):\n+    self._lock = threading.Lock()\n+    self._jobs_to_stage = {}\n+    self._file_writer = file_writer\n+\n+  def register_job(self, staging_token, dependencies):\n+    self._jobs_to_stage[staging_token] = list(dependencies), threading.Event()\n+\n+  def resolved_deps(self, staging_token, timeout=None):\n+    dependencies_list, event = self._jobs_to_stage[staging_token]\n+    try:\n+      if not event.wait(timeout):\n+        raise concurrent.futures.TimeoutError()\n+      return dependencies_list\n+    finally:\n+      del self._jobs_to_stage[staging_token]\n+\n+  def ReverseArtifactRetrievalService(self, responses, context=None):\n+    staging_token = next(responses).staging_token\n+    dependencies, event = self._jobs_to_stage[staging_token]\n+\n+    requests = queue.Queue()\n+\n+    class FakeRetrievalService(object):\n+      def ResolveArtifacts(self, request):\n+        requests.put(\n+            beam_artifact_api_pb2.ArtifactRequestWrapper(\n+                resolve_artifact=request))\n+        return next(responses).resolve_artifact_response\n+\n+      def GetArtifact(self, request):\n+        requests.put(\n+            beam_artifact_api_pb2.ArtifactRequestWrapper(get_artifact=request))\n+        while True:\n+          response = next(responses)\n+          yield response.get_artifact_response\n+          if response.is_last:\n+            break\n+\n+    def resolve():\n+      file_deps = resolve_as_files(\n+          FakeRetrievalService(),\n+          lambda name: self._file_writer(os.path.join(staging_token, name)),\n+          dependencies)\n+      dependencies[:] = file_deps\n+      requests.put(None)\n+      event.set()\n+\n+    t = threading.Thread(target=resolve)\n+    t.daemon = True\n+    t.start()\n+\n+    return _queue_iter(requests, None)\n+\n+\n+def resolve_as_files(retrieval_service, file_writer, dependencies):\n+  \"\"\"Translates a set of dependencies into file-based dependencies.\"\"\"\n+  # Resolve until nothing changes.  This ensures that they can be fetched.\n+  resolution = retrieval_service.ResolveArtifacts(\n+      beam_artifact_api_pb2.ResolveArtifactRequest(\n+          artifacts=dependencies,\n+          # Anything fetchable will do.\n+          # TODO(robertwb): Take advantage of shared filesystems, urls.\n+          preferred_urns=[],\n+      ))\n+  if resolution.error:\n+    raise RuntimeError(resolution)\n+  dependencies = resolution.replacements\n+\n+  # Fetch each of the dependencies, using file_writer to store them as\n+  # file-based artifacts.\n+  # TODO(robertwb): Consider parallelizing the actual writes.\n+  for dep in dependencies:\n+    if dep.role_urn == common_urns.artifact_roles.STAGING_TO.urn:\n+      base_name = os.path.basename(\n+          proto_utils.parse_Bytes(\n+              dep.role_payload,\n+              beam_runner_api_pb2.ArtifactStagingToRolePayload).staged_name)\n+    else:\n+      base_name = None\n+    unique_name = '-'.join(\n+        filter(\n+            None,\n+            [hashlib.sha256(dep.SerializeToString()).hexdigest(), base_name]))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQ4MDk2Ng=="}, "originalCommit": {"oid": "f10daf5ecc47d57a53e87e9a7bb8845a72f99b4c"}, "originalPosition": 199}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDYwMzU4Mg==", "bodyText": "Its typically pretty easy to figure out the name of a path component so no need.", "url": "https://github.com/apache/beam/pull/11203#discussion_r400603582", "createdAt": "2020-03-31T02:20:12Z", "author": {"login": "lukecwik"}, "path": "sdks/python/apache_beam/runners/portability/artifact_service.py", "diffHunk": "@@ -263,3 +279,205 @@ def _open(self, path, mode='r'):\n       return filesystems.FileSystems.create(path)\n     else:\n       return filesystems.FileSystems.open(path)\n+\n+\n+# The dependency-aware artifact staging and retrieval services.\n+\n+\n+def _queue_iter(queue, end_token):\n+  while True:\n+    item = queue.get()\n+    if item is end_token:\n+      break\n+    yield item\n+\n+\n+class ArtifactRetrievalService(\n+    beam_artifact_api_pb2_grpc.ArtifactRetrievalServiceServicer):\n+\n+  _DEFAULT_CHUNK_SIZE = 2 << 20\n+\n+  def __init__(\n+      self,\n+      file_reader,  # type: Callable[[str], BinaryIO],\n+      chunk_size=None,\n+  ):\n+    self._file_reader = file_reader\n+    self._chunk_size = chunk_size or self._DEFAULT_CHUNK_SIZE\n+\n+  def ResolveArtifact(self, request, context=None):\n+    return beam_artifact_api_pb2.ResolveArtifactResponse(\n+        replacements=request.artifacts)\n+\n+  def GetArtifact(self, request, context=None):\n+    if request.artifact.type_urn == common_urns.artifact_types.FILE.urn:\n+      payload = proto_utils.parse_Bytes(\n+          request.artifact.type_payload,\n+          beam_runner_api_pb2.ArtifactFilePayload)\n+      read_handle = self._file_reader(payload.path)\n+    elif request.artifact.type_urn == common_urns.artifact_types.URL.urn:\n+      payload = proto_utils.parse_Bytes(\n+          request.artifact.type_payload, beam_runner_api_pb2.ArtifactUrlPayload)\n+      # TODO(Py3): Remove the unneeded contextlib wrapper.\n+      read_handle = contextlib.closing(urlopen(payload.path))\n+    elif request.artifact.type_urn == common_urns.artifact_types.EMBEDDED.urn:\n+      payload = proto_utils.parse_Bytes(\n+          request.artifact.type_payload,\n+          beam_runner_api_pb2.EmbeddedFilePayload)\n+      read_handle = BytesIO(payload.data)\n+    else:\n+      raise NotImplementedError(request.artifact.type_urn)\n+\n+    with read_handle as fin:\n+      while True:\n+        chunk = fin.read(self._chunk_size)\n+        if not chunk:\n+          break\n+        yield beam_artifact_api_pb2.GetArtifactResponse(data=chunk)\n+\n+\n+class ArtifactStagingService(\n+    beam_artifact_api_pb2_grpc.ArtifactStagingServiceServicer):\n+  def __init__(\n+      self,\n+      file_writer,  # type: Callable[[str, Optional[str]], Tuple[BinaryIO, str]]\n+    ):\n+    self._lock = threading.Lock()\n+    self._jobs_to_stage = {}\n+    self._file_writer = file_writer\n+\n+  def register_job(self, staging_token, dependencies):\n+    self._jobs_to_stage[staging_token] = list(dependencies), threading.Event()\n+\n+  def resolved_deps(self, staging_token, timeout=None):\n+    dependencies_list, event = self._jobs_to_stage[staging_token]\n+    try:\n+      if not event.wait(timeout):\n+        raise concurrent.futures.TimeoutError()\n+      return dependencies_list\n+    finally:\n+      del self._jobs_to_stage[staging_token]\n+\n+  def ReverseArtifactRetrievalService(self, responses, context=None):\n+    staging_token = next(responses).staging_token\n+    dependencies, event = self._jobs_to_stage[staging_token]\n+\n+    requests = queue.Queue()\n+\n+    class FakeRetrievalService(object):\n+      def ResolveArtifacts(self, request):\n+        requests.put(\n+            beam_artifact_api_pb2.ArtifactRequestWrapper(\n+                resolve_artifact=request))\n+        return next(responses).resolve_artifact_response\n+\n+      def GetArtifact(self, request):\n+        requests.put(\n+            beam_artifact_api_pb2.ArtifactRequestWrapper(get_artifact=request))\n+        while True:\n+          response = next(responses)\n+          yield response.get_artifact_response\n+          if response.is_last:\n+            break\n+\n+    def resolve():\n+      file_deps = resolve_as_files(\n+          FakeRetrievalService(),\n+          lambda name: self._file_writer(os.path.join(staging_token, name)),\n+          dependencies)\n+      dependencies[:] = file_deps\n+      requests.put(None)\n+      event.set()\n+\n+    t = threading.Thread(target=resolve)\n+    t.daemon = True\n+    t.start()\n+\n+    return _queue_iter(requests, None)\n+\n+\n+def resolve_as_files(retrieval_service, file_writer, dependencies):\n+  \"\"\"Translates a set of dependencies into file-based dependencies.\"\"\"\n+  # Resolve until nothing changes.  This ensures that they can be fetched.\n+  resolution = retrieval_service.ResolveArtifacts(\n+      beam_artifact_api_pb2.ResolveArtifactRequest(\n+          artifacts=dependencies,\n+          # Anything fetchable will do.\n+          # TODO(robertwb): Take advantage of shared filesystems, urls.\n+          preferred_urns=[],\n+      ))\n+  if resolution.error:\n+    raise RuntimeError(resolution)\n+  dependencies = resolution.replacements\n+\n+  # Fetch each of the dependencies, using file_writer to store them as\n+  # file-based artifacts.\n+  # TODO(robertwb): Consider parallelizing the actual writes.\n+  for dep in dependencies:\n+    if dep.role_urn == common_urns.artifact_roles.STAGING_TO.urn:\n+      base_name = os.path.basename(\n+          proto_utils.parse_Bytes(\n+              dep.role_payload,\n+              beam_runner_api_pb2.ArtifactStagingToRolePayload).staged_name)\n+    else:\n+      base_name = None\n+    unique_name = '-'.join(\n+        filter(\n+            None,\n+            [hashlib.sha256(dep.SerializeToString()).hexdigest(), base_name]))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQ4MDk2Ng=="}, "originalCommit": {"oid": "f10daf5ecc47d57a53e87e9a7bb8845a72f99b4c"}, "originalPosition": 199}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4MzU2MDY4OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/portability/artifact_service.py", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQyMDo1Nzo0NlrOF977SA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQwMjoyNTowMFrOF-C-lw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQ4OTI4OA==", "bodyText": "Its probably best to raise an error if the staging token is already in the dict.", "url": "https://github.com/apache/beam/pull/11203#discussion_r400489288", "createdAt": "2020-03-30T20:57:46Z", "author": {"login": "lukecwik"}, "path": "sdks/python/apache_beam/runners/portability/artifact_service.py", "diffHunk": "@@ -263,3 +279,205 @@ def _open(self, path, mode='r'):\n       return filesystems.FileSystems.create(path)\n     else:\n       return filesystems.FileSystems.open(path)\n+\n+\n+# The dependency-aware artifact staging and retrieval services.\n+\n+\n+def _queue_iter(queue, end_token):\n+  while True:\n+    item = queue.get()\n+    if item is end_token:\n+      break\n+    yield item\n+\n+\n+class ArtifactRetrievalService(\n+    beam_artifact_api_pb2_grpc.ArtifactRetrievalServiceServicer):\n+\n+  _DEFAULT_CHUNK_SIZE = 2 << 20\n+\n+  def __init__(\n+      self,\n+      file_reader,  # type: Callable[[str], BinaryIO],\n+      chunk_size=None,\n+  ):\n+    self._file_reader = file_reader\n+    self._chunk_size = chunk_size or self._DEFAULT_CHUNK_SIZE\n+\n+  def ResolveArtifact(self, request, context=None):\n+    return beam_artifact_api_pb2.ResolveArtifactResponse(\n+        replacements=request.artifacts)\n+\n+  def GetArtifact(self, request, context=None):\n+    if request.artifact.type_urn == common_urns.artifact_types.FILE.urn:\n+      payload = proto_utils.parse_Bytes(\n+          request.artifact.type_payload,\n+          beam_runner_api_pb2.ArtifactFilePayload)\n+      read_handle = self._file_reader(payload.path)\n+    elif request.artifact.type_urn == common_urns.artifact_types.URL.urn:\n+      payload = proto_utils.parse_Bytes(\n+          request.artifact.type_payload, beam_runner_api_pb2.ArtifactUrlPayload)\n+      # TODO(Py3): Remove the unneeded contextlib wrapper.\n+      read_handle = contextlib.closing(urlopen(payload.path))\n+    elif request.artifact.type_urn == common_urns.artifact_types.EMBEDDED.urn:\n+      payload = proto_utils.parse_Bytes(\n+          request.artifact.type_payload,\n+          beam_runner_api_pb2.EmbeddedFilePayload)\n+      read_handle = BytesIO(payload.data)\n+    else:\n+      raise NotImplementedError(request.artifact.type_urn)\n+\n+    with read_handle as fin:\n+      while True:\n+        chunk = fin.read(self._chunk_size)\n+        if not chunk:\n+          break\n+        yield beam_artifact_api_pb2.GetArtifactResponse(data=chunk)\n+\n+\n+class ArtifactStagingService(\n+    beam_artifact_api_pb2_grpc.ArtifactStagingServiceServicer):\n+  def __init__(\n+      self,\n+      file_writer,  # type: Callable[[str, Optional[str]], Tuple[BinaryIO, str]]\n+    ):\n+    self._lock = threading.Lock()\n+    self._jobs_to_stage = {}\n+    self._file_writer = file_writer\n+\n+  def register_job(self, staging_token, dependencies):\n+    self._jobs_to_stage[staging_token] = list(dependencies), threading.Event()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f10daf5ecc47d57a53e87e9a7bb8845a72f99b4c"}, "originalPosition": 122}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDU3MjMyMQ==", "bodyText": "Yes, done.", "url": "https://github.com/apache/beam/pull/11203#discussion_r400572321", "createdAt": "2020-03-31T00:25:43Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/runners/portability/artifact_service.py", "diffHunk": "@@ -263,3 +279,205 @@ def _open(self, path, mode='r'):\n       return filesystems.FileSystems.create(path)\n     else:\n       return filesystems.FileSystems.open(path)\n+\n+\n+# The dependency-aware artifact staging and retrieval services.\n+\n+\n+def _queue_iter(queue, end_token):\n+  while True:\n+    item = queue.get()\n+    if item is end_token:\n+      break\n+    yield item\n+\n+\n+class ArtifactRetrievalService(\n+    beam_artifact_api_pb2_grpc.ArtifactRetrievalServiceServicer):\n+\n+  _DEFAULT_CHUNK_SIZE = 2 << 20\n+\n+  def __init__(\n+      self,\n+      file_reader,  # type: Callable[[str], BinaryIO],\n+      chunk_size=None,\n+  ):\n+    self._file_reader = file_reader\n+    self._chunk_size = chunk_size or self._DEFAULT_CHUNK_SIZE\n+\n+  def ResolveArtifact(self, request, context=None):\n+    return beam_artifact_api_pb2.ResolveArtifactResponse(\n+        replacements=request.artifacts)\n+\n+  def GetArtifact(self, request, context=None):\n+    if request.artifact.type_urn == common_urns.artifact_types.FILE.urn:\n+      payload = proto_utils.parse_Bytes(\n+          request.artifact.type_payload,\n+          beam_runner_api_pb2.ArtifactFilePayload)\n+      read_handle = self._file_reader(payload.path)\n+    elif request.artifact.type_urn == common_urns.artifact_types.URL.urn:\n+      payload = proto_utils.parse_Bytes(\n+          request.artifact.type_payload, beam_runner_api_pb2.ArtifactUrlPayload)\n+      # TODO(Py3): Remove the unneeded contextlib wrapper.\n+      read_handle = contextlib.closing(urlopen(payload.path))\n+    elif request.artifact.type_urn == common_urns.artifact_types.EMBEDDED.urn:\n+      payload = proto_utils.parse_Bytes(\n+          request.artifact.type_payload,\n+          beam_runner_api_pb2.EmbeddedFilePayload)\n+      read_handle = BytesIO(payload.data)\n+    else:\n+      raise NotImplementedError(request.artifact.type_urn)\n+\n+    with read_handle as fin:\n+      while True:\n+        chunk = fin.read(self._chunk_size)\n+        if not chunk:\n+          break\n+        yield beam_artifact_api_pb2.GetArtifactResponse(data=chunk)\n+\n+\n+class ArtifactStagingService(\n+    beam_artifact_api_pb2_grpc.ArtifactStagingServiceServicer):\n+  def __init__(\n+      self,\n+      file_writer,  # type: Callable[[str, Optional[str]], Tuple[BinaryIO, str]]\n+    ):\n+    self._lock = threading.Lock()\n+    self._jobs_to_stage = {}\n+    self._file_writer = file_writer\n+\n+  def register_job(self, staging_token, dependencies):\n+    self._jobs_to_stage[staging_token] = list(dependencies), threading.Event()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQ4OTI4OA=="}, "originalCommit": {"oid": "f10daf5ecc47d57a53e87e9a7bb8845a72f99b4c"}, "originalPosition": 122}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDYwNDgyMw==", "bodyText": "I think we need to hold _lock everywhere for access/mutation of _jobs_to_stage", "url": "https://github.com/apache/beam/pull/11203#discussion_r400604823", "createdAt": "2020-03-31T02:25:00Z", "author": {"login": "lukecwik"}, "path": "sdks/python/apache_beam/runners/portability/artifact_service.py", "diffHunk": "@@ -263,3 +279,205 @@ def _open(self, path, mode='r'):\n       return filesystems.FileSystems.create(path)\n     else:\n       return filesystems.FileSystems.open(path)\n+\n+\n+# The dependency-aware artifact staging and retrieval services.\n+\n+\n+def _queue_iter(queue, end_token):\n+  while True:\n+    item = queue.get()\n+    if item is end_token:\n+      break\n+    yield item\n+\n+\n+class ArtifactRetrievalService(\n+    beam_artifact_api_pb2_grpc.ArtifactRetrievalServiceServicer):\n+\n+  _DEFAULT_CHUNK_SIZE = 2 << 20\n+\n+  def __init__(\n+      self,\n+      file_reader,  # type: Callable[[str], BinaryIO],\n+      chunk_size=None,\n+  ):\n+    self._file_reader = file_reader\n+    self._chunk_size = chunk_size or self._DEFAULT_CHUNK_SIZE\n+\n+  def ResolveArtifact(self, request, context=None):\n+    return beam_artifact_api_pb2.ResolveArtifactResponse(\n+        replacements=request.artifacts)\n+\n+  def GetArtifact(self, request, context=None):\n+    if request.artifact.type_urn == common_urns.artifact_types.FILE.urn:\n+      payload = proto_utils.parse_Bytes(\n+          request.artifact.type_payload,\n+          beam_runner_api_pb2.ArtifactFilePayload)\n+      read_handle = self._file_reader(payload.path)\n+    elif request.artifact.type_urn == common_urns.artifact_types.URL.urn:\n+      payload = proto_utils.parse_Bytes(\n+          request.artifact.type_payload, beam_runner_api_pb2.ArtifactUrlPayload)\n+      # TODO(Py3): Remove the unneeded contextlib wrapper.\n+      read_handle = contextlib.closing(urlopen(payload.path))\n+    elif request.artifact.type_urn == common_urns.artifact_types.EMBEDDED.urn:\n+      payload = proto_utils.parse_Bytes(\n+          request.artifact.type_payload,\n+          beam_runner_api_pb2.EmbeddedFilePayload)\n+      read_handle = BytesIO(payload.data)\n+    else:\n+      raise NotImplementedError(request.artifact.type_urn)\n+\n+    with read_handle as fin:\n+      while True:\n+        chunk = fin.read(self._chunk_size)\n+        if not chunk:\n+          break\n+        yield beam_artifact_api_pb2.GetArtifactResponse(data=chunk)\n+\n+\n+class ArtifactStagingService(\n+    beam_artifact_api_pb2_grpc.ArtifactStagingServiceServicer):\n+  def __init__(\n+      self,\n+      file_writer,  # type: Callable[[str, Optional[str]], Tuple[BinaryIO, str]]\n+    ):\n+    self._lock = threading.Lock()\n+    self._jobs_to_stage = {}\n+    self._file_writer = file_writer\n+\n+  def register_job(self, staging_token, dependencies):\n+    self._jobs_to_stage[staging_token] = list(dependencies), threading.Event()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQ4OTI4OA=="}, "originalCommit": {"oid": "f10daf5ecc47d57a53e87e9a7bb8845a72f99b4c"}, "originalPosition": 122}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4MzU2ODY1OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/portability/artifact_service.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMFQyMTowMDowOFrOF98ANw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQwMTowNzozN1rOF-BtJA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQ5MDU1MQ==", "bodyText": "It doesn't look like we are passing any of the failures through the queue meaning the daemon thread below will get stuck forever, it would be great if we could pass through the status/error we got from the call we forwarded and stop.", "url": "https://github.com/apache/beam/pull/11203#discussion_r400490551", "createdAt": "2020-03-30T21:00:08Z", "author": {"login": "lukecwik"}, "path": "sdks/python/apache_beam/runners/portability/artifact_service.py", "diffHunk": "@@ -263,3 +279,205 @@ def _open(self, path, mode='r'):\n       return filesystems.FileSystems.create(path)\n     else:\n       return filesystems.FileSystems.open(path)\n+\n+\n+# The dependency-aware artifact staging and retrieval services.\n+\n+\n+def _queue_iter(queue, end_token):\n+  while True:\n+    item = queue.get()\n+    if item is end_token:\n+      break\n+    yield item\n+\n+\n+class ArtifactRetrievalService(\n+    beam_artifact_api_pb2_grpc.ArtifactRetrievalServiceServicer):\n+\n+  _DEFAULT_CHUNK_SIZE = 2 << 20\n+\n+  def __init__(\n+      self,\n+      file_reader,  # type: Callable[[str], BinaryIO],\n+      chunk_size=None,\n+  ):\n+    self._file_reader = file_reader\n+    self._chunk_size = chunk_size or self._DEFAULT_CHUNK_SIZE\n+\n+  def ResolveArtifact(self, request, context=None):\n+    return beam_artifact_api_pb2.ResolveArtifactResponse(\n+        replacements=request.artifacts)\n+\n+  def GetArtifact(self, request, context=None):\n+    if request.artifact.type_urn == common_urns.artifact_types.FILE.urn:\n+      payload = proto_utils.parse_Bytes(\n+          request.artifact.type_payload,\n+          beam_runner_api_pb2.ArtifactFilePayload)\n+      read_handle = self._file_reader(payload.path)\n+    elif request.artifact.type_urn == common_urns.artifact_types.URL.urn:\n+      payload = proto_utils.parse_Bytes(\n+          request.artifact.type_payload, beam_runner_api_pb2.ArtifactUrlPayload)\n+      # TODO(Py3): Remove the unneeded contextlib wrapper.\n+      read_handle = contextlib.closing(urlopen(payload.path))\n+    elif request.artifact.type_urn == common_urns.artifact_types.EMBEDDED.urn:\n+      payload = proto_utils.parse_Bytes(\n+          request.artifact.type_payload,\n+          beam_runner_api_pb2.EmbeddedFilePayload)\n+      read_handle = BytesIO(payload.data)\n+    else:\n+      raise NotImplementedError(request.artifact.type_urn)\n+\n+    with read_handle as fin:\n+      while True:\n+        chunk = fin.read(self._chunk_size)\n+        if not chunk:\n+          break\n+        yield beam_artifact_api_pb2.GetArtifactResponse(data=chunk)\n+\n+\n+class ArtifactStagingService(\n+    beam_artifact_api_pb2_grpc.ArtifactStagingServiceServicer):\n+  def __init__(\n+      self,\n+      file_writer,  # type: Callable[[str, Optional[str]], Tuple[BinaryIO, str]]\n+    ):\n+    self._lock = threading.Lock()\n+    self._jobs_to_stage = {}\n+    self._file_writer = file_writer\n+\n+  def register_job(self, staging_token, dependencies):\n+    self._jobs_to_stage[staging_token] = list(dependencies), threading.Event()\n+\n+  def resolved_deps(self, staging_token, timeout=None):\n+    dependencies_list, event = self._jobs_to_stage[staging_token]\n+    try:\n+      if not event.wait(timeout):\n+        raise concurrent.futures.TimeoutError()\n+      return dependencies_list\n+    finally:\n+      del self._jobs_to_stage[staging_token]\n+\n+  def ReverseArtifactRetrievalService(self, responses, context=None):\n+    staging_token = next(responses).staging_token\n+    dependencies, event = self._jobs_to_stage[staging_token]\n+\n+    requests = queue.Queue()\n+\n+    class FakeRetrievalService(object):\n+      def ResolveArtifacts(self, request):\n+        requests.put(\n+            beam_artifact_api_pb2.ArtifactRequestWrapper(\n+                resolve_artifact=request))\n+        return next(responses).resolve_artifact_response", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f10daf5ecc47d57a53e87e9a7bb8845a72f99b4c"}, "originalPosition": 144}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDU4Mzk3Mg==", "bodyText": "Good call. Done.", "url": "https://github.com/apache/beam/pull/11203#discussion_r400583972", "createdAt": "2020-03-31T01:07:37Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/runners/portability/artifact_service.py", "diffHunk": "@@ -263,3 +279,205 @@ def _open(self, path, mode='r'):\n       return filesystems.FileSystems.create(path)\n     else:\n       return filesystems.FileSystems.open(path)\n+\n+\n+# The dependency-aware artifact staging and retrieval services.\n+\n+\n+def _queue_iter(queue, end_token):\n+  while True:\n+    item = queue.get()\n+    if item is end_token:\n+      break\n+    yield item\n+\n+\n+class ArtifactRetrievalService(\n+    beam_artifact_api_pb2_grpc.ArtifactRetrievalServiceServicer):\n+\n+  _DEFAULT_CHUNK_SIZE = 2 << 20\n+\n+  def __init__(\n+      self,\n+      file_reader,  # type: Callable[[str], BinaryIO],\n+      chunk_size=None,\n+  ):\n+    self._file_reader = file_reader\n+    self._chunk_size = chunk_size or self._DEFAULT_CHUNK_SIZE\n+\n+  def ResolveArtifact(self, request, context=None):\n+    return beam_artifact_api_pb2.ResolveArtifactResponse(\n+        replacements=request.artifacts)\n+\n+  def GetArtifact(self, request, context=None):\n+    if request.artifact.type_urn == common_urns.artifact_types.FILE.urn:\n+      payload = proto_utils.parse_Bytes(\n+          request.artifact.type_payload,\n+          beam_runner_api_pb2.ArtifactFilePayload)\n+      read_handle = self._file_reader(payload.path)\n+    elif request.artifact.type_urn == common_urns.artifact_types.URL.urn:\n+      payload = proto_utils.parse_Bytes(\n+          request.artifact.type_payload, beam_runner_api_pb2.ArtifactUrlPayload)\n+      # TODO(Py3): Remove the unneeded contextlib wrapper.\n+      read_handle = contextlib.closing(urlopen(payload.path))\n+    elif request.artifact.type_urn == common_urns.artifact_types.EMBEDDED.urn:\n+      payload = proto_utils.parse_Bytes(\n+          request.artifact.type_payload,\n+          beam_runner_api_pb2.EmbeddedFilePayload)\n+      read_handle = BytesIO(payload.data)\n+    else:\n+      raise NotImplementedError(request.artifact.type_urn)\n+\n+    with read_handle as fin:\n+      while True:\n+        chunk = fin.read(self._chunk_size)\n+        if not chunk:\n+          break\n+        yield beam_artifact_api_pb2.GetArtifactResponse(data=chunk)\n+\n+\n+class ArtifactStagingService(\n+    beam_artifact_api_pb2_grpc.ArtifactStagingServiceServicer):\n+  def __init__(\n+      self,\n+      file_writer,  # type: Callable[[str, Optional[str]], Tuple[BinaryIO, str]]\n+    ):\n+    self._lock = threading.Lock()\n+    self._jobs_to_stage = {}\n+    self._file_writer = file_writer\n+\n+  def register_job(self, staging_token, dependencies):\n+    self._jobs_to_stage[staging_token] = list(dependencies), threading.Event()\n+\n+  def resolved_deps(self, staging_token, timeout=None):\n+    dependencies_list, event = self._jobs_to_stage[staging_token]\n+    try:\n+      if not event.wait(timeout):\n+        raise concurrent.futures.TimeoutError()\n+      return dependencies_list\n+    finally:\n+      del self._jobs_to_stage[staging_token]\n+\n+  def ReverseArtifactRetrievalService(self, responses, context=None):\n+    staging_token = next(responses).staging_token\n+    dependencies, event = self._jobs_to_stage[staging_token]\n+\n+    requests = queue.Queue()\n+\n+    class FakeRetrievalService(object):\n+      def ResolveArtifacts(self, request):\n+        requests.put(\n+            beam_artifact_api_pb2.ArtifactRequestWrapper(\n+                resolve_artifact=request))\n+        return next(responses).resolve_artifact_response", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDQ5MDU1MQ=="}, "originalCommit": {"oid": "f10daf5ecc47d57a53e87e9a7bb8845a72f99b4c"}, "originalPosition": 144}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4NDI5ODgzOnYy", "diffSide": "RIGHT", "path": "model/job-management/src/main/proto/beam_artifact_api.proto", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQwMjoyMTo0NVrOF-C7aQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQwMjoyMTo0NVrOF-C7aQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDYwNDAwOQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              // A full (ordered) set of replacements for the set of requested artifacts,\n          \n          \n            \n              // A fully (ordered) set of replacements for the set of requested artifacts,", "url": "https://github.com/apache/beam/pull/11203#discussion_r400604009", "createdAt": "2020-03-31T02:21:45Z", "author": {"login": "lukecwik"}, "path": "model/job-management/src/main/proto/beam_artifact_api.proto", "diffHunk": "@@ -67,15 +70,10 @@ message ResolveArtifactRequest {\n \n // A response for artifact resolution.\n message ResolveArtifactResponse {\n-  // A full set of replacements for the set of requested artifacts, preferably\n-  // in terms of the requested type URNs.  If there is no better resolution,\n-  // the original list is returned.\n+  // A full (ordered) set of replacements for the set of requested artifacts,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7ee5b3c786ba6eac14bdbf72cf599962000bdb3e"}, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ4NDMwMjA3OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/portability/artifact_service.py", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQwMjoyNDowMlrOF-C9gg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0zMVQwMjoyNDowMlrOF-C9gg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMDYwNDU0Ng==", "bodyText": "so clever", "url": "https://github.com/apache/beam/pull/11203#discussion_r400604546", "createdAt": "2020-03-31T02:24:02Z", "author": {"login": "lukecwik"}, "path": "sdks/python/apache_beam/runners/portability/artifact_service.py", "diffHunk": "@@ -284,12 +284,38 @@ def _open(self, path, mode='r'):\n # The dependency-aware artifact staging and retrieval services.\n \n \n-def _queue_iter(queue, end_token):\n-  while True:\n-    item = queue.get()\n-    if item is end_token:\n-      break\n-    yield item\n+class _QueueIter(object):\n+\n+  _END = object()\n+\n+  def __init__(self):\n+    self._queue = queue.Queue()\n+\n+  def put(self, item):\n+    self._queue.put(item)\n+\n+  def done(self):\n+    self._queue.put(self._END)\n+    self._queue.put(StopIteration)\n+\n+  def abort(self, exn=None):\n+    if exn is None:\n+      exn = sys.exc_info()[1]\n+    self._queue.put(self._END)\n+    self._queue.put(exn)\n+\n+  def __iter__(self):\n+    return self\n+\n+  def __next__(self):\n+    item = self._queue.get()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "baba007204286dc35f84d44e4302b366e82355eb"}, "originalPosition": 34}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1497, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}