{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzgzMzAzMjY3", "number": 11039, "title": "[BEAM-9383] Staging Dataflow artifacts from environment", "bodyText": "Thank you for your contribution! Follow this checklist to help us incorporate your contribution quickly and easily:\n\n Choose reviewer(s) and mention them in a comment (R: @username).\n Format the pull request title like [BEAM-XXX] Fixes bug in ApproximateQuantiles, where you replace BEAM-XXX with the appropriate JIRA issue, if applicable. This will automatically link the pull request to the issue.\n Update CHANGES.md with noteworthy changes.\n If this contribution is large, please file an Apache Individual Contributor License Agreement.\n\nSee the Contributor Guide for more tips on how to make review process smoother.\nPost-Commit Tests Status (on master branch)\n\n\n\nLang\nSDK\nApex\nDataflow\nFlink\nGearpump\nSamza\nSpark\n\n\n\n\nGo\n\n---\n---\n\n---\n---\n\n\n\nJava\n\n\n\n\n\n\n\n\n\nPython\n\n---\n\n\n---\n---\n\n\n\nXLang\n---\n---\n---\n\n---\n---\n\n\n\n\nPre-Commit Tests Status (on master branch)\n\n\n\n---\nJava\nPython\nGo\nWebsite\n\n\n\n\nNon-portable\n\n\n\n\n\n\nPortable\n---\n\n---\n---\n\n\n\nSee .test-infra/jenkins/README for trigger phrase, status and link of all Jenkins jobs.", "createdAt": "2020-03-04T02:30:48Z", "url": "https://github.com/apache/beam/pull/11039", "merged": true, "mergeCommit": {"oid": "84c12ebbc5cc3ec73dce772175d185d35f58c564"}, "closed": true, "closedAt": "2020-05-19T15:39:39Z", "author": {"login": "ihji"}, "timelineItems": {"totalCount": 15, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcM_GhbgBqjMxMjM3ODY0Nzk=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcivH5KABqjMzNTA0MTQ0MTE=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ce2839484830f5fc14d56f03be825ee0e14c30c7", "author": {"user": {"login": "ihji", "name": "Heejong Lee"}}, "url": "https://github.com/apache/beam/commit/ce2839484830f5fc14d56f03be825ee0e14c30c7", "committedDate": "2020-03-04T02:29:23Z", "message": "[BEAM-9383] Staging Dataflow artifacts from environment"}, "afterCommit": {"oid": "4ad6a3840921557745ff89c88fd69e5d091cd257", "author": {"user": {"login": "ihji", "name": "Heejong Lee"}}, "url": "https://github.com/apache/beam/commit/4ad6a3840921557745ff89c88fd69e5d091cd257", "committedDate": "2020-03-12T17:18:12Z", "message": "[BEAM-9383] Staging Dataflow artifacts from environment"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "4ad6a3840921557745ff89c88fd69e5d091cd257", "author": {"user": {"login": "ihji", "name": "Heejong Lee"}}, "url": "https://github.com/apache/beam/commit/4ad6a3840921557745ff89c88fd69e5d091cd257", "committedDate": "2020-03-12T17:18:12Z", "message": "[BEAM-9383] Staging Dataflow artifacts from environment"}, "afterCommit": {"oid": "d975d8b08e62bc9e585ac865fbac3912e4429f38", "author": {"user": {"login": "ihji", "name": "Heejong Lee"}}, "url": "https://github.com/apache/beam/commit/d975d8b08e62bc9e585ac865fbac3912e4429f38", "committedDate": "2020-03-12T21:06:16Z", "message": "[BEAM-9383] Staging Dataflow artifacts from environment"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d975d8b08e62bc9e585ac865fbac3912e4429f38", "author": {"user": {"login": "ihji", "name": "Heejong Lee"}}, "url": "https://github.com/apache/beam/commit/d975d8b08e62bc9e585ac865fbac3912e4429f38", "committedDate": "2020-03-12T21:06:16Z", "message": "[BEAM-9383] Staging Dataflow artifacts from environment"}, "afterCommit": {"oid": "02fe6acf5ffa580f1e6ca06bfc04ba44a8c5dd0e", "author": {"user": {"login": "ihji", "name": "Heejong Lee"}}, "url": "https://github.com/apache/beam/commit/02fe6acf5ffa580f1e6ca06bfc04ba44a8c5dd0e", "committedDate": "2020-03-12T22:07:14Z", "message": "[BEAM-9383] Staging Dataflow artifacts from environment"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzc0NjU1NDU5", "url": "https://github.com/apache/beam/pull/11039#pullrequestreview-374655459", "createdAt": "2020-03-13T22:40:46Z", "commit": {"oid": "02fe6acf5ffa580f1e6ca06bfc04ba44a8c5dd0e"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xM1QyMzo0NzozMFrOF2WKFw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xM1QyMzo0ODo1NFrOF2WLFw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjUzMDQ1NQ==", "bodyText": "Check the ROLE as well ?", "url": "https://github.com/apache/beam/pull/11039#discussion_r392530455", "createdAt": "2020-03-13T23:47:30Z", "author": {"login": "chamikaramj"}, "path": "runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowRunner.java", "diffHunk": "@@ -752,6 +759,27 @@ private Debuggee registerDebuggee(CloudDebugger debuggerClient, String uniquifie\n     }\n   }\n \n+  private List<DataflowPackage> stageArtifacts(RunnerApi.Pipeline pipeline) {\n+    ImmutableList.Builder<String> filesToStageBuilder = ImmutableList.builder();\n+    for (Map.Entry<String, RunnerApi.Environment> entry :\n+        pipeline.getComponents().getEnvironmentsMap().entrySet()) {\n+      for (RunnerApi.ArtifactInformation info : entry.getValue().getDependenciesList()) {\n+        if (!BeamUrns.getUrn(RunnerApi.StandardArtifacts.Types.FILE).equals(info.getTypeUrn())) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "02fe6acf5ffa580f1e6ca06bfc04ba44a8c5dd0e"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjUzMDQ3Mg==", "bodyText": "Please add a unit test.", "url": "https://github.com/apache/beam/pull/11039#discussion_r392530472", "createdAt": "2020-03-13T23:47:36Z", "author": {"login": "chamikaramj"}, "path": "runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowRunner.java", "diffHunk": "@@ -752,6 +759,27 @@ private Debuggee registerDebuggee(CloudDebugger debuggerClient, String uniquifie\n     }\n   }\n \n+  private List<DataflowPackage> stageArtifacts(RunnerApi.Pipeline pipeline) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "02fe6acf5ffa580f1e6ca06bfc04ba44a8c5dd0e"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjUzMDU4MQ==", "bodyText": "Please add a unit test", "url": "https://github.com/apache/beam/pull/11039#discussion_r392530581", "createdAt": "2020-03-13T23:48:12Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/runners/dataflow/internal/apiclient.py", "diffHunk": "@@ -563,19 +562,31 @@ def _gcs_file_copy(self, from_path, to_path):\n     with open(from_path, 'rb') as f:\n       self.stage_file(to_folder, to_name, f, total_size=total_size)\n \n-  def _stage_resources(self, options):\n+  def _stage_resources(self, pipeline, options):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "02fe6acf5ffa580f1e6ca06bfc04ba44a8c5dd0e"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjUzMDcxMQ==", "bodyText": "Nit: Pls use ( instead of \\ for formatting.", "url": "https://github.com/apache/beam/pull/11039#discussion_r392530711", "createdAt": "2020-03-13T23:48:54Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/runners/dataflow/internal/apiclient.py", "diffHunk": "@@ -563,19 +562,31 @@ def _gcs_file_copy(self, from_path, to_path):\n     with open(from_path, 'rb') as f:\n       self.stage_file(to_folder, to_name, f, total_size=total_size)\n \n-  def _stage_resources(self, options):\n+  def _stage_resources(self, pipeline, options):\n     google_cloud_options = options.view_as(GoogleCloudOptions)\n     if google_cloud_options.staging_location is None:\n       raise RuntimeError('The --staging_location option must be specified.')\n     if google_cloud_options.temp_location is None:\n       raise RuntimeError('The --temp_location option must be specified.')\n \n+    resources = []\n+    for _, env in pipeline.components.environments.items():\n+      for dep in env.dependencies:\n+        if dep.type_urn != common_urns.artifact_types.FILE.urn:\n+          raise RuntimeError('unsupported artifact type %s' % dep.type_urn)\n+        if dep.role_urn != common_urns.artifact_roles.STAGING_TO.urn:\n+          raise RuntimeError('unsupported role type %s' % dep.role_urn)\n+        type_payload = beam_runner_api_pb2.ArtifactFilePayload.FromString(\n+            dep.type_payload)\n+        role_payload = \\", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "02fe6acf5ffa580f1e6ca06bfc04ba44a8c5dd0e"}, "originalPosition": 29}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b6ee1880c4c90362d43bd6286c6b62bcf27f47cd", "author": {"user": {"login": "ihji", "name": "Heejong Lee"}}, "url": "https://github.com/apache/beam/commit/b6ee1880c4c90362d43bd6286c6b62bcf27f47cd", "committedDate": "2020-03-24T08:10:58Z", "message": "fix precommit errors"}, "afterCommit": {"oid": "0a955c4f5396bf445c59755f9a1b01d7f8b5df69", "author": {"user": {"login": "ihji", "name": "Heejong Lee"}}, "url": "https://github.com/apache/beam/commit/0a955c4f5396bf445c59755f9a1b01d7f8b5df69", "committedDate": "2020-04-24T02:58:35Z", "message": "[BEAM-9383] Staging Dataflow artifacts from environment"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0a955c4f5396bf445c59755f9a1b01d7f8b5df69", "author": {"user": {"login": "ihji", "name": "Heejong Lee"}}, "url": "https://github.com/apache/beam/commit/0a955c4f5396bf445c59755f9a1b01d7f8b5df69", "committedDate": "2020-04-24T02:58:35Z", "message": "[BEAM-9383] Staging Dataflow artifacts from environment"}, "afterCommit": {"oid": "331f30d6bfe8acf069476f539c4b1bdd91e03675", "author": {"user": {"login": "ihji", "name": "Heejong Lee"}}, "url": "https://github.com/apache/beam/commit/331f30d6bfe8acf069476f539c4b1bdd91e03675", "committedDate": "2020-04-24T07:19:48Z", "message": "[BEAM-9383] Staging Dataflow artifacts from environment"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA0Mjk0OTc5", "url": "https://github.com/apache/beam/pull/11039#pullrequestreview-404294979", "createdAt": "2020-05-01T17:39:12Z", "commit": {"oid": "331f30d6bfe8acf069476f539c4b1bdd91e03675"}, "state": "COMMENTED", "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wMVQxNzozOToxMlrOGPQckA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wMVQxODoxNToxNlrOGPRdJw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODY1MTI4MA==", "bodyText": "Why does this have to be distinct from staged_name? (Also, eventually we hope that designated roles can remove the need for magic names.)", "url": "https://github.com/apache/beam/pull/11039#discussion_r418651280", "createdAt": "2020-05-01T17:39:12Z", "author": {"login": "robertwb"}, "path": "model/pipeline/src/main/proto/beam_runner_api.proto", "diffHunk": "@@ -1271,6 +1271,11 @@ message DeferredArtifactPayload {\n message ArtifactStagingToRolePayload {\n   // A generated staged name (relative path under staging directory).\n   string staged_name = 1;\n+\n+  // (Optional) An artifact name when a runner supports it.\n+  // For example, DataflowRunner requires predefined names for some artifacts\n+  // such as \"dataflow-worker.jar\", \"windmill_main\".\n+  string alias_name = 2;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "331f30d6bfe8acf069476f539c4b1bdd91e03675"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODY1MjE1Mg==", "bodyText": "Isn't order important to preserve? (Also, why do we need to make a copy?)", "url": "https://github.com/apache/beam/pull/11039#discussion_r418652152", "createdAt": "2020-05-01T17:41:03Z", "author": {"login": "robertwb"}, "path": "runners/core-construction-java/src/main/java/org/apache/beam/runners/core/construction/Environments.java", "diffHunk": "@@ -210,56 +209,55 @@ public static Environment createProcessEnvironment(\n     }\n   }\n \n-  private static List<ArtifactInformation> getArtifacts(List<String> stagingFiles) {\n-    Set<String> pathsToStage = Sets.newHashSet(stagingFiles);\n+  public static List<ArtifactInformation> getArtifacts(\n+      List<String> stagingFiles, StagingFileNameGenerator generator) {\n     ImmutableList.Builder<ArtifactInformation> artifactsBuilder = ImmutableList.builder();\n-    for (String path : pathsToStage) {\n+    for (String path : ImmutableSet.copyOf(stagingFiles)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "331f30d6bfe8acf069476f539c4b1bdd91e03675"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODY1NTgwMg==", "bodyText": "This is a really big log message, even for debug. (Even computing it could be expensive, for pipelines with 1000s of stages.)", "url": "https://github.com/apache/beam/pull/11039#discussion_r418655802", "createdAt": "2020-05-01T17:49:01Z", "author": {"login": "robertwb"}, "path": "runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowRunner.java", "diffHunk": "@@ -784,7 +877,25 @@ public DataflowPipelineJob run(Pipeline pipeline) {\n         \"Executing pipeline on the Dataflow Service, which will have billing implications \"\n             + \"related to Google Compute Engine usage and other Google Cloud Services.\");\n \n-    List<DataflowPackage> packages = options.getStager().stageDefaultFiles();\n+    // Capture the sdkComponents for look up during step translations\n+    SdkComponents sdkComponents = SdkComponents.create();\n+\n+    DataflowPipelineOptions dataflowOptions = options.as(DataflowPipelineOptions.class);\n+    String workerHarnessContainerImageURL = DataflowRunner.getContainerImageForJob(dataflowOptions);\n+    RunnerApi.Environment defaultEnvironmentForDataflow =\n+        Environments.createDockerEnvironment(workerHarnessContainerImageURL);\n+\n+    sdkComponents.registerEnvironment(\n+        defaultEnvironmentForDataflow\n+            .toBuilder()\n+            .addAllDependencies(getDefaultArtifacts())\n+            .build());\n+\n+    RunnerApi.Pipeline pipelineProto = PipelineTranslation.toProto(pipeline, sdkComponents, true);\n+\n+    LOG.debug(\"Portable pipeline proto:\\n{}\", TextFormat.printToString(pipelineProto));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "331f30d6bfe8acf069476f539c4b1bdd91e03675"}, "originalPosition": 170}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODY1NzA3OQ==", "bodyText": "How does this get invoked for cross-language pipelines?", "url": "https://github.com/apache/beam/pull/11039#discussion_r418657079", "createdAt": "2020-05-01T17:51:39Z", "author": {"login": "robertwb"}, "path": "runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowRunner.java", "diffHunk": "@@ -784,7 +877,25 @@ public DataflowPipelineJob run(Pipeline pipeline) {\n         \"Executing pipeline on the Dataflow Service, which will have billing implications \"\n             + \"related to Google Compute Engine usage and other Google Cloud Services.\");\n \n-    List<DataflowPackage> packages = options.getStager().stageDefaultFiles();\n+    // Capture the sdkComponents for look up during step translations\n+    SdkComponents sdkComponents = SdkComponents.create();\n+\n+    DataflowPipelineOptions dataflowOptions = options.as(DataflowPipelineOptions.class);\n+    String workerHarnessContainerImageURL = DataflowRunner.getContainerImageForJob(dataflowOptions);\n+    RunnerApi.Environment defaultEnvironmentForDataflow =\n+        Environments.createDockerEnvironment(workerHarnessContainerImageURL);\n+\n+    sdkComponents.registerEnvironment(\n+        defaultEnvironmentForDataflow\n+            .toBuilder()\n+            .addAllDependencies(getDefaultArtifacts())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "331f30d6bfe8acf069476f539c4b1bdd91e03675"}, "originalPosition": 165}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODY2NDYyNQ==", "bodyText": "Is this = support a dataflow-only thing? Seems we don't support that in Environments.getArtifacts() (but if we did nearly all of this code could go away).", "url": "https://github.com/apache/beam/pull/11039#discussion_r418664625", "createdAt": "2020-05-01T18:07:50Z", "author": {"login": "robertwb"}, "path": "runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowRunner.java", "diffHunk": "@@ -772,6 +783,88 @@ private Debuggee registerDebuggee(CloudDebugger debuggerClient, String uniquifie\n     }\n   }\n \n+  private List<DataflowPackage> stageArtifacts(RunnerApi.Pipeline pipeline) {\n+    ImmutableList.Builder<StagedFile> filesToStageBuilder = ImmutableList.builder();\n+    for (Map.Entry<String, RunnerApi.Environment> entry :\n+        pipeline.getComponents().getEnvironmentsMap().entrySet()) {\n+      for (RunnerApi.ArtifactInformation info : entry.getValue().getDependenciesList()) {\n+        if (!BeamUrns.getUrn(RunnerApi.StandardArtifacts.Types.FILE).equals(info.getTypeUrn())) {\n+          throw new RuntimeException(\n+              String.format(\"unsupported artifact type %s\", info.getTypeUrn()));\n+        }\n+        RunnerApi.ArtifactFilePayload filePayload;\n+        try {\n+          filePayload = RunnerApi.ArtifactFilePayload.parseFrom(info.getTypePayload());\n+        } catch (InvalidProtocolBufferException e) {\n+          throw new RuntimeException(\"Error parsing artifact file payload.\", e);\n+        }\n+        if (!BeamUrns.getUrn(RunnerApi.StandardArtifacts.Roles.STAGING_TO)\n+            .equals(info.getRoleUrn())) {\n+          throw new RuntimeException(\n+              String.format(\"unsupported artifact role %s\", info.getRoleUrn()));\n+        }\n+        RunnerApi.ArtifactStagingToRolePayload stagingPayload;\n+        try {\n+          stagingPayload = RunnerApi.ArtifactStagingToRolePayload.parseFrom(info.getRolePayload());\n+        } catch (InvalidProtocolBufferException e) {\n+          throw new RuntimeException(\"Error parsing artifact staging_to role payload.\", e);\n+        }\n+        DataflowPackage target = new DataflowPackage();\n+        target.setLocation(stagingPayload.getStagedName());\n+        if (!Strings.isNullOrEmpty(stagingPayload.getAliasName())) {\n+          target.setName(stagingPayload.getAliasName());\n+        }\n+        filesToStageBuilder.add(StagedFile.of(filePayload.getPath(), target));\n+      }\n+    }\n+    return options.getStager().stageFiles(filesToStageBuilder.build());\n+  }\n+\n+  private List<RunnerApi.ArtifactInformation> getDefaultArtifacts() {\n+    ImmutableList.Builder<String> pathsToStageBuilder = ImmutableList.builder();\n+    ImmutableMap.Builder<String, String> aliasMapBuilder = ImmutableMap.builder();\n+    String windmillBinary =\n+        options.as(DataflowPipelineDebugOptions.class).getOverrideWindmillBinary();\n+    String dataflowWorkerJar = options.getDataflowWorkerJar();\n+    if (dataflowWorkerJar != null && !dataflowWorkerJar.isEmpty()) {\n+      // Put the user specified worker jar at the start of the classpath, to be consistent with the\n+      // built in worker order.\n+      pathsToStageBuilder.add(dataflowWorkerJar);\n+      aliasMapBuilder.put(dataflowWorkerJar, \"dataflow-worker.jar\");\n+    }\n+    for (String path : options.getFilesToStage()) {\n+      if (path.contains(\"=\")) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "331f30d6bfe8acf069476f539c4b1bdd91e03675"}, "originalPosition": 114}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODY2NTUyNQ==", "bodyText": "Why do we have to handle this here and above?", "url": "https://github.com/apache/beam/pull/11039#discussion_r418665525", "createdAt": "2020-05-01T18:09:43Z", "author": {"login": "robertwb"}, "path": "runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/util/PackageUtil.java", "diffHunk": "@@ -336,25 +323,26 @@ public DataflowPackage stageToFile(\n     final AtomicInteger numCached = new AtomicInteger(0);\n     List<CompletionStage<DataflowPackage>> destinationPackages = new ArrayList<>();\n \n-    for (String classpathElement : classpathElements) {\n-      DataflowPackage sourcePackage = new DataflowPackage();\n-      if (classpathElement.contains(\"=\")) {\n-        String[] components = classpathElement.split(\"=\", 2);\n-        sourcePackage.setName(components[0]);\n-        sourcePackage.setLocation(components[1]);\n-      } else {\n-        sourcePackage.setName(null);\n-        sourcePackage.setLocation(classpathElement);\n+    for (StagedFile classpathElement : classpathElements) {\n+      DataflowPackage targetPackage = classpathElement.getStagedPackage();\n+      String source = classpathElement.getSource();\n+      if (source.contains(\"=\")) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "331f30d6bfe8acf069476f539c4b1bdd91e03675"}, "originalPosition": 78}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODY2NjcxNw==", "bodyText": "This seems highly redundant with what we're already doing in Environments.getArtifacts. Can't we ensure we have a set of (existing, non-directory) files in the environment, and then have these utilities simply do the uploading?", "url": "https://github.com/apache/beam/pull/11039#discussion_r418666717", "createdAt": "2020-05-01T18:12:43Z", "author": {"login": "robertwb"}, "path": "runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/util/PackageUtil.java", "diffHunk": "@@ -442,45 +448,56 @@ public static StagingResult uploaded(PackageAttributes attributes) {\n   /** Holds the metadata necessary to stage a file or confirm that a staged file has not changed. */\n   @AutoValue\n   abstract static class PackageAttributes {\n-\n-    public static PackageAttributes forFileToStage(File source, String stagingPath)\n+    public static PackageAttributes forFileToStage(File file, String stagingPath)\n         throws IOException {\n+      return forFileToStage(file.getPath(), null, stagingPath);\n+    }\n \n+    public static PackageAttributes forFileToStage(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "331f30d6bfe8acf069476f539c4b1bdd91e03675"}, "originalPosition": 145}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODY2NzYyNg==", "bodyText": "Should we push populating artifacts into from_container_image?", "url": "https://github.com/apache/beam/pull/11039#discussion_r418667626", "createdAt": "2020-05-01T18:14:50Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/runners/dataflow/dataflow_runner.py", "diffHunk": "@@ -462,7 +462,8 @@ def run_pipeline(self, pipeline, options):\n     use_fnapi = apiclient._use_fnapi(options)\n     from apache_beam.transforms import environments\n     default_environment = environments.DockerEnvironment.from_container_image(\n-        apiclient.get_container_image_from_options(options))\n+        apiclient.get_container_image_from_options(options),\n+        artifacts=environments.python_sdk_dependencies(options))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "331f30d6bfe8acf069476f539c4b1bdd91e03675"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODY2NzgxNQ==", "bodyText": "Why this change?", "url": "https://github.com/apache/beam/pull/11039#discussion_r418667815", "createdAt": "2020-05-01T18:15:16Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/runners/dataflow/dataflow_runner_test.py", "diffHunk": "@@ -102,7 +102,8 @@ def setUp(self):\n         '--staging_location=ignored',\n         '--temp_location=/dev/null',\n         '--no_auth',\n-        '--dry_run=True'\n+        '--dry_run=True',\n+        '--sdk_location=container'", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "331f30d6bfe8acf069476f539c4b1bdd91e03675"}, "originalPosition": 6}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDEwNTAxMDY4", "url": "https://github.com/apache/beam/pull/11039#pullrequestreview-410501068", "createdAt": "2020-05-12T23:55:58Z", "commit": {"oid": "1f53e6e38dd4322f87252a0689d3b1356de7a6ef"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQyMzo1NTo1OFrOGUc8eQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMlQyMzo1NTo1OFrOGUc8eQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNDA5ODkzNw==", "bodyText": "We shouldn't be modifying the staging payload for this. \"dataflow-worker.jar\" or \"windmill_main\" should be the staged_name (that's literally what it's for). I think we can get rid of the whole StagingFileNameGenerator callback, just respect the = if there is any in the staging name path, and don't bother invoking PackageUtil.getUniqueContentName util you're staging to dataflow.", "url": "https://github.com/apache/beam/pull/11039#discussion_r424098937", "createdAt": "2020-05-12T23:55:58Z", "author": {"login": "robertwb"}, "path": "model/pipeline/src/main/proto/beam_runner_api.proto", "diffHunk": "@@ -1271,6 +1271,11 @@ message DeferredArtifactPayload {\n message ArtifactStagingToRolePayload {\n   // A generated staged name (relative path under staging directory).\n   string staged_name = 1;\n+\n+  // (Optional) An artifact name when a runner supports it.\n+  // For example, DataflowRunner requires predefined names for some artifacts\n+  // such as \"dataflow-worker.jar\", \"windmill_main\".\n+  string alias_name = 2;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODY1MTI4MA=="}, "originalCommit": {"oid": "331f30d6bfe8acf069476f539c4b1bdd91e03675"}, "originalPosition": 8}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDEzOTE3ODA2", "url": "https://github.com/apache/beam/pull/11039#pullrequestreview-413917806", "createdAt": "2020-05-18T20:30:58Z", "commit": {"oid": "3e368f7f2fc9993960d5d070a2865ae6ef161c92"}, "state": "APPROVED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQyMDozMDo1OFrOGXGfoQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOFQyMDo1Mzo0OVrOGXHJfQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjg3NjgzMw==", "bodyText": "You could just match \".*.txt\" here, rather than hard-coding the uuid format. (Same blow.)", "url": "https://github.com/apache/beam/pull/11039#discussion_r426876833", "createdAt": "2020-05-18T20:30:58Z", "author": {"login": "robertwb"}, "path": "runners/google-cloud-dataflow-java/src/test/java/org/apache/beam/runners/dataflow/util/PackageUtilTest.java", "diffHunk": "@@ -195,7 +187,7 @@ public void testFileWithExtensionPackageNamingAndSize() throws Exception {\n     PackageAttributes attr = makePackageAttributes(tmpFile, null);\n     DataflowPackage target = attr.getDestination();\n \n-    assertThat(target.getName(), RegexMatcher.matches(\"file-\" + HASH_PATTERN + \".txt\"));\n+    assertThat(target.getName(), RegexMatcher.matches(UUID_PATTERN + \".txt\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3e368f7f2fc9993960d5d070a2865ae6ef161c92"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjg4NzU0OQ==", "bodyText": "OK, we don't have to change this.", "url": "https://github.com/apache/beam/pull/11039#discussion_r426887549", "createdAt": "2020-05-18T20:53:49Z", "author": {"login": "robertwb"}, "path": "runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowRunner.java", "diffHunk": "@@ -784,7 +877,25 @@ public DataflowPipelineJob run(Pipeline pipeline) {\n         \"Executing pipeline on the Dataflow Service, which will have billing implications \"\n             + \"related to Google Compute Engine usage and other Google Cloud Services.\");\n \n-    List<DataflowPackage> packages = options.getStager().stageDefaultFiles();\n+    // Capture the sdkComponents for look up during step translations\n+    SdkComponents sdkComponents = SdkComponents.create();\n+\n+    DataflowPipelineOptions dataflowOptions = options.as(DataflowPipelineOptions.class);\n+    String workerHarnessContainerImageURL = DataflowRunner.getContainerImageForJob(dataflowOptions);\n+    RunnerApi.Environment defaultEnvironmentForDataflow =\n+        Environments.createDockerEnvironment(workerHarnessContainerImageURL);\n+\n+    sdkComponents.registerEnvironment(\n+        defaultEnvironmentForDataflow\n+            .toBuilder()\n+            .addAllDependencies(getDefaultArtifacts())\n+            .build());\n+\n+    RunnerApi.Pipeline pipelineProto = PipelineTranslation.toProto(pipeline, sdkComponents, true);\n+\n+    LOG.debug(\"Portable pipeline proto:\\n{}\", TextFormat.printToString(pipelineProto));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODY1NTgwMg=="}, "originalCommit": {"oid": "331f30d6bfe8acf069476f539c4b1bdd91e03675"}, "originalPosition": 170}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d0358130a1b3e203f20064f3f596e62fb6758058", "author": {"user": {"login": "ihji", "name": "Heejong Lee"}}, "url": "https://github.com/apache/beam/commit/d0358130a1b3e203f20064f3f596e62fb6758058", "committedDate": "2020-05-18T22:02:08Z", "message": "make pipeline files unique"}, "afterCommit": {"oid": "5298d69ee753aead758cc92ecf44558af8c5f97e", "author": {"user": {"login": "ihji", "name": "Heejong Lee"}}, "url": "https://github.com/apache/beam/commit/5298d69ee753aead758cc92ecf44558af8c5f97e", "committedDate": "2020-05-18T22:12:00Z", "message": "make pipeline files unique"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE0MDM1NzQ0", "url": "https://github.com/apache/beam/pull/11039#pullrequestreview-414035744", "createdAt": "2020-05-19T01:12:42Z", "commit": {"oid": "26045210fc0e16732e55a4dd25e813c4e98f228c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQwMToxMjo0MlrOGXMdVA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQwMToxMjo0MlrOGXMdVA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk3NDU0OA==", "bodyText": "Shouldn't we have a test to show the artifacts were properly set?", "url": "https://github.com/apache/beam/pull/11039#discussion_r426974548", "createdAt": "2020-05-19T01:12:42Z", "author": {"login": "lukecwik"}, "path": "runners/google-cloud-dataflow-java/src/test/java/org/apache/beam/runners/dataflow/DataflowPipelineTranslatorTest.java", "diffHunk": "@@ -53,9 +53,12 @@\n import org.apache.beam.model.pipeline.v1.RunnerApi.DockerPayload;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "26045210fc0e16732e55a4dd25e813c4e98f228c"}, "originalPosition": 1}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE0MDM1OTE4", "url": "https://github.com/apache/beam/pull/11039#pullrequestreview-414035918", "createdAt": "2020-05-19T01:13:23Z", "commit": {"oid": "26045210fc0e16732e55a4dd25e813c4e98f228c"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7b623517487bd8e32631e8246af49b0ac2b0c0c0", "author": {"user": {"login": "ihji", "name": "Heejong Lee"}}, "url": "https://github.com/apache/beam/commit/7b623517487bd8e32631e8246af49b0ac2b0c0c0", "committedDate": "2020-05-19T04:00:05Z", "message": "[BEAM-9383] Staging Dataflow artifacts from environment"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ee53ccc953595bba47254122d6e64c760ae3938f", "author": {"user": {"login": "ihji", "name": "Heejong Lee"}}, "url": "https://github.com/apache/beam/commit/ee53ccc953595bba47254122d6e64c760ae3938f", "committedDate": "2020-05-19T07:12:55Z", "message": "rebase, adding test"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "26045210fc0e16732e55a4dd25e813c4e98f228c", "author": {"user": {"login": "ihji", "name": "Heejong Lee"}}, "url": "https://github.com/apache/beam/commit/26045210fc0e16732e55a4dd25e813c4e98f228c", "committedDate": "2020-05-19T00:59:07Z", "message": "remove UUID check in test"}, "afterCommit": {"oid": "ee53ccc953595bba47254122d6e64c760ae3938f", "author": {"user": {"login": "ihji", "name": "Heejong Lee"}}, "url": "https://github.com/apache/beam/commit/ee53ccc953595bba47254122d6e64c760ae3938f", "committedDate": "2020-05-19T07:12:55Z", "message": "rebase, adding test"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3008, "cost": 1, "resetAt": "2021-10-28T16:48:13Z"}}}