{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE5ODE3MTUw", "number": 11748, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQwMToxMTo1MFrOD9mkRQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQwMToxMTo1MFrOD9mkRQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY1OTIxNjA1OnYy", "diffSide": "RIGHT", "path": "runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowPipelineTranslator.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQwMToxMTo1MFrOGXMcTg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xOVQwMzoxMjowNlrOGXOUVQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk3NDI4Ng==", "bodyText": "Is there some common utility we should be using here (rather than duplicating the code that's used in all the other portable runners)? What about requirements?", "url": "https://github.com/apache/beam/pull/11748#discussion_r426974286", "createdAt": "2020-05-19T01:11:50Z", "author": {"login": "robertwb"}, "path": "runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowPipelineTranslator.java", "diffHunk": "@@ -183,7 +183,10 @@ public JobSpecification translate(\n     String workerHarnessContainerImageURL =\n         DataflowRunner.getContainerImageForJob(options.as(DataflowPipelineOptions.class));\n     RunnerApi.Environment defaultEnvironmentForDataflow =\n-        Environments.createDockerEnvironment(workerHarnessContainerImageURL);\n+        Environments.createDockerEnvironment(workerHarnessContainerImageURL)\n+            .toBuilder()\n+            .addAllCapabilities(Environments.getJavaCapabilities())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a1a4cb362b35c204b2cb5ecfcfd379ecc65b6358"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzAwNTAxMw==", "bodyText": "Requirements is on the pipeline and that works.\nSince Dataflow is creating its own environment it is difficult to have common code because of the differences in the artifact staging and job APIs", "url": "https://github.com/apache/beam/pull/11748#discussion_r427005013", "createdAt": "2020-05-19T03:12:06Z", "author": {"login": "lukecwik"}, "path": "runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowPipelineTranslator.java", "diffHunk": "@@ -183,7 +183,10 @@ public JobSpecification translate(\n     String workerHarnessContainerImageURL =\n         DataflowRunner.getContainerImageForJob(options.as(DataflowPipelineOptions.class));\n     RunnerApi.Environment defaultEnvironmentForDataflow =\n-        Environments.createDockerEnvironment(workerHarnessContainerImageURL);\n+        Environments.createDockerEnvironment(workerHarnessContainerImageURL)\n+            .toBuilder()\n+            .addAllCapabilities(Environments.getJavaCapabilities())", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNjk3NDI4Ng=="}, "originalCommit": {"oid": "a1a4cb362b35c204b2cb5ecfcfd379ecc65b6358"}, "originalPosition": 7}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3804, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}