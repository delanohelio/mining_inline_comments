{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzkzODU3Nzg3", "number": 11229, "reviewThreads": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QyMTo1MzowN1rODsPP-Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxODo0MTo1M1rODtqKtA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ3NzEzNzg1OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/portability/fn_api_runner/execution.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QyMTo1MzowN1rOF9C7PA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QyMjo0MjowMFrOF9D1HA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU1NTM4OA==", "bodyText": "Fix description.\n(Interestingly, I just did this change as well for another PR.)", "url": "https://github.com/apache/beam/pull/11229#discussion_r399555388", "createdAt": "2020-03-27T21:53:07Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/runners/portability/fn_api_runner/execution.py", "diffHunk": "@@ -245,37 +254,106 @@ class FnApiRunnerExecutionContext(object):\n        ``beam.PCollection``.\n  \"\"\"\n   def __init__(self,\n-      worker_handler_factory,  # type: Callable[[Optional[str], int], List[WorkerHandler]]\n+      worker_handler_manager,  # type: worker_handlers.WorkerHandlerManager\n       pipeline_components,  # type: beam_runner_api_pb2.Components\n       safe_coders,\n       data_channel_coders,\n                ):\n     \"\"\"\n-    :param worker_handler_factory: A ``callable`` that takes in an environment\n+    :param worker_handler_manager: A ``callable`` that takes in an environment", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "30c17d5cdb4e6162174e92fbdba55a6332da25ba"}, "originalPosition": 43}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3MDIwNA==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/11229#discussion_r399570204", "createdAt": "2020-03-27T22:42:00Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/runners/portability/fn_api_runner/execution.py", "diffHunk": "@@ -245,37 +254,106 @@ class FnApiRunnerExecutionContext(object):\n        ``beam.PCollection``.\n  \"\"\"\n   def __init__(self,\n-      worker_handler_factory,  # type: Callable[[Optional[str], int], List[WorkerHandler]]\n+      worker_handler_manager,  # type: worker_handlers.WorkerHandlerManager\n       pipeline_components,  # type: beam_runner_api_pb2.Components\n       safe_coders,\n       data_channel_coders,\n                ):\n     \"\"\"\n-    :param worker_handler_factory: A ``callable`` that takes in an environment\n+    :param worker_handler_manager: A ``callable`` that takes in an environment", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU1NTM4OA=="}, "originalCommit": {"oid": "30c17d5cdb4e6162174e92fbdba55a6332da25ba"}, "originalPosition": 43}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ3NzE0MzY5OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/portability/fn_api_runner/execution.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QyMTo1NTozOFrOF9C-tw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QyMjo0MjowNlrOF9D1KQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU1NjI3OQ==", "bodyText": "Prefer ()'s to backslashes for line breaks.", "url": "https://github.com/apache/beam/pull/11229#discussion_r399556279", "createdAt": "2020-03-27T21:55:38Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/runners/portability/fn_api_runner/execution.py", "diffHunk": "@@ -245,37 +254,106 @@ class FnApiRunnerExecutionContext(object):\n        ``beam.PCollection``.\n  \"\"\"\n   def __init__(self,\n-      worker_handler_factory,  # type: Callable[[Optional[str], int], List[WorkerHandler]]\n+      worker_handler_manager,  # type: worker_handlers.WorkerHandlerManager\n       pipeline_components,  # type: beam_runner_api_pb2.Components\n       safe_coders,\n       data_channel_coders,\n                ):\n     \"\"\"\n-    :param worker_handler_factory: A ``callable`` that takes in an environment\n+    :param worker_handler_manager: A ``callable`` that takes in an environment\n         id and a number of workers, and returns a list of ``WorkerHandler``s.\n     :param pipeline_components:  (beam_runner_api_pb2.Components): TODO\n     :param safe_coders:\n     :param data_channel_coders:\n     \"\"\"\n     self.pcoll_buffers = {}  # type: MutableMapping[bytes, PartitionableBuffer]\n-    self.worker_handler_factory = worker_handler_factory\n+    self.worker_handler_manager = worker_handler_manager\n     self.pipeline_components = pipeline_components\n     self.safe_coders = safe_coders\n     self.data_channel_coders = data_channel_coders\n \n+    self.pipeline_context = pipeline_context.PipelineContext(\n+        self.pipeline_components,\n+        iterable_state_write=self._iterable_state_write)\n+    self._last_uid = -1\n+\n+  def next_uid(self):\n+    self._last_uid += 1\n+    return str(self._last_uid)\n+\n+  def _iterable_state_write(self, values, element_coder_impl):\n+    # type: (...) -> bytes\n+    token = unique_name(None, 'iter').encode('ascii')\n+    out = create_OutputStream()\n+    for element in values:\n+      element_coder_impl.encode_to_stream(element, out, True)\n+    self.worker_handler_manager.state_servicer.append_raw(\n+        beam_fn_api_pb2.StateKey(\n+            runner=beam_fn_api_pb2.StateKey.Runner(key=token)),\n+        out.get())\n+    return token\n+\n \n class BundleContextManager(object):\n \n   def __init__(self,\n-      execution_context, # type: FnApiRunnerExecutionContext\n-      process_bundle_descriptor,  # type: beam_fn_api_pb2.ProcessBundleDescriptor\n-      worker_handler,  # type: fn_runner.WorkerHandler\n-      p_context,  # type: pipeline_context.PipelineContext\n-               ):\n+               execution_context, # type: FnApiRunnerExecutionContext\n+               stage,  # type: translations.Stage\n+               num_workers,  # type: int\n+              ):\n     self.execution_context = execution_context\n-    self.process_bundle_descriptor = process_bundle_descriptor\n-    self.worker_handler = worker_handler\n-    self.pipeline_context = p_context\n+    self.stage = stage\n+    self.bundle_uid = self.execution_context.next_uid()\n+    self.num_workers = num_workers\n+\n+    # Properties that are lazily initialized\n+    self._process_bundle_descriptor = None\n+    self._worker_handlers = None\n+\n+  @property\n+  def worker_handlers(self):\n+    if self._worker_handlers is None:\n+      self._worker_handlers = self.execution_context.worker_handler_manager\\", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "30c17d5cdb4e6162174e92fbdba55a6332da25ba"}, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3MDIxNw==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/11229#discussion_r399570217", "createdAt": "2020-03-27T22:42:06Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/runners/portability/fn_api_runner/execution.py", "diffHunk": "@@ -245,37 +254,106 @@ class FnApiRunnerExecutionContext(object):\n        ``beam.PCollection``.\n  \"\"\"\n   def __init__(self,\n-      worker_handler_factory,  # type: Callable[[Optional[str], int], List[WorkerHandler]]\n+      worker_handler_manager,  # type: worker_handlers.WorkerHandlerManager\n       pipeline_components,  # type: beam_runner_api_pb2.Components\n       safe_coders,\n       data_channel_coders,\n                ):\n     \"\"\"\n-    :param worker_handler_factory: A ``callable`` that takes in an environment\n+    :param worker_handler_manager: A ``callable`` that takes in an environment\n         id and a number of workers, and returns a list of ``WorkerHandler``s.\n     :param pipeline_components:  (beam_runner_api_pb2.Components): TODO\n     :param safe_coders:\n     :param data_channel_coders:\n     \"\"\"\n     self.pcoll_buffers = {}  # type: MutableMapping[bytes, PartitionableBuffer]\n-    self.worker_handler_factory = worker_handler_factory\n+    self.worker_handler_manager = worker_handler_manager\n     self.pipeline_components = pipeline_components\n     self.safe_coders = safe_coders\n     self.data_channel_coders = data_channel_coders\n \n+    self.pipeline_context = pipeline_context.PipelineContext(\n+        self.pipeline_components,\n+        iterable_state_write=self._iterable_state_write)\n+    self._last_uid = -1\n+\n+  def next_uid(self):\n+    self._last_uid += 1\n+    return str(self._last_uid)\n+\n+  def _iterable_state_write(self, values, element_coder_impl):\n+    # type: (...) -> bytes\n+    token = unique_name(None, 'iter').encode('ascii')\n+    out = create_OutputStream()\n+    for element in values:\n+      element_coder_impl.encode_to_stream(element, out, True)\n+    self.worker_handler_manager.state_servicer.append_raw(\n+        beam_fn_api_pb2.StateKey(\n+            runner=beam_fn_api_pb2.StateKey.Runner(key=token)),\n+        out.get())\n+    return token\n+\n \n class BundleContextManager(object):\n \n   def __init__(self,\n-      execution_context, # type: FnApiRunnerExecutionContext\n-      process_bundle_descriptor,  # type: beam_fn_api_pb2.ProcessBundleDescriptor\n-      worker_handler,  # type: fn_runner.WorkerHandler\n-      p_context,  # type: pipeline_context.PipelineContext\n-               ):\n+               execution_context, # type: FnApiRunnerExecutionContext\n+               stage,  # type: translations.Stage\n+               num_workers,  # type: int\n+              ):\n     self.execution_context = execution_context\n-    self.process_bundle_descriptor = process_bundle_descriptor\n-    self.worker_handler = worker_handler\n-    self.pipeline_context = p_context\n+    self.stage = stage\n+    self.bundle_uid = self.execution_context.next_uid()\n+    self.num_workers = num_workers\n+\n+    # Properties that are lazily initialized\n+    self._process_bundle_descriptor = None\n+    self._worker_handlers = None\n+\n+  @property\n+  def worker_handlers(self):\n+    if self._worker_handlers is None:\n+      self._worker_handlers = self.execution_context.worker_handler_manager\\", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU1NjI3OQ=="}, "originalCommit": {"oid": "30c17d5cdb4e6162174e92fbdba55a6332da25ba"}, "originalPosition": 105}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ3NzE0NzE4OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/portability/fn_api_runner/execution.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QyMTo1NzoxOVrOF9DA7g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QyMjo0MjoxMVrOF9D1PQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU1Njg0Ng==", "bodyText": "I don't know how critical this is for performance (mostly for tests), but self.worker_handlers[0] might be preferable.", "url": "https://github.com/apache/beam/pull/11229#discussion_r399556846", "createdAt": "2020-03-27T21:57:19Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/runners/portability/fn_api_runner/execution.py", "diffHunk": "@@ -245,37 +254,106 @@ class FnApiRunnerExecutionContext(object):\n        ``beam.PCollection``.\n  \"\"\"\n   def __init__(self,\n-      worker_handler_factory,  # type: Callable[[Optional[str], int], List[WorkerHandler]]\n+      worker_handler_manager,  # type: worker_handlers.WorkerHandlerManager\n       pipeline_components,  # type: beam_runner_api_pb2.Components\n       safe_coders,\n       data_channel_coders,\n                ):\n     \"\"\"\n-    :param worker_handler_factory: A ``callable`` that takes in an environment\n+    :param worker_handler_manager: A ``callable`` that takes in an environment\n         id and a number of workers, and returns a list of ``WorkerHandler``s.\n     :param pipeline_components:  (beam_runner_api_pb2.Components): TODO\n     :param safe_coders:\n     :param data_channel_coders:\n     \"\"\"\n     self.pcoll_buffers = {}  # type: MutableMapping[bytes, PartitionableBuffer]\n-    self.worker_handler_factory = worker_handler_factory\n+    self.worker_handler_manager = worker_handler_manager\n     self.pipeline_components = pipeline_components\n     self.safe_coders = safe_coders\n     self.data_channel_coders = data_channel_coders\n \n+    self.pipeline_context = pipeline_context.PipelineContext(\n+        self.pipeline_components,\n+        iterable_state_write=self._iterable_state_write)\n+    self._last_uid = -1\n+\n+  def next_uid(self):\n+    self._last_uid += 1\n+    return str(self._last_uid)\n+\n+  def _iterable_state_write(self, values, element_coder_impl):\n+    # type: (...) -> bytes\n+    token = unique_name(None, 'iter').encode('ascii')\n+    out = create_OutputStream()\n+    for element in values:\n+      element_coder_impl.encode_to_stream(element, out, True)\n+    self.worker_handler_manager.state_servicer.append_raw(\n+        beam_fn_api_pb2.StateKey(\n+            runner=beam_fn_api_pb2.StateKey.Runner(key=token)),\n+        out.get())\n+    return token\n+\n \n class BundleContextManager(object):\n \n   def __init__(self,\n-      execution_context, # type: FnApiRunnerExecutionContext\n-      process_bundle_descriptor,  # type: beam_fn_api_pb2.ProcessBundleDescriptor\n-      worker_handler,  # type: fn_runner.WorkerHandler\n-      p_context,  # type: pipeline_context.PipelineContext\n-               ):\n+               execution_context, # type: FnApiRunnerExecutionContext\n+               stage,  # type: translations.Stage\n+               num_workers,  # type: int\n+              ):\n     self.execution_context = execution_context\n-    self.process_bundle_descriptor = process_bundle_descriptor\n-    self.worker_handler = worker_handler\n-    self.pipeline_context = p_context\n+    self.stage = stage\n+    self.bundle_uid = self.execution_context.next_uid()\n+    self.num_workers = num_workers\n+\n+    # Properties that are lazily initialized\n+    self._process_bundle_descriptor = None\n+    self._worker_handlers = None\n+\n+  @property\n+  def worker_handlers(self):\n+    if self._worker_handlers is None:\n+      self._worker_handlers = self.execution_context.worker_handler_manager\\\n+        .get_worker_handlers(self.stage.environment, self.num_workers)\n+    return self._worker_handlers\n+\n+  def data_api_service_descriptor(self):\n+    # All worker_handlers share the same grpc server, so we can read grpc server\n+    # info from any worker_handler and read from the first worker_handler.\n+    return next(iter(self.worker_handlers)).data_api_service_descriptor()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "30c17d5cdb4e6162174e92fbdba55a6332da25ba"}, "originalPosition": 112}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3MDIzNw==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/11229#discussion_r399570237", "createdAt": "2020-03-27T22:42:11Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/runners/portability/fn_api_runner/execution.py", "diffHunk": "@@ -245,37 +254,106 @@ class FnApiRunnerExecutionContext(object):\n        ``beam.PCollection``.\n  \"\"\"\n   def __init__(self,\n-      worker_handler_factory,  # type: Callable[[Optional[str], int], List[WorkerHandler]]\n+      worker_handler_manager,  # type: worker_handlers.WorkerHandlerManager\n       pipeline_components,  # type: beam_runner_api_pb2.Components\n       safe_coders,\n       data_channel_coders,\n                ):\n     \"\"\"\n-    :param worker_handler_factory: A ``callable`` that takes in an environment\n+    :param worker_handler_manager: A ``callable`` that takes in an environment\n         id and a number of workers, and returns a list of ``WorkerHandler``s.\n     :param pipeline_components:  (beam_runner_api_pb2.Components): TODO\n     :param safe_coders:\n     :param data_channel_coders:\n     \"\"\"\n     self.pcoll_buffers = {}  # type: MutableMapping[bytes, PartitionableBuffer]\n-    self.worker_handler_factory = worker_handler_factory\n+    self.worker_handler_manager = worker_handler_manager\n     self.pipeline_components = pipeline_components\n     self.safe_coders = safe_coders\n     self.data_channel_coders = data_channel_coders\n \n+    self.pipeline_context = pipeline_context.PipelineContext(\n+        self.pipeline_components,\n+        iterable_state_write=self._iterable_state_write)\n+    self._last_uid = -1\n+\n+  def next_uid(self):\n+    self._last_uid += 1\n+    return str(self._last_uid)\n+\n+  def _iterable_state_write(self, values, element_coder_impl):\n+    # type: (...) -> bytes\n+    token = unique_name(None, 'iter').encode('ascii')\n+    out = create_OutputStream()\n+    for element in values:\n+      element_coder_impl.encode_to_stream(element, out, True)\n+    self.worker_handler_manager.state_servicer.append_raw(\n+        beam_fn_api_pb2.StateKey(\n+            runner=beam_fn_api_pb2.StateKey.Runner(key=token)),\n+        out.get())\n+    return token\n+\n \n class BundleContextManager(object):\n \n   def __init__(self,\n-      execution_context, # type: FnApiRunnerExecutionContext\n-      process_bundle_descriptor,  # type: beam_fn_api_pb2.ProcessBundleDescriptor\n-      worker_handler,  # type: fn_runner.WorkerHandler\n-      p_context,  # type: pipeline_context.PipelineContext\n-               ):\n+               execution_context, # type: FnApiRunnerExecutionContext\n+               stage,  # type: translations.Stage\n+               num_workers,  # type: int\n+              ):\n     self.execution_context = execution_context\n-    self.process_bundle_descriptor = process_bundle_descriptor\n-    self.worker_handler = worker_handler\n-    self.pipeline_context = p_context\n+    self.stage = stage\n+    self.bundle_uid = self.execution_context.next_uid()\n+    self.num_workers = num_workers\n+\n+    # Properties that are lazily initialized\n+    self._process_bundle_descriptor = None\n+    self._worker_handlers = None\n+\n+  @property\n+  def worker_handlers(self):\n+    if self._worker_handlers is None:\n+      self._worker_handlers = self.execution_context.worker_handler_manager\\\n+        .get_worker_handlers(self.stage.environment, self.num_workers)\n+    return self._worker_handlers\n+\n+  def data_api_service_descriptor(self):\n+    # All worker_handlers share the same grpc server, so we can read grpc server\n+    # info from any worker_handler and read from the first worker_handler.\n+    return next(iter(self.worker_handlers)).data_api_service_descriptor()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU1Njg0Ng=="}, "originalCommit": {"oid": "30c17d5cdb4e6162174e92fbdba55a6332da25ba"}, "originalPosition": 112}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ3NzE0OTk5OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/portability/fn_api_runner/execution.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QyMTo1ODozOVrOF9DCrQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QyMjo0MjoxNVrOF9D1Sw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU1NzI5Mw==", "bodyText": "You should be able to pass state_api_service_descriptor=self.state_api_service_descriptor() directly to the constructor (it handles None correctly).", "url": "https://github.com/apache/beam/pull/11229#discussion_r399557293", "createdAt": "2020-03-27T21:58:39Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/runners/portability/fn_api_runner/execution.py", "diffHunk": "@@ -245,37 +254,106 @@ class FnApiRunnerExecutionContext(object):\n        ``beam.PCollection``.\n  \"\"\"\n   def __init__(self,\n-      worker_handler_factory,  # type: Callable[[Optional[str], int], List[WorkerHandler]]\n+      worker_handler_manager,  # type: worker_handlers.WorkerHandlerManager\n       pipeline_components,  # type: beam_runner_api_pb2.Components\n       safe_coders,\n       data_channel_coders,\n                ):\n     \"\"\"\n-    :param worker_handler_factory: A ``callable`` that takes in an environment\n+    :param worker_handler_manager: A ``callable`` that takes in an environment\n         id and a number of workers, and returns a list of ``WorkerHandler``s.\n     :param pipeline_components:  (beam_runner_api_pb2.Components): TODO\n     :param safe_coders:\n     :param data_channel_coders:\n     \"\"\"\n     self.pcoll_buffers = {}  # type: MutableMapping[bytes, PartitionableBuffer]\n-    self.worker_handler_factory = worker_handler_factory\n+    self.worker_handler_manager = worker_handler_manager\n     self.pipeline_components = pipeline_components\n     self.safe_coders = safe_coders\n     self.data_channel_coders = data_channel_coders\n \n+    self.pipeline_context = pipeline_context.PipelineContext(\n+        self.pipeline_components,\n+        iterable_state_write=self._iterable_state_write)\n+    self._last_uid = -1\n+\n+  def next_uid(self):\n+    self._last_uid += 1\n+    return str(self._last_uid)\n+\n+  def _iterable_state_write(self, values, element_coder_impl):\n+    # type: (...) -> bytes\n+    token = unique_name(None, 'iter').encode('ascii')\n+    out = create_OutputStream()\n+    for element in values:\n+      element_coder_impl.encode_to_stream(element, out, True)\n+    self.worker_handler_manager.state_servicer.append_raw(\n+        beam_fn_api_pb2.StateKey(\n+            runner=beam_fn_api_pb2.StateKey.Runner(key=token)),\n+        out.get())\n+    return token\n+\n \n class BundleContextManager(object):\n \n   def __init__(self,\n-      execution_context, # type: FnApiRunnerExecutionContext\n-      process_bundle_descriptor,  # type: beam_fn_api_pb2.ProcessBundleDescriptor\n-      worker_handler,  # type: fn_runner.WorkerHandler\n-      p_context,  # type: pipeline_context.PipelineContext\n-               ):\n+               execution_context, # type: FnApiRunnerExecutionContext\n+               stage,  # type: translations.Stage\n+               num_workers,  # type: int\n+              ):\n     self.execution_context = execution_context\n-    self.process_bundle_descriptor = process_bundle_descriptor\n-    self.worker_handler = worker_handler\n-    self.pipeline_context = p_context\n+    self.stage = stage\n+    self.bundle_uid = self.execution_context.next_uid()\n+    self.num_workers = num_workers\n+\n+    # Properties that are lazily initialized\n+    self._process_bundle_descriptor = None\n+    self._worker_handlers = None\n+\n+  @property\n+  def worker_handlers(self):\n+    if self._worker_handlers is None:\n+      self._worker_handlers = self.execution_context.worker_handler_manager\\\n+        .get_worker_handlers(self.stage.environment, self.num_workers)\n+    return self._worker_handlers\n+\n+  def data_api_service_descriptor(self):\n+    # All worker_handlers share the same grpc server, so we can read grpc server\n+    # info from any worker_handler and read from the first worker_handler.\n+    return next(iter(self.worker_handlers)).data_api_service_descriptor()\n+\n+  def state_api_service_descriptor(self):\n+    # All worker_handlers share the same grpc server, so we can read grpc server\n+    # info from any worker_handler and read from the first worker_handler.\n+    return next(iter(self.worker_handlers)).state_api_service_descriptor()\n+\n+  @property\n+  def process_bundle_descriptor(self):\n+    if self._process_bundle_descriptor is None:\n+      self._process_bundle_descriptor = self._build_process_bundle_descriptor()\n+    return self._process_bundle_descriptor\n+\n+  def _build_process_bundle_descriptor(self):\n+    res = beam_fn_api_pb2.ProcessBundleDescriptor(\n+        id=self.bundle_uid,\n+        transforms={\n+            transform.unique_name: transform\n+            for transform in self.stage.transforms\n+        },\n+        pcollections=dict(\n+            self.execution_context.pipeline_components.pcollections.items()),\n+        coders=dict(\n+            self.execution_context.pipeline_components.coders.items()),\n+        windowing_strategies=dict(\n+            self.execution_context.pipeline_components.windowing_strategies.\n+              items()),\n+        environments=dict(\n+            self.execution_context.pipeline_components.environments.items()))\n+\n+    state_api_serv_desc = self.state_api_service_descriptor()\n+    if state_api_serv_desc:\n+      res.state_api_service_descriptor.url = state_api_serv_desc.url", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "30c17d5cdb4e6162174e92fbdba55a6332da25ba"}, "originalPosition": 144}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3MDI1MQ==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/11229#discussion_r399570251", "createdAt": "2020-03-27T22:42:15Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/runners/portability/fn_api_runner/execution.py", "diffHunk": "@@ -245,37 +254,106 @@ class FnApiRunnerExecutionContext(object):\n        ``beam.PCollection``.\n  \"\"\"\n   def __init__(self,\n-      worker_handler_factory,  # type: Callable[[Optional[str], int], List[WorkerHandler]]\n+      worker_handler_manager,  # type: worker_handlers.WorkerHandlerManager\n       pipeline_components,  # type: beam_runner_api_pb2.Components\n       safe_coders,\n       data_channel_coders,\n                ):\n     \"\"\"\n-    :param worker_handler_factory: A ``callable`` that takes in an environment\n+    :param worker_handler_manager: A ``callable`` that takes in an environment\n         id and a number of workers, and returns a list of ``WorkerHandler``s.\n     :param pipeline_components:  (beam_runner_api_pb2.Components): TODO\n     :param safe_coders:\n     :param data_channel_coders:\n     \"\"\"\n     self.pcoll_buffers = {}  # type: MutableMapping[bytes, PartitionableBuffer]\n-    self.worker_handler_factory = worker_handler_factory\n+    self.worker_handler_manager = worker_handler_manager\n     self.pipeline_components = pipeline_components\n     self.safe_coders = safe_coders\n     self.data_channel_coders = data_channel_coders\n \n+    self.pipeline_context = pipeline_context.PipelineContext(\n+        self.pipeline_components,\n+        iterable_state_write=self._iterable_state_write)\n+    self._last_uid = -1\n+\n+  def next_uid(self):\n+    self._last_uid += 1\n+    return str(self._last_uid)\n+\n+  def _iterable_state_write(self, values, element_coder_impl):\n+    # type: (...) -> bytes\n+    token = unique_name(None, 'iter').encode('ascii')\n+    out = create_OutputStream()\n+    for element in values:\n+      element_coder_impl.encode_to_stream(element, out, True)\n+    self.worker_handler_manager.state_servicer.append_raw(\n+        beam_fn_api_pb2.StateKey(\n+            runner=beam_fn_api_pb2.StateKey.Runner(key=token)),\n+        out.get())\n+    return token\n+\n \n class BundleContextManager(object):\n \n   def __init__(self,\n-      execution_context, # type: FnApiRunnerExecutionContext\n-      process_bundle_descriptor,  # type: beam_fn_api_pb2.ProcessBundleDescriptor\n-      worker_handler,  # type: fn_runner.WorkerHandler\n-      p_context,  # type: pipeline_context.PipelineContext\n-               ):\n+               execution_context, # type: FnApiRunnerExecutionContext\n+               stage,  # type: translations.Stage\n+               num_workers,  # type: int\n+              ):\n     self.execution_context = execution_context\n-    self.process_bundle_descriptor = process_bundle_descriptor\n-    self.worker_handler = worker_handler\n-    self.pipeline_context = p_context\n+    self.stage = stage\n+    self.bundle_uid = self.execution_context.next_uid()\n+    self.num_workers = num_workers\n+\n+    # Properties that are lazily initialized\n+    self._process_bundle_descriptor = None\n+    self._worker_handlers = None\n+\n+  @property\n+  def worker_handlers(self):\n+    if self._worker_handlers is None:\n+      self._worker_handlers = self.execution_context.worker_handler_manager\\\n+        .get_worker_handlers(self.stage.environment, self.num_workers)\n+    return self._worker_handlers\n+\n+  def data_api_service_descriptor(self):\n+    # All worker_handlers share the same grpc server, so we can read grpc server\n+    # info from any worker_handler and read from the first worker_handler.\n+    return next(iter(self.worker_handlers)).data_api_service_descriptor()\n+\n+  def state_api_service_descriptor(self):\n+    # All worker_handlers share the same grpc server, so we can read grpc server\n+    # info from any worker_handler and read from the first worker_handler.\n+    return next(iter(self.worker_handlers)).state_api_service_descriptor()\n+\n+  @property\n+  def process_bundle_descriptor(self):\n+    if self._process_bundle_descriptor is None:\n+      self._process_bundle_descriptor = self._build_process_bundle_descriptor()\n+    return self._process_bundle_descriptor\n+\n+  def _build_process_bundle_descriptor(self):\n+    res = beam_fn_api_pb2.ProcessBundleDescriptor(\n+        id=self.bundle_uid,\n+        transforms={\n+            transform.unique_name: transform\n+            for transform in self.stage.transforms\n+        },\n+        pcollections=dict(\n+            self.execution_context.pipeline_components.pcollections.items()),\n+        coders=dict(\n+            self.execution_context.pipeline_components.coders.items()),\n+        windowing_strategies=dict(\n+            self.execution_context.pipeline_components.windowing_strategies.\n+              items()),\n+        environments=dict(\n+            self.execution_context.pipeline_components.environments.items()))\n+\n+    state_api_serv_desc = self.state_api_service_descriptor()\n+    if state_api_serv_desc:\n+      res.state_api_service_descriptor.url = state_api_serv_desc.url", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU1NzI5Mw=="}, "originalCommit": {"oid": "30c17d5cdb4e6162174e92fbdba55a6332da25ba"}, "originalPosition": 144}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ3NzE1NDI2OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/portability/fn_api_runner/fn_runner.py", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QyMjowMDozMVrOF9DFVg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQwMDo0MDo0NFrOF-tAMA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU1Nzk3NA==", "bodyText": "Perhaps add a state_servicer() method right on runner_execution_context (and use several places below)?", "url": "https://github.com/apache/beam/pull/11229#discussion_r399557974", "createdAt": "2020-03-27T22:00:31Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/runners/portability/fn_api_runner/fn_runner.py", "diffHunk": "@@ -369,8 +366,8 @@ def _store_side_inputs_in_state(self,\n           state_key = beam_fn_api_pb2.StateKey(\n               iterable_side_input=beam_fn_api_pb2.StateKey.IterableSideInput(\n                   transform_id=transform_id, side_input_id=tag, window=window))\n-          bundle_context_manager.worker_handler.state.append_raw(\n-              state_key, elements_data)\n+          runner_execution_context.worker_handler_manager.state_servicer\\", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "30c17d5cdb4e6162174e92fbdba55a6332da25ba"}, "originalPosition": 80}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU1ODk1NA==", "bodyText": "On second thought, perhaps the ownership of state servicer should be moved up to runner_execution_context (though the worker manager may need a reference). Your call.", "url": "https://github.com/apache/beam/pull/11229#discussion_r399558954", "createdAt": "2020-03-27T22:03:37Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/runners/portability/fn_api_runner/fn_runner.py", "diffHunk": "@@ -369,8 +366,8 @@ def _store_side_inputs_in_state(self,\n           state_key = beam_fn_api_pb2.StateKey(\n               iterable_side_input=beam_fn_api_pb2.StateKey.IterableSideInput(\n                   transform_id=transform_id, side_input_id=tag, window=window))\n-          bundle_context_manager.worker_handler.state.append_raw(\n-              state_key, elements_data)\n+          runner_execution_context.worker_handler_manager.state_servicer\\", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU1Nzk3NA=="}, "originalCommit": {"oid": "30c17d5cdb4e6162174e92fbdba55a6332da25ba"}, "originalPosition": 80}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3MDYwMQ==", "bodyText": "I've just added the state_sevicer() from your first comment, but I've created a jira issue to track fixng that later on.", "url": "https://github.com/apache/beam/pull/11229#discussion_r399570601", "createdAt": "2020-03-27T22:43:31Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/runners/portability/fn_api_runner/fn_runner.py", "diffHunk": "@@ -369,8 +366,8 @@ def _store_side_inputs_in_state(self,\n           state_key = beam_fn_api_pb2.StateKey(\n               iterable_side_input=beam_fn_api_pb2.StateKey.IterableSideInput(\n                   transform_id=transform_id, side_input_id=tag, window=window))\n-          bundle_context_manager.worker_handler.state.append_raw(\n-              state_key, elements_data)\n+          runner_execution_context.worker_handler_manager.state_servicer\\", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU1Nzk3NA=="}, "originalCommit": {"oid": "30c17d5cdb4e6162174e92fbdba55a6332da25ba"}, "originalPosition": 80}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTI5MzM2MA==", "bodyText": "Link to JIRA for refernce?", "url": "https://github.com/apache/beam/pull/11229#discussion_r401293360", "createdAt": "2020-04-01T00:40:44Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/runners/portability/fn_api_runner/fn_runner.py", "diffHunk": "@@ -369,8 +366,8 @@ def _store_side_inputs_in_state(self,\n           state_key = beam_fn_api_pb2.StateKey(\n               iterable_side_input=beam_fn_api_pb2.StateKey.IterableSideInput(\n                   transform_id=transform_id, side_input_id=tag, window=window))\n-          bundle_context_manager.worker_handler.state.append_raw(\n-              state_key, elements_data)\n+          runner_execution_context.worker_handler_manager.state_servicer\\", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU1Nzk3NA=="}, "originalCommit": {"oid": "30c17d5cdb4e6162174e92fbdba55a6332da25ba"}, "originalPosition": 80}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ3NzE1NTY4OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/portability/fn_api_runner/fn_runner.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QyMjowMToxN1rOF9DGSg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0yN1QyMjo0Mzo0MlrOF9D23w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU1ODIxOA==", "bodyText": "backslash", "url": "https://github.com/apache/beam/pull/11229#discussion_r399558218", "createdAt": "2020-03-27T22:01:17Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/runners/portability/fn_api_runner/fn_runner.py", "diffHunk": "@@ -415,24 +412,24 @@ def _run_bundle_multiple_times_for_testing(\n             cache_token_generator=cache_token_generator)\n         testing_bundle_manager.process_bundle(data_input, data_output)\n       finally:\n-        worker_handler.state.restore()\n+        runner_execution_context.worker_handler_manager.state_servicer.restore()\n \n   def _collect_written_timers_and_add_to_deferred_inputs(\n       self,\n-      pipeline_components,  # type: beam_runner_api_pb2.Components\n-      stage,  # type: translations.Stage\n+      runner_execution_context,  # type: execution.FnApiRunnerExecutionContext\n       bundle_context_manager,  # type: execution.BundleContextManager\n       deferred_inputs,  # type: MutableMapping[str, PartitionableBuffer]\n-      data_channel_coders,  # type: Mapping[str, str]\n   ):\n     # type: (...) -> None\n \n-    for transform_id, timer_writes in stage.timer_pcollections:\n+    for transform_id, timer_writes in \\", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "30c17d5cdb4e6162174e92fbdba55a6332da25ba"}, "originalPosition": 138}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU3MDY1NQ==", "bodyText": "Done", "url": "https://github.com/apache/beam/pull/11229#discussion_r399570655", "createdAt": "2020-03-27T22:43:42Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/runners/portability/fn_api_runner/fn_runner.py", "diffHunk": "@@ -415,24 +412,24 @@ def _run_bundle_multiple_times_for_testing(\n             cache_token_generator=cache_token_generator)\n         testing_bundle_manager.process_bundle(data_input, data_output)\n       finally:\n-        worker_handler.state.restore()\n+        runner_execution_context.worker_handler_manager.state_servicer.restore()\n \n   def _collect_written_timers_and_add_to_deferred_inputs(\n       self,\n-      pipeline_components,  # type: beam_runner_api_pb2.Components\n-      stage,  # type: translations.Stage\n+      runner_execution_context,  # type: execution.FnApiRunnerExecutionContext\n       bundle_context_manager,  # type: execution.BundleContextManager\n       deferred_inputs,  # type: MutableMapping[str, PartitionableBuffer]\n-      data_channel_coders,  # type: Mapping[str, str]\n   ):\n     # type: (...) -> None\n \n-    for transform_id, timer_writes in stage.timer_pcollections:\n+    for transform_id, timer_writes in \\", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5OTU1ODIxOA=="}, "originalCommit": {"oid": "30c17d5cdb4e6162174e92fbdba55a6332da25ba"}, "originalPosition": 138}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5MjAyNTAxOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/portability/fn_api_runner/fn_runner.py", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxODozOTozOFrOF_Nr_Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxOTo0MTowOFrOF_Pz-w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTgyODg2MQ==", "bodyText": "It's odd that _run_stage no longer takes as a parameter the stage to run. Perhaps bundle_context_manager (and its class?) should be named stage_context or similar?", "url": "https://github.com/apache/beam/pull/11229#discussion_r401828861", "createdAt": "2020-04-01T18:39:38Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/runners/portability/fn_api_runner/fn_runner.py", "diffHunk": "@@ -511,87 +509,32 @@ def _add_residuals_and_channel_splits_to_deferred_inputs(\n \n   def _run_stage(self,\n                  runner_execution_context,  # type: execution.FnApiRunnerExecutionContext\n-                 stage,  # type: translations.Stage\n+                 bundle_context_manager,  # type: execution.BundleContextManager", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4be760ee74be196d2edf3b6f05cefdce820c5e26"}, "originalPosition": 157}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTgzMTU1MA==", "bodyText": "On this note, perhaps it makes sense to break FnApiRunner into the (mostly stateless) runner that can execute multiple pipelines and an executor (that has methods like run_stage) that might be stateful and is initialized with and tasked with running a single pipeline. Much of what is on context(s) would become state of self of this new object.", "url": "https://github.com/apache/beam/pull/11229#discussion_r401831550", "createdAt": "2020-04-01T18:44:00Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/runners/portability/fn_api_runner/fn_runner.py", "diffHunk": "@@ -511,87 +509,32 @@ def _add_residuals_and_channel_splits_to_deferred_inputs(\n \n   def _run_stage(self,\n                  runner_execution_context,  # type: execution.FnApiRunnerExecutionContext\n-                 stage,  # type: translations.Stage\n+                 bundle_context_manager,  # type: execution.BundleContextManager", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTgyODg2MQ=="}, "originalCommit": {"oid": "4be760ee74be196d2edf3b6f05cefdce820c5e26"}, "originalPosition": 157}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTg2MzY3NQ==", "bodyText": "I'm adding all these comments to #11270", "url": "https://github.com/apache/beam/pull/11229#discussion_r401863675", "createdAt": "2020-04-01T19:41:08Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/runners/portability/fn_api_runner/fn_runner.py", "diffHunk": "@@ -511,87 +509,32 @@ def _add_residuals_and_channel_splits_to_deferred_inputs(\n \n   def _run_stage(self,\n                  runner_execution_context,  # type: execution.FnApiRunnerExecutionContext\n-                 stage,  # type: translations.Stage\n+                 bundle_context_manager,  # type: execution.BundleContextManager", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTgyODg2MQ=="}, "originalCommit": {"oid": "4be760ee74be196d2edf3b6f05cefdce820c5e26"}, "originalPosition": 157}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQ5MjAzMzgwOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/portability/fn_api_runner/execution.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxODo0MTo1M1rOF_NxTA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wMVQxOTo0MTowNVrOF_Pz4A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTgzMDIyMA==", "bodyText": "I was bitten by the fact that it is an error to access the process_bundle_descriptor before _extract_outputs is called. This should be clearly documented (and similarly for the other lazy attributes(s) in this class). Given that that's called external to this class and can't easily be checked, makes me wonder if the boundary of encapsulation needs to be adjusted here.", "url": "https://github.com/apache/beam/pull/11229#discussion_r401830220", "createdAt": "2020-04-01T18:41:53Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/runners/portability/fn_api_runner/execution.py", "diffHunk": "@@ -245,37 +254,108 @@ class FnApiRunnerExecutionContext(object):\n        ``beam.PCollection``.\n  \"\"\"\n   def __init__(self,\n-      worker_handler_factory,  # type: Callable[[Optional[str], int], List[WorkerHandler]]\n+      worker_handler_manager,  # type: worker_handlers.WorkerHandlerManager\n       pipeline_components,  # type: beam_runner_api_pb2.Components\n       safe_coders,\n       data_channel_coders,\n                ):\n     \"\"\"\n-    :param worker_handler_factory: A ``callable`` that takes in an environment\n-        id and a number of workers, and returns a list of ``WorkerHandler``s.\n+    :param worker_handler_manager: This class manages the set of worker\n+        handlers, and the communication with state / control APIs.\n     :param pipeline_components:  (beam_runner_api_pb2.Components): TODO\n     :param safe_coders:\n     :param data_channel_coders:\n     \"\"\"\n     self.pcoll_buffers = {}  # type: MutableMapping[bytes, PartitionableBuffer]\n-    self.worker_handler_factory = worker_handler_factory\n+    self.worker_handler_manager = worker_handler_manager\n     self.pipeline_components = pipeline_components\n     self.safe_coders = safe_coders\n     self.data_channel_coders = data_channel_coders\n \n+    self.pipeline_context = pipeline_context.PipelineContext(\n+        self.pipeline_components,\n+        iterable_state_write=self._iterable_state_write)\n+    self._last_uid = -1\n+\n+  @property\n+  def state_servicer(self):\n+    # TODO(BEAM-9625): Ensure FnApiRunnerExecutionContext owns StateServicer\n+    return self.worker_handler_manager.state_servicer\n+\n+  def next_uid(self):\n+    self._last_uid += 1\n+    return str(self._last_uid)\n+\n+  def _iterable_state_write(self, values, element_coder_impl):\n+    # type: (...) -> bytes\n+    token = unique_name(None, 'iter').encode('ascii')\n+    out = create_OutputStream()\n+    for element in values:\n+      element_coder_impl.encode_to_stream(element, out, True)\n+    self.worker_handler_manager.state_servicer.append_raw(\n+        beam_fn_api_pb2.StateKey(\n+            runner=beam_fn_api_pb2.StateKey.Runner(key=token)),\n+        out.get())\n+    return token\n+\n \n class BundleContextManager(object):\n \n   def __init__(self,\n-      execution_context, # type: FnApiRunnerExecutionContext\n-      process_bundle_descriptor,  # type: beam_fn_api_pb2.ProcessBundleDescriptor\n-      worker_handler,  # type: fn_runner.WorkerHandler\n-      p_context,  # type: pipeline_context.PipelineContext\n-               ):\n+               execution_context, # type: FnApiRunnerExecutionContext\n+               stage,  # type: translations.Stage\n+               num_workers,  # type: int\n+              ):\n     self.execution_context = execution_context\n-    self.process_bundle_descriptor = process_bundle_descriptor\n-    self.worker_handler = worker_handler\n-    self.pipeline_context = p_context\n+    self.stage = stage\n+    self.bundle_uid = self.execution_context.next_uid()\n+    self.num_workers = num_workers\n+\n+    # Properties that are lazily initialized\n+    self._process_bundle_descriptor = None\n+    self._worker_handlers = None\n+\n+  @property\n+  def worker_handlers(self):\n+    if self._worker_handlers is None:\n+      self._worker_handlers = (\n+          self.execution_context.worker_handler_manager.get_worker_handlers(\n+              self.stage.environment, self.num_workers))\n+    return self._worker_handlers\n+\n+  def data_api_service_descriptor(self):\n+    # All worker_handlers share the same grpc server, so we can read grpc server\n+    # info from any worker_handler and read from the first worker_handler.\n+    return self.worker_handlers[0].data_api_service_descriptor()\n+\n+  def state_api_service_descriptor(self):\n+    # All worker_handlers share the same grpc server, so we can read grpc server\n+    # info from any worker_handler and read from the first worker_handler.\n+    return self.worker_handlers[0].state_api_service_descriptor()\n+\n+  @property\n+  def process_bundle_descriptor(self):\n+    if self._process_bundle_descriptor is None:\n+      self._process_bundle_descriptor = self._build_process_bundle_descriptor()\n+    return self._process_bundle_descriptor\n+\n+  def _build_process_bundle_descriptor(self):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4be760ee74be196d2edf3b6f05cefdce820c5e26"}, "originalPosition": 132}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTg2MzY0OA==", "bodyText": "I was also bitten by this. I am trying to think of a better way to mark a Read transform as an Impulse Read, but can't think of one at the moment.\nI'll add documentation for this.\nOnce it's full streaming, the IMPULSE buffers will be enqued before the pipeline starts, and extract_outputs will work with non-impulse buffers only - thus we can modify the transform payload before starting the pipeline, and not compute the bundle descriptor lazily.", "url": "https://github.com/apache/beam/pull/11229#discussion_r401863648", "createdAt": "2020-04-01T19:41:05Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/runners/portability/fn_api_runner/execution.py", "diffHunk": "@@ -245,37 +254,108 @@ class FnApiRunnerExecutionContext(object):\n        ``beam.PCollection``.\n  \"\"\"\n   def __init__(self,\n-      worker_handler_factory,  # type: Callable[[Optional[str], int], List[WorkerHandler]]\n+      worker_handler_manager,  # type: worker_handlers.WorkerHandlerManager\n       pipeline_components,  # type: beam_runner_api_pb2.Components\n       safe_coders,\n       data_channel_coders,\n                ):\n     \"\"\"\n-    :param worker_handler_factory: A ``callable`` that takes in an environment\n-        id and a number of workers, and returns a list of ``WorkerHandler``s.\n+    :param worker_handler_manager: This class manages the set of worker\n+        handlers, and the communication with state / control APIs.\n     :param pipeline_components:  (beam_runner_api_pb2.Components): TODO\n     :param safe_coders:\n     :param data_channel_coders:\n     \"\"\"\n     self.pcoll_buffers = {}  # type: MutableMapping[bytes, PartitionableBuffer]\n-    self.worker_handler_factory = worker_handler_factory\n+    self.worker_handler_manager = worker_handler_manager\n     self.pipeline_components = pipeline_components\n     self.safe_coders = safe_coders\n     self.data_channel_coders = data_channel_coders\n \n+    self.pipeline_context = pipeline_context.PipelineContext(\n+        self.pipeline_components,\n+        iterable_state_write=self._iterable_state_write)\n+    self._last_uid = -1\n+\n+  @property\n+  def state_servicer(self):\n+    # TODO(BEAM-9625): Ensure FnApiRunnerExecutionContext owns StateServicer\n+    return self.worker_handler_manager.state_servicer\n+\n+  def next_uid(self):\n+    self._last_uid += 1\n+    return str(self._last_uid)\n+\n+  def _iterable_state_write(self, values, element_coder_impl):\n+    # type: (...) -> bytes\n+    token = unique_name(None, 'iter').encode('ascii')\n+    out = create_OutputStream()\n+    for element in values:\n+      element_coder_impl.encode_to_stream(element, out, True)\n+    self.worker_handler_manager.state_servicer.append_raw(\n+        beam_fn_api_pb2.StateKey(\n+            runner=beam_fn_api_pb2.StateKey.Runner(key=token)),\n+        out.get())\n+    return token\n+\n \n class BundleContextManager(object):\n \n   def __init__(self,\n-      execution_context, # type: FnApiRunnerExecutionContext\n-      process_bundle_descriptor,  # type: beam_fn_api_pb2.ProcessBundleDescriptor\n-      worker_handler,  # type: fn_runner.WorkerHandler\n-      p_context,  # type: pipeline_context.PipelineContext\n-               ):\n+               execution_context, # type: FnApiRunnerExecutionContext\n+               stage,  # type: translations.Stage\n+               num_workers,  # type: int\n+              ):\n     self.execution_context = execution_context\n-    self.process_bundle_descriptor = process_bundle_descriptor\n-    self.worker_handler = worker_handler\n-    self.pipeline_context = p_context\n+    self.stage = stage\n+    self.bundle_uid = self.execution_context.next_uid()\n+    self.num_workers = num_workers\n+\n+    # Properties that are lazily initialized\n+    self._process_bundle_descriptor = None\n+    self._worker_handlers = None\n+\n+  @property\n+  def worker_handlers(self):\n+    if self._worker_handlers is None:\n+      self._worker_handlers = (\n+          self.execution_context.worker_handler_manager.get_worker_handlers(\n+              self.stage.environment, self.num_workers))\n+    return self._worker_handlers\n+\n+  def data_api_service_descriptor(self):\n+    # All worker_handlers share the same grpc server, so we can read grpc server\n+    # info from any worker_handler and read from the first worker_handler.\n+    return self.worker_handlers[0].data_api_service_descriptor()\n+\n+  def state_api_service_descriptor(self):\n+    # All worker_handlers share the same grpc server, so we can read grpc server\n+    # info from any worker_handler and read from the first worker_handler.\n+    return self.worker_handlers[0].state_api_service_descriptor()\n+\n+  @property\n+  def process_bundle_descriptor(self):\n+    if self._process_bundle_descriptor is None:\n+      self._process_bundle_descriptor = self._build_process_bundle_descriptor()\n+    return self._process_bundle_descriptor\n+\n+  def _build_process_bundle_descriptor(self):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwMTgzMDIyMA=="}, "originalCommit": {"oid": "4be760ee74be196d2edf3b6f05cefdce820c5e26"}, "originalPosition": 132}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1535, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}