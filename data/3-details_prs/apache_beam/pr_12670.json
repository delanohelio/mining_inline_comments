{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDcyMTI5Mzg3", "number": 12670, "title": "[BEAM-5757] Add ElasticsearchIO: delete document support", "bodyText": "What\nThis change introduces a new builder function (withIsDeleteFn) with ElasticsearchIO.Write which can be used to effectively delete documents from the Elasticsearch index. Previously, ElasticsearchIO only supports upsert operations within an index but it is impossible to delete documents.\nWhy\nBy using the withIsDeleteFn function, the apache beam user can dynamically decide the bulk operation to be carried out for the document. Mostly, in streaming update environment, it might happen that some of the previously indexed document needs to be deleted based on some conditions but the current version of ElasticsearchIO doesn't support delete operation and hence many users end up writing empty document for those IDs. This might have a major memory space issue while Elasticsearch's segment merging to free up deleted document's allocated memory.\nJIRA Ticket\nhttps://issues.apache.org/jira/browse/BEAM-5757\nR: @echauchot @jbonofre @timrobertson100\n\nThank you for your contribution! Follow this checklist to help us incorporate your contribution quickly and easily:\n\n Choose reviewer(s) and mention them in a comment (R: @username).\n Format the pull request title like [BEAM-XXX] Fixes bug in ApproximateQuantiles, where you replace BEAM-XXX with the appropriate JIRA issue, if applicable. This will automatically link the pull request to the issue.\n Update CHANGES.md with noteworthy changes.\n If this contribution is large, please file an Apache Individual Contributor License Agreement.\n\nSee the Contributor Guide for more tips on how to make review process smoother.\nPost-Commit Tests Status (on master branch)\n\n\n\nLang\nSDK\nDataflow\nFlink\nSamza\nSpark\nTwister2\n\n\n\n\nGo\n\n---\n\n---\n\n---\n\n\nJava\n\n\n\n\n\n\n\n\nPython\n\n\n\n---\n\n---\n\n\nXLang\n\n---\n\n---\n\n---\n\n\n\nPre-Commit Tests Status (on master branch)\n\n\n\n---\nJava\nPython\nGo\nWebsite\nWhitespace\n\n\n\n\nNon-portable\n\n \n\n\n\n\n\nPortable\n---\n\n---\n---\n---\n\n\n\nSee .test-infra/jenkins/README for trigger phrase, status and link of all Jenkins jobs.\nGitHub Actions Tests Status (on master branch)\n\n\nSee CI.md for more information about GitHub Actions CI.", "createdAt": "2020-08-23T14:10:32Z", "url": "https://github.com/apache/beam/pull/12670", "merged": true, "mergeCommit": {"oid": "89a2d17624a5f2f445b7199fe7a61ec0eca8205a"}, "closed": true, "closedAt": "2020-09-03T22:52:03Z", "author": {"login": "jithin-sukumar"}, "timelineItems": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdBulthgH2gAyNDcyMTI5Mzg3OjJmMTMyOTQwNDQxM2I5NTllOWY2MmYwMDNmYzNmZTJjZjQ2OWRmNTA=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdFYrTygFqTQ4MjI1MzE2Ng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "2f1329404413b959e9f62f003fc3fe2cf469df50", "author": {"user": {"login": "jithin-sukumar", "name": "Jithin Sukumar"}}, "url": "https://github.com/apache/beam/commit/2f1329404413b959e9f62f003fc3fe2cf469df50", "committedDate": "2020-08-23T14:07:59Z", "message": "[BEAM-5757] Add ElasticsearchIO: delete document support"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDgxMzk4MDU5", "url": "https://github.com/apache/beam/pull/12670#pullrequestreview-481398059", "createdAt": "2020-09-03T00:21:27Z", "commit": {"oid": "2f1329404413b959e9f62f003fc3fe2cf469df50"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QwMDoyMToyN1rOHMQaLQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wM1QwMDo0NDo1MFrOHMRAKA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjYxMzgwNQ==", "bodyText": "Not really your problem but this is my first time looking at these tests, and this structure tests seems really odd to me. It looks like we could get rid of a lof of duplicate code if we just implemented both ElasticsearchIOIT and ElasticsearchIOTest  in elasticsearch common, then the implementations for each version could inherit from those with an (almost) empty implementation.\nAgain, not asking to do anything here, but I might try to tackle this myself, let me know if you think that's not possible.", "url": "https://github.com/apache/beam/pull/12670#discussion_r482613805", "createdAt": "2020-09-03T00:21:27Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/io/elasticsearch-tests/elasticsearch-tests-2/src/test/java/org/apache/beam/sdk/io/elasticsearch/ElasticsearchIOIT.java", "diffHunk": "@@ -140,4 +140,38 @@ public void testWritePartialUpdate() throws Exception {\n     elasticsearchIOTestCommonUpdate.setPipeline(pipeline);\n     elasticsearchIOTestCommonUpdate.testWritePartialUpdate();\n   }\n+\n+  /**\n+   * This test verifies volume deletes of Elasticsearch. The test dataset index is cloned and then\n+   * around half of the documents are deleted and the other half is partially updated using bulk\n+   * delete request. The test then asserts the documents were deleted successfully.\n+   */\n+  @Test\n+  public void testWriteWithIsDeletedFnWithPartialUpdates() throws Exception {\n+    ElasticsearchIOTestUtils.copyIndex(\n+        restClient,\n+        readConnectionConfiguration.getIndex(),\n+        updateConnectionConfiguration.getIndex());\n+    ElasticsearchIOTestCommon elasticsearchIOTestCommonDeleteFn =\n+        new ElasticsearchIOTestCommon(updateConnectionConfiguration, restClient, true);\n+    elasticsearchIOTestCommonDeleteFn.setPipeline(pipeline);\n+    elasticsearchIOTestCommonDeleteFn.testWriteWithIsDeletedFnWithPartialUpdates();\n+  }\n+\n+  /**\n+   * This test verifies volume deletes of Elasticsearch. The test dataset index is cloned and then\n+   * around half of the documents are deleted using bulk delete request. The test then asserts the\n+   * documents were deleted successfully.\n+   */\n+  @Test\n+  public void testWriteWithIsDeletedFnWithoutPartialUpdate() throws Exception {\n+    ElasticsearchIOTestUtils.copyIndex(\n+        restClient,\n+        readConnectionConfiguration.getIndex(),\n+        updateConnectionConfiguration.getIndex());\n+    ElasticsearchIOTestCommon elasticsearchIOTestCommonDeleteFn =\n+        new ElasticsearchIOTestCommon(updateConnectionConfiguration, restClient, true);\n+    elasticsearchIOTestCommonDeleteFn.setPipeline(pipeline);\n+    elasticsearchIOTestCommonDeleteFn.testWriteWithIsDeletedFnWithoutPartialUpdate();\n+  }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2f1329404413b959e9f62f003fc3fe2cf469df50"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjYyMjMyOQ==", "bodyText": "Could we instead just verify that IdFn is specified whenever DeleteFn is specified? Then we could move this check out to Write#expand and raise an exception when constructing the pipeline, rather than when it's executing. WDYT?", "url": "https://github.com/apache/beam/pull/12670#discussion_r482622329", "createdAt": "2020-09-03T00:39:57Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/io/elasticsearch/src/main/java/org/apache/beam/sdk/io/elasticsearch/ElasticsearchIO.java", "diffHunk": "@@ -1346,17 +1359,36 @@ private static String lowerCaseOrNull(String input) {\n \n       @ProcessElement\n       public void processElement(ProcessContext context) throws Exception {\n-        String document = context.element();\n-        String documentMetadata = getDocumentMetadata(document);\n-\n-        // index is an insert/upsert and update is a partial update (or insert if not existing)\n-        if (spec.getUsePartialUpdate()) {\n-          batch.add(\n-              String.format(\n-                  \"{ \\\"update\\\" : %s }%n{ \\\"doc\\\" : %s, \\\"doc_as_upsert\\\" : true }%n\",\n-                  documentMetadata, document));\n+        String document = context.element(); // use configuration and auto-generated document IDs\n+        String documentMetadata = \"{}\";\n+        boolean isDelete = false;\n+        if (spec.getIndexFn() != null || spec.getTypeFn() != null || spec.getIdFn() != null) {\n+          // parse once and reused for efficiency\n+          JsonNode parsedDocument = OBJECT_MAPPER.readTree(document);\n+          documentMetadata = getDocumentMetadata(parsedDocument);\n+          if (spec.getIsDeleteFn() != null) {\n+            isDelete = spec.getIsDeleteFn().apply(parsedDocument);\n+            // if it is a delete opration, then it is mandatory to specify the document id using\n+            // getIdFn\n+            checkArgument(\n+                !(isDelete && spec.getIdFn() == null),\n+                \"Id needs to be specified by withIdFn for delete operation\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2f1329404413b959e9f62f003fc3fe2cf469df50"}, "originalPosition": 120}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MjYyMzUyOA==", "bodyText": "nit: I'd probably write this the other way so we don't have to reason about the double-negative:\nif (isDelete) {\n  // do a delete\n} else {\n  // do an insert/upsert\n}\nBut that's a big nit, feel free to leave it this way if you prefer.", "url": "https://github.com/apache/beam/pull/12670#discussion_r482623528", "createdAt": "2020-09-03T00:44:50Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/io/elasticsearch/src/main/java/org/apache/beam/sdk/io/elasticsearch/ElasticsearchIO.java", "diffHunk": "@@ -1346,17 +1359,36 @@ private static String lowerCaseOrNull(String input) {\n \n       @ProcessElement\n       public void processElement(ProcessContext context) throws Exception {\n-        String document = context.element();\n-        String documentMetadata = getDocumentMetadata(document);\n-\n-        // index is an insert/upsert and update is a partial update (or insert if not existing)\n-        if (spec.getUsePartialUpdate()) {\n-          batch.add(\n-              String.format(\n-                  \"{ \\\"update\\\" : %s }%n{ \\\"doc\\\" : %s, \\\"doc_as_upsert\\\" : true }%n\",\n-                  documentMetadata, document));\n+        String document = context.element(); // use configuration and auto-generated document IDs\n+        String documentMetadata = \"{}\";\n+        boolean isDelete = false;\n+        if (spec.getIndexFn() != null || spec.getTypeFn() != null || spec.getIdFn() != null) {\n+          // parse once and reused for efficiency\n+          JsonNode parsedDocument = OBJECT_MAPPER.readTree(document);\n+          documentMetadata = getDocumentMetadata(parsedDocument);\n+          if (spec.getIsDeleteFn() != null) {\n+            isDelete = spec.getIsDeleteFn().apply(parsedDocument);\n+            // if it is a delete opration, then it is mandatory to specify the document id using\n+            // getIdFn\n+            checkArgument(\n+                !(isDelete && spec.getIdFn() == null),\n+                \"Id needs to be specified by withIdFn for delete operation\");\n+          }\n+        }\n+\n+        if (!isDelete) {\n+          // index is an insert/upsert and update is a partial update (or insert if not existing)\n+          if (spec.getUsePartialUpdate()) {\n+            batch.add(\n+                String.format(\n+                    \"{ \\\"update\\\" : %s }%n{ \\\"doc\\\" : %s, \\\"doc_as_upsert\\\" : true }%n\",\n+                    documentMetadata, document));\n+          } else {\n+            batch.add(String.format(\"{ \\\"index\\\" : %s }%n%s%n\", documentMetadata, document));\n+          }\n         } else {\n-          batch.add(String.format(\"{ \\\"index\\\" : %s }%n%s%n\", documentMetadata, document));\n+          // delete request used for deleting a document.\n+          batch.add(String.format(\"{ \\\"delete\\\" : %s }%n\", documentMetadata));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2f1329404413b959e9f62f003fc3fe2cf469df50"}, "originalPosition": 137}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c7217f4682efaa7bfe483c963d8e8b204d39abb8", "author": {"user": {"login": "jithin-sukumar", "name": "Jithin Sukumar"}}, "url": "https://github.com/apache/beam/commit/c7217f4682efaa7bfe483c963d8e8b204d39abb8", "committedDate": "2020-09-03T09:51:58Z", "message": "[BEAM-5757] ElasticsearchIO: fix idFn and deleteFn check"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDgyMjUzMTY2", "url": "https://github.com/apache/beam/pull/12670#pullrequestreview-482253166", "createdAt": "2020-09-03T22:51:53Z", "commit": {"oid": "c7217f4682efaa7bfe483c963d8e8b204d39abb8"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4884, "cost": 1, "resetAt": "2021-10-28T16:48:13Z"}}}