{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTAzMDkxOTU2", "number": 13105, "reviewThreads": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yN1QwOToxMzowOVrOEyP_WQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOVQxMTowMDozMVrOE2tgig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxMTI2MjMzOnYy", "diffSide": "RIGHT", "path": "runners/flink/job-server/flink_job_server.gradle", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yN1QwOToxMzowOVrOHoyBgw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yN1QyMjoyNTo0NlrOHpTR_w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjUyNDY3NQ==", "bodyText": "Maybe add a comment why this one is excluded?", "url": "https://github.com/apache/beam/pull/13105#discussion_r512524675", "createdAt": "2020-10-27T09:13:09Z", "author": {"login": "mxm"}, "path": "runners/flink/job-server/flink_job_server.gradle", "diffHunk": "@@ -166,23 +166,22 @@ def portableValidatesRunnerTask(String name, Boolean streaming, Boolean checkpoi\n         excludeCategories 'org.apache.beam.sdk.testing.UsesBundleFinalizer'\n         excludeCategories 'org.apache.beam.sdk.testing.UsesOrderedListState'\n         if (streaming) {\n+          excludeCategories 'org.apache.beam.sdk.testing.UsesBoundedSplittableParDo'\n           excludeCategories 'org.apache.beam.sdk.testing.UsesTestStreamWithProcessingTime'\n           excludeCategories 'org.apache.beam.sdk.testing.UsesTestStreamWithMultipleStages'\n           excludeCategories 'org.apache.beam.sdk.testing.UsesTestStreamWithOutputTimestamp'\n         } else {\n+          excludeCategories 'org.apache.beam.sdk.testing.UsesUnboundedSplittableParDo'\n+          excludeCategories 'org.apache.beam.sdk.testing.UsesSplittableParDoWithWindowedSideInputs'\n           excludeCategories 'org.apache.beam.sdk.testing.UsesUnboundedPCollections'\n           excludeCategories 'org.apache.beam.sdk.testing.UsesTestStream'\n         }\n-        //SplitableDoFnTests\n-        excludeCategories 'org.apache.beam.sdk.testing.UsesBoundedSplittableParDo'\n-        excludeCategories 'org.apache.beam.sdk.testing.UsesSplittableParDoWithWindowedSideInputs'\n-        excludeCategories 'org.apache.beam.sdk.testing.UsesUnboundedSplittableParDo'\n-\n       }\n     },\n     testFilter: {\n       // TODO(BEAM-10016)\n       excludeTestsMatching 'org.apache.beam.sdk.transforms.FlattenTest.testFlattenWithDifferentInputAndOutputCoders2'\n+      excludeTestsMatching 'org.apache.beam.sdk.transforms.SplittableDoFnTest.testPairWithIndexWindowedTimestampedBounded'", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "82c2fc2df459e578a833a5e2fb4d944229876c77"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjkwMTAxNQ==", "bodyText": "I haven't explore the failure yet but the test fails on the same reason(wrong results) for batch and streaming. I filed a jira for tracking this: https://issues.apache.org/jira/browse/BEAM-11141", "url": "https://github.com/apache/beam/pull/13105#discussion_r512901015", "createdAt": "2020-10-27T17:45:27Z", "author": {"login": "boyuanzz"}, "path": "runners/flink/job-server/flink_job_server.gradle", "diffHunk": "@@ -166,23 +166,22 @@ def portableValidatesRunnerTask(String name, Boolean streaming, Boolean checkpoi\n         excludeCategories 'org.apache.beam.sdk.testing.UsesBundleFinalizer'\n         excludeCategories 'org.apache.beam.sdk.testing.UsesOrderedListState'\n         if (streaming) {\n+          excludeCategories 'org.apache.beam.sdk.testing.UsesBoundedSplittableParDo'\n           excludeCategories 'org.apache.beam.sdk.testing.UsesTestStreamWithProcessingTime'\n           excludeCategories 'org.apache.beam.sdk.testing.UsesTestStreamWithMultipleStages'\n           excludeCategories 'org.apache.beam.sdk.testing.UsesTestStreamWithOutputTimestamp'\n         } else {\n+          excludeCategories 'org.apache.beam.sdk.testing.UsesUnboundedSplittableParDo'\n+          excludeCategories 'org.apache.beam.sdk.testing.UsesSplittableParDoWithWindowedSideInputs'\n           excludeCategories 'org.apache.beam.sdk.testing.UsesUnboundedPCollections'\n           excludeCategories 'org.apache.beam.sdk.testing.UsesTestStream'\n         }\n-        //SplitableDoFnTests\n-        excludeCategories 'org.apache.beam.sdk.testing.UsesBoundedSplittableParDo'\n-        excludeCategories 'org.apache.beam.sdk.testing.UsesSplittableParDoWithWindowedSideInputs'\n-        excludeCategories 'org.apache.beam.sdk.testing.UsesUnboundedSplittableParDo'\n-\n       }\n     },\n     testFilter: {\n       // TODO(BEAM-10016)\n       excludeTestsMatching 'org.apache.beam.sdk.transforms.FlattenTest.testFlattenWithDifferentInputAndOutputCoders2'\n+      excludeTestsMatching 'org.apache.beam.sdk.transforms.SplittableDoFnTest.testPairWithIndexWindowedTimestampedBounded'", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjUyNDY3NQ=="}, "originalCommit": {"oid": "82c2fc2df459e578a833a5e2fb4d944229876c77"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzA2OTU2Nw==", "bodyText": "I figured out the test failure and enabled the test in the latest commit.", "url": "https://github.com/apache/beam/pull/13105#discussion_r513069567", "createdAt": "2020-10-27T22:25:46Z", "author": {"login": "boyuanzz"}, "path": "runners/flink/job-server/flink_job_server.gradle", "diffHunk": "@@ -166,23 +166,22 @@ def portableValidatesRunnerTask(String name, Boolean streaming, Boolean checkpoi\n         excludeCategories 'org.apache.beam.sdk.testing.UsesBundleFinalizer'\n         excludeCategories 'org.apache.beam.sdk.testing.UsesOrderedListState'\n         if (streaming) {\n+          excludeCategories 'org.apache.beam.sdk.testing.UsesBoundedSplittableParDo'\n           excludeCategories 'org.apache.beam.sdk.testing.UsesTestStreamWithProcessingTime'\n           excludeCategories 'org.apache.beam.sdk.testing.UsesTestStreamWithMultipleStages'\n           excludeCategories 'org.apache.beam.sdk.testing.UsesTestStreamWithOutputTimestamp'\n         } else {\n+          excludeCategories 'org.apache.beam.sdk.testing.UsesUnboundedSplittableParDo'\n+          excludeCategories 'org.apache.beam.sdk.testing.UsesSplittableParDoWithWindowedSideInputs'\n           excludeCategories 'org.apache.beam.sdk.testing.UsesUnboundedPCollections'\n           excludeCategories 'org.apache.beam.sdk.testing.UsesTestStream'\n         }\n-        //SplitableDoFnTests\n-        excludeCategories 'org.apache.beam.sdk.testing.UsesBoundedSplittableParDo'\n-        excludeCategories 'org.apache.beam.sdk.testing.UsesSplittableParDoWithWindowedSideInputs'\n-        excludeCategories 'org.apache.beam.sdk.testing.UsesUnboundedSplittableParDo'\n-\n       }\n     },\n     testFilter: {\n       // TODO(BEAM-10016)\n       excludeTestsMatching 'org.apache.beam.sdk.transforms.FlattenTest.testFlattenWithDifferentInputAndOutputCoders2'\n+      excludeTestsMatching 'org.apache.beam.sdk.transforms.SplittableDoFnTest.testPairWithIndexWindowedTimestampedBounded'", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjUyNDY3NQ=="}, "originalCommit": {"oid": "82c2fc2df459e578a833a5e2fb4d944229876c77"}, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxMTI4MDMyOnYy", "diffSide": "RIGHT", "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/DoFnOperator.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yN1QwOToxNzozNFrOHoyMrA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yN1QxODoxODo1NlrOHpKj9A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjUyNzUzMg==", "bodyText": "I'm assuming this was a bug?", "url": "https://github.com/apache/beam/pull/13105#discussion_r512527532", "createdAt": "2020-10-27T09:17:34Z", "author": {"login": "mxm"}, "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/DoFnOperator.java", "diffHunk": "@@ -1315,7 +1316,7 @@ void processPendingProcessingTimeTimers() {\n         keyedStateBackend.setCurrentKey(internalTimer.getKey());\n         TimerData timer = internalTimer.getNamespace();\n         checkInvokeStartBundle();\n-        fireTimer(timer);\n+        fireTimerInternal((ByteBuffer) internalTimer.getKey(), timer);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "82c2fc2df459e578a833a5e2fb4d944229876c77"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjkyNjcwOA==", "bodyText": "I think so. The only difference is that fireTimerInternal will grab the lock and set the key for state backend, which is helpful when the state is needed. Another potential bug around here is that Flink operator will clean up global state first then fire the timer, which may lead to data loss if firing timer is for retrieving the state.", "url": "https://github.com/apache/beam/pull/13105#discussion_r512926708", "createdAt": "2020-10-27T18:18:56Z", "author": {"login": "boyuanzz"}, "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/DoFnOperator.java", "diffHunk": "@@ -1315,7 +1316,7 @@ void processPendingProcessingTimeTimers() {\n         keyedStateBackend.setCurrentKey(internalTimer.getKey());\n         TimerData timer = internalTimer.getNamespace();\n         checkInvokeStartBundle();\n-        fireTimer(timer);\n+        fireTimerInternal((ByteBuffer) internalTimer.getKey(), timer);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjUyNzUzMg=="}, "originalCommit": {"oid": "82c2fc2df459e578a833a5e2fb4d944229876c77"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxMTI4Nzg1OnYy", "diffSide": "RIGHT", "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/DoFnOperator.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yN1QwOToxOToyMFrOHoyROA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yN1QyMjoxODoyMlrOHpTF4g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjUyODY5Ng==", "bodyText": "Wouldn't it make sense to integrate this check with the timerUsesOutputTimestamp method?", "url": "https://github.com/apache/beam/pull/13105#discussion_r512528696", "createdAt": "2020-10-27T09:19:20Z", "author": {"login": "mxm"}, "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/DoFnOperator.java", "diffHunk": "@@ -1330,6 +1331,14 @@ private void onNewEventTimer(TimerData newTimer) {\n       }\n     }\n \n+    /** Holds the watermark when there is an sdf timer. */\n+    private void onNewSdfTimer(TimerData newTimer) {\n+      Preconditions.checkState(\n+          StateAndTimerBundleCheckpointHandler.isSdfTimer(newTimer.getTimerId()));\n+      Preconditions.checkState(timerUsesOutputTimestamp(newTimer));\n+      keyedStateInternals.addWatermarkHoldUsage(newTimer.getOutputTimestamp());\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "82c2fc2df459e578a833a5e2fb4d944229876c77"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjUyOTY3Mg==", "bodyText": "We could rename the mentioned method to onFiredTimer and include the checks for output watermark holds in there.", "url": "https://github.com/apache/beam/pull/13105#discussion_r512529672", "createdAt": "2020-10-27T09:20:48Z", "author": {"login": "mxm"}, "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/DoFnOperator.java", "diffHunk": "@@ -1330,6 +1331,14 @@ private void onNewEventTimer(TimerData newTimer) {\n       }\n     }\n \n+    /** Holds the watermark when there is an sdf timer. */\n+    private void onNewSdfTimer(TimerData newTimer) {\n+      Preconditions.checkState(\n+          StateAndTimerBundleCheckpointHandler.isSdfTimer(newTimer.getTimerId()));\n+      Preconditions.checkState(timerUsesOutputTimestamp(newTimer));\n+      keyedStateInternals.addWatermarkHoldUsage(newTimer.getOutputTimestamp());\n+    }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjUyODY5Ng=="}, "originalCommit": {"oid": "82c2fc2df459e578a833a5e2fb4d944229876c77"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjkxMDE5Ng==", "bodyText": "Sounds good.", "url": "https://github.com/apache/beam/pull/13105#discussion_r512910196", "createdAt": "2020-10-27T17:57:11Z", "author": {"login": "boyuanzz"}, "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/DoFnOperator.java", "diffHunk": "@@ -1330,6 +1331,14 @@ private void onNewEventTimer(TimerData newTimer) {\n       }\n     }\n \n+    /** Holds the watermark when there is an sdf timer. */\n+    private void onNewSdfTimer(TimerData newTimer) {\n+      Preconditions.checkState(\n+          StateAndTimerBundleCheckpointHandler.isSdfTimer(newTimer.getTimerId()));\n+      Preconditions.checkState(timerUsesOutputTimestamp(newTimer));\n+      keyedStateInternals.addWatermarkHoldUsage(newTimer.getOutputTimestamp());\n+    }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjUyODY5Ng=="}, "originalCommit": {"oid": "82c2fc2df459e578a833a5e2fb4d944229876c77"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzA2NjQ2Ng==", "bodyText": "Sorry I want to revisit the idea of having onFiredTimer here. I think it's a good idea to have onFiredTimer for firing timers. But the function onNewSdfTimer and onNewEventTimer is about to set watermark hold when registering timers. Different from event timer, an SDF timer must have the output timestamp for controlling watermark hold. It's important for SDF execution. That's why we have a check instead of an if block here.", "url": "https://github.com/apache/beam/pull/13105#discussion_r513066466", "createdAt": "2020-10-27T22:18:22Z", "author": {"login": "boyuanzz"}, "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/DoFnOperator.java", "diffHunk": "@@ -1330,6 +1331,14 @@ private void onNewEventTimer(TimerData newTimer) {\n       }\n     }\n \n+    /** Holds the watermark when there is an sdf timer. */\n+    private void onNewSdfTimer(TimerData newTimer) {\n+      Preconditions.checkState(\n+          StateAndTimerBundleCheckpointHandler.isSdfTimer(newTimer.getTimerId()));\n+      Preconditions.checkState(timerUsesOutputTimestamp(newTimer));\n+      keyedStateInternals.addWatermarkHoldUsage(newTimer.getOutputTimestamp());\n+    }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjUyODY5Ng=="}, "originalCommit": {"oid": "82c2fc2df459e578a833a5e2fb4d944229876c77"}, "originalPosition": 27}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxMTI5MDEyOnYy", "diffSide": "RIGHT", "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/DoFnOperator.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yN1QwOToxOTo1MlrOHoySmg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yN1QwOToyMTowOFrOHoyWEA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjUyOTA1MA==", "bodyText": "Wouldn't it make sense to integrate this check with the timerUsesOutputTimestamp method?", "url": "https://github.com/apache/beam/pull/13105#discussion_r512529050", "createdAt": "2020-10-27T09:19:52Z", "author": {"login": "mxm"}, "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/DoFnOperator.java", "diffHunk": "@@ -1342,6 +1351,14 @@ private void onRemovedEventTimer(TimerData removedTimer) {\n       }\n     }\n \n+    private void onRemovedSdfTimer(TimerData removedTimer) {\n+      Preconditions.checkState(\n+          StateAndTimerBundleCheckpointHandler.isSdfTimer(removedTimer.getTimerId()));\n+      Preconditions.checkState(timerUsesOutputTimestamp(removedTimer));\n+      // Remove the watermark hold which is set for this sdf timer.\n+      keyedStateInternals.removeWatermarkHoldUsage(removedTimer.getOutputTimestamp());\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "82c2fc2df459e578a833a5e2fb4d944229876c77"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjUyOTkzNg==", "bodyText": "We could rename the mentioned method to onFiredTimer and include the checks for output watermark holds in there.", "url": "https://github.com/apache/beam/pull/13105#discussion_r512529936", "createdAt": "2020-10-27T09:21:08Z", "author": {"login": "mxm"}, "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/DoFnOperator.java", "diffHunk": "@@ -1342,6 +1351,14 @@ private void onRemovedEventTimer(TimerData removedTimer) {\n       }\n     }\n \n+    private void onRemovedSdfTimer(TimerData removedTimer) {\n+      Preconditions.checkState(\n+          StateAndTimerBundleCheckpointHandler.isSdfTimer(removedTimer.getTimerId()));\n+      Preconditions.checkState(timerUsesOutputTimestamp(removedTimer));\n+      // Remove the watermark hold which is set for this sdf timer.\n+      keyedStateInternals.removeWatermarkHoldUsage(removedTimer.getOutputTimestamp());\n+    }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjUyOTA1MA=="}, "originalCommit": {"oid": "82c2fc2df459e578a833a5e2fb4d944229876c77"}, "originalPosition": 42}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxMTI5OTg2OnYy", "diffSide": "RIGHT", "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/DoFnOperator.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yN1QwOToyMjowN1rOHoyYlg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yN1QwOToyMjowN1rOHoyYlg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjUzMDU4Mg==", "bodyText": "Could be simplified by having a generic call here to onFiredTimer. See above.", "url": "https://github.com/apache/beam/pull/13105#discussion_r512530582", "createdAt": "2020-10-27T09:22:07Z", "author": {"login": "mxm"}, "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/DoFnOperator.java", "diffHunk": "@@ -1424,6 +1442,9 @@ private void registerTimer(TimerData timer, String contextTimerId) throws Except\n         case PROCESSING_TIME:\n         case SYNCHRONIZED_PROCESSING_TIME:\n           timerService.registerProcessingTimeTimer(timer, adjustTimestampForFlink(time));\n+          if (StateAndTimerBundleCheckpointHandler.isSdfTimer(timer.getTimerId())) {\n+            onNewSdfTimer(timer);\n+          }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "82c2fc2df459e578a833a5e2fb4d944229876c77"}, "originalPosition": 63}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxMTMwMDQ1OnYy", "diffSide": "RIGHT", "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/DoFnOperator.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yN1QwOToyMjoxNFrOHoyY-Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yN1QwOToyMjoxNFrOHoyY-Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjUzMDY4MQ==", "bodyText": "Could be simplified by having a generic call here to onFiredTimer. See above.", "url": "https://github.com/apache/beam/pull/13105#discussion_r512530681", "createdAt": "2020-10-27T09:22:14Z", "author": {"login": "mxm"}, "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/DoFnOperator.java", "diffHunk": "@@ -1451,6 +1472,8 @@ void onFiredOrDeletedTimer(TimerData timer) {\n         pendingTimersById.remove(getContextTimerId(timer.getTimerId(), timer.getNamespace()));\n         if (timer.getDomain() == TimeDomain.EVENT_TIME) {\n           onRemovedEventTimer(timer);\n+        } else if (StateAndTimerBundleCheckpointHandler.isSdfTimer(timer.getTimerId())) {\n+          onRemovedSdfTimer(timer);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "82c2fc2df459e578a833a5e2fb4d944229876c77"}, "originalPosition": 72}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxMTMxMTg0OnYy", "diffSide": "RIGHT", "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/ExecutableStageDoFnOperator.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yN1QwOToyNTowMlrOHoygKA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yN1QxNzo1NTo0M1rOHpJesg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjUzMjUyMA==", "bodyText": "Maybe we should move these out of this class.", "url": "https://github.com/apache/beam/pull/13105#discussion_r512532520", "createdAt": "2020-10-27T09:25:02Z", "author": {"login": "mxm"}, "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/ExecutableStageDoFnOperator.java", "diffHunk": "@@ -484,6 +530,148 @@ void setTimer(Timer<?> timerElement, TimerInternals.TimerData timerData) {\n     }\n   }\n \n+  /**\n+   * A {@link TimerInternalsFactory} for Flink operator to create a {@link\n+   * StateAndTimerBundleCheckpointHandler} to handle {@link\n+   * org.apache.beam.model.fnexecution.v1.BeamFnApi.DelayedBundleApplication}.\n+   */\n+  class SdfFlinkTimerInternalsFactory implements TimerInternalsFactory<InputT> {\n+    @Override\n+    public TimerInternals timerInternalsForKey(InputT key) {\n+      try {\n+        ByteBuffer encodedKey =\n+            (ByteBuffer) keySelector.getKey(WindowedValue.valueInGlobalWindow(key));\n+        return new SdfFlinkTimerInternals(encodedKey);\n+      } catch (Exception e) {\n+        throw new RuntimeException(\"Couldn't get a timer internals\", e);\n+      }\n+    }\n+  }\n+\n+  /**\n+   * A {@link TimerInternals} for rescheduling {@link\n+   * org.apache.beam.model.fnexecution.v1.BeamFnApi.DelayedBundleApplication}.\n+   */\n+  class SdfFlinkTimerInternals implements TimerInternals {\n+    private final ByteBuffer key;\n+\n+    SdfFlinkTimerInternals(ByteBuffer key) {\n+      this.key = key;\n+    }\n+\n+    @Override\n+    public void setTimer(\n+        StateNamespace namespace,\n+        String timerId,\n+        String timerFamilyId,\n+        Instant target,\n+        Instant outputTimestamp,\n+        TimeDomain timeDomain) {\n+      setTimer(\n+          TimerData.of(timerId, timerFamilyId, namespace, target, outputTimestamp, timeDomain));\n+    }\n+\n+    @Override\n+    public void setTimer(TimerData timerData) {\n+      try {\n+        try (Locker locker = Locker.locked(stateBackendLock)) {\n+          getKeyedStateBackend().setCurrentKey(key);\n+          timerInternals.setTimer(timerData);\n+          minEventTimeTimerTimestampInCurrentBundle =\n+              Math.min(\n+                  minEventTimeTimerTimestampInCurrentBundle,\n+                  adjustTimestampForFlink(timerData.getOutputTimestamp().getMillis()));\n+        }\n+      } catch (Exception e) {\n+        throw new RuntimeException(\"Couldn't set timer\", e);\n+      }\n+    }\n+\n+    @Override\n+    public void deleteTimer(StateNamespace namespace, String timerId, TimeDomain timeDomain) {\n+      throw new UnsupportedOperationException(\n+          \"It is not expected to use SdfFlinkTimerInternals to delete a timer\");\n+    }\n+\n+    @Override\n+    public void deleteTimer(StateNamespace namespace, String timerId, String timerFamilyId) {\n+      throw new UnsupportedOperationException(\n+          \"It is not expected to use SdfFlinkTimerInternals to delete a timer\");\n+    }\n+\n+    @Override\n+    public void deleteTimer(TimerData timerKey) {\n+      throw new UnsupportedOperationException(\n+          \"It is not expected to use SdfFlinkTimerInternals to delete a timer\");\n+    }\n+\n+    @Override\n+    public Instant currentProcessingTime() {\n+      return timerInternals.currentProcessingTime();\n+    }\n+\n+    @Override\n+    public @Nullable Instant currentSynchronizedProcessingTime() {\n+      return timerInternals.currentSynchronizedProcessingTime();\n+    }\n+\n+    @Override\n+    public Instant currentInputWatermarkTime() {\n+      return timerInternals.currentInputWatermarkTime();\n+    }\n+\n+    @Override\n+    public @Nullable Instant currentOutputWatermarkTime() {\n+      return timerInternals.currentOutputWatermarkTime();\n+    }\n+  }\n+\n+  /**\n+   * A {@link StateInternalsFactory} for Flink operator to create a {@link\n+   * StateAndTimerBundleCheckpointHandler} to handle {@link\n+   * org.apache.beam.model.fnexecution.v1.BeamFnApi.DelayedBundleApplication}.\n+   */\n+  class SdfFlinkStateInternalsFactory implements StateInternalsFactory<InputT> {\n+    @Override\n+    public StateInternals stateInternalsForKey(InputT key) {\n+      try {\n+        ByteBuffer encodedKey =\n+            (ByteBuffer) keySelector.getKey(WindowedValue.valueInGlobalWindow(key));\n+        return new SdfFlinkStateInternals(encodedKey);\n+      } catch (Exception e) {\n+        throw new RuntimeException(\"Couldn't get a state internals\", e);\n+      }\n+    }\n+  }\n+\n+  /** A {@link StateInternals} for keeping {@link DelayedBundleApplication}s as states. */\n+  class SdfFlinkStateInternals implements StateInternals {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "82c2fc2df459e578a833a5e2fb4d944229876c77"}, "originalPosition": 231}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjkwODk3OA==", "bodyText": "I want to keep SdfFlinkInternals and SdfTimerInternals as inner class so that they can access to getKeyedStateBackend(), timerInternals and stateInternals from outer class.", "url": "https://github.com/apache/beam/pull/13105#discussion_r512908978", "createdAt": "2020-10-27T17:55:43Z", "author": {"login": "boyuanzz"}, "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/ExecutableStageDoFnOperator.java", "diffHunk": "@@ -484,6 +530,148 @@ void setTimer(Timer<?> timerElement, TimerInternals.TimerData timerData) {\n     }\n   }\n \n+  /**\n+   * A {@link TimerInternalsFactory} for Flink operator to create a {@link\n+   * StateAndTimerBundleCheckpointHandler} to handle {@link\n+   * org.apache.beam.model.fnexecution.v1.BeamFnApi.DelayedBundleApplication}.\n+   */\n+  class SdfFlinkTimerInternalsFactory implements TimerInternalsFactory<InputT> {\n+    @Override\n+    public TimerInternals timerInternalsForKey(InputT key) {\n+      try {\n+        ByteBuffer encodedKey =\n+            (ByteBuffer) keySelector.getKey(WindowedValue.valueInGlobalWindow(key));\n+        return new SdfFlinkTimerInternals(encodedKey);\n+      } catch (Exception e) {\n+        throw new RuntimeException(\"Couldn't get a timer internals\", e);\n+      }\n+    }\n+  }\n+\n+  /**\n+   * A {@link TimerInternals} for rescheduling {@link\n+   * org.apache.beam.model.fnexecution.v1.BeamFnApi.DelayedBundleApplication}.\n+   */\n+  class SdfFlinkTimerInternals implements TimerInternals {\n+    private final ByteBuffer key;\n+\n+    SdfFlinkTimerInternals(ByteBuffer key) {\n+      this.key = key;\n+    }\n+\n+    @Override\n+    public void setTimer(\n+        StateNamespace namespace,\n+        String timerId,\n+        String timerFamilyId,\n+        Instant target,\n+        Instant outputTimestamp,\n+        TimeDomain timeDomain) {\n+      setTimer(\n+          TimerData.of(timerId, timerFamilyId, namespace, target, outputTimestamp, timeDomain));\n+    }\n+\n+    @Override\n+    public void setTimer(TimerData timerData) {\n+      try {\n+        try (Locker locker = Locker.locked(stateBackendLock)) {\n+          getKeyedStateBackend().setCurrentKey(key);\n+          timerInternals.setTimer(timerData);\n+          minEventTimeTimerTimestampInCurrentBundle =\n+              Math.min(\n+                  minEventTimeTimerTimestampInCurrentBundle,\n+                  adjustTimestampForFlink(timerData.getOutputTimestamp().getMillis()));\n+        }\n+      } catch (Exception e) {\n+        throw new RuntimeException(\"Couldn't set timer\", e);\n+      }\n+    }\n+\n+    @Override\n+    public void deleteTimer(StateNamespace namespace, String timerId, TimeDomain timeDomain) {\n+      throw new UnsupportedOperationException(\n+          \"It is not expected to use SdfFlinkTimerInternals to delete a timer\");\n+    }\n+\n+    @Override\n+    public void deleteTimer(StateNamespace namespace, String timerId, String timerFamilyId) {\n+      throw new UnsupportedOperationException(\n+          \"It is not expected to use SdfFlinkTimerInternals to delete a timer\");\n+    }\n+\n+    @Override\n+    public void deleteTimer(TimerData timerKey) {\n+      throw new UnsupportedOperationException(\n+          \"It is not expected to use SdfFlinkTimerInternals to delete a timer\");\n+    }\n+\n+    @Override\n+    public Instant currentProcessingTime() {\n+      return timerInternals.currentProcessingTime();\n+    }\n+\n+    @Override\n+    public @Nullable Instant currentSynchronizedProcessingTime() {\n+      return timerInternals.currentSynchronizedProcessingTime();\n+    }\n+\n+    @Override\n+    public Instant currentInputWatermarkTime() {\n+      return timerInternals.currentInputWatermarkTime();\n+    }\n+\n+    @Override\n+    public @Nullable Instant currentOutputWatermarkTime() {\n+      return timerInternals.currentOutputWatermarkTime();\n+    }\n+  }\n+\n+  /**\n+   * A {@link StateInternalsFactory} for Flink operator to create a {@link\n+   * StateAndTimerBundleCheckpointHandler} to handle {@link\n+   * org.apache.beam.model.fnexecution.v1.BeamFnApi.DelayedBundleApplication}.\n+   */\n+  class SdfFlinkStateInternalsFactory implements StateInternalsFactory<InputT> {\n+    @Override\n+    public StateInternals stateInternalsForKey(InputT key) {\n+      try {\n+        ByteBuffer encodedKey =\n+            (ByteBuffer) keySelector.getKey(WindowedValue.valueInGlobalWindow(key));\n+        return new SdfFlinkStateInternals(encodedKey);\n+      } catch (Exception e) {\n+        throw new RuntimeException(\"Couldn't get a state internals\", e);\n+      }\n+    }\n+  }\n+\n+  /** A {@link StateInternals} for keeping {@link DelayedBundleApplication}s as states. */\n+  class SdfFlinkStateInternals implements StateInternals {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjUzMjUyMA=="}, "originalCommit": {"oid": "82c2fc2df459e578a833a5e2fb4d944229876c77"}, "originalPosition": 231}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxMTMxMjcwOnYy", "diffSide": "RIGHT", "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/ExecutableStageDoFnOperator.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yN1QwOToyNToxMVrOHoygqw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yN1QwOToyNToxMVrOHoygqw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjUzMjY1MQ==", "bodyText": "Maybe we should move these out of this class.", "url": "https://github.com/apache/beam/pull/13105#discussion_r512532651", "createdAt": "2020-10-27T09:25:11Z", "author": {"login": "mxm"}, "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/ExecutableStageDoFnOperator.java", "diffHunk": "@@ -484,6 +530,148 @@ void setTimer(Timer<?> timerElement, TimerInternals.TimerData timerData) {\n     }\n   }\n \n+  /**\n+   * A {@link TimerInternalsFactory} for Flink operator to create a {@link\n+   * StateAndTimerBundleCheckpointHandler} to handle {@link\n+   * org.apache.beam.model.fnexecution.v1.BeamFnApi.DelayedBundleApplication}.\n+   */\n+  class SdfFlinkTimerInternalsFactory implements TimerInternalsFactory<InputT> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "82c2fc2df459e578a833a5e2fb4d944229876c77"}, "originalPosition": 121}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxMTQwMTY5OnYy", "diffSide": "RIGHT", "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkStreamingPortablePipelineTranslator.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yN1QwOTo0Nzo0MFrOHozYvA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yN1QyMDoyMDo1MlrOHpPVTg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjU0NzAwNA==", "bodyText": "Will SDFs ever support stateful operations? If so, this wouldn't work anymore because keys are not guaranteed to be processed on the same operator instance.", "url": "https://github.com/apache/beam/pull/13105#discussion_r512547004", "createdAt": "2020-10-27T09:47:40Z", "author": {"login": "mxm"}, "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkStreamingPortablePipelineTranslator.java", "diffHunk": "@@ -683,8 +694,24 @@ private void translateStreamingImpulse(\n                 inputPCollectionId,\n                 valueCoder.getClass().getSimpleName()));\n       }\n-      keyCoder = ((KvCoder) valueCoder).getKeyCoder();\n-      keySelector = new KvToByteBufferKeySelector(keyCoder);\n+      if (stateful) {\n+        keyCoder = ((KvCoder) valueCoder).getKeyCoder();\n+        keySelector = new KvToByteBufferKeySelector(keyCoder);\n+      } else {\n+        // For an SDF, we know that the input element should be\n+        // KV<KV<element, KV<restriction, watermarkState>>, size>. We are going to use the element\n+        // as the key.\n+        if (!(((KvCoder) valueCoder).getKeyCoder() instanceof KvCoder)) {\n+          throw new IllegalStateException(\n+              String.format(\n+                  Locale.ENGLISH,\n+                  \"The element coder for splittable DoFn '%s' must be KVCoder(KvCoder, DoubleCoder) but is: %s\",\n+                  inputPCollectionId,\n+                  valueCoder.getClass().getSimpleName()));\n+        }\n+        keyCoder = ((KvCoder) ((KvCoder) valueCoder).getKeyCoder()).getKeyCoder();\n+        keySelector = new SdfByteBufferKeySelector(keyCoder);\n+      }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "82c2fc2df459e578a833a5e2fb4d944229876c77"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjg5MTk5Ng==", "bodyText": "At least for now we don't support SDF using user states and timers. cc: @robertwb\nWould you like to explain more about \"because keys are not guaranteed to be processed on the same operator instance.\" ? Is it because we check stateful DoFn first?", "url": "https://github.com/apache/beam/pull/13105#discussion_r512891996", "createdAt": "2020-10-27T17:34:17Z", "author": {"login": "boyuanzz"}, "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkStreamingPortablePipelineTranslator.java", "diffHunk": "@@ -683,8 +694,24 @@ private void translateStreamingImpulse(\n                 inputPCollectionId,\n                 valueCoder.getClass().getSimpleName()));\n       }\n-      keyCoder = ((KvCoder) valueCoder).getKeyCoder();\n-      keySelector = new KvToByteBufferKeySelector(keyCoder);\n+      if (stateful) {\n+        keyCoder = ((KvCoder) valueCoder).getKeyCoder();\n+        keySelector = new KvToByteBufferKeySelector(keyCoder);\n+      } else {\n+        // For an SDF, we know that the input element should be\n+        // KV<KV<element, KV<restriction, watermarkState>>, size>. We are going to use the element\n+        // as the key.\n+        if (!(((KvCoder) valueCoder).getKeyCoder() instanceof KvCoder)) {\n+          throw new IllegalStateException(\n+              String.format(\n+                  Locale.ENGLISH,\n+                  \"The element coder for splittable DoFn '%s' must be KVCoder(KvCoder, DoubleCoder) but is: %s\",\n+                  inputPCollectionId,\n+                  valueCoder.getClass().getSimpleName()));\n+        }\n+        keyCoder = ((KvCoder) ((KvCoder) valueCoder).getKeyCoder()).getKeyCoder();\n+        keySelector = new SdfByteBufferKeySelector(keyCoder);\n+      }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjU0NzAwNA=="}, "originalCommit": {"oid": "82c2fc2df459e578a833a5e2fb4d944229876c77"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzAwNDg3OA==", "bodyText": "It's because we partition based on the element instead of on the key. This wouldn't work with stateful operations where we expect all keys to land on the same partition.", "url": "https://github.com/apache/beam/pull/13105#discussion_r513004878", "createdAt": "2020-10-27T20:20:52Z", "author": {"login": "mxm"}, "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/FlinkStreamingPortablePipelineTranslator.java", "diffHunk": "@@ -683,8 +694,24 @@ private void translateStreamingImpulse(\n                 inputPCollectionId,\n                 valueCoder.getClass().getSimpleName()));\n       }\n-      keyCoder = ((KvCoder) valueCoder).getKeyCoder();\n-      keySelector = new KvToByteBufferKeySelector(keyCoder);\n+      if (stateful) {\n+        keyCoder = ((KvCoder) valueCoder).getKeyCoder();\n+        keySelector = new KvToByteBufferKeySelector(keyCoder);\n+      } else {\n+        // For an SDF, we know that the input element should be\n+        // KV<KV<element, KV<restriction, watermarkState>>, size>. We are going to use the element\n+        // as the key.\n+        if (!(((KvCoder) valueCoder).getKeyCoder() instanceof KvCoder)) {\n+          throw new IllegalStateException(\n+              String.format(\n+                  Locale.ENGLISH,\n+                  \"The element coder for splittable DoFn '%s' must be KVCoder(KvCoder, DoubleCoder) but is: %s\",\n+                  inputPCollectionId,\n+                  valueCoder.getClass().getSimpleName()));\n+        }\n+        keyCoder = ((KvCoder) ((KvCoder) valueCoder).getKeyCoder()).getKeyCoder();\n+        keySelector = new SdfByteBufferKeySelector(keyCoder);\n+      }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMjU0NzAwNA=="}, "originalCommit": {"oid": "82c2fc2df459e578a833a5e2fb4d944229876c77"}, "originalPosition": 54}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIyMDExMjU2OnYy", "diffSide": "RIGHT", "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/control/BundleCheckpointHandlers.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOVQwMzoxOTo1MVrOHqGuSw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOVQxODozODo1NFrOHqpnEg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzkxMjM5NQ==", "bodyText": "Is it a good idea to rely on TimerInternals.getCurrentInputWatermark() to not hold back the watermark so much?\n@mxm", "url": "https://github.com/apache/beam/pull/13105#discussion_r513912395", "createdAt": "2020-10-29T03:19:51Z", "author": {"login": "boyuanzz"}, "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/control/BundleCheckpointHandlers.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.fnexecution.control;\n+\n+import com.google.common.collect.ImmutableList;\n+import org.apache.beam.model.fnexecution.v1.BeamFnApi.DelayedBundleApplication;\n+import org.apache.beam.model.fnexecution.v1.BeamFnApi.ProcessBundleResponse;\n+import org.apache.beam.runners.core.StateInternals;\n+import org.apache.beam.runners.core.StateInternalsFactory;\n+import org.apache.beam.runners.core.StateNamespace;\n+import org.apache.beam.runners.core.StateNamespaces;\n+import org.apache.beam.runners.core.StateTags;\n+import org.apache.beam.runners.core.TimerInternals;\n+import org.apache.beam.runners.core.TimerInternalsFactory;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.fn.IdGenerator;\n+import org.apache.beam.sdk.fn.IdGenerators;\n+import org.apache.beam.sdk.state.TimeDomain;\n+import org.apache.beam.sdk.transforms.windowing.BoundedWindow;\n+import org.apache.beam.sdk.util.CoderUtils;\n+import org.apache.beam.sdk.util.WindowedValue;\n+import org.joda.time.Instant;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/** Utility methods for creating {@link BundleCheckpointHandler}s. */\n+public class BundleCheckpointHandlers {\n+\n+  /**\n+   * A {@link BundleCheckpointHandler} which uses {@link\n+   * org.apache.beam.runners.core.TimerInternals.TimerData} ans {@link\n+   * org.apache.beam.sdk.state.ValueState} to reschedule {@link DelayedBundleApplication}.\n+   */\n+  public static class StateAndTimerBundleCheckpointHandler<T> implements BundleCheckpointHandler {\n+    private static final Logger LOG =\n+        LoggerFactory.getLogger(StateAndTimerBundleCheckpointHandler.class);\n+    private final TimerInternalsFactory<T> timerInternalsFactory;\n+    private final StateInternalsFactory<T> stateInternalsFactory;\n+    private final Coder<WindowedValue<T>> residualCoder;\n+    private final Coder windowCoder;\n+    private final IdGenerator idGenerator = IdGenerators.incrementingLongs();\n+    public static final String SDF_PREFIX = \"sdf_checkpoint\";\n+\n+    public StateAndTimerBundleCheckpointHandler(\n+        TimerInternalsFactory<T> timerInternalsFactory,\n+        StateInternalsFactory<T> stateInternalsFactory,\n+        Coder<WindowedValue<T>> residualCoder,\n+        Coder windowCoder) {\n+      this.residualCoder = residualCoder;\n+      this.windowCoder = windowCoder;\n+      this.timerInternalsFactory = timerInternalsFactory;\n+      this.stateInternalsFactory = stateInternalsFactory;\n+    }\n+\n+    /**\n+     * A helper function to help check whether the given timer is the timer which is set for\n+     * rescheduling {@link DelayedBundleApplication}.\n+     */\n+    public static boolean isSdfTimer(String timerId) {\n+      return timerId.startsWith(SDF_PREFIX);\n+    }\n+\n+    private static String constructSdfCheckpointId(String id, int index) {\n+      return SDF_PREFIX + \":\" + id + \":\" + index;\n+    }\n+\n+    @Override\n+    public void onCheckpoint(ProcessBundleResponse response) {\n+      String id = idGenerator.getId();\n+      for (int index = 0; index < response.getResidualRootsCount(); index++) {\n+        DelayedBundleApplication residual = response.getResidualRoots(index);\n+        if (!residual.hasApplication()) {\n+          continue;\n+        }\n+        String tag = constructSdfCheckpointId(id, index);\n+        try {\n+          WindowedValue<T> stateValue =\n+              CoderUtils.decodeFromByteArray(\n+                  residualCoder, residual.getApplication().getElement().toByteArray());\n+          TimerInternals timerInternals =\n+              timerInternalsFactory.timerInternalsForKey((stateValue.getValue()));\n+          StateInternals stateInternals =\n+              stateInternalsFactory.stateInternalsForKey(stateValue.getValue());\n+          // Calculate the timestamp for the timer.\n+          Instant timestamp = Instant.now();\n+          if (residual.hasRequestedTimeDelay()) {\n+            timestamp = timestamp.plus(residual.getRequestedTimeDelay().getSeconds() * 1000);\n+          }\n+          // Calculate the watermark hold for the timer.\n+          long outputTimestamp = BoundedWindow.TIMESTAMP_MAX_VALUE.getMillis();\n+          if (!residual.getApplication().getOutputWatermarksMap().isEmpty()) {\n+            for (org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.Timestamp outputWatermark :\n+                residual.getApplication().getOutputWatermarksMap().values()) {\n+              outputTimestamp = Math.min(outputTimestamp, outputWatermark.getSeconds() * 1000);\n+            }\n+          } else {\n+            outputTimestamp = BoundedWindow.TIMESTAMP_MIN_VALUE.getMillis();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "607b444d20e0cd66a25e48a19ac8260d1e7b3ecd"}, "originalPosition": 112}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDQ2NjU1Nw==", "bodyText": "You could use keyedStateInternals.minWatermarkHoldMs().", "url": "https://github.com/apache/beam/pull/13105#discussion_r514466557", "createdAt": "2020-10-29T18:10:25Z", "author": {"login": "mxm"}, "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/control/BundleCheckpointHandlers.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.fnexecution.control;\n+\n+import com.google.common.collect.ImmutableList;\n+import org.apache.beam.model.fnexecution.v1.BeamFnApi.DelayedBundleApplication;\n+import org.apache.beam.model.fnexecution.v1.BeamFnApi.ProcessBundleResponse;\n+import org.apache.beam.runners.core.StateInternals;\n+import org.apache.beam.runners.core.StateInternalsFactory;\n+import org.apache.beam.runners.core.StateNamespace;\n+import org.apache.beam.runners.core.StateNamespaces;\n+import org.apache.beam.runners.core.StateTags;\n+import org.apache.beam.runners.core.TimerInternals;\n+import org.apache.beam.runners.core.TimerInternalsFactory;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.fn.IdGenerator;\n+import org.apache.beam.sdk.fn.IdGenerators;\n+import org.apache.beam.sdk.state.TimeDomain;\n+import org.apache.beam.sdk.transforms.windowing.BoundedWindow;\n+import org.apache.beam.sdk.util.CoderUtils;\n+import org.apache.beam.sdk.util.WindowedValue;\n+import org.joda.time.Instant;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/** Utility methods for creating {@link BundleCheckpointHandler}s. */\n+public class BundleCheckpointHandlers {\n+\n+  /**\n+   * A {@link BundleCheckpointHandler} which uses {@link\n+   * org.apache.beam.runners.core.TimerInternals.TimerData} ans {@link\n+   * org.apache.beam.sdk.state.ValueState} to reschedule {@link DelayedBundleApplication}.\n+   */\n+  public static class StateAndTimerBundleCheckpointHandler<T> implements BundleCheckpointHandler {\n+    private static final Logger LOG =\n+        LoggerFactory.getLogger(StateAndTimerBundleCheckpointHandler.class);\n+    private final TimerInternalsFactory<T> timerInternalsFactory;\n+    private final StateInternalsFactory<T> stateInternalsFactory;\n+    private final Coder<WindowedValue<T>> residualCoder;\n+    private final Coder windowCoder;\n+    private final IdGenerator idGenerator = IdGenerators.incrementingLongs();\n+    public static final String SDF_PREFIX = \"sdf_checkpoint\";\n+\n+    public StateAndTimerBundleCheckpointHandler(\n+        TimerInternalsFactory<T> timerInternalsFactory,\n+        StateInternalsFactory<T> stateInternalsFactory,\n+        Coder<WindowedValue<T>> residualCoder,\n+        Coder windowCoder) {\n+      this.residualCoder = residualCoder;\n+      this.windowCoder = windowCoder;\n+      this.timerInternalsFactory = timerInternalsFactory;\n+      this.stateInternalsFactory = stateInternalsFactory;\n+    }\n+\n+    /**\n+     * A helper function to help check whether the given timer is the timer which is set for\n+     * rescheduling {@link DelayedBundleApplication}.\n+     */\n+    public static boolean isSdfTimer(String timerId) {\n+      return timerId.startsWith(SDF_PREFIX);\n+    }\n+\n+    private static String constructSdfCheckpointId(String id, int index) {\n+      return SDF_PREFIX + \":\" + id + \":\" + index;\n+    }\n+\n+    @Override\n+    public void onCheckpoint(ProcessBundleResponse response) {\n+      String id = idGenerator.getId();\n+      for (int index = 0; index < response.getResidualRootsCount(); index++) {\n+        DelayedBundleApplication residual = response.getResidualRoots(index);\n+        if (!residual.hasApplication()) {\n+          continue;\n+        }\n+        String tag = constructSdfCheckpointId(id, index);\n+        try {\n+          WindowedValue<T> stateValue =\n+              CoderUtils.decodeFromByteArray(\n+                  residualCoder, residual.getApplication().getElement().toByteArray());\n+          TimerInternals timerInternals =\n+              timerInternalsFactory.timerInternalsForKey((stateValue.getValue()));\n+          StateInternals stateInternals =\n+              stateInternalsFactory.stateInternalsForKey(stateValue.getValue());\n+          // Calculate the timestamp for the timer.\n+          Instant timestamp = Instant.now();\n+          if (residual.hasRequestedTimeDelay()) {\n+            timestamp = timestamp.plus(residual.getRequestedTimeDelay().getSeconds() * 1000);\n+          }\n+          // Calculate the watermark hold for the timer.\n+          long outputTimestamp = BoundedWindow.TIMESTAMP_MAX_VALUE.getMillis();\n+          if (!residual.getApplication().getOutputWatermarksMap().isEmpty()) {\n+            for (org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.Timestamp outputWatermark :\n+                residual.getApplication().getOutputWatermarksMap().values()) {\n+              outputTimestamp = Math.min(outputTimestamp, outputWatermark.getSeconds() * 1000);\n+            }\n+          } else {\n+            outputTimestamp = BoundedWindow.TIMESTAMP_MIN_VALUE.getMillis();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzkxMjM5NQ=="}, "originalCommit": {"oid": "607b444d20e0cd66a25e48a19ac8260d1e7b3ecd"}, "originalPosition": 112}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDQ4Mzk4Ng==", "bodyText": "Thanks, Max! I just double checked the contract we have: \n  \n    \n      beam/model/fn-execution/src/main/proto/beam_fn_api.proto\n    \n    \n        Lines 236 to 243\n      in\n      7eb0e95\n    \n    \n    \n    \n\n        \n          \n           // The map is keyed by the local output name of the PTransform. Each \n        \n\n        \n          \n           // value represents a lower bound on the timestamps of elements that \n        \n\n        \n          \n           // are produced by this PTransform into each of its output PCollections \n        \n\n        \n          \n           // when invoked with this application. \n        \n\n        \n          \n           // \n        \n\n        \n          \n           // If there is no watermark reported from RestrictionTracker, the runner will \n        \n\n        \n          \n           // use MIN_TIMESTAMP by default. \n        \n\n        \n          \n           map<string, google.protobuf.Timestamp> output_watermarks = 4; \n        \n    \n  \n\n\nLet's stick with MIN_TIMESTAMP for now.", "url": "https://github.com/apache/beam/pull/13105#discussion_r514483986", "createdAt": "2020-10-29T18:38:54Z", "author": {"login": "boyuanzz"}, "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/control/BundleCheckpointHandlers.java", "diffHunk": "@@ -0,0 +1,138 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.fnexecution.control;\n+\n+import com.google.common.collect.ImmutableList;\n+import org.apache.beam.model.fnexecution.v1.BeamFnApi.DelayedBundleApplication;\n+import org.apache.beam.model.fnexecution.v1.BeamFnApi.ProcessBundleResponse;\n+import org.apache.beam.runners.core.StateInternals;\n+import org.apache.beam.runners.core.StateInternalsFactory;\n+import org.apache.beam.runners.core.StateNamespace;\n+import org.apache.beam.runners.core.StateNamespaces;\n+import org.apache.beam.runners.core.StateTags;\n+import org.apache.beam.runners.core.TimerInternals;\n+import org.apache.beam.runners.core.TimerInternalsFactory;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.fn.IdGenerator;\n+import org.apache.beam.sdk.fn.IdGenerators;\n+import org.apache.beam.sdk.state.TimeDomain;\n+import org.apache.beam.sdk.transforms.windowing.BoundedWindow;\n+import org.apache.beam.sdk.util.CoderUtils;\n+import org.apache.beam.sdk.util.WindowedValue;\n+import org.joda.time.Instant;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/** Utility methods for creating {@link BundleCheckpointHandler}s. */\n+public class BundleCheckpointHandlers {\n+\n+  /**\n+   * A {@link BundleCheckpointHandler} which uses {@link\n+   * org.apache.beam.runners.core.TimerInternals.TimerData} ans {@link\n+   * org.apache.beam.sdk.state.ValueState} to reschedule {@link DelayedBundleApplication}.\n+   */\n+  public static class StateAndTimerBundleCheckpointHandler<T> implements BundleCheckpointHandler {\n+    private static final Logger LOG =\n+        LoggerFactory.getLogger(StateAndTimerBundleCheckpointHandler.class);\n+    private final TimerInternalsFactory<T> timerInternalsFactory;\n+    private final StateInternalsFactory<T> stateInternalsFactory;\n+    private final Coder<WindowedValue<T>> residualCoder;\n+    private final Coder windowCoder;\n+    private final IdGenerator idGenerator = IdGenerators.incrementingLongs();\n+    public static final String SDF_PREFIX = \"sdf_checkpoint\";\n+\n+    public StateAndTimerBundleCheckpointHandler(\n+        TimerInternalsFactory<T> timerInternalsFactory,\n+        StateInternalsFactory<T> stateInternalsFactory,\n+        Coder<WindowedValue<T>> residualCoder,\n+        Coder windowCoder) {\n+      this.residualCoder = residualCoder;\n+      this.windowCoder = windowCoder;\n+      this.timerInternalsFactory = timerInternalsFactory;\n+      this.stateInternalsFactory = stateInternalsFactory;\n+    }\n+\n+    /**\n+     * A helper function to help check whether the given timer is the timer which is set for\n+     * rescheduling {@link DelayedBundleApplication}.\n+     */\n+    public static boolean isSdfTimer(String timerId) {\n+      return timerId.startsWith(SDF_PREFIX);\n+    }\n+\n+    private static String constructSdfCheckpointId(String id, int index) {\n+      return SDF_PREFIX + \":\" + id + \":\" + index;\n+    }\n+\n+    @Override\n+    public void onCheckpoint(ProcessBundleResponse response) {\n+      String id = idGenerator.getId();\n+      for (int index = 0; index < response.getResidualRootsCount(); index++) {\n+        DelayedBundleApplication residual = response.getResidualRoots(index);\n+        if (!residual.hasApplication()) {\n+          continue;\n+        }\n+        String tag = constructSdfCheckpointId(id, index);\n+        try {\n+          WindowedValue<T> stateValue =\n+              CoderUtils.decodeFromByteArray(\n+                  residualCoder, residual.getApplication().getElement().toByteArray());\n+          TimerInternals timerInternals =\n+              timerInternalsFactory.timerInternalsForKey((stateValue.getValue()));\n+          StateInternals stateInternals =\n+              stateInternalsFactory.stateInternalsForKey(stateValue.getValue());\n+          // Calculate the timestamp for the timer.\n+          Instant timestamp = Instant.now();\n+          if (residual.hasRequestedTimeDelay()) {\n+            timestamp = timestamp.plus(residual.getRequestedTimeDelay().getSeconds() * 1000);\n+          }\n+          // Calculate the watermark hold for the timer.\n+          long outputTimestamp = BoundedWindow.TIMESTAMP_MAX_VALUE.getMillis();\n+          if (!residual.getApplication().getOutputWatermarksMap().isEmpty()) {\n+            for (org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.Timestamp outputWatermark :\n+                residual.getApplication().getOutputWatermarksMap().values()) {\n+              outputTimestamp = Math.min(outputTimestamp, outputWatermark.getSeconds() * 1000);\n+            }\n+          } else {\n+            outputTimestamp = BoundedWindow.TIMESTAMP_MIN_VALUE.getMillis();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzkxMjM5NQ=="}, "originalCommit": {"oid": "607b444d20e0cd66a25e48a19ac8260d1e7b3ecd"}, "originalPosition": 112}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIyODc2NDA5OnYy", "diffSide": "RIGHT", "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/ExecutableStageDoFnOperator.java", "isResolved": false, "comments": {"totalCount": 15, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0zMFQxODo0ODoyMFrOHrcA8A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQxOToxMjoxN1rOHxatow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTMwOTgwOA==", "bodyText": "This shouldn't be necessary. All timers will be drained on close(), at least in super.close().", "url": "https://github.com/apache/beam/pull/13105#discussion_r515309808", "createdAt": "2020-10-30T18:48:20Z", "author": {"login": "mxm"}, "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/ExecutableStageDoFnOperator.java", "diffHunk": "@@ -502,6 +690,8 @@ public void close() throws Exception {\n     processWatermark1(Watermark.MAX_WATERMARK);\n     while (getCurrentOutputWatermark() < Watermark.MAX_WATERMARK.getTimestamp()) {\n       invokeFinishBundle();\n+      // Sleep for 5s to wait for any timer to be fired.\n+      Thread.sleep(5000);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "96d57c29b6bf1d36f41a146521710b4ec59164d8"}, "originalPosition": 266}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTMxNDQ3Mg==", "bodyText": "From my testing, I found that if we don't free the occupation here, the DoFnOperator.onProcessingTime will never get a chance to be executed.", "url": "https://github.com/apache/beam/pull/13105#discussion_r515314472", "createdAt": "2020-10-30T18:57:58Z", "author": {"login": "boyuanzz"}, "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/ExecutableStageDoFnOperator.java", "diffHunk": "@@ -502,6 +690,8 @@ public void close() throws Exception {\n     processWatermark1(Watermark.MAX_WATERMARK);\n     while (getCurrentOutputWatermark() < Watermark.MAX_WATERMARK.getTimestamp()) {\n       invokeFinishBundle();\n+      // Sleep for 5s to wait for any timer to be fired.\n+      Thread.sleep(5000);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTMwOTgwOA=="}, "originalCommit": {"oid": "96d57c29b6bf1d36f41a146521710b4ec59164d8"}, "originalPosition": 266}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjQyMDQ3OQ==", "bodyText": "Kindly pinged : )", "url": "https://github.com/apache/beam/pull/13105#discussion_r516420479", "createdAt": "2020-11-03T04:17:54Z", "author": {"login": "boyuanzz"}, "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/ExecutableStageDoFnOperator.java", "diffHunk": "@@ -502,6 +690,8 @@ public void close() throws Exception {\n     processWatermark1(Watermark.MAX_WATERMARK);\n     while (getCurrentOutputWatermark() < Watermark.MAX_WATERMARK.getTimestamp()) {\n       invokeFinishBundle();\n+      // Sleep for 5s to wait for any timer to be fired.\n+      Thread.sleep(5000);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTMwOTgwOA=="}, "originalCommit": {"oid": "96d57c29b6bf1d36f41a146521710b4ec59164d8"}, "originalPosition": 266}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjY2NDgzNQ==", "bodyText": "This is a bug then. All processing timers should be fired on close(). It would be great to get rid of the sleep which can have unexpected side effects, e.g. when operators are chained in Flink.", "url": "https://github.com/apache/beam/pull/13105#discussion_r516664835", "createdAt": "2020-11-03T13:28:18Z", "author": {"login": "mxm"}, "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/ExecutableStageDoFnOperator.java", "diffHunk": "@@ -502,6 +690,8 @@ public void close() throws Exception {\n     processWatermark1(Watermark.MAX_WATERMARK);\n     while (getCurrentOutputWatermark() < Watermark.MAX_WATERMARK.getTimestamp()) {\n       invokeFinishBundle();\n+      // Sleep for 5s to wait for any timer to be fired.\n+      Thread.sleep(5000);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTMwOTgwOA=="}, "originalCommit": {"oid": "96d57c29b6bf1d36f41a146521710b4ec59164d8"}, "originalPosition": 266}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjk5MzI4Nw==", "bodyText": "This was not a bug before we support sdf initiate checkpoint because normal processing time timer doesn't hold watermark. Now we are setting processing time timer to reschedule sdf residuals which holds the watermark back. When entering ExecutableStageDoFnOperator.close(), we will always in the while loop until all sdf processing timers get fired and watermark holds are removed. So the comment  // Sleep for 5s to wait for any timer to be fired. is not precise. The comment should be  // Sleep for 5s to wait for any SDF timer to be fired.", "url": "https://github.com/apache/beam/pull/13105#discussion_r516993287", "createdAt": "2020-11-03T22:29:53Z", "author": {"login": "boyuanzz"}, "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/ExecutableStageDoFnOperator.java", "diffHunk": "@@ -502,6 +690,8 @@ public void close() throws Exception {\n     processWatermark1(Watermark.MAX_WATERMARK);\n     while (getCurrentOutputWatermark() < Watermark.MAX_WATERMARK.getTimestamp()) {\n       invokeFinishBundle();\n+      // Sleep for 5s to wait for any timer to be fired.\n+      Thread.sleep(5000);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTMwOTgwOA=="}, "originalCommit": {"oid": "96d57c29b6bf1d36f41a146521710b4ec59164d8"}, "originalPosition": 266}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjk5NjY3OQ==", "bodyText": "Would you like to explain more about the side effect here?", "url": "https://github.com/apache/beam/pull/13105#discussion_r516996679", "createdAt": "2020-11-03T22:38:17Z", "author": {"login": "boyuanzz"}, "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/ExecutableStageDoFnOperator.java", "diffHunk": "@@ -502,6 +690,8 @@ public void close() throws Exception {\n     processWatermark1(Watermark.MAX_WATERMARK);\n     while (getCurrentOutputWatermark() < Watermark.MAX_WATERMARK.getTimestamp()) {\n       invokeFinishBundle();\n+      // Sleep for 5s to wait for any timer to be fired.\n+      Thread.sleep(5000);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTMwOTgwOA=="}, "originalCommit": {"oid": "96d57c29b6bf1d36f41a146521710b4ec59164d8"}, "originalPosition": 266}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzU2OTEwNQ==", "bodyText": "Makes sense. Thanks for clarifying. Is there a way to only sleep if there are such pending timers and then wait for precisely as long as the maximum of such timers? It just seems like a workaround to always wait 5 seconds. Also, I'm surprised these timers get fired at all, since newer versions of Flink stop processing timer execution once closing the operator (that's why we are draining the timers manually in super.close()).", "url": "https://github.com/apache/beam/pull/13105#discussion_r517569105", "createdAt": "2020-11-04T19:07:04Z", "author": {"login": "mxm"}, "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/ExecutableStageDoFnOperator.java", "diffHunk": "@@ -502,6 +690,8 @@ public void close() throws Exception {\n     processWatermark1(Watermark.MAX_WATERMARK);\n     while (getCurrentOutputWatermark() < Watermark.MAX_WATERMARK.getTimestamp()) {\n       invokeFinishBundle();\n+      // Sleep for 5s to wait for any timer to be fired.\n+      Thread.sleep(5000);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTMwOTgwOA=="}, "originalCommit": {"oid": "96d57c29b6bf1d36f41a146521710b4ec59164d8"}, "originalPosition": 266}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzYwNzgxOA==", "bodyText": "Is there a way to only sleep if there are such pending timers and then wait for precisely as long as the maximum of such timers?\n\nOne way I'm coming up with is we only sleep when we are executing SDF/Process fn.\n\nAlso, I'm surprised these timers get fired at all, since newer versions of Flink stop processing timer execution once closing the operator (that's why we are draining the timers manually in super.close()).\n\nI haven't looked into Flink timer service yet but I guess it might be related to watermark hold.", "url": "https://github.com/apache/beam/pull/13105#discussion_r517607818", "createdAt": "2020-11-04T20:20:04Z", "author": {"login": "boyuanzz"}, "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/ExecutableStageDoFnOperator.java", "diffHunk": "@@ -502,6 +690,8 @@ public void close() throws Exception {\n     processWatermark1(Watermark.MAX_WATERMARK);\n     while (getCurrentOutputWatermark() < Watermark.MAX_WATERMARK.getTimestamp()) {\n       invokeFinishBundle();\n+      // Sleep for 5s to wait for any timer to be fired.\n+      Thread.sleep(5000);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTMwOTgwOA=="}, "originalCommit": {"oid": "96d57c29b6bf1d36f41a146521710b4ec59164d8"}, "originalPosition": 266}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzYyNDA1Nw==", "bodyText": "Updated the logic in d8bb778", "url": "https://github.com/apache/beam/pull/13105#discussion_r517624057", "createdAt": "2020-11-04T20:51:50Z", "author": {"login": "boyuanzz"}, "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/ExecutableStageDoFnOperator.java", "diffHunk": "@@ -502,6 +690,8 @@ public void close() throws Exception {\n     processWatermark1(Watermark.MAX_WATERMARK);\n     while (getCurrentOutputWatermark() < Watermark.MAX_WATERMARK.getTimestamp()) {\n       invokeFinishBundle();\n+      // Sleep for 5s to wait for any timer to be fired.\n+      Thread.sleep(5000);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTMwOTgwOA=="}, "originalCommit": {"oid": "96d57c29b6bf1d36f41a146521710b4ec59164d8"}, "originalPosition": 266}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTcyMjA4Ng==", "bodyText": "Thanks. This still feels like a workaround but at least we have it isolated for SDF only.", "url": "https://github.com/apache/beam/pull/13105#discussion_r519722086", "createdAt": "2020-11-09T10:59:37Z", "author": {"login": "mxm"}, "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/ExecutableStageDoFnOperator.java", "diffHunk": "@@ -502,6 +690,8 @@ public void close() throws Exception {\n     processWatermark1(Watermark.MAX_WATERMARK);\n     while (getCurrentOutputWatermark() < Watermark.MAX_WATERMARK.getTimestamp()) {\n       invokeFinishBundle();\n+      // Sleep for 5s to wait for any timer to be fired.\n+      Thread.sleep(5000);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTMwOTgwOA=="}, "originalCommit": {"oid": "96d57c29b6bf1d36f41a146521710b4ec59164d8"}, "originalPosition": 266}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDMyMjIwNA==", "bodyText": "I found that Thread.sleep(5s) is not a correct solution. The reason why it worked occasionally  is that the bundle is small enough and I got luck on race condition. I think we should figure out a way to be able to fire the SDF processing time timer when a bundle is closed within the life cycle of one ExecutableStageDoFnOperator.\nPlease correct me if I'm understanding it wrong:\n\nFlink starts all operators at the same time and closes the operators when the input watermark reaches MAX_TIMESTAMP, or it closes operators in a reverse topological order and close() is a blocking call?\nThe processing time timers will not be fired anymore by the system once the operator.close() is invoked.\nThe assumption around ExecutableStageDoFnOperator is that there is only one bundle executing inside one operator. When the output watermark advances to MAX_TIMESTAMP, we consider this bundle completed.\n\nWith supporting SDF initiated checkpoint, we do need to have several bundles invoked inside one ExecutableStageDoFnOperator life cycle, which means we either:\n\nEnable Flink to fire processing time timers after Operator.close() is invoked -- this may not be preferrable.\nOr we try to close the bundle before we reach to the Operator.close().\nOr we manually drain SDF timers with scarifying the ability of resumeDelay(). For example, the user may want to reschedule the SDF residuals in 5 mins but we have to fire it now.\n\nDo you have any ideas/suggestions? Thanks for your help!", "url": "https://github.com/apache/beam/pull/13105#discussion_r520322204", "createdAt": "2020-11-10T06:32:17Z", "author": {"login": "boyuanzz"}, "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/ExecutableStageDoFnOperator.java", "diffHunk": "@@ -502,6 +690,8 @@ public void close() throws Exception {\n     processWatermark1(Watermark.MAX_WATERMARK);\n     while (getCurrentOutputWatermark() < Watermark.MAX_WATERMARK.getTimestamp()) {\n       invokeFinishBundle();\n+      // Sleep for 5s to wait for any timer to be fired.\n+      Thread.sleep(5000);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTMwOTgwOA=="}, "originalCommit": {"oid": "96d57c29b6bf1d36f41a146521710b4ec59164d8"}, "originalPosition": 266}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg3NDMwMg==", "bodyText": "Double check the implementation of DoFnOperator and ExecutableStageDoFnOperator, we have already invoked finishBundle when reaching 1000 input elements or 1s processing time by default.\nThe real problem for SDF is that it's natural for SDF to read from Impluse and execute as a high fan-out DoFn. Based on current structure, once Impluse finishes, close() of SDF operator will be called, but meanwhile no more processing time timer can be registered. Simply draining timers from operator itself is not ideal.\nIs it possible for us to change something here? For example, the operator should wait for global watermark advancing to MAX_TIMESTAMP to finish? Or the task should invokes operator.close() when global watermark advancing to MAX_TIMESTAMP?", "url": "https://github.com/apache/beam/pull/13105#discussion_r520874302", "createdAt": "2020-11-10T21:07:27Z", "author": {"login": "boyuanzz"}, "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/ExecutableStageDoFnOperator.java", "diffHunk": "@@ -502,6 +690,8 @@ public void close() throws Exception {\n     processWatermark1(Watermark.MAX_WATERMARK);\n     while (getCurrentOutputWatermark() < Watermark.MAX_WATERMARK.getTimestamp()) {\n       invokeFinishBundle();\n+      // Sleep for 5s to wait for any timer to be fired.\n+      Thread.sleep(5000);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTMwOTgwOA=="}, "originalCommit": {"oid": "96d57c29b6bf1d36f41a146521710b4ec59164d8"}, "originalPosition": 266}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDk3NDg1Mg==", "bodyText": "Commit 56a004d introduces a workaround: draining processing timers manually for SDF. It's a workaround since it doesn't work efficiently if upstream advances watermark to MAX_TIMESTAMP very quickly. PTAL, @mxm", "url": "https://github.com/apache/beam/pull/13105#discussion_r520974852", "createdAt": "2020-11-11T01:00:14Z", "author": {"login": "boyuanzz"}, "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/ExecutableStageDoFnOperator.java", "diffHunk": "@@ -502,6 +690,8 @@ public void close() throws Exception {\n     processWatermark1(Watermark.MAX_WATERMARK);\n     while (getCurrentOutputWatermark() < Watermark.MAX_WATERMARK.getTimestamp()) {\n       invokeFinishBundle();\n+      // Sleep for 5s to wait for any timer to be fired.\n+      Thread.sleep(5000);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTMwOTgwOA=="}, "originalCommit": {"oid": "96d57c29b6bf1d36f41a146521710b4ec59164d8"}, "originalPosition": 266}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTI1MjkxNg==", "bodyText": "What you describe happens when you enable checkpointing or when you pass in --shutdownSourcesAfterIdleMs. The operator doesn't shutdown then and continues to process timers. The reason we do not enable this by default is that we want to cleanly shutdown pipelines during tests. Once an operator has been shut down, the entire job cannot be checkpointed anymore.\nThe new workaround looks good to me. We do the same in the super.close()method.", "url": "https://github.com/apache/beam/pull/13105#discussion_r521252916", "createdAt": "2020-11-11T10:13:16Z", "author": {"login": "mxm"}, "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/ExecutableStageDoFnOperator.java", "diffHunk": "@@ -502,6 +690,8 @@ public void close() throws Exception {\n     processWatermark1(Watermark.MAX_WATERMARK);\n     while (getCurrentOutputWatermark() < Watermark.MAX_WATERMARK.getTimestamp()) {\n       invokeFinishBundle();\n+      // Sleep for 5s to wait for any timer to be fired.\n+      Thread.sleep(5000);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTMwOTgwOA=="}, "originalCommit": {"oid": "96d57c29b6bf1d36f41a146521710b4ec59164d8"}, "originalPosition": 266}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMTU3OTkzOQ==", "bodyText": "Thanks for the explanation! It seems like this problem has got attention from Flink: https://issues.apache.org/jira/browse/FLINK-18647.\nI'm still feeling confused on when the operator.close() will be called. It seems like it happens under several condition:\n\n\nWhen checkpointing happens\n\n\nWhen source operator closes successfully, the next downstream operator's close() will be called.\n\n\nDo I understand it correctly?", "url": "https://github.com/apache/beam/pull/13105#discussion_r521579939", "createdAt": "2020-11-11T19:12:17Z", "author": {"login": "boyuanzz"}, "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/ExecutableStageDoFnOperator.java", "diffHunk": "@@ -502,6 +690,8 @@ public void close() throws Exception {\n     processWatermark1(Watermark.MAX_WATERMARK);\n     while (getCurrentOutputWatermark() < Watermark.MAX_WATERMARK.getTimestamp()) {\n       invokeFinishBundle();\n+      // Sleep for 5s to wait for any timer to be fired.\n+      Thread.sleep(5000);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNTMwOTgwOA=="}, "originalCommit": {"oid": "96d57c29b6bf1d36f41a146521710b4ec59164d8"}, "originalPosition": 266}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI1ODA0MTcwOnYy", "diffSide": "RIGHT", "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/ExecutableStageDoFnOperator.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOVQxMTowMDozMVrOHvpWnA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wOVQxOTo1NzoyOFrOHv_Vwg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTcyMjY1Mg==", "bodyText": "Perhaps add a TODO here, since we may want to eventually get rid of the sleep?", "url": "https://github.com/apache/beam/pull/13105#discussion_r519722652", "createdAt": "2020-11-09T11:00:31Z", "author": {"login": "mxm"}, "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/ExecutableStageDoFnOperator.java", "diffHunk": "@@ -502,6 +692,10 @@ public void close() throws Exception {\n     processWatermark1(Watermark.MAX_WATERMARK);\n     while (getCurrentOutputWatermark() < Watermark.MAX_WATERMARK.getTimestamp()) {\n       invokeFinishBundle();\n+      if (hasSdfProcessFn) {\n+        // Sleep for 5s to wait for any SDF timer to be fired.\n+        Thread.sleep(5000);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d8bb778e64fc591819a90677a9f2e119e706b52f"}, "originalPosition": 276}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDA4Mjg4Mg==", "bodyText": "Thanks! Filed here: https://issues.apache.org/jira/browse/BEAM-11210", "url": "https://github.com/apache/beam/pull/13105#discussion_r520082882", "createdAt": "2020-11-09T19:57:28Z", "author": {"login": "boyuanzz"}, "path": "runners/flink/src/main/java/org/apache/beam/runners/flink/translation/wrappers/streaming/ExecutableStageDoFnOperator.java", "diffHunk": "@@ -502,6 +692,10 @@ public void close() throws Exception {\n     processWatermark1(Watermark.MAX_WATERMARK);\n     while (getCurrentOutputWatermark() < Watermark.MAX_WATERMARK.getTimestamp()) {\n       invokeFinishBundle();\n+      if (hasSdfProcessFn) {\n+        // Sleep for 5s to wait for any SDF timer to be fired.\n+        Thread.sleep(5000);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTcyMjY1Mg=="}, "originalCommit": {"oid": "d8bb778e64fc591819a90677a9f2e119e706b52f"}, "originalPosition": 276}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2973, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}