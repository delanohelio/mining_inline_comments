{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzcwODYyNzg4", "number": 10764, "reviewThreads": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQxMDo1MzowNVrODdShkw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxOToxNToxMlrODdzLFA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyMDM4ODAzOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/ai/video_intelligence.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQxMDo1MzowNVrOFlzjlA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQxMjowNTo1M1rOFl1c9Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTE4NjMyNA==", "bodyText": "I think we should also accept other parameters, not only features.\nA must have is video_context, because sometimes it provides additional feature-specific parameters. Others are location_id and possibly metadata. Take a look at the interface of annotate_video()", "url": "https://github.com/apache/beam/pull/10764#discussion_r375186324", "createdAt": "2020-02-05T10:53:05Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/ai/video_intelligence.py", "diffHunk": "@@ -0,0 +1,75 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\"\"\"\n+A connector for sending API requests to the GCP Video Intelligence API.\n+\"\"\"\n+from __future__ import absolute_import\n+\n+from typing import Union\n+\n+from apache_beam import typehints\n+from apache_beam.io.gcp.ai import helper\n+from apache_beam.metrics import Metrics\n+from apache_beam.transforms import DoFn, ParDo, PTransform\n+\n+\n+class AnnotateVideo(PTransform):\n+  \"\"\"A ``PTransform`` for annotating video using the GCP Video Intelligence API\n+  ref: https://cloud.google.com/video-intelligence/docs\n+  \"\"\"\n+\n+  def __init__(self, features):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0e54a6423bb5b220a6d3e1d7bc7e937af2541033"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTIxNzM5Nw==", "bodyText": "Good idea, thanks! I'll have a look after we've finished the discussion with @aaltay about the usefulness of this PR.", "url": "https://github.com/apache/beam/pull/10764#discussion_r375217397", "createdAt": "2020-02-05T12:05:53Z", "author": {"login": "EDjur"}, "path": "sdks/python/apache_beam/io/gcp/ai/video_intelligence.py", "diffHunk": "@@ -0,0 +1,75 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\"\"\"\n+A connector for sending API requests to the GCP Video Intelligence API.\n+\"\"\"\n+from __future__ import absolute_import\n+\n+from typing import Union\n+\n+from apache_beam import typehints\n+from apache_beam.io.gcp.ai import helper\n+from apache_beam.metrics import Metrics\n+from apache_beam.transforms import DoFn, ParDo, PTransform\n+\n+\n+class AnnotateVideo(PTransform):\n+  \"\"\"A ``PTransform`` for annotating video using the GCP Video Intelligence API\n+  ref: https://cloud.google.com/video-intelligence/docs\n+  \"\"\"\n+\n+  def __init__(self, features):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTE4NjMyNA=="}, "originalCommit": {"oid": "0e54a6423bb5b220a6d3e1d7bc7e937af2541033"}, "originalPosition": 35}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyMDYwMTcxOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/ai/video_intelligence.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQxMjoxMTozNVrOFl1mpA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNVQxMjoxMTozNVrOFl1mpA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTIxOTg3Ng==", "bodyText": "In Python 2 str and bytes are the same. Since Beam still supports Python 2.7, this code must be compatible with both Python 2 and 3.\nConsider using future.utils module which provides some methods that can help you to check type of an element.", "url": "https://github.com/apache/beam/pull/10764#discussion_r375219876", "createdAt": "2020-02-05T12:11:35Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/ai/video_intelligence.py", "diffHunk": "@@ -0,0 +1,75 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\"\"\"\n+A connector for sending API requests to the GCP Video Intelligence API.\n+\"\"\"\n+from __future__ import absolute_import\n+\n+from typing import Union\n+\n+from apache_beam import typehints\n+from apache_beam.io.gcp.ai import helper\n+from apache_beam.metrics import Metrics\n+from apache_beam.transforms import DoFn, ParDo, PTransform\n+\n+\n+class AnnotateVideo(PTransform):\n+  \"\"\"A ``PTransform`` for annotating video using the GCP Video Intelligence API\n+  ref: https://cloud.google.com/video-intelligence/docs\n+  \"\"\"\n+\n+  def __init__(self, features):\n+    \"\"\"\n+      Args:\n+        features: (List[``videointelligence.enums.Feature``])\n+          the Video Intelligence API features to detect\n+    \"\"\"\n+    super(AnnotateVideo).__init__()\n+    self.features = features\n+\n+  def expand(self, pvalue):\n+    return pvalue | ParDo(self._VideoAnnotateFn(features=self.features))\n+\n+  @typehints.with_input_types(Union[str, bytes])\n+  class _VideoAnnotateFn(DoFn):\n+    \"\"\" A ``DoFn`` that sends every element to the GCP Video Intelligence API\n+      and returns a PCollection of\n+    ``google.cloud.videointelligence_v1.types.AnnotateVideoResponse``.\n+     \"\"\"\n+\n+    def __init__(self, features):\n+      super(AnnotateVideo._VideoAnnotateFn, self).__init__()\n+      self._client = None\n+      self.features = features\n+      self.counter = Metrics.counter(self.__class__, \"API Calls\")\n+\n+    def start_bundle(self):\n+      self._client = helper.get_videointelligence_client()\n+\n+    def process(self, element, *args, **kwargs):\n+      if isinstance(element, str):  # Is element an URI to a GCS bucket", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0e54a6423bb5b220a6d3e1d7bc7e937af2541033"}, "originalPosition": 64}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyNTQzNjk3OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/ml/gcp/video_intelligence.py", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxNzozNjo1NlrOFmkD1w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxODozMzoxMVrOFmlwWg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTk4MTAxNQ==", "bodyText": "Would it make sense to make 120 configurable?", "url": "https://github.com/apache/beam/pull/10764#discussion_r375981015", "createdAt": "2020-02-06T17:36:56Z", "author": {"login": "aaltay"}, "path": "sdks/python/apache_beam/ml/gcp/video_intelligence.py", "diffHunk": "@@ -0,0 +1,107 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+A connector for sending API requests to the GCP Video Intelligence API.\n+\"\"\"\n+from __future__ import absolute_import\n+\n+from future.utils import binary_type, text_type\n+from typing import Union\n+\n+from apache_beam import typehints\n+from apache_beam.ml.gcp import video_intelligence_helper as helper\n+from apache_beam.metrics import Metrics\n+from apache_beam.transforms import DoFn, ParDo, PTransform\n+\n+__all__ = ['AnnotateVideo']\n+\n+\n+class AnnotateVideo(PTransform):\n+  \"\"\"A ``PTransform`` for annotating video using the GCP Video Intelligence API\n+  ref: https://cloud.google.com/video-intelligence/docs\n+  \"\"\"\n+  def __init__(\n+      self, features, video_context=None, location_id=None, metadata=None):\n+    \"\"\"\n+      Args:\n+        features: (List[``videointelligence_v1.enums.Feature``]) Required.\n+          the Video Intelligence API features to detect\n+        video_context: (dict, ``videointelligence_v1.types.VideoContext``)\n+          Optional.\n+          Additional video context and/or feature-specific parameters.\n+        location_id: (str) Optional.\n+          Cloud region where annotation should take place.\n+          If no region is specified, a region will be determined\n+          based on video file location.\n+        metadata: (Sequence[Tuple[str, str]]) Optional.\n+          Additional metadata that is provided to the method.\n+    \"\"\"\n+    super(AnnotateVideo, self).__init__()\n+    self.features = features\n+    self.video_context = video_context\n+    self.location_id = location_id\n+    self.metadata = metadata\n+\n+  def expand(self, pvalue):\n+    return pvalue | ParDo(\n+        self._VideoAnnotateFn(\n+            features=self.features,\n+            video_context=self.video_context,\n+            location_id=self.location_id,\n+            metadata=self.metadata))\n+\n+  @typehints.with_input_types(Union[text_type, binary_type])\n+  class _VideoAnnotateFn(DoFn):\n+    \"\"\" A ``DoFn`` that sends every element to the GCP Video Intelligence API\n+      and returns a PCollection of\n+    ``google.cloud.videointelligence_v1.types.AnnotateVideoResponse``.\n+     \"\"\"\n+    def __init__(self, features, video_context, location_id, metadata):\n+      super(AnnotateVideo._VideoAnnotateFn, self).__init__()\n+      self._client = None\n+      self.features = features\n+      self.video_context = video_context\n+      self.location_id = location_id\n+      self.metadata = metadata\n+      self.counter = Metrics.counter(self.__class__, \"API Calls\")\n+\n+    def start_bundle(self):\n+      self._client = helper.get_videointelligence_client()\n+\n+    def process(self, element, *args, **kwargs):\n+      if isinstance(element, text_type):  # Is element an URI to a GCS bucket\n+        response = self._client.annotate_video(\n+            input_uri=element,\n+            features=self.features,\n+            video_context=self.video_context,\n+            location_id=self.location_id,\n+            metadata=self.metadata)\n+      elif isinstance(element, binary_type):  # Is element raw bytes\n+        response = self._client.annotate_video(\n+            input_content=element,\n+            features=self.features,\n+            video_context=self.video_context,\n+            location_id=self.location_id,\n+            metadata=self.metadata)\n+      else:\n+        raise TypeError(\n+            \"{}: input element needs to be either {} or {}\"\n+            \" got {} instead\".format(\n+                self.__class__.__name__, text_type, binary_type, type(element)))\n+      self.counter.inc()\n+      yield response.result(timeout=120)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c1abf00aff393c3e72e8837bc23e45c865ed0520"}, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjAwMDIzMg==", "bodyText": "Possibly. I haven't used the API enough to say for sure, but we could make it configurable.", "url": "https://github.com/apache/beam/pull/10764#discussion_r376000232", "createdAt": "2020-02-06T18:15:40Z", "author": {"login": "EDjur"}, "path": "sdks/python/apache_beam/ml/gcp/video_intelligence.py", "diffHunk": "@@ -0,0 +1,107 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+A connector for sending API requests to the GCP Video Intelligence API.\n+\"\"\"\n+from __future__ import absolute_import\n+\n+from future.utils import binary_type, text_type\n+from typing import Union\n+\n+from apache_beam import typehints\n+from apache_beam.ml.gcp import video_intelligence_helper as helper\n+from apache_beam.metrics import Metrics\n+from apache_beam.transforms import DoFn, ParDo, PTransform\n+\n+__all__ = ['AnnotateVideo']\n+\n+\n+class AnnotateVideo(PTransform):\n+  \"\"\"A ``PTransform`` for annotating video using the GCP Video Intelligence API\n+  ref: https://cloud.google.com/video-intelligence/docs\n+  \"\"\"\n+  def __init__(\n+      self, features, video_context=None, location_id=None, metadata=None):\n+    \"\"\"\n+      Args:\n+        features: (List[``videointelligence_v1.enums.Feature``]) Required.\n+          the Video Intelligence API features to detect\n+        video_context: (dict, ``videointelligence_v1.types.VideoContext``)\n+          Optional.\n+          Additional video context and/or feature-specific parameters.\n+        location_id: (str) Optional.\n+          Cloud region where annotation should take place.\n+          If no region is specified, a region will be determined\n+          based on video file location.\n+        metadata: (Sequence[Tuple[str, str]]) Optional.\n+          Additional metadata that is provided to the method.\n+    \"\"\"\n+    super(AnnotateVideo, self).__init__()\n+    self.features = features\n+    self.video_context = video_context\n+    self.location_id = location_id\n+    self.metadata = metadata\n+\n+  def expand(self, pvalue):\n+    return pvalue | ParDo(\n+        self._VideoAnnotateFn(\n+            features=self.features,\n+            video_context=self.video_context,\n+            location_id=self.location_id,\n+            metadata=self.metadata))\n+\n+  @typehints.with_input_types(Union[text_type, binary_type])\n+  class _VideoAnnotateFn(DoFn):\n+    \"\"\" A ``DoFn`` that sends every element to the GCP Video Intelligence API\n+      and returns a PCollection of\n+    ``google.cloud.videointelligence_v1.types.AnnotateVideoResponse``.\n+     \"\"\"\n+    def __init__(self, features, video_context, location_id, metadata):\n+      super(AnnotateVideo._VideoAnnotateFn, self).__init__()\n+      self._client = None\n+      self.features = features\n+      self.video_context = video_context\n+      self.location_id = location_id\n+      self.metadata = metadata\n+      self.counter = Metrics.counter(self.__class__, \"API Calls\")\n+\n+    def start_bundle(self):\n+      self._client = helper.get_videointelligence_client()\n+\n+    def process(self, element, *args, **kwargs):\n+      if isinstance(element, text_type):  # Is element an URI to a GCS bucket\n+        response = self._client.annotate_video(\n+            input_uri=element,\n+            features=self.features,\n+            video_context=self.video_context,\n+            location_id=self.location_id,\n+            metadata=self.metadata)\n+      elif isinstance(element, binary_type):  # Is element raw bytes\n+        response = self._client.annotate_video(\n+            input_content=element,\n+            features=self.features,\n+            video_context=self.video_context,\n+            location_id=self.location_id,\n+            metadata=self.metadata)\n+      else:\n+        raise TypeError(\n+            \"{}: input element needs to be either {} or {}\"\n+            \" got {} instead\".format(\n+                self.__class__.__name__, text_type, binary_type, type(element)))\n+      self.counter.inc()\n+      yield response.result(timeout=120)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTk4MTAxNQ=="}, "originalCommit": {"oid": "c1abf00aff393c3e72e8837bc23e45c865ed0520"}, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjAwODc5NA==", "bodyText": "I think we can make it a default argument to transform with the same default. It would be up to the users to change if they need to.", "url": "https://github.com/apache/beam/pull/10764#discussion_r376008794", "createdAt": "2020-02-06T18:33:11Z", "author": {"login": "aaltay"}, "path": "sdks/python/apache_beam/ml/gcp/video_intelligence.py", "diffHunk": "@@ -0,0 +1,107 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+A connector for sending API requests to the GCP Video Intelligence API.\n+\"\"\"\n+from __future__ import absolute_import\n+\n+from future.utils import binary_type, text_type\n+from typing import Union\n+\n+from apache_beam import typehints\n+from apache_beam.ml.gcp import video_intelligence_helper as helper\n+from apache_beam.metrics import Metrics\n+from apache_beam.transforms import DoFn, ParDo, PTransform\n+\n+__all__ = ['AnnotateVideo']\n+\n+\n+class AnnotateVideo(PTransform):\n+  \"\"\"A ``PTransform`` for annotating video using the GCP Video Intelligence API\n+  ref: https://cloud.google.com/video-intelligence/docs\n+  \"\"\"\n+  def __init__(\n+      self, features, video_context=None, location_id=None, metadata=None):\n+    \"\"\"\n+      Args:\n+        features: (List[``videointelligence_v1.enums.Feature``]) Required.\n+          the Video Intelligence API features to detect\n+        video_context: (dict, ``videointelligence_v1.types.VideoContext``)\n+          Optional.\n+          Additional video context and/or feature-specific parameters.\n+        location_id: (str) Optional.\n+          Cloud region where annotation should take place.\n+          If no region is specified, a region will be determined\n+          based on video file location.\n+        metadata: (Sequence[Tuple[str, str]]) Optional.\n+          Additional metadata that is provided to the method.\n+    \"\"\"\n+    super(AnnotateVideo, self).__init__()\n+    self.features = features\n+    self.video_context = video_context\n+    self.location_id = location_id\n+    self.metadata = metadata\n+\n+  def expand(self, pvalue):\n+    return pvalue | ParDo(\n+        self._VideoAnnotateFn(\n+            features=self.features,\n+            video_context=self.video_context,\n+            location_id=self.location_id,\n+            metadata=self.metadata))\n+\n+  @typehints.with_input_types(Union[text_type, binary_type])\n+  class _VideoAnnotateFn(DoFn):\n+    \"\"\" A ``DoFn`` that sends every element to the GCP Video Intelligence API\n+      and returns a PCollection of\n+    ``google.cloud.videointelligence_v1.types.AnnotateVideoResponse``.\n+     \"\"\"\n+    def __init__(self, features, video_context, location_id, metadata):\n+      super(AnnotateVideo._VideoAnnotateFn, self).__init__()\n+      self._client = None\n+      self.features = features\n+      self.video_context = video_context\n+      self.location_id = location_id\n+      self.metadata = metadata\n+      self.counter = Metrics.counter(self.__class__, \"API Calls\")\n+\n+    def start_bundle(self):\n+      self._client = helper.get_videointelligence_client()\n+\n+    def process(self, element, *args, **kwargs):\n+      if isinstance(element, text_type):  # Is element an URI to a GCS bucket\n+        response = self._client.annotate_video(\n+            input_uri=element,\n+            features=self.features,\n+            video_context=self.video_context,\n+            location_id=self.location_id,\n+            metadata=self.metadata)\n+      elif isinstance(element, binary_type):  # Is element raw bytes\n+        response = self._client.annotate_video(\n+            input_content=element,\n+            features=self.features,\n+            video_context=self.video_context,\n+            location_id=self.location_id,\n+            metadata=self.metadata)\n+      else:\n+        raise TypeError(\n+            \"{}: input element needs to be either {} or {}\"\n+            \" got {} instead\".format(\n+                self.__class__.__name__, text_type, binary_type, type(element)))\n+      self.counter.inc()\n+      yield response.result(timeout=120)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTk4MTAxNQ=="}, "originalCommit": {"oid": "c1abf00aff393c3e72e8837bc23e45c865ed0520"}, "originalPosition": 107}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyNTQ0MzY0OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/ml/gcp/video_intelligence.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxNzozOTowNlrOFmkIDw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxODoxNTo1M1rOFmlPVw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTk4MjA5NQ==", "bodyText": "DoFn does not return a PCollection. Maybe we can update this to something like\nA DoFn that sends each input element to the GCP Video Intelligence API service and outputs an element with the return result of the API.", "url": "https://github.com/apache/beam/pull/10764#discussion_r375982095", "createdAt": "2020-02-06T17:39:06Z", "author": {"login": "aaltay"}, "path": "sdks/python/apache_beam/ml/gcp/video_intelligence.py", "diffHunk": "@@ -0,0 +1,107 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+A connector for sending API requests to the GCP Video Intelligence API.\n+\"\"\"\n+from __future__ import absolute_import\n+\n+from future.utils import binary_type, text_type\n+from typing import Union\n+\n+from apache_beam import typehints\n+from apache_beam.ml.gcp import video_intelligence_helper as helper\n+from apache_beam.metrics import Metrics\n+from apache_beam.transforms import DoFn, ParDo, PTransform\n+\n+__all__ = ['AnnotateVideo']\n+\n+\n+class AnnotateVideo(PTransform):\n+  \"\"\"A ``PTransform`` for annotating video using the GCP Video Intelligence API\n+  ref: https://cloud.google.com/video-intelligence/docs\n+  \"\"\"\n+  def __init__(\n+      self, features, video_context=None, location_id=None, metadata=None):\n+    \"\"\"\n+      Args:\n+        features: (List[``videointelligence_v1.enums.Feature``]) Required.\n+          the Video Intelligence API features to detect\n+        video_context: (dict, ``videointelligence_v1.types.VideoContext``)\n+          Optional.\n+          Additional video context and/or feature-specific parameters.\n+        location_id: (str) Optional.\n+          Cloud region where annotation should take place.\n+          If no region is specified, a region will be determined\n+          based on video file location.\n+        metadata: (Sequence[Tuple[str, str]]) Optional.\n+          Additional metadata that is provided to the method.\n+    \"\"\"\n+    super(AnnotateVideo, self).__init__()\n+    self.features = features\n+    self.video_context = video_context\n+    self.location_id = location_id\n+    self.metadata = metadata\n+\n+  def expand(self, pvalue):\n+    return pvalue | ParDo(\n+        self._VideoAnnotateFn(\n+            features=self.features,\n+            video_context=self.video_context,\n+            location_id=self.location_id,\n+            metadata=self.metadata))\n+\n+  @typehints.with_input_types(Union[text_type, binary_type])\n+  class _VideoAnnotateFn(DoFn):\n+    \"\"\" A ``DoFn`` that sends every element to the GCP Video Intelligence API", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c1abf00aff393c3e72e8837bc23e45c865ed0520"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjAwMDM0Mw==", "bodyText": "Gotcha, thanks!", "url": "https://github.com/apache/beam/pull/10764#discussion_r376000343", "createdAt": "2020-02-06T18:15:53Z", "author": {"login": "EDjur"}, "path": "sdks/python/apache_beam/ml/gcp/video_intelligence.py", "diffHunk": "@@ -0,0 +1,107 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+A connector for sending API requests to the GCP Video Intelligence API.\n+\"\"\"\n+from __future__ import absolute_import\n+\n+from future.utils import binary_type, text_type\n+from typing import Union\n+\n+from apache_beam import typehints\n+from apache_beam.ml.gcp import video_intelligence_helper as helper\n+from apache_beam.metrics import Metrics\n+from apache_beam.transforms import DoFn, ParDo, PTransform\n+\n+__all__ = ['AnnotateVideo']\n+\n+\n+class AnnotateVideo(PTransform):\n+  \"\"\"A ``PTransform`` for annotating video using the GCP Video Intelligence API\n+  ref: https://cloud.google.com/video-intelligence/docs\n+  \"\"\"\n+  def __init__(\n+      self, features, video_context=None, location_id=None, metadata=None):\n+    \"\"\"\n+      Args:\n+        features: (List[``videointelligence_v1.enums.Feature``]) Required.\n+          the Video Intelligence API features to detect\n+        video_context: (dict, ``videointelligence_v1.types.VideoContext``)\n+          Optional.\n+          Additional video context and/or feature-specific parameters.\n+        location_id: (str) Optional.\n+          Cloud region where annotation should take place.\n+          If no region is specified, a region will be determined\n+          based on video file location.\n+        metadata: (Sequence[Tuple[str, str]]) Optional.\n+          Additional metadata that is provided to the method.\n+    \"\"\"\n+    super(AnnotateVideo, self).__init__()\n+    self.features = features\n+    self.video_context = video_context\n+    self.location_id = location_id\n+    self.metadata = metadata\n+\n+  def expand(self, pvalue):\n+    return pvalue | ParDo(\n+        self._VideoAnnotateFn(\n+            features=self.features,\n+            video_context=self.video_context,\n+            location_id=self.location_id,\n+            metadata=self.metadata))\n+\n+  @typehints.with_input_types(Union[text_type, binary_type])\n+  class _VideoAnnotateFn(DoFn):\n+    \"\"\" A ``DoFn`` that sends every element to the GCP Video Intelligence API", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTk4MjA5NQ=="}, "originalCommit": {"oid": "c1abf00aff393c3e72e8837bc23e45c865ed0520"}, "originalPosition": 70}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyNTQ0OTIyOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/ml/gcp/video_intelligence_helper.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxNzo0MDo1M1rOFmkLfA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxNzo0MDo1M1rOFmkLfA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTk4Mjk3Mg==", "bodyText": "Should we guard this similar to other optional dependencies (example: https://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/gcp/gcsio.py#L53)", "url": "https://github.com/apache/beam/pull/10764#discussion_r375982972", "createdAt": "2020-02-06T17:40:53Z", "author": {"login": "aaltay"}, "path": "sdks/python/apache_beam/ml/gcp/video_intelligence_helper.py", "diffHunk": "@@ -0,0 +1,36 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Cloud Video Intelligence client\n+\n+For internal use only; no backwards-compatibility guarantees.\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+from cachetools.func import ttl_cache\n+from google.cloud import videointelligence", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c1abf00aff393c3e72e8837bc23e45c865ed0520"}, "originalPosition": 29}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyNTQ1MzcyOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/ml/gcp/video_intelligence_helper.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxNzo0MjoxNVrOFmkOQw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxODoxNjo1M1rOFmlRQA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTk4MzY4Mw==", "bodyText": "Are we expecting to use this for other APIs as well?", "url": "https://github.com/apache/beam/pull/10764#discussion_r375983683", "createdAt": "2020-02-06T17:42:15Z", "author": {"login": "aaltay"}, "path": "sdks/python/apache_beam/ml/gcp/video_intelligence_helper.py", "diffHunk": "@@ -0,0 +1,36 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Cloud Video Intelligence client\n+\n+For internal use only; no backwards-compatibility guarantees.\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+from cachetools.func import ttl_cache\n+from google.cloud import videointelligence\n+\n+\n+@ttl_cache(maxsize=128, ttl=3600)\n+def get_videointelligence_client():", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c1abf00aff393c3e72e8837bc23e45c865ed0520"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjAwMDgzMg==", "bodyText": "I don't think so no, so it would make sense to merge this code into the main videointelligence file.", "url": "https://github.com/apache/beam/pull/10764#discussion_r376000832", "createdAt": "2020-02-06T18:16:53Z", "author": {"login": "EDjur"}, "path": "sdks/python/apache_beam/ml/gcp/video_intelligence_helper.py", "diffHunk": "@@ -0,0 +1,36 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Cloud Video Intelligence client\n+\n+For internal use only; no backwards-compatibility guarantees.\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+from cachetools.func import ttl_cache\n+from google.cloud import videointelligence\n+\n+\n+@ttl_cache(maxsize=128, ttl=3600)\n+def get_videointelligence_client():", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTk4MzY4Mw=="}, "originalCommit": {"oid": "c1abf00aff393c3e72e8837bc23e45c865ed0520"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyNTU0MjE1OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/ml/gcp/video_intelligence.py", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxODoxMDo1N1rOFmlGBw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxODozMToyNlrOFmltJg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTk5Nzk1OQ==", "bodyText": "Does the API have support for batching? If yes, it might be a good feature to support.", "url": "https://github.com/apache/beam/pull/10764#discussion_r375997959", "createdAt": "2020-02-06T18:10:57Z", "author": {"login": "aaltay"}, "path": "sdks/python/apache_beam/ml/gcp/video_intelligence.py", "diffHunk": "@@ -0,0 +1,107 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+A connector for sending API requests to the GCP Video Intelligence API.\n+\"\"\"\n+from __future__ import absolute_import\n+\n+from future.utils import binary_type, text_type\n+from typing import Union\n+\n+from apache_beam import typehints\n+from apache_beam.ml.gcp import video_intelligence_helper as helper\n+from apache_beam.metrics import Metrics\n+from apache_beam.transforms import DoFn, ParDo, PTransform\n+\n+__all__ = ['AnnotateVideo']\n+\n+\n+class AnnotateVideo(PTransform):\n+  \"\"\"A ``PTransform`` for annotating video using the GCP Video Intelligence API\n+  ref: https://cloud.google.com/video-intelligence/docs\n+  \"\"\"\n+  def __init__(\n+      self, features, video_context=None, location_id=None, metadata=None):\n+    \"\"\"\n+      Args:\n+        features: (List[``videointelligence_v1.enums.Feature``]) Required.\n+          the Video Intelligence API features to detect\n+        video_context: (dict, ``videointelligence_v1.types.VideoContext``)\n+          Optional.\n+          Additional video context and/or feature-specific parameters.\n+        location_id: (str) Optional.\n+          Cloud region where annotation should take place.\n+          If no region is specified, a region will be determined\n+          based on video file location.\n+        metadata: (Sequence[Tuple[str, str]]) Optional.\n+          Additional metadata that is provided to the method.\n+    \"\"\"\n+    super(AnnotateVideo, self).__init__()\n+    self.features = features\n+    self.video_context = video_context\n+    self.location_id = location_id\n+    self.metadata = metadata\n+\n+  def expand(self, pvalue):\n+    return pvalue | ParDo(\n+        self._VideoAnnotateFn(\n+            features=self.features,\n+            video_context=self.video_context,\n+            location_id=self.location_id,\n+            metadata=self.metadata))\n+\n+  @typehints.with_input_types(Union[text_type, binary_type])\n+  class _VideoAnnotateFn(DoFn):\n+    \"\"\" A ``DoFn`` that sends every element to the GCP Video Intelligence API\n+      and returns a PCollection of\n+    ``google.cloud.videointelligence_v1.types.AnnotateVideoResponse``.\n+     \"\"\"\n+    def __init__(self, features, video_context, location_id, metadata):\n+      super(AnnotateVideo._VideoAnnotateFn, self).__init__()\n+      self._client = None\n+      self.features = features\n+      self.video_context = video_context\n+      self.location_id = location_id\n+      self.metadata = metadata\n+      self.counter = Metrics.counter(self.__class__, \"API Calls\")\n+\n+    def start_bundle(self):\n+      self._client = helper.get_videointelligence_client()\n+\n+    def process(self, element, *args, **kwargs):\n+      if isinstance(element, text_type):  # Is element an URI to a GCS bucket", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c1abf00aff393c3e72e8837bc23e45c865ed0520"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjAwNDE5MA==", "bodyText": "As far as I can tell, it does not support batching https://cloud.google.com/video-intelligence/docs/reference/rest/v1/videos/annotate. But I may be wrong.", "url": "https://github.com/apache/beam/pull/10764#discussion_r376004190", "createdAt": "2020-02-06T18:23:51Z", "author": {"login": "EDjur"}, "path": "sdks/python/apache_beam/ml/gcp/video_intelligence.py", "diffHunk": "@@ -0,0 +1,107 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+A connector for sending API requests to the GCP Video Intelligence API.\n+\"\"\"\n+from __future__ import absolute_import\n+\n+from future.utils import binary_type, text_type\n+from typing import Union\n+\n+from apache_beam import typehints\n+from apache_beam.ml.gcp import video_intelligence_helper as helper\n+from apache_beam.metrics import Metrics\n+from apache_beam.transforms import DoFn, ParDo, PTransform\n+\n+__all__ = ['AnnotateVideo']\n+\n+\n+class AnnotateVideo(PTransform):\n+  \"\"\"A ``PTransform`` for annotating video using the GCP Video Intelligence API\n+  ref: https://cloud.google.com/video-intelligence/docs\n+  \"\"\"\n+  def __init__(\n+      self, features, video_context=None, location_id=None, metadata=None):\n+    \"\"\"\n+      Args:\n+        features: (List[``videointelligence_v1.enums.Feature``]) Required.\n+          the Video Intelligence API features to detect\n+        video_context: (dict, ``videointelligence_v1.types.VideoContext``)\n+          Optional.\n+          Additional video context and/or feature-specific parameters.\n+        location_id: (str) Optional.\n+          Cloud region where annotation should take place.\n+          If no region is specified, a region will be determined\n+          based on video file location.\n+        metadata: (Sequence[Tuple[str, str]]) Optional.\n+          Additional metadata that is provided to the method.\n+    \"\"\"\n+    super(AnnotateVideo, self).__init__()\n+    self.features = features\n+    self.video_context = video_context\n+    self.location_id = location_id\n+    self.metadata = metadata\n+\n+  def expand(self, pvalue):\n+    return pvalue | ParDo(\n+        self._VideoAnnotateFn(\n+            features=self.features,\n+            video_context=self.video_context,\n+            location_id=self.location_id,\n+            metadata=self.metadata))\n+\n+  @typehints.with_input_types(Union[text_type, binary_type])\n+  class _VideoAnnotateFn(DoFn):\n+    \"\"\" A ``DoFn`` that sends every element to the GCP Video Intelligence API\n+      and returns a PCollection of\n+    ``google.cloud.videointelligence_v1.types.AnnotateVideoResponse``.\n+     \"\"\"\n+    def __init__(self, features, video_context, location_id, metadata):\n+      super(AnnotateVideo._VideoAnnotateFn, self).__init__()\n+      self._client = None\n+      self.features = features\n+      self.video_context = video_context\n+      self.location_id = location_id\n+      self.metadata = metadata\n+      self.counter = Metrics.counter(self.__class__, \"API Calls\")\n+\n+    def start_bundle(self):\n+      self._client = helper.get_videointelligence_client()\n+\n+    def process(self, element, *args, **kwargs):\n+      if isinstance(element, text_type):  # Is element an URI to a GCS bucket", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTk5Nzk1OQ=="}, "originalCommit": {"oid": "c1abf00aff393c3e72e8837bc23e45c865ed0520"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjAwNzk3NA==", "bodyText": "Sounds good. Thank you for checking.", "url": "https://github.com/apache/beam/pull/10764#discussion_r376007974", "createdAt": "2020-02-06T18:31:26Z", "author": {"login": "aaltay"}, "path": "sdks/python/apache_beam/ml/gcp/video_intelligence.py", "diffHunk": "@@ -0,0 +1,107 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+A connector for sending API requests to the GCP Video Intelligence API.\n+\"\"\"\n+from __future__ import absolute_import\n+\n+from future.utils import binary_type, text_type\n+from typing import Union\n+\n+from apache_beam import typehints\n+from apache_beam.ml.gcp import video_intelligence_helper as helper\n+from apache_beam.metrics import Metrics\n+from apache_beam.transforms import DoFn, ParDo, PTransform\n+\n+__all__ = ['AnnotateVideo']\n+\n+\n+class AnnotateVideo(PTransform):\n+  \"\"\"A ``PTransform`` for annotating video using the GCP Video Intelligence API\n+  ref: https://cloud.google.com/video-intelligence/docs\n+  \"\"\"\n+  def __init__(\n+      self, features, video_context=None, location_id=None, metadata=None):\n+    \"\"\"\n+      Args:\n+        features: (List[``videointelligence_v1.enums.Feature``]) Required.\n+          the Video Intelligence API features to detect\n+        video_context: (dict, ``videointelligence_v1.types.VideoContext``)\n+          Optional.\n+          Additional video context and/or feature-specific parameters.\n+        location_id: (str) Optional.\n+          Cloud region where annotation should take place.\n+          If no region is specified, a region will be determined\n+          based on video file location.\n+        metadata: (Sequence[Tuple[str, str]]) Optional.\n+          Additional metadata that is provided to the method.\n+    \"\"\"\n+    super(AnnotateVideo, self).__init__()\n+    self.features = features\n+    self.video_context = video_context\n+    self.location_id = location_id\n+    self.metadata = metadata\n+\n+  def expand(self, pvalue):\n+    return pvalue | ParDo(\n+        self._VideoAnnotateFn(\n+            features=self.features,\n+            video_context=self.video_context,\n+            location_id=self.location_id,\n+            metadata=self.metadata))\n+\n+  @typehints.with_input_types(Union[text_type, binary_type])\n+  class _VideoAnnotateFn(DoFn):\n+    \"\"\" A ``DoFn`` that sends every element to the GCP Video Intelligence API\n+      and returns a PCollection of\n+    ``google.cloud.videointelligence_v1.types.AnnotateVideoResponse``.\n+     \"\"\"\n+    def __init__(self, features, video_context, location_id, metadata):\n+      super(AnnotateVideo._VideoAnnotateFn, self).__init__()\n+      self._client = None\n+      self.features = features\n+      self.video_context = video_context\n+      self.location_id = location_id\n+      self.metadata = metadata\n+      self.counter = Metrics.counter(self.__class__, \"API Calls\")\n+\n+    def start_bundle(self):\n+      self._client = helper.get_videointelligence_client()\n+\n+    def process(self, element, *args, **kwargs):\n+      if isinstance(element, text_type):  # Is element an URI to a GCS bucket", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NTk5Nzk1OQ=="}, "originalCommit": {"oid": "c1abf00aff393c3e72e8837bc23e45c865ed0520"}, "originalPosition": 87}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjMyNTczNzE2OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/ml/gcp/video_intelligence.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxOToxNToxMlrOFmnB6g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMi0wNlQxOToxNToxMlrOFmnB6g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3NjAyOTY3NA==", "bodyText": "We can default the timeout to 120 here. If you think that is a reasonable default.", "url": "https://github.com/apache/beam/pull/10764#discussion_r376029674", "createdAt": "2020-02-06T19:15:12Z", "author": {"login": "aaltay"}, "path": "sdks/python/apache_beam/ml/gcp/video_intelligence.py", "diffHunk": "@@ -0,0 +1,131 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+A connector for sending API requests to the GCP Video Intelligence API.\n+\"\"\"\n+from __future__ import absolute_import\n+\n+from cachetools.func import ttl_cache\n+from future.utils import binary_type, text_type\n+from typing import Union\n+\n+from apache_beam import typehints\n+from apache_beam.metrics import Metrics\n+from apache_beam.transforms import DoFn, ParDo, PTransform\n+\n+try:\n+  from google.cloud import videointelligence\n+except ImportError:\n+  raise ImportError(\n+      'Google Cloud Video Intelligence not supported for this execution environment '\n+      '(could not import google.cloud.videointelligence).')\n+\n+__all__ = ['AnnotateVideo']\n+\n+\n+@ttl_cache(maxsize=128, ttl=3600)\n+def get_videointelligence_client():\n+  \"\"\"Returns a Cloud Video Intelligence client.\"\"\"\n+  _client = videointelligence.VideoIntelligenceServiceClient()\n+  return _client\n+\n+\n+class AnnotateVideo(PTransform):\n+  \"\"\"A ``PTransform`` for annotating video using the GCP Video Intelligence API\n+  ref: https://cloud.google.com/video-intelligence/docs\n+  \"\"\"\n+  def __init__(\n+      self,\n+      features,\n+      video_context=None,\n+      location_id=None,\n+      metadata=None,\n+      timeout=120):\n+    \"\"\"\n+      Args:\n+        features: (List[``videointelligence_v1.enums.Feature``]) Required.\n+          the Video Intelligence API features to detect\n+        video_context: (dict, ``videointelligence_v1.types.VideoContext``)\n+          Optional.\n+          Additional video context and/or feature-specific parameters.\n+        location_id: (str) Optional.\n+          Cloud region where annotation should take place.\n+          If no region is specified, a region will be determined\n+          based on video file location.\n+        metadata: (Sequence[Tuple[str, str]]) Optional.\n+          Additional metadata that is provided to the method.\n+        timeout: (int) Optional.\n+          The time in seconds to wait for the response from the Video Intelligence API\n+    \"\"\"\n+    super(AnnotateVideo, self).__init__()\n+    self.features = features\n+    self.video_context = video_context\n+    self.location_id = location_id\n+    self.metadata = metadata\n+    self.timeout = timeout\n+\n+  def expand(self, pvalue):\n+    return pvalue | ParDo(\n+        self._VideoAnnotateFn(\n+            features=self.features,\n+            video_context=self.video_context,\n+            location_id=self.location_id,\n+            metadata=self.metadata,\n+            timeout=self.timeout))\n+\n+  @typehints.with_input_types(Union[text_type, binary_type])\n+  class _VideoAnnotateFn(DoFn):\n+    \"\"\" A DoFn that sends each input element to the GCP Video Intelligence API\n+        service and outputs an element with the return result of the API\n+        (``google.cloud.videointelligence_v1.types.AnnotateVideoResponse``).\n+     \"\"\"\n+    def __init__(self, features, video_context, location_id, metadata, timeout):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ebb701c6202ac1ac0b3d5d5992e78807bd868b2e"}, "originalPosition": 97}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2152, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}