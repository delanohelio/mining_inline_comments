{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDg1MjE2NTA1", "number": 12827, "title": "[BEAM-10885] Add Avro support to Kafka table provider", "bodyText": "Please add a meaningful description for your change here\n\nThank you for your contribution! Follow this checklist to help us incorporate your contribution quickly and easily:\n\n Choose reviewer(s) and mention them in a comment (R: @username).\n Format the pull request title like [BEAM-XXX] Fixes bug in ApproximateQuantiles, where you replace BEAM-XXX with the appropriate JIRA issue, if applicable. This will automatically link the pull request to the issue.\n Update CHANGES.md with noteworthy changes.\n If this contribution is large, please file an Apache Individual Contributor License Agreement.\n\nSee the Contributor Guide for more tips on how to make review process smoother.\nPost-Commit Tests Status (on master branch)\n\n\n\nLang\nSDK\nDataflow\nFlink\nSamza\nSpark\nTwister2\n\n\n\n\nGo\n\n---\n\n---\n\n---\n\n\nJava\n\n\n\n\n\n\n\n\nPython\n\n\n\n---\n\n---\n\n\nXLang\n\n---\n\n---\n\n---\n\n\n\nPre-Commit Tests Status (on master branch)\n\n\n\n---\nJava\nPython\nGo\nWebsite\nWhitespace\nTypescript\n\n\n\n\nNon-portable\n\n \n\n\n\n\n\n\nPortable\n---\n\n---\n---\n---\n---\n\n\n\nSee .test-infra/jenkins/README for trigger phrase, status and link of all Jenkins jobs.\nGitHub Actions Tests Status (on master branch)\n\n\n\nSee CI.md for more information about GitHub Actions CI.", "createdAt": "2020-09-11T15:56:26Z", "url": "https://github.com/apache/beam/pull/12827", "merged": true, "mergeCommit": {"oid": "7340bce95a26969abbf9702e342f0174a99f222a"}, "closed": true, "closedAt": "2020-10-14T02:09:53Z", "author": {"login": "piotr-szuberski"}, "timelineItems": {"totalCount": 42, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdIxIgSABqjM3NjI3NDM1OTA=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdSRhGqgH2gAyNDg1MjE2NTA1OmQ2YTE0ZTlhYmM4YjkzODUwZmEzZDA4YzlkZmE3MmQ5ZTRmZDc4ZWU=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c4f9b29c3bdd5e4e1092d1c483cac1b2f5facd22", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/c4f9b29c3bdd5e4e1092d1c483cac1b2f5facd22", "committedDate": "2020-09-11T15:55:18Z", "message": "[BEAM-10885] Add Avro support to Kafka table provider"}, "afterCommit": {"oid": "13dc5e0f928c89010c4951be61830012472dec35", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/13dc5e0f928c89010c4951be61830012472dec35", "committedDate": "2020-09-14T11:02:54Z", "message": "[BEAM-10885] Add Avro support to Kafka table provider"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "13dc5e0f928c89010c4951be61830012472dec35", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/13dc5e0f928c89010c4951be61830012472dec35", "committedDate": "2020-09-14T11:02:54Z", "message": "[BEAM-10885] Add Avro support to Kafka table provider"}, "afterCommit": {"oid": "ad9d5ef4011b2c78d8d94ae4ebbd711d329a37e7", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/ad9d5ef4011b2c78d8d94ae4ebbd711d329a37e7", "committedDate": "2020-09-14T11:11:03Z", "message": "[BEAM-10885] Add Avro support to Kafka table provider"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ad9d5ef4011b2c78d8d94ae4ebbd711d329a37e7", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/ad9d5ef4011b2c78d8d94ae4ebbd711d329a37e7", "committedDate": "2020-09-14T11:11:03Z", "message": "[BEAM-10885] Add Avro support to Kafka table provider"}, "afterCommit": {"oid": "43b206ebca95e67d710a8d807aa1ccb298603cb6", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/43b206ebca95e67d710a8d807aa1ccb298603cb6", "committedDate": "2020-09-14T11:35:51Z", "message": "[BEAM-10885] Add Avro support to Kafka table provider"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "43b206ebca95e67d710a8d807aa1ccb298603cb6", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/43b206ebca95e67d710a8d807aa1ccb298603cb6", "committedDate": "2020-09-14T11:35:51Z", "message": "[BEAM-10885] Add Avro support to Kafka table provider"}, "afterCommit": {"oid": "391c7d925e981d3483fa7bd41ce7b69f1c8102f7", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/391c7d925e981d3483fa7bd41ce7b69f1c8102f7", "committedDate": "2020-09-14T11:45:15Z", "message": "[BEAM-10885] Add Avro support to Kafka table provider"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "391c7d925e981d3483fa7bd41ce7b69f1c8102f7", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/391c7d925e981d3483fa7bd41ce7b69f1c8102f7", "committedDate": "2020-09-14T11:45:15Z", "message": "[BEAM-10885] Add Avro support to Kafka table provider"}, "afterCommit": {"oid": "b18894b8c444b7e037ca9c5fbc581aa515198168", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/b18894b8c444b7e037ca9c5fbc581aa515198168", "committedDate": "2020-09-14T13:28:33Z", "message": "[BEAM-10885] Add Avro support to Kafka table provider"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg4OTM0NjQ3", "url": "https://github.com/apache/beam/pull/12827#pullrequestreview-488934647", "createdAt": "2020-09-15T18:02:27Z", "commit": {"oid": "b18894b8c444b7e037ca9c5fbc581aa515198168"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxODowMjoyN1rOHSN0YA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQxODowMjoyN1rOHSN0YA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODg2MjgxNg==", "bodyText": "Nit: Can we change this to createKafkaTestRecord(String key, List values, int timestamp)?", "url": "https://github.com/apache/beam/pull/12827#discussion_r488862816", "createdAt": "2020-09-15T18:02:27Z", "author": {"login": "ibzib"}, "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/meta/provider/kafka/BeamKafkaTableTest.java", "diffHunk": "@@ -41,27 +40,49 @@\n import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.type.RelDataTypeSystem;\n import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.sql.type.SqlTypeName;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n-import org.apache.commons.csv.CSVFormat;\n import org.junit.Assert;\n import org.junit.Rule;\n import org.junit.Test;\n \n /** Test for BeamKafkaCSVTable. */\n-public class BeamKafkaCSVTableTest {\n+public abstract class BeamKafkaTableTest {\n   @Rule public TestPipeline pipeline = TestPipeline.create();\n \n-  private static final Row ROW1 = Row.withSchema(genSchema()).addValues(1L, 1, 1.0).build();\n+  protected static final Schema BEAM_SQL_SCHEMA =\n+      TestTableUtils.buildBeamSqlSchema(\n+          Schema.FieldType.INT32,\n+          \"order_id\",\n+          Schema.FieldType.INT32,\n+          \"site_id\",\n+          Schema.FieldType.INT32,\n+          \"price\");\n \n-  private static final Row ROW2 = Row.withSchema(genSchema()).addValues(2L, 2, 2.0).build();\n+  protected static final List<String> TOPICS = ImmutableList.of(\"topic1\", \"topic2\");\n+\n+  protected static final Schema SCHEMA = genSchema();\n+\n+  protected static final Row ROW1 = Row.withSchema(SCHEMA).addValues(1L, 1, 1.0).build();\n+\n+  protected static final Row ROW2 = Row.withSchema(SCHEMA).addValues(2L, 2, 2.0).build();\n+\n+  private static final Map<String, BeamSqlTable> tables = new HashMap<>();\n \n-  private static Map<String, BeamSqlTable> tables = new HashMap<>();\n   protected static BeamSqlEnv env = BeamSqlEnv.readOnly(\"test\", tables);\n \n+  protected abstract KafkaTestRecord<?> createKafkaTestRecord(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b18894b8c444b7e037ca9c5fbc581aa515198168"}, "originalPosition": 56}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "1eb87ff810dbee0f0d2de6fd581d6b6e274359b5", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/1eb87ff810dbee0f0d2de6fd581d6b6e274359b5", "committedDate": "2020-09-16T07:10:27Z", "message": "Remove booleans, use List of values"}, "afterCommit": {"oid": "30d032fa019e19d7dc2f57529f423267ede27929", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/30d032fa019e19d7dc2f57529f423267ede27929", "committedDate": "2020-09-17T09:19:56Z", "message": "Remove booleans, use List of values"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk1MDAxNTMz", "url": "https://github.com/apache/beam/pull/12827#pullrequestreview-495001533", "createdAt": "2020-09-23T19:57:16Z", "commit": {"oid": "30d032fa019e19d7dc2f57529f423267ede27929"}, "state": "COMMENTED", "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QxOTo1NzoxN1rOHW-vUA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QyMDozMDowNVrOHW_zMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg1ODY0MA==", "bodyText": "Could you instead have a method protected abstract BeamKafkaTable getTable() that gets overridden by each implementation?\nThen I think createRecorderDecoder and createRecorderEncoder can have concrete private implementations that are reused, like:\n  @Override\n  protected PCollection<Row> createRecorderEncoder(TestPipeline pipeline) {\n    BeamKafkaTable table = getTable();\n    return pipeline\n        .apply(Create.of(ROW1, ROW2))\n        .apply(table.getPTransformForInput())\n        .apply(table.getPTransformForOutput());\n  }\n\nThat way you're testing through the public interface and everything else (e.g. AvroRecorderEncoder) can be private.", "url": "https://github.com/apache/beam/pull/12827#discussion_r493858640", "createdAt": "2020-09-23T19:57:17Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/meta/provider/kafka/BeamKafkaTableTest.java", "diffHunk": "@@ -41,27 +40,49 @@\n import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.type.RelDataTypeSystem;\n import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.sql.type.SqlTypeName;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n-import org.apache.commons.csv.CSVFormat;\n import org.junit.Assert;\n import org.junit.Rule;\n import org.junit.Test;\n \n /** Test for BeamKafkaCSVTable. */\n-public class BeamKafkaCSVTableTest {\n+public abstract class BeamKafkaTableTest {\n   @Rule public TestPipeline pipeline = TestPipeline.create();\n \n-  private static final Row ROW1 = Row.withSchema(genSchema()).addValues(1L, 1, 1.0).build();\n+  protected static final Schema BEAM_SQL_SCHEMA =\n+      TestTableUtils.buildBeamSqlSchema(\n+          Schema.FieldType.INT32,\n+          \"order_id\",\n+          Schema.FieldType.INT32,\n+          \"site_id\",\n+          Schema.FieldType.INT32,\n+          \"price\");\n \n-  private static final Row ROW2 = Row.withSchema(genSchema()).addValues(2L, 2, 2.0).build();\n+  protected static final List<String> TOPICS = ImmutableList.of(\"topic1\", \"topic2\");\n+\n+  protected static final Schema SCHEMA = genSchema();\n+\n+  protected static final Row ROW1 = Row.withSchema(SCHEMA).addValues(1L, 1, 1d).build();\n+\n+  protected static final Row ROW2 = Row.withSchema(SCHEMA).addValues(2L, 2, 2d).build();\n+\n+  private static final Map<String, BeamSqlTable> tables = new HashMap<>();\n \n-  private static Map<String, BeamSqlTable> tables = new HashMap<>();\n   protected static BeamSqlEnv env = BeamSqlEnv.readOnly(\"test\", tables);\n \n+  protected abstract KafkaTestRecord<?> createKafkaTestRecord(\n+      String key, List<Object> values, long timestamp);\n+\n+  protected abstract KafkaTestTable getTable(int numberOfPartitions);\n+\n+  protected abstract PCollection<Row> createRecorderDecoder(TestPipeline pipeline);\n+\n+  protected abstract PCollection<Row> createRecorderEncoder(TestPipeline pipeline);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "30d032fa019e19d7dc2f57529f423267ede27929"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg1ODc0NA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              protected abstract KafkaTestTable getTable(int numberOfPartitions);\n          \n          \n            \n              protected abstract KafkaTestTable getTestTable(int numberOfPartitions);", "url": "https://github.com/apache/beam/pull/12827#discussion_r493858744", "createdAt": "2020-09-23T19:57:30Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/meta/provider/kafka/BeamKafkaTableTest.java", "diffHunk": "@@ -41,27 +40,49 @@\n import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.type.RelDataTypeSystem;\n import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.sql.type.SqlTypeName;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n-import org.apache.commons.csv.CSVFormat;\n import org.junit.Assert;\n import org.junit.Rule;\n import org.junit.Test;\n \n /** Test for BeamKafkaCSVTable. */\n-public class BeamKafkaCSVTableTest {\n+public abstract class BeamKafkaTableTest {\n   @Rule public TestPipeline pipeline = TestPipeline.create();\n \n-  private static final Row ROW1 = Row.withSchema(genSchema()).addValues(1L, 1, 1.0).build();\n+  protected static final Schema BEAM_SQL_SCHEMA =\n+      TestTableUtils.buildBeamSqlSchema(\n+          Schema.FieldType.INT32,\n+          \"order_id\",\n+          Schema.FieldType.INT32,\n+          \"site_id\",\n+          Schema.FieldType.INT32,\n+          \"price\");\n \n-  private static final Row ROW2 = Row.withSchema(genSchema()).addValues(2L, 2, 2.0).build();\n+  protected static final List<String> TOPICS = ImmutableList.of(\"topic1\", \"topic2\");\n+\n+  protected static final Schema SCHEMA = genSchema();\n+\n+  protected static final Row ROW1 = Row.withSchema(SCHEMA).addValues(1L, 1, 1d).build();\n+\n+  protected static final Row ROW2 = Row.withSchema(SCHEMA).addValues(2L, 2, 2d).build();\n+\n+  private static final Map<String, BeamSqlTable> tables = new HashMap<>();\n \n-  private static Map<String, BeamSqlTable> tables = new HashMap<>();\n   protected static BeamSqlEnv env = BeamSqlEnv.readOnly(\"test\", tables);\n \n+  protected abstract KafkaTestRecord<?> createKafkaTestRecord(\n+      String key, List<Object> values, long timestamp);\n+\n+  protected abstract KafkaTestTable getTable(int numberOfPartitions);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "30d032fa019e19d7dc2f57529f423267ede27929"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg2Mzg1NA==", "bodyText": "In that case it may make sense to get rid of createRecorderDecoder and createRecorderEncoder altogether and inline them in the couple of tests that use them.", "url": "https://github.com/apache/beam/pull/12827#discussion_r493863854", "createdAt": "2020-09-23T20:07:01Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/meta/provider/kafka/BeamKafkaTableTest.java", "diffHunk": "@@ -41,27 +40,49 @@\n import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.type.RelDataTypeSystem;\n import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.sql.type.SqlTypeName;\n import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n-import org.apache.commons.csv.CSVFormat;\n import org.junit.Assert;\n import org.junit.Rule;\n import org.junit.Test;\n \n /** Test for BeamKafkaCSVTable. */\n-public class BeamKafkaCSVTableTest {\n+public abstract class BeamKafkaTableTest {\n   @Rule public TestPipeline pipeline = TestPipeline.create();\n \n-  private static final Row ROW1 = Row.withSchema(genSchema()).addValues(1L, 1, 1.0).build();\n+  protected static final Schema BEAM_SQL_SCHEMA =\n+      TestTableUtils.buildBeamSqlSchema(\n+          Schema.FieldType.INT32,\n+          \"order_id\",\n+          Schema.FieldType.INT32,\n+          \"site_id\",\n+          Schema.FieldType.INT32,\n+          \"price\");\n \n-  private static final Row ROW2 = Row.withSchema(genSchema()).addValues(2L, 2, 2.0).build();\n+  protected static final List<String> TOPICS = ImmutableList.of(\"topic1\", \"topic2\");\n+\n+  protected static final Schema SCHEMA = genSchema();\n+\n+  protected static final Row ROW1 = Row.withSchema(SCHEMA).addValues(1L, 1, 1d).build();\n+\n+  protected static final Row ROW2 = Row.withSchema(SCHEMA).addValues(2L, 2, 2d).build();\n+\n+  private static final Map<String, BeamSqlTable> tables = new HashMap<>();\n \n-  private static Map<String, BeamSqlTable> tables = new HashMap<>();\n   protected static BeamSqlEnv env = BeamSqlEnv.readOnly(\"test\", tables);\n \n+  protected abstract KafkaTestRecord<?> createKafkaTestRecord(\n+      String key, List<Object> values, long timestamp);\n+\n+  protected abstract KafkaTestTable getTable(int numberOfPartitions);\n+\n+  protected abstract PCollection<Row> createRecorderDecoder(TestPipeline pipeline);\n+\n+  protected abstract PCollection<Row> createRecorderEncoder(TestPipeline pipeline);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg1ODY0MA=="}, "originalCommit": {"oid": "30d032fa019e19d7dc2f57529f423267ede27929"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg2NDg5OA==", "bodyText": "Could you add more fields to this schema to exercise more types?", "url": "https://github.com/apache/beam/pull/12827#discussion_r493864898", "createdAt": "2020-09-23T20:08:54Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/meta/provider/kafka/KafkaTableProviderIT.java", "diffHunk": "@@ -67,19 +67,25 @@\n import org.testcontainers.containers.KafkaContainer;\n \n /** This is an integration test for KafkaCSVTable. */\n-public class KafkaCSVTableIT {\n+public abstract class KafkaTableProviderIT {\n   @Rule public transient TestPipeline pipeline = TestPipeline.create();\n   @Rule public transient KafkaContainer kafka = new KafkaContainer();\n \n-  private KafkaOptions kafkaOptions;\n+  protected KafkaOptions kafkaOptions;\n \n-  private static final Schema TEST_TABLE_SCHEMA =\n+  protected static final Schema TEST_TABLE_SCHEMA =\n       Schema.builder()\n           .addNullableField(\"order_id\", Schema.FieldType.INT32)\n           .addNullableField(\"member_id\", Schema.FieldType.INT32)\n           .addNullableField(\"item_name\", Schema.FieldType.INT32)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "30d032fa019e19d7dc2f57529f423267ede27929"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg2NTc3OQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            /** This is a MockKafkaCSVTestTable. It will use a Mock Consumer. */\n          \n          \n            \n            /** This is a mock BeamKafkaTable. It will use a Mock Consumer. */", "url": "https://github.com/apache/beam/pull/12827#discussion_r493865779", "createdAt": "2020-09-23T20:10:28Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/meta/provider/kafka/KafkaTestTable.java", "diffHunk": "@@ -44,23 +48,25 @@\n import org.apache.kafka.common.record.TimestampType;\n \n /** This is a MockKafkaCSVTestTable. It will use a Mock Consumer. */", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "30d032fa019e19d7dc2f57529f423267ede27929"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg2NzE0NQ==", "bodyText": "It looks like this is only actually used in BeamCsvTableTest, let's just move it there rather than making it protected.", "url": "https://github.com/apache/beam/pull/12827#discussion_r493867145", "createdAt": "2020-09-23T20:12:59Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/meta/provider/kafka/BeamKafkaTableTest.java", "diffHunk": "@@ -184,24 +185,11 @@ private static Schema genSchema() {\n             .build());\n   }\n \n-  private static class String2KvBytes extends DoFn<String, KV<byte[], byte[]>>\n+  protected static class String2KvBytes extends DoFn<String, KV<byte[], byte[]>>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "30d032fa019e19d7dc2f57529f423267ede27929"}, "originalPosition": 211}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg2OTMzMQ==", "bodyText": "Please test more types here too. Also I'm not sure why this is using JavaTypeFactory and converting to a Beam Schema, maybe it pre-dates the modern Schema class that has a nice builder interface. Could you change it to use Schema.builder()... or Schema.of(..)?", "url": "https://github.com/apache/beam/pull/12827#discussion_r493869331", "createdAt": "2020-09-23T20:17:13Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/meta/provider/kafka/BeamKafkaTableTest.java", "diffHunk": "@@ -123,57 +144,37 @@ public void testAllLate() {\n \n   @Test\n   public void testEmptyPartitionsRate() {\n-    KafkaCSVTestTable table = getTable(3);\n+    KafkaTestTable table = getTable(3);\n     BeamTableStatistics stats = table.getTableStatistics(null);\n     Assert.assertTrue(stats.isUnknown());\n   }\n \n   @Test\n   public void allTheRecordsSameTimeRate() {\n-    KafkaCSVTestTable table = getTable(3);\n-    for (int i = 0; i < 100; i++) {\n-      table.addRecord(KafkaTestRecord.create(\"key\" + i, i + \",1,2\", \"topic1\", 1000));\n+    KafkaTestTable table = getTable(3);\n+    for (long i = 0; i < 100; i++) {\n+      table.addRecord(createKafkaTestRecord(\"key\" + i, ImmutableList.of(i, 1, 2d), 1000L));\n     }\n     BeamTableStatistics stats = table.getTableStatistics(null);\n     Assert.assertTrue(stats.isUnknown());\n   }\n \n-  private static class PrintDoFn extends DoFn<Row, Row> {\n-\n-    @ProcessElement\n-    public void process(ProcessContext c) {\n-      System.out.println(\"we are here\");\n-      System.out.println(c.element().getValues());\n-    }\n-  }\n-\n   @Test\n-  public void testCsvRecorderDecoder() {\n-    PCollection<Row> result =\n-        pipeline\n-            .apply(Create.of(\"1,\\\"1\\\",1.0\", \"2,2,2.0\"))\n-            .apply(ParDo.of(new String2KvBytes()))\n-            .apply(new BeamKafkaCSVTable.CsvRecorderDecoder(genSchema(), CSVFormat.DEFAULT));\n-\n+  public void testRecorderDecoder() {\n+    PCollection<Row> result = createRecorderDecoder(pipeline);\n     PAssert.that(result).containsInAnyOrder(ROW1, ROW2);\n \n     pipeline.run();\n   }\n \n   @Test\n-  public void testCsvRecorderEncoder() {\n-    PCollection<Row> result =\n-        pipeline\n-            .apply(Create.of(ROW1, ROW2))\n-            .apply(new BeamKafkaCSVTable.CsvRecorderEncoder(genSchema(), CSVFormat.DEFAULT))\n-            .apply(new BeamKafkaCSVTable.CsvRecorderDecoder(genSchema(), CSVFormat.DEFAULT));\n-\n+  public void testRecorderEncoder() {\n+    PCollection<Row> result = createRecorderDecoder(pipeline);\n     PAssert.that(result).containsInAnyOrder(ROW1, ROW2);\n-\n     pipeline.run();\n   }\n \n-  private static Schema genSchema() {\n+  protected static Schema genSchema() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "30d032fa019e19d7dc2f57529f423267ede27929"}, "originalPosition": 202}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg3NTgzNA==", "bodyText": "Both of these methods will repeat the schema conversion for every Row. Instead both of these methods should convert the schema once and re-use avroSchema and coder for every instance of bytes or row that comes in. There are a few ways to do this, I don't really have a preference for which:\n\nReturn a lambda with avroSchema and coder in it's closure, like\n\nreturn (bytes) -> {\n  ByteArrayInputStream inputStream = new ByteArrayInputStream(bytes);\n  GenericRecord record = coder.decode(inputStream);\n  AvroUtils.toBeamRowStruct(record, schema);\n}\n\nCreate an AvroBytesToRow class with a process method that re-uses avroSchema/coder\nSimilarly, create an AvroBytesToRow DoFn with a process method that re-uses avroSchema/coder", "url": "https://github.com/apache/beam/pull/12827#discussion_r493875834", "createdAt": "2020-09-23T20:29:44Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/utils/AvroUtils.java", "diffHunk": "@@ -428,6 +432,35 @@ public static GenericRecord toGenericRecord(\n     return new GenericRecordToRowFn(schema);\n   }\n \n+  public static Row avroBytesToRow(byte[] bytes, Schema schema) {\n+    try {\n+      org.apache.avro.Schema avroSchema = AvroUtils.toAvroSchema(schema);\n+      AvroCoder<GenericRecord> coder = AvroCoder.of(avroSchema);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "30d032fa019e19d7dc2f57529f423267ede27929"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg3NjAxNw==", "bodyText": "The last is probably the most natural for Beam", "url": "https://github.com/apache/beam/pull/12827#discussion_r493876017", "createdAt": "2020-09-23T20:30:05Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/utils/AvroUtils.java", "diffHunk": "@@ -428,6 +432,35 @@ public static GenericRecord toGenericRecord(\n     return new GenericRecordToRowFn(schema);\n   }\n \n+  public static Row avroBytesToRow(byte[] bytes, Schema schema) {\n+    try {\n+      org.apache.avro.Schema avroSchema = AvroUtils.toAvroSchema(schema);\n+      AvroCoder<GenericRecord> coder = AvroCoder.of(avroSchema);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5Mzg3NTgzNA=="}, "originalCommit": {"oid": "30d032fa019e19d7dc2f57529f423267ede27929"}, "originalPosition": 31}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "30d032fa019e19d7dc2f57529f423267ede27929", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/30d032fa019e19d7dc2f57529f423267ede27929", "committedDate": "2020-09-17T09:19:56Z", "message": "Remove booleans, use List of values"}, "afterCommit": {"oid": "3a1816ccbdc860a5f66f92d391dc58f896e79c75", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/3a1816ccbdc860a5f66f92d391dc58f896e79c75", "committedDate": "2020-09-28T13:18:03Z", "message": "Fixes after CR"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "3a1816ccbdc860a5f66f92d391dc58f896e79c75", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/3a1816ccbdc860a5f66f92d391dc58f896e79c75", "committedDate": "2020-09-28T13:18:03Z", "message": "Fixes after CR"}, "afterCommit": {"oid": "edca112a19e5cc6df41db99c43bc5dd40ea0fe9e", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/edca112a19e5cc6df41db99c43bc5dd40ea0fe9e", "committedDate": "2020-09-28T13:22:00Z", "message": "Fixes after CR"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "edca112a19e5cc6df41db99c43bc5dd40ea0fe9e", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/edca112a19e5cc6df41db99c43bc5dd40ea0fe9e", "committedDate": "2020-09-28T13:22:00Z", "message": "Fixes after CR"}, "afterCommit": {"oid": "242e8aff494ac4c9cd68dba30cf01732a7c5a949", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/242e8aff494ac4c9cd68dba30cf01732a7c5a949", "committedDate": "2020-09-28T13:50:11Z", "message": "Fixes after CR"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b6b4ac4a3c967dd9e08b7cabb6169ae0ee7fa5a0", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/b6b4ac4a3c967dd9e08b7cabb6169ae0ee7fa5a0", "committedDate": "2020-09-29T10:38:16Z", "message": "Change payloadFormat to format like in text table provider"}, "afterCommit": {"oid": "15d0265ec5e18f7ff5112ce037a34fdc32fd1014", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/15d0265ec5e18f7ff5112ce037a34fdc32fd1014", "committedDate": "2020-09-29T10:50:08Z", "message": "Change payloadFormat to format like in text table provider"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "6982e7880d4c95b826965d3ce45df04a2a715fdf", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/6982e7880d4c95b826965d3ce45df04a2a715fdf", "committedDate": "2020-09-29T11:07:52Z", "message": "Fix checkstyle"}, "afterCommit": {"oid": "0d8174c0d67451e310c759e245531eb7ce589f47", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/0d8174c0d67451e310c759e245531eb7ce589f47", "committedDate": "2020-09-29T11:59:36Z", "message": "Fix checkstyle"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk3OTg1MzAz", "url": "https://github.com/apache/beam/pull/12827#pullrequestreview-497985303", "createdAt": "2020-09-29T00:33:34Z", "commit": {"oid": "242e8aff494ac4c9cd68dba30cf01732a7c5a949"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQwMDozMzozNFrOHZURBA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wMlQyMDoyNzo1NFrOHb6s-A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjMwODQ4NA==", "bodyText": "I think I've seem issues with SchemaCoder and static members in the past, is that why this isn't static?", "url": "https://github.com/apache/beam/pull/12827#discussion_r496308484", "createdAt": "2020-09-29T00:33:34Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/meta/provider/kafka/BeamKafkaTableAvroTest.java", "diffHunk": "@@ -0,0 +1,106 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.meta.provider.kafka;\n+\n+import java.io.ByteArrayOutputStream;\n+import java.io.IOException;\n+import java.util.List;\n+import org.apache.avro.generic.GenericRecord;\n+import org.apache.beam.sdk.coders.AvroCoder;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.schemas.utils.AvroUtils;\n+import org.apache.beam.sdk.transforms.MapElements;\n+import org.apache.beam.sdk.transforms.SerializableFunction;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.sdk.values.TypeDescriptor;\n+import org.apache.beam.sdk.values.TypeDescriptors;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+\n+public class BeamKafkaTableAvroTest extends BeamKafkaTableTest {\n+  private static final Schema EMPTY_SCHEMA = Schema.builder().build();\n+\n+  private final Schema SCHEMA =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "242e8aff494ac4c9cd68dba30cf01732a7c5a949"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTAwMjExNA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            /** Test for BeamKafkaCSVTable. */\n          \n          \n            \n            /** Test utility for BeamKafkaTable implementations. */", "url": "https://github.com/apache/beam/pull/12827#discussion_r499002114", "createdAt": "2020-10-02T19:07:24Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/meta/provider/kafka/BeamKafkaTableTest.java", "diffHunk": "@@ -0,0 +1,169 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.meta.provider.kafka;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.beam.sdk.extensions.sql.impl.BeamSqlEnv;\n+import org.apache.beam.sdk.extensions.sql.impl.BeamTableStatistics;\n+import org.apache.beam.sdk.extensions.sql.meta.BeamSqlTable;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.testing.PAssert;\n+import org.apache.beam.sdk.testing.TestPipeline;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.junit.Assert;\n+import org.junit.Rule;\n+import org.junit.Test;\n+\n+/** Test for BeamKafkaCSVTable. */", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "488562713d863377f6b33730f82b39cfda207163"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTAwMjc2MQ==", "bodyText": "Please add a brief description of the abstract methods so it's clear for future implementers what they should do", "url": "https://github.com/apache/beam/pull/12827#discussion_r499002761", "createdAt": "2020-10-02T19:09:03Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/meta/provider/kafka/BeamKafkaTableTest.java", "diffHunk": "@@ -0,0 +1,169 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.meta.provider.kafka;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.beam.sdk.extensions.sql.impl.BeamSqlEnv;\n+import org.apache.beam.sdk.extensions.sql.impl.BeamTableStatistics;\n+import org.apache.beam.sdk.extensions.sql.meta.BeamSqlTable;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.testing.PAssert;\n+import org.apache.beam.sdk.testing.TestPipeline;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.junit.Assert;\n+import org.junit.Rule;\n+import org.junit.Test;\n+\n+/** Test for BeamKafkaCSVTable. */\n+public abstract class BeamKafkaTableTest {\n+  @Rule public TestPipeline pipeline = TestPipeline.create();\n+\n+  protected static final List<String> TOPICS = ImmutableList.of(\"topic1\", \"topic2\");\n+\n+  private static final Map<String, BeamSqlTable> tables = new HashMap<>();\n+\n+  protected static BeamSqlEnv env = BeamSqlEnv.readOnly(\"test\", tables);\n+\n+  protected abstract KafkaTestRecord<?> createKafkaTestRecord(String key, int i, long timestamp);\n+\n+  protected abstract KafkaTestTable getTestTable(int numberOfPartitions);\n+\n+  protected abstract BeamKafkaTable getBeamKafkaTable();\n+\n+  protected abstract PCollection<KV<byte[], byte[]>> applyRowToBytesKV(PCollection<Row> rows);\n+\n+  protected abstract List<Object> listFrom(int i);\n+\n+  protected abstract Schema getSchema();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "488562713d863377f6b33730f82b39cfda207163"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTAzNTM4NA==", "bodyText": "I don't think this test is meaningfully different from testRecorderEncoder. It looks like both of the implementations of applyRowToBytesKV are effectively the same as .apply(kafkaTable.getPTransformForOutput()), so we're not really getting a good signal that the encoder and decoder work as intended on their own.\nIt would be better if there were an abstract method like generateEncodedPayload(i) that returns the encoded counterpart for generateRow(i). Crucially, this method shouldn't use any of the code that we're testing here (like beamRow2CsvLines, or AvroUtils.getRowToAvroBytesFunction(getSchema())), it should instead generate the test data from scratch. This isn't too hard for CSV since its just a simple String. It's harder for Avro, but still doable, I think you can make it work by creating GenericRecord instances and encoding them.\nThen there could be tests like\n\ngenerate input with generateEncodedPayload, apply getPTransformForInput(), verify it matches data created with generateRow.\ngenerate input with generateRow, apply getPTransformForOutput(), verify it matches data created with generateEncodedPayload.\nwe could also have a round-trip test, like what's done in testRecorderEncoder now\n\nNote generateEncodedPayload could also be re-used in createKafkaTestRecord and it could have a concrete implementation in BeamKafkaTableTest as return KafkaTestRecord.create(key, generateEncodedPayload(i), \"topic1\", timestamp);", "url": "https://github.com/apache/beam/pull/12827#discussion_r499035384", "createdAt": "2020-10-02T20:27:54Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/meta/provider/kafka/BeamKafkaTableTest.java", "diffHunk": "@@ -0,0 +1,169 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.meta.provider.kafka;\n+\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.beam.sdk.extensions.sql.impl.BeamSqlEnv;\n+import org.apache.beam.sdk.extensions.sql.impl.BeamTableStatistics;\n+import org.apache.beam.sdk.extensions.sql.meta.BeamSqlTable;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.testing.PAssert;\n+import org.apache.beam.sdk.testing.TestPipeline;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.junit.Assert;\n+import org.junit.Rule;\n+import org.junit.Test;\n+\n+/** Test for BeamKafkaCSVTable. */\n+public abstract class BeamKafkaTableTest {\n+  @Rule public TestPipeline pipeline = TestPipeline.create();\n+\n+  protected static final List<String> TOPICS = ImmutableList.of(\"topic1\", \"topic2\");\n+\n+  private static final Map<String, BeamSqlTable> tables = new HashMap<>();\n+\n+  protected static BeamSqlEnv env = BeamSqlEnv.readOnly(\"test\", tables);\n+\n+  protected abstract KafkaTestRecord<?> createKafkaTestRecord(String key, int i, long timestamp);\n+\n+  protected abstract KafkaTestTable getTestTable(int numberOfPartitions);\n+\n+  protected abstract BeamKafkaTable getBeamKafkaTable();\n+\n+  protected abstract PCollection<KV<byte[], byte[]>> applyRowToBytesKV(PCollection<Row> rows);\n+\n+  protected abstract List<Object> listFrom(int i);\n+\n+  protected abstract Schema getSchema();\n+\n+  @Test\n+  public void testOrderedArrivalSinglePartitionRate() {\n+    KafkaTestTable table = getTestTable(1);\n+    for (int i = 0; i < 100; i++) {\n+      table.addRecord(createKafkaTestRecord(\"k\" + i, i, 500L * i));\n+    }\n+\n+    BeamTableStatistics stats = table.getTableStatistics(null);\n+    Assert.assertEquals(2d, stats.getRate(), 0.001);\n+  }\n+\n+  @Test\n+  public void testOrderedArrivalMultiplePartitionsRate() {\n+    KafkaTestTable table = getTestTable(3);\n+    for (int i = 0; i < 100; i++) {\n+      table.addRecord(createKafkaTestRecord(\"k\" + i, i, 500L * i));\n+    }\n+\n+    BeamTableStatistics stats = table.getTableStatistics(null);\n+    Assert.assertEquals(2d, stats.getRate(), 0.001);\n+  }\n+\n+  @Test\n+  public void testOnePartitionAheadRate() {\n+    KafkaTestTable table = getTestTable(3);\n+    for (int i = 0; i < 100; i++) {\n+      table.addRecord(createKafkaTestRecord(\"1\", i, 1000L * i));\n+      table.addRecord(createKafkaTestRecord(\"2\", i, 500L * i));\n+    }\n+\n+    table.setNumberOfRecordsForRate(20);\n+    BeamTableStatistics stats = table.getTableStatistics(null);\n+    Assert.assertEquals(1d, stats.getRate(), 0.001);\n+  }\n+\n+  @Test\n+  public void testLateRecords() {\n+    KafkaTestTable table = getTestTable(3);\n+\n+    table.addRecord(createKafkaTestRecord(\"1\", 132, 1000L));\n+    for (int i = 0; i < 98; i++) {\n+      table.addRecord(createKafkaTestRecord(\"1\", i, 500L));\n+    }\n+    table.addRecord(createKafkaTestRecord(\"1\", 133, 2000L));\n+\n+    table.setNumberOfRecordsForRate(200);\n+    BeamTableStatistics stats = table.getTableStatistics(null);\n+    Assert.assertEquals(1d, stats.getRate(), 0.001);\n+  }\n+\n+  @Test\n+  public void testAllLate() {\n+    KafkaTestTable table = getTestTable(3);\n+\n+    table.addRecord(createKafkaTestRecord(\"1\", 132, 1000L));\n+    for (int i = 0; i < 98; i++) {\n+      table.addRecord(createKafkaTestRecord(\"1\", i, 500L));\n+    }\n+\n+    table.setNumberOfRecordsForRate(200);\n+    BeamTableStatistics stats = table.getTableStatistics(null);\n+    Assert.assertTrue(stats.isUnknown());\n+  }\n+\n+  @Test\n+  public void testEmptyPartitionsRate() {\n+    KafkaTestTable table = getTestTable(3);\n+    BeamTableStatistics stats = table.getTableStatistics(null);\n+    Assert.assertTrue(stats.isUnknown());\n+  }\n+\n+  @Test\n+  public void allTheRecordsSameTimeRate() {\n+    KafkaTestTable table = getTestTable(3);\n+    for (int i = 0; i < 100; i++) {\n+      table.addRecord(createKafkaTestRecord(\"key\" + i, i, 1000L));\n+    }\n+    BeamTableStatistics stats = table.getTableStatistics(null);\n+    Assert.assertTrue(stats.isUnknown());\n+  }\n+\n+  @Test\n+  public void testRecorderDecoder() {\n+    BeamKafkaTable kafkaTable = getBeamKafkaTable();\n+\n+    PCollection<Row> initialRows = pipeline.apply(Create.of(generateRow(1), generateRow(2)));\n+\n+    PCollection<KV<byte[], byte[]>> bytesKV = applyRowToBytesKV(initialRows);\n+    PCollection<Row> result = bytesKV.apply(kafkaTable.getPTransformForInput());\n+\n+    PAssert.that(result).containsInAnyOrder(generateRow(1), generateRow(2));\n+    pipeline.run();\n+  }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "488562713d863377f6b33730f82b39cfda207163"}, "originalPosition": 152}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "4bed87cd47141ce9240e2cedfb60c95c2598dfc4", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/4bed87cd47141ce9240e2cedfb60c95c2598dfc4", "committedDate": "2020-10-06T15:38:15Z", "message": "Remove generification of KafkaTestRecord"}, "afterCommit": {"oid": "048f3801661e190bb84058fddf6d7bc26a13a3f5", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/048f3801661e190bb84058fddf6d7bc26a13a3f5", "committedDate": "2020-10-12T16:12:06Z", "message": "Remove generification of KafkaTestRecord"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA2OTM3MDE2", "url": "https://github.com/apache/beam/pull/12827#pullrequestreview-506937016", "createdAt": "2020-10-12T21:45:40Z", "commit": {"oid": "38a0901b3ae9c5185826520330dbc5edf28d0614"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xMlQyMTo0NTo0MVrOHgOSxA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xMlQyMzowMjo0MVrOHgP3sg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzU1MDY2MA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              /** Returns encoded payload for the tested format. */\n          \n          \n            \n              /** Returns encoded payload in the tested format corresponding to the row in `generateRow(i)`. */", "url": "https://github.com/apache/beam/pull/12827#discussion_r503550660", "createdAt": "2020-10-12T21:45:41Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/meta/provider/kafka/BeamKafkaTableTest.java", "diffHunk": "@@ -0,0 +1,170 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.meta.provider.kafka;\n+\n+import java.util.List;\n+import org.apache.beam.sdk.extensions.sql.impl.BeamTableStatistics;\n+import org.apache.beam.sdk.testing.PAssert;\n+import org.apache.beam.sdk.testing.TestPipeline;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.apache.beam.sdk.transforms.MapElements;\n+import org.apache.beam.sdk.transforms.SimpleFunction;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.junit.Assert;\n+import org.junit.Rule;\n+import org.junit.Test;\n+\n+/** Test utility for BeamKafkaTable implementations. */\n+public abstract class BeamKafkaTableTest {\n+  @Rule public TestPipeline pipeline = TestPipeline.create();\n+\n+  protected static final List<String> TOPICS = ImmutableList.of(\"topic1\", \"topic2\");\n+\n+  /** Returns proper implementation of KafkaTestTable for the tested format */\n+  protected abstract KafkaTestTable getTestTable(int numberOfPartitions);\n+\n+  /** Returns proper implementation of BeamKafkaTable for the tested format */\n+  protected abstract BeamKafkaTable getBeamKafkaTable();\n+\n+  /** Returns encoded payload for the tested format. */", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "38a0901b3ae9c5185826520330dbc5edf28d0614"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzU1MjM5NQ==", "bodyText": "nit: I think this is cleaner inlined, it doesn't look like its used anywhere else.", "url": "https://github.com/apache/beam/pull/12827#discussion_r503552395", "createdAt": "2020-10-12T21:50:36Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/meta/provider/kafka/KafkaTestTable.java", "diffHunk": "@@ -73,6 +77,10 @@ public void setNumberOfRecordsForRate(int numberOfRecordsForRate) {\n     this.numberOfRecordsForRate = numberOfRecordsForRate;\n   }\n \n+  private byte[] getRecordValueBytes(KafkaTestRecord record) {\n+    return record.getValue().toByteArray();\n+  }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "38a0901b3ae9c5185826520330dbc5edf28d0614"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzU1NTYyOA==", "bodyText": "I don't think BeamKafkaTable#getTable is used, can we get rid of it?", "url": "https://github.com/apache/beam/pull/12827#discussion_r503555628", "createdAt": "2020-10-12T21:59:27Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/kafka/BeamKafkaTable.java", "diffHunk": "@@ -91,12 +91,14 @@ public BeamKafkaTable updateConsumerProperties(Map<String, Object> configUpdates\n     return PCollection.IsBounded.UNBOUNDED;\n   }\n \n-  public abstract PTransform<PCollection<KV<byte[], byte[]>>, PCollection<Row>>\n+  protected abstract PTransform<PCollection<KV<byte[], byte[]>>, PCollection<Row>>\n       getPTransformForInput();\n \n-  public abstract PTransform<PCollection<Row>, PCollection<KV<byte[], byte[]>>>\n+  protected abstract PTransform<PCollection<Row>, PCollection<KV<byte[], byte[]>>>\n       getPTransformForOutput();\n \n+  protected abstract BeamKafkaTable getTable();\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "38a0901b3ae9c5185826520330dbc5edf28d0614"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzU3NjQ5OA==", "bodyText": "The tests above this point are the only ones that use KafkaTestTable, and they're only exercising the getTableStatistics method, which never deserializes any records. So:\n\nWe shouldn't really need to repeat these tests for each payload format.\nWe don't need a separate KafkaTestTableCSV and KafkaTestTableAvro. There could just be a single concrete KafkaTestTable that raises an error in getPTransformFor{Input,Output}.\n\nI'm fine if we don't worry about (1) for now, but I'd like to address (2) for clarity.", "url": "https://github.com/apache/beam/pull/12827#discussion_r503576498", "createdAt": "2020-10-12T23:02:41Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/meta/provider/kafka/BeamKafkaTableTest.java", "diffHunk": "@@ -0,0 +1,170 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.meta.provider.kafka;\n+\n+import java.util.List;\n+import org.apache.beam.sdk.extensions.sql.impl.BeamTableStatistics;\n+import org.apache.beam.sdk.testing.PAssert;\n+import org.apache.beam.sdk.testing.TestPipeline;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.apache.beam.sdk.transforms.MapElements;\n+import org.apache.beam.sdk.transforms.SimpleFunction;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.junit.Assert;\n+import org.junit.Rule;\n+import org.junit.Test;\n+\n+/** Test utility for BeamKafkaTable implementations. */\n+public abstract class BeamKafkaTableTest {\n+  @Rule public TestPipeline pipeline = TestPipeline.create();\n+\n+  protected static final List<String> TOPICS = ImmutableList.of(\"topic1\", \"topic2\");\n+\n+  /** Returns proper implementation of KafkaTestTable for the tested format */\n+  protected abstract KafkaTestTable getTestTable(int numberOfPartitions);\n+\n+  /** Returns proper implementation of BeamKafkaTable for the tested format */\n+  protected abstract BeamKafkaTable getBeamKafkaTable();\n+\n+  /** Returns encoded payload for the tested format. */\n+  protected abstract byte[] generateEncodedPayload(int i);\n+\n+  /** Provides a deterministic row from the given integer. */\n+  protected abstract Row generateRow(int i);\n+\n+  @Test\n+  public void testOrderedArrivalSinglePartitionRate() {\n+    KafkaTestTable table = getTestTable(1);\n+    for (int i = 0; i < 100; i++) {\n+      table.addRecord(createKafkaTestRecord(\"k\" + i, i, 500L * i));\n+    }\n+\n+    BeamTableStatistics stats = table.getTableStatistics(null);\n+    Assert.assertEquals(2d, stats.getRate(), 0.001);\n+  }\n+\n+  @Test\n+  public void testOrderedArrivalMultiplePartitionsRate() {\n+    KafkaTestTable table = getTestTable(3);\n+    for (int i = 0; i < 100; i++) {\n+      table.addRecord(createKafkaTestRecord(\"k\" + i, i, 500L * i));\n+    }\n+\n+    BeamTableStatistics stats = table.getTableStatistics(null);\n+    Assert.assertEquals(2d, stats.getRate(), 0.001);\n+  }\n+\n+  @Test\n+  public void testOnePartitionAheadRate() {\n+    KafkaTestTable table = getTestTable(3);\n+    for (int i = 0; i < 100; i++) {\n+      table.addRecord(createKafkaTestRecord(\"1\", i, 1000L * i));\n+      table.addRecord(createKafkaTestRecord(\"2\", i, 500L * i));\n+    }\n+\n+    table.setNumberOfRecordsForRate(20);\n+    BeamTableStatistics stats = table.getTableStatistics(null);\n+    Assert.assertEquals(1d, stats.getRate(), 0.001);\n+  }\n+\n+  @Test\n+  public void testLateRecords() {\n+    KafkaTestTable table = getTestTable(3);\n+\n+    table.addRecord(createKafkaTestRecord(\"1\", 132, 1000L));\n+    for (int i = 0; i < 98; i++) {\n+      table.addRecord(createKafkaTestRecord(\"1\", i, 500L));\n+    }\n+    table.addRecord(createKafkaTestRecord(\"1\", 133, 2000L));\n+\n+    table.setNumberOfRecordsForRate(200);\n+    BeamTableStatistics stats = table.getTableStatistics(null);\n+    Assert.assertEquals(1d, stats.getRate(), 0.001);\n+  }\n+\n+  @Test\n+  public void testAllLate() {\n+    KafkaTestTable table = getTestTable(3);\n+\n+    table.addRecord(createKafkaTestRecord(\"1\", 132, 1000L));\n+    for (int i = 0; i < 98; i++) {\n+      table.addRecord(createKafkaTestRecord(\"1\", i, 500L));\n+    }\n+\n+    table.setNumberOfRecordsForRate(200);\n+    BeamTableStatistics stats = table.getTableStatistics(null);\n+    Assert.assertTrue(stats.isUnknown());\n+  }\n+\n+  @Test\n+  public void testEmptyPartitionsRate() {\n+    KafkaTestTable table = getTestTable(3);\n+    BeamTableStatistics stats = table.getTableStatistics(null);\n+    Assert.assertTrue(stats.isUnknown());\n+  }\n+\n+  @Test\n+  public void allTheRecordsSameTimeRate() {\n+    KafkaTestTable table = getTestTable(3);\n+    for (int i = 0; i < 100; i++) {\n+      table.addRecord(createKafkaTestRecord(\"key\" + i, i, 1000L));\n+    }\n+    BeamTableStatistics stats = table.getTableStatistics(null);\n+    Assert.assertTrue(stats.isUnknown());\n+  }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "38a0901b3ae9c5185826520330dbc5edf28d0614"}, "originalPosition": 132}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "07782776d2e351a03e7275836be1884dc088b98b", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/07782776d2e351a03e7275836be1884dc088b98b", "committedDate": "2020-10-13T13:22:32Z", "message": "[BEAM-10885] Add Avro support to Kafka table provider"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "986c21e2f680cdce60235af0be8df96ce99be1c2", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/986c21e2f680cdce60235af0be8df96ce99be1c2", "committedDate": "2020-10-13T13:22:32Z", "message": "Remove booleans, use List of values"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "56802e30d18a98cca37ee6d9bdb8a522c2022379", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/56802e30d18a98cca37ee6d9bdb8a522c2022379", "committedDate": "2020-10-13T13:22:32Z", "message": "Fixes after CR"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1a7462d67098e341d2377d1c0e18ca238190f9bc", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/1a7462d67098e341d2377d1c0e18ca238190f9bc", "committedDate": "2020-10-13T13:22:32Z", "message": "Change payloadFormat to format like in text table provider"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e607bc6042ef423ece8a83b2980922fdf0984da9", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/e607bc6042ef423ece8a83b2980922fdf0984da9", "committedDate": "2020-10-13T13:22:32Z", "message": "Fix checkstyle"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "570eee6846fc52151487ee61e60c8361fab4f80b", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/570eee6846fc52151487ee61e60c8361fab4f80b", "committedDate": "2020-10-13T13:22:33Z", "message": "Use SimpleFunction instead of SerializableFunction"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c2b8bf803773ea81aab9aa1ee52473f2210b000b", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/c2b8bf803773ea81aab9aa1ee52473f2210b000b", "committedDate": "2020-10-13T13:22:33Z", "message": "Remove getSchema() and listFrom(), make abstract generateRow, add generateEncodedPayload(i)"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "af435332f42a92beee9a9c3f6f54d4f218745c19", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/af435332f42a92beee9a9c3f6f54d4f218745c19", "committedDate": "2020-10-13T13:22:33Z", "message": "Remove generification of KafkaTestRecord"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "14405f98b2aedfd15a6545b43728f440259d76f3", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/14405f98b2aedfd15a6545b43728f440259d76f3", "committedDate": "2020-10-13T13:22:33Z", "message": "Add missing close paren"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4f7cd0016a5865dc767bd4ed75d52554914c9e53", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/4f7cd0016a5865dc767bd4ed75d52554914c9e53", "committedDate": "2020-10-13T13:22:33Z", "message": "Get rid of getTable() and KafkaTestTable inheritance"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "76b2e51dac47411d13284e120bec675921d3159b", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/76b2e51dac47411d13284e120bec675921d3159b", "committedDate": "2020-10-13T13:22:33Z", "message": "Fix comment"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0b39204d71818fccf4bf3ef9d765387477f063ba", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/0b39204d71818fccf4bf3ef9d765387477f063ba", "committedDate": "2020-10-13T13:22:33Z", "message": "Inline getRecordValueBytes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5f866ef478fe5f093e7e10f61db878279db0f339", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/5f866ef478fe5f093e7e10f61db878279db0f339", "committedDate": "2020-10-13T13:22:33Z", "message": "Remove generification of generateProducerRecord"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "23894dabb30c2e59a6fcf8354b5fc595559c54bd", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/23894dabb30c2e59a6fcf8354b5fc595559c54bd", "committedDate": "2020-10-13T13:22:34Z", "message": "Add full-stops to javadocs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d1217994ff3cf23eaed87ef157d23a1b7abd309b", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/d1217994ff3cf23eaed87ef157d23a1b7abd309b", "committedDate": "2020-10-13T13:22:34Z", "message": "Move statistics tests to separate file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1f930ef4e55e527c6b78dcf667a8fe1f821079d5", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/1f930ef4e55e527c6b78dcf667a8fe1f821079d5", "committedDate": "2020-10-13T13:22:34Z", "message": "Throw exception instead of returning null."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "23c7188200f4c871f79e7705c8baef9b3a22f1dc", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/23c7188200f4c871f79e7705c8baef9b3a22f1dc", "committedDate": "2020-10-13T13:22:34Z", "message": "Update create-external-table.md"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1705c7bfabbf361abbde250a9ebed38ab3a0f50e", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/1705c7bfabbf361abbde250a9ebed38ab3a0f50e", "committedDate": "2020-10-13T13:22:34Z", "message": "Update CHANGES.md"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "33ebefa24080b03ced7b31f774ad19a72e3e96c1", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/33ebefa24080b03ced7b31f774ad19a72e3e96c1", "committedDate": "2020-10-13T13:17:30Z", "message": "Update CHANGES.md"}, "afterCommit": {"oid": "1705c7bfabbf361abbde250a9ebed38ab3a0f50e", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/1705c7bfabbf361abbde250a9ebed38ab3a0f50e", "committedDate": "2020-10-13T13:22:34Z", "message": "Update CHANGES.md"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "97ecb909a5671281b78713e77aa93a612497201d", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/97ecb909a5671281b78713e77aa93a612497201d", "committedDate": "2020-10-13T13:48:12Z", "message": "Use ByteArraySerializer as kafka value serializer"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA3NjcwNzMw", "url": "https://github.com/apache/beam/pull/12827#pullrequestreview-507670730", "createdAt": "2020-10-13T17:24:30Z", "commit": {"oid": "97ecb909a5671281b78713e77aa93a612497201d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxNzoyNDozMFrOHgxukw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxNzoyNDozMFrOHgxukw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDEzMTIxOQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            * Support for avro format in Kafka Table added ([BEAM-10885](https://issues.apache.org/jira/browse/BEAM-10885))\n          \n          \n            \n            * Added support for avro payload format in Beam SQL Kafka Table ([BEAM-10885](https://issues.apache.org/jira/browse/BEAM-10885))", "url": "https://github.com/apache/beam/pull/12827#discussion_r504131219", "createdAt": "2020-10-13T17:24:30Z", "author": {"login": "TheNeuralBit"}, "path": "CHANGES.md", "diffHunk": "@@ -61,7 +61,7 @@\n * Support for X source added (Java/Python) ([BEAM-X](https://issues.apache.org/jira/browse/BEAM-X)).\n \n ## New Features / Improvements\n-\n+* Support for avro format in Kafka Table added ([BEAM-10885](https://issues.apache.org/jira/browse/BEAM-10885))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "97ecb909a5671281b78713e77aa93a612497201d"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA3NjczODc1", "url": "https://github.com/apache/beam/pull/12827#pullrequestreview-507673875", "createdAt": "2020-10-13T17:28:39Z", "commit": {"oid": "97ecb909a5671281b78713e77aa93a612497201d"}, "state": "APPROVED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxNzoyODozOVrOHgx4BA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QyMzo1MDo0M1rOHg9Wiw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDEzMzYzNg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            ### Supported Payload\n          \n          \n            \n            ### Supported Payload Formats", "url": "https://github.com/apache/beam/pull/12827#discussion_r504133636", "createdAt": "2020-10-13T17:28:39Z", "author": {"login": "TheNeuralBit"}, "path": "website/www/site/content/en/documentation/dsls/sql/extensions/create-external-table.md", "diffHunk": "@@ -313,9 +315,12 @@ Write Mode supports writing to a topic.\n \n ### Supported Payload", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "97ecb909a5671281b78713e77aa93a612497201d"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDEzNDU5MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                {`csv`, `avro`}, capitalization does not matter. Defaults to `csv`.\n          \n          \n            \n                {`csv`, `avro`}. Defaults to `csv`.", "url": "https://github.com/apache/beam/pull/12827#discussion_r504134591", "createdAt": "2020-10-13T17:30:18Z", "author": {"login": "TheNeuralBit"}, "path": "website/www/site/content/en/documentation/dsls/sql/extensions/create-external-table.md", "diffHunk": "@@ -294,14 +294,16 @@ KafkaIO is experimental in Beam SQL.\n CREATE EXTERNAL TABLE [ IF NOT EXISTS ] tableName (tableElement [, tableElement ]*)\n TYPE kafka\n LOCATION 'kafka://localhost:2181/brokers'\n-TBLPROPERTIES '{\"bootstrap.servers\":\"localhost:9092\", \"topics\": [\"topic1\", \"topic2\"]}'\n+TBLPROPERTIES '{\"bootstrap.servers\":\"localhost:9092\", \"topics\": [\"topic1\", \"topic2\"], \"format\": \"avro\"}'\n ```\n \n *   `LOCATION`: The Kafka topic URL.\n *   `TBLPROPERTIES`:\n     *   `bootstrap.servers`: Optional. Allows you to specify the bootstrap\n         server.\n     *   `topics`: Optional. Allows you to specify specific topics.\n+    *   `format`: Optional. Allows you to specify the Kafka values format. Possible values are\n+    {`csv`, `avro`}, capitalization does not matter. Defaults to `csv`.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "97ecb909a5671281b78713e77aa93a612497201d"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDMyMTY3NQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            *   CSV (default)\n          \n          \n            \n                *   Beam parses the messages, attempting to parse fields according to the\n          \n          \n            \n                    types specified in the schema.\n          \n          \n            \n            *   Avro\n          \n          \n            \n                *   Beam parses the messages, attempting to parse fields according to the\n          \n          \n            \n                    types specified in the schema. Avro schema is automatically deduced.\n          \n          \n            \n            *   CSV (default)\n          \n          \n            \n                *   Beam parses the messages, attempting to parse fields according to the\n          \n          \n            \n                    types specified in the schema.\n          \n          \n            \n            *   Avro\n          \n          \n            \n                *   An Avro schema is automatically generated from the specified field\n          \n          \n            \n                    types. It is used to parse incoming messages and to format outgoing\n          \n          \n            \n                    messages.", "url": "https://github.com/apache/beam/pull/12827#discussion_r504321675", "createdAt": "2020-10-13T23:50:43Z", "author": {"login": "TheNeuralBit"}, "path": "website/www/site/content/en/documentation/dsls/sql/extensions/create-external-table.md", "diffHunk": "@@ -313,9 +315,12 @@ Write Mode supports writing to a topic.\n \n ### Supported Payload\n \n-*   CSV\n+*   CSV (default)\n     *   Beam parses the messages, attempting to parse fields according to the\n         types specified in the schema.\n+*   Avro\n+    *   Beam parses the messages, attempting to parse fields according to the\n+        types specified in the schema. Avro schema is automatically deduced.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "97ecb909a5671281b78713e77aa93a612497201d"}, "originalPosition": 28}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d15b2f7f0e8dd7927346ae4a14738d7cd86b898f", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/d15b2f7f0e8dd7927346ae4a14738d7cd86b898f", "committedDate": "2020-10-13T23:51:47Z", "message": "Update CHANGES.md"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ed18322a79a0fa8c6a88ca7ff6b1803a55b743aa", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/ed18322a79a0fa8c6a88ca7ff6b1803a55b743aa", "committedDate": "2020-10-13T23:52:01Z", "message": "Update website/www/site/content/en/documentation/dsls/sql/extensions/create-external-table.md"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5d1d7a9bb05e091100aa84e22c66ea1f1e99cc04", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/5d1d7a9bb05e091100aa84e22c66ea1f1e99cc04", "committedDate": "2020-10-13T23:52:11Z", "message": "Update website/www/site/content/en/documentation/dsls/sql/extensions/create-external-table.md"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d6a14e9abc8b93850fa3d08c9dfa72d9e4fd78ee", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/d6a14e9abc8b93850fa3d08c9dfa72d9e4fd78ee", "committedDate": "2020-10-13T23:52:25Z", "message": "Update website/www/site/content/en/documentation/dsls/sql/extensions/create-external-table.md"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2705, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}