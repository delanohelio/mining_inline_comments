{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQyNzA0NjEw", "number": 12150, "reviewThreads": {"totalCount": 46, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxMzozOTozMlrOEKg-Wg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQwMTowNjowNFrOERqozA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5NDYxNDY2OnYy", "diffSide": "RIGHT", "path": "release/src/main/python-release/python_release_automation.sh", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxMzozOTozMlrOGrmVtQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QxNjoxODo1NVrOGuGCYg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM3MDEwMQ==", "bodyText": "Should we also add python-3.8 in release/src/main/scripts/build_release_candidate.sh?\n\n  \n    \n      beam/release/src/main/scripts/build_release_candidate.sh\n    \n    \n         Line 52\n      in\n      1a858c6\n    \n    \n    \n    \n\n        \n          \n           PYTHON_VER=(\"python2.7\" \"python3.5\" \"python3.6\" \"python3.7\")", "url": "https://github.com/apache/beam/pull/12150#discussion_r448370101", "createdAt": "2020-07-01T13:39:32Z", "author": {"login": "mik-laj"}, "path": "release/src/main/python-release/python_release_automation.sh", "diffHunk": "@@ -19,7 +19,7 @@\n source release/src/main/python-release/run_release_candidate_python_quickstart.sh\n source release/src/main/python-release/run_release_candidate_python_mobile_gaming.sh\n \n-for version in 2.7 3.5 3.6 3.7\n+for version in 2.7 3.5 3.6 3.7 3.8", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1a858c652347251e074a2ea02a7905775674520e"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODQ2MDA3Mg==", "bodyText": "Also \n  \n    \n      beam/release/src/main/scripts/publish_docker_images.sh\n    \n    \n         Line 30\n      in\n      1a858c6\n    \n    \n    \n    \n\n        \n          \n           PYTHON_VER=(\"python2.7\" \"python3.5\" \"python3.6\" \"python3.7\")", "url": "https://github.com/apache/beam/pull/12150#discussion_r448460072", "createdAt": "2020-07-01T15:54:05Z", "author": {"login": "ibzib"}, "path": "release/src/main/python-release/python_release_automation.sh", "diffHunk": "@@ -19,7 +19,7 @@\n source release/src/main/python-release/run_release_candidate_python_quickstart.sh\n source release/src/main/python-release/run_release_candidate_python_mobile_gaming.sh\n \n-for version in 2.7 3.5 3.6 3.7\n+for version in 2.7 3.5 3.6 3.7 3.8", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM3MDEwMQ=="}, "originalCommit": {"oid": "1a858c652347251e074a2ea02a7905775674520e"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODQ2MjgyNg==", "bodyText": "I think so. If we are not ready to release 3.8, we can choose to not upload them to pypi.", "url": "https://github.com/apache/beam/pull/12150#discussion_r448462826", "createdAt": "2020-07-01T15:58:25Z", "author": {"login": "aaltay"}, "path": "release/src/main/python-release/python_release_automation.sh", "diffHunk": "@@ -19,7 +19,7 @@\n source release/src/main/python-release/run_release_candidate_python_quickstart.sh\n source release/src/main/python-release/run_release_candidate_python_mobile_gaming.sh\n \n-for version in 2.7 3.5 3.6 3.7\n+for version in 2.7 3.5 3.6 3.7 3.8", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM3MDEwMQ=="}, "originalCommit": {"oid": "1a858c652347251e074a2ea02a7905775674520e"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDc5Mjc3MQ==", "bodyText": "It will be the most consistent to introduce 3.8 everywhere at the same time to avoid confusion during release and to avoid filtering.\nWhat do you think about removing cp38  from \n  \n    \n      beam/.github/workflows/build_wheels.yml\n    \n    \n         Line 127\n      in\n      c7b0450\n    \n    \n    \n    \n\n        \n          \n           CIBW_BUILD: cp27-* cp35-* cp36-* cp37-* cp38-* \n        \n    \n  \n\n ?", "url": "https://github.com/apache/beam/pull/12150#discussion_r450792771", "createdAt": "2020-07-07T11:24:26Z", "author": {"login": "TobKed"}, "path": "release/src/main/python-release/python_release_automation.sh", "diffHunk": "@@ -19,7 +19,7 @@\n source release/src/main/python-release/run_release_candidate_python_quickstart.sh\n source release/src/main/python-release/run_release_candidate_python_mobile_gaming.sh\n \n-for version in 2.7 3.5 3.6 3.7\n+for version in 2.7 3.5 3.6 3.7 3.8", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM3MDEwMQ=="}, "originalCommit": {"oid": "1a858c652347251e074a2ea02a7905775674520e"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDk4NjU5NA==", "bodyText": "Please keep Py3.8, we should assume Py3.8 to be a supported version and we will release artifacts for Py38 with next release.", "url": "https://github.com/apache/beam/pull/12150#discussion_r450986594", "createdAt": "2020-07-07T16:18:55Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/python-release/python_release_automation.sh", "diffHunk": "@@ -19,7 +19,7 @@\n source release/src/main/python-release/run_release_candidate_python_quickstart.sh\n source release/src/main/python-release/run_release_candidate_python_mobile_gaming.sh\n \n-for version in 2.7 3.5 3.6 3.7\n+for version in 2.7 3.5 3.6 3.7 3.8", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODM3MDEwMQ=="}, "originalCommit": {"oid": "1a858c652347251e074a2ea02a7905775674520e"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5NTE5MzU5OnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/build_release_candidate.sh", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxNjowMDo0MVrOGrsFXA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQxNzoxNTowMFrOGsWmtw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODQ2NDIyMA==", "bodyText": "This changes from a py2 virtualenv to py3 venv. I do not know if that makes a difference. Pointing out in case this is important.", "url": "https://github.com/apache/beam/pull/12150#discussion_r448464220", "createdAt": "2020-07-01T16:00:41Z", "author": {"login": "aaltay"}, "path": "release/src/main/scripts/build_release_candidate.sh", "diffHunk": "@@ -170,26 +174,50 @@ if [[ $confirmation = \"y\" ]]; then\n   git clone ${GIT_REPO_URL}\n   cd ${BEAM_ROOT_DIR}\n   git checkout ${RELEASE_BRANCH}\n+  git push origin \"${RELEASE_BRANCH}\"\n+  RELEASE_COMMIT=$(git rev-parse --verify HEAD)\n \n-  echo '-------------------Generating Python Artifacts-----------------'\n-  cd sdks/python\n-  virtualenv ${LOCAL_PYTHON_VIRTUALENV}\n+  echo '-------------------Creating Python Virtualenv-----------------'\n+  python3 -m venv ${LOCAL_PYTHON_VIRTUALENV}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1a858c652347251e074a2ea02a7905775674520e"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODkyODMwMQ==", "bodyText": "Thanks for pointing this out. I wasn't sure which python version I should use, but since 2 is sunsetting I decided to use 3 . Now I am thinking is using fstrings was the good idea since it requires 3.6+.\nWDYT @tvalentyn ?", "url": "https://github.com/apache/beam/pull/12150#discussion_r448928301", "createdAt": "2020-07-02T11:15:44Z", "author": {"login": "TobKed"}, "path": "release/src/main/scripts/build_release_candidate.sh", "diffHunk": "@@ -170,26 +174,50 @@ if [[ $confirmation = \"y\" ]]; then\n   git clone ${GIT_REPO_URL}\n   cd ${BEAM_ROOT_DIR}\n   git checkout ${RELEASE_BRANCH}\n+  git push origin \"${RELEASE_BRANCH}\"\n+  RELEASE_COMMIT=$(git rev-parse --verify HEAD)\n \n-  echo '-------------------Generating Python Artifacts-----------------'\n-  cd sdks/python\n-  virtualenv ${LOCAL_PYTHON_VIRTUALENV}\n+  echo '-------------------Creating Python Virtualenv-----------------'\n+  python3 -m venv ${LOCAL_PYTHON_VIRTUALENV}", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODQ2NDIyMA=="}, "originalCommit": {"oid": "1a858c652347251e074a2ea02a7905775674520e"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE2MDg4Nw==", "bodyText": "Python 3 sounds good. The version of Python 3 would likely be 3.6 or higher giving that most 3.5 is reaching EOL, so not too concerned about fstrings.", "url": "https://github.com/apache/beam/pull/12150#discussion_r449160887", "createdAt": "2020-07-02T17:15:00Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/build_release_candidate.sh", "diffHunk": "@@ -170,26 +174,50 @@ if [[ $confirmation = \"y\" ]]; then\n   git clone ${GIT_REPO_URL}\n   cd ${BEAM_ROOT_DIR}\n   git checkout ${RELEASE_BRANCH}\n+  git push origin \"${RELEASE_BRANCH}\"\n+  RELEASE_COMMIT=$(git rev-parse --verify HEAD)\n \n-  echo '-------------------Generating Python Artifacts-----------------'\n-  cd sdks/python\n-  virtualenv ${LOCAL_PYTHON_VIRTUALENV}\n+  echo '-------------------Creating Python Virtualenv-----------------'\n+  python3 -m venv ${LOCAL_PYTHON_VIRTUALENV}", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODQ2NDIyMA=="}, "originalCommit": {"oid": "1a858c652347251e074a2ea02a7905775674520e"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5NTE5NzcyOnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/download_github_actions_artifacts.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxNjowMTo0N1rOGrsH7A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQxNzoyMzowNlrOGsW3zQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODQ2NDg3Ng==", "bodyText": "Could you add descriptions here on how one would get this information, and/or add example values.", "url": "https://github.com/apache/beam/pull/12150#discussion_r448464876", "createdAt": "2020-07-01T16:01:47Z", "author": {"login": "aaltay"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,231 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/TobKed/beam/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1a858c652347251e074a2ea02a7905775674520e"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE2NTI2MQ==", "bodyText": "+1.\nI think auth information should be entered during execution as opposed to be passed as arguments to the script.\nIf you know what minimal permissions need to be granted to the personal access token, that could be helpful.", "url": "https://github.com/apache/beam/pull/12150#discussion_r449165261", "createdAt": "2020-07-02T17:23:06Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,231 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/TobKed/beam/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODQ2NDg3Ng=="}, "originalCommit": {"oid": "1a858c652347251e074a2ea02a7905775674520e"}, "originalPosition": 44}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5NTE5OTk0OnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/download_github_actions_artifacts.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxNjowMjoyM1rOGrsJRg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQxMjo0NToxOVrOGsLM-w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODQ2NTIyMg==", "bodyText": "Please rename this request or request_url", "url": "https://github.com/apache/beam/pull/12150#discussion_r448465222", "createdAt": "2020-07-01T16:02:23Z", "author": {"login": "ibzib"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,231 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/TobKed/beam/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+\n+  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n+  GITHUB_TOKEN = args.github_token\n+  USER_GITHUB_ID = args.github_user\n+  REPO_URL = args.repo_url\n+  RELEASE_BRANCH = args.release_branch\n+  RELEASE_COMMIT = args.release_commit\n+  ARTIFACTS_DIR = args.artifacts_dir\n+\n+\n+def requester(url, *args, return_raw_request=False, **kwargs):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1a858c652347251e074a2ea02a7905775674520e"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk3NDA3NQ==", "bodyText": "Sure. I will do it.", "url": "https://github.com/apache/beam/pull/12150#discussion_r448974075", "createdAt": "2020-07-02T12:45:19Z", "author": {"login": "TobKed"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,231 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/TobKed/beam/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+\n+  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n+  GITHUB_TOKEN = args.github_token\n+  USER_GITHUB_ID = args.github_user\n+  REPO_URL = args.repo_url\n+  RELEASE_BRANCH = args.release_branch\n+  RELEASE_COMMIT = args.release_commit\n+  ARTIFACTS_DIR = args.artifacts_dir\n+\n+\n+def requester(url, *args, return_raw_request=False, **kwargs):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODQ2NTIyMg=="}, "originalCommit": {"oid": "1a858c652347251e074a2ea02a7905775674520e"}, "originalPosition": 62}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5NTIwOTQ4OnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/download_github_actions_artifacts.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxNjowNTowOFrOGrsPVg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQwODo0NTozNlrOGxKOzg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODQ2Njc3NA==", "bodyText": "Would it be the release manager responsible for checking the commit id is what they want?\nCan we prevent the problem of someone running a one-off in the release branch with a PR and that becoming the latest wheel? Is it possible to verify that the commit id matches what user wants?", "url": "https://github.com/apache/beam/pull/12150#discussion_r448466774", "createdAt": "2020-07-01T16:05:08Z", "author": {"login": "aaltay"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,231 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/TobKed/beam/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+\n+  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n+  GITHUB_TOKEN = args.github_token\n+  USER_GITHUB_ID = args.github_user\n+  REPO_URL = args.repo_url\n+  RELEASE_BRANCH = args.release_branch\n+  RELEASE_COMMIT = args.release_commit\n+  ARTIFACTS_DIR = args.artifacts_dir\n+\n+\n+def requester(url, *args, return_raw_request=False, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", GITHUB_TOKEN), **kwargs)\n+  r.raise_for_status()\n+  if return_raw_request:\n+    return r\n+  return r.json()\n+\n+\n+def yes_or_no(question):\n+  \"\"\"Helper function to ask yes or no question\"\"\"\n+  reply = str(input(question + \" (y/n): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  if reply == \"n\":\n+    return False\n+  else:\n+    return yes_or_no(\"Uhhhh... please enter \")\n+\n+\n+def get_build_wheels_workflow_id():\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=REPO_URL)\n+  data = requester(url)\n+  return data[\"id\"]\n+\n+\n+def get_last_run(workflow_id):\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=REPO_URL, workflow_id=workflow_id)\n+  event_types = [\"push\", \"pull_request\"]\n+  runs = []\n+  for event in event_types:\n+    data = requester(\n+        url,\n+        params={\n+            \"event\": event, \"branch\": RELEASE_BRANCH\n+        },\n+    )\n+    runs.extend(data[\"workflow_runs\"])\n+\n+  filtered_commit_runs = list(\n+      filter(lambda w: w.get(\"head_sha\", \"\") == RELEASE_COMMIT, runs))\n+  if not filtered_commit_runs:\n+    workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+        workflow_id=workflow_id)\n+    raise Exception(f\"No runs for workflow. Verify at {workflow_web_url}\")\n+\n+  sorted_runs = sorted(\n+      filtered_commit_runs,\n+      key=lambda w: dateutil.parser.parse(w[\"created_at\"]),\n+      reverse=True,\n+  )\n+  last_run = sorted_runs[0]\n+  print(\n+      f\"Found last run. SHA: {RELEASE_COMMIT}, created_at: '{last_run['created_at']}', id: {last_run['id']}\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1a858c652347251e074a2ea02a7905775674520e"}, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDIwMTAzOA==", "bodyText": "Release commit will be taken as the last commit in the release branch in build_release_candidate.sh.\nThe workflow is searched by the event type, branch and commit sha. If any of these criteria are not met script will raise exception.\nI put this print in case of any doubts or to perform additional check is commit sha passed by build_release_candidate.sh is correct.\n@tvalentyn pointed out that we probably should support only \"push\" events what I applied. It should solve the problem you mentioned.\n#12150 (comment)", "url": "https://github.com/apache/beam/pull/12150#discussion_r454201038", "createdAt": "2020-07-14T08:45:36Z", "author": {"login": "TobKed"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,231 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/TobKed/beam/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+\n+  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n+  GITHUB_TOKEN = args.github_token\n+  USER_GITHUB_ID = args.github_user\n+  REPO_URL = args.repo_url\n+  RELEASE_BRANCH = args.release_branch\n+  RELEASE_COMMIT = args.release_commit\n+  ARTIFACTS_DIR = args.artifacts_dir\n+\n+\n+def requester(url, *args, return_raw_request=False, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", GITHUB_TOKEN), **kwargs)\n+  r.raise_for_status()\n+  if return_raw_request:\n+    return r\n+  return r.json()\n+\n+\n+def yes_or_no(question):\n+  \"\"\"Helper function to ask yes or no question\"\"\"\n+  reply = str(input(question + \" (y/n): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  if reply == \"n\":\n+    return False\n+  else:\n+    return yes_or_no(\"Uhhhh... please enter \")\n+\n+\n+def get_build_wheels_workflow_id():\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=REPO_URL)\n+  data = requester(url)\n+  return data[\"id\"]\n+\n+\n+def get_last_run(workflow_id):\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=REPO_URL, workflow_id=workflow_id)\n+  event_types = [\"push\", \"pull_request\"]\n+  runs = []\n+  for event in event_types:\n+    data = requester(\n+        url,\n+        params={\n+            \"event\": event, \"branch\": RELEASE_BRANCH\n+        },\n+    )\n+    runs.extend(data[\"workflow_runs\"])\n+\n+  filtered_commit_runs = list(\n+      filter(lambda w: w.get(\"head_sha\", \"\") == RELEASE_COMMIT, runs))\n+  if not filtered_commit_runs:\n+    workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+        workflow_id=workflow_id)\n+    raise Exception(f\"No runs for workflow. Verify at {workflow_web_url}\")\n+\n+  sorted_runs = sorted(\n+      filtered_commit_runs,\n+      key=lambda w: dateutil.parser.parse(w[\"created_at\"]),\n+      reverse=True,\n+  )\n+  last_run = sorted_runs[0]\n+  print(\n+      f\"Found last run. SHA: {RELEASE_COMMIT}, created_at: '{last_run['created_at']}', id: {last_run['id']}\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODQ2Njc3NA=="}, "originalCommit": {"oid": "1a858c652347251e074a2ea02a7905775674520e"}, "originalPosition": 116}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5NTIxNTUwOnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/download_github_actions_artifacts.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxNjowNjo1M1rOGrsTFg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QxMTo0Mzo0OVrOGt6zBg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODQ2NzczNA==", "bodyText": "What is (now - last_request) > 10: checking for?", "url": "https://github.com/apache/beam/pull/12150#discussion_r448467734", "createdAt": "2020-07-01T16:06:53Z", "author": {"login": "aaltay"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,231 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/TobKed/beam/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+\n+  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n+  GITHUB_TOKEN = args.github_token\n+  USER_GITHUB_ID = args.github_user\n+  REPO_URL = args.repo_url\n+  RELEASE_BRANCH = args.release_branch\n+  RELEASE_COMMIT = args.release_commit\n+  ARTIFACTS_DIR = args.artifacts_dir\n+\n+\n+def requester(url, *args, return_raw_request=False, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", GITHUB_TOKEN), **kwargs)\n+  r.raise_for_status()\n+  if return_raw_request:\n+    return r\n+  return r.json()\n+\n+\n+def yes_or_no(question):\n+  \"\"\"Helper function to ask yes or no question\"\"\"\n+  reply = str(input(question + \" (y/n): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  if reply == \"n\":\n+    return False\n+  else:\n+    return yes_or_no(\"Uhhhh... please enter \")\n+\n+\n+def get_build_wheels_workflow_id():\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=REPO_URL)\n+  data = requester(url)\n+  return data[\"id\"]\n+\n+\n+def get_last_run(workflow_id):\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=REPO_URL, workflow_id=workflow_id)\n+  event_types = [\"push\", \"pull_request\"]\n+  runs = []\n+  for event in event_types:\n+    data = requester(\n+        url,\n+        params={\n+            \"event\": event, \"branch\": RELEASE_BRANCH\n+        },\n+    )\n+    runs.extend(data[\"workflow_runs\"])\n+\n+  filtered_commit_runs = list(\n+      filter(lambda w: w.get(\"head_sha\", \"\") == RELEASE_COMMIT, runs))\n+  if not filtered_commit_runs:\n+    workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+        workflow_id=workflow_id)\n+    raise Exception(f\"No runs for workflow. Verify at {workflow_web_url}\")\n+\n+  sorted_runs = sorted(\n+      filtered_commit_runs,\n+      key=lambda w: dateutil.parser.parse(w[\"created_at\"]),\n+      reverse=True,\n+  )\n+  last_run = sorted_runs[0]\n+  print(\n+      f\"Found last run. SHA: {RELEASE_COMMIT}, created_at: '{last_run['created_at']}', id: {last_run['id']}\"\n+  )\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      workflow_id=last_run[\"id\"])\n+  print(f\"Verify at {workflow_web_url}\")\n+  print(\n+      f\"Optional upload to GCS will be available at:\\n\"\n+      f\"\\tgs://beam-wheels-staging/{RELEASE_BRANCH}/{RELEASE_COMMIT}-{workflow_id}/\"\n+  )\n+  return last_run\n+\n+\n+def validate_run(run_data):\n+  status = run_data[\"status\"]\n+  conclusion = run_data[\"conclusion\"]\n+  if status == \"completed\" and conclusion == \"success\":\n+    return run_data\n+\n+  url = run_data[\"url\"]\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      workflow_id=run_data[\"id\"])\n+  print(\n+      f\"Waiting for Workflow run {run_data['id']} to finish. Check on {workflow_web_url}\"\n+  )\n+  start_time = time.time()\n+  last_request = start_time\n+  spinner = itertools.cycle([\"|\", \"/\", \"-\", \"\\\\\"])\n+\n+  while True:\n+    now = time.time()\n+    elapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(now - start_time))\n+    print(\n+        f\"\\r {next(spinner)} Waiting to finish. Elapsed time: {elapsed_time}. \"\n+        f\"Current state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        end=\"\",\n+    )\n+\n+    time.sleep(0.3)\n+    if (now - last_request) > 10:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1a858c652347251e074a2ea02a7905775674520e"}, "originalPosition": 154}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDgwMjQzOA==", "bodyText": "It is interval time between next requests. I added variable request_interval which is more descriptive.", "url": "https://github.com/apache/beam/pull/12150#discussion_r450802438", "createdAt": "2020-07-07T11:43:49Z", "author": {"login": "TobKed"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,231 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/TobKed/beam/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+\n+  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n+  GITHUB_TOKEN = args.github_token\n+  USER_GITHUB_ID = args.github_user\n+  REPO_URL = args.repo_url\n+  RELEASE_BRANCH = args.release_branch\n+  RELEASE_COMMIT = args.release_commit\n+  ARTIFACTS_DIR = args.artifacts_dir\n+\n+\n+def requester(url, *args, return_raw_request=False, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", GITHUB_TOKEN), **kwargs)\n+  r.raise_for_status()\n+  if return_raw_request:\n+    return r\n+  return r.json()\n+\n+\n+def yes_or_no(question):\n+  \"\"\"Helper function to ask yes or no question\"\"\"\n+  reply = str(input(question + \" (y/n): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  if reply == \"n\":\n+    return False\n+  else:\n+    return yes_or_no(\"Uhhhh... please enter \")\n+\n+\n+def get_build_wheels_workflow_id():\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=REPO_URL)\n+  data = requester(url)\n+  return data[\"id\"]\n+\n+\n+def get_last_run(workflow_id):\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=REPO_URL, workflow_id=workflow_id)\n+  event_types = [\"push\", \"pull_request\"]\n+  runs = []\n+  for event in event_types:\n+    data = requester(\n+        url,\n+        params={\n+            \"event\": event, \"branch\": RELEASE_BRANCH\n+        },\n+    )\n+    runs.extend(data[\"workflow_runs\"])\n+\n+  filtered_commit_runs = list(\n+      filter(lambda w: w.get(\"head_sha\", \"\") == RELEASE_COMMIT, runs))\n+  if not filtered_commit_runs:\n+    workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+        workflow_id=workflow_id)\n+    raise Exception(f\"No runs for workflow. Verify at {workflow_web_url}\")\n+\n+  sorted_runs = sorted(\n+      filtered_commit_runs,\n+      key=lambda w: dateutil.parser.parse(w[\"created_at\"]),\n+      reverse=True,\n+  )\n+  last_run = sorted_runs[0]\n+  print(\n+      f\"Found last run. SHA: {RELEASE_COMMIT}, created_at: '{last_run['created_at']}', id: {last_run['id']}\"\n+  )\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      workflow_id=last_run[\"id\"])\n+  print(f\"Verify at {workflow_web_url}\")\n+  print(\n+      f\"Optional upload to GCS will be available at:\\n\"\n+      f\"\\tgs://beam-wheels-staging/{RELEASE_BRANCH}/{RELEASE_COMMIT}-{workflow_id}/\"\n+  )\n+  return last_run\n+\n+\n+def validate_run(run_data):\n+  status = run_data[\"status\"]\n+  conclusion = run_data[\"conclusion\"]\n+  if status == \"completed\" and conclusion == \"success\":\n+    return run_data\n+\n+  url = run_data[\"url\"]\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      workflow_id=run_data[\"id\"])\n+  print(\n+      f\"Waiting for Workflow run {run_data['id']} to finish. Check on {workflow_web_url}\"\n+  )\n+  start_time = time.time()\n+  last_request = start_time\n+  spinner = itertools.cycle([\"|\", \"/\", \"-\", \"\\\\\"])\n+\n+  while True:\n+    now = time.time()\n+    elapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(now - start_time))\n+    print(\n+        f\"\\r {next(spinner)} Waiting to finish. Elapsed time: {elapsed_time}. \"\n+        f\"Current state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        end=\"\",\n+    )\n+\n+    time.sleep(0.3)\n+    if (now - last_request) > 10:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODQ2NzczNA=="}, "originalCommit": {"oid": "1a858c652347251e074a2ea02a7905775674520e"}, "originalPosition": 154}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5NTIxODQ4OnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/download_github_actions_artifacts.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxNjowNzozOFrOGrsU2Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQxMjo0Njo0N1rOGsLQVQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODQ2ODE4NQ==", "bodyText": "Nit: consider renaming this, if yes_or_no(...) reads like if True", "url": "https://github.com/apache/beam/pull/12150#discussion_r448468185", "createdAt": "2020-07-01T16:07:38Z", "author": {"login": "ibzib"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,231 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/TobKed/beam/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+\n+  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n+  GITHUB_TOKEN = args.github_token\n+  USER_GITHUB_ID = args.github_user\n+  REPO_URL = args.repo_url\n+  RELEASE_BRANCH = args.release_branch\n+  RELEASE_COMMIT = args.release_commit\n+  ARTIFACTS_DIR = args.artifacts_dir\n+\n+\n+def requester(url, *args, return_raw_request=False, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", GITHUB_TOKEN), **kwargs)\n+  r.raise_for_status()\n+  if return_raw_request:\n+    return r\n+  return r.json()\n+\n+\n+def yes_or_no(question):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1a858c652347251e074a2ea02a7905775674520e"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk3NDkzMw==", "bodyText": "I change it to get_yes_or_no_answer. WDYT?", "url": "https://github.com/apache/beam/pull/12150#discussion_r448974933", "createdAt": "2020-07-02T12:46:47Z", "author": {"login": "TobKed"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,231 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/TobKed/beam/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+\n+  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n+  GITHUB_TOKEN = args.github_token\n+  USER_GITHUB_ID = args.github_user\n+  REPO_URL = args.repo_url\n+  RELEASE_BRANCH = args.release_branch\n+  RELEASE_COMMIT = args.release_commit\n+  ARTIFACTS_DIR = args.artifacts_dir\n+\n+\n+def requester(url, *args, return_raw_request=False, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", GITHUB_TOKEN), **kwargs)\n+  r.raise_for_status()\n+  if return_raw_request:\n+    return r\n+  return r.json()\n+\n+\n+def yes_or_no(question):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODQ2ODE4NQ=="}, "originalCommit": {"oid": "1a858c652347251e074a2ea02a7905775674520e"}, "originalPosition": 71}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5NTI0MTkxOnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/download_github_actions_artifacts.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxNjoxMzo1NVrOGrsjSA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQxMzowMDowMlrOGsLwPw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODQ3MTg4MA==", "bodyText": "I suppose it probably shouldn't be possible to have status == completed without a conclusion, but maybe this should be else just in case?", "url": "https://github.com/apache/beam/pull/12150#discussion_r448471880", "createdAt": "2020-07-01T16:13:55Z", "author": {"login": "ibzib"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,231 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/TobKed/beam/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+\n+  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n+  GITHUB_TOKEN = args.github_token\n+  USER_GITHUB_ID = args.github_user\n+  REPO_URL = args.repo_url\n+  RELEASE_BRANCH = args.release_branch\n+  RELEASE_COMMIT = args.release_commit\n+  ARTIFACTS_DIR = args.artifacts_dir\n+\n+\n+def requester(url, *args, return_raw_request=False, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", GITHUB_TOKEN), **kwargs)\n+  r.raise_for_status()\n+  if return_raw_request:\n+    return r\n+  return r.json()\n+\n+\n+def yes_or_no(question):\n+  \"\"\"Helper function to ask yes or no question\"\"\"\n+  reply = str(input(question + \" (y/n): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  if reply == \"n\":\n+    return False\n+  else:\n+    return yes_or_no(\"Uhhhh... please enter \")\n+\n+\n+def get_build_wheels_workflow_id():\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=REPO_URL)\n+  data = requester(url)\n+  return data[\"id\"]\n+\n+\n+def get_last_run(workflow_id):\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=REPO_URL, workflow_id=workflow_id)\n+  event_types = [\"push\", \"pull_request\"]\n+  runs = []\n+  for event in event_types:\n+    data = requester(\n+        url,\n+        params={\n+            \"event\": event, \"branch\": RELEASE_BRANCH\n+        },\n+    )\n+    runs.extend(data[\"workflow_runs\"])\n+\n+  filtered_commit_runs = list(\n+      filter(lambda w: w.get(\"head_sha\", \"\") == RELEASE_COMMIT, runs))\n+  if not filtered_commit_runs:\n+    workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+        workflow_id=workflow_id)\n+    raise Exception(f\"No runs for workflow. Verify at {workflow_web_url}\")\n+\n+  sorted_runs = sorted(\n+      filtered_commit_runs,\n+      key=lambda w: dateutil.parser.parse(w[\"created_at\"]),\n+      reverse=True,\n+  )\n+  last_run = sorted_runs[0]\n+  print(\n+      f\"Found last run. SHA: {RELEASE_COMMIT}, created_at: '{last_run['created_at']}', id: {last_run['id']}\"\n+  )\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      workflow_id=last_run[\"id\"])\n+  print(f\"Verify at {workflow_web_url}\")\n+  print(\n+      f\"Optional upload to GCS will be available at:\\n\"\n+      f\"\\tgs://beam-wheels-staging/{RELEASE_BRANCH}/{RELEASE_COMMIT}-{workflow_id}/\"\n+  )\n+  return last_run\n+\n+\n+def validate_run(run_data):\n+  status = run_data[\"status\"]\n+  conclusion = run_data[\"conclusion\"]\n+  if status == \"completed\" and conclusion == \"success\":\n+    return run_data\n+\n+  url = run_data[\"url\"]\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      workflow_id=run_data[\"id\"])\n+  print(\n+      f\"Waiting for Workflow run {run_data['id']} to finish. Check on {workflow_web_url}\"\n+  )\n+  start_time = time.time()\n+  last_request = start_time\n+  spinner = itertools.cycle([\"|\", \"/\", \"-\", \"\\\\\"])\n+\n+  while True:\n+    now = time.time()\n+    elapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(now - start_time))\n+    print(\n+        f\"\\r {next(spinner)} Waiting to finish. Elapsed time: {elapsed_time}. \"\n+        f\"Current state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        end=\"\",\n+    )\n+\n+    time.sleep(0.3)\n+    if (now - last_request) > 10:\n+      last_request = now\n+      run_data = requester(url)\n+      status = run_data[\"status\"]\n+      conclusion = run_data[\"conclusion\"]\n+      if status != \"completed\":\n+        continue\n+      elif conclusion == \"success\":\n+        print(\n+            f\"\\rFinished in: {elapsed_time}. \"\n+            f\"Last state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        )\n+        return run_data\n+      elif conclusion:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1a858c652347251e074a2ea02a7905775674520e"}, "originalPosition": 167}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk4MzEwMw==", "bodyText": "Yes, your are right. I will put else here.", "url": "https://github.com/apache/beam/pull/12150#discussion_r448983103", "createdAt": "2020-07-02T13:00:02Z", "author": {"login": "TobKed"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,231 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/TobKed/beam/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+\n+  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n+  GITHUB_TOKEN = args.github_token\n+  USER_GITHUB_ID = args.github_user\n+  REPO_URL = args.repo_url\n+  RELEASE_BRANCH = args.release_branch\n+  RELEASE_COMMIT = args.release_commit\n+  ARTIFACTS_DIR = args.artifacts_dir\n+\n+\n+def requester(url, *args, return_raw_request=False, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", GITHUB_TOKEN), **kwargs)\n+  r.raise_for_status()\n+  if return_raw_request:\n+    return r\n+  return r.json()\n+\n+\n+def yes_or_no(question):\n+  \"\"\"Helper function to ask yes or no question\"\"\"\n+  reply = str(input(question + \" (y/n): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  if reply == \"n\":\n+    return False\n+  else:\n+    return yes_or_no(\"Uhhhh... please enter \")\n+\n+\n+def get_build_wheels_workflow_id():\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=REPO_URL)\n+  data = requester(url)\n+  return data[\"id\"]\n+\n+\n+def get_last_run(workflow_id):\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=REPO_URL, workflow_id=workflow_id)\n+  event_types = [\"push\", \"pull_request\"]\n+  runs = []\n+  for event in event_types:\n+    data = requester(\n+        url,\n+        params={\n+            \"event\": event, \"branch\": RELEASE_BRANCH\n+        },\n+    )\n+    runs.extend(data[\"workflow_runs\"])\n+\n+  filtered_commit_runs = list(\n+      filter(lambda w: w.get(\"head_sha\", \"\") == RELEASE_COMMIT, runs))\n+  if not filtered_commit_runs:\n+    workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+        workflow_id=workflow_id)\n+    raise Exception(f\"No runs for workflow. Verify at {workflow_web_url}\")\n+\n+  sorted_runs = sorted(\n+      filtered_commit_runs,\n+      key=lambda w: dateutil.parser.parse(w[\"created_at\"]),\n+      reverse=True,\n+  )\n+  last_run = sorted_runs[0]\n+  print(\n+      f\"Found last run. SHA: {RELEASE_COMMIT}, created_at: '{last_run['created_at']}', id: {last_run['id']}\"\n+  )\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      workflow_id=last_run[\"id\"])\n+  print(f\"Verify at {workflow_web_url}\")\n+  print(\n+      f\"Optional upload to GCS will be available at:\\n\"\n+      f\"\\tgs://beam-wheels-staging/{RELEASE_BRANCH}/{RELEASE_COMMIT}-{workflow_id}/\"\n+  )\n+  return last_run\n+\n+\n+def validate_run(run_data):\n+  status = run_data[\"status\"]\n+  conclusion = run_data[\"conclusion\"]\n+  if status == \"completed\" and conclusion == \"success\":\n+    return run_data\n+\n+  url = run_data[\"url\"]\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      workflow_id=run_data[\"id\"])\n+  print(\n+      f\"Waiting for Workflow run {run_data['id']} to finish. Check on {workflow_web_url}\"\n+  )\n+  start_time = time.time()\n+  last_request = start_time\n+  spinner = itertools.cycle([\"|\", \"/\", \"-\", \"\\\\\"])\n+\n+  while True:\n+    now = time.time()\n+    elapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(now - start_time))\n+    print(\n+        f\"\\r {next(spinner)} Waiting to finish. Elapsed time: {elapsed_time}. \"\n+        f\"Current state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        end=\"\",\n+    )\n+\n+    time.sleep(0.3)\n+    if (now - last_request) > 10:\n+      last_request = now\n+      run_data = requester(url)\n+      status = run_data[\"status\"]\n+      conclusion = run_data[\"conclusion\"]\n+      if status != \"completed\":\n+        continue\n+      elif conclusion == \"success\":\n+        print(\n+            f\"\\rFinished in: {elapsed_time}. \"\n+            f\"Last state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        )\n+        return run_data\n+      elif conclusion:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODQ3MTg4MA=="}, "originalCommit": {"oid": "1a858c652347251e074a2ea02a7905775674520e"}, "originalPosition": 167}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5NTI0NzkwOnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/download_github_actions_artifacts.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxNjoxNToyMlrOGrsm4Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QxMTo0NzoxMlrOGt65qA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODQ3MjgwMQ==", "bodyText": "Wouldn't this log message be misleading if the status was completed but the conclusion was failure?", "url": "https://github.com/apache/beam/pull/12150#discussion_r448472801", "createdAt": "2020-07-01T16:15:22Z", "author": {"login": "ibzib"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,231 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/TobKed/beam/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+\n+  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n+  GITHUB_TOKEN = args.github_token\n+  USER_GITHUB_ID = args.github_user\n+  REPO_URL = args.repo_url\n+  RELEASE_BRANCH = args.release_branch\n+  RELEASE_COMMIT = args.release_commit\n+  ARTIFACTS_DIR = args.artifacts_dir\n+\n+\n+def requester(url, *args, return_raw_request=False, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", GITHUB_TOKEN), **kwargs)\n+  r.raise_for_status()\n+  if return_raw_request:\n+    return r\n+  return r.json()\n+\n+\n+def yes_or_no(question):\n+  \"\"\"Helper function to ask yes or no question\"\"\"\n+  reply = str(input(question + \" (y/n): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  if reply == \"n\":\n+    return False\n+  else:\n+    return yes_or_no(\"Uhhhh... please enter \")\n+\n+\n+def get_build_wheels_workflow_id():\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=REPO_URL)\n+  data = requester(url)\n+  return data[\"id\"]\n+\n+\n+def get_last_run(workflow_id):\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=REPO_URL, workflow_id=workflow_id)\n+  event_types = [\"push\", \"pull_request\"]\n+  runs = []\n+  for event in event_types:\n+    data = requester(\n+        url,\n+        params={\n+            \"event\": event, \"branch\": RELEASE_BRANCH\n+        },\n+    )\n+    runs.extend(data[\"workflow_runs\"])\n+\n+  filtered_commit_runs = list(\n+      filter(lambda w: w.get(\"head_sha\", \"\") == RELEASE_COMMIT, runs))\n+  if not filtered_commit_runs:\n+    workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+        workflow_id=workflow_id)\n+    raise Exception(f\"No runs for workflow. Verify at {workflow_web_url}\")\n+\n+  sorted_runs = sorted(\n+      filtered_commit_runs,\n+      key=lambda w: dateutil.parser.parse(w[\"created_at\"]),\n+      reverse=True,\n+  )\n+  last_run = sorted_runs[0]\n+  print(\n+      f\"Found last run. SHA: {RELEASE_COMMIT}, created_at: '{last_run['created_at']}', id: {last_run['id']}\"\n+  )\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      workflow_id=last_run[\"id\"])\n+  print(f\"Verify at {workflow_web_url}\")\n+  print(\n+      f\"Optional upload to GCS will be available at:\\n\"\n+      f\"\\tgs://beam-wheels-staging/{RELEASE_BRANCH}/{RELEASE_COMMIT}-{workflow_id}/\"\n+  )\n+  return last_run\n+\n+\n+def validate_run(run_data):\n+  status = run_data[\"status\"]\n+  conclusion = run_data[\"conclusion\"]\n+  if status == \"completed\" and conclusion == \"success\":\n+    return run_data\n+\n+  url = run_data[\"url\"]\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      workflow_id=run_data[\"id\"])\n+  print(\n+      f\"Waiting for Workflow run {run_data['id']} to finish. Check on {workflow_web_url}\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1a858c652347251e074a2ea02a7905775674520e"}, "originalPosition": 138}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDgwNDEzNg==", "bodyText": "When I looked at the terminal it seems to be logical:\n\nwaiting for the workflow run to finish.\ncontinue script or stop with descriptive message.\n\nWDYT?", "url": "https://github.com/apache/beam/pull/12150#discussion_r450804136", "createdAt": "2020-07-07T11:47:12Z", "author": {"login": "TobKed"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,231 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/TobKed/beam/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+\n+  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n+  GITHUB_TOKEN = args.github_token\n+  USER_GITHUB_ID = args.github_user\n+  REPO_URL = args.repo_url\n+  RELEASE_BRANCH = args.release_branch\n+  RELEASE_COMMIT = args.release_commit\n+  ARTIFACTS_DIR = args.artifacts_dir\n+\n+\n+def requester(url, *args, return_raw_request=False, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", GITHUB_TOKEN), **kwargs)\n+  r.raise_for_status()\n+  if return_raw_request:\n+    return r\n+  return r.json()\n+\n+\n+def yes_or_no(question):\n+  \"\"\"Helper function to ask yes or no question\"\"\"\n+  reply = str(input(question + \" (y/n): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  if reply == \"n\":\n+    return False\n+  else:\n+    return yes_or_no(\"Uhhhh... please enter \")\n+\n+\n+def get_build_wheels_workflow_id():\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=REPO_URL)\n+  data = requester(url)\n+  return data[\"id\"]\n+\n+\n+def get_last_run(workflow_id):\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=REPO_URL, workflow_id=workflow_id)\n+  event_types = [\"push\", \"pull_request\"]\n+  runs = []\n+  for event in event_types:\n+    data = requester(\n+        url,\n+        params={\n+            \"event\": event, \"branch\": RELEASE_BRANCH\n+        },\n+    )\n+    runs.extend(data[\"workflow_runs\"])\n+\n+  filtered_commit_runs = list(\n+      filter(lambda w: w.get(\"head_sha\", \"\") == RELEASE_COMMIT, runs))\n+  if not filtered_commit_runs:\n+    workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+        workflow_id=workflow_id)\n+    raise Exception(f\"No runs for workflow. Verify at {workflow_web_url}\")\n+\n+  sorted_runs = sorted(\n+      filtered_commit_runs,\n+      key=lambda w: dateutil.parser.parse(w[\"created_at\"]),\n+      reverse=True,\n+  )\n+  last_run = sorted_runs[0]\n+  print(\n+      f\"Found last run. SHA: {RELEASE_COMMIT}, created_at: '{last_run['created_at']}', id: {last_run['id']}\"\n+  )\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      workflow_id=last_run[\"id\"])\n+  print(f\"Verify at {workflow_web_url}\")\n+  print(\n+      f\"Optional upload to GCS will be available at:\\n\"\n+      f\"\\tgs://beam-wheels-staging/{RELEASE_BRANCH}/{RELEASE_COMMIT}-{workflow_id}/\"\n+  )\n+  return last_run\n+\n+\n+def validate_run(run_data):\n+  status = run_data[\"status\"]\n+  conclusion = run_data[\"conclusion\"]\n+  if status == \"completed\" and conclusion == \"success\":\n+    return run_data\n+\n+  url = run_data[\"url\"]\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      workflow_id=run_data[\"id\"])\n+  print(\n+      f\"Waiting for Workflow run {run_data['id']} to finish. Check on {workflow_web_url}\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODQ3MjgwMQ=="}, "originalCommit": {"oid": "1a858c652347251e074a2ea02a7905775674520e"}, "originalPosition": 138}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5NTI1MTUwOnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/download_github_actions_artifacts.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxNjoxNjoyMVrOGrspDg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQxMjo0MTowM1rOGsLDyg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODQ3MzM1OA==", "bodyText": "Add a message here like \"run completed unsuccessfully\" in addition to the data.", "url": "https://github.com/apache/beam/pull/12150#discussion_r448473358", "createdAt": "2020-07-01T16:16:21Z", "author": {"login": "ibzib"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,231 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/TobKed/beam/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+\n+  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n+  GITHUB_TOKEN = args.github_token\n+  USER_GITHUB_ID = args.github_user\n+  REPO_URL = args.repo_url\n+  RELEASE_BRANCH = args.release_branch\n+  RELEASE_COMMIT = args.release_commit\n+  ARTIFACTS_DIR = args.artifacts_dir\n+\n+\n+def requester(url, *args, return_raw_request=False, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", GITHUB_TOKEN), **kwargs)\n+  r.raise_for_status()\n+  if return_raw_request:\n+    return r\n+  return r.json()\n+\n+\n+def yes_or_no(question):\n+  \"\"\"Helper function to ask yes or no question\"\"\"\n+  reply = str(input(question + \" (y/n): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  if reply == \"n\":\n+    return False\n+  else:\n+    return yes_or_no(\"Uhhhh... please enter \")\n+\n+\n+def get_build_wheels_workflow_id():\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=REPO_URL)\n+  data = requester(url)\n+  return data[\"id\"]\n+\n+\n+def get_last_run(workflow_id):\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=REPO_URL, workflow_id=workflow_id)\n+  event_types = [\"push\", \"pull_request\"]\n+  runs = []\n+  for event in event_types:\n+    data = requester(\n+        url,\n+        params={\n+            \"event\": event, \"branch\": RELEASE_BRANCH\n+        },\n+    )\n+    runs.extend(data[\"workflow_runs\"])\n+\n+  filtered_commit_runs = list(\n+      filter(lambda w: w.get(\"head_sha\", \"\") == RELEASE_COMMIT, runs))\n+  if not filtered_commit_runs:\n+    workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+        workflow_id=workflow_id)\n+    raise Exception(f\"No runs for workflow. Verify at {workflow_web_url}\")\n+\n+  sorted_runs = sorted(\n+      filtered_commit_runs,\n+      key=lambda w: dateutil.parser.parse(w[\"created_at\"]),\n+      reverse=True,\n+  )\n+  last_run = sorted_runs[0]\n+  print(\n+      f\"Found last run. SHA: {RELEASE_COMMIT}, created_at: '{last_run['created_at']}', id: {last_run['id']}\"\n+  )\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      workflow_id=last_run[\"id\"])\n+  print(f\"Verify at {workflow_web_url}\")\n+  print(\n+      f\"Optional upload to GCS will be available at:\\n\"\n+      f\"\\tgs://beam-wheels-staging/{RELEASE_BRANCH}/{RELEASE_COMMIT}-{workflow_id}/\"\n+  )\n+  return last_run\n+\n+\n+def validate_run(run_data):\n+  status = run_data[\"status\"]\n+  conclusion = run_data[\"conclusion\"]\n+  if status == \"completed\" and conclusion == \"success\":\n+    return run_data\n+\n+  url = run_data[\"url\"]\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      workflow_id=run_data[\"id\"])\n+  print(\n+      f\"Waiting for Workflow run {run_data['id']} to finish. Check on {workflow_web_url}\"\n+  )\n+  start_time = time.time()\n+  last_request = start_time\n+  spinner = itertools.cycle([\"|\", \"/\", \"-\", \"\\\\\"])\n+\n+  while True:\n+    now = time.time()\n+    elapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(now - start_time))\n+    print(\n+        f\"\\r {next(spinner)} Waiting to finish. Elapsed time: {elapsed_time}. \"\n+        f\"Current state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        end=\"\",\n+    )\n+\n+    time.sleep(0.3)\n+    if (now - last_request) > 10:\n+      last_request = now\n+      run_data = requester(url)\n+      status = run_data[\"status\"]\n+      conclusion = run_data[\"conclusion\"]\n+      if status != \"completed\":\n+        continue\n+      elif conclusion == \"success\":\n+        print(\n+            f\"\\rFinished in: {elapsed_time}. \"\n+            f\"Last state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        )\n+        return run_data\n+      elif conclusion:\n+        print(\"\\r\")\n+        raise Exception(run_data)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1a858c652347251e074a2ea02a7905775674520e"}, "originalPosition": 169}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODk3MTcyMg==", "bodyText": "Good idea. I extended message. Please take a look ,please.", "url": "https://github.com/apache/beam/pull/12150#discussion_r448971722", "createdAt": "2020-07-02T12:41:03Z", "author": {"login": "TobKed"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,231 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/TobKed/beam/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+\n+  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n+  GITHUB_TOKEN = args.github_token\n+  USER_GITHUB_ID = args.github_user\n+  REPO_URL = args.repo_url\n+  RELEASE_BRANCH = args.release_branch\n+  RELEASE_COMMIT = args.release_commit\n+  ARTIFACTS_DIR = args.artifacts_dir\n+\n+\n+def requester(url, *args, return_raw_request=False, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", GITHUB_TOKEN), **kwargs)\n+  r.raise_for_status()\n+  if return_raw_request:\n+    return r\n+  return r.json()\n+\n+\n+def yes_or_no(question):\n+  \"\"\"Helper function to ask yes or no question\"\"\"\n+  reply = str(input(question + \" (y/n): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  if reply == \"n\":\n+    return False\n+  else:\n+    return yes_or_no(\"Uhhhh... please enter \")\n+\n+\n+def get_build_wheels_workflow_id():\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=REPO_URL)\n+  data = requester(url)\n+  return data[\"id\"]\n+\n+\n+def get_last_run(workflow_id):\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=REPO_URL, workflow_id=workflow_id)\n+  event_types = [\"push\", \"pull_request\"]\n+  runs = []\n+  for event in event_types:\n+    data = requester(\n+        url,\n+        params={\n+            \"event\": event, \"branch\": RELEASE_BRANCH\n+        },\n+    )\n+    runs.extend(data[\"workflow_runs\"])\n+\n+  filtered_commit_runs = list(\n+      filter(lambda w: w.get(\"head_sha\", \"\") == RELEASE_COMMIT, runs))\n+  if not filtered_commit_runs:\n+    workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+        workflow_id=workflow_id)\n+    raise Exception(f\"No runs for workflow. Verify at {workflow_web_url}\")\n+\n+  sorted_runs = sorted(\n+      filtered_commit_runs,\n+      key=lambda w: dateutil.parser.parse(w[\"created_at\"]),\n+      reverse=True,\n+  )\n+  last_run = sorted_runs[0]\n+  print(\n+      f\"Found last run. SHA: {RELEASE_COMMIT}, created_at: '{last_run['created_at']}', id: {last_run['id']}\"\n+  )\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      workflow_id=last_run[\"id\"])\n+  print(f\"Verify at {workflow_web_url}\")\n+  print(\n+      f\"Optional upload to GCS will be available at:\\n\"\n+      f\"\\tgs://beam-wheels-staging/{RELEASE_BRANCH}/{RELEASE_COMMIT}-{workflow_id}/\"\n+  )\n+  return last_run\n+\n+\n+def validate_run(run_data):\n+  status = run_data[\"status\"]\n+  conclusion = run_data[\"conclusion\"]\n+  if status == \"completed\" and conclusion == \"success\":\n+    return run_data\n+\n+  url = run_data[\"url\"]\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      workflow_id=run_data[\"id\"])\n+  print(\n+      f\"Waiting for Workflow run {run_data['id']} to finish. Check on {workflow_web_url}\"\n+  )\n+  start_time = time.time()\n+  last_request = start_time\n+  spinner = itertools.cycle([\"|\", \"/\", \"-\", \"\\\\\"])\n+\n+  while True:\n+    now = time.time()\n+    elapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(now - start_time))\n+    print(\n+        f\"\\r {next(spinner)} Waiting to finish. Elapsed time: {elapsed_time}. \"\n+        f\"Current state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        end=\"\",\n+    )\n+\n+    time.sleep(0.3)\n+    if (now - last_request) > 10:\n+      last_request = now\n+      run_data = requester(url)\n+      status = run_data[\"status\"]\n+      conclusion = run_data[\"conclusion\"]\n+      if status != \"completed\":\n+        continue\n+      elif conclusion == \"success\":\n+        print(\n+            f\"\\rFinished in: {elapsed_time}. \"\n+            f\"Last state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        )\n+        return run_data\n+      elif conclusion:\n+        print(\"\\r\")\n+        raise Exception(run_data)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODQ3MzM1OA=="}, "originalCommit": {"oid": "1a858c652347251e074a2ea02a7905775674520e"}, "originalPosition": 169}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5OTcwMTMzOnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/download_github_actions_artifacts.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQxNzo0ODozMFrOGsXqIA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QxMTo0OToxM1rOGt69mg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE3ODE0NA==", "bodyText": "How about:\n\"Creating Artifacts directory. Any existing content in {ARTIFACTS_DIR} will be erased. Proceed?\"", "url": "https://github.com/apache/beam/pull/12150#discussion_r449178144", "createdAt": "2020-07-02T17:48:30Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,234 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+\n+  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n+  GITHUB_TOKEN = args.github_token\n+  USER_GITHUB_ID = args.github_user\n+  REPO_URL = args.repo_url\n+  RELEASE_BRANCH = args.release_branch\n+  RELEASE_COMMIT = args.release_commit\n+  ARTIFACTS_DIR = args.artifacts_dir\n+\n+\n+def request_url(url, return_raw_request=False, *args, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", GITHUB_TOKEN), **kwargs)\n+  r.raise_for_status()\n+  if return_raw_request:\n+    return r\n+  return r.json()\n+\n+\n+def get_yes_or_no_answer(question):\n+  \"\"\"Helper function to ask yes or no question\"\"\"\n+  reply = str(input(question + \" (y/n): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  if reply == \"n\":\n+    return False\n+  else:\n+    return get_yes_or_no_answer(\"Uhhhh... please enter \")\n+\n+\n+def get_build_wheels_workflow_id():\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=REPO_URL)\n+  data = request_url(url)\n+  return data[\"id\"]\n+\n+\n+def get_last_run(workflow_id):\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=REPO_URL, workflow_id=workflow_id)\n+  event_types = [\"push\", \"pull_request\"]\n+  runs = []\n+  for event in event_types:\n+    data = request_url(\n+        url,\n+        params={\n+            \"event\": event, \"branch\": RELEASE_BRANCH\n+        },\n+    )\n+    runs.extend(data[\"workflow_runs\"])\n+\n+  filtered_commit_runs = list(\n+      filter(lambda w: w.get(\"head_sha\", \"\") == RELEASE_COMMIT, runs))\n+  if not filtered_commit_runs:\n+    workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+        repo_url=REPO_URL, workflow_id=workflow_id)\n+    raise Exception(\n+        f\"No runs for workflow (branch {RELEASE_BRANCH}, commit {RELEASE_COMMIT}). Verify at {workflow_web_url}\"\n+    )\n+\n+  sorted_runs = sorted(\n+      filtered_commit_runs,\n+      key=lambda w: dateutil.parser.parse(w[\"created_at\"]),\n+      reverse=True,\n+  )\n+  last_run = sorted_runs[0]\n+  print(\n+      f\"Found last run. SHA: {RELEASE_COMMIT}, created_at: '{last_run['created_at']}', id: {last_run['id']}\"\n+  )\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=REPO_URL, workflow_id=last_run[\"id\"])\n+  print(f\"Verify at {workflow_web_url}\")\n+  print(\n+      f\"Optional upload to GCS will be available at:\\n\"\n+      f\"\\tgs://beam-wheels-staging/{RELEASE_BRANCH}/{RELEASE_COMMIT}-{workflow_id}/\"\n+  )\n+  return last_run\n+\n+\n+def validate_run(run_data):\n+  status = run_data[\"status\"]\n+  conclusion = run_data[\"conclusion\"]\n+  if status == \"completed\" and conclusion == \"success\":\n+    return run_data\n+\n+  url = run_data[\"url\"]\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=REPO_URL, workflow_id=run_data[\"id\"])\n+  print(\n+      f\"Started waiting for Workflow run {run_data['id']} to finish. Check on {workflow_web_url}\"\n+  )\n+  start_time = time.time()\n+  last_request = start_time\n+  spinner = itertools.cycle([\"|\", \"/\", \"-\", \"\\\\\"])\n+\n+  while True:\n+    now = time.time()\n+    elapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(now - start_time))\n+    print(\n+        f\"\\r {next(spinner)} Waiting to finish. Elapsed time: {elapsed_time}. \"\n+        f\"Current state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        end=\"\",\n+    )\n+\n+    time.sleep(0.3)\n+    if (now - last_request) > 10:\n+      last_request = now\n+      run_data = request_url(url)\n+      status = run_data[\"status\"]\n+      conclusion = run_data[\"conclusion\"]\n+      if status != \"completed\":\n+        continue\n+      elif conclusion == \"success\":\n+        print(\n+            f\"\\rFinished in: {elapsed_time}. \"\n+            f\"Last state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        )\n+        return run_data\n+      else:\n+        print(\"\\r\")\n+        raise Exception(\n+            f\"Run unsuccessful. Conclusion: {conclusion}. Payload: {run_data}\")\n+\n+\n+def reset_directory():\n+  question = (\n+      f\"Artifacts directory will be cleared. Is it OK for you?\\n\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0fc7383483cbe0c3891ade5456f0cc00abdd726d"}, "originalPosition": 177}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDgwNTE0Ng==", "bodyText": "I like your proposition. I will change it.", "url": "https://github.com/apache/beam/pull/12150#discussion_r450805146", "createdAt": "2020-07-07T11:49:13Z", "author": {"login": "TobKed"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,234 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+\n+  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n+  GITHUB_TOKEN = args.github_token\n+  USER_GITHUB_ID = args.github_user\n+  REPO_URL = args.repo_url\n+  RELEASE_BRANCH = args.release_branch\n+  RELEASE_COMMIT = args.release_commit\n+  ARTIFACTS_DIR = args.artifacts_dir\n+\n+\n+def request_url(url, return_raw_request=False, *args, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", GITHUB_TOKEN), **kwargs)\n+  r.raise_for_status()\n+  if return_raw_request:\n+    return r\n+  return r.json()\n+\n+\n+def get_yes_or_no_answer(question):\n+  \"\"\"Helper function to ask yes or no question\"\"\"\n+  reply = str(input(question + \" (y/n): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  if reply == \"n\":\n+    return False\n+  else:\n+    return get_yes_or_no_answer(\"Uhhhh... please enter \")\n+\n+\n+def get_build_wheels_workflow_id():\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=REPO_URL)\n+  data = request_url(url)\n+  return data[\"id\"]\n+\n+\n+def get_last_run(workflow_id):\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=REPO_URL, workflow_id=workflow_id)\n+  event_types = [\"push\", \"pull_request\"]\n+  runs = []\n+  for event in event_types:\n+    data = request_url(\n+        url,\n+        params={\n+            \"event\": event, \"branch\": RELEASE_BRANCH\n+        },\n+    )\n+    runs.extend(data[\"workflow_runs\"])\n+\n+  filtered_commit_runs = list(\n+      filter(lambda w: w.get(\"head_sha\", \"\") == RELEASE_COMMIT, runs))\n+  if not filtered_commit_runs:\n+    workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+        repo_url=REPO_URL, workflow_id=workflow_id)\n+    raise Exception(\n+        f\"No runs for workflow (branch {RELEASE_BRANCH}, commit {RELEASE_COMMIT}). Verify at {workflow_web_url}\"\n+    )\n+\n+  sorted_runs = sorted(\n+      filtered_commit_runs,\n+      key=lambda w: dateutil.parser.parse(w[\"created_at\"]),\n+      reverse=True,\n+  )\n+  last_run = sorted_runs[0]\n+  print(\n+      f\"Found last run. SHA: {RELEASE_COMMIT}, created_at: '{last_run['created_at']}', id: {last_run['id']}\"\n+  )\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=REPO_URL, workflow_id=last_run[\"id\"])\n+  print(f\"Verify at {workflow_web_url}\")\n+  print(\n+      f\"Optional upload to GCS will be available at:\\n\"\n+      f\"\\tgs://beam-wheels-staging/{RELEASE_BRANCH}/{RELEASE_COMMIT}-{workflow_id}/\"\n+  )\n+  return last_run\n+\n+\n+def validate_run(run_data):\n+  status = run_data[\"status\"]\n+  conclusion = run_data[\"conclusion\"]\n+  if status == \"completed\" and conclusion == \"success\":\n+    return run_data\n+\n+  url = run_data[\"url\"]\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=REPO_URL, workflow_id=run_data[\"id\"])\n+  print(\n+      f\"Started waiting for Workflow run {run_data['id']} to finish. Check on {workflow_web_url}\"\n+  )\n+  start_time = time.time()\n+  last_request = start_time\n+  spinner = itertools.cycle([\"|\", \"/\", \"-\", \"\\\\\"])\n+\n+  while True:\n+    now = time.time()\n+    elapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(now - start_time))\n+    print(\n+        f\"\\r {next(spinner)} Waiting to finish. Elapsed time: {elapsed_time}. \"\n+        f\"Current state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        end=\"\",\n+    )\n+\n+    time.sleep(0.3)\n+    if (now - last_request) > 10:\n+      last_request = now\n+      run_data = request_url(url)\n+      status = run_data[\"status\"]\n+      conclusion = run_data[\"conclusion\"]\n+      if status != \"completed\":\n+        continue\n+      elif conclusion == \"success\":\n+        print(\n+            f\"\\rFinished in: {elapsed_time}. \"\n+            f\"Last state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        )\n+        return run_data\n+      else:\n+        print(\"\\r\")\n+        raise Exception(\n+            f\"Run unsuccessful. Conclusion: {conclusion}. Payload: {run_data}\")\n+\n+\n+def reset_directory():\n+  question = (\n+      f\"Artifacts directory will be cleared. Is it OK for you?\\n\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE3ODE0NA=="}, "originalCommit": {"oid": "0fc7383483cbe0c3891ade5456f0cc00abdd726d"}, "originalPosition": 177}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5OTcwMjkyOnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/download_github_actions_artifacts.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQxNzo0OTowN1rOGsXrJw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QxMTo1MDo0N1rOGt7Amg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE3ODQwNw==", "bodyText": "use sys.exit() in scripts. It can also accept a message.", "url": "https://github.com/apache/beam/pull/12150#discussion_r449178407", "createdAt": "2020-07-02T17:49:07Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,234 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+\n+  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n+  GITHUB_TOKEN = args.github_token\n+  USER_GITHUB_ID = args.github_user\n+  REPO_URL = args.repo_url\n+  RELEASE_BRANCH = args.release_branch\n+  RELEASE_COMMIT = args.release_commit\n+  ARTIFACTS_DIR = args.artifacts_dir\n+\n+\n+def request_url(url, return_raw_request=False, *args, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", GITHUB_TOKEN), **kwargs)\n+  r.raise_for_status()\n+  if return_raw_request:\n+    return r\n+  return r.json()\n+\n+\n+def get_yes_or_no_answer(question):\n+  \"\"\"Helper function to ask yes or no question\"\"\"\n+  reply = str(input(question + \" (y/n): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  if reply == \"n\":\n+    return False\n+  else:\n+    return get_yes_or_no_answer(\"Uhhhh... please enter \")\n+\n+\n+def get_build_wheels_workflow_id():\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=REPO_URL)\n+  data = request_url(url)\n+  return data[\"id\"]\n+\n+\n+def get_last_run(workflow_id):\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=REPO_URL, workflow_id=workflow_id)\n+  event_types = [\"push\", \"pull_request\"]\n+  runs = []\n+  for event in event_types:\n+    data = request_url(\n+        url,\n+        params={\n+            \"event\": event, \"branch\": RELEASE_BRANCH\n+        },\n+    )\n+    runs.extend(data[\"workflow_runs\"])\n+\n+  filtered_commit_runs = list(\n+      filter(lambda w: w.get(\"head_sha\", \"\") == RELEASE_COMMIT, runs))\n+  if not filtered_commit_runs:\n+    workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+        repo_url=REPO_URL, workflow_id=workflow_id)\n+    raise Exception(\n+        f\"No runs for workflow (branch {RELEASE_BRANCH}, commit {RELEASE_COMMIT}). Verify at {workflow_web_url}\"\n+    )\n+\n+  sorted_runs = sorted(\n+      filtered_commit_runs,\n+      key=lambda w: dateutil.parser.parse(w[\"created_at\"]),\n+      reverse=True,\n+  )\n+  last_run = sorted_runs[0]\n+  print(\n+      f\"Found last run. SHA: {RELEASE_COMMIT}, created_at: '{last_run['created_at']}', id: {last_run['id']}\"\n+  )\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=REPO_URL, workflow_id=last_run[\"id\"])\n+  print(f\"Verify at {workflow_web_url}\")\n+  print(\n+      f\"Optional upload to GCS will be available at:\\n\"\n+      f\"\\tgs://beam-wheels-staging/{RELEASE_BRANCH}/{RELEASE_COMMIT}-{workflow_id}/\"\n+  )\n+  return last_run\n+\n+\n+def validate_run(run_data):\n+  status = run_data[\"status\"]\n+  conclusion = run_data[\"conclusion\"]\n+  if status == \"completed\" and conclusion == \"success\":\n+    return run_data\n+\n+  url = run_data[\"url\"]\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=REPO_URL, workflow_id=run_data[\"id\"])\n+  print(\n+      f\"Started waiting for Workflow run {run_data['id']} to finish. Check on {workflow_web_url}\"\n+  )\n+  start_time = time.time()\n+  last_request = start_time\n+  spinner = itertools.cycle([\"|\", \"/\", \"-\", \"\\\\\"])\n+\n+  while True:\n+    now = time.time()\n+    elapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(now - start_time))\n+    print(\n+        f\"\\r {next(spinner)} Waiting to finish. Elapsed time: {elapsed_time}. \"\n+        f\"Current state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        end=\"\",\n+    )\n+\n+    time.sleep(0.3)\n+    if (now - last_request) > 10:\n+      last_request = now\n+      run_data = request_url(url)\n+      status = run_data[\"status\"]\n+      conclusion = run_data[\"conclusion\"]\n+      if status != \"completed\":\n+        continue\n+      elif conclusion == \"success\":\n+        print(\n+            f\"\\rFinished in: {elapsed_time}. \"\n+            f\"Last state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        )\n+        return run_data\n+      else:\n+        print(\"\\r\")\n+        raise Exception(\n+            f\"Run unsuccessful. Conclusion: {conclusion}. Payload: {run_data}\")\n+\n+\n+def reset_directory():\n+  question = (\n+      f\"Artifacts directory will be cleared. Is it OK for you?\\n\"\n+      f\"Artifacts directory: {ARTIFACTS_DIR}\\n\"\n+      f\"Your answer\")\n+  if get_yes_or_no_answer(question):\n+    print(f\"Clearing directory: {ARTIFACTS_DIR}\")\n+    shutil.rmtree(ARTIFACTS_DIR, ignore_errors=True)\n+    os.makedirs(ARTIFACTS_DIR)\n+  else:\n+    print(\"You said NO for clearing artifacts directory. Quitting ...\")\n+    quit(1)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0fc7383483cbe0c3891ade5456f0cc00abdd726d"}, "originalPosition": 186}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDgwNTkxNA==", "bodyText": "Sure, I will change it.", "url": "https://github.com/apache/beam/pull/12150#discussion_r450805914", "createdAt": "2020-07-07T11:50:47Z", "author": {"login": "TobKed"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,234 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+\n+  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n+  GITHUB_TOKEN = args.github_token\n+  USER_GITHUB_ID = args.github_user\n+  REPO_URL = args.repo_url\n+  RELEASE_BRANCH = args.release_branch\n+  RELEASE_COMMIT = args.release_commit\n+  ARTIFACTS_DIR = args.artifacts_dir\n+\n+\n+def request_url(url, return_raw_request=False, *args, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", GITHUB_TOKEN), **kwargs)\n+  r.raise_for_status()\n+  if return_raw_request:\n+    return r\n+  return r.json()\n+\n+\n+def get_yes_or_no_answer(question):\n+  \"\"\"Helper function to ask yes or no question\"\"\"\n+  reply = str(input(question + \" (y/n): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  if reply == \"n\":\n+    return False\n+  else:\n+    return get_yes_or_no_answer(\"Uhhhh... please enter \")\n+\n+\n+def get_build_wheels_workflow_id():\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=REPO_URL)\n+  data = request_url(url)\n+  return data[\"id\"]\n+\n+\n+def get_last_run(workflow_id):\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=REPO_URL, workflow_id=workflow_id)\n+  event_types = [\"push\", \"pull_request\"]\n+  runs = []\n+  for event in event_types:\n+    data = request_url(\n+        url,\n+        params={\n+            \"event\": event, \"branch\": RELEASE_BRANCH\n+        },\n+    )\n+    runs.extend(data[\"workflow_runs\"])\n+\n+  filtered_commit_runs = list(\n+      filter(lambda w: w.get(\"head_sha\", \"\") == RELEASE_COMMIT, runs))\n+  if not filtered_commit_runs:\n+    workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+        repo_url=REPO_URL, workflow_id=workflow_id)\n+    raise Exception(\n+        f\"No runs for workflow (branch {RELEASE_BRANCH}, commit {RELEASE_COMMIT}). Verify at {workflow_web_url}\"\n+    )\n+\n+  sorted_runs = sorted(\n+      filtered_commit_runs,\n+      key=lambda w: dateutil.parser.parse(w[\"created_at\"]),\n+      reverse=True,\n+  )\n+  last_run = sorted_runs[0]\n+  print(\n+      f\"Found last run. SHA: {RELEASE_COMMIT}, created_at: '{last_run['created_at']}', id: {last_run['id']}\"\n+  )\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=REPO_URL, workflow_id=last_run[\"id\"])\n+  print(f\"Verify at {workflow_web_url}\")\n+  print(\n+      f\"Optional upload to GCS will be available at:\\n\"\n+      f\"\\tgs://beam-wheels-staging/{RELEASE_BRANCH}/{RELEASE_COMMIT}-{workflow_id}/\"\n+  )\n+  return last_run\n+\n+\n+def validate_run(run_data):\n+  status = run_data[\"status\"]\n+  conclusion = run_data[\"conclusion\"]\n+  if status == \"completed\" and conclusion == \"success\":\n+    return run_data\n+\n+  url = run_data[\"url\"]\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=REPO_URL, workflow_id=run_data[\"id\"])\n+  print(\n+      f\"Started waiting for Workflow run {run_data['id']} to finish. Check on {workflow_web_url}\"\n+  )\n+  start_time = time.time()\n+  last_request = start_time\n+  spinner = itertools.cycle([\"|\", \"/\", \"-\", \"\\\\\"])\n+\n+  while True:\n+    now = time.time()\n+    elapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(now - start_time))\n+    print(\n+        f\"\\r {next(spinner)} Waiting to finish. Elapsed time: {elapsed_time}. \"\n+        f\"Current state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        end=\"\",\n+    )\n+\n+    time.sleep(0.3)\n+    if (now - last_request) > 10:\n+      last_request = now\n+      run_data = request_url(url)\n+      status = run_data[\"status\"]\n+      conclusion = run_data[\"conclusion\"]\n+      if status != \"completed\":\n+        continue\n+      elif conclusion == \"success\":\n+        print(\n+            f\"\\rFinished in: {elapsed_time}. \"\n+            f\"Last state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        )\n+        return run_data\n+      else:\n+        print(\"\\r\")\n+        raise Exception(\n+            f\"Run unsuccessful. Conclusion: {conclusion}. Payload: {run_data}\")\n+\n+\n+def reset_directory():\n+  question = (\n+      f\"Artifacts directory will be cleared. Is it OK for you?\\n\"\n+      f\"Artifacts directory: {ARTIFACTS_DIR}\\n\"\n+      f\"Your answer\")\n+  if get_yes_or_no_answer(question):\n+    print(f\"Clearing directory: {ARTIFACTS_DIR}\")\n+    shutil.rmtree(ARTIFACTS_DIR, ignore_errors=True)\n+    os.makedirs(ARTIFACTS_DIR)\n+  else:\n+    print(\"You said NO for clearing artifacts directory. Quitting ...\")\n+    quit(1)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE3ODQwNw=="}, "originalCommit": {"oid": "0fc7383483cbe0c3891ade5456f0cc00abdd726d"}, "originalPosition": 186}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5OTcyNDU5OnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/download_github_actions_artifacts.py", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQxNzo1NTo1NVrOGsX4lQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQxNzo1NTo1NVrOGsX4lQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE4MTg0NQ==", "bodyText": "Please add a docstring.", "url": "https://github.com/apache/beam/pull/12150#discussion_r449181845", "createdAt": "2020-07-02T17:55:55Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,234 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+\n+  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n+  GITHUB_TOKEN = args.github_token\n+  USER_GITHUB_ID = args.github_user\n+  REPO_URL = args.repo_url\n+  RELEASE_BRANCH = args.release_branch\n+  RELEASE_COMMIT = args.release_commit\n+  ARTIFACTS_DIR = args.artifacts_dir\n+\n+\n+def request_url(url, return_raw_request=False, *args, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", GITHUB_TOKEN), **kwargs)\n+  r.raise_for_status()\n+  if return_raw_request:\n+    return r\n+  return r.json()\n+\n+\n+def get_yes_or_no_answer(question):\n+  \"\"\"Helper function to ask yes or no question\"\"\"\n+  reply = str(input(question + \" (y/n): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  if reply == \"n\":\n+    return False\n+  else:\n+    return get_yes_or_no_answer(\"Uhhhh... please enter \")\n+\n+\n+def get_build_wheels_workflow_id():\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=REPO_URL)\n+  data = request_url(url)\n+  return data[\"id\"]\n+\n+\n+def get_last_run(workflow_id):\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=REPO_URL, workflow_id=workflow_id)\n+  event_types = [\"push\", \"pull_request\"]\n+  runs = []\n+  for event in event_types:\n+    data = request_url(\n+        url,\n+        params={\n+            \"event\": event, \"branch\": RELEASE_BRANCH\n+        },\n+    )\n+    runs.extend(data[\"workflow_runs\"])\n+\n+  filtered_commit_runs = list(\n+      filter(lambda w: w.get(\"head_sha\", \"\") == RELEASE_COMMIT, runs))\n+  if not filtered_commit_runs:\n+    workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+        repo_url=REPO_URL, workflow_id=workflow_id)\n+    raise Exception(\n+        f\"No runs for workflow (branch {RELEASE_BRANCH}, commit {RELEASE_COMMIT}). Verify at {workflow_web_url}\"\n+    )\n+\n+  sorted_runs = sorted(\n+      filtered_commit_runs,\n+      key=lambda w: dateutil.parser.parse(w[\"created_at\"]),\n+      reverse=True,\n+  )\n+  last_run = sorted_runs[0]\n+  print(\n+      f\"Found last run. SHA: {RELEASE_COMMIT}, created_at: '{last_run['created_at']}', id: {last_run['id']}\"\n+  )\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=REPO_URL, workflow_id=last_run[\"id\"])\n+  print(f\"Verify at {workflow_web_url}\")\n+  print(\n+      f\"Optional upload to GCS will be available at:\\n\"\n+      f\"\\tgs://beam-wheels-staging/{RELEASE_BRANCH}/{RELEASE_COMMIT}-{workflow_id}/\"\n+  )\n+  return last_run\n+\n+\n+def validate_run(run_data):\n+  status = run_data[\"status\"]\n+  conclusion = run_data[\"conclusion\"]\n+  if status == \"completed\" and conclusion == \"success\":\n+    return run_data\n+\n+  url = run_data[\"url\"]\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=REPO_URL, workflow_id=run_data[\"id\"])\n+  print(\n+      f\"Started waiting for Workflow run {run_data['id']} to finish. Check on {workflow_web_url}\"\n+  )\n+  start_time = time.time()\n+  last_request = start_time\n+  spinner = itertools.cycle([\"|\", \"/\", \"-\", \"\\\\\"])\n+\n+  while True:\n+    now = time.time()\n+    elapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(now - start_time))\n+    print(\n+        f\"\\r {next(spinner)} Waiting to finish. Elapsed time: {elapsed_time}. \"\n+        f\"Current state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        end=\"\",\n+    )\n+\n+    time.sleep(0.3)\n+    if (now - last_request) > 10:\n+      last_request = now\n+      run_data = request_url(url)\n+      status = run_data[\"status\"]\n+      conclusion = run_data[\"conclusion\"]\n+      if status != \"completed\":\n+        continue\n+      elif conclusion == \"success\":\n+        print(\n+            f\"\\rFinished in: {elapsed_time}. \"\n+            f\"Last state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        )\n+        return run_data\n+      else:\n+        print(\"\\r\")\n+        raise Exception(\n+            f\"Run unsuccessful. Conclusion: {conclusion}. Payload: {run_data}\")\n+\n+\n+def reset_directory():\n+  question = (\n+      f\"Artifacts directory will be cleared. Is it OK for you?\\n\"\n+      f\"Artifacts directory: {ARTIFACTS_DIR}\\n\"\n+      f\"Your answer\")\n+  if get_yes_or_no_answer(question):\n+    print(f\"Clearing directory: {ARTIFACTS_DIR}\")\n+    shutil.rmtree(ARTIFACTS_DIR, ignore_errors=True)\n+    os.makedirs(ARTIFACTS_DIR)\n+  else:\n+    print(\"You said NO for clearing artifacts directory. Quitting ...\")\n+    quit(1)\n+\n+\n+def download_artifacts(artifacts_url):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0fc7383483cbe0c3891ade5456f0cc00abdd726d"}, "originalPosition": 189}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5OTcyNzQ0OnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/download_github_actions_artifacts.py", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQxNzo1NjozOFrOGsX6PQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QxMjo1MTowMlrOGwnIEA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE4MjI2OQ==", "bodyText": "Are there any hashes of the artifacts to verify that the downloaded/extracted artifacts were not corrupted?", "url": "https://github.com/apache/beam/pull/12150#discussion_r449182269", "createdAt": "2020-07-02T17:56:38Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,234 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+\n+  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n+  GITHUB_TOKEN = args.github_token\n+  USER_GITHUB_ID = args.github_user\n+  REPO_URL = args.repo_url\n+  RELEASE_BRANCH = args.release_branch\n+  RELEASE_COMMIT = args.release_commit\n+  ARTIFACTS_DIR = args.artifacts_dir\n+\n+\n+def request_url(url, return_raw_request=False, *args, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", GITHUB_TOKEN), **kwargs)\n+  r.raise_for_status()\n+  if return_raw_request:\n+    return r\n+  return r.json()\n+\n+\n+def get_yes_or_no_answer(question):\n+  \"\"\"Helper function to ask yes or no question\"\"\"\n+  reply = str(input(question + \" (y/n): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  if reply == \"n\":\n+    return False\n+  else:\n+    return get_yes_or_no_answer(\"Uhhhh... please enter \")\n+\n+\n+def get_build_wheels_workflow_id():\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=REPO_URL)\n+  data = request_url(url)\n+  return data[\"id\"]\n+\n+\n+def get_last_run(workflow_id):\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=REPO_URL, workflow_id=workflow_id)\n+  event_types = [\"push\", \"pull_request\"]\n+  runs = []\n+  for event in event_types:\n+    data = request_url(\n+        url,\n+        params={\n+            \"event\": event, \"branch\": RELEASE_BRANCH\n+        },\n+    )\n+    runs.extend(data[\"workflow_runs\"])\n+\n+  filtered_commit_runs = list(\n+      filter(lambda w: w.get(\"head_sha\", \"\") == RELEASE_COMMIT, runs))\n+  if not filtered_commit_runs:\n+    workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+        repo_url=REPO_URL, workflow_id=workflow_id)\n+    raise Exception(\n+        f\"No runs for workflow (branch {RELEASE_BRANCH}, commit {RELEASE_COMMIT}). Verify at {workflow_web_url}\"\n+    )\n+\n+  sorted_runs = sorted(\n+      filtered_commit_runs,\n+      key=lambda w: dateutil.parser.parse(w[\"created_at\"]),\n+      reverse=True,\n+  )\n+  last_run = sorted_runs[0]\n+  print(\n+      f\"Found last run. SHA: {RELEASE_COMMIT}, created_at: '{last_run['created_at']}', id: {last_run['id']}\"\n+  )\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=REPO_URL, workflow_id=last_run[\"id\"])\n+  print(f\"Verify at {workflow_web_url}\")\n+  print(\n+      f\"Optional upload to GCS will be available at:\\n\"\n+      f\"\\tgs://beam-wheels-staging/{RELEASE_BRANCH}/{RELEASE_COMMIT}-{workflow_id}/\"\n+  )\n+  return last_run\n+\n+\n+def validate_run(run_data):\n+  status = run_data[\"status\"]\n+  conclusion = run_data[\"conclusion\"]\n+  if status == \"completed\" and conclusion == \"success\":\n+    return run_data\n+\n+  url = run_data[\"url\"]\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=REPO_URL, workflow_id=run_data[\"id\"])\n+  print(\n+      f\"Started waiting for Workflow run {run_data['id']} to finish. Check on {workflow_web_url}\"\n+  )\n+  start_time = time.time()\n+  last_request = start_time\n+  spinner = itertools.cycle([\"|\", \"/\", \"-\", \"\\\\\"])\n+\n+  while True:\n+    now = time.time()\n+    elapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(now - start_time))\n+    print(\n+        f\"\\r {next(spinner)} Waiting to finish. Elapsed time: {elapsed_time}. \"\n+        f\"Current state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        end=\"\",\n+    )\n+\n+    time.sleep(0.3)\n+    if (now - last_request) > 10:\n+      last_request = now\n+      run_data = request_url(url)\n+      status = run_data[\"status\"]\n+      conclusion = run_data[\"conclusion\"]\n+      if status != \"completed\":\n+        continue\n+      elif conclusion == \"success\":\n+        print(\n+            f\"\\rFinished in: {elapsed_time}. \"\n+            f\"Last state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        )\n+        return run_data\n+      else:\n+        print(\"\\r\")\n+        raise Exception(\n+            f\"Run unsuccessful. Conclusion: {conclusion}. Payload: {run_data}\")\n+\n+\n+def reset_directory():\n+  question = (\n+      f\"Artifacts directory will be cleared. Is it OK for you?\\n\"\n+      f\"Artifacts directory: {ARTIFACTS_DIR}\\n\"\n+      f\"Your answer\")\n+  if get_yes_or_no_answer(question):\n+    print(f\"Clearing directory: {ARTIFACTS_DIR}\")\n+    shutil.rmtree(ARTIFACTS_DIR, ignore_errors=True)\n+    os.makedirs(ARTIFACTS_DIR)\n+  else:\n+    print(\"You said NO for clearing artifacts directory. Quitting ...\")\n+    quit(1)\n+\n+\n+def download_artifacts(artifacts_url):\n+  print(\"Starting downloading artifacts ... (it may take a while)\")\n+  data_artifacts = request_url(artifacts_url)\n+  filtered_artifacts = [\n+      a for a in data_artifacts[\"artifacts\"] if (\n+          a[\"name\"].startswith(\"source_gztar_zip\") or\n+          a[\"name\"].startswith(\"wheelhouse\"))\n+  ]\n+  for artifact in filtered_artifacts:\n+    url = artifact[\"archive_download_url\"]\n+    name = artifact[\"name\"]\n+    artifacts_size_mb = round(artifact[\"size_in_bytes\"] / (1024 * 1024), 2)\n+    print(\n+        f\"\\tDownloading {name}.zip artifact (size: {artifacts_size_mb} megabytes)\"\n+    )\n+    r = request_url(url, return_raw_request=True, allow_redirects=True)\n+\n+    with tempfile.NamedTemporaryFile(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0fc7383483cbe0c3891ade5456f0cc00abdd726d"}, "originalPosition": 206}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTI2NDM5MA==", "bodyText": "If not, should we add the hashes when we build the wheels?", "url": "https://github.com/apache/beam/pull/12150#discussion_r449264390", "createdAt": "2020-07-02T21:02:31Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,234 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+\n+  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n+  GITHUB_TOKEN = args.github_token\n+  USER_GITHUB_ID = args.github_user\n+  REPO_URL = args.repo_url\n+  RELEASE_BRANCH = args.release_branch\n+  RELEASE_COMMIT = args.release_commit\n+  ARTIFACTS_DIR = args.artifacts_dir\n+\n+\n+def request_url(url, return_raw_request=False, *args, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", GITHUB_TOKEN), **kwargs)\n+  r.raise_for_status()\n+  if return_raw_request:\n+    return r\n+  return r.json()\n+\n+\n+def get_yes_or_no_answer(question):\n+  \"\"\"Helper function to ask yes or no question\"\"\"\n+  reply = str(input(question + \" (y/n): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  if reply == \"n\":\n+    return False\n+  else:\n+    return get_yes_or_no_answer(\"Uhhhh... please enter \")\n+\n+\n+def get_build_wheels_workflow_id():\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=REPO_URL)\n+  data = request_url(url)\n+  return data[\"id\"]\n+\n+\n+def get_last_run(workflow_id):\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=REPO_URL, workflow_id=workflow_id)\n+  event_types = [\"push\", \"pull_request\"]\n+  runs = []\n+  for event in event_types:\n+    data = request_url(\n+        url,\n+        params={\n+            \"event\": event, \"branch\": RELEASE_BRANCH\n+        },\n+    )\n+    runs.extend(data[\"workflow_runs\"])\n+\n+  filtered_commit_runs = list(\n+      filter(lambda w: w.get(\"head_sha\", \"\") == RELEASE_COMMIT, runs))\n+  if not filtered_commit_runs:\n+    workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+        repo_url=REPO_URL, workflow_id=workflow_id)\n+    raise Exception(\n+        f\"No runs for workflow (branch {RELEASE_BRANCH}, commit {RELEASE_COMMIT}). Verify at {workflow_web_url}\"\n+    )\n+\n+  sorted_runs = sorted(\n+      filtered_commit_runs,\n+      key=lambda w: dateutil.parser.parse(w[\"created_at\"]),\n+      reverse=True,\n+  )\n+  last_run = sorted_runs[0]\n+  print(\n+      f\"Found last run. SHA: {RELEASE_COMMIT}, created_at: '{last_run['created_at']}', id: {last_run['id']}\"\n+  )\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=REPO_URL, workflow_id=last_run[\"id\"])\n+  print(f\"Verify at {workflow_web_url}\")\n+  print(\n+      f\"Optional upload to GCS will be available at:\\n\"\n+      f\"\\tgs://beam-wheels-staging/{RELEASE_BRANCH}/{RELEASE_COMMIT}-{workflow_id}/\"\n+  )\n+  return last_run\n+\n+\n+def validate_run(run_data):\n+  status = run_data[\"status\"]\n+  conclusion = run_data[\"conclusion\"]\n+  if status == \"completed\" and conclusion == \"success\":\n+    return run_data\n+\n+  url = run_data[\"url\"]\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=REPO_URL, workflow_id=run_data[\"id\"])\n+  print(\n+      f\"Started waiting for Workflow run {run_data['id']} to finish. Check on {workflow_web_url}\"\n+  )\n+  start_time = time.time()\n+  last_request = start_time\n+  spinner = itertools.cycle([\"|\", \"/\", \"-\", \"\\\\\"])\n+\n+  while True:\n+    now = time.time()\n+    elapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(now - start_time))\n+    print(\n+        f\"\\r {next(spinner)} Waiting to finish. Elapsed time: {elapsed_time}. \"\n+        f\"Current state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        end=\"\",\n+    )\n+\n+    time.sleep(0.3)\n+    if (now - last_request) > 10:\n+      last_request = now\n+      run_data = request_url(url)\n+      status = run_data[\"status\"]\n+      conclusion = run_data[\"conclusion\"]\n+      if status != \"completed\":\n+        continue\n+      elif conclusion == \"success\":\n+        print(\n+            f\"\\rFinished in: {elapsed_time}. \"\n+            f\"Last state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        )\n+        return run_data\n+      else:\n+        print(\"\\r\")\n+        raise Exception(\n+            f\"Run unsuccessful. Conclusion: {conclusion}. Payload: {run_data}\")\n+\n+\n+def reset_directory():\n+  question = (\n+      f\"Artifacts directory will be cleared. Is it OK for you?\\n\"\n+      f\"Artifacts directory: {ARTIFACTS_DIR}\\n\"\n+      f\"Your answer\")\n+  if get_yes_or_no_answer(question):\n+    print(f\"Clearing directory: {ARTIFACTS_DIR}\")\n+    shutil.rmtree(ARTIFACTS_DIR, ignore_errors=True)\n+    os.makedirs(ARTIFACTS_DIR)\n+  else:\n+    print(\"You said NO for clearing artifacts directory. Quitting ...\")\n+    quit(1)\n+\n+\n+def download_artifacts(artifacts_url):\n+  print(\"Starting downloading artifacts ... (it may take a while)\")\n+  data_artifacts = request_url(artifacts_url)\n+  filtered_artifacts = [\n+      a for a in data_artifacts[\"artifacts\"] if (\n+          a[\"name\"].startswith(\"source_gztar_zip\") or\n+          a[\"name\"].startswith(\"wheelhouse\"))\n+  ]\n+  for artifact in filtered_artifacts:\n+    url = artifact[\"archive_download_url\"]\n+    name = artifact[\"name\"]\n+    artifacts_size_mb = round(artifact[\"size_in_bytes\"] / (1024 * 1024), 2)\n+    print(\n+        f\"\\tDownloading {name}.zip artifact (size: {artifacts_size_mb} megabytes)\"\n+    )\n+    r = request_url(url, return_raw_request=True, allow_redirects=True)\n+\n+    with tempfile.NamedTemporaryFile(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE4MjI2OQ=="}, "originalCommit": {"oid": "0fc7383483cbe0c3891ade5456f0cc00abdd726d"}, "originalPosition": 206}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTU2OTMzNA==", "bodyText": "good idea, I will add hashes.", "url": "https://github.com/apache/beam/pull/12150#discussion_r451569334", "createdAt": "2020-07-08T14:02:51Z", "author": {"login": "TobKed"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,234 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+\n+  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n+  GITHUB_TOKEN = args.github_token\n+  USER_GITHUB_ID = args.github_user\n+  REPO_URL = args.repo_url\n+  RELEASE_BRANCH = args.release_branch\n+  RELEASE_COMMIT = args.release_commit\n+  ARTIFACTS_DIR = args.artifacts_dir\n+\n+\n+def request_url(url, return_raw_request=False, *args, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", GITHUB_TOKEN), **kwargs)\n+  r.raise_for_status()\n+  if return_raw_request:\n+    return r\n+  return r.json()\n+\n+\n+def get_yes_or_no_answer(question):\n+  \"\"\"Helper function to ask yes or no question\"\"\"\n+  reply = str(input(question + \" (y/n): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  if reply == \"n\":\n+    return False\n+  else:\n+    return get_yes_or_no_answer(\"Uhhhh... please enter \")\n+\n+\n+def get_build_wheels_workflow_id():\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=REPO_URL)\n+  data = request_url(url)\n+  return data[\"id\"]\n+\n+\n+def get_last_run(workflow_id):\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=REPO_URL, workflow_id=workflow_id)\n+  event_types = [\"push\", \"pull_request\"]\n+  runs = []\n+  for event in event_types:\n+    data = request_url(\n+        url,\n+        params={\n+            \"event\": event, \"branch\": RELEASE_BRANCH\n+        },\n+    )\n+    runs.extend(data[\"workflow_runs\"])\n+\n+  filtered_commit_runs = list(\n+      filter(lambda w: w.get(\"head_sha\", \"\") == RELEASE_COMMIT, runs))\n+  if not filtered_commit_runs:\n+    workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+        repo_url=REPO_URL, workflow_id=workflow_id)\n+    raise Exception(\n+        f\"No runs for workflow (branch {RELEASE_BRANCH}, commit {RELEASE_COMMIT}). Verify at {workflow_web_url}\"\n+    )\n+\n+  sorted_runs = sorted(\n+      filtered_commit_runs,\n+      key=lambda w: dateutil.parser.parse(w[\"created_at\"]),\n+      reverse=True,\n+  )\n+  last_run = sorted_runs[0]\n+  print(\n+      f\"Found last run. SHA: {RELEASE_COMMIT}, created_at: '{last_run['created_at']}', id: {last_run['id']}\"\n+  )\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=REPO_URL, workflow_id=last_run[\"id\"])\n+  print(f\"Verify at {workflow_web_url}\")\n+  print(\n+      f\"Optional upload to GCS will be available at:\\n\"\n+      f\"\\tgs://beam-wheels-staging/{RELEASE_BRANCH}/{RELEASE_COMMIT}-{workflow_id}/\"\n+  )\n+  return last_run\n+\n+\n+def validate_run(run_data):\n+  status = run_data[\"status\"]\n+  conclusion = run_data[\"conclusion\"]\n+  if status == \"completed\" and conclusion == \"success\":\n+    return run_data\n+\n+  url = run_data[\"url\"]\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=REPO_URL, workflow_id=run_data[\"id\"])\n+  print(\n+      f\"Started waiting for Workflow run {run_data['id']} to finish. Check on {workflow_web_url}\"\n+  )\n+  start_time = time.time()\n+  last_request = start_time\n+  spinner = itertools.cycle([\"|\", \"/\", \"-\", \"\\\\\"])\n+\n+  while True:\n+    now = time.time()\n+    elapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(now - start_time))\n+    print(\n+        f\"\\r {next(spinner)} Waiting to finish. Elapsed time: {elapsed_time}. \"\n+        f\"Current state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        end=\"\",\n+    )\n+\n+    time.sleep(0.3)\n+    if (now - last_request) > 10:\n+      last_request = now\n+      run_data = request_url(url)\n+      status = run_data[\"status\"]\n+      conclusion = run_data[\"conclusion\"]\n+      if status != \"completed\":\n+        continue\n+      elif conclusion == \"success\":\n+        print(\n+            f\"\\rFinished in: {elapsed_time}. \"\n+            f\"Last state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        )\n+        return run_data\n+      else:\n+        print(\"\\r\")\n+        raise Exception(\n+            f\"Run unsuccessful. Conclusion: {conclusion}. Payload: {run_data}\")\n+\n+\n+def reset_directory():\n+  question = (\n+      f\"Artifacts directory will be cleared. Is it OK for you?\\n\"\n+      f\"Artifacts directory: {ARTIFACTS_DIR}\\n\"\n+      f\"Your answer\")\n+  if get_yes_or_no_answer(question):\n+    print(f\"Clearing directory: {ARTIFACTS_DIR}\")\n+    shutil.rmtree(ARTIFACTS_DIR, ignore_errors=True)\n+    os.makedirs(ARTIFACTS_DIR)\n+  else:\n+    print(\"You said NO for clearing artifacts directory. Quitting ...\")\n+    quit(1)\n+\n+\n+def download_artifacts(artifacts_url):\n+  print(\"Starting downloading artifacts ... (it may take a while)\")\n+  data_artifacts = request_url(artifacts_url)\n+  filtered_artifacts = [\n+      a for a in data_artifacts[\"artifacts\"] if (\n+          a[\"name\"].startswith(\"source_gztar_zip\") or\n+          a[\"name\"].startswith(\"wheelhouse\"))\n+  ]\n+  for artifact in filtered_artifacts:\n+    url = artifact[\"archive_download_url\"]\n+    name = artifact[\"name\"]\n+    artifacts_size_mb = round(artifact[\"size_in_bytes\"] / (1024 * 1024), 2)\n+    print(\n+        f\"\\tDownloading {name}.zip artifact (size: {artifacts_size_mb} megabytes)\"\n+    )\n+    r = request_url(url, return_raw_request=True, allow_redirects=True)\n+\n+    with tempfile.NamedTemporaryFile(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE4MjI2OQ=="}, "originalCommit": {"oid": "0fc7383483cbe0c3891ade5456f0cc00abdd726d"}, "originalPosition": 206}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzYyNTg3Mg==", "bodyText": "I created separate PR for this: #12233\nSo it could merged to the master independently.", "url": "https://github.com/apache/beam/pull/12150#discussion_r453625872", "createdAt": "2020-07-13T12:51:02Z", "author": {"login": "TobKed"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,234 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+\n+  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n+  GITHUB_TOKEN = args.github_token\n+  USER_GITHUB_ID = args.github_user\n+  REPO_URL = args.repo_url\n+  RELEASE_BRANCH = args.release_branch\n+  RELEASE_COMMIT = args.release_commit\n+  ARTIFACTS_DIR = args.artifacts_dir\n+\n+\n+def request_url(url, return_raw_request=False, *args, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", GITHUB_TOKEN), **kwargs)\n+  r.raise_for_status()\n+  if return_raw_request:\n+    return r\n+  return r.json()\n+\n+\n+def get_yes_or_no_answer(question):\n+  \"\"\"Helper function to ask yes or no question\"\"\"\n+  reply = str(input(question + \" (y/n): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  if reply == \"n\":\n+    return False\n+  else:\n+    return get_yes_or_no_answer(\"Uhhhh... please enter \")\n+\n+\n+def get_build_wheels_workflow_id():\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=REPO_URL)\n+  data = request_url(url)\n+  return data[\"id\"]\n+\n+\n+def get_last_run(workflow_id):\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=REPO_URL, workflow_id=workflow_id)\n+  event_types = [\"push\", \"pull_request\"]\n+  runs = []\n+  for event in event_types:\n+    data = request_url(\n+        url,\n+        params={\n+            \"event\": event, \"branch\": RELEASE_BRANCH\n+        },\n+    )\n+    runs.extend(data[\"workflow_runs\"])\n+\n+  filtered_commit_runs = list(\n+      filter(lambda w: w.get(\"head_sha\", \"\") == RELEASE_COMMIT, runs))\n+  if not filtered_commit_runs:\n+    workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+        repo_url=REPO_URL, workflow_id=workflow_id)\n+    raise Exception(\n+        f\"No runs for workflow (branch {RELEASE_BRANCH}, commit {RELEASE_COMMIT}). Verify at {workflow_web_url}\"\n+    )\n+\n+  sorted_runs = sorted(\n+      filtered_commit_runs,\n+      key=lambda w: dateutil.parser.parse(w[\"created_at\"]),\n+      reverse=True,\n+  )\n+  last_run = sorted_runs[0]\n+  print(\n+      f\"Found last run. SHA: {RELEASE_COMMIT}, created_at: '{last_run['created_at']}', id: {last_run['id']}\"\n+  )\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=REPO_URL, workflow_id=last_run[\"id\"])\n+  print(f\"Verify at {workflow_web_url}\")\n+  print(\n+      f\"Optional upload to GCS will be available at:\\n\"\n+      f\"\\tgs://beam-wheels-staging/{RELEASE_BRANCH}/{RELEASE_COMMIT}-{workflow_id}/\"\n+  )\n+  return last_run\n+\n+\n+def validate_run(run_data):\n+  status = run_data[\"status\"]\n+  conclusion = run_data[\"conclusion\"]\n+  if status == \"completed\" and conclusion == \"success\":\n+    return run_data\n+\n+  url = run_data[\"url\"]\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=REPO_URL, workflow_id=run_data[\"id\"])\n+  print(\n+      f\"Started waiting for Workflow run {run_data['id']} to finish. Check on {workflow_web_url}\"\n+  )\n+  start_time = time.time()\n+  last_request = start_time\n+  spinner = itertools.cycle([\"|\", \"/\", \"-\", \"\\\\\"])\n+\n+  while True:\n+    now = time.time()\n+    elapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(now - start_time))\n+    print(\n+        f\"\\r {next(spinner)} Waiting to finish. Elapsed time: {elapsed_time}. \"\n+        f\"Current state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        end=\"\",\n+    )\n+\n+    time.sleep(0.3)\n+    if (now - last_request) > 10:\n+      last_request = now\n+      run_data = request_url(url)\n+      status = run_data[\"status\"]\n+      conclusion = run_data[\"conclusion\"]\n+      if status != \"completed\":\n+        continue\n+      elif conclusion == \"success\":\n+        print(\n+            f\"\\rFinished in: {elapsed_time}. \"\n+            f\"Last state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        )\n+        return run_data\n+      else:\n+        print(\"\\r\")\n+        raise Exception(\n+            f\"Run unsuccessful. Conclusion: {conclusion}. Payload: {run_data}\")\n+\n+\n+def reset_directory():\n+  question = (\n+      f\"Artifacts directory will be cleared. Is it OK for you?\\n\"\n+      f\"Artifacts directory: {ARTIFACTS_DIR}\\n\"\n+      f\"Your answer\")\n+  if get_yes_or_no_answer(question):\n+    print(f\"Clearing directory: {ARTIFACTS_DIR}\")\n+    shutil.rmtree(ARTIFACTS_DIR, ignore_errors=True)\n+    os.makedirs(ARTIFACTS_DIR)\n+  else:\n+    print(\"You said NO for clearing artifacts directory. Quitting ...\")\n+    quit(1)\n+\n+\n+def download_artifacts(artifacts_url):\n+  print(\"Starting downloading artifacts ... (it may take a while)\")\n+  data_artifacts = request_url(artifacts_url)\n+  filtered_artifacts = [\n+      a for a in data_artifacts[\"artifacts\"] if (\n+          a[\"name\"].startswith(\"source_gztar_zip\") or\n+          a[\"name\"].startswith(\"wheelhouse\"))\n+  ]\n+  for artifact in filtered_artifacts:\n+    url = artifact[\"archive_download_url\"]\n+    name = artifact[\"name\"]\n+    artifacts_size_mb = round(artifact[\"size_in_bytes\"] / (1024 * 1024), 2)\n+    print(\n+        f\"\\tDownloading {name}.zip artifact (size: {artifacts_size_mb} megabytes)\"\n+    )\n+    r = request_url(url, return_raw_request=True, allow_redirects=True)\n+\n+    with tempfile.NamedTemporaryFile(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE4MjI2OQ=="}, "originalCommit": {"oid": "0fc7383483cbe0c3891ade5456f0cc00abdd726d"}, "originalPosition": 206}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5OTczMzY0OnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/download_github_actions_artifacts.py", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQxNzo1ODozN1rOGsX-LQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QxNTowNzoxNFrOGwsz2w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE4MzI3Nw==", "bodyText": "return_raw_response ?", "url": "https://github.com/apache/beam/pull/12150#discussion_r449183277", "createdAt": "2020-07-02T17:58:37Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,234 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+\n+  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n+  GITHUB_TOKEN = args.github_token\n+  USER_GITHUB_ID = args.github_user\n+  REPO_URL = args.repo_url\n+  RELEASE_BRANCH = args.release_branch\n+  RELEASE_COMMIT = args.release_commit\n+  ARTIFACTS_DIR = args.artifacts_dir\n+\n+\n+def request_url(url, return_raw_request=False, *args, **kwargs):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0fc7383483cbe0c3891ade5456f0cc00abdd726d"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE5Mzg2OQ==", "bodyText": "Also we may as well always return json here (see a comment below for a suggestion to download files using streaming).", "url": "https://github.com/apache/beam/pull/12150#discussion_r449193869", "createdAt": "2020-07-02T18:20:07Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,234 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+\n+  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n+  GITHUB_TOKEN = args.github_token\n+  USER_GITHUB_ID = args.github_user\n+  REPO_URL = args.repo_url\n+  RELEASE_BRANCH = args.release_branch\n+  RELEASE_COMMIT = args.release_commit\n+  ARTIFACTS_DIR = args.artifacts_dir\n+\n+\n+def request_url(url, return_raw_request=False, *args, **kwargs):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE4MzI3Nw=="}, "originalCommit": {"oid": "0fc7383483cbe0c3891ade5456f0cc00abdd726d"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzcxOTAwMw==", "bodyText": "Thanks for pointing this out. I changed def request_url(url, return_json=True, *args, **kwargs): which seems to have more sense and as you said, allows streaming requests.", "url": "https://github.com/apache/beam/pull/12150#discussion_r453719003", "createdAt": "2020-07-13T15:07:14Z", "author": {"login": "TobKed"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,234 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+\n+  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n+  GITHUB_TOKEN = args.github_token\n+  USER_GITHUB_ID = args.github_user\n+  REPO_URL = args.repo_url\n+  RELEASE_BRANCH = args.release_branch\n+  RELEASE_COMMIT = args.release_commit\n+  ARTIFACTS_DIR = args.artifacts_dir\n+\n+\n+def request_url(url, return_raw_request=False, *args, **kwargs):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE4MzI3Nw=="}, "originalCommit": {"oid": "0fc7383483cbe0c3891ade5456f0cc00abdd726d"}, "originalPosition": 62}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5OTc4OTU0OnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/download_github_actions_artifacts.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQxODoxNjozNlrOGsYg8Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QxNDozOTozOFrOGwrkkg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE5MjE3Nw==", "bodyText": "I suggest downloading files in streaming mode:\n    with requests.get(url, auth=...,  stream=True) as r:\n        with tempfile.NamedTemporaryFile(...) as f:\n            shutil.copyfileobj(r.raw, f)\n\n(you could make another helper for that if you prefer).", "url": "https://github.com/apache/beam/pull/12150#discussion_r449192177", "createdAt": "2020-07-02T18:16:36Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,234 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+\n+  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n+  GITHUB_TOKEN = args.github_token\n+  USER_GITHUB_ID = args.github_user\n+  REPO_URL = args.repo_url\n+  RELEASE_BRANCH = args.release_branch\n+  RELEASE_COMMIT = args.release_commit\n+  ARTIFACTS_DIR = args.artifacts_dir\n+\n+\n+def request_url(url, return_raw_request=False, *args, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", GITHUB_TOKEN), **kwargs)\n+  r.raise_for_status()\n+  if return_raw_request:\n+    return r\n+  return r.json()\n+\n+\n+def get_yes_or_no_answer(question):\n+  \"\"\"Helper function to ask yes or no question\"\"\"\n+  reply = str(input(question + \" (y/n): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  if reply == \"n\":\n+    return False\n+  else:\n+    return get_yes_or_no_answer(\"Uhhhh... please enter \")\n+\n+\n+def get_build_wheels_workflow_id():\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=REPO_URL)\n+  data = request_url(url)\n+  return data[\"id\"]\n+\n+\n+def get_last_run(workflow_id):\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=REPO_URL, workflow_id=workflow_id)\n+  event_types = [\"push\", \"pull_request\"]\n+  runs = []\n+  for event in event_types:\n+    data = request_url(\n+        url,\n+        params={\n+            \"event\": event, \"branch\": RELEASE_BRANCH\n+        },\n+    )\n+    runs.extend(data[\"workflow_runs\"])\n+\n+  filtered_commit_runs = list(\n+      filter(lambda w: w.get(\"head_sha\", \"\") == RELEASE_COMMIT, runs))\n+  if not filtered_commit_runs:\n+    workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+        repo_url=REPO_URL, workflow_id=workflow_id)\n+    raise Exception(\n+        f\"No runs for workflow (branch {RELEASE_BRANCH}, commit {RELEASE_COMMIT}). Verify at {workflow_web_url}\"\n+    )\n+\n+  sorted_runs = sorted(\n+      filtered_commit_runs,\n+      key=lambda w: dateutil.parser.parse(w[\"created_at\"]),\n+      reverse=True,\n+  )\n+  last_run = sorted_runs[0]\n+  print(\n+      f\"Found last run. SHA: {RELEASE_COMMIT}, created_at: '{last_run['created_at']}', id: {last_run['id']}\"\n+  )\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=REPO_URL, workflow_id=last_run[\"id\"])\n+  print(f\"Verify at {workflow_web_url}\")\n+  print(\n+      f\"Optional upload to GCS will be available at:\\n\"\n+      f\"\\tgs://beam-wheels-staging/{RELEASE_BRANCH}/{RELEASE_COMMIT}-{workflow_id}/\"\n+  )\n+  return last_run\n+\n+\n+def validate_run(run_data):\n+  status = run_data[\"status\"]\n+  conclusion = run_data[\"conclusion\"]\n+  if status == \"completed\" and conclusion == \"success\":\n+    return run_data\n+\n+  url = run_data[\"url\"]\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=REPO_URL, workflow_id=run_data[\"id\"])\n+  print(\n+      f\"Started waiting for Workflow run {run_data['id']} to finish. Check on {workflow_web_url}\"\n+  )\n+  start_time = time.time()\n+  last_request = start_time\n+  spinner = itertools.cycle([\"|\", \"/\", \"-\", \"\\\\\"])\n+\n+  while True:\n+    now = time.time()\n+    elapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(now - start_time))\n+    print(\n+        f\"\\r {next(spinner)} Waiting to finish. Elapsed time: {elapsed_time}. \"\n+        f\"Current state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        end=\"\",\n+    )\n+\n+    time.sleep(0.3)\n+    if (now - last_request) > 10:\n+      last_request = now\n+      run_data = request_url(url)\n+      status = run_data[\"status\"]\n+      conclusion = run_data[\"conclusion\"]\n+      if status != \"completed\":\n+        continue\n+      elif conclusion == \"success\":\n+        print(\n+            f\"\\rFinished in: {elapsed_time}. \"\n+            f\"Last state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        )\n+        return run_data\n+      else:\n+        print(\"\\r\")\n+        raise Exception(\n+            f\"Run unsuccessful. Conclusion: {conclusion}. Payload: {run_data}\")\n+\n+\n+def reset_directory():\n+  question = (\n+      f\"Artifacts directory will be cleared. Is it OK for you?\\n\"\n+      f\"Artifacts directory: {ARTIFACTS_DIR}\\n\"\n+      f\"Your answer\")\n+  if get_yes_or_no_answer(question):\n+    print(f\"Clearing directory: {ARTIFACTS_DIR}\")\n+    shutil.rmtree(ARTIFACTS_DIR, ignore_errors=True)\n+    os.makedirs(ARTIFACTS_DIR)\n+  else:\n+    print(\"You said NO for clearing artifacts directory. Quitting ...\")\n+    quit(1)\n+\n+\n+def download_artifacts(artifacts_url):\n+  print(\"Starting downloading artifacts ... (it may take a while)\")\n+  data_artifacts = request_url(artifacts_url)\n+  filtered_artifacts = [\n+      a for a in data_artifacts[\"artifacts\"] if (\n+          a[\"name\"].startswith(\"source_gztar_zip\") or\n+          a[\"name\"].startswith(\"wheelhouse\"))\n+  ]\n+  for artifact in filtered_artifacts:\n+    url = artifact[\"archive_download_url\"]\n+    name = artifact[\"name\"]\n+    artifacts_size_mb = round(artifact[\"size_in_bytes\"] / (1024 * 1024), 2)\n+    print(\n+        f\"\\tDownloading {name}.zip artifact (size: {artifacts_size_mb} megabytes)\"\n+    )\n+    r = request_url(url, return_raw_request=True, allow_redirects=True)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0fc7383483cbe0c3891ade5456f0cc00abdd726d"}, "originalPosition": 204}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzY5ODcwNg==", "bodyText": "I applied your suggestion.", "url": "https://github.com/apache/beam/pull/12150#discussion_r453698706", "createdAt": "2020-07-13T14:39:38Z", "author": {"login": "TobKed"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,234 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+\n+  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n+  GITHUB_TOKEN = args.github_token\n+  USER_GITHUB_ID = args.github_user\n+  REPO_URL = args.repo_url\n+  RELEASE_BRANCH = args.release_branch\n+  RELEASE_COMMIT = args.release_commit\n+  ARTIFACTS_DIR = args.artifacts_dir\n+\n+\n+def request_url(url, return_raw_request=False, *args, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", GITHUB_TOKEN), **kwargs)\n+  r.raise_for_status()\n+  if return_raw_request:\n+    return r\n+  return r.json()\n+\n+\n+def get_yes_or_no_answer(question):\n+  \"\"\"Helper function to ask yes or no question\"\"\"\n+  reply = str(input(question + \" (y/n): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  if reply == \"n\":\n+    return False\n+  else:\n+    return get_yes_or_no_answer(\"Uhhhh... please enter \")\n+\n+\n+def get_build_wheels_workflow_id():\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=REPO_URL)\n+  data = request_url(url)\n+  return data[\"id\"]\n+\n+\n+def get_last_run(workflow_id):\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=REPO_URL, workflow_id=workflow_id)\n+  event_types = [\"push\", \"pull_request\"]\n+  runs = []\n+  for event in event_types:\n+    data = request_url(\n+        url,\n+        params={\n+            \"event\": event, \"branch\": RELEASE_BRANCH\n+        },\n+    )\n+    runs.extend(data[\"workflow_runs\"])\n+\n+  filtered_commit_runs = list(\n+      filter(lambda w: w.get(\"head_sha\", \"\") == RELEASE_COMMIT, runs))\n+  if not filtered_commit_runs:\n+    workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+        repo_url=REPO_URL, workflow_id=workflow_id)\n+    raise Exception(\n+        f\"No runs for workflow (branch {RELEASE_BRANCH}, commit {RELEASE_COMMIT}). Verify at {workflow_web_url}\"\n+    )\n+\n+  sorted_runs = sorted(\n+      filtered_commit_runs,\n+      key=lambda w: dateutil.parser.parse(w[\"created_at\"]),\n+      reverse=True,\n+  )\n+  last_run = sorted_runs[0]\n+  print(\n+      f\"Found last run. SHA: {RELEASE_COMMIT}, created_at: '{last_run['created_at']}', id: {last_run['id']}\"\n+  )\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=REPO_URL, workflow_id=last_run[\"id\"])\n+  print(f\"Verify at {workflow_web_url}\")\n+  print(\n+      f\"Optional upload to GCS will be available at:\\n\"\n+      f\"\\tgs://beam-wheels-staging/{RELEASE_BRANCH}/{RELEASE_COMMIT}-{workflow_id}/\"\n+  )\n+  return last_run\n+\n+\n+def validate_run(run_data):\n+  status = run_data[\"status\"]\n+  conclusion = run_data[\"conclusion\"]\n+  if status == \"completed\" and conclusion == \"success\":\n+    return run_data\n+\n+  url = run_data[\"url\"]\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=REPO_URL, workflow_id=run_data[\"id\"])\n+  print(\n+      f\"Started waiting for Workflow run {run_data['id']} to finish. Check on {workflow_web_url}\"\n+  )\n+  start_time = time.time()\n+  last_request = start_time\n+  spinner = itertools.cycle([\"|\", \"/\", \"-\", \"\\\\\"])\n+\n+  while True:\n+    now = time.time()\n+    elapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(now - start_time))\n+    print(\n+        f\"\\r {next(spinner)} Waiting to finish. Elapsed time: {elapsed_time}. \"\n+        f\"Current state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        end=\"\",\n+    )\n+\n+    time.sleep(0.3)\n+    if (now - last_request) > 10:\n+      last_request = now\n+      run_data = request_url(url)\n+      status = run_data[\"status\"]\n+      conclusion = run_data[\"conclusion\"]\n+      if status != \"completed\":\n+        continue\n+      elif conclusion == \"success\":\n+        print(\n+            f\"\\rFinished in: {elapsed_time}. \"\n+            f\"Last state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        )\n+        return run_data\n+      else:\n+        print(\"\\r\")\n+        raise Exception(\n+            f\"Run unsuccessful. Conclusion: {conclusion}. Payload: {run_data}\")\n+\n+\n+def reset_directory():\n+  question = (\n+      f\"Artifacts directory will be cleared. Is it OK for you?\\n\"\n+      f\"Artifacts directory: {ARTIFACTS_DIR}\\n\"\n+      f\"Your answer\")\n+  if get_yes_or_no_answer(question):\n+    print(f\"Clearing directory: {ARTIFACTS_DIR}\")\n+    shutil.rmtree(ARTIFACTS_DIR, ignore_errors=True)\n+    os.makedirs(ARTIFACTS_DIR)\n+  else:\n+    print(\"You said NO for clearing artifacts directory. Quitting ...\")\n+    quit(1)\n+\n+\n+def download_artifacts(artifacts_url):\n+  print(\"Starting downloading artifacts ... (it may take a while)\")\n+  data_artifacts = request_url(artifacts_url)\n+  filtered_artifacts = [\n+      a for a in data_artifacts[\"artifacts\"] if (\n+          a[\"name\"].startswith(\"source_gztar_zip\") or\n+          a[\"name\"].startswith(\"wheelhouse\"))\n+  ]\n+  for artifact in filtered_artifacts:\n+    url = artifact[\"archive_download_url\"]\n+    name = artifact[\"name\"]\n+    artifacts_size_mb = round(artifact[\"size_in_bytes\"] / (1024 * 1024), 2)\n+    print(\n+        f\"\\tDownloading {name}.zip artifact (size: {artifacts_size_mb} megabytes)\"\n+    )\n+    r = request_url(url, return_raw_request=True, allow_redirects=True)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE5MjE3Nw=="}, "originalCommit": {"oid": "0fc7383483cbe0c3891ade5456f0cc00abdd726d"}, "originalPosition": 204}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5OTgzMzc4OnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/download_github_actions_artifacts.py", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQxODozMTo1MVrOGsY9Yw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQxODozMTo1MVrOGsY9Yw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTE5OTQ1OQ==", "bodyText": "Let's s/Uhhhh... please enter/Please enter 'y' or 'n'", "url": "https://github.com/apache/beam/pull/12150#discussion_r449199459", "createdAt": "2020-07-02T18:31:51Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,234 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+\n+  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n+  GITHUB_TOKEN = args.github_token\n+  USER_GITHUB_ID = args.github_user\n+  REPO_URL = args.repo_url\n+  RELEASE_BRANCH = args.release_branch\n+  RELEASE_COMMIT = args.release_commit\n+  ARTIFACTS_DIR = args.artifacts_dir\n+\n+\n+def request_url(url, return_raw_request=False, *args, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", GITHUB_TOKEN), **kwargs)\n+  r.raise_for_status()\n+  if return_raw_request:\n+    return r\n+  return r.json()\n+\n+\n+def get_yes_or_no_answer(question):\n+  \"\"\"Helper function to ask yes or no question\"\"\"\n+  reply = str(input(question + \" (y/n): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  if reply == \"n\":\n+    return False\n+  else:\n+    return get_yes_or_no_answer(\"Uhhhh... please enter \")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0fc7383483cbe0c3891ade5456f0cc00abdd726d"}, "originalPosition": 79}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5OTg2MjkyOnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/download_github_actions_artifacts.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQxODo0MTo0NFrOGsZPbw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQxMToxNjoyNFrOGx5hvw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTIwNDA3OQ==", "bodyText": "Here we are making an assumption that  response data will have a key workflow_runs. If this does not happen, the script will crash with a KeyError. It would be more helpful for debugging the script if we failed with a more meaningful error and let the user know that we sent a request X and expected a reply to have fields Y, Z,... but got ... instead.\nSame comment applies to other places where we use request_url.\nConsider adding a check for expected output keys to request_url method.", "url": "https://github.com/apache/beam/pull/12150#discussion_r449204079", "createdAt": "2020-07-02T18:41:44Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,234 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+\n+  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n+  GITHUB_TOKEN = args.github_token\n+  USER_GITHUB_ID = args.github_user\n+  REPO_URL = args.repo_url\n+  RELEASE_BRANCH = args.release_branch\n+  RELEASE_COMMIT = args.release_commit\n+  ARTIFACTS_DIR = args.artifacts_dir\n+\n+\n+def request_url(url, return_raw_request=False, *args, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", GITHUB_TOKEN), **kwargs)\n+  r.raise_for_status()\n+  if return_raw_request:\n+    return r\n+  return r.json()\n+\n+\n+def get_yes_or_no_answer(question):\n+  \"\"\"Helper function to ask yes or no question\"\"\"\n+  reply = str(input(question + \" (y/n): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  if reply == \"n\":\n+    return False\n+  else:\n+    return get_yes_or_no_answer(\"Uhhhh... please enter \")\n+\n+\n+def get_build_wheels_workflow_id():\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=REPO_URL)\n+  data = request_url(url)\n+  return data[\"id\"]\n+\n+\n+def get_last_run(workflow_id):\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=REPO_URL, workflow_id=workflow_id)\n+  event_types = [\"push\", \"pull_request\"]\n+  runs = []\n+  for event in event_types:\n+    data = request_url(\n+        url,\n+        params={\n+            \"event\": event, \"branch\": RELEASE_BRANCH\n+        },\n+    )\n+    runs.extend(data[\"workflow_runs\"])", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0fc7383483cbe0c3891ade5456f0cc00abdd726d"}, "originalPosition": 100}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDk3NTkzNQ==", "bodyText": "I made something little bit different to provide more descriptive exception. Please take a look.", "url": "https://github.com/apache/beam/pull/12150#discussion_r454975935", "createdAt": "2020-07-15T11:16:24Z", "author": {"login": "TobKed"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,234 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+\n+  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n+  GITHUB_TOKEN = args.github_token\n+  USER_GITHUB_ID = args.github_user\n+  REPO_URL = args.repo_url\n+  RELEASE_BRANCH = args.release_branch\n+  RELEASE_COMMIT = args.release_commit\n+  ARTIFACTS_DIR = args.artifacts_dir\n+\n+\n+def request_url(url, return_raw_request=False, *args, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", GITHUB_TOKEN), **kwargs)\n+  r.raise_for_status()\n+  if return_raw_request:\n+    return r\n+  return r.json()\n+\n+\n+def get_yes_or_no_answer(question):\n+  \"\"\"Helper function to ask yes or no question\"\"\"\n+  reply = str(input(question + \" (y/n): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  if reply == \"n\":\n+    return False\n+  else:\n+    return get_yes_or_no_answer(\"Uhhhh... please enter \")\n+\n+\n+def get_build_wheels_workflow_id():\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=REPO_URL)\n+  data = request_url(url)\n+  return data[\"id\"]\n+\n+\n+def get_last_run(workflow_id):\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=REPO_URL, workflow_id=workflow_id)\n+  event_types = [\"push\", \"pull_request\"]\n+  runs = []\n+  for event in event_types:\n+    data = request_url(\n+        url,\n+        params={\n+            \"event\": event, \"branch\": RELEASE_BRANCH\n+        },\n+    )\n+    runs.extend(data[\"workflow_runs\"])", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTIwNDA3OQ=="}, "originalCommit": {"oid": "0fc7383483cbe0c3891ade5456f0cc00abdd726d"}, "originalPosition": 100}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5OTkyMDk3OnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/download_github_actions_artifacts.py", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQxOTowMTozOVrOGsZzTw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQxOTowMTozOVrOGsZzTw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTIxMzI2Mw==", "bodyText": "Can we print all the provided arguments and prompt the user to confirm whether they are correct before proceeding?", "url": "https://github.com/apache/beam/pull/12150#discussion_r449213263", "createdAt": "2020-07-02T19:01:39Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,234 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+\n+  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n+  GITHUB_TOKEN = args.github_token\n+  USER_GITHUB_ID = args.github_user\n+  REPO_URL = args.repo_url\n+  RELEASE_BRANCH = args.release_branch\n+  RELEASE_COMMIT = args.release_commit\n+  ARTIFACTS_DIR = args.artifacts_dir\n+\n+\n+def request_url(url, return_raw_request=False, *args, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", GITHUB_TOKEN), **kwargs)\n+  r.raise_for_status()\n+  if return_raw_request:\n+    return r\n+  return r.json()\n+\n+\n+def get_yes_or_no_answer(question):\n+  \"\"\"Helper function to ask yes or no question\"\"\"\n+  reply = str(input(question + \" (y/n): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  if reply == \"n\":\n+    return False\n+  else:\n+    return get_yes_or_no_answer(\"Uhhhh... please enter \")\n+\n+\n+def get_build_wheels_workflow_id():\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=REPO_URL)\n+  data = request_url(url)\n+  return data[\"id\"]\n+\n+\n+def get_last_run(workflow_id):\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=REPO_URL, workflow_id=workflow_id)\n+  event_types = [\"push\", \"pull_request\"]\n+  runs = []\n+  for event in event_types:\n+    data = request_url(\n+        url,\n+        params={\n+            \"event\": event, \"branch\": RELEASE_BRANCH\n+        },\n+    )\n+    runs.extend(data[\"workflow_runs\"])\n+\n+  filtered_commit_runs = list(\n+      filter(lambda w: w.get(\"head_sha\", \"\") == RELEASE_COMMIT, runs))\n+  if not filtered_commit_runs:\n+    workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+        repo_url=REPO_URL, workflow_id=workflow_id)\n+    raise Exception(\n+        f\"No runs for workflow (branch {RELEASE_BRANCH}, commit {RELEASE_COMMIT}). Verify at {workflow_web_url}\"\n+    )\n+\n+  sorted_runs = sorted(\n+      filtered_commit_runs,\n+      key=lambda w: dateutil.parser.parse(w[\"created_at\"]),\n+      reverse=True,\n+  )\n+  last_run = sorted_runs[0]\n+  print(\n+      f\"Found last run. SHA: {RELEASE_COMMIT}, created_at: '{last_run['created_at']}', id: {last_run['id']}\"\n+  )\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=REPO_URL, workflow_id=last_run[\"id\"])\n+  print(f\"Verify at {workflow_web_url}\")\n+  print(\n+      f\"Optional upload to GCS will be available at:\\n\"\n+      f\"\\tgs://beam-wheels-staging/{RELEASE_BRANCH}/{RELEASE_COMMIT}-{workflow_id}/\"\n+  )\n+  return last_run\n+\n+\n+def validate_run(run_data):\n+  status = run_data[\"status\"]\n+  conclusion = run_data[\"conclusion\"]\n+  if status == \"completed\" and conclusion == \"success\":\n+    return run_data\n+\n+  url = run_data[\"url\"]\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=REPO_URL, workflow_id=run_data[\"id\"])\n+  print(\n+      f\"Started waiting for Workflow run {run_data['id']} to finish. Check on {workflow_web_url}\"\n+  )\n+  start_time = time.time()\n+  last_request = start_time\n+  spinner = itertools.cycle([\"|\", \"/\", \"-\", \"\\\\\"])\n+\n+  while True:\n+    now = time.time()\n+    elapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(now - start_time))\n+    print(\n+        f\"\\r {next(spinner)} Waiting to finish. Elapsed time: {elapsed_time}. \"\n+        f\"Current state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        end=\"\",\n+    )\n+\n+    time.sleep(0.3)\n+    if (now - last_request) > 10:\n+      last_request = now\n+      run_data = request_url(url)\n+      status = run_data[\"status\"]\n+      conclusion = run_data[\"conclusion\"]\n+      if status != \"completed\":\n+        continue\n+      elif conclusion == \"success\":\n+        print(\n+            f\"\\rFinished in: {elapsed_time}. \"\n+            f\"Last state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        )\n+        return run_data\n+      else:\n+        print(\"\\r\")\n+        raise Exception(\n+            f\"Run unsuccessful. Conclusion: {conclusion}. Payload: {run_data}\")\n+\n+\n+def reset_directory():\n+  question = (\n+      f\"Artifacts directory will be cleared. Is it OK for you?\\n\"\n+      f\"Artifacts directory: {ARTIFACTS_DIR}\\n\"\n+      f\"Your answer\")\n+  if get_yes_or_no_answer(question):\n+    print(f\"Clearing directory: {ARTIFACTS_DIR}\")\n+    shutil.rmtree(ARTIFACTS_DIR, ignore_errors=True)\n+    os.makedirs(ARTIFACTS_DIR)\n+  else:\n+    print(\"You said NO for clearing artifacts directory. Quitting ...\")\n+    quit(1)\n+\n+\n+def download_artifacts(artifacts_url):\n+  print(\"Starting downloading artifacts ... (it may take a while)\")\n+  data_artifacts = request_url(artifacts_url)\n+  filtered_artifacts = [\n+      a for a in data_artifacts[\"artifacts\"] if (\n+          a[\"name\"].startswith(\"source_gztar_zip\") or\n+          a[\"name\"].startswith(\"wheelhouse\"))\n+  ]\n+  for artifact in filtered_artifacts:\n+    url = artifact[\"archive_download_url\"]\n+    name = artifact[\"name\"]\n+    artifacts_size_mb = round(artifact[\"size_in_bytes\"] / (1024 * 1024), 2)\n+    print(\n+        f\"\\tDownloading {name}.zip artifact (size: {artifacts_size_mb} megabytes)\"\n+    )\n+    r = request_url(url, return_raw_request=True, allow_redirects=True)\n+\n+    with tempfile.NamedTemporaryFile(\n+        \"wb\",\n+        prefix=name,\n+        suffix=\".zip\",\n+    ) as f:\n+      f.write(r.content)\n+\n+      with zipfile.ZipFile(f.name, \"r\") as zip_ref:\n+        print(f\"\\tUnzipping {len(zip_ref.filelist)} files\")\n+        zip_ref.extractall(ARTIFACTS_DIR)\n+\n+\n+if __name__ == \"__main__\":\n+  print(\n+      \"Starting script for download GitHub Actions artifacts for Build Wheels workflow\"\n+  )\n+  parse_arguments()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0fc7383483cbe0c3891ade5456f0cc00abdd726d"}, "originalPosition": 222}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc5OTk1ODQzOnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/download_github_actions_artifacts.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQxOToxNDoyNFrOGsaKPQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNFQxMToyNToxNVrOGxPepA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTIxOTEzMw==", "bodyText": "List comprehension may be simpler to follow. How about:\nruns_for_release_commit = [r for r in runs if r.get(\"head_sha\", \"\") == RELEASE_COMMIT]", "url": "https://github.com/apache/beam/pull/12150#discussion_r449219133", "createdAt": "2020-07-02T19:14:24Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,234 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+\n+  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n+  GITHUB_TOKEN = args.github_token\n+  USER_GITHUB_ID = args.github_user\n+  REPO_URL = args.repo_url\n+  RELEASE_BRANCH = args.release_branch\n+  RELEASE_COMMIT = args.release_commit\n+  ARTIFACTS_DIR = args.artifacts_dir\n+\n+\n+def request_url(url, return_raw_request=False, *args, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", GITHUB_TOKEN), **kwargs)\n+  r.raise_for_status()\n+  if return_raw_request:\n+    return r\n+  return r.json()\n+\n+\n+def get_yes_or_no_answer(question):\n+  \"\"\"Helper function to ask yes or no question\"\"\"\n+  reply = str(input(question + \" (y/n): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  if reply == \"n\":\n+    return False\n+  else:\n+    return get_yes_or_no_answer(\"Uhhhh... please enter \")\n+\n+\n+def get_build_wheels_workflow_id():\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=REPO_URL)\n+  data = request_url(url)\n+  return data[\"id\"]\n+\n+\n+def get_last_run(workflow_id):\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=REPO_URL, workflow_id=workflow_id)\n+  event_types = [\"push\", \"pull_request\"]\n+  runs = []\n+  for event in event_types:\n+    data = request_url(\n+        url,\n+        params={\n+            \"event\": event, \"branch\": RELEASE_BRANCH\n+        },\n+    )\n+    runs.extend(data[\"workflow_runs\"])\n+\n+  filtered_commit_runs = list(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0fc7383483cbe0c3891ade5456f0cc00abdd726d"}, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDI4NzAxMg==", "bodyText": "Great suggestion, applied :)", "url": "https://github.com/apache/beam/pull/12150#discussion_r454287012", "createdAt": "2020-07-14T11:25:15Z", "author": {"login": "TobKed"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,234 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+\n+  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n+  GITHUB_TOKEN = args.github_token\n+  USER_GITHUB_ID = args.github_user\n+  REPO_URL = args.repo_url\n+  RELEASE_BRANCH = args.release_branch\n+  RELEASE_COMMIT = args.release_commit\n+  ARTIFACTS_DIR = args.artifacts_dir\n+\n+\n+def request_url(url, return_raw_request=False, *args, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", GITHUB_TOKEN), **kwargs)\n+  r.raise_for_status()\n+  if return_raw_request:\n+    return r\n+  return r.json()\n+\n+\n+def get_yes_or_no_answer(question):\n+  \"\"\"Helper function to ask yes or no question\"\"\"\n+  reply = str(input(question + \" (y/n): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  if reply == \"n\":\n+    return False\n+  else:\n+    return get_yes_or_no_answer(\"Uhhhh... please enter \")\n+\n+\n+def get_build_wheels_workflow_id():\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=REPO_URL)\n+  data = request_url(url)\n+  return data[\"id\"]\n+\n+\n+def get_last_run(workflow_id):\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=REPO_URL, workflow_id=workflow_id)\n+  event_types = [\"push\", \"pull_request\"]\n+  runs = []\n+  for event in event_types:\n+    data = request_url(\n+        url,\n+        params={\n+            \"event\": event, \"branch\": RELEASE_BRANCH\n+        },\n+    )\n+    runs.extend(data[\"workflow_runs\"])\n+\n+  filtered_commit_runs = list(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTIxOTEzMw=="}, "originalCommit": {"oid": "0fc7383483cbe0c3891ade5456f0cc00abdd726d"}, "originalPosition": 102}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMDAxOTY3OnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/download_github_actions_artifacts.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQxOTozNjoxM1rOGsavcQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QxNToyMDoyOFrOGwtZxA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTIyODY1Nw==", "bodyText": "What does optional mean here?\nShould we say: Wheels for this workflow are also available at: ...\nIf we need to support in-progress workflows, then we can print this once we verified the workflow has finished.", "url": "https://github.com/apache/beam/pull/12150#discussion_r449228657", "createdAt": "2020-07-02T19:36:13Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,234 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+\n+  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n+  GITHUB_TOKEN = args.github_token\n+  USER_GITHUB_ID = args.github_user\n+  REPO_URL = args.repo_url\n+  RELEASE_BRANCH = args.release_branch\n+  RELEASE_COMMIT = args.release_commit\n+  ARTIFACTS_DIR = args.artifacts_dir\n+\n+\n+def request_url(url, return_raw_request=False, *args, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", GITHUB_TOKEN), **kwargs)\n+  r.raise_for_status()\n+  if return_raw_request:\n+    return r\n+  return r.json()\n+\n+\n+def get_yes_or_no_answer(question):\n+  \"\"\"Helper function to ask yes or no question\"\"\"\n+  reply = str(input(question + \" (y/n): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  if reply == \"n\":\n+    return False\n+  else:\n+    return get_yes_or_no_answer(\"Uhhhh... please enter \")\n+\n+\n+def get_build_wheels_workflow_id():\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=REPO_URL)\n+  data = request_url(url)\n+  return data[\"id\"]\n+\n+\n+def get_last_run(workflow_id):\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=REPO_URL, workflow_id=workflow_id)\n+  event_types = [\"push\", \"pull_request\"]\n+  runs = []\n+  for event in event_types:\n+    data = request_url(\n+        url,\n+        params={\n+            \"event\": event, \"branch\": RELEASE_BRANCH\n+        },\n+    )\n+    runs.extend(data[\"workflow_runs\"])\n+\n+  filtered_commit_runs = list(\n+      filter(lambda w: w.get(\"head_sha\", \"\") == RELEASE_COMMIT, runs))\n+  if not filtered_commit_runs:\n+    workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+        repo_url=REPO_URL, workflow_id=workflow_id)\n+    raise Exception(\n+        f\"No runs for workflow (branch {RELEASE_BRANCH}, commit {RELEASE_COMMIT}). Verify at {workflow_web_url}\"\n+    )\n+\n+  sorted_runs = sorted(\n+      filtered_commit_runs,\n+      key=lambda w: dateutil.parser.parse(w[\"created_at\"]),\n+      reverse=True,\n+  )\n+  last_run = sorted_runs[0]\n+  print(\n+      f\"Found last run. SHA: {RELEASE_COMMIT}, created_at: '{last_run['created_at']}', id: {last_run['id']}\"\n+  )\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=REPO_URL, workflow_id=last_run[\"id\"])\n+  print(f\"Verify at {workflow_web_url}\")\n+  print(\n+      f\"Optional upload to GCS will be available at:\\n\"\n+      f\"\\tgs://beam-wheels-staging/{RELEASE_BRANCH}/{RELEASE_COMMIT}-{workflow_id}/\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0fc7383483cbe0c3891ade5456f0cc00abdd726d"}, "originalPosition": 125}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzcyODcwOA==", "bodyText": "I used word \"optional\" here In case someone may want to use this script on the branch which will not upload files to GCS. But only on \"push\" event (as you mentioned below) on master and release-* branches files will be uploaded  your suggestion has more sense :)", "url": "https://github.com/apache/beam/pull/12150#discussion_r453728708", "createdAt": "2020-07-13T15:20:28Z", "author": {"login": "TobKed"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,234 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+\n+  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n+  GITHUB_TOKEN = args.github_token\n+  USER_GITHUB_ID = args.github_user\n+  REPO_URL = args.repo_url\n+  RELEASE_BRANCH = args.release_branch\n+  RELEASE_COMMIT = args.release_commit\n+  ARTIFACTS_DIR = args.artifacts_dir\n+\n+\n+def request_url(url, return_raw_request=False, *args, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", GITHUB_TOKEN), **kwargs)\n+  r.raise_for_status()\n+  if return_raw_request:\n+    return r\n+  return r.json()\n+\n+\n+def get_yes_or_no_answer(question):\n+  \"\"\"Helper function to ask yes or no question\"\"\"\n+  reply = str(input(question + \" (y/n): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  if reply == \"n\":\n+    return False\n+  else:\n+    return get_yes_or_no_answer(\"Uhhhh... please enter \")\n+\n+\n+def get_build_wheels_workflow_id():\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=REPO_URL)\n+  data = request_url(url)\n+  return data[\"id\"]\n+\n+\n+def get_last_run(workflow_id):\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=REPO_URL, workflow_id=workflow_id)\n+  event_types = [\"push\", \"pull_request\"]\n+  runs = []\n+  for event in event_types:\n+    data = request_url(\n+        url,\n+        params={\n+            \"event\": event, \"branch\": RELEASE_BRANCH\n+        },\n+    )\n+    runs.extend(data[\"workflow_runs\"])\n+\n+  filtered_commit_runs = list(\n+      filter(lambda w: w.get(\"head_sha\", \"\") == RELEASE_COMMIT, runs))\n+  if not filtered_commit_runs:\n+    workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+        repo_url=REPO_URL, workflow_id=workflow_id)\n+    raise Exception(\n+        f\"No runs for workflow (branch {RELEASE_BRANCH}, commit {RELEASE_COMMIT}). Verify at {workflow_web_url}\"\n+    )\n+\n+  sorted_runs = sorted(\n+      filtered_commit_runs,\n+      key=lambda w: dateutil.parser.parse(w[\"created_at\"]),\n+      reverse=True,\n+  )\n+  last_run = sorted_runs[0]\n+  print(\n+      f\"Found last run. SHA: {RELEASE_COMMIT}, created_at: '{last_run['created_at']}', id: {last_run['id']}\"\n+  )\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=REPO_URL, workflow_id=last_run[\"id\"])\n+  print(f\"Verify at {workflow_web_url}\")\n+  print(\n+      f\"Optional upload to GCS will be available at:\\n\"\n+      f\"\\tgs://beam-wheels-staging/{RELEASE_BRANCH}/{RELEASE_COMMIT}-{workflow_id}/\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTIyODY1Nw=="}, "originalCommit": {"oid": "0fc7383483cbe0c3891ade5456f0cc00abdd726d"}, "originalPosition": 125}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMDAzNjEwOnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/download_github_actions_artifacts.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQxOTo0MjoxNVrOGsa5Sg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QxNToyMToxMVrOGwtb_g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTIzMTE3OA==", "bodyText": "Why do we want to retrieve runs on pull_requests? Shouldn't we only consider 'push' runs only?", "url": "https://github.com/apache/beam/pull/12150#discussion_r449231178", "createdAt": "2020-07-02T19:42:15Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,234 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+\n+  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n+  GITHUB_TOKEN = args.github_token\n+  USER_GITHUB_ID = args.github_user\n+  REPO_URL = args.repo_url\n+  RELEASE_BRANCH = args.release_branch\n+  RELEASE_COMMIT = args.release_commit\n+  ARTIFACTS_DIR = args.artifacts_dir\n+\n+\n+def request_url(url, return_raw_request=False, *args, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", GITHUB_TOKEN), **kwargs)\n+  r.raise_for_status()\n+  if return_raw_request:\n+    return r\n+  return r.json()\n+\n+\n+def get_yes_or_no_answer(question):\n+  \"\"\"Helper function to ask yes or no question\"\"\"\n+  reply = str(input(question + \" (y/n): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  if reply == \"n\":\n+    return False\n+  else:\n+    return get_yes_or_no_answer(\"Uhhhh... please enter \")\n+\n+\n+def get_build_wheels_workflow_id():\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=REPO_URL)\n+  data = request_url(url)\n+  return data[\"id\"]\n+\n+\n+def get_last_run(workflow_id):\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=REPO_URL, workflow_id=workflow_id)\n+  event_types = [\"push\", \"pull_request\"]", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0fc7383483cbe0c3891ade5456f0cc00abdd726d"}, "originalPosition": 91}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzcyOTI3OA==", "bodyText": "Yes, you are right. \"push\" runs only.", "url": "https://github.com/apache/beam/pull/12150#discussion_r453729278", "createdAt": "2020-07-13T15:21:11Z", "author": {"login": "TobKed"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,234 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+\n+  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n+  GITHUB_TOKEN = args.github_token\n+  USER_GITHUB_ID = args.github_user\n+  REPO_URL = args.repo_url\n+  RELEASE_BRANCH = args.release_branch\n+  RELEASE_COMMIT = args.release_commit\n+  ARTIFACTS_DIR = args.artifacts_dir\n+\n+\n+def request_url(url, return_raw_request=False, *args, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", GITHUB_TOKEN), **kwargs)\n+  r.raise_for_status()\n+  if return_raw_request:\n+    return r\n+  return r.json()\n+\n+\n+def get_yes_or_no_answer(question):\n+  \"\"\"Helper function to ask yes or no question\"\"\"\n+  reply = str(input(question + \" (y/n): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  if reply == \"n\":\n+    return False\n+  else:\n+    return get_yes_or_no_answer(\"Uhhhh... please enter \")\n+\n+\n+def get_build_wheels_workflow_id():\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=REPO_URL)\n+  data = request_url(url)\n+  return data[\"id\"]\n+\n+\n+def get_last_run(workflow_id):\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=REPO_URL, workflow_id=workflow_id)\n+  event_types = [\"push\", \"pull_request\"]", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTIzMTE3OA=="}, "originalCommit": {"oid": "0fc7383483cbe0c3891ade5456f0cc00abdd726d"}, "originalPosition": 91}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMDEwMDczOnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/download_github_actions_artifacts.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQyMDowNjo1MFrOGsbheA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QxNjo1MzoyOFrOGwxNFQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTI0MTQ2NA==", "bodyText": "What are other options besides 'completed' that we expect to support? It's better to be explicit:\n       ....\n  while( status == \"in-progress\"):\n        # wait\n   if status == \"completed\":\n       # return  artifacts_url\n   else:\n       # error", "url": "https://github.com/apache/beam/pull/12150#discussion_r449241464", "createdAt": "2020-07-02T20:06:50Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,234 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+\n+  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n+  GITHUB_TOKEN = args.github_token\n+  USER_GITHUB_ID = args.github_user\n+  REPO_URL = args.repo_url\n+  RELEASE_BRANCH = args.release_branch\n+  RELEASE_COMMIT = args.release_commit\n+  ARTIFACTS_DIR = args.artifacts_dir\n+\n+\n+def request_url(url, return_raw_request=False, *args, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", GITHUB_TOKEN), **kwargs)\n+  r.raise_for_status()\n+  if return_raw_request:\n+    return r\n+  return r.json()\n+\n+\n+def get_yes_or_no_answer(question):\n+  \"\"\"Helper function to ask yes or no question\"\"\"\n+  reply = str(input(question + \" (y/n): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  if reply == \"n\":\n+    return False\n+  else:\n+    return get_yes_or_no_answer(\"Uhhhh... please enter \")\n+\n+\n+def get_build_wheels_workflow_id():\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=REPO_URL)\n+  data = request_url(url)\n+  return data[\"id\"]\n+\n+\n+def get_last_run(workflow_id):\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=REPO_URL, workflow_id=workflow_id)\n+  event_types = [\"push\", \"pull_request\"]\n+  runs = []\n+  for event in event_types:\n+    data = request_url(\n+        url,\n+        params={\n+            \"event\": event, \"branch\": RELEASE_BRANCH\n+        },\n+    )\n+    runs.extend(data[\"workflow_runs\"])\n+\n+  filtered_commit_runs = list(\n+      filter(lambda w: w.get(\"head_sha\", \"\") == RELEASE_COMMIT, runs))\n+  if not filtered_commit_runs:\n+    workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+        repo_url=REPO_URL, workflow_id=workflow_id)\n+    raise Exception(\n+        f\"No runs for workflow (branch {RELEASE_BRANCH}, commit {RELEASE_COMMIT}). Verify at {workflow_web_url}\"\n+    )\n+\n+  sorted_runs = sorted(\n+      filtered_commit_runs,\n+      key=lambda w: dateutil.parser.parse(w[\"created_at\"]),\n+      reverse=True,\n+  )\n+  last_run = sorted_runs[0]\n+  print(\n+      f\"Found last run. SHA: {RELEASE_COMMIT}, created_at: '{last_run['created_at']}', id: {last_run['id']}\"\n+  )\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=REPO_URL, workflow_id=last_run[\"id\"])\n+  print(f\"Verify at {workflow_web_url}\")\n+  print(\n+      f\"Optional upload to GCS will be available at:\\n\"\n+      f\"\\tgs://beam-wheels-staging/{RELEASE_BRANCH}/{RELEASE_COMMIT}-{workflow_id}/\"\n+  )\n+  return last_run\n+\n+\n+def validate_run(run_data):\n+  status = run_data[\"status\"]\n+  conclusion = run_data[\"conclusion\"]\n+  if status == \"completed\" and conclusion == \"success\":\n+    return run_data\n+\n+  url = run_data[\"url\"]\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=REPO_URL, workflow_id=run_data[\"id\"])\n+  print(\n+      f\"Started waiting for Workflow run {run_data['id']} to finish. Check on {workflow_web_url}\"\n+  )\n+  start_time = time.time()\n+  last_request = start_time\n+  spinner = itertools.cycle([\"|\", \"/\", \"-\", \"\\\\\"])\n+\n+  while True:\n+    now = time.time()\n+    elapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(now - start_time))\n+    print(\n+        f\"\\r {next(spinner)} Waiting to finish. Elapsed time: {elapsed_time}. \"\n+        f\"Current state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        end=\"\",\n+    )\n+\n+    time.sleep(0.3)\n+    if (now - last_request) > 10:\n+      last_request = now\n+      run_data = request_url(url)\n+      status = run_data[\"status\"]\n+      conclusion = run_data[\"conclusion\"]\n+      if status != \"completed\":", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0fc7383483cbe0c3891ade5456f0cc00abdd726d"}, "originalPosition": 161}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Mzc5MDk5Nw==", "bodyText": "Sure, I made it more explicit.", "url": "https://github.com/apache/beam/pull/12150#discussion_r453790997", "createdAt": "2020-07-13T16:53:28Z", "author": {"login": "TobKed"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,234 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+\n+  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n+  GITHUB_TOKEN = args.github_token\n+  USER_GITHUB_ID = args.github_user\n+  REPO_URL = args.repo_url\n+  RELEASE_BRANCH = args.release_branch\n+  RELEASE_COMMIT = args.release_commit\n+  ARTIFACTS_DIR = args.artifacts_dir\n+\n+\n+def request_url(url, return_raw_request=False, *args, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", GITHUB_TOKEN), **kwargs)\n+  r.raise_for_status()\n+  if return_raw_request:\n+    return r\n+  return r.json()\n+\n+\n+def get_yes_or_no_answer(question):\n+  \"\"\"Helper function to ask yes or no question\"\"\"\n+  reply = str(input(question + \" (y/n): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  if reply == \"n\":\n+    return False\n+  else:\n+    return get_yes_or_no_answer(\"Uhhhh... please enter \")\n+\n+\n+def get_build_wheels_workflow_id():\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=REPO_URL)\n+  data = request_url(url)\n+  return data[\"id\"]\n+\n+\n+def get_last_run(workflow_id):\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=REPO_URL, workflow_id=workflow_id)\n+  event_types = [\"push\", \"pull_request\"]\n+  runs = []\n+  for event in event_types:\n+    data = request_url(\n+        url,\n+        params={\n+            \"event\": event, \"branch\": RELEASE_BRANCH\n+        },\n+    )\n+    runs.extend(data[\"workflow_runs\"])\n+\n+  filtered_commit_runs = list(\n+      filter(lambda w: w.get(\"head_sha\", \"\") == RELEASE_COMMIT, runs))\n+  if not filtered_commit_runs:\n+    workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+        repo_url=REPO_URL, workflow_id=workflow_id)\n+    raise Exception(\n+        f\"No runs for workflow (branch {RELEASE_BRANCH}, commit {RELEASE_COMMIT}). Verify at {workflow_web_url}\"\n+    )\n+\n+  sorted_runs = sorted(\n+      filtered_commit_runs,\n+      key=lambda w: dateutil.parser.parse(w[\"created_at\"]),\n+      reverse=True,\n+  )\n+  last_run = sorted_runs[0]\n+  print(\n+      f\"Found last run. SHA: {RELEASE_COMMIT}, created_at: '{last_run['created_at']}', id: {last_run['id']}\"\n+  )\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=REPO_URL, workflow_id=last_run[\"id\"])\n+  print(f\"Verify at {workflow_web_url}\")\n+  print(\n+      f\"Optional upload to GCS will be available at:\\n\"\n+      f\"\\tgs://beam-wheels-staging/{RELEASE_BRANCH}/{RELEASE_COMMIT}-{workflow_id}/\"\n+  )\n+  return last_run\n+\n+\n+def validate_run(run_data):\n+  status = run_data[\"status\"]\n+  conclusion = run_data[\"conclusion\"]\n+  if status == \"completed\" and conclusion == \"success\":\n+    return run_data\n+\n+  url = run_data[\"url\"]\n+  workflow_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=REPO_URL, workflow_id=run_data[\"id\"])\n+  print(\n+      f\"Started waiting for Workflow run {run_data['id']} to finish. Check on {workflow_web_url}\"\n+  )\n+  start_time = time.time()\n+  last_request = start_time\n+  spinner = itertools.cycle([\"|\", \"/\", \"-\", \"\\\\\"])\n+\n+  while True:\n+    now = time.time()\n+    elapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(now - start_time))\n+    print(\n+        f\"\\r {next(spinner)} Waiting to finish. Elapsed time: {elapsed_time}. \"\n+        f\"Current state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        end=\"\",\n+    )\n+\n+    time.sleep(0.3)\n+    if (now - last_request) > 10:\n+      last_request = now\n+      run_data = request_url(url)\n+      status = run_data[\"status\"]\n+      conclusion = run_data[\"conclusion\"]\n+      if status != \"completed\":", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTI0MTQ2NA=="}, "originalCommit": {"oid": "0fc7383483cbe0c3891ade5456f0cc00abdd726d"}, "originalPosition": 161}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMDE2Nzk4OnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/download_github_actions_artifacts.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQyMDozMToyMFrOGscJ8w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wOFQxNDoyMjo0N1rOGuqi2g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTI1MTgyNw==", "bodyText": "I think this is a run ID, not a workflow ID, let's not confuse the two.\nMy understanding is that we have several workflows, one of them is \"Build wheels\", it has a (probably fixed) ID.\nThere are multiple runs in  \"Build wheels\" workflow, and each run has its own Run ID.", "url": "https://github.com/apache/beam/pull/12150#discussion_r449251827", "createdAt": "2020-07-02T20:31:20Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,234 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{workflow_id}\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0fc7383483cbe0c3891ade5456f0cc00abdd726d"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MTU4NDczMA==", "bodyText": "Yes, you are right. Excellent point. I will fix it", "url": "https://github.com/apache/beam/pull/12150#discussion_r451584730", "createdAt": "2020-07-08T14:22:47Z", "author": {"login": "TobKed"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,234 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{workflow_id}\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTI1MTgyNw=="}, "originalCommit": {"oid": "0fc7383483cbe0c3891ade5456f0cc00abdd726d"}, "originalPosition": 36}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjgwMDE4Njc1OnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/download_github_actions_artifacts.py", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQyMDozODowMFrOGscU-w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQxMToxMzo1MVrOGx5c4g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTI1NDY1MQ==", "bodyText": "The script would be easier to follow if we explicitly state the parameters here instead of passing them as global vars:\ndef get_last_run(workflow_id, release_branch_name, commit_hash)\n\nAlso instead of retrieving all data associated with the run and passing the jsons of undefied structure between functions,  consider using:\ndef get_last_run_id(workflow_id, branch_name, commit_hash)\n  \"\"\" Retrieves the latest github actions run id for the specified commit on the specified branch.\"\"\"\n\ndef get_artifacts_url(run_id):\n   \"\"\"Returns artifacts url associated with GitHub action run.\"\"\"\n  \ndef wait_for_run_completion(run_id)\n     \"\"\"Waits for run to complete if it is in progress, and verifies it completed successfully.\"\"\"\n\nIf you want to save on api calls, you can still nest helpers inside functions that use them and access api response from the outter function context.", "url": "https://github.com/apache/beam/pull/12150#discussion_r449254651", "createdAt": "2020-07-02T20:38:00Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,234 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+\n+  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n+  GITHUB_TOKEN = args.github_token\n+  USER_GITHUB_ID = args.github_user\n+  REPO_URL = args.repo_url\n+  RELEASE_BRANCH = args.release_branch\n+  RELEASE_COMMIT = args.release_commit\n+  ARTIFACTS_DIR = args.artifacts_dir\n+\n+\n+def request_url(url, return_raw_request=False, *args, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", GITHUB_TOKEN), **kwargs)\n+  r.raise_for_status()\n+  if return_raw_request:\n+    return r\n+  return r.json()\n+\n+\n+def get_yes_or_no_answer(question):\n+  \"\"\"Helper function to ask yes or no question\"\"\"\n+  reply = str(input(question + \" (y/n): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  if reply == \"n\":\n+    return False\n+  else:\n+    return get_yes_or_no_answer(\"Uhhhh... please enter \")\n+\n+\n+def get_build_wheels_workflow_id():\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=REPO_URL)\n+  data = request_url(url)\n+  return data[\"id\"]\n+\n+\n+def get_last_run(workflow_id):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0fc7383483cbe0c3891ade5456f0cc00abdd726d"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTI1NDg3NA==", "bodyText": "also please add a docstring.", "url": "https://github.com/apache/beam/pull/12150#discussion_r449254874", "createdAt": "2020-07-02T20:38:33Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,234 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+\n+  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n+  GITHUB_TOKEN = args.github_token\n+  USER_GITHUB_ID = args.github_user\n+  REPO_URL = args.repo_url\n+  RELEASE_BRANCH = args.release_branch\n+  RELEASE_COMMIT = args.release_commit\n+  ARTIFACTS_DIR = args.artifacts_dir\n+\n+\n+def request_url(url, return_raw_request=False, *args, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", GITHUB_TOKEN), **kwargs)\n+  r.raise_for_status()\n+  if return_raw_request:\n+    return r\n+  return r.json()\n+\n+\n+def get_yes_or_no_answer(question):\n+  \"\"\"Helper function to ask yes or no question\"\"\"\n+  reply = str(input(question + \" (y/n): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  if reply == \"n\":\n+    return False\n+  else:\n+    return get_yes_or_no_answer(\"Uhhhh... please enter \")\n+\n+\n+def get_build_wheels_workflow_id():\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=REPO_URL)\n+  data = request_url(url)\n+  return data[\"id\"]\n+\n+\n+def get_last_run(workflow_id):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTI1NDY1MQ=="}, "originalCommit": {"oid": "0fc7383483cbe0c3891ade5456f0cc00abdd726d"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NDk3NDY5MA==", "bodyText": "Sure, I made some bigger refactor based on your suggestions.", "url": "https://github.com/apache/beam/pull/12150#discussion_r454974690", "createdAt": "2020-07-15T11:13:51Z", "author": {"login": "TobKed"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,234 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import shutil\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+)\n+GH_API_URL_WORKFLOW_RUNS_FMT = (\n+    \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+)\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{workflow_id}\"\n+\n+\n+def parse_arguments():\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-token\", required=True)\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+\n+  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n+  GITHUB_TOKEN = args.github_token\n+  USER_GITHUB_ID = args.github_user\n+  REPO_URL = args.repo_url\n+  RELEASE_BRANCH = args.release_branch\n+  RELEASE_COMMIT = args.release_commit\n+  ARTIFACTS_DIR = args.artifacts_dir\n+\n+\n+def request_url(url, return_raw_request=False, *args, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", GITHUB_TOKEN), **kwargs)\n+  r.raise_for_status()\n+  if return_raw_request:\n+    return r\n+  return r.json()\n+\n+\n+def get_yes_or_no_answer(question):\n+  \"\"\"Helper function to ask yes or no question\"\"\"\n+  reply = str(input(question + \" (y/n): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  if reply == \"n\":\n+    return False\n+  else:\n+    return get_yes_or_no_answer(\"Uhhhh... please enter \")\n+\n+\n+def get_build_wheels_workflow_id():\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=REPO_URL)\n+  data = request_url(url)\n+  return data[\"id\"]\n+\n+\n+def get_last_run(workflow_id):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0OTI1NDY1MQ=="}, "originalCommit": {"oid": "0fc7383483cbe0c3891ade5456f0cc00abdd726d"}, "originalPosition": 88}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg1NjQ1MDc3OnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/build_release_candidate.sh", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMFQyMzo1Njo0M1rOG0jO-Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQwODowODo0OFrOG0s5GA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzc1NjQwOQ==", "bodyText": "What is the purpose of   git push origin \"${RELEASE_BRANCH}\" ?", "url": "https://github.com/apache/beam/pull/12150#discussion_r457756409", "createdAt": "2020-07-20T23:56:43Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/build_release_candidate.sh", "diffHunk": "@@ -154,41 +155,67 @@ if [[ $confirmation = \"y\" ]]; then\n   rm -rf ~/${LOCAL_JAVA_STAGING_DIR}\n fi\n \n-echo \"[Current Step]: Stage python binaries\"\n+\n+echo \"[Current Step]: Stage python binaries and wheels\"\n+echo \"===============================Pre-requirements========================\"\n+echo \"Please make sure you have configured and started your gpg by running ./preparation_before_release.sh.\"\n echo \"Do you want to proceed? [y|N]\"\n read confirmation\n if [[ $confirmation = \"y\" ]]; then\n   echo \"============Staging Python Binaries on dist.apache.org=========\"\n   cd ~\n-  if [[ -d ${LOCAL_PYTHON_STAGING_DIR} ]]; then\n-    rm -rf ${LOCAL_PYTHON_STAGING_DIR}\n+  if [[ -d \"${LOCAL_PYTHON_STAGING_DIR}\" ]]; then\n+    rm -rf \"${LOCAL_PYTHON_STAGING_DIR}\"\n   fi\n-  mkdir -p ${LOCAL_PYTHON_STAGING_DIR}\n-  cd ${LOCAL_PYTHON_STAGING_DIR}\n+  mkdir -p \"${LOCAL_PYTHON_STAGING_DIR}\"\n+  cd \"${LOCAL_PYTHON_STAGING_DIR}\"\n \n   echo '-------------------Cloning Beam Release Branch-----------------'\n-  git clone ${GIT_REPO_URL}\n-  cd ${BEAM_ROOT_DIR}\n-  git checkout ${RELEASE_BRANCH}\n+  git clone \"${GIT_REPO_URL}\"\n+  cd \"${BEAM_ROOT_DIR}\"\n+  git checkout \"${RELEASE_BRANCH}\"\n+  git push origin \"${RELEASE_BRANCH}\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "58926d2c43351ef2ed1ba7394afa11fc2f3f2515"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzkxNDY0OA==", "bodyText": "Good point. It is unnecessary, I will delete it.", "url": "https://github.com/apache/beam/pull/12150#discussion_r457914648", "createdAt": "2020-07-21T08:08:48Z", "author": {"login": "TobKed"}, "path": "release/src/main/scripts/build_release_candidate.sh", "diffHunk": "@@ -154,41 +155,67 @@ if [[ $confirmation = \"y\" ]]; then\n   rm -rf ~/${LOCAL_JAVA_STAGING_DIR}\n fi\n \n-echo \"[Current Step]: Stage python binaries\"\n+\n+echo \"[Current Step]: Stage python binaries and wheels\"\n+echo \"===============================Pre-requirements========================\"\n+echo \"Please make sure you have configured and started your gpg by running ./preparation_before_release.sh.\"\n echo \"Do you want to proceed? [y|N]\"\n read confirmation\n if [[ $confirmation = \"y\" ]]; then\n   echo \"============Staging Python Binaries on dist.apache.org=========\"\n   cd ~\n-  if [[ -d ${LOCAL_PYTHON_STAGING_DIR} ]]; then\n-    rm -rf ${LOCAL_PYTHON_STAGING_DIR}\n+  if [[ -d \"${LOCAL_PYTHON_STAGING_DIR}\" ]]; then\n+    rm -rf \"${LOCAL_PYTHON_STAGING_DIR}\"\n   fi\n-  mkdir -p ${LOCAL_PYTHON_STAGING_DIR}\n-  cd ${LOCAL_PYTHON_STAGING_DIR}\n+  mkdir -p \"${LOCAL_PYTHON_STAGING_DIR}\"\n+  cd \"${LOCAL_PYTHON_STAGING_DIR}\"\n \n   echo '-------------------Cloning Beam Release Branch-----------------'\n-  git clone ${GIT_REPO_URL}\n-  cd ${BEAM_ROOT_DIR}\n-  git checkout ${RELEASE_BRANCH}\n+  git clone \"${GIT_REPO_URL}\"\n+  cd \"${BEAM_ROOT_DIR}\"\n+  git checkout \"${RELEASE_BRANCH}\"\n+  git push origin \"${RELEASE_BRANCH}\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzc1NjQwOQ=="}, "originalCommit": {"oid": "58926d2c43351ef2ed1ba7394afa11fc2f3f2515"}, "originalPosition": 50}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg1NjQ1MzkwOnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/build_release_candidate.sh", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMFQyMzo1ODoyOVrOG0jQ9Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQwODoxODo1NlrOG0tQGw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzc1NjkxNw==", "bodyText": "Let's move the echo inside the loop.", "url": "https://github.com/apache/beam/pull/12150#discussion_r457756917", "createdAt": "2020-07-20T23:58:29Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/build_release_candidate.sh", "diffHunk": "@@ -154,41 +155,67 @@ if [[ $confirmation = \"y\" ]]; then\n   rm -rf ~/${LOCAL_JAVA_STAGING_DIR}\n fi\n \n-echo \"[Current Step]: Stage python binaries\"\n+\n+echo \"[Current Step]: Stage python binaries and wheels\"\n+echo \"===============================Pre-requirements========================\"\n+echo \"Please make sure you have configured and started your gpg by running ./preparation_before_release.sh.\"\n echo \"Do you want to proceed? [y|N]\"\n read confirmation\n if [[ $confirmation = \"y\" ]]; then\n   echo \"============Staging Python Binaries on dist.apache.org=========\"\n   cd ~\n-  if [[ -d ${LOCAL_PYTHON_STAGING_DIR} ]]; then\n-    rm -rf ${LOCAL_PYTHON_STAGING_DIR}\n+  if [[ -d \"${LOCAL_PYTHON_STAGING_DIR}\" ]]; then\n+    rm -rf \"${LOCAL_PYTHON_STAGING_DIR}\"\n   fi\n-  mkdir -p ${LOCAL_PYTHON_STAGING_DIR}\n-  cd ${LOCAL_PYTHON_STAGING_DIR}\n+  mkdir -p \"${LOCAL_PYTHON_STAGING_DIR}\"\n+  cd \"${LOCAL_PYTHON_STAGING_DIR}\"\n \n   echo '-------------------Cloning Beam Release Branch-----------------'\n-  git clone ${GIT_REPO_URL}\n-  cd ${BEAM_ROOT_DIR}\n-  git checkout ${RELEASE_BRANCH}\n+  git clone \"${GIT_REPO_URL}\"\n+  cd \"${BEAM_ROOT_DIR}\"\n+  git checkout \"${RELEASE_BRANCH}\"\n+  git push origin \"${RELEASE_BRANCH}\"\n+  RELEASE_COMMIT=$(git rev-parse --verify HEAD)\n \n-  echo '-------------------Generating Python Artifacts-----------------'\n-  cd sdks/python\n-  virtualenv ${LOCAL_PYTHON_VIRTUALENV}\n-  source ${LOCAL_PYTHON_VIRTUALENV}/bin/activate\n-  pip install -r build-requirements.txt\n-  python setup.py sdist --format=zip\n-  cd dist\n+  echo '-------------------Creating Python Virtualenv-----------------'\n+  python3 -m venv \"${LOCAL_PYTHON_VIRTUALENV}\"\n+  source \"${LOCAL_PYTHON_VIRTUALENV}/bin/activate\"\n+  pip install requests python-dateutil\n+\n+  echo '--------------Fetching GitHub Actions Artifacts--------------'\n+  python release/src/main/scripts/download_github_actions_artifacts.py \\\n+    --github-user \"${USER_GITHUB_ID}\" \\\n+    --repo-url \"${GIT_REPO_BASE_URL}\" \\\n+    --release-branch \"${RELEASE_BRANCH}\" \\\n+    --release-commit \"${RELEASE_COMMIT}\" \\\n+    --artifacts_dir \"${PYTHON_ARTIFACTS_DIR}\"\n \n   svn co https://dist.apache.org/repos/dist/dev/beam\n-  mkdir -p beam/${RELEASE}/${PYTHON_ARTIFACTS_DIR}\n-  cp apache-beam-${RELEASE}.zip beam/${RELEASE}/${PYTHON_ARTIFACTS_DIR}/apache-beam-${RELEASE}.zip\n-  cd beam/${RELEASE}/${PYTHON_ARTIFACTS_DIR}\n+  mkdir -p \"beam/${RELEASE}/${PYTHON_ARTIFACTS_DIR}\"\n+  cp -ar \"${PYTHON_ARTIFACTS_DIR}/\" \"beam/${RELEASE}/${PYTHON_ARTIFACTS_DIR}/\"\n+  cd \"beam/${RELEASE}/${PYTHON_ARTIFACTS_DIR}\"\n+\n+  echo \"------Checking Hash Value for apache-beam-${RELEASE}.zip-----\"\n+  sha512sum -c \"apache-beam-${RELEASE}.zip.sha512\"\n \n   echo \"------Signing Source Release apache-beam-${RELEASE}.zip------\"\n-  gpg --local-user ${SIGNING_KEY} --armor --detach-sig apache-beam-${RELEASE}.zip\n+  gpg --local-user \"${SIGNING_KEY}\" --armor --detach-sig \"apache-beam-${RELEASE}.zip\"\n \n-  echo \"------Creating Hash Value for apache-beam-${RELEASE}.zip------\"\n-  sha512sum apache-beam-${RELEASE}.zip > apache-beam-${RELEASE}.zip.sha512\n+  echo \"-----Checking Hash Value for apache-beam-${RELEASE}.tar.gz----\"\n+  sha512sum -c \"apache-beam-${RELEASE}.tar.gz.sha512\"\n+\n+  echo \"-----Signing Source Release apache-beam-${RELEASE}.tar.gz-----\"\n+  gpg --local-user \"${SIGNING_KEY}\" --armor --detach-sig \"apache-beam-${RELEASE}.tar.gz\"\n+\n+  echo \"-----Checking Hash Value for apache-beam-${RELEASE} wheels-----\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "58926d2c43351ef2ed1ba7394afa11fc2f3f2515"}, "originalPosition": 96}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzkyMDUzOQ==", "bodyText": "Sure \ud83d\udc4d", "url": "https://github.com/apache/beam/pull/12150#discussion_r457920539", "createdAt": "2020-07-21T08:18:56Z", "author": {"login": "TobKed"}, "path": "release/src/main/scripts/build_release_candidate.sh", "diffHunk": "@@ -154,41 +155,67 @@ if [[ $confirmation = \"y\" ]]; then\n   rm -rf ~/${LOCAL_JAVA_STAGING_DIR}\n fi\n \n-echo \"[Current Step]: Stage python binaries\"\n+\n+echo \"[Current Step]: Stage python binaries and wheels\"\n+echo \"===============================Pre-requirements========================\"\n+echo \"Please make sure you have configured and started your gpg by running ./preparation_before_release.sh.\"\n echo \"Do you want to proceed? [y|N]\"\n read confirmation\n if [[ $confirmation = \"y\" ]]; then\n   echo \"============Staging Python Binaries on dist.apache.org=========\"\n   cd ~\n-  if [[ -d ${LOCAL_PYTHON_STAGING_DIR} ]]; then\n-    rm -rf ${LOCAL_PYTHON_STAGING_DIR}\n+  if [[ -d \"${LOCAL_PYTHON_STAGING_DIR}\" ]]; then\n+    rm -rf \"${LOCAL_PYTHON_STAGING_DIR}\"\n   fi\n-  mkdir -p ${LOCAL_PYTHON_STAGING_DIR}\n-  cd ${LOCAL_PYTHON_STAGING_DIR}\n+  mkdir -p \"${LOCAL_PYTHON_STAGING_DIR}\"\n+  cd \"${LOCAL_PYTHON_STAGING_DIR}\"\n \n   echo '-------------------Cloning Beam Release Branch-----------------'\n-  git clone ${GIT_REPO_URL}\n-  cd ${BEAM_ROOT_DIR}\n-  git checkout ${RELEASE_BRANCH}\n+  git clone \"${GIT_REPO_URL}\"\n+  cd \"${BEAM_ROOT_DIR}\"\n+  git checkout \"${RELEASE_BRANCH}\"\n+  git push origin \"${RELEASE_BRANCH}\"\n+  RELEASE_COMMIT=$(git rev-parse --verify HEAD)\n \n-  echo '-------------------Generating Python Artifacts-----------------'\n-  cd sdks/python\n-  virtualenv ${LOCAL_PYTHON_VIRTUALENV}\n-  source ${LOCAL_PYTHON_VIRTUALENV}/bin/activate\n-  pip install -r build-requirements.txt\n-  python setup.py sdist --format=zip\n-  cd dist\n+  echo '-------------------Creating Python Virtualenv-----------------'\n+  python3 -m venv \"${LOCAL_PYTHON_VIRTUALENV}\"\n+  source \"${LOCAL_PYTHON_VIRTUALENV}/bin/activate\"\n+  pip install requests python-dateutil\n+\n+  echo '--------------Fetching GitHub Actions Artifacts--------------'\n+  python release/src/main/scripts/download_github_actions_artifacts.py \\\n+    --github-user \"${USER_GITHUB_ID}\" \\\n+    --repo-url \"${GIT_REPO_BASE_URL}\" \\\n+    --release-branch \"${RELEASE_BRANCH}\" \\\n+    --release-commit \"${RELEASE_COMMIT}\" \\\n+    --artifacts_dir \"${PYTHON_ARTIFACTS_DIR}\"\n \n   svn co https://dist.apache.org/repos/dist/dev/beam\n-  mkdir -p beam/${RELEASE}/${PYTHON_ARTIFACTS_DIR}\n-  cp apache-beam-${RELEASE}.zip beam/${RELEASE}/${PYTHON_ARTIFACTS_DIR}/apache-beam-${RELEASE}.zip\n-  cd beam/${RELEASE}/${PYTHON_ARTIFACTS_DIR}\n+  mkdir -p \"beam/${RELEASE}/${PYTHON_ARTIFACTS_DIR}\"\n+  cp -ar \"${PYTHON_ARTIFACTS_DIR}/\" \"beam/${RELEASE}/${PYTHON_ARTIFACTS_DIR}/\"\n+  cd \"beam/${RELEASE}/${PYTHON_ARTIFACTS_DIR}\"\n+\n+  echo \"------Checking Hash Value for apache-beam-${RELEASE}.zip-----\"\n+  sha512sum -c \"apache-beam-${RELEASE}.zip.sha512\"\n \n   echo \"------Signing Source Release apache-beam-${RELEASE}.zip------\"\n-  gpg --local-user ${SIGNING_KEY} --armor --detach-sig apache-beam-${RELEASE}.zip\n+  gpg --local-user \"${SIGNING_KEY}\" --armor --detach-sig \"apache-beam-${RELEASE}.zip\"\n \n-  echo \"------Creating Hash Value for apache-beam-${RELEASE}.zip------\"\n-  sha512sum apache-beam-${RELEASE}.zip > apache-beam-${RELEASE}.zip.sha512\n+  echo \"-----Checking Hash Value for apache-beam-${RELEASE}.tar.gz----\"\n+  sha512sum -c \"apache-beam-${RELEASE}.tar.gz.sha512\"\n+\n+  echo \"-----Signing Source Release apache-beam-${RELEASE}.tar.gz-----\"\n+  gpg --local-user \"${SIGNING_KEY}\" --armor --detach-sig \"apache-beam-${RELEASE}.tar.gz\"\n+\n+  echo \"-----Checking Hash Value for apache-beam-${RELEASE} wheels-----\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzc1NjkxNw=="}, "originalCommit": {"oid": "58926d2c43351ef2ed1ba7394afa11fc2f3f2515"}, "originalPosition": 96}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg1NjQ3NDM3OnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/build_release_candidate.sh", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQwMDowODo1MlrOG0jc5Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQxMjozNjo0M1rOG014xA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzc1OTk3Mw==", "bodyText": "Should we be passing \"beam/${RELEASE}/${PYTHON_ARTIFACTS_DIR}\" or some other folder under \"beam/${RELEASE}/\"?", "url": "https://github.com/apache/beam/pull/12150#discussion_r457759973", "createdAt": "2020-07-21T00:08:52Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/build_release_candidate.sh", "diffHunk": "@@ -154,41 +155,67 @@ if [[ $confirmation = \"y\" ]]; then\n   rm -rf ~/${LOCAL_JAVA_STAGING_DIR}\n fi\n \n-echo \"[Current Step]: Stage python binaries\"\n+\n+echo \"[Current Step]: Stage python binaries and wheels\"\n+echo \"===============================Pre-requirements========================\"\n+echo \"Please make sure you have configured and started your gpg by running ./preparation_before_release.sh.\"\n echo \"Do you want to proceed? [y|N]\"\n read confirmation\n if [[ $confirmation = \"y\" ]]; then\n   echo \"============Staging Python Binaries on dist.apache.org=========\"\n   cd ~\n-  if [[ -d ${LOCAL_PYTHON_STAGING_DIR} ]]; then\n-    rm -rf ${LOCAL_PYTHON_STAGING_DIR}\n+  if [[ -d \"${LOCAL_PYTHON_STAGING_DIR}\" ]]; then\n+    rm -rf \"${LOCAL_PYTHON_STAGING_DIR}\"\n   fi\n-  mkdir -p ${LOCAL_PYTHON_STAGING_DIR}\n-  cd ${LOCAL_PYTHON_STAGING_DIR}\n+  mkdir -p \"${LOCAL_PYTHON_STAGING_DIR}\"\n+  cd \"${LOCAL_PYTHON_STAGING_DIR}\"\n \n   echo '-------------------Cloning Beam Release Branch-----------------'\n-  git clone ${GIT_REPO_URL}\n-  cd ${BEAM_ROOT_DIR}\n-  git checkout ${RELEASE_BRANCH}\n+  git clone \"${GIT_REPO_URL}\"\n+  cd \"${BEAM_ROOT_DIR}\"\n+  git checkout \"${RELEASE_BRANCH}\"\n+  git push origin \"${RELEASE_BRANCH}\"\n+  RELEASE_COMMIT=$(git rev-parse --verify HEAD)\n \n-  echo '-------------------Generating Python Artifacts-----------------'\n-  cd sdks/python\n-  virtualenv ${LOCAL_PYTHON_VIRTUALENV}\n-  source ${LOCAL_PYTHON_VIRTUALENV}/bin/activate\n-  pip install -r build-requirements.txt\n-  python setup.py sdist --format=zip\n-  cd dist\n+  echo '-------------------Creating Python Virtualenv-----------------'\n+  python3 -m venv \"${LOCAL_PYTHON_VIRTUALENV}\"\n+  source \"${LOCAL_PYTHON_VIRTUALENV}/bin/activate\"\n+  pip install requests python-dateutil\n+\n+  echo '--------------Fetching GitHub Actions Artifacts--------------'\n+  python release/src/main/scripts/download_github_actions_artifacts.py \\\n+    --github-user \"${USER_GITHUB_ID}\" \\\n+    --repo-url \"${GIT_REPO_BASE_URL}\" \\\n+    --release-branch \"${RELEASE_BRANCH}\" \\\n+    --release-commit \"${RELEASE_COMMIT}\" \\\n+    --artifacts_dir \"${PYTHON_ARTIFACTS_DIR}\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "58926d2c43351ef2ed1ba7394afa11fc2f3f2515"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODA2MjAyMA==", "bodyText": "Yea, you are right. I made some unnecessary steps, I refactored it. I also noticed that removing staging directory was incorrect, I fix it here 468b2d4", "url": "https://github.com/apache/beam/pull/12150#discussion_r458062020", "createdAt": "2020-07-21T12:36:43Z", "author": {"login": "TobKed"}, "path": "release/src/main/scripts/build_release_candidate.sh", "diffHunk": "@@ -154,41 +155,67 @@ if [[ $confirmation = \"y\" ]]; then\n   rm -rf ~/${LOCAL_JAVA_STAGING_DIR}\n fi\n \n-echo \"[Current Step]: Stage python binaries\"\n+\n+echo \"[Current Step]: Stage python binaries and wheels\"\n+echo \"===============================Pre-requirements========================\"\n+echo \"Please make sure you have configured and started your gpg by running ./preparation_before_release.sh.\"\n echo \"Do you want to proceed? [y|N]\"\n read confirmation\n if [[ $confirmation = \"y\" ]]; then\n   echo \"============Staging Python Binaries on dist.apache.org=========\"\n   cd ~\n-  if [[ -d ${LOCAL_PYTHON_STAGING_DIR} ]]; then\n-    rm -rf ${LOCAL_PYTHON_STAGING_DIR}\n+  if [[ -d \"${LOCAL_PYTHON_STAGING_DIR}\" ]]; then\n+    rm -rf \"${LOCAL_PYTHON_STAGING_DIR}\"\n   fi\n-  mkdir -p ${LOCAL_PYTHON_STAGING_DIR}\n-  cd ${LOCAL_PYTHON_STAGING_DIR}\n+  mkdir -p \"${LOCAL_PYTHON_STAGING_DIR}\"\n+  cd \"${LOCAL_PYTHON_STAGING_DIR}\"\n \n   echo '-------------------Cloning Beam Release Branch-----------------'\n-  git clone ${GIT_REPO_URL}\n-  cd ${BEAM_ROOT_DIR}\n-  git checkout ${RELEASE_BRANCH}\n+  git clone \"${GIT_REPO_URL}\"\n+  cd \"${BEAM_ROOT_DIR}\"\n+  git checkout \"${RELEASE_BRANCH}\"\n+  git push origin \"${RELEASE_BRANCH}\"\n+  RELEASE_COMMIT=$(git rev-parse --verify HEAD)\n \n-  echo '-------------------Generating Python Artifacts-----------------'\n-  cd sdks/python\n-  virtualenv ${LOCAL_PYTHON_VIRTUALENV}\n-  source ${LOCAL_PYTHON_VIRTUALENV}/bin/activate\n-  pip install -r build-requirements.txt\n-  python setup.py sdist --format=zip\n-  cd dist\n+  echo '-------------------Creating Python Virtualenv-----------------'\n+  python3 -m venv \"${LOCAL_PYTHON_VIRTUALENV}\"\n+  source \"${LOCAL_PYTHON_VIRTUALENV}/bin/activate\"\n+  pip install requests python-dateutil\n+\n+  echo '--------------Fetching GitHub Actions Artifacts--------------'\n+  python release/src/main/scripts/download_github_actions_artifacts.py \\\n+    --github-user \"${USER_GITHUB_ID}\" \\\n+    --repo-url \"${GIT_REPO_BASE_URL}\" \\\n+    --release-branch \"${RELEASE_BRANCH}\" \\\n+    --release-commit \"${RELEASE_COMMIT}\" \\\n+    --artifacts_dir \"${PYTHON_ARTIFACTS_DIR}\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzc1OTk3Mw=="}, "originalCommit": {"oid": "58926d2c43351ef2ed1ba7394afa11fc2f3f2515"}, "originalPosition": 71}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg1NjQ4MjU0OnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/download_github_actions_artifacts.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQwMDoxMzowOVrOG0jhrQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQwODoyMToyMlrOG0tVpQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzc2MTE5Nw==", "bodyText": "nit: s/form/for", "url": "https://github.com/apache/beam/pull/12150#discussion_r457761197", "createdAt": "2020-07-21T00:13:09Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,314 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import pprint\n+import shutil\n+import sys\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+GH_API_URL_WORKFLOW_RUNS_FMT = \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+GH_API_URL_WORKFLOW_RUN_FMT = \"https://api.github.com/repos/{repo_url}/actions/runs/{run_id}\"\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{run_id}\"\n+\n+\n+def parse_arguments():\n+  \"\"\"\n+  Gets all neccessary data from the user by parsing arguments or asking for input.\n+  Return: github_token, user_github_id, repo_url, release_branch, release_commit, artifacts_dir\n+  \"\"\"\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+  github_token = ask_for_github_token()\n+\n+  print(\"You passed following arguments:\")\n+  pprint.pprint({**vars(args), **{\"github_token\": github_token}})\n+\n+  if not get_yes_or_no_answer(\"Do you want to continue?\"):\n+    print(\"You said NO. Quitting ...\")\n+    sys.exit(1)\n+\n+  user_github_id = args.github_user\n+  repo_url = args.repo_url\n+  release_branch = args.release_branch\n+  release_commit = args.release_commit\n+  artifacts_dir = args.artifacts_dir\n+\n+  return github_token, user_github_id, repo_url, release_branch, release_commit, artifacts_dir\n+\n+\n+def ask_for_github_token():\n+  \"\"\"Ask for github token and print basic information about it.\"\"\"\n+  url = \"https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token\"\n+  message = (\n+      f\"You need to have a github access token with public_repo scope. \"\n+      f\"More info about creating access tokens can be found here {url}\")\n+  print(message)\n+  github_token = input(\"Enter github token: \")\n+  if not github_token:\n+    return ask_for_github_token()\n+  return github_token\n+\n+\n+def request_url(url, github_token, return_json=True, *args, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token.\"\"\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "58926d2c43351ef2ed1ba7394afa11fc2f3f2515"}, "originalPosition": 86}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzkyMTk1Nw==", "bodyText": "Fixed.", "url": "https://github.com/apache/beam/pull/12150#discussion_r457921957", "createdAt": "2020-07-21T08:21:22Z", "author": {"login": "TobKed"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,314 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import pprint\n+import shutil\n+import sys\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+GH_API_URL_WORKFLOW_RUNS_FMT = \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+GH_API_URL_WORKFLOW_RUN_FMT = \"https://api.github.com/repos/{repo_url}/actions/runs/{run_id}\"\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{run_id}\"\n+\n+\n+def parse_arguments():\n+  \"\"\"\n+  Gets all neccessary data from the user by parsing arguments or asking for input.\n+  Return: github_token, user_github_id, repo_url, release_branch, release_commit, artifacts_dir\n+  \"\"\"\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+  github_token = ask_for_github_token()\n+\n+  print(\"You passed following arguments:\")\n+  pprint.pprint({**vars(args), **{\"github_token\": github_token}})\n+\n+  if not get_yes_or_no_answer(\"Do you want to continue?\"):\n+    print(\"You said NO. Quitting ...\")\n+    sys.exit(1)\n+\n+  user_github_id = args.github_user\n+  repo_url = args.repo_url\n+  release_branch = args.release_branch\n+  release_commit = args.release_commit\n+  artifacts_dir = args.artifacts_dir\n+\n+  return github_token, user_github_id, repo_url, release_branch, release_commit, artifacts_dir\n+\n+\n+def ask_for_github_token():\n+  \"\"\"Ask for github token and print basic information about it.\"\"\"\n+  url = \"https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token\"\n+  message = (\n+      f\"You need to have a github access token with public_repo scope. \"\n+      f\"More info about creating access tokens can be found here {url}\")\n+  print(message)\n+  github_token = input(\"Enter github token: \")\n+  if not github_token:\n+    return ask_for_github_token()\n+  return github_token\n+\n+\n+def request_url(url, github_token, return_json=True, *args, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token.\"\"\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzc2MTE5Nw=="}, "originalCommit": {"oid": "58926d2c43351ef2ed1ba7394afa11fc2f3f2515"}, "originalPosition": 86}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg1NjUxNjUxOnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/download_github_actions_artifacts.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQwMDozMDo1NFrOG0j1Mg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQwODozNzowMFrOG0t68Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzc2NjE5NA==", "bodyText": "seeing two nested context managers reusing the same variable (as f).", "url": "https://github.com/apache/beam/pull/12150#discussion_r457766194", "createdAt": "2020-07-21T00:30:54Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,314 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import pprint\n+import shutil\n+import sys\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+GH_API_URL_WORKFLOW_RUNS_FMT = \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+GH_API_URL_WORKFLOW_RUN_FMT = \"https://api.github.com/repos/{repo_url}/actions/runs/{run_id}\"\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{run_id}\"\n+\n+\n+def parse_arguments():\n+  \"\"\"\n+  Gets all neccessary data from the user by parsing arguments or asking for input.\n+  Return: github_token, user_github_id, repo_url, release_branch, release_commit, artifacts_dir\n+  \"\"\"\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+  github_token = ask_for_github_token()\n+\n+  print(\"You passed following arguments:\")\n+  pprint.pprint({**vars(args), **{\"github_token\": github_token}})\n+\n+  if not get_yes_or_no_answer(\"Do you want to continue?\"):\n+    print(\"You said NO. Quitting ...\")\n+    sys.exit(1)\n+\n+  user_github_id = args.github_user\n+  repo_url = args.repo_url\n+  release_branch = args.release_branch\n+  release_commit = args.release_commit\n+  artifacts_dir = args.artifacts_dir\n+\n+  return github_token, user_github_id, repo_url, release_branch, release_commit, artifacts_dir\n+\n+\n+def ask_for_github_token():\n+  \"\"\"Ask for github token and print basic information about it.\"\"\"\n+  url = \"https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token\"\n+  message = (\n+      f\"You need to have a github access token with public_repo scope. \"\n+      f\"More info about creating access tokens can be found here {url}\")\n+  print(message)\n+  github_token = input(\"Enter github token: \")\n+  if not github_token:\n+    return ask_for_github_token()\n+  return github_token\n+\n+\n+def request_url(url, github_token, return_json=True, *args, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token.\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", github_token), **kwargs)\n+  if return_json:\n+    r.raise_for_status()\n+    return r.json()\n+  return r\n+\n+\n+def safe_get(data, key, url=None):\n+  \"\"\"Gets data by the key with informative Exception in case of non existent key.\"\"\"\n+  if key not in data:\n+    message = f'There is missing key: \"{key}\" in response data: {data}.'\n+    if url:\n+      message += f\" Requested url: {url}\"\n+    raise ValueError(message)\n+  return data.get(key)\n+\n+\n+def get_yes_or_no_answer(question):\n+  \"\"\"Asks yes or no question.\"\"\"\n+  reply = str(input(question + \" 'y' or 'n'): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  elif reply == \"n\":\n+    return False\n+  else:\n+    return get_yes_or_no_answer(\"Uhhhh... please enter\")\n+\n+\n+def get_build_wheels_workflow_id(repo_url, github_token):\n+  \"\"\"Gets workflow id.\"\"\"\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=repo_url)\n+  data = request_url(url, github_token)\n+  return safe_get(data, \"id\", url)\n+\n+\n+def get_single_workflow_run_data(run_id, repo_url, github_token):\n+  \"\"\"Gets single workflow run data (github api payload).\"\"\"\n+  url = GH_API_URL_WORKFLOW_RUN_FMT.format(repo_url=repo_url, run_id=run_id)\n+  return request_url(url, github_token)\n+\n+\n+def get_last_run_id(\n+    workflow_id, repo_url, release_branch, release_commit, github_token):\n+  \"\"\"\n+  Gets id of last run for given workflow, repo, branch and commit.\n+  Raises exception when no run found.\n+  \"\"\"\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=repo_url, workflow_id=workflow_id)\n+  data = request_url(\n+      url,\n+      github_token,\n+      params={\n+          \"event\": \"push\", \"branch\": release_branch\n+      },\n+  )\n+  runs = safe_get(data, \"workflow_runs\", url)\n+\n+  filtered_commit_runs = [\n+      r for r in runs if r.get(\"head_sha\", \"\") == release_commit\n+  ]\n+\n+  if not filtered_commit_runs:\n+    workflow_run_web_url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+        repo_url=repo_url, workflow_id=workflow_id)\n+    raise Exception(\n+        f\"No runs for workflow (branch {release_branch}, commit {release_commit}). Verify at {workflow_run_web_url}\"\n+    )\n+\n+  sorted_runs = sorted(\n+      filtered_commit_runs,\n+      key=lambda w: dateutil.parser.parse(w[\"created_at\"]),\n+      reverse=True,\n+  )\n+  last_run = sorted_runs[0]\n+  print(\n+      f\"Found last run. SHA: {release_commit}, created_at: '{last_run['created_at']}', id: {last_run['id']}\"\n+  )\n+  workflow_run_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=repo_url, run_id=last_run[\"id\"])\n+  print(f\"Verify at {workflow_run_web_url}\")\n+  print(\n+      f\"Upload to GCS available at: gs://beam-wheels-staging/{release_branch}/{release_commit}-{workflow_id}/\"\n+  )\n+  return safe_get(last_run, \"id\")\n+\n+\n+def validate_run(run_id, repo_url, github_token):\n+  \"\"\"Validates workflow run. Verifies succesfull status and waits if run is not finished.\"\"\"\n+  run_data = get_single_workflow_run_data(run_id, repo_url, github_token)\n+  status = safe_get(run_data, \"status\")\n+  conclusion = safe_get(run_data, \"conclusion\")\n+\n+  if status == \"completed\" and conclusion == \"success\":\n+    return run_id\n+  elif status in [\"queued\", \"in_progress\"]:\n+    wait_for_workflow_run_to_finish(\n+        run_id, repo_url, status, conclusion, github_token)\n+  else:\n+    run_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+        repo_url=repo_url, run_id=run_id)\n+    raise Exception(\n+        f\"Run unsuccessful. Status: {status}. Conclusion: {conclusion}. Check at: {run_web_url}\"\n+    )\n+\n+\n+def wait_for_workflow_run_to_finish(\n+    run_id, repo_url, status, conclusion, github_token):\n+  \"\"\"Waits for given workflow run to finish succesfully\"\"\"\n+  run_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=repo_url, run_id=run_id)\n+  print(\n+      f\"Started waiting for Workflow run {run_id} to finish. Check on {run_web_url}\"\n+  )\n+  start_time = time.time()\n+  last_request = start_time\n+  spinner = itertools.cycle([\"|\", \"/\", \"-\", \"\\\\\"])\n+  request_interval = 10\n+\n+  while True:\n+    now = time.time()\n+    elapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(now - start_time))\n+    print(\n+        f\"\\r {next(spinner)} Waiting to finish. Elapsed time: {elapsed_time}. \"\n+        f\"Current state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        end=\"\",\n+    )\n+\n+    time.sleep(0.3)\n+    if (now - last_request) > request_interval:\n+      last_request = now\n+      run_data = get_single_workflow_run_data(run_id, repo_url, github_token)\n+      status = safe_get(run_data, \"status\")\n+      conclusion = safe_get(run_data, \"conclusion\")\n+      if status in [\"queued\", \"in_progress\"]:\n+        continue\n+      elif status == \"completed\" and conclusion == \"success\":\n+        print(\n+            f\"\\rFinished in: {elapsed_time}. \"\n+            f\"Last state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        )\n+        return run_id\n+      else:\n+        print(\"\\r\")\n+        raise Exception(\n+            f\"Run unsuccessful. Conclusion: {conclusion}. Check at: {run_web_url}\"\n+        )\n+\n+\n+def reset_directory(artifacts_dir):\n+  \"\"\"Clears directory asking for confirmation before.\"\"\"\n+  question = (\n+      f\"Creating Artifacts directory. Any existing content in {artifacts_dir} will be erased. Proceed?\\n\"\n+      f\"Your answer\")\n+  if get_yes_or_no_answer(question):\n+    print(f\"Clearing directory: {artifacts_dir}\")\n+    shutil.rmtree(artifacts_dir, ignore_errors=True)\n+    os.makedirs(artifacts_dir)\n+  else:\n+    print(\"You said NO for clearing artifacts directory. Quitting ...\")\n+    sys.exit(1)\n+\n+\n+def download_artifacts(run_id, repo_url, artifacts_dir, github_token):\n+  \"\"\"Downloads github artifacts from given run.\"\"\"\n+  print(\"Starting downloading artifacts ... (it may take a while)\")\n+  run_data = get_single_workflow_run_data(run_id, repo_url, github_token)\n+  artifacts_url = safe_get(run_data, \"artifacts_url\")\n+  data_artifacts = request_url(artifacts_url, github_token)\n+  artifacts = safe_get(data_artifacts, \"artifacts\", artifacts_url)\n+  filtered_artifacts = [\n+      a for a in artifacts if (\n+          a[\"name\"].startswith(\"source_gztar_zip\") or\n+          a[\"name\"].startswith(\"wheelhouse\"))\n+  ]\n+  for artifact in filtered_artifacts:\n+    url = safe_get(artifact, \"archive_download_url\")\n+    name = safe_get(artifact, \"name\")\n+    size_in_bytes = safe_get(artifact, \"size_in_bytes\")\n+\n+    download_single_artifact(\n+        url, name, size_in_bytes, artifacts_dir, github_token)\n+\n+\n+def download_single_artifact(\n+    url, name, size_in_bytes, artifacts_dir, github_token):\n+  \"\"\"Downloads single github artifact.\"\"\"\n+  artifacts_size_mb = round(size_in_bytes / (1024 * 1024), 2)\n+  print(\n+      f\"\\tDownloading {name}.zip artifact (size: {artifacts_size_mb} megabytes)\"\n+  )\n+\n+  with tempfile.NamedTemporaryFile(\n+    \"wb\", prefix=name, suffix=\".zip\"\n+  ) as f, request_url(\n+    url, github_token, return_json=False, allow_redirects=True, stream=True\n+  ) as r:\n+    with open(f.name, \"wb\") as f:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "58926d2c43351ef2ed1ba7394afa11fc2f3f2515"}, "originalPosition": 284}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzkzMTUwNQ==", "bodyText": "Oh, I missed that. Thanks, fixed.", "url": "https://github.com/apache/beam/pull/12150#discussion_r457931505", "createdAt": "2020-07-21T08:37:00Z", "author": {"login": "TobKed"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,314 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import pprint\n+import shutil\n+import sys\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+GH_API_URL_WORKFLOW_RUNS_FMT = \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+GH_API_URL_WORKFLOW_RUN_FMT = \"https://api.github.com/repos/{repo_url}/actions/runs/{run_id}\"\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{run_id}\"\n+\n+\n+def parse_arguments():\n+  \"\"\"\n+  Gets all neccessary data from the user by parsing arguments or asking for input.\n+  Return: github_token, user_github_id, repo_url, release_branch, release_commit, artifacts_dir\n+  \"\"\"\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+  github_token = ask_for_github_token()\n+\n+  print(\"You passed following arguments:\")\n+  pprint.pprint({**vars(args), **{\"github_token\": github_token}})\n+\n+  if not get_yes_or_no_answer(\"Do you want to continue?\"):\n+    print(\"You said NO. Quitting ...\")\n+    sys.exit(1)\n+\n+  user_github_id = args.github_user\n+  repo_url = args.repo_url\n+  release_branch = args.release_branch\n+  release_commit = args.release_commit\n+  artifacts_dir = args.artifacts_dir\n+\n+  return github_token, user_github_id, repo_url, release_branch, release_commit, artifacts_dir\n+\n+\n+def ask_for_github_token():\n+  \"\"\"Ask for github token and print basic information about it.\"\"\"\n+  url = \"https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token\"\n+  message = (\n+      f\"You need to have a github access token with public_repo scope. \"\n+      f\"More info about creating access tokens can be found here {url}\")\n+  print(message)\n+  github_token = input(\"Enter github token: \")\n+  if not github_token:\n+    return ask_for_github_token()\n+  return github_token\n+\n+\n+def request_url(url, github_token, return_json=True, *args, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token.\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", github_token), **kwargs)\n+  if return_json:\n+    r.raise_for_status()\n+    return r.json()\n+  return r\n+\n+\n+def safe_get(data, key, url=None):\n+  \"\"\"Gets data by the key with informative Exception in case of non existent key.\"\"\"\n+  if key not in data:\n+    message = f'There is missing key: \"{key}\" in response data: {data}.'\n+    if url:\n+      message += f\" Requested url: {url}\"\n+    raise ValueError(message)\n+  return data.get(key)\n+\n+\n+def get_yes_or_no_answer(question):\n+  \"\"\"Asks yes or no question.\"\"\"\n+  reply = str(input(question + \" 'y' or 'n'): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  elif reply == \"n\":\n+    return False\n+  else:\n+    return get_yes_or_no_answer(\"Uhhhh... please enter\")\n+\n+\n+def get_build_wheels_workflow_id(repo_url, github_token):\n+  \"\"\"Gets workflow id.\"\"\"\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=repo_url)\n+  data = request_url(url, github_token)\n+  return safe_get(data, \"id\", url)\n+\n+\n+def get_single_workflow_run_data(run_id, repo_url, github_token):\n+  \"\"\"Gets single workflow run data (github api payload).\"\"\"\n+  url = GH_API_URL_WORKFLOW_RUN_FMT.format(repo_url=repo_url, run_id=run_id)\n+  return request_url(url, github_token)\n+\n+\n+def get_last_run_id(\n+    workflow_id, repo_url, release_branch, release_commit, github_token):\n+  \"\"\"\n+  Gets id of last run for given workflow, repo, branch and commit.\n+  Raises exception when no run found.\n+  \"\"\"\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=repo_url, workflow_id=workflow_id)\n+  data = request_url(\n+      url,\n+      github_token,\n+      params={\n+          \"event\": \"push\", \"branch\": release_branch\n+      },\n+  )\n+  runs = safe_get(data, \"workflow_runs\", url)\n+\n+  filtered_commit_runs = [\n+      r for r in runs if r.get(\"head_sha\", \"\") == release_commit\n+  ]\n+\n+  if not filtered_commit_runs:\n+    workflow_run_web_url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+        repo_url=repo_url, workflow_id=workflow_id)\n+    raise Exception(\n+        f\"No runs for workflow (branch {release_branch}, commit {release_commit}). Verify at {workflow_run_web_url}\"\n+    )\n+\n+  sorted_runs = sorted(\n+      filtered_commit_runs,\n+      key=lambda w: dateutil.parser.parse(w[\"created_at\"]),\n+      reverse=True,\n+  )\n+  last_run = sorted_runs[0]\n+  print(\n+      f\"Found last run. SHA: {release_commit}, created_at: '{last_run['created_at']}', id: {last_run['id']}\"\n+  )\n+  workflow_run_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=repo_url, run_id=last_run[\"id\"])\n+  print(f\"Verify at {workflow_run_web_url}\")\n+  print(\n+      f\"Upload to GCS available at: gs://beam-wheels-staging/{release_branch}/{release_commit}-{workflow_id}/\"\n+  )\n+  return safe_get(last_run, \"id\")\n+\n+\n+def validate_run(run_id, repo_url, github_token):\n+  \"\"\"Validates workflow run. Verifies succesfull status and waits if run is not finished.\"\"\"\n+  run_data = get_single_workflow_run_data(run_id, repo_url, github_token)\n+  status = safe_get(run_data, \"status\")\n+  conclusion = safe_get(run_data, \"conclusion\")\n+\n+  if status == \"completed\" and conclusion == \"success\":\n+    return run_id\n+  elif status in [\"queued\", \"in_progress\"]:\n+    wait_for_workflow_run_to_finish(\n+        run_id, repo_url, status, conclusion, github_token)\n+  else:\n+    run_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+        repo_url=repo_url, run_id=run_id)\n+    raise Exception(\n+        f\"Run unsuccessful. Status: {status}. Conclusion: {conclusion}. Check at: {run_web_url}\"\n+    )\n+\n+\n+def wait_for_workflow_run_to_finish(\n+    run_id, repo_url, status, conclusion, github_token):\n+  \"\"\"Waits for given workflow run to finish succesfully\"\"\"\n+  run_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=repo_url, run_id=run_id)\n+  print(\n+      f\"Started waiting for Workflow run {run_id} to finish. Check on {run_web_url}\"\n+  )\n+  start_time = time.time()\n+  last_request = start_time\n+  spinner = itertools.cycle([\"|\", \"/\", \"-\", \"\\\\\"])\n+  request_interval = 10\n+\n+  while True:\n+    now = time.time()\n+    elapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(now - start_time))\n+    print(\n+        f\"\\r {next(spinner)} Waiting to finish. Elapsed time: {elapsed_time}. \"\n+        f\"Current state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        end=\"\",\n+    )\n+\n+    time.sleep(0.3)\n+    if (now - last_request) > request_interval:\n+      last_request = now\n+      run_data = get_single_workflow_run_data(run_id, repo_url, github_token)\n+      status = safe_get(run_data, \"status\")\n+      conclusion = safe_get(run_data, \"conclusion\")\n+      if status in [\"queued\", \"in_progress\"]:\n+        continue\n+      elif status == \"completed\" and conclusion == \"success\":\n+        print(\n+            f\"\\rFinished in: {elapsed_time}. \"\n+            f\"Last state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        )\n+        return run_id\n+      else:\n+        print(\"\\r\")\n+        raise Exception(\n+            f\"Run unsuccessful. Conclusion: {conclusion}. Check at: {run_web_url}\"\n+        )\n+\n+\n+def reset_directory(artifacts_dir):\n+  \"\"\"Clears directory asking for confirmation before.\"\"\"\n+  question = (\n+      f\"Creating Artifacts directory. Any existing content in {artifacts_dir} will be erased. Proceed?\\n\"\n+      f\"Your answer\")\n+  if get_yes_or_no_answer(question):\n+    print(f\"Clearing directory: {artifacts_dir}\")\n+    shutil.rmtree(artifacts_dir, ignore_errors=True)\n+    os.makedirs(artifacts_dir)\n+  else:\n+    print(\"You said NO for clearing artifacts directory. Quitting ...\")\n+    sys.exit(1)\n+\n+\n+def download_artifacts(run_id, repo_url, artifacts_dir, github_token):\n+  \"\"\"Downloads github artifacts from given run.\"\"\"\n+  print(\"Starting downloading artifacts ... (it may take a while)\")\n+  run_data = get_single_workflow_run_data(run_id, repo_url, github_token)\n+  artifacts_url = safe_get(run_data, \"artifacts_url\")\n+  data_artifacts = request_url(artifacts_url, github_token)\n+  artifacts = safe_get(data_artifacts, \"artifacts\", artifacts_url)\n+  filtered_artifacts = [\n+      a for a in artifacts if (\n+          a[\"name\"].startswith(\"source_gztar_zip\") or\n+          a[\"name\"].startswith(\"wheelhouse\"))\n+  ]\n+  for artifact in filtered_artifacts:\n+    url = safe_get(artifact, \"archive_download_url\")\n+    name = safe_get(artifact, \"name\")\n+    size_in_bytes = safe_get(artifact, \"size_in_bytes\")\n+\n+    download_single_artifact(\n+        url, name, size_in_bytes, artifacts_dir, github_token)\n+\n+\n+def download_single_artifact(\n+    url, name, size_in_bytes, artifacts_dir, github_token):\n+  \"\"\"Downloads single github artifact.\"\"\"\n+  artifacts_size_mb = round(size_in_bytes / (1024 * 1024), 2)\n+  print(\n+      f\"\\tDownloading {name}.zip artifact (size: {artifacts_size_mb} megabytes)\"\n+  )\n+\n+  with tempfile.NamedTemporaryFile(\n+    \"wb\", prefix=name, suffix=\".zip\"\n+  ) as f, request_url(\n+    url, github_token, return_json=False, allow_redirects=True, stream=True\n+  ) as r:\n+    with open(f.name, \"wb\") as f:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzc2NjE5NA=="}, "originalCommit": {"oid": "58926d2c43351ef2ed1ba7394afa11fc2f3f2515"}, "originalPosition": 284}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg1NjUzMTAyOnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/download_github_actions_artifacts.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQwMDozODo1NFrOG0j-Eg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQwODozOTowOVrOG0t_sQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzc2ODQ2Ng==", "bodyText": "The docstring\n\"\"\"Gets workflow id\"\"\"\nis not adding any information since it repeats the function name. You can expand or remove the docstring.\nFor example: \"\"\"Gets the ID of the Github Actions workflow responsible for building wheels.\"\"\"", "url": "https://github.com/apache/beam/pull/12150#discussion_r457768466", "createdAt": "2020-07-21T00:38:54Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,314 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import pprint\n+import shutil\n+import sys\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+GH_API_URL_WORKFLOW_RUNS_FMT = \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+GH_API_URL_WORKFLOW_RUN_FMT = \"https://api.github.com/repos/{repo_url}/actions/runs/{run_id}\"\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{run_id}\"\n+\n+\n+def parse_arguments():\n+  \"\"\"\n+  Gets all neccessary data from the user by parsing arguments or asking for input.\n+  Return: github_token, user_github_id, repo_url, release_branch, release_commit, artifacts_dir\n+  \"\"\"\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+  github_token = ask_for_github_token()\n+\n+  print(\"You passed following arguments:\")\n+  pprint.pprint({**vars(args), **{\"github_token\": github_token}})\n+\n+  if not get_yes_or_no_answer(\"Do you want to continue?\"):\n+    print(\"You said NO. Quitting ...\")\n+    sys.exit(1)\n+\n+  user_github_id = args.github_user\n+  repo_url = args.repo_url\n+  release_branch = args.release_branch\n+  release_commit = args.release_commit\n+  artifacts_dir = args.artifacts_dir\n+\n+  return github_token, user_github_id, repo_url, release_branch, release_commit, artifacts_dir\n+\n+\n+def ask_for_github_token():\n+  \"\"\"Ask for github token and print basic information about it.\"\"\"\n+  url = \"https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token\"\n+  message = (\n+      f\"You need to have a github access token with public_repo scope. \"\n+      f\"More info about creating access tokens can be found here {url}\")\n+  print(message)\n+  github_token = input(\"Enter github token: \")\n+  if not github_token:\n+    return ask_for_github_token()\n+  return github_token\n+\n+\n+def request_url(url, github_token, return_json=True, *args, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token.\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", github_token), **kwargs)\n+  if return_json:\n+    r.raise_for_status()\n+    return r.json()\n+  return r\n+\n+\n+def safe_get(data, key, url=None):\n+  \"\"\"Gets data by the key with informative Exception in case of non existent key.\"\"\"\n+  if key not in data:\n+    message = f'There is missing key: \"{key}\" in response data: {data}.'\n+    if url:\n+      message += f\" Requested url: {url}\"\n+    raise ValueError(message)\n+  return data.get(key)\n+\n+\n+def get_yes_or_no_answer(question):\n+  \"\"\"Asks yes or no question.\"\"\"\n+  reply = str(input(question + \" 'y' or 'n'): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  elif reply == \"n\":\n+    return False\n+  else:\n+    return get_yes_or_no_answer(\"Uhhhh... please enter\")\n+\n+\n+def get_build_wheels_workflow_id(repo_url, github_token):\n+  \"\"\"Gets workflow id.\"\"\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "58926d2c43351ef2ed1ba7394afa11fc2f3f2515"}, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzkzMjcyMQ==", "bodyText": "Thank you, I will apply your suggestion.", "url": "https://github.com/apache/beam/pull/12150#discussion_r457932721", "createdAt": "2020-07-21T08:39:09Z", "author": {"login": "TobKed"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,314 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import pprint\n+import shutil\n+import sys\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+GH_API_URL_WORKFLOW_RUNS_FMT = \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+GH_API_URL_WORKFLOW_RUN_FMT = \"https://api.github.com/repos/{repo_url}/actions/runs/{run_id}\"\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{run_id}\"\n+\n+\n+def parse_arguments():\n+  \"\"\"\n+  Gets all neccessary data from the user by parsing arguments or asking for input.\n+  Return: github_token, user_github_id, repo_url, release_branch, release_commit, artifacts_dir\n+  \"\"\"\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+  github_token = ask_for_github_token()\n+\n+  print(\"You passed following arguments:\")\n+  pprint.pprint({**vars(args), **{\"github_token\": github_token}})\n+\n+  if not get_yes_or_no_answer(\"Do you want to continue?\"):\n+    print(\"You said NO. Quitting ...\")\n+    sys.exit(1)\n+\n+  user_github_id = args.github_user\n+  repo_url = args.repo_url\n+  release_branch = args.release_branch\n+  release_commit = args.release_commit\n+  artifacts_dir = args.artifacts_dir\n+\n+  return github_token, user_github_id, repo_url, release_branch, release_commit, artifacts_dir\n+\n+\n+def ask_for_github_token():\n+  \"\"\"Ask for github token and print basic information about it.\"\"\"\n+  url = \"https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token\"\n+  message = (\n+      f\"You need to have a github access token with public_repo scope. \"\n+      f\"More info about creating access tokens can be found here {url}\")\n+  print(message)\n+  github_token = input(\"Enter github token: \")\n+  if not github_token:\n+    return ask_for_github_token()\n+  return github_token\n+\n+\n+def request_url(url, github_token, return_json=True, *args, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token.\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", github_token), **kwargs)\n+  if return_json:\n+    r.raise_for_status()\n+    return r.json()\n+  return r\n+\n+\n+def safe_get(data, key, url=None):\n+  \"\"\"Gets data by the key with informative Exception in case of non existent key.\"\"\"\n+  if key not in data:\n+    message = f'There is missing key: \"{key}\" in response data: {data}.'\n+    if url:\n+      message += f\" Requested url: {url}\"\n+    raise ValueError(message)\n+  return data.get(key)\n+\n+\n+def get_yes_or_no_answer(question):\n+  \"\"\"Asks yes or no question.\"\"\"\n+  reply = str(input(question + \" 'y' or 'n'): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  elif reply == \"n\":\n+    return False\n+  else:\n+    return get_yes_or_no_answer(\"Uhhhh... please enter\")\n+\n+\n+def get_build_wheels_workflow_id(repo_url, github_token):\n+  \"\"\"Gets workflow id.\"\"\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzc2ODQ2Ng=="}, "originalCommit": {"oid": "58926d2c43351ef2ed1ba7394afa11fc2f3f2515"}, "originalPosition": 116}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg1NjU1NTQzOnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/download_github_actions_artifacts.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQwMDo1MjoyMFrOG0kMjw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQwODo0MDo1OVrOG0uD6g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzc3MjE3NQ==", "bodyText": "How about\ndef safe_get(response_dict, key, original_url=None):\n  \"\"\"Looks up attribute values from a parsed JSON HTTP response.\"\"\"", "url": "https://github.com/apache/beam/pull/12150#discussion_r457772175", "createdAt": "2020-07-21T00:52:20Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -51,26 +55,56 @@ def parse_arguments():\n \n   args = parser.parse_args()\n \n-  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n-  GITHUB_TOKEN = args.github_token\n-  USER_GITHUB_ID = args.github_user\n-  REPO_URL = args.repo_url\n-  RELEASE_BRANCH = args.release_branch\n-  RELEASE_COMMIT = args.release_commit\n-  ARTIFACTS_DIR = args.artifacts_dir\n+  github_token = ask_for_github_token()\n+  print(\"You passed following arguments:\")\n+  pprint.pprint({**vars(args), **{\"github_token\": github_token}})\n+  if not get_yes_or_no_answer(\"Do you want to continue?\"):\n+    print(\"You said NO. Quitting ...\")\n+    sys.exit(1)\n+\n+  user_github_id = args.github_user\n+  repo_url = args.repo_url\n+  release_branch = args.release_branch\n+  release_commit = args.release_commit\n+  artifacts_dir = args.artifacts_dir\n+\n+  return github_token, user_github_id, repo_url, release_branch, release_commit, artifacts_dir\n+\n \n+def ask_for_github_token():\n+  \"\"\"Ask for github token and print basic information about it\"\"\"\n+  url = \"https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token\"\n+  message = (\n+      f\"You need to have a github access token with public_repo scope. \"\n+      f\"More info about creating access tokens can be found here {url}\")\n+  print(message)\n+  github_token = input(\"Enter github token: \")\n+  if not github_token:\n+    return ask_for_github_token()\n+  return github_token\n \n-def request_url(url, return_json=True, *args, **kwargs):\n+\n+def request_url(url, github_token, return_json=True, *args, **kwargs):\n   \"\"\"Helper function form making requests authorized by GitHub token\"\"\"\n-  r = requests.get(url, *args, auth=(\"token\", GITHUB_TOKEN), **kwargs)\n+  r = requests.get(url, *args, auth=(\"token\", github_token), **kwargs)\n   if return_json:\n     r.raise_for_status()\n     return r.json()\n   return r\n \n \n+def safe_get(data, key, url=None):\n+  \"\"\"Gets data by the key with informative Exception in case of non existent key.\"\"\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6957a8825d5cec7542c420bf0333d7eed05cd37a"}, "originalPosition": 76}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzkzMzgwMg==", "bodyText": "I like your suggestion. Thank you. I will apply it.", "url": "https://github.com/apache/beam/pull/12150#discussion_r457933802", "createdAt": "2020-07-21T08:40:59Z", "author": {"login": "TobKed"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -51,26 +55,56 @@ def parse_arguments():\n \n   args = parser.parse_args()\n \n-  global GITHUB_TOKEN, USER_GITHUB_ID, REPO_URL, RELEASE_BRANCH, RELEASE_COMMIT, ARTIFACTS_DIR\n-  GITHUB_TOKEN = args.github_token\n-  USER_GITHUB_ID = args.github_user\n-  REPO_URL = args.repo_url\n-  RELEASE_BRANCH = args.release_branch\n-  RELEASE_COMMIT = args.release_commit\n-  ARTIFACTS_DIR = args.artifacts_dir\n+  github_token = ask_for_github_token()\n+  print(\"You passed following arguments:\")\n+  pprint.pprint({**vars(args), **{\"github_token\": github_token}})\n+  if not get_yes_or_no_answer(\"Do you want to continue?\"):\n+    print(\"You said NO. Quitting ...\")\n+    sys.exit(1)\n+\n+  user_github_id = args.github_user\n+  repo_url = args.repo_url\n+  release_branch = args.release_branch\n+  release_commit = args.release_commit\n+  artifacts_dir = args.artifacts_dir\n+\n+  return github_token, user_github_id, repo_url, release_branch, release_commit, artifacts_dir\n+\n \n+def ask_for_github_token():\n+  \"\"\"Ask for github token and print basic information about it\"\"\"\n+  url = \"https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token\"\n+  message = (\n+      f\"You need to have a github access token with public_repo scope. \"\n+      f\"More info about creating access tokens can be found here {url}\")\n+  print(message)\n+  github_token = input(\"Enter github token: \")\n+  if not github_token:\n+    return ask_for_github_token()\n+  return github_token\n \n-def request_url(url, return_json=True, *args, **kwargs):\n+\n+def request_url(url, github_token, return_json=True, *args, **kwargs):\n   \"\"\"Helper function form making requests authorized by GitHub token\"\"\"\n-  r = requests.get(url, *args, auth=(\"token\", GITHUB_TOKEN), **kwargs)\n+  r = requests.get(url, *args, auth=(\"token\", github_token), **kwargs)\n   if return_json:\n     r.raise_for_status()\n     return r.json()\n   return r\n \n \n+def safe_get(data, key, url=None):\n+  \"\"\"Gets data by the key with informative Exception in case of non existent key.\"\"\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzc3MjE3NQ=="}, "originalCommit": {"oid": "6957a8825d5cec7542c420bf0333d7eed05cd37a"}, "originalPosition": 76}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg1NjU2Njc1OnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/build_release_candidate.sh", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQwMDo1OTowNFrOG0kTWQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQxNjo1MDo0OVrOG1BBJg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzc3MzkxMw==", "bodyText": "Was there a change from .zip to .tar .gz for the source archive? See: https://dist.apache.org/repos/dist/dev/beam/2.23.0/python/", "url": "https://github.com/apache/beam/pull/12150#discussion_r457773913", "createdAt": "2020-07-21T00:59:04Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/build_release_candidate.sh", "diffHunk": "@@ -205,7 +205,7 @@ if [[ $confirmation = \"y\" ]]; then\n   sha512sum -c apache-beam-${RELEASE}.tar.gz.sha512\n \n   echo \"-----Signing Source Release apache-beam-${RELEASE}.tar.gz-----\"\n-  gpg --local-user ${SIGNING_KEY} --armor --detach-sig apache-beam-${RELEASE}.zip\n+  gpg --local-user ${SIGNING_KEY} --armor --detach-sig apache-beam-${RELEASE}.tar.gz", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7bc36d878a02c3dba1068c43c5cc0f6c6b9a2ae5"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODA2NTI5MQ==", "bodyText": "I kept .zip but also added .taz.gz  . Can only one type of source archive exist?\nIn this particular line I change it because .tar.gz should be here as it is in echo above, but .zip was signed twice.", "url": "https://github.com/apache/beam/pull/12150#discussion_r458065291", "createdAt": "2020-07-21T12:42:19Z", "author": {"login": "TobKed"}, "path": "release/src/main/scripts/build_release_candidate.sh", "diffHunk": "@@ -205,7 +205,7 @@ if [[ $confirmation = \"y\" ]]; then\n   sha512sum -c apache-beam-${RELEASE}.tar.gz.sha512\n \n   echo \"-----Signing Source Release apache-beam-${RELEASE}.tar.gz-----\"\n-  gpg --local-user ${SIGNING_KEY} --armor --detach-sig apache-beam-${RELEASE}.zip\n+  gpg --local-user ${SIGNING_KEY} --armor --detach-sig apache-beam-${RELEASE}.tar.gz", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzc3MzkxMw=="}, "originalCommit": {"oid": "7bc36d878a02c3dba1068c43c5cc0f6c6b9a2ae5"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODI0NDM5MA==", "bodyText": "https://pypi.org/project/apache-beam/#files also stores only 'zip' version of sources. I don't see a reason to add a .tar.gz artifact if the content is the same.", "url": "https://github.com/apache/beam/pull/12150#discussion_r458244390", "createdAt": "2020-07-21T16:50:49Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/build_release_candidate.sh", "diffHunk": "@@ -205,7 +205,7 @@ if [[ $confirmation = \"y\" ]]; then\n   sha512sum -c apache-beam-${RELEASE}.tar.gz.sha512\n \n   echo \"-----Signing Source Release apache-beam-${RELEASE}.tar.gz-----\"\n-  gpg --local-user ${SIGNING_KEY} --armor --detach-sig apache-beam-${RELEASE}.zip\n+  gpg --local-user ${SIGNING_KEY} --armor --detach-sig apache-beam-${RELEASE}.tar.gz", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzc3MzkxMw=="}, "originalCommit": {"oid": "7bc36d878a02c3dba1068c43c5cc0f6c6b9a2ae5"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg1NjU3ODQzOnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/download_github_actions_artifacts.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQwMTowNTozMVrOG0kaDQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQwOTowMDo1NVrOG0uzvw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzc3NTYyOQ==", "bodyText": "How about:\nGCS location corresponding to artifacts built in this run: \n\nAlso at the end of GCS path do we have workflow_id or last_run[\"id\"] ?", "url": "https://github.com/apache/beam/pull/12150#discussion_r457775629", "createdAt": "2020-07-21T01:05:31Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,314 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import pprint\n+import shutil\n+import sys\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+GH_API_URL_WORKFLOW_RUNS_FMT = \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+GH_API_URL_WORKFLOW_RUN_FMT = \"https://api.github.com/repos/{repo_url}/actions/runs/{run_id}\"\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{run_id}\"\n+\n+\n+def parse_arguments():\n+  \"\"\"\n+  Gets all neccessary data from the user by parsing arguments or asking for input.\n+  Return: github_token, user_github_id, repo_url, release_branch, release_commit, artifacts_dir\n+  \"\"\"\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+  github_token = ask_for_github_token()\n+\n+  print(\"You passed following arguments:\")\n+  pprint.pprint({**vars(args), **{\"github_token\": github_token}})\n+\n+  if not get_yes_or_no_answer(\"Do you want to continue?\"):\n+    print(\"You said NO. Quitting ...\")\n+    sys.exit(1)\n+\n+  user_github_id = args.github_user\n+  repo_url = args.repo_url\n+  release_branch = args.release_branch\n+  release_commit = args.release_commit\n+  artifacts_dir = args.artifacts_dir\n+\n+  return github_token, user_github_id, repo_url, release_branch, release_commit, artifacts_dir\n+\n+\n+def ask_for_github_token():\n+  \"\"\"Ask for github token and print basic information about it.\"\"\"\n+  url = \"https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token\"\n+  message = (\n+      f\"You need to have a github access token with public_repo scope. \"\n+      f\"More info about creating access tokens can be found here {url}\")\n+  print(message)\n+  github_token = input(\"Enter github token: \")\n+  if not github_token:\n+    return ask_for_github_token()\n+  return github_token\n+\n+\n+def request_url(url, github_token, return_json=True, *args, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token.\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", github_token), **kwargs)\n+  if return_json:\n+    r.raise_for_status()\n+    return r.json()\n+  return r\n+\n+\n+def safe_get(data, key, url=None):\n+  \"\"\"Gets data by the key with informative Exception in case of non existent key.\"\"\"\n+  if key not in data:\n+    message = f'There is missing key: \"{key}\" in response data: {data}.'\n+    if url:\n+      message += f\" Requested url: {url}\"\n+    raise ValueError(message)\n+  return data.get(key)\n+\n+\n+def get_yes_or_no_answer(question):\n+  \"\"\"Asks yes or no question.\"\"\"\n+  reply = str(input(question + \" 'y' or 'n'): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  elif reply == \"n\":\n+    return False\n+  else:\n+    return get_yes_or_no_answer(\"Uhhhh... please enter\")\n+\n+\n+def get_build_wheels_workflow_id(repo_url, github_token):\n+  \"\"\"Gets workflow id.\"\"\"\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=repo_url)\n+  data = request_url(url, github_token)\n+  return safe_get(data, \"id\", url)\n+\n+\n+def get_single_workflow_run_data(run_id, repo_url, github_token):\n+  \"\"\"Gets single workflow run data (github api payload).\"\"\"\n+  url = GH_API_URL_WORKFLOW_RUN_FMT.format(repo_url=repo_url, run_id=run_id)\n+  return request_url(url, github_token)\n+\n+\n+def get_last_run_id(\n+    workflow_id, repo_url, release_branch, release_commit, github_token):\n+  \"\"\"\n+  Gets id of last run for given workflow, repo, branch and commit.\n+  Raises exception when no run found.\n+  \"\"\"\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=repo_url, workflow_id=workflow_id)\n+  data = request_url(\n+      url,\n+      github_token,\n+      params={\n+          \"event\": \"push\", \"branch\": release_branch\n+      },\n+  )\n+  runs = safe_get(data, \"workflow_runs\", url)\n+\n+  filtered_commit_runs = [\n+      r for r in runs if r.get(\"head_sha\", \"\") == release_commit\n+  ]\n+\n+  if not filtered_commit_runs:\n+    workflow_run_web_url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+        repo_url=repo_url, workflow_id=workflow_id)\n+    raise Exception(\n+        f\"No runs for workflow (branch {release_branch}, commit {release_commit}). Verify at {workflow_run_web_url}\"\n+    )\n+\n+  sorted_runs = sorted(\n+      filtered_commit_runs,\n+      key=lambda w: dateutil.parser.parse(w[\"created_at\"]),\n+      reverse=True,\n+  )\n+  last_run = sorted_runs[0]\n+  print(\n+      f\"Found last run. SHA: {release_commit}, created_at: '{last_run['created_at']}', id: {last_run['id']}\"\n+  )\n+  workflow_run_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=repo_url, run_id=last_run[\"id\"])\n+  print(f\"Verify at {workflow_run_web_url}\")\n+  print(\n+      f\"Upload to GCS available at: gs://beam-wheels-staging/{release_branch}/{release_commit}-{workflow_id}/\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "58926d2c43351ef2ed1ba7394afa11fc2f3f2515"}, "originalPosition": 169}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzk0NjA0Nw==", "bodyText": "it should be last_run[\"id\"]. Thanks for pointing this out. I fix it and applied your suggestion about message.", "url": "https://github.com/apache/beam/pull/12150#discussion_r457946047", "createdAt": "2020-07-21T09:00:55Z", "author": {"login": "TobKed"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,314 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import pprint\n+import shutil\n+import sys\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+GH_API_URL_WORKFLOW_RUNS_FMT = \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+GH_API_URL_WORKFLOW_RUN_FMT = \"https://api.github.com/repos/{repo_url}/actions/runs/{run_id}\"\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{run_id}\"\n+\n+\n+def parse_arguments():\n+  \"\"\"\n+  Gets all neccessary data from the user by parsing arguments or asking for input.\n+  Return: github_token, user_github_id, repo_url, release_branch, release_commit, artifacts_dir\n+  \"\"\"\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+  github_token = ask_for_github_token()\n+\n+  print(\"You passed following arguments:\")\n+  pprint.pprint({**vars(args), **{\"github_token\": github_token}})\n+\n+  if not get_yes_or_no_answer(\"Do you want to continue?\"):\n+    print(\"You said NO. Quitting ...\")\n+    sys.exit(1)\n+\n+  user_github_id = args.github_user\n+  repo_url = args.repo_url\n+  release_branch = args.release_branch\n+  release_commit = args.release_commit\n+  artifacts_dir = args.artifacts_dir\n+\n+  return github_token, user_github_id, repo_url, release_branch, release_commit, artifacts_dir\n+\n+\n+def ask_for_github_token():\n+  \"\"\"Ask for github token and print basic information about it.\"\"\"\n+  url = \"https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token\"\n+  message = (\n+      f\"You need to have a github access token with public_repo scope. \"\n+      f\"More info about creating access tokens can be found here {url}\")\n+  print(message)\n+  github_token = input(\"Enter github token: \")\n+  if not github_token:\n+    return ask_for_github_token()\n+  return github_token\n+\n+\n+def request_url(url, github_token, return_json=True, *args, **kwargs):\n+  \"\"\"Helper function form making requests authorized by GitHub token.\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", github_token), **kwargs)\n+  if return_json:\n+    r.raise_for_status()\n+    return r.json()\n+  return r\n+\n+\n+def safe_get(data, key, url=None):\n+  \"\"\"Gets data by the key with informative Exception in case of non existent key.\"\"\"\n+  if key not in data:\n+    message = f'There is missing key: \"{key}\" in response data: {data}.'\n+    if url:\n+      message += f\" Requested url: {url}\"\n+    raise ValueError(message)\n+  return data.get(key)\n+\n+\n+def get_yes_or_no_answer(question):\n+  \"\"\"Asks yes or no question.\"\"\"\n+  reply = str(input(question + \" 'y' or 'n'): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  elif reply == \"n\":\n+    return False\n+  else:\n+    return get_yes_or_no_answer(\"Uhhhh... please enter\")\n+\n+\n+def get_build_wheels_workflow_id(repo_url, github_token):\n+  \"\"\"Gets workflow id.\"\"\"\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=repo_url)\n+  data = request_url(url, github_token)\n+  return safe_get(data, \"id\", url)\n+\n+\n+def get_single_workflow_run_data(run_id, repo_url, github_token):\n+  \"\"\"Gets single workflow run data (github api payload).\"\"\"\n+  url = GH_API_URL_WORKFLOW_RUN_FMT.format(repo_url=repo_url, run_id=run_id)\n+  return request_url(url, github_token)\n+\n+\n+def get_last_run_id(\n+    workflow_id, repo_url, release_branch, release_commit, github_token):\n+  \"\"\"\n+  Gets id of last run for given workflow, repo, branch and commit.\n+  Raises exception when no run found.\n+  \"\"\"\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=repo_url, workflow_id=workflow_id)\n+  data = request_url(\n+      url,\n+      github_token,\n+      params={\n+          \"event\": \"push\", \"branch\": release_branch\n+      },\n+  )\n+  runs = safe_get(data, \"workflow_runs\", url)\n+\n+  filtered_commit_runs = [\n+      r for r in runs if r.get(\"head_sha\", \"\") == release_commit\n+  ]\n+\n+  if not filtered_commit_runs:\n+    workflow_run_web_url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+        repo_url=repo_url, workflow_id=workflow_id)\n+    raise Exception(\n+        f\"No runs for workflow (branch {release_branch}, commit {release_commit}). Verify at {workflow_run_web_url}\"\n+    )\n+\n+  sorted_runs = sorted(\n+      filtered_commit_runs,\n+      key=lambda w: dateutil.parser.parse(w[\"created_at\"]),\n+      reverse=True,\n+  )\n+  last_run = sorted_runs[0]\n+  print(\n+      f\"Found last run. SHA: {release_commit}, created_at: '{last_run['created_at']}', id: {last_run['id']}\"\n+  )\n+  workflow_run_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=repo_url, run_id=last_run[\"id\"])\n+  print(f\"Verify at {workflow_run_web_url}\")\n+  print(\n+      f\"Upload to GCS available at: gs://beam-wheels-staging/{release_branch}/{release_commit}-{workflow_id}/\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1Nzc3NTYyOQ=="}, "originalCommit": {"oid": "58926d2c43351ef2ed1ba7394afa11fc2f3f2515"}, "originalPosition": 169}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg1OTUzNTc2OnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/download_github_actions_artifacts.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQxNjozOTozNFrOG1AkQw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQwOTozMzo0MFrOG1anUg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODIzNjk5NQ==", "bodyText": "return last_run_id", "url": "https://github.com/apache/beam/pull/12150#discussion_r458236995", "createdAt": "2020-07-21T16:39:34Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,316 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import pprint\n+import shutil\n+import sys\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+GH_API_URL_WORKFLOW_RUNS_FMT = \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+GH_API_URL_WORKFLOW_RUN_FMT = \"https://api.github.com/repos/{repo_url}/actions/runs/{run_id}\"\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{run_id}\"\n+\n+\n+def parse_arguments():\n+  \"\"\"\n+  Gets all neccessary data from the user by parsing arguments or asking for input.\n+  Return: github_token, user_github_id, repo_url, release_branch, release_commit, artifacts_dir\n+  \"\"\"\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+  github_token = ask_for_github_token()\n+\n+  print(\"You passed following arguments:\")\n+  pprint.pprint({**vars(args), **{\"github_token\": github_token}})\n+\n+  if not get_yes_or_no_answer(\"Do you want to continue?\"):\n+    print(\"You said NO. Quitting ...\")\n+    sys.exit(1)\n+\n+  user_github_id = args.github_user\n+  repo_url = args.repo_url\n+  release_branch = args.release_branch\n+  release_commit = args.release_commit\n+  artifacts_dir = args.artifacts_dir\n+\n+  return github_token, user_github_id, repo_url, release_branch, release_commit, artifacts_dir\n+\n+\n+def ask_for_github_token():\n+  \"\"\"Ask for github token and print basic information about it.\"\"\"\n+  url = \"https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token\"\n+  message = (\n+      f\"You need to have a github access token with public_repo scope. \"\n+      f\"More info about creating access tokens can be found here {url}\")\n+  print(message)\n+  github_token = input(\"Enter github token: \")\n+  if not github_token:\n+    return ask_for_github_token()\n+  return github_token\n+\n+\n+def request_url(url, github_token, return_json=True, *args, **kwargs):\n+  \"\"\"Helper function for making requests authorized by GitHub token.\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", github_token), **kwargs)\n+  if return_json:\n+    r.raise_for_status()\n+    return r.json()\n+  return r\n+\n+\n+def safe_get(data, key, url=None):\n+  \"\"\"Looks up attribute values from a parsed JSON HTTP response.\"\"\"\n+  if key not in data:\n+    message = f'There is missing key: \"{key}\" in response data: {data}.'\n+    if url:\n+      message += f\" Requested url: {url}\"\n+    raise ValueError(message)\n+  return data.get(key)\n+\n+\n+def get_yes_or_no_answer(question):\n+  \"\"\"Asks yes or no question.\"\"\"\n+  reply = str(input(question + \" 'y' or 'n'): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  elif reply == \"n\":\n+    return False\n+  else:\n+    return get_yes_or_no_answer(\"Uhhhh... please enter\")\n+\n+\n+def get_build_wheels_workflow_id(repo_url, github_token):\n+  \"\"\"Gets the ID of the Github Actions workflow responsible for building wheels.\"\"\"\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=repo_url)\n+  data = request_url(url, github_token)\n+  return safe_get(data, \"id\", url)\n+\n+\n+def get_single_workflow_run_data(run_id, repo_url, github_token):\n+  \"\"\"Gets single workflow run data (github api payload).\"\"\"\n+  url = GH_API_URL_WORKFLOW_RUN_FMT.format(repo_url=repo_url, run_id=run_id)\n+  return request_url(url, github_token)\n+\n+\n+def get_last_run_id(\n+    workflow_id, repo_url, release_branch, release_commit, github_token):\n+  \"\"\"\n+  Gets id of last run for given workflow, repo, branch and commit.\n+  Raises exception when no run found.\n+  \"\"\"\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=repo_url, workflow_id=workflow_id)\n+  data = request_url(\n+      url,\n+      github_token,\n+      params={\n+          \"event\": \"push\", \"branch\": release_branch\n+      },\n+  )\n+  runs = safe_get(data, \"workflow_runs\", url)\n+\n+  filtered_commit_runs = [\n+      r for r in runs if r.get(\"head_sha\", \"\") == release_commit\n+  ]\n+\n+  if not filtered_commit_runs:\n+    workflow_run_web_url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+        repo_url=repo_url, workflow_id=workflow_id)\n+    raise Exception(\n+        f\"No runs for workflow (branch {release_branch}, commit {release_commit}). Verify at {workflow_run_web_url}\"\n+    )\n+\n+  sorted_runs = sorted(\n+      filtered_commit_runs,\n+      key=lambda w: dateutil.parser.parse(w[\"created_at\"]),\n+      reverse=True,\n+  )\n+  last_run = sorted_runs[0]\n+  last_run_id = safe_get(last_run, \"id\")\n+  print(\n+      f\"Found last run. SHA: {release_commit}, created_at: '{last_run['created_at']}', id: {last_run_id}\"\n+  )\n+  workflow_run_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=repo_url, run_id=last_run_id)\n+  print(f\"Verify at {workflow_run_web_url}\")\n+  print(\n+      f\"GCS location corresponding to artifacts built in this run: \"\n+      f\"gs://beam-wheels-staging/{release_branch}/{release_commit}-{last_run_id}/\"\n+  )\n+  return safe_get(last_run, \"id\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "468b2d41d0d1bef10489b73e64aaed5bf38ea6de"}, "originalPosition": 173}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODY2Mzc2Mg==", "bodyText": "Thanks. I missed that. Fixed.", "url": "https://github.com/apache/beam/pull/12150#discussion_r458663762", "createdAt": "2020-07-22T09:33:40Z", "author": {"login": "TobKed"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,316 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import pprint\n+import shutil\n+import sys\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+GH_API_URL_WORKFLOW_RUNS_FMT = \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+GH_API_URL_WORKFLOW_RUN_FMT = \"https://api.github.com/repos/{repo_url}/actions/runs/{run_id}\"\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{run_id}\"\n+\n+\n+def parse_arguments():\n+  \"\"\"\n+  Gets all neccessary data from the user by parsing arguments or asking for input.\n+  Return: github_token, user_github_id, repo_url, release_branch, release_commit, artifacts_dir\n+  \"\"\"\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+  github_token = ask_for_github_token()\n+\n+  print(\"You passed following arguments:\")\n+  pprint.pprint({**vars(args), **{\"github_token\": github_token}})\n+\n+  if not get_yes_or_no_answer(\"Do you want to continue?\"):\n+    print(\"You said NO. Quitting ...\")\n+    sys.exit(1)\n+\n+  user_github_id = args.github_user\n+  repo_url = args.repo_url\n+  release_branch = args.release_branch\n+  release_commit = args.release_commit\n+  artifacts_dir = args.artifacts_dir\n+\n+  return github_token, user_github_id, repo_url, release_branch, release_commit, artifacts_dir\n+\n+\n+def ask_for_github_token():\n+  \"\"\"Ask for github token and print basic information about it.\"\"\"\n+  url = \"https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token\"\n+  message = (\n+      f\"You need to have a github access token with public_repo scope. \"\n+      f\"More info about creating access tokens can be found here {url}\")\n+  print(message)\n+  github_token = input(\"Enter github token: \")\n+  if not github_token:\n+    return ask_for_github_token()\n+  return github_token\n+\n+\n+def request_url(url, github_token, return_json=True, *args, **kwargs):\n+  \"\"\"Helper function for making requests authorized by GitHub token.\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", github_token), **kwargs)\n+  if return_json:\n+    r.raise_for_status()\n+    return r.json()\n+  return r\n+\n+\n+def safe_get(data, key, url=None):\n+  \"\"\"Looks up attribute values from a parsed JSON HTTP response.\"\"\"\n+  if key not in data:\n+    message = f'There is missing key: \"{key}\" in response data: {data}.'\n+    if url:\n+      message += f\" Requested url: {url}\"\n+    raise ValueError(message)\n+  return data.get(key)\n+\n+\n+def get_yes_or_no_answer(question):\n+  \"\"\"Asks yes or no question.\"\"\"\n+  reply = str(input(question + \" 'y' or 'n'): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  elif reply == \"n\":\n+    return False\n+  else:\n+    return get_yes_or_no_answer(\"Uhhhh... please enter\")\n+\n+\n+def get_build_wheels_workflow_id(repo_url, github_token):\n+  \"\"\"Gets the ID of the Github Actions workflow responsible for building wheels.\"\"\"\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=repo_url)\n+  data = request_url(url, github_token)\n+  return safe_get(data, \"id\", url)\n+\n+\n+def get_single_workflow_run_data(run_id, repo_url, github_token):\n+  \"\"\"Gets single workflow run data (github api payload).\"\"\"\n+  url = GH_API_URL_WORKFLOW_RUN_FMT.format(repo_url=repo_url, run_id=run_id)\n+  return request_url(url, github_token)\n+\n+\n+def get_last_run_id(\n+    workflow_id, repo_url, release_branch, release_commit, github_token):\n+  \"\"\"\n+  Gets id of last run for given workflow, repo, branch and commit.\n+  Raises exception when no run found.\n+  \"\"\"\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=repo_url, workflow_id=workflow_id)\n+  data = request_url(\n+      url,\n+      github_token,\n+      params={\n+          \"event\": \"push\", \"branch\": release_branch\n+      },\n+  )\n+  runs = safe_get(data, \"workflow_runs\", url)\n+\n+  filtered_commit_runs = [\n+      r for r in runs if r.get(\"head_sha\", \"\") == release_commit\n+  ]\n+\n+  if not filtered_commit_runs:\n+    workflow_run_web_url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+        repo_url=repo_url, workflow_id=workflow_id)\n+    raise Exception(\n+        f\"No runs for workflow (branch {release_branch}, commit {release_commit}). Verify at {workflow_run_web_url}\"\n+    )\n+\n+  sorted_runs = sorted(\n+      filtered_commit_runs,\n+      key=lambda w: dateutil.parser.parse(w[\"created_at\"]),\n+      reverse=True,\n+  )\n+  last_run = sorted_runs[0]\n+  last_run_id = safe_get(last_run, \"id\")\n+  print(\n+      f\"Found last run. SHA: {release_commit}, created_at: '{last_run['created_at']}', id: {last_run_id}\"\n+  )\n+  workflow_run_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=repo_url, run_id=last_run_id)\n+  print(f\"Verify at {workflow_run_web_url}\")\n+  print(\n+      f\"GCS location corresponding to artifacts built in this run: \"\n+      f\"gs://beam-wheels-staging/{release_branch}/{release_commit}-{last_run_id}/\"\n+  )\n+  return safe_get(last_run, \"id\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODIzNjk5NQ=="}, "originalCommit": {"oid": "468b2d41d0d1bef10489b73e64aaed5bf38ea6de"}, "originalPosition": 173}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg1OTU0NzM5OnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/download_github_actions_artifacts.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQxNjo0MjoxNFrOG1AraA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxMDo1MTo0MVrOG1dLwQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODIzODgyNA==", "bodyText": "It's not clear from reading the code of download_single_artifact why there is an assumption that the 'single artifact' will be a 'zip archive', and why download_single_artifact also extracts the archive.", "url": "https://github.com/apache/beam/pull/12150#discussion_r458238824", "createdAt": "2020-07-21T16:42:14Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,316 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import pprint\n+import shutil\n+import sys\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+GH_API_URL_WORKFLOW_RUNS_FMT = \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+GH_API_URL_WORKFLOW_RUN_FMT = \"https://api.github.com/repos/{repo_url}/actions/runs/{run_id}\"\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{run_id}\"\n+\n+\n+def parse_arguments():\n+  \"\"\"\n+  Gets all neccessary data from the user by parsing arguments or asking for input.\n+  Return: github_token, user_github_id, repo_url, release_branch, release_commit, artifacts_dir\n+  \"\"\"\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+  github_token = ask_for_github_token()\n+\n+  print(\"You passed following arguments:\")\n+  pprint.pprint({**vars(args), **{\"github_token\": github_token}})\n+\n+  if not get_yes_or_no_answer(\"Do you want to continue?\"):\n+    print(\"You said NO. Quitting ...\")\n+    sys.exit(1)\n+\n+  user_github_id = args.github_user\n+  repo_url = args.repo_url\n+  release_branch = args.release_branch\n+  release_commit = args.release_commit\n+  artifacts_dir = args.artifacts_dir\n+\n+  return github_token, user_github_id, repo_url, release_branch, release_commit, artifacts_dir\n+\n+\n+def ask_for_github_token():\n+  \"\"\"Ask for github token and print basic information about it.\"\"\"\n+  url = \"https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token\"\n+  message = (\n+      f\"You need to have a github access token with public_repo scope. \"\n+      f\"More info about creating access tokens can be found here {url}\")\n+  print(message)\n+  github_token = input(\"Enter github token: \")\n+  if not github_token:\n+    return ask_for_github_token()\n+  return github_token\n+\n+\n+def request_url(url, github_token, return_json=True, *args, **kwargs):\n+  \"\"\"Helper function for making requests authorized by GitHub token.\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", github_token), **kwargs)\n+  if return_json:\n+    r.raise_for_status()\n+    return r.json()\n+  return r\n+\n+\n+def safe_get(data, key, url=None):\n+  \"\"\"Looks up attribute values from a parsed JSON HTTP response.\"\"\"\n+  if key not in data:\n+    message = f'There is missing key: \"{key}\" in response data: {data}.'\n+    if url:\n+      message += f\" Requested url: {url}\"\n+    raise ValueError(message)\n+  return data.get(key)\n+\n+\n+def get_yes_or_no_answer(question):\n+  \"\"\"Asks yes or no question.\"\"\"\n+  reply = str(input(question + \" 'y' or 'n'): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  elif reply == \"n\":\n+    return False\n+  else:\n+    return get_yes_or_no_answer(\"Uhhhh... please enter\")\n+\n+\n+def get_build_wheels_workflow_id(repo_url, github_token):\n+  \"\"\"Gets the ID of the Github Actions workflow responsible for building wheels.\"\"\"\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=repo_url)\n+  data = request_url(url, github_token)\n+  return safe_get(data, \"id\", url)\n+\n+\n+def get_single_workflow_run_data(run_id, repo_url, github_token):\n+  \"\"\"Gets single workflow run data (github api payload).\"\"\"\n+  url = GH_API_URL_WORKFLOW_RUN_FMT.format(repo_url=repo_url, run_id=run_id)\n+  return request_url(url, github_token)\n+\n+\n+def get_last_run_id(\n+    workflow_id, repo_url, release_branch, release_commit, github_token):\n+  \"\"\"\n+  Gets id of last run for given workflow, repo, branch and commit.\n+  Raises exception when no run found.\n+  \"\"\"\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=repo_url, workflow_id=workflow_id)\n+  data = request_url(\n+      url,\n+      github_token,\n+      params={\n+          \"event\": \"push\", \"branch\": release_branch\n+      },\n+  )\n+  runs = safe_get(data, \"workflow_runs\", url)\n+\n+  filtered_commit_runs = [\n+      r for r in runs if r.get(\"head_sha\", \"\") == release_commit\n+  ]\n+\n+  if not filtered_commit_runs:\n+    workflow_run_web_url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+        repo_url=repo_url, workflow_id=workflow_id)\n+    raise Exception(\n+        f\"No runs for workflow (branch {release_branch}, commit {release_commit}). Verify at {workflow_run_web_url}\"\n+    )\n+\n+  sorted_runs = sorted(\n+      filtered_commit_runs,\n+      key=lambda w: dateutil.parser.parse(w[\"created_at\"]),\n+      reverse=True,\n+  )\n+  last_run = sorted_runs[0]\n+  last_run_id = safe_get(last_run, \"id\")\n+  print(\n+      f\"Found last run. SHA: {release_commit}, created_at: '{last_run['created_at']}', id: {last_run_id}\"\n+  )\n+  workflow_run_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=repo_url, run_id=last_run_id)\n+  print(f\"Verify at {workflow_run_web_url}\")\n+  print(\n+      f\"GCS location corresponding to artifacts built in this run: \"\n+      f\"gs://beam-wheels-staging/{release_branch}/{release_commit}-{last_run_id}/\"\n+  )\n+  return safe_get(last_run, \"id\")\n+\n+\n+def validate_run(run_id, repo_url, github_token):\n+  \"\"\"Validates workflow run. Verifies succesfull status and waits if run is not finished.\"\"\"\n+  run_data = get_single_workflow_run_data(run_id, repo_url, github_token)\n+  status = safe_get(run_data, \"status\")\n+  conclusion = safe_get(run_data, \"conclusion\")\n+\n+  if status == \"completed\" and conclusion == \"success\":\n+    return run_id\n+  elif status in [\"queued\", \"in_progress\"]:\n+    wait_for_workflow_run_to_finish(\n+        run_id, repo_url, status, conclusion, github_token)\n+  else:\n+    run_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+        repo_url=repo_url, run_id=run_id)\n+    raise Exception(\n+        f\"Run unsuccessful. Status: {status}. Conclusion: {conclusion}. Check at: {run_web_url}\"\n+    )\n+\n+\n+def wait_for_workflow_run_to_finish(\n+    run_id, repo_url, status, conclusion, github_token):\n+  \"\"\"Waits for given workflow run to finish succesfully\"\"\"\n+  run_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=repo_url, run_id=run_id)\n+  print(\n+      f\"Started waiting for Workflow run {run_id} to finish. Check on {run_web_url}\"\n+  )\n+  start_time = time.time()\n+  last_request = start_time\n+  spinner = itertools.cycle([\"|\", \"/\", \"-\", \"\\\\\"])\n+  request_interval = 10\n+\n+  while True:\n+    now = time.time()\n+    elapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(now - start_time))\n+    print(\n+        f\"\\r {next(spinner)} Waiting to finish. Elapsed time: {elapsed_time}. \"\n+        f\"Current state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        end=\"\",\n+    )\n+\n+    time.sleep(0.3)\n+    if (now - last_request) > request_interval:\n+      last_request = now\n+      run_data = get_single_workflow_run_data(run_id, repo_url, github_token)\n+      status = safe_get(run_data, \"status\")\n+      conclusion = safe_get(run_data, \"conclusion\")\n+      if status in [\"queued\", \"in_progress\"]:\n+        continue\n+      elif status == \"completed\" and conclusion == \"success\":\n+        print(\n+            f\"\\rFinished in: {elapsed_time}. \"\n+            f\"Last state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        )\n+        return run_id\n+      else:\n+        print(\"\\r\")\n+        raise Exception(\n+            f\"Run unsuccessful. Conclusion: {conclusion}. Check at: {run_web_url}\"\n+        )\n+\n+\n+def reset_directory(artifacts_dir):\n+  \"\"\"Clears directory asking for confirmation before.\"\"\"\n+  question = (\n+      f\"Creating Artifacts directory. Any existing content in {artifacts_dir} will be erased. Proceed?\\n\"\n+      f\"Your answer\")\n+  if get_yes_or_no_answer(question):\n+    print(f\"Clearing directory: {artifacts_dir}\")\n+    shutil.rmtree(artifacts_dir, ignore_errors=True)\n+    os.makedirs(artifacts_dir)\n+  else:\n+    print(\"You said NO for clearing artifacts directory. Quitting ...\")\n+    sys.exit(1)\n+\n+\n+def download_artifacts(run_id, repo_url, artifacts_dir, github_token):\n+  \"\"\"Downloads github artifacts from given run.\"\"\"\n+  print(\"Starting downloading artifacts ... (it may take a while)\")\n+  run_data = get_single_workflow_run_data(run_id, repo_url, github_token)\n+  artifacts_url = safe_get(run_data, \"artifacts_url\")\n+  data_artifacts = request_url(artifacts_url, github_token)\n+  artifacts = safe_get(data_artifacts, \"artifacts\", artifacts_url)\n+  filtered_artifacts = [\n+      a for a in artifacts if (\n+          a[\"name\"].startswith(\"source_gztar_zip\") or\n+          a[\"name\"].startswith(\"wheelhouse\"))\n+  ]\n+  for artifact in filtered_artifacts:\n+    url = safe_get(artifact, \"archive_download_url\")\n+    name = safe_get(artifact, \"name\")\n+    size_in_bytes = safe_get(artifact, \"size_in_bytes\")\n+\n+    download_single_artifact(\n+        url, name, size_in_bytes, artifacts_dir, github_token)\n+\n+\n+def download_single_artifact(\n+    url, name, size_in_bytes, artifacts_dir, github_token):\n+  \"\"\"Downloads single github artifact.\"\"\"\n+  artifacts_size_mb = round(size_in_bytes / (1024 * 1024), 2)\n+  print(\n+      f\"\\tDownloading {name}.zip artifact (size: {artifacts_size_mb} megabytes)\"\n+  )\n+\n+  with tempfile.NamedTemporaryFile(\n+    \"wb\", prefix=name, suffix=\".zip\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "468b2d41d0d1bef10489b73e64aaed5bf38ea6de"}, "originalPosition": 282}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODcwNTg1Nw==", "bodyText": "I refactored it. I made download_single_artifact and extract_single_artifact methods and updated docstring.", "url": "https://github.com/apache/beam/pull/12150#discussion_r458705857", "createdAt": "2020-07-22T10:51:41Z", "author": {"login": "TobKed"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,316 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import pprint\n+import shutil\n+import sys\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+GH_API_URL_WORKFLOW_RUNS_FMT = \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+GH_API_URL_WORKFLOW_RUN_FMT = \"https://api.github.com/repos/{repo_url}/actions/runs/{run_id}\"\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{run_id}\"\n+\n+\n+def parse_arguments():\n+  \"\"\"\n+  Gets all neccessary data from the user by parsing arguments or asking for input.\n+  Return: github_token, user_github_id, repo_url, release_branch, release_commit, artifacts_dir\n+  \"\"\"\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+  github_token = ask_for_github_token()\n+\n+  print(\"You passed following arguments:\")\n+  pprint.pprint({**vars(args), **{\"github_token\": github_token}})\n+\n+  if not get_yes_or_no_answer(\"Do you want to continue?\"):\n+    print(\"You said NO. Quitting ...\")\n+    sys.exit(1)\n+\n+  user_github_id = args.github_user\n+  repo_url = args.repo_url\n+  release_branch = args.release_branch\n+  release_commit = args.release_commit\n+  artifacts_dir = args.artifacts_dir\n+\n+  return github_token, user_github_id, repo_url, release_branch, release_commit, artifacts_dir\n+\n+\n+def ask_for_github_token():\n+  \"\"\"Ask for github token and print basic information about it.\"\"\"\n+  url = \"https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token\"\n+  message = (\n+      f\"You need to have a github access token with public_repo scope. \"\n+      f\"More info about creating access tokens can be found here {url}\")\n+  print(message)\n+  github_token = input(\"Enter github token: \")\n+  if not github_token:\n+    return ask_for_github_token()\n+  return github_token\n+\n+\n+def request_url(url, github_token, return_json=True, *args, **kwargs):\n+  \"\"\"Helper function for making requests authorized by GitHub token.\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", github_token), **kwargs)\n+  if return_json:\n+    r.raise_for_status()\n+    return r.json()\n+  return r\n+\n+\n+def safe_get(data, key, url=None):\n+  \"\"\"Looks up attribute values from a parsed JSON HTTP response.\"\"\"\n+  if key not in data:\n+    message = f'There is missing key: \"{key}\" in response data: {data}.'\n+    if url:\n+      message += f\" Requested url: {url}\"\n+    raise ValueError(message)\n+  return data.get(key)\n+\n+\n+def get_yes_or_no_answer(question):\n+  \"\"\"Asks yes or no question.\"\"\"\n+  reply = str(input(question + \" 'y' or 'n'): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  elif reply == \"n\":\n+    return False\n+  else:\n+    return get_yes_or_no_answer(\"Uhhhh... please enter\")\n+\n+\n+def get_build_wheels_workflow_id(repo_url, github_token):\n+  \"\"\"Gets the ID of the Github Actions workflow responsible for building wheels.\"\"\"\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=repo_url)\n+  data = request_url(url, github_token)\n+  return safe_get(data, \"id\", url)\n+\n+\n+def get_single_workflow_run_data(run_id, repo_url, github_token):\n+  \"\"\"Gets single workflow run data (github api payload).\"\"\"\n+  url = GH_API_URL_WORKFLOW_RUN_FMT.format(repo_url=repo_url, run_id=run_id)\n+  return request_url(url, github_token)\n+\n+\n+def get_last_run_id(\n+    workflow_id, repo_url, release_branch, release_commit, github_token):\n+  \"\"\"\n+  Gets id of last run for given workflow, repo, branch and commit.\n+  Raises exception when no run found.\n+  \"\"\"\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=repo_url, workflow_id=workflow_id)\n+  data = request_url(\n+      url,\n+      github_token,\n+      params={\n+          \"event\": \"push\", \"branch\": release_branch\n+      },\n+  )\n+  runs = safe_get(data, \"workflow_runs\", url)\n+\n+  filtered_commit_runs = [\n+      r for r in runs if r.get(\"head_sha\", \"\") == release_commit\n+  ]\n+\n+  if not filtered_commit_runs:\n+    workflow_run_web_url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+        repo_url=repo_url, workflow_id=workflow_id)\n+    raise Exception(\n+        f\"No runs for workflow (branch {release_branch}, commit {release_commit}). Verify at {workflow_run_web_url}\"\n+    )\n+\n+  sorted_runs = sorted(\n+      filtered_commit_runs,\n+      key=lambda w: dateutil.parser.parse(w[\"created_at\"]),\n+      reverse=True,\n+  )\n+  last_run = sorted_runs[0]\n+  last_run_id = safe_get(last_run, \"id\")\n+  print(\n+      f\"Found last run. SHA: {release_commit}, created_at: '{last_run['created_at']}', id: {last_run_id}\"\n+  )\n+  workflow_run_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=repo_url, run_id=last_run_id)\n+  print(f\"Verify at {workflow_run_web_url}\")\n+  print(\n+      f\"GCS location corresponding to artifacts built in this run: \"\n+      f\"gs://beam-wheels-staging/{release_branch}/{release_commit}-{last_run_id}/\"\n+  )\n+  return safe_get(last_run, \"id\")\n+\n+\n+def validate_run(run_id, repo_url, github_token):\n+  \"\"\"Validates workflow run. Verifies succesfull status and waits if run is not finished.\"\"\"\n+  run_data = get_single_workflow_run_data(run_id, repo_url, github_token)\n+  status = safe_get(run_data, \"status\")\n+  conclusion = safe_get(run_data, \"conclusion\")\n+\n+  if status == \"completed\" and conclusion == \"success\":\n+    return run_id\n+  elif status in [\"queued\", \"in_progress\"]:\n+    wait_for_workflow_run_to_finish(\n+        run_id, repo_url, status, conclusion, github_token)\n+  else:\n+    run_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+        repo_url=repo_url, run_id=run_id)\n+    raise Exception(\n+        f\"Run unsuccessful. Status: {status}. Conclusion: {conclusion}. Check at: {run_web_url}\"\n+    )\n+\n+\n+def wait_for_workflow_run_to_finish(\n+    run_id, repo_url, status, conclusion, github_token):\n+  \"\"\"Waits for given workflow run to finish succesfully\"\"\"\n+  run_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=repo_url, run_id=run_id)\n+  print(\n+      f\"Started waiting for Workflow run {run_id} to finish. Check on {run_web_url}\"\n+  )\n+  start_time = time.time()\n+  last_request = start_time\n+  spinner = itertools.cycle([\"|\", \"/\", \"-\", \"\\\\\"])\n+  request_interval = 10\n+\n+  while True:\n+    now = time.time()\n+    elapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(now - start_time))\n+    print(\n+        f\"\\r {next(spinner)} Waiting to finish. Elapsed time: {elapsed_time}. \"\n+        f\"Current state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        end=\"\",\n+    )\n+\n+    time.sleep(0.3)\n+    if (now - last_request) > request_interval:\n+      last_request = now\n+      run_data = get_single_workflow_run_data(run_id, repo_url, github_token)\n+      status = safe_get(run_data, \"status\")\n+      conclusion = safe_get(run_data, \"conclusion\")\n+      if status in [\"queued\", \"in_progress\"]:\n+        continue\n+      elif status == \"completed\" and conclusion == \"success\":\n+        print(\n+            f\"\\rFinished in: {elapsed_time}. \"\n+            f\"Last state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        )\n+        return run_id\n+      else:\n+        print(\"\\r\")\n+        raise Exception(\n+            f\"Run unsuccessful. Conclusion: {conclusion}. Check at: {run_web_url}\"\n+        )\n+\n+\n+def reset_directory(artifacts_dir):\n+  \"\"\"Clears directory asking for confirmation before.\"\"\"\n+  question = (\n+      f\"Creating Artifacts directory. Any existing content in {artifacts_dir} will be erased. Proceed?\\n\"\n+      f\"Your answer\")\n+  if get_yes_or_no_answer(question):\n+    print(f\"Clearing directory: {artifacts_dir}\")\n+    shutil.rmtree(artifacts_dir, ignore_errors=True)\n+    os.makedirs(artifacts_dir)\n+  else:\n+    print(\"You said NO for clearing artifacts directory. Quitting ...\")\n+    sys.exit(1)\n+\n+\n+def download_artifacts(run_id, repo_url, artifacts_dir, github_token):\n+  \"\"\"Downloads github artifacts from given run.\"\"\"\n+  print(\"Starting downloading artifacts ... (it may take a while)\")\n+  run_data = get_single_workflow_run_data(run_id, repo_url, github_token)\n+  artifacts_url = safe_get(run_data, \"artifacts_url\")\n+  data_artifacts = request_url(artifacts_url, github_token)\n+  artifacts = safe_get(data_artifacts, \"artifacts\", artifacts_url)\n+  filtered_artifacts = [\n+      a for a in artifacts if (\n+          a[\"name\"].startswith(\"source_gztar_zip\") or\n+          a[\"name\"].startswith(\"wheelhouse\"))\n+  ]\n+  for artifact in filtered_artifacts:\n+    url = safe_get(artifact, \"archive_download_url\")\n+    name = safe_get(artifact, \"name\")\n+    size_in_bytes = safe_get(artifact, \"size_in_bytes\")\n+\n+    download_single_artifact(\n+        url, name, size_in_bytes, artifacts_dir, github_token)\n+\n+\n+def download_single_artifact(\n+    url, name, size_in_bytes, artifacts_dir, github_token):\n+  \"\"\"Downloads single github artifact.\"\"\"\n+  artifacts_size_mb = round(size_in_bytes / (1024 * 1024), 2)\n+  print(\n+      f\"\\tDownloading {name}.zip artifact (size: {artifacts_size_mb} megabytes)\"\n+  )\n+\n+  with tempfile.NamedTemporaryFile(\n+    \"wb\", prefix=name, suffix=\".zip\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODIzODgyNA=="}, "originalCommit": {"oid": "468b2d41d0d1bef10489b73e64aaed5bf38ea6de"}, "originalPosition": 282}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg1OTU2MjUxOnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/download_github_actions_artifacts.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMVQxNjo0NTo1MVrOG1A0sA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxMDo1MjoxNFrOG1dMvQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODI0MTIwMA==", "bodyText": "We are we opening the same file for write twice?", "url": "https://github.com/apache/beam/pull/12150#discussion_r458241200", "createdAt": "2020-07-21T16:45:51Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,316 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import pprint\n+import shutil\n+import sys\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+GH_API_URL_WORKFLOW_RUNS_FMT = \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+GH_API_URL_WORKFLOW_RUN_FMT = \"https://api.github.com/repos/{repo_url}/actions/runs/{run_id}\"\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{run_id}\"\n+\n+\n+def parse_arguments():\n+  \"\"\"\n+  Gets all neccessary data from the user by parsing arguments or asking for input.\n+  Return: github_token, user_github_id, repo_url, release_branch, release_commit, artifacts_dir\n+  \"\"\"\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+  github_token = ask_for_github_token()\n+\n+  print(\"You passed following arguments:\")\n+  pprint.pprint({**vars(args), **{\"github_token\": github_token}})\n+\n+  if not get_yes_or_no_answer(\"Do you want to continue?\"):\n+    print(\"You said NO. Quitting ...\")\n+    sys.exit(1)\n+\n+  user_github_id = args.github_user\n+  repo_url = args.repo_url\n+  release_branch = args.release_branch\n+  release_commit = args.release_commit\n+  artifacts_dir = args.artifacts_dir\n+\n+  return github_token, user_github_id, repo_url, release_branch, release_commit, artifacts_dir\n+\n+\n+def ask_for_github_token():\n+  \"\"\"Ask for github token and print basic information about it.\"\"\"\n+  url = \"https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token\"\n+  message = (\n+      f\"You need to have a github access token with public_repo scope. \"\n+      f\"More info about creating access tokens can be found here {url}\")\n+  print(message)\n+  github_token = input(\"Enter github token: \")\n+  if not github_token:\n+    return ask_for_github_token()\n+  return github_token\n+\n+\n+def request_url(url, github_token, return_json=True, *args, **kwargs):\n+  \"\"\"Helper function for making requests authorized by GitHub token.\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", github_token), **kwargs)\n+  if return_json:\n+    r.raise_for_status()\n+    return r.json()\n+  return r\n+\n+\n+def safe_get(data, key, url=None):\n+  \"\"\"Looks up attribute values from a parsed JSON HTTP response.\"\"\"\n+  if key not in data:\n+    message = f'There is missing key: \"{key}\" in response data: {data}.'\n+    if url:\n+      message += f\" Requested url: {url}\"\n+    raise ValueError(message)\n+  return data.get(key)\n+\n+\n+def get_yes_or_no_answer(question):\n+  \"\"\"Asks yes or no question.\"\"\"\n+  reply = str(input(question + \" 'y' or 'n'): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  elif reply == \"n\":\n+    return False\n+  else:\n+    return get_yes_or_no_answer(\"Uhhhh... please enter\")\n+\n+\n+def get_build_wheels_workflow_id(repo_url, github_token):\n+  \"\"\"Gets the ID of the Github Actions workflow responsible for building wheels.\"\"\"\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=repo_url)\n+  data = request_url(url, github_token)\n+  return safe_get(data, \"id\", url)\n+\n+\n+def get_single_workflow_run_data(run_id, repo_url, github_token):\n+  \"\"\"Gets single workflow run data (github api payload).\"\"\"\n+  url = GH_API_URL_WORKFLOW_RUN_FMT.format(repo_url=repo_url, run_id=run_id)\n+  return request_url(url, github_token)\n+\n+\n+def get_last_run_id(\n+    workflow_id, repo_url, release_branch, release_commit, github_token):\n+  \"\"\"\n+  Gets id of last run for given workflow, repo, branch and commit.\n+  Raises exception when no run found.\n+  \"\"\"\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=repo_url, workflow_id=workflow_id)\n+  data = request_url(\n+      url,\n+      github_token,\n+      params={\n+          \"event\": \"push\", \"branch\": release_branch\n+      },\n+  )\n+  runs = safe_get(data, \"workflow_runs\", url)\n+\n+  filtered_commit_runs = [\n+      r for r in runs if r.get(\"head_sha\", \"\") == release_commit\n+  ]\n+\n+  if not filtered_commit_runs:\n+    workflow_run_web_url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+        repo_url=repo_url, workflow_id=workflow_id)\n+    raise Exception(\n+        f\"No runs for workflow (branch {release_branch}, commit {release_commit}). Verify at {workflow_run_web_url}\"\n+    )\n+\n+  sorted_runs = sorted(\n+      filtered_commit_runs,\n+      key=lambda w: dateutil.parser.parse(w[\"created_at\"]),\n+      reverse=True,\n+  )\n+  last_run = sorted_runs[0]\n+  last_run_id = safe_get(last_run, \"id\")\n+  print(\n+      f\"Found last run. SHA: {release_commit}, created_at: '{last_run['created_at']}', id: {last_run_id}\"\n+  )\n+  workflow_run_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=repo_url, run_id=last_run_id)\n+  print(f\"Verify at {workflow_run_web_url}\")\n+  print(\n+      f\"GCS location corresponding to artifacts built in this run: \"\n+      f\"gs://beam-wheels-staging/{release_branch}/{release_commit}-{last_run_id}/\"\n+  )\n+  return safe_get(last_run, \"id\")\n+\n+\n+def validate_run(run_id, repo_url, github_token):\n+  \"\"\"Validates workflow run. Verifies succesfull status and waits if run is not finished.\"\"\"\n+  run_data = get_single_workflow_run_data(run_id, repo_url, github_token)\n+  status = safe_get(run_data, \"status\")\n+  conclusion = safe_get(run_data, \"conclusion\")\n+\n+  if status == \"completed\" and conclusion == \"success\":\n+    return run_id\n+  elif status in [\"queued\", \"in_progress\"]:\n+    wait_for_workflow_run_to_finish(\n+        run_id, repo_url, status, conclusion, github_token)\n+  else:\n+    run_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+        repo_url=repo_url, run_id=run_id)\n+    raise Exception(\n+        f\"Run unsuccessful. Status: {status}. Conclusion: {conclusion}. Check at: {run_web_url}\"\n+    )\n+\n+\n+def wait_for_workflow_run_to_finish(\n+    run_id, repo_url, status, conclusion, github_token):\n+  \"\"\"Waits for given workflow run to finish succesfully\"\"\"\n+  run_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=repo_url, run_id=run_id)\n+  print(\n+      f\"Started waiting for Workflow run {run_id} to finish. Check on {run_web_url}\"\n+  )\n+  start_time = time.time()\n+  last_request = start_time\n+  spinner = itertools.cycle([\"|\", \"/\", \"-\", \"\\\\\"])\n+  request_interval = 10\n+\n+  while True:\n+    now = time.time()\n+    elapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(now - start_time))\n+    print(\n+        f\"\\r {next(spinner)} Waiting to finish. Elapsed time: {elapsed_time}. \"\n+        f\"Current state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        end=\"\",\n+    )\n+\n+    time.sleep(0.3)\n+    if (now - last_request) > request_interval:\n+      last_request = now\n+      run_data = get_single_workflow_run_data(run_id, repo_url, github_token)\n+      status = safe_get(run_data, \"status\")\n+      conclusion = safe_get(run_data, \"conclusion\")\n+      if status in [\"queued\", \"in_progress\"]:\n+        continue\n+      elif status == \"completed\" and conclusion == \"success\":\n+        print(\n+            f\"\\rFinished in: {elapsed_time}. \"\n+            f\"Last state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        )\n+        return run_id\n+      else:\n+        print(\"\\r\")\n+        raise Exception(\n+            f\"Run unsuccessful. Conclusion: {conclusion}. Check at: {run_web_url}\"\n+        )\n+\n+\n+def reset_directory(artifacts_dir):\n+  \"\"\"Clears directory asking for confirmation before.\"\"\"\n+  question = (\n+      f\"Creating Artifacts directory. Any existing content in {artifacts_dir} will be erased. Proceed?\\n\"\n+      f\"Your answer\")\n+  if get_yes_or_no_answer(question):\n+    print(f\"Clearing directory: {artifacts_dir}\")\n+    shutil.rmtree(artifacts_dir, ignore_errors=True)\n+    os.makedirs(artifacts_dir)\n+  else:\n+    print(\"You said NO for clearing artifacts directory. Quitting ...\")\n+    sys.exit(1)\n+\n+\n+def download_artifacts(run_id, repo_url, artifacts_dir, github_token):\n+  \"\"\"Downloads github artifacts from given run.\"\"\"\n+  print(\"Starting downloading artifacts ... (it may take a while)\")\n+  run_data = get_single_workflow_run_data(run_id, repo_url, github_token)\n+  artifacts_url = safe_get(run_data, \"artifacts_url\")\n+  data_artifacts = request_url(artifacts_url, github_token)\n+  artifacts = safe_get(data_artifacts, \"artifacts\", artifacts_url)\n+  filtered_artifacts = [\n+      a for a in artifacts if (\n+          a[\"name\"].startswith(\"source_gztar_zip\") or\n+          a[\"name\"].startswith(\"wheelhouse\"))\n+  ]\n+  for artifact in filtered_artifacts:\n+    url = safe_get(artifact, \"archive_download_url\")\n+    name = safe_get(artifact, \"name\")\n+    size_in_bytes = safe_get(artifact, \"size_in_bytes\")\n+\n+    download_single_artifact(\n+        url, name, size_in_bytes, artifacts_dir, github_token)\n+\n+\n+def download_single_artifact(\n+    url, name, size_in_bytes, artifacts_dir, github_token):\n+  \"\"\"Downloads single github artifact.\"\"\"\n+  artifacts_size_mb = round(size_in_bytes / (1024 * 1024), 2)\n+  print(\n+      f\"\\tDownloading {name}.zip artifact (size: {artifacts_size_mb} megabytes)\"\n+  )\n+\n+  with tempfile.NamedTemporaryFile(\n+    \"wb\", prefix=name, suffix=\".zip\"\n+  ) as f, request_url(\n+    url, github_token, return_json=False, allow_redirects=True, stream=True\n+  ) as r:\n+    with open(f.name, \"wb\") as _f:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "468b2d41d0d1bef10489b73e64aaed5bf38ea6de"}, "originalPosition": 286}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODcwNjEwOQ==", "bodyText": "I refactored slightly downloading artifacts. It should not be a problem now.", "url": "https://github.com/apache/beam/pull/12150#discussion_r458706109", "createdAt": "2020-07-22T10:52:14Z", "author": {"login": "TobKed"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,316 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import pprint\n+import shutil\n+import sys\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+GH_API_URL_WORKFLOW_RUNS_FMT = \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+GH_API_URL_WORKFLOW_RUN_FMT = \"https://api.github.com/repos/{repo_url}/actions/runs/{run_id}\"\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{run_id}\"\n+\n+\n+def parse_arguments():\n+  \"\"\"\n+  Gets all neccessary data from the user by parsing arguments or asking for input.\n+  Return: github_token, user_github_id, repo_url, release_branch, release_commit, artifacts_dir\n+  \"\"\"\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+  github_token = ask_for_github_token()\n+\n+  print(\"You passed following arguments:\")\n+  pprint.pprint({**vars(args), **{\"github_token\": github_token}})\n+\n+  if not get_yes_or_no_answer(\"Do you want to continue?\"):\n+    print(\"You said NO. Quitting ...\")\n+    sys.exit(1)\n+\n+  user_github_id = args.github_user\n+  repo_url = args.repo_url\n+  release_branch = args.release_branch\n+  release_commit = args.release_commit\n+  artifacts_dir = args.artifacts_dir\n+\n+  return github_token, user_github_id, repo_url, release_branch, release_commit, artifacts_dir\n+\n+\n+def ask_for_github_token():\n+  \"\"\"Ask for github token and print basic information about it.\"\"\"\n+  url = \"https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token\"\n+  message = (\n+      f\"You need to have a github access token with public_repo scope. \"\n+      f\"More info about creating access tokens can be found here {url}\")\n+  print(message)\n+  github_token = input(\"Enter github token: \")\n+  if not github_token:\n+    return ask_for_github_token()\n+  return github_token\n+\n+\n+def request_url(url, github_token, return_json=True, *args, **kwargs):\n+  \"\"\"Helper function for making requests authorized by GitHub token.\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", github_token), **kwargs)\n+  if return_json:\n+    r.raise_for_status()\n+    return r.json()\n+  return r\n+\n+\n+def safe_get(data, key, url=None):\n+  \"\"\"Looks up attribute values from a parsed JSON HTTP response.\"\"\"\n+  if key not in data:\n+    message = f'There is missing key: \"{key}\" in response data: {data}.'\n+    if url:\n+      message += f\" Requested url: {url}\"\n+    raise ValueError(message)\n+  return data.get(key)\n+\n+\n+def get_yes_or_no_answer(question):\n+  \"\"\"Asks yes or no question.\"\"\"\n+  reply = str(input(question + \" 'y' or 'n'): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  elif reply == \"n\":\n+    return False\n+  else:\n+    return get_yes_or_no_answer(\"Uhhhh... please enter\")\n+\n+\n+def get_build_wheels_workflow_id(repo_url, github_token):\n+  \"\"\"Gets the ID of the Github Actions workflow responsible for building wheels.\"\"\"\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=repo_url)\n+  data = request_url(url, github_token)\n+  return safe_get(data, \"id\", url)\n+\n+\n+def get_single_workflow_run_data(run_id, repo_url, github_token):\n+  \"\"\"Gets single workflow run data (github api payload).\"\"\"\n+  url = GH_API_URL_WORKFLOW_RUN_FMT.format(repo_url=repo_url, run_id=run_id)\n+  return request_url(url, github_token)\n+\n+\n+def get_last_run_id(\n+    workflow_id, repo_url, release_branch, release_commit, github_token):\n+  \"\"\"\n+  Gets id of last run for given workflow, repo, branch and commit.\n+  Raises exception when no run found.\n+  \"\"\"\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=repo_url, workflow_id=workflow_id)\n+  data = request_url(\n+      url,\n+      github_token,\n+      params={\n+          \"event\": \"push\", \"branch\": release_branch\n+      },\n+  )\n+  runs = safe_get(data, \"workflow_runs\", url)\n+\n+  filtered_commit_runs = [\n+      r for r in runs if r.get(\"head_sha\", \"\") == release_commit\n+  ]\n+\n+  if not filtered_commit_runs:\n+    workflow_run_web_url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+        repo_url=repo_url, workflow_id=workflow_id)\n+    raise Exception(\n+        f\"No runs for workflow (branch {release_branch}, commit {release_commit}). Verify at {workflow_run_web_url}\"\n+    )\n+\n+  sorted_runs = sorted(\n+      filtered_commit_runs,\n+      key=lambda w: dateutil.parser.parse(w[\"created_at\"]),\n+      reverse=True,\n+  )\n+  last_run = sorted_runs[0]\n+  last_run_id = safe_get(last_run, \"id\")\n+  print(\n+      f\"Found last run. SHA: {release_commit}, created_at: '{last_run['created_at']}', id: {last_run_id}\"\n+  )\n+  workflow_run_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=repo_url, run_id=last_run_id)\n+  print(f\"Verify at {workflow_run_web_url}\")\n+  print(\n+      f\"GCS location corresponding to artifacts built in this run: \"\n+      f\"gs://beam-wheels-staging/{release_branch}/{release_commit}-{last_run_id}/\"\n+  )\n+  return safe_get(last_run, \"id\")\n+\n+\n+def validate_run(run_id, repo_url, github_token):\n+  \"\"\"Validates workflow run. Verifies succesfull status and waits if run is not finished.\"\"\"\n+  run_data = get_single_workflow_run_data(run_id, repo_url, github_token)\n+  status = safe_get(run_data, \"status\")\n+  conclusion = safe_get(run_data, \"conclusion\")\n+\n+  if status == \"completed\" and conclusion == \"success\":\n+    return run_id\n+  elif status in [\"queued\", \"in_progress\"]:\n+    wait_for_workflow_run_to_finish(\n+        run_id, repo_url, status, conclusion, github_token)\n+  else:\n+    run_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+        repo_url=repo_url, run_id=run_id)\n+    raise Exception(\n+        f\"Run unsuccessful. Status: {status}. Conclusion: {conclusion}. Check at: {run_web_url}\"\n+    )\n+\n+\n+def wait_for_workflow_run_to_finish(\n+    run_id, repo_url, status, conclusion, github_token):\n+  \"\"\"Waits for given workflow run to finish succesfully\"\"\"\n+  run_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=repo_url, run_id=run_id)\n+  print(\n+      f\"Started waiting for Workflow run {run_id} to finish. Check on {run_web_url}\"\n+  )\n+  start_time = time.time()\n+  last_request = start_time\n+  spinner = itertools.cycle([\"|\", \"/\", \"-\", \"\\\\\"])\n+  request_interval = 10\n+\n+  while True:\n+    now = time.time()\n+    elapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(now - start_time))\n+    print(\n+        f\"\\r {next(spinner)} Waiting to finish. Elapsed time: {elapsed_time}. \"\n+        f\"Current state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        end=\"\",\n+    )\n+\n+    time.sleep(0.3)\n+    if (now - last_request) > request_interval:\n+      last_request = now\n+      run_data = get_single_workflow_run_data(run_id, repo_url, github_token)\n+      status = safe_get(run_data, \"status\")\n+      conclusion = safe_get(run_data, \"conclusion\")\n+      if status in [\"queued\", \"in_progress\"]:\n+        continue\n+      elif status == \"completed\" and conclusion == \"success\":\n+        print(\n+            f\"\\rFinished in: {elapsed_time}. \"\n+            f\"Last state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        )\n+        return run_id\n+      else:\n+        print(\"\\r\")\n+        raise Exception(\n+            f\"Run unsuccessful. Conclusion: {conclusion}. Check at: {run_web_url}\"\n+        )\n+\n+\n+def reset_directory(artifacts_dir):\n+  \"\"\"Clears directory asking for confirmation before.\"\"\"\n+  question = (\n+      f\"Creating Artifacts directory. Any existing content in {artifacts_dir} will be erased. Proceed?\\n\"\n+      f\"Your answer\")\n+  if get_yes_or_no_answer(question):\n+    print(f\"Clearing directory: {artifacts_dir}\")\n+    shutil.rmtree(artifacts_dir, ignore_errors=True)\n+    os.makedirs(artifacts_dir)\n+  else:\n+    print(\"You said NO for clearing artifacts directory. Quitting ...\")\n+    sys.exit(1)\n+\n+\n+def download_artifacts(run_id, repo_url, artifacts_dir, github_token):\n+  \"\"\"Downloads github artifacts from given run.\"\"\"\n+  print(\"Starting downloading artifacts ... (it may take a while)\")\n+  run_data = get_single_workflow_run_data(run_id, repo_url, github_token)\n+  artifacts_url = safe_get(run_data, \"artifacts_url\")\n+  data_artifacts = request_url(artifacts_url, github_token)\n+  artifacts = safe_get(data_artifacts, \"artifacts\", artifacts_url)\n+  filtered_artifacts = [\n+      a for a in artifacts if (\n+          a[\"name\"].startswith(\"source_gztar_zip\") or\n+          a[\"name\"].startswith(\"wheelhouse\"))\n+  ]\n+  for artifact in filtered_artifacts:\n+    url = safe_get(artifact, \"archive_download_url\")\n+    name = safe_get(artifact, \"name\")\n+    size_in_bytes = safe_get(artifact, \"size_in_bytes\")\n+\n+    download_single_artifact(\n+        url, name, size_in_bytes, artifacts_dir, github_token)\n+\n+\n+def download_single_artifact(\n+    url, name, size_in_bytes, artifacts_dir, github_token):\n+  \"\"\"Downloads single github artifact.\"\"\"\n+  artifacts_size_mb = round(size_in_bytes / (1024 * 1024), 2)\n+  print(\n+      f\"\\tDownloading {name}.zip artifact (size: {artifacts_size_mb} megabytes)\"\n+  )\n+\n+  with tempfile.NamedTemporaryFile(\n+    \"wb\", prefix=name, suffix=\".zip\"\n+  ) as f, request_url(\n+    url, github_token, return_json=False, allow_redirects=True, stream=True\n+  ) as r:\n+    with open(f.name, \"wb\") as _f:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODI0MTIwMA=="}, "originalCommit": {"oid": "468b2d41d0d1bef10489b73e64aaed5bf38ea6de"}, "originalPosition": 286}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2NDkwOTc1OnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/build_release_candidate.sh", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMTowNzowMlrOG10O5w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNVQxODoyNjowNVrOG3GeWQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA4MzQ5NQ==", "bodyText": "Stage python source distribution and wheels on dist.apache.org", "url": "https://github.com/apache/beam/pull/12150#discussion_r459083495", "createdAt": "2020-07-22T21:07:02Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/build_release_candidate.sh", "diffHunk": "@@ -19,7 +19,7 @@\n # This script will create a Release Candidate, includes:\n # 1. Build and stage java artifacts\n # 2. Stage source release on dist.apache.org\n-# 3. Stage python binaries\n+# 3. Stage python binaries and wheels on dist.apache.org", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "004f7401ef9cc8ea72a45415bcc974aadd2ccb0d"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDQzMDkzNw==", "bodyText": "Fixed.", "url": "https://github.com/apache/beam/pull/12150#discussion_r460430937", "createdAt": "2020-07-25T18:26:05Z", "author": {"login": "TobKed"}, "path": "release/src/main/scripts/build_release_candidate.sh", "diffHunk": "@@ -19,7 +19,7 @@\n # This script will create a Release Candidate, includes:\n # 1. Build and stage java artifacts\n # 2. Stage source release on dist.apache.org\n-# 3. Stage python binaries\n+# 3. Stage python binaries and wheels on dist.apache.org", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA4MzQ5NQ=="}, "originalCommit": {"oid": "004f7401ef9cc8ea72a45415bcc974aadd2ccb0d"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2NDkxMDk0OnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/build_release_candidate.sh", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMTowNzoyNlrOG10PqA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNVQxODoyNjo0MVrOG3GejA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA4MzY4OA==", "bodyText": "Stage python source distribution and wheels", "url": "https://github.com/apache/beam/pull/12150#discussion_r459083688", "createdAt": "2020-07-22T21:07:26Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/build_release_candidate.sh", "diffHunk": "@@ -154,41 +155,60 @@ if [[ $confirmation = \"y\" ]]; then\n   rm -rf ~/${LOCAL_JAVA_STAGING_DIR}\n fi\n \n-echo \"[Current Step]: Stage python binaries\"\n+\n+echo \"[Current Step]: Stage python binaries and wheels\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "004f7401ef9cc8ea72a45415bcc974aadd2ccb0d"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDQzMDk4OA==", "bodyText": "I put Stage python source distribution and wheels on dist.apache.org as it is in comment above", "url": "https://github.com/apache/beam/pull/12150#discussion_r460430988", "createdAt": "2020-07-25T18:26:41Z", "author": {"login": "TobKed"}, "path": "release/src/main/scripts/build_release_candidate.sh", "diffHunk": "@@ -154,41 +155,60 @@ if [[ $confirmation = \"y\" ]]; then\n   rm -rf ~/${LOCAL_JAVA_STAGING_DIR}\n fi\n \n-echo \"[Current Step]: Stage python binaries\"\n+\n+echo \"[Current Step]: Stage python binaries and wheels\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA4MzY4OA=="}, "originalCommit": {"oid": "004f7401ef9cc8ea72a45415bcc974aadd2ccb0d"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2NDkxNjM4OnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/build_release_candidate.sh", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMTowODo1NVrOG10S9Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNVQxODoxNToxN1rOG3Ga3A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA4NDUzMw==", "bodyText": "We can remove this prerequisite or move it to the very beginning of the script since it applies to prior steps  as well.", "url": "https://github.com/apache/beam/pull/12150#discussion_r459084533", "createdAt": "2020-07-22T21:08:55Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/build_release_candidate.sh", "diffHunk": "@@ -154,41 +155,60 @@ if [[ $confirmation = \"y\" ]]; then\n   rm -rf ~/${LOCAL_JAVA_STAGING_DIR}\n fi\n \n-echo \"[Current Step]: Stage python binaries\"\n+\n+echo \"[Current Step]: Stage python binaries and wheels\"\n+echo \"===============================Pre-requirements========================\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "004f7401ef9cc8ea72a45415bcc974aadd2ccb0d"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDQzMDA0NA==", "bodyText": "I moved it to the top. Let's see how it works.", "url": "https://github.com/apache/beam/pull/12150#discussion_r460430044", "createdAt": "2020-07-25T18:15:17Z", "author": {"login": "TobKed"}, "path": "release/src/main/scripts/build_release_candidate.sh", "diffHunk": "@@ -154,41 +155,60 @@ if [[ $confirmation = \"y\" ]]; then\n   rm -rf ~/${LOCAL_JAVA_STAGING_DIR}\n fi\n \n-echo \"[Current Step]: Stage python binaries\"\n+\n+echo \"[Current Step]: Stage python binaries and wheels\"\n+echo \"===============================Pre-requirements========================\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA4NDUzMw=="}, "originalCommit": {"oid": "004f7401ef9cc8ea72a45415bcc974aadd2ccb0d"}, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2NDk0MDM0OnYy", "diffSide": "RIGHT", "path": "website/www/site/content/en/contribute/release-guide.md", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMToxNjoxNFrOG10hTg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNVQxODozNjoyNlrOG3GiAA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA4ODIwNg==", "bodyText": "Also here: python source distribution and wheels.\nnit: let's fix the link to dist.apache.orG while we are at it.", "url": "https://github.com/apache/beam/pull/12150#discussion_r459088206", "createdAt": "2020-07-22T21:16:14Z", "author": {"login": "tvalentyn"}, "path": "website/www/site/content/en/contribute/release-guide.md", "diffHunk": "@@ -562,7 +562,7 @@ For this step, we recommend you using automation script to create a RC, but you\n   1. Run gradle release to create rc tag and push source release into github repo.\n   1. Run gradle publish to push java artifacts into Maven staging repo.\n   1. Stage source release into dist.apache.org dev [repo](https://dist.apache.org/repos/dist/dev/beam/).\n-  1. Stage,sign and hash python binaries into dist.apache.ord dev repo python dir\n+  1. Stage, sign and hash python binaries and wheels into dist.apache.ord dev repo python dir", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "004f7401ef9cc8ea72a45415bcc974aadd2ccb0d"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDQzMTg3Mg==", "bodyText": "Fixed.", "url": "https://github.com/apache/beam/pull/12150#discussion_r460431872", "createdAt": "2020-07-25T18:36:26Z", "author": {"login": "TobKed"}, "path": "website/www/site/content/en/contribute/release-guide.md", "diffHunk": "@@ -562,7 +562,7 @@ For this step, we recommend you using automation script to create a RC, but you\n   1. Run gradle release to create rc tag and push source release into github repo.\n   1. Run gradle publish to push java artifacts into Maven staging repo.\n   1. Stage source release into dist.apache.org dev [repo](https://dist.apache.org/repos/dist/dev/beam/).\n-  1. Stage,sign and hash python binaries into dist.apache.ord dev repo python dir\n+  1. Stage, sign and hash python binaries and wheels into dist.apache.ord dev repo python dir", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTA4ODIwNg=="}, "originalCommit": {"oid": "004f7401ef9cc8ea72a45415bcc974aadd2ccb0d"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2NTEzODg3OnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/download_github_actions_artifacts.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMjoyNzoxN1rOG12Z0A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNVQxNzo1NzozMVrOG3GVcw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTExOTA1Ng==", "bodyText": "Can we pass full path to artifacts_dir to this script, so that this directory is easier to locate from this and other log messages?", "url": "https://github.com/apache/beam/pull/12150#discussion_r459119056", "createdAt": "2020-07-22T22:27:17Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,324 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import pprint\n+import shutil\n+import sys\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+GH_API_URL_WORKFLOW_RUNS_FMT = \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+GH_API_URL_WORKFLOW_RUN_FMT = \"https://api.github.com/repos/{repo_url}/actions/runs/{run_id}\"\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{run_id}\"\n+\n+\n+def parse_arguments():\n+  \"\"\"\n+  Gets all neccessary data from the user by parsing arguments or asking for input.\n+  Return: github_token, user_github_id, repo_url, release_branch, release_commit, artifacts_dir\n+  \"\"\"\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+  github_token = ask_for_github_token()\n+\n+  print(\"You passed following arguments:\")\n+  pprint.pprint({**vars(args), **{\"github_token\": github_token}})\n+\n+  if not get_yes_or_no_answer(\"Do you want to continue?\"):\n+    print(\"You said NO. Quitting ...\")\n+    sys.exit(1)\n+\n+  user_github_id = args.github_user\n+  repo_url = args.repo_url\n+  release_branch = args.release_branch\n+  release_commit = args.release_commit\n+  artifacts_dir = args.artifacts_dir\n+\n+  return github_token, user_github_id, repo_url, release_branch, release_commit, artifacts_dir\n+\n+\n+def ask_for_github_token():\n+  \"\"\"Ask for github token and print basic information about it.\"\"\"\n+  url = \"https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token\"\n+  message = (\n+      f\"You need to have a github access token with public_repo scope. \"\n+      f\"More info about creating access tokens can be found here {url}\")\n+  print(message)\n+  github_token = input(\"Enter github token: \")\n+  if not github_token:\n+    return ask_for_github_token()\n+  return github_token\n+\n+\n+def request_url(url, github_token, return_json=True, *args, **kwargs):\n+  \"\"\"Helper function for making requests authorized by GitHub token.\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", github_token), **kwargs)\n+  if return_json:\n+    r.raise_for_status()\n+    return r.json()\n+  return r\n+\n+\n+def safe_get(data, key, url=None):\n+  \"\"\"Looks up attribute values from a parsed JSON HTTP response.\"\"\"\n+  if key not in data:\n+    message = f'There is missing key: \"{key}\" in response data: {data}.'\n+    if url:\n+      message += f\" Requested url: {url}\"\n+    raise ValueError(message)\n+  return data.get(key)\n+\n+\n+def get_yes_or_no_answer(question):\n+  \"\"\"Asks yes or no question.\"\"\"\n+  reply = str(input(question + \" 'y' or 'n'): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  elif reply == \"n\":\n+    return False\n+  else:\n+    return get_yes_or_no_answer(\"Uhhhh... please enter\")\n+\n+\n+def get_build_wheels_workflow_id(repo_url, github_token):\n+  \"\"\"Gets the ID of the Github Actions workflow responsible for building wheels.\"\"\"\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=repo_url)\n+  data = request_url(url, github_token)\n+  return safe_get(data, \"id\", url)\n+\n+\n+def get_single_workflow_run_data(run_id, repo_url, github_token):\n+  \"\"\"Gets single workflow run data (github api payload).\"\"\"\n+  url = GH_API_URL_WORKFLOW_RUN_FMT.format(repo_url=repo_url, run_id=run_id)\n+  return request_url(url, github_token)\n+\n+\n+def get_last_run_id(\n+    workflow_id, repo_url, release_branch, release_commit, github_token):\n+  \"\"\"\n+  Gets id of last run for given workflow, repo, branch and commit.\n+  Raises exception when no run found.\n+  \"\"\"\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=repo_url, workflow_id=workflow_id)\n+  data = request_url(\n+      url,\n+      github_token,\n+      params={\n+          \"event\": \"push\", \"branch\": release_branch\n+      },\n+  )\n+  runs = safe_get(data, \"workflow_runs\", url)\n+\n+  filtered_commit_runs = [\n+      r for r in runs if r.get(\"head_sha\", \"\") == release_commit\n+  ]\n+\n+  if not filtered_commit_runs:\n+    workflow_run_web_url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+        repo_url=repo_url, workflow_id=workflow_id)\n+    raise Exception(\n+        f\"No runs for workflow (branch {release_branch}, commit {release_commit}). Verify at {workflow_run_web_url}\"\n+    )\n+\n+  sorted_runs = sorted(\n+      filtered_commit_runs,\n+      key=lambda w: dateutil.parser.parse(w[\"created_at\"]),\n+      reverse=True,\n+  )\n+  last_run = sorted_runs[0]\n+  last_run_id = safe_get(last_run, \"id\")\n+  print(\n+      f\"Found last run. SHA: {release_commit}, created_at: '{last_run['created_at']}', id: {last_run_id}\"\n+  )\n+  workflow_run_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=repo_url, run_id=last_run_id)\n+  print(f\"Verify at {workflow_run_web_url}\")\n+  print(\n+      f\"GCS location corresponding to artifacts built in this run: \"\n+      f\"gs://beam-wheels-staging/{release_branch}/{release_commit}-{last_run_id}/\"\n+  )\n+  return last_run_id\n+\n+\n+def validate_run(run_id, repo_url, github_token):\n+  \"\"\"Validates workflow run. Verifies succesfull status and waits if run is not finished.\"\"\"\n+  run_data = get_single_workflow_run_data(run_id, repo_url, github_token)\n+  status = safe_get(run_data, \"status\")\n+  conclusion = safe_get(run_data, \"conclusion\")\n+\n+  if status == \"completed\" and conclusion == \"success\":\n+    return run_id\n+  elif status in [\"queued\", \"in_progress\"]:\n+    wait_for_workflow_run_to_finish(\n+        run_id, repo_url, status, conclusion, github_token)\n+  else:\n+    run_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+        repo_url=repo_url, run_id=run_id)\n+    raise Exception(\n+        f\"Run unsuccessful. Status: {status}. Conclusion: {conclusion}. Check at: {run_web_url}\"\n+    )\n+\n+\n+def wait_for_workflow_run_to_finish(\n+    run_id, repo_url, status, conclusion, github_token):\n+  \"\"\"Waits for given workflow run to finish succesfully\"\"\"\n+  run_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=repo_url, run_id=run_id)\n+  print(\n+      f\"Started waiting for Workflow run {run_id} to finish. Check on {run_web_url}\"\n+  )\n+  start_time = time.time()\n+  last_request = start_time\n+  spinner = itertools.cycle([\"|\", \"/\", \"-\", \"\\\\\"])\n+  request_interval = 10\n+\n+  while True:\n+    now = time.time()\n+    elapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(now - start_time))\n+    print(\n+        f\"\\r {next(spinner)} Waiting to finish. Elapsed time: {elapsed_time}. \"\n+        f\"Current state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        end=\"\",\n+    )\n+\n+    time.sleep(0.3)\n+    if (now - last_request) > request_interval:\n+      last_request = now\n+      run_data = get_single_workflow_run_data(run_id, repo_url, github_token)\n+      status = safe_get(run_data, \"status\")\n+      conclusion = safe_get(run_data, \"conclusion\")\n+      if status in [\"queued\", \"in_progress\"]:\n+        continue\n+      elif status == \"completed\" and conclusion == \"success\":\n+        print(\n+            f\"\\rFinished in: {elapsed_time}. \"\n+            f\"Last state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        )\n+        return run_id\n+      else:\n+        print(\"\\r\")\n+        raise Exception(\n+            f\"Run unsuccessful. Conclusion: {conclusion}. Check at: {run_web_url}\"\n+        )\n+\n+\n+def reset_directory(artifacts_dir):\n+  \"\"\"Clears directory asking for confirmation before.\"\"\"\n+  question = (\n+      f\"Creating Artifacts directory. Any existing content in {artifacts_dir} will be erased. Proceed?\\n\"\n+      f\"Your answer\")\n+  if get_yes_or_no_answer(question):\n+    print(f\"Clearing directory: {artifacts_dir}\")\n+    shutil.rmtree(artifacts_dir, ignore_errors=True)\n+    os.makedirs(artifacts_dir)\n+  else:\n+    print(\"You said NO for clearing artifacts directory. Quitting ...\")\n+    sys.exit(1)\n+\n+\n+def fetch_github_artifacts(run_id, repo_url, artifacts_dir, github_token):\n+  \"\"\"Downloads and extracts github artifacts with source dist and wheels from given run.\"\"\"\n+  print(\"Starting downloading artifacts ... (it may take a while)\")\n+  run_data = get_single_workflow_run_data(run_id, repo_url, github_token)\n+  artifacts_url = safe_get(run_data, \"artifacts_url\")\n+  data_artifacts = request_url(artifacts_url, github_token)\n+  artifacts = safe_get(data_artifacts, \"artifacts\", artifacts_url)\n+  filtered_artifacts = [\n+      a for a in artifacts if (\n+          a[\"name\"].startswith(\"source_zip\") or\n+          a[\"name\"].startswith(\"wheelhouse\"))\n+  ]\n+  for artifact in filtered_artifacts:\n+    url = safe_get(artifact, \"archive_download_url\")\n+    name = safe_get(artifact, \"name\")\n+    size_in_bytes = safe_get(artifact, \"size_in_bytes\")\n+\n+    fd, temp_file_path = tempfile.mkstemp(prefix=name, suffix=\".zip\")\n+    try:\n+      os.close(fd)\n+      download_single_artifact(\n+          url, name, size_in_bytes, temp_file_path, github_token)\n+      extract_single_artifact(temp_file_path, artifacts_dir)\n+    finally:\n+      os.remove(temp_file_path)\n+\n+\n+def download_single_artifact(\n+    url, name, size_in_bytes, target_file_path, github_token):\n+  artifacts_size_mb = round(size_in_bytes / (1024 * 1024), 2)\n+  print(\n+      f\"\\tDownloading {name}.zip artifact (size: {artifacts_size_mb} megabytes)\"\n+  )\n+\n+  with request_url(url,\n+                   github_token,\n+                   return_json=False,\n+                   allow_redirects=True,\n+                   stream=True) as r:\n+    with open(target_file_path, \"wb\") as f:\n+      shutil.copyfileobj(r.raw, f)\n+\n+\n+def extract_single_artifact(file_path, output_dir):\n+  with zipfile.ZipFile(file_path, \"r\") as zip_ref:\n+    print(f\"\\tUnzipping {len(zip_ref.filelist)} files\")\n+    zip_ref.extractall(output_dir)\n+\n+\n+if __name__ == \"__main__\":\n+  print(\n+      \"Starting script for download GitHub Actions artifacts for Build Wheels workflow\"\n+  )\n+  (\n+      github_token,\n+      user_github_id,\n+      repo_url,\n+      release_branch,\n+      release_commit,\n+      artifacts_dir,\n+  ) = parse_arguments()\n+\n+  try:\n+    workflow_id = get_build_wheels_workflow_id(repo_url, github_token)\n+    run_id = get_last_run_id(\n+        workflow_id, repo_url, release_branch, release_commit, github_token)\n+    validate_run(run_id, repo_url, github_token)\n+    reset_directory(artifacts_dir)\n+    fetch_github_artifacts(run_id, repo_url, artifacts_dir, github_token)\n+    print(\"Script finished successfully!\")\n+    print(f\"Artifacts available in directory: {artifacts_dir}\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "004f7401ef9cc8ea72a45415bcc974aadd2ccb0d"}, "originalPosition": 322}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDQyODY1OQ==", "bodyText": "Sure, I made fix for that.", "url": "https://github.com/apache/beam/pull/12150#discussion_r460428659", "createdAt": "2020-07-25T17:57:31Z", "author": {"login": "TobKed"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,324 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import pprint\n+import shutil\n+import sys\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+GH_API_URL_WORKFLOW_RUNS_FMT = \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+GH_API_URL_WORKFLOW_RUN_FMT = \"https://api.github.com/repos/{repo_url}/actions/runs/{run_id}\"\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{run_id}\"\n+\n+\n+def parse_arguments():\n+  \"\"\"\n+  Gets all neccessary data from the user by parsing arguments or asking for input.\n+  Return: github_token, user_github_id, repo_url, release_branch, release_commit, artifacts_dir\n+  \"\"\"\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+  github_token = ask_for_github_token()\n+\n+  print(\"You passed following arguments:\")\n+  pprint.pprint({**vars(args), **{\"github_token\": github_token}})\n+\n+  if not get_yes_or_no_answer(\"Do you want to continue?\"):\n+    print(\"You said NO. Quitting ...\")\n+    sys.exit(1)\n+\n+  user_github_id = args.github_user\n+  repo_url = args.repo_url\n+  release_branch = args.release_branch\n+  release_commit = args.release_commit\n+  artifacts_dir = args.artifacts_dir\n+\n+  return github_token, user_github_id, repo_url, release_branch, release_commit, artifacts_dir\n+\n+\n+def ask_for_github_token():\n+  \"\"\"Ask for github token and print basic information about it.\"\"\"\n+  url = \"https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token\"\n+  message = (\n+      f\"You need to have a github access token with public_repo scope. \"\n+      f\"More info about creating access tokens can be found here {url}\")\n+  print(message)\n+  github_token = input(\"Enter github token: \")\n+  if not github_token:\n+    return ask_for_github_token()\n+  return github_token\n+\n+\n+def request_url(url, github_token, return_json=True, *args, **kwargs):\n+  \"\"\"Helper function for making requests authorized by GitHub token.\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", github_token), **kwargs)\n+  if return_json:\n+    r.raise_for_status()\n+    return r.json()\n+  return r\n+\n+\n+def safe_get(data, key, url=None):\n+  \"\"\"Looks up attribute values from a parsed JSON HTTP response.\"\"\"\n+  if key not in data:\n+    message = f'There is missing key: \"{key}\" in response data: {data}.'\n+    if url:\n+      message += f\" Requested url: {url}\"\n+    raise ValueError(message)\n+  return data.get(key)\n+\n+\n+def get_yes_or_no_answer(question):\n+  \"\"\"Asks yes or no question.\"\"\"\n+  reply = str(input(question + \" 'y' or 'n'): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  elif reply == \"n\":\n+    return False\n+  else:\n+    return get_yes_or_no_answer(\"Uhhhh... please enter\")\n+\n+\n+def get_build_wheels_workflow_id(repo_url, github_token):\n+  \"\"\"Gets the ID of the Github Actions workflow responsible for building wheels.\"\"\"\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=repo_url)\n+  data = request_url(url, github_token)\n+  return safe_get(data, \"id\", url)\n+\n+\n+def get_single_workflow_run_data(run_id, repo_url, github_token):\n+  \"\"\"Gets single workflow run data (github api payload).\"\"\"\n+  url = GH_API_URL_WORKFLOW_RUN_FMT.format(repo_url=repo_url, run_id=run_id)\n+  return request_url(url, github_token)\n+\n+\n+def get_last_run_id(\n+    workflow_id, repo_url, release_branch, release_commit, github_token):\n+  \"\"\"\n+  Gets id of last run for given workflow, repo, branch and commit.\n+  Raises exception when no run found.\n+  \"\"\"\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=repo_url, workflow_id=workflow_id)\n+  data = request_url(\n+      url,\n+      github_token,\n+      params={\n+          \"event\": \"push\", \"branch\": release_branch\n+      },\n+  )\n+  runs = safe_get(data, \"workflow_runs\", url)\n+\n+  filtered_commit_runs = [\n+      r for r in runs if r.get(\"head_sha\", \"\") == release_commit\n+  ]\n+\n+  if not filtered_commit_runs:\n+    workflow_run_web_url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+        repo_url=repo_url, workflow_id=workflow_id)\n+    raise Exception(\n+        f\"No runs for workflow (branch {release_branch}, commit {release_commit}). Verify at {workflow_run_web_url}\"\n+    )\n+\n+  sorted_runs = sorted(\n+      filtered_commit_runs,\n+      key=lambda w: dateutil.parser.parse(w[\"created_at\"]),\n+      reverse=True,\n+  )\n+  last_run = sorted_runs[0]\n+  last_run_id = safe_get(last_run, \"id\")\n+  print(\n+      f\"Found last run. SHA: {release_commit}, created_at: '{last_run['created_at']}', id: {last_run_id}\"\n+  )\n+  workflow_run_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=repo_url, run_id=last_run_id)\n+  print(f\"Verify at {workflow_run_web_url}\")\n+  print(\n+      f\"GCS location corresponding to artifacts built in this run: \"\n+      f\"gs://beam-wheels-staging/{release_branch}/{release_commit}-{last_run_id}/\"\n+  )\n+  return last_run_id\n+\n+\n+def validate_run(run_id, repo_url, github_token):\n+  \"\"\"Validates workflow run. Verifies succesfull status and waits if run is not finished.\"\"\"\n+  run_data = get_single_workflow_run_data(run_id, repo_url, github_token)\n+  status = safe_get(run_data, \"status\")\n+  conclusion = safe_get(run_data, \"conclusion\")\n+\n+  if status == \"completed\" and conclusion == \"success\":\n+    return run_id\n+  elif status in [\"queued\", \"in_progress\"]:\n+    wait_for_workflow_run_to_finish(\n+        run_id, repo_url, status, conclusion, github_token)\n+  else:\n+    run_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+        repo_url=repo_url, run_id=run_id)\n+    raise Exception(\n+        f\"Run unsuccessful. Status: {status}. Conclusion: {conclusion}. Check at: {run_web_url}\"\n+    )\n+\n+\n+def wait_for_workflow_run_to_finish(\n+    run_id, repo_url, status, conclusion, github_token):\n+  \"\"\"Waits for given workflow run to finish succesfully\"\"\"\n+  run_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=repo_url, run_id=run_id)\n+  print(\n+      f\"Started waiting for Workflow run {run_id} to finish. Check on {run_web_url}\"\n+  )\n+  start_time = time.time()\n+  last_request = start_time\n+  spinner = itertools.cycle([\"|\", \"/\", \"-\", \"\\\\\"])\n+  request_interval = 10\n+\n+  while True:\n+    now = time.time()\n+    elapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(now - start_time))\n+    print(\n+        f\"\\r {next(spinner)} Waiting to finish. Elapsed time: {elapsed_time}. \"\n+        f\"Current state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        end=\"\",\n+    )\n+\n+    time.sleep(0.3)\n+    if (now - last_request) > request_interval:\n+      last_request = now\n+      run_data = get_single_workflow_run_data(run_id, repo_url, github_token)\n+      status = safe_get(run_data, \"status\")\n+      conclusion = safe_get(run_data, \"conclusion\")\n+      if status in [\"queued\", \"in_progress\"]:\n+        continue\n+      elif status == \"completed\" and conclusion == \"success\":\n+        print(\n+            f\"\\rFinished in: {elapsed_time}. \"\n+            f\"Last state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        )\n+        return run_id\n+      else:\n+        print(\"\\r\")\n+        raise Exception(\n+            f\"Run unsuccessful. Conclusion: {conclusion}. Check at: {run_web_url}\"\n+        )\n+\n+\n+def reset_directory(artifacts_dir):\n+  \"\"\"Clears directory asking for confirmation before.\"\"\"\n+  question = (\n+      f\"Creating Artifacts directory. Any existing content in {artifacts_dir} will be erased. Proceed?\\n\"\n+      f\"Your answer\")\n+  if get_yes_or_no_answer(question):\n+    print(f\"Clearing directory: {artifacts_dir}\")\n+    shutil.rmtree(artifacts_dir, ignore_errors=True)\n+    os.makedirs(artifacts_dir)\n+  else:\n+    print(\"You said NO for clearing artifacts directory. Quitting ...\")\n+    sys.exit(1)\n+\n+\n+def fetch_github_artifacts(run_id, repo_url, artifacts_dir, github_token):\n+  \"\"\"Downloads and extracts github artifacts with source dist and wheels from given run.\"\"\"\n+  print(\"Starting downloading artifacts ... (it may take a while)\")\n+  run_data = get_single_workflow_run_data(run_id, repo_url, github_token)\n+  artifacts_url = safe_get(run_data, \"artifacts_url\")\n+  data_artifacts = request_url(artifacts_url, github_token)\n+  artifacts = safe_get(data_artifacts, \"artifacts\", artifacts_url)\n+  filtered_artifacts = [\n+      a for a in artifacts if (\n+          a[\"name\"].startswith(\"source_zip\") or\n+          a[\"name\"].startswith(\"wheelhouse\"))\n+  ]\n+  for artifact in filtered_artifacts:\n+    url = safe_get(artifact, \"archive_download_url\")\n+    name = safe_get(artifact, \"name\")\n+    size_in_bytes = safe_get(artifact, \"size_in_bytes\")\n+\n+    fd, temp_file_path = tempfile.mkstemp(prefix=name, suffix=\".zip\")\n+    try:\n+      os.close(fd)\n+      download_single_artifact(\n+          url, name, size_in_bytes, temp_file_path, github_token)\n+      extract_single_artifact(temp_file_path, artifacts_dir)\n+    finally:\n+      os.remove(temp_file_path)\n+\n+\n+def download_single_artifact(\n+    url, name, size_in_bytes, target_file_path, github_token):\n+  artifacts_size_mb = round(size_in_bytes / (1024 * 1024), 2)\n+  print(\n+      f\"\\tDownloading {name}.zip artifact (size: {artifacts_size_mb} megabytes)\"\n+  )\n+\n+  with request_url(url,\n+                   github_token,\n+                   return_json=False,\n+                   allow_redirects=True,\n+                   stream=True) as r:\n+    with open(target_file_path, \"wb\") as f:\n+      shutil.copyfileobj(r.raw, f)\n+\n+\n+def extract_single_artifact(file_path, output_dir):\n+  with zipfile.ZipFile(file_path, \"r\") as zip_ref:\n+    print(f\"\\tUnzipping {len(zip_ref.filelist)} files\")\n+    zip_ref.extractall(output_dir)\n+\n+\n+if __name__ == \"__main__\":\n+  print(\n+      \"Starting script for download GitHub Actions artifacts for Build Wheels workflow\"\n+  )\n+  (\n+      github_token,\n+      user_github_id,\n+      repo_url,\n+      release_branch,\n+      release_commit,\n+      artifacts_dir,\n+  ) = parse_arguments()\n+\n+  try:\n+    workflow_id = get_build_wheels_workflow_id(repo_url, github_token)\n+    run_id = get_last_run_id(\n+        workflow_id, repo_url, release_branch, release_commit, github_token)\n+    validate_run(run_id, repo_url, github_token)\n+    reset_directory(artifacts_dir)\n+    fetch_github_artifacts(run_id, repo_url, artifacts_dir, github_token)\n+    print(\"Script finished successfully!\")\n+    print(f\"Artifacts available in directory: {artifacts_dir}\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTExOTA1Ng=="}, "originalCommit": {"oid": "004f7401ef9cc8ea72a45415bcc974aadd2ccb0d"}, "originalPosition": 322}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2NTE1NDYzOnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/download_github_actions_artifacts.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQyMjozNDoxMVrOG12jlQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNVQxODo1ODowNFrOG3GpOg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTEyMTU1Nw==", "bodyText": "When we execute this script from parent shell script, entire parent directory is recreated, so this check is not very useful.\nWe can remove this check or only prompt user if this directory actually exists:\nif (os.path.isdir(...)):\n  # prompt & clean\nos.makedirs(artifacts_dir)", "url": "https://github.com/apache/beam/pull/12150#discussion_r459121557", "createdAt": "2020-07-22T22:34:11Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,324 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import pprint\n+import shutil\n+import sys\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+GH_API_URL_WORKFLOW_RUNS_FMT = \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+GH_API_URL_WORKFLOW_RUN_FMT = \"https://api.github.com/repos/{repo_url}/actions/runs/{run_id}\"\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{run_id}\"\n+\n+\n+def parse_arguments():\n+  \"\"\"\n+  Gets all neccessary data from the user by parsing arguments or asking for input.\n+  Return: github_token, user_github_id, repo_url, release_branch, release_commit, artifacts_dir\n+  \"\"\"\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+  github_token = ask_for_github_token()\n+\n+  print(\"You passed following arguments:\")\n+  pprint.pprint({**vars(args), **{\"github_token\": github_token}})\n+\n+  if not get_yes_or_no_answer(\"Do you want to continue?\"):\n+    print(\"You said NO. Quitting ...\")\n+    sys.exit(1)\n+\n+  user_github_id = args.github_user\n+  repo_url = args.repo_url\n+  release_branch = args.release_branch\n+  release_commit = args.release_commit\n+  artifacts_dir = args.artifacts_dir\n+\n+  return github_token, user_github_id, repo_url, release_branch, release_commit, artifacts_dir\n+\n+\n+def ask_for_github_token():\n+  \"\"\"Ask for github token and print basic information about it.\"\"\"\n+  url = \"https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token\"\n+  message = (\n+      f\"You need to have a github access token with public_repo scope. \"\n+      f\"More info about creating access tokens can be found here {url}\")\n+  print(message)\n+  github_token = input(\"Enter github token: \")\n+  if not github_token:\n+    return ask_for_github_token()\n+  return github_token\n+\n+\n+def request_url(url, github_token, return_json=True, *args, **kwargs):\n+  \"\"\"Helper function for making requests authorized by GitHub token.\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", github_token), **kwargs)\n+  if return_json:\n+    r.raise_for_status()\n+    return r.json()\n+  return r\n+\n+\n+def safe_get(data, key, url=None):\n+  \"\"\"Looks up attribute values from a parsed JSON HTTP response.\"\"\"\n+  if key not in data:\n+    message = f'There is missing key: \"{key}\" in response data: {data}.'\n+    if url:\n+      message += f\" Requested url: {url}\"\n+    raise ValueError(message)\n+  return data.get(key)\n+\n+\n+def get_yes_or_no_answer(question):\n+  \"\"\"Asks yes or no question.\"\"\"\n+  reply = str(input(question + \" 'y' or 'n'): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  elif reply == \"n\":\n+    return False\n+  else:\n+    return get_yes_or_no_answer(\"Uhhhh... please enter\")\n+\n+\n+def get_build_wheels_workflow_id(repo_url, github_token):\n+  \"\"\"Gets the ID of the Github Actions workflow responsible for building wheels.\"\"\"\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=repo_url)\n+  data = request_url(url, github_token)\n+  return safe_get(data, \"id\", url)\n+\n+\n+def get_single_workflow_run_data(run_id, repo_url, github_token):\n+  \"\"\"Gets single workflow run data (github api payload).\"\"\"\n+  url = GH_API_URL_WORKFLOW_RUN_FMT.format(repo_url=repo_url, run_id=run_id)\n+  return request_url(url, github_token)\n+\n+\n+def get_last_run_id(\n+    workflow_id, repo_url, release_branch, release_commit, github_token):\n+  \"\"\"\n+  Gets id of last run for given workflow, repo, branch and commit.\n+  Raises exception when no run found.\n+  \"\"\"\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=repo_url, workflow_id=workflow_id)\n+  data = request_url(\n+      url,\n+      github_token,\n+      params={\n+          \"event\": \"push\", \"branch\": release_branch\n+      },\n+  )\n+  runs = safe_get(data, \"workflow_runs\", url)\n+\n+  filtered_commit_runs = [\n+      r for r in runs if r.get(\"head_sha\", \"\") == release_commit\n+  ]\n+\n+  if not filtered_commit_runs:\n+    workflow_run_web_url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+        repo_url=repo_url, workflow_id=workflow_id)\n+    raise Exception(\n+        f\"No runs for workflow (branch {release_branch}, commit {release_commit}). Verify at {workflow_run_web_url}\"\n+    )\n+\n+  sorted_runs = sorted(\n+      filtered_commit_runs,\n+      key=lambda w: dateutil.parser.parse(w[\"created_at\"]),\n+      reverse=True,\n+  )\n+  last_run = sorted_runs[0]\n+  last_run_id = safe_get(last_run, \"id\")\n+  print(\n+      f\"Found last run. SHA: {release_commit}, created_at: '{last_run['created_at']}', id: {last_run_id}\"\n+  )\n+  workflow_run_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=repo_url, run_id=last_run_id)\n+  print(f\"Verify at {workflow_run_web_url}\")\n+  print(\n+      f\"GCS location corresponding to artifacts built in this run: \"\n+      f\"gs://beam-wheels-staging/{release_branch}/{release_commit}-{last_run_id}/\"\n+  )\n+  return last_run_id\n+\n+\n+def validate_run(run_id, repo_url, github_token):\n+  \"\"\"Validates workflow run. Verifies succesfull status and waits if run is not finished.\"\"\"\n+  run_data = get_single_workflow_run_data(run_id, repo_url, github_token)\n+  status = safe_get(run_data, \"status\")\n+  conclusion = safe_get(run_data, \"conclusion\")\n+\n+  if status == \"completed\" and conclusion == \"success\":\n+    return run_id\n+  elif status in [\"queued\", \"in_progress\"]:\n+    wait_for_workflow_run_to_finish(\n+        run_id, repo_url, status, conclusion, github_token)\n+  else:\n+    run_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+        repo_url=repo_url, run_id=run_id)\n+    raise Exception(\n+        f\"Run unsuccessful. Status: {status}. Conclusion: {conclusion}. Check at: {run_web_url}\"\n+    )\n+\n+\n+def wait_for_workflow_run_to_finish(\n+    run_id, repo_url, status, conclusion, github_token):\n+  \"\"\"Waits for given workflow run to finish succesfully\"\"\"\n+  run_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=repo_url, run_id=run_id)\n+  print(\n+      f\"Started waiting for Workflow run {run_id} to finish. Check on {run_web_url}\"\n+  )\n+  start_time = time.time()\n+  last_request = start_time\n+  spinner = itertools.cycle([\"|\", \"/\", \"-\", \"\\\\\"])\n+  request_interval = 10\n+\n+  while True:\n+    now = time.time()\n+    elapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(now - start_time))\n+    print(\n+        f\"\\r {next(spinner)} Waiting to finish. Elapsed time: {elapsed_time}. \"\n+        f\"Current state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        end=\"\",\n+    )\n+\n+    time.sleep(0.3)\n+    if (now - last_request) > request_interval:\n+      last_request = now\n+      run_data = get_single_workflow_run_data(run_id, repo_url, github_token)\n+      status = safe_get(run_data, \"status\")\n+      conclusion = safe_get(run_data, \"conclusion\")\n+      if status in [\"queued\", \"in_progress\"]:\n+        continue\n+      elif status == \"completed\" and conclusion == \"success\":\n+        print(\n+            f\"\\rFinished in: {elapsed_time}. \"\n+            f\"Last state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        )\n+        return run_id\n+      else:\n+        print(\"\\r\")\n+        raise Exception(\n+            f\"Run unsuccessful. Conclusion: {conclusion}. Check at: {run_web_url}\"\n+        )\n+\n+\n+def reset_directory(artifacts_dir):\n+  \"\"\"Clears directory asking for confirmation before.\"\"\"\n+  question = (\n+      f\"Creating Artifacts directory. Any existing content in {artifacts_dir} will be erased. Proceed?\\n\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "004f7401ef9cc8ea72a45415bcc974aadd2ccb0d"}, "originalPosition": 241}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDQzMzcyMg==", "bodyText": "Nice. I refactored this function. Please take a look :)", "url": "https://github.com/apache/beam/pull/12150#discussion_r460433722", "createdAt": "2020-07-25T18:58:04Z", "author": {"login": "TobKed"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -0,0 +1,324 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\"\"\n+import argparse\n+import itertools\n+import os\n+import pprint\n+import shutil\n+import sys\n+import tempfile\n+import time\n+import zipfile\n+\n+import dateutil.parser\n+import requests\n+\n+GH_API_URL_WORKLOW_FMT = \"https://api.github.com/repos/{repo_url}/actions/workflows/build_wheels.yml\"\n+GH_API_URL_WORKFLOW_RUNS_FMT = \"https://api.github.com/repos/{repo_url}/actions/workflows/{workflow_id}/runs\"\n+GH_API_URL_WORKFLOW_RUN_FMT = \"https://api.github.com/repos/{repo_url}/actions/runs/{run_id}\"\n+GH_WEB_URL_WORKLOW_RUN_FMT = \"https://github.com/{repo_url}/actions/runs/{run_id}\"\n+\n+\n+def parse_arguments():\n+  \"\"\"\n+  Gets all neccessary data from the user by parsing arguments or asking for input.\n+  Return: github_token, user_github_id, repo_url, release_branch, release_commit, artifacts_dir\n+  \"\"\"\n+  parser = argparse.ArgumentParser(\n+      description=\n+      \"Script for downloading GitHub Actions artifacts from 'Build python wheels' workflow.\"\n+  )\n+  parser.add_argument(\"--github-user\", required=True)\n+  parser.add_argument(\"--repo-url\", required=True)\n+  parser.add_argument(\"--release-branch\", required=True)\n+  parser.add_argument(\"--release-commit\", required=True)\n+  parser.add_argument(\"--artifacts_dir\", required=True)\n+\n+  args = parser.parse_args()\n+  github_token = ask_for_github_token()\n+\n+  print(\"You passed following arguments:\")\n+  pprint.pprint({**vars(args), **{\"github_token\": github_token}})\n+\n+  if not get_yes_or_no_answer(\"Do you want to continue?\"):\n+    print(\"You said NO. Quitting ...\")\n+    sys.exit(1)\n+\n+  user_github_id = args.github_user\n+  repo_url = args.repo_url\n+  release_branch = args.release_branch\n+  release_commit = args.release_commit\n+  artifacts_dir = args.artifacts_dir\n+\n+  return github_token, user_github_id, repo_url, release_branch, release_commit, artifacts_dir\n+\n+\n+def ask_for_github_token():\n+  \"\"\"Ask for github token and print basic information about it.\"\"\"\n+  url = \"https://docs.github.com/en/github/authenticating-to-github/creating-a-personal-access-token\"\n+  message = (\n+      f\"You need to have a github access token with public_repo scope. \"\n+      f\"More info about creating access tokens can be found here {url}\")\n+  print(message)\n+  github_token = input(\"Enter github token: \")\n+  if not github_token:\n+    return ask_for_github_token()\n+  return github_token\n+\n+\n+def request_url(url, github_token, return_json=True, *args, **kwargs):\n+  \"\"\"Helper function for making requests authorized by GitHub token.\"\"\"\n+  r = requests.get(url, *args, auth=(\"token\", github_token), **kwargs)\n+  if return_json:\n+    r.raise_for_status()\n+    return r.json()\n+  return r\n+\n+\n+def safe_get(data, key, url=None):\n+  \"\"\"Looks up attribute values from a parsed JSON HTTP response.\"\"\"\n+  if key not in data:\n+    message = f'There is missing key: \"{key}\" in response data: {data}.'\n+    if url:\n+      message += f\" Requested url: {url}\"\n+    raise ValueError(message)\n+  return data.get(key)\n+\n+\n+def get_yes_or_no_answer(question):\n+  \"\"\"Asks yes or no question.\"\"\"\n+  reply = str(input(question + \" 'y' or 'n'): \")).lower().strip()\n+  if reply == \"y\":\n+    return True\n+  elif reply == \"n\":\n+    return False\n+  else:\n+    return get_yes_or_no_answer(\"Uhhhh... please enter\")\n+\n+\n+def get_build_wheels_workflow_id(repo_url, github_token):\n+  \"\"\"Gets the ID of the Github Actions workflow responsible for building wheels.\"\"\"\n+  url = GH_API_URL_WORKLOW_FMT.format(repo_url=repo_url)\n+  data = request_url(url, github_token)\n+  return safe_get(data, \"id\", url)\n+\n+\n+def get_single_workflow_run_data(run_id, repo_url, github_token):\n+  \"\"\"Gets single workflow run data (github api payload).\"\"\"\n+  url = GH_API_URL_WORKFLOW_RUN_FMT.format(repo_url=repo_url, run_id=run_id)\n+  return request_url(url, github_token)\n+\n+\n+def get_last_run_id(\n+    workflow_id, repo_url, release_branch, release_commit, github_token):\n+  \"\"\"\n+  Gets id of last run for given workflow, repo, branch and commit.\n+  Raises exception when no run found.\n+  \"\"\"\n+  url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+      repo_url=repo_url, workflow_id=workflow_id)\n+  data = request_url(\n+      url,\n+      github_token,\n+      params={\n+          \"event\": \"push\", \"branch\": release_branch\n+      },\n+  )\n+  runs = safe_get(data, \"workflow_runs\", url)\n+\n+  filtered_commit_runs = [\n+      r for r in runs if r.get(\"head_sha\", \"\") == release_commit\n+  ]\n+\n+  if not filtered_commit_runs:\n+    workflow_run_web_url = GH_API_URL_WORKFLOW_RUNS_FMT.format(\n+        repo_url=repo_url, workflow_id=workflow_id)\n+    raise Exception(\n+        f\"No runs for workflow (branch {release_branch}, commit {release_commit}). Verify at {workflow_run_web_url}\"\n+    )\n+\n+  sorted_runs = sorted(\n+      filtered_commit_runs,\n+      key=lambda w: dateutil.parser.parse(w[\"created_at\"]),\n+      reverse=True,\n+  )\n+  last_run = sorted_runs[0]\n+  last_run_id = safe_get(last_run, \"id\")\n+  print(\n+      f\"Found last run. SHA: {release_commit}, created_at: '{last_run['created_at']}', id: {last_run_id}\"\n+  )\n+  workflow_run_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=repo_url, run_id=last_run_id)\n+  print(f\"Verify at {workflow_run_web_url}\")\n+  print(\n+      f\"GCS location corresponding to artifacts built in this run: \"\n+      f\"gs://beam-wheels-staging/{release_branch}/{release_commit}-{last_run_id}/\"\n+  )\n+  return last_run_id\n+\n+\n+def validate_run(run_id, repo_url, github_token):\n+  \"\"\"Validates workflow run. Verifies succesfull status and waits if run is not finished.\"\"\"\n+  run_data = get_single_workflow_run_data(run_id, repo_url, github_token)\n+  status = safe_get(run_data, \"status\")\n+  conclusion = safe_get(run_data, \"conclusion\")\n+\n+  if status == \"completed\" and conclusion == \"success\":\n+    return run_id\n+  elif status in [\"queued\", \"in_progress\"]:\n+    wait_for_workflow_run_to_finish(\n+        run_id, repo_url, status, conclusion, github_token)\n+  else:\n+    run_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+        repo_url=repo_url, run_id=run_id)\n+    raise Exception(\n+        f\"Run unsuccessful. Status: {status}. Conclusion: {conclusion}. Check at: {run_web_url}\"\n+    )\n+\n+\n+def wait_for_workflow_run_to_finish(\n+    run_id, repo_url, status, conclusion, github_token):\n+  \"\"\"Waits for given workflow run to finish succesfully\"\"\"\n+  run_web_url = GH_WEB_URL_WORKLOW_RUN_FMT.format(\n+      repo_url=repo_url, run_id=run_id)\n+  print(\n+      f\"Started waiting for Workflow run {run_id} to finish. Check on {run_web_url}\"\n+  )\n+  start_time = time.time()\n+  last_request = start_time\n+  spinner = itertools.cycle([\"|\", \"/\", \"-\", \"\\\\\"])\n+  request_interval = 10\n+\n+  while True:\n+    now = time.time()\n+    elapsed_time = time.strftime(\"%H:%M:%S\", time.gmtime(now - start_time))\n+    print(\n+        f\"\\r {next(spinner)} Waiting to finish. Elapsed time: {elapsed_time}. \"\n+        f\"Current state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        end=\"\",\n+    )\n+\n+    time.sleep(0.3)\n+    if (now - last_request) > request_interval:\n+      last_request = now\n+      run_data = get_single_workflow_run_data(run_id, repo_url, github_token)\n+      status = safe_get(run_data, \"status\")\n+      conclusion = safe_get(run_data, \"conclusion\")\n+      if status in [\"queued\", \"in_progress\"]:\n+        continue\n+      elif status == \"completed\" and conclusion == \"success\":\n+        print(\n+            f\"\\rFinished in: {elapsed_time}. \"\n+            f\"Last state: status: `{status}`, conclusion: `{conclusion}`.\",\n+        )\n+        return run_id\n+      else:\n+        print(\"\\r\")\n+        raise Exception(\n+            f\"Run unsuccessful. Conclusion: {conclusion}. Check at: {run_web_url}\"\n+        )\n+\n+\n+def reset_directory(artifacts_dir):\n+  \"\"\"Clears directory asking for confirmation before.\"\"\"\n+  question = (\n+      f\"Creating Artifacts directory. Any existing content in {artifacts_dir} will be erased. Proceed?\\n\"", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTEyMTU1Nw=="}, "originalCommit": {"oid": "004f7401ef9cc8ea72a45415bcc974aadd2ccb0d"}, "originalPosition": 241}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2OTU3OTY1OnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/download_github_actions_artifacts.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQwMDo1NDozNlrOG2gREQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNVQxMTo1NTo1MlrOG3Ec5g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTgwNDk0NQ==", "bodyText": "Given that source_zip is now one file, will it still be wrapped in an envelope of another zip archive?", "url": "https://github.com/apache/beam/pull/12150#discussion_r459804945", "createdAt": "2020-07-24T00:54:36Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -258,7 +258,7 @@ def download_artifacts(run_id, repo_url, artifacts_dir, github_token):\n   artifacts = safe_get(data_artifacts, \"artifacts\", artifacts_url)\n   filtered_artifacts = [\n       a for a in artifacts if (\n-          a[\"name\"].startswith(\"source_gztar_zip\") or\n+          a[\"name\"].startswith(\"source_zip\") or", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6751fff67578a025892dce324e3ac98b85ecd382"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM5Nzc5OA==", "bodyText": "I checked to be 100% sure. Wrapper zip file contain zipped source dist and checkshum file as well. (preview on my local fork here)", "url": "https://github.com/apache/beam/pull/12150#discussion_r460397798", "createdAt": "2020-07-25T11:55:52Z", "author": {"login": "TobKed"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -258,7 +258,7 @@ def download_artifacts(run_id, repo_url, artifacts_dir, github_token):\n   artifacts = safe_get(data_artifacts, \"artifacts\", artifacts_url)\n   filtered_artifacts = [\n       a for a in artifacts if (\n-          a[\"name\"].startswith(\"source_gztar_zip\") or\n+          a[\"name\"].startswith(\"source_zip\") or", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTgwNDk0NQ=="}, "originalCommit": {"oid": "6751fff67578a025892dce324e3ac98b85ecd382"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2OTU4MjYwOnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/download_github_actions_artifacts.py", "isResolved": false, "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQwMDo1NjozM1rOG2gSvw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQxNjo0MTo0NFrOG7oqNA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTgwNTM3NQ==", "bodyText": "Unrelated to this PR: why are we building wheels for every push and every PR? Should we do it only for pushes to the release branch? Sorry if it was already discussed - feel free to point me to a discussion.", "url": "https://github.com/apache/beam/pull/12150#discussion_r459805375", "createdAt": "2020-07-24T00:56:33Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -170,7 +170,7 @@ def get_last_run_id(\n       f\"GCS location corresponding to artifacts built in this run: \"\n       f\"gs://beam-wheels-staging/{release_branch}/{release_commit}-{last_run_id}/\"\n   )\n-  return safe_get(last_run, \"id\")\n+  return last_run_id", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d261d3ecaa7db9eb6e990046ab1f35040a752133"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDM5Njg2MA==", "bodyText": "Here is some related discussion from previous PR which introduces gh-actions:\n#11877 (comment)\nThe idea of building source dist / wheels was that it could be a good check for python related changes on PR (path filtering). I can imagine that some change could slip in which would cause problems with building wheels later on. Check on push to master and schedule also helps to find some potential bugs.\nScheduled run on master was inspired by Apache Airflow workflow: https://github.com/apache/airflow/blob/master/.github/workflows/ci.yml#L503\nWhat do you think about this approach?", "url": "https://github.com/apache/beam/pull/12150#discussion_r460396860", "createdAt": "2020-07-25T11:44:18Z", "author": {"login": "TobKed"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -170,7 +170,7 @@ def get_last_run_id(\n       f\"GCS location corresponding to artifacts built in this run: \"\n       f\"gs://beam-wheels-staging/{release_branch}/{release_commit}-{last_run_id}/\"\n   )\n-  return safe_get(last_run, \"id\")\n+  return last_run_id", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTgwNTM3NQ=="}, "originalCommit": {"oid": "d261d3ecaa7db9eb6e990046ab1f35040a752133"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTIwNjgyMg==", "bodyText": "My concerns are mostly around quota. If actions quota is not a concern, then it's fine.\nIf it is easy to configure, i would skip \"Upload to GCS\" steps for merges to master.", "url": "https://github.com/apache/beam/pull/12150#discussion_r461206822", "createdAt": "2020-07-27T22:29:24Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -170,7 +170,7 @@ def get_last_run_id(\n       f\"GCS location corresponding to artifacts built in this run: \"\n       f\"gs://beam-wheels-staging/{release_branch}/{release_commit}-{last_run_id}/\"\n   )\n-  return safe_get(last_run, \"id\")\n+  return last_run_id", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTgwNTM3NQ=="}, "originalCommit": {"oid": "d261d3ecaa7db9eb6e990046ab1f35040a752133"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mjk1NjAzMQ==", "bodyText": "My concerns are mostly around quota. If actions quota is not a concern, then it's fine.\n\nI suppose quota for actions should not be a problem (docs). AFAIK apache has Enteprise plan.\n\nIf it is easy to configure, i would skip \"Upload to GCS\" steps for merges to master.\n\nWhy would you like to skip it?", "url": "https://github.com/apache/beam/pull/12150#discussion_r462956031", "createdAt": "2020-07-30T12:20:44Z", "author": {"login": "TobKed"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -170,7 +170,7 @@ def get_last_run_id(\n       f\"GCS location corresponding to artifacts built in this run: \"\n       f\"gs://beam-wheels-staging/{release_branch}/{release_commit}-{last_run_id}/\"\n   )\n-  return safe_get(last_run, \"id\")\n+  return last_run_id", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTgwNTM3NQ=="}, "originalCommit": {"oid": "d261d3ecaa7db9eb6e990046ab1f35040a752133"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzg4NTIyMQ==", "bodyText": "To save GCS quota, since they are created on each pushed commit.", "url": "https://github.com/apache/beam/pull/12150#discussion_r463885221", "createdAt": "2020-07-31T23:26:30Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -170,7 +170,7 @@ def get_last_run_id(\n       f\"GCS location corresponding to artifacts built in this run: \"\n       f\"gs://beam-wheels-staging/{release_branch}/{release_commit}-{last_run_id}/\"\n   )\n-  return safe_get(last_run, \"id\")\n+  return last_run_id", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTgwNTM3NQ=="}, "originalCommit": {"oid": "d261d3ecaa7db9eb6e990046ab1f35040a752133"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzg4NjE3NA==", "bodyText": "I checked the lifecycle config for the bucket with wheels, looks like we delete them after 1yr.\ngsutil lifecycle get  gs://beam-wheels-staging/\n\n{\"rule\": [{\"action\": {\"type\": \"Delete\"}, \"condition\": {\"age\": 365, \"isLive\": true}}, {\"action\": {\"type\": \"Delete\"}, \"condition\": {\"age\": 90, \"isLive\": false}}]}", "url": "https://github.com/apache/beam/pull/12150#discussion_r463886174", "createdAt": "2020-07-31T23:31:17Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -170,7 +170,7 @@ def get_last_run_id(\n       f\"GCS location corresponding to artifacts built in this run: \"\n       f\"gs://beam-wheels-staging/{release_branch}/{release_commit}-{last_run_id}/\"\n   )\n-  return safe_get(last_run, \"id\")\n+  return last_run_id", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTgwNTM3NQ=="}, "originalCommit": {"oid": "d261d3ecaa7db9eb6e990046ab1f35040a752133"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzkyMDA2NQ==", "bodyText": "I checked what is the quota for operations on GCS and it seems huge:\n\nThere is no limit to writes across multiple objects, which includes uploading, updating, and deleting objects. Buckets initially support roughly 1000 writes per second and then scale as needed.\n\nsource: https://cloud.google.com/storage/quotas#objects\nWhat do you think about this lifecycle bucket settings? I checked and size of the files on the bucket is approximately 42GB, github actions are enabled for 1 month now. Rounding this numbers up, after one year it storage occupancy will be ~600GB and remains more or less constant.", "url": "https://github.com/apache/beam/pull/12150#discussion_r463920065", "createdAt": "2020-08-01T04:25:38Z", "author": {"login": "TobKed"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -170,7 +170,7 @@ def get_last_run_id(\n       f\"GCS location corresponding to artifacts built in this run: \"\n       f\"gs://beam-wheels-staging/{release_branch}/{release_commit}-{last_run_id}/\"\n   )\n-  return safe_get(last_run, \"id\")\n+  return last_run_id", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTgwNTM3NQ=="}, "originalCommit": {"oid": "d261d3ecaa7db9eb6e990046ab1f35040a752133"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTE4NTMzMg==", "bodyText": "will probably be ok. if it's extra complexity to skip that step I wouldn't about it worry about it for now.", "url": "https://github.com/apache/beam/pull/12150#discussion_r465185332", "createdAt": "2020-08-04T16:41:44Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -170,7 +170,7 @@ def get_last_run_id(\n       f\"GCS location corresponding to artifacts built in this run: \"\n       f\"gs://beam-wheels-staging/{release_branch}/{release_commit}-{last_run_id}/\"\n   )\n-  return safe_get(last_run, \"id\")\n+  return last_run_id", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTgwNTM3NQ=="}, "originalCommit": {"oid": "d261d3ecaa7db9eb6e990046ab1f35040a752133"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2OTU5ODIwOnYy", "diffSide": "RIGHT", "path": "release/src/main/scripts/download_github_actions_artifacts.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNFQwMTowNjowNFrOG2gbZw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yNVQxNzozNDozNlrOG3GOCA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTgwNzU5MQ==", "bodyText": "This code will run on Py3 only so you can use tempfile.TemporaryDirectory() context manager:\n    with tempfile.TemporaryDirectory() as tmp:\n      temp_file_path = os.path.join(tmp, name)    # or name+'.zip'?\n      download_single_artifact(\n           url, name, size_in_bytes, temp_file_path, github_token)\n      extract_single_artifact(temp_file_path, artifacts_dir)", "url": "https://github.com/apache/beam/pull/12150#discussion_r459807591", "createdAt": "2020-07-24T01:06:04Z", "author": {"login": "tvalentyn"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -266,28 +266,36 @@ def download_artifacts(run_id, repo_url, artifacts_dir, github_token):\n     name = safe_get(artifact, \"name\")\n     size_in_bytes = safe_get(artifact, \"size_in_bytes\")\n \n-    download_single_artifact(\n-        url, name, size_in_bytes, artifacts_dir, github_token)\n+    fd, temp_file_path = tempfile.mkstemp(prefix=name, suffix=\".zip\")\n+    try:\n+      os.close(fd)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8a2aea4393226f16d2c5338f26ae5624be8353ec"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MDQyNjc2MA==", "bodyText": "Great tip. I will use TemporaryDirectory, much more nicer.", "url": "https://github.com/apache/beam/pull/12150#discussion_r460426760", "createdAt": "2020-07-25T17:34:36Z", "author": {"login": "TobKed"}, "path": "release/src/main/scripts/download_github_actions_artifacts.py", "diffHunk": "@@ -266,28 +266,36 @@ def download_artifacts(run_id, repo_url, artifacts_dir, github_token):\n     name = safe_get(artifact, \"name\")\n     size_in_bytes = safe_get(artifact, \"size_in_bytes\")\n \n-    download_single_artifact(\n-        url, name, size_in_bytes, artifacts_dir, github_token)\n+    fd, temp_file_path = tempfile.mkstemp(prefix=name, suffix=\".zip\")\n+    try:\n+      os.close(fd)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTgwNzU5MQ=="}, "originalCommit": {"oid": "8a2aea4393226f16d2c5338f26ae5624be8353ec"}, "originalPosition": 19}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3435, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}