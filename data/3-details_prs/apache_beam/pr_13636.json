{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTQ2OTc3MTQx", "number": 13636, "title": "[BEAM-11411] [BEAM-11410] Kafka to pub sub E2E test", "bodyText": "E2E test for Kafka to Pub/Sub pipeline example.\nThis test initializes Apache Kafka and Google Cloud Pub/Sub Emulator using Testcontainers Kafka and GCloud modules respectively. After that we publish a message to Kafka topic and wait for it to appear in Pub/Sub topic. If message is not received in 2 minutes test fails.\n\nThank you for your contribution! Follow this checklist to help us incorporate your contribution quickly and easily:\n\n Choose reviewer(s) and mention them in a comment (R: @username).\n Format the pull request title like [BEAM-XXX] Fixes bug in ApproximateQuantiles, where you replace BEAM-XXX with the appropriate JIRA issue, if applicable. This will automatically link the pull request to the issue.\n Update CHANGES.md with noteworthy changes.\n If this contribution is large, please file an Apache Individual Contributor License Agreement.\n\nSee the Contributor Guide for more tips on how to make review process smoother.\nPost-Commit Tests Status (on master branch)\n\n\n\nLang\nSDK\nDataflow\nFlink\nSamza\nSpark\nTwister2\n\n\n\n\nGo\n\n---\n\n---\n\n---\n\n\nJava\n\n\n\n\n\n\n\n\nPython\n\n\n\n---\n\n---\n\n\nXLang\n\n\n\n---\n\n---\n\n\n\nPre-Commit Tests Status (on master branch)\n\n\n\n---\nJava\nPython\nGo\nWebsite\nWhitespace\nTypescript\n\n\n\n\nNon-portable\n\n \n\n\n\n\n\n\nPortable\n---\n\n---\n---\n---\n---\n\n\n\nSee .test-infra/jenkins/README for trigger phrase, status and link of all Jenkins jobs.\nGitHub Actions Tests Status (on master branch)\n\n\n\nSee CI.md for more information about GitHub Actions CI.", "createdAt": "2020-12-30T14:58:59Z", "url": "https://github.com/apache/beam/pull/13636", "merged": true, "mergeCommit": {"oid": "62c304d36e30f3010ca06bf25fd19c32ba5a15bc"}, "closed": true, "closedAt": "2021-01-25T17:11:24Z", "author": {"login": "ramazan-yapparov"}, "timelineItems": {"totalCount": 27, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdqiLguAH2gAyNTQ2OTc3MTQxOmFiZGEwYWVlNzUzMGNiMzMzMGE0Mzc4M2I0NDFjMDkyM2YwMDM2Yjc=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdzZAkKgH2gAyNTQ2OTc3MTQxOjllNmFjMjA1MGQyMTdhMTMzZDgxODkyZWNiZWM2ZjdhYjhiZjNkMmQ=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "abda0aee7530cb3330a43783b441c0923f0036b7", "author": {"user": {"login": "daria-malkova", "name": "daria.malkova"}}, "url": "https://github.com/apache/beam/commit/abda0aee7530cb3330a43783b441c0923f0036b7", "committedDate": "2020-12-28T08:51:24Z", "message": "Add E2E test with kafka and pubsub emulators"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6eaca3ef5a3d733eac9f623098c8e2a057295edc", "author": {"user": {"login": "daria-malkova", "name": "daria.malkova"}}, "url": "https://github.com/apache/beam/commit/6eaca3ef5a3d733eac9f623098c8e2a057295edc", "committedDate": "2020-12-28T09:13:43Z", "message": "add dependencies"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "70109d61b6ed34a653a8645f08f67d0769a98d3f", "author": {"user": {"login": "daria-malkova", "name": "daria.malkova"}}, "url": "https://github.com/apache/beam/commit/70109d61b6ed34a653a8645f08f67d0769a98d3f", "committedDate": "2020-12-28T09:41:57Z", "message": "add more dependencies"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d03aaee379f4576121f7a81475124ecfd4019541", "author": {"user": {"login": "daria-malkova", "name": "daria.malkova"}}, "url": "https://github.com/apache/beam/commit/d03aaee379f4576121f7a81475124ecfd4019541", "committedDate": "2020-12-28T10:04:35Z", "message": "add more and more dependencies"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "baf0aaa784a9fa01bce0b96a99f712c7cad49680", "author": {"user": {"login": "ramazan-yapparov", "name": null}}, "url": "https://github.com/apache/beam/commit/baf0aaa784a9fa01bce0b96a99f712c7cad49680", "committedDate": "2020-12-28T16:28:39Z", "message": "Merge branch 'master' of https://github.com/akvelon/beam into KafkaToPubSubE2E"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3928c47430c7f7112f07faa5dd3abe4df3a42f8f", "author": {"user": {"login": "ramazan-yapparov", "name": null}}, "url": "https://github.com/apache/beam/commit/3928c47430c7f7112f07faa5dd3abe4df3a42f8f", "committedDate": "2020-12-29T12:09:10Z", "message": "- added testcontainers gcloud dependency\n- updated TestPubsubSignal to be compatible with PubSub emulator\n- KafkaToPubsubTest refactoring"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e5910831aedfa8b01046a2296fddb24580378296", "author": {"user": {"login": "ramazan-yapparov", "name": null}}, "url": "https://github.com/apache/beam/commit/e5910831aedfa8b01046a2296fddb24580378296", "committedDate": "2020-12-29T13:54:32Z", "message": "- reverted unnecessary changes\n- changed logging to throwing errors"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9cea89e7c2f6622e6f8dfe05624e0be7b7431cc9", "author": {"user": {"login": "ramazan-yapparov", "name": null}}, "url": "https://github.com/apache/beam/commit/9cea89e7c2f6622e6f8dfe05624e0be7b7431cc9", "committedDate": "2020-12-29T14:25:57Z", "message": "- moved RunKafkaContainer to utils package\n- moved E2E test to separate test class"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fd8fda7c04f75a8341c713644f8926e7d33f5016", "author": {"user": {"login": "ramazan-yapparov", "name": null}}, "url": "https://github.com/apache/beam/commit/fd8fda7c04f75a8341c713644f8926e7d33f5016", "committedDate": "2020-12-30T09:20:54Z", "message": "- reverted unnecessary changes\n- added newline at the end of file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9dcac86262329ffc02927a6001d15ac11a6870a3", "author": {"user": {"login": "ramazan-yapparov", "name": null}}, "url": "https://github.com/apache/beam/commit/9dcac86262329ffc02927a6001d15ac11a6870a3", "committedDate": "2020-12-30T15:04:47Z", "message": "- added missing license headers"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bc7b38a6753b514a6df07dc56e20e7fd4500fd8c", "author": {"user": {"login": "ramazan-yapparov", "name": null}}, "url": "https://github.com/apache/beam/commit/bc7b38a6753b514a6df07dc56e20e7fd4500fd8c", "committedDate": "2020-12-30T16:03:50Z", "message": "fixed formatting"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYwMTQ0NDIy", "url": "https://github.com/apache/beam/pull/13636#pullrequestreview-560144422", "createdAt": "2020-12-30T17:49:24Z", "commit": {"oid": "bc7b38a6753b514a6df07dc56e20e7fd4500fd8c"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0zMFQxNzo0OToyNVrOIMyLgw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0zMFQxNzo1NjoyMlrOIMyTHg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDI3NTk3MQ==", "bodyText": "You might look at using TestPubsub to create the test topic instead of creating it manually. TestPubsub also has a method that you can use to check the topic receives some expected messages, which would save you from creating the readFromPubsub transform to signal success from within the pipeline: \n  \n    \n      beam/sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsub/TestPubsub.java\n    \n    \n         Line 342\n      in\n      5e17b69\n    \n    \n    \n    \n\n        \n          \n             public PollingAssertion assertThatTopicEventuallyReceives(Matcher<PubsubMessage>... matchers) { \n        \n    \n  \n\n\nIt will be tricky to make this work with the pubsub test container though, since we'll need to start the test container before the TestPubsub Rule initializes its topic. This would be really useful infrastructure though as it would allow us to run many other pubsub tests against the fake instead of prod pubsub.", "url": "https://github.com/apache/beam/pull/13636#discussion_r550275971", "createdAt": "2020-12-30T17:49:25Z", "author": {"login": "TheNeuralBit"}, "path": "examples/java/src/test/java/org/apache/beam/examples/complete/kafkatopubsub/KafkaToPubsubE2ETest.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.examples.complete.kafkatopubsub;\n+\n+import static org.apache.beam.examples.complete.kafkatopubsub.transforms.FormatTransform.readFromKafka;\n+\n+import com.google.auth.Credentials;\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.function.Supplier;\n+import org.apache.beam.examples.complete.kafkatopubsub.utils.RunKafkaContainer;\n+import org.apache.beam.runners.direct.DirectOptions;\n+import org.apache.beam.sdk.PipelineResult;\n+import org.apache.beam.sdk.extensions.gcp.auth.NoopCredentialFactory;\n+import org.apache.beam.sdk.extensions.gcp.options.GcpOptions;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubClient;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubIO;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubJsonClient;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubOptions;\n+import org.apache.beam.sdk.io.gcp.pubsub.TestPubsubSignal;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.testing.TestPipeline;\n+import org.apache.beam.sdk.transforms.Values;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.joda.time.Duration;\n+import org.junit.BeforeClass;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.testcontainers.containers.PubSubEmulatorContainer;\n+import org.testcontainers.utility.DockerImageName;\n+\n+/** E2E test for {@link KafkaToPubsub} pipeline. */\n+public class KafkaToPubsubE2ETest {\n+\n+  @Rule public final transient TestPipeline pipeline = TestPipeline.fromOptions(OPTIONS);\n+  @Rule public transient TestPubsubSignal signal = TestPubsubSignal.fromOptions(OPTIONS);\n+\n+  private static final String PUBSUB_EMULATOR_IMAGE =\n+      \"gcr.io/google.com/cloudsdktool/cloud-sdk:316.0.0-emulators\";\n+  private static final String PUBSUB_MESSAGE = \"test pubsub message\";\n+  private static final String PROJECT_ID = \"try-kafka-pubsub\";\n+  private static final String TOPIC_NAME = \"listen-to-kafka\";\n+  private static final PubsubClient.TopicPath TOPIC_PATH =\n+      PubsubClient.topicPathFromName(PROJECT_ID, TOPIC_NAME);\n+  private static final PipelineOptions OPTIONS = TestPipeline.testingPipelineOptions();\n+\n+  @BeforeClass\n+  public static void beforeClass() throws Exception {\n+    Credentials credentials = NoopCredentialFactory.fromOptions(OPTIONS).getCredential();\n+    OPTIONS.as(GcpOptions.class).setGcpCredential(credentials);\n+    OPTIONS.as(GcpOptions.class).setProject(PROJECT_ID);\n+    setupPubsubContainer(OPTIONS.as(PubsubOptions.class));\n+    createPubsubTopicForTest(OPTIONS.as(PubsubOptions.class));\n+  }\n+\n+  @Test\n+  public void testKafkaToPubsubE2E() throws IOException {\n+    pipeline.getOptions().as(DirectOptions.class).setBlockOnRun(false);\n+\n+    RunKafkaContainer rkc = new RunKafkaContainer(PUBSUB_MESSAGE);\n+    String bootstrapServer = rkc.getBootstrapServer();\n+    String[] kafkaTopicsList = new String[] {rkc.getTopicName()};\n+\n+    String pubsubTopicPath = TOPIC_PATH.getPath();\n+\n+    Map<String, Object> kafkaConfig = new HashMap<>();\n+    Map<String, String> sslConfig = new HashMap<>();\n+\n+    PCollection<KV<String, String>> readStrings =\n+        pipeline.apply(\n+            \"readFromKafka\",\n+            readFromKafka(bootstrapServer, Arrays.asList(kafkaTopicsList), kafkaConfig, sslConfig));\n+\n+    PCollection<String> readFromPubsub =\n+        readStrings\n+            .apply(Values.create())\n+            .apply(\"writeToPubSub\", PubsubIO.writeStrings().to(pubsubTopicPath))\n+            .getPipeline()\n+            .apply(\"readFromPubsub\", PubsubIO.readStrings().fromTopic(pubsubTopicPath));\n+\n+    readFromPubsub.apply(\n+        \"waitForTestMessage\",\n+        signal.signalSuccessWhen(\n+            readFromPubsub.getCoder(),\n+            input -> {\n+              if (input == null) {\n+                return false;\n+              }\n+              return input.stream().anyMatch(message -> Objects.equals(message, PUBSUB_MESSAGE));\n+            }));\n+\n+    Supplier<Void> start = signal.waitForStart(Duration.standardSeconds(10));\n+    pipeline.apply(signal.signalStart());\n+    PipelineResult job = pipeline.run();\n+    start.get();\n+    signal.waitForSuccess(Duration.standardMinutes(2));\n+    try {\n+      job.cancel();\n+    } catch (IOException | UnsupportedOperationException e) {\n+      throw new AssertionError(\"Could not stop pipeline.\", e);\n+    }\n+  }\n+\n+  private static void setupPubsubContainer(PubsubOptions options) {\n+    PubSubEmulatorContainer emulator =\n+        new PubSubEmulatorContainer(DockerImageName.parse(PUBSUB_EMULATOR_IMAGE));\n+    emulator.start();\n+    String pubsubUrl = emulator.getEmulatorEndpoint();\n+    options.setPubsubRootUrl(\"http://\" + pubsubUrl);\n+  }\n+\n+  private static void createPubsubTopicForTest(PubsubOptions options) {\n+    try {\n+      PubsubClient pubsubClient = PubsubJsonClient.FACTORY.newClient(null, null, options);\n+      pubsubClient.createTopic(TOPIC_PATH);\n+    } catch (Exception e) {\n+      throw new RuntimeException(e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc7b38a6753b514a6df07dc56e20e7fd4500fd8c"}, "originalPosition": 136}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDI3NzgzMA==", "bodyText": "Could you instead inject the data in the test after the pipeline has started?", "url": "https://github.com/apache/beam/pull/13636#discussion_r550277830", "createdAt": "2020-12-30T17:56:06Z", "author": {"login": "TheNeuralBit"}, "path": "examples/java/src/test/java/org/apache/beam/examples/complete/kafkatopubsub/utils/RunKafkaContainer.java", "diffHunk": "@@ -0,0 +1,81 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.examples.complete.kafkatopubsub.utils;\n+\n+import java.util.UUID;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.ScheduledFuture;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+import org.apache.kafka.clients.producer.KafkaProducer;\n+import org.apache.kafka.clients.producer.ProducerConfig;\n+import org.apache.kafka.clients.producer.ProducerRecord;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.testcontainers.containers.KafkaContainer;\n+import org.testcontainers.utility.DockerImageName;\n+\n+/** Run kafka container in separate thread to produce message. */\n+public class RunKafkaContainer {\n+\n+  private static final String KAFKA_IMAGE_NAME = \"confluentinc/cp-kafka:5.4.3\";\n+  private final String topicName;\n+  private final KafkaProducer<String, String> producer;\n+  private final String bootstrapServer;\n+\n+  public RunKafkaContainer(String pubsubMessage) {\n+    bootstrapServer = setupKafkaContainer();\n+    topicName = \"messages-topic\";\n+    producer =\n+        new KafkaProducer<>(\n+            ImmutableMap.of(\n+                ProducerConfig.BOOTSTRAP_SERVERS_CONFIG,\n+                bootstrapServer,\n+                ProducerConfig.CLIENT_ID_CONFIG,\n+                UUID.randomUUID().toString()),\n+            new StringSerializer(),\n+            new StringSerializer());\n+    Runnable kafkaProducer =\n+        () -> {\n+          try {\n+            producer.send(new ProducerRecord<>(topicName, \"testcontainers\", pubsubMessage)).get();\n+            System.out.println(\"Producer sent\");\n+          } catch (ExecutionException | InterruptedException e) {\n+            throw new RuntimeException(\"Something went wrong in kafka producer\", e);\n+          }\n+        };\n+    // Without saving `.schedule(...)` result to variable checkframework will fail\n+    @SuppressWarnings(\"unused\")\n+    ScheduledFuture<?> schedule =\n+        Executors.newSingleThreadScheduledExecutor().schedule(kafkaProducer, 10, TimeUnit.SECONDS);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc7b38a6753b514a6df07dc56e20e7fd4500fd8c"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MDI3NzkxOA==", "bodyText": "It would be preferable to run the exact KafkaToPubsub pipeline, then use utilities outside of the pipeline to inject data to the kafka topic, and then to verify the pubsub topic receives the expected messages. As noted in my other comment TestPubsub can help with the latter.", "url": "https://github.com/apache/beam/pull/13636#discussion_r550277918", "createdAt": "2020-12-30T17:56:22Z", "author": {"login": "TheNeuralBit"}, "path": "examples/java/src/test/java/org/apache/beam/examples/complete/kafkatopubsub/KafkaToPubsubE2ETest.java", "diffHunk": "@@ -0,0 +1,139 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.examples.complete.kafkatopubsub;\n+\n+import static org.apache.beam.examples.complete.kafkatopubsub.transforms.FormatTransform.readFromKafka;\n+\n+import com.google.auth.Credentials;\n+import java.io.IOException;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.Map;\n+import java.util.Objects;\n+import java.util.function.Supplier;\n+import org.apache.beam.examples.complete.kafkatopubsub.utils.RunKafkaContainer;\n+import org.apache.beam.runners.direct.DirectOptions;\n+import org.apache.beam.sdk.PipelineResult;\n+import org.apache.beam.sdk.extensions.gcp.auth.NoopCredentialFactory;\n+import org.apache.beam.sdk.extensions.gcp.options.GcpOptions;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubClient;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubIO;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubJsonClient;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubOptions;\n+import org.apache.beam.sdk.io.gcp.pubsub.TestPubsubSignal;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.testing.TestPipeline;\n+import org.apache.beam.sdk.transforms.Values;\n+import org.apache.beam.sdk.values.KV;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.joda.time.Duration;\n+import org.junit.BeforeClass;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.testcontainers.containers.PubSubEmulatorContainer;\n+import org.testcontainers.utility.DockerImageName;\n+\n+/** E2E test for {@link KafkaToPubsub} pipeline. */\n+public class KafkaToPubsubE2ETest {\n+\n+  @Rule public final transient TestPipeline pipeline = TestPipeline.fromOptions(OPTIONS);\n+  @Rule public transient TestPubsubSignal signal = TestPubsubSignal.fromOptions(OPTIONS);\n+\n+  private static final String PUBSUB_EMULATOR_IMAGE =\n+      \"gcr.io/google.com/cloudsdktool/cloud-sdk:316.0.0-emulators\";\n+  private static final String PUBSUB_MESSAGE = \"test pubsub message\";\n+  private static final String PROJECT_ID = \"try-kafka-pubsub\";\n+  private static final String TOPIC_NAME = \"listen-to-kafka\";\n+  private static final PubsubClient.TopicPath TOPIC_PATH =\n+      PubsubClient.topicPathFromName(PROJECT_ID, TOPIC_NAME);\n+  private static final PipelineOptions OPTIONS = TestPipeline.testingPipelineOptions();\n+\n+  @BeforeClass\n+  public static void beforeClass() throws Exception {\n+    Credentials credentials = NoopCredentialFactory.fromOptions(OPTIONS).getCredential();\n+    OPTIONS.as(GcpOptions.class).setGcpCredential(credentials);\n+    OPTIONS.as(GcpOptions.class).setProject(PROJECT_ID);\n+    setupPubsubContainer(OPTIONS.as(PubsubOptions.class));\n+    createPubsubTopicForTest(OPTIONS.as(PubsubOptions.class));\n+  }\n+\n+  @Test\n+  public void testKafkaToPubsubE2E() throws IOException {\n+    pipeline.getOptions().as(DirectOptions.class).setBlockOnRun(false);\n+\n+    RunKafkaContainer rkc = new RunKafkaContainer(PUBSUB_MESSAGE);\n+    String bootstrapServer = rkc.getBootstrapServer();\n+    String[] kafkaTopicsList = new String[] {rkc.getTopicName()};\n+\n+    String pubsubTopicPath = TOPIC_PATH.getPath();\n+\n+    Map<String, Object> kafkaConfig = new HashMap<>();\n+    Map<String, String> sslConfig = new HashMap<>();\n+\n+    PCollection<KV<String, String>> readStrings =\n+        pipeline.apply(\n+            \"readFromKafka\",\n+            readFromKafka(bootstrapServer, Arrays.asList(kafkaTopicsList), kafkaConfig, sslConfig));\n+\n+    PCollection<String> readFromPubsub =\n+        readStrings\n+            .apply(Values.create())\n+            .apply(\"writeToPubSub\", PubsubIO.writeStrings().to(pubsubTopicPath))\n+            .getPipeline()\n+            .apply(\"readFromPubsub\", PubsubIO.readStrings().fromTopic(pubsubTopicPath));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bc7b38a6753b514a6df07dc56e20e7fd4500fd8c"}, "originalPosition": 98}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4cf50bfcf103cf5b33360fce0dce280eb431bcf7", "author": {"user": {"login": "ramazan-yapparov", "name": null}}, "url": "https://github.com/apache/beam/commit/4cf50bfcf103cf5b33360fce0dce280eb431bcf7", "committedDate": "2021-01-12T12:26:24Z", "message": "Moved from using TestPubsubSignal to using TestPubsub"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7798b354105d6f7793d1d99c638bb365c10641ae", "author": {"user": {"login": "ramazan-yapparov", "name": null}}, "url": "https://github.com/apache/beam/commit/7798b354105d6f7793d1d99c638bb365c10641ae", "committedDate": "2021-01-12T14:25:26Z", "message": "- changed manual containers execution to using @ClassRule\n- removed RunKafkaContainer class completely\n- sending kafka message directly in test instead of using a scheduler"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ccb082e1d29b0266dabf7de3bac41880b44e852d", "author": {"user": {"login": "ramazan-yapparov", "name": null}}, "url": "https://github.com/apache/beam/commit/ccb082e1d29b0266dabf7de3bac41880b44e852d", "committedDate": "2021-01-13T10:33:20Z", "message": "- updates test so it now runs actual pipeline instead of building it manually\n- added new property to KafkaToPubsubOptions for kafka consumer configuration"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dea9b6f4d476c9ddeffb37f63fa1245bef3e0299", "author": {"user": {"login": "ramazan-yapparov", "name": null}}, "url": "https://github.com/apache/beam/commit/dea9b6f4d476c9ddeffb37f63fa1245bef3e0299", "committedDate": "2021-01-13T10:35:34Z", "message": "Merge branch 'master' of github.com:akvelon/beam into KafkaToPubSubE2E"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c66262f8871b2fa105edc27862eff1e84c5cf547", "author": {"user": {"login": "ramazan-yapparov", "name": null}}, "url": "https://github.com/apache/beam/commit/c66262f8871b2fa105edc27862eff1e84c5cf547", "committedDate": "2021-01-13T12:21:07Z", "message": "- increased message waiting duration to 1 minute\n- reverted unnecessary change in TestPubsubSignal\n- minor fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "579c00e1dd116258569be3d091d883eb5fdc19c9", "author": {"user": {"login": "ramazan-yapparov", "name": null}}, "url": "https://github.com/apache/beam/commit/579c00e1dd116258569be3d091d883eb5fdc19c9", "committedDate": "2021-01-13T13:19:08Z", "message": "Fixed formatting issues"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "00208863d8ad96f082856cfe034a2f3052fb524c", "author": {"user": {"login": "ramazan-yapparov", "name": null}}, "url": "https://github.com/apache/beam/commit/00208863d8ad96f082856cfe034a2f3052fb524c", "committedDate": "2021-01-13T13:36:38Z", "message": "Fixed styling issue"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY3NzUyMjc1", "url": "https://github.com/apache/beam/pull/13636#pullrequestreview-567752275", "createdAt": "2021-01-13T23:54:51Z", "commit": {"oid": "00208863d8ad96f082856cfe034a2f3052fb524c"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xM1QyMzo1NDo1MlrOITJxxQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xM1QyMzo1OToyM1rOITJ4LA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Njk1NDA1Mw==", "bodyText": "Could you rename this to KafkaToPubsubIT? Our build files assume *Test is a unit test and *IT is an integration test.", "url": "https://github.com/apache/beam/pull/13636#discussion_r556954053", "createdAt": "2021-01-13T23:54:52Z", "author": {"login": "TheNeuralBit"}, "path": "examples/java/src/test/java/org/apache/beam/examples/complete/kafkatopubsub/KafkaToPubsubE2ETest.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.examples.complete.kafkatopubsub;\n+\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.hasProperty;\n+\n+import com.google.auth.Credentials;\n+import java.nio.charset.StandardCharsets;\n+import java.util.UUID;\n+import java.util.concurrent.ExecutionException;\n+import org.apache.beam.examples.complete.kafkatopubsub.options.KafkaToPubsubOptions;\n+import org.apache.beam.examples.complete.kafkatopubsub.transforms.FormatTransform.FORMAT;\n+import org.apache.beam.runners.direct.DirectOptions;\n+import org.apache.beam.sdk.PipelineResult;\n+import org.apache.beam.sdk.extensions.gcp.auth.NoopCredentialFactory;\n+import org.apache.beam.sdk.extensions.gcp.options.GcpOptions;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubOptions;\n+import org.apache.beam.sdk.io.gcp.pubsub.TestPubsub;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.testing.TestPipeline;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.producer.KafkaProducer;\n+import org.apache.kafka.clients.producer.ProducerConfig;\n+import org.apache.kafka.clients.producer.ProducerRecord;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.joda.time.Duration;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.testcontainers.containers.KafkaContainer;\n+import org.testcontainers.containers.PubSubEmulatorContainer;\n+import org.testcontainers.utility.DockerImageName;\n+\n+/** E2E test for {@link KafkaToPubsub} pipeline. */\n+public class KafkaToPubsubE2ETest {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "00208863d8ad96f082856cfe034a2f3052fb524c"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Njk1NTMxMQ==", "bodyText": "We have a precommit check that should run this example on Dataflow. It looks like this test isn't run there now, but that's likely because the name is Test and not IT.\nWhen you rename the test and this runs on Dataflow, this timeout won't be long enough, since Dataflow takes several minutes to start up workers. You should bump it up to 10 minutes probably.", "url": "https://github.com/apache/beam/pull/13636#discussion_r556955311", "createdAt": "2021-01-13T23:58:15Z", "author": {"login": "TheNeuralBit"}, "path": "examples/java/src/test/java/org/apache/beam/examples/complete/kafkatopubsub/KafkaToPubsubE2ETest.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.examples.complete.kafkatopubsub;\n+\n+import static org.hamcrest.Matchers.equalTo;\n+import static org.hamcrest.Matchers.hasProperty;\n+\n+import com.google.auth.Credentials;\n+import java.nio.charset.StandardCharsets;\n+import java.util.UUID;\n+import java.util.concurrent.ExecutionException;\n+import org.apache.beam.examples.complete.kafkatopubsub.options.KafkaToPubsubOptions;\n+import org.apache.beam.examples.complete.kafkatopubsub.transforms.FormatTransform.FORMAT;\n+import org.apache.beam.runners.direct.DirectOptions;\n+import org.apache.beam.sdk.PipelineResult;\n+import org.apache.beam.sdk.extensions.gcp.auth.NoopCredentialFactory;\n+import org.apache.beam.sdk.extensions.gcp.options.GcpOptions;\n+import org.apache.beam.sdk.io.gcp.pubsub.PubsubOptions;\n+import org.apache.beam.sdk.io.gcp.pubsub.TestPubsub;\n+import org.apache.beam.sdk.options.PipelineOptions;\n+import org.apache.beam.sdk.testing.TestPipeline;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+import org.apache.kafka.clients.consumer.ConsumerConfig;\n+import org.apache.kafka.clients.producer.KafkaProducer;\n+import org.apache.kafka.clients.producer.ProducerConfig;\n+import org.apache.kafka.clients.producer.ProducerRecord;\n+import org.apache.kafka.common.serialization.StringSerializer;\n+import org.joda.time.Duration;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.ClassRule;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.testcontainers.containers.KafkaContainer;\n+import org.testcontainers.containers.PubSubEmulatorContainer;\n+import org.testcontainers.utility.DockerImageName;\n+\n+/** E2E test for {@link KafkaToPubsub} pipeline. */\n+public class KafkaToPubsubE2ETest {\n+  private static final String PUBSUB_EMULATOR_IMAGE =\n+      \"gcr.io/google.com/cloudsdktool/cloud-sdk:316.0.0-emulators\";\n+  private static final String KAFKA_IMAGE_NAME = \"confluentinc/cp-kafka:5.4.3\";\n+  private static final String PUBSUB_MESSAGE = \"test pubsub message\";\n+  private static final String KAFKA_TOPIC_NAME = \"messages-topic\";\n+  private static final String PROJECT_ID = \"try-kafka-pubsub\";\n+  private static final PipelineOptions OPTIONS = TestPipeline.testingPipelineOptions();\n+\n+  @ClassRule\n+  public static final PubSubEmulatorContainer PUB_SUB_EMULATOR_CONTAINER =\n+      new PubSubEmulatorContainer(DockerImageName.parse(PUBSUB_EMULATOR_IMAGE));\n+\n+  @ClassRule\n+  public static final KafkaContainer KAFKA_CONTAINER =\n+      new KafkaContainer(DockerImageName.parse(KAFKA_IMAGE_NAME));\n+\n+  @Rule public final transient TestPipeline pipeline = TestPipeline.fromOptions(OPTIONS);\n+  @Rule public final transient TestPubsub testPubsub = TestPubsub.fromOptions(OPTIONS);\n+\n+  @BeforeClass\n+  public static void beforeClass() throws Exception {\n+    Credentials credentials = NoopCredentialFactory.fromOptions(OPTIONS).getCredential();\n+    OPTIONS.as(DirectOptions.class).setBlockOnRun(false);\n+    OPTIONS.as(GcpOptions.class).setGcpCredential(credentials);\n+    OPTIONS.as(GcpOptions.class).setProject(PROJECT_ID);\n+    OPTIONS\n+        .as(PubsubOptions.class)\n+        .setPubsubRootUrl(\"http://\" + PUB_SUB_EMULATOR_CONTAINER.getEmulatorEndpoint());\n+    OPTIONS.as(KafkaToPubsubOptions.class).setOutputFormat(FORMAT.PUBSUB);\n+    OPTIONS\n+        .as(KafkaToPubsubOptions.class)\n+        .setBootstrapServers(KAFKA_CONTAINER.getBootstrapServers());\n+    OPTIONS.as(KafkaToPubsubOptions.class).setInputTopics(KAFKA_TOPIC_NAME);\n+    OPTIONS\n+        .as(KafkaToPubsubOptions.class)\n+        .setKafkaConsumerConfig(ConsumerConfig.AUTO_OFFSET_RESET_CONFIG + \"=earliest\");\n+  }\n+\n+  @Before\n+  public void setUp() {\n+    OPTIONS.as(KafkaToPubsubOptions.class).setOutputTopic(testPubsub.topicPath().getPath());\n+  }\n+\n+  @Test\n+  public void testKafkaToPubsubE2E() throws Exception {\n+    PipelineResult job = KafkaToPubsub.run(pipeline, OPTIONS.as(KafkaToPubsubOptions.class));\n+\n+    sendKafkaMessage();\n+    testPubsub\n+        .assertThatTopicEventuallyReceives(\n+            hasProperty(\"payload\", equalTo(PUBSUB_MESSAGE.getBytes(StandardCharsets.UTF_8))))\n+        .waitForUpTo(Duration.standardMinutes(1));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "00208863d8ad96f082856cfe034a2f3052fb524c"}, "originalPosition": 106}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Njk1NTY5Mg==", "bodyText": "Can we do without this?", "url": "https://github.com/apache/beam/pull/13636#discussion_r556955692", "createdAt": "2021-01-13T23:59:23Z", "author": {"login": "TheNeuralBit"}, "path": "examples/java/build.gradle", "diffHunk": "@@ -56,6 +56,7 @@ dependencies {\n   compile library.java.vendored_guava_26_0_jre\n   compile library.java.kafka_clients\n   compile project(path: \":sdks:java:core\", configuration: \"shadow\")\n+  compile project(path: \":runners:direct-java\", configuration: \"shadow\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "00208863d8ad96f082856cfe034a2f3052fb524c"}, "originalPosition": 4}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f68fd02d0f50acbb1425cfeb4618f4438d47f350", "author": {"user": {"login": "ramazan-yapparov", "name": null}}, "url": "https://github.com/apache/beam/commit/f68fd02d0f50acbb1425cfeb4618f4438d47f350", "committedDate": "2021-01-14T11:50:03Z", "message": "Merge branch 'master' of github.com:apache/beam into KafkaToPubSubE2E"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "46f44c96e545900289af0309fa238442d4e57d4b", "author": {"user": {"login": "ramazan-yapparov", "name": null}}, "url": "https://github.com/apache/beam/commit/46f44c96e545900289af0309fa238442d4e57d4b", "committedDate": "2021-01-14T12:56:47Z", "message": "Intentionally broke the test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "24ddb6e9eee92445696aa162abe3aa5daaafdeb8", "author": {"user": {"login": "ramazan-yapparov", "name": null}}, "url": "https://github.com/apache/beam/commit/24ddb6e9eee92445696aa162abe3aa5daaafdeb8", "committedDate": "2021-01-14T13:39:31Z", "message": "Fixed broken test"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTczODMxMzc0", "url": "https://github.com/apache/beam/pull/13636#pullrequestreview-573831374", "createdAt": "2021-01-21T23:55:26Z", "commit": {"oid": "24ddb6e9eee92445696aa162abe3aa5daaafdeb8"}, "state": "APPROVED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQyMzo1NToyN1rOIYOgqg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMVQyMzo1NzowOVrOIYOi5A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjI3NDQ3NA==", "bodyText": "nit: If I were writing this I would probably combine these two lines and avoid creating the Pair:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    .map(kv -> Pair.of(kv[0], kv[1]))\n          \n          \n            \n                    .collect(Collectors.toMap(Pair::getKey, Pair::getValue));\n          \n          \n            \n                    .collect(Collectors.toMap(kv -> kv[0], kv -> kv[1]));\n          \n      \n    \n    \n  \n\nIf you prefer it with the Pair that's fine too.\nOne thing I think we should change is make this a private static method in KafkaToPubsub, since it's only used there.", "url": "https://github.com/apache/beam/pull/13636#discussion_r562274474", "createdAt": "2021-01-21T23:55:27Z", "author": {"login": "TheNeuralBit"}, "path": "examples/java/src/main/java/org/apache/beam/examples/complete/kafkatopubsub/kafka/consumer/Utils.java", "diffHunk": "@@ -162,4 +165,11 @@ public static boolean isSslSpecified(KafkaToPubsubOptions options) {\n         || options.getKeystorePath() != null\n         || options.getKeyPassword() != null;\n   }\n+\n+  public static Map<String, Object> parseKafkaConsumerConfig(String kafkaConsumerConfig) {\n+    return Arrays.stream(kafkaConsumerConfig.split(\";\"))\n+        .map(s -> s.split(\"=\"))\n+        .map(kv -> Pair.of(kv[0], kv[1]))\n+        .collect(Collectors.toMap(Pair::getKey, Pair::getValue));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "24ddb6e9eee92445696aa162abe3aa5daaafdeb8"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MjI3NTA0NA==", "bodyText": "Took a closer look at this. It looks like the dependency is necessary because DirectOptions is referenced in the new test. Could you make it a testCompile dependency?", "url": "https://github.com/apache/beam/pull/13636#discussion_r562275044", "createdAt": "2021-01-21T23:57:09Z", "author": {"login": "TheNeuralBit"}, "path": "examples/java/build.gradle", "diffHunk": "@@ -56,6 +56,7 @@ dependencies {\n   compile library.java.vendored_guava_26_0_jre\n   compile library.java.kafka_clients\n   compile project(path: \":sdks:java:core\", configuration: \"shadow\")\n+  compile project(path: \":runners:direct-java\", configuration: \"shadow\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Njk1NTY5Mg=="}, "originalCommit": {"oid": "00208863d8ad96f082856cfe034a2f3052fb524c"}, "originalPosition": 4}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f6410c53553497eed48c574c81b0a55d26090304", "author": {"user": {"login": "ramazan-yapparov", "name": null}}, "url": "https://github.com/apache/beam/commit/f6410c53553497eed48c574c81b0a55d26090304", "committedDate": "2021-01-22T09:19:31Z", "message": "Minor fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3e166d922ba9d4d0e8cc8d6b89d0f197707f4a42", "author": {"user": {"login": "ramazan-yapparov", "name": null}}, "url": "https://github.com/apache/beam/commit/3e166d922ba9d4d0e8cc8d6b89d0f197707f4a42", "committedDate": "2021-01-22T09:20:21Z", "message": "Merge branch 'master' of github.com:apache/beam into KafkaToPubSubE2E"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9e6ac2050d217a133d81892ecbec6f7ab8bf3d2d", "author": {"user": {"login": "ramazan-yapparov", "name": null}}, "url": "https://github.com/apache/beam/commit/9e6ac2050d217a133d81892ecbec6f7ab8bf3d2d", "committedDate": "2021-01-24T21:15:37Z", "message": "Merge branch 'master' of github.com:apache/beam into KafkaToPubSubE2E"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4301, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}