{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzkzMzAzMDQz", "number": 11210, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yM1QxODoxMjo0OFrOD1aLAw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wOFQwNjoxMDoyM1rOD6hoKw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU3MzI5OTIzOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/experimental/spannerio.py", "isResolved": true, "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yM1QxODoxMjo0OFrOGK1khA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMFQwMToxMDowM1rOGS_eow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDAxNjY0NA==", "bodyText": "I've updated the batch process to support the dataflow runner. The process is almost the same as the previous commit but now I've added the ToList() combine transform before passing the mutation groups from to the _BatchFn to create batches.", "url": "https://github.com/apache/beam/pull/11210#discussion_r414016644", "createdAt": "2020-04-23T18:12:48Z", "author": {"login": "mszb"}, "path": "sdks/python/apache_beam/io/gcp/experimental/spannerio.py", "diffHunk": "@@ -1008,31 +1007,30 @@ def _reset_count(self):\n     self._cells = 0\n \n   def process(self, element):\n-    mg_info = element.info\n+    for elem in element:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "05e6468955c42061f6b8ad2646bbd3f84a488f37"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTk1ODc0Mg==", "bodyText": "Can you clarify ? Why would Dataflow need the elements to be combined to a list ? All runners should be able to operate on a PCollection of mutation groups.", "url": "https://github.com/apache/beam/pull/11210#discussion_r421958742", "createdAt": "2020-05-08T06:11:20Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/io/gcp/experimental/spannerio.py", "diffHunk": "@@ -1008,31 +1007,30 @@ def _reset_count(self):\n     self._cells = 0\n \n   def process(self, element):\n-    mg_info = element.info\n+    for elem in element:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDAxNjY0NA=="}, "originalCommit": {"oid": "05e6468955c42061f6b8ad2646bbd3f84a488f37"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjEwMTgwNQ==", "bodyText": "There was no issue in processing mutation group, the issue was with the batch size. According to the Beam execution model, \u2018The division of the collection into bundles is arbitrary and selected by the runner.\u2019 Which causes finish_bundle to be called multiple times rather than on the complete collection unit which causes the improper number of batches in the dataflow runner. That's the reason I've added the ToList transform to make a single collection and generate the batches properly.", "url": "https://github.com/apache/beam/pull/11210#discussion_r422101805", "createdAt": "2020-05-08T11:55:33Z", "author": {"login": "mszb"}, "path": "sdks/python/apache_beam/io/gcp/experimental/spannerio.py", "diffHunk": "@@ -1008,31 +1007,30 @@ def _reset_count(self):\n     self._cells = 0\n \n   def process(self, element):\n-    mg_info = element.info\n+    for elem in element:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDAxNjY0NA=="}, "originalCommit": {"oid": "05e6468955c42061f6b8ad2646bbd3f84a488f37"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjE4MDY5Mw==", "bodyText": "\"Which causes finish_bundle to be called multiple times\" do you mean that finish_bundle will be called once per bundle ?\nThis is the expected behavior and users will observe this behavior as well. Implementation should work for arbitrary bundle sizes without users having to group PCollection elements together.", "url": "https://github.com/apache/beam/pull/11210#discussion_r422180693", "createdAt": "2020-05-08T14:37:51Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/io/gcp/experimental/spannerio.py", "diffHunk": "@@ -1008,31 +1007,30 @@ def _reset_count(self):\n     self._cells = 0\n \n   def process(self, element):\n-    mg_info = element.info\n+    for elem in element:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDAxNjY0NA=="}, "originalCommit": {"oid": "05e6468955c42061f6b8ad2646bbd3f84a488f37"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjI4MDY3MQ==", "bodyText": "Make sense, in that case, we don't need to alter the connector code anymore, it was working as expected. Thanks, @chamikaramj for the feedback as it is always helpful.\nI'll remove the changes from the spanner io connector and update the IT test code for the assertion.", "url": "https://github.com/apache/beam/pull/11210#discussion_r422280671", "createdAt": "2020-05-08T17:48:34Z", "author": {"login": "mszb"}, "path": "sdks/python/apache_beam/io/gcp/experimental/spannerio.py", "diffHunk": "@@ -1008,31 +1007,30 @@ def _reset_count(self):\n     self._cells = 0\n \n   def process(self, element):\n-    mg_info = element.info\n+    for elem in element:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDAxNjY0NA=="}, "originalCommit": {"oid": "05e6468955c42061f6b8ad2646bbd3f84a488f37"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjI4MjcwNg==", "bodyText": "Thanks. Lemme know when this is ready for another look. Also lets trigger the IT with new changes to make sure it passes.", "url": "https://github.com/apache/beam/pull/11210#discussion_r422282706", "createdAt": "2020-05-08T17:52:46Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/io/gcp/experimental/spannerio.py", "diffHunk": "@@ -1008,31 +1007,30 @@ def _reset_count(self):\n     self._cells = 0\n \n   def process(self, element):\n-    mg_info = element.info\n+    for elem in element:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDAxNjY0NA=="}, "originalCommit": {"oid": "05e6468955c42061f6b8ad2646bbd3f84a488f37"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjU2NzU4Nw==", "bodyText": "Done!", "url": "https://github.com/apache/beam/pull/11210#discussion_r422567587", "createdAt": "2020-05-10T01:10:03Z", "author": {"login": "mszb"}, "path": "sdks/python/apache_beam/io/gcp/experimental/spannerio.py", "diffHunk": "@@ -1008,31 +1007,30 @@ def _reset_count(self):\n     self._cells = 0\n \n   def process(self, element):\n-    mg_info = element.info\n+    for elem in element:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNDAxNjY0NA=="}, "originalCommit": {"oid": "05e6468955c42061f6b8ad2646bbd3f84a488f37"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYyNjk0ODU3OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/experimental/spannerio_test.py", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wOFQwNjowOTo1NlrOGSaSuQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMFQwMTowOTo0N1rOGS_ejg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTk1ODMyOQ==", "bodyText": "Why do we need to perform this combining to run the test ?", "url": "https://github.com/apache/beam/pull/11210#discussion_r421958329", "createdAt": "2020-05-08T06:09:56Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/io/gcp/experimental/spannerio_test.py", "diffHunk": "@@ -499,6 +499,7 @@ def test_batch_byte_size(\n       # and each bach should contains 25 mutations.\n       res = (\n           p | beam.Create(mutation_group)\n+          | 'combine to list' >> beam.combiners.ToList()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "72cc863fbc112f8fdce342bfc240146541c8cca7"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjEwNDEzNg==", "bodyText": "Yes, the _BatchFn requires a single iterable of collection and loop through them to make the batches. Just replicating the same pipeline for the batching in the _WriteGroup transform.", "url": "https://github.com/apache/beam/pull/11210#discussion_r422104136", "createdAt": "2020-05-08T12:01:44Z", "author": {"login": "mszb"}, "path": "sdks/python/apache_beam/io/gcp/experimental/spannerio_test.py", "diffHunk": "@@ -499,6 +499,7 @@ def test_batch_byte_size(\n       # and each bach should contains 25 mutations.\n       res = (\n           p | beam.Create(mutation_group)\n+          | 'combine to list' >> beam.combiners.ToList()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTk1ODMyOQ=="}, "originalCommit": {"oid": "72cc863fbc112f8fdce342bfc240146541c8cca7"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjE4MTQ2Nw==", "bodyText": "Do users have to do this as well ? Seems like we are missing something in the implementation. How does Java implementation operate ?", "url": "https://github.com/apache/beam/pull/11210#discussion_r422181467", "createdAt": "2020-05-08T14:39:15Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/io/gcp/experimental/spannerio_test.py", "diffHunk": "@@ -499,6 +499,7 @@ def test_batch_byte_size(\n       # and each bach should contains 25 mutations.\n       res = (\n           p | beam.Create(mutation_group)\n+          | 'combine to list' >> beam.combiners.ToList()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTk1ODMyOQ=="}, "originalCommit": {"oid": "72cc863fbc112f8fdce342bfc240146541c8cca7"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjI4MDYxNA==", "bodyText": "The user does not have to add ToList transform in the production pipeline. I only added this to test the batch process.\nThe previous implementation of batching (without ToList transform) was as per the java implementation but without the sorting of the transactions by table and primary key (this is also documented as a feature to be added later).", "url": "https://github.com/apache/beam/pull/11210#discussion_r422280614", "createdAt": "2020-05-08T17:48:28Z", "author": {"login": "mszb"}, "path": "sdks/python/apache_beam/io/gcp/experimental/spannerio_test.py", "diffHunk": "@@ -499,6 +499,7 @@ def test_batch_byte_size(\n       # and each bach should contains 25 mutations.\n       res = (\n           p | beam.Create(mutation_group)\n+          | 'combine to list' >> beam.combiners.ToList()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTk1ODMyOQ=="}, "originalCommit": {"oid": "72cc863fbc112f8fdce342bfc240146541c8cca7"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjU2NzU2Ng==", "bodyText": "Done!", "url": "https://github.com/apache/beam/pull/11210#discussion_r422567566", "createdAt": "2020-05-10T01:09:47Z", "author": {"login": "mszb"}, "path": "sdks/python/apache_beam/io/gcp/experimental/spannerio_test.py", "diffHunk": "@@ -499,6 +499,7 @@ def test_batch_byte_size(\n       # and each bach should contains 25 mutations.\n       res = (\n           p | beam.Create(mutation_group)\n+          | 'combine to list' >> beam.combiners.ToList()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTk1ODMyOQ=="}, "originalCommit": {"oid": "72cc863fbc112f8fdce342bfc240146541c8cca7"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYyNjk0OTU1OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/experimental/spannerio.py", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wOFQwNjoxMDoyM1rOGSaTQg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMFQwMTowODoyMFrOGS_eMg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTk1ODQ2Ng==", "bodyText": "This seems like a change to the implementation not part of the integration test. Probably should be a separate PR with a JIRA.", "url": "https://github.com/apache/beam/pull/11210#discussion_r421958466", "createdAt": "2020-05-08T06:10:23Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/io/gcp/experimental/spannerio.py", "diffHunk": "@@ -1008,31 +1007,30 @@ def _reset_count(self):\n     self._cells = 0\n \n   def process(self, element):\n-    mg_info = element.info\n+    for elem in element:\n+      mg_info = elem.info\n+      if mg_info['byte_size'] + self._size_in_bytes > \\", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "72cc863fbc112f8fdce342bfc240146541c8cca7"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjEyNjQ4OQ==", "bodyText": "Sure. Should I create a new Jira ticket and (1) add ticket number in this PR for reference OR (2) create a new PR for this change, and once it gets merge then I rebase this PR and request review?\nI think the first approach required less time to close the tickets! What you suggest?", "url": "https://github.com/apache/beam/pull/11210#discussion_r422126489", "createdAt": "2020-05-08T12:55:10Z", "author": {"login": "mszb"}, "path": "sdks/python/apache_beam/io/gcp/experimental/spannerio.py", "diffHunk": "@@ -1008,31 +1007,30 @@ def _reset_count(self):\n     self._cells = 0\n \n   def process(self, element):\n-    mg_info = element.info\n+    for elem in element:\n+      mg_info = elem.info\n+      if mg_info['byte_size'] + self._size_in_bytes > \\", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTk1ODQ2Ng=="}, "originalCommit": {"oid": "72cc863fbc112f8fdce342bfc240146541c8cca7"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjE4MjYzMw==", "bodyText": "I think (2) is better but we should fix the Spanner connector implementation to work for arbitrary bundle sizes than reducing the bundle to a single element for the test.", "url": "https://github.com/apache/beam/pull/11210#discussion_r422182633", "createdAt": "2020-05-08T14:41:19Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/io/gcp/experimental/spannerio.py", "diffHunk": "@@ -1008,31 +1007,30 @@ def _reset_count(self):\n     self._cells = 0\n \n   def process(self, element):\n-    mg_info = element.info\n+    for elem in element:\n+      mg_info = elem.info\n+      if mg_info['byte_size'] + self._size_in_bytes > \\", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTk1ODQ2Ng=="}, "originalCommit": {"oid": "72cc863fbc112f8fdce342bfc240146541c8cca7"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjU2NzQ3NA==", "bodyText": "Since i've reverted the changes from the connector, there is no need to create new tickets. Resolving this conversation! - Thanks!", "url": "https://github.com/apache/beam/pull/11210#discussion_r422567474", "createdAt": "2020-05-10T01:08:20Z", "author": {"login": "mszb"}, "path": "sdks/python/apache_beam/io/gcp/experimental/spannerio.py", "diffHunk": "@@ -1008,31 +1007,30 @@ def _reset_count(self):\n     self._cells = 0\n \n   def process(self, element):\n-    mg_info = element.info\n+    for elem in element:\n+      mg_info = elem.info\n+      if mg_info['byte_size'] + self._size_in_bytes > \\", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTk1ODQ2Ng=="}, "originalCommit": {"oid": "72cc863fbc112f8fdce342bfc240146541c8cca7"}, "originalPosition": 33}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1513, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}