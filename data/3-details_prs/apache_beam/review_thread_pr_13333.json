{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTIwNzYxMjMy", "number": 13333, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNlQxODo0OTozOVrOE5oNwQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNlQxOTowMTowOVrOE5ofKQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI4ODYzMTY5OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/transforms.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNlQxODo0OTozOVrOH0MuNg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNlQxODo0OTozOVrOH0MuNg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDQ5NjQzOA==", "bodyText": "nit: maybe add a comment like this to clarify the intention\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        return expr.proxy(\n          \n          \n            \n                        ).iloc[:0] if partition[expr._id] is None else partition[expr._id]\n          \n          \n            \n                        # Use proxy if there's no data in this partition\n          \n          \n            \n                        return expr.proxy(\n          \n          \n            \n                        ).iloc[:0] if partition[expr._id] is None else partition[expr._id]", "url": "https://github.com/apache/beam/pull/13333#discussion_r524496438", "createdAt": "2020-11-16T18:49:39Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/transforms.py", "diffHunk": "@@ -223,8 +235,12 @@ def expand(self, pcolls):\n \n         # Actually evaluate the expressions.\n         def evaluate(partition, stage=self.stage, **side_inputs):\n+          def lookup(expr):\n+            return expr.proxy(\n+            ).iloc[:0] if partition[expr._id] is None else partition[expr._id]", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9ef95b5ede1e5a66de21b84c4f8e4d3b525379ee"}, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI4ODY3NjI1OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/transforms.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNlQxOTowMTowOVrOH0NJEw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xNlQxOToxMDoxMFrOH0NdUQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDUwMzMxNQ==", "bodyText": "This is frustratingly similar to _ReBatch... but I don't see a reasonable way to combine them.", "url": "https://github.com/apache/beam/pull/13333#discussion_r524503315", "createdAt": "2020-11-16T19:01:09Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/transforms.py", "diffHunk": "@@ -410,6 +426,35 @@ def _total_memory_usage(frame):\n     float('inf')\n \n \n+class _PreBatch(beam.DoFn):\n+  def __init__(self, target_size=TARGET_PARTITION_SIZE):\n+    self._target_size = target_size\n+\n+  def start_bundle(self):\n+    self._parts = collections.defaultdict(list)\n+    self._running_size = 0\n+\n+  def process(\n+      self,\n+      part,\n+      window=beam.DoFn.WindowParam,\n+      timestamp=beam.DoFn.TimestampParam):\n+    part_size = _total_memory_usage(part)\n+    if part_size >= self._target_size:\n+      yield part\n+    else:\n+      self._running_size += part_size\n+      self._parts[window, timestamp].append(part)\n+      if self._running_size >= self._target_size:\n+        yield from self.finish_bundle()\n+\n+  def finish_bundle(self):\n+    for (window, timestamp), parts in self._parts.items():\n+      yield windowed_value.WindowedValue(\n+          pd.concat(parts), timestamp, (window, ))\n+    self.start_bundle()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9ef95b5ede1e5a66de21b84c4f8e4d3b525379ee"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDUwODQ5Nw==", "bodyText": "Yeah, I was thinking exactly the same...", "url": "https://github.com/apache/beam/pull/13333#discussion_r524508497", "createdAt": "2020-11-16T19:10:10Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/transforms.py", "diffHunk": "@@ -410,6 +426,35 @@ def _total_memory_usage(frame):\n     float('inf')\n \n \n+class _PreBatch(beam.DoFn):\n+  def __init__(self, target_size=TARGET_PARTITION_SIZE):\n+    self._target_size = target_size\n+\n+  def start_bundle(self):\n+    self._parts = collections.defaultdict(list)\n+    self._running_size = 0\n+\n+  def process(\n+      self,\n+      part,\n+      window=beam.DoFn.WindowParam,\n+      timestamp=beam.DoFn.TimestampParam):\n+    part_size = _total_memory_usage(part)\n+    if part_size >= self._target_size:\n+      yield part\n+    else:\n+      self._running_size += part_size\n+      self._parts[window, timestamp].append(part)\n+      if self._running_size >= self._target_size:\n+        yield from self.finish_bundle()\n+\n+  def finish_bundle(self):\n+    for (window, timestamp), parts in self._parts.items():\n+      yield windowed_value.WindowedValue(\n+          pd.concat(parts), timestamp, (window, ))\n+    self.start_bundle()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNDUwMzMxNQ=="}, "originalCommit": {"oid": "9ef95b5ede1e5a66de21b84c4f8e4d3b525379ee"}, "originalPosition": 70}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2795, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}