{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzY3NjAxMDIz", "number": 10694, "title": "[BEAM-9132] Avoid logging misleading error messages during pipeline failure", "bodyText": "We have observed these errors in a state-intense application:\nError processing instruction 107. Original traceback is\nTraceback (most recent call last):\n  File \"apache_beam/runners/common.py\", line 780, in apache_beam.runners.common.DoFnRunner.process\n  File \"apache_beam/runners/common.py\", line 587, in apache_beam.runners.common.PerWindowInvoker.invoke_process\n  File \"apache_beam/runners/common.py\", line 659, in apache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\n  File \"apache_beam/runners/common.py\", line 880, in apache_beam.runners.common._OutputProcessor.process_outputs\n  File \"apache_beam/runners/common.py\", line 895, in apache_beam.runners.common._OutputProcessor.process_outputs\n  File \"redacted.py\", line 56, in process\n    recent_events_map = load_recent_events_map(recent_events_state)\n  File \"redacted.py\", line 128, in _load_recent_events_map\n    items_in_recent_events_bag = list(recent_events_state.read())\n  File \"apache_beam/runners/worker/bundle_processor.py\", line 335, in __iter__\n    for elem in self.first:\n  File \"apache_beam/runners/worker/bundle_processor.py\", line 214, in __iter__\n    self._state_key, self._coder_impl, is_cached=self._is_cached)\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 692, in blocking_get\n    self._materialize_iter(state_key, coder))\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 723, in _materialize_iter\n    self._underlying.get_raw(state_key, continuation_token)\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 603, in get_raw\n    continuation_token=continuation_token)))\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 637, in _blocking_request\n    raise RuntimeError(response.error)\nRuntimeError: Unknown process bundle instruction id '107'\n\nNotice that the error is thrown on the Runner side in the GrpcStateService.\nExplanation\nWe experienced a network split of the Flink cluster which caused the job to\nfail. The logging implied a failure of the state requests right before the\nnetwork split. However, the opposite is true, the failure occured during\nshutdown of the pipeline where the state request handler has already been removed.\nSolution\nEnsure that we shutdown the environment and any pending clients which may be\nprocessing pending requests.\nPost-Commit Tests Status (on master branch)\n\n\n\nLang\nSDK\nApex\nDataflow\nFlink\nGearpump\nSamza\nSpark\n\n\n\n\nGo\n\n---\n---\n\n---\n---\n\n\n\nJava\n\n\n\n\n\n\n\n\n\nPython\n\n---\n\n\n---\n---\n\n\n\nXLang\n---\n---\n---\n\n---\n---\n---\n\n\n\nPre-Commit Tests Status (on master branch)\n\n\n\n---\nJava\nPython\nGo\nWebsite\n\n\n\n\nNon-portable\n\n\n\n\n\n\nPortable\n---\n\n---\n---\n\n\n\nSee .test-infra/jenkins/README for trigger phrase, status and link of all Jenkins jobs.", "createdAt": "2020-01-27T17:01:22Z", "url": "https://github.com/apache/beam/pull/10694", "merged": true, "mergeCommit": {"oid": "7f04e5f1a02ccb18165bef9c4ce9a29db97bfe47"}, "closed": true, "closedAt": "2020-01-31T13:50:46Z", "author": {"login": "mxm"}, "timelineItems": {"totalCount": 13, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABb-2EdtgBqjI5ODY4NDU4OTA=", "endCursor": "Y3Vyc29yOnYyOpPPAAABb_uNY-gFqTM1MTQ2NzgzNg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "1ed4626c3a54749a4c4018549a443902c3ba8de5", "author": {"user": {"login": "mxm", "name": "Maximilian Michels"}}, "url": "https://github.com/apache/beam/commit/1ed4626c3a54749a4c4018549a443902c3ba8de5", "committedDate": "2020-01-27T16:48:54Z", "message": "[BEAM-9132] Use a unique bundle id across all SDK workers bound to the same environment\n\nWe have observed these errors in a state-intense application:\n\n```\nError processing instruction 107. Original traceback is\nTraceback (most recent call last):\n  File \"apache_beam/runners/common.py\", line 780, in apache_beam.runners.common.DoFnRunner.process\n  File \"apache_beam/runners/common.py\", line 587, in apache_beam.runners.common.PerWindowInvoker.invoke_process\n  File \"apache_beam/runners/common.py\", line 659, in apache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\n  File \"apache_beam/runners/common.py\", line 880, in apache_beam.runners.common._OutputProcessor.process_outputs\n  File \"apache_beam/runners/common.py\", line 895, in apache_beam.runners.common._OutputProcessor.process_outputs\n  File \"redacted.py\", line 56, in process\n    recent_events_map = load_recent_events_map(recent_events_state)\n  File \"redacted.py\", line 128, in _load_recent_events_map\n    items_in_recent_events_bag = list(recent_events_state.read())\n  File \"apache_beam/runners/worker/bundle_processor.py\", line 335, in __iter__\n    for elem in self.first:\n  File \"apache_beam/runners/worker/bundle_processor.py\", line 214, in __iter__\n    self._state_key, self._coder_impl, is_cached=self._is_cached)\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 692, in blocking_get\n    self._materialize_iter(state_key, coder))\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 723, in _materialize_iter\n    self._underlying.get_raw(state_key, continuation_token)\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 603, in get_raw\n    continuation_token=continuation_token)))\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 637, in _blocking_request\n    raise RuntimeError(response.error)\nRuntimeError: Unknown process bundle instruction id '107'\n```\n\nNotice that the error is thrown on the Runner side in the GrpcStateService.\n\nExplanation: The error occurs when multiple ExecutableStages are scheduled on\nthe same TaskManager. Depending on how many SDK workers are available, they may\nend up sharing the same environment. This means that they will also share the\nsame GrpcStateService. The state service uses the bundle id to reference the\nStateRequestHandler of the currently active bundle. The problem is that the code\nused a from zero ascending id generator for each stage, even if it shared the\nsame environment.\n\nThe bundle id generator always start from 0 which eventually leads to a race\ncondition between the state requests of the transforms which share the same\nenvironments. Their ids will overlap leading to falsely removing state handlers\nof other stages in GrpcStateService.\n\nSolution: Use a unique id generator per environment which is shared by all the\nstages within an environment."}, "afterCommit": {"oid": "0a2713f9e1a8ad2dda68e08d2759fde1f61a15dd", "author": {"user": {"login": "mxm", "name": "Maximilian Michels"}}, "url": "https://github.com/apache/beam/commit/0a2713f9e1a8ad2dda68e08d2759fde1f61a15dd", "committedDate": "2020-01-28T18:52:19Z", "message": "[BEAM-9132] Avoid logging misleading error messages during pipeline failure\n\nWe have observed these errors in a state-intense application:\n\n```\nError processing instruction 107. Original traceback is\nTraceback (most recent call last):\n  File \"apache_beam/runners/common.py\", line 780, in apache_beam.runners.common.DoFnRunner.process\n  File \"apache_beam/runners/common.py\", line 587, in apache_beam.runners.common.PerWindowInvoker.invoke_process\n  File \"apache_beam/runners/common.py\", line 659, in apache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\n  File \"apache_beam/runners/common.py\", line 880, in apache_beam.runners.common._OutputProcessor.process_outputs\n  File \"apache_beam/runners/common.py\", line 895, in apache_beam.runners.common._OutputProcessor.process_outputs\n  File \"redacted.py\", line 56, in process\n    recent_events_map = load_recent_events_map(recent_events_state)\n  File \"redacted.py\", line 128, in _load_recent_events_map\n    items_in_recent_events_bag = list(recent_events_state.read())\n  File \"apache_beam/runners/worker/bundle_processor.py\", line 335, in __iter__\n    for elem in self.first:\n  File \"apache_beam/runners/worker/bundle_processor.py\", line 214, in __iter__\n    self._state_key, self._coder_impl, is_cached=self._is_cached)\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 692, in blocking_get\n    self._materialize_iter(state_key, coder))\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 723, in _materialize_iter\n    self._underlying.get_raw(state_key, continuation_token)\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 603, in get_raw\n    continuation_token=continuation_token)))\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 637, in _blocking_request\n    raise RuntimeError(response.error)\nRuntimeError: Unknown process bundle instruction id '107'\n```\n\nNotice that the error is thrown on the Runner side in the GrpcStateService.\n\nExplanation\n===========\n\nWe experienced a network split of the Flink cluster which caused the job to\nfail. The logging implied a failure of the state requests right before the\nnetwork split. However, the opposite is true, the failure occured during\nshutdown of the pipeline where the state request handler has already been removed.\n\nSolution\n========\n\nEnsure that we shutdown the environment and any pending clients which may be\nprocessing pending requests."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ5NjMwNDcw", "url": "https://github.com/apache/beam/pull/10694#pullrequestreview-349630470", "createdAt": "2020-01-28T19:10:42Z", "commit": {"oid": "0a2713f9e1a8ad2dda68e08d2759fde1f61a15dd"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOFQxOToxMDo0MlrOFixHeQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOFQxOToxMDo0MlrOFixHeQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjAwMDYzMw==", "bodyText": "Isn't close only called from unref? If so, how does this change the behavior? (Possibly some more explanation needs to be added.)", "url": "https://github.com/apache/beam/pull/10694#discussion_r372000633", "createdAt": "2020-01-28T19:10:42Z", "author": {"login": "tweise"}, "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/control/DefaultJobBundleFactory.java", "diffHunk": "@@ -464,6 +474,8 @@ ServerInfo getServerInfo() {\n     }\n \n     public void close() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0a2713f9e1a8ad2dda68e08d2759fde1f61a15dd"}, "originalPosition": 48}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ5NjMxOTQw", "url": "https://github.com/apache/beam/pull/10694#pullrequestreview-349631940", "createdAt": "2020-01-28T19:13:01Z", "commit": {"oid": "0a2713f9e1a8ad2dda68e08d2759fde1f61a15dd"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOFQxOToxMzowMVrOFixLwg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOFQxOToxMzowMVrOFixLwg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjAwMTczMA==", "bodyText": "What would cause this extra ref in the actual operator lifecycle?", "url": "https://github.com/apache/beam/pull/10694#discussion_r372001730", "createdAt": "2020-01-28T19:13:01Z", "author": {"login": "tweise"}, "path": "runners/java-fn-execution/src/test/java/org/apache/beam/runners/fnexecution/control/DefaultJobBundleFactoryTest.java", "diffHunk": "@@ -360,6 +360,19 @@ public void closesEnvironmentOnCleanup() throws Exception {\n     verify(remoteEnvironment).close();\n   }\n \n+  @Test\n+  public void closesEnvironmentOnCleanupWithPendingRefs() throws Exception {\n+    try (DefaultJobBundleFactory bundleFactory =\n+        createDefaultJobBundleFactory(envFactoryProviderMap)) {\n+      DefaultJobBundleFactory.SimpleStageBundleFactory stageBundleFactory =\n+          (DefaultJobBundleFactory.SimpleStageBundleFactory)\n+              bundleFactory.forStage(getExecutableStage(environment));\n+      // The client is still being used, e.g. when the pipeline fails and is shut down\n+      stageBundleFactory.currentClient.wrappedClient.ref();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0a2713f9e1a8ad2dda68e08d2759fde1f61a15dd"}, "originalPosition": 12}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ5NjM1MjM2", "url": "https://github.com/apache/beam/pull/10694#pullrequestreview-349635236", "createdAt": "2020-01-28T19:18:06Z", "commit": {"oid": "0a2713f9e1a8ad2dda68e08d2759fde1f61a15dd"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOFQxOToxODowN1rOFixVyw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOFQxOToxODowN1rOFixVyw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjAwNDI5OQ==", "bodyText": "Worth mentioning that this is added to close the environments irrespective of open bundles, since this will occur only during shutdown?", "url": "https://github.com/apache/beam/pull/10694#discussion_r372004299", "createdAt": "2020-01-28T19:18:07Z", "author": {"login": "tweise"}, "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/control/DefaultJobBundleFactory.java", "diffHunk": "@@ -255,6 +255,14 @@ public void close() throws Exception {\n     // Clear the cache. This closes all active environments.\n     // note this may cause open calls to be cancelled by the peer\n     for (LoadingCache<Environment, WrappedSdkHarnessClient> environmentCache : environmentCaches) {\n+      for (WrappedSdkHarnessClient client : environmentCache.asMap().values()) {\n+        try {\n+          client.close();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0a2713f9e1a8ad2dda68e08d2759fde1f61a15dd"}, "originalPosition": 6}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0a2713f9e1a8ad2dda68e08d2759fde1f61a15dd", "author": {"user": {"login": "mxm", "name": "Maximilian Michels"}}, "url": "https://github.com/apache/beam/commit/0a2713f9e1a8ad2dda68e08d2759fde1f61a15dd", "committedDate": "2020-01-28T18:52:19Z", "message": "[BEAM-9132] Avoid logging misleading error messages during pipeline failure\n\nWe have observed these errors in a state-intense application:\n\n```\nError processing instruction 107. Original traceback is\nTraceback (most recent call last):\n  File \"apache_beam/runners/common.py\", line 780, in apache_beam.runners.common.DoFnRunner.process\n  File \"apache_beam/runners/common.py\", line 587, in apache_beam.runners.common.PerWindowInvoker.invoke_process\n  File \"apache_beam/runners/common.py\", line 659, in apache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\n  File \"apache_beam/runners/common.py\", line 880, in apache_beam.runners.common._OutputProcessor.process_outputs\n  File \"apache_beam/runners/common.py\", line 895, in apache_beam.runners.common._OutputProcessor.process_outputs\n  File \"redacted.py\", line 56, in process\n    recent_events_map = load_recent_events_map(recent_events_state)\n  File \"redacted.py\", line 128, in _load_recent_events_map\n    items_in_recent_events_bag = list(recent_events_state.read())\n  File \"apache_beam/runners/worker/bundle_processor.py\", line 335, in __iter__\n    for elem in self.first:\n  File \"apache_beam/runners/worker/bundle_processor.py\", line 214, in __iter__\n    self._state_key, self._coder_impl, is_cached=self._is_cached)\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 692, in blocking_get\n    self._materialize_iter(state_key, coder))\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 723, in _materialize_iter\n    self._underlying.get_raw(state_key, continuation_token)\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 603, in get_raw\n    continuation_token=continuation_token)))\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 637, in _blocking_request\n    raise RuntimeError(response.error)\nRuntimeError: Unknown process bundle instruction id '107'\n```\n\nNotice that the error is thrown on the Runner side in the GrpcStateService.\n\nExplanation\n===========\n\nWe experienced a network split of the Flink cluster which caused the job to\nfail. The logging implied a failure of the state requests right before the\nnetwork split. However, the opposite is true, the failure occured during\nshutdown of the pipeline where the state request handler has already been removed.\n\nSolution\n========\n\nEnsure that we shutdown the environment and any pending clients which may be\nprocessing pending requests."}, "afterCommit": {"oid": "54b1d8ff52b906251d8c0fcbd10abe3584e039c0", "author": {"user": {"login": "mxm", "name": "Maximilian Michels"}}, "url": "https://github.com/apache/beam/commit/54b1d8ff52b906251d8c0fcbd10abe3584e039c0", "committedDate": "2020-01-29T16:29:10Z", "message": "[BEAM-9132] Avoid logging misleading error messages during pipeline failure\n\nWe have observed these errors in a state-intense application:\n\n```\nError processing instruction 107. Original traceback is\nTraceback (most recent call last):\n  File \"apache_beam/runners/common.py\", line 780, in apache_beam.runners.common.DoFnRunner.process\n  File \"apache_beam/runners/common.py\", line 587, in apache_beam.runners.common.PerWindowInvoker.invoke_process\n  File \"apache_beam/runners/common.py\", line 659, in apache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\n  File \"apache_beam/runners/common.py\", line 880, in apache_beam.runners.common._OutputProcessor.process_outputs\n  File \"apache_beam/runners/common.py\", line 895, in apache_beam.runners.common._OutputProcessor.process_outputs\n  File \"redacted.py\", line 56, in process\n    recent_events_map = load_recent_events_map(recent_events_state)\n  File \"redacted.py\", line 128, in _load_recent_events_map\n    items_in_recent_events_bag = list(recent_events_state.read())\n  File \"apache_beam/runners/worker/bundle_processor.py\", line 335, in __iter__\n    for elem in self.first:\n  File \"apache_beam/runners/worker/bundle_processor.py\", line 214, in __iter__\n    self._state_key, self._coder_impl, is_cached=self._is_cached)\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 692, in blocking_get\n    self._materialize_iter(state_key, coder))\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 723, in _materialize_iter\n    self._underlying.get_raw(state_key, continuation_token)\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 603, in get_raw\n    continuation_token=continuation_token)))\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 637, in _blocking_request\n    raise RuntimeError(response.error)\nRuntimeError: Unknown process bundle instruction id '107'\n```\n\nNotice that the error is thrown on the Runner side in the GrpcStateService.\n\nExplanation\n===========\n\nWe experienced a network split of the Flink cluster which caused the job to\nfail. The logging implied a failure of the state requests right before the\nnetwork split. However, the opposite is true, the failure occured during\nshutdown of the pipeline where the state request handler has already been removed.\n\nSolution\n========\n\nEnsure that we shutdown the environment and any pending clients which may be\nprocessing pending requests."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "54b1d8ff52b906251d8c0fcbd10abe3584e039c0", "author": {"user": {"login": "mxm", "name": "Maximilian Michels"}}, "url": "https://github.com/apache/beam/commit/54b1d8ff52b906251d8c0fcbd10abe3584e039c0", "committedDate": "2020-01-29T16:29:10Z", "message": "[BEAM-9132] Avoid logging misleading error messages during pipeline failure\n\nWe have observed these errors in a state-intense application:\n\n```\nError processing instruction 107. Original traceback is\nTraceback (most recent call last):\n  File \"apache_beam/runners/common.py\", line 780, in apache_beam.runners.common.DoFnRunner.process\n  File \"apache_beam/runners/common.py\", line 587, in apache_beam.runners.common.PerWindowInvoker.invoke_process\n  File \"apache_beam/runners/common.py\", line 659, in apache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\n  File \"apache_beam/runners/common.py\", line 880, in apache_beam.runners.common._OutputProcessor.process_outputs\n  File \"apache_beam/runners/common.py\", line 895, in apache_beam.runners.common._OutputProcessor.process_outputs\n  File \"redacted.py\", line 56, in process\n    recent_events_map = load_recent_events_map(recent_events_state)\n  File \"redacted.py\", line 128, in _load_recent_events_map\n    items_in_recent_events_bag = list(recent_events_state.read())\n  File \"apache_beam/runners/worker/bundle_processor.py\", line 335, in __iter__\n    for elem in self.first:\n  File \"apache_beam/runners/worker/bundle_processor.py\", line 214, in __iter__\n    self._state_key, self._coder_impl, is_cached=self._is_cached)\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 692, in blocking_get\n    self._materialize_iter(state_key, coder))\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 723, in _materialize_iter\n    self._underlying.get_raw(state_key, continuation_token)\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 603, in get_raw\n    continuation_token=continuation_token)))\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 637, in _blocking_request\n    raise RuntimeError(response.error)\nRuntimeError: Unknown process bundle instruction id '107'\n```\n\nNotice that the error is thrown on the Runner side in the GrpcStateService.\n\nExplanation\n===========\n\nWe experienced a network split of the Flink cluster which caused the job to\nfail. The logging implied a failure of the state requests right before the\nnetwork split. However, the opposite is true, the failure occured during\nshutdown of the pipeline where the state request handler has already been removed.\n\nSolution\n========\n\nEnsure that we shutdown the environment and any pending clients which may be\nprocessing pending requests."}, "afterCommit": {"oid": "ae714925001f4ebb829d2a935238451b8caff37b", "author": {"user": {"login": "mxm", "name": "Maximilian Michels"}}, "url": "https://github.com/apache/beam/commit/ae714925001f4ebb829d2a935238451b8caff37b", "committedDate": "2020-01-29T16:42:08Z", "message": "[BEAM-9132] Avoid logging misleading error messages during pipeline failure\n\nWe have observed these errors in a state-intense application:\n\n```\nError processing instruction 107. Original traceback is\nTraceback (most recent call last):\n  File \"apache_beam/runners/common.py\", line 780, in apache_beam.runners.common.DoFnRunner.process\n  File \"apache_beam/runners/common.py\", line 587, in apache_beam.runners.common.PerWindowInvoker.invoke_process\n  File \"apache_beam/runners/common.py\", line 659, in apache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\n  File \"apache_beam/runners/common.py\", line 880, in apache_beam.runners.common._OutputProcessor.process_outputs\n  File \"apache_beam/runners/common.py\", line 895, in apache_beam.runners.common._OutputProcessor.process_outputs\n  File \"redacted.py\", line 56, in process\n    recent_events_map = load_recent_events_map(recent_events_state)\n  File \"redacted.py\", line 128, in _load_recent_events_map\n    items_in_recent_events_bag = list(recent_events_state.read())\n  File \"apache_beam/runners/worker/bundle_processor.py\", line 335, in __iter__\n    for elem in self.first:\n  File \"apache_beam/runners/worker/bundle_processor.py\", line 214, in __iter__\n    self._state_key, self._coder_impl, is_cached=self._is_cached)\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 692, in blocking_get\n    self._materialize_iter(state_key, coder))\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 723, in _materialize_iter\n    self._underlying.get_raw(state_key, continuation_token)\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 603, in get_raw\n    continuation_token=continuation_token)))\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 637, in _blocking_request\n    raise RuntimeError(response.error)\nRuntimeError: Unknown process bundle instruction id '107'\n```\n\nNotice that the error is thrown on the Runner side in the GrpcStateService.\n\nExplanation\n===========\n\nWe experienced a network split of the Flink cluster which caused the job to\nfail. The logging implied a failure of the state requests right before the\nnetwork split. However, the opposite is true, the failure occured during\nshutdown of the pipeline where the state request handler has already been removed.\n\nSolution\n========\n\nEnsure that we shutdown the environment and any pending clients which may be\nprocessing pending requests."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ae714925001f4ebb829d2a935238451b8caff37b", "author": {"user": {"login": "mxm", "name": "Maximilian Michels"}}, "url": "https://github.com/apache/beam/commit/ae714925001f4ebb829d2a935238451b8caff37b", "committedDate": "2020-01-29T16:42:08Z", "message": "[BEAM-9132] Avoid logging misleading error messages during pipeline failure\n\nWe have observed these errors in a state-intense application:\n\n```\nError processing instruction 107. Original traceback is\nTraceback (most recent call last):\n  File \"apache_beam/runners/common.py\", line 780, in apache_beam.runners.common.DoFnRunner.process\n  File \"apache_beam/runners/common.py\", line 587, in apache_beam.runners.common.PerWindowInvoker.invoke_process\n  File \"apache_beam/runners/common.py\", line 659, in apache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\n  File \"apache_beam/runners/common.py\", line 880, in apache_beam.runners.common._OutputProcessor.process_outputs\n  File \"apache_beam/runners/common.py\", line 895, in apache_beam.runners.common._OutputProcessor.process_outputs\n  File \"redacted.py\", line 56, in process\n    recent_events_map = load_recent_events_map(recent_events_state)\n  File \"redacted.py\", line 128, in _load_recent_events_map\n    items_in_recent_events_bag = list(recent_events_state.read())\n  File \"apache_beam/runners/worker/bundle_processor.py\", line 335, in __iter__\n    for elem in self.first:\n  File \"apache_beam/runners/worker/bundle_processor.py\", line 214, in __iter__\n    self._state_key, self._coder_impl, is_cached=self._is_cached)\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 692, in blocking_get\n    self._materialize_iter(state_key, coder))\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 723, in _materialize_iter\n    self._underlying.get_raw(state_key, continuation_token)\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 603, in get_raw\n    continuation_token=continuation_token)))\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 637, in _blocking_request\n    raise RuntimeError(response.error)\nRuntimeError: Unknown process bundle instruction id '107'\n```\n\nNotice that the error is thrown on the Runner side in the GrpcStateService.\n\nExplanation\n===========\n\nWe experienced a network split of the Flink cluster which caused the job to\nfail. The logging implied a failure of the state requests right before the\nnetwork split. However, the opposite is true, the failure occured during\nshutdown of the pipeline where the state request handler has already been removed.\n\nSolution\n========\n\nEnsure that we shutdown the environment and any pending clients which may be\nprocessing pending requests."}, "afterCommit": {"oid": "132e627cddb4392196694b608a0011a3a3f46462", "author": {"user": {"login": "mxm", "name": "Maximilian Michels"}}, "url": "https://github.com/apache/beam/commit/132e627cddb4392196694b608a0011a3a3f46462", "committedDate": "2020-01-29T17:48:56Z", "message": "[BEAM-9132] Avoid logging misleading error messages during pipeline failure\n\nWe have observed these errors in a state-intense application:\n\n```\nError processing instruction 107. Original traceback is\nTraceback (most recent call last):\n  File \"apache_beam/runners/common.py\", line 780, in apache_beam.runners.common.DoFnRunner.process\n  File \"apache_beam/runners/common.py\", line 587, in apache_beam.runners.common.PerWindowInvoker.invoke_process\n  File \"apache_beam/runners/common.py\", line 659, in apache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\n  File \"apache_beam/runners/common.py\", line 880, in apache_beam.runners.common._OutputProcessor.process_outputs\n  File \"apache_beam/runners/common.py\", line 895, in apache_beam.runners.common._OutputProcessor.process_outputs\n  File \"redacted.py\", line 56, in process\n    recent_events_map = load_recent_events_map(recent_events_state)\n  File \"redacted.py\", line 128, in _load_recent_events_map\n    items_in_recent_events_bag = list(recent_events_state.read())\n  File \"apache_beam/runners/worker/bundle_processor.py\", line 335, in __iter__\n    for elem in self.first:\n  File \"apache_beam/runners/worker/bundle_processor.py\", line 214, in __iter__\n    self._state_key, self._coder_impl, is_cached=self._is_cached)\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 692, in blocking_get\n    self._materialize_iter(state_key, coder))\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 723, in _materialize_iter\n    self._underlying.get_raw(state_key, continuation_token)\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 603, in get_raw\n    continuation_token=continuation_token)))\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 637, in _blocking_request\n    raise RuntimeError(response.error)\nRuntimeError: Unknown process bundle instruction id '107'\n```\n\nNotice that the error is thrown on the Runner side in the GrpcStateService.\n\nExplanation\n===========\n\nWe experienced a network split of the Flink cluster which caused the job to\nfail. The logging implied a failure of the state requests right before the\nnetwork split. However, the opposite is true, the failure occured during\nshutdown of the pipeline where the state request handler has already been removed.\n\nSolution\n========\n\nEnsure that we shutdown the environment and any pending clients which may be\nprocessing pending requests."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUwMzY3MDk0", "url": "https://github.com/apache/beam/pull/10694#pullrequestreview-350367094", "createdAt": "2020-01-29T19:28:55Z", "commit": {"oid": "132e627cddb4392196694b608a0011a3a3f46462"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOVQxOToyODo1NVrOFjU0Tw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yOVQxOToyODo1NVrOFjU0Tw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MjU4NTU1MQ==", "bodyText": "Looks like this was responsible for the cleanup failing. bundle.close() may throw leaving the environment still referenced. My tests do not yield any more errors like in the description.", "url": "https://github.com/apache/beam/pull/10694#discussion_r372585551", "createdAt": "2020-01-29T19:28:55Z", "author": {"login": "mxm"}, "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/control/DefaultJobBundleFactory.java", "diffHunk": "@@ -406,11 +407,14 @@ public void split(double fractionOfRemainder) {\n \n         @Override\n         public void close() throws Exception {\n-          bundle.close();\n-          currentClient.wrappedClient.unref();\n-          if (loadBalanceBundles) {\n-            availableCaches.offer(currentCache);\n-            availableCachesSemaphore.release();\n+          try {\n+            bundle.close();\n+          } finally {\n+            currentClient.wrappedClient.unref();\n+            if (loadBalanceBundles) {\n+              availableCaches.offer(currentCache);\n+              availableCachesSemaphore.release();\n+            }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "132e627cddb4392196694b608a0011a3a3f46462"}, "originalPosition": 37}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "132e627cddb4392196694b608a0011a3a3f46462", "author": {"user": {"login": "mxm", "name": "Maximilian Michels"}}, "url": "https://github.com/apache/beam/commit/132e627cddb4392196694b608a0011a3a3f46462", "committedDate": "2020-01-29T17:48:56Z", "message": "[BEAM-9132] Avoid logging misleading error messages during pipeline failure\n\nWe have observed these errors in a state-intense application:\n\n```\nError processing instruction 107. Original traceback is\nTraceback (most recent call last):\n  File \"apache_beam/runners/common.py\", line 780, in apache_beam.runners.common.DoFnRunner.process\n  File \"apache_beam/runners/common.py\", line 587, in apache_beam.runners.common.PerWindowInvoker.invoke_process\n  File \"apache_beam/runners/common.py\", line 659, in apache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\n  File \"apache_beam/runners/common.py\", line 880, in apache_beam.runners.common._OutputProcessor.process_outputs\n  File \"apache_beam/runners/common.py\", line 895, in apache_beam.runners.common._OutputProcessor.process_outputs\n  File \"redacted.py\", line 56, in process\n    recent_events_map = load_recent_events_map(recent_events_state)\n  File \"redacted.py\", line 128, in _load_recent_events_map\n    items_in_recent_events_bag = list(recent_events_state.read())\n  File \"apache_beam/runners/worker/bundle_processor.py\", line 335, in __iter__\n    for elem in self.first:\n  File \"apache_beam/runners/worker/bundle_processor.py\", line 214, in __iter__\n    self._state_key, self._coder_impl, is_cached=self._is_cached)\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 692, in blocking_get\n    self._materialize_iter(state_key, coder))\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 723, in _materialize_iter\n    self._underlying.get_raw(state_key, continuation_token)\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 603, in get_raw\n    continuation_token=continuation_token)))\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 637, in _blocking_request\n    raise RuntimeError(response.error)\nRuntimeError: Unknown process bundle instruction id '107'\n```\n\nNotice that the error is thrown on the Runner side in the GrpcStateService.\n\nExplanation\n===========\n\nWe experienced a network split of the Flink cluster which caused the job to\nfail. The logging implied a failure of the state requests right before the\nnetwork split. However, the opposite is true, the failure occured during\nshutdown of the pipeline where the state request handler has already been removed.\n\nSolution\n========\n\nEnsure that we shutdown the environment and any pending clients which may be\nprocessing pending requests."}, "afterCommit": {"oid": "22d0bcbbcb87a05839ec7ff629cefcc16457e776", "author": {"user": {"login": "mxm", "name": "Maximilian Michels"}}, "url": "https://github.com/apache/beam/commit/22d0bcbbcb87a05839ec7ff629cefcc16457e776", "committedDate": "2020-01-29T20:54:48Z", "message": "[BEAM-9132] Avoid logging misleading error messages during pipeline failure\n\nWe have observed these errors in a state-intense application:\n\n```\nError processing instruction 107. Original traceback is\nTraceback (most recent call last):\n  File \"apache_beam/runners/common.py\", line 780, in apache_beam.runners.common.DoFnRunner.process\n  File \"apache_beam/runners/common.py\", line 587, in apache_beam.runners.common.PerWindowInvoker.invoke_process\n  File \"apache_beam/runners/common.py\", line 659, in apache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\n  File \"apache_beam/runners/common.py\", line 880, in apache_beam.runners.common._OutputProcessor.process_outputs\n  File \"apache_beam/runners/common.py\", line 895, in apache_beam.runners.common._OutputProcessor.process_outputs\n  File \"redacted.py\", line 56, in process\n    recent_events_map = load_recent_events_map(recent_events_state)\n  File \"redacted.py\", line 128, in _load_recent_events_map\n    items_in_recent_events_bag = list(recent_events_state.read())\n  File \"apache_beam/runners/worker/bundle_processor.py\", line 335, in __iter__\n    for elem in self.first:\n  File \"apache_beam/runners/worker/bundle_processor.py\", line 214, in __iter__\n    self._state_key, self._coder_impl, is_cached=self._is_cached)\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 692, in blocking_get\n    self._materialize_iter(state_key, coder))\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 723, in _materialize_iter\n    self._underlying.get_raw(state_key, continuation_token)\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 603, in get_raw\n    continuation_token=continuation_token)))\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 637, in _blocking_request\n    raise RuntimeError(response.error)\nRuntimeError: Unknown process bundle instruction id '107'\n```\n\nNotice that the error is thrown on the Runner side in the GrpcStateService.\n\nExplanation\n===========\n\nWe experienced a network split of the Flink cluster which caused the job to\nfail. The logging implied a failure of the state requests right before the\nnetwork split. However, the opposite is true, the failure occured during\nshutdown of the pipeline where the state request handler has already been removed.\n\nSolution\n========\n\nEnsure that we shutdown the environment and any pending clients which may be\nprocessing pending requests."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUxMDI0MTg3", "url": "https://github.com/apache/beam/pull/10694#pullrequestreview-351024187", "createdAt": "2020-01-30T17:55:21Z", "commit": {"oid": "22d0bcbbcb87a05839ec7ff629cefcc16457e776"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7a0c82fd6a8b323bfceb0222dd3766fd14f7443b", "author": {"user": {"login": "mxm", "name": "Maximilian Michels"}}, "url": "https://github.com/apache/beam/commit/7a0c82fd6a8b323bfceb0222dd3766fd14f7443b", "committedDate": "2020-01-31T10:47:26Z", "message": "[BEAM-9132] Avoid logging misleading error messages during pipeline failure\n\nWe have observed these errors in a state-intense application:\n\n```\nError processing instruction 107. Original traceback is\nTraceback (most recent call last):\n  File \"apache_beam/runners/common.py\", line 780, in apache_beam.runners.common.DoFnRunner.process\n  File \"apache_beam/runners/common.py\", line 587, in apache_beam.runners.common.PerWindowInvoker.invoke_process\n  File \"apache_beam/runners/common.py\", line 659, in apache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\n  File \"apache_beam/runners/common.py\", line 880, in apache_beam.runners.common._OutputProcessor.process_outputs\n  File \"apache_beam/runners/common.py\", line 895, in apache_beam.runners.common._OutputProcessor.process_outputs\n  File \"redacted.py\", line 56, in process\n    recent_events_map = load_recent_events_map(recent_events_state)\n  File \"redacted.py\", line 128, in _load_recent_events_map\n    items_in_recent_events_bag = list(recent_events_state.read())\n  File \"apache_beam/runners/worker/bundle_processor.py\", line 335, in __iter__\n    for elem in self.first:\n  File \"apache_beam/runners/worker/bundle_processor.py\", line 214, in __iter__\n    self._state_key, self._coder_impl, is_cached=self._is_cached)\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 692, in blocking_get\n    self._materialize_iter(state_key, coder))\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 723, in _materialize_iter\n    self._underlying.get_raw(state_key, continuation_token)\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 603, in get_raw\n    continuation_token=continuation_token)))\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 637, in _blocking_request\n    raise RuntimeError(response.error)\nRuntimeError: Unknown process bundle instruction id '107'\n```\n\nNotice that the error is thrown on the Runner side in the GrpcStateService.\n\nExplanation\n===========\n\nWe experienced a network split of the Flink cluster which caused the job to\nfail. The logging implied a failure of the state requests right before the\nnetwork split. However, the opposite is true, the failure occured during\nshutdown of the pipeline where the state request handler has already been removed.\n\nSolution\n========\n\nEnsure that we shutdown the environment and any pending clients which may be\nprocessing pending requests."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "22d0bcbbcb87a05839ec7ff629cefcc16457e776", "author": {"user": {"login": "mxm", "name": "Maximilian Michels"}}, "url": "https://github.com/apache/beam/commit/22d0bcbbcb87a05839ec7ff629cefcc16457e776", "committedDate": "2020-01-29T20:54:48Z", "message": "[BEAM-9132] Avoid logging misleading error messages during pipeline failure\n\nWe have observed these errors in a state-intense application:\n\n```\nError processing instruction 107. Original traceback is\nTraceback (most recent call last):\n  File \"apache_beam/runners/common.py\", line 780, in apache_beam.runners.common.DoFnRunner.process\n  File \"apache_beam/runners/common.py\", line 587, in apache_beam.runners.common.PerWindowInvoker.invoke_process\n  File \"apache_beam/runners/common.py\", line 659, in apache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\n  File \"apache_beam/runners/common.py\", line 880, in apache_beam.runners.common._OutputProcessor.process_outputs\n  File \"apache_beam/runners/common.py\", line 895, in apache_beam.runners.common._OutputProcessor.process_outputs\n  File \"redacted.py\", line 56, in process\n    recent_events_map = load_recent_events_map(recent_events_state)\n  File \"redacted.py\", line 128, in _load_recent_events_map\n    items_in_recent_events_bag = list(recent_events_state.read())\n  File \"apache_beam/runners/worker/bundle_processor.py\", line 335, in __iter__\n    for elem in self.first:\n  File \"apache_beam/runners/worker/bundle_processor.py\", line 214, in __iter__\n    self._state_key, self._coder_impl, is_cached=self._is_cached)\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 692, in blocking_get\n    self._materialize_iter(state_key, coder))\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 723, in _materialize_iter\n    self._underlying.get_raw(state_key, continuation_token)\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 603, in get_raw\n    continuation_token=continuation_token)))\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 637, in _blocking_request\n    raise RuntimeError(response.error)\nRuntimeError: Unknown process bundle instruction id '107'\n```\n\nNotice that the error is thrown on the Runner side in the GrpcStateService.\n\nExplanation\n===========\n\nWe experienced a network split of the Flink cluster which caused the job to\nfail. The logging implied a failure of the state requests right before the\nnetwork split. However, the opposite is true, the failure occured during\nshutdown of the pipeline where the state request handler has already been removed.\n\nSolution\n========\n\nEnsure that we shutdown the environment and any pending clients which may be\nprocessing pending requests."}, "afterCommit": {"oid": "7a0c82fd6a8b323bfceb0222dd3766fd14f7443b", "author": {"user": {"login": "mxm", "name": "Maximilian Michels"}}, "url": "https://github.com/apache/beam/commit/7a0c82fd6a8b323bfceb0222dd3766fd14f7443b", "committedDate": "2020-01-31T10:47:26Z", "message": "[BEAM-9132] Avoid logging misleading error messages during pipeline failure\n\nWe have observed these errors in a state-intense application:\n\n```\nError processing instruction 107. Original traceback is\nTraceback (most recent call last):\n  File \"apache_beam/runners/common.py\", line 780, in apache_beam.runners.common.DoFnRunner.process\n  File \"apache_beam/runners/common.py\", line 587, in apache_beam.runners.common.PerWindowInvoker.invoke_process\n  File \"apache_beam/runners/common.py\", line 659, in apache_beam.runners.common.PerWindowInvoker._invoke_process_per_window\n  File \"apache_beam/runners/common.py\", line 880, in apache_beam.runners.common._OutputProcessor.process_outputs\n  File \"apache_beam/runners/common.py\", line 895, in apache_beam.runners.common._OutputProcessor.process_outputs\n  File \"redacted.py\", line 56, in process\n    recent_events_map = load_recent_events_map(recent_events_state)\n  File \"redacted.py\", line 128, in _load_recent_events_map\n    items_in_recent_events_bag = list(recent_events_state.read())\n  File \"apache_beam/runners/worker/bundle_processor.py\", line 335, in __iter__\n    for elem in self.first:\n  File \"apache_beam/runners/worker/bundle_processor.py\", line 214, in __iter__\n    self._state_key, self._coder_impl, is_cached=self._is_cached)\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 692, in blocking_get\n    self._materialize_iter(state_key, coder))\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 723, in _materialize_iter\n    self._underlying.get_raw(state_key, continuation_token)\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 603, in get_raw\n    continuation_token=continuation_token)))\n  File \"apache_beam/runners/worker/sdk_worker.py\", line 637, in _blocking_request\n    raise RuntimeError(response.error)\nRuntimeError: Unknown process bundle instruction id '107'\n```\n\nNotice that the error is thrown on the Runner side in the GrpcStateService.\n\nExplanation\n===========\n\nWe experienced a network split of the Flink cluster which caused the job to\nfail. The logging implied a failure of the state requests right before the\nnetwork split. However, the opposite is true, the failure occured during\nshutdown of the pipeline where the state request handler has already been removed.\n\nSolution\n========\n\nEnsure that we shutdown the environment and any pending clients which may be\nprocessing pending requests."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzUxNDY3ODM2", "url": "https://github.com/apache/beam/pull/10694#pullrequestreview-351467836", "createdAt": "2020-01-31T12:16:41Z", "commit": {"oid": "7a0c82fd6a8b323bfceb0222dd3766fd14f7443b"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0zMVQxMjoxNjo0MlrOFkJtQA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0zMVQxMjoxNjo0MlrOFkJtQA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MzQ1MjA5Ng==", "bodyText": "I discovered another issue in this code path. ref() is not called on the client in this case. Also, unref() will never be called because the code below does not insert the call to the bundle close. close() is only ever called on unref().", "url": "https://github.com/apache/beam/pull/10694#discussion_r373452096", "createdAt": "2020-01-31T12:16:42Z", "author": {"login": "mxm"}, "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/control/DefaultJobBundleFactory.java", "diffHunk": "@@ -342,22 +343,14 @@ public RemoteBundle getBundle(\n       // TODO: Consider having BundleProcessor#newBundle take in an OutputReceiverFactory rather\n       // than constructing the receiver map here. Every bundle factory will need this.\n \n-      if (environmentExpirationMillis == 0 && !loadBalanceBundles) {\n-        return currentClient.processor.newBundle(\n-            getOutputReceivers(currentClient.processBundleDescriptor, outputReceiverFactory)\n-                .build(),\n-            stateRequestHandler,\n-            progressHandler);\n-      }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7a0c82fd6a8b323bfceb0222dd3766fd14f7443b"}, "originalPosition": 31}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3613, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}