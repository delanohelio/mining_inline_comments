{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDMyNzE5ODU1", "number": 11975, "title": "[BEAM-9198] BeamSQL aggregation analytics functionality", "bodyText": "Google Summer of Code 2020: Main PR for BEAM-9198\nStudent: John Mora - @jhnmora000\nMentor: Rui Wang - @amaliujia\nProject Link:\nLink\nDescription:\nImplement aggregation analytics functionality for Apache Beam.\nGoogle Summer of Code 2020 Proposal:\n\nProposal\n\nDesign Doc:\n\nDocument\n\nAdditional PRs:\n\nSupport for ZetaSQL\nConcept-proof implementation of Window Functions\nImplement value_nth test\n\n\nThank you for your contribution! Follow this checklist to help us incorporate your contribution quickly and easily:\n\n Choose reviewer(s) and mention them in a comment (R: @username).\n Format the pull request title like [BEAM-XXX] Fixes bug in ApproximateQuantiles, where you replace BEAM-XXX with the appropriate JIRA issue, if applicable. This will automatically link the pull request to the issue.\n Update CHANGES.md with noteworthy changes.\n If this contribution is large, please file an Apache Individual Contributor License Agreement.\n\nSee the Contributor Guide for more tips on how to make review process smoother.\nPost-Commit Tests Status (on master branch)\n\n\n\nLang\nSDK\nApex\nDataflow\nFlink\nSamza\nSpark\n\n\n\n\nGo\n\n---\n---\n\n---\n\n\n\nJava\n\n\n\n\n\n\n\n\nPython\n\n---\n\n\n---\n\n\n\nXLang\n---\n---\n---\n\n---\n---\n\n\n\nPre-Commit Tests Status (on master branch)\n\n\n\n---\nJava\nPython\nGo\nWebsite\n\n\n\n\nNon-portable\n\n\n\n\n\n\nPortable\n---\n\n---\n---\n\n\n\nSee .test-infra/jenkins/README for trigger phrase, status and link of all Jenkins jobs.", "createdAt": "2020-06-10T21:46:28Z", "url": "https://github.com/apache/beam/pull/11975", "merged": true, "mergeCommit": {"oid": "b80dc54b87e35743452d873df501dbf86222bb27"}, "closed": true, "closedAt": "2020-07-15T00:58:09Z", "author": {"login": "jhnmora000"}, "timelineItems": {"totalCount": 16, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcrF1GYgFqTQzMDE5MDc5Nw==", "endCursor": "Y3Vyc29yOnYyOpPPAAABc08q_GAH2gAyNDMyNzE5ODU1OjdlNTM2NzgyZDYxMDM4NDNkZmU2NWNjM2UzY2VkN2M4MWI1MzEyOWY=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMwMTkwNzk3", "url": "https://github.com/apache/beam/pull/11975#pullrequestreview-430190797", "createdAt": "2020-06-14T06:12:21Z", "commit": {"oid": "45d984811bf06e0e5a6d90ca28b21cebaf389f52"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNFQwNjoxMjoyMVrOGjbAvg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNFQwNjoxMjoyMVrOGjbAvg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTc5NTkwMg==", "bodyText": "I am wondering if this transform can be reused? https://github.com/apache/beam/blob/master/sdks/java/extensions/sorter/src/main/java/org/apache/beam/sdk/extensions/sorter/SortValues.java", "url": "https://github.com/apache/beam/pull/11975#discussion_r439795902", "createdAt": "2020-06-14T06:12:21Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamWindowRel.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.rel;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.BeamCostModel;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.NodeStats;\n+import org.apache.beam.sdk.extensions.sql.impl.transform.BeamBuiltinAggregations;\n+import org.apache.beam.sdk.extensions.sql.impl.utils.CalciteUtils;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.transforms.Combine;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionList;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptCluster;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptPlanner;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelTraitSet;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelFieldCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.Window;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.metadata.RelMetadataQuery;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.type.RelDataType;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexInputRef;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexLiteral;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Lists;\n+\n+public class BeamWindowRel extends Window implements BeamRelNode {\n+  public BeamWindowRel(\n+      RelOptCluster cluster,\n+      RelTraitSet traitSet,\n+      RelNode input,\n+      List<RexLiteral> constants,\n+      RelDataType rowType,\n+      List<Group> groups) {\n+    super(cluster, traitSet, input, constants, rowType, groups);\n+  }\n+\n+  @Override\n+  public PTransform<PCollectionList<Row>, PCollection<Row>> buildPTransform() {\n+    Schema outputSchema = CalciteUtils.toSchema(getRowType());\n+    final List<FieldAggregation> analyticFields =\n+        this.groups.stream()\n+            .map(\n+                anAnalyticGroup -> {\n+                  List<Integer> partitionKeysDef = anAnalyticGroup.keys.toList();\n+                  List<Integer> orderByKeys = Lists.newArrayList();\n+                  List<Boolean> orderByDirections = Lists.newArrayList();\n+                  List<Boolean> orderByNullDirections = Lists.newArrayList();\n+                  anAnalyticGroup.orderKeys.getFieldCollations().stream()\n+                      .forEach(\n+                          fc -> {\n+                            orderByKeys.add(fc.getFieldIndex());\n+                            orderByDirections.add(\n+                                fc.direction == RelFieldCollation.Direction.ASCENDING);\n+                            orderByNullDirections.add(\n+                                fc.nullDirection == RelFieldCollation.NullDirection.FIRST);\n+                          });\n+                  int lowerB = Integer.MAX_VALUE; // Unbounded by default\n+                  int upperB = Integer.MAX_VALUE; // Unbounded by default\n+                  if (anAnalyticGroup.lowerBound.isCurrentRow()) {\n+                    lowerB = 0;\n+                  } else if (anAnalyticGroup.lowerBound.isPreceding()) {\n+                    // pending\n+                  } else if (anAnalyticGroup.lowerBound.isFollowing()) {\n+                    // pending\n+                  }\n+                  if (anAnalyticGroup.upperBound.isCurrentRow()) {\n+                    upperB = 0;\n+                  } else if (anAnalyticGroup.upperBound.isPreceding()) {\n+                    // pending\n+                  } else if (anAnalyticGroup.upperBound.isFollowing()) {\n+                    // pending\n+                  }\n+                  // Assume a single input for now\n+                  final List<Integer> aggregationFields = Lists.newArrayList();\n+                  anAnalyticGroup.aggCalls.stream()\n+                      .forEach(\n+                          anAggCall -> {\n+                            anAggCall.operands.stream()\n+                                .forEach(\n+                                    anAggCallInput -> {\n+                                      aggregationFields.add(\n+                                          ((RexInputRef) anAggCallInput).getIndex());\n+                                    });\n+                          });\n+                  return new FieldAggregation(\n+                      partitionKeysDef,\n+                      orderByKeys,\n+                      orderByDirections,\n+                      orderByNullDirections,\n+                      lowerB,\n+                      upperB,\n+                      anAnalyticGroup.isRows,\n+                      aggregationFields);\n+                })\n+            .collect(toList());\n+    return new Transform(outputSchema, analyticFields);\n+  }\n+\n+  private static class FieldAggregation implements Serializable {\n+\n+    private List<Integer> partitionKeys;\n+    private List<Integer> orderKeys;\n+    private List<Boolean> orderOrientations;\n+    private List<Boolean> orderNulls;\n+    private int lowerLimit = Integer.MAX_VALUE;\n+    private int upperLimit = Integer.MAX_VALUE;\n+    private boolean rows = true;\n+    private List<Integer> inputFields;\n+    // private AggFunction  ... pending\n+\n+    public FieldAggregation(\n+        List<Integer> partitionKeys,\n+        List<Integer> orderKeys,\n+        List<Boolean> orderOrientations,\n+        List<Boolean> orderNulls,\n+        int lowerLimit,\n+        int upperLimit,\n+        boolean rows,\n+        List<Integer> fields) {\n+      this.partitionKeys = partitionKeys;\n+      this.orderKeys = orderKeys;\n+      this.orderOrientations = orderOrientations;\n+      this.orderNulls = orderNulls;\n+      this.lowerLimit = lowerLimit;\n+      this.upperLimit = upperLimit;\n+      this.rows = rows;\n+      this.inputFields = fields;\n+    }\n+  }\n+\n+  @Override\n+  public NodeStats estimateNodeStats(RelMetadataQuery mq) {\n+    NodeStats inputStat = BeamSqlRelUtils.getNodeStats(this.input, mq);\n+    return inputStat;\n+  }\n+\n+  @Override\n+  public BeamCostModel beamComputeSelfCost(RelOptPlanner planner, RelMetadataQuery mq) {\n+    NodeStats inputStat = BeamSqlRelUtils.getNodeStats(this.input, mq);\n+    float multiplier = 1f + 0.125f;\n+    return BeamCostModel.FACTORY.makeCost(\n+        inputStat.getRowCount() * multiplier, inputStat.getRate() * multiplier);\n+  }\n+\n+  private static class Transform extends PTransform<PCollectionList<Row>, PCollection<Row>> {\n+\n+    private Schema outputSchema;\n+    private List<FieldAggregation> aggFields;\n+\n+    public Transform(Schema s, List<FieldAggregation> af) {\n+      this.outputSchema = s;\n+      this.aggFields = af;\n+    }\n+\n+    @Override\n+    public PCollection<Row> expand(PCollectionList<Row> input) {\n+      PCollection<Row> r = input.get(0);\n+      for (FieldAggregation af : aggFields) {\n+        org.apache.beam.sdk.schemas.transforms.Group.ByFields<Row> myg =\n+            org.apache.beam.sdk.schemas.transforms.Group.byFieldIds(af.partitionKeys);\n+        r = r.apply(\"partitionBy\", myg);\n+        r = r.apply(\"orderBy\", ParDo.of(sortPartition(af))).setRowSchema(r.getSchema());\n+        r = r.apply(\"aggCall\", ParDo.of(aggField(outputSchema, af))).setRowSchema(outputSchema);\n+      }\n+      return r;\n+    }\n+  }\n+\n+  private static DoFn<Row, Row> aggField(\n+      final Schema outputSchema, final FieldAggregation fieldAgg) {\n+    return new DoFn<Row, Row>() {\n+      @ProcessElement\n+      public void processElement(\n+          @Element Row inputPartition, OutputReceiver<Row> out, ProcessContext c) {\n+        Collection<Row> inputPartitions = inputPartition.getArray(1); // 1 -> value\n+        List<Row> sortedRowsAsList = new ArrayList<Row>(inputPartitions);\n+        for (int idx = 0; idx < sortedRowsAsList.size(); idx++) {\n+          int lowerIndex = idx - fieldAgg.lowerLimit;\n+          int upperIndex = idx + fieldAgg.upperLimit + 1;\n+          lowerIndex = lowerIndex < 0 ? 0 : lowerIndex;\n+          upperIndex = upperIndex > sortedRowsAsList.size() ? sortedRowsAsList.size() : upperIndex;\n+          List<Row> aggRange = sortedRowsAsList.subList(lowerIndex, upperIndex);\n+\n+          // Just concept-proof\n+          // Assume that aggFun = SUM\n+          // Assume dataType = INTEGER\n+          final Combine.CombineFn<Integer, int[], Integer> aggFunction =\n+              (Combine.CombineFn<Integer, int[], Integer>)\n+                  BeamBuiltinAggregations.create(\"SUM\", Schema.FieldType.INT32);\n+          int[] aggAccumulator = aggFunction.createAccumulator();\n+\n+          // Assume a simple expression within SUM($aUniqueDirectField)\n+          final int aggFieldIndex = fieldAgg.inputFields.get(0);\n+\n+          for (Row aggRow : aggRange) {\n+            Integer valueToAgg = aggRow.getInt32(aggFieldIndex);\n+            aggFunction.addInput(aggAccumulator, valueToAgg);\n+          }\n+          Integer aggOutput = aggFunction.extractOutput(aggAccumulator);\n+          List<Object> fieldValues =\n+              Lists.newArrayListWithCapacity(sortedRowsAsList.get(idx).getFieldCount());\n+          fieldValues.addAll(sortedRowsAsList.get(idx).getValues());\n+          fieldValues.add(aggOutput);\n+          Row ou = Row.withSchema(outputSchema).addValues(fieldValues).build();\n+          out.output(ou);\n+        }\n+      }\n+    };\n+  }\n+\n+  private static DoFn<Row, Row> sortPartition(final FieldAggregation fieldAgg) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d984811bf06e0e5a6d90ca28b21cebaf389f52"}, "originalPosition": 236}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMwMTkxMzcz", "url": "https://github.com/apache/beam/pull/11975#pullrequestreview-430191373", "createdAt": "2020-06-14T06:25:00Z", "commit": {"oid": "45d984811bf06e0e5a6d90ca28b21cebaf389f52"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNFQwNjoyNTowMFrOGjbDSw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNFQwNjoyNTowMFrOGjbDSw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTc5NjU1NQ==", "bodyText": "This is nice to use schema's transforms.", "url": "https://github.com/apache/beam/pull/11975#discussion_r439796555", "createdAt": "2020-06-14T06:25:00Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamWindowRel.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.rel;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.BeamCostModel;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.NodeStats;\n+import org.apache.beam.sdk.extensions.sql.impl.transform.BeamBuiltinAggregations;\n+import org.apache.beam.sdk.extensions.sql.impl.utils.CalciteUtils;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.transforms.Combine;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionList;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptCluster;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptPlanner;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelTraitSet;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelFieldCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.Window;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.metadata.RelMetadataQuery;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.type.RelDataType;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexInputRef;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexLiteral;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Lists;\n+\n+public class BeamWindowRel extends Window implements BeamRelNode {\n+  public BeamWindowRel(\n+      RelOptCluster cluster,\n+      RelTraitSet traitSet,\n+      RelNode input,\n+      List<RexLiteral> constants,\n+      RelDataType rowType,\n+      List<Group> groups) {\n+    super(cluster, traitSet, input, constants, rowType, groups);\n+  }\n+\n+  @Override\n+  public PTransform<PCollectionList<Row>, PCollection<Row>> buildPTransform() {\n+    Schema outputSchema = CalciteUtils.toSchema(getRowType());\n+    final List<FieldAggregation> analyticFields =\n+        this.groups.stream()\n+            .map(\n+                anAnalyticGroup -> {\n+                  List<Integer> partitionKeysDef = anAnalyticGroup.keys.toList();\n+                  List<Integer> orderByKeys = Lists.newArrayList();\n+                  List<Boolean> orderByDirections = Lists.newArrayList();\n+                  List<Boolean> orderByNullDirections = Lists.newArrayList();\n+                  anAnalyticGroup.orderKeys.getFieldCollations().stream()\n+                      .forEach(\n+                          fc -> {\n+                            orderByKeys.add(fc.getFieldIndex());\n+                            orderByDirections.add(\n+                                fc.direction == RelFieldCollation.Direction.ASCENDING);\n+                            orderByNullDirections.add(\n+                                fc.nullDirection == RelFieldCollation.NullDirection.FIRST);\n+                          });\n+                  int lowerB = Integer.MAX_VALUE; // Unbounded by default\n+                  int upperB = Integer.MAX_VALUE; // Unbounded by default\n+                  if (anAnalyticGroup.lowerBound.isCurrentRow()) {\n+                    lowerB = 0;\n+                  } else if (anAnalyticGroup.lowerBound.isPreceding()) {\n+                    // pending\n+                  } else if (anAnalyticGroup.lowerBound.isFollowing()) {\n+                    // pending\n+                  }\n+                  if (anAnalyticGroup.upperBound.isCurrentRow()) {\n+                    upperB = 0;\n+                  } else if (anAnalyticGroup.upperBound.isPreceding()) {\n+                    // pending\n+                  } else if (anAnalyticGroup.upperBound.isFollowing()) {\n+                    // pending\n+                  }\n+                  // Assume a single input for now\n+                  final List<Integer> aggregationFields = Lists.newArrayList();\n+                  anAnalyticGroup.aggCalls.stream()\n+                      .forEach(\n+                          anAggCall -> {\n+                            anAggCall.operands.stream()\n+                                .forEach(\n+                                    anAggCallInput -> {\n+                                      aggregationFields.add(\n+                                          ((RexInputRef) anAggCallInput).getIndex());\n+                                    });\n+                          });\n+                  return new FieldAggregation(\n+                      partitionKeysDef,\n+                      orderByKeys,\n+                      orderByDirections,\n+                      orderByNullDirections,\n+                      lowerB,\n+                      upperB,\n+                      anAnalyticGroup.isRows,\n+                      aggregationFields);\n+                })\n+            .collect(toList());\n+    return new Transform(outputSchema, analyticFields);\n+  }\n+\n+  private static class FieldAggregation implements Serializable {\n+\n+    private List<Integer> partitionKeys;\n+    private List<Integer> orderKeys;\n+    private List<Boolean> orderOrientations;\n+    private List<Boolean> orderNulls;\n+    private int lowerLimit = Integer.MAX_VALUE;\n+    private int upperLimit = Integer.MAX_VALUE;\n+    private boolean rows = true;\n+    private List<Integer> inputFields;\n+    // private AggFunction  ... pending\n+\n+    public FieldAggregation(\n+        List<Integer> partitionKeys,\n+        List<Integer> orderKeys,\n+        List<Boolean> orderOrientations,\n+        List<Boolean> orderNulls,\n+        int lowerLimit,\n+        int upperLimit,\n+        boolean rows,\n+        List<Integer> fields) {\n+      this.partitionKeys = partitionKeys;\n+      this.orderKeys = orderKeys;\n+      this.orderOrientations = orderOrientations;\n+      this.orderNulls = orderNulls;\n+      this.lowerLimit = lowerLimit;\n+      this.upperLimit = upperLimit;\n+      this.rows = rows;\n+      this.inputFields = fields;\n+    }\n+  }\n+\n+  @Override\n+  public NodeStats estimateNodeStats(RelMetadataQuery mq) {\n+    NodeStats inputStat = BeamSqlRelUtils.getNodeStats(this.input, mq);\n+    return inputStat;\n+  }\n+\n+  @Override\n+  public BeamCostModel beamComputeSelfCost(RelOptPlanner planner, RelMetadataQuery mq) {\n+    NodeStats inputStat = BeamSqlRelUtils.getNodeStats(this.input, mq);\n+    float multiplier = 1f + 0.125f;\n+    return BeamCostModel.FACTORY.makeCost(\n+        inputStat.getRowCount() * multiplier, inputStat.getRate() * multiplier);\n+  }\n+\n+  private static class Transform extends PTransform<PCollectionList<Row>, PCollection<Row>> {\n+\n+    private Schema outputSchema;\n+    private List<FieldAggregation> aggFields;\n+\n+    public Transform(Schema s, List<FieldAggregation> af) {\n+      this.outputSchema = s;\n+      this.aggFields = af;\n+    }\n+\n+    @Override\n+    public PCollection<Row> expand(PCollectionList<Row> input) {\n+      PCollection<Row> r = input.get(0);\n+      for (FieldAggregation af : aggFields) {\n+        org.apache.beam.sdk.schemas.transforms.Group.ByFields<Row> myg =\n+            org.apache.beam.sdk.schemas.transforms.Group.byFieldIds(af.partitionKeys);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d984811bf06e0e5a6d90ca28b21cebaf389f52"}, "originalPosition": 185}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMwMTkxNDgw", "url": "https://github.com/apache/beam/pull/11975#pullrequestreview-430191480", "createdAt": "2020-06-14T06:26:56Z", "commit": {"oid": "45d984811bf06e0e5a6d90ca28b21cebaf389f52"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNFQwNjoyNjo1NlrOGjbDyg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNFQwNjoyNjo1NlrOGjbDyg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTc5NjY4Mg==", "bodyText": "Interesting. I didn't know that there is no aggregate calls in WindowRel.\nDo you know where those calls are defined?", "url": "https://github.com/apache/beam/pull/11975#discussion_r439796682", "createdAt": "2020-06-14T06:26:56Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamWindowRel.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.rel;\n+\n+import static java.util.stream.Collectors.toList;\n+\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.BeamCostModel;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.NodeStats;\n+import org.apache.beam.sdk.extensions.sql.impl.transform.BeamBuiltinAggregations;\n+import org.apache.beam.sdk.extensions.sql.impl.utils.CalciteUtils;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.transforms.Combine;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionList;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptCluster;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptPlanner;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelTraitSet;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelFieldCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.Window;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.metadata.RelMetadataQuery;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.type.RelDataType;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexInputRef;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexLiteral;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Lists;\n+\n+public class BeamWindowRel extends Window implements BeamRelNode {\n+  public BeamWindowRel(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d984811bf06e0e5a6d90ca28b21cebaf389f52"}, "originalPosition": 52}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDMwMTkxNTU5", "url": "https://github.com/apache/beam/pull/11975#pullrequestreview-430191559", "createdAt": "2020-06-14T06:28:08Z", "commit": {"oid": "45d984811bf06e0e5a6d90ca28b21cebaf389f52"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNFQwNjoyODowOFrOGjbEKA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNFQwNjoyODowOFrOGjbEKA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzOTc5Njc3Ng==", "bodyText": "Can you paste logical plan of this query in to comments? Just to help me better understand what Calcite produces at least on Logical plan level.", "url": "https://github.com/apache/beam/pull/11975#discussion_r439796776", "createdAt": "2020-06-14T06:28:08Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/BeamAnalyticFunctionsExperimentTest.java", "diffHunk": "@@ -0,0 +1,187 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql;\n+\n+import java.util.Iterator;\n+import java.util.List;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.testing.PAssert;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.Row;\n+import org.junit.Ignore;\n+import org.junit.Test;\n+\n+/**\n+ * A simple Analytic Functions experiment for BeamSQL created in order to understand the query\n+ * processing workflow of BeamSQL and Calcite.\n+ */\n+public class BeamAnalyticFunctionsExperimentTest extends BeamSqlDslBase {\n+\n+  /**\n+   * Table schema and data taken from\n+   * https://cloud.google.com/bigquery/docs/reference/standard-sql/analytic-function-concepts#produce_table\n+   *\n+   * <p>Compute a cumulative sum query taken from\n+   * https://cloud.google.com/bigquery/docs/reference/standard-sql/analytic-function-concepts#compute_a_cumulative_sum\n+   */\n+  @Test\n+  public void testOverCumulativeSum() throws Exception {\n+    pipeline.enableAbandonedNodeEnforcement(false);\n+    Schema schema =\n+        Schema.builder()\n+            .addStringField(\"item\")\n+            .addStringField(\"category\")\n+            .addInt32Field(\"purchases\")\n+            .build();\n+    PCollection<Row> inputRows =\n+        pipeline\n+            .apply(\n+                Create.of(\n+                    TestUtils.rowsBuilderOf(schema)\n+                        .addRows(\n+                            \"kale\",\n+                            \"vegetable\",\n+                            23,\n+                            \"orange\",\n+                            \"fruit\",\n+                            2,\n+                            \"cabbage\",\n+                            \"vegetable\",\n+                            9,\n+                            \"apple\",\n+                            \"fruit\",\n+                            8,\n+                            \"leek\",\n+                            \"vegetable\",\n+                            2,\n+                            \"lettuce\",\n+                            \"vegetable\",\n+                            10)\n+                        .getRows()))\n+            .setRowSchema(schema);\n+    String sql =\n+        \"SELECT item, purchases, category, sum(purchases) over \"\n+            + \"(PARTITION BY category ORDER BY purchases ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)\"\n+            + \" as total_purchases  FROM PCOLLECTION\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "45d984811bf06e0e5a6d90ca28b21cebaf389f52"}, "originalPosition": 81}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM2MjA4NTk5", "url": "https://github.com/apache/beam/pull/11975#pullrequestreview-436208599", "createdAt": "2020-06-23T22:40:38Z", "commit": {"oid": "c05fca76e7fa2e2c53a3e392dc083d543fe4c0ad"}, "state": "COMMENTED", "comments": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QyMjo0MDozOVrOGn9BAA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yM1QyMjo1ODoyMVrOGn9X4A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU0NzMyOA==", "bodyText": "Add java doc for classes (java doc means comments starts with /* and ends with */", "url": "https://github.com/apache/beam/pull/11975#discussion_r444547328", "createdAt": "2020-06-23T22:40:39Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamWindowRel.java", "diffHunk": "@@ -0,0 +1,317 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.rel;\n+\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.BeamCostModel;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.NodeStats;\n+import org.apache.beam.sdk.extensions.sql.impl.transform.agg.AggregationCombineFnAdapter;\n+import org.apache.beam.sdk.extensions.sql.impl.utils.CalciteUtils;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.transforms.Combine;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionList;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptCluster;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptPlanner;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelTraitSet;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelFieldCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.AggregateCall;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.Window;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.metadata.RelMetadataQuery;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.type.RelDataType;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexLiteral;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Lists;\n+\n+public class BeamWindowRel extends Window implements BeamRelNode {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c05fca76e7fa2e2c53a3e392dc083d543fe4c0ad"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU0NzcwNQ==", "bodyText": "Add a test that includes DESC for ORDER BY?", "url": "https://github.com/apache/beam/pull/11975#discussion_r444547705", "createdAt": "2020-06-23T22:41:46Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamWindowRel.java", "diffHunk": "@@ -0,0 +1,317 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.rel;\n+\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.BeamCostModel;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.NodeStats;\n+import org.apache.beam.sdk.extensions.sql.impl.transform.agg.AggregationCombineFnAdapter;\n+import org.apache.beam.sdk.extensions.sql.impl.utils.CalciteUtils;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.transforms.Combine;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionList;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptCluster;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptPlanner;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelTraitSet;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelFieldCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.AggregateCall;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.Window;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.metadata.RelMetadataQuery;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.type.RelDataType;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexLiteral;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Lists;\n+\n+public class BeamWindowRel extends Window implements BeamRelNode {\n+  public BeamWindowRel(\n+      RelOptCluster cluster,\n+      RelTraitSet traitSet,\n+      RelNode input,\n+      List<RexLiteral> constants,\n+      RelDataType rowType,\n+      List<Group> groups) {\n+    super(cluster, traitSet, input, constants, rowType, groups);\n+  }\n+\n+  @Override\n+  public PTransform<PCollectionList<Row>, PCollection<Row>> buildPTransform() {\n+    Schema outputSchema = CalciteUtils.toSchema(getRowType());\n+    final List<FieldAggregation> analyticFields = Lists.newArrayList();\n+    this.groups.stream()\n+        .forEach(\n+            anAnalyticGroup -> {\n+              List<Integer> partitionKeysDef = anAnalyticGroup.keys.toList();\n+              List<Integer> orderByKeys = Lists.newArrayList();\n+              List<Boolean> orderByDirections = Lists.newArrayList();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c05fca76e7fa2e2c53a3e392dc083d543fe4c0ad"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU0ODE1NA==", "bodyText": "Add a test or add a checkArgument to disable (either one works for me) for NULL last or NULL first in ORDER BY.\nFor NULL handling, depends on you, you can leave it for future PRs.", "url": "https://github.com/apache/beam/pull/11975#discussion_r444548154", "createdAt": "2020-06-23T22:43:07Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamWindowRel.java", "diffHunk": "@@ -0,0 +1,317 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.rel;\n+\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.BeamCostModel;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.NodeStats;\n+import org.apache.beam.sdk.extensions.sql.impl.transform.agg.AggregationCombineFnAdapter;\n+import org.apache.beam.sdk.extensions.sql.impl.utils.CalciteUtils;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.transforms.Combine;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionList;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptCluster;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptPlanner;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelTraitSet;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelFieldCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.AggregateCall;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.Window;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.metadata.RelMetadataQuery;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.type.RelDataType;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexLiteral;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Lists;\n+\n+public class BeamWindowRel extends Window implements BeamRelNode {\n+  public BeamWindowRel(\n+      RelOptCluster cluster,\n+      RelTraitSet traitSet,\n+      RelNode input,\n+      List<RexLiteral> constants,\n+      RelDataType rowType,\n+      List<Group> groups) {\n+    super(cluster, traitSet, input, constants, rowType, groups);\n+  }\n+\n+  @Override\n+  public PTransform<PCollectionList<Row>, PCollection<Row>> buildPTransform() {\n+    Schema outputSchema = CalciteUtils.toSchema(getRowType());\n+    final List<FieldAggregation> analyticFields = Lists.newArrayList();\n+    this.groups.stream()\n+        .forEach(\n+            anAnalyticGroup -> {\n+              List<Integer> partitionKeysDef = anAnalyticGroup.keys.toList();\n+              List<Integer> orderByKeys = Lists.newArrayList();\n+              List<Boolean> orderByDirections = Lists.newArrayList();\n+              List<Boolean> orderByNullDirections = Lists.newArrayList();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c05fca76e7fa2e2c53a3e392dc083d543fe4c0ad"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU0OTMxNw==", "bodyText": "Better to use checkArgument to stop execution when you are seeing an unsupported case.\nSee: https://www.baeldung.com/guava-preconditions", "url": "https://github.com/apache/beam/pull/11975#discussion_r444549317", "createdAt": "2020-06-23T22:46:29Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamWindowRel.java", "diffHunk": "@@ -0,0 +1,317 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.rel;\n+\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.BeamCostModel;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.NodeStats;\n+import org.apache.beam.sdk.extensions.sql.impl.transform.agg.AggregationCombineFnAdapter;\n+import org.apache.beam.sdk.extensions.sql.impl.utils.CalciteUtils;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.transforms.Combine;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionList;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptCluster;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptPlanner;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelTraitSet;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelFieldCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.AggregateCall;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.Window;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.metadata.RelMetadataQuery;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.type.RelDataType;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexLiteral;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Lists;\n+\n+public class BeamWindowRel extends Window implements BeamRelNode {\n+  public BeamWindowRel(\n+      RelOptCluster cluster,\n+      RelTraitSet traitSet,\n+      RelNode input,\n+      List<RexLiteral> constants,\n+      RelDataType rowType,\n+      List<Group> groups) {\n+    super(cluster, traitSet, input, constants, rowType, groups);\n+  }\n+\n+  @Override\n+  public PTransform<PCollectionList<Row>, PCollection<Row>> buildPTransform() {\n+    Schema outputSchema = CalciteUtils.toSchema(getRowType());\n+    final List<FieldAggregation> analyticFields = Lists.newArrayList();\n+    this.groups.stream()\n+        .forEach(\n+            anAnalyticGroup -> {\n+              List<Integer> partitionKeysDef = anAnalyticGroup.keys.toList();\n+              List<Integer> orderByKeys = Lists.newArrayList();\n+              List<Boolean> orderByDirections = Lists.newArrayList();\n+              List<Boolean> orderByNullDirections = Lists.newArrayList();\n+              anAnalyticGroup.orderKeys.getFieldCollations().stream()\n+                  .forEach(\n+                      fc -> {\n+                        orderByKeys.add(fc.getFieldIndex());\n+                        orderByDirections.add(\n+                            fc.direction == RelFieldCollation.Direction.ASCENDING);\n+                        orderByNullDirections.add(\n+                            fc.nullDirection == RelFieldCollation.NullDirection.FIRST);\n+                      });\n+              int lowerB = Integer.MAX_VALUE; // Unbounded by default\n+              int upperB = Integer.MAX_VALUE; // Unbounded by default\n+              if (anAnalyticGroup.lowerBound.isCurrentRow()) {\n+                lowerB = 0;\n+              } else if (anAnalyticGroup.lowerBound.isPreceding()) {\n+                // pending", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c05fca76e7fa2e2c53a3e392dc083d543fe4c0ad"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU0OTM1NQ==", "bodyText": "Same", "url": "https://github.com/apache/beam/pull/11975#discussion_r444549355", "createdAt": "2020-06-23T22:46:38Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamWindowRel.java", "diffHunk": "@@ -0,0 +1,317 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.rel;\n+\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.BeamCostModel;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.NodeStats;\n+import org.apache.beam.sdk.extensions.sql.impl.transform.agg.AggregationCombineFnAdapter;\n+import org.apache.beam.sdk.extensions.sql.impl.utils.CalciteUtils;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.transforms.Combine;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionList;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptCluster;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptPlanner;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelTraitSet;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelFieldCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.AggregateCall;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.Window;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.metadata.RelMetadataQuery;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.type.RelDataType;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexLiteral;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Lists;\n+\n+public class BeamWindowRel extends Window implements BeamRelNode {\n+  public BeamWindowRel(\n+      RelOptCluster cluster,\n+      RelTraitSet traitSet,\n+      RelNode input,\n+      List<RexLiteral> constants,\n+      RelDataType rowType,\n+      List<Group> groups) {\n+    super(cluster, traitSet, input, constants, rowType, groups);\n+  }\n+\n+  @Override\n+  public PTransform<PCollectionList<Row>, PCollection<Row>> buildPTransform() {\n+    Schema outputSchema = CalciteUtils.toSchema(getRowType());\n+    final List<FieldAggregation> analyticFields = Lists.newArrayList();\n+    this.groups.stream()\n+        .forEach(\n+            anAnalyticGroup -> {\n+              List<Integer> partitionKeysDef = anAnalyticGroup.keys.toList();\n+              List<Integer> orderByKeys = Lists.newArrayList();\n+              List<Boolean> orderByDirections = Lists.newArrayList();\n+              List<Boolean> orderByNullDirections = Lists.newArrayList();\n+              anAnalyticGroup.orderKeys.getFieldCollations().stream()\n+                  .forEach(\n+                      fc -> {\n+                        orderByKeys.add(fc.getFieldIndex());\n+                        orderByDirections.add(\n+                            fc.direction == RelFieldCollation.Direction.ASCENDING);\n+                        orderByNullDirections.add(\n+                            fc.nullDirection == RelFieldCollation.NullDirection.FIRST);\n+                      });\n+              int lowerB = Integer.MAX_VALUE; // Unbounded by default\n+              int upperB = Integer.MAX_VALUE; // Unbounded by default\n+              if (anAnalyticGroup.lowerBound.isCurrentRow()) {\n+                lowerB = 0;\n+              } else if (anAnalyticGroup.lowerBound.isPreceding()) {\n+                // pending\n+              } else if (anAnalyticGroup.lowerBound.isFollowing()) {\n+                // pending", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c05fca76e7fa2e2c53a3e392dc083d543fe4c0ad"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU0OTM5OQ==", "bodyText": "Same", "url": "https://github.com/apache/beam/pull/11975#discussion_r444549399", "createdAt": "2020-06-23T22:46:45Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamWindowRel.java", "diffHunk": "@@ -0,0 +1,317 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.rel;\n+\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.BeamCostModel;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.NodeStats;\n+import org.apache.beam.sdk.extensions.sql.impl.transform.agg.AggregationCombineFnAdapter;\n+import org.apache.beam.sdk.extensions.sql.impl.utils.CalciteUtils;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.transforms.Combine;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionList;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptCluster;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptPlanner;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelTraitSet;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelFieldCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.AggregateCall;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.Window;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.metadata.RelMetadataQuery;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.type.RelDataType;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexLiteral;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Lists;\n+\n+public class BeamWindowRel extends Window implements BeamRelNode {\n+  public BeamWindowRel(\n+      RelOptCluster cluster,\n+      RelTraitSet traitSet,\n+      RelNode input,\n+      List<RexLiteral> constants,\n+      RelDataType rowType,\n+      List<Group> groups) {\n+    super(cluster, traitSet, input, constants, rowType, groups);\n+  }\n+\n+  @Override\n+  public PTransform<PCollectionList<Row>, PCollection<Row>> buildPTransform() {\n+    Schema outputSchema = CalciteUtils.toSchema(getRowType());\n+    final List<FieldAggregation> analyticFields = Lists.newArrayList();\n+    this.groups.stream()\n+        .forEach(\n+            anAnalyticGroup -> {\n+              List<Integer> partitionKeysDef = anAnalyticGroup.keys.toList();\n+              List<Integer> orderByKeys = Lists.newArrayList();\n+              List<Boolean> orderByDirections = Lists.newArrayList();\n+              List<Boolean> orderByNullDirections = Lists.newArrayList();\n+              anAnalyticGroup.orderKeys.getFieldCollations().stream()\n+                  .forEach(\n+                      fc -> {\n+                        orderByKeys.add(fc.getFieldIndex());\n+                        orderByDirections.add(\n+                            fc.direction == RelFieldCollation.Direction.ASCENDING);\n+                        orderByNullDirections.add(\n+                            fc.nullDirection == RelFieldCollation.NullDirection.FIRST);\n+                      });\n+              int lowerB = Integer.MAX_VALUE; // Unbounded by default\n+              int upperB = Integer.MAX_VALUE; // Unbounded by default\n+              if (anAnalyticGroup.lowerBound.isCurrentRow()) {\n+                lowerB = 0;\n+              } else if (anAnalyticGroup.lowerBound.isPreceding()) {\n+                // pending\n+              } else if (anAnalyticGroup.lowerBound.isFollowing()) {\n+                // pending\n+              }\n+              if (anAnalyticGroup.upperBound.isCurrentRow()) {\n+                upperB = 0;\n+              } else if (anAnalyticGroup.upperBound.isPreceding()) {\n+                // pending", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c05fca76e7fa2e2c53a3e392dc083d543fe4c0ad"}, "originalPosition": 92}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU0OTQyNw==", "bodyText": "Same", "url": "https://github.com/apache/beam/pull/11975#discussion_r444549427", "createdAt": "2020-06-23T22:46:49Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamWindowRel.java", "diffHunk": "@@ -0,0 +1,317 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.rel;\n+\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.BeamCostModel;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.NodeStats;\n+import org.apache.beam.sdk.extensions.sql.impl.transform.agg.AggregationCombineFnAdapter;\n+import org.apache.beam.sdk.extensions.sql.impl.utils.CalciteUtils;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.transforms.Combine;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionList;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptCluster;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptPlanner;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelTraitSet;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelFieldCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.AggregateCall;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.Window;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.metadata.RelMetadataQuery;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.type.RelDataType;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexLiteral;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Lists;\n+\n+public class BeamWindowRel extends Window implements BeamRelNode {\n+  public BeamWindowRel(\n+      RelOptCluster cluster,\n+      RelTraitSet traitSet,\n+      RelNode input,\n+      List<RexLiteral> constants,\n+      RelDataType rowType,\n+      List<Group> groups) {\n+    super(cluster, traitSet, input, constants, rowType, groups);\n+  }\n+\n+  @Override\n+  public PTransform<PCollectionList<Row>, PCollection<Row>> buildPTransform() {\n+    Schema outputSchema = CalciteUtils.toSchema(getRowType());\n+    final List<FieldAggregation> analyticFields = Lists.newArrayList();\n+    this.groups.stream()\n+        .forEach(\n+            anAnalyticGroup -> {\n+              List<Integer> partitionKeysDef = anAnalyticGroup.keys.toList();\n+              List<Integer> orderByKeys = Lists.newArrayList();\n+              List<Boolean> orderByDirections = Lists.newArrayList();\n+              List<Boolean> orderByNullDirections = Lists.newArrayList();\n+              anAnalyticGroup.orderKeys.getFieldCollations().stream()\n+                  .forEach(\n+                      fc -> {\n+                        orderByKeys.add(fc.getFieldIndex());\n+                        orderByDirections.add(\n+                            fc.direction == RelFieldCollation.Direction.ASCENDING);\n+                        orderByNullDirections.add(\n+                            fc.nullDirection == RelFieldCollation.NullDirection.FIRST);\n+                      });\n+              int lowerB = Integer.MAX_VALUE; // Unbounded by default\n+              int upperB = Integer.MAX_VALUE; // Unbounded by default\n+              if (anAnalyticGroup.lowerBound.isCurrentRow()) {\n+                lowerB = 0;\n+              } else if (anAnalyticGroup.lowerBound.isPreceding()) {\n+                // pending\n+              } else if (anAnalyticGroup.lowerBound.isFollowing()) {\n+                // pending\n+              }\n+              if (anAnalyticGroup.upperBound.isCurrentRow()) {\n+                upperB = 0;\n+              } else if (anAnalyticGroup.upperBound.isPreceding()) {\n+                // pending\n+              } else if (anAnalyticGroup.upperBound.isFollowing()) {\n+                // pending", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c05fca76e7fa2e2c53a3e392dc083d543fe4c0ad"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU0OTc1Mg==", "bodyText": "Based on your implementation below, it will be really awesome that you add what is supported or what are constrains. Then you can gradually update this java doc once you add new features.", "url": "https://github.com/apache/beam/pull/11975#discussion_r444549752", "createdAt": "2020-06-23T22:47:46Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamWindowRel.java", "diffHunk": "@@ -0,0 +1,317 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.rel;\n+\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.BeamCostModel;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.NodeStats;\n+import org.apache.beam.sdk.extensions.sql.impl.transform.agg.AggregationCombineFnAdapter;\n+import org.apache.beam.sdk.extensions.sql.impl.utils.CalciteUtils;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.transforms.Combine;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionList;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptCluster;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptPlanner;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelTraitSet;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelFieldCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.AggregateCall;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.Window;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.metadata.RelMetadataQuery;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.type.RelDataType;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexLiteral;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Lists;\n+\n+public class BeamWindowRel extends Window implements BeamRelNode {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU0NzMyOA=="}, "originalCommit": {"oid": "c05fca76e7fa2e2c53a3e392dc083d543fe4c0ad"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU1MDA5Nw==", "bodyText": "Even though you will stop executions on some unsupported cases, I think it is still ok to keep this class definition (e.g. no need to remove those unused field).", "url": "https://github.com/apache/beam/pull/11975#discussion_r444550097", "createdAt": "2020-06-23T22:48:52Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamWindowRel.java", "diffHunk": "@@ -0,0 +1,317 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.rel;\n+\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.BeamCostModel;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.NodeStats;\n+import org.apache.beam.sdk.extensions.sql.impl.transform.agg.AggregationCombineFnAdapter;\n+import org.apache.beam.sdk.extensions.sql.impl.utils.CalciteUtils;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.transforms.Combine;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionList;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptCluster;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptPlanner;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelTraitSet;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelFieldCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.AggregateCall;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.Window;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.metadata.RelMetadataQuery;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.type.RelDataType;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexLiteral;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Lists;\n+\n+public class BeamWindowRel extends Window implements BeamRelNode {\n+  public BeamWindowRel(\n+      RelOptCluster cluster,\n+      RelTraitSet traitSet,\n+      RelNode input,\n+      List<RexLiteral> constants,\n+      RelDataType rowType,\n+      List<Group> groups) {\n+    super(cluster, traitSet, input, constants, rowType, groups);\n+  }\n+\n+  @Override\n+  public PTransform<PCollectionList<Row>, PCollection<Row>> buildPTransform() {\n+    Schema outputSchema = CalciteUtils.toSchema(getRowType());\n+    final List<FieldAggregation> analyticFields = Lists.newArrayList();\n+    this.groups.stream()\n+        .forEach(\n+            anAnalyticGroup -> {\n+              List<Integer> partitionKeysDef = anAnalyticGroup.keys.toList();\n+              List<Integer> orderByKeys = Lists.newArrayList();\n+              List<Boolean> orderByDirections = Lists.newArrayList();\n+              List<Boolean> orderByNullDirections = Lists.newArrayList();\n+              anAnalyticGroup.orderKeys.getFieldCollations().stream()\n+                  .forEach(\n+                      fc -> {\n+                        orderByKeys.add(fc.getFieldIndex());\n+                        orderByDirections.add(\n+                            fc.direction == RelFieldCollation.Direction.ASCENDING);\n+                        orderByNullDirections.add(\n+                            fc.nullDirection == RelFieldCollation.NullDirection.FIRST);\n+                      });\n+              int lowerB = Integer.MAX_VALUE; // Unbounded by default\n+              int upperB = Integer.MAX_VALUE; // Unbounded by default\n+              if (anAnalyticGroup.lowerBound.isCurrentRow()) {\n+                lowerB = 0;\n+              } else if (anAnalyticGroup.lowerBound.isPreceding()) {\n+                // pending\n+              } else if (anAnalyticGroup.lowerBound.isFollowing()) {\n+                // pending\n+              }\n+              if (anAnalyticGroup.upperBound.isCurrentRow()) {\n+                upperB = 0;\n+              } else if (anAnalyticGroup.upperBound.isPreceding()) {\n+                // pending\n+              } else if (anAnalyticGroup.upperBound.isFollowing()) {\n+                // pending\n+              }\n+              final int lowerBFinal = lowerB;\n+              final int upperBFinal = upperB;\n+              List<AggregateCall> aggregateCalls = anAnalyticGroup.getAggregateCalls(this);\n+              aggregateCalls.stream()\n+                  .forEach(\n+                      anAggCall -> {\n+                        List<Integer> argList = anAggCall.getArgList();\n+                        Schema.Field field =\n+                            CalciteUtils.toField(anAggCall.getName(), anAggCall.getType());\n+                        Combine.CombineFn combineFn =\n+                            AggregationCombineFnAdapter.createCombineFn(\n+                                anAggCall, field, anAggCall.getAggregation().getName());\n+                        FieldAggregation fieldAggregation =\n+                            new FieldAggregation(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c05fca76e7fa2e2c53a3e392dc083d543fe4c0ad"}, "originalPosition": 109}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU1MDI5Mw==", "bodyText": "Add a function java doc to describe your choice of cost and why.", "url": "https://github.com/apache/beam/pull/11975#discussion_r444550293", "createdAt": "2020-06-23T22:49:29Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamWindowRel.java", "diffHunk": "@@ -0,0 +1,317 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.rel;\n+\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.BeamCostModel;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.NodeStats;\n+import org.apache.beam.sdk.extensions.sql.impl.transform.agg.AggregationCombineFnAdapter;\n+import org.apache.beam.sdk.extensions.sql.impl.utils.CalciteUtils;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.transforms.Combine;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionList;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptCluster;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptPlanner;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelTraitSet;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelFieldCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.AggregateCall;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.Window;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.metadata.RelMetadataQuery;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.type.RelDataType;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexLiteral;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Lists;\n+\n+public class BeamWindowRel extends Window implements BeamRelNode {\n+  public BeamWindowRel(\n+      RelOptCluster cluster,\n+      RelTraitSet traitSet,\n+      RelNode input,\n+      List<RexLiteral> constants,\n+      RelDataType rowType,\n+      List<Group> groups) {\n+    super(cluster, traitSet, input, constants, rowType, groups);\n+  }\n+\n+  @Override\n+  public PTransform<PCollectionList<Row>, PCollection<Row>> buildPTransform() {\n+    Schema outputSchema = CalciteUtils.toSchema(getRowType());\n+    final List<FieldAggregation> analyticFields = Lists.newArrayList();\n+    this.groups.stream()\n+        .forEach(\n+            anAnalyticGroup -> {\n+              List<Integer> partitionKeysDef = anAnalyticGroup.keys.toList();\n+              List<Integer> orderByKeys = Lists.newArrayList();\n+              List<Boolean> orderByDirections = Lists.newArrayList();\n+              List<Boolean> orderByNullDirections = Lists.newArrayList();\n+              anAnalyticGroup.orderKeys.getFieldCollations().stream()\n+                  .forEach(\n+                      fc -> {\n+                        orderByKeys.add(fc.getFieldIndex());\n+                        orderByDirections.add(\n+                            fc.direction == RelFieldCollation.Direction.ASCENDING);\n+                        orderByNullDirections.add(\n+                            fc.nullDirection == RelFieldCollation.NullDirection.FIRST);\n+                      });\n+              int lowerB = Integer.MAX_VALUE; // Unbounded by default\n+              int upperB = Integer.MAX_VALUE; // Unbounded by default\n+              if (anAnalyticGroup.lowerBound.isCurrentRow()) {\n+                lowerB = 0;\n+              } else if (anAnalyticGroup.lowerBound.isPreceding()) {\n+                // pending\n+              } else if (anAnalyticGroup.lowerBound.isFollowing()) {\n+                // pending\n+              }\n+              if (anAnalyticGroup.upperBound.isCurrentRow()) {\n+                upperB = 0;\n+              } else if (anAnalyticGroup.upperBound.isPreceding()) {\n+                // pending\n+              } else if (anAnalyticGroup.upperBound.isFollowing()) {\n+                // pending\n+              }\n+              final int lowerBFinal = lowerB;\n+              final int upperBFinal = upperB;\n+              List<AggregateCall> aggregateCalls = anAnalyticGroup.getAggregateCalls(this);\n+              aggregateCalls.stream()\n+                  .forEach(\n+                      anAggCall -> {\n+                        List<Integer> argList = anAggCall.getArgList();\n+                        Schema.Field field =\n+                            CalciteUtils.toField(anAggCall.getName(), anAggCall.getType());\n+                        Combine.CombineFn combineFn =\n+                            AggregationCombineFnAdapter.createCombineFn(\n+                                anAggCall, field, anAggCall.getAggregation().getName());\n+                        FieldAggregation fieldAggregation =\n+                            new FieldAggregation(\n+                                partitionKeysDef,\n+                                orderByKeys,\n+                                orderByDirections,\n+                                orderByNullDirections,\n+                                lowerBFinal,\n+                                upperBFinal,\n+                                anAnalyticGroup.isRows,\n+                                argList,\n+                                combineFn,\n+                                field);\n+                        analyticFields.add(fieldAggregation);\n+                      });\n+            });\n+\n+    return new Transform(outputSchema, analyticFields);\n+  }\n+\n+  private static class FieldAggregation implements Serializable {\n+\n+    private List<Integer> partitionKeys;\n+    private List<Integer> orderKeys;\n+    private List<Boolean> orderOrientations;\n+    private List<Boolean> orderNulls;\n+    private int lowerLimit = Integer.MAX_VALUE;\n+    private int upperLimit = Integer.MAX_VALUE;\n+    private boolean rows = true;\n+    private List<Integer> inputFields;\n+    private Combine.CombineFn combineFn;\n+    private Schema.Field outputField;\n+\n+    public FieldAggregation(\n+        List<Integer> partitionKeys,\n+        List<Integer> orderKeys,\n+        List<Boolean> orderOrientations,\n+        List<Boolean> orderNulls,\n+        int lowerLimit,\n+        int upperLimit,\n+        boolean rows,\n+        List<Integer> inputFields,\n+        Combine.CombineFn combineFn,\n+        Schema.Field outputField) {\n+      this.partitionKeys = partitionKeys;\n+      this.orderKeys = orderKeys;\n+      this.orderOrientations = orderOrientations;\n+      this.orderNulls = orderNulls;\n+      this.lowerLimit = lowerLimit;\n+      this.upperLimit = upperLimit;\n+      this.rows = rows;\n+      this.inputFields = inputFields;\n+      this.combineFn = combineFn;\n+      this.outputField = outputField;\n+    }\n+  }\n+\n+  @Override\n+  public NodeStats estimateNodeStats(RelMetadataQuery mq) {\n+    NodeStats inputStat = BeamSqlRelUtils.getNodeStats(this.input, mq);\n+    return inputStat;\n+  }\n+\n+  @Override\n+  public BeamCostModel beamComputeSelfCost(RelOptPlanner planner, RelMetadataQuery mq) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c05fca76e7fa2e2c53a3e392dc083d543fe4c0ad"}, "originalPosition": 171}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU1MjM5MQ==", "bodyText": "The mock key generation here could be simplified by, something like\n              windowedStream\n                  .apply(WithKeys.of(\"dummy\"))\n                  .apply(GroupByKey.create())\n\nnote that maybe do not for many schema manipulation.", "url": "https://github.com/apache/beam/pull/11975#discussion_r444552391", "createdAt": "2020-06-23T22:55:48Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamWindowRel.java", "diffHunk": "@@ -0,0 +1,317 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.rel;\n+\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.BeamCostModel;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.NodeStats;\n+import org.apache.beam.sdk.extensions.sql.impl.transform.agg.AggregationCombineFnAdapter;\n+import org.apache.beam.sdk.extensions.sql.impl.utils.CalciteUtils;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.transforms.Combine;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionList;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptCluster;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptPlanner;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelTraitSet;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelFieldCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.AggregateCall;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.Window;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.metadata.RelMetadataQuery;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.type.RelDataType;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexLiteral;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Lists;\n+\n+public class BeamWindowRel extends Window implements BeamRelNode {\n+  public BeamWindowRel(\n+      RelOptCluster cluster,\n+      RelTraitSet traitSet,\n+      RelNode input,\n+      List<RexLiteral> constants,\n+      RelDataType rowType,\n+      List<Group> groups) {\n+    super(cluster, traitSet, input, constants, rowType, groups);\n+  }\n+\n+  @Override\n+  public PTransform<PCollectionList<Row>, PCollection<Row>> buildPTransform() {\n+    Schema outputSchema = CalciteUtils.toSchema(getRowType());\n+    final List<FieldAggregation> analyticFields = Lists.newArrayList();\n+    this.groups.stream()\n+        .forEach(\n+            anAnalyticGroup -> {\n+              List<Integer> partitionKeysDef = anAnalyticGroup.keys.toList();\n+              List<Integer> orderByKeys = Lists.newArrayList();\n+              List<Boolean> orderByDirections = Lists.newArrayList();\n+              List<Boolean> orderByNullDirections = Lists.newArrayList();\n+              anAnalyticGroup.orderKeys.getFieldCollations().stream()\n+                  .forEach(\n+                      fc -> {\n+                        orderByKeys.add(fc.getFieldIndex());\n+                        orderByDirections.add(\n+                            fc.direction == RelFieldCollation.Direction.ASCENDING);\n+                        orderByNullDirections.add(\n+                            fc.nullDirection == RelFieldCollation.NullDirection.FIRST);\n+                      });\n+              int lowerB = Integer.MAX_VALUE; // Unbounded by default\n+              int upperB = Integer.MAX_VALUE; // Unbounded by default\n+              if (anAnalyticGroup.lowerBound.isCurrentRow()) {\n+                lowerB = 0;\n+              } else if (anAnalyticGroup.lowerBound.isPreceding()) {\n+                // pending\n+              } else if (anAnalyticGroup.lowerBound.isFollowing()) {\n+                // pending\n+              }\n+              if (anAnalyticGroup.upperBound.isCurrentRow()) {\n+                upperB = 0;\n+              } else if (anAnalyticGroup.upperBound.isPreceding()) {\n+                // pending\n+              } else if (anAnalyticGroup.upperBound.isFollowing()) {\n+                // pending\n+              }\n+              final int lowerBFinal = lowerB;\n+              final int upperBFinal = upperB;\n+              List<AggregateCall> aggregateCalls = anAnalyticGroup.getAggregateCalls(this);\n+              aggregateCalls.stream()\n+                  .forEach(\n+                      anAggCall -> {\n+                        List<Integer> argList = anAggCall.getArgList();\n+                        Schema.Field field =\n+                            CalciteUtils.toField(anAggCall.getName(), anAggCall.getType());\n+                        Combine.CombineFn combineFn =\n+                            AggregationCombineFnAdapter.createCombineFn(\n+                                anAggCall, field, anAggCall.getAggregation().getName());\n+                        FieldAggregation fieldAggregation =\n+                            new FieldAggregation(\n+                                partitionKeysDef,\n+                                orderByKeys,\n+                                orderByDirections,\n+                                orderByNullDirections,\n+                                lowerBFinal,\n+                                upperBFinal,\n+                                anAnalyticGroup.isRows,\n+                                argList,\n+                                combineFn,\n+                                field);\n+                        analyticFields.add(fieldAggregation);\n+                      });\n+            });\n+\n+    return new Transform(outputSchema, analyticFields);\n+  }\n+\n+  private static class FieldAggregation implements Serializable {\n+\n+    private List<Integer> partitionKeys;\n+    private List<Integer> orderKeys;\n+    private List<Boolean> orderOrientations;\n+    private List<Boolean> orderNulls;\n+    private int lowerLimit = Integer.MAX_VALUE;\n+    private int upperLimit = Integer.MAX_VALUE;\n+    private boolean rows = true;\n+    private List<Integer> inputFields;\n+    private Combine.CombineFn combineFn;\n+    private Schema.Field outputField;\n+\n+    public FieldAggregation(\n+        List<Integer> partitionKeys,\n+        List<Integer> orderKeys,\n+        List<Boolean> orderOrientations,\n+        List<Boolean> orderNulls,\n+        int lowerLimit,\n+        int upperLimit,\n+        boolean rows,\n+        List<Integer> inputFields,\n+        Combine.CombineFn combineFn,\n+        Schema.Field outputField) {\n+      this.partitionKeys = partitionKeys;\n+      this.orderKeys = orderKeys;\n+      this.orderOrientations = orderOrientations;\n+      this.orderNulls = orderNulls;\n+      this.lowerLimit = lowerLimit;\n+      this.upperLimit = upperLimit;\n+      this.rows = rows;\n+      this.inputFields = inputFields;\n+      this.combineFn = combineFn;\n+      this.outputField = outputField;\n+    }\n+  }\n+\n+  @Override\n+  public NodeStats estimateNodeStats(RelMetadataQuery mq) {\n+    NodeStats inputStat = BeamSqlRelUtils.getNodeStats(this.input, mq);\n+    return inputStat;\n+  }\n+\n+  @Override\n+  public BeamCostModel beamComputeSelfCost(RelOptPlanner planner, RelMetadataQuery mq) {\n+    NodeStats inputStat = BeamSqlRelUtils.getNodeStats(this.input, mq);\n+    float multiplier = 1f + 0.125f;\n+    return BeamCostModel.FACTORY.makeCost(\n+        inputStat.getRowCount() * multiplier, inputStat.getRate() * multiplier);\n+  }\n+\n+  private static class Transform extends PTransform<PCollectionList<Row>, PCollection<Row>> {\n+\n+    private Schema outputSchema;\n+    private List<FieldAggregation> aggFields;\n+\n+    public Transform(Schema schema, List<FieldAggregation> fieldAgg) {\n+      this.outputSchema = schema;\n+      this.aggFields = fieldAgg;\n+    }\n+\n+    @Override\n+    public PCollection<Row> expand(PCollectionList<Row> input) {\n+      PCollection<Row> inputData = input.get(0);\n+      Schema inputSchema = inputData.getSchema();\n+      for (FieldAggregation af : aggFields) {\n+        if (af.partitionKeys.isEmpty()) {\n+          // This sections simulate a KV Row\n+          // Similar to the output of Group.byFieldIds\n+          // When no partitions are specified\n+          Schema inputSch = inputData.getSchema();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c05fca76e7fa2e2c53a3e392dc083d543fe4c0ad"}, "originalPosition": 197}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU1Mjg3Ng==", "bodyText": "Can you skip sort transform when there is no order by? Also leave a comment to say migrate to SortValues transform in the future.", "url": "https://github.com/apache/beam/pull/11975#discussion_r444552876", "createdAt": "2020-06-23T22:57:24Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamWindowRel.java", "diffHunk": "@@ -0,0 +1,317 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.rel;\n+\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.BeamCostModel;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.NodeStats;\n+import org.apache.beam.sdk.extensions.sql.impl.transform.agg.AggregationCombineFnAdapter;\n+import org.apache.beam.sdk.extensions.sql.impl.utils.CalciteUtils;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.transforms.Combine;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionList;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptCluster;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptPlanner;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelTraitSet;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelFieldCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.AggregateCall;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.Window;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.metadata.RelMetadataQuery;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.type.RelDataType;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexLiteral;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Lists;\n+\n+public class BeamWindowRel extends Window implements BeamRelNode {\n+  public BeamWindowRel(\n+      RelOptCluster cluster,\n+      RelTraitSet traitSet,\n+      RelNode input,\n+      List<RexLiteral> constants,\n+      RelDataType rowType,\n+      List<Group> groups) {\n+    super(cluster, traitSet, input, constants, rowType, groups);\n+  }\n+\n+  @Override\n+  public PTransform<PCollectionList<Row>, PCollection<Row>> buildPTransform() {\n+    Schema outputSchema = CalciteUtils.toSchema(getRowType());\n+    final List<FieldAggregation> analyticFields = Lists.newArrayList();\n+    this.groups.stream()\n+        .forEach(\n+            anAnalyticGroup -> {\n+              List<Integer> partitionKeysDef = anAnalyticGroup.keys.toList();\n+              List<Integer> orderByKeys = Lists.newArrayList();\n+              List<Boolean> orderByDirections = Lists.newArrayList();\n+              List<Boolean> orderByNullDirections = Lists.newArrayList();\n+              anAnalyticGroup.orderKeys.getFieldCollations().stream()\n+                  .forEach(\n+                      fc -> {\n+                        orderByKeys.add(fc.getFieldIndex());\n+                        orderByDirections.add(\n+                            fc.direction == RelFieldCollation.Direction.ASCENDING);\n+                        orderByNullDirections.add(\n+                            fc.nullDirection == RelFieldCollation.NullDirection.FIRST);\n+                      });\n+              int lowerB = Integer.MAX_VALUE; // Unbounded by default\n+              int upperB = Integer.MAX_VALUE; // Unbounded by default\n+              if (anAnalyticGroup.lowerBound.isCurrentRow()) {\n+                lowerB = 0;\n+              } else if (anAnalyticGroup.lowerBound.isPreceding()) {\n+                // pending\n+              } else if (anAnalyticGroup.lowerBound.isFollowing()) {\n+                // pending\n+              }\n+              if (anAnalyticGroup.upperBound.isCurrentRow()) {\n+                upperB = 0;\n+              } else if (anAnalyticGroup.upperBound.isPreceding()) {\n+                // pending\n+              } else if (anAnalyticGroup.upperBound.isFollowing()) {\n+                // pending\n+              }\n+              final int lowerBFinal = lowerB;\n+              final int upperBFinal = upperB;\n+              List<AggregateCall> aggregateCalls = anAnalyticGroup.getAggregateCalls(this);\n+              aggregateCalls.stream()\n+                  .forEach(\n+                      anAggCall -> {\n+                        List<Integer> argList = anAggCall.getArgList();\n+                        Schema.Field field =\n+                            CalciteUtils.toField(anAggCall.getName(), anAggCall.getType());\n+                        Combine.CombineFn combineFn =\n+                            AggregationCombineFnAdapter.createCombineFn(\n+                                anAggCall, field, anAggCall.getAggregation().getName());\n+                        FieldAggregation fieldAggregation =\n+                            new FieldAggregation(\n+                                partitionKeysDef,\n+                                orderByKeys,\n+                                orderByDirections,\n+                                orderByNullDirections,\n+                                lowerBFinal,\n+                                upperBFinal,\n+                                anAnalyticGroup.isRows,\n+                                argList,\n+                                combineFn,\n+                                field);\n+                        analyticFields.add(fieldAggregation);\n+                      });\n+            });\n+\n+    return new Transform(outputSchema, analyticFields);\n+  }\n+\n+  private static class FieldAggregation implements Serializable {\n+\n+    private List<Integer> partitionKeys;\n+    private List<Integer> orderKeys;\n+    private List<Boolean> orderOrientations;\n+    private List<Boolean> orderNulls;\n+    private int lowerLimit = Integer.MAX_VALUE;\n+    private int upperLimit = Integer.MAX_VALUE;\n+    private boolean rows = true;\n+    private List<Integer> inputFields;\n+    private Combine.CombineFn combineFn;\n+    private Schema.Field outputField;\n+\n+    public FieldAggregation(\n+        List<Integer> partitionKeys,\n+        List<Integer> orderKeys,\n+        List<Boolean> orderOrientations,\n+        List<Boolean> orderNulls,\n+        int lowerLimit,\n+        int upperLimit,\n+        boolean rows,\n+        List<Integer> inputFields,\n+        Combine.CombineFn combineFn,\n+        Schema.Field outputField) {\n+      this.partitionKeys = partitionKeys;\n+      this.orderKeys = orderKeys;\n+      this.orderOrientations = orderOrientations;\n+      this.orderNulls = orderNulls;\n+      this.lowerLimit = lowerLimit;\n+      this.upperLimit = upperLimit;\n+      this.rows = rows;\n+      this.inputFields = inputFields;\n+      this.combineFn = combineFn;\n+      this.outputField = outputField;\n+    }\n+  }\n+\n+  @Override\n+  public NodeStats estimateNodeStats(RelMetadataQuery mq) {\n+    NodeStats inputStat = BeamSqlRelUtils.getNodeStats(this.input, mq);\n+    return inputStat;\n+  }\n+\n+  @Override\n+  public BeamCostModel beamComputeSelfCost(RelOptPlanner planner, RelMetadataQuery mq) {\n+    NodeStats inputStat = BeamSqlRelUtils.getNodeStats(this.input, mq);\n+    float multiplier = 1f + 0.125f;\n+    return BeamCostModel.FACTORY.makeCost(\n+        inputStat.getRowCount() * multiplier, inputStat.getRate() * multiplier);\n+  }\n+\n+  private static class Transform extends PTransform<PCollectionList<Row>, PCollection<Row>> {\n+\n+    private Schema outputSchema;\n+    private List<FieldAggregation> aggFields;\n+\n+    public Transform(Schema schema, List<FieldAggregation> fieldAgg) {\n+      this.outputSchema = schema;\n+      this.aggFields = fieldAgg;\n+    }\n+\n+    @Override\n+    public PCollection<Row> expand(PCollectionList<Row> input) {\n+      PCollection<Row> inputData = input.get(0);\n+      Schema inputSchema = inputData.getSchema();\n+      for (FieldAggregation af : aggFields) {\n+        if (af.partitionKeys.isEmpty()) {\n+          // This sections simulate a KV Row\n+          // Similar to the output of Group.byFieldIds\n+          // When no partitions are specified\n+          Schema inputSch = inputData.getSchema();\n+          Schema mockKeySchema =\n+              Schema.of(Schema.Field.of(\"mock\", Schema.FieldType.STRING.withNullable(true)));\n+          Schema simulatedKeyValueSchema =\n+              Schema.of(\n+                  Schema.Field.of(\"key\", Schema.FieldType.row(mockKeySchema)),\n+                  Schema.Field.of(\n+                      \"value\", Schema.FieldType.iterable(Schema.FieldType.row(inputSch))));\n+          PCollection<Iterable<Row>> apply =\n+              inputData.apply(org.apache.beam.sdk.schemas.transforms.Group.globally());\n+          inputData =\n+              apply\n+                  .apply(ParDo.of(uniquePartition(mockKeySchema, simulatedKeyValueSchema)))\n+                  .setRowSchema(simulatedKeyValueSchema);\n+        } else {\n+          org.apache.beam.sdk.schemas.transforms.Group.ByFields<Row> myg =\n+              org.apache.beam.sdk.schemas.transforms.Group.byFieldIds(af.partitionKeys);\n+          inputData = inputData.apply(\"partitionBy\", myg);\n+        }\n+        inputData =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c05fca76e7fa2e2c53a3e392dc083d543fe4c0ad"}, "originalPosition": 216}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU1MzExNw==", "bodyText": "Add a comment to explain what this piece of code is doing. Basically it stops converting in the OVER clause case.", "url": "https://github.com/apache/beam/pull/11975#discussion_r444553117", "createdAt": "2020-06-23T22:58:06Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rule/BeamCalcRule.java", "diffHunk": "@@ -37,7 +40,20 @@ private BeamCalcRule() {\n \n   @Override\n   public boolean matches(RelOptRuleCall x) {\n-    return true;\n+    boolean hasRexOver = false;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c05fca76e7fa2e2c53a3e392dc083d543fe4c0ad"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU1MzE4NA==", "bodyText": "Class java doc will be very helpful.", "url": "https://github.com/apache/beam/pull/11975#discussion_r444553184", "createdAt": "2020-06-23T22:58:21Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rule/BeamWindowRule.java", "diffHunk": "@@ -0,0 +1,46 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.rule;\n+\n+import org.apache.beam.sdk.extensions.sql.impl.rel.BeamLogicalConvention;\n+import org.apache.beam.sdk.extensions.sql.impl.rel.BeamWindowRel;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.Convention;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.convert.ConverterRule;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.Window;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.logical.LogicalWindow;\n+\n+public class BeamWindowRule extends ConverterRule {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c05fca76e7fa2e2c53a3e392dc083d543fe4c0ad"}, "originalPosition": 28}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM2OTI0ODky", "url": "https://github.com/apache/beam/pull/11975#pullrequestreview-436924892", "createdAt": "2020-06-24T19:01:21Z", "commit": {"oid": "c05fca76e7fa2e2c53a3e392dc083d543fe4c0ad"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQxOTowMToyMVrOGofMgQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQxOTowMToyMVrOGofMgQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTEwNzMyOQ==", "bodyText": "In fact, if there is no order by but only partition by, combine per key will be the best API because backend can do combiner lift optimizations, which works as follow:\nKV -> GroupByKey -> KV -> Combine\ncan be optimized as\nKV -> local combine -> K Combined V -> GroupByKey -> Combine all combined Vs.\nSo basically there could be a pre-combine before shuffle (GroupByKey), and after that each worker will only need to combine those pre-combined value (because of associativity rule).  This optimization will reduce lots of data through shuffle.\nI think this can be left for a future work. Please log a JIRA to document this idea.", "url": "https://github.com/apache/beam/pull/11975#discussion_r445107329", "createdAt": "2020-06-24T19:01:21Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamWindowRel.java", "diffHunk": "@@ -0,0 +1,317 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl.rel;\n+\n+import java.io.Serializable;\n+import java.util.ArrayList;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.List;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.BeamCostModel;\n+import org.apache.beam.sdk.extensions.sql.impl.planner.NodeStats;\n+import org.apache.beam.sdk.extensions.sql.impl.transform.agg.AggregationCombineFnAdapter;\n+import org.apache.beam.sdk.extensions.sql.impl.utils.CalciteUtils;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.transforms.Combine;\n+import org.apache.beam.sdk.transforms.DoFn;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ParDo;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionList;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptCluster;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelOptPlanner;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.plan.RelTraitSet;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelFieldCollation;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.RelNode;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.AggregateCall;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.core.Window;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.metadata.RelMetadataQuery;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rel.type.RelDataType;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexLiteral;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Lists;\n+\n+public class BeamWindowRel extends Window implements BeamRelNode {\n+  public BeamWindowRel(\n+      RelOptCluster cluster,\n+      RelTraitSet traitSet,\n+      RelNode input,\n+      List<RexLiteral> constants,\n+      RelDataType rowType,\n+      List<Group> groups) {\n+    super(cluster, traitSet, input, constants, rowType, groups);\n+  }\n+\n+  @Override\n+  public PTransform<PCollectionList<Row>, PCollection<Row>> buildPTransform() {\n+    Schema outputSchema = CalciteUtils.toSchema(getRowType());\n+    final List<FieldAggregation> analyticFields = Lists.newArrayList();\n+    this.groups.stream()\n+        .forEach(\n+            anAnalyticGroup -> {\n+              List<Integer> partitionKeysDef = anAnalyticGroup.keys.toList();\n+              List<Integer> orderByKeys = Lists.newArrayList();\n+              List<Boolean> orderByDirections = Lists.newArrayList();\n+              List<Boolean> orderByNullDirections = Lists.newArrayList();\n+              anAnalyticGroup.orderKeys.getFieldCollations().stream()\n+                  .forEach(\n+                      fc -> {\n+                        orderByKeys.add(fc.getFieldIndex());\n+                        orderByDirections.add(\n+                            fc.direction == RelFieldCollation.Direction.ASCENDING);\n+                        orderByNullDirections.add(\n+                            fc.nullDirection == RelFieldCollation.NullDirection.FIRST);\n+                      });\n+              int lowerB = Integer.MAX_VALUE; // Unbounded by default\n+              int upperB = Integer.MAX_VALUE; // Unbounded by default\n+              if (anAnalyticGroup.lowerBound.isCurrentRow()) {\n+                lowerB = 0;\n+              } else if (anAnalyticGroup.lowerBound.isPreceding()) {\n+                // pending\n+              } else if (anAnalyticGroup.lowerBound.isFollowing()) {\n+                // pending\n+              }\n+              if (anAnalyticGroup.upperBound.isCurrentRow()) {\n+                upperB = 0;\n+              } else if (anAnalyticGroup.upperBound.isPreceding()) {\n+                // pending\n+              } else if (anAnalyticGroup.upperBound.isFollowing()) {\n+                // pending\n+              }\n+              final int lowerBFinal = lowerB;\n+              final int upperBFinal = upperB;\n+              List<AggregateCall> aggregateCalls = anAnalyticGroup.getAggregateCalls(this);\n+              aggregateCalls.stream()\n+                  .forEach(\n+                      anAggCall -> {\n+                        List<Integer> argList = anAggCall.getArgList();\n+                        Schema.Field field =\n+                            CalciteUtils.toField(anAggCall.getName(), anAggCall.getType());\n+                        Combine.CombineFn combineFn =\n+                            AggregationCombineFnAdapter.createCombineFn(\n+                                anAggCall, field, anAggCall.getAggregation().getName());\n+                        FieldAggregation fieldAggregation =\n+                            new FieldAggregation(\n+                                partitionKeysDef,\n+                                orderByKeys,\n+                                orderByDirections,\n+                                orderByNullDirections,\n+                                lowerBFinal,\n+                                upperBFinal,\n+                                anAnalyticGroup.isRows,\n+                                argList,\n+                                combineFn,\n+                                field);\n+                        analyticFields.add(fieldAggregation);\n+                      });\n+            });\n+\n+    return new Transform(outputSchema, analyticFields);\n+  }\n+\n+  private static class FieldAggregation implements Serializable {\n+\n+    private List<Integer> partitionKeys;\n+    private List<Integer> orderKeys;\n+    private List<Boolean> orderOrientations;\n+    private List<Boolean> orderNulls;\n+    private int lowerLimit = Integer.MAX_VALUE;\n+    private int upperLimit = Integer.MAX_VALUE;\n+    private boolean rows = true;\n+    private List<Integer> inputFields;\n+    private Combine.CombineFn combineFn;\n+    private Schema.Field outputField;\n+\n+    public FieldAggregation(\n+        List<Integer> partitionKeys,\n+        List<Integer> orderKeys,\n+        List<Boolean> orderOrientations,\n+        List<Boolean> orderNulls,\n+        int lowerLimit,\n+        int upperLimit,\n+        boolean rows,\n+        List<Integer> inputFields,\n+        Combine.CombineFn combineFn,\n+        Schema.Field outputField) {\n+      this.partitionKeys = partitionKeys;\n+      this.orderKeys = orderKeys;\n+      this.orderOrientations = orderOrientations;\n+      this.orderNulls = orderNulls;\n+      this.lowerLimit = lowerLimit;\n+      this.upperLimit = upperLimit;\n+      this.rows = rows;\n+      this.inputFields = inputFields;\n+      this.combineFn = combineFn;\n+      this.outputField = outputField;\n+    }\n+  }\n+\n+  @Override\n+  public NodeStats estimateNodeStats(RelMetadataQuery mq) {\n+    NodeStats inputStat = BeamSqlRelUtils.getNodeStats(this.input, mq);\n+    return inputStat;\n+  }\n+\n+  @Override\n+  public BeamCostModel beamComputeSelfCost(RelOptPlanner planner, RelMetadataQuery mq) {\n+    NodeStats inputStat = BeamSqlRelUtils.getNodeStats(this.input, mq);\n+    float multiplier = 1f + 0.125f;\n+    return BeamCostModel.FACTORY.makeCost(\n+        inputStat.getRowCount() * multiplier, inputStat.getRate() * multiplier);\n+  }\n+\n+  private static class Transform extends PTransform<PCollectionList<Row>, PCollection<Row>> {\n+\n+    private Schema outputSchema;\n+    private List<FieldAggregation> aggFields;\n+\n+    public Transform(Schema schema, List<FieldAggregation> fieldAgg) {\n+      this.outputSchema = schema;\n+      this.aggFields = fieldAgg;\n+    }\n+\n+    @Override\n+    public PCollection<Row> expand(PCollectionList<Row> input) {\n+      PCollection<Row> inputData = input.get(0);\n+      Schema inputSchema = inputData.getSchema();\n+      for (FieldAggregation af : aggFields) {\n+        if (af.partitionKeys.isEmpty()) {\n+          // This sections simulate a KV Row\n+          // Similar to the output of Group.byFieldIds\n+          // When no partitions are specified\n+          Schema inputSch = inputData.getSchema();\n+          Schema mockKeySchema =\n+              Schema.of(Schema.Field.of(\"mock\", Schema.FieldType.STRING.withNullable(true)));\n+          Schema simulatedKeyValueSchema =\n+              Schema.of(\n+                  Schema.Field.of(\"key\", Schema.FieldType.row(mockKeySchema)),\n+                  Schema.Field.of(\n+                      \"value\", Schema.FieldType.iterable(Schema.FieldType.row(inputSch))));\n+          PCollection<Iterable<Row>> apply =\n+              inputData.apply(org.apache.beam.sdk.schemas.transforms.Group.globally());\n+          inputData =\n+              apply\n+                  .apply(ParDo.of(uniquePartition(mockKeySchema, simulatedKeyValueSchema)))\n+                  .setRowSchema(simulatedKeyValueSchema);\n+        } else {\n+          org.apache.beam.sdk.schemas.transforms.Group.ByFields<Row> myg =\n+              org.apache.beam.sdk.schemas.transforms.Group.byFieldIds(af.partitionKeys);\n+          inputData = inputData.apply(\"partitionBy\", myg);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c05fca76e7fa2e2c53a3e392dc083d543fe4c0ad"}, "originalPosition": 214}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2NzgwNTg0", "url": "https://github.com/apache/beam/pull/11975#pullrequestreview-446780584", "createdAt": "2020-07-11T05:44:08Z", "commit": {"oid": "65e0732e1ce638b2f3e34a6d75631f453a75ee43"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2NzgwNjE0", "url": "https://github.com/apache/beam/pull/11975#pullrequestreview-446780614", "createdAt": "2020-07-11T05:44:57Z", "commit": {"oid": "65e0732e1ce638b2f3e34a6d75631f453a75ee43"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMVQwNTo0NDo1OFrOGwKq7Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMVQwNTo0NDo1OFrOGwKq7Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzE1OTY2MQ==", "bodyText": "Can you remove the \"Experiment\" from class? I am going to merge this PR so it won't be experiment anymore.", "url": "https://github.com/apache/beam/pull/11975#discussion_r453159661", "createdAt": "2020-07-11T05:44:58Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/BeamAnalyticFunctionsExperimentTest.java", "diffHunk": "@@ -0,0 +1,366 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql;\n+\n+import java.util.List;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.testing.PAssert;\n+import org.apache.beam.sdk.transforms.Create;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.Row;\n+import org.junit.Test;\n+\n+/**\n+ * A simple Analytic Functions experiment for BeamSQL created in order to understand the query\n+ * processing workflow of BeamSQL and Calcite.\n+ */\n+public class BeamAnalyticFunctionsExperimentTest extends BeamSqlDslBase {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "65e0732e1ce638b2f3e34a6d75631f453a75ee43"}, "originalPosition": 32}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cda6813683c513ec4c3cdcee3299ecdcd683373f", "author": {"user": {"login": "jhnmora000", "name": null}}, "url": "https://github.com/apache/beam/commit/cda6813683c513ec4c3cdcee3299ecdcd683373f", "committedDate": "2020-07-14T21:11:16Z", "message": "[BEAM-9198] BeamSQL aggregation analytics functionality\n\nA simple Analytic Functions experiment for BeamSQL created\nin order to understand the query processing workflow of \nBeamSQL and Calcite.\n\nThe experiment is implemented in the test BeamAnalyticFunctionsExperimentTest.testSimpleOverFunction(), \nwhen executing it a \"BEAM_LOGICAL but does not implement\nthe required interface\" exception is thrown."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "548fe5e0466e2e929a5ab323ba4e6ad23fea864f", "author": {"user": {"login": "amaliujia", "name": "Rui Wang"}}, "url": "https://github.com/apache/beam/commit/548fe5e0466e2e929a5ab323ba4e6ad23fea864f", "committedDate": "2020-07-14T21:11:17Z", "message": "now BeamWindowRule.convert() is executed."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e4881b5983042526600dbbb9802ff0e968a0b469", "author": {"user": {"login": "jhnmora000", "name": null}}, "url": "https://github.com/apache/beam/commit/e4881b5983042526600dbbb9802ff0e968a0b469", "committedDate": "2020-07-14T21:11:19Z", "message": "Cumulative sum experiment"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6115948f2e67556c0c7f1b6e030f09a7f015c27f", "author": {"user": {"login": "jhnmora000", "name": null}}, "url": "https://github.com/apache/beam/commit/6115948f2e67556c0c7f1b6e030f09a7f015c27f", "committedDate": "2020-07-14T21:11:20Z", "message": "rewrite hard-coded sections"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1866d371b400a39ae97683984818f1e9d2c82ff7", "author": {"user": {"login": "jhnmora000", "name": null}}, "url": "https://github.com/apache/beam/commit/1866d371b400a39ae97683984818f1e9d2c82ff7", "committedDate": "2020-07-14T21:11:21Z", "message": "Fix style warnings"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b2c7334986a7e03c50603041422df460a75f3bab", "author": {"user": {"login": "jhnmora000", "name": null}}, "url": "https://github.com/apache/beam/commit/b2c7334986a7e03c50603041422df460a75f3bab", "committedDate": "2020-07-14T21:11:22Z", "message": "Some improvements\n\n- Add test for ORDER BY DESC.\n- Add Java docs.\n- New registry for Analytic Functions.\n- Remove dummy fields from partition transforms.\n- Add exceptions for unsupported features.\n- Make public GroupByFields.toKVs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a29d54818c0f2fbb2db2d3c6e925f14685e4d051", "author": {"user": {"login": "jhnmora000", "name": null}}, "url": "https://github.com/apache/beam/commit/a29d54818c0f2fbb2db2d3c6e925f14685e4d051", "committedDate": "2020-07-14T21:11:23Z", "message": "Improvements:\n\n- Add support for bounded windows.\n- Add support for RANGE windows.\n- Add tests for more cases."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7e536782d6103843dfe65cc3e3ced7c81b53129f", "author": {"user": {"login": "jhnmora000", "name": null}}, "url": "https://github.com/apache/beam/commit/7e536782d6103843dfe65cc3e3ced7c81b53129f", "committedDate": "2020-07-14T21:11:24Z", "message": "Fix style violations"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4213, "cost": 1, "resetAt": "2021-10-28T16:48:13Z"}}}