{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzgzNDYxNDky", "number": 11040, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQxODoxOTo1OVrODlJuKQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMlQxNjo1ODo0NVrODnjEMg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQwMjgzMTc3OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/bigquery_read_it_test.py", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQxODoxOTo1OVrOFx4WAg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQxODoxOTo1OVrOFx4WAg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzg0NzY4Mg==", "bodyText": "could you use the value provider in another one of the tests in this file? Since each test in this file takes ~5min to run, I'd prefer to avoid adding a new test.", "url": "https://github.com/apache/beam/pull/11040#discussion_r387847682", "createdAt": "2020-03-04T18:19:59Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/bigquery_read_it_test.py", "diffHunk": "@@ -162,6 +163,15 @@ def test_iobase_source(self):\n               query=self.query, use_standard_sql=True, project=self.project))\n       assert_that(result, equal_to(self.TABLE_DATA))\n \n+  @attr('IT')\n+  def test_valueprovider_query_string(self):\n+    query = StaticValueProvider(str, self.query)\n+    with beam.Pipeline(argv=self.args) as p:\n+      result = (\n+          p | 'read' >> beam.io._ReadFromBigQuery(\n+              query=query, use_standard_sql=True, project=self.project))\n+      assert_that(result, equal_to(self.TABLE_DATA))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3f37c81364b4eac46689abd92dce53af54d4b59"}, "originalPosition": 19}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQwMjg0NjkwOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQxODoyNDoxN1rOFx4fTQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNFQxODoyNDoxN1rOFx4fTQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4Nzg1MDA2MQ==", "bodyText": "I would probably do this without changing the class variable.\nI'd do a local variable: query = self.query.get(), and do it on every instance where self.query is accessed.\nThe reason is that the Source objects may be recreated in different workers, and the  self.query variable would contain the original ValueProvider in all of those.", "url": "https://github.com/apache/beam/pull/11040#discussion_r387850061", "createdAt": "2020-03-04T18:24:17Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -644,6 +644,8 @@ def estimate_size(self):\n           self.table_reference.tableId)\n       return int(table.numBytes)\n     else:\n+      if isinstance(self.query, ValueProvider):\n+        self.query = self.query.get()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a3f37c81364b4eac46689abd92dce53af54d4b59"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQwODg1MDg4OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/bigquery_read_it_test.py", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wNlQwOToxMzoxN1rOFyxv8w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQxMToyOToyMlrOF0K_Wg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODc4ODIxMQ==", "bodyText": "Do we need an integration test to cover your value provider's logic? Take a look at TestReadFromBigQuery test case in bigquery_test.py. Those are unit tests for _ReadFromBigQuery that actually run very fast, because pipeline is not executed.\nAdding new tests in bigquery_read_it_test.py causes huge overhead, since they are all executed by three runners (Direct, Dataflow and Flink) on every supported Python version.", "url": "https://github.com/apache/beam/pull/11040#discussion_r388788211", "createdAt": "2020-03-06T09:13:17Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/bigquery_read_it_test.py", "diffHunk": "@@ -156,12 +157,19 @@ def test_native_source(self):\n \n   @attr('IT')\n   def test_iobase_source(self):\n+    query = StaticValueProvider(str, self.query)\n     with beam.Pipeline(argv=self.args) as p:\n       result = (\n           p | 'read' >> beam.io._ReadFromBigQuery(\n               query=self.query, use_standard_sql=True, project=self.project))\n       assert_that(result, equal_to(self.TABLE_DATA))\n \n+    with beam.Pipeline(argv=self.args) as p:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "935e3169937f10897fc6c0453263afb36548db8d"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTUzMjcyNQ==", "bodyText": "To actually evaluate the value providers, the pipeline needs to be executed right? Cause these are realistically only 'known' at runtime. The tests in TestReadFromBigQuery just validate the input data to the initialisation.\nWe can of course just validate that query is of type ValueProvider after initialising a pipeline, but I figured we want to check that the value provider query is actually evaluated to a string type on pipeline execution.\nAm I perhaps missing something?", "url": "https://github.com/apache/beam/pull/11040#discussion_r389532725", "createdAt": "2020-03-09T09:06:10Z", "author": {"login": "EDjur"}, "path": "sdks/python/apache_beam/io/gcp/bigquery_read_it_test.py", "diffHunk": "@@ -156,12 +157,19 @@ def test_native_source(self):\n \n   @attr('IT')\n   def test_iobase_source(self):\n+    query = StaticValueProvider(str, self.query)\n     with beam.Pipeline(argv=self.args) as p:\n       result = (\n           p | 'read' >> beam.io._ReadFromBigQuery(\n               query=self.query, use_standard_sql=True, project=self.project))\n       assert_that(result, equal_to(self.TABLE_DATA))\n \n+    with beam.Pipeline(argv=self.args) as p:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODc4ODIxMQ=="}, "originalCommit": {"oid": "935e3169937f10897fc6c0453263afb36548db8d"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTgzNTkyMg==", "bodyText": "What I would say is use the value provider in the first pipeline of this method, and don't add a second pipeline. I think that should be fine. WDYT @kamilwu ?", "url": "https://github.com/apache/beam/pull/11040#discussion_r389835922", "createdAt": "2020-03-09T17:13:53Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/bigquery_read_it_test.py", "diffHunk": "@@ -156,12 +157,19 @@ def test_native_source(self):\n \n   @attr('IT')\n   def test_iobase_source(self):\n+    query = StaticValueProvider(str, self.query)\n     with beam.Pipeline(argv=self.args) as p:\n       result = (\n           p | 'read' >> beam.io._ReadFromBigQuery(\n               query=self.query, use_standard_sql=True, project=self.project))\n       assert_that(result, equal_to(self.TABLE_DATA))\n \n+    with beam.Pipeline(argv=self.args) as p:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODc4ODIxMQ=="}, "originalCommit": {"oid": "935e3169937f10897fc6c0453263afb36548db8d"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDI1MDMzMA==", "bodyText": "@EDjur Thanks for explanation. That's right, if we want to check that query is successfully evaluated to a string, we have to execute the pipeline.\n@pabloem I think this is good idea. Let's do it this way.", "url": "https://github.com/apache/beam/pull/11040#discussion_r390250330", "createdAt": "2020-03-10T11:29:22Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/bigquery_read_it_test.py", "diffHunk": "@@ -156,12 +157,19 @@ def test_native_source(self):\n \n   @attr('IT')\n   def test_iobase_source(self):\n+    query = StaticValueProvider(str, self.query)\n     with beam.Pipeline(argv=self.args) as p:\n       result = (\n           p | 'read' >> beam.io._ReadFromBigQuery(\n               query=self.query, use_standard_sql=True, project=self.project))\n       assert_that(result, equal_to(self.TABLE_DATA))\n \n+    with beam.Pipeline(argv=self.args) as p:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4ODc4ODIxMQ=="}, "originalCommit": {"oid": "935e3169937f10897fc6c0453263afb36548db8d"}, "originalPosition": 19}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQyNzk1NTcwOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMlQxNjo1ODo0NVrOF1nLlw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xM1QwOTo0MzozNFrOF19RkQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTc2MDc5MQ==", "bodyText": "There's a check_accessible decorator that could be used for this function (as well as for estimate_size).\nI think you could also test if self.query is a ValueProvider or not in the constructor. If it's not, you can then create a StaticValueProvider object. self.evaluate_query_valueprovider() would be unnecessary.\nHere'a en example:\n\n  \n    \n      beam/sdks/python/apache_beam/io/filebasedsource.py\n    \n    \n        Lines 115 to 117\n      in\n      f75838f\n    \n    \n    \n    \n\n        \n          \n           if isinstance(file_pattern, (str, unicode)): \n        \n\n        \n          \n             file_pattern = StaticValueProvider(str, file_pattern) \n        \n\n        \n          \n           self._pattern = file_pattern", "url": "https://github.com/apache/beam/pull/11040#discussion_r391760791", "createdAt": "2020-03-12T16:58:45Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -694,14 +699,16 @@ def read(self, range_tracker):\n     raise NotImplementedError('BigQuery source must be split before being read')\n \n   def _setup_temporary_dataset(self, bq):\n+    query = self.evaluate_query_valueprovider()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "72285e347dc4bb1c46b09dc46d6f4bc15e0a1c9a"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MjEyMjc2OQ==", "bodyText": "Thanks for the tip re: check_accessible, I didn't know about that. I've updated the PR based on these suggestions.", "url": "https://github.com/apache/beam/pull/11040#discussion_r392122769", "createdAt": "2020-03-13T09:43:34Z", "author": {"login": "EDjur"}, "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -694,14 +699,16 @@ def read(self, range_tracker):\n     raise NotImplementedError('BigQuery source must be split before being read')\n \n   def _setup_temporary_dataset(self, bq):\n+    query = self.evaluate_query_valueprovider()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MTc2MDc5MQ=="}, "originalCommit": {"oid": "72285e347dc4bb1c46b09dc46d6f4bc15e0a1c9a"}, "originalPosition": 36}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1774, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}