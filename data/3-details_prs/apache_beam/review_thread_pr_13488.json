{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTMyNzIyMDQ4", "number": 13488, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQyMzowNDoyMFrOFFTYVQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwMTo0NTo1NFrOFFWb1Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQxMTA0NzI1OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/io.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQyMzowNDoyMFrOIFwkoA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQyMzoxMjowMFrOIGkK7Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjkwOTYwMA==", "bodyText": "Can we make this warn that using splittable=True with quoted newlines could lead to dataloss?", "url": "https://github.com/apache/beam/pull/13488#discussion_r542909600", "createdAt": "2020-12-14T23:04:20Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/io.py", "diffHunk": "@@ -31,16 +33,28 @@\n _DEFAULT_BYTES_CHUNKSIZE = 1 << 20\n \n \n-def read_csv(path, *args, **kwargs):\n+def read_csv(path, *args, splittable=False, **kwargs):\n   \"\"\"Emulates `pd.read_csv` from Pandas, but as a Beam PTransform.\n \n   Use this as\n \n       df = p | beam.dataframe.io.read_csv(...)\n \n   to get a deferred Beam dataframe representing the contents of the file.\n+\n+  If your files are large and records do not contain quoted newlines, you may\n+  pass the extra argument splittable=True to enable dynamic splitting for this\n+  read.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "77ca3fc8709fb7ffb3273fb72765b0c6892359d1"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mzc1NDk4OQ==", "bodyText": "Good point. Done.", "url": "https://github.com/apache/beam/pull/13488#discussion_r543754989", "createdAt": "2020-12-15T23:12:00Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/io.py", "diffHunk": "@@ -31,16 +33,28 @@\n _DEFAULT_BYTES_CHUNKSIZE = 1 << 20\n \n \n-def read_csv(path, *args, **kwargs):\n+def read_csv(path, *args, splittable=False, **kwargs):\n   \"\"\"Emulates `pd.read_csv` from Pandas, but as a Beam PTransform.\n \n   Use this as\n \n       df = p | beam.dataframe.io.read_csv(...)\n \n   to get a deferred Beam dataframe representing the contents of the file.\n+\n+  If your files are large and records do not contain quoted newlines, you may\n+  pass the extra argument splittable=True to enable dynamic splitting for this\n+  read.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjkwOTYwMA=="}, "originalCommit": {"oid": "77ca3fc8709fb7ffb3273fb72765b0c6892359d1"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQxMTIxNjk2OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/io.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQyMzo1Nzo0NVrOIFyDNA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQyMzoyNToyMVrOIGkiWg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjkzMzgxMg==", "bodyText": "Might be helpful to clarify that this is splitting on delimiters between records, it's easy to get mixed up in the CSV case where there's also a field delimiter.\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            class _DelimSplitter(_Splitter):\n          \n          \n            \n              def __init__(self, delim, read_chunk_size=_DEFAULT_BYTES_CHUNKSIZE):\n          \n          \n            \n            class _RecordDelimSplitter(_Splitter):\n          \n          \n            \n              \"\"\" A _Splitter that splits on delimiters between records. \"\"\"\n          \n          \n            \n              def __init__(self, delim, read_chunk_size=_DEFAULT_BYTES_CHUNKSIZE):", "url": "https://github.com/apache/beam/pull/13488#discussion_r542933812", "createdAt": "2020-12-14T23:57:45Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/io.py", "diffHunk": "@@ -192,14 +207,134 @@ def expand(self, root):\n                 self.reader,\n                 self.args,\n                 self.kwargs,\n+                self.binary,\n                 self.incremental,\n-                self.splittable,\n-                self.binary)))\n+                self.splitter)))\n     from apache_beam.dataframe import convert\n     return convert.to_dataframe(\n         pcoll, proxy=_prefix_range_index_with(':', sample[:0]))\n \n \n+class _Splitter:\n+  def empty_buffer(self):\n+    raise NotImplementedError(self)\n+\n+  def read_header(self, handle):\n+    raise NotImplementedError(self)\n+\n+  def read_to_record_boundary(self, buffered, handle):\n+    raise NotImplementedError(self)\n+\n+\n+class _DelimSplitter(_Splitter):\n+  def __init__(self, delim, read_chunk_size=_DEFAULT_BYTES_CHUNKSIZE):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "77ca3fc8709fb7ffb3273fb72765b0c6892359d1"}, "originalPosition": 100}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mzc2MDk4Ng==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/13488#discussion_r543760986", "createdAt": "2020-12-15T23:25:21Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/io.py", "diffHunk": "@@ -192,14 +207,134 @@ def expand(self, root):\n                 self.reader,\n                 self.args,\n                 self.kwargs,\n+                self.binary,\n                 self.incremental,\n-                self.splittable,\n-                self.binary)))\n+                self.splitter)))\n     from apache_beam.dataframe import convert\n     return convert.to_dataframe(\n         pcoll, proxy=_prefix_range_index_with(':', sample[:0]))\n \n \n+class _Splitter:\n+  def empty_buffer(self):\n+    raise NotImplementedError(self)\n+\n+  def read_header(self, handle):\n+    raise NotImplementedError(self)\n+\n+  def read_to_record_boundary(self, buffered, handle):\n+    raise NotImplementedError(self)\n+\n+\n+class _DelimSplitter(_Splitter):\n+  def __init__(self, delim, read_chunk_size=_DEFAULT_BYTES_CHUNKSIZE):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MjkzMzgxMg=="}, "originalCommit": {"oid": "77ca3fc8709fb7ffb3273fb72765b0c6892359d1"}, "originalPosition": 100}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQxMTU0NzczOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/io.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQwMTo0NTo1NFrOIF091Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNVQyMzoyNDoxOFrOIGkgmw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mjk4MTU4OQ==", "bodyText": "Could you add docstrings and/or typehints for this class so its clear what implementations should do", "url": "https://github.com/apache/beam/pull/13488#discussion_r542981589", "createdAt": "2020-12-15T01:45:54Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/io.py", "diffHunk": "@@ -192,14 +207,133 @@ def expand(self, root):\n                 self.reader,\n                 self.args,\n                 self.kwargs,\n+                self.binary,\n                 self.incremental,\n-                self.splittable,\n-                self.binary)))\n+                self.splitter)))\n     from apache_beam.dataframe import convert\n     return convert.to_dataframe(\n         pcoll, proxy=_prefix_range_index_with(':', sample[:0]))\n \n \n+class _Splitter:\n+  def empty_buffer(self):\n+    raise NotImplementedError(self)\n+\n+  def read_header(self, handle):\n+    raise NotImplementedError(self)\n+\n+  def read_to_record_boundary(self, buffered, handle):\n+    raise NotImplementedError(self)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f23dc2d67398ebe11de6b91af335af6e02aa1fa2"}, "originalPosition": 96}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mzc2MDUzOQ==", "bodyText": "I actually tried to add typehints initially; they work poorly due to the fact that this works both on bytes and strings (but it's hard for mypy to know that it will be all one or all the other). But I added some comments at least.", "url": "https://github.com/apache/beam/pull/13488#discussion_r543760539", "createdAt": "2020-12-15T23:24:18Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/io.py", "diffHunk": "@@ -192,14 +207,133 @@ def expand(self, root):\n                 self.reader,\n                 self.args,\n                 self.kwargs,\n+                self.binary,\n                 self.incremental,\n-                self.splittable,\n-                self.binary)))\n+                self.splitter)))\n     from apache_beam.dataframe import convert\n     return convert.to_dataframe(\n         pcoll, proxy=_prefix_range_index_with(':', sample[:0]))\n \n \n+class _Splitter:\n+  def empty_buffer(self):\n+    raise NotImplementedError(self)\n+\n+  def read_header(self, handle):\n+    raise NotImplementedError(self)\n+\n+  def read_to_record_boundary(self, buffered, handle):\n+    raise NotImplementedError(self)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mjk4MTU4OQ=="}, "originalCommit": {"oid": "f23dc2d67398ebe11de6b91af335af6e02aa1fa2"}, "originalPosition": 96}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2503, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}