{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTIyNTkyODg4", "number": 13365, "reviewThreads": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQyMDo1ODo1OVrOE9Y9WA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMFQwMzowMzo1NFrOFQrpFQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyODA3NTEyOnYy", "diffSide": "RIGHT", "path": "website/www/site/content/en/blog/kafka-to-pubsub-template.md", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQyMDo1ODo1OVrOH6Dq5Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQxODoxMToyOVrOIUnIlw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDYzOTU4OQ==", "bodyText": "Would not this be a Dataflow template?", "url": "https://github.com/apache/beam/pull/13365#discussion_r530639589", "createdAt": "2020-11-25T20:58:59Z", "author": {"login": "aaltay"}, "path": "website/www/site/content/en/blog/kafka-to-pubsub-template.md", "diffHunk": "@@ -0,0 +1,69 @@\n+---\n+layout: post\n+title:  \"Template to ingest data from Apache Kafka to Google Cloud Pub/Sub\"\n+date:   2020-10-28 00:00:01 -0800\n+categories:\n+  - blog\n+  - java\n+authors:\n+  - Ilya Kozyrev\n+  - Artur Khanin\n+  - Alex Kosolapov\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+In this blog post we present an example template that creates a pipeline\n+to read data from a single or multiple topics from\n+[Apache Kafka](https://kafka.apache.org/) and write data into a topic\n+in [Google Pub/Sub](https://cloud.google.com/pubsub).\n+The template provides code examples to \n+implement simple yet powerful pipelines and also provides an out-of-the-box solution \n+that you can just _\"plug'n'play\"_. \n+\n+We hope you will find this template useful for setting up data pipelines between Kafka and Pub/Sub.\n+\n+# Template specs\n+\n+Supported data formats:\n+- Serializable plaintext formats, such as JSON\n+- [PubSubMessage](https://cloud.google.com/pubsub/docs/reference/rest/v1/PubsubMessage).\n+\n+Supported input source configurations:\n+- Single or multiple Apache Kafka bootstrap servers\n+- Apache Kafka SASL/SCRAM authentication over plaintext or SSL connection\n+- Secrets vault service [HashiCorp Vault](https://www.vaultproject.io/).\n+\n+Supported destination configuration:\n+- Single Google Pub/Sub topic.\n+\n+In a simple scenario, the template will create an Apache Beam pipeline that will read messages from a source Kafka server with a source topic, and stream the text messages into specified Pub/Sub destination topic. Other scenarios may need Kafka SASL/SCRAM authentication, that can be performed over plain text or SSL encrypted connection. The template supports using a single Kafka user account to authenticate in the provided source Kafka servers and topics. To support SASL authenticaton over SSL the template will need an SSL certificate location and access to a secrets vault service with Kafka username and password, currently supporting HashiCorp Vault.\n+\n+# Where can I run this template?\n+\n+There are two ways to execute the pipeline.\n+1. Locally. This way has many options - run directly from your IntelliJ, or create `.jar` file and run\n+it in the terminal, or use your favourite method.\n+2. In [Google Cloud](https://cloud.google.com/). Using Google Cloud [Dataflow](https://cloud.google.com/dataflow) with `gcloud`\n+command-line tool you can create a Flex Template out of this Beam template and execute it in Google Cloud Platform.\n+\n+The only difference between local and cloud execution is that **Flex version of this template doesn't support SSL configuration.**\n+\n+# Next Steps\n+Give this **first Beam template** a try, and let us know your feedback adding comments to [BEAM-11065 JIRA ticket](https://issues.apache.org/jira/browse/BEAM-11065) or sending an email in [this thread](https://lists.apache.org/thread.html/r8db90b3a1271188afb31ea52ccfed231f276f26ded3855d90084fe85%40%3Cdev.beam.apache.org%3E)!", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "28147fa1f416336ac7ba69fde6fbc99ff4df5d4a"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODQ4MzYwNw==", "bodyText": "Changed this to Beam example", "url": "https://github.com/apache/beam/pull/13365#discussion_r558483607", "createdAt": "2021-01-15T18:11:29Z", "author": {"login": "KhaninArtur"}, "path": "website/www/site/content/en/blog/kafka-to-pubsub-template.md", "diffHunk": "@@ -0,0 +1,69 @@\n+---\n+layout: post\n+title:  \"Template to ingest data from Apache Kafka to Google Cloud Pub/Sub\"\n+date:   2020-10-28 00:00:01 -0800\n+categories:\n+  - blog\n+  - java\n+authors:\n+  - Ilya Kozyrev\n+  - Artur Khanin\n+  - Alex Kosolapov\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+In this blog post we present an example template that creates a pipeline\n+to read data from a single or multiple topics from\n+[Apache Kafka](https://kafka.apache.org/) and write data into a topic\n+in [Google Pub/Sub](https://cloud.google.com/pubsub).\n+The template provides code examples to \n+implement simple yet powerful pipelines and also provides an out-of-the-box solution \n+that you can just _\"plug'n'play\"_. \n+\n+We hope you will find this template useful for setting up data pipelines between Kafka and Pub/Sub.\n+\n+# Template specs\n+\n+Supported data formats:\n+- Serializable plaintext formats, such as JSON\n+- [PubSubMessage](https://cloud.google.com/pubsub/docs/reference/rest/v1/PubsubMessage).\n+\n+Supported input source configurations:\n+- Single or multiple Apache Kafka bootstrap servers\n+- Apache Kafka SASL/SCRAM authentication over plaintext or SSL connection\n+- Secrets vault service [HashiCorp Vault](https://www.vaultproject.io/).\n+\n+Supported destination configuration:\n+- Single Google Pub/Sub topic.\n+\n+In a simple scenario, the template will create an Apache Beam pipeline that will read messages from a source Kafka server with a source topic, and stream the text messages into specified Pub/Sub destination topic. Other scenarios may need Kafka SASL/SCRAM authentication, that can be performed over plain text or SSL encrypted connection. The template supports using a single Kafka user account to authenticate in the provided source Kafka servers and topics. To support SASL authenticaton over SSL the template will need an SSL certificate location and access to a secrets vault service with Kafka username and password, currently supporting HashiCorp Vault.\n+\n+# Where can I run this template?\n+\n+There are two ways to execute the pipeline.\n+1. Locally. This way has many options - run directly from your IntelliJ, or create `.jar` file and run\n+it in the terminal, or use your favourite method.\n+2. In [Google Cloud](https://cloud.google.com/). Using Google Cloud [Dataflow](https://cloud.google.com/dataflow) with `gcloud`\n+command-line tool you can create a Flex Template out of this Beam template and execute it in Google Cloud Platform.\n+\n+The only difference between local and cloud execution is that **Flex version of this template doesn't support SSL configuration.**\n+\n+# Next Steps\n+Give this **first Beam template** a try, and let us know your feedback adding comments to [BEAM-11065 JIRA ticket](https://issues.apache.org/jira/browse/BEAM-11065) or sending an email in [this thread](https://lists.apache.org/thread.html/r8db90b3a1271188afb31ea52ccfed231f276f26ded3855d90084fe85%40%3Cdev.beam.apache.org%3E)!", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDYzOTU4OQ=="}, "originalCommit": {"oid": "28147fa1f416336ac7ba69fde6fbc99ff4df5d4a"}, "originalPosition": 64}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ4NDMxMDYwOnYy", "diffSide": "RIGHT", "path": "website/www/site/content/en/blog/kafka-to-pubsub-template.md", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wN1QyMDo1NzoxOFrOIP8DXg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQxNzozODoxMFrOIUlyZQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzU4MzQ1NA==", "bodyText": "I'd use \"plain text\" unless you specifically mean this phrase in the context of cryptography\nhttps://developers.google.com/style/word-list#plain-text", "url": "https://github.com/apache/beam/pull/13365#discussion_r553583454", "createdAt": "2021-01-07T20:57:18Z", "author": {"login": "rosetn"}, "path": "website/www/site/content/en/blog/kafka-to-pubsub-template.md", "diffHunk": "@@ -0,0 +1,69 @@\n+---\n+layout: post\n+title:  \"Template to ingest data from Apache Kafka to Google Cloud Pub/Sub\"\n+date:   2020-10-28 00:00:01 -0800\n+categories:\n+  - blog\n+  - java\n+authors:\n+  - Ilya Kozyrev\n+  - Artur Khanin\n+  - Alex Kosolapov\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+In this blog post we present an example template that creates a pipeline\n+to read data from a single or multiple topics from\n+[Apache Kafka](https://kafka.apache.org/) and write data into a topic\n+in [Google Pub/Sub](https://cloud.google.com/pubsub).\n+The template provides code examples to \n+implement simple yet powerful pipelines and also provides an out-of-the-box solution \n+that you can just _\"plug'n'play\"_. \n+\n+We hope you will find this template useful for setting up data pipelines between Kafka and Pub/Sub.\n+\n+# Template specs\n+\n+Supported data formats:\n+- Serializable plaintext formats, such as JSON", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "28147fa1f416336ac7ba69fde6fbc99ff4df5d4a"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODQ2MTU0MQ==", "bodyText": "Changed to \"plain text\"", "url": "https://github.com/apache/beam/pull/13365#discussion_r558461541", "createdAt": "2021-01-15T17:38:10Z", "author": {"login": "KhaninArtur"}, "path": "website/www/site/content/en/blog/kafka-to-pubsub-template.md", "diffHunk": "@@ -0,0 +1,69 @@\n+---\n+layout: post\n+title:  \"Template to ingest data from Apache Kafka to Google Cloud Pub/Sub\"\n+date:   2020-10-28 00:00:01 -0800\n+categories:\n+  - blog\n+  - java\n+authors:\n+  - Ilya Kozyrev\n+  - Artur Khanin\n+  - Alex Kosolapov\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+In this blog post we present an example template that creates a pipeline\n+to read data from a single or multiple topics from\n+[Apache Kafka](https://kafka.apache.org/) and write data into a topic\n+in [Google Pub/Sub](https://cloud.google.com/pubsub).\n+The template provides code examples to \n+implement simple yet powerful pipelines and also provides an out-of-the-box solution \n+that you can just _\"plug'n'play\"_. \n+\n+We hope you will find this template useful for setting up data pipelines between Kafka and Pub/Sub.\n+\n+# Template specs\n+\n+Supported data formats:\n+- Serializable plaintext formats, such as JSON", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzU4MzQ1NA=="}, "originalCommit": {"oid": "28147fa1f416336ac7ba69fde6fbc99ff4df5d4a"}, "originalPosition": 40}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ4NDMxNTcyOnYy", "diffSide": "RIGHT", "path": "website/www/site/content/en/blog/kafka-to-pubsub-template.md", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wN1QyMDo1OTowNlrOIP8GqA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQxNzozODoxNVrOIUlyrQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzU4NDI5Ng==", "bodyText": "Suggesting adding a noun to make it easier to read--\"from a single topic or multiple topics\"", "url": "https://github.com/apache/beam/pull/13365#discussion_r553584296", "createdAt": "2021-01-07T20:59:06Z", "author": {"login": "rosetn"}, "path": "website/www/site/content/en/blog/kafka-to-pubsub-template.md", "diffHunk": "@@ -0,0 +1,69 @@\n+---\n+layout: post\n+title:  \"Template to ingest data from Apache Kafka to Google Cloud Pub/Sub\"\n+date:   2020-10-28 00:00:01 -0800\n+categories:\n+  - blog\n+  - java\n+authors:\n+  - Ilya Kozyrev\n+  - Artur Khanin\n+  - Alex Kosolapov\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+In this blog post we present an example template that creates a pipeline\n+to read data from a single or multiple topics from", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "28147fa1f416336ac7ba69fde6fbc99ff4df5d4a"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODQ2MTYxMw==", "bodyText": "Added", "url": "https://github.com/apache/beam/pull/13365#discussion_r558461613", "createdAt": "2021-01-15T17:38:15Z", "author": {"login": "KhaninArtur"}, "path": "website/www/site/content/en/blog/kafka-to-pubsub-template.md", "diffHunk": "@@ -0,0 +1,69 @@\n+---\n+layout: post\n+title:  \"Template to ingest data from Apache Kafka to Google Cloud Pub/Sub\"\n+date:   2020-10-28 00:00:01 -0800\n+categories:\n+  - blog\n+  - java\n+authors:\n+  - Ilya Kozyrev\n+  - Artur Khanin\n+  - Alex Kosolapov\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+In this blog post we present an example template that creates a pipeline\n+to read data from a single or multiple topics from", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzU4NDI5Ng=="}, "originalCommit": {"oid": "28147fa1f416336ac7ba69fde6fbc99ff4df5d4a"}, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzQ4NDMyNzQzOnYy", "diffSide": "RIGHT", "path": "website/www/site/content/en/blog/kafka-to-pubsub-template.md", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wN1QyMTowMzozNVrOIP8OFw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNVQxNzozODo0MVrOIUlzqw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzU4NjE5OQ==", "bodyText": "Should we link to Flex Templates page? https://cloud.google.com/dataflow/docs/concepts/dataflow-templates", "url": "https://github.com/apache/beam/pull/13365#discussion_r553586199", "createdAt": "2021-01-07T21:03:35Z", "author": {"login": "rosetn"}, "path": "website/www/site/content/en/blog/kafka-to-pubsub-template.md", "diffHunk": "@@ -0,0 +1,69 @@\n+---\n+layout: post\n+title:  \"Template to ingest data from Apache Kafka to Google Cloud Pub/Sub\"\n+date:   2020-10-28 00:00:01 -0800\n+categories:\n+  - blog\n+  - java\n+authors:\n+  - Ilya Kozyrev\n+  - Artur Khanin\n+  - Alex Kosolapov\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+In this blog post we present an example template that creates a pipeline\n+to read data from a single or multiple topics from\n+[Apache Kafka](https://kafka.apache.org/) and write data into a topic\n+in [Google Pub/Sub](https://cloud.google.com/pubsub).\n+The template provides code examples to \n+implement simple yet powerful pipelines and also provides an out-of-the-box solution \n+that you can just _\"plug'n'play\"_. \n+\n+We hope you will find this template useful for setting up data pipelines between Kafka and Pub/Sub.\n+\n+# Template specs\n+\n+Supported data formats:\n+- Serializable plaintext formats, such as JSON\n+- [PubSubMessage](https://cloud.google.com/pubsub/docs/reference/rest/v1/PubsubMessage).\n+\n+Supported input source configurations:\n+- Single or multiple Apache Kafka bootstrap servers\n+- Apache Kafka SASL/SCRAM authentication over plaintext or SSL connection\n+- Secrets vault service [HashiCorp Vault](https://www.vaultproject.io/).\n+\n+Supported destination configuration:\n+- Single Google Pub/Sub topic.\n+\n+In a simple scenario, the template will create an Apache Beam pipeline that will read messages from a source Kafka server with a source topic, and stream the text messages into specified Pub/Sub destination topic. Other scenarios may need Kafka SASL/SCRAM authentication, that can be performed over plain text or SSL encrypted connection. The template supports using a single Kafka user account to authenticate in the provided source Kafka servers and topics. To support SASL authenticaton over SSL the template will need an SSL certificate location and access to a secrets vault service with Kafka username and password, currently supporting HashiCorp Vault.\n+\n+# Where can I run this template?\n+\n+There are two ways to execute the pipeline.\n+1. Locally. This way has many options - run directly from your IntelliJ, or create `.jar` file and run\n+it in the terminal, or use your favourite method.\n+2. In [Google Cloud](https://cloud.google.com/). Using Google Cloud [Dataflow](https://cloud.google.com/dataflow) with `gcloud`\n+command-line tool you can create a Flex Template out of this Beam template and execute it in Google Cloud Platform.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "28147fa1f416336ac7ba69fde6fbc99ff4df5d4a"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODQ2MTg2Nw==", "bodyText": "Added link to Flex Templates", "url": "https://github.com/apache/beam/pull/13365#discussion_r558461867", "createdAt": "2021-01-15T17:38:41Z", "author": {"login": "KhaninArtur"}, "path": "website/www/site/content/en/blog/kafka-to-pubsub-template.md", "diffHunk": "@@ -0,0 +1,69 @@\n+---\n+layout: post\n+title:  \"Template to ingest data from Apache Kafka to Google Cloud Pub/Sub\"\n+date:   2020-10-28 00:00:01 -0800\n+categories:\n+  - blog\n+  - java\n+authors:\n+  - Ilya Kozyrev\n+  - Artur Khanin\n+  - Alex Kosolapov\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+In this blog post we present an example template that creates a pipeline\n+to read data from a single or multiple topics from\n+[Apache Kafka](https://kafka.apache.org/) and write data into a topic\n+in [Google Pub/Sub](https://cloud.google.com/pubsub).\n+The template provides code examples to \n+implement simple yet powerful pipelines and also provides an out-of-the-box solution \n+that you can just _\"plug'n'play\"_. \n+\n+We hope you will find this template useful for setting up data pipelines between Kafka and Pub/Sub.\n+\n+# Template specs\n+\n+Supported data formats:\n+- Serializable plaintext formats, such as JSON\n+- [PubSubMessage](https://cloud.google.com/pubsub/docs/reference/rest/v1/PubsubMessage).\n+\n+Supported input source configurations:\n+- Single or multiple Apache Kafka bootstrap servers\n+- Apache Kafka SASL/SCRAM authentication over plaintext or SSL connection\n+- Secrets vault service [HashiCorp Vault](https://www.vaultproject.io/).\n+\n+Supported destination configuration:\n+- Single Google Pub/Sub topic.\n+\n+In a simple scenario, the template will create an Apache Beam pipeline that will read messages from a source Kafka server with a source topic, and stream the text messages into specified Pub/Sub destination topic. Other scenarios may need Kafka SASL/SCRAM authentication, that can be performed over plain text or SSL encrypted connection. The template supports using a single Kafka user account to authenticate in the provided source Kafka servers and topics. To support SASL authenticaton over SSL the template will need an SSL certificate location and access to a secrets vault service with Kafka username and password, currently supporting HashiCorp Vault.\n+\n+# Where can I run this template?\n+\n+There are two ways to execute the pipeline.\n+1. Locally. This way has many options - run directly from your IntelliJ, or create `.jar` file and run\n+it in the terminal, or use your favourite method.\n+2. In [Google Cloud](https://cloud.google.com/). Using Google Cloud [Dataflow](https://cloud.google.com/dataflow) with `gcloud`\n+command-line tool you can create a Flex Template out of this Beam template and execute it in Google Cloud Platform.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzU4NjE5OQ=="}, "originalCommit": {"oid": "28147fa1f416336ac7ba69fde6fbc99ff4df5d4a"}, "originalPosition": 59}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUxNzYzNDIyOnYy", "diffSide": "RIGHT", "path": "website/www/site/content/en/blog/kafka-to-pubsub-example.md", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNlQwMTozMDo1NVrOIU2_9A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xOFQxMjozMDoxNFrOIVnODg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODc0MzU0MA==", "bodyText": "For 2.27.0 - I would suggest linking to https://beam.apache.org/blog/beam-2.27.0/ and adding a line item to that release post about this template.", "url": "https://github.com/apache/beam/pull/13365#discussion_r558743540", "createdAt": "2021-01-16T01:30:55Z", "author": {"login": "aaltay"}, "path": "website/www/site/content/en/blog/kafka-to-pubsub-example.md", "diffHunk": "@@ -0,0 +1,89 @@\n+---\n+layout: post\n+title:  \"Example to ingest data from Apache Kafka to Google Cloud Pub/Sub\"\n+date:   2021-01-15 00:00:01 -0800\n+categories:\n+  - blog\n+  - java\n+authors:\n+  - arturkhanin\n+  - ilyakozyrev\n+  - alexkosolapov\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+In this blog post we present an example that creates a pipeline to read data from a single topic or\n+multiple topics from [Apache Kafka](https://kafka.apache.org/) and write data into a topic\n+in [Google Pub/Sub](https://cloud.google.com/pubsub). The example provides code samples to implement\n+simple yet powerful pipelines and also provides an out-of-the-box solution that you can just _\"\n+plug'n'play\"_.\n+\n+This end-to-end example is included\n+in [Apache Beam release 2.27](https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12319527&version=12349380)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bf8404ea1bea39bbf6f6023b5341809abb3a61f5"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTUzMzU4Mg==", "bodyText": "Thanks for the suggestion! Did this.", "url": "https://github.com/apache/beam/pull/13365#discussion_r559533582", "createdAt": "2021-01-18T12:30:14Z", "author": {"login": "KhaninArtur"}, "path": "website/www/site/content/en/blog/kafka-to-pubsub-example.md", "diffHunk": "@@ -0,0 +1,89 @@\n+---\n+layout: post\n+title:  \"Example to ingest data from Apache Kafka to Google Cloud Pub/Sub\"\n+date:   2021-01-15 00:00:01 -0800\n+categories:\n+  - blog\n+  - java\n+authors:\n+  - arturkhanin\n+  - ilyakozyrev\n+  - alexkosolapov\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+In this blog post we present an example that creates a pipeline to read data from a single topic or\n+multiple topics from [Apache Kafka](https://kafka.apache.org/) and write data into a topic\n+in [Google Pub/Sub](https://cloud.google.com/pubsub). The example provides code samples to implement\n+simple yet powerful pipelines and also provides an out-of-the-box solution that you can just _\"\n+plug'n'play\"_.\n+\n+This end-to-end example is included\n+in [Apache Beam release 2.27](https://issues.apache.org/jira/secure/ReleaseNote.jspa?projectId=12319527&version=12349380)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODc0MzU0MA=="}, "originalCommit": {"oid": "bf8404ea1bea39bbf6f6023b5341809abb3a61f5"}, "originalPosition": 34}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzUzMDM2NTY1OnYy", "diffSide": "RIGHT", "path": "website/www/site/content/en/blog/kafka-to-pubsub-example.md", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMFQwMzowMzo1NFrOIWq9aQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yMFQxMjoxODo1OVrOIW7qwg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDY0MzQzMw==", "bodyText": "Nit: You don't need any end punctuations for these list items.\nMore information here: https://developers.google.com/style/lists#numbered,-lettered,-and-bulleted-lists", "url": "https://github.com/apache/beam/pull/13365#discussion_r560643433", "createdAt": "2021-01-20T03:03:54Z", "author": {"login": "rosetn"}, "path": "website/www/site/content/en/blog/kafka-to-pubsub-example.md", "diffHunk": "@@ -0,0 +1,89 @@\n+---\n+layout: post\n+title:  \"Example to ingest data from Apache Kafka to Google Cloud Pub/Sub\"\n+date:   2021-01-15 00:00:01 -0800\n+categories:\n+  - blog\n+  - java\n+authors:\n+  - arturkhanin\n+  - ilyakozyrev\n+  - alexkosolapov\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+In this blog post we present an example that creates a pipeline to read data from a single topic or\n+multiple topics from [Apache Kafka](https://kafka.apache.org/) and write data into a topic\n+in [Google Pub/Sub](https://cloud.google.com/pubsub). The example provides code samples to implement\n+simple yet powerful pipelines and also provides an out-of-the-box solution that you can just _\"\n+plug'n'play\"_.\n+\n+This end-to-end example is included\n+in [Apache Beam release 2.27](https://beam.apache.org/blog/beam-2.27.0/)\n+and can be downloaded [here](https://beam.apache.org/get-started/downloads/#2270-2020-12-22).\n+\n+We hope you will find this example useful for setting up data pipelines between Kafka and Pub/Sub.\n+\n+# Example specs\n+\n+Supported data formats:\n+\n+- Serializable plain text formats, such as JSON\n+- [PubSubMessage](https://cloud.google.com/pubsub/docs/reference/rest/v1/PubsubMessage).", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "aec12296fdd4c9c5bc8639d524a1cac12a21f435"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDkxNzE4Ng==", "bodyText": "Thank you! Fixed it.", "url": "https://github.com/apache/beam/pull/13365#discussion_r560917186", "createdAt": "2021-01-20T12:18:59Z", "author": {"login": "KhaninArtur"}, "path": "website/www/site/content/en/blog/kafka-to-pubsub-example.md", "diffHunk": "@@ -0,0 +1,89 @@\n+---\n+layout: post\n+title:  \"Example to ingest data from Apache Kafka to Google Cloud Pub/Sub\"\n+date:   2021-01-15 00:00:01 -0800\n+categories:\n+  - blog\n+  - java\n+authors:\n+  - arturkhanin\n+  - ilyakozyrev\n+  - alexkosolapov\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+In this blog post we present an example that creates a pipeline to read data from a single topic or\n+multiple topics from [Apache Kafka](https://kafka.apache.org/) and write data into a topic\n+in [Google Pub/Sub](https://cloud.google.com/pubsub). The example provides code samples to implement\n+simple yet powerful pipelines and also provides an out-of-the-box solution that you can just _\"\n+plug'n'play\"_.\n+\n+This end-to-end example is included\n+in [Apache Beam release 2.27](https://beam.apache.org/blog/beam-2.27.0/)\n+and can be downloaded [here](https://beam.apache.org/get-started/downloads/#2270-2020-12-22).\n+\n+We hope you will find this example useful for setting up data pipelines between Kafka and Pub/Sub.\n+\n+# Example specs\n+\n+Supported data formats:\n+\n+- Serializable plain text formats, such as JSON\n+- [PubSubMessage](https://cloud.google.com/pubsub/docs/reference/rest/v1/PubsubMessage).", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MDY0MzQzMw=="}, "originalCommit": {"oid": "aec12296fdd4c9c5bc8639d524a1cac12a21f435"}, "originalPosition": 44}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2825, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}