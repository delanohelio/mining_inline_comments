{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDIwNDMzMzMz", "number": 11754, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMFQwMDoyNjoxMFrOD-BH3w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMFQwMDoyNjoyMVrOD-BIAQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2MzU2NzAzOnYy", "diffSide": "RIGHT", "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/example/BeamSqlExample.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMFQwMDoyNjoxMFrOGX3LLw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMFQwMDozNzo1MFrOGX3X8Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY3NDQxNQ==", "bodyText": "could you change this to withRowSchema(type)? It does the same thing, but it's less verbose", "url": "https://github.com/apache/beam/pull/11754#discussion_r427674415", "createdAt": "2020-05-20T00:26:10Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/example/BeamSqlExample.java", "diffHunk": "@@ -66,38 +68,47 @@ public static void main(String[] args) {\n         inputTable.apply(SqlTransform.query(\"select c1, c2, c3 from PCOLLECTION where c1 > 1\"));\n \n     // print the output record of case 1;\n-    outputStream.apply(\n-        \"log_result\",\n-        MapElements.via(\n-            new SimpleFunction<Row, Row>() {\n-              @Override\n-              public Row apply(Row input) {\n-                // expect output:\n-                //  PCOLLECTION: [3, row, 3.0]\n-                //  PCOLLECTION: [2, row, 2.0]\n-                System.out.println(\"PCOLLECTION: \" + input.getValues());\n-                return input;\n-              }\n-            }));\n+    outputStream\n+        .apply(\n+            \"log_result\",\n+            MapElements.via(\n+                new SimpleFunction<Row, Row>() {\n+                  @Override\n+                  public Row apply(Row input) {\n+                    // expect output:\n+                    //  PCOLLECTION: [3, row, 3.0]\n+                    //  PCOLLECTION: [2, row, 2.0]\n+                    System.out.println(\"PCOLLECTION: \" + input.getValues());\n+                    return input;\n+                  }\n+                }))\n+        .setCoder(RowCoder.of(type));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "76b8c0a01b9f47633002b70ef95b739c7a61252d"}, "originalPosition": 47}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY3NzY4MQ==", "bodyText": "I can do that. I did setRowSchema(type) and it worked!", "url": "https://github.com/apache/beam/pull/11754#discussion_r427677681", "createdAt": "2020-05-20T00:37:50Z", "author": {"login": "omarismail94"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/example/BeamSqlExample.java", "diffHunk": "@@ -66,38 +68,47 @@ public static void main(String[] args) {\n         inputTable.apply(SqlTransform.query(\"select c1, c2, c3 from PCOLLECTION where c1 > 1\"));\n \n     // print the output record of case 1;\n-    outputStream.apply(\n-        \"log_result\",\n-        MapElements.via(\n-            new SimpleFunction<Row, Row>() {\n-              @Override\n-              public Row apply(Row input) {\n-                // expect output:\n-                //  PCOLLECTION: [3, row, 3.0]\n-                //  PCOLLECTION: [2, row, 2.0]\n-                System.out.println(\"PCOLLECTION: \" + input.getValues());\n-                return input;\n-              }\n-            }));\n+    outputStream\n+        .apply(\n+            \"log_result\",\n+            MapElements.via(\n+                new SimpleFunction<Row, Row>() {\n+                  @Override\n+                  public Row apply(Row input) {\n+                    // expect output:\n+                    //  PCOLLECTION: [3, row, 3.0]\n+                    //  PCOLLECTION: [2, row, 2.0]\n+                    System.out.println(\"PCOLLECTION: \" + input.getValues());\n+                    return input;\n+                  }\n+                }))\n+        .setCoder(RowCoder.of(type));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY3NDQxNQ=="}, "originalCommit": {"oid": "76b8c0a01b9f47633002b70ef95b739c7a61252d"}, "originalPosition": 47}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2MzU2NzM3OnYy", "diffSide": "RIGHT", "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/example/BeamSqlExample.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMFQwMDoyNjoyMVrOGX3LaA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMFQwMToxMzowMlrOGX37Lw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY3NDQ3Mg==", "bodyText": "Here as well", "url": "https://github.com/apache/beam/pull/11754#discussion_r427674472", "createdAt": "2020-05-20T00:26:21Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/example/BeamSqlExample.java", "diffHunk": "@@ -66,38 +68,47 @@ public static void main(String[] args) {\n         inputTable.apply(SqlTransform.query(\"select c1, c2, c3 from PCOLLECTION where c1 > 1\"));\n \n     // print the output record of case 1;\n-    outputStream.apply(\n-        \"log_result\",\n-        MapElements.via(\n-            new SimpleFunction<Row, Row>() {\n-              @Override\n-              public Row apply(Row input) {\n-                // expect output:\n-                //  PCOLLECTION: [3, row, 3.0]\n-                //  PCOLLECTION: [2, row, 2.0]\n-                System.out.println(\"PCOLLECTION: \" + input.getValues());\n-                return input;\n-              }\n-            }));\n+    outputStream\n+        .apply(\n+            \"log_result\",\n+            MapElements.via(\n+                new SimpleFunction<Row, Row>() {\n+                  @Override\n+                  public Row apply(Row input) {\n+                    // expect output:\n+                    //  PCOLLECTION: [3, row, 3.0]\n+                    //  PCOLLECTION: [2, row, 2.0]\n+                    System.out.println(\"PCOLLECTION: \" + input.getValues());\n+                    return input;\n+                  }\n+                }))\n+        .setCoder(RowCoder.of(type));\n \n     // Case 2. run the query with SqlTransform.query over result PCollection of case 1.\n     PCollection<Row> outputStream2 =\n         PCollectionTuple.of(new TupleTag<>(\"CASE1_RESULT\"), outputStream)\n             .apply(SqlTransform.query(\"select c2, sum(c3) from CASE1_RESULT group by c2\"));\n \n     // print the output record of case 2;\n-    outputStream2.apply(\n-        \"log_result\",\n-        MapElements.via(\n-            new SimpleFunction<Row, Row>() {\n-              @Override\n-              public Row apply(Row input) {\n-                // expect output:\n-                //  CASE1_RESULT: [row, 5.0]\n-                System.out.println(\"CASE1_RESULT: \" + input.getValues());\n-                return input;\n-              }\n-            }));\n+    outputStream2\n+        .apply(\n+            \"log_result\",\n+            MapElements.via(\n+                new SimpleFunction<Row, Row>() {\n+                  @Override\n+                  public Row apply(Row input) {\n+                    // expect output:\n+                    //  CASE1_RESULT: [row, 5.0]\n+                    System.out.println(\"CASE1_RESULT: \" + input.getValues());\n+                    return input;\n+                  }\n+                }))\n+        .setCoder(\n+            RowCoder.of(\n+                Schema.builder()\n+                    .addStringField(\"stringField\")\n+                    .addDoubleField(\"doubleField\")\n+                    .build()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "76b8c0a01b9f47633002b70ef95b739c7a61252d"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY3ODAzMw==", "bodyText": "I tried setRowSchema(type) and it failed with : java.lang.ClassCastException: java.lang.String cannot be cast to java.lang.Integer.\nI think it is inferring the schema as 3 fields, but the result only returns two fields, and that's why it throws the error", "url": "https://github.com/apache/beam/pull/11754#discussion_r427678033", "createdAt": "2020-05-20T00:39:12Z", "author": {"login": "omarismail94"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/example/BeamSqlExample.java", "diffHunk": "@@ -66,38 +68,47 @@ public static void main(String[] args) {\n         inputTable.apply(SqlTransform.query(\"select c1, c2, c3 from PCOLLECTION where c1 > 1\"));\n \n     // print the output record of case 1;\n-    outputStream.apply(\n-        \"log_result\",\n-        MapElements.via(\n-            new SimpleFunction<Row, Row>() {\n-              @Override\n-              public Row apply(Row input) {\n-                // expect output:\n-                //  PCOLLECTION: [3, row, 3.0]\n-                //  PCOLLECTION: [2, row, 2.0]\n-                System.out.println(\"PCOLLECTION: \" + input.getValues());\n-                return input;\n-              }\n-            }));\n+    outputStream\n+        .apply(\n+            \"log_result\",\n+            MapElements.via(\n+                new SimpleFunction<Row, Row>() {\n+                  @Override\n+                  public Row apply(Row input) {\n+                    // expect output:\n+                    //  PCOLLECTION: [3, row, 3.0]\n+                    //  PCOLLECTION: [2, row, 2.0]\n+                    System.out.println(\"PCOLLECTION: \" + input.getValues());\n+                    return input;\n+                  }\n+                }))\n+        .setCoder(RowCoder.of(type));\n \n     // Case 2. run the query with SqlTransform.query over result PCollection of case 1.\n     PCollection<Row> outputStream2 =\n         PCollectionTuple.of(new TupleTag<>(\"CASE1_RESULT\"), outputStream)\n             .apply(SqlTransform.query(\"select c2, sum(c3) from CASE1_RESULT group by c2\"));\n \n     // print the output record of case 2;\n-    outputStream2.apply(\n-        \"log_result\",\n-        MapElements.via(\n-            new SimpleFunction<Row, Row>() {\n-              @Override\n-              public Row apply(Row input) {\n-                // expect output:\n-                //  CASE1_RESULT: [row, 5.0]\n-                System.out.println(\"CASE1_RESULT: \" + input.getValues());\n-                return input;\n-              }\n-            }));\n+    outputStream2\n+        .apply(\n+            \"log_result\",\n+            MapElements.via(\n+                new SimpleFunction<Row, Row>() {\n+                  @Override\n+                  public Row apply(Row input) {\n+                    // expect output:\n+                    //  CASE1_RESULT: [row, 5.0]\n+                    System.out.println(\"CASE1_RESULT: \" + input.getValues());\n+                    return input;\n+                  }\n+                }))\n+        .setCoder(\n+            RowCoder.of(\n+                Schema.builder()\n+                    .addStringField(\"stringField\")\n+                    .addDoubleField(\"doubleField\")\n+                    .build()));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY3NDQ3Mg=="}, "originalCommit": {"oid": "76b8c0a01b9f47633002b70ef95b739c7a61252d"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY3ODcyNw==", "bodyText": "This is part of the Stack trace that makes me think that\nCaused by: java.lang.ClassCastException: java.lang.String cannot be cast to java.lang.Integer\n        at org.apache.beam.sdk.coders.VarIntCoder.encode(VarIntCoder.java:33)\n        at org.apache.beam.sdk.coders.RowCoderGenerator$EncodeInstruction.encodeDelegate(RowCoderGenerator.java:270)\n        at org.apache.beam.sdk.coders.Coder$ByteBuddy$E99UrF3W.encode(Unknown Source)\n        at org.apache.beam.sdk.coders.Coder$ByteBuddy$E99UrF3W.encode(Unknown Source)\n        at org.apache.beam.sdk.schemas.SchemaCoder.encode(SchemaCoder.java:115)", "url": "https://github.com/apache/beam/pull/11754#discussion_r427678727", "createdAt": "2020-05-20T00:41:40Z", "author": {"login": "omarismail94"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/example/BeamSqlExample.java", "diffHunk": "@@ -66,38 +68,47 @@ public static void main(String[] args) {\n         inputTable.apply(SqlTransform.query(\"select c1, c2, c3 from PCOLLECTION where c1 > 1\"));\n \n     // print the output record of case 1;\n-    outputStream.apply(\n-        \"log_result\",\n-        MapElements.via(\n-            new SimpleFunction<Row, Row>() {\n-              @Override\n-              public Row apply(Row input) {\n-                // expect output:\n-                //  PCOLLECTION: [3, row, 3.0]\n-                //  PCOLLECTION: [2, row, 2.0]\n-                System.out.println(\"PCOLLECTION: \" + input.getValues());\n-                return input;\n-              }\n-            }));\n+    outputStream\n+        .apply(\n+            \"log_result\",\n+            MapElements.via(\n+                new SimpleFunction<Row, Row>() {\n+                  @Override\n+                  public Row apply(Row input) {\n+                    // expect output:\n+                    //  PCOLLECTION: [3, row, 3.0]\n+                    //  PCOLLECTION: [2, row, 2.0]\n+                    System.out.println(\"PCOLLECTION: \" + input.getValues());\n+                    return input;\n+                  }\n+                }))\n+        .setCoder(RowCoder.of(type));\n \n     // Case 2. run the query with SqlTransform.query over result PCollection of case 1.\n     PCollection<Row> outputStream2 =\n         PCollectionTuple.of(new TupleTag<>(\"CASE1_RESULT\"), outputStream)\n             .apply(SqlTransform.query(\"select c2, sum(c3) from CASE1_RESULT group by c2\"));\n \n     // print the output record of case 2;\n-    outputStream2.apply(\n-        \"log_result\",\n-        MapElements.via(\n-            new SimpleFunction<Row, Row>() {\n-              @Override\n-              public Row apply(Row input) {\n-                // expect output:\n-                //  CASE1_RESULT: [row, 5.0]\n-                System.out.println(\"CASE1_RESULT: \" + input.getValues());\n-                return input;\n-              }\n-            }));\n+    outputStream2\n+        .apply(\n+            \"log_result\",\n+            MapElements.via(\n+                new SimpleFunction<Row, Row>() {\n+                  @Override\n+                  public Row apply(Row input) {\n+                    // expect output:\n+                    //  CASE1_RESULT: [row, 5.0]\n+                    System.out.println(\"CASE1_RESULT: \" + input.getValues());\n+                    return input;\n+                  }\n+                }))\n+        .setCoder(\n+            RowCoder.of(\n+                Schema.builder()\n+                    .addStringField(\"stringField\")\n+                    .addDoubleField(\"doubleField\")\n+                    .build()));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY3NDQ3Mg=="}, "originalCommit": {"oid": "76b8c0a01b9f47633002b70ef95b739c7a61252d"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY4MTU4MA==", "bodyText": "oh for this call you will need to use\nSchema.builder()\n\ufffc                    .addStringField(\"stringField\")\n\ufffc                    .addDoubleField(\"doubleField\")\n\ufffc                    .build()\n\nlike you had in the setCoder call", "url": "https://github.com/apache/beam/pull/11754#discussion_r427681580", "createdAt": "2020-05-20T00:52:45Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/example/BeamSqlExample.java", "diffHunk": "@@ -66,38 +68,47 @@ public static void main(String[] args) {\n         inputTable.apply(SqlTransform.query(\"select c1, c2, c3 from PCOLLECTION where c1 > 1\"));\n \n     // print the output record of case 1;\n-    outputStream.apply(\n-        \"log_result\",\n-        MapElements.via(\n-            new SimpleFunction<Row, Row>() {\n-              @Override\n-              public Row apply(Row input) {\n-                // expect output:\n-                //  PCOLLECTION: [3, row, 3.0]\n-                //  PCOLLECTION: [2, row, 2.0]\n-                System.out.println(\"PCOLLECTION: \" + input.getValues());\n-                return input;\n-              }\n-            }));\n+    outputStream\n+        .apply(\n+            \"log_result\",\n+            MapElements.via(\n+                new SimpleFunction<Row, Row>() {\n+                  @Override\n+                  public Row apply(Row input) {\n+                    // expect output:\n+                    //  PCOLLECTION: [3, row, 3.0]\n+                    //  PCOLLECTION: [2, row, 2.0]\n+                    System.out.println(\"PCOLLECTION: \" + input.getValues());\n+                    return input;\n+                  }\n+                }))\n+        .setCoder(RowCoder.of(type));\n \n     // Case 2. run the query with SqlTransform.query over result PCollection of case 1.\n     PCollection<Row> outputStream2 =\n         PCollectionTuple.of(new TupleTag<>(\"CASE1_RESULT\"), outputStream)\n             .apply(SqlTransform.query(\"select c2, sum(c3) from CASE1_RESULT group by c2\"));\n \n     // print the output record of case 2;\n-    outputStream2.apply(\n-        \"log_result\",\n-        MapElements.via(\n-            new SimpleFunction<Row, Row>() {\n-              @Override\n-              public Row apply(Row input) {\n-                // expect output:\n-                //  CASE1_RESULT: [row, 5.0]\n-                System.out.println(\"CASE1_RESULT: \" + input.getValues());\n-                return input;\n-              }\n-            }));\n+    outputStream2\n+        .apply(\n+            \"log_result\",\n+            MapElements.via(\n+                new SimpleFunction<Row, Row>() {\n+                  @Override\n+                  public Row apply(Row input) {\n+                    // expect output:\n+                    //  CASE1_RESULT: [row, 5.0]\n+                    System.out.println(\"CASE1_RESULT: \" + input.getValues());\n+                    return input;\n+                  }\n+                }))\n+        .setCoder(\n+            RowCoder.of(\n+                Schema.builder()\n+                    .addStringField(\"stringField\")\n+                    .addDoubleField(\"doubleField\")\n+                    .build()));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY3NDQ3Mg=="}, "originalCommit": {"oid": "76b8c0a01b9f47633002b70ef95b739c7a61252d"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY4NjcwMw==", "bodyText": "Actually, it is not due to the reduction in the number of field, but the order in which the fields are selected in the SELECT statement. Here is the order it expects\n\nInt, String, Double\n\nand the fields that represent those types are: c1, c2, c3\nIf your results print out of order, it fails due to the ClassCastException. I tried doing this query and it failed:\nselect  c2, sum(c1), sum(c3) from CASE1_RESULT group by c2,\nbut if I do\nselect  sum(c1),c2, sum(c3) from CASE1_RESULT group by c2\nit works! You can see that in the one that failed, c1 and c2s positions have switched, so the encoder trips out. What's cool is that you can see the results correctly calculated in:\n System.out.println(\"CASE1_RESULT: \" + input.getValues());\nbut it seems that when the result is encoded, the program throws an error due to the results being out of order. I guess this is because it sees .setRowSchema(type);, and as the order of the schema is \"Int, String, Double\", the results have to abide by that rule. That why it fails when we did:\nc2, sum(c3) from CASE1_RESULT group by c2", "url": "https://github.com/apache/beam/pull/11754#discussion_r427686703", "createdAt": "2020-05-20T01:13:02Z", "author": {"login": "omarismail94"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/example/BeamSqlExample.java", "diffHunk": "@@ -66,38 +68,47 @@ public static void main(String[] args) {\n         inputTable.apply(SqlTransform.query(\"select c1, c2, c3 from PCOLLECTION where c1 > 1\"));\n \n     // print the output record of case 1;\n-    outputStream.apply(\n-        \"log_result\",\n-        MapElements.via(\n-            new SimpleFunction<Row, Row>() {\n-              @Override\n-              public Row apply(Row input) {\n-                // expect output:\n-                //  PCOLLECTION: [3, row, 3.0]\n-                //  PCOLLECTION: [2, row, 2.0]\n-                System.out.println(\"PCOLLECTION: \" + input.getValues());\n-                return input;\n-              }\n-            }));\n+    outputStream\n+        .apply(\n+            \"log_result\",\n+            MapElements.via(\n+                new SimpleFunction<Row, Row>() {\n+                  @Override\n+                  public Row apply(Row input) {\n+                    // expect output:\n+                    //  PCOLLECTION: [3, row, 3.0]\n+                    //  PCOLLECTION: [2, row, 2.0]\n+                    System.out.println(\"PCOLLECTION: \" + input.getValues());\n+                    return input;\n+                  }\n+                }))\n+        .setCoder(RowCoder.of(type));\n \n     // Case 2. run the query with SqlTransform.query over result PCollection of case 1.\n     PCollection<Row> outputStream2 =\n         PCollectionTuple.of(new TupleTag<>(\"CASE1_RESULT\"), outputStream)\n             .apply(SqlTransform.query(\"select c2, sum(c3) from CASE1_RESULT group by c2\"));\n \n     // print the output record of case 2;\n-    outputStream2.apply(\n-        \"log_result\",\n-        MapElements.via(\n-            new SimpleFunction<Row, Row>() {\n-              @Override\n-              public Row apply(Row input) {\n-                // expect output:\n-                //  CASE1_RESULT: [row, 5.0]\n-                System.out.println(\"CASE1_RESULT: \" + input.getValues());\n-                return input;\n-              }\n-            }));\n+    outputStream2\n+        .apply(\n+            \"log_result\",\n+            MapElements.via(\n+                new SimpleFunction<Row, Row>() {\n+                  @Override\n+                  public Row apply(Row input) {\n+                    // expect output:\n+                    //  CASE1_RESULT: [row, 5.0]\n+                    System.out.println(\"CASE1_RESULT: \" + input.getValues());\n+                    return input;\n+                  }\n+                }))\n+        .setCoder(\n+            RowCoder.of(\n+                Schema.builder()\n+                    .addStringField(\"stringField\")\n+                    .addDoubleField(\"doubleField\")\n+                    .build()));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyNzY3NDQ3Mg=="}, "originalCommit": {"oid": "76b8c0a01b9f47633002b70ef95b739c7a61252d"}, "originalPosition": 85}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3816, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}