{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDcyOTQxNjY1", "number": 12678, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNVQxNzoyNzowMlrOEcLA5w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNVQxNzozNTo1MlrOEcLNfw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk3OTc2MDM5OnYy", "diffSide": "RIGHT", "path": "runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowPipelineTranslator.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNVQxNzoyNzowMlrOHGifCA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQwMDoyMzo0OFrOHPelvQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjYxODUwNA==", "bodyText": "Is ALLOWS_SHARDABLE_STATE  supported by both streaming engine and windmill appliance? If it's only for streaming engine, is it safe to populate this field for both?", "url": "https://github.com/apache/beam/pull/12678#discussion_r476618504", "createdAt": "2020-08-25T17:27:02Z", "author": {"login": "boyuanzz"}, "path": "runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowPipelineTranslator.java", "diffHunk": "@@ -1264,6 +1268,10 @@ private static void translateFn(\n     // in streaming but does not work in batch\n     if (context.getPipelineOptions().isStreaming() && isStateful) {\n       stepContext.addInput(PropertyNames.USES_KEYED_STATE, \"true\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c672e4c07c64f7ab18d6f59f69daab8b60ee0d17"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjgzOTMyMQ==", "bodyText": "As a first step, it's only supported by streaming engine. But it's fine to set it in both cases since the field will be ignored in appliance. We will need to wait for the backend to recognize this property anyway, otherwise the pipeline will check fail.", "url": "https://github.com/apache/beam/pull/12678#discussion_r476839321", "createdAt": "2020-08-25T23:12:40Z", "author": {"login": "nehsyc"}, "path": "runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowPipelineTranslator.java", "diffHunk": "@@ -1264,6 +1268,10 @@ private static void translateFn(\n     // in streaming but does not work in batch\n     if (context.getPipelineOptions().isStreaming() && isStateful) {\n       stepContext.addInput(PropertyNames.USES_KEYED_STATE, \"true\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjYxODUwNA=="}, "originalCommit": {"oid": "c672e4c07c64f7ab18d6f59f69daab8b60ee0d17"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTk5MTg2OQ==", "bodyText": "Update on this:\nI added an experiment to gate the auto-sharding so this can be merged without waiting for the backend. It will also make the testing easier.\nI also added a check for the experiment, \"beam_fn_api\". My intention was to disable the feature for unified worker but I guess this way we would disable auto-sharding for both unified worker and java worker using fn api - I remember that we are not going to support the latter so it seems fine to me. But let me know if my understanding is incorrect.", "url": "https://github.com/apache/beam/pull/12678#discussion_r485991869", "createdAt": "2020-09-10T00:23:48Z", "author": {"login": "nehsyc"}, "path": "runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowPipelineTranslator.java", "diffHunk": "@@ -1264,6 +1268,10 @@ private static void translateFn(\n     // in streaming but does not work in batch\n     if (context.getPipelineOptions().isStreaming() && isStateful) {\n       stepContext.addInput(PropertyNames.USES_KEYED_STATE, \"true\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjYxODUwNA=="}, "originalCommit": {"oid": "c672e4c07c64f7ab18d6f59f69daab8b60ee0d17"}, "originalPosition": 35}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk3OTc5MjYzOnYy", "diffSide": "RIGHT", "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/GroupIntoBatches.java", "isResolved": false, "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNVQxNzozNTo1MlrOHGiy-A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQwMDoyODoyOFrOHPeqrA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjYyMzYwOA==", "bodyText": "I don't think we want to make GroupInToBatchesDoFn as public. Instead of adding property in translateFn , we can do it at transform level, where you can check transform instanceof GroupIntoBatches, for example: https://github.com/apache/beam/blob/master/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowPipelineTranslator.java#L752", "url": "https://github.com/apache/beam/pull/12678#discussion_r476623608", "createdAt": "2020-08-25T17:35:52Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/GroupIntoBatches.java", "diffHunk": "@@ -100,8 +99,7 @@ public long getBatchSize() {\n         ParDo.of(new GroupIntoBatchesDoFn<>(batchSize, allowedLateness, keyCoder, valueCoder)));\n   }\n \n-  @VisibleForTesting\n-  static class GroupIntoBatchesDoFn<K, InputT>\n+  public static class GroupIntoBatchesDoFn<K, InputT>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c672e4c07c64f7ab18d6f59f69daab8b60ee0d17"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjgzNTAwMA==", "bodyText": "Yeah I did try matching the transform by transform instanceof GroupIntoBatches but got error:\nInconvertible types; cannot cast 'org.apache.beam.runners.dataflow.PrimitiveParDoSingleFactory.ParDoSingle<InputT,OutputT>' to 'org.apache.beam.sdk.transforms.GroupIntoBatches'\n\nAny ideas?", "url": "https://github.com/apache/beam/pull/12678#discussion_r476835000", "createdAt": "2020-08-25T23:08:41Z", "author": {"login": "nehsyc"}, "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/GroupIntoBatches.java", "diffHunk": "@@ -100,8 +99,7 @@ public long getBatchSize() {\n         ParDo.of(new GroupIntoBatchesDoFn<>(batchSize, allowedLateness, keyCoder, valueCoder)));\n   }\n \n-  @VisibleForTesting\n-  static class GroupIntoBatchesDoFn<K, InputT>\n+  public static class GroupIntoBatchesDoFn<K, InputT>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjYyMzYwOA=="}, "originalCommit": {"oid": "c672e4c07c64f7ab18d6f59f69daab8b60ee0d17"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njg2MjE0OA==", "bodyText": "Have you tried registerTransformTranslator ?", "url": "https://github.com/apache/beam/pull/12678#discussion_r476862148", "createdAt": "2020-08-25T23:34:19Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/GroupIntoBatches.java", "diffHunk": "@@ -100,8 +99,7 @@ public long getBatchSize() {\n         ParDo.of(new GroupIntoBatchesDoFn<>(batchSize, allowedLateness, keyCoder, valueCoder)));\n   }\n \n-  @VisibleForTesting\n-  static class GroupIntoBatchesDoFn<K, InputT>\n+  public static class GroupIntoBatchesDoFn<K, InputT>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjYyMzYwOA=="}, "originalCommit": {"oid": "c672e4c07c64f7ab18d6f59f69daab8b60ee0d17"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjkwOTQwNA==", "bodyText": "I assume that we would still need to access to GroupIntoBatchesDoFn if we register a separate translator, to fill USER_FN for example: https://github.com/apache/beam/blob/master/runners/google-cloud-dataflow-java/src/main/java/org/apache/beam/runners/dataflow/DataflowPipelineTranslator.java#L1241.\nCan the same transform go though multiple translators? Is that what you were suggesting?", "url": "https://github.com/apache/beam/pull/12678#discussion_r476909404", "createdAt": "2020-08-26T00:25:18Z", "author": {"login": "nehsyc"}, "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/GroupIntoBatches.java", "diffHunk": "@@ -100,8 +99,7 @@ public long getBatchSize() {\n         ParDo.of(new GroupIntoBatchesDoFn<>(batchSize, allowedLateness, keyCoder, valueCoder)));\n   }\n \n-  @VisibleForTesting\n-  static class GroupIntoBatchesDoFn<K, InputT>\n+  public static class GroupIntoBatchesDoFn<K, InputT>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjYyMzYwOA=="}, "originalCommit": {"oid": "c672e4c07c64f7ab18d6f59f69daab8b60ee0d17"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njk5MTEyNw==", "bodyText": "I was thinking about we could check GroupIntoBatches directly but it turns out that the translation happens after transform expansions, where we only can get ParDo(GroupIntoBatchesDoFn). One thing we can do to avoid exposing GroupIntoBatchesDoFn is to make DoFnSignature understand that this is a shardable stateful DoFn, like what we do for RESTRICTION_ENCODING.  @lukecwik Do you have any suggestion here?", "url": "https://github.com/apache/beam/pull/12678#discussion_r476991127", "createdAt": "2020-08-26T02:27:06Z", "author": {"login": "boyuanzz"}, "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/GroupIntoBatches.java", "diffHunk": "@@ -100,8 +99,7 @@ public long getBatchSize() {\n         ParDo.of(new GroupIntoBatchesDoFn<>(batchSize, allowedLateness, keyCoder, valueCoder)));\n   }\n \n-  @VisibleForTesting\n-  static class GroupIntoBatchesDoFn<K, InputT>\n+  public static class GroupIntoBatchesDoFn<K, InputT>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjYyMzYwOA=="}, "originalCommit": {"oid": "c672e4c07c64f7ab18d6f59f69daab8b60ee0d17"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NzQ5MjYwOQ==", "bodyText": "There have been a few ways this has been done in the past:\n\n(easiest), record which objects need this property within the DataflowRunner and then lookup this information during translation (e.g. doesPCollectionRequireIndexedFormat)\nreplace the public GroupIntoBatches transform with a Dataflow specific primitive that makes any additional information visible that is needed during translation (e.g. DataflowRunner.CombineGroupedValues)", "url": "https://github.com/apache/beam/pull/12678#discussion_r477492609", "createdAt": "2020-08-26T18:10:25Z", "author": {"login": "lukecwik"}, "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/GroupIntoBatches.java", "diffHunk": "@@ -100,8 +99,7 @@ public long getBatchSize() {\n         ParDo.of(new GroupIntoBatchesDoFn<>(batchSize, allowedLateness, keyCoder, valueCoder)));\n   }\n \n-  @VisibleForTesting\n-  static class GroupIntoBatchesDoFn<K, InputT>\n+  public static class GroupIntoBatchesDoFn<K, InputT>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjYyMzYwOA=="}, "originalCommit": {"oid": "c672e4c07c64f7ab18d6f59f69daab8b60ee0d17"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTk5MzEzMg==", "bodyText": "Thanks! I applied the first solution recommended above and updated the PR accordingly - I added an override for streaming GroupIntoBatches which records the input PCollection, and also a transform matcher to pass the override validation. PTAL.", "url": "https://github.com/apache/beam/pull/12678#discussion_r485993132", "createdAt": "2020-09-10T00:28:28Z", "author": {"login": "nehsyc"}, "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/GroupIntoBatches.java", "diffHunk": "@@ -100,8 +99,7 @@ public long getBatchSize() {\n         ParDo.of(new GroupIntoBatchesDoFn<>(batchSize, allowedLateness, keyCoder, valueCoder)));\n   }\n \n-  @VisibleForTesting\n-  static class GroupIntoBatchesDoFn<K, InputT>\n+  public static class GroupIntoBatchesDoFn<K, InputT>", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjYyMzYwOA=="}, "originalCommit": {"oid": "c672e4c07c64f7ab18d6f59f69daab8b60ee0d17"}, "originalPosition": 14}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 580, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}