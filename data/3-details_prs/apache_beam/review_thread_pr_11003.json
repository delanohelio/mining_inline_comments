{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzgxNTE0MjQx", "number": 11003, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQxODo1Mjo1NlrODmbCBg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQxODo1Mjo1NlrODmbCBg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQxNjE1MzY2OnYy", "diffSide": "RIGHT", "path": "sdks/java/extensions/sql/datacatalog/src/test/java/org/apache/beam/sdk/extensions/sql/meta/provider/datacatalog/DataCatalogBigQueryIT.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQxODo1Mjo1NlrOFz1OwQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0wOVQxOToxMDozM1rOFz1zBg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTg5MzgyNQ==", "bodyText": "I would suggest to add .withMethod(Method.FILE_LOADS) to be explicit. It connects it better with the comment above. And is protected in case the default changes.", "url": "https://github.com/apache/beam/pull/11003#discussion_r389893825", "createdAt": "2020-03-09T18:52:56Z", "author": {"login": "kennknowles"}, "path": "sdks/java/extensions/sql/datacatalog/src/test/java/org/apache/beam/sdk/extensions/sql/meta/provider/datacatalog/DataCatalogBigQueryIT.java", "diffHunk": "@@ -69,9 +73,18 @@\n \n     @Test\n     public void testRead() throws Exception {\n-      bigQuery.insertRows(ID_NAME_SCHEMA, row(1, \"name1\"), row(2, \"name2\"), row(3, \"name3\"));\n-\n       TableReference bqTable = bigQuery.tableReference();\n+\n+      // Streaming inserts do not work with DIRECT_READ mode, there is a several hour lag.\n+      PCollection<Row> data =\n+          writePipeline.apply(Create.of(row(1, \"name1\"), row(2, \"name2\"), row(3, \"name3\")));\n+      data.apply(\n+          BigQueryIO.<Row>write()\n+              .withSchema(BigQueryUtils.toTableSchema(ID_NAME_SCHEMA))\n+              .withFormatFunction(BigQueryUtils.toTableRow())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5238997e3b47b8743062aabcb57a237793859397"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTkwMzExMA==", "bodyText": "Done", "url": "https://github.com/apache/beam/pull/11003#discussion_r389903110", "createdAt": "2020-03-09T19:10:33Z", "author": {"login": "apilloud"}, "path": "sdks/java/extensions/sql/datacatalog/src/test/java/org/apache/beam/sdk/extensions/sql/meta/provider/datacatalog/DataCatalogBigQueryIT.java", "diffHunk": "@@ -69,9 +73,18 @@\n \n     @Test\n     public void testRead() throws Exception {\n-      bigQuery.insertRows(ID_NAME_SCHEMA, row(1, \"name1\"), row(2, \"name2\"), row(3, \"name3\"));\n-\n       TableReference bqTable = bigQuery.tableReference();\n+\n+      // Streaming inserts do not work with DIRECT_READ mode, there is a several hour lag.\n+      PCollection<Row> data =\n+          writePipeline.apply(Create.of(row(1, \"name1\"), row(2, \"name2\"), row(3, \"name3\")));\n+      data.apply(\n+          BigQueryIO.<Row>write()\n+              .withSchema(BigQueryUtils.toTableSchema(ID_NAME_SCHEMA))\n+              .withFormatFunction(BigQueryUtils.toTableRow())", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM4OTg5MzgyNQ=="}, "originalCommit": {"oid": "5238997e3b47b8743062aabcb57a237793859397"}, "originalPosition": 36}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 1951, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}