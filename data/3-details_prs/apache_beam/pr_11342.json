{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDAwNjM3ODUz", "number": 11342, "title": "[BEAM-9577] New artifact staging and retrieval service for Java.", "bodyText": "Please add a meaningful description for your change here\n\nThank you for your contribution! Follow this checklist to help us incorporate your contribution quickly and easily:\n\n Choose reviewer(s) and mention them in a comment (R: @username).\n Format the pull request title like [BEAM-XXX] Fixes bug in ApproximateQuantiles, where you replace BEAM-XXX with the appropriate JIRA issue, if applicable. This will automatically link the pull request to the issue.\n Update CHANGES.md with noteworthy changes.\n If this contribution is large, please file an Apache Individual Contributor License Agreement.\n\nSee the Contributor Guide for more tips on how to make review process smoother.\nPost-Commit Tests Status (on master branch)\n\n\n\nLang\nSDK\nApex\nDataflow\nFlink\nGearpump\nSamza\nSpark\n\n\n\n\nGo\n\n---\n---\n\n---\n---\n\n\n\nJava\n\n\n\n\n\n\n\n\n\nPython\n\n---\n\n\n---\n---\n\n\n\nXLang\n---\n---\n---\n\n---\n---\n\n\n\n\nPre-Commit Tests Status (on master branch)\n\n\n\n---\nJava\nPython\nGo\nWebsite\n\n\n\n\nNon-portable\n\n\n\n\n\n\nPortable\n---\n\n---\n---\n\n\n\nSee .test-infra/jenkins/README for trigger phrase, status and link of all Jenkins jobs.", "createdAt": "2020-04-08T05:33:00Z", "url": "https://github.com/apache/beam/pull/11342", "merged": true, "mergeCommit": {"oid": "ec67a9374671ea9ae670fb0f3935ead2ebed7981"}, "closed": true, "closedAt": "2020-04-23T20:17:29Z", "author": {"login": "robertwb"}, "timelineItems": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcVjTh3ABqjMyMTI5OTA2NjM=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcafMV1gBqjMyNjU3MzI5MTE=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0129512d514615b9e603ccc84874095f80ac61e3", "author": {"user": {"login": "robertwb", "name": "Robert Bradshaw"}}, "url": "https://github.com/apache/beam/commit/0129512d514615b9e603ccc84874095f80ac61e3", "committedDate": "2020-04-08T05:06:47Z", "message": "[BEAM-9577] Multi-threaded artifact staging service backend.\n\nThis allows a staging service backed by a slower/high-latency\n(possibly distributed) filesystem to upload files in parallel."}, "afterCommit": {"oid": "7aa2fb0bcf7ddff3bf6a57d5677251ae9f62d359", "author": {"user": {"login": "robertwb", "name": "Robert Bradshaw"}}, "url": "https://github.com/apache/beam/commit/7aa2fb0bcf7ddff3bf6a57d5677251ae9f62d359", "committedDate": "2020-04-08T05:31:25Z", "message": "[BEAM-9577] Multi-threaded artifact staging service backend.\n\nThis allows a staging service backed by a slower/high-latency\n(possibly distributed) filesystem to upload files in parallel."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "7aa2fb0bcf7ddff3bf6a57d5677251ae9f62d359", "author": {"user": {"login": "robertwb", "name": "Robert Bradshaw"}}, "url": "https://github.com/apache/beam/commit/7aa2fb0bcf7ddff3bf6a57d5677251ae9f62d359", "committedDate": "2020-04-08T05:31:25Z", "message": "[BEAM-9577] Multi-threaded artifact staging service backend.\n\nThis allows a staging service backed by a slower/high-latency\n(possibly distributed) filesystem to upload files in parallel."}, "afterCommit": {"oid": "fde1d43ca27fdbb66cc6f0706bb85dc6ef3cc3bd", "author": {"user": {"login": "robertwb", "name": "Robert Bradshaw"}}, "url": "https://github.com/apache/beam/commit/fde1d43ca27fdbb66cc6f0706bb85dc6ef3cc3bd", "committedDate": "2020-04-08T22:39:17Z", "message": "make findbugs happy"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f813a905c58c6e3458c09136a89e24c82cb11ed9", "author": {"user": {"login": "robertwb", "name": "Robert Bradshaw"}}, "url": "https://github.com/apache/beam/commit/f813a905c58c6e3458c09136a89e24c82cb11ed9", "committedDate": "2020-04-10T20:33:25Z", "message": "[BEAM-9577] New artifact staging and retrieval service for Java."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9c8718e46a3692034de9c9a9ed0754bab325cec5", "author": {"user": {"login": "robertwb", "name": "Robert Bradshaw"}}, "url": "https://github.com/apache/beam/commit/9c8718e46a3692034de9c9a9ed0754bab325cec5", "committedDate": "2020-04-10T20:33:25Z", "message": "[BEAM-9577] Multi-threaded artifact staging service backend.\n\nThis allows a staging service backed by a slower/high-latency\n(possibly distributed) filesystem to upload files in parallel."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "fde1d43ca27fdbb66cc6f0706bb85dc6ef3cc3bd", "author": {"user": {"login": "robertwb", "name": "Robert Bradshaw"}}, "url": "https://github.com/apache/beam/commit/fde1d43ca27fdbb66cc6f0706bb85dc6ef3cc3bd", "committedDate": "2020-04-08T22:39:17Z", "message": "make findbugs happy"}, "afterCommit": {"oid": "9c8718e46a3692034de9c9a9ed0754bab325cec5", "author": {"user": {"login": "robertwb", "name": "Robert Bradshaw"}}, "url": "https://github.com/apache/beam/commit/9c8718e46a3692034de9c9a9ed0754bab325cec5", "committedDate": "2020-04-10T20:33:25Z", "message": "[BEAM-9577] Multi-threaded artifact staging service backend.\n\nThis allows a staging service backed by a slower/high-latency\n(possibly distributed) filesystem to upload files in parallel."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk0MDM1OTM0", "url": "https://github.com/apache/beam/pull/11342#pullrequestreview-394035934", "createdAt": "2020-04-15T18:38:25Z", "commit": {"oid": "9c8718e46a3692034de9c9a9ed0754bab325cec5"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 16, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQxODozODoyNVrOGGGozg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xN1QyMzoyNzowNFrOGHfvgw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTA1MzM5MA==", "bodyText": "nit: statingToken -> stagingToken", "url": "https://github.com/apache/beam/pull/11342#discussion_r409053390", "createdAt": "2020-04-15T18:38:25Z", "author": {"login": "lukecwik"}, "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/artifact/ArtifactStagingService.java", "diffHunk": "@@ -0,0 +1,606 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.fnexecution.artifact;\n+\n+import com.google.auto.value.AutoValue;\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.channels.Channels;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.FutureTask;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactApi;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactStagingServiceGrpc;\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+import org.apache.beam.runners.fnexecution.FnService;\n+import org.apache.beam.sdk.io.FileSystems;\n+import org.apache.beam.sdk.io.fs.ResolveOptions;\n+import org.apache.beam.sdk.io.fs.ResourceId;\n+import org.apache.beam.sdk.util.MimeTypes;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.ByteString;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.InvalidProtocolBufferException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.Status;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.StatusException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.stub.StreamObserver;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Splitter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class ArtifactStagingService\n+    extends ArtifactStagingServiceGrpc.ArtifactStagingServiceImplBase implements FnService {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(ArtifactStagingService.class);\n+\n+  private final ArtifactDestinationProvider destinationProvider;\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> toStage =\n+      new ConcurrentHashMap<>();\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> staged =\n+      new ConcurrentHashMap<>();\n+\n+  public ArtifactStagingService(ArtifactDestinationProvider destinationProvider) {\n+    this.destinationProvider = destinationProvider;\n+  }\n+\n+  /**\n+   * Registers a set of artifacts to be staged with this service.\n+   *\n+   * <p>A client (e.g. a Beam SDK) is expected to connect to this service with the given staging\n+   * token and offer resolution and retrieval of this set of artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   * @param artifacts all artifacts to stage, keyed by environment\n+   */\n+  public void registerJob(\n+      String stagingToken, Map<String, List<RunnerApi.ArtifactInformation>> artifacts) {\n+    assert !toStage.containsKey(stagingToken);\n+    toStage.put(stagingToken, artifacts);\n+  }\n+\n+  /**\n+   * Returns the rewritten artifacts associated with this job, keyed by environment.\n+   *\n+   * <p>This should be called after the client has finished offering artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   */\n+  public Map<String, List<RunnerApi.ArtifactInformation>> getStagedArtifacts(String stagingToken) {\n+    toStage.remove(stagingToken);\n+    return staged.remove(stagingToken);\n+  }\n+\n+  /** Provides a concrete location to which artifacts can be staged on retrieval. */\n+  public interface ArtifactDestinationProvider {\n+    ArtifactDestination getDestination(String stagingToken, String name) throws IOException;\n+  }\n+\n+  /**\n+   * A pairing of a newly created artifact type and an ouptut stream that will be readable at that\n+   * type.\n+   */\n+  @AutoValue\n+  public abstract static class ArtifactDestination {\n+    public static ArtifactDestination create(\n+        String typeUrn, ByteString typePayload, OutputStream out) {\n+      return new AutoValue_ArtifactStagingService_ArtifactDestination(typeUrn, typePayload, out);\n+    }\n+\n+    public static ArtifactDestination fromFile(String path) throws IOException {\n+      return fromFile(\n+          path,\n+          Channels.newOutputStream(\n+              FileSystems.create(\n+                  FileSystems.matchNewResource(path, false /* isDirectory */), MimeTypes.BINARY)));\n+    }\n+\n+    public static ArtifactDestination fromFile(String path, OutputStream out) {\n+      return create(\n+          ArtifactRetrievalService.FILE_ARTIFACT_URN,\n+          RunnerApi.ArtifactFilePayload.newBuilder().setPath(path).build().toByteString(),\n+          out);\n+    }\n+\n+    public abstract String getTypeUrn();\n+\n+    public abstract ByteString getTypePayload();\n+\n+    public abstract OutputStream getOutputStream();\n+  }\n+\n+  /**\n+   * An ArtifactDestinationProvider that places new artifacts as files in a Beam filesystem.\n+   *\n+   * @param root the directory in which to place all artifacts\n+   */\n+  public static ArtifactDestinationProvider beamFilesystemArtifactDestinationProvider(String root) {\n+    return (statingToken, name) -> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c8718e46a3692034de9c9a9ed0754bab325cec5"}, "originalPosition": 147}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDQ5OTE0Ng==", "bodyText": "This will avoid a copy being done via toByteArray\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                      dest.getOutputStream().write(chunk.toByteArray());\n          \n          \n            \n                      chunk.writeTo(dest.getOutputStream());", "url": "https://github.com/apache/beam/pull/11342#discussion_r410499146", "createdAt": "2020-04-17T22:28:00Z", "author": {"login": "lukecwik"}, "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/artifact/ArtifactStagingService.java", "diffHunk": "@@ -0,0 +1,606 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.fnexecution.artifact;\n+\n+import com.google.auto.value.AutoValue;\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.channels.Channels;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.FutureTask;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactApi;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactStagingServiceGrpc;\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+import org.apache.beam.runners.fnexecution.FnService;\n+import org.apache.beam.sdk.io.FileSystems;\n+import org.apache.beam.sdk.io.fs.ResolveOptions;\n+import org.apache.beam.sdk.io.fs.ResourceId;\n+import org.apache.beam.sdk.util.MimeTypes;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.ByteString;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.InvalidProtocolBufferException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.Status;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.StatusException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.stub.StreamObserver;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Splitter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class ArtifactStagingService\n+    extends ArtifactStagingServiceGrpc.ArtifactStagingServiceImplBase implements FnService {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(ArtifactStagingService.class);\n+\n+  private final ArtifactDestinationProvider destinationProvider;\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> toStage =\n+      new ConcurrentHashMap<>();\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> staged =\n+      new ConcurrentHashMap<>();\n+\n+  public ArtifactStagingService(ArtifactDestinationProvider destinationProvider) {\n+    this.destinationProvider = destinationProvider;\n+  }\n+\n+  /**\n+   * Registers a set of artifacts to be staged with this service.\n+   *\n+   * <p>A client (e.g. a Beam SDK) is expected to connect to this service with the given staging\n+   * token and offer resolution and retrieval of this set of artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   * @param artifacts all artifacts to stage, keyed by environment\n+   */\n+  public void registerJob(\n+      String stagingToken, Map<String, List<RunnerApi.ArtifactInformation>> artifacts) {\n+    assert !toStage.containsKey(stagingToken);\n+    toStage.put(stagingToken, artifacts);\n+  }\n+\n+  /**\n+   * Returns the rewritten artifacts associated with this job, keyed by environment.\n+   *\n+   * <p>This should be called after the client has finished offering artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   */\n+  public Map<String, List<RunnerApi.ArtifactInformation>> getStagedArtifacts(String stagingToken) {\n+    toStage.remove(stagingToken);\n+    return staged.remove(stagingToken);\n+  }\n+\n+  /** Provides a concrete location to which artifacts can be staged on retrieval. */\n+  public interface ArtifactDestinationProvider {\n+    ArtifactDestination getDestination(String stagingToken, String name) throws IOException;\n+  }\n+\n+  /**\n+   * A pairing of a newly created artifact type and an ouptut stream that will be readable at that\n+   * type.\n+   */\n+  @AutoValue\n+  public abstract static class ArtifactDestination {\n+    public static ArtifactDestination create(\n+        String typeUrn, ByteString typePayload, OutputStream out) {\n+      return new AutoValue_ArtifactStagingService_ArtifactDestination(typeUrn, typePayload, out);\n+    }\n+\n+    public static ArtifactDestination fromFile(String path) throws IOException {\n+      return fromFile(\n+          path,\n+          Channels.newOutputStream(\n+              FileSystems.create(\n+                  FileSystems.matchNewResource(path, false /* isDirectory */), MimeTypes.BINARY)));\n+    }\n+\n+    public static ArtifactDestination fromFile(String path, OutputStream out) {\n+      return create(\n+          ArtifactRetrievalService.FILE_ARTIFACT_URN,\n+          RunnerApi.ArtifactFilePayload.newBuilder().setPath(path).build().toByteString(),\n+          out);\n+    }\n+\n+    public abstract String getTypeUrn();\n+\n+    public abstract ByteString getTypePayload();\n+\n+    public abstract OutputStream getOutputStream();\n+  }\n+\n+  /**\n+   * An ArtifactDestinationProvider that places new artifacts as files in a Beam filesystem.\n+   *\n+   * @param root the directory in which to place all artifacts\n+   */\n+  public static ArtifactDestinationProvider beamFilesystemArtifactDestinationProvider(String root) {\n+    return (statingToken, name) -> {\n+      ResourceId path =\n+          FileSystems.matchNewResource(root, true)\n+              .resolve(statingToken, ResolveOptions.StandardResolveOptions.RESOLVE_DIRECTORY)\n+              .resolve(name, ResolveOptions.StandardResolveOptions.RESOLVE_FILE);\n+      return ArtifactDestination.fromFile(path.toString());\n+    };\n+  }\n+\n+  private enum State {\n+    START,\n+    RESOLVE,\n+    GET,\n+    GETCHUNK,\n+    DONE,\n+    ERROR,\n+  }\n+\n+  /**\n+   * Like the standard Semaphore, but allows an aquire to go over the limit if there is any room.\n+   *\n+   * <p>Also allows setting an error, to avoid issues with un-released aquires after error.\n+   */\n+  private static class OverflowingSemaphore {\n+    private int totalPermits;\n+    private int usedPermits;\n+    private Exception exception;\n+\n+    public OverflowingSemaphore(int totalPermits) {\n+      this.totalPermits = totalPermits;\n+      this.usedPermits = 0;\n+    }\n+\n+    synchronized void aquire(int permits) throws Exception {\n+      while (usedPermits >= totalPermits) {\n+        if (exception != null) {\n+          throw exception;\n+        }\n+        this.wait();\n+      }\n+      usedPermits += permits;\n+    }\n+\n+    synchronized void release(int permits) {\n+      usedPermits -= permits;\n+      this.notifyAll();\n+    }\n+\n+    synchronized void setException(Exception exception) {\n+      this.exception = exception;\n+      this.notifyAll();\n+    }\n+  }\n+\n+  /** A task that pulls bytes off a queue and actually writes them to a staging location. */\n+  private class StoreArtifact implements Callable<RunnerApi.ArtifactInformation> {\n+\n+    private String stagingToken;\n+    private String name;\n+    private RunnerApi.ArtifactInformation originalArtifact;\n+    private BlockingQueue<ByteString> bytesQueue;\n+    private OverflowingSemaphore totalPendingBytes;\n+\n+    public StoreArtifact(\n+        String stagingToken,\n+        String name,\n+        RunnerApi.ArtifactInformation originalArtifact,\n+        BlockingQueue<ByteString> bytesQueue,\n+        OverflowingSemaphore totalPendingBytes) {\n+      this.stagingToken = stagingToken;\n+      this.name = name;\n+      this.originalArtifact = originalArtifact;\n+      this.bytesQueue = bytesQueue;\n+      this.totalPendingBytes = totalPendingBytes;\n+    }\n+\n+    @Override\n+    public RunnerApi.ArtifactInformation call() throws IOException {\n+      try {\n+        ArtifactDestination dest = destinationProvider.getDestination(stagingToken, name);\n+        LOG.debug(\"Storing artifact for {}.{} at {}\", stagingToken, name, dest);\n+        ByteString chunk = bytesQueue.take();\n+        while (chunk.size() > 0) {\n+          totalPendingBytes.release(chunk.size());\n+          dest.getOutputStream().write(chunk.toByteArray());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c8718e46a3692034de9c9a9ed0754bab325cec5"}, "originalPosition": 231}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDUwMTE2Nw==", "bodyText": "Consider using CompletedFuture.completedFuture(fetched.get())\nhttps://docs.oracle.com/javase/8/docs/api/java/util/concurrent/CompletableFuture.html#completedFuture-U-", "url": "https://github.com/apache/beam/pull/11342#discussion_r410501167", "createdAt": "2020-04-17T22:35:28Z", "author": {"login": "lukecwik"}, "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/artifact/ArtifactStagingService.java", "diffHunk": "@@ -0,0 +1,606 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.fnexecution.artifact;\n+\n+import com.google.auto.value.AutoValue;\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.channels.Channels;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.FutureTask;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactApi;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactStagingServiceGrpc;\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+import org.apache.beam.runners.fnexecution.FnService;\n+import org.apache.beam.sdk.io.FileSystems;\n+import org.apache.beam.sdk.io.fs.ResolveOptions;\n+import org.apache.beam.sdk.io.fs.ResourceId;\n+import org.apache.beam.sdk.util.MimeTypes;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.ByteString;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.InvalidProtocolBufferException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.Status;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.StatusException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.stub.StreamObserver;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Splitter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class ArtifactStagingService\n+    extends ArtifactStagingServiceGrpc.ArtifactStagingServiceImplBase implements FnService {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(ArtifactStagingService.class);\n+\n+  private final ArtifactDestinationProvider destinationProvider;\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> toStage =\n+      new ConcurrentHashMap<>();\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> staged =\n+      new ConcurrentHashMap<>();\n+\n+  public ArtifactStagingService(ArtifactDestinationProvider destinationProvider) {\n+    this.destinationProvider = destinationProvider;\n+  }\n+\n+  /**\n+   * Registers a set of artifacts to be staged with this service.\n+   *\n+   * <p>A client (e.g. a Beam SDK) is expected to connect to this service with the given staging\n+   * token and offer resolution and retrieval of this set of artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   * @param artifacts all artifacts to stage, keyed by environment\n+   */\n+  public void registerJob(\n+      String stagingToken, Map<String, List<RunnerApi.ArtifactInformation>> artifacts) {\n+    assert !toStage.containsKey(stagingToken);\n+    toStage.put(stagingToken, artifacts);\n+  }\n+\n+  /**\n+   * Returns the rewritten artifacts associated with this job, keyed by environment.\n+   *\n+   * <p>This should be called after the client has finished offering artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   */\n+  public Map<String, List<RunnerApi.ArtifactInformation>> getStagedArtifacts(String stagingToken) {\n+    toStage.remove(stagingToken);\n+    return staged.remove(stagingToken);\n+  }\n+\n+  /** Provides a concrete location to which artifacts can be staged on retrieval. */\n+  public interface ArtifactDestinationProvider {\n+    ArtifactDestination getDestination(String stagingToken, String name) throws IOException;\n+  }\n+\n+  /**\n+   * A pairing of a newly created artifact type and an ouptut stream that will be readable at that\n+   * type.\n+   */\n+  @AutoValue\n+  public abstract static class ArtifactDestination {\n+    public static ArtifactDestination create(\n+        String typeUrn, ByteString typePayload, OutputStream out) {\n+      return new AutoValue_ArtifactStagingService_ArtifactDestination(typeUrn, typePayload, out);\n+    }\n+\n+    public static ArtifactDestination fromFile(String path) throws IOException {\n+      return fromFile(\n+          path,\n+          Channels.newOutputStream(\n+              FileSystems.create(\n+                  FileSystems.matchNewResource(path, false /* isDirectory */), MimeTypes.BINARY)));\n+    }\n+\n+    public static ArtifactDestination fromFile(String path, OutputStream out) {\n+      return create(\n+          ArtifactRetrievalService.FILE_ARTIFACT_URN,\n+          RunnerApi.ArtifactFilePayload.newBuilder().setPath(path).build().toByteString(),\n+          out);\n+    }\n+\n+    public abstract String getTypeUrn();\n+\n+    public abstract ByteString getTypePayload();\n+\n+    public abstract OutputStream getOutputStream();\n+  }\n+\n+  /**\n+   * An ArtifactDestinationProvider that places new artifacts as files in a Beam filesystem.\n+   *\n+   * @param root the directory in which to place all artifacts\n+   */\n+  public static ArtifactDestinationProvider beamFilesystemArtifactDestinationProvider(String root) {\n+    return (statingToken, name) -> {\n+      ResourceId path =\n+          FileSystems.matchNewResource(root, true)\n+              .resolve(statingToken, ResolveOptions.StandardResolveOptions.RESOLVE_DIRECTORY)\n+              .resolve(name, ResolveOptions.StandardResolveOptions.RESOLVE_FILE);\n+      return ArtifactDestination.fromFile(path.toString());\n+    };\n+  }\n+\n+  private enum State {\n+    START,\n+    RESOLVE,\n+    GET,\n+    GETCHUNK,\n+    DONE,\n+    ERROR,\n+  }\n+\n+  /**\n+   * Like the standard Semaphore, but allows an aquire to go over the limit if there is any room.\n+   *\n+   * <p>Also allows setting an error, to avoid issues with un-released aquires after error.\n+   */\n+  private static class OverflowingSemaphore {\n+    private int totalPermits;\n+    private int usedPermits;\n+    private Exception exception;\n+\n+    public OverflowingSemaphore(int totalPermits) {\n+      this.totalPermits = totalPermits;\n+      this.usedPermits = 0;\n+    }\n+\n+    synchronized void aquire(int permits) throws Exception {\n+      while (usedPermits >= totalPermits) {\n+        if (exception != null) {\n+          throw exception;\n+        }\n+        this.wait();\n+      }\n+      usedPermits += permits;\n+    }\n+\n+    synchronized void release(int permits) {\n+      usedPermits -= permits;\n+      this.notifyAll();\n+    }\n+\n+    synchronized void setException(Exception exception) {\n+      this.exception = exception;\n+      this.notifyAll();\n+    }\n+  }\n+\n+  /** A task that pulls bytes off a queue and actually writes them to a staging location. */\n+  private class StoreArtifact implements Callable<RunnerApi.ArtifactInformation> {\n+\n+    private String stagingToken;\n+    private String name;\n+    private RunnerApi.ArtifactInformation originalArtifact;\n+    private BlockingQueue<ByteString> bytesQueue;\n+    private OverflowingSemaphore totalPendingBytes;\n+\n+    public StoreArtifact(\n+        String stagingToken,\n+        String name,\n+        RunnerApi.ArtifactInformation originalArtifact,\n+        BlockingQueue<ByteString> bytesQueue,\n+        OverflowingSemaphore totalPendingBytes) {\n+      this.stagingToken = stagingToken;\n+      this.name = name;\n+      this.originalArtifact = originalArtifact;\n+      this.bytesQueue = bytesQueue;\n+      this.totalPendingBytes = totalPendingBytes;\n+    }\n+\n+    @Override\n+    public RunnerApi.ArtifactInformation call() throws IOException {\n+      try {\n+        ArtifactDestination dest = destinationProvider.getDestination(stagingToken, name);\n+        LOG.debug(\"Storing artifact for {}.{} at {}\", stagingToken, name, dest);\n+        ByteString chunk = bytesQueue.take();\n+        while (chunk.size() > 0) {\n+          totalPendingBytes.release(chunk.size());\n+          dest.getOutputStream().write(chunk.toByteArray());\n+          chunk = bytesQueue.take();\n+        }\n+        dest.getOutputStream().close();\n+        return originalArtifact\n+            .toBuilder()\n+            .setTypeUrn(dest.getTypeUrn())\n+            .setTypePayload(dest.getTypePayload())\n+            .build();\n+      } catch (IOException | InterruptedException exn) {\n+        // As this thread will no longer be draining the queue, we don't want to get stuck writing\n+        // to it.\n+        totalPendingBytes.setException(exn);\n+        LOG.error(\"Exception staging artifacts\", exn);\n+        if (exn instanceof IOException) {\n+          throw (IOException) exn;\n+        } else {\n+          throw new RuntimeException(exn);\n+        }\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public StreamObserver<ArtifactApi.ArtifactResponseWrapper> reverseArtifactRetrievalService(\n+      StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+\n+    return new StreamObserver<ArtifactApi.ArtifactResponseWrapper>() {\n+\n+      /** The maximum number of parallel threads to use to stage. */\n+      public static final int THREAD_POOL_SIZE = 10;\n+\n+      /** The maximum number of bytes to buffer across all writes before throttling. */\n+      public static final int MAX_PENDING_BYTES = 100 << 20; // 100 MB\n+\n+      String stagingToken;\n+      Map<String, List<RunnerApi.ArtifactInformation>> toResolve;\n+      Map<String, List<Future<RunnerApi.ArtifactInformation>>> stagedFutures;\n+      ExecutorService stagingExecutor;\n+      OverflowingSemaphore totalPendingBytes;\n+\n+      State state = State.START;\n+      Queue<String> pendingResolves;\n+      String currentEnvironment;\n+      int nameIndex;\n+      Queue<RunnerApi.ArtifactInformation> pendingGets;\n+      BlockingQueue<ByteString> currentOutput;\n+\n+      @Override\n+      @SuppressFBWarnings(value = \"SF_SWITCH_FALLTHROUGH\", justification = \"fallthrough intended\")\n+      public synchronized void onNext(ArtifactApi.ArtifactResponseWrapper responseWrapper) {\n+        switch (state) {\n+          case START:\n+            stagingToken = responseWrapper.getStagingToken();\n+            LOG.info(\"Staging artifacts for {}.\", stagingToken);\n+            toResolve = toStage.get(stagingToken);\n+            stagedFutures = new ConcurrentHashMap<>();\n+            pendingResolves = new ArrayDeque<>();\n+            pendingResolves.addAll(toResolve.keySet());\n+            stagingExecutor = Executors.newFixedThreadPool(THREAD_POOL_SIZE);\n+            totalPendingBytes = new OverflowingSemaphore(MAX_PENDING_BYTES);\n+            resolveNextEnvironment(responseObserver);\n+            break;\n+\n+          case RESOLVE:\n+            {\n+              currentEnvironment = pendingResolves.remove();\n+              stagedFutures.put(currentEnvironment, new ArrayList<>());\n+              pendingGets = new ArrayDeque<>();\n+              for (RunnerApi.ArtifactInformation artifact :\n+                  responseWrapper.getResolveArtifactResponse().getReplacementsList()) {\n+                Optional<RunnerApi.ArtifactInformation> fetched = getLocal(artifact);\n+                if (fetched.isPresent()) {\n+                  stagedFutures\n+                      .get(currentEnvironment)\n+                      .add(new FutureTask<RunnerApi.ArtifactInformation>(() -> fetched.get()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c8718e46a3692034de9c9a9ed0754bab325cec5"}, "originalPosition": 306}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDUwNTUyNg==", "bodyText": "An implementation could return an empty byte string but still say it isn't the last one which would incorrectly translate into EOF. Consider using an EOF bytestring instance object and doing == comparison to detect that its specifically the EOF instance.", "url": "https://github.com/apache/beam/pull/11342#discussion_r410505526", "createdAt": "2020-04-17T22:52:50Z", "author": {"login": "lukecwik"}, "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/artifact/ArtifactStagingService.java", "diffHunk": "@@ -0,0 +1,606 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.fnexecution.artifact;\n+\n+import com.google.auto.value.AutoValue;\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.channels.Channels;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.FutureTask;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactApi;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactStagingServiceGrpc;\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+import org.apache.beam.runners.fnexecution.FnService;\n+import org.apache.beam.sdk.io.FileSystems;\n+import org.apache.beam.sdk.io.fs.ResolveOptions;\n+import org.apache.beam.sdk.io.fs.ResourceId;\n+import org.apache.beam.sdk.util.MimeTypes;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.ByteString;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.InvalidProtocolBufferException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.Status;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.StatusException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.stub.StreamObserver;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Splitter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class ArtifactStagingService\n+    extends ArtifactStagingServiceGrpc.ArtifactStagingServiceImplBase implements FnService {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(ArtifactStagingService.class);\n+\n+  private final ArtifactDestinationProvider destinationProvider;\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> toStage =\n+      new ConcurrentHashMap<>();\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> staged =\n+      new ConcurrentHashMap<>();\n+\n+  public ArtifactStagingService(ArtifactDestinationProvider destinationProvider) {\n+    this.destinationProvider = destinationProvider;\n+  }\n+\n+  /**\n+   * Registers a set of artifacts to be staged with this service.\n+   *\n+   * <p>A client (e.g. a Beam SDK) is expected to connect to this service with the given staging\n+   * token and offer resolution and retrieval of this set of artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   * @param artifacts all artifacts to stage, keyed by environment\n+   */\n+  public void registerJob(\n+      String stagingToken, Map<String, List<RunnerApi.ArtifactInformation>> artifacts) {\n+    assert !toStage.containsKey(stagingToken);\n+    toStage.put(stagingToken, artifacts);\n+  }\n+\n+  /**\n+   * Returns the rewritten artifacts associated with this job, keyed by environment.\n+   *\n+   * <p>This should be called after the client has finished offering artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   */\n+  public Map<String, List<RunnerApi.ArtifactInformation>> getStagedArtifacts(String stagingToken) {\n+    toStage.remove(stagingToken);\n+    return staged.remove(stagingToken);\n+  }\n+\n+  /** Provides a concrete location to which artifacts can be staged on retrieval. */\n+  public interface ArtifactDestinationProvider {\n+    ArtifactDestination getDestination(String stagingToken, String name) throws IOException;\n+  }\n+\n+  /**\n+   * A pairing of a newly created artifact type and an ouptut stream that will be readable at that\n+   * type.\n+   */\n+  @AutoValue\n+  public abstract static class ArtifactDestination {\n+    public static ArtifactDestination create(\n+        String typeUrn, ByteString typePayload, OutputStream out) {\n+      return new AutoValue_ArtifactStagingService_ArtifactDestination(typeUrn, typePayload, out);\n+    }\n+\n+    public static ArtifactDestination fromFile(String path) throws IOException {\n+      return fromFile(\n+          path,\n+          Channels.newOutputStream(\n+              FileSystems.create(\n+                  FileSystems.matchNewResource(path, false /* isDirectory */), MimeTypes.BINARY)));\n+    }\n+\n+    public static ArtifactDestination fromFile(String path, OutputStream out) {\n+      return create(\n+          ArtifactRetrievalService.FILE_ARTIFACT_URN,\n+          RunnerApi.ArtifactFilePayload.newBuilder().setPath(path).build().toByteString(),\n+          out);\n+    }\n+\n+    public abstract String getTypeUrn();\n+\n+    public abstract ByteString getTypePayload();\n+\n+    public abstract OutputStream getOutputStream();\n+  }\n+\n+  /**\n+   * An ArtifactDestinationProvider that places new artifacts as files in a Beam filesystem.\n+   *\n+   * @param root the directory in which to place all artifacts\n+   */\n+  public static ArtifactDestinationProvider beamFilesystemArtifactDestinationProvider(String root) {\n+    return (statingToken, name) -> {\n+      ResourceId path =\n+          FileSystems.matchNewResource(root, true)\n+              .resolve(statingToken, ResolveOptions.StandardResolveOptions.RESOLVE_DIRECTORY)\n+              .resolve(name, ResolveOptions.StandardResolveOptions.RESOLVE_FILE);\n+      return ArtifactDestination.fromFile(path.toString());\n+    };\n+  }\n+\n+  private enum State {\n+    START,\n+    RESOLVE,\n+    GET,\n+    GETCHUNK,\n+    DONE,\n+    ERROR,\n+  }\n+\n+  /**\n+   * Like the standard Semaphore, but allows an aquire to go over the limit if there is any room.\n+   *\n+   * <p>Also allows setting an error, to avoid issues with un-released aquires after error.\n+   */\n+  private static class OverflowingSemaphore {\n+    private int totalPermits;\n+    private int usedPermits;\n+    private Exception exception;\n+\n+    public OverflowingSemaphore(int totalPermits) {\n+      this.totalPermits = totalPermits;\n+      this.usedPermits = 0;\n+    }\n+\n+    synchronized void aquire(int permits) throws Exception {\n+      while (usedPermits >= totalPermits) {\n+        if (exception != null) {\n+          throw exception;\n+        }\n+        this.wait();\n+      }\n+      usedPermits += permits;\n+    }\n+\n+    synchronized void release(int permits) {\n+      usedPermits -= permits;\n+      this.notifyAll();\n+    }\n+\n+    synchronized void setException(Exception exception) {\n+      this.exception = exception;\n+      this.notifyAll();\n+    }\n+  }\n+\n+  /** A task that pulls bytes off a queue and actually writes them to a staging location. */\n+  private class StoreArtifact implements Callable<RunnerApi.ArtifactInformation> {\n+\n+    private String stagingToken;\n+    private String name;\n+    private RunnerApi.ArtifactInformation originalArtifact;\n+    private BlockingQueue<ByteString> bytesQueue;\n+    private OverflowingSemaphore totalPendingBytes;\n+\n+    public StoreArtifact(\n+        String stagingToken,\n+        String name,\n+        RunnerApi.ArtifactInformation originalArtifact,\n+        BlockingQueue<ByteString> bytesQueue,\n+        OverflowingSemaphore totalPendingBytes) {\n+      this.stagingToken = stagingToken;\n+      this.name = name;\n+      this.originalArtifact = originalArtifact;\n+      this.bytesQueue = bytesQueue;\n+      this.totalPendingBytes = totalPendingBytes;\n+    }\n+\n+    @Override\n+    public RunnerApi.ArtifactInformation call() throws IOException {\n+      try {\n+        ArtifactDestination dest = destinationProvider.getDestination(stagingToken, name);\n+        LOG.debug(\"Storing artifact for {}.{} at {}\", stagingToken, name, dest);\n+        ByteString chunk = bytesQueue.take();\n+        while (chunk.size() > 0) {\n+          totalPendingBytes.release(chunk.size());\n+          dest.getOutputStream().write(chunk.toByteArray());\n+          chunk = bytesQueue.take();\n+        }\n+        dest.getOutputStream().close();\n+        return originalArtifact\n+            .toBuilder()\n+            .setTypeUrn(dest.getTypeUrn())\n+            .setTypePayload(dest.getTypePayload())\n+            .build();\n+      } catch (IOException | InterruptedException exn) {\n+        // As this thread will no longer be draining the queue, we don't want to get stuck writing\n+        // to it.\n+        totalPendingBytes.setException(exn);\n+        LOG.error(\"Exception staging artifacts\", exn);\n+        if (exn instanceof IOException) {\n+          throw (IOException) exn;\n+        } else {\n+          throw new RuntimeException(exn);\n+        }\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public StreamObserver<ArtifactApi.ArtifactResponseWrapper> reverseArtifactRetrievalService(\n+      StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+\n+    return new StreamObserver<ArtifactApi.ArtifactResponseWrapper>() {\n+\n+      /** The maximum number of parallel threads to use to stage. */\n+      public static final int THREAD_POOL_SIZE = 10;\n+\n+      /** The maximum number of bytes to buffer across all writes before throttling. */\n+      public static final int MAX_PENDING_BYTES = 100 << 20; // 100 MB\n+\n+      String stagingToken;\n+      Map<String, List<RunnerApi.ArtifactInformation>> toResolve;\n+      Map<String, List<Future<RunnerApi.ArtifactInformation>>> stagedFutures;\n+      ExecutorService stagingExecutor;\n+      OverflowingSemaphore totalPendingBytes;\n+\n+      State state = State.START;\n+      Queue<String> pendingResolves;\n+      String currentEnvironment;\n+      int nameIndex;\n+      Queue<RunnerApi.ArtifactInformation> pendingGets;\n+      BlockingQueue<ByteString> currentOutput;\n+\n+      @Override\n+      @SuppressFBWarnings(value = \"SF_SWITCH_FALLTHROUGH\", justification = \"fallthrough intended\")\n+      public synchronized void onNext(ArtifactApi.ArtifactResponseWrapper responseWrapper) {\n+        switch (state) {\n+          case START:\n+            stagingToken = responseWrapper.getStagingToken();\n+            LOG.info(\"Staging artifacts for {}.\", stagingToken);\n+            toResolve = toStage.get(stagingToken);\n+            stagedFutures = new ConcurrentHashMap<>();\n+            pendingResolves = new ArrayDeque<>();\n+            pendingResolves.addAll(toResolve.keySet());\n+            stagingExecutor = Executors.newFixedThreadPool(THREAD_POOL_SIZE);\n+            totalPendingBytes = new OverflowingSemaphore(MAX_PENDING_BYTES);\n+            resolveNextEnvironment(responseObserver);\n+            break;\n+\n+          case RESOLVE:\n+            {\n+              currentEnvironment = pendingResolves.remove();\n+              stagedFutures.put(currentEnvironment, new ArrayList<>());\n+              pendingGets = new ArrayDeque<>();\n+              for (RunnerApi.ArtifactInformation artifact :\n+                  responseWrapper.getResolveArtifactResponse().getReplacementsList()) {\n+                Optional<RunnerApi.ArtifactInformation> fetched = getLocal(artifact);\n+                if (fetched.isPresent()) {\n+                  stagedFutures\n+                      .get(currentEnvironment)\n+                      .add(new FutureTask<RunnerApi.ArtifactInformation>(() -> fetched.get()));\n+                } else {\n+                  pendingGets.add(artifact);\n+                  responseObserver.onNext(\n+                      ArtifactApi.ArtifactRequestWrapper.newBuilder()\n+                          .setGetArtifact(\n+                              ArtifactApi.GetArtifactRequest.newBuilder().setArtifact(artifact))\n+                          .build());\n+                }\n+              }\n+              LOG.info(\n+                  \"Getting {} artifacts for {}.{}.\",\n+                  pendingGets.size(),\n+                  stagingToken,\n+                  pendingResolves.peek());\n+              if (pendingGets.isEmpty()) {\n+                resolveNextEnvironment(responseObserver);\n+              } else {\n+                state = State.GET;\n+              }\n+              break;\n+            }\n+\n+          case GET:\n+            RunnerApi.ArtifactInformation currentArtifact = pendingGets.remove();\n+            String name = createFilename(nameIndex++, currentEnvironment, currentArtifact);\n+            try {\n+              LOG.debug(\"Storing artifacts for {} as {}\", stagingToken, name);\n+              currentOutput = new ArrayBlockingQueue<ByteString>(100);\n+              stagedFutures\n+                  .get(currentEnvironment)\n+                  .add(\n+                      stagingExecutor.submit(\n+                          new StoreArtifact(\n+                              stagingToken,\n+                              name,\n+                              currentArtifact,\n+                              currentOutput,\n+                              totalPendingBytes)));\n+            } catch (Exception exn) {\n+              LOG.error(\"Error submitting.\", exn);\n+              responseObserver.onError(exn);\n+            }\n+            state = State.GETCHUNK;\n+            // fall through\n+\n+          case GETCHUNK:\n+            try {\n+              ByteString chunk = responseWrapper.getGetArtifactResponse().getData();\n+              if (chunk.size() > 0) {\n+                totalPendingBytes.aquire(chunk.size());\n+                currentOutput.put(chunk);\n+              }\n+              if (responseWrapper.getIsLast()) {\n+                currentOutput.put(ByteString.EMPTY); // The EOF value.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c8718e46a3692034de9c9a9ed0754bab325cec5"}, "originalPosition": 360}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDUwNjA3OQ==", "bodyText": "Consider using IdGenerators.incrementingLongs and storing a static final reference within this class instead of using nameIndex:\nhttps://github.com/apache/beam/blob/master/sdks/java/fn-execution/src/main/java/org/apache/beam/sdk/fn/IdGenerators.java#L26", "url": "https://github.com/apache/beam/pull/11342#discussion_r410506079", "createdAt": "2020-04-17T22:55:04Z", "author": {"login": "lukecwik"}, "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/artifact/ArtifactStagingService.java", "diffHunk": "@@ -0,0 +1,606 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.fnexecution.artifact;\n+\n+import com.google.auto.value.AutoValue;\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.channels.Channels;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.FutureTask;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactApi;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactStagingServiceGrpc;\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+import org.apache.beam.runners.fnexecution.FnService;\n+import org.apache.beam.sdk.io.FileSystems;\n+import org.apache.beam.sdk.io.fs.ResolveOptions;\n+import org.apache.beam.sdk.io.fs.ResourceId;\n+import org.apache.beam.sdk.util.MimeTypes;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.ByteString;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.InvalidProtocolBufferException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.Status;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.StatusException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.stub.StreamObserver;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Splitter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class ArtifactStagingService\n+    extends ArtifactStagingServiceGrpc.ArtifactStagingServiceImplBase implements FnService {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(ArtifactStagingService.class);\n+\n+  private final ArtifactDestinationProvider destinationProvider;\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> toStage =\n+      new ConcurrentHashMap<>();\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> staged =\n+      new ConcurrentHashMap<>();\n+\n+  public ArtifactStagingService(ArtifactDestinationProvider destinationProvider) {\n+    this.destinationProvider = destinationProvider;\n+  }\n+\n+  /**\n+   * Registers a set of artifacts to be staged with this service.\n+   *\n+   * <p>A client (e.g. a Beam SDK) is expected to connect to this service with the given staging\n+   * token and offer resolution and retrieval of this set of artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   * @param artifacts all artifacts to stage, keyed by environment\n+   */\n+  public void registerJob(\n+      String stagingToken, Map<String, List<RunnerApi.ArtifactInformation>> artifacts) {\n+    assert !toStage.containsKey(stagingToken);\n+    toStage.put(stagingToken, artifacts);\n+  }\n+\n+  /**\n+   * Returns the rewritten artifacts associated with this job, keyed by environment.\n+   *\n+   * <p>This should be called after the client has finished offering artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   */\n+  public Map<String, List<RunnerApi.ArtifactInformation>> getStagedArtifacts(String stagingToken) {\n+    toStage.remove(stagingToken);\n+    return staged.remove(stagingToken);\n+  }\n+\n+  /** Provides a concrete location to which artifacts can be staged on retrieval. */\n+  public interface ArtifactDestinationProvider {\n+    ArtifactDestination getDestination(String stagingToken, String name) throws IOException;\n+  }\n+\n+  /**\n+   * A pairing of a newly created artifact type and an ouptut stream that will be readable at that\n+   * type.\n+   */\n+  @AutoValue\n+  public abstract static class ArtifactDestination {\n+    public static ArtifactDestination create(\n+        String typeUrn, ByteString typePayload, OutputStream out) {\n+      return new AutoValue_ArtifactStagingService_ArtifactDestination(typeUrn, typePayload, out);\n+    }\n+\n+    public static ArtifactDestination fromFile(String path) throws IOException {\n+      return fromFile(\n+          path,\n+          Channels.newOutputStream(\n+              FileSystems.create(\n+                  FileSystems.matchNewResource(path, false /* isDirectory */), MimeTypes.BINARY)));\n+    }\n+\n+    public static ArtifactDestination fromFile(String path, OutputStream out) {\n+      return create(\n+          ArtifactRetrievalService.FILE_ARTIFACT_URN,\n+          RunnerApi.ArtifactFilePayload.newBuilder().setPath(path).build().toByteString(),\n+          out);\n+    }\n+\n+    public abstract String getTypeUrn();\n+\n+    public abstract ByteString getTypePayload();\n+\n+    public abstract OutputStream getOutputStream();\n+  }\n+\n+  /**\n+   * An ArtifactDestinationProvider that places new artifacts as files in a Beam filesystem.\n+   *\n+   * @param root the directory in which to place all artifacts\n+   */\n+  public static ArtifactDestinationProvider beamFilesystemArtifactDestinationProvider(String root) {\n+    return (statingToken, name) -> {\n+      ResourceId path =\n+          FileSystems.matchNewResource(root, true)\n+              .resolve(statingToken, ResolveOptions.StandardResolveOptions.RESOLVE_DIRECTORY)\n+              .resolve(name, ResolveOptions.StandardResolveOptions.RESOLVE_FILE);\n+      return ArtifactDestination.fromFile(path.toString());\n+    };\n+  }\n+\n+  private enum State {\n+    START,\n+    RESOLVE,\n+    GET,\n+    GETCHUNK,\n+    DONE,\n+    ERROR,\n+  }\n+\n+  /**\n+   * Like the standard Semaphore, but allows an aquire to go over the limit if there is any room.\n+   *\n+   * <p>Also allows setting an error, to avoid issues with un-released aquires after error.\n+   */\n+  private static class OverflowingSemaphore {\n+    private int totalPermits;\n+    private int usedPermits;\n+    private Exception exception;\n+\n+    public OverflowingSemaphore(int totalPermits) {\n+      this.totalPermits = totalPermits;\n+      this.usedPermits = 0;\n+    }\n+\n+    synchronized void aquire(int permits) throws Exception {\n+      while (usedPermits >= totalPermits) {\n+        if (exception != null) {\n+          throw exception;\n+        }\n+        this.wait();\n+      }\n+      usedPermits += permits;\n+    }\n+\n+    synchronized void release(int permits) {\n+      usedPermits -= permits;\n+      this.notifyAll();\n+    }\n+\n+    synchronized void setException(Exception exception) {\n+      this.exception = exception;\n+      this.notifyAll();\n+    }\n+  }\n+\n+  /** A task that pulls bytes off a queue and actually writes them to a staging location. */\n+  private class StoreArtifact implements Callable<RunnerApi.ArtifactInformation> {\n+\n+    private String stagingToken;\n+    private String name;\n+    private RunnerApi.ArtifactInformation originalArtifact;\n+    private BlockingQueue<ByteString> bytesQueue;\n+    private OverflowingSemaphore totalPendingBytes;\n+\n+    public StoreArtifact(\n+        String stagingToken,\n+        String name,\n+        RunnerApi.ArtifactInformation originalArtifact,\n+        BlockingQueue<ByteString> bytesQueue,\n+        OverflowingSemaphore totalPendingBytes) {\n+      this.stagingToken = stagingToken;\n+      this.name = name;\n+      this.originalArtifact = originalArtifact;\n+      this.bytesQueue = bytesQueue;\n+      this.totalPendingBytes = totalPendingBytes;\n+    }\n+\n+    @Override\n+    public RunnerApi.ArtifactInformation call() throws IOException {\n+      try {\n+        ArtifactDestination dest = destinationProvider.getDestination(stagingToken, name);\n+        LOG.debug(\"Storing artifact for {}.{} at {}\", stagingToken, name, dest);\n+        ByteString chunk = bytesQueue.take();\n+        while (chunk.size() > 0) {\n+          totalPendingBytes.release(chunk.size());\n+          dest.getOutputStream().write(chunk.toByteArray());\n+          chunk = bytesQueue.take();\n+        }\n+        dest.getOutputStream().close();\n+        return originalArtifact\n+            .toBuilder()\n+            .setTypeUrn(dest.getTypeUrn())\n+            .setTypePayload(dest.getTypePayload())\n+            .build();\n+      } catch (IOException | InterruptedException exn) {\n+        // As this thread will no longer be draining the queue, we don't want to get stuck writing\n+        // to it.\n+        totalPendingBytes.setException(exn);\n+        LOG.error(\"Exception staging artifacts\", exn);\n+        if (exn instanceof IOException) {\n+          throw (IOException) exn;\n+        } else {\n+          throw new RuntimeException(exn);\n+        }\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public StreamObserver<ArtifactApi.ArtifactResponseWrapper> reverseArtifactRetrievalService(\n+      StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+\n+    return new StreamObserver<ArtifactApi.ArtifactResponseWrapper>() {\n+\n+      /** The maximum number of parallel threads to use to stage. */\n+      public static final int THREAD_POOL_SIZE = 10;\n+\n+      /** The maximum number of bytes to buffer across all writes before throttling. */\n+      public static final int MAX_PENDING_BYTES = 100 << 20; // 100 MB\n+\n+      String stagingToken;\n+      Map<String, List<RunnerApi.ArtifactInformation>> toResolve;\n+      Map<String, List<Future<RunnerApi.ArtifactInformation>>> stagedFutures;\n+      ExecutorService stagingExecutor;\n+      OverflowingSemaphore totalPendingBytes;\n+\n+      State state = State.START;\n+      Queue<String> pendingResolves;\n+      String currentEnvironment;\n+      int nameIndex;\n+      Queue<RunnerApi.ArtifactInformation> pendingGets;\n+      BlockingQueue<ByteString> currentOutput;\n+\n+      @Override\n+      @SuppressFBWarnings(value = \"SF_SWITCH_FALLTHROUGH\", justification = \"fallthrough intended\")\n+      public synchronized void onNext(ArtifactApi.ArtifactResponseWrapper responseWrapper) {\n+        switch (state) {\n+          case START:\n+            stagingToken = responseWrapper.getStagingToken();\n+            LOG.info(\"Staging artifacts for {}.\", stagingToken);\n+            toResolve = toStage.get(stagingToken);\n+            stagedFutures = new ConcurrentHashMap<>();\n+            pendingResolves = new ArrayDeque<>();\n+            pendingResolves.addAll(toResolve.keySet());\n+            stagingExecutor = Executors.newFixedThreadPool(THREAD_POOL_SIZE);\n+            totalPendingBytes = new OverflowingSemaphore(MAX_PENDING_BYTES);\n+            resolveNextEnvironment(responseObserver);\n+            break;\n+\n+          case RESOLVE:\n+            {\n+              currentEnvironment = pendingResolves.remove();\n+              stagedFutures.put(currentEnvironment, new ArrayList<>());\n+              pendingGets = new ArrayDeque<>();\n+              for (RunnerApi.ArtifactInformation artifact :\n+                  responseWrapper.getResolveArtifactResponse().getReplacementsList()) {\n+                Optional<RunnerApi.ArtifactInformation> fetched = getLocal(artifact);\n+                if (fetched.isPresent()) {\n+                  stagedFutures\n+                      .get(currentEnvironment)\n+                      .add(new FutureTask<RunnerApi.ArtifactInformation>(() -> fetched.get()));\n+                } else {\n+                  pendingGets.add(artifact);\n+                  responseObserver.onNext(\n+                      ArtifactApi.ArtifactRequestWrapper.newBuilder()\n+                          .setGetArtifact(\n+                              ArtifactApi.GetArtifactRequest.newBuilder().setArtifact(artifact))\n+                          .build());\n+                }\n+              }\n+              LOG.info(\n+                  \"Getting {} artifacts for {}.{}.\",\n+                  pendingGets.size(),\n+                  stagingToken,\n+                  pendingResolves.peek());\n+              if (pendingGets.isEmpty()) {\n+                resolveNextEnvironment(responseObserver);\n+              } else {\n+                state = State.GET;\n+              }\n+              break;\n+            }\n+\n+          case GET:\n+            RunnerApi.ArtifactInformation currentArtifact = pendingGets.remove();\n+            String name = createFilename(nameIndex++, currentEnvironment, currentArtifact);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c8718e46a3692034de9c9a9ed0754bab325cec5"}, "originalPosition": 331}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDUwNzkzOA==", "bodyText": "This won't support Chinese/Russian/Japanese/.. users since they have alphabets that typically don't contain these characters.\nIt might make more sense to use the full path string escaped instead of trying to figure out the base name by replacing the File.separator with something else like _\nSee:\nhttps://docs.oracle.com/javase/8/docs/api/java/io/File.html#separator", "url": "https://github.com/apache/beam/pull/11342#discussion_r410507938", "createdAt": "2020-04-17T23:03:02Z", "author": {"login": "lukecwik"}, "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/artifact/ArtifactStagingService.java", "diffHunk": "@@ -0,0 +1,606 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.fnexecution.artifact;\n+\n+import com.google.auto.value.AutoValue;\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.channels.Channels;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.FutureTask;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactApi;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactStagingServiceGrpc;\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+import org.apache.beam.runners.fnexecution.FnService;\n+import org.apache.beam.sdk.io.FileSystems;\n+import org.apache.beam.sdk.io.fs.ResolveOptions;\n+import org.apache.beam.sdk.io.fs.ResourceId;\n+import org.apache.beam.sdk.util.MimeTypes;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.ByteString;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.InvalidProtocolBufferException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.Status;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.StatusException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.stub.StreamObserver;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Splitter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class ArtifactStagingService\n+    extends ArtifactStagingServiceGrpc.ArtifactStagingServiceImplBase implements FnService {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(ArtifactStagingService.class);\n+\n+  private final ArtifactDestinationProvider destinationProvider;\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> toStage =\n+      new ConcurrentHashMap<>();\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> staged =\n+      new ConcurrentHashMap<>();\n+\n+  public ArtifactStagingService(ArtifactDestinationProvider destinationProvider) {\n+    this.destinationProvider = destinationProvider;\n+  }\n+\n+  /**\n+   * Registers a set of artifacts to be staged with this service.\n+   *\n+   * <p>A client (e.g. a Beam SDK) is expected to connect to this service with the given staging\n+   * token and offer resolution and retrieval of this set of artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   * @param artifacts all artifacts to stage, keyed by environment\n+   */\n+  public void registerJob(\n+      String stagingToken, Map<String, List<RunnerApi.ArtifactInformation>> artifacts) {\n+    assert !toStage.containsKey(stagingToken);\n+    toStage.put(stagingToken, artifacts);\n+  }\n+\n+  /**\n+   * Returns the rewritten artifacts associated with this job, keyed by environment.\n+   *\n+   * <p>This should be called after the client has finished offering artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   */\n+  public Map<String, List<RunnerApi.ArtifactInformation>> getStagedArtifacts(String stagingToken) {\n+    toStage.remove(stagingToken);\n+    return staged.remove(stagingToken);\n+  }\n+\n+  /** Provides a concrete location to which artifacts can be staged on retrieval. */\n+  public interface ArtifactDestinationProvider {\n+    ArtifactDestination getDestination(String stagingToken, String name) throws IOException;\n+  }\n+\n+  /**\n+   * A pairing of a newly created artifact type and an ouptut stream that will be readable at that\n+   * type.\n+   */\n+  @AutoValue\n+  public abstract static class ArtifactDestination {\n+    public static ArtifactDestination create(\n+        String typeUrn, ByteString typePayload, OutputStream out) {\n+      return new AutoValue_ArtifactStagingService_ArtifactDestination(typeUrn, typePayload, out);\n+    }\n+\n+    public static ArtifactDestination fromFile(String path) throws IOException {\n+      return fromFile(\n+          path,\n+          Channels.newOutputStream(\n+              FileSystems.create(\n+                  FileSystems.matchNewResource(path, false /* isDirectory */), MimeTypes.BINARY)));\n+    }\n+\n+    public static ArtifactDestination fromFile(String path, OutputStream out) {\n+      return create(\n+          ArtifactRetrievalService.FILE_ARTIFACT_URN,\n+          RunnerApi.ArtifactFilePayload.newBuilder().setPath(path).build().toByteString(),\n+          out);\n+    }\n+\n+    public abstract String getTypeUrn();\n+\n+    public abstract ByteString getTypePayload();\n+\n+    public abstract OutputStream getOutputStream();\n+  }\n+\n+  /**\n+   * An ArtifactDestinationProvider that places new artifacts as files in a Beam filesystem.\n+   *\n+   * @param root the directory in which to place all artifacts\n+   */\n+  public static ArtifactDestinationProvider beamFilesystemArtifactDestinationProvider(String root) {\n+    return (statingToken, name) -> {\n+      ResourceId path =\n+          FileSystems.matchNewResource(root, true)\n+              .resolve(statingToken, ResolveOptions.StandardResolveOptions.RESOLVE_DIRECTORY)\n+              .resolve(name, ResolveOptions.StandardResolveOptions.RESOLVE_FILE);\n+      return ArtifactDestination.fromFile(path.toString());\n+    };\n+  }\n+\n+  private enum State {\n+    START,\n+    RESOLVE,\n+    GET,\n+    GETCHUNK,\n+    DONE,\n+    ERROR,\n+  }\n+\n+  /**\n+   * Like the standard Semaphore, but allows an aquire to go over the limit if there is any room.\n+   *\n+   * <p>Also allows setting an error, to avoid issues with un-released aquires after error.\n+   */\n+  private static class OverflowingSemaphore {\n+    private int totalPermits;\n+    private int usedPermits;\n+    private Exception exception;\n+\n+    public OverflowingSemaphore(int totalPermits) {\n+      this.totalPermits = totalPermits;\n+      this.usedPermits = 0;\n+    }\n+\n+    synchronized void aquire(int permits) throws Exception {\n+      while (usedPermits >= totalPermits) {\n+        if (exception != null) {\n+          throw exception;\n+        }\n+        this.wait();\n+      }\n+      usedPermits += permits;\n+    }\n+\n+    synchronized void release(int permits) {\n+      usedPermits -= permits;\n+      this.notifyAll();\n+    }\n+\n+    synchronized void setException(Exception exception) {\n+      this.exception = exception;\n+      this.notifyAll();\n+    }\n+  }\n+\n+  /** A task that pulls bytes off a queue and actually writes them to a staging location. */\n+  private class StoreArtifact implements Callable<RunnerApi.ArtifactInformation> {\n+\n+    private String stagingToken;\n+    private String name;\n+    private RunnerApi.ArtifactInformation originalArtifact;\n+    private BlockingQueue<ByteString> bytesQueue;\n+    private OverflowingSemaphore totalPendingBytes;\n+\n+    public StoreArtifact(\n+        String stagingToken,\n+        String name,\n+        RunnerApi.ArtifactInformation originalArtifact,\n+        BlockingQueue<ByteString> bytesQueue,\n+        OverflowingSemaphore totalPendingBytes) {\n+      this.stagingToken = stagingToken;\n+      this.name = name;\n+      this.originalArtifact = originalArtifact;\n+      this.bytesQueue = bytesQueue;\n+      this.totalPendingBytes = totalPendingBytes;\n+    }\n+\n+    @Override\n+    public RunnerApi.ArtifactInformation call() throws IOException {\n+      try {\n+        ArtifactDestination dest = destinationProvider.getDestination(stagingToken, name);\n+        LOG.debug(\"Storing artifact for {}.{} at {}\", stagingToken, name, dest);\n+        ByteString chunk = bytesQueue.take();\n+        while (chunk.size() > 0) {\n+          totalPendingBytes.release(chunk.size());\n+          dest.getOutputStream().write(chunk.toByteArray());\n+          chunk = bytesQueue.take();\n+        }\n+        dest.getOutputStream().close();\n+        return originalArtifact\n+            .toBuilder()\n+            .setTypeUrn(dest.getTypeUrn())\n+            .setTypePayload(dest.getTypePayload())\n+            .build();\n+      } catch (IOException | InterruptedException exn) {\n+        // As this thread will no longer be draining the queue, we don't want to get stuck writing\n+        // to it.\n+        totalPendingBytes.setException(exn);\n+        LOG.error(\"Exception staging artifacts\", exn);\n+        if (exn instanceof IOException) {\n+          throw (IOException) exn;\n+        } else {\n+          throw new RuntimeException(exn);\n+        }\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public StreamObserver<ArtifactApi.ArtifactResponseWrapper> reverseArtifactRetrievalService(\n+      StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+\n+    return new StreamObserver<ArtifactApi.ArtifactResponseWrapper>() {\n+\n+      /** The maximum number of parallel threads to use to stage. */\n+      public static final int THREAD_POOL_SIZE = 10;\n+\n+      /** The maximum number of bytes to buffer across all writes before throttling. */\n+      public static final int MAX_PENDING_BYTES = 100 << 20; // 100 MB\n+\n+      String stagingToken;\n+      Map<String, List<RunnerApi.ArtifactInformation>> toResolve;\n+      Map<String, List<Future<RunnerApi.ArtifactInformation>>> stagedFutures;\n+      ExecutorService stagingExecutor;\n+      OverflowingSemaphore totalPendingBytes;\n+\n+      State state = State.START;\n+      Queue<String> pendingResolves;\n+      String currentEnvironment;\n+      int nameIndex;\n+      Queue<RunnerApi.ArtifactInformation> pendingGets;\n+      BlockingQueue<ByteString> currentOutput;\n+\n+      @Override\n+      @SuppressFBWarnings(value = \"SF_SWITCH_FALLTHROUGH\", justification = \"fallthrough intended\")\n+      public synchronized void onNext(ArtifactApi.ArtifactResponseWrapper responseWrapper) {\n+        switch (state) {\n+          case START:\n+            stagingToken = responseWrapper.getStagingToken();\n+            LOG.info(\"Staging artifacts for {}.\", stagingToken);\n+            toResolve = toStage.get(stagingToken);\n+            stagedFutures = new ConcurrentHashMap<>();\n+            pendingResolves = new ArrayDeque<>();\n+            pendingResolves.addAll(toResolve.keySet());\n+            stagingExecutor = Executors.newFixedThreadPool(THREAD_POOL_SIZE);\n+            totalPendingBytes = new OverflowingSemaphore(MAX_PENDING_BYTES);\n+            resolveNextEnvironment(responseObserver);\n+            break;\n+\n+          case RESOLVE:\n+            {\n+              currentEnvironment = pendingResolves.remove();\n+              stagedFutures.put(currentEnvironment, new ArrayList<>());\n+              pendingGets = new ArrayDeque<>();\n+              for (RunnerApi.ArtifactInformation artifact :\n+                  responseWrapper.getResolveArtifactResponse().getReplacementsList()) {\n+                Optional<RunnerApi.ArtifactInformation> fetched = getLocal(artifact);\n+                if (fetched.isPresent()) {\n+                  stagedFutures\n+                      .get(currentEnvironment)\n+                      .add(new FutureTask<RunnerApi.ArtifactInformation>(() -> fetched.get()));\n+                } else {\n+                  pendingGets.add(artifact);\n+                  responseObserver.onNext(\n+                      ArtifactApi.ArtifactRequestWrapper.newBuilder()\n+                          .setGetArtifact(\n+                              ArtifactApi.GetArtifactRequest.newBuilder().setArtifact(artifact))\n+                          .build());\n+                }\n+              }\n+              LOG.info(\n+                  \"Getting {} artifacts for {}.{}.\",\n+                  pendingGets.size(),\n+                  stagingToken,\n+                  pendingResolves.peek());\n+              if (pendingGets.isEmpty()) {\n+                resolveNextEnvironment(responseObserver);\n+              } else {\n+                state = State.GET;\n+              }\n+              break;\n+            }\n+\n+          case GET:\n+            RunnerApi.ArtifactInformation currentArtifact = pendingGets.remove();\n+            String name = createFilename(nameIndex++, currentEnvironment, currentArtifact);\n+            try {\n+              LOG.debug(\"Storing artifacts for {} as {}\", stagingToken, name);\n+              currentOutput = new ArrayBlockingQueue<ByteString>(100);\n+              stagedFutures\n+                  .get(currentEnvironment)\n+                  .add(\n+                      stagingExecutor.submit(\n+                          new StoreArtifact(\n+                              stagingToken,\n+                              name,\n+                              currentArtifact,\n+                              currentOutput,\n+                              totalPendingBytes)));\n+            } catch (Exception exn) {\n+              LOG.error(\"Error submitting.\", exn);\n+              responseObserver.onError(exn);\n+            }\n+            state = State.GETCHUNK;\n+            // fall through\n+\n+          case GETCHUNK:\n+            try {\n+              ByteString chunk = responseWrapper.getGetArtifactResponse().getData();\n+              if (chunk.size() > 0) {\n+                totalPendingBytes.aquire(chunk.size());\n+                currentOutput.put(chunk);\n+              }\n+              if (responseWrapper.getIsLast()) {\n+                currentOutput.put(ByteString.EMPTY); // The EOF value.\n+                if (pendingGets.isEmpty()) {\n+                  resolveNextEnvironment(responseObserver);\n+                } else {\n+                  state = State.GET;\n+                  LOG.debug(\"Waiting for {}\", pendingGets.peek());\n+                }\n+              }\n+            } catch (Exception exn) {\n+              LOG.error(\"Error submitting.\", exn);\n+              onError(exn);\n+            }\n+            break;\n+\n+          default:\n+            responseObserver.onError(\n+                new StatusException(\n+                    Status.INVALID_ARGUMENT.withDescription(\"Illegal state \" + state)));\n+        }\n+      }\n+\n+      private void resolveNextEnvironment(\n+          StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+        if (pendingResolves.isEmpty()) {\n+          finishStaging(responseObserver);\n+        } else {\n+          state = State.RESOLVE;\n+          LOG.info(\"Resolving artifacts for {}.{}.\", stagingToken, pendingResolves.peek());\n+          responseObserver.onNext(\n+              ArtifactApi.ArtifactRequestWrapper.newBuilder()\n+                  .setResolveArtifact(\n+                      ArtifactApi.ResolveArtifactsRequest.newBuilder()\n+                          .addAllArtifacts(toResolve.get(pendingResolves.peek())))\n+                  .build());\n+        }\n+      }\n+\n+      private void finishStaging(\n+          StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+        LOG.debug(\"Finishing staging for {}.\", stagingToken);\n+        Map<String, List<RunnerApi.ArtifactInformation>> staged = new HashMap<>();\n+        try {\n+          for (Map.Entry<String, List<Future<RunnerApi.ArtifactInformation>>> entry :\n+              stagedFutures.entrySet()) {\n+            List<RunnerApi.ArtifactInformation> envStaged = new ArrayList<>();\n+            for (Future<RunnerApi.ArtifactInformation> future : entry.getValue()) {\n+              envStaged.add(future.get());\n+            }\n+            staged.put(entry.getKey(), envStaged);\n+          }\n+          ArtifactStagingService.this.staged.put(stagingToken, staged);\n+          stagingExecutor.shutdown();\n+          state = State.DONE;\n+          LOG.info(\"Artifacts fully staged for {}.\", stagingToken);\n+          responseObserver.onCompleted();\n+        } catch (Exception exn) {\n+          LOG.error(\"Error staging artifacts\", exn);\n+          responseObserver.onError(exn);\n+          state = State.ERROR;\n+          return;\n+        }\n+      }\n+\n+      /**\n+       * Return an alternative artifact if we do not need to get this over the artifact API, or\n+       * possibly at all.\n+       */\n+      private Optional<RunnerApi.ArtifactInformation> getLocal(\n+          RunnerApi.ArtifactInformation artifact) {\n+        return Optional.empty();\n+      }\n+\n+      /**\n+       * Attempts to provide a reasonable filename for the artifact.\n+       *\n+       * @param index a monotonically increasing index, which provides uniqueness\n+       * @param environment the environment id\n+       * @param artifact the artifact itself\n+       */\n+      private String createFilename(\n+          int index, String environment, RunnerApi.ArtifactInformation artifact) {\n+        String path;\n+        try {\n+          if (artifact.getRoleUrn().equals(ArtifactRetrievalService.STAGING_TO_ARTIFACT_URN)) {\n+            path =\n+                RunnerApi.ArtifactStagingToRolePayload.parseFrom(artifact.getRolePayload())\n+                    .getStagedName();\n+          } else if (artifact.getTypeUrn().equals(ArtifactRetrievalService.FILE_ARTIFACT_URN)) {\n+            path = RunnerApi.ArtifactFilePayload.parseFrom(artifact.getTypePayload()).getPath();\n+          } else if (artifact.getTypeUrn().equals(ArtifactRetrievalService.URL_ARTIFACT_URN)) {\n+            path = RunnerApi.ArtifactUrlPayload.parseFrom(artifact.getTypePayload()).getUrl();\n+          } else {\n+            path = \"artifact\";\n+          }\n+        } catch (InvalidProtocolBufferException exn) {\n+          throw new RuntimeException(exn);\n+        }\n+        // Limit to the last contiguous alpha-numeric sequence. In particular, this will exclude\n+        // all path separators.\n+        List<String> components = Splitter.onPattern(\"[^A-Za-z-_.]]\").splitToList(path);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c8718e46a3692034de9c9a9ed0754bab325cec5"}, "originalPosition": 459}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDUwODcyOA==", "bodyText": "assert isn't run unless a JVM flag is enabled, did you want to use checkState instead and/or responseObserver.error(...)?", "url": "https://github.com/apache/beam/pull/11342#discussion_r410508728", "createdAt": "2020-04-17T23:06:19Z", "author": {"login": "lukecwik"}, "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/artifact/ArtifactStagingService.java", "diffHunk": "@@ -0,0 +1,606 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.fnexecution.artifact;\n+\n+import com.google.auto.value.AutoValue;\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.channels.Channels;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.FutureTask;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactApi;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactStagingServiceGrpc;\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+import org.apache.beam.runners.fnexecution.FnService;\n+import org.apache.beam.sdk.io.FileSystems;\n+import org.apache.beam.sdk.io.fs.ResolveOptions;\n+import org.apache.beam.sdk.io.fs.ResourceId;\n+import org.apache.beam.sdk.util.MimeTypes;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.ByteString;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.InvalidProtocolBufferException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.Status;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.StatusException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.stub.StreamObserver;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Splitter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class ArtifactStagingService\n+    extends ArtifactStagingServiceGrpc.ArtifactStagingServiceImplBase implements FnService {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(ArtifactStagingService.class);\n+\n+  private final ArtifactDestinationProvider destinationProvider;\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> toStage =\n+      new ConcurrentHashMap<>();\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> staged =\n+      new ConcurrentHashMap<>();\n+\n+  public ArtifactStagingService(ArtifactDestinationProvider destinationProvider) {\n+    this.destinationProvider = destinationProvider;\n+  }\n+\n+  /**\n+   * Registers a set of artifacts to be staged with this service.\n+   *\n+   * <p>A client (e.g. a Beam SDK) is expected to connect to this service with the given staging\n+   * token and offer resolution and retrieval of this set of artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   * @param artifacts all artifacts to stage, keyed by environment\n+   */\n+  public void registerJob(\n+      String stagingToken, Map<String, List<RunnerApi.ArtifactInformation>> artifacts) {\n+    assert !toStage.containsKey(stagingToken);\n+    toStage.put(stagingToken, artifacts);\n+  }\n+\n+  /**\n+   * Returns the rewritten artifacts associated with this job, keyed by environment.\n+   *\n+   * <p>This should be called after the client has finished offering artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   */\n+  public Map<String, List<RunnerApi.ArtifactInformation>> getStagedArtifacts(String stagingToken) {\n+    toStage.remove(stagingToken);\n+    return staged.remove(stagingToken);\n+  }\n+\n+  /** Provides a concrete location to which artifacts can be staged on retrieval. */\n+  public interface ArtifactDestinationProvider {\n+    ArtifactDestination getDestination(String stagingToken, String name) throws IOException;\n+  }\n+\n+  /**\n+   * A pairing of a newly created artifact type and an ouptut stream that will be readable at that\n+   * type.\n+   */\n+  @AutoValue\n+  public abstract static class ArtifactDestination {\n+    public static ArtifactDestination create(\n+        String typeUrn, ByteString typePayload, OutputStream out) {\n+      return new AutoValue_ArtifactStagingService_ArtifactDestination(typeUrn, typePayload, out);\n+    }\n+\n+    public static ArtifactDestination fromFile(String path) throws IOException {\n+      return fromFile(\n+          path,\n+          Channels.newOutputStream(\n+              FileSystems.create(\n+                  FileSystems.matchNewResource(path, false /* isDirectory */), MimeTypes.BINARY)));\n+    }\n+\n+    public static ArtifactDestination fromFile(String path, OutputStream out) {\n+      return create(\n+          ArtifactRetrievalService.FILE_ARTIFACT_URN,\n+          RunnerApi.ArtifactFilePayload.newBuilder().setPath(path).build().toByteString(),\n+          out);\n+    }\n+\n+    public abstract String getTypeUrn();\n+\n+    public abstract ByteString getTypePayload();\n+\n+    public abstract OutputStream getOutputStream();\n+  }\n+\n+  /**\n+   * An ArtifactDestinationProvider that places new artifacts as files in a Beam filesystem.\n+   *\n+   * @param root the directory in which to place all artifacts\n+   */\n+  public static ArtifactDestinationProvider beamFilesystemArtifactDestinationProvider(String root) {\n+    return (statingToken, name) -> {\n+      ResourceId path =\n+          FileSystems.matchNewResource(root, true)\n+              .resolve(statingToken, ResolveOptions.StandardResolveOptions.RESOLVE_DIRECTORY)\n+              .resolve(name, ResolveOptions.StandardResolveOptions.RESOLVE_FILE);\n+      return ArtifactDestination.fromFile(path.toString());\n+    };\n+  }\n+\n+  private enum State {\n+    START,\n+    RESOLVE,\n+    GET,\n+    GETCHUNK,\n+    DONE,\n+    ERROR,\n+  }\n+\n+  /**\n+   * Like the standard Semaphore, but allows an aquire to go over the limit if there is any room.\n+   *\n+   * <p>Also allows setting an error, to avoid issues with un-released aquires after error.\n+   */\n+  private static class OverflowingSemaphore {\n+    private int totalPermits;\n+    private int usedPermits;\n+    private Exception exception;\n+\n+    public OverflowingSemaphore(int totalPermits) {\n+      this.totalPermits = totalPermits;\n+      this.usedPermits = 0;\n+    }\n+\n+    synchronized void aquire(int permits) throws Exception {\n+      while (usedPermits >= totalPermits) {\n+        if (exception != null) {\n+          throw exception;\n+        }\n+        this.wait();\n+      }\n+      usedPermits += permits;\n+    }\n+\n+    synchronized void release(int permits) {\n+      usedPermits -= permits;\n+      this.notifyAll();\n+    }\n+\n+    synchronized void setException(Exception exception) {\n+      this.exception = exception;\n+      this.notifyAll();\n+    }\n+  }\n+\n+  /** A task that pulls bytes off a queue and actually writes them to a staging location. */\n+  private class StoreArtifact implements Callable<RunnerApi.ArtifactInformation> {\n+\n+    private String stagingToken;\n+    private String name;\n+    private RunnerApi.ArtifactInformation originalArtifact;\n+    private BlockingQueue<ByteString> bytesQueue;\n+    private OverflowingSemaphore totalPendingBytes;\n+\n+    public StoreArtifact(\n+        String stagingToken,\n+        String name,\n+        RunnerApi.ArtifactInformation originalArtifact,\n+        BlockingQueue<ByteString> bytesQueue,\n+        OverflowingSemaphore totalPendingBytes) {\n+      this.stagingToken = stagingToken;\n+      this.name = name;\n+      this.originalArtifact = originalArtifact;\n+      this.bytesQueue = bytesQueue;\n+      this.totalPendingBytes = totalPendingBytes;\n+    }\n+\n+    @Override\n+    public RunnerApi.ArtifactInformation call() throws IOException {\n+      try {\n+        ArtifactDestination dest = destinationProvider.getDestination(stagingToken, name);\n+        LOG.debug(\"Storing artifact for {}.{} at {}\", stagingToken, name, dest);\n+        ByteString chunk = bytesQueue.take();\n+        while (chunk.size() > 0) {\n+          totalPendingBytes.release(chunk.size());\n+          dest.getOutputStream().write(chunk.toByteArray());\n+          chunk = bytesQueue.take();\n+        }\n+        dest.getOutputStream().close();\n+        return originalArtifact\n+            .toBuilder()\n+            .setTypeUrn(dest.getTypeUrn())\n+            .setTypePayload(dest.getTypePayload())\n+            .build();\n+      } catch (IOException | InterruptedException exn) {\n+        // As this thread will no longer be draining the queue, we don't want to get stuck writing\n+        // to it.\n+        totalPendingBytes.setException(exn);\n+        LOG.error(\"Exception staging artifacts\", exn);\n+        if (exn instanceof IOException) {\n+          throw (IOException) exn;\n+        } else {\n+          throw new RuntimeException(exn);\n+        }\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public StreamObserver<ArtifactApi.ArtifactResponseWrapper> reverseArtifactRetrievalService(\n+      StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+\n+    return new StreamObserver<ArtifactApi.ArtifactResponseWrapper>() {\n+\n+      /** The maximum number of parallel threads to use to stage. */\n+      public static final int THREAD_POOL_SIZE = 10;\n+\n+      /** The maximum number of bytes to buffer across all writes before throttling. */\n+      public static final int MAX_PENDING_BYTES = 100 << 20; // 100 MB\n+\n+      String stagingToken;\n+      Map<String, List<RunnerApi.ArtifactInformation>> toResolve;\n+      Map<String, List<Future<RunnerApi.ArtifactInformation>>> stagedFutures;\n+      ExecutorService stagingExecutor;\n+      OverflowingSemaphore totalPendingBytes;\n+\n+      State state = State.START;\n+      Queue<String> pendingResolves;\n+      String currentEnvironment;\n+      int nameIndex;\n+      Queue<RunnerApi.ArtifactInformation> pendingGets;\n+      BlockingQueue<ByteString> currentOutput;\n+\n+      @Override\n+      @SuppressFBWarnings(value = \"SF_SWITCH_FALLTHROUGH\", justification = \"fallthrough intended\")\n+      public synchronized void onNext(ArtifactApi.ArtifactResponseWrapper responseWrapper) {\n+        switch (state) {\n+          case START:\n+            stagingToken = responseWrapper.getStagingToken();\n+            LOG.info(\"Staging artifacts for {}.\", stagingToken);\n+            toResolve = toStage.get(stagingToken);\n+            stagedFutures = new ConcurrentHashMap<>();\n+            pendingResolves = new ArrayDeque<>();\n+            pendingResolves.addAll(toResolve.keySet());\n+            stagingExecutor = Executors.newFixedThreadPool(THREAD_POOL_SIZE);\n+            totalPendingBytes = new OverflowingSemaphore(MAX_PENDING_BYTES);\n+            resolveNextEnvironment(responseObserver);\n+            break;\n+\n+          case RESOLVE:\n+            {\n+              currentEnvironment = pendingResolves.remove();\n+              stagedFutures.put(currentEnvironment, new ArrayList<>());\n+              pendingGets = new ArrayDeque<>();\n+              for (RunnerApi.ArtifactInformation artifact :\n+                  responseWrapper.getResolveArtifactResponse().getReplacementsList()) {\n+                Optional<RunnerApi.ArtifactInformation> fetched = getLocal(artifact);\n+                if (fetched.isPresent()) {\n+                  stagedFutures\n+                      .get(currentEnvironment)\n+                      .add(new FutureTask<RunnerApi.ArtifactInformation>(() -> fetched.get()));\n+                } else {\n+                  pendingGets.add(artifact);\n+                  responseObserver.onNext(\n+                      ArtifactApi.ArtifactRequestWrapper.newBuilder()\n+                          .setGetArtifact(\n+                              ArtifactApi.GetArtifactRequest.newBuilder().setArtifact(artifact))\n+                          .build());\n+                }\n+              }\n+              LOG.info(\n+                  \"Getting {} artifacts for {}.{}.\",\n+                  pendingGets.size(),\n+                  stagingToken,\n+                  pendingResolves.peek());\n+              if (pendingGets.isEmpty()) {\n+                resolveNextEnvironment(responseObserver);\n+              } else {\n+                state = State.GET;\n+              }\n+              break;\n+            }\n+\n+          case GET:\n+            RunnerApi.ArtifactInformation currentArtifact = pendingGets.remove();\n+            String name = createFilename(nameIndex++, currentEnvironment, currentArtifact);\n+            try {\n+              LOG.debug(\"Storing artifacts for {} as {}\", stagingToken, name);\n+              currentOutput = new ArrayBlockingQueue<ByteString>(100);\n+              stagedFutures\n+                  .get(currentEnvironment)\n+                  .add(\n+                      stagingExecutor.submit(\n+                          new StoreArtifact(\n+                              stagingToken,\n+                              name,\n+                              currentArtifact,\n+                              currentOutput,\n+                              totalPendingBytes)));\n+            } catch (Exception exn) {\n+              LOG.error(\"Error submitting.\", exn);\n+              responseObserver.onError(exn);\n+            }\n+            state = State.GETCHUNK;\n+            // fall through\n+\n+          case GETCHUNK:\n+            try {\n+              ByteString chunk = responseWrapper.getGetArtifactResponse().getData();\n+              if (chunk.size() > 0) {\n+                totalPendingBytes.aquire(chunk.size());\n+                currentOutput.put(chunk);\n+              }\n+              if (responseWrapper.getIsLast()) {\n+                currentOutput.put(ByteString.EMPTY); // The EOF value.\n+                if (pendingGets.isEmpty()) {\n+                  resolveNextEnvironment(responseObserver);\n+                } else {\n+                  state = State.GET;\n+                  LOG.debug(\"Waiting for {}\", pendingGets.peek());\n+                }\n+              }\n+            } catch (Exception exn) {\n+              LOG.error(\"Error submitting.\", exn);\n+              onError(exn);\n+            }\n+            break;\n+\n+          default:\n+            responseObserver.onError(\n+                new StatusException(\n+                    Status.INVALID_ARGUMENT.withDescription(\"Illegal state \" + state)));\n+        }\n+      }\n+\n+      private void resolveNextEnvironment(\n+          StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+        if (pendingResolves.isEmpty()) {\n+          finishStaging(responseObserver);\n+        } else {\n+          state = State.RESOLVE;\n+          LOG.info(\"Resolving artifacts for {}.{}.\", stagingToken, pendingResolves.peek());\n+          responseObserver.onNext(\n+              ArtifactApi.ArtifactRequestWrapper.newBuilder()\n+                  .setResolveArtifact(\n+                      ArtifactApi.ResolveArtifactsRequest.newBuilder()\n+                          .addAllArtifacts(toResolve.get(pendingResolves.peek())))\n+                  .build());\n+        }\n+      }\n+\n+      private void finishStaging(\n+          StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+        LOG.debug(\"Finishing staging for {}.\", stagingToken);\n+        Map<String, List<RunnerApi.ArtifactInformation>> staged = new HashMap<>();\n+        try {\n+          for (Map.Entry<String, List<Future<RunnerApi.ArtifactInformation>>> entry :\n+              stagedFutures.entrySet()) {\n+            List<RunnerApi.ArtifactInformation> envStaged = new ArrayList<>();\n+            for (Future<RunnerApi.ArtifactInformation> future : entry.getValue()) {\n+              envStaged.add(future.get());\n+            }\n+            staged.put(entry.getKey(), envStaged);\n+          }\n+          ArtifactStagingService.this.staged.put(stagingToken, staged);\n+          stagingExecutor.shutdown();\n+          state = State.DONE;\n+          LOG.info(\"Artifacts fully staged for {}.\", stagingToken);\n+          responseObserver.onCompleted();\n+        } catch (Exception exn) {\n+          LOG.error(\"Error staging artifacts\", exn);\n+          responseObserver.onError(exn);\n+          state = State.ERROR;\n+          return;\n+        }\n+      }\n+\n+      /**\n+       * Return an alternative artifact if we do not need to get this over the artifact API, or\n+       * possibly at all.\n+       */\n+      private Optional<RunnerApi.ArtifactInformation> getLocal(\n+          RunnerApi.ArtifactInformation artifact) {\n+        return Optional.empty();\n+      }\n+\n+      /**\n+       * Attempts to provide a reasonable filename for the artifact.\n+       *\n+       * @param index a monotonically increasing index, which provides uniqueness\n+       * @param environment the environment id\n+       * @param artifact the artifact itself\n+       */\n+      private String createFilename(\n+          int index, String environment, RunnerApi.ArtifactInformation artifact) {\n+        String path;\n+        try {\n+          if (artifact.getRoleUrn().equals(ArtifactRetrievalService.STAGING_TO_ARTIFACT_URN)) {\n+            path =\n+                RunnerApi.ArtifactStagingToRolePayload.parseFrom(artifact.getRolePayload())\n+                    .getStagedName();\n+          } else if (artifact.getTypeUrn().equals(ArtifactRetrievalService.FILE_ARTIFACT_URN)) {\n+            path = RunnerApi.ArtifactFilePayload.parseFrom(artifact.getTypePayload()).getPath();\n+          } else if (artifact.getTypeUrn().equals(ArtifactRetrievalService.URL_ARTIFACT_URN)) {\n+            path = RunnerApi.ArtifactUrlPayload.parseFrom(artifact.getTypePayload()).getUrl();\n+          } else {\n+            path = \"artifact\";\n+          }\n+        } catch (InvalidProtocolBufferException exn) {\n+          throw new RuntimeException(exn);\n+        }\n+        // Limit to the last contiguous alpha-numeric sequence. In particular, this will exclude\n+        // all path separators.\n+        List<String> components = Splitter.onPattern(\"[^A-Za-z-_.]]\").splitToList(path);\n+        String base = components.get(components.size() - 1);\n+        return clip(String.format(\"%d-%s-%s\", index, clip(environment, 25), base), 100);\n+      }\n+\n+      private String clip(String s, int maxLength) {\n+        return s.length() < maxLength ? s : s.substring(0, maxLength);\n+      }\n+\n+      @Override\n+      public void onError(Throwable throwable) {\n+        stagingExecutor.shutdownNow();\n+        LOG.error(\"Error staging artifacts\", throwable);\n+        state = State.ERROR;\n+      }\n+\n+      @Override\n+      public void onCompleted() {\n+        assert state == State.DONE;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c8718e46a3692034de9c9a9ed0754bab325cec5"}, "originalPosition": 477}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDUwODk3MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                private ArtifactRetrievalService retrievalService;\n          \n          \n            \n            \n          \n          \n            \n                public StagingRequestObserver(ArtifactRetrievalService retrievalService) {\n          \n          \n            \n                  this.retrievalService = retrievalService;\n          \n          \n            \n                }\n          \n          \n            \n            \n          \n          \n            \n                CountDownLatch latch = new CountDownLatch(1);\n          \n          \n            \n                StreamObserver<ArtifactApi.ArtifactResponseWrapper> responseObserver;\n          \n          \n            \n                Throwable error;\n          \n          \n            \n                private final ArtifactRetrievalService retrievalService;\n          \n          \n            \n                private final CountDownLatch latch = new CountDownLatch(1);\n          \n          \n            \n                private final StreamObserver<ArtifactApi.ArtifactResponseWrapper> responseObserver;\n          \n          \n            \n                private Throwable error;\n          \n          \n            \n            \n          \n          \n            \n                public StagingRequestObserver(ArtifactRetrievalService retrievalService) {\n          \n          \n            \n                  this.retrievalService = retrievalService;\n          \n          \n            \n                }", "url": "https://github.com/apache/beam/pull/11342#discussion_r410508971", "createdAt": "2020-04-17T23:07:31Z", "author": {"login": "lukecwik"}, "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/artifact/ArtifactStagingService.java", "diffHunk": "@@ -0,0 +1,606 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.fnexecution.artifact;\n+\n+import com.google.auto.value.AutoValue;\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.channels.Channels;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.FutureTask;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactApi;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactStagingServiceGrpc;\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+import org.apache.beam.runners.fnexecution.FnService;\n+import org.apache.beam.sdk.io.FileSystems;\n+import org.apache.beam.sdk.io.fs.ResolveOptions;\n+import org.apache.beam.sdk.io.fs.ResourceId;\n+import org.apache.beam.sdk.util.MimeTypes;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.ByteString;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.InvalidProtocolBufferException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.Status;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.StatusException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.stub.StreamObserver;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Splitter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class ArtifactStagingService\n+    extends ArtifactStagingServiceGrpc.ArtifactStagingServiceImplBase implements FnService {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(ArtifactStagingService.class);\n+\n+  private final ArtifactDestinationProvider destinationProvider;\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> toStage =\n+      new ConcurrentHashMap<>();\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> staged =\n+      new ConcurrentHashMap<>();\n+\n+  public ArtifactStagingService(ArtifactDestinationProvider destinationProvider) {\n+    this.destinationProvider = destinationProvider;\n+  }\n+\n+  /**\n+   * Registers a set of artifacts to be staged with this service.\n+   *\n+   * <p>A client (e.g. a Beam SDK) is expected to connect to this service with the given staging\n+   * token and offer resolution and retrieval of this set of artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   * @param artifacts all artifacts to stage, keyed by environment\n+   */\n+  public void registerJob(\n+      String stagingToken, Map<String, List<RunnerApi.ArtifactInformation>> artifacts) {\n+    assert !toStage.containsKey(stagingToken);\n+    toStage.put(stagingToken, artifacts);\n+  }\n+\n+  /**\n+   * Returns the rewritten artifacts associated with this job, keyed by environment.\n+   *\n+   * <p>This should be called after the client has finished offering artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   */\n+  public Map<String, List<RunnerApi.ArtifactInformation>> getStagedArtifacts(String stagingToken) {\n+    toStage.remove(stagingToken);\n+    return staged.remove(stagingToken);\n+  }\n+\n+  /** Provides a concrete location to which artifacts can be staged on retrieval. */\n+  public interface ArtifactDestinationProvider {\n+    ArtifactDestination getDestination(String stagingToken, String name) throws IOException;\n+  }\n+\n+  /**\n+   * A pairing of a newly created artifact type and an ouptut stream that will be readable at that\n+   * type.\n+   */\n+  @AutoValue\n+  public abstract static class ArtifactDestination {\n+    public static ArtifactDestination create(\n+        String typeUrn, ByteString typePayload, OutputStream out) {\n+      return new AutoValue_ArtifactStagingService_ArtifactDestination(typeUrn, typePayload, out);\n+    }\n+\n+    public static ArtifactDestination fromFile(String path) throws IOException {\n+      return fromFile(\n+          path,\n+          Channels.newOutputStream(\n+              FileSystems.create(\n+                  FileSystems.matchNewResource(path, false /* isDirectory */), MimeTypes.BINARY)));\n+    }\n+\n+    public static ArtifactDestination fromFile(String path, OutputStream out) {\n+      return create(\n+          ArtifactRetrievalService.FILE_ARTIFACT_URN,\n+          RunnerApi.ArtifactFilePayload.newBuilder().setPath(path).build().toByteString(),\n+          out);\n+    }\n+\n+    public abstract String getTypeUrn();\n+\n+    public abstract ByteString getTypePayload();\n+\n+    public abstract OutputStream getOutputStream();\n+  }\n+\n+  /**\n+   * An ArtifactDestinationProvider that places new artifacts as files in a Beam filesystem.\n+   *\n+   * @param root the directory in which to place all artifacts\n+   */\n+  public static ArtifactDestinationProvider beamFilesystemArtifactDestinationProvider(String root) {\n+    return (statingToken, name) -> {\n+      ResourceId path =\n+          FileSystems.matchNewResource(root, true)\n+              .resolve(statingToken, ResolveOptions.StandardResolveOptions.RESOLVE_DIRECTORY)\n+              .resolve(name, ResolveOptions.StandardResolveOptions.RESOLVE_FILE);\n+      return ArtifactDestination.fromFile(path.toString());\n+    };\n+  }\n+\n+  private enum State {\n+    START,\n+    RESOLVE,\n+    GET,\n+    GETCHUNK,\n+    DONE,\n+    ERROR,\n+  }\n+\n+  /**\n+   * Like the standard Semaphore, but allows an aquire to go over the limit if there is any room.\n+   *\n+   * <p>Also allows setting an error, to avoid issues with un-released aquires after error.\n+   */\n+  private static class OverflowingSemaphore {\n+    private int totalPermits;\n+    private int usedPermits;\n+    private Exception exception;\n+\n+    public OverflowingSemaphore(int totalPermits) {\n+      this.totalPermits = totalPermits;\n+      this.usedPermits = 0;\n+    }\n+\n+    synchronized void aquire(int permits) throws Exception {\n+      while (usedPermits >= totalPermits) {\n+        if (exception != null) {\n+          throw exception;\n+        }\n+        this.wait();\n+      }\n+      usedPermits += permits;\n+    }\n+\n+    synchronized void release(int permits) {\n+      usedPermits -= permits;\n+      this.notifyAll();\n+    }\n+\n+    synchronized void setException(Exception exception) {\n+      this.exception = exception;\n+      this.notifyAll();\n+    }\n+  }\n+\n+  /** A task that pulls bytes off a queue and actually writes them to a staging location. */\n+  private class StoreArtifact implements Callable<RunnerApi.ArtifactInformation> {\n+\n+    private String stagingToken;\n+    private String name;\n+    private RunnerApi.ArtifactInformation originalArtifact;\n+    private BlockingQueue<ByteString> bytesQueue;\n+    private OverflowingSemaphore totalPendingBytes;\n+\n+    public StoreArtifact(\n+        String stagingToken,\n+        String name,\n+        RunnerApi.ArtifactInformation originalArtifact,\n+        BlockingQueue<ByteString> bytesQueue,\n+        OverflowingSemaphore totalPendingBytes) {\n+      this.stagingToken = stagingToken;\n+      this.name = name;\n+      this.originalArtifact = originalArtifact;\n+      this.bytesQueue = bytesQueue;\n+      this.totalPendingBytes = totalPendingBytes;\n+    }\n+\n+    @Override\n+    public RunnerApi.ArtifactInformation call() throws IOException {\n+      try {\n+        ArtifactDestination dest = destinationProvider.getDestination(stagingToken, name);\n+        LOG.debug(\"Storing artifact for {}.{} at {}\", stagingToken, name, dest);\n+        ByteString chunk = bytesQueue.take();\n+        while (chunk.size() > 0) {\n+          totalPendingBytes.release(chunk.size());\n+          dest.getOutputStream().write(chunk.toByteArray());\n+          chunk = bytesQueue.take();\n+        }\n+        dest.getOutputStream().close();\n+        return originalArtifact\n+            .toBuilder()\n+            .setTypeUrn(dest.getTypeUrn())\n+            .setTypePayload(dest.getTypePayload())\n+            .build();\n+      } catch (IOException | InterruptedException exn) {\n+        // As this thread will no longer be draining the queue, we don't want to get stuck writing\n+        // to it.\n+        totalPendingBytes.setException(exn);\n+        LOG.error(\"Exception staging artifacts\", exn);\n+        if (exn instanceof IOException) {\n+          throw (IOException) exn;\n+        } else {\n+          throw new RuntimeException(exn);\n+        }\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public StreamObserver<ArtifactApi.ArtifactResponseWrapper> reverseArtifactRetrievalService(\n+      StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+\n+    return new StreamObserver<ArtifactApi.ArtifactResponseWrapper>() {\n+\n+      /** The maximum number of parallel threads to use to stage. */\n+      public static final int THREAD_POOL_SIZE = 10;\n+\n+      /** The maximum number of bytes to buffer across all writes before throttling. */\n+      public static final int MAX_PENDING_BYTES = 100 << 20; // 100 MB\n+\n+      String stagingToken;\n+      Map<String, List<RunnerApi.ArtifactInformation>> toResolve;\n+      Map<String, List<Future<RunnerApi.ArtifactInformation>>> stagedFutures;\n+      ExecutorService stagingExecutor;\n+      OverflowingSemaphore totalPendingBytes;\n+\n+      State state = State.START;\n+      Queue<String> pendingResolves;\n+      String currentEnvironment;\n+      int nameIndex;\n+      Queue<RunnerApi.ArtifactInformation> pendingGets;\n+      BlockingQueue<ByteString> currentOutput;\n+\n+      @Override\n+      @SuppressFBWarnings(value = \"SF_SWITCH_FALLTHROUGH\", justification = \"fallthrough intended\")\n+      public synchronized void onNext(ArtifactApi.ArtifactResponseWrapper responseWrapper) {\n+        switch (state) {\n+          case START:\n+            stagingToken = responseWrapper.getStagingToken();\n+            LOG.info(\"Staging artifacts for {}.\", stagingToken);\n+            toResolve = toStage.get(stagingToken);\n+            stagedFutures = new ConcurrentHashMap<>();\n+            pendingResolves = new ArrayDeque<>();\n+            pendingResolves.addAll(toResolve.keySet());\n+            stagingExecutor = Executors.newFixedThreadPool(THREAD_POOL_SIZE);\n+            totalPendingBytes = new OverflowingSemaphore(MAX_PENDING_BYTES);\n+            resolveNextEnvironment(responseObserver);\n+            break;\n+\n+          case RESOLVE:\n+            {\n+              currentEnvironment = pendingResolves.remove();\n+              stagedFutures.put(currentEnvironment, new ArrayList<>());\n+              pendingGets = new ArrayDeque<>();\n+              for (RunnerApi.ArtifactInformation artifact :\n+                  responseWrapper.getResolveArtifactResponse().getReplacementsList()) {\n+                Optional<RunnerApi.ArtifactInformation> fetched = getLocal(artifact);\n+                if (fetched.isPresent()) {\n+                  stagedFutures\n+                      .get(currentEnvironment)\n+                      .add(new FutureTask<RunnerApi.ArtifactInformation>(() -> fetched.get()));\n+                } else {\n+                  pendingGets.add(artifact);\n+                  responseObserver.onNext(\n+                      ArtifactApi.ArtifactRequestWrapper.newBuilder()\n+                          .setGetArtifact(\n+                              ArtifactApi.GetArtifactRequest.newBuilder().setArtifact(artifact))\n+                          .build());\n+                }\n+              }\n+              LOG.info(\n+                  \"Getting {} artifacts for {}.{}.\",\n+                  pendingGets.size(),\n+                  stagingToken,\n+                  pendingResolves.peek());\n+              if (pendingGets.isEmpty()) {\n+                resolveNextEnvironment(responseObserver);\n+              } else {\n+                state = State.GET;\n+              }\n+              break;\n+            }\n+\n+          case GET:\n+            RunnerApi.ArtifactInformation currentArtifact = pendingGets.remove();\n+            String name = createFilename(nameIndex++, currentEnvironment, currentArtifact);\n+            try {\n+              LOG.debug(\"Storing artifacts for {} as {}\", stagingToken, name);\n+              currentOutput = new ArrayBlockingQueue<ByteString>(100);\n+              stagedFutures\n+                  .get(currentEnvironment)\n+                  .add(\n+                      stagingExecutor.submit(\n+                          new StoreArtifact(\n+                              stagingToken,\n+                              name,\n+                              currentArtifact,\n+                              currentOutput,\n+                              totalPendingBytes)));\n+            } catch (Exception exn) {\n+              LOG.error(\"Error submitting.\", exn);\n+              responseObserver.onError(exn);\n+            }\n+            state = State.GETCHUNK;\n+            // fall through\n+\n+          case GETCHUNK:\n+            try {\n+              ByteString chunk = responseWrapper.getGetArtifactResponse().getData();\n+              if (chunk.size() > 0) {\n+                totalPendingBytes.aquire(chunk.size());\n+                currentOutput.put(chunk);\n+              }\n+              if (responseWrapper.getIsLast()) {\n+                currentOutput.put(ByteString.EMPTY); // The EOF value.\n+                if (pendingGets.isEmpty()) {\n+                  resolveNextEnvironment(responseObserver);\n+                } else {\n+                  state = State.GET;\n+                  LOG.debug(\"Waiting for {}\", pendingGets.peek());\n+                }\n+              }\n+            } catch (Exception exn) {\n+              LOG.error(\"Error submitting.\", exn);\n+              onError(exn);\n+            }\n+            break;\n+\n+          default:\n+            responseObserver.onError(\n+                new StatusException(\n+                    Status.INVALID_ARGUMENT.withDescription(\"Illegal state \" + state)));\n+        }\n+      }\n+\n+      private void resolveNextEnvironment(\n+          StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+        if (pendingResolves.isEmpty()) {\n+          finishStaging(responseObserver);\n+        } else {\n+          state = State.RESOLVE;\n+          LOG.info(\"Resolving artifacts for {}.{}.\", stagingToken, pendingResolves.peek());\n+          responseObserver.onNext(\n+              ArtifactApi.ArtifactRequestWrapper.newBuilder()\n+                  .setResolveArtifact(\n+                      ArtifactApi.ResolveArtifactsRequest.newBuilder()\n+                          .addAllArtifacts(toResolve.get(pendingResolves.peek())))\n+                  .build());\n+        }\n+      }\n+\n+      private void finishStaging(\n+          StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+        LOG.debug(\"Finishing staging for {}.\", stagingToken);\n+        Map<String, List<RunnerApi.ArtifactInformation>> staged = new HashMap<>();\n+        try {\n+          for (Map.Entry<String, List<Future<RunnerApi.ArtifactInformation>>> entry :\n+              stagedFutures.entrySet()) {\n+            List<RunnerApi.ArtifactInformation> envStaged = new ArrayList<>();\n+            for (Future<RunnerApi.ArtifactInformation> future : entry.getValue()) {\n+              envStaged.add(future.get());\n+            }\n+            staged.put(entry.getKey(), envStaged);\n+          }\n+          ArtifactStagingService.this.staged.put(stagingToken, staged);\n+          stagingExecutor.shutdown();\n+          state = State.DONE;\n+          LOG.info(\"Artifacts fully staged for {}.\", stagingToken);\n+          responseObserver.onCompleted();\n+        } catch (Exception exn) {\n+          LOG.error(\"Error staging artifacts\", exn);\n+          responseObserver.onError(exn);\n+          state = State.ERROR;\n+          return;\n+        }\n+      }\n+\n+      /**\n+       * Return an alternative artifact if we do not need to get this over the artifact API, or\n+       * possibly at all.\n+       */\n+      private Optional<RunnerApi.ArtifactInformation> getLocal(\n+          RunnerApi.ArtifactInformation artifact) {\n+        return Optional.empty();\n+      }\n+\n+      /**\n+       * Attempts to provide a reasonable filename for the artifact.\n+       *\n+       * @param index a monotonically increasing index, which provides uniqueness\n+       * @param environment the environment id\n+       * @param artifact the artifact itself\n+       */\n+      private String createFilename(\n+          int index, String environment, RunnerApi.ArtifactInformation artifact) {\n+        String path;\n+        try {\n+          if (artifact.getRoleUrn().equals(ArtifactRetrievalService.STAGING_TO_ARTIFACT_URN)) {\n+            path =\n+                RunnerApi.ArtifactStagingToRolePayload.parseFrom(artifact.getRolePayload())\n+                    .getStagedName();\n+          } else if (artifact.getTypeUrn().equals(ArtifactRetrievalService.FILE_ARTIFACT_URN)) {\n+            path = RunnerApi.ArtifactFilePayload.parseFrom(artifact.getTypePayload()).getPath();\n+          } else if (artifact.getTypeUrn().equals(ArtifactRetrievalService.URL_ARTIFACT_URN)) {\n+            path = RunnerApi.ArtifactUrlPayload.parseFrom(artifact.getTypePayload()).getUrl();\n+          } else {\n+            path = \"artifact\";\n+          }\n+        } catch (InvalidProtocolBufferException exn) {\n+          throw new RuntimeException(exn);\n+        }\n+        // Limit to the last contiguous alpha-numeric sequence. In particular, this will exclude\n+        // all path separators.\n+        List<String> components = Splitter.onPattern(\"[^A-Za-z-_.]]\").splitToList(path);\n+        String base = components.get(components.size() - 1);\n+        return clip(String.format(\"%d-%s-%s\", index, clip(environment, 25), base), 100);\n+      }\n+\n+      private String clip(String s, int maxLength) {\n+        return s.length() < maxLength ? s : s.substring(0, maxLength);\n+      }\n+\n+      @Override\n+      public void onError(Throwable throwable) {\n+        stagingExecutor.shutdownNow();\n+        LOG.error(\"Error staging artifacts\", throwable);\n+        state = State.ERROR;\n+      }\n+\n+      @Override\n+      public void onCompleted() {\n+        assert state == State.DONE;\n+      }\n+    };\n+  }\n+\n+  @Override\n+  public void close() throws Exception {\n+    // Nothing to close.\n+  }\n+\n+  /**\n+   * Lazily stages artifacts by letting an ArtifactStagingService resolve and request artifacts.\n+   *\n+   * @param retrievalService an ArtifactRetrievalService used to resolve and retrieve artifacts\n+   * @param stagingService an ArtifactStagingService stub which will request artifacts\n+   * @param stagingToken the staging token of the job whose artifacts will be retrieved\n+   * @throws InterruptedException\n+   * @throws IOException\n+   */\n+  public static void offer(\n+      ArtifactRetrievalService retrievalService,\n+      ArtifactStagingServiceGrpc.ArtifactStagingServiceStub stagingService,\n+      String stagingToken)\n+      throws InterruptedException, IOException {\n+    StagingRequestObserver requestObserver = new StagingRequestObserver(retrievalService);\n+    requestObserver.responseObserver =\n+        stagingService.reverseArtifactRetrievalService(requestObserver);\n+    requestObserver.responseObserver.onNext(\n+        ArtifactApi.ArtifactResponseWrapper.newBuilder().setStagingToken(stagingToken).build());\n+    requestObserver.waitUntilDone();\n+    if (requestObserver.error != null) {\n+      if (requestObserver.error instanceof IOException) {\n+        throw (IOException) requestObserver.error;\n+      } else {\n+        throw new IOException(requestObserver.error);\n+      }\n+    }\n+  }\n+\n+  /** Actually implements the reverse retrieval protocol. */\n+  private static class StagingRequestObserver\n+      implements StreamObserver<ArtifactApi.ArtifactRequestWrapper> {\n+\n+    private ArtifactRetrievalService retrievalService;\n+\n+    public StagingRequestObserver(ArtifactRetrievalService retrievalService) {\n+      this.retrievalService = retrievalService;\n+    }\n+\n+    CountDownLatch latch = new CountDownLatch(1);\n+    StreamObserver<ArtifactApi.ArtifactResponseWrapper> responseObserver;\n+    Throwable error;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c8718e46a3692034de9c9a9ed0754bab325cec5"}, "originalPosition": 528}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDUwOTExOQ==", "bodyText": "checkState?", "url": "https://github.com/apache/beam/pull/11342#discussion_r410509119", "createdAt": "2020-04-17T23:08:09Z", "author": {"login": "lukecwik"}, "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/artifact/ArtifactStagingService.java", "diffHunk": "@@ -0,0 +1,606 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.fnexecution.artifact;\n+\n+import com.google.auto.value.AutoValue;\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.channels.Channels;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.FutureTask;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactApi;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactStagingServiceGrpc;\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+import org.apache.beam.runners.fnexecution.FnService;\n+import org.apache.beam.sdk.io.FileSystems;\n+import org.apache.beam.sdk.io.fs.ResolveOptions;\n+import org.apache.beam.sdk.io.fs.ResourceId;\n+import org.apache.beam.sdk.util.MimeTypes;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.ByteString;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.InvalidProtocolBufferException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.Status;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.StatusException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.stub.StreamObserver;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Splitter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class ArtifactStagingService\n+    extends ArtifactStagingServiceGrpc.ArtifactStagingServiceImplBase implements FnService {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(ArtifactStagingService.class);\n+\n+  private final ArtifactDestinationProvider destinationProvider;\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> toStage =\n+      new ConcurrentHashMap<>();\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> staged =\n+      new ConcurrentHashMap<>();\n+\n+  public ArtifactStagingService(ArtifactDestinationProvider destinationProvider) {\n+    this.destinationProvider = destinationProvider;\n+  }\n+\n+  /**\n+   * Registers a set of artifacts to be staged with this service.\n+   *\n+   * <p>A client (e.g. a Beam SDK) is expected to connect to this service with the given staging\n+   * token and offer resolution and retrieval of this set of artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   * @param artifacts all artifacts to stage, keyed by environment\n+   */\n+  public void registerJob(\n+      String stagingToken, Map<String, List<RunnerApi.ArtifactInformation>> artifacts) {\n+    assert !toStage.containsKey(stagingToken);\n+    toStage.put(stagingToken, artifacts);\n+  }\n+\n+  /**\n+   * Returns the rewritten artifacts associated with this job, keyed by environment.\n+   *\n+   * <p>This should be called after the client has finished offering artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   */\n+  public Map<String, List<RunnerApi.ArtifactInformation>> getStagedArtifacts(String stagingToken) {\n+    toStage.remove(stagingToken);\n+    return staged.remove(stagingToken);\n+  }\n+\n+  /** Provides a concrete location to which artifacts can be staged on retrieval. */\n+  public interface ArtifactDestinationProvider {\n+    ArtifactDestination getDestination(String stagingToken, String name) throws IOException;\n+  }\n+\n+  /**\n+   * A pairing of a newly created artifact type and an ouptut stream that will be readable at that\n+   * type.\n+   */\n+  @AutoValue\n+  public abstract static class ArtifactDestination {\n+    public static ArtifactDestination create(\n+        String typeUrn, ByteString typePayload, OutputStream out) {\n+      return new AutoValue_ArtifactStagingService_ArtifactDestination(typeUrn, typePayload, out);\n+    }\n+\n+    public static ArtifactDestination fromFile(String path) throws IOException {\n+      return fromFile(\n+          path,\n+          Channels.newOutputStream(\n+              FileSystems.create(\n+                  FileSystems.matchNewResource(path, false /* isDirectory */), MimeTypes.BINARY)));\n+    }\n+\n+    public static ArtifactDestination fromFile(String path, OutputStream out) {\n+      return create(\n+          ArtifactRetrievalService.FILE_ARTIFACT_URN,\n+          RunnerApi.ArtifactFilePayload.newBuilder().setPath(path).build().toByteString(),\n+          out);\n+    }\n+\n+    public abstract String getTypeUrn();\n+\n+    public abstract ByteString getTypePayload();\n+\n+    public abstract OutputStream getOutputStream();\n+  }\n+\n+  /**\n+   * An ArtifactDestinationProvider that places new artifacts as files in a Beam filesystem.\n+   *\n+   * @param root the directory in which to place all artifacts\n+   */\n+  public static ArtifactDestinationProvider beamFilesystemArtifactDestinationProvider(String root) {\n+    return (statingToken, name) -> {\n+      ResourceId path =\n+          FileSystems.matchNewResource(root, true)\n+              .resolve(statingToken, ResolveOptions.StandardResolveOptions.RESOLVE_DIRECTORY)\n+              .resolve(name, ResolveOptions.StandardResolveOptions.RESOLVE_FILE);\n+      return ArtifactDestination.fromFile(path.toString());\n+    };\n+  }\n+\n+  private enum State {\n+    START,\n+    RESOLVE,\n+    GET,\n+    GETCHUNK,\n+    DONE,\n+    ERROR,\n+  }\n+\n+  /**\n+   * Like the standard Semaphore, but allows an aquire to go over the limit if there is any room.\n+   *\n+   * <p>Also allows setting an error, to avoid issues with un-released aquires after error.\n+   */\n+  private static class OverflowingSemaphore {\n+    private int totalPermits;\n+    private int usedPermits;\n+    private Exception exception;\n+\n+    public OverflowingSemaphore(int totalPermits) {\n+      this.totalPermits = totalPermits;\n+      this.usedPermits = 0;\n+    }\n+\n+    synchronized void aquire(int permits) throws Exception {\n+      while (usedPermits >= totalPermits) {\n+        if (exception != null) {\n+          throw exception;\n+        }\n+        this.wait();\n+      }\n+      usedPermits += permits;\n+    }\n+\n+    synchronized void release(int permits) {\n+      usedPermits -= permits;\n+      this.notifyAll();\n+    }\n+\n+    synchronized void setException(Exception exception) {\n+      this.exception = exception;\n+      this.notifyAll();\n+    }\n+  }\n+\n+  /** A task that pulls bytes off a queue and actually writes them to a staging location. */\n+  private class StoreArtifact implements Callable<RunnerApi.ArtifactInformation> {\n+\n+    private String stagingToken;\n+    private String name;\n+    private RunnerApi.ArtifactInformation originalArtifact;\n+    private BlockingQueue<ByteString> bytesQueue;\n+    private OverflowingSemaphore totalPendingBytes;\n+\n+    public StoreArtifact(\n+        String stagingToken,\n+        String name,\n+        RunnerApi.ArtifactInformation originalArtifact,\n+        BlockingQueue<ByteString> bytesQueue,\n+        OverflowingSemaphore totalPendingBytes) {\n+      this.stagingToken = stagingToken;\n+      this.name = name;\n+      this.originalArtifact = originalArtifact;\n+      this.bytesQueue = bytesQueue;\n+      this.totalPendingBytes = totalPendingBytes;\n+    }\n+\n+    @Override\n+    public RunnerApi.ArtifactInformation call() throws IOException {\n+      try {\n+        ArtifactDestination dest = destinationProvider.getDestination(stagingToken, name);\n+        LOG.debug(\"Storing artifact for {}.{} at {}\", stagingToken, name, dest);\n+        ByteString chunk = bytesQueue.take();\n+        while (chunk.size() > 0) {\n+          totalPendingBytes.release(chunk.size());\n+          dest.getOutputStream().write(chunk.toByteArray());\n+          chunk = bytesQueue.take();\n+        }\n+        dest.getOutputStream().close();\n+        return originalArtifact\n+            .toBuilder()\n+            .setTypeUrn(dest.getTypeUrn())\n+            .setTypePayload(dest.getTypePayload())\n+            .build();\n+      } catch (IOException | InterruptedException exn) {\n+        // As this thread will no longer be draining the queue, we don't want to get stuck writing\n+        // to it.\n+        totalPendingBytes.setException(exn);\n+        LOG.error(\"Exception staging artifacts\", exn);\n+        if (exn instanceof IOException) {\n+          throw (IOException) exn;\n+        } else {\n+          throw new RuntimeException(exn);\n+        }\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public StreamObserver<ArtifactApi.ArtifactResponseWrapper> reverseArtifactRetrievalService(\n+      StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+\n+    return new StreamObserver<ArtifactApi.ArtifactResponseWrapper>() {\n+\n+      /** The maximum number of parallel threads to use to stage. */\n+      public static final int THREAD_POOL_SIZE = 10;\n+\n+      /** The maximum number of bytes to buffer across all writes before throttling. */\n+      public static final int MAX_PENDING_BYTES = 100 << 20; // 100 MB\n+\n+      String stagingToken;\n+      Map<String, List<RunnerApi.ArtifactInformation>> toResolve;\n+      Map<String, List<Future<RunnerApi.ArtifactInformation>>> stagedFutures;\n+      ExecutorService stagingExecutor;\n+      OverflowingSemaphore totalPendingBytes;\n+\n+      State state = State.START;\n+      Queue<String> pendingResolves;\n+      String currentEnvironment;\n+      int nameIndex;\n+      Queue<RunnerApi.ArtifactInformation> pendingGets;\n+      BlockingQueue<ByteString> currentOutput;\n+\n+      @Override\n+      @SuppressFBWarnings(value = \"SF_SWITCH_FALLTHROUGH\", justification = \"fallthrough intended\")\n+      public synchronized void onNext(ArtifactApi.ArtifactResponseWrapper responseWrapper) {\n+        switch (state) {\n+          case START:\n+            stagingToken = responseWrapper.getStagingToken();\n+            LOG.info(\"Staging artifacts for {}.\", stagingToken);\n+            toResolve = toStage.get(stagingToken);\n+            stagedFutures = new ConcurrentHashMap<>();\n+            pendingResolves = new ArrayDeque<>();\n+            pendingResolves.addAll(toResolve.keySet());\n+            stagingExecutor = Executors.newFixedThreadPool(THREAD_POOL_SIZE);\n+            totalPendingBytes = new OverflowingSemaphore(MAX_PENDING_BYTES);\n+            resolveNextEnvironment(responseObserver);\n+            break;\n+\n+          case RESOLVE:\n+            {\n+              currentEnvironment = pendingResolves.remove();\n+              stagedFutures.put(currentEnvironment, new ArrayList<>());\n+              pendingGets = new ArrayDeque<>();\n+              for (RunnerApi.ArtifactInformation artifact :\n+                  responseWrapper.getResolveArtifactResponse().getReplacementsList()) {\n+                Optional<RunnerApi.ArtifactInformation> fetched = getLocal(artifact);\n+                if (fetched.isPresent()) {\n+                  stagedFutures\n+                      .get(currentEnvironment)\n+                      .add(new FutureTask<RunnerApi.ArtifactInformation>(() -> fetched.get()));\n+                } else {\n+                  pendingGets.add(artifact);\n+                  responseObserver.onNext(\n+                      ArtifactApi.ArtifactRequestWrapper.newBuilder()\n+                          .setGetArtifact(\n+                              ArtifactApi.GetArtifactRequest.newBuilder().setArtifact(artifact))\n+                          .build());\n+                }\n+              }\n+              LOG.info(\n+                  \"Getting {} artifacts for {}.{}.\",\n+                  pendingGets.size(),\n+                  stagingToken,\n+                  pendingResolves.peek());\n+              if (pendingGets.isEmpty()) {\n+                resolveNextEnvironment(responseObserver);\n+              } else {\n+                state = State.GET;\n+              }\n+              break;\n+            }\n+\n+          case GET:\n+            RunnerApi.ArtifactInformation currentArtifact = pendingGets.remove();\n+            String name = createFilename(nameIndex++, currentEnvironment, currentArtifact);\n+            try {\n+              LOG.debug(\"Storing artifacts for {} as {}\", stagingToken, name);\n+              currentOutput = new ArrayBlockingQueue<ByteString>(100);\n+              stagedFutures\n+                  .get(currentEnvironment)\n+                  .add(\n+                      stagingExecutor.submit(\n+                          new StoreArtifact(\n+                              stagingToken,\n+                              name,\n+                              currentArtifact,\n+                              currentOutput,\n+                              totalPendingBytes)));\n+            } catch (Exception exn) {\n+              LOG.error(\"Error submitting.\", exn);\n+              responseObserver.onError(exn);\n+            }\n+            state = State.GETCHUNK;\n+            // fall through\n+\n+          case GETCHUNK:\n+            try {\n+              ByteString chunk = responseWrapper.getGetArtifactResponse().getData();\n+              if (chunk.size() > 0) {\n+                totalPendingBytes.aquire(chunk.size());\n+                currentOutput.put(chunk);\n+              }\n+              if (responseWrapper.getIsLast()) {\n+                currentOutput.put(ByteString.EMPTY); // The EOF value.\n+                if (pendingGets.isEmpty()) {\n+                  resolveNextEnvironment(responseObserver);\n+                } else {\n+                  state = State.GET;\n+                  LOG.debug(\"Waiting for {}\", pendingGets.peek());\n+                }\n+              }\n+            } catch (Exception exn) {\n+              LOG.error(\"Error submitting.\", exn);\n+              onError(exn);\n+            }\n+            break;\n+\n+          default:\n+            responseObserver.onError(\n+                new StatusException(\n+                    Status.INVALID_ARGUMENT.withDescription(\"Illegal state \" + state)));\n+        }\n+      }\n+\n+      private void resolveNextEnvironment(\n+          StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+        if (pendingResolves.isEmpty()) {\n+          finishStaging(responseObserver);\n+        } else {\n+          state = State.RESOLVE;\n+          LOG.info(\"Resolving artifacts for {}.{}.\", stagingToken, pendingResolves.peek());\n+          responseObserver.onNext(\n+              ArtifactApi.ArtifactRequestWrapper.newBuilder()\n+                  .setResolveArtifact(\n+                      ArtifactApi.ResolveArtifactsRequest.newBuilder()\n+                          .addAllArtifacts(toResolve.get(pendingResolves.peek())))\n+                  .build());\n+        }\n+      }\n+\n+      private void finishStaging(\n+          StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+        LOG.debug(\"Finishing staging for {}.\", stagingToken);\n+        Map<String, List<RunnerApi.ArtifactInformation>> staged = new HashMap<>();\n+        try {\n+          for (Map.Entry<String, List<Future<RunnerApi.ArtifactInformation>>> entry :\n+              stagedFutures.entrySet()) {\n+            List<RunnerApi.ArtifactInformation> envStaged = new ArrayList<>();\n+            for (Future<RunnerApi.ArtifactInformation> future : entry.getValue()) {\n+              envStaged.add(future.get());\n+            }\n+            staged.put(entry.getKey(), envStaged);\n+          }\n+          ArtifactStagingService.this.staged.put(stagingToken, staged);\n+          stagingExecutor.shutdown();\n+          state = State.DONE;\n+          LOG.info(\"Artifacts fully staged for {}.\", stagingToken);\n+          responseObserver.onCompleted();\n+        } catch (Exception exn) {\n+          LOG.error(\"Error staging artifacts\", exn);\n+          responseObserver.onError(exn);\n+          state = State.ERROR;\n+          return;\n+        }\n+      }\n+\n+      /**\n+       * Return an alternative artifact if we do not need to get this over the artifact API, or\n+       * possibly at all.\n+       */\n+      private Optional<RunnerApi.ArtifactInformation> getLocal(\n+          RunnerApi.ArtifactInformation artifact) {\n+        return Optional.empty();\n+      }\n+\n+      /**\n+       * Attempts to provide a reasonable filename for the artifact.\n+       *\n+       * @param index a monotonically increasing index, which provides uniqueness\n+       * @param environment the environment id\n+       * @param artifact the artifact itself\n+       */\n+      private String createFilename(\n+          int index, String environment, RunnerApi.ArtifactInformation artifact) {\n+        String path;\n+        try {\n+          if (artifact.getRoleUrn().equals(ArtifactRetrievalService.STAGING_TO_ARTIFACT_URN)) {\n+            path =\n+                RunnerApi.ArtifactStagingToRolePayload.parseFrom(artifact.getRolePayload())\n+                    .getStagedName();\n+          } else if (artifact.getTypeUrn().equals(ArtifactRetrievalService.FILE_ARTIFACT_URN)) {\n+            path = RunnerApi.ArtifactFilePayload.parseFrom(artifact.getTypePayload()).getPath();\n+          } else if (artifact.getTypeUrn().equals(ArtifactRetrievalService.URL_ARTIFACT_URN)) {\n+            path = RunnerApi.ArtifactUrlPayload.parseFrom(artifact.getTypePayload()).getUrl();\n+          } else {\n+            path = \"artifact\";\n+          }\n+        } catch (InvalidProtocolBufferException exn) {\n+          throw new RuntimeException(exn);\n+        }\n+        // Limit to the last contiguous alpha-numeric sequence. In particular, this will exclude\n+        // all path separators.\n+        List<String> components = Splitter.onPattern(\"[^A-Za-z-_.]]\").splitToList(path);\n+        String base = components.get(components.size() - 1);\n+        return clip(String.format(\"%d-%s-%s\", index, clip(environment, 25), base), 100);\n+      }\n+\n+      private String clip(String s, int maxLength) {\n+        return s.length() < maxLength ? s : s.substring(0, maxLength);\n+      }\n+\n+      @Override\n+      public void onError(Throwable throwable) {\n+        stagingExecutor.shutdownNow();\n+        LOG.error(\"Error staging artifacts\", throwable);\n+        state = State.ERROR;\n+      }\n+\n+      @Override\n+      public void onCompleted() {\n+        assert state == State.DONE;\n+      }\n+    };\n+  }\n+\n+  @Override\n+  public void close() throws Exception {\n+    // Nothing to close.\n+  }\n+\n+  /**\n+   * Lazily stages artifacts by letting an ArtifactStagingService resolve and request artifacts.\n+   *\n+   * @param retrievalService an ArtifactRetrievalService used to resolve and retrieve artifacts\n+   * @param stagingService an ArtifactStagingService stub which will request artifacts\n+   * @param stagingToken the staging token of the job whose artifacts will be retrieved\n+   * @throws InterruptedException\n+   * @throws IOException\n+   */\n+  public static void offer(\n+      ArtifactRetrievalService retrievalService,\n+      ArtifactStagingServiceGrpc.ArtifactStagingServiceStub stagingService,\n+      String stagingToken)\n+      throws InterruptedException, IOException {\n+    StagingRequestObserver requestObserver = new StagingRequestObserver(retrievalService);\n+    requestObserver.responseObserver =\n+        stagingService.reverseArtifactRetrievalService(requestObserver);\n+    requestObserver.responseObserver.onNext(\n+        ArtifactApi.ArtifactResponseWrapper.newBuilder().setStagingToken(stagingToken).build());\n+    requestObserver.waitUntilDone();\n+    if (requestObserver.error != null) {\n+      if (requestObserver.error instanceof IOException) {\n+        throw (IOException) requestObserver.error;\n+      } else {\n+        throw new IOException(requestObserver.error);\n+      }\n+    }\n+  }\n+\n+  /** Actually implements the reverse retrieval protocol. */\n+  private static class StagingRequestObserver\n+      implements StreamObserver<ArtifactApi.ArtifactRequestWrapper> {\n+\n+    private ArtifactRetrievalService retrievalService;\n+\n+    public StagingRequestObserver(ArtifactRetrievalService retrievalService) {\n+      this.retrievalService = retrievalService;\n+    }\n+\n+    CountDownLatch latch = new CountDownLatch(1);\n+    StreamObserver<ArtifactApi.ArtifactResponseWrapper> responseObserver;\n+    Throwable error;\n+\n+    @Override\n+    public void onNext(ArtifactApi.ArtifactRequestWrapper requestWrapper) {\n+      assert responseObserver != null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c8718e46a3692034de9c9a9ed0754bab325cec5"}, "originalPosition": 532}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDUwOTkxOA==", "bodyText": "I had problems like this as well when using gRPC API. You should be able to pass in stagingService to the StagingRequestObserver constructor allowing the responseObserver to be final since you should be able to pass this to reverseArtifactRetrievalService", "url": "https://github.com/apache/beam/pull/11342#discussion_r410509918", "createdAt": "2020-04-17T23:11:44Z", "author": {"login": "lukecwik"}, "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/artifact/ArtifactStagingService.java", "diffHunk": "@@ -0,0 +1,606 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.fnexecution.artifact;\n+\n+import com.google.auto.value.AutoValue;\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.channels.Channels;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.FutureTask;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactApi;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactStagingServiceGrpc;\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+import org.apache.beam.runners.fnexecution.FnService;\n+import org.apache.beam.sdk.io.FileSystems;\n+import org.apache.beam.sdk.io.fs.ResolveOptions;\n+import org.apache.beam.sdk.io.fs.ResourceId;\n+import org.apache.beam.sdk.util.MimeTypes;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.ByteString;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.InvalidProtocolBufferException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.Status;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.StatusException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.stub.StreamObserver;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Splitter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class ArtifactStagingService\n+    extends ArtifactStagingServiceGrpc.ArtifactStagingServiceImplBase implements FnService {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(ArtifactStagingService.class);\n+\n+  private final ArtifactDestinationProvider destinationProvider;\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> toStage =\n+      new ConcurrentHashMap<>();\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> staged =\n+      new ConcurrentHashMap<>();\n+\n+  public ArtifactStagingService(ArtifactDestinationProvider destinationProvider) {\n+    this.destinationProvider = destinationProvider;\n+  }\n+\n+  /**\n+   * Registers a set of artifacts to be staged with this service.\n+   *\n+   * <p>A client (e.g. a Beam SDK) is expected to connect to this service with the given staging\n+   * token and offer resolution and retrieval of this set of artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   * @param artifacts all artifacts to stage, keyed by environment\n+   */\n+  public void registerJob(\n+      String stagingToken, Map<String, List<RunnerApi.ArtifactInformation>> artifacts) {\n+    assert !toStage.containsKey(stagingToken);\n+    toStage.put(stagingToken, artifacts);\n+  }\n+\n+  /**\n+   * Returns the rewritten artifacts associated with this job, keyed by environment.\n+   *\n+   * <p>This should be called after the client has finished offering artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   */\n+  public Map<String, List<RunnerApi.ArtifactInformation>> getStagedArtifacts(String stagingToken) {\n+    toStage.remove(stagingToken);\n+    return staged.remove(stagingToken);\n+  }\n+\n+  /** Provides a concrete location to which artifacts can be staged on retrieval. */\n+  public interface ArtifactDestinationProvider {\n+    ArtifactDestination getDestination(String stagingToken, String name) throws IOException;\n+  }\n+\n+  /**\n+   * A pairing of a newly created artifact type and an ouptut stream that will be readable at that\n+   * type.\n+   */\n+  @AutoValue\n+  public abstract static class ArtifactDestination {\n+    public static ArtifactDestination create(\n+        String typeUrn, ByteString typePayload, OutputStream out) {\n+      return new AutoValue_ArtifactStagingService_ArtifactDestination(typeUrn, typePayload, out);\n+    }\n+\n+    public static ArtifactDestination fromFile(String path) throws IOException {\n+      return fromFile(\n+          path,\n+          Channels.newOutputStream(\n+              FileSystems.create(\n+                  FileSystems.matchNewResource(path, false /* isDirectory */), MimeTypes.BINARY)));\n+    }\n+\n+    public static ArtifactDestination fromFile(String path, OutputStream out) {\n+      return create(\n+          ArtifactRetrievalService.FILE_ARTIFACT_URN,\n+          RunnerApi.ArtifactFilePayload.newBuilder().setPath(path).build().toByteString(),\n+          out);\n+    }\n+\n+    public abstract String getTypeUrn();\n+\n+    public abstract ByteString getTypePayload();\n+\n+    public abstract OutputStream getOutputStream();\n+  }\n+\n+  /**\n+   * An ArtifactDestinationProvider that places new artifacts as files in a Beam filesystem.\n+   *\n+   * @param root the directory in which to place all artifacts\n+   */\n+  public static ArtifactDestinationProvider beamFilesystemArtifactDestinationProvider(String root) {\n+    return (statingToken, name) -> {\n+      ResourceId path =\n+          FileSystems.matchNewResource(root, true)\n+              .resolve(statingToken, ResolveOptions.StandardResolveOptions.RESOLVE_DIRECTORY)\n+              .resolve(name, ResolveOptions.StandardResolveOptions.RESOLVE_FILE);\n+      return ArtifactDestination.fromFile(path.toString());\n+    };\n+  }\n+\n+  private enum State {\n+    START,\n+    RESOLVE,\n+    GET,\n+    GETCHUNK,\n+    DONE,\n+    ERROR,\n+  }\n+\n+  /**\n+   * Like the standard Semaphore, but allows an aquire to go over the limit if there is any room.\n+   *\n+   * <p>Also allows setting an error, to avoid issues with un-released aquires after error.\n+   */\n+  private static class OverflowingSemaphore {\n+    private int totalPermits;\n+    private int usedPermits;\n+    private Exception exception;\n+\n+    public OverflowingSemaphore(int totalPermits) {\n+      this.totalPermits = totalPermits;\n+      this.usedPermits = 0;\n+    }\n+\n+    synchronized void aquire(int permits) throws Exception {\n+      while (usedPermits >= totalPermits) {\n+        if (exception != null) {\n+          throw exception;\n+        }\n+        this.wait();\n+      }\n+      usedPermits += permits;\n+    }\n+\n+    synchronized void release(int permits) {\n+      usedPermits -= permits;\n+      this.notifyAll();\n+    }\n+\n+    synchronized void setException(Exception exception) {\n+      this.exception = exception;\n+      this.notifyAll();\n+    }\n+  }\n+\n+  /** A task that pulls bytes off a queue and actually writes them to a staging location. */\n+  private class StoreArtifact implements Callable<RunnerApi.ArtifactInformation> {\n+\n+    private String stagingToken;\n+    private String name;\n+    private RunnerApi.ArtifactInformation originalArtifact;\n+    private BlockingQueue<ByteString> bytesQueue;\n+    private OverflowingSemaphore totalPendingBytes;\n+\n+    public StoreArtifact(\n+        String stagingToken,\n+        String name,\n+        RunnerApi.ArtifactInformation originalArtifact,\n+        BlockingQueue<ByteString> bytesQueue,\n+        OverflowingSemaphore totalPendingBytes) {\n+      this.stagingToken = stagingToken;\n+      this.name = name;\n+      this.originalArtifact = originalArtifact;\n+      this.bytesQueue = bytesQueue;\n+      this.totalPendingBytes = totalPendingBytes;\n+    }\n+\n+    @Override\n+    public RunnerApi.ArtifactInformation call() throws IOException {\n+      try {\n+        ArtifactDestination dest = destinationProvider.getDestination(stagingToken, name);\n+        LOG.debug(\"Storing artifact for {}.{} at {}\", stagingToken, name, dest);\n+        ByteString chunk = bytesQueue.take();\n+        while (chunk.size() > 0) {\n+          totalPendingBytes.release(chunk.size());\n+          dest.getOutputStream().write(chunk.toByteArray());\n+          chunk = bytesQueue.take();\n+        }\n+        dest.getOutputStream().close();\n+        return originalArtifact\n+            .toBuilder()\n+            .setTypeUrn(dest.getTypeUrn())\n+            .setTypePayload(dest.getTypePayload())\n+            .build();\n+      } catch (IOException | InterruptedException exn) {\n+        // As this thread will no longer be draining the queue, we don't want to get stuck writing\n+        // to it.\n+        totalPendingBytes.setException(exn);\n+        LOG.error(\"Exception staging artifacts\", exn);\n+        if (exn instanceof IOException) {\n+          throw (IOException) exn;\n+        } else {\n+          throw new RuntimeException(exn);\n+        }\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public StreamObserver<ArtifactApi.ArtifactResponseWrapper> reverseArtifactRetrievalService(\n+      StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+\n+    return new StreamObserver<ArtifactApi.ArtifactResponseWrapper>() {\n+\n+      /** The maximum number of parallel threads to use to stage. */\n+      public static final int THREAD_POOL_SIZE = 10;\n+\n+      /** The maximum number of bytes to buffer across all writes before throttling. */\n+      public static final int MAX_PENDING_BYTES = 100 << 20; // 100 MB\n+\n+      String stagingToken;\n+      Map<String, List<RunnerApi.ArtifactInformation>> toResolve;\n+      Map<String, List<Future<RunnerApi.ArtifactInformation>>> stagedFutures;\n+      ExecutorService stagingExecutor;\n+      OverflowingSemaphore totalPendingBytes;\n+\n+      State state = State.START;\n+      Queue<String> pendingResolves;\n+      String currentEnvironment;\n+      int nameIndex;\n+      Queue<RunnerApi.ArtifactInformation> pendingGets;\n+      BlockingQueue<ByteString> currentOutput;\n+\n+      @Override\n+      @SuppressFBWarnings(value = \"SF_SWITCH_FALLTHROUGH\", justification = \"fallthrough intended\")\n+      public synchronized void onNext(ArtifactApi.ArtifactResponseWrapper responseWrapper) {\n+        switch (state) {\n+          case START:\n+            stagingToken = responseWrapper.getStagingToken();\n+            LOG.info(\"Staging artifacts for {}.\", stagingToken);\n+            toResolve = toStage.get(stagingToken);\n+            stagedFutures = new ConcurrentHashMap<>();\n+            pendingResolves = new ArrayDeque<>();\n+            pendingResolves.addAll(toResolve.keySet());\n+            stagingExecutor = Executors.newFixedThreadPool(THREAD_POOL_SIZE);\n+            totalPendingBytes = new OverflowingSemaphore(MAX_PENDING_BYTES);\n+            resolveNextEnvironment(responseObserver);\n+            break;\n+\n+          case RESOLVE:\n+            {\n+              currentEnvironment = pendingResolves.remove();\n+              stagedFutures.put(currentEnvironment, new ArrayList<>());\n+              pendingGets = new ArrayDeque<>();\n+              for (RunnerApi.ArtifactInformation artifact :\n+                  responseWrapper.getResolveArtifactResponse().getReplacementsList()) {\n+                Optional<RunnerApi.ArtifactInformation> fetched = getLocal(artifact);\n+                if (fetched.isPresent()) {\n+                  stagedFutures\n+                      .get(currentEnvironment)\n+                      .add(new FutureTask<RunnerApi.ArtifactInformation>(() -> fetched.get()));\n+                } else {\n+                  pendingGets.add(artifact);\n+                  responseObserver.onNext(\n+                      ArtifactApi.ArtifactRequestWrapper.newBuilder()\n+                          .setGetArtifact(\n+                              ArtifactApi.GetArtifactRequest.newBuilder().setArtifact(artifact))\n+                          .build());\n+                }\n+              }\n+              LOG.info(\n+                  \"Getting {} artifacts for {}.{}.\",\n+                  pendingGets.size(),\n+                  stagingToken,\n+                  pendingResolves.peek());\n+              if (pendingGets.isEmpty()) {\n+                resolveNextEnvironment(responseObserver);\n+              } else {\n+                state = State.GET;\n+              }\n+              break;\n+            }\n+\n+          case GET:\n+            RunnerApi.ArtifactInformation currentArtifact = pendingGets.remove();\n+            String name = createFilename(nameIndex++, currentEnvironment, currentArtifact);\n+            try {\n+              LOG.debug(\"Storing artifacts for {} as {}\", stagingToken, name);\n+              currentOutput = new ArrayBlockingQueue<ByteString>(100);\n+              stagedFutures\n+                  .get(currentEnvironment)\n+                  .add(\n+                      stagingExecutor.submit(\n+                          new StoreArtifact(\n+                              stagingToken,\n+                              name,\n+                              currentArtifact,\n+                              currentOutput,\n+                              totalPendingBytes)));\n+            } catch (Exception exn) {\n+              LOG.error(\"Error submitting.\", exn);\n+              responseObserver.onError(exn);\n+            }\n+            state = State.GETCHUNK;\n+            // fall through\n+\n+          case GETCHUNK:\n+            try {\n+              ByteString chunk = responseWrapper.getGetArtifactResponse().getData();\n+              if (chunk.size() > 0) {\n+                totalPendingBytes.aquire(chunk.size());\n+                currentOutput.put(chunk);\n+              }\n+              if (responseWrapper.getIsLast()) {\n+                currentOutput.put(ByteString.EMPTY); // The EOF value.\n+                if (pendingGets.isEmpty()) {\n+                  resolveNextEnvironment(responseObserver);\n+                } else {\n+                  state = State.GET;\n+                  LOG.debug(\"Waiting for {}\", pendingGets.peek());\n+                }\n+              }\n+            } catch (Exception exn) {\n+              LOG.error(\"Error submitting.\", exn);\n+              onError(exn);\n+            }\n+            break;\n+\n+          default:\n+            responseObserver.onError(\n+                new StatusException(\n+                    Status.INVALID_ARGUMENT.withDescription(\"Illegal state \" + state)));\n+        }\n+      }\n+\n+      private void resolveNextEnvironment(\n+          StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+        if (pendingResolves.isEmpty()) {\n+          finishStaging(responseObserver);\n+        } else {\n+          state = State.RESOLVE;\n+          LOG.info(\"Resolving artifacts for {}.{}.\", stagingToken, pendingResolves.peek());\n+          responseObserver.onNext(\n+              ArtifactApi.ArtifactRequestWrapper.newBuilder()\n+                  .setResolveArtifact(\n+                      ArtifactApi.ResolveArtifactsRequest.newBuilder()\n+                          .addAllArtifacts(toResolve.get(pendingResolves.peek())))\n+                  .build());\n+        }\n+      }\n+\n+      private void finishStaging(\n+          StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+        LOG.debug(\"Finishing staging for {}.\", stagingToken);\n+        Map<String, List<RunnerApi.ArtifactInformation>> staged = new HashMap<>();\n+        try {\n+          for (Map.Entry<String, List<Future<RunnerApi.ArtifactInformation>>> entry :\n+              stagedFutures.entrySet()) {\n+            List<RunnerApi.ArtifactInformation> envStaged = new ArrayList<>();\n+            for (Future<RunnerApi.ArtifactInformation> future : entry.getValue()) {\n+              envStaged.add(future.get());\n+            }\n+            staged.put(entry.getKey(), envStaged);\n+          }\n+          ArtifactStagingService.this.staged.put(stagingToken, staged);\n+          stagingExecutor.shutdown();\n+          state = State.DONE;\n+          LOG.info(\"Artifacts fully staged for {}.\", stagingToken);\n+          responseObserver.onCompleted();\n+        } catch (Exception exn) {\n+          LOG.error(\"Error staging artifacts\", exn);\n+          responseObserver.onError(exn);\n+          state = State.ERROR;\n+          return;\n+        }\n+      }\n+\n+      /**\n+       * Return an alternative artifact if we do not need to get this over the artifact API, or\n+       * possibly at all.\n+       */\n+      private Optional<RunnerApi.ArtifactInformation> getLocal(\n+          RunnerApi.ArtifactInformation artifact) {\n+        return Optional.empty();\n+      }\n+\n+      /**\n+       * Attempts to provide a reasonable filename for the artifact.\n+       *\n+       * @param index a monotonically increasing index, which provides uniqueness\n+       * @param environment the environment id\n+       * @param artifact the artifact itself\n+       */\n+      private String createFilename(\n+          int index, String environment, RunnerApi.ArtifactInformation artifact) {\n+        String path;\n+        try {\n+          if (artifact.getRoleUrn().equals(ArtifactRetrievalService.STAGING_TO_ARTIFACT_URN)) {\n+            path =\n+                RunnerApi.ArtifactStagingToRolePayload.parseFrom(artifact.getRolePayload())\n+                    .getStagedName();\n+          } else if (artifact.getTypeUrn().equals(ArtifactRetrievalService.FILE_ARTIFACT_URN)) {\n+            path = RunnerApi.ArtifactFilePayload.parseFrom(artifact.getTypePayload()).getPath();\n+          } else if (artifact.getTypeUrn().equals(ArtifactRetrievalService.URL_ARTIFACT_URN)) {\n+            path = RunnerApi.ArtifactUrlPayload.parseFrom(artifact.getTypePayload()).getUrl();\n+          } else {\n+            path = \"artifact\";\n+          }\n+        } catch (InvalidProtocolBufferException exn) {\n+          throw new RuntimeException(exn);\n+        }\n+        // Limit to the last contiguous alpha-numeric sequence. In particular, this will exclude\n+        // all path separators.\n+        List<String> components = Splitter.onPattern(\"[^A-Za-z-_.]]\").splitToList(path);\n+        String base = components.get(components.size() - 1);\n+        return clip(String.format(\"%d-%s-%s\", index, clip(environment, 25), base), 100);\n+      }\n+\n+      private String clip(String s, int maxLength) {\n+        return s.length() < maxLength ? s : s.substring(0, maxLength);\n+      }\n+\n+      @Override\n+      public void onError(Throwable throwable) {\n+        stagingExecutor.shutdownNow();\n+        LOG.error(\"Error staging artifacts\", throwable);\n+        state = State.ERROR;\n+      }\n+\n+      @Override\n+      public void onCompleted() {\n+        assert state == State.DONE;\n+      }\n+    };\n+  }\n+\n+  @Override\n+  public void close() throws Exception {\n+    // Nothing to close.\n+  }\n+\n+  /**\n+   * Lazily stages artifacts by letting an ArtifactStagingService resolve and request artifacts.\n+   *\n+   * @param retrievalService an ArtifactRetrievalService used to resolve and retrieve artifacts\n+   * @param stagingService an ArtifactStagingService stub which will request artifacts\n+   * @param stagingToken the staging token of the job whose artifacts will be retrieved\n+   * @throws InterruptedException\n+   * @throws IOException\n+   */\n+  public static void offer(\n+      ArtifactRetrievalService retrievalService,\n+      ArtifactStagingServiceGrpc.ArtifactStagingServiceStub stagingService,\n+      String stagingToken)\n+      throws InterruptedException, IOException {\n+    StagingRequestObserver requestObserver = new StagingRequestObserver(retrievalService);\n+    requestObserver.responseObserver =\n+        stagingService.reverseArtifactRetrievalService(requestObserver);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c8718e46a3692034de9c9a9ed0754bab325cec5"}, "originalPosition": 503}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDUxMTQ0MA==", "bodyText": "You could use a CompletableFuture instead of latch and error. In the onCompleted/onError methods you complete the future. waitUntilDone would then just be future.get", "url": "https://github.com/apache/beam/pull/11342#discussion_r410511440", "createdAt": "2020-04-17T23:18:51Z", "author": {"login": "lukecwik"}, "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/artifact/ArtifactStagingService.java", "diffHunk": "@@ -0,0 +1,606 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.fnexecution.artifact;\n+\n+import com.google.auto.value.AutoValue;\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.channels.Channels;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.FutureTask;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactApi;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactStagingServiceGrpc;\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+import org.apache.beam.runners.fnexecution.FnService;\n+import org.apache.beam.sdk.io.FileSystems;\n+import org.apache.beam.sdk.io.fs.ResolveOptions;\n+import org.apache.beam.sdk.io.fs.ResourceId;\n+import org.apache.beam.sdk.util.MimeTypes;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.ByteString;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.InvalidProtocolBufferException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.Status;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.StatusException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.stub.StreamObserver;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Splitter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class ArtifactStagingService\n+    extends ArtifactStagingServiceGrpc.ArtifactStagingServiceImplBase implements FnService {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(ArtifactStagingService.class);\n+\n+  private final ArtifactDestinationProvider destinationProvider;\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> toStage =\n+      new ConcurrentHashMap<>();\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> staged =\n+      new ConcurrentHashMap<>();\n+\n+  public ArtifactStagingService(ArtifactDestinationProvider destinationProvider) {\n+    this.destinationProvider = destinationProvider;\n+  }\n+\n+  /**\n+   * Registers a set of artifacts to be staged with this service.\n+   *\n+   * <p>A client (e.g. a Beam SDK) is expected to connect to this service with the given staging\n+   * token and offer resolution and retrieval of this set of artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   * @param artifacts all artifacts to stage, keyed by environment\n+   */\n+  public void registerJob(\n+      String stagingToken, Map<String, List<RunnerApi.ArtifactInformation>> artifacts) {\n+    assert !toStage.containsKey(stagingToken);\n+    toStage.put(stagingToken, artifacts);\n+  }\n+\n+  /**\n+   * Returns the rewritten artifacts associated with this job, keyed by environment.\n+   *\n+   * <p>This should be called after the client has finished offering artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   */\n+  public Map<String, List<RunnerApi.ArtifactInformation>> getStagedArtifacts(String stagingToken) {\n+    toStage.remove(stagingToken);\n+    return staged.remove(stagingToken);\n+  }\n+\n+  /** Provides a concrete location to which artifacts can be staged on retrieval. */\n+  public interface ArtifactDestinationProvider {\n+    ArtifactDestination getDestination(String stagingToken, String name) throws IOException;\n+  }\n+\n+  /**\n+   * A pairing of a newly created artifact type and an ouptut stream that will be readable at that\n+   * type.\n+   */\n+  @AutoValue\n+  public abstract static class ArtifactDestination {\n+    public static ArtifactDestination create(\n+        String typeUrn, ByteString typePayload, OutputStream out) {\n+      return new AutoValue_ArtifactStagingService_ArtifactDestination(typeUrn, typePayload, out);\n+    }\n+\n+    public static ArtifactDestination fromFile(String path) throws IOException {\n+      return fromFile(\n+          path,\n+          Channels.newOutputStream(\n+              FileSystems.create(\n+                  FileSystems.matchNewResource(path, false /* isDirectory */), MimeTypes.BINARY)));\n+    }\n+\n+    public static ArtifactDestination fromFile(String path, OutputStream out) {\n+      return create(\n+          ArtifactRetrievalService.FILE_ARTIFACT_URN,\n+          RunnerApi.ArtifactFilePayload.newBuilder().setPath(path).build().toByteString(),\n+          out);\n+    }\n+\n+    public abstract String getTypeUrn();\n+\n+    public abstract ByteString getTypePayload();\n+\n+    public abstract OutputStream getOutputStream();\n+  }\n+\n+  /**\n+   * An ArtifactDestinationProvider that places new artifacts as files in a Beam filesystem.\n+   *\n+   * @param root the directory in which to place all artifacts\n+   */\n+  public static ArtifactDestinationProvider beamFilesystemArtifactDestinationProvider(String root) {\n+    return (statingToken, name) -> {\n+      ResourceId path =\n+          FileSystems.matchNewResource(root, true)\n+              .resolve(statingToken, ResolveOptions.StandardResolveOptions.RESOLVE_DIRECTORY)\n+              .resolve(name, ResolveOptions.StandardResolveOptions.RESOLVE_FILE);\n+      return ArtifactDestination.fromFile(path.toString());\n+    };\n+  }\n+\n+  private enum State {\n+    START,\n+    RESOLVE,\n+    GET,\n+    GETCHUNK,\n+    DONE,\n+    ERROR,\n+  }\n+\n+  /**\n+   * Like the standard Semaphore, but allows an aquire to go over the limit if there is any room.\n+   *\n+   * <p>Also allows setting an error, to avoid issues with un-released aquires after error.\n+   */\n+  private static class OverflowingSemaphore {\n+    private int totalPermits;\n+    private int usedPermits;\n+    private Exception exception;\n+\n+    public OverflowingSemaphore(int totalPermits) {\n+      this.totalPermits = totalPermits;\n+      this.usedPermits = 0;\n+    }\n+\n+    synchronized void aquire(int permits) throws Exception {\n+      while (usedPermits >= totalPermits) {\n+        if (exception != null) {\n+          throw exception;\n+        }\n+        this.wait();\n+      }\n+      usedPermits += permits;\n+    }\n+\n+    synchronized void release(int permits) {\n+      usedPermits -= permits;\n+      this.notifyAll();\n+    }\n+\n+    synchronized void setException(Exception exception) {\n+      this.exception = exception;\n+      this.notifyAll();\n+    }\n+  }\n+\n+  /** A task that pulls bytes off a queue and actually writes them to a staging location. */\n+  private class StoreArtifact implements Callable<RunnerApi.ArtifactInformation> {\n+\n+    private String stagingToken;\n+    private String name;\n+    private RunnerApi.ArtifactInformation originalArtifact;\n+    private BlockingQueue<ByteString> bytesQueue;\n+    private OverflowingSemaphore totalPendingBytes;\n+\n+    public StoreArtifact(\n+        String stagingToken,\n+        String name,\n+        RunnerApi.ArtifactInformation originalArtifact,\n+        BlockingQueue<ByteString> bytesQueue,\n+        OverflowingSemaphore totalPendingBytes) {\n+      this.stagingToken = stagingToken;\n+      this.name = name;\n+      this.originalArtifact = originalArtifact;\n+      this.bytesQueue = bytesQueue;\n+      this.totalPendingBytes = totalPendingBytes;\n+    }\n+\n+    @Override\n+    public RunnerApi.ArtifactInformation call() throws IOException {\n+      try {\n+        ArtifactDestination dest = destinationProvider.getDestination(stagingToken, name);\n+        LOG.debug(\"Storing artifact for {}.{} at {}\", stagingToken, name, dest);\n+        ByteString chunk = bytesQueue.take();\n+        while (chunk.size() > 0) {\n+          totalPendingBytes.release(chunk.size());\n+          dest.getOutputStream().write(chunk.toByteArray());\n+          chunk = bytesQueue.take();\n+        }\n+        dest.getOutputStream().close();\n+        return originalArtifact\n+            .toBuilder()\n+            .setTypeUrn(dest.getTypeUrn())\n+            .setTypePayload(dest.getTypePayload())\n+            .build();\n+      } catch (IOException | InterruptedException exn) {\n+        // As this thread will no longer be draining the queue, we don't want to get stuck writing\n+        // to it.\n+        totalPendingBytes.setException(exn);\n+        LOG.error(\"Exception staging artifacts\", exn);\n+        if (exn instanceof IOException) {\n+          throw (IOException) exn;\n+        } else {\n+          throw new RuntimeException(exn);\n+        }\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public StreamObserver<ArtifactApi.ArtifactResponseWrapper> reverseArtifactRetrievalService(\n+      StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+\n+    return new StreamObserver<ArtifactApi.ArtifactResponseWrapper>() {\n+\n+      /** The maximum number of parallel threads to use to stage. */\n+      public static final int THREAD_POOL_SIZE = 10;\n+\n+      /** The maximum number of bytes to buffer across all writes before throttling. */\n+      public static final int MAX_PENDING_BYTES = 100 << 20; // 100 MB\n+\n+      String stagingToken;\n+      Map<String, List<RunnerApi.ArtifactInformation>> toResolve;\n+      Map<String, List<Future<RunnerApi.ArtifactInformation>>> stagedFutures;\n+      ExecutorService stagingExecutor;\n+      OverflowingSemaphore totalPendingBytes;\n+\n+      State state = State.START;\n+      Queue<String> pendingResolves;\n+      String currentEnvironment;\n+      int nameIndex;\n+      Queue<RunnerApi.ArtifactInformation> pendingGets;\n+      BlockingQueue<ByteString> currentOutput;\n+\n+      @Override\n+      @SuppressFBWarnings(value = \"SF_SWITCH_FALLTHROUGH\", justification = \"fallthrough intended\")\n+      public synchronized void onNext(ArtifactApi.ArtifactResponseWrapper responseWrapper) {\n+        switch (state) {\n+          case START:\n+            stagingToken = responseWrapper.getStagingToken();\n+            LOG.info(\"Staging artifacts for {}.\", stagingToken);\n+            toResolve = toStage.get(stagingToken);\n+            stagedFutures = new ConcurrentHashMap<>();\n+            pendingResolves = new ArrayDeque<>();\n+            pendingResolves.addAll(toResolve.keySet());\n+            stagingExecutor = Executors.newFixedThreadPool(THREAD_POOL_SIZE);\n+            totalPendingBytes = new OverflowingSemaphore(MAX_PENDING_BYTES);\n+            resolveNextEnvironment(responseObserver);\n+            break;\n+\n+          case RESOLVE:\n+            {\n+              currentEnvironment = pendingResolves.remove();\n+              stagedFutures.put(currentEnvironment, new ArrayList<>());\n+              pendingGets = new ArrayDeque<>();\n+              for (RunnerApi.ArtifactInformation artifact :\n+                  responseWrapper.getResolveArtifactResponse().getReplacementsList()) {\n+                Optional<RunnerApi.ArtifactInformation> fetched = getLocal(artifact);\n+                if (fetched.isPresent()) {\n+                  stagedFutures\n+                      .get(currentEnvironment)\n+                      .add(new FutureTask<RunnerApi.ArtifactInformation>(() -> fetched.get()));\n+                } else {\n+                  pendingGets.add(artifact);\n+                  responseObserver.onNext(\n+                      ArtifactApi.ArtifactRequestWrapper.newBuilder()\n+                          .setGetArtifact(\n+                              ArtifactApi.GetArtifactRequest.newBuilder().setArtifact(artifact))\n+                          .build());\n+                }\n+              }\n+              LOG.info(\n+                  \"Getting {} artifacts for {}.{}.\",\n+                  pendingGets.size(),\n+                  stagingToken,\n+                  pendingResolves.peek());\n+              if (pendingGets.isEmpty()) {\n+                resolveNextEnvironment(responseObserver);\n+              } else {\n+                state = State.GET;\n+              }\n+              break;\n+            }\n+\n+          case GET:\n+            RunnerApi.ArtifactInformation currentArtifact = pendingGets.remove();\n+            String name = createFilename(nameIndex++, currentEnvironment, currentArtifact);\n+            try {\n+              LOG.debug(\"Storing artifacts for {} as {}\", stagingToken, name);\n+              currentOutput = new ArrayBlockingQueue<ByteString>(100);\n+              stagedFutures\n+                  .get(currentEnvironment)\n+                  .add(\n+                      stagingExecutor.submit(\n+                          new StoreArtifact(\n+                              stagingToken,\n+                              name,\n+                              currentArtifact,\n+                              currentOutput,\n+                              totalPendingBytes)));\n+            } catch (Exception exn) {\n+              LOG.error(\"Error submitting.\", exn);\n+              responseObserver.onError(exn);\n+            }\n+            state = State.GETCHUNK;\n+            // fall through\n+\n+          case GETCHUNK:\n+            try {\n+              ByteString chunk = responseWrapper.getGetArtifactResponse().getData();\n+              if (chunk.size() > 0) {\n+                totalPendingBytes.aquire(chunk.size());\n+                currentOutput.put(chunk);\n+              }\n+              if (responseWrapper.getIsLast()) {\n+                currentOutput.put(ByteString.EMPTY); // The EOF value.\n+                if (pendingGets.isEmpty()) {\n+                  resolveNextEnvironment(responseObserver);\n+                } else {\n+                  state = State.GET;\n+                  LOG.debug(\"Waiting for {}\", pendingGets.peek());\n+                }\n+              }\n+            } catch (Exception exn) {\n+              LOG.error(\"Error submitting.\", exn);\n+              onError(exn);\n+            }\n+            break;\n+\n+          default:\n+            responseObserver.onError(\n+                new StatusException(\n+                    Status.INVALID_ARGUMENT.withDescription(\"Illegal state \" + state)));\n+        }\n+      }\n+\n+      private void resolveNextEnvironment(\n+          StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+        if (pendingResolves.isEmpty()) {\n+          finishStaging(responseObserver);\n+        } else {\n+          state = State.RESOLVE;\n+          LOG.info(\"Resolving artifacts for {}.{}.\", stagingToken, pendingResolves.peek());\n+          responseObserver.onNext(\n+              ArtifactApi.ArtifactRequestWrapper.newBuilder()\n+                  .setResolveArtifact(\n+                      ArtifactApi.ResolveArtifactsRequest.newBuilder()\n+                          .addAllArtifacts(toResolve.get(pendingResolves.peek())))\n+                  .build());\n+        }\n+      }\n+\n+      private void finishStaging(\n+          StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+        LOG.debug(\"Finishing staging for {}.\", stagingToken);\n+        Map<String, List<RunnerApi.ArtifactInformation>> staged = new HashMap<>();\n+        try {\n+          for (Map.Entry<String, List<Future<RunnerApi.ArtifactInformation>>> entry :\n+              stagedFutures.entrySet()) {\n+            List<RunnerApi.ArtifactInformation> envStaged = new ArrayList<>();\n+            for (Future<RunnerApi.ArtifactInformation> future : entry.getValue()) {\n+              envStaged.add(future.get());\n+            }\n+            staged.put(entry.getKey(), envStaged);\n+          }\n+          ArtifactStagingService.this.staged.put(stagingToken, staged);\n+          stagingExecutor.shutdown();\n+          state = State.DONE;\n+          LOG.info(\"Artifacts fully staged for {}.\", stagingToken);\n+          responseObserver.onCompleted();\n+        } catch (Exception exn) {\n+          LOG.error(\"Error staging artifacts\", exn);\n+          responseObserver.onError(exn);\n+          state = State.ERROR;\n+          return;\n+        }\n+      }\n+\n+      /**\n+       * Return an alternative artifact if we do not need to get this over the artifact API, or\n+       * possibly at all.\n+       */\n+      private Optional<RunnerApi.ArtifactInformation> getLocal(\n+          RunnerApi.ArtifactInformation artifact) {\n+        return Optional.empty();\n+      }\n+\n+      /**\n+       * Attempts to provide a reasonable filename for the artifact.\n+       *\n+       * @param index a monotonically increasing index, which provides uniqueness\n+       * @param environment the environment id\n+       * @param artifact the artifact itself\n+       */\n+      private String createFilename(\n+          int index, String environment, RunnerApi.ArtifactInformation artifact) {\n+        String path;\n+        try {\n+          if (artifact.getRoleUrn().equals(ArtifactRetrievalService.STAGING_TO_ARTIFACT_URN)) {\n+            path =\n+                RunnerApi.ArtifactStagingToRolePayload.parseFrom(artifact.getRolePayload())\n+                    .getStagedName();\n+          } else if (artifact.getTypeUrn().equals(ArtifactRetrievalService.FILE_ARTIFACT_URN)) {\n+            path = RunnerApi.ArtifactFilePayload.parseFrom(artifact.getTypePayload()).getPath();\n+          } else if (artifact.getTypeUrn().equals(ArtifactRetrievalService.URL_ARTIFACT_URN)) {\n+            path = RunnerApi.ArtifactUrlPayload.parseFrom(artifact.getTypePayload()).getUrl();\n+          } else {\n+            path = \"artifact\";\n+          }\n+        } catch (InvalidProtocolBufferException exn) {\n+          throw new RuntimeException(exn);\n+        }\n+        // Limit to the last contiguous alpha-numeric sequence. In particular, this will exclude\n+        // all path separators.\n+        List<String> components = Splitter.onPattern(\"[^A-Za-z-_.]]\").splitToList(path);\n+        String base = components.get(components.size() - 1);\n+        return clip(String.format(\"%d-%s-%s\", index, clip(environment, 25), base), 100);\n+      }\n+\n+      private String clip(String s, int maxLength) {\n+        return s.length() < maxLength ? s : s.substring(0, maxLength);\n+      }\n+\n+      @Override\n+      public void onError(Throwable throwable) {\n+        stagingExecutor.shutdownNow();\n+        LOG.error(\"Error staging artifacts\", throwable);\n+        state = State.ERROR;\n+      }\n+\n+      @Override\n+      public void onCompleted() {\n+        assert state == State.DONE;\n+      }\n+    };\n+  }\n+\n+  @Override\n+  public void close() throws Exception {\n+    // Nothing to close.\n+  }\n+\n+  /**\n+   * Lazily stages artifacts by letting an ArtifactStagingService resolve and request artifacts.\n+   *\n+   * @param retrievalService an ArtifactRetrievalService used to resolve and retrieve artifacts\n+   * @param stagingService an ArtifactStagingService stub which will request artifacts\n+   * @param stagingToken the staging token of the job whose artifacts will be retrieved\n+   * @throws InterruptedException\n+   * @throws IOException\n+   */\n+  public static void offer(\n+      ArtifactRetrievalService retrievalService,\n+      ArtifactStagingServiceGrpc.ArtifactStagingServiceStub stagingService,\n+      String stagingToken)\n+      throws InterruptedException, IOException {\n+    StagingRequestObserver requestObserver = new StagingRequestObserver(retrievalService);\n+    requestObserver.responseObserver =\n+        stagingService.reverseArtifactRetrievalService(requestObserver);\n+    requestObserver.responseObserver.onNext(\n+        ArtifactApi.ArtifactResponseWrapper.newBuilder().setStagingToken(stagingToken).build());\n+    requestObserver.waitUntilDone();\n+    if (requestObserver.error != null) {\n+      if (requestObserver.error instanceof IOException) {\n+        throw (IOException) requestObserver.error;\n+      } else {\n+        throw new IOException(requestObserver.error);\n+      }\n+    }\n+  }\n+\n+  /** Actually implements the reverse retrieval protocol. */\n+  private static class StagingRequestObserver\n+      implements StreamObserver<ArtifactApi.ArtifactRequestWrapper> {\n+\n+    private ArtifactRetrievalService retrievalService;\n+\n+    public StagingRequestObserver(ArtifactRetrievalService retrievalService) {\n+      this.retrievalService = retrievalService;\n+    }\n+\n+    CountDownLatch latch = new CountDownLatch(1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c8718e46a3692034de9c9a9ed0754bab325cec5"}, "originalPosition": 526}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDUxMjQ5Mw==", "bodyText": "why does this need to be synchronized?", "url": "https://github.com/apache/beam/pull/11342#discussion_r410512493", "createdAt": "2020-04-17T23:23:15Z", "author": {"login": "lukecwik"}, "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/artifact/ArtifactStagingService.java", "diffHunk": "@@ -0,0 +1,606 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.fnexecution.artifact;\n+\n+import com.google.auto.value.AutoValue;\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.channels.Channels;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.FutureTask;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactApi;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactStagingServiceGrpc;\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+import org.apache.beam.runners.fnexecution.FnService;\n+import org.apache.beam.sdk.io.FileSystems;\n+import org.apache.beam.sdk.io.fs.ResolveOptions;\n+import org.apache.beam.sdk.io.fs.ResourceId;\n+import org.apache.beam.sdk.util.MimeTypes;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.ByteString;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.InvalidProtocolBufferException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.Status;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.StatusException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.stub.StreamObserver;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Splitter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class ArtifactStagingService\n+    extends ArtifactStagingServiceGrpc.ArtifactStagingServiceImplBase implements FnService {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(ArtifactStagingService.class);\n+\n+  private final ArtifactDestinationProvider destinationProvider;\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> toStage =\n+      new ConcurrentHashMap<>();\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> staged =\n+      new ConcurrentHashMap<>();\n+\n+  public ArtifactStagingService(ArtifactDestinationProvider destinationProvider) {\n+    this.destinationProvider = destinationProvider;\n+  }\n+\n+  /**\n+   * Registers a set of artifacts to be staged with this service.\n+   *\n+   * <p>A client (e.g. a Beam SDK) is expected to connect to this service with the given staging\n+   * token and offer resolution and retrieval of this set of artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   * @param artifacts all artifacts to stage, keyed by environment\n+   */\n+  public void registerJob(\n+      String stagingToken, Map<String, List<RunnerApi.ArtifactInformation>> artifacts) {\n+    assert !toStage.containsKey(stagingToken);\n+    toStage.put(stagingToken, artifacts);\n+  }\n+\n+  /**\n+   * Returns the rewritten artifacts associated with this job, keyed by environment.\n+   *\n+   * <p>This should be called after the client has finished offering artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   */\n+  public Map<String, List<RunnerApi.ArtifactInformation>> getStagedArtifacts(String stagingToken) {\n+    toStage.remove(stagingToken);\n+    return staged.remove(stagingToken);\n+  }\n+\n+  /** Provides a concrete location to which artifacts can be staged on retrieval. */\n+  public interface ArtifactDestinationProvider {\n+    ArtifactDestination getDestination(String stagingToken, String name) throws IOException;\n+  }\n+\n+  /**\n+   * A pairing of a newly created artifact type and an ouptut stream that will be readable at that\n+   * type.\n+   */\n+  @AutoValue\n+  public abstract static class ArtifactDestination {\n+    public static ArtifactDestination create(\n+        String typeUrn, ByteString typePayload, OutputStream out) {\n+      return new AutoValue_ArtifactStagingService_ArtifactDestination(typeUrn, typePayload, out);\n+    }\n+\n+    public static ArtifactDestination fromFile(String path) throws IOException {\n+      return fromFile(\n+          path,\n+          Channels.newOutputStream(\n+              FileSystems.create(\n+                  FileSystems.matchNewResource(path, false /* isDirectory */), MimeTypes.BINARY)));\n+    }\n+\n+    public static ArtifactDestination fromFile(String path, OutputStream out) {\n+      return create(\n+          ArtifactRetrievalService.FILE_ARTIFACT_URN,\n+          RunnerApi.ArtifactFilePayload.newBuilder().setPath(path).build().toByteString(),\n+          out);\n+    }\n+\n+    public abstract String getTypeUrn();\n+\n+    public abstract ByteString getTypePayload();\n+\n+    public abstract OutputStream getOutputStream();\n+  }\n+\n+  /**\n+   * An ArtifactDestinationProvider that places new artifacts as files in a Beam filesystem.\n+   *\n+   * @param root the directory in which to place all artifacts\n+   */\n+  public static ArtifactDestinationProvider beamFilesystemArtifactDestinationProvider(String root) {\n+    return (statingToken, name) -> {\n+      ResourceId path =\n+          FileSystems.matchNewResource(root, true)\n+              .resolve(statingToken, ResolveOptions.StandardResolveOptions.RESOLVE_DIRECTORY)\n+              .resolve(name, ResolveOptions.StandardResolveOptions.RESOLVE_FILE);\n+      return ArtifactDestination.fromFile(path.toString());\n+    };\n+  }\n+\n+  private enum State {\n+    START,\n+    RESOLVE,\n+    GET,\n+    GETCHUNK,\n+    DONE,\n+    ERROR,\n+  }\n+\n+  /**\n+   * Like the standard Semaphore, but allows an aquire to go over the limit if there is any room.\n+   *\n+   * <p>Also allows setting an error, to avoid issues with un-released aquires after error.\n+   */\n+  private static class OverflowingSemaphore {\n+    private int totalPermits;\n+    private int usedPermits;\n+    private Exception exception;\n+\n+    public OverflowingSemaphore(int totalPermits) {\n+      this.totalPermits = totalPermits;\n+      this.usedPermits = 0;\n+    }\n+\n+    synchronized void aquire(int permits) throws Exception {\n+      while (usedPermits >= totalPermits) {\n+        if (exception != null) {\n+          throw exception;\n+        }\n+        this.wait();\n+      }\n+      usedPermits += permits;\n+    }\n+\n+    synchronized void release(int permits) {\n+      usedPermits -= permits;\n+      this.notifyAll();\n+    }\n+\n+    synchronized void setException(Exception exception) {\n+      this.exception = exception;\n+      this.notifyAll();\n+    }\n+  }\n+\n+  /** A task that pulls bytes off a queue and actually writes them to a staging location. */\n+  private class StoreArtifact implements Callable<RunnerApi.ArtifactInformation> {\n+\n+    private String stagingToken;\n+    private String name;\n+    private RunnerApi.ArtifactInformation originalArtifact;\n+    private BlockingQueue<ByteString> bytesQueue;\n+    private OverflowingSemaphore totalPendingBytes;\n+\n+    public StoreArtifact(\n+        String stagingToken,\n+        String name,\n+        RunnerApi.ArtifactInformation originalArtifact,\n+        BlockingQueue<ByteString> bytesQueue,\n+        OverflowingSemaphore totalPendingBytes) {\n+      this.stagingToken = stagingToken;\n+      this.name = name;\n+      this.originalArtifact = originalArtifact;\n+      this.bytesQueue = bytesQueue;\n+      this.totalPendingBytes = totalPendingBytes;\n+    }\n+\n+    @Override\n+    public RunnerApi.ArtifactInformation call() throws IOException {\n+      try {\n+        ArtifactDestination dest = destinationProvider.getDestination(stagingToken, name);\n+        LOG.debug(\"Storing artifact for {}.{} at {}\", stagingToken, name, dest);\n+        ByteString chunk = bytesQueue.take();\n+        while (chunk.size() > 0) {\n+          totalPendingBytes.release(chunk.size());\n+          dest.getOutputStream().write(chunk.toByteArray());\n+          chunk = bytesQueue.take();\n+        }\n+        dest.getOutputStream().close();\n+        return originalArtifact\n+            .toBuilder()\n+            .setTypeUrn(dest.getTypeUrn())\n+            .setTypePayload(dest.getTypePayload())\n+            .build();\n+      } catch (IOException | InterruptedException exn) {\n+        // As this thread will no longer be draining the queue, we don't want to get stuck writing\n+        // to it.\n+        totalPendingBytes.setException(exn);\n+        LOG.error(\"Exception staging artifacts\", exn);\n+        if (exn instanceof IOException) {\n+          throw (IOException) exn;\n+        } else {\n+          throw new RuntimeException(exn);\n+        }\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public StreamObserver<ArtifactApi.ArtifactResponseWrapper> reverseArtifactRetrievalService(\n+      StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+\n+    return new StreamObserver<ArtifactApi.ArtifactResponseWrapper>() {\n+\n+      /** The maximum number of parallel threads to use to stage. */\n+      public static final int THREAD_POOL_SIZE = 10;\n+\n+      /** The maximum number of bytes to buffer across all writes before throttling. */\n+      public static final int MAX_PENDING_BYTES = 100 << 20; // 100 MB\n+\n+      String stagingToken;\n+      Map<String, List<RunnerApi.ArtifactInformation>> toResolve;\n+      Map<String, List<Future<RunnerApi.ArtifactInformation>>> stagedFutures;\n+      ExecutorService stagingExecutor;\n+      OverflowingSemaphore totalPendingBytes;\n+\n+      State state = State.START;\n+      Queue<String> pendingResolves;\n+      String currentEnvironment;\n+      int nameIndex;\n+      Queue<RunnerApi.ArtifactInformation> pendingGets;\n+      BlockingQueue<ByteString> currentOutput;\n+\n+      @Override\n+      @SuppressFBWarnings(value = \"SF_SWITCH_FALLTHROUGH\", justification = \"fallthrough intended\")\n+      public synchronized void onNext(ArtifactApi.ArtifactResponseWrapper responseWrapper) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c8718e46a3692034de9c9a9ed0754bab325cec5"}, "originalPosition": 281}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDUxMjc2Ng==", "bodyText": "Did you want to make this static so that we are only buffering 100mb for the entire process or did you want this limit per file?", "url": "https://github.com/apache/beam/pull/11342#discussion_r410512766", "createdAt": "2020-04-17T23:24:37Z", "author": {"login": "lukecwik"}, "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/artifact/ArtifactStagingService.java", "diffHunk": "@@ -0,0 +1,606 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.fnexecution.artifact;\n+\n+import com.google.auto.value.AutoValue;\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.channels.Channels;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.FutureTask;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactApi;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactStagingServiceGrpc;\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+import org.apache.beam.runners.fnexecution.FnService;\n+import org.apache.beam.sdk.io.FileSystems;\n+import org.apache.beam.sdk.io.fs.ResolveOptions;\n+import org.apache.beam.sdk.io.fs.ResourceId;\n+import org.apache.beam.sdk.util.MimeTypes;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.ByteString;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.InvalidProtocolBufferException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.Status;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.StatusException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.stub.StreamObserver;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Splitter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class ArtifactStagingService\n+    extends ArtifactStagingServiceGrpc.ArtifactStagingServiceImplBase implements FnService {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(ArtifactStagingService.class);\n+\n+  private final ArtifactDestinationProvider destinationProvider;\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> toStage =\n+      new ConcurrentHashMap<>();\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> staged =\n+      new ConcurrentHashMap<>();\n+\n+  public ArtifactStagingService(ArtifactDestinationProvider destinationProvider) {\n+    this.destinationProvider = destinationProvider;\n+  }\n+\n+  /**\n+   * Registers a set of artifacts to be staged with this service.\n+   *\n+   * <p>A client (e.g. a Beam SDK) is expected to connect to this service with the given staging\n+   * token and offer resolution and retrieval of this set of artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   * @param artifacts all artifacts to stage, keyed by environment\n+   */\n+  public void registerJob(\n+      String stagingToken, Map<String, List<RunnerApi.ArtifactInformation>> artifacts) {\n+    assert !toStage.containsKey(stagingToken);\n+    toStage.put(stagingToken, artifacts);\n+  }\n+\n+  /**\n+   * Returns the rewritten artifacts associated with this job, keyed by environment.\n+   *\n+   * <p>This should be called after the client has finished offering artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   */\n+  public Map<String, List<RunnerApi.ArtifactInformation>> getStagedArtifacts(String stagingToken) {\n+    toStage.remove(stagingToken);\n+    return staged.remove(stagingToken);\n+  }\n+\n+  /** Provides a concrete location to which artifacts can be staged on retrieval. */\n+  public interface ArtifactDestinationProvider {\n+    ArtifactDestination getDestination(String stagingToken, String name) throws IOException;\n+  }\n+\n+  /**\n+   * A pairing of a newly created artifact type and an ouptut stream that will be readable at that\n+   * type.\n+   */\n+  @AutoValue\n+  public abstract static class ArtifactDestination {\n+    public static ArtifactDestination create(\n+        String typeUrn, ByteString typePayload, OutputStream out) {\n+      return new AutoValue_ArtifactStagingService_ArtifactDestination(typeUrn, typePayload, out);\n+    }\n+\n+    public static ArtifactDestination fromFile(String path) throws IOException {\n+      return fromFile(\n+          path,\n+          Channels.newOutputStream(\n+              FileSystems.create(\n+                  FileSystems.matchNewResource(path, false /* isDirectory */), MimeTypes.BINARY)));\n+    }\n+\n+    public static ArtifactDestination fromFile(String path, OutputStream out) {\n+      return create(\n+          ArtifactRetrievalService.FILE_ARTIFACT_URN,\n+          RunnerApi.ArtifactFilePayload.newBuilder().setPath(path).build().toByteString(),\n+          out);\n+    }\n+\n+    public abstract String getTypeUrn();\n+\n+    public abstract ByteString getTypePayload();\n+\n+    public abstract OutputStream getOutputStream();\n+  }\n+\n+  /**\n+   * An ArtifactDestinationProvider that places new artifacts as files in a Beam filesystem.\n+   *\n+   * @param root the directory in which to place all artifacts\n+   */\n+  public static ArtifactDestinationProvider beamFilesystemArtifactDestinationProvider(String root) {\n+    return (statingToken, name) -> {\n+      ResourceId path =\n+          FileSystems.matchNewResource(root, true)\n+              .resolve(statingToken, ResolveOptions.StandardResolveOptions.RESOLVE_DIRECTORY)\n+              .resolve(name, ResolveOptions.StandardResolveOptions.RESOLVE_FILE);\n+      return ArtifactDestination.fromFile(path.toString());\n+    };\n+  }\n+\n+  private enum State {\n+    START,\n+    RESOLVE,\n+    GET,\n+    GETCHUNK,\n+    DONE,\n+    ERROR,\n+  }\n+\n+  /**\n+   * Like the standard Semaphore, but allows an aquire to go over the limit if there is any room.\n+   *\n+   * <p>Also allows setting an error, to avoid issues with un-released aquires after error.\n+   */\n+  private static class OverflowingSemaphore {\n+    private int totalPermits;\n+    private int usedPermits;\n+    private Exception exception;\n+\n+    public OverflowingSemaphore(int totalPermits) {\n+      this.totalPermits = totalPermits;\n+      this.usedPermits = 0;\n+    }\n+\n+    synchronized void aquire(int permits) throws Exception {\n+      while (usedPermits >= totalPermits) {\n+        if (exception != null) {\n+          throw exception;\n+        }\n+        this.wait();\n+      }\n+      usedPermits += permits;\n+    }\n+\n+    synchronized void release(int permits) {\n+      usedPermits -= permits;\n+      this.notifyAll();\n+    }\n+\n+    synchronized void setException(Exception exception) {\n+      this.exception = exception;\n+      this.notifyAll();\n+    }\n+  }\n+\n+  /** A task that pulls bytes off a queue and actually writes them to a staging location. */\n+  private class StoreArtifact implements Callable<RunnerApi.ArtifactInformation> {\n+\n+    private String stagingToken;\n+    private String name;\n+    private RunnerApi.ArtifactInformation originalArtifact;\n+    private BlockingQueue<ByteString> bytesQueue;\n+    private OverflowingSemaphore totalPendingBytes;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c8718e46a3692034de9c9a9ed0754bab325cec5"}, "originalPosition": 208}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDUxMzA3Mg==", "bodyText": "expetedContents -> expectedContents", "url": "https://github.com/apache/beam/pull/11342#discussion_r410513072", "createdAt": "2020-04-17T23:25:51Z", "author": {"login": "lukecwik"}, "path": "runners/java-fn-execution/src/test/java/org/apache/beam/runners/fnexecution/artifact/ArtifactStagingServiceTest.java", "diffHunk": "@@ -0,0 +1,189 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.fnexecution.artifact;\n+\n+import static org.junit.Assert.assertEquals;\n+\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactApi;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactRetrievalServiceGrpc;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactStagingServiceGrpc;\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+import org.apache.beam.runners.fnexecution.GrpcFnServer;\n+import org.apache.beam.runners.fnexecution.InProcessServerFactory;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.ByteString;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.ManagedChannel;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.inprocess.InProcessChannelBuilder;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.stub.StreamObserver;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Strings;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Lists;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.JUnit4;\n+\n+@RunWith(JUnit4.class)\n+public class ArtifactStagingServiceTest {\n+  private static final int TEST_BUFFER_SIZE = 1 << 10;\n+  private GrpcFnServer<ArtifactStagingService> stagingServer;\n+  private ArtifactStagingService stagingService;\n+  private GrpcFnServer<ArtifactRetrievalService> retrievalServer;\n+  private ArtifactRetrievalService retrievalService;\n+  private ArtifactStagingServiceGrpc.ArtifactStagingServiceStub stagingStub;\n+  private ArtifactRetrievalServiceGrpc.ArtifactRetrievalServiceBlockingStub retrievalBlockingStub;\n+  private Path stagingDir;\n+  @Rule public TemporaryFolder tempFolder = new TemporaryFolder();\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    stagingDir = tempFolder.newFolder(\"staging\").toPath();\n+    stagingService =\n+        new ArtifactStagingService(\n+            ArtifactStagingService.beamFilesystemArtifactDestinationProvider(\n+                stagingDir.toString()));\n+    stagingServer =\n+        GrpcFnServer.allocatePortAndCreateFor(stagingService, InProcessServerFactory.create());\n+    ManagedChannel stagingChannel =\n+        InProcessChannelBuilder.forName(stagingServer.getApiServiceDescriptor().getUrl()).build();\n+    stagingStub = ArtifactStagingServiceGrpc.newStub(stagingChannel);\n+\n+    retrievalService = new ArtifactRetrievalService(TEST_BUFFER_SIZE);\n+    retrievalServer =\n+        GrpcFnServer.allocatePortAndCreateFor(retrievalService, InProcessServerFactory.create());\n+    ManagedChannel retrievalChannel =\n+        InProcessChannelBuilder.forName(retrievalServer.getApiServiceDescriptor().getUrl()).build();\n+    retrievalBlockingStub = ArtifactRetrievalServiceGrpc.newBlockingStub(retrievalChannel);\n+  }\n+\n+  private static class FakeArtifactRetrievalService extends ArtifactRetrievalService {\n+\n+    @Override\n+    public void resolveArtifacts(\n+        ArtifactApi.ResolveArtifactsRequest request,\n+        StreamObserver<ArtifactApi.ResolveArtifactsResponse> responseObserver) {\n+      ArtifactApi.ResolveArtifactsResponse.Builder response =\n+          ArtifactApi.ResolveArtifactsResponse.newBuilder();\n+      for (RunnerApi.ArtifactInformation artifact : request.getArtifactsList()) {\n+        if (artifact.getTypeUrn().equals(\"resolved\")) {\n+          response.addReplacements(artifact);\n+        } else if (artifact.getTypeUrn().equals(\"unresolved\")) {\n+          response.addReplacements(artifact.toBuilder().setTypeUrn(\"resolved\").build());\n+        } else {\n+          throw new UnsupportedOperationException(artifact.getTypeUrn());\n+        }\n+      }\n+      responseObserver.onNext(response.build());\n+      responseObserver.onCompleted();\n+    }\n+\n+    @Override\n+    public void getArtifact(\n+        ArtifactApi.GetArtifactRequest request,\n+        StreamObserver<ArtifactApi.GetArtifactResponse> responseObserver) {\n+      if (request.getArtifact().getTypeUrn().equals(\"resolved\")) {\n+        ByteString data = request.getArtifact().getTypePayload();\n+        responseObserver.onNext(\n+            ArtifactApi.GetArtifactResponse.newBuilder().setData(data.substring(0, 1)).build());\n+        responseObserver.onNext(\n+            ArtifactApi.GetArtifactResponse.newBuilder().setData(data.substring(1)).build());\n+        responseObserver.onCompleted();\n+      } else {\n+        throw new UnsupportedOperationException(request.getArtifact().getTypeUrn());\n+      }\n+    }\n+\n+    public static RunnerApi.ArtifactInformation resolvedArtifact(String contents) {\n+      return RunnerApi.ArtifactInformation.newBuilder()\n+          .setTypeUrn(\"resolved\")\n+          .setTypePayload(ByteString.copyFromUtf8(contents))\n+          .setRoleUrn(contents)\n+          .build();\n+    }\n+\n+    public static RunnerApi.ArtifactInformation unresolvedArtifact(String contents) {\n+      return RunnerApi.ArtifactInformation.newBuilder()\n+          .setTypeUrn(\"unresolved\")\n+          .setTypePayload(ByteString.copyFromUtf8(contents))\n+          .setRoleUrn(contents)\n+          .build();\n+    }\n+  }\n+\n+  private String getArtifact(RunnerApi.ArtifactInformation artifact) {\n+    ByteString all = ByteString.EMPTY;\n+    Iterator<ArtifactApi.GetArtifactResponse> response =\n+        retrievalBlockingStub.getArtifact(\n+            ArtifactApi.GetArtifactRequest.newBuilder().setArtifact(artifact).build());\n+    while (response.hasNext()) {\n+      all = all.concat(response.next().getData());\n+    }\n+    return all.toStringUtf8();\n+  }\n+\n+  @Test\n+  public void testStageArtifacts() throws IOException, InterruptedException {\n+    List<String> contentsList =\n+        ImmutableList.of(\"a\", \"bb\", Strings.repeat(\"xyz\", TEST_BUFFER_SIZE * 3 / 4));\n+    stagingService.registerJob(\n+        \"stagingToken\",\n+        ImmutableMap.of(\n+            \"env1\",\n+            Lists.transform(contentsList, FakeArtifactRetrievalService::resolvedArtifact),\n+            \"env2\",\n+            Lists.transform(contentsList, FakeArtifactRetrievalService::unresolvedArtifact)));\n+    ArtifactStagingService.offer(new FakeArtifactRetrievalService(), stagingStub, \"stagingToken\");\n+    Map<String, List<RunnerApi.ArtifactInformation>> staged =\n+        stagingService.getStagedArtifacts(\"stagingToken\");\n+    assertEquals(2, staged.size());\n+    checkArtifacts(contentsList, staged.get(\"env1\"));\n+    checkArtifacts(contentsList, staged.get(\"env2\"));\n+  }\n+\n+  private void checkArtifacts(\n+      Collection<String> expetedContents, List<RunnerApi.ArtifactInformation> staged) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c8718e46a3692034de9c9a9ed0754bab325cec5"}, "originalPosition": 168}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDUxMzI1OA==", "bodyText": "Consider using the GrpcCleanupRule as seen here:\nhttps://github.com/grpc/grpc-java/blob/68297d6d7c17453eeae0e0ffbce03edc1eda0a12/examples/src/test/java/io/grpc/examples/helloworld/HelloWorldServerTest.java#L49", "url": "https://github.com/apache/beam/pull/11342#discussion_r410513258", "createdAt": "2020-04-17T23:26:55Z", "author": {"login": "lukecwik"}, "path": "runners/java-fn-execution/src/test/java/org/apache/beam/runners/fnexecution/artifact/ArtifactStagingServiceTest.java", "diffHunk": "@@ -0,0 +1,189 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.fnexecution.artifact;\n+\n+import static org.junit.Assert.assertEquals;\n+\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactApi;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactRetrievalServiceGrpc;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactStagingServiceGrpc;\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+import org.apache.beam.runners.fnexecution.GrpcFnServer;\n+import org.apache.beam.runners.fnexecution.InProcessServerFactory;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.ByteString;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.ManagedChannel;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.inprocess.InProcessChannelBuilder;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.stub.StreamObserver;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Strings;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Lists;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.JUnit4;\n+\n+@RunWith(JUnit4.class)\n+public class ArtifactStagingServiceTest {\n+  private static final int TEST_BUFFER_SIZE = 1 << 10;\n+  private GrpcFnServer<ArtifactStagingService> stagingServer;\n+  private ArtifactStagingService stagingService;\n+  private GrpcFnServer<ArtifactRetrievalService> retrievalServer;\n+  private ArtifactRetrievalService retrievalService;\n+  private ArtifactStagingServiceGrpc.ArtifactStagingServiceStub stagingStub;\n+  private ArtifactRetrievalServiceGrpc.ArtifactRetrievalServiceBlockingStub retrievalBlockingStub;\n+  private Path stagingDir;\n+  @Rule public TemporaryFolder tempFolder = new TemporaryFolder();\n+\n+  @Before\n+  public void setUp() throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c8718e46a3692034de9c9a9ed0754bab325cec5"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDUxMzI4Mw==", "bodyText": "Consider using the GrpcCleanupRule as seen here:\nhttps://github.com/grpc/grpc-java/blob/68297d6d7c17453eeae0e0ffbce03edc1eda0a12/examples/src/test/java/io/grpc/examples/helloworld/HelloWorldServerTest.java#L49", "url": "https://github.com/apache/beam/pull/11342#discussion_r410513283", "createdAt": "2020-04-17T23:27:04Z", "author": {"login": "lukecwik"}, "path": "runners/java-fn-execution/src/test/java/org/apache/beam/runners/fnexecution/artifact/ArtifactRetrievalServiceTest.java", "diffHunk": "@@ -0,0 +1,137 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.fnexecution.artifact;\n+\n+import static org.junit.Assert.assertEquals;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.Iterator;\n+import java.util.Map;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactApi;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactRetrievalServiceGrpc;\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+import org.apache.beam.runners.fnexecution.GrpcFnServer;\n+import org.apache.beam.runners.fnexecution.InProcessServerFactory;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.ByteString;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.ManagedChannel;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.inprocess.InProcessChannelBuilder;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Charsets;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Strings;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.JUnit4;\n+\n+@RunWith(JUnit4.class)\n+public class ArtifactRetrievalServiceTest {\n+  private static final int TEST_BUFFER_SIZE = 1 << 10;\n+  private GrpcFnServer<ArtifactRetrievalService> retrievalServer;\n+  private ArtifactRetrievalService retrievalService;\n+  private ArtifactRetrievalServiceGrpc.ArtifactRetrievalServiceStub retrievalStub;\n+  private ArtifactRetrievalServiceGrpc.ArtifactRetrievalServiceBlockingStub retrievalBlockingStub;\n+  private Path stagingDir;\n+  @Rule public TemporaryFolder tempFolder = new TemporaryFolder();\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    retrievalService = new ArtifactRetrievalService(TEST_BUFFER_SIZE);\n+    retrievalServer =\n+        GrpcFnServer.allocatePortAndCreateFor(retrievalService, InProcessServerFactory.create());\n+    ManagedChannel retrievalChannel =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c8718e46a3692034de9c9a9ed0754bab325cec5"}, "originalPosition": 62}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk1ODg1NTQx", "url": "https://github.com/apache/beam/pull/11342#pullrequestreview-395885541", "createdAt": "2020-04-18T06:06:13Z", "commit": {"oid": "9c8718e46a3692034de9c9a9ed0754bab325cec5"}, "state": "COMMENTED", "comments": {"totalCount": 16, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xOFQwNjowNjoxM1rOGHoOGw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xOFQwNzozMDo1OVrOGHo27Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDY1MjE4Nw==", "bodyText": "The limit is per connection (but shared across files). Making it shared for the whole process is an interesting idea, but would significantly complicate the error handling, so I'll leave it as is for now.", "url": "https://github.com/apache/beam/pull/11342#discussion_r410652187", "createdAt": "2020-04-18T06:06:13Z", "author": {"login": "robertwb"}, "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/artifact/ArtifactStagingService.java", "diffHunk": "@@ -0,0 +1,606 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.fnexecution.artifact;\n+\n+import com.google.auto.value.AutoValue;\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.channels.Channels;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.FutureTask;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactApi;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactStagingServiceGrpc;\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+import org.apache.beam.runners.fnexecution.FnService;\n+import org.apache.beam.sdk.io.FileSystems;\n+import org.apache.beam.sdk.io.fs.ResolveOptions;\n+import org.apache.beam.sdk.io.fs.ResourceId;\n+import org.apache.beam.sdk.util.MimeTypes;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.ByteString;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.InvalidProtocolBufferException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.Status;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.StatusException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.stub.StreamObserver;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Splitter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class ArtifactStagingService\n+    extends ArtifactStagingServiceGrpc.ArtifactStagingServiceImplBase implements FnService {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(ArtifactStagingService.class);\n+\n+  private final ArtifactDestinationProvider destinationProvider;\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> toStage =\n+      new ConcurrentHashMap<>();\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> staged =\n+      new ConcurrentHashMap<>();\n+\n+  public ArtifactStagingService(ArtifactDestinationProvider destinationProvider) {\n+    this.destinationProvider = destinationProvider;\n+  }\n+\n+  /**\n+   * Registers a set of artifacts to be staged with this service.\n+   *\n+   * <p>A client (e.g. a Beam SDK) is expected to connect to this service with the given staging\n+   * token and offer resolution and retrieval of this set of artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   * @param artifacts all artifacts to stage, keyed by environment\n+   */\n+  public void registerJob(\n+      String stagingToken, Map<String, List<RunnerApi.ArtifactInformation>> artifacts) {\n+    assert !toStage.containsKey(stagingToken);\n+    toStage.put(stagingToken, artifacts);\n+  }\n+\n+  /**\n+   * Returns the rewritten artifacts associated with this job, keyed by environment.\n+   *\n+   * <p>This should be called after the client has finished offering artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   */\n+  public Map<String, List<RunnerApi.ArtifactInformation>> getStagedArtifacts(String stagingToken) {\n+    toStage.remove(stagingToken);\n+    return staged.remove(stagingToken);\n+  }\n+\n+  /** Provides a concrete location to which artifacts can be staged on retrieval. */\n+  public interface ArtifactDestinationProvider {\n+    ArtifactDestination getDestination(String stagingToken, String name) throws IOException;\n+  }\n+\n+  /**\n+   * A pairing of a newly created artifact type and an ouptut stream that will be readable at that\n+   * type.\n+   */\n+  @AutoValue\n+  public abstract static class ArtifactDestination {\n+    public static ArtifactDestination create(\n+        String typeUrn, ByteString typePayload, OutputStream out) {\n+      return new AutoValue_ArtifactStagingService_ArtifactDestination(typeUrn, typePayload, out);\n+    }\n+\n+    public static ArtifactDestination fromFile(String path) throws IOException {\n+      return fromFile(\n+          path,\n+          Channels.newOutputStream(\n+              FileSystems.create(\n+                  FileSystems.matchNewResource(path, false /* isDirectory */), MimeTypes.BINARY)));\n+    }\n+\n+    public static ArtifactDestination fromFile(String path, OutputStream out) {\n+      return create(\n+          ArtifactRetrievalService.FILE_ARTIFACT_URN,\n+          RunnerApi.ArtifactFilePayload.newBuilder().setPath(path).build().toByteString(),\n+          out);\n+    }\n+\n+    public abstract String getTypeUrn();\n+\n+    public abstract ByteString getTypePayload();\n+\n+    public abstract OutputStream getOutputStream();\n+  }\n+\n+  /**\n+   * An ArtifactDestinationProvider that places new artifacts as files in a Beam filesystem.\n+   *\n+   * @param root the directory in which to place all artifacts\n+   */\n+  public static ArtifactDestinationProvider beamFilesystemArtifactDestinationProvider(String root) {\n+    return (statingToken, name) -> {\n+      ResourceId path =\n+          FileSystems.matchNewResource(root, true)\n+              .resolve(statingToken, ResolveOptions.StandardResolveOptions.RESOLVE_DIRECTORY)\n+              .resolve(name, ResolveOptions.StandardResolveOptions.RESOLVE_FILE);\n+      return ArtifactDestination.fromFile(path.toString());\n+    };\n+  }\n+\n+  private enum State {\n+    START,\n+    RESOLVE,\n+    GET,\n+    GETCHUNK,\n+    DONE,\n+    ERROR,\n+  }\n+\n+  /**\n+   * Like the standard Semaphore, but allows an aquire to go over the limit if there is any room.\n+   *\n+   * <p>Also allows setting an error, to avoid issues with un-released aquires after error.\n+   */\n+  private static class OverflowingSemaphore {\n+    private int totalPermits;\n+    private int usedPermits;\n+    private Exception exception;\n+\n+    public OverflowingSemaphore(int totalPermits) {\n+      this.totalPermits = totalPermits;\n+      this.usedPermits = 0;\n+    }\n+\n+    synchronized void aquire(int permits) throws Exception {\n+      while (usedPermits >= totalPermits) {\n+        if (exception != null) {\n+          throw exception;\n+        }\n+        this.wait();\n+      }\n+      usedPermits += permits;\n+    }\n+\n+    synchronized void release(int permits) {\n+      usedPermits -= permits;\n+      this.notifyAll();\n+    }\n+\n+    synchronized void setException(Exception exception) {\n+      this.exception = exception;\n+      this.notifyAll();\n+    }\n+  }\n+\n+  /** A task that pulls bytes off a queue and actually writes them to a staging location. */\n+  private class StoreArtifact implements Callable<RunnerApi.ArtifactInformation> {\n+\n+    private String stagingToken;\n+    private String name;\n+    private RunnerApi.ArtifactInformation originalArtifact;\n+    private BlockingQueue<ByteString> bytesQueue;\n+    private OverflowingSemaphore totalPendingBytes;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDUxMjc2Ng=="}, "originalCommit": {"oid": "9c8718e46a3692034de9c9a9ed0754bab325cec5"}, "originalPosition": 208}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDY1MjczOQ==", "bodyText": "Good point. Done.", "url": "https://github.com/apache/beam/pull/11342#discussion_r410652739", "createdAt": "2020-04-18T06:07:33Z", "author": {"login": "robertwb"}, "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/artifact/ArtifactStagingService.java", "diffHunk": "@@ -0,0 +1,606 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.fnexecution.artifact;\n+\n+import com.google.auto.value.AutoValue;\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.channels.Channels;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.FutureTask;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactApi;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactStagingServiceGrpc;\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+import org.apache.beam.runners.fnexecution.FnService;\n+import org.apache.beam.sdk.io.FileSystems;\n+import org.apache.beam.sdk.io.fs.ResolveOptions;\n+import org.apache.beam.sdk.io.fs.ResourceId;\n+import org.apache.beam.sdk.util.MimeTypes;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.ByteString;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.InvalidProtocolBufferException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.Status;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.StatusException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.stub.StreamObserver;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Splitter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class ArtifactStagingService\n+    extends ArtifactStagingServiceGrpc.ArtifactStagingServiceImplBase implements FnService {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(ArtifactStagingService.class);\n+\n+  private final ArtifactDestinationProvider destinationProvider;\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> toStage =\n+      new ConcurrentHashMap<>();\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> staged =\n+      new ConcurrentHashMap<>();\n+\n+  public ArtifactStagingService(ArtifactDestinationProvider destinationProvider) {\n+    this.destinationProvider = destinationProvider;\n+  }\n+\n+  /**\n+   * Registers a set of artifacts to be staged with this service.\n+   *\n+   * <p>A client (e.g. a Beam SDK) is expected to connect to this service with the given staging\n+   * token and offer resolution and retrieval of this set of artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   * @param artifacts all artifacts to stage, keyed by environment\n+   */\n+  public void registerJob(\n+      String stagingToken, Map<String, List<RunnerApi.ArtifactInformation>> artifacts) {\n+    assert !toStage.containsKey(stagingToken);\n+    toStage.put(stagingToken, artifacts);\n+  }\n+\n+  /**\n+   * Returns the rewritten artifacts associated with this job, keyed by environment.\n+   *\n+   * <p>This should be called after the client has finished offering artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   */\n+  public Map<String, List<RunnerApi.ArtifactInformation>> getStagedArtifacts(String stagingToken) {\n+    toStage.remove(stagingToken);\n+    return staged.remove(stagingToken);\n+  }\n+\n+  /** Provides a concrete location to which artifacts can be staged on retrieval. */\n+  public interface ArtifactDestinationProvider {\n+    ArtifactDestination getDestination(String stagingToken, String name) throws IOException;\n+  }\n+\n+  /**\n+   * A pairing of a newly created artifact type and an ouptut stream that will be readable at that\n+   * type.\n+   */\n+  @AutoValue\n+  public abstract static class ArtifactDestination {\n+    public static ArtifactDestination create(\n+        String typeUrn, ByteString typePayload, OutputStream out) {\n+      return new AutoValue_ArtifactStagingService_ArtifactDestination(typeUrn, typePayload, out);\n+    }\n+\n+    public static ArtifactDestination fromFile(String path) throws IOException {\n+      return fromFile(\n+          path,\n+          Channels.newOutputStream(\n+              FileSystems.create(\n+                  FileSystems.matchNewResource(path, false /* isDirectory */), MimeTypes.BINARY)));\n+    }\n+\n+    public static ArtifactDestination fromFile(String path, OutputStream out) {\n+      return create(\n+          ArtifactRetrievalService.FILE_ARTIFACT_URN,\n+          RunnerApi.ArtifactFilePayload.newBuilder().setPath(path).build().toByteString(),\n+          out);\n+    }\n+\n+    public abstract String getTypeUrn();\n+\n+    public abstract ByteString getTypePayload();\n+\n+    public abstract OutputStream getOutputStream();\n+  }\n+\n+  /**\n+   * An ArtifactDestinationProvider that places new artifacts as files in a Beam filesystem.\n+   *\n+   * @param root the directory in which to place all artifacts\n+   */\n+  public static ArtifactDestinationProvider beamFilesystemArtifactDestinationProvider(String root) {\n+    return (statingToken, name) -> {\n+      ResourceId path =\n+          FileSystems.matchNewResource(root, true)\n+              .resolve(statingToken, ResolveOptions.StandardResolveOptions.RESOLVE_DIRECTORY)\n+              .resolve(name, ResolveOptions.StandardResolveOptions.RESOLVE_FILE);\n+      return ArtifactDestination.fromFile(path.toString());\n+    };\n+  }\n+\n+  private enum State {\n+    START,\n+    RESOLVE,\n+    GET,\n+    GETCHUNK,\n+    DONE,\n+    ERROR,\n+  }\n+\n+  /**\n+   * Like the standard Semaphore, but allows an aquire to go over the limit if there is any room.\n+   *\n+   * <p>Also allows setting an error, to avoid issues with un-released aquires after error.\n+   */\n+  private static class OverflowingSemaphore {\n+    private int totalPermits;\n+    private int usedPermits;\n+    private Exception exception;\n+\n+    public OverflowingSemaphore(int totalPermits) {\n+      this.totalPermits = totalPermits;\n+      this.usedPermits = 0;\n+    }\n+\n+    synchronized void aquire(int permits) throws Exception {\n+      while (usedPermits >= totalPermits) {\n+        if (exception != null) {\n+          throw exception;\n+        }\n+        this.wait();\n+      }\n+      usedPermits += permits;\n+    }\n+\n+    synchronized void release(int permits) {\n+      usedPermits -= permits;\n+      this.notifyAll();\n+    }\n+\n+    synchronized void setException(Exception exception) {\n+      this.exception = exception;\n+      this.notifyAll();\n+    }\n+  }\n+\n+  /** A task that pulls bytes off a queue and actually writes them to a staging location. */\n+  private class StoreArtifact implements Callable<RunnerApi.ArtifactInformation> {\n+\n+    private String stagingToken;\n+    private String name;\n+    private RunnerApi.ArtifactInformation originalArtifact;\n+    private BlockingQueue<ByteString> bytesQueue;\n+    private OverflowingSemaphore totalPendingBytes;\n+\n+    public StoreArtifact(\n+        String stagingToken,\n+        String name,\n+        RunnerApi.ArtifactInformation originalArtifact,\n+        BlockingQueue<ByteString> bytesQueue,\n+        OverflowingSemaphore totalPendingBytes) {\n+      this.stagingToken = stagingToken;\n+      this.name = name;\n+      this.originalArtifact = originalArtifact;\n+      this.bytesQueue = bytesQueue;\n+      this.totalPendingBytes = totalPendingBytes;\n+    }\n+\n+    @Override\n+    public RunnerApi.ArtifactInformation call() throws IOException {\n+      try {\n+        ArtifactDestination dest = destinationProvider.getDestination(stagingToken, name);\n+        LOG.debug(\"Storing artifact for {}.{} at {}\", stagingToken, name, dest);\n+        ByteString chunk = bytesQueue.take();\n+        while (chunk.size() > 0) {\n+          totalPendingBytes.release(chunk.size());\n+          dest.getOutputStream().write(chunk.toByteArray());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDQ5OTE0Ng=="}, "originalCommit": {"oid": "9c8718e46a3692034de9c9a9ed0754bab325cec5"}, "originalPosition": 231}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDY1MzQ2MA==", "bodyText": "There is no guarantee that onNext will get called by the same thread each time, but there's a fair amount of instance state that needs to be guarded. This is for memory synchronization, not to disable concurrency.", "url": "https://github.com/apache/beam/pull/11342#discussion_r410653460", "createdAt": "2020-04-18T06:09:19Z", "author": {"login": "robertwb"}, "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/artifact/ArtifactStagingService.java", "diffHunk": "@@ -0,0 +1,606 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.fnexecution.artifact;\n+\n+import com.google.auto.value.AutoValue;\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.channels.Channels;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.FutureTask;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactApi;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactStagingServiceGrpc;\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+import org.apache.beam.runners.fnexecution.FnService;\n+import org.apache.beam.sdk.io.FileSystems;\n+import org.apache.beam.sdk.io.fs.ResolveOptions;\n+import org.apache.beam.sdk.io.fs.ResourceId;\n+import org.apache.beam.sdk.util.MimeTypes;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.ByteString;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.InvalidProtocolBufferException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.Status;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.StatusException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.stub.StreamObserver;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Splitter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class ArtifactStagingService\n+    extends ArtifactStagingServiceGrpc.ArtifactStagingServiceImplBase implements FnService {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(ArtifactStagingService.class);\n+\n+  private final ArtifactDestinationProvider destinationProvider;\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> toStage =\n+      new ConcurrentHashMap<>();\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> staged =\n+      new ConcurrentHashMap<>();\n+\n+  public ArtifactStagingService(ArtifactDestinationProvider destinationProvider) {\n+    this.destinationProvider = destinationProvider;\n+  }\n+\n+  /**\n+   * Registers a set of artifacts to be staged with this service.\n+   *\n+   * <p>A client (e.g. a Beam SDK) is expected to connect to this service with the given staging\n+   * token and offer resolution and retrieval of this set of artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   * @param artifacts all artifacts to stage, keyed by environment\n+   */\n+  public void registerJob(\n+      String stagingToken, Map<String, List<RunnerApi.ArtifactInformation>> artifacts) {\n+    assert !toStage.containsKey(stagingToken);\n+    toStage.put(stagingToken, artifacts);\n+  }\n+\n+  /**\n+   * Returns the rewritten artifacts associated with this job, keyed by environment.\n+   *\n+   * <p>This should be called after the client has finished offering artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   */\n+  public Map<String, List<RunnerApi.ArtifactInformation>> getStagedArtifacts(String stagingToken) {\n+    toStage.remove(stagingToken);\n+    return staged.remove(stagingToken);\n+  }\n+\n+  /** Provides a concrete location to which artifacts can be staged on retrieval. */\n+  public interface ArtifactDestinationProvider {\n+    ArtifactDestination getDestination(String stagingToken, String name) throws IOException;\n+  }\n+\n+  /**\n+   * A pairing of a newly created artifact type and an ouptut stream that will be readable at that\n+   * type.\n+   */\n+  @AutoValue\n+  public abstract static class ArtifactDestination {\n+    public static ArtifactDestination create(\n+        String typeUrn, ByteString typePayload, OutputStream out) {\n+      return new AutoValue_ArtifactStagingService_ArtifactDestination(typeUrn, typePayload, out);\n+    }\n+\n+    public static ArtifactDestination fromFile(String path) throws IOException {\n+      return fromFile(\n+          path,\n+          Channels.newOutputStream(\n+              FileSystems.create(\n+                  FileSystems.matchNewResource(path, false /* isDirectory */), MimeTypes.BINARY)));\n+    }\n+\n+    public static ArtifactDestination fromFile(String path, OutputStream out) {\n+      return create(\n+          ArtifactRetrievalService.FILE_ARTIFACT_URN,\n+          RunnerApi.ArtifactFilePayload.newBuilder().setPath(path).build().toByteString(),\n+          out);\n+    }\n+\n+    public abstract String getTypeUrn();\n+\n+    public abstract ByteString getTypePayload();\n+\n+    public abstract OutputStream getOutputStream();\n+  }\n+\n+  /**\n+   * An ArtifactDestinationProvider that places new artifacts as files in a Beam filesystem.\n+   *\n+   * @param root the directory in which to place all artifacts\n+   */\n+  public static ArtifactDestinationProvider beamFilesystemArtifactDestinationProvider(String root) {\n+    return (statingToken, name) -> {\n+      ResourceId path =\n+          FileSystems.matchNewResource(root, true)\n+              .resolve(statingToken, ResolveOptions.StandardResolveOptions.RESOLVE_DIRECTORY)\n+              .resolve(name, ResolveOptions.StandardResolveOptions.RESOLVE_FILE);\n+      return ArtifactDestination.fromFile(path.toString());\n+    };\n+  }\n+\n+  private enum State {\n+    START,\n+    RESOLVE,\n+    GET,\n+    GETCHUNK,\n+    DONE,\n+    ERROR,\n+  }\n+\n+  /**\n+   * Like the standard Semaphore, but allows an aquire to go over the limit if there is any room.\n+   *\n+   * <p>Also allows setting an error, to avoid issues with un-released aquires after error.\n+   */\n+  private static class OverflowingSemaphore {\n+    private int totalPermits;\n+    private int usedPermits;\n+    private Exception exception;\n+\n+    public OverflowingSemaphore(int totalPermits) {\n+      this.totalPermits = totalPermits;\n+      this.usedPermits = 0;\n+    }\n+\n+    synchronized void aquire(int permits) throws Exception {\n+      while (usedPermits >= totalPermits) {\n+        if (exception != null) {\n+          throw exception;\n+        }\n+        this.wait();\n+      }\n+      usedPermits += permits;\n+    }\n+\n+    synchronized void release(int permits) {\n+      usedPermits -= permits;\n+      this.notifyAll();\n+    }\n+\n+    synchronized void setException(Exception exception) {\n+      this.exception = exception;\n+      this.notifyAll();\n+    }\n+  }\n+\n+  /** A task that pulls bytes off a queue and actually writes them to a staging location. */\n+  private class StoreArtifact implements Callable<RunnerApi.ArtifactInformation> {\n+\n+    private String stagingToken;\n+    private String name;\n+    private RunnerApi.ArtifactInformation originalArtifact;\n+    private BlockingQueue<ByteString> bytesQueue;\n+    private OverflowingSemaphore totalPendingBytes;\n+\n+    public StoreArtifact(\n+        String stagingToken,\n+        String name,\n+        RunnerApi.ArtifactInformation originalArtifact,\n+        BlockingQueue<ByteString> bytesQueue,\n+        OverflowingSemaphore totalPendingBytes) {\n+      this.stagingToken = stagingToken;\n+      this.name = name;\n+      this.originalArtifact = originalArtifact;\n+      this.bytesQueue = bytesQueue;\n+      this.totalPendingBytes = totalPendingBytes;\n+    }\n+\n+    @Override\n+    public RunnerApi.ArtifactInformation call() throws IOException {\n+      try {\n+        ArtifactDestination dest = destinationProvider.getDestination(stagingToken, name);\n+        LOG.debug(\"Storing artifact for {}.{} at {}\", stagingToken, name, dest);\n+        ByteString chunk = bytesQueue.take();\n+        while (chunk.size() > 0) {\n+          totalPendingBytes.release(chunk.size());\n+          dest.getOutputStream().write(chunk.toByteArray());\n+          chunk = bytesQueue.take();\n+        }\n+        dest.getOutputStream().close();\n+        return originalArtifact\n+            .toBuilder()\n+            .setTypeUrn(dest.getTypeUrn())\n+            .setTypePayload(dest.getTypePayload())\n+            .build();\n+      } catch (IOException | InterruptedException exn) {\n+        // As this thread will no longer be draining the queue, we don't want to get stuck writing\n+        // to it.\n+        totalPendingBytes.setException(exn);\n+        LOG.error(\"Exception staging artifacts\", exn);\n+        if (exn instanceof IOException) {\n+          throw (IOException) exn;\n+        } else {\n+          throw new RuntimeException(exn);\n+        }\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public StreamObserver<ArtifactApi.ArtifactResponseWrapper> reverseArtifactRetrievalService(\n+      StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+\n+    return new StreamObserver<ArtifactApi.ArtifactResponseWrapper>() {\n+\n+      /** The maximum number of parallel threads to use to stage. */\n+      public static final int THREAD_POOL_SIZE = 10;\n+\n+      /** The maximum number of bytes to buffer across all writes before throttling. */\n+      public static final int MAX_PENDING_BYTES = 100 << 20; // 100 MB\n+\n+      String stagingToken;\n+      Map<String, List<RunnerApi.ArtifactInformation>> toResolve;\n+      Map<String, List<Future<RunnerApi.ArtifactInformation>>> stagedFutures;\n+      ExecutorService stagingExecutor;\n+      OverflowingSemaphore totalPendingBytes;\n+\n+      State state = State.START;\n+      Queue<String> pendingResolves;\n+      String currentEnvironment;\n+      int nameIndex;\n+      Queue<RunnerApi.ArtifactInformation> pendingGets;\n+      BlockingQueue<ByteString> currentOutput;\n+\n+      @Override\n+      @SuppressFBWarnings(value = \"SF_SWITCH_FALLTHROUGH\", justification = \"fallthrough intended\")\n+      public synchronized void onNext(ArtifactApi.ArtifactResponseWrapper responseWrapper) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDUxMjQ5Mw=="}, "originalCommit": {"oid": "9c8718e46a3692034de9c9a9ed0754bab325cec5"}, "originalPosition": 281}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDY1NTg0NA==", "bodyText": "Ah, yes, that's nicer.", "url": "https://github.com/apache/beam/pull/11342#discussion_r410655844", "createdAt": "2020-04-18T06:22:20Z", "author": {"login": "robertwb"}, "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/artifact/ArtifactStagingService.java", "diffHunk": "@@ -0,0 +1,606 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.fnexecution.artifact;\n+\n+import com.google.auto.value.AutoValue;\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.channels.Channels;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.FutureTask;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactApi;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactStagingServiceGrpc;\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+import org.apache.beam.runners.fnexecution.FnService;\n+import org.apache.beam.sdk.io.FileSystems;\n+import org.apache.beam.sdk.io.fs.ResolveOptions;\n+import org.apache.beam.sdk.io.fs.ResourceId;\n+import org.apache.beam.sdk.util.MimeTypes;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.ByteString;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.InvalidProtocolBufferException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.Status;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.StatusException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.stub.StreamObserver;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Splitter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class ArtifactStagingService\n+    extends ArtifactStagingServiceGrpc.ArtifactStagingServiceImplBase implements FnService {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(ArtifactStagingService.class);\n+\n+  private final ArtifactDestinationProvider destinationProvider;\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> toStage =\n+      new ConcurrentHashMap<>();\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> staged =\n+      new ConcurrentHashMap<>();\n+\n+  public ArtifactStagingService(ArtifactDestinationProvider destinationProvider) {\n+    this.destinationProvider = destinationProvider;\n+  }\n+\n+  /**\n+   * Registers a set of artifacts to be staged with this service.\n+   *\n+   * <p>A client (e.g. a Beam SDK) is expected to connect to this service with the given staging\n+   * token and offer resolution and retrieval of this set of artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   * @param artifacts all artifacts to stage, keyed by environment\n+   */\n+  public void registerJob(\n+      String stagingToken, Map<String, List<RunnerApi.ArtifactInformation>> artifacts) {\n+    assert !toStage.containsKey(stagingToken);\n+    toStage.put(stagingToken, artifacts);\n+  }\n+\n+  /**\n+   * Returns the rewritten artifacts associated with this job, keyed by environment.\n+   *\n+   * <p>This should be called after the client has finished offering artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   */\n+  public Map<String, List<RunnerApi.ArtifactInformation>> getStagedArtifacts(String stagingToken) {\n+    toStage.remove(stagingToken);\n+    return staged.remove(stagingToken);\n+  }\n+\n+  /** Provides a concrete location to which artifacts can be staged on retrieval. */\n+  public interface ArtifactDestinationProvider {\n+    ArtifactDestination getDestination(String stagingToken, String name) throws IOException;\n+  }\n+\n+  /**\n+   * A pairing of a newly created artifact type and an ouptut stream that will be readable at that\n+   * type.\n+   */\n+  @AutoValue\n+  public abstract static class ArtifactDestination {\n+    public static ArtifactDestination create(\n+        String typeUrn, ByteString typePayload, OutputStream out) {\n+      return new AutoValue_ArtifactStagingService_ArtifactDestination(typeUrn, typePayload, out);\n+    }\n+\n+    public static ArtifactDestination fromFile(String path) throws IOException {\n+      return fromFile(\n+          path,\n+          Channels.newOutputStream(\n+              FileSystems.create(\n+                  FileSystems.matchNewResource(path, false /* isDirectory */), MimeTypes.BINARY)));\n+    }\n+\n+    public static ArtifactDestination fromFile(String path, OutputStream out) {\n+      return create(\n+          ArtifactRetrievalService.FILE_ARTIFACT_URN,\n+          RunnerApi.ArtifactFilePayload.newBuilder().setPath(path).build().toByteString(),\n+          out);\n+    }\n+\n+    public abstract String getTypeUrn();\n+\n+    public abstract ByteString getTypePayload();\n+\n+    public abstract OutputStream getOutputStream();\n+  }\n+\n+  /**\n+   * An ArtifactDestinationProvider that places new artifacts as files in a Beam filesystem.\n+   *\n+   * @param root the directory in which to place all artifacts\n+   */\n+  public static ArtifactDestinationProvider beamFilesystemArtifactDestinationProvider(String root) {\n+    return (statingToken, name) -> {\n+      ResourceId path =\n+          FileSystems.matchNewResource(root, true)\n+              .resolve(statingToken, ResolveOptions.StandardResolveOptions.RESOLVE_DIRECTORY)\n+              .resolve(name, ResolveOptions.StandardResolveOptions.RESOLVE_FILE);\n+      return ArtifactDestination.fromFile(path.toString());\n+    };\n+  }\n+\n+  private enum State {\n+    START,\n+    RESOLVE,\n+    GET,\n+    GETCHUNK,\n+    DONE,\n+    ERROR,\n+  }\n+\n+  /**\n+   * Like the standard Semaphore, but allows an aquire to go over the limit if there is any room.\n+   *\n+   * <p>Also allows setting an error, to avoid issues with un-released aquires after error.\n+   */\n+  private static class OverflowingSemaphore {\n+    private int totalPermits;\n+    private int usedPermits;\n+    private Exception exception;\n+\n+    public OverflowingSemaphore(int totalPermits) {\n+      this.totalPermits = totalPermits;\n+      this.usedPermits = 0;\n+    }\n+\n+    synchronized void aquire(int permits) throws Exception {\n+      while (usedPermits >= totalPermits) {\n+        if (exception != null) {\n+          throw exception;\n+        }\n+        this.wait();\n+      }\n+      usedPermits += permits;\n+    }\n+\n+    synchronized void release(int permits) {\n+      usedPermits -= permits;\n+      this.notifyAll();\n+    }\n+\n+    synchronized void setException(Exception exception) {\n+      this.exception = exception;\n+      this.notifyAll();\n+    }\n+  }\n+\n+  /** A task that pulls bytes off a queue and actually writes them to a staging location. */\n+  private class StoreArtifact implements Callable<RunnerApi.ArtifactInformation> {\n+\n+    private String stagingToken;\n+    private String name;\n+    private RunnerApi.ArtifactInformation originalArtifact;\n+    private BlockingQueue<ByteString> bytesQueue;\n+    private OverflowingSemaphore totalPendingBytes;\n+\n+    public StoreArtifact(\n+        String stagingToken,\n+        String name,\n+        RunnerApi.ArtifactInformation originalArtifact,\n+        BlockingQueue<ByteString> bytesQueue,\n+        OverflowingSemaphore totalPendingBytes) {\n+      this.stagingToken = stagingToken;\n+      this.name = name;\n+      this.originalArtifact = originalArtifact;\n+      this.bytesQueue = bytesQueue;\n+      this.totalPendingBytes = totalPendingBytes;\n+    }\n+\n+    @Override\n+    public RunnerApi.ArtifactInformation call() throws IOException {\n+      try {\n+        ArtifactDestination dest = destinationProvider.getDestination(stagingToken, name);\n+        LOG.debug(\"Storing artifact for {}.{} at {}\", stagingToken, name, dest);\n+        ByteString chunk = bytesQueue.take();\n+        while (chunk.size() > 0) {\n+          totalPendingBytes.release(chunk.size());\n+          dest.getOutputStream().write(chunk.toByteArray());\n+          chunk = bytesQueue.take();\n+        }\n+        dest.getOutputStream().close();\n+        return originalArtifact\n+            .toBuilder()\n+            .setTypeUrn(dest.getTypeUrn())\n+            .setTypePayload(dest.getTypePayload())\n+            .build();\n+      } catch (IOException | InterruptedException exn) {\n+        // As this thread will no longer be draining the queue, we don't want to get stuck writing\n+        // to it.\n+        totalPendingBytes.setException(exn);\n+        LOG.error(\"Exception staging artifacts\", exn);\n+        if (exn instanceof IOException) {\n+          throw (IOException) exn;\n+        } else {\n+          throw new RuntimeException(exn);\n+        }\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public StreamObserver<ArtifactApi.ArtifactResponseWrapper> reverseArtifactRetrievalService(\n+      StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+\n+    return new StreamObserver<ArtifactApi.ArtifactResponseWrapper>() {\n+\n+      /** The maximum number of parallel threads to use to stage. */\n+      public static final int THREAD_POOL_SIZE = 10;\n+\n+      /** The maximum number of bytes to buffer across all writes before throttling. */\n+      public static final int MAX_PENDING_BYTES = 100 << 20; // 100 MB\n+\n+      String stagingToken;\n+      Map<String, List<RunnerApi.ArtifactInformation>> toResolve;\n+      Map<String, List<Future<RunnerApi.ArtifactInformation>>> stagedFutures;\n+      ExecutorService stagingExecutor;\n+      OverflowingSemaphore totalPendingBytes;\n+\n+      State state = State.START;\n+      Queue<String> pendingResolves;\n+      String currentEnvironment;\n+      int nameIndex;\n+      Queue<RunnerApi.ArtifactInformation> pendingGets;\n+      BlockingQueue<ByteString> currentOutput;\n+\n+      @Override\n+      @SuppressFBWarnings(value = \"SF_SWITCH_FALLTHROUGH\", justification = \"fallthrough intended\")\n+      public synchronized void onNext(ArtifactApi.ArtifactResponseWrapper responseWrapper) {\n+        switch (state) {\n+          case START:\n+            stagingToken = responseWrapper.getStagingToken();\n+            LOG.info(\"Staging artifacts for {}.\", stagingToken);\n+            toResolve = toStage.get(stagingToken);\n+            stagedFutures = new ConcurrentHashMap<>();\n+            pendingResolves = new ArrayDeque<>();\n+            pendingResolves.addAll(toResolve.keySet());\n+            stagingExecutor = Executors.newFixedThreadPool(THREAD_POOL_SIZE);\n+            totalPendingBytes = new OverflowingSemaphore(MAX_PENDING_BYTES);\n+            resolveNextEnvironment(responseObserver);\n+            break;\n+\n+          case RESOLVE:\n+            {\n+              currentEnvironment = pendingResolves.remove();\n+              stagedFutures.put(currentEnvironment, new ArrayList<>());\n+              pendingGets = new ArrayDeque<>();\n+              for (RunnerApi.ArtifactInformation artifact :\n+                  responseWrapper.getResolveArtifactResponse().getReplacementsList()) {\n+                Optional<RunnerApi.ArtifactInformation> fetched = getLocal(artifact);\n+                if (fetched.isPresent()) {\n+                  stagedFutures\n+                      .get(currentEnvironment)\n+                      .add(new FutureTask<RunnerApi.ArtifactInformation>(() -> fetched.get()));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDUwMTE2Nw=="}, "originalCommit": {"oid": "9c8718e46a3692034de9c9a9ed0754bab325cec5"}, "originalPosition": 306}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDY1NjM0NA==", "bodyText": "Switched to idGenerator. Keeping it as an instance member so that each staging is consecutive starting at 0.", "url": "https://github.com/apache/beam/pull/11342#discussion_r410656344", "createdAt": "2020-04-18T06:27:26Z", "author": {"login": "robertwb"}, "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/artifact/ArtifactStagingService.java", "diffHunk": "@@ -0,0 +1,606 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.fnexecution.artifact;\n+\n+import com.google.auto.value.AutoValue;\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.channels.Channels;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.FutureTask;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactApi;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactStagingServiceGrpc;\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+import org.apache.beam.runners.fnexecution.FnService;\n+import org.apache.beam.sdk.io.FileSystems;\n+import org.apache.beam.sdk.io.fs.ResolveOptions;\n+import org.apache.beam.sdk.io.fs.ResourceId;\n+import org.apache.beam.sdk.util.MimeTypes;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.ByteString;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.InvalidProtocolBufferException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.Status;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.StatusException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.stub.StreamObserver;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Splitter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class ArtifactStagingService\n+    extends ArtifactStagingServiceGrpc.ArtifactStagingServiceImplBase implements FnService {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(ArtifactStagingService.class);\n+\n+  private final ArtifactDestinationProvider destinationProvider;\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> toStage =\n+      new ConcurrentHashMap<>();\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> staged =\n+      new ConcurrentHashMap<>();\n+\n+  public ArtifactStagingService(ArtifactDestinationProvider destinationProvider) {\n+    this.destinationProvider = destinationProvider;\n+  }\n+\n+  /**\n+   * Registers a set of artifacts to be staged with this service.\n+   *\n+   * <p>A client (e.g. a Beam SDK) is expected to connect to this service with the given staging\n+   * token and offer resolution and retrieval of this set of artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   * @param artifacts all artifacts to stage, keyed by environment\n+   */\n+  public void registerJob(\n+      String stagingToken, Map<String, List<RunnerApi.ArtifactInformation>> artifacts) {\n+    assert !toStage.containsKey(stagingToken);\n+    toStage.put(stagingToken, artifacts);\n+  }\n+\n+  /**\n+   * Returns the rewritten artifacts associated with this job, keyed by environment.\n+   *\n+   * <p>This should be called after the client has finished offering artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   */\n+  public Map<String, List<RunnerApi.ArtifactInformation>> getStagedArtifacts(String stagingToken) {\n+    toStage.remove(stagingToken);\n+    return staged.remove(stagingToken);\n+  }\n+\n+  /** Provides a concrete location to which artifacts can be staged on retrieval. */\n+  public interface ArtifactDestinationProvider {\n+    ArtifactDestination getDestination(String stagingToken, String name) throws IOException;\n+  }\n+\n+  /**\n+   * A pairing of a newly created artifact type and an ouptut stream that will be readable at that\n+   * type.\n+   */\n+  @AutoValue\n+  public abstract static class ArtifactDestination {\n+    public static ArtifactDestination create(\n+        String typeUrn, ByteString typePayload, OutputStream out) {\n+      return new AutoValue_ArtifactStagingService_ArtifactDestination(typeUrn, typePayload, out);\n+    }\n+\n+    public static ArtifactDestination fromFile(String path) throws IOException {\n+      return fromFile(\n+          path,\n+          Channels.newOutputStream(\n+              FileSystems.create(\n+                  FileSystems.matchNewResource(path, false /* isDirectory */), MimeTypes.BINARY)));\n+    }\n+\n+    public static ArtifactDestination fromFile(String path, OutputStream out) {\n+      return create(\n+          ArtifactRetrievalService.FILE_ARTIFACT_URN,\n+          RunnerApi.ArtifactFilePayload.newBuilder().setPath(path).build().toByteString(),\n+          out);\n+    }\n+\n+    public abstract String getTypeUrn();\n+\n+    public abstract ByteString getTypePayload();\n+\n+    public abstract OutputStream getOutputStream();\n+  }\n+\n+  /**\n+   * An ArtifactDestinationProvider that places new artifacts as files in a Beam filesystem.\n+   *\n+   * @param root the directory in which to place all artifacts\n+   */\n+  public static ArtifactDestinationProvider beamFilesystemArtifactDestinationProvider(String root) {\n+    return (statingToken, name) -> {\n+      ResourceId path =\n+          FileSystems.matchNewResource(root, true)\n+              .resolve(statingToken, ResolveOptions.StandardResolveOptions.RESOLVE_DIRECTORY)\n+              .resolve(name, ResolveOptions.StandardResolveOptions.RESOLVE_FILE);\n+      return ArtifactDestination.fromFile(path.toString());\n+    };\n+  }\n+\n+  private enum State {\n+    START,\n+    RESOLVE,\n+    GET,\n+    GETCHUNK,\n+    DONE,\n+    ERROR,\n+  }\n+\n+  /**\n+   * Like the standard Semaphore, but allows an aquire to go over the limit if there is any room.\n+   *\n+   * <p>Also allows setting an error, to avoid issues with un-released aquires after error.\n+   */\n+  private static class OverflowingSemaphore {\n+    private int totalPermits;\n+    private int usedPermits;\n+    private Exception exception;\n+\n+    public OverflowingSemaphore(int totalPermits) {\n+      this.totalPermits = totalPermits;\n+      this.usedPermits = 0;\n+    }\n+\n+    synchronized void aquire(int permits) throws Exception {\n+      while (usedPermits >= totalPermits) {\n+        if (exception != null) {\n+          throw exception;\n+        }\n+        this.wait();\n+      }\n+      usedPermits += permits;\n+    }\n+\n+    synchronized void release(int permits) {\n+      usedPermits -= permits;\n+      this.notifyAll();\n+    }\n+\n+    synchronized void setException(Exception exception) {\n+      this.exception = exception;\n+      this.notifyAll();\n+    }\n+  }\n+\n+  /** A task that pulls bytes off a queue and actually writes them to a staging location. */\n+  private class StoreArtifact implements Callable<RunnerApi.ArtifactInformation> {\n+\n+    private String stagingToken;\n+    private String name;\n+    private RunnerApi.ArtifactInformation originalArtifact;\n+    private BlockingQueue<ByteString> bytesQueue;\n+    private OverflowingSemaphore totalPendingBytes;\n+\n+    public StoreArtifact(\n+        String stagingToken,\n+        String name,\n+        RunnerApi.ArtifactInformation originalArtifact,\n+        BlockingQueue<ByteString> bytesQueue,\n+        OverflowingSemaphore totalPendingBytes) {\n+      this.stagingToken = stagingToken;\n+      this.name = name;\n+      this.originalArtifact = originalArtifact;\n+      this.bytesQueue = bytesQueue;\n+      this.totalPendingBytes = totalPendingBytes;\n+    }\n+\n+    @Override\n+    public RunnerApi.ArtifactInformation call() throws IOException {\n+      try {\n+        ArtifactDestination dest = destinationProvider.getDestination(stagingToken, name);\n+        LOG.debug(\"Storing artifact for {}.{} at {}\", stagingToken, name, dest);\n+        ByteString chunk = bytesQueue.take();\n+        while (chunk.size() > 0) {\n+          totalPendingBytes.release(chunk.size());\n+          dest.getOutputStream().write(chunk.toByteArray());\n+          chunk = bytesQueue.take();\n+        }\n+        dest.getOutputStream().close();\n+        return originalArtifact\n+            .toBuilder()\n+            .setTypeUrn(dest.getTypeUrn())\n+            .setTypePayload(dest.getTypePayload())\n+            .build();\n+      } catch (IOException | InterruptedException exn) {\n+        // As this thread will no longer be draining the queue, we don't want to get stuck writing\n+        // to it.\n+        totalPendingBytes.setException(exn);\n+        LOG.error(\"Exception staging artifacts\", exn);\n+        if (exn instanceof IOException) {\n+          throw (IOException) exn;\n+        } else {\n+          throw new RuntimeException(exn);\n+        }\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public StreamObserver<ArtifactApi.ArtifactResponseWrapper> reverseArtifactRetrievalService(\n+      StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+\n+    return new StreamObserver<ArtifactApi.ArtifactResponseWrapper>() {\n+\n+      /** The maximum number of parallel threads to use to stage. */\n+      public static final int THREAD_POOL_SIZE = 10;\n+\n+      /** The maximum number of bytes to buffer across all writes before throttling. */\n+      public static final int MAX_PENDING_BYTES = 100 << 20; // 100 MB\n+\n+      String stagingToken;\n+      Map<String, List<RunnerApi.ArtifactInformation>> toResolve;\n+      Map<String, List<Future<RunnerApi.ArtifactInformation>>> stagedFutures;\n+      ExecutorService stagingExecutor;\n+      OverflowingSemaphore totalPendingBytes;\n+\n+      State state = State.START;\n+      Queue<String> pendingResolves;\n+      String currentEnvironment;\n+      int nameIndex;\n+      Queue<RunnerApi.ArtifactInformation> pendingGets;\n+      BlockingQueue<ByteString> currentOutput;\n+\n+      @Override\n+      @SuppressFBWarnings(value = \"SF_SWITCH_FALLTHROUGH\", justification = \"fallthrough intended\")\n+      public synchronized void onNext(ArtifactApi.ArtifactResponseWrapper responseWrapper) {\n+        switch (state) {\n+          case START:\n+            stagingToken = responseWrapper.getStagingToken();\n+            LOG.info(\"Staging artifacts for {}.\", stagingToken);\n+            toResolve = toStage.get(stagingToken);\n+            stagedFutures = new ConcurrentHashMap<>();\n+            pendingResolves = new ArrayDeque<>();\n+            pendingResolves.addAll(toResolve.keySet());\n+            stagingExecutor = Executors.newFixedThreadPool(THREAD_POOL_SIZE);\n+            totalPendingBytes = new OverflowingSemaphore(MAX_PENDING_BYTES);\n+            resolveNextEnvironment(responseObserver);\n+            break;\n+\n+          case RESOLVE:\n+            {\n+              currentEnvironment = pendingResolves.remove();\n+              stagedFutures.put(currentEnvironment, new ArrayList<>());\n+              pendingGets = new ArrayDeque<>();\n+              for (RunnerApi.ArtifactInformation artifact :\n+                  responseWrapper.getResolveArtifactResponse().getReplacementsList()) {\n+                Optional<RunnerApi.ArtifactInformation> fetched = getLocal(artifact);\n+                if (fetched.isPresent()) {\n+                  stagedFutures\n+                      .get(currentEnvironment)\n+                      .add(new FutureTask<RunnerApi.ArtifactInformation>(() -> fetched.get()));\n+                } else {\n+                  pendingGets.add(artifact);\n+                  responseObserver.onNext(\n+                      ArtifactApi.ArtifactRequestWrapper.newBuilder()\n+                          .setGetArtifact(\n+                              ArtifactApi.GetArtifactRequest.newBuilder().setArtifact(artifact))\n+                          .build());\n+                }\n+              }\n+              LOG.info(\n+                  \"Getting {} artifacts for {}.{}.\",\n+                  pendingGets.size(),\n+                  stagingToken,\n+                  pendingResolves.peek());\n+              if (pendingGets.isEmpty()) {\n+                resolveNextEnvironment(responseObserver);\n+              } else {\n+                state = State.GET;\n+              }\n+              break;\n+            }\n+\n+          case GET:\n+            RunnerApi.ArtifactInformation currentArtifact = pendingGets.remove();\n+            String name = createFilename(nameIndex++, currentEnvironment, currentArtifact);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDUwNjA3OQ=="}, "originalCommit": {"oid": "9c8718e46a3692034de9c9a9ed0754bab325cec5"}, "originalPosition": 331}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDY1NjY5Mg==", "bodyText": "That's actually how I had it originally, and one of the bug finders complained. (I was also concerned about the empty, or any, byte string getting interned.) I verify that chunk.size() > 0 above to avoid \"accidentally\" sending the EOF value. (I also considered writing my own queue implementation that had an explicit stop method, but this seemed overkill.)", "url": "https://github.com/apache/beam/pull/11342#discussion_r410656692", "createdAt": "2020-04-18T06:30:33Z", "author": {"login": "robertwb"}, "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/artifact/ArtifactStagingService.java", "diffHunk": "@@ -0,0 +1,606 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.fnexecution.artifact;\n+\n+import com.google.auto.value.AutoValue;\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.channels.Channels;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.FutureTask;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactApi;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactStagingServiceGrpc;\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+import org.apache.beam.runners.fnexecution.FnService;\n+import org.apache.beam.sdk.io.FileSystems;\n+import org.apache.beam.sdk.io.fs.ResolveOptions;\n+import org.apache.beam.sdk.io.fs.ResourceId;\n+import org.apache.beam.sdk.util.MimeTypes;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.ByteString;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.InvalidProtocolBufferException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.Status;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.StatusException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.stub.StreamObserver;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Splitter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class ArtifactStagingService\n+    extends ArtifactStagingServiceGrpc.ArtifactStagingServiceImplBase implements FnService {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(ArtifactStagingService.class);\n+\n+  private final ArtifactDestinationProvider destinationProvider;\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> toStage =\n+      new ConcurrentHashMap<>();\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> staged =\n+      new ConcurrentHashMap<>();\n+\n+  public ArtifactStagingService(ArtifactDestinationProvider destinationProvider) {\n+    this.destinationProvider = destinationProvider;\n+  }\n+\n+  /**\n+   * Registers a set of artifacts to be staged with this service.\n+   *\n+   * <p>A client (e.g. a Beam SDK) is expected to connect to this service with the given staging\n+   * token and offer resolution and retrieval of this set of artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   * @param artifacts all artifacts to stage, keyed by environment\n+   */\n+  public void registerJob(\n+      String stagingToken, Map<String, List<RunnerApi.ArtifactInformation>> artifacts) {\n+    assert !toStage.containsKey(stagingToken);\n+    toStage.put(stagingToken, artifacts);\n+  }\n+\n+  /**\n+   * Returns the rewritten artifacts associated with this job, keyed by environment.\n+   *\n+   * <p>This should be called after the client has finished offering artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   */\n+  public Map<String, List<RunnerApi.ArtifactInformation>> getStagedArtifacts(String stagingToken) {\n+    toStage.remove(stagingToken);\n+    return staged.remove(stagingToken);\n+  }\n+\n+  /** Provides a concrete location to which artifacts can be staged on retrieval. */\n+  public interface ArtifactDestinationProvider {\n+    ArtifactDestination getDestination(String stagingToken, String name) throws IOException;\n+  }\n+\n+  /**\n+   * A pairing of a newly created artifact type and an ouptut stream that will be readable at that\n+   * type.\n+   */\n+  @AutoValue\n+  public abstract static class ArtifactDestination {\n+    public static ArtifactDestination create(\n+        String typeUrn, ByteString typePayload, OutputStream out) {\n+      return new AutoValue_ArtifactStagingService_ArtifactDestination(typeUrn, typePayload, out);\n+    }\n+\n+    public static ArtifactDestination fromFile(String path) throws IOException {\n+      return fromFile(\n+          path,\n+          Channels.newOutputStream(\n+              FileSystems.create(\n+                  FileSystems.matchNewResource(path, false /* isDirectory */), MimeTypes.BINARY)));\n+    }\n+\n+    public static ArtifactDestination fromFile(String path, OutputStream out) {\n+      return create(\n+          ArtifactRetrievalService.FILE_ARTIFACT_URN,\n+          RunnerApi.ArtifactFilePayload.newBuilder().setPath(path).build().toByteString(),\n+          out);\n+    }\n+\n+    public abstract String getTypeUrn();\n+\n+    public abstract ByteString getTypePayload();\n+\n+    public abstract OutputStream getOutputStream();\n+  }\n+\n+  /**\n+   * An ArtifactDestinationProvider that places new artifacts as files in a Beam filesystem.\n+   *\n+   * @param root the directory in which to place all artifacts\n+   */\n+  public static ArtifactDestinationProvider beamFilesystemArtifactDestinationProvider(String root) {\n+    return (statingToken, name) -> {\n+      ResourceId path =\n+          FileSystems.matchNewResource(root, true)\n+              .resolve(statingToken, ResolveOptions.StandardResolveOptions.RESOLVE_DIRECTORY)\n+              .resolve(name, ResolveOptions.StandardResolveOptions.RESOLVE_FILE);\n+      return ArtifactDestination.fromFile(path.toString());\n+    };\n+  }\n+\n+  private enum State {\n+    START,\n+    RESOLVE,\n+    GET,\n+    GETCHUNK,\n+    DONE,\n+    ERROR,\n+  }\n+\n+  /**\n+   * Like the standard Semaphore, but allows an aquire to go over the limit if there is any room.\n+   *\n+   * <p>Also allows setting an error, to avoid issues with un-released aquires after error.\n+   */\n+  private static class OverflowingSemaphore {\n+    private int totalPermits;\n+    private int usedPermits;\n+    private Exception exception;\n+\n+    public OverflowingSemaphore(int totalPermits) {\n+      this.totalPermits = totalPermits;\n+      this.usedPermits = 0;\n+    }\n+\n+    synchronized void aquire(int permits) throws Exception {\n+      while (usedPermits >= totalPermits) {\n+        if (exception != null) {\n+          throw exception;\n+        }\n+        this.wait();\n+      }\n+      usedPermits += permits;\n+    }\n+\n+    synchronized void release(int permits) {\n+      usedPermits -= permits;\n+      this.notifyAll();\n+    }\n+\n+    synchronized void setException(Exception exception) {\n+      this.exception = exception;\n+      this.notifyAll();\n+    }\n+  }\n+\n+  /** A task that pulls bytes off a queue and actually writes them to a staging location. */\n+  private class StoreArtifact implements Callable<RunnerApi.ArtifactInformation> {\n+\n+    private String stagingToken;\n+    private String name;\n+    private RunnerApi.ArtifactInformation originalArtifact;\n+    private BlockingQueue<ByteString> bytesQueue;\n+    private OverflowingSemaphore totalPendingBytes;\n+\n+    public StoreArtifact(\n+        String stagingToken,\n+        String name,\n+        RunnerApi.ArtifactInformation originalArtifact,\n+        BlockingQueue<ByteString> bytesQueue,\n+        OverflowingSemaphore totalPendingBytes) {\n+      this.stagingToken = stagingToken;\n+      this.name = name;\n+      this.originalArtifact = originalArtifact;\n+      this.bytesQueue = bytesQueue;\n+      this.totalPendingBytes = totalPendingBytes;\n+    }\n+\n+    @Override\n+    public RunnerApi.ArtifactInformation call() throws IOException {\n+      try {\n+        ArtifactDestination dest = destinationProvider.getDestination(stagingToken, name);\n+        LOG.debug(\"Storing artifact for {}.{} at {}\", stagingToken, name, dest);\n+        ByteString chunk = bytesQueue.take();\n+        while (chunk.size() > 0) {\n+          totalPendingBytes.release(chunk.size());\n+          dest.getOutputStream().write(chunk.toByteArray());\n+          chunk = bytesQueue.take();\n+        }\n+        dest.getOutputStream().close();\n+        return originalArtifact\n+            .toBuilder()\n+            .setTypeUrn(dest.getTypeUrn())\n+            .setTypePayload(dest.getTypePayload())\n+            .build();\n+      } catch (IOException | InterruptedException exn) {\n+        // As this thread will no longer be draining the queue, we don't want to get stuck writing\n+        // to it.\n+        totalPendingBytes.setException(exn);\n+        LOG.error(\"Exception staging artifacts\", exn);\n+        if (exn instanceof IOException) {\n+          throw (IOException) exn;\n+        } else {\n+          throw new RuntimeException(exn);\n+        }\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public StreamObserver<ArtifactApi.ArtifactResponseWrapper> reverseArtifactRetrievalService(\n+      StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+\n+    return new StreamObserver<ArtifactApi.ArtifactResponseWrapper>() {\n+\n+      /** The maximum number of parallel threads to use to stage. */\n+      public static final int THREAD_POOL_SIZE = 10;\n+\n+      /** The maximum number of bytes to buffer across all writes before throttling. */\n+      public static final int MAX_PENDING_BYTES = 100 << 20; // 100 MB\n+\n+      String stagingToken;\n+      Map<String, List<RunnerApi.ArtifactInformation>> toResolve;\n+      Map<String, List<Future<RunnerApi.ArtifactInformation>>> stagedFutures;\n+      ExecutorService stagingExecutor;\n+      OverflowingSemaphore totalPendingBytes;\n+\n+      State state = State.START;\n+      Queue<String> pendingResolves;\n+      String currentEnvironment;\n+      int nameIndex;\n+      Queue<RunnerApi.ArtifactInformation> pendingGets;\n+      BlockingQueue<ByteString> currentOutput;\n+\n+      @Override\n+      @SuppressFBWarnings(value = \"SF_SWITCH_FALLTHROUGH\", justification = \"fallthrough intended\")\n+      public synchronized void onNext(ArtifactApi.ArtifactResponseWrapper responseWrapper) {\n+        switch (state) {\n+          case START:\n+            stagingToken = responseWrapper.getStagingToken();\n+            LOG.info(\"Staging artifacts for {}.\", stagingToken);\n+            toResolve = toStage.get(stagingToken);\n+            stagedFutures = new ConcurrentHashMap<>();\n+            pendingResolves = new ArrayDeque<>();\n+            pendingResolves.addAll(toResolve.keySet());\n+            stagingExecutor = Executors.newFixedThreadPool(THREAD_POOL_SIZE);\n+            totalPendingBytes = new OverflowingSemaphore(MAX_PENDING_BYTES);\n+            resolveNextEnvironment(responseObserver);\n+            break;\n+\n+          case RESOLVE:\n+            {\n+              currentEnvironment = pendingResolves.remove();\n+              stagedFutures.put(currentEnvironment, new ArrayList<>());\n+              pendingGets = new ArrayDeque<>();\n+              for (RunnerApi.ArtifactInformation artifact :\n+                  responseWrapper.getResolveArtifactResponse().getReplacementsList()) {\n+                Optional<RunnerApi.ArtifactInformation> fetched = getLocal(artifact);\n+                if (fetched.isPresent()) {\n+                  stagedFutures\n+                      .get(currentEnvironment)\n+                      .add(new FutureTask<RunnerApi.ArtifactInformation>(() -> fetched.get()));\n+                } else {\n+                  pendingGets.add(artifact);\n+                  responseObserver.onNext(\n+                      ArtifactApi.ArtifactRequestWrapper.newBuilder()\n+                          .setGetArtifact(\n+                              ArtifactApi.GetArtifactRequest.newBuilder().setArtifact(artifact))\n+                          .build());\n+                }\n+              }\n+              LOG.info(\n+                  \"Getting {} artifacts for {}.{}.\",\n+                  pendingGets.size(),\n+                  stagingToken,\n+                  pendingResolves.peek());\n+              if (pendingGets.isEmpty()) {\n+                resolveNextEnvironment(responseObserver);\n+              } else {\n+                state = State.GET;\n+              }\n+              break;\n+            }\n+\n+          case GET:\n+            RunnerApi.ArtifactInformation currentArtifact = pendingGets.remove();\n+            String name = createFilename(nameIndex++, currentEnvironment, currentArtifact);\n+            try {\n+              LOG.debug(\"Storing artifacts for {} as {}\", stagingToken, name);\n+              currentOutput = new ArrayBlockingQueue<ByteString>(100);\n+              stagedFutures\n+                  .get(currentEnvironment)\n+                  .add(\n+                      stagingExecutor.submit(\n+                          new StoreArtifact(\n+                              stagingToken,\n+                              name,\n+                              currentArtifact,\n+                              currentOutput,\n+                              totalPendingBytes)));\n+            } catch (Exception exn) {\n+              LOG.error(\"Error submitting.\", exn);\n+              responseObserver.onError(exn);\n+            }\n+            state = State.GETCHUNK;\n+            // fall through\n+\n+          case GETCHUNK:\n+            try {\n+              ByteString chunk = responseWrapper.getGetArtifactResponse().getData();\n+              if (chunk.size() > 0) {\n+                totalPendingBytes.aquire(chunk.size());\n+                currentOutput.put(chunk);\n+              }\n+              if (responseWrapper.getIsLast()) {\n+                currentOutput.put(ByteString.EMPTY); // The EOF value.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDUwNTUyNg=="}, "originalCommit": {"oid": "9c8718e46a3692034de9c9a9ed0754bab325cec5"}, "originalPosition": 360}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDY1NzMwMA==", "bodyText": "This is not needed, just nice to have. Even for foreign languages, it'll likely grab the extension, if any. IMHO escaping the name probably wouldn't be that useful, nor would be grabbing the full path and then chopping things off in the middle of part of a directory, and it might expose more than a user wants (e.g. their username as part of their home directory path). File.separator only applies to the local filesystem of this process, which might not apply to the filesystem (local or not) of the caller.", "url": "https://github.com/apache/beam/pull/11342#discussion_r410657300", "createdAt": "2020-04-18T06:37:06Z", "author": {"login": "robertwb"}, "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/artifact/ArtifactStagingService.java", "diffHunk": "@@ -0,0 +1,606 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.fnexecution.artifact;\n+\n+import com.google.auto.value.AutoValue;\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.channels.Channels;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.FutureTask;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactApi;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactStagingServiceGrpc;\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+import org.apache.beam.runners.fnexecution.FnService;\n+import org.apache.beam.sdk.io.FileSystems;\n+import org.apache.beam.sdk.io.fs.ResolveOptions;\n+import org.apache.beam.sdk.io.fs.ResourceId;\n+import org.apache.beam.sdk.util.MimeTypes;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.ByteString;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.InvalidProtocolBufferException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.Status;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.StatusException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.stub.StreamObserver;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Splitter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class ArtifactStagingService\n+    extends ArtifactStagingServiceGrpc.ArtifactStagingServiceImplBase implements FnService {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(ArtifactStagingService.class);\n+\n+  private final ArtifactDestinationProvider destinationProvider;\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> toStage =\n+      new ConcurrentHashMap<>();\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> staged =\n+      new ConcurrentHashMap<>();\n+\n+  public ArtifactStagingService(ArtifactDestinationProvider destinationProvider) {\n+    this.destinationProvider = destinationProvider;\n+  }\n+\n+  /**\n+   * Registers a set of artifacts to be staged with this service.\n+   *\n+   * <p>A client (e.g. a Beam SDK) is expected to connect to this service with the given staging\n+   * token and offer resolution and retrieval of this set of artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   * @param artifacts all artifacts to stage, keyed by environment\n+   */\n+  public void registerJob(\n+      String stagingToken, Map<String, List<RunnerApi.ArtifactInformation>> artifacts) {\n+    assert !toStage.containsKey(stagingToken);\n+    toStage.put(stagingToken, artifacts);\n+  }\n+\n+  /**\n+   * Returns the rewritten artifacts associated with this job, keyed by environment.\n+   *\n+   * <p>This should be called after the client has finished offering artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   */\n+  public Map<String, List<RunnerApi.ArtifactInformation>> getStagedArtifacts(String stagingToken) {\n+    toStage.remove(stagingToken);\n+    return staged.remove(stagingToken);\n+  }\n+\n+  /** Provides a concrete location to which artifacts can be staged on retrieval. */\n+  public interface ArtifactDestinationProvider {\n+    ArtifactDestination getDestination(String stagingToken, String name) throws IOException;\n+  }\n+\n+  /**\n+   * A pairing of a newly created artifact type and an ouptut stream that will be readable at that\n+   * type.\n+   */\n+  @AutoValue\n+  public abstract static class ArtifactDestination {\n+    public static ArtifactDestination create(\n+        String typeUrn, ByteString typePayload, OutputStream out) {\n+      return new AutoValue_ArtifactStagingService_ArtifactDestination(typeUrn, typePayload, out);\n+    }\n+\n+    public static ArtifactDestination fromFile(String path) throws IOException {\n+      return fromFile(\n+          path,\n+          Channels.newOutputStream(\n+              FileSystems.create(\n+                  FileSystems.matchNewResource(path, false /* isDirectory */), MimeTypes.BINARY)));\n+    }\n+\n+    public static ArtifactDestination fromFile(String path, OutputStream out) {\n+      return create(\n+          ArtifactRetrievalService.FILE_ARTIFACT_URN,\n+          RunnerApi.ArtifactFilePayload.newBuilder().setPath(path).build().toByteString(),\n+          out);\n+    }\n+\n+    public abstract String getTypeUrn();\n+\n+    public abstract ByteString getTypePayload();\n+\n+    public abstract OutputStream getOutputStream();\n+  }\n+\n+  /**\n+   * An ArtifactDestinationProvider that places new artifacts as files in a Beam filesystem.\n+   *\n+   * @param root the directory in which to place all artifacts\n+   */\n+  public static ArtifactDestinationProvider beamFilesystemArtifactDestinationProvider(String root) {\n+    return (statingToken, name) -> {\n+      ResourceId path =\n+          FileSystems.matchNewResource(root, true)\n+              .resolve(statingToken, ResolveOptions.StandardResolveOptions.RESOLVE_DIRECTORY)\n+              .resolve(name, ResolveOptions.StandardResolveOptions.RESOLVE_FILE);\n+      return ArtifactDestination.fromFile(path.toString());\n+    };\n+  }\n+\n+  private enum State {\n+    START,\n+    RESOLVE,\n+    GET,\n+    GETCHUNK,\n+    DONE,\n+    ERROR,\n+  }\n+\n+  /**\n+   * Like the standard Semaphore, but allows an aquire to go over the limit if there is any room.\n+   *\n+   * <p>Also allows setting an error, to avoid issues with un-released aquires after error.\n+   */\n+  private static class OverflowingSemaphore {\n+    private int totalPermits;\n+    private int usedPermits;\n+    private Exception exception;\n+\n+    public OverflowingSemaphore(int totalPermits) {\n+      this.totalPermits = totalPermits;\n+      this.usedPermits = 0;\n+    }\n+\n+    synchronized void aquire(int permits) throws Exception {\n+      while (usedPermits >= totalPermits) {\n+        if (exception != null) {\n+          throw exception;\n+        }\n+        this.wait();\n+      }\n+      usedPermits += permits;\n+    }\n+\n+    synchronized void release(int permits) {\n+      usedPermits -= permits;\n+      this.notifyAll();\n+    }\n+\n+    synchronized void setException(Exception exception) {\n+      this.exception = exception;\n+      this.notifyAll();\n+    }\n+  }\n+\n+  /** A task that pulls bytes off a queue and actually writes them to a staging location. */\n+  private class StoreArtifact implements Callable<RunnerApi.ArtifactInformation> {\n+\n+    private String stagingToken;\n+    private String name;\n+    private RunnerApi.ArtifactInformation originalArtifact;\n+    private BlockingQueue<ByteString> bytesQueue;\n+    private OverflowingSemaphore totalPendingBytes;\n+\n+    public StoreArtifact(\n+        String stagingToken,\n+        String name,\n+        RunnerApi.ArtifactInformation originalArtifact,\n+        BlockingQueue<ByteString> bytesQueue,\n+        OverflowingSemaphore totalPendingBytes) {\n+      this.stagingToken = stagingToken;\n+      this.name = name;\n+      this.originalArtifact = originalArtifact;\n+      this.bytesQueue = bytesQueue;\n+      this.totalPendingBytes = totalPendingBytes;\n+    }\n+\n+    @Override\n+    public RunnerApi.ArtifactInformation call() throws IOException {\n+      try {\n+        ArtifactDestination dest = destinationProvider.getDestination(stagingToken, name);\n+        LOG.debug(\"Storing artifact for {}.{} at {}\", stagingToken, name, dest);\n+        ByteString chunk = bytesQueue.take();\n+        while (chunk.size() > 0) {\n+          totalPendingBytes.release(chunk.size());\n+          dest.getOutputStream().write(chunk.toByteArray());\n+          chunk = bytesQueue.take();\n+        }\n+        dest.getOutputStream().close();\n+        return originalArtifact\n+            .toBuilder()\n+            .setTypeUrn(dest.getTypeUrn())\n+            .setTypePayload(dest.getTypePayload())\n+            .build();\n+      } catch (IOException | InterruptedException exn) {\n+        // As this thread will no longer be draining the queue, we don't want to get stuck writing\n+        // to it.\n+        totalPendingBytes.setException(exn);\n+        LOG.error(\"Exception staging artifacts\", exn);\n+        if (exn instanceof IOException) {\n+          throw (IOException) exn;\n+        } else {\n+          throw new RuntimeException(exn);\n+        }\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public StreamObserver<ArtifactApi.ArtifactResponseWrapper> reverseArtifactRetrievalService(\n+      StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+\n+    return new StreamObserver<ArtifactApi.ArtifactResponseWrapper>() {\n+\n+      /** The maximum number of parallel threads to use to stage. */\n+      public static final int THREAD_POOL_SIZE = 10;\n+\n+      /** The maximum number of bytes to buffer across all writes before throttling. */\n+      public static final int MAX_PENDING_BYTES = 100 << 20; // 100 MB\n+\n+      String stagingToken;\n+      Map<String, List<RunnerApi.ArtifactInformation>> toResolve;\n+      Map<String, List<Future<RunnerApi.ArtifactInformation>>> stagedFutures;\n+      ExecutorService stagingExecutor;\n+      OverflowingSemaphore totalPendingBytes;\n+\n+      State state = State.START;\n+      Queue<String> pendingResolves;\n+      String currentEnvironment;\n+      int nameIndex;\n+      Queue<RunnerApi.ArtifactInformation> pendingGets;\n+      BlockingQueue<ByteString> currentOutput;\n+\n+      @Override\n+      @SuppressFBWarnings(value = \"SF_SWITCH_FALLTHROUGH\", justification = \"fallthrough intended\")\n+      public synchronized void onNext(ArtifactApi.ArtifactResponseWrapper responseWrapper) {\n+        switch (state) {\n+          case START:\n+            stagingToken = responseWrapper.getStagingToken();\n+            LOG.info(\"Staging artifacts for {}.\", stagingToken);\n+            toResolve = toStage.get(stagingToken);\n+            stagedFutures = new ConcurrentHashMap<>();\n+            pendingResolves = new ArrayDeque<>();\n+            pendingResolves.addAll(toResolve.keySet());\n+            stagingExecutor = Executors.newFixedThreadPool(THREAD_POOL_SIZE);\n+            totalPendingBytes = new OverflowingSemaphore(MAX_PENDING_BYTES);\n+            resolveNextEnvironment(responseObserver);\n+            break;\n+\n+          case RESOLVE:\n+            {\n+              currentEnvironment = pendingResolves.remove();\n+              stagedFutures.put(currentEnvironment, new ArrayList<>());\n+              pendingGets = new ArrayDeque<>();\n+              for (RunnerApi.ArtifactInformation artifact :\n+                  responseWrapper.getResolveArtifactResponse().getReplacementsList()) {\n+                Optional<RunnerApi.ArtifactInformation> fetched = getLocal(artifact);\n+                if (fetched.isPresent()) {\n+                  stagedFutures\n+                      .get(currentEnvironment)\n+                      .add(new FutureTask<RunnerApi.ArtifactInformation>(() -> fetched.get()));\n+                } else {\n+                  pendingGets.add(artifact);\n+                  responseObserver.onNext(\n+                      ArtifactApi.ArtifactRequestWrapper.newBuilder()\n+                          .setGetArtifact(\n+                              ArtifactApi.GetArtifactRequest.newBuilder().setArtifact(artifact))\n+                          .build());\n+                }\n+              }\n+              LOG.info(\n+                  \"Getting {} artifacts for {}.{}.\",\n+                  pendingGets.size(),\n+                  stagingToken,\n+                  pendingResolves.peek());\n+              if (pendingGets.isEmpty()) {\n+                resolveNextEnvironment(responseObserver);\n+              } else {\n+                state = State.GET;\n+              }\n+              break;\n+            }\n+\n+          case GET:\n+            RunnerApi.ArtifactInformation currentArtifact = pendingGets.remove();\n+            String name = createFilename(nameIndex++, currentEnvironment, currentArtifact);\n+            try {\n+              LOG.debug(\"Storing artifacts for {} as {}\", stagingToken, name);\n+              currentOutput = new ArrayBlockingQueue<ByteString>(100);\n+              stagedFutures\n+                  .get(currentEnvironment)\n+                  .add(\n+                      stagingExecutor.submit(\n+                          new StoreArtifact(\n+                              stagingToken,\n+                              name,\n+                              currentArtifact,\n+                              currentOutput,\n+                              totalPendingBytes)));\n+            } catch (Exception exn) {\n+              LOG.error(\"Error submitting.\", exn);\n+              responseObserver.onError(exn);\n+            }\n+            state = State.GETCHUNK;\n+            // fall through\n+\n+          case GETCHUNK:\n+            try {\n+              ByteString chunk = responseWrapper.getGetArtifactResponse().getData();\n+              if (chunk.size() > 0) {\n+                totalPendingBytes.aquire(chunk.size());\n+                currentOutput.put(chunk);\n+              }\n+              if (responseWrapper.getIsLast()) {\n+                currentOutput.put(ByteString.EMPTY); // The EOF value.\n+                if (pendingGets.isEmpty()) {\n+                  resolveNextEnvironment(responseObserver);\n+                } else {\n+                  state = State.GET;\n+                  LOG.debug(\"Waiting for {}\", pendingGets.peek());\n+                }\n+              }\n+            } catch (Exception exn) {\n+              LOG.error(\"Error submitting.\", exn);\n+              onError(exn);\n+            }\n+            break;\n+\n+          default:\n+            responseObserver.onError(\n+                new StatusException(\n+                    Status.INVALID_ARGUMENT.withDescription(\"Illegal state \" + state)));\n+        }\n+      }\n+\n+      private void resolveNextEnvironment(\n+          StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+        if (pendingResolves.isEmpty()) {\n+          finishStaging(responseObserver);\n+        } else {\n+          state = State.RESOLVE;\n+          LOG.info(\"Resolving artifacts for {}.{}.\", stagingToken, pendingResolves.peek());\n+          responseObserver.onNext(\n+              ArtifactApi.ArtifactRequestWrapper.newBuilder()\n+                  .setResolveArtifact(\n+                      ArtifactApi.ResolveArtifactsRequest.newBuilder()\n+                          .addAllArtifacts(toResolve.get(pendingResolves.peek())))\n+                  .build());\n+        }\n+      }\n+\n+      private void finishStaging(\n+          StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+        LOG.debug(\"Finishing staging for {}.\", stagingToken);\n+        Map<String, List<RunnerApi.ArtifactInformation>> staged = new HashMap<>();\n+        try {\n+          for (Map.Entry<String, List<Future<RunnerApi.ArtifactInformation>>> entry :\n+              stagedFutures.entrySet()) {\n+            List<RunnerApi.ArtifactInformation> envStaged = new ArrayList<>();\n+            for (Future<RunnerApi.ArtifactInformation> future : entry.getValue()) {\n+              envStaged.add(future.get());\n+            }\n+            staged.put(entry.getKey(), envStaged);\n+          }\n+          ArtifactStagingService.this.staged.put(stagingToken, staged);\n+          stagingExecutor.shutdown();\n+          state = State.DONE;\n+          LOG.info(\"Artifacts fully staged for {}.\", stagingToken);\n+          responseObserver.onCompleted();\n+        } catch (Exception exn) {\n+          LOG.error(\"Error staging artifacts\", exn);\n+          responseObserver.onError(exn);\n+          state = State.ERROR;\n+          return;\n+        }\n+      }\n+\n+      /**\n+       * Return an alternative artifact if we do not need to get this over the artifact API, or\n+       * possibly at all.\n+       */\n+      private Optional<RunnerApi.ArtifactInformation> getLocal(\n+          RunnerApi.ArtifactInformation artifact) {\n+        return Optional.empty();\n+      }\n+\n+      /**\n+       * Attempts to provide a reasonable filename for the artifact.\n+       *\n+       * @param index a monotonically increasing index, which provides uniqueness\n+       * @param environment the environment id\n+       * @param artifact the artifact itself\n+       */\n+      private String createFilename(\n+          int index, String environment, RunnerApi.ArtifactInformation artifact) {\n+        String path;\n+        try {\n+          if (artifact.getRoleUrn().equals(ArtifactRetrievalService.STAGING_TO_ARTIFACT_URN)) {\n+            path =\n+                RunnerApi.ArtifactStagingToRolePayload.parseFrom(artifact.getRolePayload())\n+                    .getStagedName();\n+          } else if (artifact.getTypeUrn().equals(ArtifactRetrievalService.FILE_ARTIFACT_URN)) {\n+            path = RunnerApi.ArtifactFilePayload.parseFrom(artifact.getTypePayload()).getPath();\n+          } else if (artifact.getTypeUrn().equals(ArtifactRetrievalService.URL_ARTIFACT_URN)) {\n+            path = RunnerApi.ArtifactUrlPayload.parseFrom(artifact.getTypePayload()).getUrl();\n+          } else {\n+            path = \"artifact\";\n+          }\n+        } catch (InvalidProtocolBufferException exn) {\n+          throw new RuntimeException(exn);\n+        }\n+        // Limit to the last contiguous alpha-numeric sequence. In particular, this will exclude\n+        // all path separators.\n+        List<String> components = Splitter.onPattern(\"[^A-Za-z-_.]]\").splitToList(path);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDUwNzkzOA=="}, "originalCommit": {"oid": "9c8718e46a3692034de9c9a9ed0754bab325cec5"}, "originalPosition": 459}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDY1Nzg3MA==", "bodyText": "Good point. Done.", "url": "https://github.com/apache/beam/pull/11342#discussion_r410657870", "createdAt": "2020-04-18T06:42:17Z", "author": {"login": "robertwb"}, "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/artifact/ArtifactStagingService.java", "diffHunk": "@@ -0,0 +1,606 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.fnexecution.artifact;\n+\n+import com.google.auto.value.AutoValue;\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.channels.Channels;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.FutureTask;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactApi;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactStagingServiceGrpc;\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+import org.apache.beam.runners.fnexecution.FnService;\n+import org.apache.beam.sdk.io.FileSystems;\n+import org.apache.beam.sdk.io.fs.ResolveOptions;\n+import org.apache.beam.sdk.io.fs.ResourceId;\n+import org.apache.beam.sdk.util.MimeTypes;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.ByteString;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.InvalidProtocolBufferException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.Status;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.StatusException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.stub.StreamObserver;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Splitter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class ArtifactStagingService\n+    extends ArtifactStagingServiceGrpc.ArtifactStagingServiceImplBase implements FnService {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(ArtifactStagingService.class);\n+\n+  private final ArtifactDestinationProvider destinationProvider;\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> toStage =\n+      new ConcurrentHashMap<>();\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> staged =\n+      new ConcurrentHashMap<>();\n+\n+  public ArtifactStagingService(ArtifactDestinationProvider destinationProvider) {\n+    this.destinationProvider = destinationProvider;\n+  }\n+\n+  /**\n+   * Registers a set of artifacts to be staged with this service.\n+   *\n+   * <p>A client (e.g. a Beam SDK) is expected to connect to this service with the given staging\n+   * token and offer resolution and retrieval of this set of artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   * @param artifacts all artifacts to stage, keyed by environment\n+   */\n+  public void registerJob(\n+      String stagingToken, Map<String, List<RunnerApi.ArtifactInformation>> artifacts) {\n+    assert !toStage.containsKey(stagingToken);\n+    toStage.put(stagingToken, artifacts);\n+  }\n+\n+  /**\n+   * Returns the rewritten artifacts associated with this job, keyed by environment.\n+   *\n+   * <p>This should be called after the client has finished offering artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   */\n+  public Map<String, List<RunnerApi.ArtifactInformation>> getStagedArtifacts(String stagingToken) {\n+    toStage.remove(stagingToken);\n+    return staged.remove(stagingToken);\n+  }\n+\n+  /** Provides a concrete location to which artifacts can be staged on retrieval. */\n+  public interface ArtifactDestinationProvider {\n+    ArtifactDestination getDestination(String stagingToken, String name) throws IOException;\n+  }\n+\n+  /**\n+   * A pairing of a newly created artifact type and an ouptut stream that will be readable at that\n+   * type.\n+   */\n+  @AutoValue\n+  public abstract static class ArtifactDestination {\n+    public static ArtifactDestination create(\n+        String typeUrn, ByteString typePayload, OutputStream out) {\n+      return new AutoValue_ArtifactStagingService_ArtifactDestination(typeUrn, typePayload, out);\n+    }\n+\n+    public static ArtifactDestination fromFile(String path) throws IOException {\n+      return fromFile(\n+          path,\n+          Channels.newOutputStream(\n+              FileSystems.create(\n+                  FileSystems.matchNewResource(path, false /* isDirectory */), MimeTypes.BINARY)));\n+    }\n+\n+    public static ArtifactDestination fromFile(String path, OutputStream out) {\n+      return create(\n+          ArtifactRetrievalService.FILE_ARTIFACT_URN,\n+          RunnerApi.ArtifactFilePayload.newBuilder().setPath(path).build().toByteString(),\n+          out);\n+    }\n+\n+    public abstract String getTypeUrn();\n+\n+    public abstract ByteString getTypePayload();\n+\n+    public abstract OutputStream getOutputStream();\n+  }\n+\n+  /**\n+   * An ArtifactDestinationProvider that places new artifacts as files in a Beam filesystem.\n+   *\n+   * @param root the directory in which to place all artifacts\n+   */\n+  public static ArtifactDestinationProvider beamFilesystemArtifactDestinationProvider(String root) {\n+    return (statingToken, name) -> {\n+      ResourceId path =\n+          FileSystems.matchNewResource(root, true)\n+              .resolve(statingToken, ResolveOptions.StandardResolveOptions.RESOLVE_DIRECTORY)\n+              .resolve(name, ResolveOptions.StandardResolveOptions.RESOLVE_FILE);\n+      return ArtifactDestination.fromFile(path.toString());\n+    };\n+  }\n+\n+  private enum State {\n+    START,\n+    RESOLVE,\n+    GET,\n+    GETCHUNK,\n+    DONE,\n+    ERROR,\n+  }\n+\n+  /**\n+   * Like the standard Semaphore, but allows an aquire to go over the limit if there is any room.\n+   *\n+   * <p>Also allows setting an error, to avoid issues with un-released aquires after error.\n+   */\n+  private static class OverflowingSemaphore {\n+    private int totalPermits;\n+    private int usedPermits;\n+    private Exception exception;\n+\n+    public OverflowingSemaphore(int totalPermits) {\n+      this.totalPermits = totalPermits;\n+      this.usedPermits = 0;\n+    }\n+\n+    synchronized void aquire(int permits) throws Exception {\n+      while (usedPermits >= totalPermits) {\n+        if (exception != null) {\n+          throw exception;\n+        }\n+        this.wait();\n+      }\n+      usedPermits += permits;\n+    }\n+\n+    synchronized void release(int permits) {\n+      usedPermits -= permits;\n+      this.notifyAll();\n+    }\n+\n+    synchronized void setException(Exception exception) {\n+      this.exception = exception;\n+      this.notifyAll();\n+    }\n+  }\n+\n+  /** A task that pulls bytes off a queue and actually writes them to a staging location. */\n+  private class StoreArtifact implements Callable<RunnerApi.ArtifactInformation> {\n+\n+    private String stagingToken;\n+    private String name;\n+    private RunnerApi.ArtifactInformation originalArtifact;\n+    private BlockingQueue<ByteString> bytesQueue;\n+    private OverflowingSemaphore totalPendingBytes;\n+\n+    public StoreArtifact(\n+        String stagingToken,\n+        String name,\n+        RunnerApi.ArtifactInformation originalArtifact,\n+        BlockingQueue<ByteString> bytesQueue,\n+        OverflowingSemaphore totalPendingBytes) {\n+      this.stagingToken = stagingToken;\n+      this.name = name;\n+      this.originalArtifact = originalArtifact;\n+      this.bytesQueue = bytesQueue;\n+      this.totalPendingBytes = totalPendingBytes;\n+    }\n+\n+    @Override\n+    public RunnerApi.ArtifactInformation call() throws IOException {\n+      try {\n+        ArtifactDestination dest = destinationProvider.getDestination(stagingToken, name);\n+        LOG.debug(\"Storing artifact for {}.{} at {}\", stagingToken, name, dest);\n+        ByteString chunk = bytesQueue.take();\n+        while (chunk.size() > 0) {\n+          totalPendingBytes.release(chunk.size());\n+          dest.getOutputStream().write(chunk.toByteArray());\n+          chunk = bytesQueue.take();\n+        }\n+        dest.getOutputStream().close();\n+        return originalArtifact\n+            .toBuilder()\n+            .setTypeUrn(dest.getTypeUrn())\n+            .setTypePayload(dest.getTypePayload())\n+            .build();\n+      } catch (IOException | InterruptedException exn) {\n+        // As this thread will no longer be draining the queue, we don't want to get stuck writing\n+        // to it.\n+        totalPendingBytes.setException(exn);\n+        LOG.error(\"Exception staging artifacts\", exn);\n+        if (exn instanceof IOException) {\n+          throw (IOException) exn;\n+        } else {\n+          throw new RuntimeException(exn);\n+        }\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public StreamObserver<ArtifactApi.ArtifactResponseWrapper> reverseArtifactRetrievalService(\n+      StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+\n+    return new StreamObserver<ArtifactApi.ArtifactResponseWrapper>() {\n+\n+      /** The maximum number of parallel threads to use to stage. */\n+      public static final int THREAD_POOL_SIZE = 10;\n+\n+      /** The maximum number of bytes to buffer across all writes before throttling. */\n+      public static final int MAX_PENDING_BYTES = 100 << 20; // 100 MB\n+\n+      String stagingToken;\n+      Map<String, List<RunnerApi.ArtifactInformation>> toResolve;\n+      Map<String, List<Future<RunnerApi.ArtifactInformation>>> stagedFutures;\n+      ExecutorService stagingExecutor;\n+      OverflowingSemaphore totalPendingBytes;\n+\n+      State state = State.START;\n+      Queue<String> pendingResolves;\n+      String currentEnvironment;\n+      int nameIndex;\n+      Queue<RunnerApi.ArtifactInformation> pendingGets;\n+      BlockingQueue<ByteString> currentOutput;\n+\n+      @Override\n+      @SuppressFBWarnings(value = \"SF_SWITCH_FALLTHROUGH\", justification = \"fallthrough intended\")\n+      public synchronized void onNext(ArtifactApi.ArtifactResponseWrapper responseWrapper) {\n+        switch (state) {\n+          case START:\n+            stagingToken = responseWrapper.getStagingToken();\n+            LOG.info(\"Staging artifacts for {}.\", stagingToken);\n+            toResolve = toStage.get(stagingToken);\n+            stagedFutures = new ConcurrentHashMap<>();\n+            pendingResolves = new ArrayDeque<>();\n+            pendingResolves.addAll(toResolve.keySet());\n+            stagingExecutor = Executors.newFixedThreadPool(THREAD_POOL_SIZE);\n+            totalPendingBytes = new OverflowingSemaphore(MAX_PENDING_BYTES);\n+            resolveNextEnvironment(responseObserver);\n+            break;\n+\n+          case RESOLVE:\n+            {\n+              currentEnvironment = pendingResolves.remove();\n+              stagedFutures.put(currentEnvironment, new ArrayList<>());\n+              pendingGets = new ArrayDeque<>();\n+              for (RunnerApi.ArtifactInformation artifact :\n+                  responseWrapper.getResolveArtifactResponse().getReplacementsList()) {\n+                Optional<RunnerApi.ArtifactInformation> fetched = getLocal(artifact);\n+                if (fetched.isPresent()) {\n+                  stagedFutures\n+                      .get(currentEnvironment)\n+                      .add(new FutureTask<RunnerApi.ArtifactInformation>(() -> fetched.get()));\n+                } else {\n+                  pendingGets.add(artifact);\n+                  responseObserver.onNext(\n+                      ArtifactApi.ArtifactRequestWrapper.newBuilder()\n+                          .setGetArtifact(\n+                              ArtifactApi.GetArtifactRequest.newBuilder().setArtifact(artifact))\n+                          .build());\n+                }\n+              }\n+              LOG.info(\n+                  \"Getting {} artifacts for {}.{}.\",\n+                  pendingGets.size(),\n+                  stagingToken,\n+                  pendingResolves.peek());\n+              if (pendingGets.isEmpty()) {\n+                resolveNextEnvironment(responseObserver);\n+              } else {\n+                state = State.GET;\n+              }\n+              break;\n+            }\n+\n+          case GET:\n+            RunnerApi.ArtifactInformation currentArtifact = pendingGets.remove();\n+            String name = createFilename(nameIndex++, currentEnvironment, currentArtifact);\n+            try {\n+              LOG.debug(\"Storing artifacts for {} as {}\", stagingToken, name);\n+              currentOutput = new ArrayBlockingQueue<ByteString>(100);\n+              stagedFutures\n+                  .get(currentEnvironment)\n+                  .add(\n+                      stagingExecutor.submit(\n+                          new StoreArtifact(\n+                              stagingToken,\n+                              name,\n+                              currentArtifact,\n+                              currentOutput,\n+                              totalPendingBytes)));\n+            } catch (Exception exn) {\n+              LOG.error(\"Error submitting.\", exn);\n+              responseObserver.onError(exn);\n+            }\n+            state = State.GETCHUNK;\n+            // fall through\n+\n+          case GETCHUNK:\n+            try {\n+              ByteString chunk = responseWrapper.getGetArtifactResponse().getData();\n+              if (chunk.size() > 0) {\n+                totalPendingBytes.aquire(chunk.size());\n+                currentOutput.put(chunk);\n+              }\n+              if (responseWrapper.getIsLast()) {\n+                currentOutput.put(ByteString.EMPTY); // The EOF value.\n+                if (pendingGets.isEmpty()) {\n+                  resolveNextEnvironment(responseObserver);\n+                } else {\n+                  state = State.GET;\n+                  LOG.debug(\"Waiting for {}\", pendingGets.peek());\n+                }\n+              }\n+            } catch (Exception exn) {\n+              LOG.error(\"Error submitting.\", exn);\n+              onError(exn);\n+            }\n+            break;\n+\n+          default:\n+            responseObserver.onError(\n+                new StatusException(\n+                    Status.INVALID_ARGUMENT.withDescription(\"Illegal state \" + state)));\n+        }\n+      }\n+\n+      private void resolveNextEnvironment(\n+          StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+        if (pendingResolves.isEmpty()) {\n+          finishStaging(responseObserver);\n+        } else {\n+          state = State.RESOLVE;\n+          LOG.info(\"Resolving artifacts for {}.{}.\", stagingToken, pendingResolves.peek());\n+          responseObserver.onNext(\n+              ArtifactApi.ArtifactRequestWrapper.newBuilder()\n+                  .setResolveArtifact(\n+                      ArtifactApi.ResolveArtifactsRequest.newBuilder()\n+                          .addAllArtifacts(toResolve.get(pendingResolves.peek())))\n+                  .build());\n+        }\n+      }\n+\n+      private void finishStaging(\n+          StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+        LOG.debug(\"Finishing staging for {}.\", stagingToken);\n+        Map<String, List<RunnerApi.ArtifactInformation>> staged = new HashMap<>();\n+        try {\n+          for (Map.Entry<String, List<Future<RunnerApi.ArtifactInformation>>> entry :\n+              stagedFutures.entrySet()) {\n+            List<RunnerApi.ArtifactInformation> envStaged = new ArrayList<>();\n+            for (Future<RunnerApi.ArtifactInformation> future : entry.getValue()) {\n+              envStaged.add(future.get());\n+            }\n+            staged.put(entry.getKey(), envStaged);\n+          }\n+          ArtifactStagingService.this.staged.put(stagingToken, staged);\n+          stagingExecutor.shutdown();\n+          state = State.DONE;\n+          LOG.info(\"Artifacts fully staged for {}.\", stagingToken);\n+          responseObserver.onCompleted();\n+        } catch (Exception exn) {\n+          LOG.error(\"Error staging artifacts\", exn);\n+          responseObserver.onError(exn);\n+          state = State.ERROR;\n+          return;\n+        }\n+      }\n+\n+      /**\n+       * Return an alternative artifact if we do not need to get this over the artifact API, or\n+       * possibly at all.\n+       */\n+      private Optional<RunnerApi.ArtifactInformation> getLocal(\n+          RunnerApi.ArtifactInformation artifact) {\n+        return Optional.empty();\n+      }\n+\n+      /**\n+       * Attempts to provide a reasonable filename for the artifact.\n+       *\n+       * @param index a monotonically increasing index, which provides uniqueness\n+       * @param environment the environment id\n+       * @param artifact the artifact itself\n+       */\n+      private String createFilename(\n+          int index, String environment, RunnerApi.ArtifactInformation artifact) {\n+        String path;\n+        try {\n+          if (artifact.getRoleUrn().equals(ArtifactRetrievalService.STAGING_TO_ARTIFACT_URN)) {\n+            path =\n+                RunnerApi.ArtifactStagingToRolePayload.parseFrom(artifact.getRolePayload())\n+                    .getStagedName();\n+          } else if (artifact.getTypeUrn().equals(ArtifactRetrievalService.FILE_ARTIFACT_URN)) {\n+            path = RunnerApi.ArtifactFilePayload.parseFrom(artifact.getTypePayload()).getPath();\n+          } else if (artifact.getTypeUrn().equals(ArtifactRetrievalService.URL_ARTIFACT_URN)) {\n+            path = RunnerApi.ArtifactUrlPayload.parseFrom(artifact.getTypePayload()).getUrl();\n+          } else {\n+            path = \"artifact\";\n+          }\n+        } catch (InvalidProtocolBufferException exn) {\n+          throw new RuntimeException(exn);\n+        }\n+        // Limit to the last contiguous alpha-numeric sequence. In particular, this will exclude\n+        // all path separators.\n+        List<String> components = Splitter.onPattern(\"[^A-Za-z-_.]]\").splitToList(path);\n+        String base = components.get(components.size() - 1);\n+        return clip(String.format(\"%d-%s-%s\", index, clip(environment, 25), base), 100);\n+      }\n+\n+      private String clip(String s, int maxLength) {\n+        return s.length() < maxLength ? s : s.substring(0, maxLength);\n+      }\n+\n+      @Override\n+      public void onError(Throwable throwable) {\n+        stagingExecutor.shutdownNow();\n+        LOG.error(\"Error staging artifacts\", throwable);\n+        state = State.ERROR;\n+      }\n+\n+      @Override\n+      public void onCompleted() {\n+        assert state == State.DONE;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDUwODcyOA=="}, "originalCommit": {"oid": "9c8718e46a3692034de9c9a9ed0754bab325cec5"}, "originalPosition": 477}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDY1ODUwNg==", "bodyText": "Ah, yes. Clever. (It feels a bit odd to actually be doing something in the constructor, but it is a private class.)", "url": "https://github.com/apache/beam/pull/11342#discussion_r410658506", "createdAt": "2020-04-18T06:48:42Z", "author": {"login": "robertwb"}, "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/artifact/ArtifactStagingService.java", "diffHunk": "@@ -0,0 +1,606 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.fnexecution.artifact;\n+\n+import com.google.auto.value.AutoValue;\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.channels.Channels;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.FutureTask;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactApi;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactStagingServiceGrpc;\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+import org.apache.beam.runners.fnexecution.FnService;\n+import org.apache.beam.sdk.io.FileSystems;\n+import org.apache.beam.sdk.io.fs.ResolveOptions;\n+import org.apache.beam.sdk.io.fs.ResourceId;\n+import org.apache.beam.sdk.util.MimeTypes;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.ByteString;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.InvalidProtocolBufferException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.Status;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.StatusException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.stub.StreamObserver;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Splitter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class ArtifactStagingService\n+    extends ArtifactStagingServiceGrpc.ArtifactStagingServiceImplBase implements FnService {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(ArtifactStagingService.class);\n+\n+  private final ArtifactDestinationProvider destinationProvider;\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> toStage =\n+      new ConcurrentHashMap<>();\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> staged =\n+      new ConcurrentHashMap<>();\n+\n+  public ArtifactStagingService(ArtifactDestinationProvider destinationProvider) {\n+    this.destinationProvider = destinationProvider;\n+  }\n+\n+  /**\n+   * Registers a set of artifacts to be staged with this service.\n+   *\n+   * <p>A client (e.g. a Beam SDK) is expected to connect to this service with the given staging\n+   * token and offer resolution and retrieval of this set of artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   * @param artifacts all artifacts to stage, keyed by environment\n+   */\n+  public void registerJob(\n+      String stagingToken, Map<String, List<RunnerApi.ArtifactInformation>> artifacts) {\n+    assert !toStage.containsKey(stagingToken);\n+    toStage.put(stagingToken, artifacts);\n+  }\n+\n+  /**\n+   * Returns the rewritten artifacts associated with this job, keyed by environment.\n+   *\n+   * <p>This should be called after the client has finished offering artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   */\n+  public Map<String, List<RunnerApi.ArtifactInformation>> getStagedArtifacts(String stagingToken) {\n+    toStage.remove(stagingToken);\n+    return staged.remove(stagingToken);\n+  }\n+\n+  /** Provides a concrete location to which artifacts can be staged on retrieval. */\n+  public interface ArtifactDestinationProvider {\n+    ArtifactDestination getDestination(String stagingToken, String name) throws IOException;\n+  }\n+\n+  /**\n+   * A pairing of a newly created artifact type and an ouptut stream that will be readable at that\n+   * type.\n+   */\n+  @AutoValue\n+  public abstract static class ArtifactDestination {\n+    public static ArtifactDestination create(\n+        String typeUrn, ByteString typePayload, OutputStream out) {\n+      return new AutoValue_ArtifactStagingService_ArtifactDestination(typeUrn, typePayload, out);\n+    }\n+\n+    public static ArtifactDestination fromFile(String path) throws IOException {\n+      return fromFile(\n+          path,\n+          Channels.newOutputStream(\n+              FileSystems.create(\n+                  FileSystems.matchNewResource(path, false /* isDirectory */), MimeTypes.BINARY)));\n+    }\n+\n+    public static ArtifactDestination fromFile(String path, OutputStream out) {\n+      return create(\n+          ArtifactRetrievalService.FILE_ARTIFACT_URN,\n+          RunnerApi.ArtifactFilePayload.newBuilder().setPath(path).build().toByteString(),\n+          out);\n+    }\n+\n+    public abstract String getTypeUrn();\n+\n+    public abstract ByteString getTypePayload();\n+\n+    public abstract OutputStream getOutputStream();\n+  }\n+\n+  /**\n+   * An ArtifactDestinationProvider that places new artifacts as files in a Beam filesystem.\n+   *\n+   * @param root the directory in which to place all artifacts\n+   */\n+  public static ArtifactDestinationProvider beamFilesystemArtifactDestinationProvider(String root) {\n+    return (statingToken, name) -> {\n+      ResourceId path =\n+          FileSystems.matchNewResource(root, true)\n+              .resolve(statingToken, ResolveOptions.StandardResolveOptions.RESOLVE_DIRECTORY)\n+              .resolve(name, ResolveOptions.StandardResolveOptions.RESOLVE_FILE);\n+      return ArtifactDestination.fromFile(path.toString());\n+    };\n+  }\n+\n+  private enum State {\n+    START,\n+    RESOLVE,\n+    GET,\n+    GETCHUNK,\n+    DONE,\n+    ERROR,\n+  }\n+\n+  /**\n+   * Like the standard Semaphore, but allows an aquire to go over the limit if there is any room.\n+   *\n+   * <p>Also allows setting an error, to avoid issues with un-released aquires after error.\n+   */\n+  private static class OverflowingSemaphore {\n+    private int totalPermits;\n+    private int usedPermits;\n+    private Exception exception;\n+\n+    public OverflowingSemaphore(int totalPermits) {\n+      this.totalPermits = totalPermits;\n+      this.usedPermits = 0;\n+    }\n+\n+    synchronized void aquire(int permits) throws Exception {\n+      while (usedPermits >= totalPermits) {\n+        if (exception != null) {\n+          throw exception;\n+        }\n+        this.wait();\n+      }\n+      usedPermits += permits;\n+    }\n+\n+    synchronized void release(int permits) {\n+      usedPermits -= permits;\n+      this.notifyAll();\n+    }\n+\n+    synchronized void setException(Exception exception) {\n+      this.exception = exception;\n+      this.notifyAll();\n+    }\n+  }\n+\n+  /** A task that pulls bytes off a queue and actually writes them to a staging location. */\n+  private class StoreArtifact implements Callable<RunnerApi.ArtifactInformation> {\n+\n+    private String stagingToken;\n+    private String name;\n+    private RunnerApi.ArtifactInformation originalArtifact;\n+    private BlockingQueue<ByteString> bytesQueue;\n+    private OverflowingSemaphore totalPendingBytes;\n+\n+    public StoreArtifact(\n+        String stagingToken,\n+        String name,\n+        RunnerApi.ArtifactInformation originalArtifact,\n+        BlockingQueue<ByteString> bytesQueue,\n+        OverflowingSemaphore totalPendingBytes) {\n+      this.stagingToken = stagingToken;\n+      this.name = name;\n+      this.originalArtifact = originalArtifact;\n+      this.bytesQueue = bytesQueue;\n+      this.totalPendingBytes = totalPendingBytes;\n+    }\n+\n+    @Override\n+    public RunnerApi.ArtifactInformation call() throws IOException {\n+      try {\n+        ArtifactDestination dest = destinationProvider.getDestination(stagingToken, name);\n+        LOG.debug(\"Storing artifact for {}.{} at {}\", stagingToken, name, dest);\n+        ByteString chunk = bytesQueue.take();\n+        while (chunk.size() > 0) {\n+          totalPendingBytes.release(chunk.size());\n+          dest.getOutputStream().write(chunk.toByteArray());\n+          chunk = bytesQueue.take();\n+        }\n+        dest.getOutputStream().close();\n+        return originalArtifact\n+            .toBuilder()\n+            .setTypeUrn(dest.getTypeUrn())\n+            .setTypePayload(dest.getTypePayload())\n+            .build();\n+      } catch (IOException | InterruptedException exn) {\n+        // As this thread will no longer be draining the queue, we don't want to get stuck writing\n+        // to it.\n+        totalPendingBytes.setException(exn);\n+        LOG.error(\"Exception staging artifacts\", exn);\n+        if (exn instanceof IOException) {\n+          throw (IOException) exn;\n+        } else {\n+          throw new RuntimeException(exn);\n+        }\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public StreamObserver<ArtifactApi.ArtifactResponseWrapper> reverseArtifactRetrievalService(\n+      StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+\n+    return new StreamObserver<ArtifactApi.ArtifactResponseWrapper>() {\n+\n+      /** The maximum number of parallel threads to use to stage. */\n+      public static final int THREAD_POOL_SIZE = 10;\n+\n+      /** The maximum number of bytes to buffer across all writes before throttling. */\n+      public static final int MAX_PENDING_BYTES = 100 << 20; // 100 MB\n+\n+      String stagingToken;\n+      Map<String, List<RunnerApi.ArtifactInformation>> toResolve;\n+      Map<String, List<Future<RunnerApi.ArtifactInformation>>> stagedFutures;\n+      ExecutorService stagingExecutor;\n+      OverflowingSemaphore totalPendingBytes;\n+\n+      State state = State.START;\n+      Queue<String> pendingResolves;\n+      String currentEnvironment;\n+      int nameIndex;\n+      Queue<RunnerApi.ArtifactInformation> pendingGets;\n+      BlockingQueue<ByteString> currentOutput;\n+\n+      @Override\n+      @SuppressFBWarnings(value = \"SF_SWITCH_FALLTHROUGH\", justification = \"fallthrough intended\")\n+      public synchronized void onNext(ArtifactApi.ArtifactResponseWrapper responseWrapper) {\n+        switch (state) {\n+          case START:\n+            stagingToken = responseWrapper.getStagingToken();\n+            LOG.info(\"Staging artifacts for {}.\", stagingToken);\n+            toResolve = toStage.get(stagingToken);\n+            stagedFutures = new ConcurrentHashMap<>();\n+            pendingResolves = new ArrayDeque<>();\n+            pendingResolves.addAll(toResolve.keySet());\n+            stagingExecutor = Executors.newFixedThreadPool(THREAD_POOL_SIZE);\n+            totalPendingBytes = new OverflowingSemaphore(MAX_PENDING_BYTES);\n+            resolveNextEnvironment(responseObserver);\n+            break;\n+\n+          case RESOLVE:\n+            {\n+              currentEnvironment = pendingResolves.remove();\n+              stagedFutures.put(currentEnvironment, new ArrayList<>());\n+              pendingGets = new ArrayDeque<>();\n+              for (RunnerApi.ArtifactInformation artifact :\n+                  responseWrapper.getResolveArtifactResponse().getReplacementsList()) {\n+                Optional<RunnerApi.ArtifactInformation> fetched = getLocal(artifact);\n+                if (fetched.isPresent()) {\n+                  stagedFutures\n+                      .get(currentEnvironment)\n+                      .add(new FutureTask<RunnerApi.ArtifactInformation>(() -> fetched.get()));\n+                } else {\n+                  pendingGets.add(artifact);\n+                  responseObserver.onNext(\n+                      ArtifactApi.ArtifactRequestWrapper.newBuilder()\n+                          .setGetArtifact(\n+                              ArtifactApi.GetArtifactRequest.newBuilder().setArtifact(artifact))\n+                          .build());\n+                }\n+              }\n+              LOG.info(\n+                  \"Getting {} artifacts for {}.{}.\",\n+                  pendingGets.size(),\n+                  stagingToken,\n+                  pendingResolves.peek());\n+              if (pendingGets.isEmpty()) {\n+                resolveNextEnvironment(responseObserver);\n+              } else {\n+                state = State.GET;\n+              }\n+              break;\n+            }\n+\n+          case GET:\n+            RunnerApi.ArtifactInformation currentArtifact = pendingGets.remove();\n+            String name = createFilename(nameIndex++, currentEnvironment, currentArtifact);\n+            try {\n+              LOG.debug(\"Storing artifacts for {} as {}\", stagingToken, name);\n+              currentOutput = new ArrayBlockingQueue<ByteString>(100);\n+              stagedFutures\n+                  .get(currentEnvironment)\n+                  .add(\n+                      stagingExecutor.submit(\n+                          new StoreArtifact(\n+                              stagingToken,\n+                              name,\n+                              currentArtifact,\n+                              currentOutput,\n+                              totalPendingBytes)));\n+            } catch (Exception exn) {\n+              LOG.error(\"Error submitting.\", exn);\n+              responseObserver.onError(exn);\n+            }\n+            state = State.GETCHUNK;\n+            // fall through\n+\n+          case GETCHUNK:\n+            try {\n+              ByteString chunk = responseWrapper.getGetArtifactResponse().getData();\n+              if (chunk.size() > 0) {\n+                totalPendingBytes.aquire(chunk.size());\n+                currentOutput.put(chunk);\n+              }\n+              if (responseWrapper.getIsLast()) {\n+                currentOutput.put(ByteString.EMPTY); // The EOF value.\n+                if (pendingGets.isEmpty()) {\n+                  resolveNextEnvironment(responseObserver);\n+                } else {\n+                  state = State.GET;\n+                  LOG.debug(\"Waiting for {}\", pendingGets.peek());\n+                }\n+              }\n+            } catch (Exception exn) {\n+              LOG.error(\"Error submitting.\", exn);\n+              onError(exn);\n+            }\n+            break;\n+\n+          default:\n+            responseObserver.onError(\n+                new StatusException(\n+                    Status.INVALID_ARGUMENT.withDescription(\"Illegal state \" + state)));\n+        }\n+      }\n+\n+      private void resolveNextEnvironment(\n+          StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+        if (pendingResolves.isEmpty()) {\n+          finishStaging(responseObserver);\n+        } else {\n+          state = State.RESOLVE;\n+          LOG.info(\"Resolving artifacts for {}.{}.\", stagingToken, pendingResolves.peek());\n+          responseObserver.onNext(\n+              ArtifactApi.ArtifactRequestWrapper.newBuilder()\n+                  .setResolveArtifact(\n+                      ArtifactApi.ResolveArtifactsRequest.newBuilder()\n+                          .addAllArtifacts(toResolve.get(pendingResolves.peek())))\n+                  .build());\n+        }\n+      }\n+\n+      private void finishStaging(\n+          StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+        LOG.debug(\"Finishing staging for {}.\", stagingToken);\n+        Map<String, List<RunnerApi.ArtifactInformation>> staged = new HashMap<>();\n+        try {\n+          for (Map.Entry<String, List<Future<RunnerApi.ArtifactInformation>>> entry :\n+              stagedFutures.entrySet()) {\n+            List<RunnerApi.ArtifactInformation> envStaged = new ArrayList<>();\n+            for (Future<RunnerApi.ArtifactInformation> future : entry.getValue()) {\n+              envStaged.add(future.get());\n+            }\n+            staged.put(entry.getKey(), envStaged);\n+          }\n+          ArtifactStagingService.this.staged.put(stagingToken, staged);\n+          stagingExecutor.shutdown();\n+          state = State.DONE;\n+          LOG.info(\"Artifacts fully staged for {}.\", stagingToken);\n+          responseObserver.onCompleted();\n+        } catch (Exception exn) {\n+          LOG.error(\"Error staging artifacts\", exn);\n+          responseObserver.onError(exn);\n+          state = State.ERROR;\n+          return;\n+        }\n+      }\n+\n+      /**\n+       * Return an alternative artifact if we do not need to get this over the artifact API, or\n+       * possibly at all.\n+       */\n+      private Optional<RunnerApi.ArtifactInformation> getLocal(\n+          RunnerApi.ArtifactInformation artifact) {\n+        return Optional.empty();\n+      }\n+\n+      /**\n+       * Attempts to provide a reasonable filename for the artifact.\n+       *\n+       * @param index a monotonically increasing index, which provides uniqueness\n+       * @param environment the environment id\n+       * @param artifact the artifact itself\n+       */\n+      private String createFilename(\n+          int index, String environment, RunnerApi.ArtifactInformation artifact) {\n+        String path;\n+        try {\n+          if (artifact.getRoleUrn().equals(ArtifactRetrievalService.STAGING_TO_ARTIFACT_URN)) {\n+            path =\n+                RunnerApi.ArtifactStagingToRolePayload.parseFrom(artifact.getRolePayload())\n+                    .getStagedName();\n+          } else if (artifact.getTypeUrn().equals(ArtifactRetrievalService.FILE_ARTIFACT_URN)) {\n+            path = RunnerApi.ArtifactFilePayload.parseFrom(artifact.getTypePayload()).getPath();\n+          } else if (artifact.getTypeUrn().equals(ArtifactRetrievalService.URL_ARTIFACT_URN)) {\n+            path = RunnerApi.ArtifactUrlPayload.parseFrom(artifact.getTypePayload()).getUrl();\n+          } else {\n+            path = \"artifact\";\n+          }\n+        } catch (InvalidProtocolBufferException exn) {\n+          throw new RuntimeException(exn);\n+        }\n+        // Limit to the last contiguous alpha-numeric sequence. In particular, this will exclude\n+        // all path separators.\n+        List<String> components = Splitter.onPattern(\"[^A-Za-z-_.]]\").splitToList(path);\n+        String base = components.get(components.size() - 1);\n+        return clip(String.format(\"%d-%s-%s\", index, clip(environment, 25), base), 100);\n+      }\n+\n+      private String clip(String s, int maxLength) {\n+        return s.length() < maxLength ? s : s.substring(0, maxLength);\n+      }\n+\n+      @Override\n+      public void onError(Throwable throwable) {\n+        stagingExecutor.shutdownNow();\n+        LOG.error(\"Error staging artifacts\", throwable);\n+        state = State.ERROR;\n+      }\n+\n+      @Override\n+      public void onCompleted() {\n+        assert state == State.DONE;\n+      }\n+    };\n+  }\n+\n+  @Override\n+  public void close() throws Exception {\n+    // Nothing to close.\n+  }\n+\n+  /**\n+   * Lazily stages artifacts by letting an ArtifactStagingService resolve and request artifacts.\n+   *\n+   * @param retrievalService an ArtifactRetrievalService used to resolve and retrieve artifacts\n+   * @param stagingService an ArtifactStagingService stub which will request artifacts\n+   * @param stagingToken the staging token of the job whose artifacts will be retrieved\n+   * @throws InterruptedException\n+   * @throws IOException\n+   */\n+  public static void offer(\n+      ArtifactRetrievalService retrievalService,\n+      ArtifactStagingServiceGrpc.ArtifactStagingServiceStub stagingService,\n+      String stagingToken)\n+      throws InterruptedException, IOException {\n+    StagingRequestObserver requestObserver = new StagingRequestObserver(retrievalService);\n+    requestObserver.responseObserver =\n+        stagingService.reverseArtifactRetrievalService(requestObserver);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDUwOTkxOA=="}, "originalCommit": {"oid": "9c8718e46a3692034de9c9a9ed0754bab325cec5"}, "originalPosition": 503}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDY1ODY3NA==", "bodyText": "No longer needed.", "url": "https://github.com/apache/beam/pull/11342#discussion_r410658674", "createdAt": "2020-04-18T06:50:18Z", "author": {"login": "robertwb"}, "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/artifact/ArtifactStagingService.java", "diffHunk": "@@ -0,0 +1,606 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.fnexecution.artifact;\n+\n+import com.google.auto.value.AutoValue;\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.channels.Channels;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.FutureTask;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactApi;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactStagingServiceGrpc;\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+import org.apache.beam.runners.fnexecution.FnService;\n+import org.apache.beam.sdk.io.FileSystems;\n+import org.apache.beam.sdk.io.fs.ResolveOptions;\n+import org.apache.beam.sdk.io.fs.ResourceId;\n+import org.apache.beam.sdk.util.MimeTypes;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.ByteString;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.InvalidProtocolBufferException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.Status;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.StatusException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.stub.StreamObserver;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Splitter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class ArtifactStagingService\n+    extends ArtifactStagingServiceGrpc.ArtifactStagingServiceImplBase implements FnService {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(ArtifactStagingService.class);\n+\n+  private final ArtifactDestinationProvider destinationProvider;\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> toStage =\n+      new ConcurrentHashMap<>();\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> staged =\n+      new ConcurrentHashMap<>();\n+\n+  public ArtifactStagingService(ArtifactDestinationProvider destinationProvider) {\n+    this.destinationProvider = destinationProvider;\n+  }\n+\n+  /**\n+   * Registers a set of artifacts to be staged with this service.\n+   *\n+   * <p>A client (e.g. a Beam SDK) is expected to connect to this service with the given staging\n+   * token and offer resolution and retrieval of this set of artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   * @param artifacts all artifacts to stage, keyed by environment\n+   */\n+  public void registerJob(\n+      String stagingToken, Map<String, List<RunnerApi.ArtifactInformation>> artifacts) {\n+    assert !toStage.containsKey(stagingToken);\n+    toStage.put(stagingToken, artifacts);\n+  }\n+\n+  /**\n+   * Returns the rewritten artifacts associated with this job, keyed by environment.\n+   *\n+   * <p>This should be called after the client has finished offering artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   */\n+  public Map<String, List<RunnerApi.ArtifactInformation>> getStagedArtifacts(String stagingToken) {\n+    toStage.remove(stagingToken);\n+    return staged.remove(stagingToken);\n+  }\n+\n+  /** Provides a concrete location to which artifacts can be staged on retrieval. */\n+  public interface ArtifactDestinationProvider {\n+    ArtifactDestination getDestination(String stagingToken, String name) throws IOException;\n+  }\n+\n+  /**\n+   * A pairing of a newly created artifact type and an ouptut stream that will be readable at that\n+   * type.\n+   */\n+  @AutoValue\n+  public abstract static class ArtifactDestination {\n+    public static ArtifactDestination create(\n+        String typeUrn, ByteString typePayload, OutputStream out) {\n+      return new AutoValue_ArtifactStagingService_ArtifactDestination(typeUrn, typePayload, out);\n+    }\n+\n+    public static ArtifactDestination fromFile(String path) throws IOException {\n+      return fromFile(\n+          path,\n+          Channels.newOutputStream(\n+              FileSystems.create(\n+                  FileSystems.matchNewResource(path, false /* isDirectory */), MimeTypes.BINARY)));\n+    }\n+\n+    public static ArtifactDestination fromFile(String path, OutputStream out) {\n+      return create(\n+          ArtifactRetrievalService.FILE_ARTIFACT_URN,\n+          RunnerApi.ArtifactFilePayload.newBuilder().setPath(path).build().toByteString(),\n+          out);\n+    }\n+\n+    public abstract String getTypeUrn();\n+\n+    public abstract ByteString getTypePayload();\n+\n+    public abstract OutputStream getOutputStream();\n+  }\n+\n+  /**\n+   * An ArtifactDestinationProvider that places new artifacts as files in a Beam filesystem.\n+   *\n+   * @param root the directory in which to place all artifacts\n+   */\n+  public static ArtifactDestinationProvider beamFilesystemArtifactDestinationProvider(String root) {\n+    return (statingToken, name) -> {\n+      ResourceId path =\n+          FileSystems.matchNewResource(root, true)\n+              .resolve(statingToken, ResolveOptions.StandardResolveOptions.RESOLVE_DIRECTORY)\n+              .resolve(name, ResolveOptions.StandardResolveOptions.RESOLVE_FILE);\n+      return ArtifactDestination.fromFile(path.toString());\n+    };\n+  }\n+\n+  private enum State {\n+    START,\n+    RESOLVE,\n+    GET,\n+    GETCHUNK,\n+    DONE,\n+    ERROR,\n+  }\n+\n+  /**\n+   * Like the standard Semaphore, but allows an aquire to go over the limit if there is any room.\n+   *\n+   * <p>Also allows setting an error, to avoid issues with un-released aquires after error.\n+   */\n+  private static class OverflowingSemaphore {\n+    private int totalPermits;\n+    private int usedPermits;\n+    private Exception exception;\n+\n+    public OverflowingSemaphore(int totalPermits) {\n+      this.totalPermits = totalPermits;\n+      this.usedPermits = 0;\n+    }\n+\n+    synchronized void aquire(int permits) throws Exception {\n+      while (usedPermits >= totalPermits) {\n+        if (exception != null) {\n+          throw exception;\n+        }\n+        this.wait();\n+      }\n+      usedPermits += permits;\n+    }\n+\n+    synchronized void release(int permits) {\n+      usedPermits -= permits;\n+      this.notifyAll();\n+    }\n+\n+    synchronized void setException(Exception exception) {\n+      this.exception = exception;\n+      this.notifyAll();\n+    }\n+  }\n+\n+  /** A task that pulls bytes off a queue and actually writes them to a staging location. */\n+  private class StoreArtifact implements Callable<RunnerApi.ArtifactInformation> {\n+\n+    private String stagingToken;\n+    private String name;\n+    private RunnerApi.ArtifactInformation originalArtifact;\n+    private BlockingQueue<ByteString> bytesQueue;\n+    private OverflowingSemaphore totalPendingBytes;\n+\n+    public StoreArtifact(\n+        String stagingToken,\n+        String name,\n+        RunnerApi.ArtifactInformation originalArtifact,\n+        BlockingQueue<ByteString> bytesQueue,\n+        OverflowingSemaphore totalPendingBytes) {\n+      this.stagingToken = stagingToken;\n+      this.name = name;\n+      this.originalArtifact = originalArtifact;\n+      this.bytesQueue = bytesQueue;\n+      this.totalPendingBytes = totalPendingBytes;\n+    }\n+\n+    @Override\n+    public RunnerApi.ArtifactInformation call() throws IOException {\n+      try {\n+        ArtifactDestination dest = destinationProvider.getDestination(stagingToken, name);\n+        LOG.debug(\"Storing artifact for {}.{} at {}\", stagingToken, name, dest);\n+        ByteString chunk = bytesQueue.take();\n+        while (chunk.size() > 0) {\n+          totalPendingBytes.release(chunk.size());\n+          dest.getOutputStream().write(chunk.toByteArray());\n+          chunk = bytesQueue.take();\n+        }\n+        dest.getOutputStream().close();\n+        return originalArtifact\n+            .toBuilder()\n+            .setTypeUrn(dest.getTypeUrn())\n+            .setTypePayload(dest.getTypePayload())\n+            .build();\n+      } catch (IOException | InterruptedException exn) {\n+        // As this thread will no longer be draining the queue, we don't want to get stuck writing\n+        // to it.\n+        totalPendingBytes.setException(exn);\n+        LOG.error(\"Exception staging artifacts\", exn);\n+        if (exn instanceof IOException) {\n+          throw (IOException) exn;\n+        } else {\n+          throw new RuntimeException(exn);\n+        }\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public StreamObserver<ArtifactApi.ArtifactResponseWrapper> reverseArtifactRetrievalService(\n+      StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+\n+    return new StreamObserver<ArtifactApi.ArtifactResponseWrapper>() {\n+\n+      /** The maximum number of parallel threads to use to stage. */\n+      public static final int THREAD_POOL_SIZE = 10;\n+\n+      /** The maximum number of bytes to buffer across all writes before throttling. */\n+      public static final int MAX_PENDING_BYTES = 100 << 20; // 100 MB\n+\n+      String stagingToken;\n+      Map<String, List<RunnerApi.ArtifactInformation>> toResolve;\n+      Map<String, List<Future<RunnerApi.ArtifactInformation>>> stagedFutures;\n+      ExecutorService stagingExecutor;\n+      OverflowingSemaphore totalPendingBytes;\n+\n+      State state = State.START;\n+      Queue<String> pendingResolves;\n+      String currentEnvironment;\n+      int nameIndex;\n+      Queue<RunnerApi.ArtifactInformation> pendingGets;\n+      BlockingQueue<ByteString> currentOutput;\n+\n+      @Override\n+      @SuppressFBWarnings(value = \"SF_SWITCH_FALLTHROUGH\", justification = \"fallthrough intended\")\n+      public synchronized void onNext(ArtifactApi.ArtifactResponseWrapper responseWrapper) {\n+        switch (state) {\n+          case START:\n+            stagingToken = responseWrapper.getStagingToken();\n+            LOG.info(\"Staging artifacts for {}.\", stagingToken);\n+            toResolve = toStage.get(stagingToken);\n+            stagedFutures = new ConcurrentHashMap<>();\n+            pendingResolves = new ArrayDeque<>();\n+            pendingResolves.addAll(toResolve.keySet());\n+            stagingExecutor = Executors.newFixedThreadPool(THREAD_POOL_SIZE);\n+            totalPendingBytes = new OverflowingSemaphore(MAX_PENDING_BYTES);\n+            resolveNextEnvironment(responseObserver);\n+            break;\n+\n+          case RESOLVE:\n+            {\n+              currentEnvironment = pendingResolves.remove();\n+              stagedFutures.put(currentEnvironment, new ArrayList<>());\n+              pendingGets = new ArrayDeque<>();\n+              for (RunnerApi.ArtifactInformation artifact :\n+                  responseWrapper.getResolveArtifactResponse().getReplacementsList()) {\n+                Optional<RunnerApi.ArtifactInformation> fetched = getLocal(artifact);\n+                if (fetched.isPresent()) {\n+                  stagedFutures\n+                      .get(currentEnvironment)\n+                      .add(new FutureTask<RunnerApi.ArtifactInformation>(() -> fetched.get()));\n+                } else {\n+                  pendingGets.add(artifact);\n+                  responseObserver.onNext(\n+                      ArtifactApi.ArtifactRequestWrapper.newBuilder()\n+                          .setGetArtifact(\n+                              ArtifactApi.GetArtifactRequest.newBuilder().setArtifact(artifact))\n+                          .build());\n+                }\n+              }\n+              LOG.info(\n+                  \"Getting {} artifacts for {}.{}.\",\n+                  pendingGets.size(),\n+                  stagingToken,\n+                  pendingResolves.peek());\n+              if (pendingGets.isEmpty()) {\n+                resolveNextEnvironment(responseObserver);\n+              } else {\n+                state = State.GET;\n+              }\n+              break;\n+            }\n+\n+          case GET:\n+            RunnerApi.ArtifactInformation currentArtifact = pendingGets.remove();\n+            String name = createFilename(nameIndex++, currentEnvironment, currentArtifact);\n+            try {\n+              LOG.debug(\"Storing artifacts for {} as {}\", stagingToken, name);\n+              currentOutput = new ArrayBlockingQueue<ByteString>(100);\n+              stagedFutures\n+                  .get(currentEnvironment)\n+                  .add(\n+                      stagingExecutor.submit(\n+                          new StoreArtifact(\n+                              stagingToken,\n+                              name,\n+                              currentArtifact,\n+                              currentOutput,\n+                              totalPendingBytes)));\n+            } catch (Exception exn) {\n+              LOG.error(\"Error submitting.\", exn);\n+              responseObserver.onError(exn);\n+            }\n+            state = State.GETCHUNK;\n+            // fall through\n+\n+          case GETCHUNK:\n+            try {\n+              ByteString chunk = responseWrapper.getGetArtifactResponse().getData();\n+              if (chunk.size() > 0) {\n+                totalPendingBytes.aquire(chunk.size());\n+                currentOutput.put(chunk);\n+              }\n+              if (responseWrapper.getIsLast()) {\n+                currentOutput.put(ByteString.EMPTY); // The EOF value.\n+                if (pendingGets.isEmpty()) {\n+                  resolveNextEnvironment(responseObserver);\n+                } else {\n+                  state = State.GET;\n+                  LOG.debug(\"Waiting for {}\", pendingGets.peek());\n+                }\n+              }\n+            } catch (Exception exn) {\n+              LOG.error(\"Error submitting.\", exn);\n+              onError(exn);\n+            }\n+            break;\n+\n+          default:\n+            responseObserver.onError(\n+                new StatusException(\n+                    Status.INVALID_ARGUMENT.withDescription(\"Illegal state \" + state)));\n+        }\n+      }\n+\n+      private void resolveNextEnvironment(\n+          StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+        if (pendingResolves.isEmpty()) {\n+          finishStaging(responseObserver);\n+        } else {\n+          state = State.RESOLVE;\n+          LOG.info(\"Resolving artifacts for {}.{}.\", stagingToken, pendingResolves.peek());\n+          responseObserver.onNext(\n+              ArtifactApi.ArtifactRequestWrapper.newBuilder()\n+                  .setResolveArtifact(\n+                      ArtifactApi.ResolveArtifactsRequest.newBuilder()\n+                          .addAllArtifacts(toResolve.get(pendingResolves.peek())))\n+                  .build());\n+        }\n+      }\n+\n+      private void finishStaging(\n+          StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+        LOG.debug(\"Finishing staging for {}.\", stagingToken);\n+        Map<String, List<RunnerApi.ArtifactInformation>> staged = new HashMap<>();\n+        try {\n+          for (Map.Entry<String, List<Future<RunnerApi.ArtifactInformation>>> entry :\n+              stagedFutures.entrySet()) {\n+            List<RunnerApi.ArtifactInformation> envStaged = new ArrayList<>();\n+            for (Future<RunnerApi.ArtifactInformation> future : entry.getValue()) {\n+              envStaged.add(future.get());\n+            }\n+            staged.put(entry.getKey(), envStaged);\n+          }\n+          ArtifactStagingService.this.staged.put(stagingToken, staged);\n+          stagingExecutor.shutdown();\n+          state = State.DONE;\n+          LOG.info(\"Artifacts fully staged for {}.\", stagingToken);\n+          responseObserver.onCompleted();\n+        } catch (Exception exn) {\n+          LOG.error(\"Error staging artifacts\", exn);\n+          responseObserver.onError(exn);\n+          state = State.ERROR;\n+          return;\n+        }\n+      }\n+\n+      /**\n+       * Return an alternative artifact if we do not need to get this over the artifact API, or\n+       * possibly at all.\n+       */\n+      private Optional<RunnerApi.ArtifactInformation> getLocal(\n+          RunnerApi.ArtifactInformation artifact) {\n+        return Optional.empty();\n+      }\n+\n+      /**\n+       * Attempts to provide a reasonable filename for the artifact.\n+       *\n+       * @param index a monotonically increasing index, which provides uniqueness\n+       * @param environment the environment id\n+       * @param artifact the artifact itself\n+       */\n+      private String createFilename(\n+          int index, String environment, RunnerApi.ArtifactInformation artifact) {\n+        String path;\n+        try {\n+          if (artifact.getRoleUrn().equals(ArtifactRetrievalService.STAGING_TO_ARTIFACT_URN)) {\n+            path =\n+                RunnerApi.ArtifactStagingToRolePayload.parseFrom(artifact.getRolePayload())\n+                    .getStagedName();\n+          } else if (artifact.getTypeUrn().equals(ArtifactRetrievalService.FILE_ARTIFACT_URN)) {\n+            path = RunnerApi.ArtifactFilePayload.parseFrom(artifact.getTypePayload()).getPath();\n+          } else if (artifact.getTypeUrn().equals(ArtifactRetrievalService.URL_ARTIFACT_URN)) {\n+            path = RunnerApi.ArtifactUrlPayload.parseFrom(artifact.getTypePayload()).getUrl();\n+          } else {\n+            path = \"artifact\";\n+          }\n+        } catch (InvalidProtocolBufferException exn) {\n+          throw new RuntimeException(exn);\n+        }\n+        // Limit to the last contiguous alpha-numeric sequence. In particular, this will exclude\n+        // all path separators.\n+        List<String> components = Splitter.onPattern(\"[^A-Za-z-_.]]\").splitToList(path);\n+        String base = components.get(components.size() - 1);\n+        return clip(String.format(\"%d-%s-%s\", index, clip(environment, 25), base), 100);\n+      }\n+\n+      private String clip(String s, int maxLength) {\n+        return s.length() < maxLength ? s : s.substring(0, maxLength);\n+      }\n+\n+      @Override\n+      public void onError(Throwable throwable) {\n+        stagingExecutor.shutdownNow();\n+        LOG.error(\"Error staging artifacts\", throwable);\n+        state = State.ERROR;\n+      }\n+\n+      @Override\n+      public void onCompleted() {\n+        assert state == State.DONE;\n+      }\n+    };\n+  }\n+\n+  @Override\n+  public void close() throws Exception {\n+    // Nothing to close.\n+  }\n+\n+  /**\n+   * Lazily stages artifacts by letting an ArtifactStagingService resolve and request artifacts.\n+   *\n+   * @param retrievalService an ArtifactRetrievalService used to resolve and retrieve artifacts\n+   * @param stagingService an ArtifactStagingService stub which will request artifacts\n+   * @param stagingToken the staging token of the job whose artifacts will be retrieved\n+   * @throws InterruptedException\n+   * @throws IOException\n+   */\n+  public static void offer(\n+      ArtifactRetrievalService retrievalService,\n+      ArtifactStagingServiceGrpc.ArtifactStagingServiceStub stagingService,\n+      String stagingToken)\n+      throws InterruptedException, IOException {\n+    StagingRequestObserver requestObserver = new StagingRequestObserver(retrievalService);\n+    requestObserver.responseObserver =\n+        stagingService.reverseArtifactRetrievalService(requestObserver);\n+    requestObserver.responseObserver.onNext(\n+        ArtifactApi.ArtifactResponseWrapper.newBuilder().setStagingToken(stagingToken).build());\n+    requestObserver.waitUntilDone();\n+    if (requestObserver.error != null) {\n+      if (requestObserver.error instanceof IOException) {\n+        throw (IOException) requestObserver.error;\n+      } else {\n+        throw new IOException(requestObserver.error);\n+      }\n+    }\n+  }\n+\n+  /** Actually implements the reverse retrieval protocol. */\n+  private static class StagingRequestObserver\n+      implements StreamObserver<ArtifactApi.ArtifactRequestWrapper> {\n+\n+    private ArtifactRetrievalService retrievalService;\n+\n+    public StagingRequestObserver(ArtifactRetrievalService retrievalService) {\n+      this.retrievalService = retrievalService;\n+    }\n+\n+    CountDownLatch latch = new CountDownLatch(1);\n+    StreamObserver<ArtifactApi.ArtifactResponseWrapper> responseObserver;\n+    Throwable error;\n+\n+    @Override\n+    public void onNext(ArtifactApi.ArtifactRequestWrapper requestWrapper) {\n+      assert responseObserver != null;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDUwOTExOQ=="}, "originalCommit": {"oid": "9c8718e46a3692034de9c9a9ed0754bab325cec5"}, "originalPosition": 532}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDY2MDA3NQ==", "bodyText": "Yes, this is nicer. (Thought about making offer non-blocking as well, but the benefits don't seem to out-weigh making it error-prone to use.)", "url": "https://github.com/apache/beam/pull/11342#discussion_r410660075", "createdAt": "2020-04-18T07:04:07Z", "author": {"login": "robertwb"}, "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/artifact/ArtifactStagingService.java", "diffHunk": "@@ -0,0 +1,606 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.fnexecution.artifact;\n+\n+import com.google.auto.value.AutoValue;\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.channels.Channels;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.FutureTask;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactApi;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactStagingServiceGrpc;\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+import org.apache.beam.runners.fnexecution.FnService;\n+import org.apache.beam.sdk.io.FileSystems;\n+import org.apache.beam.sdk.io.fs.ResolveOptions;\n+import org.apache.beam.sdk.io.fs.ResourceId;\n+import org.apache.beam.sdk.util.MimeTypes;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.ByteString;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.InvalidProtocolBufferException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.Status;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.StatusException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.stub.StreamObserver;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Splitter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class ArtifactStagingService\n+    extends ArtifactStagingServiceGrpc.ArtifactStagingServiceImplBase implements FnService {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(ArtifactStagingService.class);\n+\n+  private final ArtifactDestinationProvider destinationProvider;\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> toStage =\n+      new ConcurrentHashMap<>();\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> staged =\n+      new ConcurrentHashMap<>();\n+\n+  public ArtifactStagingService(ArtifactDestinationProvider destinationProvider) {\n+    this.destinationProvider = destinationProvider;\n+  }\n+\n+  /**\n+   * Registers a set of artifacts to be staged with this service.\n+   *\n+   * <p>A client (e.g. a Beam SDK) is expected to connect to this service with the given staging\n+   * token and offer resolution and retrieval of this set of artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   * @param artifacts all artifacts to stage, keyed by environment\n+   */\n+  public void registerJob(\n+      String stagingToken, Map<String, List<RunnerApi.ArtifactInformation>> artifacts) {\n+    assert !toStage.containsKey(stagingToken);\n+    toStage.put(stagingToken, artifacts);\n+  }\n+\n+  /**\n+   * Returns the rewritten artifacts associated with this job, keyed by environment.\n+   *\n+   * <p>This should be called after the client has finished offering artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   */\n+  public Map<String, List<RunnerApi.ArtifactInformation>> getStagedArtifacts(String stagingToken) {\n+    toStage.remove(stagingToken);\n+    return staged.remove(stagingToken);\n+  }\n+\n+  /** Provides a concrete location to which artifacts can be staged on retrieval. */\n+  public interface ArtifactDestinationProvider {\n+    ArtifactDestination getDestination(String stagingToken, String name) throws IOException;\n+  }\n+\n+  /**\n+   * A pairing of a newly created artifact type and an ouptut stream that will be readable at that\n+   * type.\n+   */\n+  @AutoValue\n+  public abstract static class ArtifactDestination {\n+    public static ArtifactDestination create(\n+        String typeUrn, ByteString typePayload, OutputStream out) {\n+      return new AutoValue_ArtifactStagingService_ArtifactDestination(typeUrn, typePayload, out);\n+    }\n+\n+    public static ArtifactDestination fromFile(String path) throws IOException {\n+      return fromFile(\n+          path,\n+          Channels.newOutputStream(\n+              FileSystems.create(\n+                  FileSystems.matchNewResource(path, false /* isDirectory */), MimeTypes.BINARY)));\n+    }\n+\n+    public static ArtifactDestination fromFile(String path, OutputStream out) {\n+      return create(\n+          ArtifactRetrievalService.FILE_ARTIFACT_URN,\n+          RunnerApi.ArtifactFilePayload.newBuilder().setPath(path).build().toByteString(),\n+          out);\n+    }\n+\n+    public abstract String getTypeUrn();\n+\n+    public abstract ByteString getTypePayload();\n+\n+    public abstract OutputStream getOutputStream();\n+  }\n+\n+  /**\n+   * An ArtifactDestinationProvider that places new artifacts as files in a Beam filesystem.\n+   *\n+   * @param root the directory in which to place all artifacts\n+   */\n+  public static ArtifactDestinationProvider beamFilesystemArtifactDestinationProvider(String root) {\n+    return (statingToken, name) -> {\n+      ResourceId path =\n+          FileSystems.matchNewResource(root, true)\n+              .resolve(statingToken, ResolveOptions.StandardResolveOptions.RESOLVE_DIRECTORY)\n+              .resolve(name, ResolveOptions.StandardResolveOptions.RESOLVE_FILE);\n+      return ArtifactDestination.fromFile(path.toString());\n+    };\n+  }\n+\n+  private enum State {\n+    START,\n+    RESOLVE,\n+    GET,\n+    GETCHUNK,\n+    DONE,\n+    ERROR,\n+  }\n+\n+  /**\n+   * Like the standard Semaphore, but allows an aquire to go over the limit if there is any room.\n+   *\n+   * <p>Also allows setting an error, to avoid issues with un-released aquires after error.\n+   */\n+  private static class OverflowingSemaphore {\n+    private int totalPermits;\n+    private int usedPermits;\n+    private Exception exception;\n+\n+    public OverflowingSemaphore(int totalPermits) {\n+      this.totalPermits = totalPermits;\n+      this.usedPermits = 0;\n+    }\n+\n+    synchronized void aquire(int permits) throws Exception {\n+      while (usedPermits >= totalPermits) {\n+        if (exception != null) {\n+          throw exception;\n+        }\n+        this.wait();\n+      }\n+      usedPermits += permits;\n+    }\n+\n+    synchronized void release(int permits) {\n+      usedPermits -= permits;\n+      this.notifyAll();\n+    }\n+\n+    synchronized void setException(Exception exception) {\n+      this.exception = exception;\n+      this.notifyAll();\n+    }\n+  }\n+\n+  /** A task that pulls bytes off a queue and actually writes them to a staging location. */\n+  private class StoreArtifact implements Callable<RunnerApi.ArtifactInformation> {\n+\n+    private String stagingToken;\n+    private String name;\n+    private RunnerApi.ArtifactInformation originalArtifact;\n+    private BlockingQueue<ByteString> bytesQueue;\n+    private OverflowingSemaphore totalPendingBytes;\n+\n+    public StoreArtifact(\n+        String stagingToken,\n+        String name,\n+        RunnerApi.ArtifactInformation originalArtifact,\n+        BlockingQueue<ByteString> bytesQueue,\n+        OverflowingSemaphore totalPendingBytes) {\n+      this.stagingToken = stagingToken;\n+      this.name = name;\n+      this.originalArtifact = originalArtifact;\n+      this.bytesQueue = bytesQueue;\n+      this.totalPendingBytes = totalPendingBytes;\n+    }\n+\n+    @Override\n+    public RunnerApi.ArtifactInformation call() throws IOException {\n+      try {\n+        ArtifactDestination dest = destinationProvider.getDestination(stagingToken, name);\n+        LOG.debug(\"Storing artifact for {}.{} at {}\", stagingToken, name, dest);\n+        ByteString chunk = bytesQueue.take();\n+        while (chunk.size() > 0) {\n+          totalPendingBytes.release(chunk.size());\n+          dest.getOutputStream().write(chunk.toByteArray());\n+          chunk = bytesQueue.take();\n+        }\n+        dest.getOutputStream().close();\n+        return originalArtifact\n+            .toBuilder()\n+            .setTypeUrn(dest.getTypeUrn())\n+            .setTypePayload(dest.getTypePayload())\n+            .build();\n+      } catch (IOException | InterruptedException exn) {\n+        // As this thread will no longer be draining the queue, we don't want to get stuck writing\n+        // to it.\n+        totalPendingBytes.setException(exn);\n+        LOG.error(\"Exception staging artifacts\", exn);\n+        if (exn instanceof IOException) {\n+          throw (IOException) exn;\n+        } else {\n+          throw new RuntimeException(exn);\n+        }\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public StreamObserver<ArtifactApi.ArtifactResponseWrapper> reverseArtifactRetrievalService(\n+      StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+\n+    return new StreamObserver<ArtifactApi.ArtifactResponseWrapper>() {\n+\n+      /** The maximum number of parallel threads to use to stage. */\n+      public static final int THREAD_POOL_SIZE = 10;\n+\n+      /** The maximum number of bytes to buffer across all writes before throttling. */\n+      public static final int MAX_PENDING_BYTES = 100 << 20; // 100 MB\n+\n+      String stagingToken;\n+      Map<String, List<RunnerApi.ArtifactInformation>> toResolve;\n+      Map<String, List<Future<RunnerApi.ArtifactInformation>>> stagedFutures;\n+      ExecutorService stagingExecutor;\n+      OverflowingSemaphore totalPendingBytes;\n+\n+      State state = State.START;\n+      Queue<String> pendingResolves;\n+      String currentEnvironment;\n+      int nameIndex;\n+      Queue<RunnerApi.ArtifactInformation> pendingGets;\n+      BlockingQueue<ByteString> currentOutput;\n+\n+      @Override\n+      @SuppressFBWarnings(value = \"SF_SWITCH_FALLTHROUGH\", justification = \"fallthrough intended\")\n+      public synchronized void onNext(ArtifactApi.ArtifactResponseWrapper responseWrapper) {\n+        switch (state) {\n+          case START:\n+            stagingToken = responseWrapper.getStagingToken();\n+            LOG.info(\"Staging artifacts for {}.\", stagingToken);\n+            toResolve = toStage.get(stagingToken);\n+            stagedFutures = new ConcurrentHashMap<>();\n+            pendingResolves = new ArrayDeque<>();\n+            pendingResolves.addAll(toResolve.keySet());\n+            stagingExecutor = Executors.newFixedThreadPool(THREAD_POOL_SIZE);\n+            totalPendingBytes = new OverflowingSemaphore(MAX_PENDING_BYTES);\n+            resolveNextEnvironment(responseObserver);\n+            break;\n+\n+          case RESOLVE:\n+            {\n+              currentEnvironment = pendingResolves.remove();\n+              stagedFutures.put(currentEnvironment, new ArrayList<>());\n+              pendingGets = new ArrayDeque<>();\n+              for (RunnerApi.ArtifactInformation artifact :\n+                  responseWrapper.getResolveArtifactResponse().getReplacementsList()) {\n+                Optional<RunnerApi.ArtifactInformation> fetched = getLocal(artifact);\n+                if (fetched.isPresent()) {\n+                  stagedFutures\n+                      .get(currentEnvironment)\n+                      .add(new FutureTask<RunnerApi.ArtifactInformation>(() -> fetched.get()));\n+                } else {\n+                  pendingGets.add(artifact);\n+                  responseObserver.onNext(\n+                      ArtifactApi.ArtifactRequestWrapper.newBuilder()\n+                          .setGetArtifact(\n+                              ArtifactApi.GetArtifactRequest.newBuilder().setArtifact(artifact))\n+                          .build());\n+                }\n+              }\n+              LOG.info(\n+                  \"Getting {} artifacts for {}.{}.\",\n+                  pendingGets.size(),\n+                  stagingToken,\n+                  pendingResolves.peek());\n+              if (pendingGets.isEmpty()) {\n+                resolveNextEnvironment(responseObserver);\n+              } else {\n+                state = State.GET;\n+              }\n+              break;\n+            }\n+\n+          case GET:\n+            RunnerApi.ArtifactInformation currentArtifact = pendingGets.remove();\n+            String name = createFilename(nameIndex++, currentEnvironment, currentArtifact);\n+            try {\n+              LOG.debug(\"Storing artifacts for {} as {}\", stagingToken, name);\n+              currentOutput = new ArrayBlockingQueue<ByteString>(100);\n+              stagedFutures\n+                  .get(currentEnvironment)\n+                  .add(\n+                      stagingExecutor.submit(\n+                          new StoreArtifact(\n+                              stagingToken,\n+                              name,\n+                              currentArtifact,\n+                              currentOutput,\n+                              totalPendingBytes)));\n+            } catch (Exception exn) {\n+              LOG.error(\"Error submitting.\", exn);\n+              responseObserver.onError(exn);\n+            }\n+            state = State.GETCHUNK;\n+            // fall through\n+\n+          case GETCHUNK:\n+            try {\n+              ByteString chunk = responseWrapper.getGetArtifactResponse().getData();\n+              if (chunk.size() > 0) {\n+                totalPendingBytes.aquire(chunk.size());\n+                currentOutput.put(chunk);\n+              }\n+              if (responseWrapper.getIsLast()) {\n+                currentOutput.put(ByteString.EMPTY); // The EOF value.\n+                if (pendingGets.isEmpty()) {\n+                  resolveNextEnvironment(responseObserver);\n+                } else {\n+                  state = State.GET;\n+                  LOG.debug(\"Waiting for {}\", pendingGets.peek());\n+                }\n+              }\n+            } catch (Exception exn) {\n+              LOG.error(\"Error submitting.\", exn);\n+              onError(exn);\n+            }\n+            break;\n+\n+          default:\n+            responseObserver.onError(\n+                new StatusException(\n+                    Status.INVALID_ARGUMENT.withDescription(\"Illegal state \" + state)));\n+        }\n+      }\n+\n+      private void resolveNextEnvironment(\n+          StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+        if (pendingResolves.isEmpty()) {\n+          finishStaging(responseObserver);\n+        } else {\n+          state = State.RESOLVE;\n+          LOG.info(\"Resolving artifacts for {}.{}.\", stagingToken, pendingResolves.peek());\n+          responseObserver.onNext(\n+              ArtifactApi.ArtifactRequestWrapper.newBuilder()\n+                  .setResolveArtifact(\n+                      ArtifactApi.ResolveArtifactsRequest.newBuilder()\n+                          .addAllArtifacts(toResolve.get(pendingResolves.peek())))\n+                  .build());\n+        }\n+      }\n+\n+      private void finishStaging(\n+          StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+        LOG.debug(\"Finishing staging for {}.\", stagingToken);\n+        Map<String, List<RunnerApi.ArtifactInformation>> staged = new HashMap<>();\n+        try {\n+          for (Map.Entry<String, List<Future<RunnerApi.ArtifactInformation>>> entry :\n+              stagedFutures.entrySet()) {\n+            List<RunnerApi.ArtifactInformation> envStaged = new ArrayList<>();\n+            for (Future<RunnerApi.ArtifactInformation> future : entry.getValue()) {\n+              envStaged.add(future.get());\n+            }\n+            staged.put(entry.getKey(), envStaged);\n+          }\n+          ArtifactStagingService.this.staged.put(stagingToken, staged);\n+          stagingExecutor.shutdown();\n+          state = State.DONE;\n+          LOG.info(\"Artifacts fully staged for {}.\", stagingToken);\n+          responseObserver.onCompleted();\n+        } catch (Exception exn) {\n+          LOG.error(\"Error staging artifacts\", exn);\n+          responseObserver.onError(exn);\n+          state = State.ERROR;\n+          return;\n+        }\n+      }\n+\n+      /**\n+       * Return an alternative artifact if we do not need to get this over the artifact API, or\n+       * possibly at all.\n+       */\n+      private Optional<RunnerApi.ArtifactInformation> getLocal(\n+          RunnerApi.ArtifactInformation artifact) {\n+        return Optional.empty();\n+      }\n+\n+      /**\n+       * Attempts to provide a reasonable filename for the artifact.\n+       *\n+       * @param index a monotonically increasing index, which provides uniqueness\n+       * @param environment the environment id\n+       * @param artifact the artifact itself\n+       */\n+      private String createFilename(\n+          int index, String environment, RunnerApi.ArtifactInformation artifact) {\n+        String path;\n+        try {\n+          if (artifact.getRoleUrn().equals(ArtifactRetrievalService.STAGING_TO_ARTIFACT_URN)) {\n+            path =\n+                RunnerApi.ArtifactStagingToRolePayload.parseFrom(artifact.getRolePayload())\n+                    .getStagedName();\n+          } else if (artifact.getTypeUrn().equals(ArtifactRetrievalService.FILE_ARTIFACT_URN)) {\n+            path = RunnerApi.ArtifactFilePayload.parseFrom(artifact.getTypePayload()).getPath();\n+          } else if (artifact.getTypeUrn().equals(ArtifactRetrievalService.URL_ARTIFACT_URN)) {\n+            path = RunnerApi.ArtifactUrlPayload.parseFrom(artifact.getTypePayload()).getUrl();\n+          } else {\n+            path = \"artifact\";\n+          }\n+        } catch (InvalidProtocolBufferException exn) {\n+          throw new RuntimeException(exn);\n+        }\n+        // Limit to the last contiguous alpha-numeric sequence. In particular, this will exclude\n+        // all path separators.\n+        List<String> components = Splitter.onPattern(\"[^A-Za-z-_.]]\").splitToList(path);\n+        String base = components.get(components.size() - 1);\n+        return clip(String.format(\"%d-%s-%s\", index, clip(environment, 25), base), 100);\n+      }\n+\n+      private String clip(String s, int maxLength) {\n+        return s.length() < maxLength ? s : s.substring(0, maxLength);\n+      }\n+\n+      @Override\n+      public void onError(Throwable throwable) {\n+        stagingExecutor.shutdownNow();\n+        LOG.error(\"Error staging artifacts\", throwable);\n+        state = State.ERROR;\n+      }\n+\n+      @Override\n+      public void onCompleted() {\n+        assert state == State.DONE;\n+      }\n+    };\n+  }\n+\n+  @Override\n+  public void close() throws Exception {\n+    // Nothing to close.\n+  }\n+\n+  /**\n+   * Lazily stages artifacts by letting an ArtifactStagingService resolve and request artifacts.\n+   *\n+   * @param retrievalService an ArtifactRetrievalService used to resolve and retrieve artifacts\n+   * @param stagingService an ArtifactStagingService stub which will request artifacts\n+   * @param stagingToken the staging token of the job whose artifacts will be retrieved\n+   * @throws InterruptedException\n+   * @throws IOException\n+   */\n+  public static void offer(\n+      ArtifactRetrievalService retrievalService,\n+      ArtifactStagingServiceGrpc.ArtifactStagingServiceStub stagingService,\n+      String stagingToken)\n+      throws InterruptedException, IOException {\n+    StagingRequestObserver requestObserver = new StagingRequestObserver(retrievalService);\n+    requestObserver.responseObserver =\n+        stagingService.reverseArtifactRetrievalService(requestObserver);\n+    requestObserver.responseObserver.onNext(\n+        ArtifactApi.ArtifactResponseWrapper.newBuilder().setStagingToken(stagingToken).build());\n+    requestObserver.waitUntilDone();\n+    if (requestObserver.error != null) {\n+      if (requestObserver.error instanceof IOException) {\n+        throw (IOException) requestObserver.error;\n+      } else {\n+        throw new IOException(requestObserver.error);\n+      }\n+    }\n+  }\n+\n+  /** Actually implements the reverse retrieval protocol. */\n+  private static class StagingRequestObserver\n+      implements StreamObserver<ArtifactApi.ArtifactRequestWrapper> {\n+\n+    private ArtifactRetrievalService retrievalService;\n+\n+    public StagingRequestObserver(ArtifactRetrievalService retrievalService) {\n+      this.retrievalService = retrievalService;\n+    }\n+\n+    CountDownLatch latch = new CountDownLatch(1);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDUxMTQ0MA=="}, "originalCommit": {"oid": "9c8718e46a3692034de9c9a9ed0754bab325cec5"}, "originalPosition": 526}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDY2MDA5MA==", "bodyText": "Refactored.", "url": "https://github.com/apache/beam/pull/11342#discussion_r410660090", "createdAt": "2020-04-18T07:04:28Z", "author": {"login": "robertwb"}, "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/artifact/ArtifactStagingService.java", "diffHunk": "@@ -0,0 +1,606 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.fnexecution.artifact;\n+\n+import com.google.auto.value.AutoValue;\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.channels.Channels;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.FutureTask;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactApi;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactStagingServiceGrpc;\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+import org.apache.beam.runners.fnexecution.FnService;\n+import org.apache.beam.sdk.io.FileSystems;\n+import org.apache.beam.sdk.io.fs.ResolveOptions;\n+import org.apache.beam.sdk.io.fs.ResourceId;\n+import org.apache.beam.sdk.util.MimeTypes;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.ByteString;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.InvalidProtocolBufferException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.Status;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.StatusException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.stub.StreamObserver;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Splitter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class ArtifactStagingService\n+    extends ArtifactStagingServiceGrpc.ArtifactStagingServiceImplBase implements FnService {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(ArtifactStagingService.class);\n+\n+  private final ArtifactDestinationProvider destinationProvider;\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> toStage =\n+      new ConcurrentHashMap<>();\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> staged =\n+      new ConcurrentHashMap<>();\n+\n+  public ArtifactStagingService(ArtifactDestinationProvider destinationProvider) {\n+    this.destinationProvider = destinationProvider;\n+  }\n+\n+  /**\n+   * Registers a set of artifacts to be staged with this service.\n+   *\n+   * <p>A client (e.g. a Beam SDK) is expected to connect to this service with the given staging\n+   * token and offer resolution and retrieval of this set of artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   * @param artifacts all artifacts to stage, keyed by environment\n+   */\n+  public void registerJob(\n+      String stagingToken, Map<String, List<RunnerApi.ArtifactInformation>> artifacts) {\n+    assert !toStage.containsKey(stagingToken);\n+    toStage.put(stagingToken, artifacts);\n+  }\n+\n+  /**\n+   * Returns the rewritten artifacts associated with this job, keyed by environment.\n+   *\n+   * <p>This should be called after the client has finished offering artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   */\n+  public Map<String, List<RunnerApi.ArtifactInformation>> getStagedArtifacts(String stagingToken) {\n+    toStage.remove(stagingToken);\n+    return staged.remove(stagingToken);\n+  }\n+\n+  /** Provides a concrete location to which artifacts can be staged on retrieval. */\n+  public interface ArtifactDestinationProvider {\n+    ArtifactDestination getDestination(String stagingToken, String name) throws IOException;\n+  }\n+\n+  /**\n+   * A pairing of a newly created artifact type and an ouptut stream that will be readable at that\n+   * type.\n+   */\n+  @AutoValue\n+  public abstract static class ArtifactDestination {\n+    public static ArtifactDestination create(\n+        String typeUrn, ByteString typePayload, OutputStream out) {\n+      return new AutoValue_ArtifactStagingService_ArtifactDestination(typeUrn, typePayload, out);\n+    }\n+\n+    public static ArtifactDestination fromFile(String path) throws IOException {\n+      return fromFile(\n+          path,\n+          Channels.newOutputStream(\n+              FileSystems.create(\n+                  FileSystems.matchNewResource(path, false /* isDirectory */), MimeTypes.BINARY)));\n+    }\n+\n+    public static ArtifactDestination fromFile(String path, OutputStream out) {\n+      return create(\n+          ArtifactRetrievalService.FILE_ARTIFACT_URN,\n+          RunnerApi.ArtifactFilePayload.newBuilder().setPath(path).build().toByteString(),\n+          out);\n+    }\n+\n+    public abstract String getTypeUrn();\n+\n+    public abstract ByteString getTypePayload();\n+\n+    public abstract OutputStream getOutputStream();\n+  }\n+\n+  /**\n+   * An ArtifactDestinationProvider that places new artifacts as files in a Beam filesystem.\n+   *\n+   * @param root the directory in which to place all artifacts\n+   */\n+  public static ArtifactDestinationProvider beamFilesystemArtifactDestinationProvider(String root) {\n+    return (statingToken, name) -> {\n+      ResourceId path =\n+          FileSystems.matchNewResource(root, true)\n+              .resolve(statingToken, ResolveOptions.StandardResolveOptions.RESOLVE_DIRECTORY)\n+              .resolve(name, ResolveOptions.StandardResolveOptions.RESOLVE_FILE);\n+      return ArtifactDestination.fromFile(path.toString());\n+    };\n+  }\n+\n+  private enum State {\n+    START,\n+    RESOLVE,\n+    GET,\n+    GETCHUNK,\n+    DONE,\n+    ERROR,\n+  }\n+\n+  /**\n+   * Like the standard Semaphore, but allows an aquire to go over the limit if there is any room.\n+   *\n+   * <p>Also allows setting an error, to avoid issues with un-released aquires after error.\n+   */\n+  private static class OverflowingSemaphore {\n+    private int totalPermits;\n+    private int usedPermits;\n+    private Exception exception;\n+\n+    public OverflowingSemaphore(int totalPermits) {\n+      this.totalPermits = totalPermits;\n+      this.usedPermits = 0;\n+    }\n+\n+    synchronized void aquire(int permits) throws Exception {\n+      while (usedPermits >= totalPermits) {\n+        if (exception != null) {\n+          throw exception;\n+        }\n+        this.wait();\n+      }\n+      usedPermits += permits;\n+    }\n+\n+    synchronized void release(int permits) {\n+      usedPermits -= permits;\n+      this.notifyAll();\n+    }\n+\n+    synchronized void setException(Exception exception) {\n+      this.exception = exception;\n+      this.notifyAll();\n+    }\n+  }\n+\n+  /** A task that pulls bytes off a queue and actually writes them to a staging location. */\n+  private class StoreArtifact implements Callable<RunnerApi.ArtifactInformation> {\n+\n+    private String stagingToken;\n+    private String name;\n+    private RunnerApi.ArtifactInformation originalArtifact;\n+    private BlockingQueue<ByteString> bytesQueue;\n+    private OverflowingSemaphore totalPendingBytes;\n+\n+    public StoreArtifact(\n+        String stagingToken,\n+        String name,\n+        RunnerApi.ArtifactInformation originalArtifact,\n+        BlockingQueue<ByteString> bytesQueue,\n+        OverflowingSemaphore totalPendingBytes) {\n+      this.stagingToken = stagingToken;\n+      this.name = name;\n+      this.originalArtifact = originalArtifact;\n+      this.bytesQueue = bytesQueue;\n+      this.totalPendingBytes = totalPendingBytes;\n+    }\n+\n+    @Override\n+    public RunnerApi.ArtifactInformation call() throws IOException {\n+      try {\n+        ArtifactDestination dest = destinationProvider.getDestination(stagingToken, name);\n+        LOG.debug(\"Storing artifact for {}.{} at {}\", stagingToken, name, dest);\n+        ByteString chunk = bytesQueue.take();\n+        while (chunk.size() > 0) {\n+          totalPendingBytes.release(chunk.size());\n+          dest.getOutputStream().write(chunk.toByteArray());\n+          chunk = bytesQueue.take();\n+        }\n+        dest.getOutputStream().close();\n+        return originalArtifact\n+            .toBuilder()\n+            .setTypeUrn(dest.getTypeUrn())\n+            .setTypePayload(dest.getTypePayload())\n+            .build();\n+      } catch (IOException | InterruptedException exn) {\n+        // As this thread will no longer be draining the queue, we don't want to get stuck writing\n+        // to it.\n+        totalPendingBytes.setException(exn);\n+        LOG.error(\"Exception staging artifacts\", exn);\n+        if (exn instanceof IOException) {\n+          throw (IOException) exn;\n+        } else {\n+          throw new RuntimeException(exn);\n+        }\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public StreamObserver<ArtifactApi.ArtifactResponseWrapper> reverseArtifactRetrievalService(\n+      StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+\n+    return new StreamObserver<ArtifactApi.ArtifactResponseWrapper>() {\n+\n+      /** The maximum number of parallel threads to use to stage. */\n+      public static final int THREAD_POOL_SIZE = 10;\n+\n+      /** The maximum number of bytes to buffer across all writes before throttling. */\n+      public static final int MAX_PENDING_BYTES = 100 << 20; // 100 MB\n+\n+      String stagingToken;\n+      Map<String, List<RunnerApi.ArtifactInformation>> toResolve;\n+      Map<String, List<Future<RunnerApi.ArtifactInformation>>> stagedFutures;\n+      ExecutorService stagingExecutor;\n+      OverflowingSemaphore totalPendingBytes;\n+\n+      State state = State.START;\n+      Queue<String> pendingResolves;\n+      String currentEnvironment;\n+      int nameIndex;\n+      Queue<RunnerApi.ArtifactInformation> pendingGets;\n+      BlockingQueue<ByteString> currentOutput;\n+\n+      @Override\n+      @SuppressFBWarnings(value = \"SF_SWITCH_FALLTHROUGH\", justification = \"fallthrough intended\")\n+      public synchronized void onNext(ArtifactApi.ArtifactResponseWrapper responseWrapper) {\n+        switch (state) {\n+          case START:\n+            stagingToken = responseWrapper.getStagingToken();\n+            LOG.info(\"Staging artifacts for {}.\", stagingToken);\n+            toResolve = toStage.get(stagingToken);\n+            stagedFutures = new ConcurrentHashMap<>();\n+            pendingResolves = new ArrayDeque<>();\n+            pendingResolves.addAll(toResolve.keySet());\n+            stagingExecutor = Executors.newFixedThreadPool(THREAD_POOL_SIZE);\n+            totalPendingBytes = new OverflowingSemaphore(MAX_PENDING_BYTES);\n+            resolveNextEnvironment(responseObserver);\n+            break;\n+\n+          case RESOLVE:\n+            {\n+              currentEnvironment = pendingResolves.remove();\n+              stagedFutures.put(currentEnvironment, new ArrayList<>());\n+              pendingGets = new ArrayDeque<>();\n+              for (RunnerApi.ArtifactInformation artifact :\n+                  responseWrapper.getResolveArtifactResponse().getReplacementsList()) {\n+                Optional<RunnerApi.ArtifactInformation> fetched = getLocal(artifact);\n+                if (fetched.isPresent()) {\n+                  stagedFutures\n+                      .get(currentEnvironment)\n+                      .add(new FutureTask<RunnerApi.ArtifactInformation>(() -> fetched.get()));\n+                } else {\n+                  pendingGets.add(artifact);\n+                  responseObserver.onNext(\n+                      ArtifactApi.ArtifactRequestWrapper.newBuilder()\n+                          .setGetArtifact(\n+                              ArtifactApi.GetArtifactRequest.newBuilder().setArtifact(artifact))\n+                          .build());\n+                }\n+              }\n+              LOG.info(\n+                  \"Getting {} artifacts for {}.{}.\",\n+                  pendingGets.size(),\n+                  stagingToken,\n+                  pendingResolves.peek());\n+              if (pendingGets.isEmpty()) {\n+                resolveNextEnvironment(responseObserver);\n+              } else {\n+                state = State.GET;\n+              }\n+              break;\n+            }\n+\n+          case GET:\n+            RunnerApi.ArtifactInformation currentArtifact = pendingGets.remove();\n+            String name = createFilename(nameIndex++, currentEnvironment, currentArtifact);\n+            try {\n+              LOG.debug(\"Storing artifacts for {} as {}\", stagingToken, name);\n+              currentOutput = new ArrayBlockingQueue<ByteString>(100);\n+              stagedFutures\n+                  .get(currentEnvironment)\n+                  .add(\n+                      stagingExecutor.submit(\n+                          new StoreArtifact(\n+                              stagingToken,\n+                              name,\n+                              currentArtifact,\n+                              currentOutput,\n+                              totalPendingBytes)));\n+            } catch (Exception exn) {\n+              LOG.error(\"Error submitting.\", exn);\n+              responseObserver.onError(exn);\n+            }\n+            state = State.GETCHUNK;\n+            // fall through\n+\n+          case GETCHUNK:\n+            try {\n+              ByteString chunk = responseWrapper.getGetArtifactResponse().getData();\n+              if (chunk.size() > 0) {\n+                totalPendingBytes.aquire(chunk.size());\n+                currentOutput.put(chunk);\n+              }\n+              if (responseWrapper.getIsLast()) {\n+                currentOutput.put(ByteString.EMPTY); // The EOF value.\n+                if (pendingGets.isEmpty()) {\n+                  resolveNextEnvironment(responseObserver);\n+                } else {\n+                  state = State.GET;\n+                  LOG.debug(\"Waiting for {}\", pendingGets.peek());\n+                }\n+              }\n+            } catch (Exception exn) {\n+              LOG.error(\"Error submitting.\", exn);\n+              onError(exn);\n+            }\n+            break;\n+\n+          default:\n+            responseObserver.onError(\n+                new StatusException(\n+                    Status.INVALID_ARGUMENT.withDescription(\"Illegal state \" + state)));\n+        }\n+      }\n+\n+      private void resolveNextEnvironment(\n+          StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+        if (pendingResolves.isEmpty()) {\n+          finishStaging(responseObserver);\n+        } else {\n+          state = State.RESOLVE;\n+          LOG.info(\"Resolving artifacts for {}.{}.\", stagingToken, pendingResolves.peek());\n+          responseObserver.onNext(\n+              ArtifactApi.ArtifactRequestWrapper.newBuilder()\n+                  .setResolveArtifact(\n+                      ArtifactApi.ResolveArtifactsRequest.newBuilder()\n+                          .addAllArtifacts(toResolve.get(pendingResolves.peek())))\n+                  .build());\n+        }\n+      }\n+\n+      private void finishStaging(\n+          StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+        LOG.debug(\"Finishing staging for {}.\", stagingToken);\n+        Map<String, List<RunnerApi.ArtifactInformation>> staged = new HashMap<>();\n+        try {\n+          for (Map.Entry<String, List<Future<RunnerApi.ArtifactInformation>>> entry :\n+              stagedFutures.entrySet()) {\n+            List<RunnerApi.ArtifactInformation> envStaged = new ArrayList<>();\n+            for (Future<RunnerApi.ArtifactInformation> future : entry.getValue()) {\n+              envStaged.add(future.get());\n+            }\n+            staged.put(entry.getKey(), envStaged);\n+          }\n+          ArtifactStagingService.this.staged.put(stagingToken, staged);\n+          stagingExecutor.shutdown();\n+          state = State.DONE;\n+          LOG.info(\"Artifacts fully staged for {}.\", stagingToken);\n+          responseObserver.onCompleted();\n+        } catch (Exception exn) {\n+          LOG.error(\"Error staging artifacts\", exn);\n+          responseObserver.onError(exn);\n+          state = State.ERROR;\n+          return;\n+        }\n+      }\n+\n+      /**\n+       * Return an alternative artifact if we do not need to get this over the artifact API, or\n+       * possibly at all.\n+       */\n+      private Optional<RunnerApi.ArtifactInformation> getLocal(\n+          RunnerApi.ArtifactInformation artifact) {\n+        return Optional.empty();\n+      }\n+\n+      /**\n+       * Attempts to provide a reasonable filename for the artifact.\n+       *\n+       * @param index a monotonically increasing index, which provides uniqueness\n+       * @param environment the environment id\n+       * @param artifact the artifact itself\n+       */\n+      private String createFilename(\n+          int index, String environment, RunnerApi.ArtifactInformation artifact) {\n+        String path;\n+        try {\n+          if (artifact.getRoleUrn().equals(ArtifactRetrievalService.STAGING_TO_ARTIFACT_URN)) {\n+            path =\n+                RunnerApi.ArtifactStagingToRolePayload.parseFrom(artifact.getRolePayload())\n+                    .getStagedName();\n+          } else if (artifact.getTypeUrn().equals(ArtifactRetrievalService.FILE_ARTIFACT_URN)) {\n+            path = RunnerApi.ArtifactFilePayload.parseFrom(artifact.getTypePayload()).getPath();\n+          } else if (artifact.getTypeUrn().equals(ArtifactRetrievalService.URL_ARTIFACT_URN)) {\n+            path = RunnerApi.ArtifactUrlPayload.parseFrom(artifact.getTypePayload()).getUrl();\n+          } else {\n+            path = \"artifact\";\n+          }\n+        } catch (InvalidProtocolBufferException exn) {\n+          throw new RuntimeException(exn);\n+        }\n+        // Limit to the last contiguous alpha-numeric sequence. In particular, this will exclude\n+        // all path separators.\n+        List<String> components = Splitter.onPattern(\"[^A-Za-z-_.]]\").splitToList(path);\n+        String base = components.get(components.size() - 1);\n+        return clip(String.format(\"%d-%s-%s\", index, clip(environment, 25), base), 100);\n+      }\n+\n+      private String clip(String s, int maxLength) {\n+        return s.length() < maxLength ? s : s.substring(0, maxLength);\n+      }\n+\n+      @Override\n+      public void onError(Throwable throwable) {\n+        stagingExecutor.shutdownNow();\n+        LOG.error(\"Error staging artifacts\", throwable);\n+        state = State.ERROR;\n+      }\n+\n+      @Override\n+      public void onCompleted() {\n+        assert state == State.DONE;\n+      }\n+    };\n+  }\n+\n+  @Override\n+  public void close() throws Exception {\n+    // Nothing to close.\n+  }\n+\n+  /**\n+   * Lazily stages artifacts by letting an ArtifactStagingService resolve and request artifacts.\n+   *\n+   * @param retrievalService an ArtifactRetrievalService used to resolve and retrieve artifacts\n+   * @param stagingService an ArtifactStagingService stub which will request artifacts\n+   * @param stagingToken the staging token of the job whose artifacts will be retrieved\n+   * @throws InterruptedException\n+   * @throws IOException\n+   */\n+  public static void offer(\n+      ArtifactRetrievalService retrievalService,\n+      ArtifactStagingServiceGrpc.ArtifactStagingServiceStub stagingService,\n+      String stagingToken)\n+      throws InterruptedException, IOException {\n+    StagingRequestObserver requestObserver = new StagingRequestObserver(retrievalService);\n+    requestObserver.responseObserver =\n+        stagingService.reverseArtifactRetrievalService(requestObserver);\n+    requestObserver.responseObserver.onNext(\n+        ArtifactApi.ArtifactResponseWrapper.newBuilder().setStagingToken(stagingToken).build());\n+    requestObserver.waitUntilDone();\n+    if (requestObserver.error != null) {\n+      if (requestObserver.error instanceof IOException) {\n+        throw (IOException) requestObserver.error;\n+      } else {\n+        throw new IOException(requestObserver.error);\n+      }\n+    }\n+  }\n+\n+  /** Actually implements the reverse retrieval protocol. */\n+  private static class StagingRequestObserver\n+      implements StreamObserver<ArtifactApi.ArtifactRequestWrapper> {\n+\n+    private ArtifactRetrievalService retrievalService;\n+\n+    public StagingRequestObserver(ArtifactRetrievalService retrievalService) {\n+      this.retrievalService = retrievalService;\n+    }\n+\n+    CountDownLatch latch = new CountDownLatch(1);\n+    StreamObserver<ArtifactApi.ArtifactResponseWrapper> responseObserver;\n+    Throwable error;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDUwODk3MQ=="}, "originalCommit": {"oid": "9c8718e46a3692034de9c9a9ed0754bab325cec5"}, "originalPosition": 528}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDY2MjA5Mw==", "bodyText": "Ah, didn't know about that one. Done.", "url": "https://github.com/apache/beam/pull/11342#discussion_r410662093", "createdAt": "2020-04-18T07:26:03Z", "author": {"login": "robertwb"}, "path": "runners/java-fn-execution/src/test/java/org/apache/beam/runners/fnexecution/artifact/ArtifactRetrievalServiceTest.java", "diffHunk": "@@ -0,0 +1,137 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.fnexecution.artifact;\n+\n+import static org.junit.Assert.assertEquals;\n+\n+import java.io.IOException;\n+import java.nio.file.Files;\n+import java.nio.file.Path;\n+import java.nio.file.Paths;\n+import java.util.Iterator;\n+import java.util.Map;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactApi;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactRetrievalServiceGrpc;\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+import org.apache.beam.runners.fnexecution.GrpcFnServer;\n+import org.apache.beam.runners.fnexecution.InProcessServerFactory;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.ByteString;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.ManagedChannel;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.inprocess.InProcessChannelBuilder;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Charsets;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Strings;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.JUnit4;\n+\n+@RunWith(JUnit4.class)\n+public class ArtifactRetrievalServiceTest {\n+  private static final int TEST_BUFFER_SIZE = 1 << 10;\n+  private GrpcFnServer<ArtifactRetrievalService> retrievalServer;\n+  private ArtifactRetrievalService retrievalService;\n+  private ArtifactRetrievalServiceGrpc.ArtifactRetrievalServiceStub retrievalStub;\n+  private ArtifactRetrievalServiceGrpc.ArtifactRetrievalServiceBlockingStub retrievalBlockingStub;\n+  private Path stagingDir;\n+  @Rule public TemporaryFolder tempFolder = new TemporaryFolder();\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    retrievalService = new ArtifactRetrievalService(TEST_BUFFER_SIZE);\n+    retrievalServer =\n+        GrpcFnServer.allocatePortAndCreateFor(retrievalService, InProcessServerFactory.create());\n+    ManagedChannel retrievalChannel =", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDUxMzI4Mw=="}, "originalCommit": {"oid": "9c8718e46a3692034de9c9a9ed0754bab325cec5"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDY2MjU1MQ==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/11342#discussion_r410662551", "createdAt": "2020-04-18T07:30:10Z", "author": {"login": "robertwb"}, "path": "runners/java-fn-execution/src/test/java/org/apache/beam/runners/fnexecution/artifact/ArtifactStagingServiceTest.java", "diffHunk": "@@ -0,0 +1,189 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.fnexecution.artifact;\n+\n+import static org.junit.Assert.assertEquals;\n+\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactApi;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactRetrievalServiceGrpc;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactStagingServiceGrpc;\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+import org.apache.beam.runners.fnexecution.GrpcFnServer;\n+import org.apache.beam.runners.fnexecution.InProcessServerFactory;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.ByteString;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.ManagedChannel;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.inprocess.InProcessChannelBuilder;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.stub.StreamObserver;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Strings;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Lists;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.JUnit4;\n+\n+@RunWith(JUnit4.class)\n+public class ArtifactStagingServiceTest {\n+  private static final int TEST_BUFFER_SIZE = 1 << 10;\n+  private GrpcFnServer<ArtifactStagingService> stagingServer;\n+  private ArtifactStagingService stagingService;\n+  private GrpcFnServer<ArtifactRetrievalService> retrievalServer;\n+  private ArtifactRetrievalService retrievalService;\n+  private ArtifactStagingServiceGrpc.ArtifactStagingServiceStub stagingStub;\n+  private ArtifactRetrievalServiceGrpc.ArtifactRetrievalServiceBlockingStub retrievalBlockingStub;\n+  private Path stagingDir;\n+  @Rule public TemporaryFolder tempFolder = new TemporaryFolder();\n+\n+  @Before\n+  public void setUp() throws Exception {\n+    stagingDir = tempFolder.newFolder(\"staging\").toPath();\n+    stagingService =\n+        new ArtifactStagingService(\n+            ArtifactStagingService.beamFilesystemArtifactDestinationProvider(\n+                stagingDir.toString()));\n+    stagingServer =\n+        GrpcFnServer.allocatePortAndCreateFor(stagingService, InProcessServerFactory.create());\n+    ManagedChannel stagingChannel =\n+        InProcessChannelBuilder.forName(stagingServer.getApiServiceDescriptor().getUrl()).build();\n+    stagingStub = ArtifactStagingServiceGrpc.newStub(stagingChannel);\n+\n+    retrievalService = new ArtifactRetrievalService(TEST_BUFFER_SIZE);\n+    retrievalServer =\n+        GrpcFnServer.allocatePortAndCreateFor(retrievalService, InProcessServerFactory.create());\n+    ManagedChannel retrievalChannel =\n+        InProcessChannelBuilder.forName(retrievalServer.getApiServiceDescriptor().getUrl()).build();\n+    retrievalBlockingStub = ArtifactRetrievalServiceGrpc.newBlockingStub(retrievalChannel);\n+  }\n+\n+  private static class FakeArtifactRetrievalService extends ArtifactRetrievalService {\n+\n+    @Override\n+    public void resolveArtifacts(\n+        ArtifactApi.ResolveArtifactsRequest request,\n+        StreamObserver<ArtifactApi.ResolveArtifactsResponse> responseObserver) {\n+      ArtifactApi.ResolveArtifactsResponse.Builder response =\n+          ArtifactApi.ResolveArtifactsResponse.newBuilder();\n+      for (RunnerApi.ArtifactInformation artifact : request.getArtifactsList()) {\n+        if (artifact.getTypeUrn().equals(\"resolved\")) {\n+          response.addReplacements(artifact);\n+        } else if (artifact.getTypeUrn().equals(\"unresolved\")) {\n+          response.addReplacements(artifact.toBuilder().setTypeUrn(\"resolved\").build());\n+        } else {\n+          throw new UnsupportedOperationException(artifact.getTypeUrn());\n+        }\n+      }\n+      responseObserver.onNext(response.build());\n+      responseObserver.onCompleted();\n+    }\n+\n+    @Override\n+    public void getArtifact(\n+        ArtifactApi.GetArtifactRequest request,\n+        StreamObserver<ArtifactApi.GetArtifactResponse> responseObserver) {\n+      if (request.getArtifact().getTypeUrn().equals(\"resolved\")) {\n+        ByteString data = request.getArtifact().getTypePayload();\n+        responseObserver.onNext(\n+            ArtifactApi.GetArtifactResponse.newBuilder().setData(data.substring(0, 1)).build());\n+        responseObserver.onNext(\n+            ArtifactApi.GetArtifactResponse.newBuilder().setData(data.substring(1)).build());\n+        responseObserver.onCompleted();\n+      } else {\n+        throw new UnsupportedOperationException(request.getArtifact().getTypeUrn());\n+      }\n+    }\n+\n+    public static RunnerApi.ArtifactInformation resolvedArtifact(String contents) {\n+      return RunnerApi.ArtifactInformation.newBuilder()\n+          .setTypeUrn(\"resolved\")\n+          .setTypePayload(ByteString.copyFromUtf8(contents))\n+          .setRoleUrn(contents)\n+          .build();\n+    }\n+\n+    public static RunnerApi.ArtifactInformation unresolvedArtifact(String contents) {\n+      return RunnerApi.ArtifactInformation.newBuilder()\n+          .setTypeUrn(\"unresolved\")\n+          .setTypePayload(ByteString.copyFromUtf8(contents))\n+          .setRoleUrn(contents)\n+          .build();\n+    }\n+  }\n+\n+  private String getArtifact(RunnerApi.ArtifactInformation artifact) {\n+    ByteString all = ByteString.EMPTY;\n+    Iterator<ArtifactApi.GetArtifactResponse> response =\n+        retrievalBlockingStub.getArtifact(\n+            ArtifactApi.GetArtifactRequest.newBuilder().setArtifact(artifact).build());\n+    while (response.hasNext()) {\n+      all = all.concat(response.next().getData());\n+    }\n+    return all.toStringUtf8();\n+  }\n+\n+  @Test\n+  public void testStageArtifacts() throws IOException, InterruptedException {\n+    List<String> contentsList =\n+        ImmutableList.of(\"a\", \"bb\", Strings.repeat(\"xyz\", TEST_BUFFER_SIZE * 3 / 4));\n+    stagingService.registerJob(\n+        \"stagingToken\",\n+        ImmutableMap.of(\n+            \"env1\",\n+            Lists.transform(contentsList, FakeArtifactRetrievalService::resolvedArtifact),\n+            \"env2\",\n+            Lists.transform(contentsList, FakeArtifactRetrievalService::unresolvedArtifact)));\n+    ArtifactStagingService.offer(new FakeArtifactRetrievalService(), stagingStub, \"stagingToken\");\n+    Map<String, List<RunnerApi.ArtifactInformation>> staged =\n+        stagingService.getStagedArtifacts(\"stagingToken\");\n+    assertEquals(2, staged.size());\n+    checkArtifacts(contentsList, staged.get(\"env1\"));\n+    checkArtifacts(contentsList, staged.get(\"env2\"));\n+  }\n+\n+  private void checkArtifacts(\n+      Collection<String> expetedContents, List<RunnerApi.ArtifactInformation> staged) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDUxMzA3Mg=="}, "originalCommit": {"oid": "9c8718e46a3692034de9c9a9ed0754bab325cec5"}, "originalPosition": 168}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDY2MjU3OQ==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/11342#discussion_r410662579", "createdAt": "2020-04-18T07:30:17Z", "author": {"login": "robertwb"}, "path": "runners/java-fn-execution/src/test/java/org/apache/beam/runners/fnexecution/artifact/ArtifactStagingServiceTest.java", "diffHunk": "@@ -0,0 +1,189 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.fnexecution.artifact;\n+\n+import static org.junit.Assert.assertEquals;\n+\n+import java.io.IOException;\n+import java.nio.file.Path;\n+import java.util.Collection;\n+import java.util.Iterator;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactApi;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactRetrievalServiceGrpc;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactStagingServiceGrpc;\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+import org.apache.beam.runners.fnexecution.GrpcFnServer;\n+import org.apache.beam.runners.fnexecution.InProcessServerFactory;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.ByteString;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.ManagedChannel;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.inprocess.InProcessChannelBuilder;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.stub.StreamObserver;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Strings;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableList;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.Lists;\n+import org.junit.After;\n+import org.junit.Before;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.JUnit4;\n+\n+@RunWith(JUnit4.class)\n+public class ArtifactStagingServiceTest {\n+  private static final int TEST_BUFFER_SIZE = 1 << 10;\n+  private GrpcFnServer<ArtifactStagingService> stagingServer;\n+  private ArtifactStagingService stagingService;\n+  private GrpcFnServer<ArtifactRetrievalService> retrievalServer;\n+  private ArtifactRetrievalService retrievalService;\n+  private ArtifactStagingServiceGrpc.ArtifactStagingServiceStub stagingStub;\n+  private ArtifactRetrievalServiceGrpc.ArtifactRetrievalServiceBlockingStub retrievalBlockingStub;\n+  private Path stagingDir;\n+  @Rule public TemporaryFolder tempFolder = new TemporaryFolder();\n+\n+  @Before\n+  public void setUp() throws Exception {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDUxMzI1OA=="}, "originalCommit": {"oid": "9c8718e46a3692034de9c9a9ed0754bab325cec5"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDY2MjYzNw==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/11342#discussion_r410662637", "createdAt": "2020-04-18T07:30:59Z", "author": {"login": "robertwb"}, "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/artifact/ArtifactStagingService.java", "diffHunk": "@@ -0,0 +1,606 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.fnexecution.artifact;\n+\n+import com.google.auto.value.AutoValue;\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.channels.Channels;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.FutureTask;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactApi;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactStagingServiceGrpc;\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+import org.apache.beam.runners.fnexecution.FnService;\n+import org.apache.beam.sdk.io.FileSystems;\n+import org.apache.beam.sdk.io.fs.ResolveOptions;\n+import org.apache.beam.sdk.io.fs.ResourceId;\n+import org.apache.beam.sdk.util.MimeTypes;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.ByteString;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.InvalidProtocolBufferException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.Status;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.StatusException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.stub.StreamObserver;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Splitter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class ArtifactStagingService\n+    extends ArtifactStagingServiceGrpc.ArtifactStagingServiceImplBase implements FnService {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(ArtifactStagingService.class);\n+\n+  private final ArtifactDestinationProvider destinationProvider;\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> toStage =\n+      new ConcurrentHashMap<>();\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> staged =\n+      new ConcurrentHashMap<>();\n+\n+  public ArtifactStagingService(ArtifactDestinationProvider destinationProvider) {\n+    this.destinationProvider = destinationProvider;\n+  }\n+\n+  /**\n+   * Registers a set of artifacts to be staged with this service.\n+   *\n+   * <p>A client (e.g. a Beam SDK) is expected to connect to this service with the given staging\n+   * token and offer resolution and retrieval of this set of artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   * @param artifacts all artifacts to stage, keyed by environment\n+   */\n+  public void registerJob(\n+      String stagingToken, Map<String, List<RunnerApi.ArtifactInformation>> artifacts) {\n+    assert !toStage.containsKey(stagingToken);\n+    toStage.put(stagingToken, artifacts);\n+  }\n+\n+  /**\n+   * Returns the rewritten artifacts associated with this job, keyed by environment.\n+   *\n+   * <p>This should be called after the client has finished offering artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   */\n+  public Map<String, List<RunnerApi.ArtifactInformation>> getStagedArtifacts(String stagingToken) {\n+    toStage.remove(stagingToken);\n+    return staged.remove(stagingToken);\n+  }\n+\n+  /** Provides a concrete location to which artifacts can be staged on retrieval. */\n+  public interface ArtifactDestinationProvider {\n+    ArtifactDestination getDestination(String stagingToken, String name) throws IOException;\n+  }\n+\n+  /**\n+   * A pairing of a newly created artifact type and an ouptut stream that will be readable at that\n+   * type.\n+   */\n+  @AutoValue\n+  public abstract static class ArtifactDestination {\n+    public static ArtifactDestination create(\n+        String typeUrn, ByteString typePayload, OutputStream out) {\n+      return new AutoValue_ArtifactStagingService_ArtifactDestination(typeUrn, typePayload, out);\n+    }\n+\n+    public static ArtifactDestination fromFile(String path) throws IOException {\n+      return fromFile(\n+          path,\n+          Channels.newOutputStream(\n+              FileSystems.create(\n+                  FileSystems.matchNewResource(path, false /* isDirectory */), MimeTypes.BINARY)));\n+    }\n+\n+    public static ArtifactDestination fromFile(String path, OutputStream out) {\n+      return create(\n+          ArtifactRetrievalService.FILE_ARTIFACT_URN,\n+          RunnerApi.ArtifactFilePayload.newBuilder().setPath(path).build().toByteString(),\n+          out);\n+    }\n+\n+    public abstract String getTypeUrn();\n+\n+    public abstract ByteString getTypePayload();\n+\n+    public abstract OutputStream getOutputStream();\n+  }\n+\n+  /**\n+   * An ArtifactDestinationProvider that places new artifacts as files in a Beam filesystem.\n+   *\n+   * @param root the directory in which to place all artifacts\n+   */\n+  public static ArtifactDestinationProvider beamFilesystemArtifactDestinationProvider(String root) {\n+    return (statingToken, name) -> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwOTA1MzM5MA=="}, "originalCommit": {"oid": "9c8718e46a3692034de9c9a9ed0754bab325cec5"}, "originalPosition": 147}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk4NTQxODU4", "url": "https://github.com/apache/beam/pull/11342#pullrequestreview-398541858", "createdAt": "2020-04-22T20:03:43Z", "commit": {"oid": "7b1429d1c9da5b90e2a91c0052359b1f719df2a1"}, "state": "APPROVED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQyMDowMzo0M1rOGKJLrQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMlQyMDoxNDowOVrOGKJoUA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzI4OTM4OQ==", "bodyText": "Makes sense, just have to be careful is all.", "url": "https://github.com/apache/beam/pull/11342#discussion_r413289389", "createdAt": "2020-04-22T20:03:43Z", "author": {"login": "lukecwik"}, "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/artifact/ArtifactStagingService.java", "diffHunk": "@@ -0,0 +1,606 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.fnexecution.artifact;\n+\n+import com.google.auto.value.AutoValue;\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.channels.Channels;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.FutureTask;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactApi;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactStagingServiceGrpc;\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+import org.apache.beam.runners.fnexecution.FnService;\n+import org.apache.beam.sdk.io.FileSystems;\n+import org.apache.beam.sdk.io.fs.ResolveOptions;\n+import org.apache.beam.sdk.io.fs.ResourceId;\n+import org.apache.beam.sdk.util.MimeTypes;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.ByteString;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.InvalidProtocolBufferException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.Status;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.StatusException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.stub.StreamObserver;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Splitter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class ArtifactStagingService\n+    extends ArtifactStagingServiceGrpc.ArtifactStagingServiceImplBase implements FnService {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(ArtifactStagingService.class);\n+\n+  private final ArtifactDestinationProvider destinationProvider;\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> toStage =\n+      new ConcurrentHashMap<>();\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> staged =\n+      new ConcurrentHashMap<>();\n+\n+  public ArtifactStagingService(ArtifactDestinationProvider destinationProvider) {\n+    this.destinationProvider = destinationProvider;\n+  }\n+\n+  /**\n+   * Registers a set of artifacts to be staged with this service.\n+   *\n+   * <p>A client (e.g. a Beam SDK) is expected to connect to this service with the given staging\n+   * token and offer resolution and retrieval of this set of artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   * @param artifacts all artifacts to stage, keyed by environment\n+   */\n+  public void registerJob(\n+      String stagingToken, Map<String, List<RunnerApi.ArtifactInformation>> artifacts) {\n+    assert !toStage.containsKey(stagingToken);\n+    toStage.put(stagingToken, artifacts);\n+  }\n+\n+  /**\n+   * Returns the rewritten artifacts associated with this job, keyed by environment.\n+   *\n+   * <p>This should be called after the client has finished offering artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   */\n+  public Map<String, List<RunnerApi.ArtifactInformation>> getStagedArtifacts(String stagingToken) {\n+    toStage.remove(stagingToken);\n+    return staged.remove(stagingToken);\n+  }\n+\n+  /** Provides a concrete location to which artifacts can be staged on retrieval. */\n+  public interface ArtifactDestinationProvider {\n+    ArtifactDestination getDestination(String stagingToken, String name) throws IOException;\n+  }\n+\n+  /**\n+   * A pairing of a newly created artifact type and an ouptut stream that will be readable at that\n+   * type.\n+   */\n+  @AutoValue\n+  public abstract static class ArtifactDestination {\n+    public static ArtifactDestination create(\n+        String typeUrn, ByteString typePayload, OutputStream out) {\n+      return new AutoValue_ArtifactStagingService_ArtifactDestination(typeUrn, typePayload, out);\n+    }\n+\n+    public static ArtifactDestination fromFile(String path) throws IOException {\n+      return fromFile(\n+          path,\n+          Channels.newOutputStream(\n+              FileSystems.create(\n+                  FileSystems.matchNewResource(path, false /* isDirectory */), MimeTypes.BINARY)));\n+    }\n+\n+    public static ArtifactDestination fromFile(String path, OutputStream out) {\n+      return create(\n+          ArtifactRetrievalService.FILE_ARTIFACT_URN,\n+          RunnerApi.ArtifactFilePayload.newBuilder().setPath(path).build().toByteString(),\n+          out);\n+    }\n+\n+    public abstract String getTypeUrn();\n+\n+    public abstract ByteString getTypePayload();\n+\n+    public abstract OutputStream getOutputStream();\n+  }\n+\n+  /**\n+   * An ArtifactDestinationProvider that places new artifacts as files in a Beam filesystem.\n+   *\n+   * @param root the directory in which to place all artifacts\n+   */\n+  public static ArtifactDestinationProvider beamFilesystemArtifactDestinationProvider(String root) {\n+    return (statingToken, name) -> {\n+      ResourceId path =\n+          FileSystems.matchNewResource(root, true)\n+              .resolve(statingToken, ResolveOptions.StandardResolveOptions.RESOLVE_DIRECTORY)\n+              .resolve(name, ResolveOptions.StandardResolveOptions.RESOLVE_FILE);\n+      return ArtifactDestination.fromFile(path.toString());\n+    };\n+  }\n+\n+  private enum State {\n+    START,\n+    RESOLVE,\n+    GET,\n+    GETCHUNK,\n+    DONE,\n+    ERROR,\n+  }\n+\n+  /**\n+   * Like the standard Semaphore, but allows an aquire to go over the limit if there is any room.\n+   *\n+   * <p>Also allows setting an error, to avoid issues with un-released aquires after error.\n+   */\n+  private static class OverflowingSemaphore {\n+    private int totalPermits;\n+    private int usedPermits;\n+    private Exception exception;\n+\n+    public OverflowingSemaphore(int totalPermits) {\n+      this.totalPermits = totalPermits;\n+      this.usedPermits = 0;\n+    }\n+\n+    synchronized void aquire(int permits) throws Exception {\n+      while (usedPermits >= totalPermits) {\n+        if (exception != null) {\n+          throw exception;\n+        }\n+        this.wait();\n+      }\n+      usedPermits += permits;\n+    }\n+\n+    synchronized void release(int permits) {\n+      usedPermits -= permits;\n+      this.notifyAll();\n+    }\n+\n+    synchronized void setException(Exception exception) {\n+      this.exception = exception;\n+      this.notifyAll();\n+    }\n+  }\n+\n+  /** A task that pulls bytes off a queue and actually writes them to a staging location. */\n+  private class StoreArtifact implements Callable<RunnerApi.ArtifactInformation> {\n+\n+    private String stagingToken;\n+    private String name;\n+    private RunnerApi.ArtifactInformation originalArtifact;\n+    private BlockingQueue<ByteString> bytesQueue;\n+    private OverflowingSemaphore totalPendingBytes;\n+\n+    public StoreArtifact(\n+        String stagingToken,\n+        String name,\n+        RunnerApi.ArtifactInformation originalArtifact,\n+        BlockingQueue<ByteString> bytesQueue,\n+        OverflowingSemaphore totalPendingBytes) {\n+      this.stagingToken = stagingToken;\n+      this.name = name;\n+      this.originalArtifact = originalArtifact;\n+      this.bytesQueue = bytesQueue;\n+      this.totalPendingBytes = totalPendingBytes;\n+    }\n+\n+    @Override\n+    public RunnerApi.ArtifactInformation call() throws IOException {\n+      try {\n+        ArtifactDestination dest = destinationProvider.getDestination(stagingToken, name);\n+        LOG.debug(\"Storing artifact for {}.{} at {}\", stagingToken, name, dest);\n+        ByteString chunk = bytesQueue.take();\n+        while (chunk.size() > 0) {\n+          totalPendingBytes.release(chunk.size());\n+          dest.getOutputStream().write(chunk.toByteArray());\n+          chunk = bytesQueue.take();\n+        }\n+        dest.getOutputStream().close();\n+        return originalArtifact\n+            .toBuilder()\n+            .setTypeUrn(dest.getTypeUrn())\n+            .setTypePayload(dest.getTypePayload())\n+            .build();\n+      } catch (IOException | InterruptedException exn) {\n+        // As this thread will no longer be draining the queue, we don't want to get stuck writing\n+        // to it.\n+        totalPendingBytes.setException(exn);\n+        LOG.error(\"Exception staging artifacts\", exn);\n+        if (exn instanceof IOException) {\n+          throw (IOException) exn;\n+        } else {\n+          throw new RuntimeException(exn);\n+        }\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public StreamObserver<ArtifactApi.ArtifactResponseWrapper> reverseArtifactRetrievalService(\n+      StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+\n+    return new StreamObserver<ArtifactApi.ArtifactResponseWrapper>() {\n+\n+      /** The maximum number of parallel threads to use to stage. */\n+      public static final int THREAD_POOL_SIZE = 10;\n+\n+      /** The maximum number of bytes to buffer across all writes before throttling. */\n+      public static final int MAX_PENDING_BYTES = 100 << 20; // 100 MB\n+\n+      String stagingToken;\n+      Map<String, List<RunnerApi.ArtifactInformation>> toResolve;\n+      Map<String, List<Future<RunnerApi.ArtifactInformation>>> stagedFutures;\n+      ExecutorService stagingExecutor;\n+      OverflowingSemaphore totalPendingBytes;\n+\n+      State state = State.START;\n+      Queue<String> pendingResolves;\n+      String currentEnvironment;\n+      int nameIndex;\n+      Queue<RunnerApi.ArtifactInformation> pendingGets;\n+      BlockingQueue<ByteString> currentOutput;\n+\n+      @Override\n+      @SuppressFBWarnings(value = \"SF_SWITCH_FALLTHROUGH\", justification = \"fallthrough intended\")\n+      public synchronized void onNext(ArtifactApi.ArtifactResponseWrapper responseWrapper) {\n+        switch (state) {\n+          case START:\n+            stagingToken = responseWrapper.getStagingToken();\n+            LOG.info(\"Staging artifacts for {}.\", stagingToken);\n+            toResolve = toStage.get(stagingToken);\n+            stagedFutures = new ConcurrentHashMap<>();\n+            pendingResolves = new ArrayDeque<>();\n+            pendingResolves.addAll(toResolve.keySet());\n+            stagingExecutor = Executors.newFixedThreadPool(THREAD_POOL_SIZE);\n+            totalPendingBytes = new OverflowingSemaphore(MAX_PENDING_BYTES);\n+            resolveNextEnvironment(responseObserver);\n+            break;\n+\n+          case RESOLVE:\n+            {\n+              currentEnvironment = pendingResolves.remove();\n+              stagedFutures.put(currentEnvironment, new ArrayList<>());\n+              pendingGets = new ArrayDeque<>();\n+              for (RunnerApi.ArtifactInformation artifact :\n+                  responseWrapper.getResolveArtifactResponse().getReplacementsList()) {\n+                Optional<RunnerApi.ArtifactInformation> fetched = getLocal(artifact);\n+                if (fetched.isPresent()) {\n+                  stagedFutures\n+                      .get(currentEnvironment)\n+                      .add(new FutureTask<RunnerApi.ArtifactInformation>(() -> fetched.get()));\n+                } else {\n+                  pendingGets.add(artifact);\n+                  responseObserver.onNext(\n+                      ArtifactApi.ArtifactRequestWrapper.newBuilder()\n+                          .setGetArtifact(\n+                              ArtifactApi.GetArtifactRequest.newBuilder().setArtifact(artifact))\n+                          .build());\n+                }\n+              }\n+              LOG.info(\n+                  \"Getting {} artifacts for {}.{}.\",\n+                  pendingGets.size(),\n+                  stagingToken,\n+                  pendingResolves.peek());\n+              if (pendingGets.isEmpty()) {\n+                resolveNextEnvironment(responseObserver);\n+              } else {\n+                state = State.GET;\n+              }\n+              break;\n+            }\n+\n+          case GET:\n+            RunnerApi.ArtifactInformation currentArtifact = pendingGets.remove();\n+            String name = createFilename(nameIndex++, currentEnvironment, currentArtifact);\n+            try {\n+              LOG.debug(\"Storing artifacts for {} as {}\", stagingToken, name);\n+              currentOutput = new ArrayBlockingQueue<ByteString>(100);\n+              stagedFutures\n+                  .get(currentEnvironment)\n+                  .add(\n+                      stagingExecutor.submit(\n+                          new StoreArtifact(\n+                              stagingToken,\n+                              name,\n+                              currentArtifact,\n+                              currentOutput,\n+                              totalPendingBytes)));\n+            } catch (Exception exn) {\n+              LOG.error(\"Error submitting.\", exn);\n+              responseObserver.onError(exn);\n+            }\n+            state = State.GETCHUNK;\n+            // fall through\n+\n+          case GETCHUNK:\n+            try {\n+              ByteString chunk = responseWrapper.getGetArtifactResponse().getData();\n+              if (chunk.size() > 0) {\n+                totalPendingBytes.aquire(chunk.size());\n+                currentOutput.put(chunk);\n+              }\n+              if (responseWrapper.getIsLast()) {\n+                currentOutput.put(ByteString.EMPTY); // The EOF value.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDUwNTUyNg=="}, "originalCommit": {"oid": "9c8718e46a3692034de9c9a9ed0754bab325cec5"}, "originalPosition": 360}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzI5MjE4NQ==", "bodyText": "I was suggesting using the file separator for escaping so you could create a file name that doesn't contain it and not for figuring out the basename of the file.\nAs you say its optional and this can be improved later by choosing a better file name. Also, the stage_to payload will likely have the original file name + hash.", "url": "https://github.com/apache/beam/pull/11342#discussion_r413292185", "createdAt": "2020-04-22T20:08:00Z", "author": {"login": "lukecwik"}, "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/artifact/ArtifactStagingService.java", "diffHunk": "@@ -0,0 +1,606 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.fnexecution.artifact;\n+\n+import com.google.auto.value.AutoValue;\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.channels.Channels;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.CountDownLatch;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import java.util.concurrent.FutureTask;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactApi;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactStagingServiceGrpc;\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+import org.apache.beam.runners.fnexecution.FnService;\n+import org.apache.beam.sdk.io.FileSystems;\n+import org.apache.beam.sdk.io.fs.ResolveOptions;\n+import org.apache.beam.sdk.io.fs.ResourceId;\n+import org.apache.beam.sdk.util.MimeTypes;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.ByteString;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.InvalidProtocolBufferException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.Status;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.StatusException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.stub.StreamObserver;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Splitter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class ArtifactStagingService\n+    extends ArtifactStagingServiceGrpc.ArtifactStagingServiceImplBase implements FnService {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(ArtifactStagingService.class);\n+\n+  private final ArtifactDestinationProvider destinationProvider;\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> toStage =\n+      new ConcurrentHashMap<>();\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> staged =\n+      new ConcurrentHashMap<>();\n+\n+  public ArtifactStagingService(ArtifactDestinationProvider destinationProvider) {\n+    this.destinationProvider = destinationProvider;\n+  }\n+\n+  /**\n+   * Registers a set of artifacts to be staged with this service.\n+   *\n+   * <p>A client (e.g. a Beam SDK) is expected to connect to this service with the given staging\n+   * token and offer resolution and retrieval of this set of artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   * @param artifacts all artifacts to stage, keyed by environment\n+   */\n+  public void registerJob(\n+      String stagingToken, Map<String, List<RunnerApi.ArtifactInformation>> artifacts) {\n+    assert !toStage.containsKey(stagingToken);\n+    toStage.put(stagingToken, artifacts);\n+  }\n+\n+  /**\n+   * Returns the rewritten artifacts associated with this job, keyed by environment.\n+   *\n+   * <p>This should be called after the client has finished offering artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   */\n+  public Map<String, List<RunnerApi.ArtifactInformation>> getStagedArtifacts(String stagingToken) {\n+    toStage.remove(stagingToken);\n+    return staged.remove(stagingToken);\n+  }\n+\n+  /** Provides a concrete location to which artifacts can be staged on retrieval. */\n+  public interface ArtifactDestinationProvider {\n+    ArtifactDestination getDestination(String stagingToken, String name) throws IOException;\n+  }\n+\n+  /**\n+   * A pairing of a newly created artifact type and an ouptut stream that will be readable at that\n+   * type.\n+   */\n+  @AutoValue\n+  public abstract static class ArtifactDestination {\n+    public static ArtifactDestination create(\n+        String typeUrn, ByteString typePayload, OutputStream out) {\n+      return new AutoValue_ArtifactStagingService_ArtifactDestination(typeUrn, typePayload, out);\n+    }\n+\n+    public static ArtifactDestination fromFile(String path) throws IOException {\n+      return fromFile(\n+          path,\n+          Channels.newOutputStream(\n+              FileSystems.create(\n+                  FileSystems.matchNewResource(path, false /* isDirectory */), MimeTypes.BINARY)));\n+    }\n+\n+    public static ArtifactDestination fromFile(String path, OutputStream out) {\n+      return create(\n+          ArtifactRetrievalService.FILE_ARTIFACT_URN,\n+          RunnerApi.ArtifactFilePayload.newBuilder().setPath(path).build().toByteString(),\n+          out);\n+    }\n+\n+    public abstract String getTypeUrn();\n+\n+    public abstract ByteString getTypePayload();\n+\n+    public abstract OutputStream getOutputStream();\n+  }\n+\n+  /**\n+   * An ArtifactDestinationProvider that places new artifacts as files in a Beam filesystem.\n+   *\n+   * @param root the directory in which to place all artifacts\n+   */\n+  public static ArtifactDestinationProvider beamFilesystemArtifactDestinationProvider(String root) {\n+    return (statingToken, name) -> {\n+      ResourceId path =\n+          FileSystems.matchNewResource(root, true)\n+              .resolve(statingToken, ResolveOptions.StandardResolveOptions.RESOLVE_DIRECTORY)\n+              .resolve(name, ResolveOptions.StandardResolveOptions.RESOLVE_FILE);\n+      return ArtifactDestination.fromFile(path.toString());\n+    };\n+  }\n+\n+  private enum State {\n+    START,\n+    RESOLVE,\n+    GET,\n+    GETCHUNK,\n+    DONE,\n+    ERROR,\n+  }\n+\n+  /**\n+   * Like the standard Semaphore, but allows an aquire to go over the limit if there is any room.\n+   *\n+   * <p>Also allows setting an error, to avoid issues with un-released aquires after error.\n+   */\n+  private static class OverflowingSemaphore {\n+    private int totalPermits;\n+    private int usedPermits;\n+    private Exception exception;\n+\n+    public OverflowingSemaphore(int totalPermits) {\n+      this.totalPermits = totalPermits;\n+      this.usedPermits = 0;\n+    }\n+\n+    synchronized void aquire(int permits) throws Exception {\n+      while (usedPermits >= totalPermits) {\n+        if (exception != null) {\n+          throw exception;\n+        }\n+        this.wait();\n+      }\n+      usedPermits += permits;\n+    }\n+\n+    synchronized void release(int permits) {\n+      usedPermits -= permits;\n+      this.notifyAll();\n+    }\n+\n+    synchronized void setException(Exception exception) {\n+      this.exception = exception;\n+      this.notifyAll();\n+    }\n+  }\n+\n+  /** A task that pulls bytes off a queue and actually writes them to a staging location. */\n+  private class StoreArtifact implements Callable<RunnerApi.ArtifactInformation> {\n+\n+    private String stagingToken;\n+    private String name;\n+    private RunnerApi.ArtifactInformation originalArtifact;\n+    private BlockingQueue<ByteString> bytesQueue;\n+    private OverflowingSemaphore totalPendingBytes;\n+\n+    public StoreArtifact(\n+        String stagingToken,\n+        String name,\n+        RunnerApi.ArtifactInformation originalArtifact,\n+        BlockingQueue<ByteString> bytesQueue,\n+        OverflowingSemaphore totalPendingBytes) {\n+      this.stagingToken = stagingToken;\n+      this.name = name;\n+      this.originalArtifact = originalArtifact;\n+      this.bytesQueue = bytesQueue;\n+      this.totalPendingBytes = totalPendingBytes;\n+    }\n+\n+    @Override\n+    public RunnerApi.ArtifactInformation call() throws IOException {\n+      try {\n+        ArtifactDestination dest = destinationProvider.getDestination(stagingToken, name);\n+        LOG.debug(\"Storing artifact for {}.{} at {}\", stagingToken, name, dest);\n+        ByteString chunk = bytesQueue.take();\n+        while (chunk.size() > 0) {\n+          totalPendingBytes.release(chunk.size());\n+          dest.getOutputStream().write(chunk.toByteArray());\n+          chunk = bytesQueue.take();\n+        }\n+        dest.getOutputStream().close();\n+        return originalArtifact\n+            .toBuilder()\n+            .setTypeUrn(dest.getTypeUrn())\n+            .setTypePayload(dest.getTypePayload())\n+            .build();\n+      } catch (IOException | InterruptedException exn) {\n+        // As this thread will no longer be draining the queue, we don't want to get stuck writing\n+        // to it.\n+        totalPendingBytes.setException(exn);\n+        LOG.error(\"Exception staging artifacts\", exn);\n+        if (exn instanceof IOException) {\n+          throw (IOException) exn;\n+        } else {\n+          throw new RuntimeException(exn);\n+        }\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public StreamObserver<ArtifactApi.ArtifactResponseWrapper> reverseArtifactRetrievalService(\n+      StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+\n+    return new StreamObserver<ArtifactApi.ArtifactResponseWrapper>() {\n+\n+      /** The maximum number of parallel threads to use to stage. */\n+      public static final int THREAD_POOL_SIZE = 10;\n+\n+      /** The maximum number of bytes to buffer across all writes before throttling. */\n+      public static final int MAX_PENDING_BYTES = 100 << 20; // 100 MB\n+\n+      String stagingToken;\n+      Map<String, List<RunnerApi.ArtifactInformation>> toResolve;\n+      Map<String, List<Future<RunnerApi.ArtifactInformation>>> stagedFutures;\n+      ExecutorService stagingExecutor;\n+      OverflowingSemaphore totalPendingBytes;\n+\n+      State state = State.START;\n+      Queue<String> pendingResolves;\n+      String currentEnvironment;\n+      int nameIndex;\n+      Queue<RunnerApi.ArtifactInformation> pendingGets;\n+      BlockingQueue<ByteString> currentOutput;\n+\n+      @Override\n+      @SuppressFBWarnings(value = \"SF_SWITCH_FALLTHROUGH\", justification = \"fallthrough intended\")\n+      public synchronized void onNext(ArtifactApi.ArtifactResponseWrapper responseWrapper) {\n+        switch (state) {\n+          case START:\n+            stagingToken = responseWrapper.getStagingToken();\n+            LOG.info(\"Staging artifacts for {}.\", stagingToken);\n+            toResolve = toStage.get(stagingToken);\n+            stagedFutures = new ConcurrentHashMap<>();\n+            pendingResolves = new ArrayDeque<>();\n+            pendingResolves.addAll(toResolve.keySet());\n+            stagingExecutor = Executors.newFixedThreadPool(THREAD_POOL_SIZE);\n+            totalPendingBytes = new OverflowingSemaphore(MAX_PENDING_BYTES);\n+            resolveNextEnvironment(responseObserver);\n+            break;\n+\n+          case RESOLVE:\n+            {\n+              currentEnvironment = pendingResolves.remove();\n+              stagedFutures.put(currentEnvironment, new ArrayList<>());\n+              pendingGets = new ArrayDeque<>();\n+              for (RunnerApi.ArtifactInformation artifact :\n+                  responseWrapper.getResolveArtifactResponse().getReplacementsList()) {\n+                Optional<RunnerApi.ArtifactInformation> fetched = getLocal(artifact);\n+                if (fetched.isPresent()) {\n+                  stagedFutures\n+                      .get(currentEnvironment)\n+                      .add(new FutureTask<RunnerApi.ArtifactInformation>(() -> fetched.get()));\n+                } else {\n+                  pendingGets.add(artifact);\n+                  responseObserver.onNext(\n+                      ArtifactApi.ArtifactRequestWrapper.newBuilder()\n+                          .setGetArtifact(\n+                              ArtifactApi.GetArtifactRequest.newBuilder().setArtifact(artifact))\n+                          .build());\n+                }\n+              }\n+              LOG.info(\n+                  \"Getting {} artifacts for {}.{}.\",\n+                  pendingGets.size(),\n+                  stagingToken,\n+                  pendingResolves.peek());\n+              if (pendingGets.isEmpty()) {\n+                resolveNextEnvironment(responseObserver);\n+              } else {\n+                state = State.GET;\n+              }\n+              break;\n+            }\n+\n+          case GET:\n+            RunnerApi.ArtifactInformation currentArtifact = pendingGets.remove();\n+            String name = createFilename(nameIndex++, currentEnvironment, currentArtifact);\n+            try {\n+              LOG.debug(\"Storing artifacts for {} as {}\", stagingToken, name);\n+              currentOutput = new ArrayBlockingQueue<ByteString>(100);\n+              stagedFutures\n+                  .get(currentEnvironment)\n+                  .add(\n+                      stagingExecutor.submit(\n+                          new StoreArtifact(\n+                              stagingToken,\n+                              name,\n+                              currentArtifact,\n+                              currentOutput,\n+                              totalPendingBytes)));\n+            } catch (Exception exn) {\n+              LOG.error(\"Error submitting.\", exn);\n+              responseObserver.onError(exn);\n+            }\n+            state = State.GETCHUNK;\n+            // fall through\n+\n+          case GETCHUNK:\n+            try {\n+              ByteString chunk = responseWrapper.getGetArtifactResponse().getData();\n+              if (chunk.size() > 0) {\n+                totalPendingBytes.aquire(chunk.size());\n+                currentOutput.put(chunk);\n+              }\n+              if (responseWrapper.getIsLast()) {\n+                currentOutput.put(ByteString.EMPTY); // The EOF value.\n+                if (pendingGets.isEmpty()) {\n+                  resolveNextEnvironment(responseObserver);\n+                } else {\n+                  state = State.GET;\n+                  LOG.debug(\"Waiting for {}\", pendingGets.peek());\n+                }\n+              }\n+            } catch (Exception exn) {\n+              LOG.error(\"Error submitting.\", exn);\n+              onError(exn);\n+            }\n+            break;\n+\n+          default:\n+            responseObserver.onError(\n+                new StatusException(\n+                    Status.INVALID_ARGUMENT.withDescription(\"Illegal state \" + state)));\n+        }\n+      }\n+\n+      private void resolveNextEnvironment(\n+          StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+        if (pendingResolves.isEmpty()) {\n+          finishStaging(responseObserver);\n+        } else {\n+          state = State.RESOLVE;\n+          LOG.info(\"Resolving artifacts for {}.{}.\", stagingToken, pendingResolves.peek());\n+          responseObserver.onNext(\n+              ArtifactApi.ArtifactRequestWrapper.newBuilder()\n+                  .setResolveArtifact(\n+                      ArtifactApi.ResolveArtifactsRequest.newBuilder()\n+                          .addAllArtifacts(toResolve.get(pendingResolves.peek())))\n+                  .build());\n+        }\n+      }\n+\n+      private void finishStaging(\n+          StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+        LOG.debug(\"Finishing staging for {}.\", stagingToken);\n+        Map<String, List<RunnerApi.ArtifactInformation>> staged = new HashMap<>();\n+        try {\n+          for (Map.Entry<String, List<Future<RunnerApi.ArtifactInformation>>> entry :\n+              stagedFutures.entrySet()) {\n+            List<RunnerApi.ArtifactInformation> envStaged = new ArrayList<>();\n+            for (Future<RunnerApi.ArtifactInformation> future : entry.getValue()) {\n+              envStaged.add(future.get());\n+            }\n+            staged.put(entry.getKey(), envStaged);\n+          }\n+          ArtifactStagingService.this.staged.put(stagingToken, staged);\n+          stagingExecutor.shutdown();\n+          state = State.DONE;\n+          LOG.info(\"Artifacts fully staged for {}.\", stagingToken);\n+          responseObserver.onCompleted();\n+        } catch (Exception exn) {\n+          LOG.error(\"Error staging artifacts\", exn);\n+          responseObserver.onError(exn);\n+          state = State.ERROR;\n+          return;\n+        }\n+      }\n+\n+      /**\n+       * Return an alternative artifact if we do not need to get this over the artifact API, or\n+       * possibly at all.\n+       */\n+      private Optional<RunnerApi.ArtifactInformation> getLocal(\n+          RunnerApi.ArtifactInformation artifact) {\n+        return Optional.empty();\n+      }\n+\n+      /**\n+       * Attempts to provide a reasonable filename for the artifact.\n+       *\n+       * @param index a monotonically increasing index, which provides uniqueness\n+       * @param environment the environment id\n+       * @param artifact the artifact itself\n+       */\n+      private String createFilename(\n+          int index, String environment, RunnerApi.ArtifactInformation artifact) {\n+        String path;\n+        try {\n+          if (artifact.getRoleUrn().equals(ArtifactRetrievalService.STAGING_TO_ARTIFACT_URN)) {\n+            path =\n+                RunnerApi.ArtifactStagingToRolePayload.parseFrom(artifact.getRolePayload())\n+                    .getStagedName();\n+          } else if (artifact.getTypeUrn().equals(ArtifactRetrievalService.FILE_ARTIFACT_URN)) {\n+            path = RunnerApi.ArtifactFilePayload.parseFrom(artifact.getTypePayload()).getPath();\n+          } else if (artifact.getTypeUrn().equals(ArtifactRetrievalService.URL_ARTIFACT_URN)) {\n+            path = RunnerApi.ArtifactUrlPayload.parseFrom(artifact.getTypePayload()).getUrl();\n+          } else {\n+            path = \"artifact\";\n+          }\n+        } catch (InvalidProtocolBufferException exn) {\n+          throw new RuntimeException(exn);\n+        }\n+        // Limit to the last contiguous alpha-numeric sequence. In particular, this will exclude\n+        // all path separators.\n+        List<String> components = Splitter.onPattern(\"[^A-Za-z-_.]]\").splitToList(path);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDUwNzkzOA=="}, "originalCommit": {"oid": "9c8718e46a3692034de9c9a9ed0754bab325cec5"}, "originalPosition": 459}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzI5NDU0MA==", "bodyText": "complete the future with the error?", "url": "https://github.com/apache/beam/pull/11342#discussion_r413294540", "createdAt": "2020-04-22T20:11:43Z", "author": {"login": "lukecwik"}, "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/artifact/ArtifactStagingService.java", "diffHunk": "@@ -0,0 +1,602 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.fnexecution.artifact;\n+\n+import com.google.auto.value.AutoValue;\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.channels.Channels;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactApi;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactStagingServiceGrpc;\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+import org.apache.beam.runners.fnexecution.FnService;\n+import org.apache.beam.sdk.fn.IdGenerator;\n+import org.apache.beam.sdk.fn.IdGenerators;\n+import org.apache.beam.sdk.io.FileSystems;\n+import org.apache.beam.sdk.io.fs.ResolveOptions;\n+import org.apache.beam.sdk.io.fs.ResourceId;\n+import org.apache.beam.sdk.util.MimeTypes;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.ByteString;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.InvalidProtocolBufferException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.Status;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.StatusException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.stub.StreamObserver;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Splitter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class ArtifactStagingService\n+    extends ArtifactStagingServiceGrpc.ArtifactStagingServiceImplBase implements FnService {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(ArtifactStagingService.class);\n+\n+  private final ArtifactDestinationProvider destinationProvider;\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> toStage =\n+      new ConcurrentHashMap<>();\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> staged =\n+      new ConcurrentHashMap<>();\n+\n+  public ArtifactStagingService(ArtifactDestinationProvider destinationProvider) {\n+    this.destinationProvider = destinationProvider;\n+  }\n+\n+  /**\n+   * Registers a set of artifacts to be staged with this service.\n+   *\n+   * <p>A client (e.g. a Beam SDK) is expected to connect to this service with the given staging\n+   * token and offer resolution and retrieval of this set of artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   * @param artifacts all artifacts to stage, keyed by environment\n+   */\n+  public void registerJob(\n+      String stagingToken, Map<String, List<RunnerApi.ArtifactInformation>> artifacts) {\n+    assert !toStage.containsKey(stagingToken);\n+    toStage.put(stagingToken, artifacts);\n+  }\n+\n+  /**\n+   * Returns the rewritten artifacts associated with this job, keyed by environment.\n+   *\n+   * <p>This should be called after the client has finished offering artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   */\n+  public Map<String, List<RunnerApi.ArtifactInformation>> getStagedArtifacts(String stagingToken) {\n+    toStage.remove(stagingToken);\n+    return staged.remove(stagingToken);\n+  }\n+\n+  /** Provides a concrete location to which artifacts can be staged on retrieval. */\n+  public interface ArtifactDestinationProvider {\n+    ArtifactDestination getDestination(String stagingToken, String name) throws IOException;\n+  }\n+\n+  /**\n+   * A pairing of a newly created artifact type and an ouptut stream that will be readable at that\n+   * type.\n+   */\n+  @AutoValue\n+  public abstract static class ArtifactDestination {\n+    public static ArtifactDestination create(\n+        String typeUrn, ByteString typePayload, OutputStream out) {\n+      return new AutoValue_ArtifactStagingService_ArtifactDestination(typeUrn, typePayload, out);\n+    }\n+\n+    public static ArtifactDestination fromFile(String path) throws IOException {\n+      return fromFile(\n+          path,\n+          Channels.newOutputStream(\n+              FileSystems.create(\n+                  FileSystems.matchNewResource(path, false /* isDirectory */), MimeTypes.BINARY)));\n+    }\n+\n+    public static ArtifactDestination fromFile(String path, OutputStream out) {\n+      return create(\n+          ArtifactRetrievalService.FILE_ARTIFACT_URN,\n+          RunnerApi.ArtifactFilePayload.newBuilder().setPath(path).build().toByteString(),\n+          out);\n+    }\n+\n+    public abstract String getTypeUrn();\n+\n+    public abstract ByteString getTypePayload();\n+\n+    public abstract OutputStream getOutputStream();\n+  }\n+\n+  /**\n+   * An ArtifactDestinationProvider that places new artifacts as files in a Beam filesystem.\n+   *\n+   * @param root the directory in which to place all artifacts\n+   */\n+  public static ArtifactDestinationProvider beamFilesystemArtifactDestinationProvider(String root) {\n+    return (stagingToken, name) -> {\n+      ResourceId path =\n+          FileSystems.matchNewResource(root, true)\n+              .resolve(stagingToken, ResolveOptions.StandardResolveOptions.RESOLVE_DIRECTORY)\n+              .resolve(name, ResolveOptions.StandardResolveOptions.RESOLVE_FILE);\n+      return ArtifactDestination.fromFile(path.toString());\n+    };\n+  }\n+\n+  private enum State {\n+    START,\n+    RESOLVE,\n+    GET,\n+    GETCHUNK,\n+    DONE,\n+    ERROR,\n+  }\n+\n+  /**\n+   * Like the standard Semaphore, but allows an aquire to go over the limit if there is any room.\n+   *\n+   * <p>Also allows setting an error, to avoid issues with un-released aquires after error.\n+   */\n+  private static class OverflowingSemaphore {\n+    private int totalPermits;\n+    private int usedPermits;\n+    private Exception exception;\n+\n+    public OverflowingSemaphore(int totalPermits) {\n+      this.totalPermits = totalPermits;\n+      this.usedPermits = 0;\n+    }\n+\n+    synchronized void aquire(int permits) throws Exception {\n+      while (usedPermits >= totalPermits) {\n+        if (exception != null) {\n+          throw exception;\n+        }\n+        this.wait();\n+      }\n+      usedPermits += permits;\n+    }\n+\n+    synchronized void release(int permits) {\n+      usedPermits -= permits;\n+      this.notifyAll();\n+    }\n+\n+    synchronized void setException(Exception exception) {\n+      this.exception = exception;\n+      this.notifyAll();\n+    }\n+  }\n+\n+  /** A task that pulls bytes off a queue and actually writes them to a staging location. */\n+  private class StoreArtifact implements Callable<RunnerApi.ArtifactInformation> {\n+\n+    private String stagingToken;\n+    private String name;\n+    private RunnerApi.ArtifactInformation originalArtifact;\n+    private BlockingQueue<ByteString> bytesQueue;\n+    private OverflowingSemaphore totalPendingBytes;\n+\n+    public StoreArtifact(\n+        String stagingToken,\n+        String name,\n+        RunnerApi.ArtifactInformation originalArtifact,\n+        BlockingQueue<ByteString> bytesQueue,\n+        OverflowingSemaphore totalPendingBytes) {\n+      this.stagingToken = stagingToken;\n+      this.name = name;\n+      this.originalArtifact = originalArtifact;\n+      this.bytesQueue = bytesQueue;\n+      this.totalPendingBytes = totalPendingBytes;\n+    }\n+\n+    @Override\n+    public RunnerApi.ArtifactInformation call() throws IOException {\n+      try {\n+        ArtifactDestination dest = destinationProvider.getDestination(stagingToken, name);\n+        LOG.debug(\"Storing artifact for {}.{} at {}\", stagingToken, name, dest);\n+        ByteString chunk = bytesQueue.take();\n+        while (chunk.size() > 0) {\n+          totalPendingBytes.release(chunk.size());\n+          chunk.writeTo(dest.getOutputStream());\n+          chunk = bytesQueue.take();\n+        }\n+        dest.getOutputStream().close();\n+        return originalArtifact\n+            .toBuilder()\n+            .setTypeUrn(dest.getTypeUrn())\n+            .setTypePayload(dest.getTypePayload())\n+            .build();\n+      } catch (IOException | InterruptedException exn) {\n+        // As this thread will no longer be draining the queue, we don't want to get stuck writing\n+        // to it.\n+        totalPendingBytes.setException(exn);\n+        LOG.error(\"Exception staging artifacts\", exn);\n+        if (exn instanceof IOException) {\n+          throw (IOException) exn;\n+        } else {\n+          throw new RuntimeException(exn);\n+        }\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public StreamObserver<ArtifactApi.ArtifactResponseWrapper> reverseArtifactRetrievalService(\n+      StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+\n+    return new StreamObserver<ArtifactApi.ArtifactResponseWrapper>() {\n+\n+      /** The maximum number of parallel threads to use to stage. */\n+      public static final int THREAD_POOL_SIZE = 10;\n+\n+      /** The maximum number of bytes to buffer across all writes before throttling. */\n+      public static final int MAX_PENDING_BYTES = 100 << 20; // 100 MB\n+\n+      IdGenerator idGenerator = IdGenerators.incrementingLongs();\n+\n+      String stagingToken;\n+      Map<String, List<RunnerApi.ArtifactInformation>> toResolve;\n+      Map<String, List<Future<RunnerApi.ArtifactInformation>>> stagedFutures;\n+      ExecutorService stagingExecutor;\n+      OverflowingSemaphore totalPendingBytes;\n+\n+      State state = State.START;\n+      Queue<String> pendingResolves;\n+      String currentEnvironment;\n+      Queue<RunnerApi.ArtifactInformation> pendingGets;\n+      BlockingQueue<ByteString> currentOutput;\n+\n+      @Override\n+      @SuppressFBWarnings(value = \"SF_SWITCH_FALLTHROUGH\", justification = \"fallthrough intended\")\n+      // May be called by different threads for the same request; synchronized for memory\n+      // synchronization.\n+      public synchronized void onNext(ArtifactApi.ArtifactResponseWrapper responseWrapper) {\n+        switch (state) {\n+          case START:\n+            stagingToken = responseWrapper.getStagingToken();\n+            LOG.info(\"Staging artifacts for {}.\", stagingToken);\n+            toResolve = toStage.get(stagingToken);\n+            stagedFutures = new ConcurrentHashMap<>();\n+            pendingResolves = new ArrayDeque<>();\n+            pendingResolves.addAll(toResolve.keySet());\n+            stagingExecutor = Executors.newFixedThreadPool(THREAD_POOL_SIZE);\n+            totalPendingBytes = new OverflowingSemaphore(MAX_PENDING_BYTES);\n+            resolveNextEnvironment(responseObserver);\n+            break;\n+\n+          case RESOLVE:\n+            {\n+              currentEnvironment = pendingResolves.remove();\n+              stagedFutures.put(currentEnvironment, new ArrayList<>());\n+              pendingGets = new ArrayDeque<>();\n+              for (RunnerApi.ArtifactInformation artifact :\n+                  responseWrapper.getResolveArtifactResponse().getReplacementsList()) {\n+                Optional<RunnerApi.ArtifactInformation> fetched = getLocal(artifact);\n+                if (fetched.isPresent()) {\n+                  stagedFutures\n+                      .get(currentEnvironment)\n+                      .add(CompletableFuture.completedFuture(fetched.get()));\n+                } else {\n+                  pendingGets.add(artifact);\n+                  responseObserver.onNext(\n+                      ArtifactApi.ArtifactRequestWrapper.newBuilder()\n+                          .setGetArtifact(\n+                              ArtifactApi.GetArtifactRequest.newBuilder().setArtifact(artifact))\n+                          .build());\n+                }\n+              }\n+              LOG.info(\n+                  \"Getting {} artifacts for {}.{}.\",\n+                  pendingGets.size(),\n+                  stagingToken,\n+                  pendingResolves.peek());\n+              if (pendingGets.isEmpty()) {\n+                resolveNextEnvironment(responseObserver);\n+              } else {\n+                state = State.GET;\n+              }\n+              break;\n+            }\n+\n+          case GET:\n+            RunnerApi.ArtifactInformation currentArtifact = pendingGets.remove();\n+            String name = createFilename(currentEnvironment, currentArtifact);\n+            try {\n+              LOG.debug(\"Storing artifacts for {} as {}\", stagingToken, name);\n+              currentOutput = new ArrayBlockingQueue<ByteString>(100);\n+              stagedFutures\n+                  .get(currentEnvironment)\n+                  .add(\n+                      stagingExecutor.submit(\n+                          new StoreArtifact(\n+                              stagingToken,\n+                              name,\n+                              currentArtifact,\n+                              currentOutput,\n+                              totalPendingBytes)));\n+            } catch (Exception exn) {\n+              LOG.error(\"Error submitting.\", exn);\n+              responseObserver.onError(exn);\n+            }\n+            state = State.GETCHUNK;\n+            // fall through\n+\n+          case GETCHUNK:\n+            try {\n+              ByteString chunk = responseWrapper.getGetArtifactResponse().getData();\n+              if (chunk.size() > 0) { // Make sure we don't accidentally send the EOF value.\n+                totalPendingBytes.aquire(chunk.size());\n+                currentOutput.put(chunk);\n+              }\n+              if (responseWrapper.getIsLast()) {\n+                currentOutput.put(ByteString.EMPTY); // The EOF value.\n+                if (pendingGets.isEmpty()) {\n+                  resolveNextEnvironment(responseObserver);\n+                } else {\n+                  state = State.GET;\n+                  LOG.debug(\"Waiting for {}\", pendingGets.peek());\n+                }\n+              }\n+            } catch (Exception exn) {\n+              LOG.error(\"Error submitting.\", exn);\n+              onError(exn);\n+            }\n+            break;\n+\n+          default:\n+            responseObserver.onError(\n+                new StatusException(\n+                    Status.INVALID_ARGUMENT.withDescription(\"Illegal state \" + state)));\n+        }\n+      }\n+\n+      private void resolveNextEnvironment(\n+          StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+        if (pendingResolves.isEmpty()) {\n+          finishStaging(responseObserver);\n+        } else {\n+          state = State.RESOLVE;\n+          LOG.info(\"Resolving artifacts for {}.{}.\", stagingToken, pendingResolves.peek());\n+          responseObserver.onNext(\n+              ArtifactApi.ArtifactRequestWrapper.newBuilder()\n+                  .setResolveArtifact(\n+                      ArtifactApi.ResolveArtifactsRequest.newBuilder()\n+                          .addAllArtifacts(toResolve.get(pendingResolves.peek())))\n+                  .build());\n+        }\n+      }\n+\n+      private void finishStaging(\n+          StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+        LOG.debug(\"Finishing staging for {}.\", stagingToken);\n+        Map<String, List<RunnerApi.ArtifactInformation>> staged = new HashMap<>();\n+        try {\n+          for (Map.Entry<String, List<Future<RunnerApi.ArtifactInformation>>> entry :\n+              stagedFutures.entrySet()) {\n+            List<RunnerApi.ArtifactInformation> envStaged = new ArrayList<>();\n+            for (Future<RunnerApi.ArtifactInformation> future : entry.getValue()) {\n+              envStaged.add(future.get());\n+            }\n+            staged.put(entry.getKey(), envStaged);\n+          }\n+          ArtifactStagingService.this.staged.put(stagingToken, staged);\n+          stagingExecutor.shutdown();\n+          state = State.DONE;\n+          LOG.info(\"Artifacts fully staged for {}.\", stagingToken);\n+          responseObserver.onCompleted();\n+        } catch (Exception exn) {\n+          LOG.error(\"Error staging artifacts\", exn);\n+          responseObserver.onError(exn);\n+          state = State.ERROR;\n+          return;\n+        }\n+      }\n+\n+      /**\n+       * Return an alternative artifact if we do not need to get this over the artifact API, or\n+       * possibly at all.\n+       */\n+      private Optional<RunnerApi.ArtifactInformation> getLocal(\n+          RunnerApi.ArtifactInformation artifact) {\n+        return Optional.empty();\n+      }\n+\n+      /**\n+       * Attempts to provide a reasonable filename for the artifact.\n+       *\n+       * @param index a monotonically increasing index, which provides uniqueness\n+       * @param environment the environment id\n+       * @param artifact the artifact itself\n+       */\n+      private String createFilename(String environment, RunnerApi.ArtifactInformation artifact) {\n+        String path;\n+        try {\n+          if (artifact.getRoleUrn().equals(ArtifactRetrievalService.STAGING_TO_ARTIFACT_URN)) {\n+            path =\n+                RunnerApi.ArtifactStagingToRolePayload.parseFrom(artifact.getRolePayload())\n+                    .getStagedName();\n+          } else if (artifact.getTypeUrn().equals(ArtifactRetrievalService.FILE_ARTIFACT_URN)) {\n+            path = RunnerApi.ArtifactFilePayload.parseFrom(artifact.getTypePayload()).getPath();\n+          } else if (artifact.getTypeUrn().equals(ArtifactRetrievalService.URL_ARTIFACT_URN)) {\n+            path = RunnerApi.ArtifactUrlPayload.parseFrom(artifact.getTypePayload()).getUrl();\n+          } else {\n+            path = \"artifact\";\n+          }\n+        } catch (InvalidProtocolBufferException exn) {\n+          throw new RuntimeException(exn);\n+        }\n+        // Limit to the last contiguous alpha-numeric sequence. In particular, this will exclude\n+        // all path separators.\n+        List<String> components = Splitter.onPattern(\"[^A-Za-z-_.]]\").splitToList(path);\n+        String base = components.get(components.size() - 1);\n+        return clip(\n+            String.format(\"%s-%s-%s\", idGenerator.getId(), clip(environment, 25), base), 100);\n+      }\n+\n+      private String clip(String s, int maxLength) {\n+        return s.length() < maxLength ? s : s.substring(0, maxLength);\n+      }\n+\n+      @Override\n+      public void onError(Throwable throwable) {\n+        stagingExecutor.shutdownNow();\n+        LOG.error(\"Error staging artifacts\", throwable);\n+        state = State.ERROR;\n+      }\n+\n+      @Override\n+      public void onCompleted() {\n+        Preconditions.checkArgument(state == State.DONE);\n+      }\n+    };\n+  }\n+\n+  @Override\n+  public void close() throws Exception {\n+    // Nothing to close.\n+  }\n+\n+  /**\n+   * Lazily stages artifacts by letting an ArtifactStagingService resolve and request artifacts.\n+   *\n+   * @param retrievalService an ArtifactRetrievalService used to resolve and retrieve artifacts\n+   * @param stagingService an ArtifactStagingService stub which will request artifacts\n+   * @param stagingToken the staging token of the job whose artifacts will be retrieved\n+   * @throws InterruptedException\n+   * @throws IOException\n+   */\n+  public static void offer(\n+      ArtifactRetrievalService retrievalService,\n+      ArtifactStagingServiceGrpc.ArtifactStagingServiceStub stagingService,\n+      String stagingToken)\n+      throws ExecutionException, InterruptedException {\n+    new StagingDriver(retrievalService, stagingService, stagingToken).getCompletionFuture().get();\n+  }\n+\n+  /** Actually implements the reverse retrieval protocol. */\n+  private static class StagingDriver implements StreamObserver<ArtifactApi.ArtifactRequestWrapper> {\n+\n+    private final ArtifactRetrievalService retrievalService;\n+    private final StreamObserver<ArtifactApi.ArtifactResponseWrapper> responseObserver;\n+    private final CompletableFuture<Void> completionFuture;\n+\n+    public StagingDriver(\n+        ArtifactRetrievalService retrievalService,\n+        ArtifactStagingServiceGrpc.ArtifactStagingServiceStub stagingService,\n+        String stagingToken) {\n+      this.retrievalService = retrievalService;\n+      responseObserver = stagingService.reverseArtifactRetrievalService(this);\n+      responseObserver.onNext(\n+          ArtifactApi.ArtifactResponseWrapper.newBuilder().setStagingToken(stagingToken).build());\n+      completionFuture = new CompletableFuture<Void>();\n+    }\n+\n+    public CompletableFuture<?> getCompletionFuture() {\n+      return completionFuture;\n+    }\n+\n+    @Override\n+    public void onNext(ArtifactApi.ArtifactRequestWrapper requestWrapper) {\n+      if (requestWrapper.hasResolveArtifact()) {\n+        retrievalService.resolveArtifacts(\n+            requestWrapper.getResolveArtifact(),\n+            new StreamObserver<ArtifactApi.ResolveArtifactsResponse>() {\n+\n+              @Override\n+              public void onNext(ArtifactApi.ResolveArtifactsResponse resolveArtifactsResponse) {\n+                responseObserver.onNext(\n+                    ArtifactApi.ArtifactResponseWrapper.newBuilder()\n+                        .setResolveArtifactResponse(resolveArtifactsResponse)\n+                        .build());\n+              }\n+\n+              @Override\n+              public void onError(Throwable throwable) {\n+                responseObserver.onError(throwable);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7b1429d1c9da5b90e2a91c0052359b1f719df2a1"}, "originalPosition": 549}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzI5NDY2Mw==", "bodyText": "complete the future with the error?", "url": "https://github.com/apache/beam/pull/11342#discussion_r413294663", "createdAt": "2020-04-22T20:11:51Z", "author": {"login": "lukecwik"}, "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/artifact/ArtifactStagingService.java", "diffHunk": "@@ -0,0 +1,602 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.fnexecution.artifact;\n+\n+import com.google.auto.value.AutoValue;\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.channels.Channels;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactApi;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactStagingServiceGrpc;\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+import org.apache.beam.runners.fnexecution.FnService;\n+import org.apache.beam.sdk.fn.IdGenerator;\n+import org.apache.beam.sdk.fn.IdGenerators;\n+import org.apache.beam.sdk.io.FileSystems;\n+import org.apache.beam.sdk.io.fs.ResolveOptions;\n+import org.apache.beam.sdk.io.fs.ResourceId;\n+import org.apache.beam.sdk.util.MimeTypes;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.ByteString;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.InvalidProtocolBufferException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.Status;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.StatusException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.stub.StreamObserver;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Splitter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class ArtifactStagingService\n+    extends ArtifactStagingServiceGrpc.ArtifactStagingServiceImplBase implements FnService {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(ArtifactStagingService.class);\n+\n+  private final ArtifactDestinationProvider destinationProvider;\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> toStage =\n+      new ConcurrentHashMap<>();\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> staged =\n+      new ConcurrentHashMap<>();\n+\n+  public ArtifactStagingService(ArtifactDestinationProvider destinationProvider) {\n+    this.destinationProvider = destinationProvider;\n+  }\n+\n+  /**\n+   * Registers a set of artifacts to be staged with this service.\n+   *\n+   * <p>A client (e.g. a Beam SDK) is expected to connect to this service with the given staging\n+   * token and offer resolution and retrieval of this set of artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   * @param artifacts all artifacts to stage, keyed by environment\n+   */\n+  public void registerJob(\n+      String stagingToken, Map<String, List<RunnerApi.ArtifactInformation>> artifacts) {\n+    assert !toStage.containsKey(stagingToken);\n+    toStage.put(stagingToken, artifacts);\n+  }\n+\n+  /**\n+   * Returns the rewritten artifacts associated with this job, keyed by environment.\n+   *\n+   * <p>This should be called after the client has finished offering artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   */\n+  public Map<String, List<RunnerApi.ArtifactInformation>> getStagedArtifacts(String stagingToken) {\n+    toStage.remove(stagingToken);\n+    return staged.remove(stagingToken);\n+  }\n+\n+  /** Provides a concrete location to which artifacts can be staged on retrieval. */\n+  public interface ArtifactDestinationProvider {\n+    ArtifactDestination getDestination(String stagingToken, String name) throws IOException;\n+  }\n+\n+  /**\n+   * A pairing of a newly created artifact type and an ouptut stream that will be readable at that\n+   * type.\n+   */\n+  @AutoValue\n+  public abstract static class ArtifactDestination {\n+    public static ArtifactDestination create(\n+        String typeUrn, ByteString typePayload, OutputStream out) {\n+      return new AutoValue_ArtifactStagingService_ArtifactDestination(typeUrn, typePayload, out);\n+    }\n+\n+    public static ArtifactDestination fromFile(String path) throws IOException {\n+      return fromFile(\n+          path,\n+          Channels.newOutputStream(\n+              FileSystems.create(\n+                  FileSystems.matchNewResource(path, false /* isDirectory */), MimeTypes.BINARY)));\n+    }\n+\n+    public static ArtifactDestination fromFile(String path, OutputStream out) {\n+      return create(\n+          ArtifactRetrievalService.FILE_ARTIFACT_URN,\n+          RunnerApi.ArtifactFilePayload.newBuilder().setPath(path).build().toByteString(),\n+          out);\n+    }\n+\n+    public abstract String getTypeUrn();\n+\n+    public abstract ByteString getTypePayload();\n+\n+    public abstract OutputStream getOutputStream();\n+  }\n+\n+  /**\n+   * An ArtifactDestinationProvider that places new artifacts as files in a Beam filesystem.\n+   *\n+   * @param root the directory in which to place all artifacts\n+   */\n+  public static ArtifactDestinationProvider beamFilesystemArtifactDestinationProvider(String root) {\n+    return (stagingToken, name) -> {\n+      ResourceId path =\n+          FileSystems.matchNewResource(root, true)\n+              .resolve(stagingToken, ResolveOptions.StandardResolveOptions.RESOLVE_DIRECTORY)\n+              .resolve(name, ResolveOptions.StandardResolveOptions.RESOLVE_FILE);\n+      return ArtifactDestination.fromFile(path.toString());\n+    };\n+  }\n+\n+  private enum State {\n+    START,\n+    RESOLVE,\n+    GET,\n+    GETCHUNK,\n+    DONE,\n+    ERROR,\n+  }\n+\n+  /**\n+   * Like the standard Semaphore, but allows an aquire to go over the limit if there is any room.\n+   *\n+   * <p>Also allows setting an error, to avoid issues with un-released aquires after error.\n+   */\n+  private static class OverflowingSemaphore {\n+    private int totalPermits;\n+    private int usedPermits;\n+    private Exception exception;\n+\n+    public OverflowingSemaphore(int totalPermits) {\n+      this.totalPermits = totalPermits;\n+      this.usedPermits = 0;\n+    }\n+\n+    synchronized void aquire(int permits) throws Exception {\n+      while (usedPermits >= totalPermits) {\n+        if (exception != null) {\n+          throw exception;\n+        }\n+        this.wait();\n+      }\n+      usedPermits += permits;\n+    }\n+\n+    synchronized void release(int permits) {\n+      usedPermits -= permits;\n+      this.notifyAll();\n+    }\n+\n+    synchronized void setException(Exception exception) {\n+      this.exception = exception;\n+      this.notifyAll();\n+    }\n+  }\n+\n+  /** A task that pulls bytes off a queue and actually writes them to a staging location. */\n+  private class StoreArtifact implements Callable<RunnerApi.ArtifactInformation> {\n+\n+    private String stagingToken;\n+    private String name;\n+    private RunnerApi.ArtifactInformation originalArtifact;\n+    private BlockingQueue<ByteString> bytesQueue;\n+    private OverflowingSemaphore totalPendingBytes;\n+\n+    public StoreArtifact(\n+        String stagingToken,\n+        String name,\n+        RunnerApi.ArtifactInformation originalArtifact,\n+        BlockingQueue<ByteString> bytesQueue,\n+        OverflowingSemaphore totalPendingBytes) {\n+      this.stagingToken = stagingToken;\n+      this.name = name;\n+      this.originalArtifact = originalArtifact;\n+      this.bytesQueue = bytesQueue;\n+      this.totalPendingBytes = totalPendingBytes;\n+    }\n+\n+    @Override\n+    public RunnerApi.ArtifactInformation call() throws IOException {\n+      try {\n+        ArtifactDestination dest = destinationProvider.getDestination(stagingToken, name);\n+        LOG.debug(\"Storing artifact for {}.{} at {}\", stagingToken, name, dest);\n+        ByteString chunk = bytesQueue.take();\n+        while (chunk.size() > 0) {\n+          totalPendingBytes.release(chunk.size());\n+          chunk.writeTo(dest.getOutputStream());\n+          chunk = bytesQueue.take();\n+        }\n+        dest.getOutputStream().close();\n+        return originalArtifact\n+            .toBuilder()\n+            .setTypeUrn(dest.getTypeUrn())\n+            .setTypePayload(dest.getTypePayload())\n+            .build();\n+      } catch (IOException | InterruptedException exn) {\n+        // As this thread will no longer be draining the queue, we don't want to get stuck writing\n+        // to it.\n+        totalPendingBytes.setException(exn);\n+        LOG.error(\"Exception staging artifacts\", exn);\n+        if (exn instanceof IOException) {\n+          throw (IOException) exn;\n+        } else {\n+          throw new RuntimeException(exn);\n+        }\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public StreamObserver<ArtifactApi.ArtifactResponseWrapper> reverseArtifactRetrievalService(\n+      StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+\n+    return new StreamObserver<ArtifactApi.ArtifactResponseWrapper>() {\n+\n+      /** The maximum number of parallel threads to use to stage. */\n+      public static final int THREAD_POOL_SIZE = 10;\n+\n+      /** The maximum number of bytes to buffer across all writes before throttling. */\n+      public static final int MAX_PENDING_BYTES = 100 << 20; // 100 MB\n+\n+      IdGenerator idGenerator = IdGenerators.incrementingLongs();\n+\n+      String stagingToken;\n+      Map<String, List<RunnerApi.ArtifactInformation>> toResolve;\n+      Map<String, List<Future<RunnerApi.ArtifactInformation>>> stagedFutures;\n+      ExecutorService stagingExecutor;\n+      OverflowingSemaphore totalPendingBytes;\n+\n+      State state = State.START;\n+      Queue<String> pendingResolves;\n+      String currentEnvironment;\n+      Queue<RunnerApi.ArtifactInformation> pendingGets;\n+      BlockingQueue<ByteString> currentOutput;\n+\n+      @Override\n+      @SuppressFBWarnings(value = \"SF_SWITCH_FALLTHROUGH\", justification = \"fallthrough intended\")\n+      // May be called by different threads for the same request; synchronized for memory\n+      // synchronization.\n+      public synchronized void onNext(ArtifactApi.ArtifactResponseWrapper responseWrapper) {\n+        switch (state) {\n+          case START:\n+            stagingToken = responseWrapper.getStagingToken();\n+            LOG.info(\"Staging artifacts for {}.\", stagingToken);\n+            toResolve = toStage.get(stagingToken);\n+            stagedFutures = new ConcurrentHashMap<>();\n+            pendingResolves = new ArrayDeque<>();\n+            pendingResolves.addAll(toResolve.keySet());\n+            stagingExecutor = Executors.newFixedThreadPool(THREAD_POOL_SIZE);\n+            totalPendingBytes = new OverflowingSemaphore(MAX_PENDING_BYTES);\n+            resolveNextEnvironment(responseObserver);\n+            break;\n+\n+          case RESOLVE:\n+            {\n+              currentEnvironment = pendingResolves.remove();\n+              stagedFutures.put(currentEnvironment, new ArrayList<>());\n+              pendingGets = new ArrayDeque<>();\n+              for (RunnerApi.ArtifactInformation artifact :\n+                  responseWrapper.getResolveArtifactResponse().getReplacementsList()) {\n+                Optional<RunnerApi.ArtifactInformation> fetched = getLocal(artifact);\n+                if (fetched.isPresent()) {\n+                  stagedFutures\n+                      .get(currentEnvironment)\n+                      .add(CompletableFuture.completedFuture(fetched.get()));\n+                } else {\n+                  pendingGets.add(artifact);\n+                  responseObserver.onNext(\n+                      ArtifactApi.ArtifactRequestWrapper.newBuilder()\n+                          .setGetArtifact(\n+                              ArtifactApi.GetArtifactRequest.newBuilder().setArtifact(artifact))\n+                          .build());\n+                }\n+              }\n+              LOG.info(\n+                  \"Getting {} artifacts for {}.{}.\",\n+                  pendingGets.size(),\n+                  stagingToken,\n+                  pendingResolves.peek());\n+              if (pendingGets.isEmpty()) {\n+                resolveNextEnvironment(responseObserver);\n+              } else {\n+                state = State.GET;\n+              }\n+              break;\n+            }\n+\n+          case GET:\n+            RunnerApi.ArtifactInformation currentArtifact = pendingGets.remove();\n+            String name = createFilename(currentEnvironment, currentArtifact);\n+            try {\n+              LOG.debug(\"Storing artifacts for {} as {}\", stagingToken, name);\n+              currentOutput = new ArrayBlockingQueue<ByteString>(100);\n+              stagedFutures\n+                  .get(currentEnvironment)\n+                  .add(\n+                      stagingExecutor.submit(\n+                          new StoreArtifact(\n+                              stagingToken,\n+                              name,\n+                              currentArtifact,\n+                              currentOutput,\n+                              totalPendingBytes)));\n+            } catch (Exception exn) {\n+              LOG.error(\"Error submitting.\", exn);\n+              responseObserver.onError(exn);\n+            }\n+            state = State.GETCHUNK;\n+            // fall through\n+\n+          case GETCHUNK:\n+            try {\n+              ByteString chunk = responseWrapper.getGetArtifactResponse().getData();\n+              if (chunk.size() > 0) { // Make sure we don't accidentally send the EOF value.\n+                totalPendingBytes.aquire(chunk.size());\n+                currentOutput.put(chunk);\n+              }\n+              if (responseWrapper.getIsLast()) {\n+                currentOutput.put(ByteString.EMPTY); // The EOF value.\n+                if (pendingGets.isEmpty()) {\n+                  resolveNextEnvironment(responseObserver);\n+                } else {\n+                  state = State.GET;\n+                  LOG.debug(\"Waiting for {}\", pendingGets.peek());\n+                }\n+              }\n+            } catch (Exception exn) {\n+              LOG.error(\"Error submitting.\", exn);\n+              onError(exn);\n+            }\n+            break;\n+\n+          default:\n+            responseObserver.onError(\n+                new StatusException(\n+                    Status.INVALID_ARGUMENT.withDescription(\"Illegal state \" + state)));\n+        }\n+      }\n+\n+      private void resolveNextEnvironment(\n+          StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+        if (pendingResolves.isEmpty()) {\n+          finishStaging(responseObserver);\n+        } else {\n+          state = State.RESOLVE;\n+          LOG.info(\"Resolving artifacts for {}.{}.\", stagingToken, pendingResolves.peek());\n+          responseObserver.onNext(\n+              ArtifactApi.ArtifactRequestWrapper.newBuilder()\n+                  .setResolveArtifact(\n+                      ArtifactApi.ResolveArtifactsRequest.newBuilder()\n+                          .addAllArtifacts(toResolve.get(pendingResolves.peek())))\n+                  .build());\n+        }\n+      }\n+\n+      private void finishStaging(\n+          StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+        LOG.debug(\"Finishing staging for {}.\", stagingToken);\n+        Map<String, List<RunnerApi.ArtifactInformation>> staged = new HashMap<>();\n+        try {\n+          for (Map.Entry<String, List<Future<RunnerApi.ArtifactInformation>>> entry :\n+              stagedFutures.entrySet()) {\n+            List<RunnerApi.ArtifactInformation> envStaged = new ArrayList<>();\n+            for (Future<RunnerApi.ArtifactInformation> future : entry.getValue()) {\n+              envStaged.add(future.get());\n+            }\n+            staged.put(entry.getKey(), envStaged);\n+          }\n+          ArtifactStagingService.this.staged.put(stagingToken, staged);\n+          stagingExecutor.shutdown();\n+          state = State.DONE;\n+          LOG.info(\"Artifacts fully staged for {}.\", stagingToken);\n+          responseObserver.onCompleted();\n+        } catch (Exception exn) {\n+          LOG.error(\"Error staging artifacts\", exn);\n+          responseObserver.onError(exn);\n+          state = State.ERROR;\n+          return;\n+        }\n+      }\n+\n+      /**\n+       * Return an alternative artifact if we do not need to get this over the artifact API, or\n+       * possibly at all.\n+       */\n+      private Optional<RunnerApi.ArtifactInformation> getLocal(\n+          RunnerApi.ArtifactInformation artifact) {\n+        return Optional.empty();\n+      }\n+\n+      /**\n+       * Attempts to provide a reasonable filename for the artifact.\n+       *\n+       * @param index a monotonically increasing index, which provides uniqueness\n+       * @param environment the environment id\n+       * @param artifact the artifact itself\n+       */\n+      private String createFilename(String environment, RunnerApi.ArtifactInformation artifact) {\n+        String path;\n+        try {\n+          if (artifact.getRoleUrn().equals(ArtifactRetrievalService.STAGING_TO_ARTIFACT_URN)) {\n+            path =\n+                RunnerApi.ArtifactStagingToRolePayload.parseFrom(artifact.getRolePayload())\n+                    .getStagedName();\n+          } else if (artifact.getTypeUrn().equals(ArtifactRetrievalService.FILE_ARTIFACT_URN)) {\n+            path = RunnerApi.ArtifactFilePayload.parseFrom(artifact.getTypePayload()).getPath();\n+          } else if (artifact.getTypeUrn().equals(ArtifactRetrievalService.URL_ARTIFACT_URN)) {\n+            path = RunnerApi.ArtifactUrlPayload.parseFrom(artifact.getTypePayload()).getUrl();\n+          } else {\n+            path = \"artifact\";\n+          }\n+        } catch (InvalidProtocolBufferException exn) {\n+          throw new RuntimeException(exn);\n+        }\n+        // Limit to the last contiguous alpha-numeric sequence. In particular, this will exclude\n+        // all path separators.\n+        List<String> components = Splitter.onPattern(\"[^A-Za-z-_.]]\").splitToList(path);\n+        String base = components.get(components.size() - 1);\n+        return clip(\n+            String.format(\"%s-%s-%s\", idGenerator.getId(), clip(environment, 25), base), 100);\n+      }\n+\n+      private String clip(String s, int maxLength) {\n+        return s.length() < maxLength ? s : s.substring(0, maxLength);\n+      }\n+\n+      @Override\n+      public void onError(Throwable throwable) {\n+        stagingExecutor.shutdownNow();\n+        LOG.error(\"Error staging artifacts\", throwable);\n+        state = State.ERROR;\n+      }\n+\n+      @Override\n+      public void onCompleted() {\n+        Preconditions.checkArgument(state == State.DONE);\n+      }\n+    };\n+  }\n+\n+  @Override\n+  public void close() throws Exception {\n+    // Nothing to close.\n+  }\n+\n+  /**\n+   * Lazily stages artifacts by letting an ArtifactStagingService resolve and request artifacts.\n+   *\n+   * @param retrievalService an ArtifactRetrievalService used to resolve and retrieve artifacts\n+   * @param stagingService an ArtifactStagingService stub which will request artifacts\n+   * @param stagingToken the staging token of the job whose artifacts will be retrieved\n+   * @throws InterruptedException\n+   * @throws IOException\n+   */\n+  public static void offer(\n+      ArtifactRetrievalService retrievalService,\n+      ArtifactStagingServiceGrpc.ArtifactStagingServiceStub stagingService,\n+      String stagingToken)\n+      throws ExecutionException, InterruptedException {\n+    new StagingDriver(retrievalService, stagingService, stagingToken).getCompletionFuture().get();\n+  }\n+\n+  /** Actually implements the reverse retrieval protocol. */\n+  private static class StagingDriver implements StreamObserver<ArtifactApi.ArtifactRequestWrapper> {\n+\n+    private final ArtifactRetrievalService retrievalService;\n+    private final StreamObserver<ArtifactApi.ArtifactResponseWrapper> responseObserver;\n+    private final CompletableFuture<Void> completionFuture;\n+\n+    public StagingDriver(\n+        ArtifactRetrievalService retrievalService,\n+        ArtifactStagingServiceGrpc.ArtifactStagingServiceStub stagingService,\n+        String stagingToken) {\n+      this.retrievalService = retrievalService;\n+      responseObserver = stagingService.reverseArtifactRetrievalService(this);\n+      responseObserver.onNext(\n+          ArtifactApi.ArtifactResponseWrapper.newBuilder().setStagingToken(stagingToken).build());\n+      completionFuture = new CompletableFuture<Void>();\n+    }\n+\n+    public CompletableFuture<?> getCompletionFuture() {\n+      return completionFuture;\n+    }\n+\n+    @Override\n+    public void onNext(ArtifactApi.ArtifactRequestWrapper requestWrapper) {\n+      if (requestWrapper.hasResolveArtifact()) {\n+        retrievalService.resolveArtifacts(\n+            requestWrapper.getResolveArtifact(),\n+            new StreamObserver<ArtifactApi.ResolveArtifactsResponse>() {\n+\n+              @Override\n+              public void onNext(ArtifactApi.ResolveArtifactsResponse resolveArtifactsResponse) {\n+                responseObserver.onNext(\n+                    ArtifactApi.ArtifactResponseWrapper.newBuilder()\n+                        .setResolveArtifactResponse(resolveArtifactsResponse)\n+                        .build());\n+              }\n+\n+              @Override\n+              public void onError(Throwable throwable) {\n+                responseObserver.onError(throwable);\n+              }\n+\n+              @Override\n+              public void onCompleted() {}\n+            });\n+      } else if (requestWrapper.hasGetArtifact()) {\n+        retrievalService.getArtifact(\n+            requestWrapper.getGetArtifact(),\n+            new StreamObserver<ArtifactApi.GetArtifactResponse>() {\n+\n+              @Override\n+              public void onNext(ArtifactApi.GetArtifactResponse getArtifactResponse) {\n+                responseObserver.onNext(\n+                    ArtifactApi.ArtifactResponseWrapper.newBuilder()\n+                        .setGetArtifactResponse(getArtifactResponse)\n+                        .build());\n+              }\n+\n+              @Override\n+              public void onError(Throwable throwable) {\n+                responseObserver.onError(throwable);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7b1429d1c9da5b90e2a91c0052359b1f719df2a1"}, "originalPosition": 570}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzI5NTMxOA==", "bodyText": "complete the future with the error?", "url": "https://github.com/apache/beam/pull/11342#discussion_r413295318", "createdAt": "2020-04-22T20:12:25Z", "author": {"login": "lukecwik"}, "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/artifact/ArtifactStagingService.java", "diffHunk": "@@ -0,0 +1,602 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.fnexecution.artifact;\n+\n+import com.google.auto.value.AutoValue;\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.channels.Channels;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactApi;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactStagingServiceGrpc;\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+import org.apache.beam.runners.fnexecution.FnService;\n+import org.apache.beam.sdk.fn.IdGenerator;\n+import org.apache.beam.sdk.fn.IdGenerators;\n+import org.apache.beam.sdk.io.FileSystems;\n+import org.apache.beam.sdk.io.fs.ResolveOptions;\n+import org.apache.beam.sdk.io.fs.ResourceId;\n+import org.apache.beam.sdk.util.MimeTypes;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.ByteString;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.InvalidProtocolBufferException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.Status;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.StatusException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.stub.StreamObserver;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Splitter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class ArtifactStagingService\n+    extends ArtifactStagingServiceGrpc.ArtifactStagingServiceImplBase implements FnService {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(ArtifactStagingService.class);\n+\n+  private final ArtifactDestinationProvider destinationProvider;\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> toStage =\n+      new ConcurrentHashMap<>();\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> staged =\n+      new ConcurrentHashMap<>();\n+\n+  public ArtifactStagingService(ArtifactDestinationProvider destinationProvider) {\n+    this.destinationProvider = destinationProvider;\n+  }\n+\n+  /**\n+   * Registers a set of artifacts to be staged with this service.\n+   *\n+   * <p>A client (e.g. a Beam SDK) is expected to connect to this service with the given staging\n+   * token and offer resolution and retrieval of this set of artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   * @param artifacts all artifacts to stage, keyed by environment\n+   */\n+  public void registerJob(\n+      String stagingToken, Map<String, List<RunnerApi.ArtifactInformation>> artifacts) {\n+    assert !toStage.containsKey(stagingToken);\n+    toStage.put(stagingToken, artifacts);\n+  }\n+\n+  /**\n+   * Returns the rewritten artifacts associated with this job, keyed by environment.\n+   *\n+   * <p>This should be called after the client has finished offering artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   */\n+  public Map<String, List<RunnerApi.ArtifactInformation>> getStagedArtifacts(String stagingToken) {\n+    toStage.remove(stagingToken);\n+    return staged.remove(stagingToken);\n+  }\n+\n+  /** Provides a concrete location to which artifacts can be staged on retrieval. */\n+  public interface ArtifactDestinationProvider {\n+    ArtifactDestination getDestination(String stagingToken, String name) throws IOException;\n+  }\n+\n+  /**\n+   * A pairing of a newly created artifact type and an ouptut stream that will be readable at that\n+   * type.\n+   */\n+  @AutoValue\n+  public abstract static class ArtifactDestination {\n+    public static ArtifactDestination create(\n+        String typeUrn, ByteString typePayload, OutputStream out) {\n+      return new AutoValue_ArtifactStagingService_ArtifactDestination(typeUrn, typePayload, out);\n+    }\n+\n+    public static ArtifactDestination fromFile(String path) throws IOException {\n+      return fromFile(\n+          path,\n+          Channels.newOutputStream(\n+              FileSystems.create(\n+                  FileSystems.matchNewResource(path, false /* isDirectory */), MimeTypes.BINARY)));\n+    }\n+\n+    public static ArtifactDestination fromFile(String path, OutputStream out) {\n+      return create(\n+          ArtifactRetrievalService.FILE_ARTIFACT_URN,\n+          RunnerApi.ArtifactFilePayload.newBuilder().setPath(path).build().toByteString(),\n+          out);\n+    }\n+\n+    public abstract String getTypeUrn();\n+\n+    public abstract ByteString getTypePayload();\n+\n+    public abstract OutputStream getOutputStream();\n+  }\n+\n+  /**\n+   * An ArtifactDestinationProvider that places new artifacts as files in a Beam filesystem.\n+   *\n+   * @param root the directory in which to place all artifacts\n+   */\n+  public static ArtifactDestinationProvider beamFilesystemArtifactDestinationProvider(String root) {\n+    return (stagingToken, name) -> {\n+      ResourceId path =\n+          FileSystems.matchNewResource(root, true)\n+              .resolve(stagingToken, ResolveOptions.StandardResolveOptions.RESOLVE_DIRECTORY)\n+              .resolve(name, ResolveOptions.StandardResolveOptions.RESOLVE_FILE);\n+      return ArtifactDestination.fromFile(path.toString());\n+    };\n+  }\n+\n+  private enum State {\n+    START,\n+    RESOLVE,\n+    GET,\n+    GETCHUNK,\n+    DONE,\n+    ERROR,\n+  }\n+\n+  /**\n+   * Like the standard Semaphore, but allows an aquire to go over the limit if there is any room.\n+   *\n+   * <p>Also allows setting an error, to avoid issues with un-released aquires after error.\n+   */\n+  private static class OverflowingSemaphore {\n+    private int totalPermits;\n+    private int usedPermits;\n+    private Exception exception;\n+\n+    public OverflowingSemaphore(int totalPermits) {\n+      this.totalPermits = totalPermits;\n+      this.usedPermits = 0;\n+    }\n+\n+    synchronized void aquire(int permits) throws Exception {\n+      while (usedPermits >= totalPermits) {\n+        if (exception != null) {\n+          throw exception;\n+        }\n+        this.wait();\n+      }\n+      usedPermits += permits;\n+    }\n+\n+    synchronized void release(int permits) {\n+      usedPermits -= permits;\n+      this.notifyAll();\n+    }\n+\n+    synchronized void setException(Exception exception) {\n+      this.exception = exception;\n+      this.notifyAll();\n+    }\n+  }\n+\n+  /** A task that pulls bytes off a queue and actually writes them to a staging location. */\n+  private class StoreArtifact implements Callable<RunnerApi.ArtifactInformation> {\n+\n+    private String stagingToken;\n+    private String name;\n+    private RunnerApi.ArtifactInformation originalArtifact;\n+    private BlockingQueue<ByteString> bytesQueue;\n+    private OverflowingSemaphore totalPendingBytes;\n+\n+    public StoreArtifact(\n+        String stagingToken,\n+        String name,\n+        RunnerApi.ArtifactInformation originalArtifact,\n+        BlockingQueue<ByteString> bytesQueue,\n+        OverflowingSemaphore totalPendingBytes) {\n+      this.stagingToken = stagingToken;\n+      this.name = name;\n+      this.originalArtifact = originalArtifact;\n+      this.bytesQueue = bytesQueue;\n+      this.totalPendingBytes = totalPendingBytes;\n+    }\n+\n+    @Override\n+    public RunnerApi.ArtifactInformation call() throws IOException {\n+      try {\n+        ArtifactDestination dest = destinationProvider.getDestination(stagingToken, name);\n+        LOG.debug(\"Storing artifact for {}.{} at {}\", stagingToken, name, dest);\n+        ByteString chunk = bytesQueue.take();\n+        while (chunk.size() > 0) {\n+          totalPendingBytes.release(chunk.size());\n+          chunk.writeTo(dest.getOutputStream());\n+          chunk = bytesQueue.take();\n+        }\n+        dest.getOutputStream().close();\n+        return originalArtifact\n+            .toBuilder()\n+            .setTypeUrn(dest.getTypeUrn())\n+            .setTypePayload(dest.getTypePayload())\n+            .build();\n+      } catch (IOException | InterruptedException exn) {\n+        // As this thread will no longer be draining the queue, we don't want to get stuck writing\n+        // to it.\n+        totalPendingBytes.setException(exn);\n+        LOG.error(\"Exception staging artifacts\", exn);\n+        if (exn instanceof IOException) {\n+          throw (IOException) exn;\n+        } else {\n+          throw new RuntimeException(exn);\n+        }\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public StreamObserver<ArtifactApi.ArtifactResponseWrapper> reverseArtifactRetrievalService(\n+      StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+\n+    return new StreamObserver<ArtifactApi.ArtifactResponseWrapper>() {\n+\n+      /** The maximum number of parallel threads to use to stage. */\n+      public static final int THREAD_POOL_SIZE = 10;\n+\n+      /** The maximum number of bytes to buffer across all writes before throttling. */\n+      public static final int MAX_PENDING_BYTES = 100 << 20; // 100 MB\n+\n+      IdGenerator idGenerator = IdGenerators.incrementingLongs();\n+\n+      String stagingToken;\n+      Map<String, List<RunnerApi.ArtifactInformation>> toResolve;\n+      Map<String, List<Future<RunnerApi.ArtifactInformation>>> stagedFutures;\n+      ExecutorService stagingExecutor;\n+      OverflowingSemaphore totalPendingBytes;\n+\n+      State state = State.START;\n+      Queue<String> pendingResolves;\n+      String currentEnvironment;\n+      Queue<RunnerApi.ArtifactInformation> pendingGets;\n+      BlockingQueue<ByteString> currentOutput;\n+\n+      @Override\n+      @SuppressFBWarnings(value = \"SF_SWITCH_FALLTHROUGH\", justification = \"fallthrough intended\")\n+      // May be called by different threads for the same request; synchronized for memory\n+      // synchronization.\n+      public synchronized void onNext(ArtifactApi.ArtifactResponseWrapper responseWrapper) {\n+        switch (state) {\n+          case START:\n+            stagingToken = responseWrapper.getStagingToken();\n+            LOG.info(\"Staging artifacts for {}.\", stagingToken);\n+            toResolve = toStage.get(stagingToken);\n+            stagedFutures = new ConcurrentHashMap<>();\n+            pendingResolves = new ArrayDeque<>();\n+            pendingResolves.addAll(toResolve.keySet());\n+            stagingExecutor = Executors.newFixedThreadPool(THREAD_POOL_SIZE);\n+            totalPendingBytes = new OverflowingSemaphore(MAX_PENDING_BYTES);\n+            resolveNextEnvironment(responseObserver);\n+            break;\n+\n+          case RESOLVE:\n+            {\n+              currentEnvironment = pendingResolves.remove();\n+              stagedFutures.put(currentEnvironment, new ArrayList<>());\n+              pendingGets = new ArrayDeque<>();\n+              for (RunnerApi.ArtifactInformation artifact :\n+                  responseWrapper.getResolveArtifactResponse().getReplacementsList()) {\n+                Optional<RunnerApi.ArtifactInformation> fetched = getLocal(artifact);\n+                if (fetched.isPresent()) {\n+                  stagedFutures\n+                      .get(currentEnvironment)\n+                      .add(CompletableFuture.completedFuture(fetched.get()));\n+                } else {\n+                  pendingGets.add(artifact);\n+                  responseObserver.onNext(\n+                      ArtifactApi.ArtifactRequestWrapper.newBuilder()\n+                          .setGetArtifact(\n+                              ArtifactApi.GetArtifactRequest.newBuilder().setArtifact(artifact))\n+                          .build());\n+                }\n+              }\n+              LOG.info(\n+                  \"Getting {} artifacts for {}.{}.\",\n+                  pendingGets.size(),\n+                  stagingToken,\n+                  pendingResolves.peek());\n+              if (pendingGets.isEmpty()) {\n+                resolveNextEnvironment(responseObserver);\n+              } else {\n+                state = State.GET;\n+              }\n+              break;\n+            }\n+\n+          case GET:\n+            RunnerApi.ArtifactInformation currentArtifact = pendingGets.remove();\n+            String name = createFilename(currentEnvironment, currentArtifact);\n+            try {\n+              LOG.debug(\"Storing artifacts for {} as {}\", stagingToken, name);\n+              currentOutput = new ArrayBlockingQueue<ByteString>(100);\n+              stagedFutures\n+                  .get(currentEnvironment)\n+                  .add(\n+                      stagingExecutor.submit(\n+                          new StoreArtifact(\n+                              stagingToken,\n+                              name,\n+                              currentArtifact,\n+                              currentOutput,\n+                              totalPendingBytes)));\n+            } catch (Exception exn) {\n+              LOG.error(\"Error submitting.\", exn);\n+              responseObserver.onError(exn);\n+            }\n+            state = State.GETCHUNK;\n+            // fall through\n+\n+          case GETCHUNK:\n+            try {\n+              ByteString chunk = responseWrapper.getGetArtifactResponse().getData();\n+              if (chunk.size() > 0) { // Make sure we don't accidentally send the EOF value.\n+                totalPendingBytes.aquire(chunk.size());\n+                currentOutput.put(chunk);\n+              }\n+              if (responseWrapper.getIsLast()) {\n+                currentOutput.put(ByteString.EMPTY); // The EOF value.\n+                if (pendingGets.isEmpty()) {\n+                  resolveNextEnvironment(responseObserver);\n+                } else {\n+                  state = State.GET;\n+                  LOG.debug(\"Waiting for {}\", pendingGets.peek());\n+                }\n+              }\n+            } catch (Exception exn) {\n+              LOG.error(\"Error submitting.\", exn);\n+              onError(exn);\n+            }\n+            break;\n+\n+          default:\n+            responseObserver.onError(\n+                new StatusException(\n+                    Status.INVALID_ARGUMENT.withDescription(\"Illegal state \" + state)));\n+        }\n+      }\n+\n+      private void resolveNextEnvironment(\n+          StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+        if (pendingResolves.isEmpty()) {\n+          finishStaging(responseObserver);\n+        } else {\n+          state = State.RESOLVE;\n+          LOG.info(\"Resolving artifacts for {}.{}.\", stagingToken, pendingResolves.peek());\n+          responseObserver.onNext(\n+              ArtifactApi.ArtifactRequestWrapper.newBuilder()\n+                  .setResolveArtifact(\n+                      ArtifactApi.ResolveArtifactsRequest.newBuilder()\n+                          .addAllArtifacts(toResolve.get(pendingResolves.peek())))\n+                  .build());\n+        }\n+      }\n+\n+      private void finishStaging(\n+          StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+        LOG.debug(\"Finishing staging for {}.\", stagingToken);\n+        Map<String, List<RunnerApi.ArtifactInformation>> staged = new HashMap<>();\n+        try {\n+          for (Map.Entry<String, List<Future<RunnerApi.ArtifactInformation>>> entry :\n+              stagedFutures.entrySet()) {\n+            List<RunnerApi.ArtifactInformation> envStaged = new ArrayList<>();\n+            for (Future<RunnerApi.ArtifactInformation> future : entry.getValue()) {\n+              envStaged.add(future.get());\n+            }\n+            staged.put(entry.getKey(), envStaged);\n+          }\n+          ArtifactStagingService.this.staged.put(stagingToken, staged);\n+          stagingExecutor.shutdown();\n+          state = State.DONE;\n+          LOG.info(\"Artifacts fully staged for {}.\", stagingToken);\n+          responseObserver.onCompleted();\n+        } catch (Exception exn) {\n+          LOG.error(\"Error staging artifacts\", exn);\n+          responseObserver.onError(exn);\n+          state = State.ERROR;\n+          return;\n+        }\n+      }\n+\n+      /**\n+       * Return an alternative artifact if we do not need to get this over the artifact API, or\n+       * possibly at all.\n+       */\n+      private Optional<RunnerApi.ArtifactInformation> getLocal(\n+          RunnerApi.ArtifactInformation artifact) {\n+        return Optional.empty();\n+      }\n+\n+      /**\n+       * Attempts to provide a reasonable filename for the artifact.\n+       *\n+       * @param index a monotonically increasing index, which provides uniqueness\n+       * @param environment the environment id\n+       * @param artifact the artifact itself\n+       */\n+      private String createFilename(String environment, RunnerApi.ArtifactInformation artifact) {\n+        String path;\n+        try {\n+          if (artifact.getRoleUrn().equals(ArtifactRetrievalService.STAGING_TO_ARTIFACT_URN)) {\n+            path =\n+                RunnerApi.ArtifactStagingToRolePayload.parseFrom(artifact.getRolePayload())\n+                    .getStagedName();\n+          } else if (artifact.getTypeUrn().equals(ArtifactRetrievalService.FILE_ARTIFACT_URN)) {\n+            path = RunnerApi.ArtifactFilePayload.parseFrom(artifact.getTypePayload()).getPath();\n+          } else if (artifact.getTypeUrn().equals(ArtifactRetrievalService.URL_ARTIFACT_URN)) {\n+            path = RunnerApi.ArtifactUrlPayload.parseFrom(artifact.getTypePayload()).getUrl();\n+          } else {\n+            path = \"artifact\";\n+          }\n+        } catch (InvalidProtocolBufferException exn) {\n+          throw new RuntimeException(exn);\n+        }\n+        // Limit to the last contiguous alpha-numeric sequence. In particular, this will exclude\n+        // all path separators.\n+        List<String> components = Splitter.onPattern(\"[^A-Za-z-_.]]\").splitToList(path);\n+        String base = components.get(components.size() - 1);\n+        return clip(\n+            String.format(\"%s-%s-%s\", idGenerator.getId(), clip(environment, 25), base), 100);\n+      }\n+\n+      private String clip(String s, int maxLength) {\n+        return s.length() < maxLength ? s : s.substring(0, maxLength);\n+      }\n+\n+      @Override\n+      public void onError(Throwable throwable) {\n+        stagingExecutor.shutdownNow();\n+        LOG.error(\"Error staging artifacts\", throwable);\n+        state = State.ERROR;\n+      }\n+\n+      @Override\n+      public void onCompleted() {\n+        Preconditions.checkArgument(state == State.DONE);\n+      }\n+    };\n+  }\n+\n+  @Override\n+  public void close() throws Exception {\n+    // Nothing to close.\n+  }\n+\n+  /**\n+   * Lazily stages artifacts by letting an ArtifactStagingService resolve and request artifacts.\n+   *\n+   * @param retrievalService an ArtifactRetrievalService used to resolve and retrieve artifacts\n+   * @param stagingService an ArtifactStagingService stub which will request artifacts\n+   * @param stagingToken the staging token of the job whose artifacts will be retrieved\n+   * @throws InterruptedException\n+   * @throws IOException\n+   */\n+  public static void offer(\n+      ArtifactRetrievalService retrievalService,\n+      ArtifactStagingServiceGrpc.ArtifactStagingServiceStub stagingService,\n+      String stagingToken)\n+      throws ExecutionException, InterruptedException {\n+    new StagingDriver(retrievalService, stagingService, stagingToken).getCompletionFuture().get();\n+  }\n+\n+  /** Actually implements the reverse retrieval protocol. */\n+  private static class StagingDriver implements StreamObserver<ArtifactApi.ArtifactRequestWrapper> {\n+\n+    private final ArtifactRetrievalService retrievalService;\n+    private final StreamObserver<ArtifactApi.ArtifactResponseWrapper> responseObserver;\n+    private final CompletableFuture<Void> completionFuture;\n+\n+    public StagingDriver(\n+        ArtifactRetrievalService retrievalService,\n+        ArtifactStagingServiceGrpc.ArtifactStagingServiceStub stagingService,\n+        String stagingToken) {\n+      this.retrievalService = retrievalService;\n+      responseObserver = stagingService.reverseArtifactRetrievalService(this);\n+      responseObserver.onNext(\n+          ArtifactApi.ArtifactResponseWrapper.newBuilder().setStagingToken(stagingToken).build());\n+      completionFuture = new CompletableFuture<Void>();\n+    }\n+\n+    public CompletableFuture<?> getCompletionFuture() {\n+      return completionFuture;\n+    }\n+\n+    @Override\n+    public void onNext(ArtifactApi.ArtifactRequestWrapper requestWrapper) {\n+      if (requestWrapper.hasResolveArtifact()) {\n+        retrievalService.resolveArtifacts(\n+            requestWrapper.getResolveArtifact(),\n+            new StreamObserver<ArtifactApi.ResolveArtifactsResponse>() {\n+\n+              @Override\n+              public void onNext(ArtifactApi.ResolveArtifactsResponse resolveArtifactsResponse) {\n+                responseObserver.onNext(\n+                    ArtifactApi.ArtifactResponseWrapper.newBuilder()\n+                        .setResolveArtifactResponse(resolveArtifactsResponse)\n+                        .build());\n+              }\n+\n+              @Override\n+              public void onError(Throwable throwable) {\n+                responseObserver.onError(throwable);\n+              }\n+\n+              @Override\n+              public void onCompleted() {}\n+            });\n+      } else if (requestWrapper.hasGetArtifact()) {\n+        retrievalService.getArtifact(\n+            requestWrapper.getGetArtifact(),\n+            new StreamObserver<ArtifactApi.GetArtifactResponse>() {\n+\n+              @Override\n+              public void onNext(ArtifactApi.GetArtifactResponse getArtifactResponse) {\n+                responseObserver.onNext(\n+                    ArtifactApi.ArtifactResponseWrapper.newBuilder()\n+                        .setGetArtifactResponse(getArtifactResponse)\n+                        .build());\n+              }\n+\n+              @Override\n+              public void onError(Throwable throwable) {\n+                responseObserver.onError(throwable);\n+              }\n+\n+              @Override\n+              public void onCompleted() {\n+                responseObserver.onNext(\n+                    ArtifactApi.ArtifactResponseWrapper.newBuilder()\n+                        .setGetArtifactResponse(\n+                            ArtifactApi.GetArtifactResponse.newBuilder().build())\n+                        .setIsLast(true)\n+                        .build());\n+              }\n+            });\n+      } else {\n+        responseObserver.onError(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7b1429d1c9da5b90e2a91c0052359b1f719df2a1"}, "originalPosition": 584}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMzI5NjcyMA==", "bodyText": "if the future is completed, we should call responseObserver.onError with the exception\nThis allows us to propagate the root cause further along.", "url": "https://github.com/apache/beam/pull/11342#discussion_r413296720", "createdAt": "2020-04-22T20:14:09Z", "author": {"login": "lukecwik"}, "path": "runners/java-fn-execution/src/main/java/org/apache/beam/runners/fnexecution/artifact/ArtifactStagingService.java", "diffHunk": "@@ -0,0 +1,602 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.runners.fnexecution.artifact;\n+\n+import com.google.auto.value.AutoValue;\n+import edu.umd.cs.findbugs.annotations.SuppressFBWarnings;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.nio.channels.Channels;\n+import java.util.ArrayDeque;\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.Queue;\n+import java.util.concurrent.ArrayBlockingQueue;\n+import java.util.concurrent.BlockingQueue;\n+import java.util.concurrent.Callable;\n+import java.util.concurrent.CompletableFuture;\n+import java.util.concurrent.ConcurrentHashMap;\n+import java.util.concurrent.ConcurrentMap;\n+import java.util.concurrent.ExecutionException;\n+import java.util.concurrent.ExecutorService;\n+import java.util.concurrent.Executors;\n+import java.util.concurrent.Future;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactApi;\n+import org.apache.beam.model.jobmanagement.v1.ArtifactStagingServiceGrpc;\n+import org.apache.beam.model.pipeline.v1.RunnerApi;\n+import org.apache.beam.runners.fnexecution.FnService;\n+import org.apache.beam.sdk.fn.IdGenerator;\n+import org.apache.beam.sdk.fn.IdGenerators;\n+import org.apache.beam.sdk.io.FileSystems;\n+import org.apache.beam.sdk.io.fs.ResolveOptions;\n+import org.apache.beam.sdk.io.fs.ResourceId;\n+import org.apache.beam.sdk.util.MimeTypes;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.ByteString;\n+import org.apache.beam.vendor.grpc.v1p26p0.com.google.protobuf.InvalidProtocolBufferException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.Status;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.StatusException;\n+import org.apache.beam.vendor.grpc.v1p26p0.io.grpc.stub.StreamObserver;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Splitter;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+public class ArtifactStagingService\n+    extends ArtifactStagingServiceGrpc.ArtifactStagingServiceImplBase implements FnService {\n+\n+  private static final Logger LOG = LoggerFactory.getLogger(ArtifactStagingService.class);\n+\n+  private final ArtifactDestinationProvider destinationProvider;\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> toStage =\n+      new ConcurrentHashMap<>();\n+\n+  private final ConcurrentMap<String, Map<String, List<RunnerApi.ArtifactInformation>>> staged =\n+      new ConcurrentHashMap<>();\n+\n+  public ArtifactStagingService(ArtifactDestinationProvider destinationProvider) {\n+    this.destinationProvider = destinationProvider;\n+  }\n+\n+  /**\n+   * Registers a set of artifacts to be staged with this service.\n+   *\n+   * <p>A client (e.g. a Beam SDK) is expected to connect to this service with the given staging\n+   * token and offer resolution and retrieval of this set of artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   * @param artifacts all artifacts to stage, keyed by environment\n+   */\n+  public void registerJob(\n+      String stagingToken, Map<String, List<RunnerApi.ArtifactInformation>> artifacts) {\n+    assert !toStage.containsKey(stagingToken);\n+    toStage.put(stagingToken, artifacts);\n+  }\n+\n+  /**\n+   * Returns the rewritten artifacts associated with this job, keyed by environment.\n+   *\n+   * <p>This should be called after the client has finished offering artifacts.\n+   *\n+   * @param stagingToken a staging token for this job\n+   */\n+  public Map<String, List<RunnerApi.ArtifactInformation>> getStagedArtifacts(String stagingToken) {\n+    toStage.remove(stagingToken);\n+    return staged.remove(stagingToken);\n+  }\n+\n+  /** Provides a concrete location to which artifacts can be staged on retrieval. */\n+  public interface ArtifactDestinationProvider {\n+    ArtifactDestination getDestination(String stagingToken, String name) throws IOException;\n+  }\n+\n+  /**\n+   * A pairing of a newly created artifact type and an ouptut stream that will be readable at that\n+   * type.\n+   */\n+  @AutoValue\n+  public abstract static class ArtifactDestination {\n+    public static ArtifactDestination create(\n+        String typeUrn, ByteString typePayload, OutputStream out) {\n+      return new AutoValue_ArtifactStagingService_ArtifactDestination(typeUrn, typePayload, out);\n+    }\n+\n+    public static ArtifactDestination fromFile(String path) throws IOException {\n+      return fromFile(\n+          path,\n+          Channels.newOutputStream(\n+              FileSystems.create(\n+                  FileSystems.matchNewResource(path, false /* isDirectory */), MimeTypes.BINARY)));\n+    }\n+\n+    public static ArtifactDestination fromFile(String path, OutputStream out) {\n+      return create(\n+          ArtifactRetrievalService.FILE_ARTIFACT_URN,\n+          RunnerApi.ArtifactFilePayload.newBuilder().setPath(path).build().toByteString(),\n+          out);\n+    }\n+\n+    public abstract String getTypeUrn();\n+\n+    public abstract ByteString getTypePayload();\n+\n+    public abstract OutputStream getOutputStream();\n+  }\n+\n+  /**\n+   * An ArtifactDestinationProvider that places new artifacts as files in a Beam filesystem.\n+   *\n+   * @param root the directory in which to place all artifacts\n+   */\n+  public static ArtifactDestinationProvider beamFilesystemArtifactDestinationProvider(String root) {\n+    return (stagingToken, name) -> {\n+      ResourceId path =\n+          FileSystems.matchNewResource(root, true)\n+              .resolve(stagingToken, ResolveOptions.StandardResolveOptions.RESOLVE_DIRECTORY)\n+              .resolve(name, ResolveOptions.StandardResolveOptions.RESOLVE_FILE);\n+      return ArtifactDestination.fromFile(path.toString());\n+    };\n+  }\n+\n+  private enum State {\n+    START,\n+    RESOLVE,\n+    GET,\n+    GETCHUNK,\n+    DONE,\n+    ERROR,\n+  }\n+\n+  /**\n+   * Like the standard Semaphore, but allows an aquire to go over the limit if there is any room.\n+   *\n+   * <p>Also allows setting an error, to avoid issues with un-released aquires after error.\n+   */\n+  private static class OverflowingSemaphore {\n+    private int totalPermits;\n+    private int usedPermits;\n+    private Exception exception;\n+\n+    public OverflowingSemaphore(int totalPermits) {\n+      this.totalPermits = totalPermits;\n+      this.usedPermits = 0;\n+    }\n+\n+    synchronized void aquire(int permits) throws Exception {\n+      while (usedPermits >= totalPermits) {\n+        if (exception != null) {\n+          throw exception;\n+        }\n+        this.wait();\n+      }\n+      usedPermits += permits;\n+    }\n+\n+    synchronized void release(int permits) {\n+      usedPermits -= permits;\n+      this.notifyAll();\n+    }\n+\n+    synchronized void setException(Exception exception) {\n+      this.exception = exception;\n+      this.notifyAll();\n+    }\n+  }\n+\n+  /** A task that pulls bytes off a queue and actually writes them to a staging location. */\n+  private class StoreArtifact implements Callable<RunnerApi.ArtifactInformation> {\n+\n+    private String stagingToken;\n+    private String name;\n+    private RunnerApi.ArtifactInformation originalArtifact;\n+    private BlockingQueue<ByteString> bytesQueue;\n+    private OverflowingSemaphore totalPendingBytes;\n+\n+    public StoreArtifact(\n+        String stagingToken,\n+        String name,\n+        RunnerApi.ArtifactInformation originalArtifact,\n+        BlockingQueue<ByteString> bytesQueue,\n+        OverflowingSemaphore totalPendingBytes) {\n+      this.stagingToken = stagingToken;\n+      this.name = name;\n+      this.originalArtifact = originalArtifact;\n+      this.bytesQueue = bytesQueue;\n+      this.totalPendingBytes = totalPendingBytes;\n+    }\n+\n+    @Override\n+    public RunnerApi.ArtifactInformation call() throws IOException {\n+      try {\n+        ArtifactDestination dest = destinationProvider.getDestination(stagingToken, name);\n+        LOG.debug(\"Storing artifact for {}.{} at {}\", stagingToken, name, dest);\n+        ByteString chunk = bytesQueue.take();\n+        while (chunk.size() > 0) {\n+          totalPendingBytes.release(chunk.size());\n+          chunk.writeTo(dest.getOutputStream());\n+          chunk = bytesQueue.take();\n+        }\n+        dest.getOutputStream().close();\n+        return originalArtifact\n+            .toBuilder()\n+            .setTypeUrn(dest.getTypeUrn())\n+            .setTypePayload(dest.getTypePayload())\n+            .build();\n+      } catch (IOException | InterruptedException exn) {\n+        // As this thread will no longer be draining the queue, we don't want to get stuck writing\n+        // to it.\n+        totalPendingBytes.setException(exn);\n+        LOG.error(\"Exception staging artifacts\", exn);\n+        if (exn instanceof IOException) {\n+          throw (IOException) exn;\n+        } else {\n+          throw new RuntimeException(exn);\n+        }\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public StreamObserver<ArtifactApi.ArtifactResponseWrapper> reverseArtifactRetrievalService(\n+      StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+\n+    return new StreamObserver<ArtifactApi.ArtifactResponseWrapper>() {\n+\n+      /** The maximum number of parallel threads to use to stage. */\n+      public static final int THREAD_POOL_SIZE = 10;\n+\n+      /** The maximum number of bytes to buffer across all writes before throttling. */\n+      public static final int MAX_PENDING_BYTES = 100 << 20; // 100 MB\n+\n+      IdGenerator idGenerator = IdGenerators.incrementingLongs();\n+\n+      String stagingToken;\n+      Map<String, List<RunnerApi.ArtifactInformation>> toResolve;\n+      Map<String, List<Future<RunnerApi.ArtifactInformation>>> stagedFutures;\n+      ExecutorService stagingExecutor;\n+      OverflowingSemaphore totalPendingBytes;\n+\n+      State state = State.START;\n+      Queue<String> pendingResolves;\n+      String currentEnvironment;\n+      Queue<RunnerApi.ArtifactInformation> pendingGets;\n+      BlockingQueue<ByteString> currentOutput;\n+\n+      @Override\n+      @SuppressFBWarnings(value = \"SF_SWITCH_FALLTHROUGH\", justification = \"fallthrough intended\")\n+      // May be called by different threads for the same request; synchronized for memory\n+      // synchronization.\n+      public synchronized void onNext(ArtifactApi.ArtifactResponseWrapper responseWrapper) {\n+        switch (state) {\n+          case START:\n+            stagingToken = responseWrapper.getStagingToken();\n+            LOG.info(\"Staging artifacts for {}.\", stagingToken);\n+            toResolve = toStage.get(stagingToken);\n+            stagedFutures = new ConcurrentHashMap<>();\n+            pendingResolves = new ArrayDeque<>();\n+            pendingResolves.addAll(toResolve.keySet());\n+            stagingExecutor = Executors.newFixedThreadPool(THREAD_POOL_SIZE);\n+            totalPendingBytes = new OverflowingSemaphore(MAX_PENDING_BYTES);\n+            resolveNextEnvironment(responseObserver);\n+            break;\n+\n+          case RESOLVE:\n+            {\n+              currentEnvironment = pendingResolves.remove();\n+              stagedFutures.put(currentEnvironment, new ArrayList<>());\n+              pendingGets = new ArrayDeque<>();\n+              for (RunnerApi.ArtifactInformation artifact :\n+                  responseWrapper.getResolveArtifactResponse().getReplacementsList()) {\n+                Optional<RunnerApi.ArtifactInformation> fetched = getLocal(artifact);\n+                if (fetched.isPresent()) {\n+                  stagedFutures\n+                      .get(currentEnvironment)\n+                      .add(CompletableFuture.completedFuture(fetched.get()));\n+                } else {\n+                  pendingGets.add(artifact);\n+                  responseObserver.onNext(\n+                      ArtifactApi.ArtifactRequestWrapper.newBuilder()\n+                          .setGetArtifact(\n+                              ArtifactApi.GetArtifactRequest.newBuilder().setArtifact(artifact))\n+                          .build());\n+                }\n+              }\n+              LOG.info(\n+                  \"Getting {} artifacts for {}.{}.\",\n+                  pendingGets.size(),\n+                  stagingToken,\n+                  pendingResolves.peek());\n+              if (pendingGets.isEmpty()) {\n+                resolveNextEnvironment(responseObserver);\n+              } else {\n+                state = State.GET;\n+              }\n+              break;\n+            }\n+\n+          case GET:\n+            RunnerApi.ArtifactInformation currentArtifact = pendingGets.remove();\n+            String name = createFilename(currentEnvironment, currentArtifact);\n+            try {\n+              LOG.debug(\"Storing artifacts for {} as {}\", stagingToken, name);\n+              currentOutput = new ArrayBlockingQueue<ByteString>(100);\n+              stagedFutures\n+                  .get(currentEnvironment)\n+                  .add(\n+                      stagingExecutor.submit(\n+                          new StoreArtifact(\n+                              stagingToken,\n+                              name,\n+                              currentArtifact,\n+                              currentOutput,\n+                              totalPendingBytes)));\n+            } catch (Exception exn) {\n+              LOG.error(\"Error submitting.\", exn);\n+              responseObserver.onError(exn);\n+            }\n+            state = State.GETCHUNK;\n+            // fall through\n+\n+          case GETCHUNK:\n+            try {\n+              ByteString chunk = responseWrapper.getGetArtifactResponse().getData();\n+              if (chunk.size() > 0) { // Make sure we don't accidentally send the EOF value.\n+                totalPendingBytes.aquire(chunk.size());\n+                currentOutput.put(chunk);\n+              }\n+              if (responseWrapper.getIsLast()) {\n+                currentOutput.put(ByteString.EMPTY); // The EOF value.\n+                if (pendingGets.isEmpty()) {\n+                  resolveNextEnvironment(responseObserver);\n+                } else {\n+                  state = State.GET;\n+                  LOG.debug(\"Waiting for {}\", pendingGets.peek());\n+                }\n+              }\n+            } catch (Exception exn) {\n+              LOG.error(\"Error submitting.\", exn);\n+              onError(exn);\n+            }\n+            break;\n+\n+          default:\n+            responseObserver.onError(\n+                new StatusException(\n+                    Status.INVALID_ARGUMENT.withDescription(\"Illegal state \" + state)));\n+        }\n+      }\n+\n+      private void resolveNextEnvironment(\n+          StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+        if (pendingResolves.isEmpty()) {\n+          finishStaging(responseObserver);\n+        } else {\n+          state = State.RESOLVE;\n+          LOG.info(\"Resolving artifacts for {}.{}.\", stagingToken, pendingResolves.peek());\n+          responseObserver.onNext(\n+              ArtifactApi.ArtifactRequestWrapper.newBuilder()\n+                  .setResolveArtifact(\n+                      ArtifactApi.ResolveArtifactsRequest.newBuilder()\n+                          .addAllArtifacts(toResolve.get(pendingResolves.peek())))\n+                  .build());\n+        }\n+      }\n+\n+      private void finishStaging(\n+          StreamObserver<ArtifactApi.ArtifactRequestWrapper> responseObserver) {\n+        LOG.debug(\"Finishing staging for {}.\", stagingToken);\n+        Map<String, List<RunnerApi.ArtifactInformation>> staged = new HashMap<>();\n+        try {\n+          for (Map.Entry<String, List<Future<RunnerApi.ArtifactInformation>>> entry :\n+              stagedFutures.entrySet()) {\n+            List<RunnerApi.ArtifactInformation> envStaged = new ArrayList<>();\n+            for (Future<RunnerApi.ArtifactInformation> future : entry.getValue()) {\n+              envStaged.add(future.get());\n+            }\n+            staged.put(entry.getKey(), envStaged);\n+          }\n+          ArtifactStagingService.this.staged.put(stagingToken, staged);\n+          stagingExecutor.shutdown();\n+          state = State.DONE;\n+          LOG.info(\"Artifacts fully staged for {}.\", stagingToken);\n+          responseObserver.onCompleted();\n+        } catch (Exception exn) {\n+          LOG.error(\"Error staging artifacts\", exn);\n+          responseObserver.onError(exn);\n+          state = State.ERROR;\n+          return;\n+        }\n+      }\n+\n+      /**\n+       * Return an alternative artifact if we do not need to get this over the artifact API, or\n+       * possibly at all.\n+       */\n+      private Optional<RunnerApi.ArtifactInformation> getLocal(\n+          RunnerApi.ArtifactInformation artifact) {\n+        return Optional.empty();\n+      }\n+\n+      /**\n+       * Attempts to provide a reasonable filename for the artifact.\n+       *\n+       * @param index a monotonically increasing index, which provides uniqueness\n+       * @param environment the environment id\n+       * @param artifact the artifact itself\n+       */\n+      private String createFilename(String environment, RunnerApi.ArtifactInformation artifact) {\n+        String path;\n+        try {\n+          if (artifact.getRoleUrn().equals(ArtifactRetrievalService.STAGING_TO_ARTIFACT_URN)) {\n+            path =\n+                RunnerApi.ArtifactStagingToRolePayload.parseFrom(artifact.getRolePayload())\n+                    .getStagedName();\n+          } else if (artifact.getTypeUrn().equals(ArtifactRetrievalService.FILE_ARTIFACT_URN)) {\n+            path = RunnerApi.ArtifactFilePayload.parseFrom(artifact.getTypePayload()).getPath();\n+          } else if (artifact.getTypeUrn().equals(ArtifactRetrievalService.URL_ARTIFACT_URN)) {\n+            path = RunnerApi.ArtifactUrlPayload.parseFrom(artifact.getTypePayload()).getUrl();\n+          } else {\n+            path = \"artifact\";\n+          }\n+        } catch (InvalidProtocolBufferException exn) {\n+          throw new RuntimeException(exn);\n+        }\n+        // Limit to the last contiguous alpha-numeric sequence. In particular, this will exclude\n+        // all path separators.\n+        List<String> components = Splitter.onPattern(\"[^A-Za-z-_.]]\").splitToList(path);\n+        String base = components.get(components.size() - 1);\n+        return clip(\n+            String.format(\"%s-%s-%s\", idGenerator.getId(), clip(environment, 25), base), 100);\n+      }\n+\n+      private String clip(String s, int maxLength) {\n+        return s.length() < maxLength ? s : s.substring(0, maxLength);\n+      }\n+\n+      @Override\n+      public void onError(Throwable throwable) {\n+        stagingExecutor.shutdownNow();\n+        LOG.error(\"Error staging artifacts\", throwable);\n+        state = State.ERROR;\n+      }\n+\n+      @Override\n+      public void onCompleted() {\n+        Preconditions.checkArgument(state == State.DONE);\n+      }\n+    };\n+  }\n+\n+  @Override\n+  public void close() throws Exception {\n+    // Nothing to close.\n+  }\n+\n+  /**\n+   * Lazily stages artifacts by letting an ArtifactStagingService resolve and request artifacts.\n+   *\n+   * @param retrievalService an ArtifactRetrievalService used to resolve and retrieve artifacts\n+   * @param stagingService an ArtifactStagingService stub which will request artifacts\n+   * @param stagingToken the staging token of the job whose artifacts will be retrieved\n+   * @throws InterruptedException\n+   * @throws IOException\n+   */\n+  public static void offer(\n+      ArtifactRetrievalService retrievalService,\n+      ArtifactStagingServiceGrpc.ArtifactStagingServiceStub stagingService,\n+      String stagingToken)\n+      throws ExecutionException, InterruptedException {\n+    new StagingDriver(retrievalService, stagingService, stagingToken).getCompletionFuture().get();\n+  }\n+\n+  /** Actually implements the reverse retrieval protocol. */\n+  private static class StagingDriver implements StreamObserver<ArtifactApi.ArtifactRequestWrapper> {\n+\n+    private final ArtifactRetrievalService retrievalService;\n+    private final StreamObserver<ArtifactApi.ArtifactResponseWrapper> responseObserver;\n+    private final CompletableFuture<Void> completionFuture;\n+\n+    public StagingDriver(\n+        ArtifactRetrievalService retrievalService,\n+        ArtifactStagingServiceGrpc.ArtifactStagingServiceStub stagingService,\n+        String stagingToken) {\n+      this.retrievalService = retrievalService;\n+      responseObserver = stagingService.reverseArtifactRetrievalService(this);\n+      responseObserver.onNext(\n+          ArtifactApi.ArtifactResponseWrapper.newBuilder().setStagingToken(stagingToken).build());\n+      completionFuture = new CompletableFuture<Void>();\n+    }\n+\n+    public CompletableFuture<?> getCompletionFuture() {\n+      return completionFuture;\n+    }\n+\n+    @Override\n+    public void onNext(ArtifactApi.ArtifactRequestWrapper requestWrapper) {\n+      if (requestWrapper.hasResolveArtifact()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7b1429d1c9da5b90e2a91c0052359b1f719df2a1"}, "originalPosition": 534}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "01af3aad89fa2bd3cd04f0eb455c7baf533295f7", "author": {"user": {"login": "robertwb", "name": "Robert Bradshaw"}}, "url": "https://github.com/apache/beam/commit/01af3aad89fa2bd3cd04f0eb455c7baf533295f7", "committedDate": "2020-04-23T16:08:16Z", "message": "Use futures, better error handling."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d377f74bc7e7cc3cdf8bdcfaeb4585c3d329ca39", "author": {"user": {"login": "robertwb", "name": "Robert Bradshaw"}}, "url": "https://github.com/apache/beam/commit/d377f74bc7e7cc3cdf8bdcfaeb4585c3d329ca39", "committedDate": "2020-04-22T23:46:04Z", "message": "More complete treatment of errors."}, "afterCommit": {"oid": "01af3aad89fa2bd3cd04f0eb455c7baf533295f7", "author": {"user": {"login": "robertwb", "name": "Robert Bradshaw"}}, "url": "https://github.com/apache/beam/commit/01af3aad89fa2bd3cd04f0eb455c7baf533295f7", "committedDate": "2020-04-23T16:08:16Z", "message": "Use futures, better error handling."}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4526, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}