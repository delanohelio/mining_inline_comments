{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDIxMDQwOTYx", "number": 11766, "reviewThreads": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMVQyMzowNzo1M1rOEBiqmQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQxODowMzo1M1rOECrGuQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcwMDUxOTkzOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/frames_test.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMVQyMzowNzo1M1rOGdc5fQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQyMjo0NDozNVrOGeGZbA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzUzNTM1Nw==", "bodyText": "What is this for?", "url": "https://github.com/apache/beam/pull/11766#discussion_r433535357", "createdAt": "2020-06-01T23:07:53Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/frames_test.py", "diffHunk": "@@ -23,6 +23,7 @@\n \n from apache_beam.dataframe import expressions\n from apache_beam.dataframe import frame_base\n+from apache_beam.dataframe import frames  # pylint: disable=unused-import", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "83781367c9e16625c14146076dd0e44bac9ce746"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDIxNTI3Ng==", "bodyText": "It makes sure the wrapper code is populated with the various types of frames.", "url": "https://github.com/apache/beam/pull/11766#discussion_r434215276", "createdAt": "2020-06-02T22:44:35Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/frames_test.py", "diffHunk": "@@ -23,6 +23,7 @@\n \n from apache_beam.dataframe import expressions\n from apache_beam.dataframe import frame_base\n+from apache_beam.dataframe import frames  # pylint: disable=unused-import", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzUzNTM1Nw=="}, "originalCommit": {"oid": "83781367c9e16625c14146076dd0e44bac9ce746"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcwMDUyMzY3OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/partitionings.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMVQyMzowOTo1OFrOGdc76A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQyMjo0MjoxMFrOGeGWZQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzUzNTk3Ng==", "bodyText": "Previously this was 10 right (in partitioned_by_index)? Assuming this intentional, but I just wanted to double-check its not a typo.", "url": "https://github.com/apache/beam/pull/11766#discussion_r433535976", "createdAt": "2020-06-01T23:09:58Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/partitionings.py", "diffHunk": "@@ -0,0 +1,133 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+from __future__ import absolute_import\n+\n+from typing import Any\n+from typing import Iterable\n+from typing import TypeVar\n+\n+import pandas as pd\n+\n+Frame = TypeVar('Frame', bound=pd.core.generic.NDFrame)\n+\n+\n+class Partitioning(object):\n+  \"\"\"A class representing a (consistent) partitioning of dataframe objects.\n+  \"\"\"\n+  def is_subpartition_of(self, other):\n+    # type: (Partitioning) -> bool\n+\n+    \"\"\"Returns whether self is a sub-partition of other.\n+\n+    Specifically, returns whether something partitioned by self is necissarily\n+    also partitioned by other.\n+    \"\"\"\n+    raise NotImplementedError\n+\n+  def partition_fn(self, df):\n+    # type: (Frame) -> Iterable[Tuple[Any, Frame]]\n+\n+    \"\"\"A callable that actually performs the partitioning of a Frame df.\n+\n+    This will be invoked via a FlatMap in conjunction with a GroupKey to\n+    achieve the desired partitioning.\n+    \"\"\"\n+    raise NotImplementedError\n+\n+\n+class Index(Partitioning):\n+  \"\"\"A partitioning by index (either fully or partially).\n+\n+  If the set of \"levels\" of the index to consider is not specified, the entire\n+  index is used.\n+\n+  These form a partial order, given by\n+\n+      Nothing() < Index([i]) < Index([i, j]) < ... < Index() < Singleton()\n+  \"\"\"\n+\n+  _INDEX_PARTITIONS = 100", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "83781367c9e16625c14146076dd0e44bac9ce746"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDIxNDUwMQ==", "bodyText": "Oh, I was just testing things. I'll change it back. (It would be great to get rid of this altogether, as it limits parallelism, but that's not part of this change.)", "url": "https://github.com/apache/beam/pull/11766#discussion_r434214501", "createdAt": "2020-06-02T22:42:10Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/partitionings.py", "diffHunk": "@@ -0,0 +1,133 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+from __future__ import absolute_import\n+\n+from typing import Any\n+from typing import Iterable\n+from typing import TypeVar\n+\n+import pandas as pd\n+\n+Frame = TypeVar('Frame', bound=pd.core.generic.NDFrame)\n+\n+\n+class Partitioning(object):\n+  \"\"\"A class representing a (consistent) partitioning of dataframe objects.\n+  \"\"\"\n+  def is_subpartition_of(self, other):\n+    # type: (Partitioning) -> bool\n+\n+    \"\"\"Returns whether self is a sub-partition of other.\n+\n+    Specifically, returns whether something partitioned by self is necissarily\n+    also partitioned by other.\n+    \"\"\"\n+    raise NotImplementedError\n+\n+  def partition_fn(self, df):\n+    # type: (Frame) -> Iterable[Tuple[Any, Frame]]\n+\n+    \"\"\"A callable that actually performs the partitioning of a Frame df.\n+\n+    This will be invoked via a FlatMap in conjunction with a GroupKey to\n+    achieve the desired partitioning.\n+    \"\"\"\n+    raise NotImplementedError\n+\n+\n+class Index(Partitioning):\n+  \"\"\"A partitioning by index (either fully or partially).\n+\n+  If the set of \"levels\" of the index to consider is not specified, the entire\n+  index is used.\n+\n+  These form a partial order, given by\n+\n+      Nothing() < Index([i]) < Index([i, j]) < ... < Index() < Singleton()\n+  \"\"\"\n+\n+  _INDEX_PARTITIONS = 100", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzUzNTk3Ng=="}, "originalCommit": {"oid": "83781367c9e16625c14146076dd0e44bac9ce746"}, "originalPosition": 63}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcwMDUzNjE1OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/partitionings.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMVQyMzoxNjo1NFrOGddDpQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQyMjo0OToxNFrOGeGfgg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzUzNzk1Nw==", "bodyText": "This ordering is determined by is_subpartition_of correct? I wonder if there's a way to clearly say that in this docstring?", "url": "https://github.com/apache/beam/pull/11766#discussion_r433537957", "createdAt": "2020-06-01T23:16:54Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/partitionings.py", "diffHunk": "@@ -0,0 +1,133 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+from __future__ import absolute_import\n+\n+from typing import Any\n+from typing import Iterable\n+from typing import TypeVar\n+\n+import pandas as pd\n+\n+Frame = TypeVar('Frame', bound=pd.core.generic.NDFrame)\n+\n+\n+class Partitioning(object):\n+  \"\"\"A class representing a (consistent) partitioning of dataframe objects.\n+  \"\"\"\n+  def is_subpartition_of(self, other):\n+    # type: (Partitioning) -> bool\n+\n+    \"\"\"Returns whether self is a sub-partition of other.\n+\n+    Specifically, returns whether something partitioned by self is necissarily\n+    also partitioned by other.\n+    \"\"\"\n+    raise NotImplementedError\n+\n+  def partition_fn(self, df):\n+    # type: (Frame) -> Iterable[Tuple[Any, Frame]]\n+\n+    \"\"\"A callable that actually performs the partitioning of a Frame df.\n+\n+    This will be invoked via a FlatMap in conjunction with a GroupKey to\n+    achieve the desired partitioning.\n+    \"\"\"\n+    raise NotImplementedError\n+\n+\n+class Index(Partitioning):\n+  \"\"\"A partitioning by index (either fully or partially).\n+\n+  If the set of \"levels\" of the index to consider is not specified, the entire\n+  index is used.\n+\n+  These form a partial order, given by\n+\n+      Nothing() < Index([i]) < Index([i, j]) < ... < Index() < Singleton()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "83781367c9e16625c14146076dd0e44bac9ce746"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDIxNjgzNA==", "bodyText": "Clarified.", "url": "https://github.com/apache/beam/pull/11766#discussion_r434216834", "createdAt": "2020-06-02T22:49:14Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/partitionings.py", "diffHunk": "@@ -0,0 +1,133 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+from __future__ import absolute_import\n+\n+from typing import Any\n+from typing import Iterable\n+from typing import TypeVar\n+\n+import pandas as pd\n+\n+Frame = TypeVar('Frame', bound=pd.core.generic.NDFrame)\n+\n+\n+class Partitioning(object):\n+  \"\"\"A class representing a (consistent) partitioning of dataframe objects.\n+  \"\"\"\n+  def is_subpartition_of(self, other):\n+    # type: (Partitioning) -> bool\n+\n+    \"\"\"Returns whether self is a sub-partition of other.\n+\n+    Specifically, returns whether something partitioned by self is necissarily\n+    also partitioned by other.\n+    \"\"\"\n+    raise NotImplementedError\n+\n+  def partition_fn(self, df):\n+    # type: (Frame) -> Iterable[Tuple[Any, Frame]]\n+\n+    \"\"\"A callable that actually performs the partitioning of a Frame df.\n+\n+    This will be invoked via a FlatMap in conjunction with a GroupKey to\n+    achieve the desired partitioning.\n+    \"\"\"\n+    raise NotImplementedError\n+\n+\n+class Index(Partitioning):\n+  \"\"\"A partitioning by index (either fully or partially).\n+\n+  If the set of \"levels\" of the index to consider is not specified, the entire\n+  index is used.\n+\n+  These form a partial order, given by\n+\n+      Nothing() < Index([i]) < Index([i, j]) < ... < Index() < Singleton()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzUzNzk1Nw=="}, "originalCommit": {"oid": "83781367c9e16625c14146076dd0e44bac9ce746"}, "originalPosition": 60}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcwMDUzODAzOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/partitionings.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMVQyMzoxNzo1OFrOGddExA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQyMjo1MDo0OVrOGeGhaQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzUzODI0NA==", "bodyText": "nit: I think I'd prefer is_subpartitioning_of", "url": "https://github.com/apache/beam/pull/11766#discussion_r433538244", "createdAt": "2020-06-01T23:17:58Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/partitionings.py", "diffHunk": "@@ -0,0 +1,133 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+from __future__ import absolute_import\n+\n+from typing import Any\n+from typing import Iterable\n+from typing import TypeVar\n+\n+import pandas as pd\n+\n+Frame = TypeVar('Frame', bound=pd.core.generic.NDFrame)\n+\n+\n+class Partitioning(object):\n+  \"\"\"A class representing a (consistent) partitioning of dataframe objects.\n+  \"\"\"\n+  def is_subpartition_of(self, other):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "83781367c9e16625c14146076dd0e44bac9ce746"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDIxNzMyMQ==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/11766#discussion_r434217321", "createdAt": "2020-06-02T22:50:49Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/partitionings.py", "diffHunk": "@@ -0,0 +1,133 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+from __future__ import absolute_import\n+\n+from typing import Any\n+from typing import Iterable\n+from typing import TypeVar\n+\n+import pandas as pd\n+\n+Frame = TypeVar('Frame', bound=pd.core.generic.NDFrame)\n+\n+\n+class Partitioning(object):\n+  \"\"\"A class representing a (consistent) partitioning of dataframe objects.\n+  \"\"\"\n+  def is_subpartition_of(self, other):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzUzODI0NA=="}, "originalCommit": {"oid": "83781367c9e16625c14146076dd0e44bac9ce746"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcwMDU2MTIxOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/expressions.py", "isResolved": false, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMVQyMzozMToxN1rOGddTGQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQwMDo0OTo0NFrOGfc7JQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzU0MTkxMw==", "bodyText": "The meaning of this function is a little confusing now since it implies some connection to the input partitioning, but it also has it's own partitioning.  Would renaming it to outputs_.. or produces_.. still be accurate, or is the output partitioning actually a function of both \"preserves\" and the input?\nI also think we should consider changing .._partition_by to .._partitioning for clarity.", "url": "https://github.com/apache/beam/pull/11766#discussion_r433541913", "createdAt": "2020-06-01T23:31:17Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/expressions.py", "diffHunk": "@@ -85,16 +87,10 @@ def evaluate_at(self, session):  # type: (Session) -> T\n     \"\"\"Returns the result of self with the bindings given in session.\"\"\"\n     raise NotImplementedError(type(self))\n \n-  def requires_partition_by_index(self):  # type: () -> bool\n-    \"\"\"Whether this expression requires its argument(s) to be partitioned\n-    by index.\"\"\"\n-    # TODO: It might be necessary to support partitioning by part of the index,\n-    # for some args, which would require returning more than a boolean here.\n+  def requires_partition_by(self):  # type: () -> Partitioning\n     raise NotImplementedError(type(self))\n \n-  def preserves_partition_by_index(self):  # type: () -> bool\n-    \"\"\"Whether the result of this expression will be partitioned by index\n-    whenever all of its inputs are partitioned by index.\"\"\"\n+  def preserves_partition_by(self):  # type: () -> Partitioning", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "83781367c9e16625c14146076dd0e44bac9ce746"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDIxNTEyNw==", "bodyText": "Yes, it's a function of both the input and the operation. E.g. an elementwise operation preserves all existing partitioning, but does not guarantee any.", "url": "https://github.com/apache/beam/pull/11766#discussion_r434215127", "createdAt": "2020-06-02T22:44:04Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/expressions.py", "diffHunk": "@@ -85,16 +87,10 @@ def evaluate_at(self, session):  # type: (Session) -> T\n     \"\"\"Returns the result of self with the bindings given in session.\"\"\"\n     raise NotImplementedError(type(self))\n \n-  def requires_partition_by_index(self):  # type: () -> bool\n-    \"\"\"Whether this expression requires its argument(s) to be partitioned\n-    by index.\"\"\"\n-    # TODO: It might be necessary to support partitioning by part of the index,\n-    # for some args, which would require returning more than a boolean here.\n+  def requires_partition_by(self):  # type: () -> Partitioning\n     raise NotImplementedError(type(self))\n \n-  def preserves_partition_by_index(self):  # type: () -> bool\n-    \"\"\"Whether the result of this expression will be partitioned by index\n-    whenever all of its inputs are partitioned by index.\"\"\"\n+  def preserves_partition_by(self):  # type: () -> Partitioning", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzU0MTkxMw=="}, "originalCommit": {"oid": "83781367c9e16625c14146076dd0e44bac9ce746"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDkxNjg0NA==", "bodyText": "Ah makes sense. So perhaps \"preserves\" could be thought of as an upper bound on the partitioning of the output (similar to how \"requires\" is a lower bound on the partitioning of the input).\nIt looks like every current expression has preserves set to either Nothing or Singleton. Wouldn't it be simpler to just keep preserves as a boolean? Or maybe you have some other expression in mind where a boolean won't be sufficient?", "url": "https://github.com/apache/beam/pull/11766#discussion_r434916844", "createdAt": "2020-06-03T23:48:25Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/expressions.py", "diffHunk": "@@ -85,16 +87,10 @@ def evaluate_at(self, session):  # type: (Session) -> T\n     \"\"\"Returns the result of self with the bindings given in session.\"\"\"\n     raise NotImplementedError(type(self))\n \n-  def requires_partition_by_index(self):  # type: () -> bool\n-    \"\"\"Whether this expression requires its argument(s) to be partitioned\n-    by index.\"\"\"\n-    # TODO: It might be necessary to support partitioning by part of the index,\n-    # for some args, which would require returning more than a boolean here.\n+  def requires_partition_by(self):  # type: () -> Partitioning\n     raise NotImplementedError(type(self))\n \n-  def preserves_partition_by_index(self):  # type: () -> bool\n-    \"\"\"Whether the result of this expression will be partitioned by index\n-    whenever all of its inputs are partitioned by index.\"\"\"\n+  def preserves_partition_by(self):  # type: () -> Partitioning", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzU0MTkxMw=="}, "originalCommit": {"oid": "83781367c9e16625c14146076dd0e44bac9ce746"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTM3MzczMg==", "bodyText": "There are operations, such as setting a column to be an additional level of the index, that would do partial preservation. But perhaps that's not worth the additional complexity. I can change this to a boolean if you'd rather.", "url": "https://github.com/apache/beam/pull/11766#discussion_r435373732", "createdAt": "2020-06-04T16:02:48Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/expressions.py", "diffHunk": "@@ -85,16 +87,10 @@ def evaluate_at(self, session):  # type: (Session) -> T\n     \"\"\"Returns the result of self with the bindings given in session.\"\"\"\n     raise NotImplementedError(type(self))\n \n-  def requires_partition_by_index(self):  # type: () -> bool\n-    \"\"\"Whether this expression requires its argument(s) to be partitioned\n-    by index.\"\"\"\n-    # TODO: It might be necessary to support partitioning by part of the index,\n-    # for some args, which would require returning more than a boolean here.\n+  def requires_partition_by(self):  # type: () -> Partitioning\n     raise NotImplementedError(type(self))\n \n-  def preserves_partition_by_index(self):  # type: () -> bool\n-    \"\"\"Whether the result of this expression will be partitioned by index\n-    whenever all of its inputs are partitioned by index.\"\"\"\n+  def preserves_partition_by(self):  # type: () -> Partitioning", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzU0MTkxMw=="}, "originalCommit": {"oid": "83781367c9e16625c14146076dd0e44bac9ce746"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTQyMjUxMQ==", "bodyText": "Ah that makes sense. And I guess the name \"preserves\" is actually intuitive now that I understand it's setting an upper bound on the output partitioning.\nI think the complexity is worth it, unless there's a chance those operations will never materialize. Can you just add a docstring indicating that \"preserves\" sets an upper bound on the output partitioning (or any other language to make sure readers can grok it)? A similar comment about requires would be good too.", "url": "https://github.com/apache/beam/pull/11766#discussion_r435422511", "createdAt": "2020-06-04T17:21:19Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/expressions.py", "diffHunk": "@@ -85,16 +87,10 @@ def evaluate_at(self, session):  # type: (Session) -> T\n     \"\"\"Returns the result of self with the bindings given in session.\"\"\"\n     raise NotImplementedError(type(self))\n \n-  def requires_partition_by_index(self):  # type: () -> bool\n-    \"\"\"Whether this expression requires its argument(s) to be partitioned\n-    by index.\"\"\"\n-    # TODO: It might be necessary to support partitioning by part of the index,\n-    # for some args, which would require returning more than a boolean here.\n+  def requires_partition_by(self):  # type: () -> Partitioning\n     raise NotImplementedError(type(self))\n \n-  def preserves_partition_by_index(self):  # type: () -> bool\n-    \"\"\"Whether the result of this expression will be partitioned by index\n-    whenever all of its inputs are partitioned by index.\"\"\"\n+  def preserves_partition_by(self):  # type: () -> Partitioning", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzU0MTkxMw=="}, "originalCommit": {"oid": "83781367c9e16625c14146076dd0e44bac9ce746"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTYzMjkzMw==", "bodyText": "Docstring comments added.", "url": "https://github.com/apache/beam/pull/11766#discussion_r435632933", "createdAt": "2020-06-05T00:49:44Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/expressions.py", "diffHunk": "@@ -85,16 +87,10 @@ def evaluate_at(self, session):  # type: (Session) -> T\n     \"\"\"Returns the result of self with the bindings given in session.\"\"\"\n     raise NotImplementedError(type(self))\n \n-  def requires_partition_by_index(self):  # type: () -> bool\n-    \"\"\"Whether this expression requires its argument(s) to be partitioned\n-    by index.\"\"\"\n-    # TODO: It might be necessary to support partitioning by part of the index,\n-    # for some args, which would require returning more than a boolean here.\n+  def requires_partition_by(self):  # type: () -> Partitioning\n     raise NotImplementedError(type(self))\n \n-  def preserves_partition_by_index(self):  # type: () -> bool\n-    \"\"\"Whether the result of this expression will be partitioned by index\n-    whenever all of its inputs are partitioned by index.\"\"\"\n+  def preserves_partition_by(self):  # type: () -> Partitioning", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzU0MTkxMw=="}, "originalCommit": {"oid": "83781367c9e16625c14146076dd0e44bac9ce746"}, "originalPosition": 24}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcxMjI1NDQ4OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/partitionings.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQxNzoyNzo0M1rOGfQUbg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQwMDo1NTo0OFrOGfdAzg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTQyNjQxNA==", "bodyText": "I think that making Nothing falsy and relying on that in logic elsewhere harms readability. What do you think about dropping this and just explicitly checking for Nothing when needed?", "url": "https://github.com/apache/beam/pull/11766#discussion_r435426414", "createdAt": "2020-06-04T17:27:43Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/partitionings.py", "diffHunk": "@@ -0,0 +1,136 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+from __future__ import absolute_import\n+\n+from typing import Any\n+from typing import Iterable\n+from typing import TypeVar\n+\n+import pandas as pd\n+\n+Frame = TypeVar('Frame', bound=pd.core.generic.NDFrame)\n+\n+\n+class Partitioning(object):\n+  \"\"\"A class representing a (consistent) partitioning of dataframe objects.\n+  \"\"\"\n+  def is_subpartitioning_of(self, other):\n+    # type: (Partitioning) -> bool\n+\n+    \"\"\"Returns whether self is a sub-partition of other.\n+\n+    Specifically, returns whether something partitioned by self is necissarily\n+    also partitioned by other.\n+    \"\"\"\n+    raise NotImplementedError\n+\n+  def partition_fn(self, df):\n+    # type: (Frame) -> Iterable[Tuple[Any, Frame]]\n+\n+    \"\"\"A callable that actually performs the partitioning of a Frame df.\n+\n+    This will be invoked via a FlatMap in conjunction with a GroupKey to\n+    achieve the desired partitioning.\n+    \"\"\"\n+    raise NotImplementedError\n+\n+\n+class Index(Partitioning):\n+  \"\"\"A partitioning by index (either fully or partially).\n+\n+  If the set of \"levels\" of the index to consider is not specified, the entire\n+  index is used.\n+\n+  These form a partial order, given by\n+\n+      Nothing() < Index([i]) < Index([i, j]) < ... < Index() < Singleton()\n+\n+  The ordering is implemented via the is_subpartitioning_of method, where the\n+  examples on the right are subpartitionings of the examples on the left above.\n+  \"\"\"\n+\n+  _INDEX_PARTITIONS = 10\n+\n+  def __init__(self, levels=None):\n+    self._levels = levels\n+\n+  def __eq__(self, other):\n+    return type(self) == type(other) and self._levels == other._levels\n+\n+  def __hash__(self):\n+    if self._levels:\n+      return hash(tuple(sorted(self._levels)))\n+    else:\n+      return hash(type(self))\n+\n+  def is_subpartitioning_of(self, other):\n+    if isinstance(other, Nothing):\n+      return True\n+    elif isinstance(other, Index):\n+      if self._levels is None:\n+        return True\n+      elif other._levels is None:\n+        return False\n+      else:\n+        return all(level in other._levels for level in self._levels)\n+    else:\n+      return False\n+\n+  def partition_fn(self, df):\n+    if self._levels is None:\n+      levels = list(range(df.index.nlevels))\n+    else:\n+      levels = self._levels\n+    hashes = sum(\n+        pd.util.hash_array(df.index.get_level_values(level))\n+        for level in levels)\n+    for key in range(self._INDEX_PARTITIONS):\n+      yield key, df[hashes % self._INDEX_PARTITIONS == key]\n+\n+\n+class Singleton(Partitioning):\n+  \"\"\"A partitioning co-locating all data to a singleton partition.\n+  \"\"\"\n+  def __eq__(self, other):\n+    return type(self) == type(other)\n+\n+  def __hash__(self):\n+    return hash(type(self))\n+\n+  def is_subpartitioning_of(self, other):\n+    return True\n+\n+  def partition_fn(self, df):\n+    yield None, df\n+\n+\n+class Nothing(Partitioning):\n+  \"\"\"A partitioning imposing no constraints on the actual partitioning.\n+  \"\"\"\n+  def __eq__(self, other):\n+    return type(self) == type(other)\n+\n+  def __hash__(self):\n+    return hash(type(self))\n+\n+  def is_subpartitioning_of(self, other):\n+    return not other\n+\n+  def __bool__(self):\n+    return False\n+\n+  __nonzero__ = __bool__", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46ac950199789a7c1b84df2146271b0db61f5cfa"}, "originalPosition": 136}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTYzNDM4Mg==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/11766#discussion_r435634382", "createdAt": "2020-06-05T00:55:48Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/partitionings.py", "diffHunk": "@@ -0,0 +1,136 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+from __future__ import absolute_import\n+\n+from typing import Any\n+from typing import Iterable\n+from typing import TypeVar\n+\n+import pandas as pd\n+\n+Frame = TypeVar('Frame', bound=pd.core.generic.NDFrame)\n+\n+\n+class Partitioning(object):\n+  \"\"\"A class representing a (consistent) partitioning of dataframe objects.\n+  \"\"\"\n+  def is_subpartitioning_of(self, other):\n+    # type: (Partitioning) -> bool\n+\n+    \"\"\"Returns whether self is a sub-partition of other.\n+\n+    Specifically, returns whether something partitioned by self is necissarily\n+    also partitioned by other.\n+    \"\"\"\n+    raise NotImplementedError\n+\n+  def partition_fn(self, df):\n+    # type: (Frame) -> Iterable[Tuple[Any, Frame]]\n+\n+    \"\"\"A callable that actually performs the partitioning of a Frame df.\n+\n+    This will be invoked via a FlatMap in conjunction with a GroupKey to\n+    achieve the desired partitioning.\n+    \"\"\"\n+    raise NotImplementedError\n+\n+\n+class Index(Partitioning):\n+  \"\"\"A partitioning by index (either fully or partially).\n+\n+  If the set of \"levels\" of the index to consider is not specified, the entire\n+  index is used.\n+\n+  These form a partial order, given by\n+\n+      Nothing() < Index([i]) < Index([i, j]) < ... < Index() < Singleton()\n+\n+  The ordering is implemented via the is_subpartitioning_of method, where the\n+  examples on the right are subpartitionings of the examples on the left above.\n+  \"\"\"\n+\n+  _INDEX_PARTITIONS = 10\n+\n+  def __init__(self, levels=None):\n+    self._levels = levels\n+\n+  def __eq__(self, other):\n+    return type(self) == type(other) and self._levels == other._levels\n+\n+  def __hash__(self):\n+    if self._levels:\n+      return hash(tuple(sorted(self._levels)))\n+    else:\n+      return hash(type(self))\n+\n+  def is_subpartitioning_of(self, other):\n+    if isinstance(other, Nothing):\n+      return True\n+    elif isinstance(other, Index):\n+      if self._levels is None:\n+        return True\n+      elif other._levels is None:\n+        return False\n+      else:\n+        return all(level in other._levels for level in self._levels)\n+    else:\n+      return False\n+\n+  def partition_fn(self, df):\n+    if self._levels is None:\n+      levels = list(range(df.index.nlevels))\n+    else:\n+      levels = self._levels\n+    hashes = sum(\n+        pd.util.hash_array(df.index.get_level_values(level))\n+        for level in levels)\n+    for key in range(self._INDEX_PARTITIONS):\n+      yield key, df[hashes % self._INDEX_PARTITIONS == key]\n+\n+\n+class Singleton(Partitioning):\n+  \"\"\"A partitioning co-locating all data to a singleton partition.\n+  \"\"\"\n+  def __eq__(self, other):\n+    return type(self) == type(other)\n+\n+  def __hash__(self):\n+    return hash(type(self))\n+\n+  def is_subpartitioning_of(self, other):\n+    return True\n+\n+  def partition_fn(self, df):\n+    yield None, df\n+\n+\n+class Nothing(Partitioning):\n+  \"\"\"A partitioning imposing no constraints on the actual partitioning.\n+  \"\"\"\n+  def __eq__(self, other):\n+    return type(self) == type(other)\n+\n+  def __hash__(self):\n+    return hash(type(self))\n+\n+  def is_subpartitioning_of(self, other):\n+    return not other\n+\n+  def __bool__(self):\n+    return False\n+\n+  __nonzero__ = __bool__", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTQyNjQxNA=="}, "originalCommit": {"oid": "46ac950199789a7c1b84df2146271b0db61f5cfa"}, "originalPosition": 136}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcxMjI2ODA1OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/partitionings.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQxNzozMToyNlrOGfQc5g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQwMDo1MDozOFrOGfc7_Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTQyODU4Mg==", "bodyText": "Isn't Singleton completely partitioning the data into one element per partition? This description doesn't seem consistent to me, maybe I'm misunderstanding", "url": "https://github.com/apache/beam/pull/11766#discussion_r435428582", "createdAt": "2020-06-04T17:31:26Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/partitionings.py", "diffHunk": "@@ -0,0 +1,136 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+from __future__ import absolute_import\n+\n+from typing import Any\n+from typing import Iterable\n+from typing import TypeVar\n+\n+import pandas as pd\n+\n+Frame = TypeVar('Frame', bound=pd.core.generic.NDFrame)\n+\n+\n+class Partitioning(object):\n+  \"\"\"A class representing a (consistent) partitioning of dataframe objects.\n+  \"\"\"\n+  def is_subpartitioning_of(self, other):\n+    # type: (Partitioning) -> bool\n+\n+    \"\"\"Returns whether self is a sub-partition of other.\n+\n+    Specifically, returns whether something partitioned by self is necissarily\n+    also partitioned by other.\n+    \"\"\"\n+    raise NotImplementedError\n+\n+  def partition_fn(self, df):\n+    # type: (Frame) -> Iterable[Tuple[Any, Frame]]\n+\n+    \"\"\"A callable that actually performs the partitioning of a Frame df.\n+\n+    This will be invoked via a FlatMap in conjunction with a GroupKey to\n+    achieve the desired partitioning.\n+    \"\"\"\n+    raise NotImplementedError\n+\n+\n+class Index(Partitioning):\n+  \"\"\"A partitioning by index (either fully or partially).\n+\n+  If the set of \"levels\" of the index to consider is not specified, the entire\n+  index is used.\n+\n+  These form a partial order, given by\n+\n+      Nothing() < Index([i]) < Index([i, j]) < ... < Index() < Singleton()\n+\n+  The ordering is implemented via the is_subpartitioning_of method, where the\n+  examples on the right are subpartitionings of the examples on the left above.\n+  \"\"\"\n+\n+  _INDEX_PARTITIONS = 10\n+\n+  def __init__(self, levels=None):\n+    self._levels = levels\n+\n+  def __eq__(self, other):\n+    return type(self) == type(other) and self._levels == other._levels\n+\n+  def __hash__(self):\n+    if self._levels:\n+      return hash(tuple(sorted(self._levels)))\n+    else:\n+      return hash(type(self))\n+\n+  def is_subpartitioning_of(self, other):\n+    if isinstance(other, Nothing):\n+      return True\n+    elif isinstance(other, Index):\n+      if self._levels is None:\n+        return True\n+      elif other._levels is None:\n+        return False\n+      else:\n+        return all(level in other._levels for level in self._levels)\n+    else:\n+      return False\n+\n+  def partition_fn(self, df):\n+    if self._levels is None:\n+      levels = list(range(df.index.nlevels))\n+    else:\n+      levels = self._levels\n+    hashes = sum(\n+        pd.util.hash_array(df.index.get_level_values(level))\n+        for level in levels)\n+    for key in range(self._INDEX_PARTITIONS):\n+      yield key, df[hashes % self._INDEX_PARTITIONS == key]\n+\n+\n+class Singleton(Partitioning):\n+  \"\"\"A partitioning co-locating all data to a singleton partition.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46ac950199789a7c1b84df2146271b0db61f5cfa"}, "originalPosition": 106}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTYzMzE0OQ==", "bodyText": "Reworded.", "url": "https://github.com/apache/beam/pull/11766#discussion_r435633149", "createdAt": "2020-06-05T00:50:38Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/partitionings.py", "diffHunk": "@@ -0,0 +1,136 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+from __future__ import absolute_import\n+\n+from typing import Any\n+from typing import Iterable\n+from typing import TypeVar\n+\n+import pandas as pd\n+\n+Frame = TypeVar('Frame', bound=pd.core.generic.NDFrame)\n+\n+\n+class Partitioning(object):\n+  \"\"\"A class representing a (consistent) partitioning of dataframe objects.\n+  \"\"\"\n+  def is_subpartitioning_of(self, other):\n+    # type: (Partitioning) -> bool\n+\n+    \"\"\"Returns whether self is a sub-partition of other.\n+\n+    Specifically, returns whether something partitioned by self is necissarily\n+    also partitioned by other.\n+    \"\"\"\n+    raise NotImplementedError\n+\n+  def partition_fn(self, df):\n+    # type: (Frame) -> Iterable[Tuple[Any, Frame]]\n+\n+    \"\"\"A callable that actually performs the partitioning of a Frame df.\n+\n+    This will be invoked via a FlatMap in conjunction with a GroupKey to\n+    achieve the desired partitioning.\n+    \"\"\"\n+    raise NotImplementedError\n+\n+\n+class Index(Partitioning):\n+  \"\"\"A partitioning by index (either fully or partially).\n+\n+  If the set of \"levels\" of the index to consider is not specified, the entire\n+  index is used.\n+\n+  These form a partial order, given by\n+\n+      Nothing() < Index([i]) < Index([i, j]) < ... < Index() < Singleton()\n+\n+  The ordering is implemented via the is_subpartitioning_of method, where the\n+  examples on the right are subpartitionings of the examples on the left above.\n+  \"\"\"\n+\n+  _INDEX_PARTITIONS = 10\n+\n+  def __init__(self, levels=None):\n+    self._levels = levels\n+\n+  def __eq__(self, other):\n+    return type(self) == type(other) and self._levels == other._levels\n+\n+  def __hash__(self):\n+    if self._levels:\n+      return hash(tuple(sorted(self._levels)))\n+    else:\n+      return hash(type(self))\n+\n+  def is_subpartitioning_of(self, other):\n+    if isinstance(other, Nothing):\n+      return True\n+    elif isinstance(other, Index):\n+      if self._levels is None:\n+        return True\n+      elif other._levels is None:\n+        return False\n+      else:\n+        return all(level in other._levels for level in self._levels)\n+    else:\n+      return False\n+\n+  def partition_fn(self, df):\n+    if self._levels is None:\n+      levels = list(range(df.index.nlevels))\n+    else:\n+      levels = self._levels\n+    hashes = sum(\n+        pd.util.hash_array(df.index.get_level_values(level))\n+        for level in levels)\n+    for key in range(self._INDEX_PARTITIONS):\n+      yield key, df[hashes % self._INDEX_PARTITIONS == key]\n+\n+\n+class Singleton(Partitioning):\n+  \"\"\"A partitioning co-locating all data to a singleton partition.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTQyODU4Mg=="}, "originalCommit": {"oid": "46ac950199789a7c1b84df2146271b0db61f5cfa"}, "originalPosition": 106}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcxMjM4ODQxOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/transforms.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQxODowMzo1M1rOGfRpFQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNVQwMDo1NjoxMFrOGfdBMA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTQ0ODA4NQ==", "bodyText": "Had trouble justifying this logic to myself, ended up writing a little proof which I'm a bit embarrassed to share with a Math PhD:\noutput partitioning of expr = min(expr.preserves, input partitioning)\ninput partitioning >= expr.requires\n\nthus if expr.requires >= required output AND expr.preserves >= required output\nthen output partitioning of expr >= required output\n\nOtherwise we need to go up the tree of inputs to figure out their partitionings\n\nThis may be the least concise way to express this so I don't know if it's worth putting in a comment verbatim, but something to that effect would be helpful (assuming I've got it right)", "url": "https://github.com/apache/beam/pull/11766#discussion_r435448085", "createdAt": "2020-06-04T18:03:53Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/transforms.py", "diffHunk": "@@ -138,36 +140,35 @@ def evaluate(partition, stage=self.stage):\n     class Stage(object):\n       \"\"\"Used to build up a set of operations that can be fused together.\n       \"\"\"\n-      def __init__(self, inputs, is_grouping):\n+      def __init__(self, inputs, partitioning):\n         self.inputs = set(inputs)\n-        self.is_grouping = is_grouping or len(self.inputs) > 1\n+        if len(self.inputs) > 1 and not partitioning:\n+          # We have to shuffle to co-locate, might as well partition.\n+          self.partitioning = partitionings.Index()\n+        else:\n+          self.partitioning = partitioning\n         self.ops = []\n         self.outputs = set()\n \n     # First define some helper functions.\n-    def output_is_partitioned_by_index(expr, stage):\n-      if expr in stage.inputs:\n-        return stage.is_grouping\n-      elif expr.preserves_partition_by_index():\n-        if expr.requires_partition_by_index():\n+    def output_is_partitioned_by(expr, stage, partitioning):\n+      if not partitioning:\n+        return True\n+      elif stage.partitioning == partitionings.Singleton():\n+        # Within a stage, the singleton partitioning is trivially preserved.\n+        return True\n+      elif expr in stage.inputs:\n+        return stage.partitioning.is_subpartitioning_of(partitioning)\n+      elif expr.preserves_partition_by().is_subpartitioning_of(partitioning):\n+        if expr.requires_partition_by().is_subpartitioning_of(partitioning):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "46ac950199789a7c1b84df2146271b0db61f5cfa"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTYzNDQ4MA==", "bodyText": "Yeah, fleshing this out with more comments.", "url": "https://github.com/apache/beam/pull/11766#discussion_r435634480", "createdAt": "2020-06-05T00:56:10Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/transforms.py", "diffHunk": "@@ -138,36 +140,35 @@ def evaluate(partition, stage=self.stage):\n     class Stage(object):\n       \"\"\"Used to build up a set of operations that can be fused together.\n       \"\"\"\n-      def __init__(self, inputs, is_grouping):\n+      def __init__(self, inputs, partitioning):\n         self.inputs = set(inputs)\n-        self.is_grouping = is_grouping or len(self.inputs) > 1\n+        if len(self.inputs) > 1 and not partitioning:\n+          # We have to shuffle to co-locate, might as well partition.\n+          self.partitioning = partitionings.Index()\n+        else:\n+          self.partitioning = partitioning\n         self.ops = []\n         self.outputs = set()\n \n     # First define some helper functions.\n-    def output_is_partitioned_by_index(expr, stage):\n-      if expr in stage.inputs:\n-        return stage.is_grouping\n-      elif expr.preserves_partition_by_index():\n-        if expr.requires_partition_by_index():\n+    def output_is_partitioned_by(expr, stage, partitioning):\n+      if not partitioning:\n+        return True\n+      elif stage.partitioning == partitionings.Singleton():\n+        # Within a stage, the singleton partitioning is trivially preserved.\n+        return True\n+      elif expr in stage.inputs:\n+        return stage.partitioning.is_subpartitioning_of(partitioning)\n+      elif expr.preserves_partition_by().is_subpartitioning_of(partitioning):\n+        if expr.requires_partition_by().is_subpartitioning_of(partitioning):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTQ0ODA4NQ=="}, "originalCommit": {"oid": "46ac950199789a7c1b84df2146271b0db61f5cfa"}, "originalPosition": 64}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3833, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}