{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDg2NzQ0Mzcy", "number": 12841, "reviewThreads": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQwNzowMToxM1rOEj6mHA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxODowNzoxMFrOElEVCg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2MDk1NjQ0OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/io.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQwNzowMToxM1rOHSi3kg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QwMDoyMjo0MFrOHTIeQw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIwNzY5OA==", "bodyText": "Please add pydocs for public API here (or add a TODO/JIRA for this).", "url": "https://github.com/apache/beam/pull/12841#discussion_r489207698", "createdAt": "2020-09-16T07:01:13Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/dataframe/io.py", "diffHunk": "@@ -0,0 +1,178 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+from __future__ import absolute_import\n+\n+from io import BytesIO\n+from io import StringIO\n+from io import TextIOWrapper\n+\n+import pandas as pd\n+\n+import apache_beam as beam\n+from apache_beam import io\n+from apache_beam.dataframe import frame_base\n+\n+\n+def read_csv(path, *args, **kwargs):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ab66e1ce1dfb1308a89a9cea21dbc9502c8c43e8"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTgyMzgxMQ==", "bodyText": "The idea here is to mirror the Pandas APIs. I suppose I should reference them at least.", "url": "https://github.com/apache/beam/pull/12841#discussion_r489823811", "createdAt": "2020-09-17T00:22:40Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/io.py", "diffHunk": "@@ -0,0 +1,178 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+from __future__ import absolute_import\n+\n+from io import BytesIO\n+from io import StringIO\n+from io import TextIOWrapper\n+\n+import pandas as pd\n+\n+import apache_beam as beam\n+from apache_beam import io\n+from apache_beam.dataframe import frame_base\n+\n+\n+def read_csv(path, *args, **kwargs):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIwNzY5OA=="}, "originalCommit": {"oid": "ab66e1ce1dfb1308a89a9cea21dbc9502c8c43e8"}, "originalPosition": 30}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2MDk2MDkzOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/io.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQwNzowMjozOFrOHSi6Tw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QwMDoyMzowMVrOHTIenA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIwODM5OQ==", "bodyText": "Is there a reason to provide these as methods instead of transforms (similar to other IO connectors) ?", "url": "https://github.com/apache/beam/pull/12841#discussion_r489208399", "createdAt": "2020-09-16T07:02:38Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/dataframe/io.py", "diffHunk": "@@ -0,0 +1,178 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+from __future__ import absolute_import\n+\n+from io import BytesIO\n+from io import StringIO\n+from io import TextIOWrapper\n+\n+import pandas as pd\n+\n+import apache_beam as beam\n+from apache_beam import io\n+from apache_beam.dataframe import frame_base\n+\n+\n+def read_csv(path, *args, **kwargs):\n+  return _ReadFromPandas(pd.read_csv, path, args, kwargs)\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ab66e1ce1dfb1308a89a9cea21dbc9502c8c43e8"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTgyMzkwMA==", "bodyText": "Mirroring the Pandas APIs. The _ReadFromPandas will be widely shared.", "url": "https://github.com/apache/beam/pull/12841#discussion_r489823900", "createdAt": "2020-09-17T00:23:01Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/io.py", "diffHunk": "@@ -0,0 +1,178 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+from __future__ import absolute_import\n+\n+from io import BytesIO\n+from io import StringIO\n+from io import TextIOWrapper\n+\n+import pandas as pd\n+\n+import apache_beam as beam\n+from apache_beam import io\n+from apache_beam.dataframe import frame_base\n+\n+\n+def read_csv(path, *args, **kwargs):\n+  return _ReadFromPandas(pd.read_csv, path, args, kwargs)\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIwODM5OQ=="}, "originalCommit": {"oid": "ab66e1ce1dfb1308a89a9cea21dbc9502c8c43e8"}, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2MTA1MDg1OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/io.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQwNzoyOToxM1rOHSjwnA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QxNTozOTozOVrOHToreQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIyMjMwMA==", "bodyText": "Probably we can replace above file-handling related transforms with transforms available in fileio.\nhttps://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/fileio.py\nFor example,\nfileio.MatchFiles(self.path) | ParDo(_ReadFromPandasFromReadableFileDoFn())\n(ReadableFile.metadata.path gives the file path).", "url": "https://github.com/apache/beam/pull/12841#discussion_r489222300", "createdAt": "2020-09-16T07:29:13Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/dataframe/io.py", "diffHunk": "@@ -0,0 +1,178 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+from __future__ import absolute_import\n+\n+from io import BytesIO\n+from io import StringIO\n+from io import TextIOWrapper\n+\n+import pandas as pd\n+\n+import apache_beam as beam\n+from apache_beam import io\n+from apache_beam.dataframe import frame_base\n+\n+\n+def read_csv(path, *args, **kwargs):\n+  return _ReadFromPandas(pd.read_csv, path, args, kwargs)\n+\n+\n+def write_csv(df, path, *args, **kwargs):\n+  from apache_beam.dataframe import convert\n+  # TODO(roberwb): Amortize the computation for multiple writes?\n+  return convert.to_pcollection(df) | _WriteToPandas(\n+      pd.DataFrame.to_csv, path, args, kwargs, incremental=True, binary=False)\n+\n+\n+def _prefix_range_index_with(prefix, df):\n+  if isinstance(df.index, pd.RangeIndex):\n+    return df.set_index(prefix + df.index.map(str).astype(str))\n+  else:\n+    return df\n+\n+\n+class _ReadFromPandas(beam.PTransform):\n+  def __init__(self, reader, path, args, kwargs):\n+    if not isinstance(path, str):\n+      raise frame_base.WontImplementError('non-deferred')\n+    self.reader = reader\n+    self.path = path\n+    self.args = args\n+    self.kwargs = kwargs\n+\n+  def expand(self, root):\n+    # TODO(robertwb): Handle streaming (with explicit schema).\n+    paths_pcoll = root | beam.Create([self.path])\n+    first = io.filesystems.FileSystems.match([self.path],\n+                                             limits=[1\n+                                                     ])[0].metadata_list[0].path\n+    with io.filesystems.FileSystems.open(first) as handle:\n+      df = next(self.reader(handle, *self.args, chunksize=100, **self.kwargs))\n+\n+    # TODO(robertwb): Actually make an SDF.\n+    def expand_pattern(pattern):\n+      for match_result in io.filesystems.FileSystems.match([pattern]):\n+        for metadata in match_result.metadata_list:\n+          yield metadata.path\n+\n+    pcoll = (\n+        paths_pcoll\n+        | beam.FlatMap(expand_pattern)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ab66e1ce1dfb1308a89a9cea21dbc9502c8c43e8"}, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDM1MTQ4MQ==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/12841#discussion_r490351481", "createdAt": "2020-09-17T15:39:39Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/io.py", "diffHunk": "@@ -0,0 +1,178 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+from __future__ import absolute_import\n+\n+from io import BytesIO\n+from io import StringIO\n+from io import TextIOWrapper\n+\n+import pandas as pd\n+\n+import apache_beam as beam\n+from apache_beam import io\n+from apache_beam.dataframe import frame_base\n+\n+\n+def read_csv(path, *args, **kwargs):\n+  return _ReadFromPandas(pd.read_csv, path, args, kwargs)\n+\n+\n+def write_csv(df, path, *args, **kwargs):\n+  from apache_beam.dataframe import convert\n+  # TODO(roberwb): Amortize the computation for multiple writes?\n+  return convert.to_pcollection(df) | _WriteToPandas(\n+      pd.DataFrame.to_csv, path, args, kwargs, incremental=True, binary=False)\n+\n+\n+def _prefix_range_index_with(prefix, df):\n+  if isinstance(df.index, pd.RangeIndex):\n+    return df.set_index(prefix + df.index.map(str).astype(str))\n+  else:\n+    return df\n+\n+\n+class _ReadFromPandas(beam.PTransform):\n+  def __init__(self, reader, path, args, kwargs):\n+    if not isinstance(path, str):\n+      raise frame_base.WontImplementError('non-deferred')\n+    self.reader = reader\n+    self.path = path\n+    self.args = args\n+    self.kwargs = kwargs\n+\n+  def expand(self, root):\n+    # TODO(robertwb): Handle streaming (with explicit schema).\n+    paths_pcoll = root | beam.Create([self.path])\n+    first = io.filesystems.FileSystems.match([self.path],\n+                                             limits=[1\n+                                                     ])[0].metadata_list[0].path\n+    with io.filesystems.FileSystems.open(first) as handle:\n+      df = next(self.reader(handle, *self.args, chunksize=100, **self.kwargs))\n+\n+    # TODO(robertwb): Actually make an SDF.\n+    def expand_pattern(pattern):\n+      for match_result in io.filesystems.FileSystems.match([pattern]):\n+        for metadata in match_result.metadata_list:\n+          yield metadata.path\n+\n+    pcoll = (\n+        paths_pcoll\n+        | beam.FlatMap(expand_pattern)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIyMjMwMA=="}, "originalCommit": {"oid": "ab66e1ce1dfb1308a89a9cea21dbc9502c8c43e8"}, "originalPosition": 74}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2MTE0ODY2OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/io.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQwNzo1NToxNlrOHSksGg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QxNTozOTo0M1rOHTorqw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIzNzUzMA==", "bodyText": "Instead of extending FileBasedSink here please implement a fileio.FileSink and use fileio.WriteToFiles.\nhttps://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/fileio.py#L76", "url": "https://github.com/apache/beam/pull/12841#discussion_r489237530", "createdAt": "2020-09-16T07:55:16Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/dataframe/io.py", "diffHunk": "@@ -0,0 +1,178 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+from __future__ import absolute_import\n+\n+from io import BytesIO\n+from io import StringIO\n+from io import TextIOWrapper\n+\n+import pandas as pd\n+\n+import apache_beam as beam\n+from apache_beam import io\n+from apache_beam.dataframe import frame_base\n+\n+\n+def read_csv(path, *args, **kwargs):\n+  return _ReadFromPandas(pd.read_csv, path, args, kwargs)\n+\n+\n+def write_csv(df, path, *args, **kwargs):\n+  from apache_beam.dataframe import convert\n+  # TODO(roberwb): Amortize the computation for multiple writes?\n+  return convert.to_pcollection(df) | _WriteToPandas(\n+      pd.DataFrame.to_csv, path, args, kwargs, incremental=True, binary=False)\n+\n+\n+def _prefix_range_index_with(prefix, df):\n+  if isinstance(df.index, pd.RangeIndex):\n+    return df.set_index(prefix + df.index.map(str).astype(str))\n+  else:\n+    return df\n+\n+\n+class _ReadFromPandas(beam.PTransform):\n+  def __init__(self, reader, path, args, kwargs):\n+    if not isinstance(path, str):\n+      raise frame_base.WontImplementError('non-deferred')\n+    self.reader = reader\n+    self.path = path\n+    self.args = args\n+    self.kwargs = kwargs\n+\n+  def expand(self, root):\n+    # TODO(robertwb): Handle streaming (with explicit schema).\n+    paths_pcoll = root | beam.Create([self.path])\n+    first = io.filesystems.FileSystems.match([self.path],\n+                                             limits=[1\n+                                                     ])[0].metadata_list[0].path\n+    with io.filesystems.FileSystems.open(first) as handle:\n+      df = next(self.reader(handle, *self.args, chunksize=100, **self.kwargs))\n+\n+    # TODO(robertwb): Actually make an SDF.\n+    def expand_pattern(pattern):\n+      for match_result in io.filesystems.FileSystems.match([pattern]):\n+        for metadata in match_result.metadata_list:\n+          yield metadata.path\n+\n+    pcoll = (\n+        paths_pcoll\n+        | beam.FlatMap(expand_pattern)\n+        | beam.ParDo(_ReadFromPandasDoFn(self.reader, self.args, self.kwargs)))\n+    from apache_beam.dataframe import convert\n+    return convert.to_dataframe(\n+        pcoll, proxy=_prefix_range_index_with(':', df[:0]))\n+\n+\n+class _ReadFromPandasDoFn(beam.DoFn):\n+  def __init__(self, reader, args, kwargs):\n+    # avoid pickling issues\n+    self.reader = reader.__name__\n+    self.args = args\n+    self.kwargs = kwargs\n+\n+  def process(self, path):\n+    reader = getattr(pd, self.reader)\n+    for df in reader(path, *self.args, chunksize=100, **self.kwargs):\n+      yield _prefix_range_index_with(path + ':', df)\n+\n+\n+class _WriteToPandas(beam.PTransform):\n+  def __init__(\n+      self, writer, path, args, kwargs, incremental=False, binary=True):\n+    self.writer = writer\n+    self.path = path\n+    self.args = args\n+    self.kwargs = kwargs\n+    self.incremental = incremental\n+    self.binary = binary\n+\n+  def expand(self, pcoll):\n+    return pcoll | io.Write(\n+        _WriteToPandasFileBasedSink(\n+            self.writer,\n+            self.path,\n+            self.args,\n+            self.kwargs,\n+            self.incremental,\n+            self.binary))\n+\n+\n+class _WriteToPandasFileBasedSink(io.FileBasedSink):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ab66e1ce1dfb1308a89a9cea21dbc9502c8c43e8"}, "originalPosition": 115}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDM1MTUzMQ==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/12841#discussion_r490351531", "createdAt": "2020-09-17T15:39:43Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/io.py", "diffHunk": "@@ -0,0 +1,178 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+from __future__ import absolute_import\n+\n+from io import BytesIO\n+from io import StringIO\n+from io import TextIOWrapper\n+\n+import pandas as pd\n+\n+import apache_beam as beam\n+from apache_beam import io\n+from apache_beam.dataframe import frame_base\n+\n+\n+def read_csv(path, *args, **kwargs):\n+  return _ReadFromPandas(pd.read_csv, path, args, kwargs)\n+\n+\n+def write_csv(df, path, *args, **kwargs):\n+  from apache_beam.dataframe import convert\n+  # TODO(roberwb): Amortize the computation for multiple writes?\n+  return convert.to_pcollection(df) | _WriteToPandas(\n+      pd.DataFrame.to_csv, path, args, kwargs, incremental=True, binary=False)\n+\n+\n+def _prefix_range_index_with(prefix, df):\n+  if isinstance(df.index, pd.RangeIndex):\n+    return df.set_index(prefix + df.index.map(str).astype(str))\n+  else:\n+    return df\n+\n+\n+class _ReadFromPandas(beam.PTransform):\n+  def __init__(self, reader, path, args, kwargs):\n+    if not isinstance(path, str):\n+      raise frame_base.WontImplementError('non-deferred')\n+    self.reader = reader\n+    self.path = path\n+    self.args = args\n+    self.kwargs = kwargs\n+\n+  def expand(self, root):\n+    # TODO(robertwb): Handle streaming (with explicit schema).\n+    paths_pcoll = root | beam.Create([self.path])\n+    first = io.filesystems.FileSystems.match([self.path],\n+                                             limits=[1\n+                                                     ])[0].metadata_list[0].path\n+    with io.filesystems.FileSystems.open(first) as handle:\n+      df = next(self.reader(handle, *self.args, chunksize=100, **self.kwargs))\n+\n+    # TODO(robertwb): Actually make an SDF.\n+    def expand_pattern(pattern):\n+      for match_result in io.filesystems.FileSystems.match([pattern]):\n+        for metadata in match_result.metadata_list:\n+          yield metadata.path\n+\n+    pcoll = (\n+        paths_pcoll\n+        | beam.FlatMap(expand_pattern)\n+        | beam.ParDo(_ReadFromPandasDoFn(self.reader, self.args, self.kwargs)))\n+    from apache_beam.dataframe import convert\n+    return convert.to_dataframe(\n+        pcoll, proxy=_prefix_range_index_with(':', df[:0]))\n+\n+\n+class _ReadFromPandasDoFn(beam.DoFn):\n+  def __init__(self, reader, args, kwargs):\n+    # avoid pickling issues\n+    self.reader = reader.__name__\n+    self.args = args\n+    self.kwargs = kwargs\n+\n+  def process(self, path):\n+    reader = getattr(pd, self.reader)\n+    for df in reader(path, *self.args, chunksize=100, **self.kwargs):\n+      yield _prefix_range_index_with(path + ':', df)\n+\n+\n+class _WriteToPandas(beam.PTransform):\n+  def __init__(\n+      self, writer, path, args, kwargs, incremental=False, binary=True):\n+    self.writer = writer\n+    self.path = path\n+    self.args = args\n+    self.kwargs = kwargs\n+    self.incremental = incremental\n+    self.binary = binary\n+\n+  def expand(self, pcoll):\n+    return pcoll | io.Write(\n+        _WriteToPandasFileBasedSink(\n+            self.writer,\n+            self.path,\n+            self.args,\n+            self.kwargs,\n+            self.incremental,\n+            self.binary))\n+\n+\n+class _WriteToPandasFileBasedSink(io.FileBasedSink):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTIzNzUzMA=="}, "originalCommit": {"oid": "ab66e1ce1dfb1308a89a9cea21dbc9502c8c43e8"}, "originalPosition": 115}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA3Mjk3MTUyOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/io.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxNzo0NTo1MVrOHUWZtw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxODo1MToyNFrOHUYWRA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTEwMDU5OQ==", "bodyText": "Import at top (here and below) ?", "url": "https://github.com/apache/beam/pull/12841#discussion_r491100599", "createdAt": "2020-09-18T17:45:51Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/dataframe/io.py", "diffHunk": "@@ -0,0 +1,180 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+from __future__ import absolute_import\n+\n+from io import BytesIO\n+from io import StringIO\n+from io import TextIOWrapper\n+\n+import pandas as pd\n+\n+import apache_beam as beam\n+from apache_beam import io\n+from apache_beam.dataframe import frame_base\n+from apache_beam.io import fileio\n+\n+\n+def read_csv(path, *args, **kwargs):\n+  \"\"\"Emulates `pd.read_csv` from Pandas, but as a Beam PTransform.\n+\n+  Use this as\n+\n+      df = p | beam.dataframe.io.read_csv(...)\n+\n+  to get a deferred Beam dataframe representing the contents of the file.\n+  \"\"\"\n+  return _ReadFromPandas(pd.read_csv, path, args, kwargs)\n+\n+\n+def write_csv(df, path, *args, **kwargs):\n+  from apache_beam.dataframe import convert", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1be53570550a175badfddfe5143ce825ce8ee088"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTEzMjQ4NA==", "bodyText": "I was running into circular import issues. Will add a comment.", "url": "https://github.com/apache/beam/pull/12841#discussion_r491132484", "createdAt": "2020-09-18T18:51:24Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/io.py", "diffHunk": "@@ -0,0 +1,180 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+from __future__ import absolute_import\n+\n+from io import BytesIO\n+from io import StringIO\n+from io import TextIOWrapper\n+\n+import pandas as pd\n+\n+import apache_beam as beam\n+from apache_beam import io\n+from apache_beam.dataframe import frame_base\n+from apache_beam.io import fileio\n+\n+\n+def read_csv(path, *args, **kwargs):\n+  \"\"\"Emulates `pd.read_csv` from Pandas, but as a Beam PTransform.\n+\n+  Use this as\n+\n+      df = p | beam.dataframe.io.read_csv(...)\n+\n+  to get a deferred Beam dataframe representing the contents of the file.\n+  \"\"\"\n+  return _ReadFromPandas(pd.read_csv, path, args, kwargs)\n+\n+\n+def write_csv(df, path, *args, **kwargs):\n+  from apache_beam.dataframe import convert", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTEwMDU5OQ=="}, "originalCommit": {"oid": "1be53570550a175badfddfe5143ce825ce8ee088"}, "originalPosition": 44}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA3MzAzNDY1OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/io_test.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxODowNjoyOVrOHUXA1A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxOTowMDozNFrOHUYmeQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTExMDYxMg==", "bodyText": "test_read_csv (seems like this is testing read_csv) ?", "url": "https://github.com/apache/beam/pull/12841#discussion_r491110612", "createdAt": "2020-09-18T18:06:29Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/dataframe/io_test.py", "diffHunk": "@@ -0,0 +1,67 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+from __future__ import absolute_import\n+\n+import glob\n+import os\n+import shutil\n+import sys\n+import tempfile\n+import unittest\n+\n+import apache_beam as beam\n+from apache_beam.dataframe import io\n+\n+\n+class IOTest(unittest.TestCase):\n+  def setUp(self):\n+    self._temp_roots = []\n+\n+  def tearDown(self):\n+    for root in self._temp_roots:\n+      shutil.rmtree(root)\n+\n+  def temp_dir(self, files=None):\n+    dir = tempfile.mkdtemp(prefix='beam-test')\n+    self._temp_roots.append(dir)\n+    if files:\n+      for name, contents in files.items():\n+        with open(os.path.join(dir, name), 'w') as fout:\n+          fout.write(contents)\n+    return dir + os.sep\n+\n+  def read_all_lines(self, pattern):\n+    for path in glob.glob(pattern):\n+      with open(path) as fin:\n+        # TODO(Py3): yield from\n+        for line in fin:\n+          yield line.rstrip('\\n')\n+\n+  @unittest.skipIf(sys.version_info[0] < 3, 'unicode issues')\n+  def test_write_csv(self):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1be53570550a175badfddfe5143ce825ce8ee088"}, "originalPosition": 55}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTEzNjYzMw==", "bodyText": "This tests tests both read and write.", "url": "https://github.com/apache/beam/pull/12841#discussion_r491136633", "createdAt": "2020-09-18T19:00:34Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/io_test.py", "diffHunk": "@@ -0,0 +1,67 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+from __future__ import absolute_import\n+\n+import glob\n+import os\n+import shutil\n+import sys\n+import tempfile\n+import unittest\n+\n+import apache_beam as beam\n+from apache_beam.dataframe import io\n+\n+\n+class IOTest(unittest.TestCase):\n+  def setUp(self):\n+    self._temp_roots = []\n+\n+  def tearDown(self):\n+    for root in self._temp_roots:\n+      shutil.rmtree(root)\n+\n+  def temp_dir(self, files=None):\n+    dir = tempfile.mkdtemp(prefix='beam-test')\n+    self._temp_roots.append(dir)\n+    if files:\n+      for name, contents in files.items():\n+        with open(os.path.join(dir, name), 'w') as fout:\n+          fout.write(contents)\n+    return dir + os.sep\n+\n+  def read_all_lines(self, pattern):\n+    for path in glob.glob(pattern):\n+      with open(path) as fin:\n+        # TODO(Py3): yield from\n+        for line in fin:\n+          yield line.rstrip('\\n')\n+\n+  @unittest.skipIf(sys.version_info[0] < 3, 'unicode issues')\n+  def test_write_csv(self):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTExMDYxMg=="}, "originalCommit": {"oid": "1be53570550a175badfddfe5143ce825ce8ee088"}, "originalPosition": 55}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA3MzAzNjkwOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/io_test.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxODowNzoxMFrOHUXCOw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxOTowMDo0MFrOHUYmoQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTExMDk3MQ==", "bodyText": "Add a test for write_cvs as well ?", "url": "https://github.com/apache/beam/pull/12841#discussion_r491110971", "createdAt": "2020-09-18T18:07:10Z", "author": {"login": "chamikaramj"}, "path": "sdks/python/apache_beam/dataframe/io_test.py", "diffHunk": "@@ -0,0 +1,67 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+from __future__ import absolute_import\n+\n+import glob\n+import os\n+import shutil\n+import sys\n+import tempfile\n+import unittest\n+\n+import apache_beam as beam\n+from apache_beam.dataframe import io\n+\n+\n+class IOTest(unittest.TestCase):\n+  def setUp(self):\n+    self._temp_roots = []\n+\n+  def tearDown(self):\n+    for root in self._temp_roots:\n+      shutil.rmtree(root)\n+\n+  def temp_dir(self, files=None):\n+    dir = tempfile.mkdtemp(prefix='beam-test')\n+    self._temp_roots.append(dir)\n+    if files:\n+      for name, contents in files.items():\n+        with open(os.path.join(dir, name), 'w') as fout:\n+          fout.write(contents)\n+    return dir + os.sep\n+\n+  def read_all_lines(self, pattern):\n+    for path in glob.glob(pattern):\n+      with open(path) as fin:\n+        # TODO(Py3): yield from\n+        for line in fin:\n+          yield line.rstrip('\\n')\n+\n+  @unittest.skipIf(sys.version_info[0] < 3, 'unicode issues')\n+  def test_write_csv(self):\n+    input = self.temp_dir({'1.csv': 'a,b\\n1,2\\n', '2.csv': 'a,b\\n3,4\\n'})\n+    output = self.temp_dir()\n+    with beam.Pipeline() as p:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1be53570550a175badfddfe5143ce825ce8ee088"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTEzNjY3Mw==", "bodyText": "This tests tests both read and write. Updated name.", "url": "https://github.com/apache/beam/pull/12841#discussion_r491136673", "createdAt": "2020-09-18T19:00:40Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/io_test.py", "diffHunk": "@@ -0,0 +1,67 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+\n+from __future__ import absolute_import\n+\n+import glob\n+import os\n+import shutil\n+import sys\n+import tempfile\n+import unittest\n+\n+import apache_beam as beam\n+from apache_beam.dataframe import io\n+\n+\n+class IOTest(unittest.TestCase):\n+  def setUp(self):\n+    self._temp_roots = []\n+\n+  def tearDown(self):\n+    for root in self._temp_roots:\n+      shutil.rmtree(root)\n+\n+  def temp_dir(self, files=None):\n+    dir = tempfile.mkdtemp(prefix='beam-test')\n+    self._temp_roots.append(dir)\n+    if files:\n+      for name, contents in files.items():\n+        with open(os.path.join(dir, name), 'w') as fout:\n+          fout.write(contents)\n+    return dir + os.sep\n+\n+  def read_all_lines(self, pattern):\n+    for path in glob.glob(pattern):\n+      with open(path) as fin:\n+        # TODO(Py3): yield from\n+        for line in fin:\n+          yield line.rstrip('\\n')\n+\n+  @unittest.skipIf(sys.version_info[0] < 3, 'unicode issues')\n+  def test_write_csv(self):\n+    input = self.temp_dir({'1.csv': 'a,b\\n1,2\\n', '2.csv': 'a,b\\n3,4\\n'})\n+    output = self.temp_dir()\n+    with beam.Pipeline() as p:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTExMDk3MQ=="}, "originalCommit": {"oid": "1be53570550a175badfddfe5143ce825ce8ee088"}, "originalPosition": 58}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3319, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}