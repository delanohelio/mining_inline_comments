{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTI1MDI1MzUz", "number": 13401, "title": "[BEAM-11324] Add additional verification in PartitioningSession", "bodyText": "This PR modifies PartitioningSession so it re-executes expressions with a variety of partitioned inputs, determined by the expression's requires_partition_by specification. It also verifies that the output for each type of partitioned input is partitioned consistent with the expression's preserves_partition_by specification.\nThis detected the issue fixed in #13398, and detected an additional issue with Series.agg's pre-aggregation, fixed in ac1e3a.\nPost-Commit Tests Status (on master branch)\n\n\n\nLang\nSDK\nDataflow\nFlink\nSamza\nSpark\nTwister2\n\n\n\n\nGo\n\n---\n\n---\n\n---\n\n\nJava\n\n\n\n\n\n\n\n\nPython\n\n\n\n---\n\n---\n\n\nXLang\n\n\n\n---\n\n---\n\n\n\nPre-Commit Tests Status (on master branch)\n\n\n\n---\nJava\nPython\nGo\nWebsite\nWhitespace\nTypescript\n\n\n\n\nNon-portable\n\n \n\n\n\n\n\n\nPortable\n---\n\n---\n---\n---\n---\n\n\n\nSee .test-infra/jenkins/README for trigger phrase, status and link of all Jenkins jobs.\nGitHub Actions Tests Status (on master branch)\n\n\n\nSee CI.md for more information about GitHub Actions CI.", "createdAt": "2020-11-21T00:39:36Z", "url": "https://github.com/apache/beam/pull/13401", "merged": true, "mergeCommit": {"oid": "bd825f574e342cfa83fb09767c7d5a19a3accc55"}, "closed": true, "closedAt": "2020-11-24T21:36:37Z", "author": {"login": "TheNeuralBit"}, "timelineItems": {"totalCount": 19, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdeg_k1AFqTUzNTg1OTM0MA==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdfuhG6gH2gAyNTI1MDI1MzUzOmM4NmZjYTZjOGY5YmIyOTZkMWQwNjUyZWEwMDEyYzQ4MTEzZWQ0ZmQ=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM1ODU5MzQw", "url": "https://github.com/apache/beam/pull/13401#pullrequestreview-535859340", "createdAt": "2020-11-21T00:41:22Z", "commit": {"oid": "ac1e3a3705ecd00bfdafea8bda207c419bc42633"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMVQwMDo0MToyMlrOH3lASg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMVQwMDo0MToyMlrOH3lASg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODA0MDAxMA==", "bodyText": "Note this only stores the most recently computed result. We may want to also verify that each input partitioning yields equivalent results (modulo ordering).", "url": "https://github.com/apache/beam/pull/13401#discussion_r528040010", "createdAt": "2020-11-21T00:41:22Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/expressions.py", "diffHunk": "@@ -67,28 +72,57 @@ def is_scalar(expr):\n         result = super(PartitioningSession, self).evaluate(expr)\n       else:\n         scaler_args = [arg for arg in expr.args() if is_scalar(arg)]\n-        parts = collections.defaultdict(\n-            lambda: Session({arg: self.evaluate(arg)\n-                             for arg in scaler_args}))\n-        for arg in expr.args():\n-          if not is_scalar(arg):\n-            input = self.evaluate(arg)\n-            for key, part in expr.requires_partition_by().test_partition_fn(\n-                input):\n-              parts[key]._bindings[arg] = part\n-        if not parts:\n-          parts[None]  # Create at least one entry.\n-\n-        results = []\n-        for session in parts.values():\n-          if any(len(session.lookup(arg)) for arg in expr.args()\n-                 if not is_scalar(arg)):\n-            results.append(session.evaluate(expr))\n-        if results:\n-          result = pd.concat(results)\n-        else:\n-          # Choose any single session.\n-          result = next(iter(parts.values())).evaluate(expr)\n+\n+        def evaluate_with(input_partitioning):\n+          parts = collections.defaultdict(\n+              lambda: Session({arg: self.evaluate(arg)\n+                               for arg in scaler_args}))\n+          for arg in expr.args():\n+            if not is_scalar(arg):\n+              input = self.evaluate(arg)\n+              for key, part in input_partitioning.test_partition_fn(input):\n+                parts[key]._bindings[arg] = part\n+          if not parts:\n+            parts[None]  # Create at least one entry.\n+\n+          results = []\n+          for session in parts.values():\n+            if any(len(session.lookup(arg)) for arg in expr.args()\n+                   if not is_scalar(arg)):\n+              results.append(session.evaluate(expr))\n+\n+          expected_output_partitioning = expr.preserves_partition_by(\n+          ) if input_partitioning.is_subpartitioning_of(\n+              expr.preserves_partition_by()) else input_partitioning\n+\n+          if not expected_output_partitioning.check(results):\n+            raise AssertionError(\n+                f\"\"\"Expression does not preserve partitioning!\n+                Expression: {expr}\n+                Requires: {expr.requires_partition_by()}\n+                Preserves: {expr.preserves_partition_by()}\n+                Input partitioning: {input_partitioning}\n+                Expected output partitioning: {expected_output_partitioning}\n+                \"\"\")\n+\n+          if results:\n+            return pd.concat(results)\n+          else:\n+            # Choose any single session.\n+            return next(iter(parts.values())).evaluate(expr)\n+\n+        input_partitioning = expr.requires_partition_by()\n+\n+        while input_partitioning is not None:\n+          result = evaluate_with(input_partitioning)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ac1e3a3705ecd00bfdafea8bda207c419bc42633"}, "originalPosition": 88}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM1ODY3MDIy", "url": "https://github.com/apache/beam/pull/13401#pullrequestreview-535867022", "createdAt": "2020-11-21T01:25:11Z", "commit": {"oid": "79a08776618b8e1474862479fe6fd83f381758dd"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMVQwMToyNToxMVrOH3lfXQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMVQwMTozNDoyNVrOH3lkng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODA0Nzk2NQ==", "bodyText": "Well, it could be something different...", "url": "https://github.com/apache/beam/pull/13401#discussion_r528047965", "createdAt": "2020-11-21T01:25:11Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/expressions.py", "diffHunk": "@@ -67,28 +72,57 @@ def is_scalar(expr):\n         result = super(PartitioningSession, self).evaluate(expr)\n       else:\n         scaler_args = [arg for arg in expr.args() if is_scalar(arg)]\n-        parts = collections.defaultdict(\n-            lambda: Session({arg: self.evaluate(arg)\n-                             for arg in scaler_args}))\n-        for arg in expr.args():\n-          if not is_scalar(arg):\n-            input = self.evaluate(arg)\n-            for key, part in expr.requires_partition_by().test_partition_fn(\n-                input):\n-              parts[key]._bindings[arg] = part\n-        if not parts:\n-          parts[None]  # Create at least one entry.\n-\n-        results = []\n-        for session in parts.values():\n-          if any(len(session.lookup(arg)) for arg in expr.args()\n-                 if not is_scalar(arg)):\n-            results.append(session.evaluate(expr))\n-        if results:\n-          result = pd.concat(results)\n-        else:\n-          # Choose any single session.\n-          result = next(iter(parts.values())).evaluate(expr)\n+\n+        def evaluate_with(input_partitioning):\n+          parts = collections.defaultdict(\n+              lambda: Session({arg: self.evaluate(arg)\n+                               for arg in scaler_args}))\n+          for arg in expr.args():\n+            if not is_scalar(arg):\n+              input = self.evaluate(arg)\n+              for key, part in input_partitioning.test_partition_fn(input):\n+                parts[key]._bindings[arg] = part\n+          if not parts:\n+            parts[None]  # Create at least one entry.\n+\n+          results = []\n+          for session in parts.values():\n+            if any(len(session.lookup(arg)) for arg in expr.args()\n+                   if not is_scalar(arg)):\n+              results.append(session.evaluate(expr))\n+\n+          expected_output_partitioning = expr.preserves_partition_by(\n+          ) if input_partitioning.is_subpartitioning_of(\n+              expr.preserves_partition_by()) else input_partitioning\n+\n+          if not expected_output_partitioning.check(results):\n+            raise AssertionError(\n+                f\"\"\"Expression does not preserve partitioning!\n+                Expression: {expr}\n+                Requires: {expr.requires_partition_by()}\n+                Preserves: {expr.preserves_partition_by()}\n+                Input partitioning: {input_partitioning}\n+                Expected output partitioning: {expected_output_partitioning}\n+                \"\"\")\n+\n+          if results:\n+            return pd.concat(results)\n+          else:\n+            # Choose any single session.\n+            return next(iter(parts.values())).evaluate(expr)\n+\n+        input_partitioning = expr.requires_partition_by()\n+\n+        while input_partitioning is not None:\n+          result = evaluate_with(input_partitioning)\n+\n+          if input_partitioning == partitionings.Nothing():\n+            input_partitioning = partitionings.Index()\n+          elif isinstance(input_partitioning, partitionings.Index):\n+            input_partitioning = partitionings.Singleton()\n+          else:  # partitionings.Singleton()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "79a08776618b8e1474862479fe6fd83f381758dd"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODA0ODExMQ==", "bodyText": "This loop isn't obvious to follow. Perhaps iterate over set([input_partitioning, Nothing(), Index(), Singleton()]) and continue in the cases where it's not a subpartition of index_partitioning.", "url": "https://github.com/apache/beam/pull/13401#discussion_r528048111", "createdAt": "2020-11-21T01:26:12Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/expressions.py", "diffHunk": "@@ -67,28 +72,57 @@ def is_scalar(expr):\n         result = super(PartitioningSession, self).evaluate(expr)\n       else:\n         scaler_args = [arg for arg in expr.args() if is_scalar(arg)]\n-        parts = collections.defaultdict(\n-            lambda: Session({arg: self.evaluate(arg)\n-                             for arg in scaler_args}))\n-        for arg in expr.args():\n-          if not is_scalar(arg):\n-            input = self.evaluate(arg)\n-            for key, part in expr.requires_partition_by().test_partition_fn(\n-                input):\n-              parts[key]._bindings[arg] = part\n-        if not parts:\n-          parts[None]  # Create at least one entry.\n-\n-        results = []\n-        for session in parts.values():\n-          if any(len(session.lookup(arg)) for arg in expr.args()\n-                 if not is_scalar(arg)):\n-            results.append(session.evaluate(expr))\n-        if results:\n-          result = pd.concat(results)\n-        else:\n-          # Choose any single session.\n-          result = next(iter(parts.values())).evaluate(expr)\n+\n+        def evaluate_with(input_partitioning):\n+          parts = collections.defaultdict(\n+              lambda: Session({arg: self.evaluate(arg)\n+                               for arg in scaler_args}))\n+          for arg in expr.args():\n+            if not is_scalar(arg):\n+              input = self.evaluate(arg)\n+              for key, part in input_partitioning.test_partition_fn(input):\n+                parts[key]._bindings[arg] = part\n+          if not parts:\n+            parts[None]  # Create at least one entry.\n+\n+          results = []\n+          for session in parts.values():\n+            if any(len(session.lookup(arg)) for arg in expr.args()\n+                   if not is_scalar(arg)):\n+              results.append(session.evaluate(expr))\n+\n+          expected_output_partitioning = expr.preserves_partition_by(\n+          ) if input_partitioning.is_subpartitioning_of(\n+              expr.preserves_partition_by()) else input_partitioning\n+\n+          if not expected_output_partitioning.check(results):\n+            raise AssertionError(\n+                f\"\"\"Expression does not preserve partitioning!\n+                Expression: {expr}\n+                Requires: {expr.requires_partition_by()}\n+                Preserves: {expr.preserves_partition_by()}\n+                Input partitioning: {input_partitioning}\n+                Expected output partitioning: {expected_output_partitioning}\n+                \"\"\")\n+\n+          if results:\n+            return pd.concat(results)\n+          else:\n+            # Choose any single session.\n+            return next(iter(parts.values())).evaluate(expr)\n+\n+        input_partitioning = expr.requires_partition_by()\n+\n+        while input_partitioning is not None:\n+          result = evaluate_with(input_partitioning)\n+\n+          if input_partitioning == partitionings.Nothing():", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "79a08776618b8e1474862479fe6fd83f381758dd"}, "originalPosition": 90}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODA0ODI3Mg==", "bodyText": "Did yapf suggest this?", "url": "https://github.com/apache/beam/pull/13401#discussion_r528048272", "createdAt": "2020-11-21T01:27:13Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/frames.py", "diffHunk": "@@ -1401,17 +1403,20 @@ def replace(self, limit, **kwargs):\n   def reset_index(self, level=None, **kwargs):\n     if level is not None and not isinstance(level, (tuple, list)):\n       level = [level]\n+\n     if level is None or len(level) == self._expr.proxy().index.nlevels:\n       # TODO: Could do distributed re-index with offsets.\n       requires_partition_by = partitionings.Singleton()\n     else:\n       requires_partition_by = partitionings.Nothing()\n+\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "79a08776618b8e1474862479fe6fd83f381758dd"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODA0ODQ0Nw==", "bodyText": "I wonder how expensive this will get. Hopefully not too bad. It could, however, mess up anything that depends on the random seed.", "url": "https://github.com/apache/beam/pull/13401#discussion_r528048447", "createdAt": "2020-11-21T01:28:35Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/expressions.py", "diffHunk": "@@ -48,10 +48,15 @@ def lookup(self, expr):  #  type: (Expression) -> Any\n class PartitioningSession(Session):\n   \"\"\"An extension of Session that enforces actual partitioning of inputs.\n \n-  When evaluating an expression, inputs are partitioned according to its\n-  `requires_partition_by` specifications, the expression is evaluated on each\n-  partition separately, and the final result concatinated, as if this were\n-  actually executed in a parallel manner.\n+  Each expression is evaluated multiple times for various supported", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "79a08776618b8e1474862479fe6fd83f381758dd"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODA0OTMxMA==", "bodyText": "This isn't a very strong check if the dataframes are fairly sparse (as they are in most examples). We could try concat + repartition and verify the results are the same.", "url": "https://github.com/apache/beam/pull/13401#discussion_r528049310", "createdAt": "2020-11-21T01:34:25Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/partitionings.py", "diffHunk": "@@ -115,6 +115,23 @@ def partition_fn(self, df, num_partitions):\n     for key in range(num_partitions):\n       yield key, df[hashes % num_partitions == key]\n \n+  def check(self, dfs):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "79a08776618b8e1474862479fe6fd83f381758dd"}, "originalPosition": 4}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM2OTQ4MTEy", "url": "https://github.com/apache/beam/pull/13401#pullrequestreview-536948112", "createdAt": "2020-11-24T00:25:27Z", "commit": {"oid": "79a08776618b8e1474862479fe6fd83f381758dd"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQwMDoyNToyN1rOH4kpQQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNFQwMDoyNToyN1rOH4kpQQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyOTA4MjY4OQ==", "bodyText": "Let's do that.", "url": "https://github.com/apache/beam/pull/13401#discussion_r529082689", "createdAt": "2020-11-24T00:25:27Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/expressions.py", "diffHunk": "@@ -48,10 +48,15 @@ def lookup(self, expr):  #  type: (Expression) -> Any\n class PartitioningSession(Session):\n   \"\"\"An extension of Session that enforces actual partitioning of inputs.\n \n-  When evaluating an expression, inputs are partitioned according to its\n-  `requires_partition_by` specifications, the expression is evaluated on each\n-  partition separately, and the final result concatinated, as if this were\n-  actually executed in a parallel manner.\n+  Each expression is evaluated multiple times for various supported", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODA0ODQ0Nw=="}, "originalCommit": {"oid": "79a08776618b8e1474862479fe6fd83f381758dd"}, "originalPosition": 8}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9af3c3214e0abf8e11f4930b6223252d8b574600", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/9af3c3214e0abf8e11f4930b6223252d8b574600", "committedDate": "2020-11-24T02:32:25Z", "message": "Default to distributed=True in frames_test.py:"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d0ae355dacb9bd515e626d20a3a20ce91f9f562b", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/d0ae355dacb9bd515e626d20a3a20ce91f9f562b", "committedDate": "2020-11-24T02:32:25Z", "message": "Add additional partitioning verification to PartitioningSession"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8fabffc24af8143f9cff17bc72f1c330011150ee", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/8fabffc24af8143f9cff17bc72f1c330011150ee", "committedDate": "2020-11-24T02:32:25Z", "message": "Series pre-agg doesn't preserve partitioning"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fe213240ad70ae1bc82e6ccfe1203807c714e01d", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/fe213240ad70ae1bc82e6ccfe1203807c714e01d", "committedDate": "2020-11-24T02:32:25Z", "message": "reset_index doesn't preserve partitioning"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "896c1143ee95abaab310302527e9909b450031b9", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/896c1143ee95abaab310302527e9909b450031b9", "committedDate": "2020-11-24T02:32:25Z", "message": "remove whitespace"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b0f3fc2d9a0bae457d00aabf88eb85ff2e598399", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/b0f3fc2d9a0bae457d00aabf88eb85ff2e598399", "committedDate": "2020-11-24T02:32:25Z", "message": "store and recover random state, clarify loop"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f1a46c2b722f4808772488cd8a9ec1a01efffd49", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/f1a46c2b722f4808772488cd8a9ec1a01efffd49", "committedDate": "2020-11-24T02:32:25Z", "message": "add TODO"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f672f3c2708d79880d4a89f4ee87500121224024", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/f672f3c2708d79880d4a89f4ee87500121224024", "committedDate": "2020-11-24T02:32:25Z", "message": "map_index doesn't preserve partitioning"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d2d8cf9a0bdeba75cdc4de520ddfb2d44967026f", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/d2d8cf9a0bdeba75cdc4de520ddfb2d44967026f", "committedDate": "2020-11-24T02:32:25Z", "message": "lint"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9dfbadea3ab745a3fabf4ab0f355ed4e361e8d86", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/9dfbadea3ab745a3fabf4ab0f355ed4e361e8d86", "committedDate": "2020-11-24T02:34:41Z", "message": "lint"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "53408f5f34e3d20d8c46c6ffec66af1f0a31162e", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/53408f5f34e3d20d8c46c6ffec66af1f0a31162e", "committedDate": "2020-11-24T01:44:33Z", "message": "lint"}, "afterCommit": {"oid": "9dfbadea3ab745a3fabf4ab0f355ed4e361e8d86", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/9dfbadea3ab745a3fabf4ab0f355ed4e361e8d86", "committedDate": "2020-11-24T02:34:41Z", "message": "lint"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3c882faae889b88daffc77e496637b171bb8021b", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/3c882faae889b88daffc77e496637b171bb8021b", "committedDate": "2020-11-24T02:55:49Z", "message": "lint"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5dcdc9c5432dc8123415a5f761b26f775ef84af5", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/5dcdc9c5432dc8123415a5f761b26f775ef84af5", "committedDate": "2020-11-24T18:31:25Z", "message": "Disallow grouping by a series"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c73224e04940c5d2216942a17dadede7c1238592", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/c73224e04940c5d2216942a17dadede7c1238592", "committedDate": "2020-11-24T18:33:24Z", "message": "lint"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0b917fd532d156c90bb50d876f2abc5009544247", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/0b917fd532d156c90bb50d876f2abc5009544247", "committedDate": "2020-11-24T18:47:18Z", "message": "lint"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c86fca6c8f9bb296d1d0652ea0012c48113ed4fd", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/c86fca6c8f9bb296d1d0652ea0012c48113ed4fd", "committedDate": "2020-11-24T19:00:41Z", "message": "import order"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4514, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}