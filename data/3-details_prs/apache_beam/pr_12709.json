{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDc1MDAyNDE2", "number": 12709, "title": "[BEAM-8258] add more options and monitoring to nexmark launcher", "bodyText": "Added batch mode option to the launcher and incoporated changes from Yichi's pr.\ndifferent requirements for different running modes\nAdded automatic job cancellation for nexmark Launcher\n\nThank you for your contribution! Follow this checklist to help us incorporate your contribution quickly and easily:\n\n Choose reviewer(s) and mention them in a comment (R: @username).\n Format the pull request title like [BEAM-XXX] Fixes bug in ApproximateQuantiles, where you replace BEAM-XXX with the appropriate JIRA issue, if applicable. This will automatically link the pull request to the issue.\n Update CHANGES.md with noteworthy changes.\n If this contribution is large, please file an Apache Individual Contributor License Agreement.\n\nSee the Contributor Guide for more tips on how to make review process smoother.\nPost-Commit Tests Status (on master branch)\n\n\n\nLang\nSDK\nDataflow\nFlink\nSamza\nSpark\nTwister2\n\n\n\n\nGo\n\n---\n\n---\n\n---\n\n\nJava\n\n\n\n\n\n\n\n\nPython\n\n\n\n---\n\n---\n\n\nXLang\n\n---\n\n---\n\n---\n\n\n\nPre-Commit Tests Status (on master branch)\n\n\n\n---\nJava\nPython\nGo\nWebsite\nWhitespace\n\n\n\n\nNon-portable\n\n \n\n\n\n\n\nPortable\n---\n\n---\n---\n---\n\n\n\nSee .test-infra/jenkins/README for trigger phrase, status and link of all Jenkins jobs.\nGitHub Actions Tests Status (on master branch)\n\n\n\nSee CI.md for more information about GitHub Actions CI.", "createdAt": "2020-08-27T23:28:04Z", "url": "https://github.com/apache/beam/pull/12709", "merged": true, "mergeCommit": {"oid": "6b18b59671b4975c149c41b4c56813ff42568667"}, "closed": true, "closedAt": "2020-09-09T14:26:59Z", "author": {"login": "leiyiz"}, "timelineItems": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdDI6YagH2gAyNDc1MDAyNDE2OjgzYzM4YjlmMmIzOGEyOThjOGVjY2I5MWE4MThhNWI5MDM2MzNjZjM=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdHAt5NAFqTQ4NDU3MTg0MQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "83c38b9f2b38a298c8eccb91a818a5b903633cf3", "author": {"user": {"login": "leiyiz", "name": "Leiyi Zhang"}}, "url": "https://github.com/apache/beam/commit/83c38b9f2b38a298c8eccb91a818a5b903633cf3", "committedDate": "2020-08-27T23:22:01Z", "message": "streamline launcher"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDgwMTg5MTIy", "url": "https://github.com/apache/beam/pull/12709#pullrequestreview-480189122", "createdAt": "2020-09-01T23:44:57Z", "commit": {"oid": "fea6af21ac98b03b74453f4009222bf83028a92c"}, "state": "COMMENTED", "comments": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMVQyMzo0NDo1N1rOHLL9Jg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMlQwMDo0NDoyMFrOHLM-lg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQ5MjI2Mg==", "bodyText": "can we just import time", "url": "https://github.com/apache/beam/pull/12709#discussion_r481492262", "createdAt": "2020-09-01T23:44:57Z", "author": {"login": "y1chi"}, "path": "sdks/python/apache_beam/testing/benchmarks/nexmark/nexmark_launcher.py", "diffHunk": "@@ -67,18 +67,20 @@\n import logging\n import sys\n import uuid\n-\n-from google.cloud import pubsub\n+from time import sleep", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fea6af21ac98b03b74453f4009222bf83028a92c"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQ5NDAzNg==", "bodyText": "can we raise exception instead?", "url": "https://github.com/apache/beam/pull/12709#discussion_r481494036", "createdAt": "2020-09-01T23:50:51Z", "author": {"login": "y1chi"}, "path": "sdks/python/apache_beam/testing/benchmarks/nexmark/nexmark_launcher.py", "diffHunk": "@@ -156,34 +191,32 @@ def parse_args(self):\n \n     # Usage with Dataflow requires a project to be supplied.\n     self.project = self.pipeline_options.view_as(GoogleCloudOptions).project\n-    if self.project is None:\n-      parser.print_usage()\n-      print(sys.argv[0] + ': error: argument --project is required')\n-      sys.exit(1)\n-\n-    # Pub/Sub is currently available for use only in streaming pipelines.\n     self.streaming = self.pipeline_options.view_as(StandardOptions).streaming\n-    if self.streaming is None:\n-      parser.print_usage()\n-      print(sys.argv[0] + ': error: argument --streaming is required')\n-      sys.exit(1)\n \n     # wait_until_finish ensures that the streaming job is canceled.\n     self.wait_until_finish_duration = (\n         self.pipeline_options.view_as(TestOptions).wait_until_finish_duration)\n-    if self.wait_until_finish_duration is None:\n-      parser.print_usage()\n-      print(sys.argv[0] + ': error: argument --wait_until_finish_duration is required')  # pylint: disable=line-too-long\n-      sys.exit(1)\n+    self.runner = self.pipeline_options.view_as(StandardOptions).runner\n+\n+    if self.streaming:\n+      if self.wait_until_finish_duration is None\\\n+          or self.project is None or self.runner != 'DataflowRunner':\n+        print('error: argument --wait_until_finish_duration\\n' +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fea6af21ac98b03b74453f4009222bf83028a92c"}, "originalPosition": 135}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQ5NDYxMQ==", "bodyText": "why are we limiting this to dataflow runner? the benchmark should be made available to all runners", "url": "https://github.com/apache/beam/pull/12709#discussion_r481494611", "createdAt": "2020-09-01T23:53:00Z", "author": {"login": "y1chi"}, "path": "sdks/python/apache_beam/testing/benchmarks/nexmark/nexmark_launcher.py", "diffHunk": "@@ -156,34 +191,32 @@ def parse_args(self):\n \n     # Usage with Dataflow requires a project to be supplied.\n     self.project = self.pipeline_options.view_as(GoogleCloudOptions).project\n-    if self.project is None:\n-      parser.print_usage()\n-      print(sys.argv[0] + ': error: argument --project is required')\n-      sys.exit(1)\n-\n-    # Pub/Sub is currently available for use only in streaming pipelines.\n     self.streaming = self.pipeline_options.view_as(StandardOptions).streaming\n-    if self.streaming is None:\n-      parser.print_usage()\n-      print(sys.argv[0] + ': error: argument --streaming is required')\n-      sys.exit(1)\n \n     # wait_until_finish ensures that the streaming job is canceled.\n     self.wait_until_finish_duration = (\n         self.pipeline_options.view_as(TestOptions).wait_until_finish_duration)\n-    if self.wait_until_finish_duration is None:\n-      parser.print_usage()\n-      print(sys.argv[0] + ': error: argument --wait_until_finish_duration is required')  # pylint: disable=line-too-long\n-      sys.exit(1)\n+    self.runner = self.pipeline_options.view_as(StandardOptions).runner\n+\n+    if self.streaming:\n+      if self.wait_until_finish_duration is None\\\n+          or self.project is None or self.runner != 'DataflowRunner':", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fea6af21ac98b03b74453f4009222bf83028a92c"}, "originalPosition": 134}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQ5NDc3Ng==", "bodyText": "ditto", "url": "https://github.com/apache/beam/pull/12709#discussion_r481494776", "createdAt": "2020-09-01T23:53:38Z", "author": {"login": "y1chi"}, "path": "sdks/python/apache_beam/testing/benchmarks/nexmark/nexmark_launcher.py", "diffHunk": "@@ -156,34 +191,32 @@ def parse_args(self):\n \n     # Usage with Dataflow requires a project to be supplied.\n     self.project = self.pipeline_options.view_as(GoogleCloudOptions).project\n-    if self.project is None:\n-      parser.print_usage()\n-      print(sys.argv[0] + ': error: argument --project is required')\n-      sys.exit(1)\n-\n-    # Pub/Sub is currently available for use only in streaming pipelines.\n     self.streaming = self.pipeline_options.view_as(StandardOptions).streaming\n-    if self.streaming is None:\n-      parser.print_usage()\n-      print(sys.argv[0] + ': error: argument --streaming is required')\n-      sys.exit(1)\n \n     # wait_until_finish ensures that the streaming job is canceled.\n     self.wait_until_finish_duration = (\n         self.pipeline_options.view_as(TestOptions).wait_until_finish_duration)\n-    if self.wait_until_finish_duration is None:\n-      parser.print_usage()\n-      print(sys.argv[0] + ': error: argument --wait_until_finish_duration is required')  # pylint: disable=line-too-long\n-      sys.exit(1)\n+    self.runner = self.pipeline_options.view_as(StandardOptions).runner\n+\n+    if self.streaming:\n+      if self.wait_until_finish_duration is None\\\n+          or self.project is None or self.runner != 'DataflowRunner':\n+        print('error: argument --wait_until_finish_duration\\n' +\n+              '--project and --DataflowRunner required when running in streaming mode')  # pylint: disable=line-too-long\n+        sys.exit(1)\n+    else:\n+      if self.args.input is None:\n+        print('error: argument --input is required when running in batch mode')", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fea6af21ac98b03b74453f4009222bf83028a92c"}, "originalPosition": 140}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQ5Njc1OQ==", "bodyText": "we should use google pydoc style.", "url": "https://github.com/apache/beam/pull/12709#discussion_r481496759", "createdAt": "2020-09-02T00:00:26Z", "author": {"login": "y1chi"}, "path": "sdks/python/apache_beam/testing/benchmarks/nexmark/nexmark_util.py", "diffHunk": "@@ -230,6 +230,15 @@ def millis_to_timestamp(millis):\n \n def get_counter_metric(result, namespace, name):\n   # type: (PipelineResult, str, str) -> int\n+\n+  \"\"\"\n+  get specific counter metric from pipeline result", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fea6af21ac98b03b74453f4009222bf83028a92c"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQ5OTQxMA==", "bodyText": "class is probably not needed.", "url": "https://github.com/apache/beam/pull/12709#discussion_r481499410", "createdAt": "2020-09-02T00:09:24Z", "author": {"login": "y1chi"}, "path": "sdks/python/apache_beam/testing/benchmarks/nexmark/nexmark_launcher.py", "diffHunk": "@@ -200,46 +233,128 @@ def generate_events(self):\n \n     logging.info('Finished event generation.')\n \n+  def read_from_file(self):\n+    return (\n+        self.pipeline\n+        | 'reading_from_file' >> beam.io.ReadFromText(self.args.input)\n+        | 'deserialization' >> beam.ParDo(nexmark_util.ParseJsonEventFn())\n+        | 'timestamping' >>\n+        beam.Map(lambda e: window.TimestampedValue(e, e.date_time)))\n+\n+  def read_from_pubsub(self):\n     # Read from PubSub into a PCollection.\n-    if self.args.subscription_name:\n-      raw_events = self.pipeline | 'ReadPubSub' >> beam.io.ReadFromPubSub(\n-          subscription=sub.full_name)\n+    if self.subscription_name:\n+      raw_events = self.pipeline | 'ReadPubSub_sub' >> beam.io.ReadFromPubSub(\n+          subscription=self.subscription_name,\n+          with_attributes=True,\n+          id_label='id',\n+          timestamp_attribute='timestamp')\n     else:\n-      raw_events = self.pipeline | 'ReadPubSub' >> beam.io.ReadFromPubSub(\n-          topic=topic.full_name)\n-    raw_events = (\n+      raw_events = self.pipeline | 'ReadPubSub_topic' >> beam.io.ReadFromPubSub(\n+          topic=self.topic_name,\n+          with_attributes=True,\n+          id_label='id',\n+          timestamp_attribute='timestamp')\n+    events = (\n         raw_events\n-        | 'deserialization' >> beam.ParDo(nexmark_util.ParseJsonEvnetFn())\n-        | 'timestamping' >>\n-        beam.Map(lambda e: window.TimestampedValue(e, e.date_time)))\n-    return raw_events\n+        | 'pubsub_unwrap' >> beam.Map(lambda m: m.data)\n+        | 'deserialization' >> beam.ParDo(nexmark_util.ParseJsonEventFn()))\n+    return events\n \n   def run_query(self, query, query_args, query_errors):\n     try:\n-      self.parse_args()\n       self.pipeline = beam.Pipeline(options=self.pipeline_options)\n       nexmark_util.setup_coder()\n \n       event_monitor = Monitor('.events', 'event')\n       result_monitor = Monitor('.results', 'result')\n \n-      events = self.generate_events()\n+      if self.streaming:\n+        if self.pubsub_mode != 'SUBSCRIBE_ONLY':\n+          self.generate_events()\n+        if self.pubsub_mode == 'PUBLISH_ONLY':\n+          return\n+        events = self.read_from_pubsub()\n+      else:\n+        events = self.read_from_file()\n+\n       events = events | 'event_monitor' >> beam.ParDo(event_monitor.doFn)\n       output = query.load(events, query_args)\n       output | 'result_monitor' >> beam.ParDo(result_monitor.doFn)  # pylint: disable=expression-not-assigned\n \n       result = self.pipeline.run()\n-      job_duration = (\n-          self.pipeline_options.view_as(TestOptions).wait_until_finish_duration)\n-      if self.pipeline_options.view_as(StandardOptions).runner == 'DataflowRunner':  # pylint: disable=line-too-long\n-        result.wait_until_finish(duration=job_duration)\n-        result.cancel()\n+      if self.runner == 'DataflowRunner':\n+        result.wait_until_finish(duration=self.wait_until_finish_duration)\n       else:\n         result.wait_until_finish()\n+      perf = self.monitor(result, event_monitor, result_monitor)\n+      self.__class__.log_performance(perf)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fea6af21ac98b03b74453f4009222bf83028a92c"}, "originalPosition": 231}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTUwMzQ4NQ==", "bodyText": "typo acticity -> activity", "url": "https://github.com/apache/beam/pull/12709#discussion_r481503485", "createdAt": "2020-09-02T00:23:13Z", "author": {"login": "y1chi"}, "path": "sdks/python/apache_beam/testing/benchmarks/nexmark/nexmark_launcher.py", "diffHunk": "@@ -200,46 +233,128 @@ def generate_events(self):\n \n     logging.info('Finished event generation.')\n \n+  def read_from_file(self):\n+    return (\n+        self.pipeline\n+        | 'reading_from_file' >> beam.io.ReadFromText(self.args.input)\n+        | 'deserialization' >> beam.ParDo(nexmark_util.ParseJsonEventFn())\n+        | 'timestamping' >>\n+        beam.Map(lambda e: window.TimestampedValue(e, e.date_time)))\n+\n+  def read_from_pubsub(self):\n     # Read from PubSub into a PCollection.\n-    if self.args.subscription_name:\n-      raw_events = self.pipeline | 'ReadPubSub' >> beam.io.ReadFromPubSub(\n-          subscription=sub.full_name)\n+    if self.subscription_name:\n+      raw_events = self.pipeline | 'ReadPubSub_sub' >> beam.io.ReadFromPubSub(\n+          subscription=self.subscription_name,\n+          with_attributes=True,\n+          id_label='id',\n+          timestamp_attribute='timestamp')\n     else:\n-      raw_events = self.pipeline | 'ReadPubSub' >> beam.io.ReadFromPubSub(\n-          topic=topic.full_name)\n-    raw_events = (\n+      raw_events = self.pipeline | 'ReadPubSub_topic' >> beam.io.ReadFromPubSub(\n+          topic=self.topic_name,\n+          with_attributes=True,\n+          id_label='id',\n+          timestamp_attribute='timestamp')\n+    events = (\n         raw_events\n-        | 'deserialization' >> beam.ParDo(nexmark_util.ParseJsonEvnetFn())\n-        | 'timestamping' >>\n-        beam.Map(lambda e: window.TimestampedValue(e, e.date_time)))\n-    return raw_events\n+        | 'pubsub_unwrap' >> beam.Map(lambda m: m.data)\n+        | 'deserialization' >> beam.ParDo(nexmark_util.ParseJsonEventFn()))\n+    return events\n \n   def run_query(self, query, query_args, query_errors):\n     try:\n-      self.parse_args()\n       self.pipeline = beam.Pipeline(options=self.pipeline_options)\n       nexmark_util.setup_coder()\n \n       event_monitor = Monitor('.events', 'event')\n       result_monitor = Monitor('.results', 'result')\n \n-      events = self.generate_events()\n+      if self.streaming:\n+        if self.pubsub_mode != 'SUBSCRIBE_ONLY':\n+          self.generate_events()\n+        if self.pubsub_mode == 'PUBLISH_ONLY':\n+          return\n+        events = self.read_from_pubsub()\n+      else:\n+        events = self.read_from_file()\n+\n       events = events | 'event_monitor' >> beam.ParDo(event_monitor.doFn)\n       output = query.load(events, query_args)\n       output | 'result_monitor' >> beam.ParDo(result_monitor.doFn)  # pylint: disable=expression-not-assigned\n \n       result = self.pipeline.run()\n-      job_duration = (\n-          self.pipeline_options.view_as(TestOptions).wait_until_finish_duration)\n-      if self.pipeline_options.view_as(StandardOptions).runner == 'DataflowRunner':  # pylint: disable=line-too-long\n-        result.wait_until_finish(duration=job_duration)\n-        result.cancel()\n+      if self.runner == 'DataflowRunner':\n+        result.wait_until_finish(duration=self.wait_until_finish_duration)\n       else:\n         result.wait_until_finish()\n+      perf = self.monitor(result, event_monitor, result_monitor)\n+      self.__class__.log_performance(perf)\n+\n     except Exception as exc:\n       query_errors.append(str(exc))\n       raise\n \n+  def monitor(self, job, event_monitor, result_monitor):\n+    last_active_ms = -1\n+    perf = None\n+    cancel_job = False\n+    waiting_for_shutdown = False\n+\n+    while True:\n+      now = int(time() * 1000)  # current time in ms\n+      logging.debug('now is %d', now)\n+\n+      curr_perf = NexmarkLauncher.get_performance(\n+          job, event_monitor, result_monitor)\n+      if perf is None or curr_perf.is_active(perf):\n+        last_active_ms = now\n+      if self.streaming and not waiting_for_shutdown:\n+        quiet_duration = (now - last_active_ms) // 1000\n+        if curr_perf.event_count >= self.args.num_events and\\\n+           curr_perf.result_count >= 0 and quiet_duration > self.DONE_DELAY:\n+          logging.info('streaming query appears to have finished executing')\n+          waiting_for_shutdown = True\n+          cancel_job = True\n+        elif quiet_duration > self.TERMINATE_DELAY:\n+          logging.error(\n+              'streaming query have been stuck for %d seconds', quiet_duration)\n+          logging.error('canceling streaming job')\n+          waiting_for_shutdown = True\n+          cancel_job = True\n+        elif quiet_duration > self.WARNING_DELAY:\n+          logging.warning(\n+              'streaming query have been stuck for %d seconds', quiet_duration)\n+\n+        if cancel_job:\n+          job.cancel()\n+\n+      stopped = PipelineState.is_terminal(job.state)\n+      if stopped:\n+        break\n+\n+      perf = curr_perf\n+      if not waiting_for_shutdown:\n+        if last_active_ms == now:\n+          logging.info('acticity seen, new performance data extracted')", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fea6af21ac98b03b74453f4009222bf83028a92c"}, "originalPosition": 278}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTUwNTU2NA==", "bodyText": "if we are proactively terminating the job, wait_until_finish_duration is not needed then.", "url": "https://github.com/apache/beam/pull/12709#discussion_r481505564", "createdAt": "2020-09-02T00:30:40Z", "author": {"login": "y1chi"}, "path": "sdks/python/apache_beam/testing/benchmarks/nexmark/nexmark_launcher.py", "diffHunk": "@@ -200,46 +233,128 @@ def generate_events(self):\n \n     logging.info('Finished event generation.')\n \n+  def read_from_file(self):\n+    return (\n+        self.pipeline\n+        | 'reading_from_file' >> beam.io.ReadFromText(self.args.input)\n+        | 'deserialization' >> beam.ParDo(nexmark_util.ParseJsonEventFn())\n+        | 'timestamping' >>\n+        beam.Map(lambda e: window.TimestampedValue(e, e.date_time)))\n+\n+  def read_from_pubsub(self):\n     # Read from PubSub into a PCollection.\n-    if self.args.subscription_name:\n-      raw_events = self.pipeline | 'ReadPubSub' >> beam.io.ReadFromPubSub(\n-          subscription=sub.full_name)\n+    if self.subscription_name:\n+      raw_events = self.pipeline | 'ReadPubSub_sub' >> beam.io.ReadFromPubSub(\n+          subscription=self.subscription_name,\n+          with_attributes=True,\n+          id_label='id',\n+          timestamp_attribute='timestamp')\n     else:\n-      raw_events = self.pipeline | 'ReadPubSub' >> beam.io.ReadFromPubSub(\n-          topic=topic.full_name)\n-    raw_events = (\n+      raw_events = self.pipeline | 'ReadPubSub_topic' >> beam.io.ReadFromPubSub(\n+          topic=self.topic_name,\n+          with_attributes=True,\n+          id_label='id',\n+          timestamp_attribute='timestamp')\n+    events = (\n         raw_events\n-        | 'deserialization' >> beam.ParDo(nexmark_util.ParseJsonEvnetFn())\n-        | 'timestamping' >>\n-        beam.Map(lambda e: window.TimestampedValue(e, e.date_time)))\n-    return raw_events\n+        | 'pubsub_unwrap' >> beam.Map(lambda m: m.data)\n+        | 'deserialization' >> beam.ParDo(nexmark_util.ParseJsonEventFn()))\n+    return events\n \n   def run_query(self, query, query_args, query_errors):\n     try:\n-      self.parse_args()\n       self.pipeline = beam.Pipeline(options=self.pipeline_options)\n       nexmark_util.setup_coder()\n \n       event_monitor = Monitor('.events', 'event')\n       result_monitor = Monitor('.results', 'result')\n \n-      events = self.generate_events()\n+      if self.streaming:\n+        if self.pubsub_mode != 'SUBSCRIBE_ONLY':\n+          self.generate_events()\n+        if self.pubsub_mode == 'PUBLISH_ONLY':\n+          return\n+        events = self.read_from_pubsub()\n+      else:\n+        events = self.read_from_file()\n+\n       events = events | 'event_monitor' >> beam.ParDo(event_monitor.doFn)\n       output = query.load(events, query_args)\n       output | 'result_monitor' >> beam.ParDo(result_monitor.doFn)  # pylint: disable=expression-not-assigned\n \n       result = self.pipeline.run()\n-      job_duration = (\n-          self.pipeline_options.view_as(TestOptions).wait_until_finish_duration)\n-      if self.pipeline_options.view_as(StandardOptions).runner == 'DataflowRunner':  # pylint: disable=line-too-long\n-        result.wait_until_finish(duration=job_duration)\n-        result.cancel()\n+      if self.runner == 'DataflowRunner':\n+        result.wait_until_finish(duration=self.wait_until_finish_duration)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fea6af21ac98b03b74453f4009222bf83028a92c"}, "originalPosition": 227}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTUwODQ5Nw==", "bodyText": "you can add these fields to NexmarkPerf init as kwarg.", "url": "https://github.com/apache/beam/pull/12709#discussion_r481508497", "createdAt": "2020-09-02T00:42:14Z", "author": {"login": "y1chi"}, "path": "sdks/python/apache_beam/testing/benchmarks/nexmark/nexmark_launcher.py", "diffHunk": "@@ -263,24 +378,27 @@ def get_performance(result, event_monitor, result_monitor):\n         result_monitor.namespace,\n         result_monitor.name_prefix + MonitorSuffix.EVENT_TIME)\n \n+    perf = NexmarkPerf()\n+    perf.event_count = event_count", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fea6af21ac98b03b74453f4009222bf83028a92c"}, "originalPosition": 306}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTUwOTAxNA==", "bodyText": "nit: lets s/other/previous_perf/, s/is_active/has_progress/, I think this will make it more understandable.", "url": "https://github.com/apache/beam/pull/12709#discussion_r481509014", "createdAt": "2020-09-02T00:44:20Z", "author": {"login": "y1chi"}, "path": "sdks/python/apache_beam/testing/benchmarks/nexmark/nexmark_perf.py", "diffHunk": "@@ -0,0 +1,42 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+performance summary for a run of nexmark query\n+\"\"\"\n+\n+\n+class NexmarkPerf(object):\n+  def __init__(self):\n+    self.runtime_sec = -1.0\n+    self.event_count = -1\n+    self.event_per_sec = -1.0\n+    self.result_count = -1\n+\n+  def is_active(self, other):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fea6af21ac98b03b74453f4009222bf83028a92c"}, "originalPosition": 30}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d3bb694d2a87c6764228ce70173cb1251796ce69", "author": {"user": {"login": "leiyiz", "name": "Leiyi Zhang"}}, "url": "https://github.com/apache/beam/commit/d3bb694d2a87c6764228ce70173cb1251796ce69", "committedDate": "2020-09-03T19:41:42Z", "message": "job monitoring and auto cancelling"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1c0d677a84c0d6502a383485a6eaa1de0ca25113", "author": {"user": {"login": "leiyiz", "name": "Leiyi Zhang"}}, "url": "https://github.com/apache/beam/commit/1c0d677a84c0d6502a383485a6eaa1de0ca25113", "committedDate": "2020-09-04T01:16:54Z", "message": "resolve issues in review"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b5eb0cb9868fff1f6db0a33f378b59e40f8f4274", "author": {"user": {"login": "leiyiz", "name": "Leiyi Zhang"}}, "url": "https://github.com/apache/beam/commit/b5eb0cb9868fff1f6db0a33f378b59e40f8f4274", "committedDate": "2020-09-04T01:24:50Z", "message": "removed wait_until_finish_duration argument requirement"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1b2f8e9e5922db425fc2f1a59be3b3234ed17d7d", "author": {"user": {"login": "leiyiz", "name": "Leiyi Zhang"}}, "url": "https://github.com/apache/beam/commit/1b2f8e9e5922db425fc2f1a59be3b3234ed17d7d", "committedDate": "2020-09-04T01:33:43Z", "message": "remove unused import"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg0MTUwNjE3", "url": "https://github.com/apache/beam/pull/12709#pullrequestreview-484150617", "createdAt": "2020-09-08T13:40:16Z", "commit": {"oid": "1b2f8e9e5922db425fc2f1a59be3b3234ed17d7d"}, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxMzo0MDoxN1rOHOdsuw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxMzo1NToxMVrOHOeX6Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDkyODY5OQ==", "bodyText": "Do you need to timestamp as well?", "url": "https://github.com/apache/beam/pull/12709#discussion_r484928699", "createdAt": "2020-09-08T13:40:17Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/testing/benchmarks/nexmark/nexmark_launcher.py", "diffHunk": "@@ -200,46 +223,126 @@ def generate_events(self):\n \n     logging.info('Finished event generation.')\n \n+  def read_from_file(self):\n+    return (\n+        self.pipeline\n+        | 'reading_from_file' >> beam.io.ReadFromText(self.args.input)\n+        | 'deserialization' >> beam.ParDo(nexmark_util.ParseJsonEventFn())\n+        | 'timestamping' >>\n+        beam.Map(lambda e: window.TimestampedValue(e, e.date_time)))\n+\n+  def read_from_pubsub(self):\n     # Read from PubSub into a PCollection.\n-    if self.args.subscription_name:\n-      raw_events = self.pipeline | 'ReadPubSub' >> beam.io.ReadFromPubSub(\n-          subscription=sub.full_name)\n+    if self.subscription_name:\n+      raw_events = self.pipeline | 'ReadPubSub_sub' >> beam.io.ReadFromPubSub(\n+          subscription=self.subscription_name,\n+          with_attributes=True,\n+          timestamp_attribute='timestamp')\n     else:\n-      raw_events = self.pipeline | 'ReadPubSub' >> beam.io.ReadFromPubSub(\n-          topic=topic.full_name)\n-    raw_events = (\n+      raw_events = self.pipeline | 'ReadPubSub_topic' >> beam.io.ReadFromPubSub(\n+          topic=self.topic_name,\n+          with_attributes=True,\n+          timestamp_attribute='timestamp')\n+    events = (\n         raw_events\n-        | 'deserialization' >> beam.ParDo(nexmark_util.ParseJsonEvnetFn())\n-        | 'timestamping' >>\n-        beam.Map(lambda e: window.TimestampedValue(e, e.date_time)))\n-    return raw_events\n+        | 'pubsub_unwrap' >> beam.Map(lambda m: m.data)\n+        | 'deserialization' >> beam.ParDo(nexmark_util.ParseJsonEventFn()))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1b2f8e9e5922db425fc2f1a59be3b3234ed17d7d"}, "originalPosition": 192}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDkzMDUzNA==", "bodyText": "We don't usually rely on \\ to add newlines. We use parentheses (e.g. if (curr_perf.event_count >=.... \\n\\t something something):", "url": "https://github.com/apache/beam/pull/12709#discussion_r484930534", "createdAt": "2020-09-08T13:42:54Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/testing/benchmarks/nexmark/nexmark_launcher.py", "diffHunk": "@@ -200,46 +223,126 @@ def generate_events(self):\n \n     logging.info('Finished event generation.')\n \n+  def read_from_file(self):\n+    return (\n+        self.pipeline\n+        | 'reading_from_file' >> beam.io.ReadFromText(self.args.input)\n+        | 'deserialization' >> beam.ParDo(nexmark_util.ParseJsonEventFn())\n+        | 'timestamping' >>\n+        beam.Map(lambda e: window.TimestampedValue(e, e.date_time)))\n+\n+  def read_from_pubsub(self):\n     # Read from PubSub into a PCollection.\n-    if self.args.subscription_name:\n-      raw_events = self.pipeline | 'ReadPubSub' >> beam.io.ReadFromPubSub(\n-          subscription=sub.full_name)\n+    if self.subscription_name:\n+      raw_events = self.pipeline | 'ReadPubSub_sub' >> beam.io.ReadFromPubSub(\n+          subscription=self.subscription_name,\n+          with_attributes=True,\n+          timestamp_attribute='timestamp')\n     else:\n-      raw_events = self.pipeline | 'ReadPubSub' >> beam.io.ReadFromPubSub(\n-          topic=topic.full_name)\n-    raw_events = (\n+      raw_events = self.pipeline | 'ReadPubSub_topic' >> beam.io.ReadFromPubSub(\n+          topic=self.topic_name,\n+          with_attributes=True,\n+          timestamp_attribute='timestamp')\n+    events = (\n         raw_events\n-        | 'deserialization' >> beam.ParDo(nexmark_util.ParseJsonEvnetFn())\n-        | 'timestamping' >>\n-        beam.Map(lambda e: window.TimestampedValue(e, e.date_time)))\n-    return raw_events\n+        | 'pubsub_unwrap' >> beam.Map(lambda m: m.data)\n+        | 'deserialization' >> beam.ParDo(nexmark_util.ParseJsonEventFn()))\n+    return events\n \n   def run_query(self, query, query_args, query_errors):\n     try:\n-      self.parse_args()\n       self.pipeline = beam.Pipeline(options=self.pipeline_options)\n       nexmark_util.setup_coder()\n \n       event_monitor = Monitor('.events', 'event')\n       result_monitor = Monitor('.results', 'result')\n \n-      events = self.generate_events()\n+      if self.streaming:\n+        if self.pubsub_mode != 'SUBSCRIBE_ONLY':\n+          self.generate_events()\n+        if self.pubsub_mode == 'PUBLISH_ONLY':\n+          return\n+        events = self.read_from_pubsub()\n+      else:\n+        events = self.read_from_file()\n+\n       events = events | 'event_monitor' >> beam.ParDo(event_monitor.doFn)\n       output = query.load(events, query_args)\n       output | 'result_monitor' >> beam.ParDo(result_monitor.doFn)  # pylint: disable=expression-not-assigned\n \n       result = self.pipeline.run()\n-      job_duration = (\n-          self.pipeline_options.view_as(TestOptions).wait_until_finish_duration)\n-      if self.pipeline_options.view_as(StandardOptions).runner == 'DataflowRunner':  # pylint: disable=line-too-long\n-        result.wait_until_finish(duration=job_duration)\n-        result.cancel()\n-      else:\n+      if not self.streaming:\n         result.wait_until_finish()\n+      perf = self.monitor(result, event_monitor, result_monitor)\n+      self.log_performance(perf)\n+\n     except Exception as exc:\n       query_errors.append(str(exc))\n       raise\n \n+  def monitor(self, job, event_monitor, result_monitor):\n+    logging.info('starting to monitor the job')\n+    last_active_ms = -1\n+    perf = None\n+    cancel_job = False\n+    waiting_for_shutdown = False\n+\n+    while True:\n+      now = int(time.time() * 1000)  # current time in ms\n+      logging.debug('now is %d', now)\n+\n+      curr_perf = NexmarkLauncher.get_performance(\n+          job, event_monitor, result_monitor)\n+      if perf is None or curr_perf.has_progress(perf):\n+        last_active_ms = now\n+      if self.streaming and not waiting_for_shutdown:\n+        quiet_duration = (now - last_active_ms) // 1000\n+        if curr_perf.event_count >= self.args.num_events and\\", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1b2f8e9e5922db425fc2f1a59be3b3234ed17d7d"}, "originalPosition": 251}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDkzMjY5MQ==", "bodyText": "@leiyiz the logic in this method is a little difficult to follow (the spurious codecov annotations don't help either) - do you think you could add a pydoc at the top roughly describing what the method does?", "url": "https://github.com/apache/beam/pull/12709#discussion_r484932691", "createdAt": "2020-09-08T13:45:47Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/testing/benchmarks/nexmark/nexmark_launcher.py", "diffHunk": "@@ -200,46 +223,126 @@ def generate_events(self):\n \n     logging.info('Finished event generation.')\n \n+  def read_from_file(self):\n+    return (\n+        self.pipeline\n+        | 'reading_from_file' >> beam.io.ReadFromText(self.args.input)\n+        | 'deserialization' >> beam.ParDo(nexmark_util.ParseJsonEventFn())\n+        | 'timestamping' >>\n+        beam.Map(lambda e: window.TimestampedValue(e, e.date_time)))\n+\n+  def read_from_pubsub(self):\n     # Read from PubSub into a PCollection.\n-    if self.args.subscription_name:\n-      raw_events = self.pipeline | 'ReadPubSub' >> beam.io.ReadFromPubSub(\n-          subscription=sub.full_name)\n+    if self.subscription_name:\n+      raw_events = self.pipeline | 'ReadPubSub_sub' >> beam.io.ReadFromPubSub(\n+          subscription=self.subscription_name,\n+          with_attributes=True,\n+          timestamp_attribute='timestamp')\n     else:\n-      raw_events = self.pipeline | 'ReadPubSub' >> beam.io.ReadFromPubSub(\n-          topic=topic.full_name)\n-    raw_events = (\n+      raw_events = self.pipeline | 'ReadPubSub_topic' >> beam.io.ReadFromPubSub(\n+          topic=self.topic_name,\n+          with_attributes=True,\n+          timestamp_attribute='timestamp')\n+    events = (\n         raw_events\n-        | 'deserialization' >> beam.ParDo(nexmark_util.ParseJsonEvnetFn())\n-        | 'timestamping' >>\n-        beam.Map(lambda e: window.TimestampedValue(e, e.date_time)))\n-    return raw_events\n+        | 'pubsub_unwrap' >> beam.Map(lambda m: m.data)\n+        | 'deserialization' >> beam.ParDo(nexmark_util.ParseJsonEventFn()))\n+    return events\n \n   def run_query(self, query, query_args, query_errors):\n     try:\n-      self.parse_args()\n       self.pipeline = beam.Pipeline(options=self.pipeline_options)\n       nexmark_util.setup_coder()\n \n       event_monitor = Monitor('.events', 'event')\n       result_monitor = Monitor('.results', 'result')\n \n-      events = self.generate_events()\n+      if self.streaming:\n+        if self.pubsub_mode != 'SUBSCRIBE_ONLY':\n+          self.generate_events()\n+        if self.pubsub_mode == 'PUBLISH_ONLY':\n+          return\n+        events = self.read_from_pubsub()\n+      else:\n+        events = self.read_from_file()\n+\n       events = events | 'event_monitor' >> beam.ParDo(event_monitor.doFn)\n       output = query.load(events, query_args)\n       output | 'result_monitor' >> beam.ParDo(result_monitor.doFn)  # pylint: disable=expression-not-assigned\n \n       result = self.pipeline.run()\n-      job_duration = (\n-          self.pipeline_options.view_as(TestOptions).wait_until_finish_duration)\n-      if self.pipeline_options.view_as(StandardOptions).runner == 'DataflowRunner':  # pylint: disable=line-too-long\n-        result.wait_until_finish(duration=job_duration)\n-        result.cancel()\n-      else:\n+      if not self.streaming:\n         result.wait_until_finish()\n+      perf = self.monitor(result, event_monitor, result_monitor)\n+      self.log_performance(perf)\n+\n     except Exception as exc:\n       query_errors.append(str(exc))\n       raise\n \n+  def monitor(self, job, event_monitor, result_monitor):\n+    logging.info('starting to monitor the job')\n+    last_active_ms = -1\n+    perf = None\n+    cancel_job = False\n+    waiting_for_shutdown = False\n+\n+    while True:\n+      now = int(time.time() * 1000)  # current time in ms\n+      logging.debug('now is %d', now)\n+\n+      curr_perf = NexmarkLauncher.get_performance(\n+          job, event_monitor, result_monitor)\n+      if perf is None or curr_perf.has_progress(perf):\n+        last_active_ms = now\n+      if self.streaming and not waiting_for_shutdown:\n+        quiet_duration = (now - last_active_ms) // 1000\n+        if curr_perf.event_count >= self.args.num_events and\\\n+           curr_perf.result_count >= 0 and quiet_duration > self.DONE_DELAY:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1b2f8e9e5922db425fc2f1a59be3b3234ed17d7d"}, "originalPosition": 252}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDkzMzI1NA==", "bodyText": "It looks like you can call self.cleanup for most of these, and save a few lines? : )", "url": "https://github.com/apache/beam/pull/12709#discussion_r484933254", "createdAt": "2020-09-08T13:46:32Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/testing/benchmarks/nexmark/nexmark_launcher.py", "diffHunk": "@@ -96,24 +94,41 @@\n \n \n class NexmarkLauncher(object):\n+\n+  # how long after some result is seen and no activity seen do we cancel job\n+  DONE_DELAY = 5 * 60\n+  # delay in seconds between sample perf data\n+  PERF_DELAY = 20\n+  # delay before cancelling the job when pipeline appears to be stuck\n+  TERMINATE_DELAY = 1 * 60 * 60\n+  # delay before warning when pipeline appears to be stuck\n+  WARNING_DELAY = 10 * 60\n+\n   def __init__(self):\n     self.parse_args()\n-    self.uuid = str(uuid.uuid4())\n-    self.topic_name = self.args.topic_name + self.uuid\n-    self.subscription_name = self.args.subscription_name + self.uuid\n-    publish_client = pubsub.Client(project=self.project)\n-    topic = publish_client.topic(self.topic_name)\n-    if topic.exists():\n-      logging.info('deleting topic %s', self.topic_name)\n-      topic.delete()\n-    logging.info('creating topic %s', self.topic_name)\n-    topic.create()\n-    sub = topic.subscription(self.subscription_name)\n-    if sub.exists():\n-      logging.info('deleting sub %s', self.topic_name)\n-      sub.delete()\n-    logging.info('creating sub %s', self.topic_name)\n-    sub.create()\n+    self.manage_resources = self.args.manage_resources\n+    self.uuid = str(uuid.uuid4()) if self.manage_resources else ''\n+    self.topic_name = (\n+        self.args.topic_name + self.uuid if self.args.topic_name else None)\n+    self.subscription_name = (\n+        self.args.subscription_name +\n+        self.uuid if self.args.subscription_name else None)\n+    self.pubsub_mode = self.args.pubsub_mode\n+    if self.manage_resources:\n+      from google.cloud import pubsub\n+      publish_client = pubsub.Client(project=self.project)\n+      topic = publish_client.topic(self.topic_name)\n+      if topic.exists():\n+        logging.info('deleting topic %s', self.topic_name)\n+        topic.delete()\n+      logging.info('creating topic %s', self.topic_name)\n+      topic.create()\n+      sub = topic.subscription(self.subscription_name)\n+      if sub.exists():\n+        logging.info('deleting sub %s', self.topic_name)\n+        sub.delete()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1b2f8e9e5922db425fc2f1a59be3b3234ed17d7d"}, "originalPosition": 77}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDkzNzY1OA==", "bodyText": "let's use parentheses instead of \\", "url": "https://github.com/apache/beam/pull/12709#discussion_r484937658", "createdAt": "2020-09-08T13:52:25Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/testing/benchmarks/nexmark/nexmark_perf.py", "diffHunk": "@@ -0,0 +1,49 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+performance summary for a run of nexmark query\n+\"\"\"\n+\n+\n+class NexmarkPerf(object):\n+  def __init__(\n+      self,\n+      runtime_sec=None,\n+      event_count=None,\n+      event_per_sec=None,\n+      result_count=None):\n+    self.runtime_sec = runtime_sec if runtime_sec else -1.0\n+    self.event_count = event_count if event_count else -1\n+    self.event_per_sec = event_per_sec if event_per_sec else -1.0\n+    self.result_count = result_count if result_count else -1\n+\n+  def has_progress(self, previous_perf):\n+    # type: (NexmarkPerf) -> bool\n+\n+    \"\"\"\n+    Args:\n+      previous_perf: a NexmarkPerf object to be compared to self\n+\n+    Returns:\n+      True if there are activity between self and other NexmarkPerf values\n+    \"\"\"\n+    if self.runtime_sec != previous_perf.runtime_sec or\\", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1b2f8e9e5922db425fc2f1a59be3b3234ed17d7d"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDkzODMzMQ==", "bodyText": "e.g.\nif (self.r_s != ... or\n    self.abc != self.def or ...):", "url": "https://github.com/apache/beam/pull/12709#discussion_r484938331", "createdAt": "2020-09-08T13:53:18Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/testing/benchmarks/nexmark/nexmark_perf.py", "diffHunk": "@@ -0,0 +1,49 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+performance summary for a run of nexmark query\n+\"\"\"\n+\n+\n+class NexmarkPerf(object):\n+  def __init__(\n+      self,\n+      runtime_sec=None,\n+      event_count=None,\n+      event_per_sec=None,\n+      result_count=None):\n+    self.runtime_sec = runtime_sec if runtime_sec else -1.0\n+    self.event_count = event_count if event_count else -1\n+    self.event_per_sec = event_per_sec if event_per_sec else -1.0\n+    self.result_count = result_count if result_count else -1\n+\n+  def has_progress(self, previous_perf):\n+    # type: (NexmarkPerf) -> bool\n+\n+    \"\"\"\n+    Args:\n+      previous_perf: a NexmarkPerf object to be compared to self\n+\n+    Returns:\n+      True if there are activity between self and other NexmarkPerf values\n+    \"\"\"\n+    if self.runtime_sec != previous_perf.runtime_sec or\\", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDkzNzY1OA=="}, "originalCommit": {"oid": "1b2f8e9e5922db425fc2f1a59be3b3234ed17d7d"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NDkzOTc1Mw==", "bodyText": "Also, is progress in runtime_sec an indicator of progress in the pipeline? Perhaps could you add pydoc for this class describing what each attribute represents?", "url": "https://github.com/apache/beam/pull/12709#discussion_r484939753", "createdAt": "2020-09-08T13:55:11Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/testing/benchmarks/nexmark/nexmark_perf.py", "diffHunk": "@@ -0,0 +1,49 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+performance summary for a run of nexmark query\n+\"\"\"\n+\n+\n+class NexmarkPerf(object):\n+  def __init__(\n+      self,\n+      runtime_sec=None,\n+      event_count=None,\n+      event_per_sec=None,\n+      result_count=None):\n+    self.runtime_sec = runtime_sec if runtime_sec else -1.0\n+    self.event_count = event_count if event_count else -1\n+    self.event_per_sec = event_per_sec if event_per_sec else -1.0\n+    self.result_count = result_count if result_count else -1\n+\n+  def has_progress(self, previous_perf):\n+    # type: (NexmarkPerf) -> bool\n+\n+    \"\"\"\n+    Args:\n+      previous_perf: a NexmarkPerf object to be compared to self\n+\n+    Returns:\n+      True if there are activity between self and other NexmarkPerf values\n+    \"\"\"\n+    if self.runtime_sec != previous_perf.runtime_sec or\\\n+       self.event_count != previous_perf.event_count or\\\n+       self.result_count != previous_perf.result_count:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1b2f8e9e5922db425fc2f1a59be3b3234ed17d7d"}, "originalPosition": 47}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b0b62500de9354faac2686affab5d6222dec2d84", "author": {"user": {"login": "leiyiz", "name": "Leiyi Zhang"}}, "url": "https://github.com/apache/beam/commit/b0b62500de9354faac2686affab5d6222dec2d84", "committedDate": "2020-09-08T22:35:49Z", "message": "added more docs and better formatting"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg0NTcxODQx", "url": "https://github.com/apache/beam/pull/12709#pullrequestreview-484571841", "createdAt": "2020-09-09T00:04:50Z", "commit": {"oid": "b0b62500de9354faac2686affab5d6222dec2d84"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4527, "cost": 1, "resetAt": "2021-10-28T16:48:13Z"}}}