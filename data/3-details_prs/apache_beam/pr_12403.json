{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDU4MjAzODQ0", "number": 12403, "title": "[BEAM-10597] Propagate BigQuery streaming insert throttled time to Dataflow worker", "bodyText": "r: @chamikaramj @ihji\nFYI: this change is very similar to #8973\nPost-Commit Tests Status (on master branch)\n\n\n\nLang\nSDK\nDataflow\nFlink\nSamza\nSpark\nTwister2\n\n\n\n\nGo\n\n---\n\n---\n\n---\n\n\nJava\n\n\n\n\n\n\n\n\nPython\n\n\n\n---\n\n---\n\n\nXLang\n\n---\n\n---\n\n---\n\n\n\nPre-Commit Tests Status (on master branch)\n\n\n\n---\nJava\nPython\nGo\nWebsite\n\n\n\n\nNon-portable\n\n\n\n\n\n\nPortable\n---\n\n---\n---\n\n\n\nSee .test-infra/jenkins/README for trigger phrase, status and link of all Jenkins jobs.", "createdAt": "2020-07-29T05:31:34Z", "url": "https://github.com/apache/beam/pull/12403", "merged": true, "mergeCommit": {"oid": "00408654904c233df2de62762a07405a4768b5a6"}, "closed": true, "closedAt": "2020-08-21T16:45:22Z", "author": {"login": "robinyqiu"}, "timelineItems": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc6FNw9gBqjM2MDU1NTkxNjI=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdA6H3LgBqjM2Nzc2MjIyODY=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d3a6b079a371c63d5d7d074e453433ca421a6522", "author": {"user": {"login": "robinyqiu", "name": "Yueyang Qiu"}}, "url": "https://github.com/apache/beam/commit/d3a6b079a371c63d5d7d074e453433ca421a6522", "committedDate": "2020-07-29T19:09:47Z", "message": "Propagate BigQuery streaming insert throttled time to Dataflow worker in Python SDK"}, "afterCommit": {"oid": "09077d0e6bbfbbb79e8d417801ea7b5dd0b9148e", "author": {"user": {"login": "robinyqiu", "name": "Yueyang Qiu"}}, "url": "https://github.com/apache/beam/commit/09077d0e6bbfbbb79e8d417801ea7b5dd0b9148e", "committedDate": "2020-07-30T19:58:02Z", "message": "Propagate BigQuery streaming insert throttled time to Dataflow worker in Python SDK"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDYwMjAwOTAz", "url": "https://github.com/apache/beam/pull/12403#pullrequestreview-460200903", "createdAt": "2020-08-03T17:17:22Z", "commit": {"oid": "09077d0e6bbfbbb79e8d417801ea7b5dd0b9148e"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QxNzoxNzoyMlrOG7B4FQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QxNzoyMTozOFrOG7CAtA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDU0OTkwOQ==", "bodyText": "Can we use the same name as above (\"cumulativeThrottlingSeconds\") and move it to a constant (and also do ms to sec conversion when setting) ?", "url": "https://github.com/apache/beam/pull/12403#discussion_r464549909", "createdAt": "2020-08-03T17:17:22Z", "author": {"login": "chamikaramj"}, "path": "runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/BatchModeExecutionContext.java", "diffHunk": "@@ -543,6 +547,16 @@ public Long extractThrottleTime() {\n         totalThrottleTime += httpClientApiThrottlingTime.getCumulative();\n       }\n \n+      CounterCell bigqueryStreamingInsertThrottleTime =\n+          container.tryGetCounter(\n+              MetricName.named(\n+                  BIGQUERY_STREAMING_INSERT_THROTTLE_TIME_NAMESPACE,\n+                  BIGQUERY_STREAMING_INSERT_THROTTLE_TIME_NAME));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "09077d0e6bbfbbb79e8d417801ea7b5dd0b9148e"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDU1MDcwOQ==", "bodyText": "Is there a reason why we needed to use a  unique name for BQ but not for GCS or Datastore ?", "url": "https://github.com/apache/beam/pull/12403#discussion_r464550709", "createdAt": "2020-08-03T17:18:49Z", "author": {"login": "chamikaramj"}, "path": "runners/google-cloud-dataflow-java/worker/src/main/java/org/apache/beam/runners/dataflow/worker/StreamingDataflowWorker.java", "diffHunk": "@@ -520,8 +526,11 @@ public int getSize() {\n     private void translateKnownStepCounters(CounterUpdate stepCounterUpdate) {\n       CounterStructuredName structuredName =\n           stepCounterUpdate.getStructuredNameAndMetadata().getName();\n-      if (THROTTLING_MSECS_METRIC_NAME.getNamespace().equals(structuredName.getOriginNamespace())\n-          && THROTTLING_MSECS_METRIC_NAME.getName().equals(structuredName.getName())) {\n+      if ((THROTTLING_MSECS_METRIC_NAME.getNamespace().equals(structuredName.getOriginNamespace())\n+              && THROTTLING_MSECS_METRIC_NAME.getName().equals(structuredName.getName()))\n+          || (BIGQUERY_STREAMING_INSERT_THROTTLE_TIME_NAMESPACE.equals(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "09077d0e6bbfbbb79e8d417801ea7b5dd0b9148e"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDU1MjExNg==", "bodyText": "This is for failures. Probably you need to increment the counter for backoff1 for rate limit errors above.\ncc: @ihji", "url": "https://github.com/apache/beam/pull/12403#discussion_r464552116", "createdAt": "2020-08-03T17:21:38Z", "author": {"login": "chamikaramj"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryServicesImpl.java", "diffHunk": "@@ -867,6 +872,7 @@ public void deleteDataset(String projectId, String datasetId)\n         }\n         try {\n           sleeper.sleep(nextBackoffMillis);\n+          throttlingMilliSeconds.inc(nextBackoffMillis);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "09077d0e6bbfbbb79e8d417801ea7b5dd0b9148e"}, "originalPosition": 23}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f596b43e30ad585ad4c39fa45db903afa301d6ac", "author": {"user": {"login": "robinyqiu", "name": "Yueyang Qiu"}}, "url": "https://github.com/apache/beam/commit/f596b43e30ad585ad4c39fa45db903afa301d6ac", "committedDate": "2020-08-17T23:15:32Z", "message": "GCS and Datastore report throttling-msecs as well"}, "afterCommit": {"oid": "9dc9157fe6126c20af3db7dd68ba68433ec661ad", "author": {"user": {"login": "robinyqiu", "name": "Yueyang Qiu"}}, "url": "https://github.com/apache/beam/commit/9dc9157fe6126c20af3db7dd68ba68433ec661ad", "committedDate": "2020-08-17T23:20:44Z", "message": "GCS and Datastore report throttling-msecs as well"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9dc9157fe6126c20af3db7dd68ba68433ec661ad", "author": {"user": {"login": "robinyqiu", "name": "Yueyang Qiu"}}, "url": "https://github.com/apache/beam/commit/9dc9157fe6126c20af3db7dd68ba68433ec661ad", "committedDate": "2020-08-17T23:20:44Z", "message": "GCS and Datastore report throttling-msecs as well"}, "afterCommit": {"oid": "819615081793eb535025bb7bf6d278c50725c686", "author": {"user": {"login": "robinyqiu", "name": "Yueyang Qiu"}}, "url": "https://github.com/apache/beam/commit/819615081793eb535025bb7bf6d278c50725c686", "committedDate": "2020-08-17T23:54:13Z", "message": "GCS and Datastore report throttling-msecs as well"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDcxODIzNzQ0", "url": "https://github.com/apache/beam/pull/12403#pullrequestreview-471823744", "createdAt": "2020-08-20T17:13:30Z", "commit": {"oid": "621a4c375dd4f2bdc2eaee0bb5b3601ce1802513"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQxNzoxMzozMFrOHELnIQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQxNzoxMzozMFrOHELnIQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE0NjU5Mw==", "bodyText": "Please consider adding this to Python as well (in  a separate PR).\ncc: @pabloem", "url": "https://github.com/apache/beam/pull/12403#discussion_r474146593", "createdAt": "2020-08-20T17:13:30Z", "author": {"login": "chamikaramj"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/bigquery/BigQueryServicesImpl.java", "diffHunk": "@@ -424,6 +427,9 @@ public Job getJob(JobReference jobRef, Sleeper sleeper, BackOff backoff)\n     private final PipelineOptions options;\n     private final long maxRowsPerBatch;\n     private final long maxRowBatchSize;\n+    // aggregate the total time spent in exponential backoff", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "621a4c375dd4f2bdc2eaee0bb5b3601ce1802513"}, "originalPosition": 21}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDcxODIzODYz", "url": "https://github.com/apache/beam/pull/12403#pullrequestreview-471823863", "createdAt": "2020-08-20T17:13:39Z", "commit": {"oid": "621a4c375dd4f2bdc2eaee0bb5b3601ce1802513"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bffcd2376b4ef6ba7ce14faf0443129dea28c824", "author": {"user": {"login": "robinyqiu", "name": "Yueyang Qiu"}}, "url": "https://github.com/apache/beam/commit/bffcd2376b4ef6ba7ce14faf0443129dea28c824", "committedDate": "2020-08-21T00:59:47Z", "message": "Propagate BigQuery streaming insert throttled time to Dataflow worker in Java SDK"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "621a4c375dd4f2bdc2eaee0bb5b3601ce1802513", "author": {"user": {"login": "robinyqiu", "name": "Yueyang Qiu"}}, "url": "https://github.com/apache/beam/commit/621a4c375dd4f2bdc2eaee0bb5b3601ce1802513", "committedDate": "2020-08-18T23:52:30Z", "message": "Count throttled time in backoff1"}, "afterCommit": {"oid": "bffcd2376b4ef6ba7ce14faf0443129dea28c824", "author": {"user": {"login": "robinyqiu", "name": "Yueyang Qiu"}}, "url": "https://github.com/apache/beam/commit/bffcd2376b4ef6ba7ce14faf0443129dea28c824", "committedDate": "2020-08-21T00:59:47Z", "message": "Propagate BigQuery streaming insert throttled time to Dataflow worker in Java SDK"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3576, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}