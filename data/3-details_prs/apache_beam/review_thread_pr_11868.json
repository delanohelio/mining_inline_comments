{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDI1MzY5MDc5", "number": 11868, "reviewThreads": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQxOToxMjowNFrOECstNg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQwMDoyNzowMFrOEDq3ig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcxMjY1MDc4OnYy", "diffSide": "RIGHT", "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamTableFunctionScanRel.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQxOToxMjowNFrOGfUQcw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQwMDowMDoyMFrOGg0THw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTQ5MDkzMQ==", "bodyText": "This approach works, but it increases complexity, reduces debugability, and is more error prone when compared to a simple 'switch case' statement and static methods.", "url": "https://github.com/apache/beam/pull/11868#discussion_r435490931", "createdAt": "2020-06-04T19:12:04Z", "author": {"login": "apilloud"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamTableFunctionScanRel.java", "diffHunk": "@@ -95,29 +186,19 @@ public TableFunctionScan copy(\n           input);\n       String operatorName = ((RexCall) getCall()).getOperator().getName();\n       checkArgument(\n-          operatorName.equals(\"TUMBLE\"),\n-          \"Only support TUMBLE table-valued function. Current operator: %s\",\n+          TVFStreamingUtils.WINDOWING_TVF.contains(operatorName),\n+          \"Only support %s table-valued functions. Current operator: %s\",\n+          TVFStreamingUtils.WINDOWING_TVF,\n           operatorName);\n-      RexCall call = ((RexCall) getCall());\n-      RexInputRef wmCol = (RexInputRef) call.getOperands().get(1);\n-      PCollection<Row> upstream = input.get(0);\n-      Schema outputSchema = CalciteUtils.toSchema(getRowType());\n-      FixedWindows windowFn = FixedWindows.of(durationParameter(call.getOperands().get(2)));\n-      PCollection<Row> streamWithWindowMetadata =\n-          upstream\n-              .apply(ParDo.of(new FixedWindowDoFn(windowFn, wmCol.getIndex(), outputSchema)))\n-              .setRowSchema(outputSchema);\n-\n-      PCollection<Row> windowedStream =\n-          assignTimestampsAndWindow(\n-              streamWithWindowMetadata, wmCol.getIndex(), (WindowFn) windowFn);\n \n-      return windowedStream;\n+      return tvfToPTransformMap.get(operatorName).toPTransform(((RexCall) getCall()), input.get(0));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "185ed224c658fa41f7b35a1c34bdcd75474fc863"}, "originalPosition": 151}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA2NDI3Nw==", "bodyText": "I am planning to keep it for now. Because we will support user-defined table-valued function in the near future, seems to me that such way will be extensible for UDTVF.", "url": "https://github.com/apache/beam/pull/11868#discussion_r437064277", "createdAt": "2020-06-08T23:59:38Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamTableFunctionScanRel.java", "diffHunk": "@@ -95,29 +186,19 @@ public TableFunctionScan copy(\n           input);\n       String operatorName = ((RexCall) getCall()).getOperator().getName();\n       checkArgument(\n-          operatorName.equals(\"TUMBLE\"),\n-          \"Only support TUMBLE table-valued function. Current operator: %s\",\n+          TVFStreamingUtils.WINDOWING_TVF.contains(operatorName),\n+          \"Only support %s table-valued functions. Current operator: %s\",\n+          TVFStreamingUtils.WINDOWING_TVF,\n           operatorName);\n-      RexCall call = ((RexCall) getCall());\n-      RexInputRef wmCol = (RexInputRef) call.getOperands().get(1);\n-      PCollection<Row> upstream = input.get(0);\n-      Schema outputSchema = CalciteUtils.toSchema(getRowType());\n-      FixedWindows windowFn = FixedWindows.of(durationParameter(call.getOperands().get(2)));\n-      PCollection<Row> streamWithWindowMetadata =\n-          upstream\n-              .apply(ParDo.of(new FixedWindowDoFn(windowFn, wmCol.getIndex(), outputSchema)))\n-              .setRowSchema(outputSchema);\n-\n-      PCollection<Row> windowedStream =\n-          assignTimestampsAndWindow(\n-              streamWithWindowMetadata, wmCol.getIndex(), (WindowFn) windowFn);\n \n-      return windowedStream;\n+      return tvfToPTransformMap.get(operatorName).toPTransform(((RexCall) getCall()), input.get(0));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTQ5MDkzMQ=="}, "originalCommit": {"oid": "185ed224c658fa41f7b35a1c34bdcd75474fc863"}, "originalPosition": 151}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA2NDQ3OQ==", "bodyText": "If it turns that UDTVF will goes to different Rel or same Rel but different code path, I will switch here back to 'switch case'", "url": "https://github.com/apache/beam/pull/11868#discussion_r437064479", "createdAt": "2020-06-09T00:00:20Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamTableFunctionScanRel.java", "diffHunk": "@@ -95,29 +186,19 @@ public TableFunctionScan copy(\n           input);\n       String operatorName = ((RexCall) getCall()).getOperator().getName();\n       checkArgument(\n-          operatorName.equals(\"TUMBLE\"),\n-          \"Only support TUMBLE table-valued function. Current operator: %s\",\n+          TVFStreamingUtils.WINDOWING_TVF.contains(operatorName),\n+          \"Only support %s table-valued functions. Current operator: %s\",\n+          TVFStreamingUtils.WINDOWING_TVF,\n           operatorName);\n-      RexCall call = ((RexCall) getCall());\n-      RexInputRef wmCol = (RexInputRef) call.getOperands().get(1);\n-      PCollection<Row> upstream = input.get(0);\n-      Schema outputSchema = CalciteUtils.toSchema(getRowType());\n-      FixedWindows windowFn = FixedWindows.of(durationParameter(call.getOperands().get(2)));\n-      PCollection<Row> streamWithWindowMetadata =\n-          upstream\n-              .apply(ParDo.of(new FixedWindowDoFn(windowFn, wmCol.getIndex(), outputSchema)))\n-              .setRowSchema(outputSchema);\n-\n-      PCollection<Row> windowedStream =\n-          assignTimestampsAndWindow(\n-              streamWithWindowMetadata, wmCol.getIndex(), (WindowFn) windowFn);\n \n-      return windowedStream;\n+      return tvfToPTransformMap.get(operatorName).toPTransform(((RexCall) getCall()), input.get(0));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTQ5MDkzMQ=="}, "originalCommit": {"oid": "185ed224c658fa41f7b35a1c34bdcd75474fc863"}, "originalPosition": 151}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcxMjY3NDE1OnYy", "diffSide": "RIGHT", "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamTableFunctionScanRel.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQxOToxOToxNlrOGfUfMg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQwMDoxNDoxNFrOGg0hWQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTQ5NDcwNg==", "bodyText": "TVFStreamingUtils.WINDOWING_TVF is not correct here, you should be checking against the map keys tvfToPTransformMap.keySet() (or you could make this the default case on a switch statement).", "url": "https://github.com/apache/beam/pull/11868#discussion_r435494706", "createdAt": "2020-06-04T19:19:16Z", "author": {"login": "apilloud"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamTableFunctionScanRel.java", "diffHunk": "@@ -95,29 +186,19 @@ public TableFunctionScan copy(\n           input);\n       String operatorName = ((RexCall) getCall()).getOperator().getName();\n       checkArgument(\n-          operatorName.equals(\"TUMBLE\"),\n-          \"Only support TUMBLE table-valued function. Current operator: %s\",\n+          TVFStreamingUtils.WINDOWING_TVF.contains(operatorName),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "185ed224c658fa41f7b35a1c34bdcd75474fc863"}, "originalPosition": 132}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA2ODEyMQ==", "bodyText": "Good point!", "url": "https://github.com/apache/beam/pull/11868#discussion_r437068121", "createdAt": "2020-06-09T00:14:14Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamTableFunctionScanRel.java", "diffHunk": "@@ -95,29 +186,19 @@ public TableFunctionScan copy(\n           input);\n       String operatorName = ((RexCall) getCall()).getOperator().getName();\n       checkArgument(\n-          operatorName.equals(\"TUMBLE\"),\n-          \"Only support TUMBLE table-valued function. Current operator: %s\",\n+          TVFStreamingUtils.WINDOWING_TVF.contains(operatorName),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTQ5NDcwNg=="}, "originalCommit": {"oid": "185ed224c658fa41f7b35a1c34bdcd75474fc863"}, "originalPosition": 132}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcxMjY3OTY2OnYy", "diffSide": "RIGHT", "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/TVFToPTransform.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQxOToyMTowN1rOGfUiyQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQwMDowMDozOFrOGg0Tcg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTQ5NTYyNQ==", "bodyText": "This isn't a public interface, it is a private implementation detail of BeamTableFunctionScanRel. Please move it there.", "url": "https://github.com/apache/beam/pull/11868#discussion_r435495625", "createdAt": "2020-06-04T19:21:07Z", "author": {"login": "apilloud"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/TVFToPTransform.java", "diffHunk": "@@ -0,0 +1,27 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl;\n+\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexCall;\n+\n+/** Provides a function that produces a PCollection based on TVF and upstream PCollection. */\n+public interface TVFToPTransform {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "185ed224c658fa41f7b35a1c34bdcd75474fc863"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjE4NTI2OA==", "bodyText": "+1", "url": "https://github.com/apache/beam/pull/11868#discussion_r436185268", "createdAt": "2020-06-05T22:04:11Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/TVFToPTransform.java", "diffHunk": "@@ -0,0 +1,27 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl;\n+\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexCall;\n+\n+/** Provides a function that produces a PCollection based on TVF and upstream PCollection. */\n+public interface TVFToPTransform {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTQ5NTYyNQ=="}, "originalCommit": {"oid": "185ed224c658fa41f7b35a1c34bdcd75474fc863"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA2NDU2Mg==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/11868#discussion_r437064562", "createdAt": "2020-06-09T00:00:38Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/TVFToPTransform.java", "diffHunk": "@@ -0,0 +1,27 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl;\n+\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.vendor.calcite.v1_20_0.org.apache.calcite.rex.RexCall;\n+\n+/** Provides a function that produces a PCollection based on TVF and upstream PCollection. */\n+public interface TVFToPTransform {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTQ5NTYyNQ=="}, "originalCommit": {"oid": "185ed224c658fa41f7b35a1c34bdcd75474fc863"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcxMjY4OTExOnYy", "diffSide": "RIGHT", "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/TVFSlidingWindowFn.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQxOToyMzo1M1rOGfUogQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQwMDowMjowNFrOGg0U9w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTQ5NzA4OQ==", "bodyText": "nit: From here to the end of the file is boilerplate that AutoValue does for you. Could you use that instead?", "url": "https://github.com/apache/beam/pull/11868#discussion_r435497089", "createdAt": "2020-06-04T19:23:53Z", "author": {"login": "apilloud"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/TVFSlidingWindowFn.java", "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl;\n+\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Objects;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.extensions.sql.impl.utils.TVFStreamingUtils;\n+import org.apache.beam.sdk.transforms.windowing.IntervalWindow;\n+import org.apache.beam.sdk.transforms.windowing.NonMergingWindowFn;\n+import org.apache.beam.sdk.transforms.windowing.WindowFn;\n+import org.apache.beam.sdk.transforms.windowing.WindowFn.AssignContext;\n+import org.apache.beam.sdk.transforms.windowing.WindowMappingFn;\n+import org.apache.beam.sdk.values.Row;\n+import org.joda.time.Duration;\n+\n+/**\n+ * TVFSlidingWindowFn assigns window based on input row's \"window_start\" and \"window_end\"\n+ * timestamps.\n+ */\n+public class TVFSlidingWindowFn extends NonMergingWindowFn<Object, IntervalWindow> {\n+  /** Amount of time between generated windows. */\n+  private final Duration period;\n+\n+  /** Size of the generated windows. */\n+  private final Duration size;\n+\n+  public static TVFSlidingWindowFn of(Duration size, Duration period) {\n+    return new TVFSlidingWindowFn(size, period);\n+  }\n+\n+  private TVFSlidingWindowFn(Duration size, Duration period) {\n+    this.period = period;\n+    this.size = size;\n+  }\n+\n+  @Override\n+  public Collection<IntervalWindow> assignWindows(AssignContext c) throws Exception {\n+    Row curRow = (Row) c.element();\n+    // In sliding window as TVF syntax, each row contains's its window's start and end as metadata,\n+    // thus we can assign a window directly based on window's start and end metadata.\n+    return Arrays.asList(\n+        new IntervalWindow(\n+            curRow.getDateTime(TVFStreamingUtils.WINDOW_START).toInstant(),\n+            curRow.getDateTime(TVFStreamingUtils.WINDOW_END).toInstant()));\n+  }\n+\n+  @Override\n+  public boolean isCompatible(WindowFn<?, ?> other) {\n+    return equals(other);\n+  }\n+\n+  @Override\n+  public Coder<IntervalWindow> windowCoder() {\n+    return IntervalWindow.getCoder();\n+  }\n+\n+  @Override\n+  public WindowMappingFn<IntervalWindow> getDefaultWindowMappingFn() {\n+    throw new UnsupportedOperationException(\n+        \"TVFSlidingWindow does not support side input windows.\");\n+  }\n+\n+  @Override", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "185ed224c658fa41f7b35a1c34bdcd75474fc863"}, "originalPosition": 80}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA2NDk1MQ==", "bodyText": "Done. Thanks!", "url": "https://github.com/apache/beam/pull/11868#discussion_r437064951", "createdAt": "2020-06-09T00:02:04Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/TVFSlidingWindowFn.java", "diffHunk": "@@ -0,0 +1,101 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.extensions.sql.impl;\n+\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Objects;\n+import org.apache.beam.sdk.coders.Coder;\n+import org.apache.beam.sdk.extensions.sql.impl.utils.TVFStreamingUtils;\n+import org.apache.beam.sdk.transforms.windowing.IntervalWindow;\n+import org.apache.beam.sdk.transforms.windowing.NonMergingWindowFn;\n+import org.apache.beam.sdk.transforms.windowing.WindowFn;\n+import org.apache.beam.sdk.transforms.windowing.WindowFn.AssignContext;\n+import org.apache.beam.sdk.transforms.windowing.WindowMappingFn;\n+import org.apache.beam.sdk.values.Row;\n+import org.joda.time.Duration;\n+\n+/**\n+ * TVFSlidingWindowFn assigns window based on input row's \"window_start\" and \"window_end\"\n+ * timestamps.\n+ */\n+public class TVFSlidingWindowFn extends NonMergingWindowFn<Object, IntervalWindow> {\n+  /** Amount of time between generated windows. */\n+  private final Duration period;\n+\n+  /** Size of the generated windows. */\n+  private final Duration size;\n+\n+  public static TVFSlidingWindowFn of(Duration size, Duration period) {\n+    return new TVFSlidingWindowFn(size, period);\n+  }\n+\n+  private TVFSlidingWindowFn(Duration size, Duration period) {\n+    this.period = period;\n+    this.size = size;\n+  }\n+\n+  @Override\n+  public Collection<IntervalWindow> assignWindows(AssignContext c) throws Exception {\n+    Row curRow = (Row) c.element();\n+    // In sliding window as TVF syntax, each row contains's its window's start and end as metadata,\n+    // thus we can assign a window directly based on window's start and end metadata.\n+    return Arrays.asList(\n+        new IntervalWindow(\n+            curRow.getDateTime(TVFStreamingUtils.WINDOW_START).toInstant(),\n+            curRow.getDateTime(TVFStreamingUtils.WINDOW_END).toInstant()));\n+  }\n+\n+  @Override\n+  public boolean isCompatible(WindowFn<?, ?> other) {\n+    return equals(other);\n+  }\n+\n+  @Override\n+  public Coder<IntervalWindow> windowCoder() {\n+    return IntervalWindow.getCoder();\n+  }\n+\n+  @Override\n+  public WindowMappingFn<IntervalWindow> getDefaultWindowMappingFn() {\n+    throw new UnsupportedOperationException(\n+        \"TVFSlidingWindow does not support side input windows.\");\n+  }\n+\n+  @Override", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTQ5NzA4OQ=="}, "originalCommit": {"oid": "185ed224c658fa41f7b35a1c34bdcd75474fc863"}, "originalPosition": 80}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcxMjc3NjcyOnYy", "diffSide": "RIGHT", "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamTableFunctionScanRel.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQxOTo1MjoyNFrOGfVg4g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQwMDoxNzozNFrOGg0kvA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTUxMTUyMg==", "bodyText": "This block here looks to be really innovative to me! It looks like this is what makes session_end work? This also scares me, I don't see how it can work without creating hot key and scalability problems. Is there a doc explaining how this works?", "url": "https://github.com/apache/beam/pull/11868#discussion_r435511522", "createdAt": "2020-06-04T19:52:24Z", "author": {"login": "apilloud"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamTableFunctionScanRel.java", "diffHunk": "@@ -85,6 +97,85 @@ public TableFunctionScan copy(\n   }\n \n   private class Transform extends PTransform<PCollectionList<Row>, PCollection<Row>> {\n+    private TVFToPTransform tumbleToPTransform =\n+        (call, upstream) -> {\n+          RexInputRef wmCol = (RexInputRef) call.getOperands().get(1);\n+          Schema outputSchema = CalciteUtils.toSchema(getRowType());\n+          FixedWindows windowFn = FixedWindows.of(durationParameter(call.getOperands().get(2)));\n+          PCollection<Row> streamWithWindowMetadata =\n+              upstream\n+                  .apply(ParDo.of(new FixedWindowDoFn(windowFn, wmCol.getIndex(), outputSchema)))\n+                  .setRowSchema(outputSchema);\n+\n+          PCollection<Row> windowedStream =\n+              assignTimestampsAndWindow(\n+                  streamWithWindowMetadata, wmCol.getIndex(), (WindowFn) windowFn);\n+\n+          return windowedStream;\n+        };\n+\n+    private TVFToPTransform hopToPTransform =\n+        (call, upstream) -> {\n+          RexInputRef wmCol = (RexInputRef) call.getOperands().get(1);\n+          Schema outputSchema = CalciteUtils.toSchema(getRowType());\n+\n+          Duration size = durationParameter(call.getOperands().get(2));\n+          Duration period = durationParameter(call.getOperands().get(3));\n+          SlidingWindows windowFn = SlidingWindows.of(size).every(period);\n+          PCollection<Row> streamWithWindowMetadata =\n+              upstream\n+                  .apply(ParDo.of(new SlidingWindowDoFn(windowFn, wmCol.getIndex(), outputSchema)))\n+                  .setRowSchema(outputSchema);\n+\n+          // Sliding window needs this special WindowFn to assign windows based on window_start,\n+          // window_end metadata.\n+          WindowFn specialWindowFn = TVFSlidingWindowFn.of(size, period);\n+\n+          PCollection<Row> windowedStream =\n+              assignTimestampsAndWindow(\n+                  streamWithWindowMetadata, wmCol.getIndex(), specialWindowFn);\n+\n+          return windowedStream;\n+        };\n+\n+    private TVFToPTransform sessionToPTransform =\n+        (call, upstream) -> {\n+          RexInputRef wmCol = (RexInputRef) call.getOperands().get(1);\n+          Duration gap = durationParameter(call.getOperands().get(2));\n+\n+          Sessions sessions = Sessions.withGapDuration(gap);\n+\n+          PCollection<Row> windowedStream =\n+              assignTimestampsAndWindow(upstream, wmCol.getIndex(), sessions);\n+\n+          Schema outputSchema = CalciteUtils.toSchema(getRowType());\n+          // To extract session's window metadata, we apply a GroupByKey with a dummy key. It is\n+          // because\n+          // session is merging window. After GBK, SessionWindowDoFn will help extract window_start,\n+          // window_end metadata.\n+          PCollection<Row> streamWithWindowMetadata =\n+              windowedStream\n+                  .apply(WithKeys.of(\"dummy\"))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "185ed224c658fa41f7b35a1c34bdcd75474fc863"}, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA2NTQxMQ==", "bodyText": "I don't know if there is any documentation. This is indeed the way to get SESSION_END (I found from our codebase).\nFor the scalability concern, note that GBK work on per-key and per-window basis, so at least this GBK have a GROUP BY window to reduce hot keys.\nOf course it still might be hot keys if there is a super large SESSION window, I have logged https://jira.apache.org/jira/browse/BEAM-10216 for improvement idea.", "url": "https://github.com/apache/beam/pull/11868#discussion_r437065411", "createdAt": "2020-06-09T00:04:04Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamTableFunctionScanRel.java", "diffHunk": "@@ -85,6 +97,85 @@ public TableFunctionScan copy(\n   }\n \n   private class Transform extends PTransform<PCollectionList<Row>, PCollection<Row>> {\n+    private TVFToPTransform tumbleToPTransform =\n+        (call, upstream) -> {\n+          RexInputRef wmCol = (RexInputRef) call.getOperands().get(1);\n+          Schema outputSchema = CalciteUtils.toSchema(getRowType());\n+          FixedWindows windowFn = FixedWindows.of(durationParameter(call.getOperands().get(2)));\n+          PCollection<Row> streamWithWindowMetadata =\n+              upstream\n+                  .apply(ParDo.of(new FixedWindowDoFn(windowFn, wmCol.getIndex(), outputSchema)))\n+                  .setRowSchema(outputSchema);\n+\n+          PCollection<Row> windowedStream =\n+              assignTimestampsAndWindow(\n+                  streamWithWindowMetadata, wmCol.getIndex(), (WindowFn) windowFn);\n+\n+          return windowedStream;\n+        };\n+\n+    private TVFToPTransform hopToPTransform =\n+        (call, upstream) -> {\n+          RexInputRef wmCol = (RexInputRef) call.getOperands().get(1);\n+          Schema outputSchema = CalciteUtils.toSchema(getRowType());\n+\n+          Duration size = durationParameter(call.getOperands().get(2));\n+          Duration period = durationParameter(call.getOperands().get(3));\n+          SlidingWindows windowFn = SlidingWindows.of(size).every(period);\n+          PCollection<Row> streamWithWindowMetadata =\n+              upstream\n+                  .apply(ParDo.of(new SlidingWindowDoFn(windowFn, wmCol.getIndex(), outputSchema)))\n+                  .setRowSchema(outputSchema);\n+\n+          // Sliding window needs this special WindowFn to assign windows based on window_start,\n+          // window_end metadata.\n+          WindowFn specialWindowFn = TVFSlidingWindowFn.of(size, period);\n+\n+          PCollection<Row> windowedStream =\n+              assignTimestampsAndWindow(\n+                  streamWithWindowMetadata, wmCol.getIndex(), specialWindowFn);\n+\n+          return windowedStream;\n+        };\n+\n+    private TVFToPTransform sessionToPTransform =\n+        (call, upstream) -> {\n+          RexInputRef wmCol = (RexInputRef) call.getOperands().get(1);\n+          Duration gap = durationParameter(call.getOperands().get(2));\n+\n+          Sessions sessions = Sessions.withGapDuration(gap);\n+\n+          PCollection<Row> windowedStream =\n+              assignTimestampsAndWindow(upstream, wmCol.getIndex(), sessions);\n+\n+          Schema outputSchema = CalciteUtils.toSchema(getRowType());\n+          // To extract session's window metadata, we apply a GroupByKey with a dummy key. It is\n+          // because\n+          // session is merging window. After GBK, SessionWindowDoFn will help extract window_start,\n+          // window_end metadata.\n+          PCollection<Row> streamWithWindowMetadata =\n+              windowedStream\n+                  .apply(WithKeys.of(\"dummy\"))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTUxMTUyMg=="}, "originalCommit": {"oid": "185ed224c658fa41f7b35a1c34bdcd75474fc863"}, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA2ODk4OA==", "bodyText": "This product is for processing big data so 'super large' is the target workflow. Can you point me at the existing code that does this?", "url": "https://github.com/apache/beam/pull/11868#discussion_r437068988", "createdAt": "2020-06-09T00:17:34Z", "author": {"login": "apilloud"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamTableFunctionScanRel.java", "diffHunk": "@@ -85,6 +97,85 @@ public TableFunctionScan copy(\n   }\n \n   private class Transform extends PTransform<PCollectionList<Row>, PCollection<Row>> {\n+    private TVFToPTransform tumbleToPTransform =\n+        (call, upstream) -> {\n+          RexInputRef wmCol = (RexInputRef) call.getOperands().get(1);\n+          Schema outputSchema = CalciteUtils.toSchema(getRowType());\n+          FixedWindows windowFn = FixedWindows.of(durationParameter(call.getOperands().get(2)));\n+          PCollection<Row> streamWithWindowMetadata =\n+              upstream\n+                  .apply(ParDo.of(new FixedWindowDoFn(windowFn, wmCol.getIndex(), outputSchema)))\n+                  .setRowSchema(outputSchema);\n+\n+          PCollection<Row> windowedStream =\n+              assignTimestampsAndWindow(\n+                  streamWithWindowMetadata, wmCol.getIndex(), (WindowFn) windowFn);\n+\n+          return windowedStream;\n+        };\n+\n+    private TVFToPTransform hopToPTransform =\n+        (call, upstream) -> {\n+          RexInputRef wmCol = (RexInputRef) call.getOperands().get(1);\n+          Schema outputSchema = CalciteUtils.toSchema(getRowType());\n+\n+          Duration size = durationParameter(call.getOperands().get(2));\n+          Duration period = durationParameter(call.getOperands().get(3));\n+          SlidingWindows windowFn = SlidingWindows.of(size).every(period);\n+          PCollection<Row> streamWithWindowMetadata =\n+              upstream\n+                  .apply(ParDo.of(new SlidingWindowDoFn(windowFn, wmCol.getIndex(), outputSchema)))\n+                  .setRowSchema(outputSchema);\n+\n+          // Sliding window needs this special WindowFn to assign windows based on window_start,\n+          // window_end metadata.\n+          WindowFn specialWindowFn = TVFSlidingWindowFn.of(size, period);\n+\n+          PCollection<Row> windowedStream =\n+              assignTimestampsAndWindow(\n+                  streamWithWindowMetadata, wmCol.getIndex(), specialWindowFn);\n+\n+          return windowedStream;\n+        };\n+\n+    private TVFToPTransform sessionToPTransform =\n+        (call, upstream) -> {\n+          RexInputRef wmCol = (RexInputRef) call.getOperands().get(1);\n+          Duration gap = durationParameter(call.getOperands().get(2));\n+\n+          Sessions sessions = Sessions.withGapDuration(gap);\n+\n+          PCollection<Row> windowedStream =\n+              assignTimestampsAndWindow(upstream, wmCol.getIndex(), sessions);\n+\n+          Schema outputSchema = CalciteUtils.toSchema(getRowType());\n+          // To extract session's window metadata, we apply a GroupByKey with a dummy key. It is\n+          // because\n+          // session is merging window. After GBK, SessionWindowDoFn will help extract window_start,\n+          // window_end metadata.\n+          PCollection<Row> streamWithWindowMetadata =\n+              windowedStream\n+                  .apply(WithKeys.of(\"dummy\"))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTUxMTUyMg=="}, "originalCommit": {"oid": "185ed224c658fa41f7b35a1c34bdcd75474fc863"}, "originalPosition": 102}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcxMjc4MDg1OnYy", "diffSide": "RIGHT", "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamTableFunctionScanRel.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQxOTo1MzozN1rOGfVjeg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQwMDowNDoyNVrOGg0XCQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTUxMjE4Ng==", "bodyText": "Why did Row become Object here? How can we keep this as Row?", "url": "https://github.com/apache/beam/pull/11868#discussion_r435512186", "createdAt": "2020-06-04T19:53:37Z", "author": {"login": "apilloud"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamTableFunctionScanRel.java", "diffHunk": "@@ -95,29 +186,19 @@ public TableFunctionScan copy(\n           input);\n       String operatorName = ((RexCall) getCall()).getOperator().getName();\n       checkArgument(\n-          operatorName.equals(\"TUMBLE\"),\n-          \"Only support TUMBLE table-valued function. Current operator: %s\",\n+          TVFStreamingUtils.WINDOWING_TVF.contains(operatorName),\n+          \"Only support %s table-valued functions. Current operator: %s\",\n+          TVFStreamingUtils.WINDOWING_TVF,\n           operatorName);\n-      RexCall call = ((RexCall) getCall());\n-      RexInputRef wmCol = (RexInputRef) call.getOperands().get(1);\n-      PCollection<Row> upstream = input.get(0);\n-      Schema outputSchema = CalciteUtils.toSchema(getRowType());\n-      FixedWindows windowFn = FixedWindows.of(durationParameter(call.getOperands().get(2)));\n-      PCollection<Row> streamWithWindowMetadata =\n-          upstream\n-              .apply(ParDo.of(new FixedWindowDoFn(windowFn, wmCol.getIndex(), outputSchema)))\n-              .setRowSchema(outputSchema);\n-\n-      PCollection<Row> windowedStream =\n-          assignTimestampsAndWindow(\n-              streamWithWindowMetadata, wmCol.getIndex(), (WindowFn) windowFn);\n \n-      return windowedStream;\n+      return tvfToPTransformMap.get(operatorName).toPTransform(((RexCall) getCall()), input.get(0));\n     }\n \n     /** Extract timestamps from the windowFieldIndex, then window into windowFns. */\n     private PCollection<Row> assignTimestampsAndWindow(\n-        PCollection<Row> upstream, int windowFieldIndex, WindowFn<Row, IntervalWindow> windowFn) {\n+        PCollection<Row> upstream,\n+        int windowFieldIndex,\n+        WindowFn<Object, IntervalWindow> windowFn) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "185ed224c658fa41f7b35a1c34bdcd75474fc863"}, "originalPosition": 159}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA2NTQ4MQ==", "bodyText": "Cast session to WindowFn and now it is Row", "url": "https://github.com/apache/beam/pull/11868#discussion_r437065481", "createdAt": "2020-06-09T00:04:25Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamTableFunctionScanRel.java", "diffHunk": "@@ -95,29 +186,19 @@ public TableFunctionScan copy(\n           input);\n       String operatorName = ((RexCall) getCall()).getOperator().getName();\n       checkArgument(\n-          operatorName.equals(\"TUMBLE\"),\n-          \"Only support TUMBLE table-valued function. Current operator: %s\",\n+          TVFStreamingUtils.WINDOWING_TVF.contains(operatorName),\n+          \"Only support %s table-valued functions. Current operator: %s\",\n+          TVFStreamingUtils.WINDOWING_TVF,\n           operatorName);\n-      RexCall call = ((RexCall) getCall());\n-      RexInputRef wmCol = (RexInputRef) call.getOperands().get(1);\n-      PCollection<Row> upstream = input.get(0);\n-      Schema outputSchema = CalciteUtils.toSchema(getRowType());\n-      FixedWindows windowFn = FixedWindows.of(durationParameter(call.getOperands().get(2)));\n-      PCollection<Row> streamWithWindowMetadata =\n-          upstream\n-              .apply(ParDo.of(new FixedWindowDoFn(windowFn, wmCol.getIndex(), outputSchema)))\n-              .setRowSchema(outputSchema);\n-\n-      PCollection<Row> windowedStream =\n-          assignTimestampsAndWindow(\n-              streamWithWindowMetadata, wmCol.getIndex(), (WindowFn) windowFn);\n \n-      return windowedStream;\n+      return tvfToPTransformMap.get(operatorName).toPTransform(((RexCall) getCall()), input.get(0));\n     }\n \n     /** Extract timestamps from the windowFieldIndex, then window into windowFns. */\n     private PCollection<Row> assignTimestampsAndWindow(\n-        PCollection<Row> upstream, int windowFieldIndex, WindowFn<Row, IntervalWindow> windowFn) {\n+        PCollection<Row> upstream,\n+        int windowFieldIndex,\n+        WindowFn<Object, IntervalWindow> windowFn) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTUxMjE4Ng=="}, "originalCommit": {"oid": "185ed224c658fa41f7b35a1c34bdcd75474fc863"}, "originalPosition": 159}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcxMjgxMjgyOnYy", "diffSide": "RIGHT", "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamTableFunctionScanRel.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQyMDowMzo1MlrOGfV33Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQwMDowNzoyNVrOGg0aBQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTUxNzQwNQ==", "bodyText": "This is going to iterate over every element in the window, that won't work. You might be able to make something that works reasonably well with CombineFn. (I don't think this is something we will figure out in PR comments.)", "url": "https://github.com/apache/beam/pull/11868#discussion_r435517405", "createdAt": "2020-06-04T20:03:52Z", "author": {"login": "apilloud"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamTableFunctionScanRel.java", "diffHunk": "@@ -166,6 +247,54 @@ public void processElement(ProcessContext c) {\n     }\n   }\n \n+  private static class SlidingWindowDoFn extends DoFn<Row, Row> {\n+    private final int windowFieldIndex;\n+    private final SlidingWindows windowFn;\n+    private final Schema outputSchema;\n+\n+    public SlidingWindowDoFn(SlidingWindows windowFn, int windowFieldIndex, Schema schema) {\n+      this.windowFn = windowFn;\n+      this.windowFieldIndex = windowFieldIndex;\n+      this.outputSchema = schema;\n+    }\n+\n+    @ProcessElement\n+    public void processElement(ProcessContext c) {\n+      Row row = c.element();\n+      Collection<IntervalWindow> windows =\n+          windowFn.assignWindows(row.getDateTime(windowFieldIndex).toInstant());\n+      for (IntervalWindow window : windows) {\n+        Row.Builder builder = Row.withSchema(outputSchema);\n+        builder.addValues(row.getValues());\n+        builder.addValue(window.start());\n+        builder.addValue(window.end());\n+        c.output(builder.build());\n+      }\n+    }\n+  }\n+\n+  private static class SessionWindowDoFn extends DoFn<KV<String, Iterable<Row>>, Row> {\n+    private final Schema outputSchema;\n+\n+    public SessionWindowDoFn(Schema schema) {\n+      this.outputSchema = schema;\n+    }\n+\n+    @ProcessElement\n+    public void processElement(\n+        @Element KV<String, Iterable<Row>> element, BoundedWindow window, OutputReceiver<Row> out) {\n+      IntervalWindow intervalWindow = (IntervalWindow) window;\n+      for (Row cur : element.getValue()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "185ed224c658fa41f7b35a1c34bdcd75474fc863"}, "originalPosition": 204}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA2NjI0NQ==", "bodyText": "See scalability comment above. Because GBK works on per-key and per-window basis, and I used \"dummy\" key above, thus this ParDo will go through every element in a session window. If that window is large, this could cause a problem. (Hot key is always a concern for any GBK).\nLogged https://jira.apache.org/jira/browse/BEAM-10216 for future improvement.", "url": "https://github.com/apache/beam/pull/11868#discussion_r437066245", "createdAt": "2020-06-09T00:07:25Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamTableFunctionScanRel.java", "diffHunk": "@@ -166,6 +247,54 @@ public void processElement(ProcessContext c) {\n     }\n   }\n \n+  private static class SlidingWindowDoFn extends DoFn<Row, Row> {\n+    private final int windowFieldIndex;\n+    private final SlidingWindows windowFn;\n+    private final Schema outputSchema;\n+\n+    public SlidingWindowDoFn(SlidingWindows windowFn, int windowFieldIndex, Schema schema) {\n+      this.windowFn = windowFn;\n+      this.windowFieldIndex = windowFieldIndex;\n+      this.outputSchema = schema;\n+    }\n+\n+    @ProcessElement\n+    public void processElement(ProcessContext c) {\n+      Row row = c.element();\n+      Collection<IntervalWindow> windows =\n+          windowFn.assignWindows(row.getDateTime(windowFieldIndex).toInstant());\n+      for (IntervalWindow window : windows) {\n+        Row.Builder builder = Row.withSchema(outputSchema);\n+        builder.addValues(row.getValues());\n+        builder.addValue(window.start());\n+        builder.addValue(window.end());\n+        c.output(builder.build());\n+      }\n+    }\n+  }\n+\n+  private static class SessionWindowDoFn extends DoFn<KV<String, Iterable<Row>>, Row> {\n+    private final Schema outputSchema;\n+\n+    public SessionWindowDoFn(Schema schema) {\n+      this.outputSchema = schema;\n+    }\n+\n+    @ProcessElement\n+    public void processElement(\n+        @Element KV<String, Iterable<Row>> element, BoundedWindow window, OutputReceiver<Row> out) {\n+      IntervalWindow intervalWindow = (IntervalWindow) window;\n+      for (Row cur : element.getValue()) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTUxNzQwNQ=="}, "originalCommit": {"oid": "185ed224c658fa41f7b35a1c34bdcd75474fc863"}, "originalPosition": 204}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcxMjg3MjcxOnYy", "diffSide": "RIGHT", "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/SqlAnalyzer.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQyMDoyMzowNlrOGfWd5w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQwMDoyMTo1NlrOGg0pFA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTUyNzE0Mw==", "bodyText": "The constant 123 here (and repeated below) is suppose to be a globally unique ID out of com.google.zetasql.ZetaSQLFunction.FunctionSignatureId. This one is FN_BITWISE_NOT_UINT64. I'm pretty sure that doesn't match this function signature. If we don't care about these, could you use com.google.zetasql.ZetaSQLFunction.FunctionSignatureId.FN_INVALID_FUNCTION_ID.", "url": "https://github.com/apache/beam/pull/11868#discussion_r435527143", "createdAt": "2020-06-04T20:23:06Z", "author": {"login": "apilloud"}, "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/SqlAnalyzer.java", "diffHunk": "@@ -206,7 +206,37 @@ private void addBuiltinFunctionsToCatalog(SimpleCatalog catalog, AnalyzerOptions\n     // TUMBLE\n     catalog.addTableValuedFunction(\n         new TableValuedFunction.ForwardInputSchemaToOutputSchemaWithAppendedColumnTVF(\n-            ImmutableList.of(\"TUMBLE\"),\n+            ImmutableList.of(TVFStreamingUtils.FIXED_WINDOW_TVF),\n+            new FunctionSignature(\n+                retType, ImmutableList.of(inputTableType, descriptorType, stringType), 123),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "185ed224c658fa41f7b35a1c34bdcd75474fc863"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA2NTYxMg==", "bodyText": "Good point. I changed it back to -1. I have seen -1usage in internal codebase.", "url": "https://github.com/apache/beam/pull/11868#discussion_r437065612", "createdAt": "2020-06-09T00:04:57Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/SqlAnalyzer.java", "diffHunk": "@@ -206,7 +206,37 @@ private void addBuiltinFunctionsToCatalog(SimpleCatalog catalog, AnalyzerOptions\n     // TUMBLE\n     catalog.addTableValuedFunction(\n         new TableValuedFunction.ForwardInputSchemaToOutputSchemaWithAppendedColumnTVF(\n-            ImmutableList.of(\"TUMBLE\"),\n+            ImmutableList.of(TVFStreamingUtils.FIXED_WINDOW_TVF),\n+            new FunctionSignature(\n+                retType, ImmutableList.of(inputTableType, descriptorType, stringType), 123),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTUyNzE0Mw=="}, "originalCommit": {"oid": "185ed224c658fa41f7b35a1c34bdcd75474fc863"}, "originalPosition": 7}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA3MDEwMA==", "bodyText": "-1 is __FunctionSignatureId__switch_must_have_a_default__, but I don't see any harm in using that.", "url": "https://github.com/apache/beam/pull/11868#discussion_r437070100", "createdAt": "2020-06-09T00:21:56Z", "author": {"login": "apilloud"}, "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/SqlAnalyzer.java", "diffHunk": "@@ -206,7 +206,37 @@ private void addBuiltinFunctionsToCatalog(SimpleCatalog catalog, AnalyzerOptions\n     // TUMBLE\n     catalog.addTableValuedFunction(\n         new TableValuedFunction.ForwardInputSchemaToOutputSchemaWithAppendedColumnTVF(\n-            ImmutableList.of(\"TUMBLE\"),\n+            ImmutableList.of(TVFStreamingUtils.FIXED_WINDOW_TVF),\n+            new FunctionSignature(\n+                retType, ImmutableList.of(inputTableType, descriptorType, stringType), 123),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTUyNzE0Mw=="}, "originalCommit": {"oid": "185ed224c658fa41f7b35a1c34bdcd75474fc863"}, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcxMjg5Mjc2OnYy", "diffSide": "RIGHT", "path": "sdks/java/extensions/sql/zetasql/src/test/java/org/apache/beam/sdk/extensions/sql/zetasql/ZetaSQLDialectSpecTest.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQyMDoyOTo0MVrOGfWq0w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQwMDowODoxMFrOGg0axw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTUzMDQ1MQ==", "bodyText": "nit: Are these really ZetaSQLDialectSpecTests? There are no matching compliance tests. Its probably worth moving these tests into their own file.", "url": "https://github.com/apache/beam/pull/11868#discussion_r435530451", "createdAt": "2020-06-04T20:29:41Z", "author": {"login": "apilloud"}, "path": "sdks/java/extensions/sql/zetasql/src/test/java/org/apache/beam/sdk/extensions/sql/zetasql/ZetaSQLDialectSpecTest.java", "diffHunk": "@@ -4805,6 +4805,93 @@ public void testTVFTumbleAggregation() {\n     pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n   }\n \n+  @Test", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "185ed224c658fa41f7b35a1c34bdcd75474fc863"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjE3ODkyMw==", "bodyText": "+1. IIRC there are some other tests in this file that are testing our streaming extension. It makes sense to separate them to other file.", "url": "https://github.com/apache/beam/pull/11868#discussion_r436178923", "createdAt": "2020-06-05T21:48:09Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/zetasql/src/test/java/org/apache/beam/sdk/extensions/sql/zetasql/ZetaSQLDialectSpecTest.java", "diffHunk": "@@ -4805,6 +4805,93 @@ public void testTVFTumbleAggregation() {\n     pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n   }\n \n+  @Test", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTUzMDQ1MQ=="}, "originalCommit": {"oid": "185ed224c658fa41f7b35a1c34bdcd75474fc863"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNjE4ODE2Ng==", "bodyText": "Good point. It can be a good point to move all streaming tests to another place.", "url": "https://github.com/apache/beam/pull/11868#discussion_r436188166", "createdAt": "2020-06-05T22:14:33Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/zetasql/src/test/java/org/apache/beam/sdk/extensions/sql/zetasql/ZetaSQLDialectSpecTest.java", "diffHunk": "@@ -4805,6 +4805,93 @@ public void testTVFTumbleAggregation() {\n     pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n   }\n \n+  @Test", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTUzMDQ1MQ=="}, "originalCommit": {"oid": "185ed224c658fa41f7b35a1c34bdcd75474fc863"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA2NjQzOQ==", "bodyText": "Have moved all streaming tests to another file.", "url": "https://github.com/apache/beam/pull/11868#discussion_r437066439", "createdAt": "2020-06-09T00:08:10Z", "author": {"login": "amaliujia"}, "path": "sdks/java/extensions/sql/zetasql/src/test/java/org/apache/beam/sdk/extensions/sql/zetasql/ZetaSQLDialectSpecTest.java", "diffHunk": "@@ -4805,6 +4805,93 @@ public void testTVFTumbleAggregation() {\n     pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n   }\n \n+  @Test", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTUzMDQ1MQ=="}, "originalCommit": {"oid": "185ed224c658fa41f7b35a1c34bdcd75474fc863"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcxMjkwMzY2OnYy", "diffSide": "RIGHT", "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/translation/ExpressionConverter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQyMDozMzoxNFrOGfWxvQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQyMDozMzoxNFrOGfWxvQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTUzMjIyMQ==", "bodyText": "nit: Use checkArgument?", "url": "https://github.com/apache/beam/pull/11868#discussion_r435532221", "createdAt": "2020-06-04T20:33:14Z", "author": {"login": "apilloud"}, "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/translation/ExpressionConverter.java", "diffHunk": "@@ -607,7 +630,13 @@ private RexInputRef convertWatermarkedResolvedColumnToRexInputRef(\n \n   private ResolvedColumn extractWatermarkColumnFromDescriptor(\n       ResolvedNodes.ResolvedDescriptor descriptor) {\n-    return descriptor.getDescriptorColumnList().get(0);\n+    ResolvedColumn wmCol = descriptor.getDescriptorColumnList().get(0);\n+    if (wmCol.getType().getKind() != TYPE_TIMESTAMP) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "185ed224c658fa41f7b35a1c34bdcd75474fc863"}, "originalPosition": 70}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcxMjkwMzc2OnYy", "diffSide": "RIGHT", "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/translation/ExpressionConverter.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQyMDozMzoxNlrOGfWx0Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wNFQyMDozMzoxNlrOGfWx0Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNTUzMjI0MQ==", "bodyText": "nit: inline this function?", "url": "https://github.com/apache/beam/pull/11868#discussion_r435532241", "createdAt": "2020-06-04T20:33:16Z", "author": {"login": "apilloud"}, "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/translation/ExpressionConverter.java", "diffHunk": "@@ -607,7 +630,13 @@ private RexInputRef convertWatermarkedResolvedColumnToRexInputRef(\n \n   private ResolvedColumn extractWatermarkColumnFromDescriptor(\n       ResolvedNodes.ResolvedDescriptor descriptor) {\n-    return descriptor.getDescriptorColumnList().get(0);\n+    ResolvedColumn wmCol = descriptor.getDescriptorColumnList().get(0);\n+    if (wmCol.getType().getKind() != TYPE_TIMESTAMP) {\n+      throw new IllegalArgumentException(\n+          \"Watermarked column should be TIMESTAMP type: \"\n+              + extractWatermarkColumnNameFromDescriptor(descriptor));\n+    }\n+    return wmCol;\n   }\n \n   private String extractWatermarkColumnNameFromDescriptor(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "185ed224c658fa41f7b35a1c34bdcd75474fc863"}, "originalPosition": 78}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjcyMjgzNTMwOnYy", "diffSide": "RIGHT", "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/utils/TVFStreamingUtils.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQwMDoyNzowMFrOGg0uOA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wOVQwMDoyNzowMFrOGg0uOA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNzA3MTQxNg==", "bodyText": "This appears to be unused now?", "url": "https://github.com/apache/beam/pull/11868#discussion_r437071416", "createdAt": "2020-06-09T00:27:00Z", "author": {"login": "apilloud"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/utils/TVFStreamingUtils.java", "diffHunk": "@@ -17,8 +17,17 @@\n  */\n package org.apache.beam.sdk.extensions.sql.impl.utils;\n \n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableSet;\n+\n /** Provides static constants or utils for TVF streaming. */\n public class TVFStreamingUtils {\n   public static final String WINDOW_START = \"window_start\";\n   public static final String WINDOW_END = \"window_end\";\n+\n+  public static final String FIXED_WINDOW_TVF = \"TUMBLE\";\n+  public static final String SLIDING_WINDOW_TVF = \"HOP\";\n+  public static final String SESSION_WINDOW_TVF = \"SESSION\";\n+\n+  public static final ImmutableSet<String> WINDOWING_TVF =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "377f924d8bfbd7e6f7bb04e75e9011bd9ab3993e"}, "originalPosition": 15}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3740, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}