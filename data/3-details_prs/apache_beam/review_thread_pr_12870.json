{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDg5NDUzNjQw", "number": 12870, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQyMzoxNjozMlrOEqgzeQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQyMzoxNjozMlrOEqgzeQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzEzMDEzMTEzOnYy", "diffSide": "RIGHT", "path": "runners/google-cloud-dataflow-java/build.gradle", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wNVQyMzoxNjozMlrOHcw0eA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0wN1QxNjowNDoxM1rOHd6sIQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTkyMjA0MA==", "bodyText": "Why change the name to drop LegacyWorker? If the plan is to reuse this for other runner versions should the worker:legacy-worker:shadowJar dependency be injected somehow as well?", "url": "https://github.com/apache/beam/pull/12870#discussion_r499922040", "createdAt": "2020-10-05T23:16:32Z", "author": {"login": "tysonjh"}, "path": "runners/google-cloud-dataflow-java/build.gradle", "diffHunk": "@@ -151,33 +161,34 @@ def commonExcludeCategories = [\n \n // For the following test tasks using legacy worker, set workerHarnessContainerImage to empty to\n // make Dataflow pick up the non-versioned container image, which handles a staged worker jar.\n-task validatesRunnerLegacyWorkerTest(type: Test) {\n-  group = \"Verification\"\n-  dependsOn \":runners:google-cloud-dataflow-java:worker:legacy-worker:shadowJar\"\n-\n-  systemProperty \"beamTestPipelineOptions\", JsonOutput.toJson([\n-          \"--runner=TestDataflowRunner\",\n-          \"--project=${dataflowProject}\",\n-          \"--region=${dataflowRegion}\",\n-          \"--tempRoot=${dataflowValidatesTempRoot}\",\n-          \"--dataflowWorkerJar=${dataflowLegacyWorkerJar}\",\n-          \"--workerHarnessContainerImage=\",\n-  ])\n-\n-  // Increase test parallelism up to the number of Gradle workers. By default this is equal\n-  // to the number of CPU cores, but can be increased by setting --max-workers=N.\n-  maxParallelForks Integer.MAX_VALUE\n-  classpath = configurations.validatesRunner\n-  testClassesDirs = files(project(\":sdks:java:core\").sourceSets.test.output.classesDirs) +\n-          files(project(project.path).sourceSets.test.output.classesDirs)\n-  useJUnit {\n-    includeCategories 'org.apache.beam.sdk.testing.ValidatesRunner'\n-    commonExcludeCategories.each {\n-      excludeCategories it\n+def createValidatesRunnerTest = { name, pipelineOptions=legacyPipelineOptions, disabledTests=[] ->", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a074f62a07d036fdca96a404c79fd8ef84889bf1"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDQ0MTkyMQ==", "bodyText": "The actual task name is the same, and defined on line 238. Here I have just made a function for producing variants. The new variant is defined on line 244.", "url": "https://github.com/apache/beam/pull/12870#discussion_r500441921", "createdAt": "2020-10-06T16:38:55Z", "author": {"login": "kennknowles"}, "path": "runners/google-cloud-dataflow-java/build.gradle", "diffHunk": "@@ -151,33 +161,34 @@ def commonExcludeCategories = [\n \n // For the following test tasks using legacy worker, set workerHarnessContainerImage to empty to\n // make Dataflow pick up the non-versioned container image, which handles a staged worker jar.\n-task validatesRunnerLegacyWorkerTest(type: Test) {\n-  group = \"Verification\"\n-  dependsOn \":runners:google-cloud-dataflow-java:worker:legacy-worker:shadowJar\"\n-\n-  systemProperty \"beamTestPipelineOptions\", JsonOutput.toJson([\n-          \"--runner=TestDataflowRunner\",\n-          \"--project=${dataflowProject}\",\n-          \"--region=${dataflowRegion}\",\n-          \"--tempRoot=${dataflowValidatesTempRoot}\",\n-          \"--dataflowWorkerJar=${dataflowLegacyWorkerJar}\",\n-          \"--workerHarnessContainerImage=\",\n-  ])\n-\n-  // Increase test parallelism up to the number of Gradle workers. By default this is equal\n-  // to the number of CPU cores, but can be increased by setting --max-workers=N.\n-  maxParallelForks Integer.MAX_VALUE\n-  classpath = configurations.validatesRunner\n-  testClassesDirs = files(project(\":sdks:java:core\").sourceSets.test.output.classesDirs) +\n-          files(project(project.path).sourceSets.test.output.classesDirs)\n-  useJUnit {\n-    includeCategories 'org.apache.beam.sdk.testing.ValidatesRunner'\n-    commonExcludeCategories.each {\n-      excludeCategories it\n+def createValidatesRunnerTest = { name, pipelineOptions=legacyPipelineOptions, disabledTests=[] ->", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTkyMjA0MA=="}, "originalCommit": {"oid": "a074f62a07d036fdca96a404c79fd8ef84889bf1"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMDUxMTc5NA==", "bodyText": "I meant the name of this method specifically, not the tasks. This method has a dependsOn dependency with the legacy worker, so it will always be for the legacy worker and the naming change seems to make this less clear. Unless of course, in the future, this method could be used for new runners (e.g. runner v2)?\nI was considering if it would possible to pull out the dependsOn ...legacy-worker:shadowJar (by passing it in as a parameter, specifying the dependency in some other scope, or some other injection mechanism) and then reusing the createValidatesRunnerTest method for the runner v2 by passing in pipelineOptions + [\"--experiments=use_runner_v2\"].", "url": "https://github.com/apache/beam/pull/12870#discussion_r500511794", "createdAt": "2020-10-06T18:31:09Z", "author": {"login": "tysonjh"}, "path": "runners/google-cloud-dataflow-java/build.gradle", "diffHunk": "@@ -151,33 +161,34 @@ def commonExcludeCategories = [\n \n // For the following test tasks using legacy worker, set workerHarnessContainerImage to empty to\n // make Dataflow pick up the non-versioned container image, which handles a staged worker jar.\n-task validatesRunnerLegacyWorkerTest(type: Test) {\n-  group = \"Verification\"\n-  dependsOn \":runners:google-cloud-dataflow-java:worker:legacy-worker:shadowJar\"\n-\n-  systemProperty \"beamTestPipelineOptions\", JsonOutput.toJson([\n-          \"--runner=TestDataflowRunner\",\n-          \"--project=${dataflowProject}\",\n-          \"--region=${dataflowRegion}\",\n-          \"--tempRoot=${dataflowValidatesTempRoot}\",\n-          \"--dataflowWorkerJar=${dataflowLegacyWorkerJar}\",\n-          \"--workerHarnessContainerImage=\",\n-  ])\n-\n-  // Increase test parallelism up to the number of Gradle workers. By default this is equal\n-  // to the number of CPU cores, but can be increased by setting --max-workers=N.\n-  maxParallelForks Integer.MAX_VALUE\n-  classpath = configurations.validatesRunner\n-  testClassesDirs = files(project(\":sdks:java:core\").sourceSets.test.output.classesDirs) +\n-          files(project(project.path).sourceSets.test.output.classesDirs)\n-  useJUnit {\n-    includeCategories 'org.apache.beam.sdk.testing.ValidatesRunner'\n-    commonExcludeCategories.each {\n-      excludeCategories it\n+def createValidatesRunnerTest = { name, pipelineOptions=legacyPipelineOptions, disabledTests=[] ->", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTkyMjA0MA=="}, "originalCommit": {"oid": "a074f62a07d036fdca96a404c79fd8ef84889bf1"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMTEzMjMyMQ==", "bodyText": "Agree with your naming point, and pushed a rename.\nI believe that is possible to continue to configure with a block but Groovy's scope configuration blocks confuse the heck out of me so I did not try to do it. I expect you can do it either by passing the closure in to the createValidatesRunner function or by returning something that is ready to accept a block. I'm a bit hazy on how/when the latter works.", "url": "https://github.com/apache/beam/pull/12870#discussion_r501132321", "createdAt": "2020-10-07T16:04:13Z", "author": {"login": "kennknowles"}, "path": "runners/google-cloud-dataflow-java/build.gradle", "diffHunk": "@@ -151,33 +161,34 @@ def commonExcludeCategories = [\n \n // For the following test tasks using legacy worker, set workerHarnessContainerImage to empty to\n // make Dataflow pick up the non-versioned container image, which handles a staged worker jar.\n-task validatesRunnerLegacyWorkerTest(type: Test) {\n-  group = \"Verification\"\n-  dependsOn \":runners:google-cloud-dataflow-java:worker:legacy-worker:shadowJar\"\n-\n-  systemProperty \"beamTestPipelineOptions\", JsonOutput.toJson([\n-          \"--runner=TestDataflowRunner\",\n-          \"--project=${dataflowProject}\",\n-          \"--region=${dataflowRegion}\",\n-          \"--tempRoot=${dataflowValidatesTempRoot}\",\n-          \"--dataflowWorkerJar=${dataflowLegacyWorkerJar}\",\n-          \"--workerHarnessContainerImage=\",\n-  ])\n-\n-  // Increase test parallelism up to the number of Gradle workers. By default this is equal\n-  // to the number of CPU cores, but can be increased by setting --max-workers=N.\n-  maxParallelForks Integer.MAX_VALUE\n-  classpath = configurations.validatesRunner\n-  testClassesDirs = files(project(\":sdks:java:core\").sourceSets.test.output.classesDirs) +\n-          files(project(project.path).sourceSets.test.output.classesDirs)\n-  useJUnit {\n-    includeCategories 'org.apache.beam.sdk.testing.ValidatesRunner'\n-    commonExcludeCategories.each {\n-      excludeCategories it\n+def createValidatesRunnerTest = { name, pipelineOptions=legacyPipelineOptions, disabledTests=[] ->", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5OTkyMjA0MA=="}, "originalCommit": {"oid": "a074f62a07d036fdca96a404c79fd8ef84889bf1"}, "originalPosition": 44}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3161, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}