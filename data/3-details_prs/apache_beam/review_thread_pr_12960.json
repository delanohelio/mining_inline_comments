{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDk0NDk5NzI0", "number": 12960, "reviewThreads": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxOTozOTozOFrOEtMcuw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOVQxOTo0MToyMlrOEzdB7A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE1ODI1MzM5OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/bigquery_tools.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxOTozOTozOFrOHg2gNA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQwMDoyMTowNFrOHpVl5Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDIwOTQ2MA==", "bodyText": "The BigQueryReader is only used in the Dataflow native BigQuerySource - I don't think this is compatible, so we should probably revert changes to it.\nLet's focus on temp_dataset for _CustomBigQuerySource.", "url": "https://github.com/apache/beam/pull/12960#discussion_r504209460", "createdAt": "2020-10-13T19:39:38Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/bigquery_tools.py", "diffHunk": "@@ -1096,7 +1114,8 @@ def __init__(\n       test_bigquery_client=None,\n       use_legacy_sql=True,\n       flatten_results=True,\n-      kms_key=None):\n+      kms_key=None,\n+      temp_dataset=None):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "71c3ea69535268d1e37a8b97decefbf1a0e466ab"}, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzEwNzQyOQ==", "bodyText": "reverted changes to BigQueryReader", "url": "https://github.com/apache/beam/pull/12960#discussion_r513107429", "createdAt": "2020-10-28T00:21:04Z", "author": {"login": "frankzhao"}, "path": "sdks/python/apache_beam/io/gcp/bigquery_tools.py", "diffHunk": "@@ -1096,7 +1114,8 @@ def __init__(\n       test_bigquery_client=None,\n       use_legacy_sql=True,\n       flatten_results=True,\n-      kms_key=None):\n+      kms_key=None,\n+      temp_dataset=None):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDIwOTQ2MA=="}, "originalCommit": {"oid": "71c3ea69535268d1e37a8b97decefbf1a0e466ab"}, "originalPosition": 116}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIyMzg2OTY5OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/bigquery_tools.py", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOVQxOTozNjo1OVrOHqrmiQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOVQxOTozNjo1OVrOHqrmiQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDUxNjYxNw==", "bodyText": "in beam, we usually break lines using parentheses, kind of like this:\ndataset_id = (\n    dataset_reference.datasetId if dataset_reference else temp_table.datasetId)", "url": "https://github.com/apache/beam/pull/12960#discussion_r514516617", "createdAt": "2020-10-29T19:36:59Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/bigquery_tools.py", "diffHunk": "@@ -731,16 +744,19 @@ def create_temporary_dataset(self, project_id, location):\n   @retry.with_exponential_backoff(\n       num_retries=MAX_RETRIES,\n       retry_filter=retry.retry_on_server_errors_and_timeout_filter)\n-  def clean_up_temporary_dataset(self, project_id):\n+  def clean_up_temporary_dataset(self, project_id, dataset_reference=None):\n+    if dataset_reference:\n+      project_id = dataset_reference.projectId\n     temp_table = self._get_temp_table(project_id)\n+    dataset_id = dataset_reference.datasetId if dataset_reference \\", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "be45d63d6bc32ee0ca38f45b1b5764cf746b1c74"}, "originalPosition": 75}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIyMzg4NDYwOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOVQxOTo0MToyMlrOHqrvmA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOVQyMTo1MzoyNFrOHqwEow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDUxODkzNg==", "bodyText": "how about we add a get_temporary_dataset function to BigqueryWrapper, and we can define a self.temp_dataset = self.temp_dataset or bq.get_temporary_dataset() (this logic would need to run in the split, and `- and once we've done that, we can just pass the dataset name around to every call? That way we will treat the user-defined dataset and the automatic dataset the same way?", "url": "https://github.com/apache/beam/pull/12960#discussion_r514518936", "createdAt": "2020-10-29T19:41:22Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -712,6 +713,7 @@ def __init__(\n     self.bq_io_metadata = None  # Populate in setup, as it may make an RPC\n     self.bigquery_job_labels = bigquery_job_labels or {}\n     self.use_json_exports = use_json_exports\n+    self.temp_dataset = temp_dataset", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "be45d63d6bc32ee0ca38f45b1b5764cf746b1c74"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDUyMDU4NA==", "bodyText": "let me know what you think about this implementation @frankzhao\nI understand changing it may be troublesome, but doing this would simplify the logic quite a bit", "url": "https://github.com/apache/beam/pull/12960#discussion_r514520584", "createdAt": "2020-10-29T19:44:39Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -712,6 +713,7 @@ def __init__(\n     self.bq_io_metadata = None  # Populate in setup, as it may make an RPC\n     self.bigquery_job_labels = bigquery_job_labels or {}\n     self.use_json_exports = use_json_exports\n+    self.temp_dataset = temp_dataset", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDUxODkzNg=="}, "originalCommit": {"oid": "be45d63d6bc32ee0ca38f45b1b5764cf746b1c74"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDU4OTg1OQ==", "bodyText": "I agree, let me take look at it", "url": "https://github.com/apache/beam/pull/12960#discussion_r514589859", "createdAt": "2020-10-29T21:53:24Z", "author": {"login": "frankzhao"}, "path": "sdks/python/apache_beam/io/gcp/bigquery.py", "diffHunk": "@@ -712,6 +713,7 @@ def __init__(\n     self.bq_io_metadata = None  # Populate in setup, as it may make an RPC\n     self.bigquery_job_labels = bigquery_job_labels or {}\n     self.use_json_exports = use_json_exports\n+    self.temp_dataset = temp_dataset", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDUxODkzNg=="}, "originalCommit": {"oid": "be45d63d6bc32ee0ca38f45b1b5764cf746b1c74"}, "originalPosition": 14}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3261, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}