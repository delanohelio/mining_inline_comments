{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQwMjAzMzA1", "number": 12090, "title": "[BEAM-10336,BEAM-10337] Add SchemaIO abstraction and implement for PubSub", "bodyText": "Created a schema capable IO abstraction interface and implemented for pubsub.\nInvolves a SchemaIOProvider to instantiate the SchemaIO, which can be used to create schema aware reader and writer transforms.\nR:@TheNeuralBit\nR:@robinyqiu\n\nPost-Commit Tests Status (on master branch)\n\n\n\nLang\nSDK\nDataflow\nFlink\nSamza\nSpark\n\n\n\n\nGo\n\n---\n\n---\n\n\n\nJava\n\n\n\n\n\n\n\nPython\n\n\n\n---\n\n\n\nXLang\n---\n---\n\n---\n---\n\n\n\nPre-Commit Tests Status (on master branch)\n\n\n\n---\nJava\nPython\nGo\nWebsite\n\n\n\n\nNon-portable\n\n\n\n\n\n\nPortable\n---\n\n---\n---\n\n\n\nSee .test-infra/jenkins/README for trigger phrase, status and link of all Jenkins jobs.", "createdAt": "2020-06-25T19:02:51Z", "url": "https://github.com/apache/beam/pull/12090", "merged": true, "mergeCommit": {"oid": "28c2c7720f62910477e23e48499d5c2320d0b3bf"}, "closed": true, "closedAt": "2020-07-07T19:43:12Z", "author": {"login": "sclukas77"}, "timelineItems": {"totalCount": 18, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcu49dqgFqTQzNzk0Mzc5Mg==", "endCursor": "Y3Vyc29yOnYyOpPPAAABcyqBbUAFqTQ0NDE0MDczMg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM3OTQzNzky", "url": "https://github.com/apache/beam/pull/12090#pullrequestreview-437943792", "createdAt": "2020-06-26T00:29:17Z", "commit": {"oid": "fdcfdbdee40194d90a16a02f1b2d46f9123ac120"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQwMDoyOToxN1rOGpQE2A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQwMToxNzowMVrOGpQwYQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTkwODE4NA==", "bodyText": "It would be better if we could map the tableProperties into a Row by leveraging RowJson.RowJsonDeserializer initialized with configurationSchema(), then there wouldn't be any logic specific to pubsub here.\nThe biggest hang-up with that is \"useFlatSchema\", since its not actually part of the JSON - is there a reason we can't move all of the logic for detecting flat vs. nested schemas into PubsubSchemaCapableIOProvider#from?", "url": "https://github.com/apache/beam/pull/12090#discussion_r445908184", "createdAt": "2020-06-26T00:29:17Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/pubsub/PubsubJsonTableProvider.java", "diffHunk": "@@ -47,32 +44,40 @@\n @Experimental\n @AutoService(TableProvider.class)\n public class PubsubJsonTableProvider extends InMemoryMetaTableProvider {\n+  static final String TIMESTAMP_FIELD = \"event_timestamp\";\n+  static final String ATTRIBUTES_FIELD = \"attributes\";\n+  static final String PAYLOAD_FIELD = \"payload\";\n \n   @Override\n   public String getTableType() {\n     return \"pubsub\";\n   }\n \n   @Override\n-  public BeamSqlTable buildBeamSqlTable(Table tableDefintion) {\n-    JSONObject tableProperties = tableDefintion.getProperties();\n+  public BeamSqlTable buildBeamSqlTable(Table tableDefinition) {\n+    JSONObject tableProperties = tableDefinition.getProperties();\n     String timestampAttributeKey = tableProperties.getString(\"timestampAttributeKey\");\n     String deadLetterQueue = tableProperties.getString(\"deadLetterQueue\");\n-    validateDlq(deadLetterQueue);\n \n-    Schema schema = tableDefintion.getSchema();\n+    Schema schema = tableDefinition.getSchema();\n+    String location = tableDefinition.getLocation();\n+    Schema dataSchema = tableDefinition.getSchema();\n+\n+    validateDlq(deadLetterQueue);\n     validateEventTimestamp(schema);\n \n-    PubsubIOTableConfiguration config =\n-        PubsubIOTableConfiguration.builder()\n-            .setSchema(schema)\n-            .setTimestampAttribute(timestampAttributeKey)\n-            .setDeadLetterQueue(deadLetterQueue)\n-            .setTopic(tableDefintion.getLocation())\n-            .setUseFlatSchema(!definesAttributeAndPayload(schema))\n+    PubsubSchemaCapableIOProvider ioProvider = new PubsubSchemaCapableIOProvider();\n+    Schema configurationSchema = ioProvider.configurationSchema();\n+\n+    Row configurationRow =\n+        Row.withSchema(configurationSchema)\n+            .withFieldValue(\"timestampAttributeKey\", timestampAttributeKey)\n+            .withFieldValue(\"deadLetterQueue\", deadLetterQueue)\n+            .withFieldValue(\"useFlatSchema\", !definesAttributeAndPayload(schema))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fdcfdbdee40194d90a16a02f1b2d46f9123ac120"}, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTkwODE5MQ==", "bodyText": "Could you move this validation to the new implementation (probably in the from method)? We'll want to make sure we still do the validation when this is used outside of SQL (e.g. for cross-language).", "url": "https://github.com/apache/beam/pull/12090#discussion_r445908191", "createdAt": "2020-06-26T00:29:19Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/pubsub/PubsubJsonTableProvider.java", "diffHunk": "@@ -47,32 +44,40 @@\n @Experimental\n @AutoService(TableProvider.class)\n public class PubsubJsonTableProvider extends InMemoryMetaTableProvider {\n+  static final String TIMESTAMP_FIELD = \"event_timestamp\";\n+  static final String ATTRIBUTES_FIELD = \"attributes\";\n+  static final String PAYLOAD_FIELD = \"payload\";\n \n   @Override\n   public String getTableType() {\n     return \"pubsub\";\n   }\n \n   @Override\n-  public BeamSqlTable buildBeamSqlTable(Table tableDefintion) {\n-    JSONObject tableProperties = tableDefintion.getProperties();\n+  public BeamSqlTable buildBeamSqlTable(Table tableDefinition) {\n+    JSONObject tableProperties = tableDefinition.getProperties();\n     String timestampAttributeKey = tableProperties.getString(\"timestampAttributeKey\");\n     String deadLetterQueue = tableProperties.getString(\"deadLetterQueue\");\n-    validateDlq(deadLetterQueue);\n \n-    Schema schema = tableDefintion.getSchema();\n+    Schema schema = tableDefinition.getSchema();\n+    String location = tableDefinition.getLocation();\n+    Schema dataSchema = tableDefinition.getSchema();\n+\n+    validateDlq(deadLetterQueue);\n     validateEventTimestamp(schema);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fdcfdbdee40194d90a16a02f1b2d46f9123ac120"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTkxMDA1MA==", "bodyText": "nit: it won't be new forever :)\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            /** Provides a new schema aware IO abstraction interface. */\n          \n          \n            \n            /** Provides abstractions for schema-aware IOs. */", "url": "https://github.com/apache/beam/pull/12090#discussion_r445910050", "createdAt": "2020-06-26T00:37:01Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/io/package-info.java", "diffHunk": "@@ -0,0 +1,20 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+/** Provides a new schema aware IO abstraction interface. */", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fdcfdbdee40194d90a16a02f1b2d46f9123ac120"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTkxMDcyMg==", "bodyText": "Please add @DefaultAnnotation(NonNull.class) like this: \n  \n    \n      beam/sdks/java/core/src/main/java/org/apache/beam/sdk/package-info.java\n    \n    \n        Lines 29 to 30\n      in\n      451af51\n    \n    \n    \n    \n\n        \n          \n           @DefaultAnnotation(NonNull.class) \n        \n\n        \n          \n           package org.apache.beam.sdk; \n        \n    \n  \n\n\nThat's supposed to make spotbugs verify we never pass null to a function argument, unless it's explicitly allowed with @Nullable", "url": "https://github.com/apache/beam/pull/12090#discussion_r445910722", "createdAt": "2020-06-26T00:39:42Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/io/package-info.java", "diffHunk": "@@ -0,0 +1,20 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+/** Provides a new schema aware IO abstraction interface. */\n+package org.apache.beam.sdk.schemas.io;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fdcfdbdee40194d90a16a02f1b2d46f9123ac120"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTkxMTY2MQ==", "bodyText": "This could defer to PubsubSchemaIOProvider#identifier(), but you'd need to have an instance of it (could be a static member, or you could add a constructor and create one there).", "url": "https://github.com/apache/beam/pull/12090#discussion_r445911661", "createdAt": "2020-06-26T00:43:35Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/pubsub/PubsubJsonTableProvider.java", "diffHunk": "@@ -47,32 +44,40 @@\n @Experimental\n @AutoService(TableProvider.class)\n public class PubsubJsonTableProvider extends InMemoryMetaTableProvider {\n+  static final String TIMESTAMP_FIELD = \"event_timestamp\";\n+  static final String ATTRIBUTES_FIELD = \"attributes\";\n+  static final String PAYLOAD_FIELD = \"payload\";\n \n   @Override\n   public String getTableType() {\n     return \"pubsub\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fdcfdbdee40194d90a16a02f1b2d46f9123ac120"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTkxNTc1NQ==", "bodyText": "I think we should make this a private static inner class within PubsubSchemaCapableIOProvider so no one tries to use it on its own.", "url": "https://github.com/apache/beam/pull/12090#discussion_r445915755", "createdAt": "2020-06-26T01:00:56Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsub/PubsubSchemaIO.java", "diffHunk": "@@ -0,0 +1,131 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsub;\n+\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.DLQ_TAG;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.MAIN_TAG;\n+\n+import java.io.Serializable;\n+import org.apache.beam.sdk.annotations.Internal;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.schemas.io.SchemaIO;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionTuple;\n+import org.apache.beam.sdk.values.POutput;\n+import org.apache.beam.sdk.values.Row;\n+\n+/** An abstraction to create schema aware IOs. */\n+@Internal\n+public class PubsubSchemaIO implements SchemaIO, Serializable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fdcfdbdee40194d90a16a02f1b2d46f9123ac120"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTkxOTMyOQ==", "bodyText": "Hm I feel like this also should not be public... but I see that's actually my fault since I did it originally. Would you mind fixing my mistake and making this a private static inner class?", "url": "https://github.com/apache/beam/pull/12090#discussion_r445919329", "createdAt": "2020-06-26T01:17:01Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsub/RowToPubsubMessage.java", "diffHunk": "@@ -38,29 +37,28 @@\n  * <p>Currently only supports writing a flat schema into a JSON payload. This means that all Row\n  * field values are written to the {@link PubsubMessage} JSON payload, except for {@code\n  * event_timestamp}, which is either ignored or written to the message attributes, depending on\n- * whether {@link PubsubJsonTableProvider.PubsubIOTableConfiguration#getTimestampAttribute()} is\n- * set.\n+ * whether config.getValue(\"timestampAttributeKey\") is set.\n  */\n @Experimental\n public class RowToPubsubMessage extends PTransform<PCollection<Row>, PCollection<PubsubMessage>> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fdcfdbdee40194d90a16a02f1b2d46f9123ac120"}, "originalPosition": 24}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM4NjAwMTUw", "url": "https://github.com/apache/beam/pull/12090#pullrequestreview-438600150", "createdAt": "2020-06-26T21:16:35Z", "commit": {"oid": "0b1804967423a7d35cdbe99261133e44279bd5a3"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQyMToxNjozNVrOGpu8Lw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yN1QwMDoyNjoyNlrOGpxxHg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQxMzg3MQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            /** Exception thrown when the request for a table is invalid, such as invalid metadata. */\n          \n          \n            \n            /** Exception thrown when the configuration for a {@link SchemaIO} is invalid. */", "url": "https://github.com/apache/beam/pull/12090#discussion_r446413871", "createdAt": "2020-06-26T21:16:35Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/io/InvalidConfigurationException.java", "diffHunk": "@@ -0,0 +1,33 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.schemas.io;\n+\n+/** Exception thrown when the request for a table is invalid, such as invalid metadata. */", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0b1804967423a7d35cdbe99261133e44279bd5a3"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQxNDczMA==", "bodyText": "Can you add a note that this can throw an InvalidConfigurationException?", "url": "https://github.com/apache/beam/pull/12090#discussion_r446414730", "createdAt": "2020-06-26T21:19:05Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/io/SchemaCapableIOProvider.java", "diffHunk": "@@ -0,0 +1,38 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.schemas.io;\n+\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.values.Row;\n+\n+public interface SchemaCapableIOProvider {\n+  /** Returns an id that uniquely represents this IO. */\n+  String identifier();\n+\n+  /**\n+   * Returns the expected schema of the configuration object. Note this is distinct from the schema\n+   * of the data source itself.\n+   */\n+  Schema configurationSchema();\n+\n+  /**\n+   * Produce a SchemaIO given a String representing the data's location, the schema of the data that\n+   * resides there, and some IO-specific configuration object.\n+   */", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0b1804967423a7d35cdbe99261133e44279bd5a3"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQ1ODYzMQ==", "bodyText": "I don't think we want to lose the information in these doc comments. Could you move it into the javadoc for PubSubSchemaCapableIOProvider?", "url": "https://github.com/apache/beam/pull/12090#discussion_r446458631", "createdAt": "2020-06-27T00:15:57Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/pubsub/PubsubJsonTableProvider.java", "diffHunk": "@@ -54,125 +47,29 @@ public String getTableType() {\n   }\n \n   @Override\n-  public BeamSqlTable buildBeamSqlTable(Table tableDefintion) {\n-    JSONObject tableProperties = tableDefintion.getProperties();\n+  public BeamSqlTable buildBeamSqlTable(Table tableDefinition) {\n+    JSONObject tableProperties = tableDefinition.getProperties();\n     String timestampAttributeKey = tableProperties.getString(\"timestampAttributeKey\");\n     String deadLetterQueue = tableProperties.getString(\"deadLetterQueue\");\n-    validateDlq(deadLetterQueue);\n-\n-    Schema schema = tableDefintion.getSchema();\n-    validateEventTimestamp(schema);\n-\n-    PubsubIOTableConfiguration config =\n-        PubsubIOTableConfiguration.builder()\n-            .setSchema(schema)\n-            .setTimestampAttribute(timestampAttributeKey)\n-            .setDeadLetterQueue(deadLetterQueue)\n-            .setTopic(tableDefintion.getLocation())\n-            .setUseFlatSchema(!definesAttributeAndPayload(schema))\n-            .build();\n-\n-    return PubsubIOJsonTable.withConfiguration(config);\n-  }\n-\n-  private void validateEventTimestamp(Schema schema) {\n-    if (!fieldPresent(schema, TIMESTAMP_FIELD, TIMESTAMP)) {\n-      throw new InvalidTableException(\n-          \"Unsupported schema specified for Pubsub source in CREATE TABLE.\"\n-              + \"CREATE TABLE for Pubsub topic must include at least 'event_timestamp' field of \"\n-              + \"type 'TIMESTAMP'\");\n-    }\n-  }\n-\n-  private boolean definesAttributeAndPayload(Schema schema) {\n-    return fieldPresent(\n-            schema, ATTRIBUTES_FIELD, Schema.FieldType.map(VARCHAR.withNullable(false), VARCHAR))\n-        && (schema.hasField(PAYLOAD_FIELD)\n-            && ROW.equals(schema.getField(PAYLOAD_FIELD).getType().getTypeName()));\n-  }\n-\n-  private boolean fieldPresent(Schema schema, String field, Schema.FieldType expectedType) {\n-    return schema.hasField(field)\n-        && expectedType.equivalent(\n-            schema.getField(field).getType(), Schema.EquivalenceNullablePolicy.IGNORE);\n-  }\n-\n-  private void validateDlq(String deadLetterQueue) {\n-    if (deadLetterQueue != null && deadLetterQueue.isEmpty()) {\n-      throw new InvalidTableException(\"Dead letter queue topic name is not specified\");\n-    }\n-  }\n-\n-  @AutoValue\n-  public abstract static class PubsubIOTableConfiguration implements Serializable {\n-    public boolean useDlq() {\n-      return getDeadLetterQueue() != null;\n-    }\n-\n-    public boolean useTimestampAttribute() {\n-      return getTimestampAttribute() != null;\n-    }\n-\n-    /** Determines whether or not the messages should be represented with a flattened schema. */\n-    abstract boolean getUseFlatSchema();\n-\n-    /**\n-     * Optional attribute key of the Pubsub message from which to extract the event timestamp.\n-     *\n-     * <p>This attribute has to conform to the same requirements as in {@link\n-     * PubsubIO.Read.Builder#withTimestampAttribute}.\n-     *\n-     * <p>Short version: it has to be either millis since epoch or string in RFC 3339 format.\n-     *\n-     * <p>If the attribute is specified then event timestamps will be extracted from the specified\n-     * attribute. If it is not specified then message publish timestamp will be used.\n-     */\n-    @Nullable\n-    abstract String getTimestampAttribute();\n-\n-    /**\n-     * Optional topic path which will be used as a dead letter queue.\n-     *\n-     * <p>Messages that cannot be processed will be sent to this topic. If it is not specified then\n-     * exception will be thrown for errors during processing causing the pipeline to crash.\n-     */\n-    @Nullable\n-    abstract String getDeadLetterQueue();\n \n-    /**\n-     * Pubsub topic name.\n-     *\n-     * <p>Topic is the only way to specify the Pubsub source. Explicitly specifying the subscription\n-     * is not supported at the moment. Subscriptions are automatically created (but not deleted).\n-     */\n-    abstract String getTopic();\n+    Schema schema = tableDefinition.getSchema();\n+    String location = tableDefinition.getLocation();\n+    Schema dataSchema = tableDefinition.getSchema();\n \n-    /**\n-     * Table schema, describes Pubsub message schema.\n-     *\n-     * <p>If {@link #getUseFlatSchema()} is not set, schema must contain exactly fields\n-     * 'event_timestamp', 'attributes, and 'payload'. Else, it must contain just 'event_timestamp'.\n-     * See {@linkA PubsubMessageToRow} for details.\n-     */\n-    public abstract Schema getSchema();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0b1804967423a7d35cdbe99261133e44279bd5a3"}, "originalPosition": 139}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjQ2MDE5MA==", "bodyText": "This should just catch InvalidConfigurationException e, not any Exception.\nAlso you should include the information from the original exception when re-throwing. Either use e.getMessage() to insert the original message into the new one, or add the exception as a cause (new InvalidTableException(msg, e)), or both.\nI think that should fix the unit test that's failing.", "url": "https://github.com/apache/beam/pull/12090#discussion_r446460190", "createdAt": "2020-06-27T00:26:26Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/pubsub/PubsubJsonTableProvider.java", "diffHunk": "@@ -54,125 +47,29 @@ public String getTableType() {\n   }\n \n   @Override\n-  public BeamSqlTable buildBeamSqlTable(Table tableDefintion) {\n-    JSONObject tableProperties = tableDefintion.getProperties();\n+  public BeamSqlTable buildBeamSqlTable(Table tableDefinition) {\n+    JSONObject tableProperties = tableDefinition.getProperties();\n     String timestampAttributeKey = tableProperties.getString(\"timestampAttributeKey\");\n     String deadLetterQueue = tableProperties.getString(\"deadLetterQueue\");\n-    validateDlq(deadLetterQueue);\n-\n-    Schema schema = tableDefintion.getSchema();\n-    validateEventTimestamp(schema);\n-\n-    PubsubIOTableConfiguration config =\n-        PubsubIOTableConfiguration.builder()\n-            .setSchema(schema)\n-            .setTimestampAttribute(timestampAttributeKey)\n-            .setDeadLetterQueue(deadLetterQueue)\n-            .setTopic(tableDefintion.getLocation())\n-            .setUseFlatSchema(!definesAttributeAndPayload(schema))\n-            .build();\n-\n-    return PubsubIOJsonTable.withConfiguration(config);\n-  }\n-\n-  private void validateEventTimestamp(Schema schema) {\n-    if (!fieldPresent(schema, TIMESTAMP_FIELD, TIMESTAMP)) {\n-      throw new InvalidTableException(\n-          \"Unsupported schema specified for Pubsub source in CREATE TABLE.\"\n-              + \"CREATE TABLE for Pubsub topic must include at least 'event_timestamp' field of \"\n-              + \"type 'TIMESTAMP'\");\n-    }\n-  }\n-\n-  private boolean definesAttributeAndPayload(Schema schema) {\n-    return fieldPresent(\n-            schema, ATTRIBUTES_FIELD, Schema.FieldType.map(VARCHAR.withNullable(false), VARCHAR))\n-        && (schema.hasField(PAYLOAD_FIELD)\n-            && ROW.equals(schema.getField(PAYLOAD_FIELD).getType().getTypeName()));\n-  }\n-\n-  private boolean fieldPresent(Schema schema, String field, Schema.FieldType expectedType) {\n-    return schema.hasField(field)\n-        && expectedType.equivalent(\n-            schema.getField(field).getType(), Schema.EquivalenceNullablePolicy.IGNORE);\n-  }\n-\n-  private void validateDlq(String deadLetterQueue) {\n-    if (deadLetterQueue != null && deadLetterQueue.isEmpty()) {\n-      throw new InvalidTableException(\"Dead letter queue topic name is not specified\");\n-    }\n-  }\n-\n-  @AutoValue\n-  public abstract static class PubsubIOTableConfiguration implements Serializable {\n-    public boolean useDlq() {\n-      return getDeadLetterQueue() != null;\n-    }\n-\n-    public boolean useTimestampAttribute() {\n-      return getTimestampAttribute() != null;\n-    }\n-\n-    /** Determines whether or not the messages should be represented with a flattened schema. */\n-    abstract boolean getUseFlatSchema();\n-\n-    /**\n-     * Optional attribute key of the Pubsub message from which to extract the event timestamp.\n-     *\n-     * <p>This attribute has to conform to the same requirements as in {@link\n-     * PubsubIO.Read.Builder#withTimestampAttribute}.\n-     *\n-     * <p>Short version: it has to be either millis since epoch or string in RFC 3339 format.\n-     *\n-     * <p>If the attribute is specified then event timestamps will be extracted from the specified\n-     * attribute. If it is not specified then message publish timestamp will be used.\n-     */\n-    @Nullable\n-    abstract String getTimestampAttribute();\n-\n-    /**\n-     * Optional topic path which will be used as a dead letter queue.\n-     *\n-     * <p>Messages that cannot be processed will be sent to this topic. If it is not specified then\n-     * exception will be thrown for errors during processing causing the pipeline to crash.\n-     */\n-    @Nullable\n-    abstract String getDeadLetterQueue();\n \n-    /**\n-     * Pubsub topic name.\n-     *\n-     * <p>Topic is the only way to specify the Pubsub source. Explicitly specifying the subscription\n-     * is not supported at the moment. Subscriptions are automatically created (but not deleted).\n-     */\n-    abstract String getTopic();\n+    Schema schema = tableDefinition.getSchema();\n+    String location = tableDefinition.getLocation();\n+    Schema dataSchema = tableDefinition.getSchema();\n \n-    /**\n-     * Table schema, describes Pubsub message schema.\n-     *\n-     * <p>If {@link #getUseFlatSchema()} is not set, schema must contain exactly fields\n-     * 'event_timestamp', 'attributes, and 'payload'. Else, it must contain just 'event_timestamp'.\n-     * See {@linkA PubsubMessageToRow} for details.\n-     */\n-    public abstract Schema getSchema();\n+    PubsubSchemaCapableIOProvider ioProvider = new PubsubSchemaCapableIOProvider();\n+    Schema configurationSchema = ioProvider.configurationSchema();\n \n-    static Builder builder() {\n-      return new AutoValue_PubsubJsonTableProvider_PubsubIOTableConfiguration.Builder();\n-    }\n-\n-    @AutoValue.Builder\n-    abstract static class Builder {\n-      abstract Builder setUseFlatSchema(boolean useFlatSchema);\n-\n-      abstract Builder setSchema(Schema schema);\n-\n-      abstract Builder setTimestampAttribute(String timestampAttribute);\n-\n-      abstract Builder setDeadLetterQueue(String deadLetterQueue);\n-\n-      abstract Builder setTopic(String topic);\n+    Row configurationRow =\n+        Row.withSchema(configurationSchema)\n+            .withFieldValue(\"timestampAttributeKey\", timestampAttributeKey)\n+            .withFieldValue(\"deadLetterQueue\", deadLetterQueue)\n+            .build();\n \n-      abstract PubsubIOTableConfiguration build();\n+    try {\n+      SchemaIO pubsubSchemaIO = ioProvider.from(location, configurationRow, dataSchema);\n+      return PubsubIOJsonTable.withConfiguration(pubsubSchemaIO, schema);\n+    } catch (Exception InvalidConfigurationException) {\n+      throw new InvalidTableException(\"Invalid configuration of table\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0b1804967423a7d35cdbe99261133e44279bd5a3"}, "originalPosition": 169}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM4NzMyMTI0", "url": "https://github.com/apache/beam/pull/12090#pullrequestreview-438732124", "createdAt": "2020-06-28T00:05:49Z", "commit": {"oid": "0b1804967423a7d35cdbe99261133e44279bd5a3"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM4NzMzOTg5", "url": "https://github.com/apache/beam/pull/12090#pullrequestreview-438733989", "createdAt": "2020-06-28T00:52:48Z", "commit": {"oid": "0b1804967423a7d35cdbe99261133e44279bd5a3"}, "state": "COMMENTED", "comments": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yOFQwMDo1Mjo0OFrOGp5XUA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yOFQwMTozNjozMVrOGp5ijQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU4NDY1Ng==", "bodyText": "Now that configuration is gone, this function could be better named as something like fromSchemaIO().\nAlso, the second parameter schema doesn't seem necessary. You can get that information from pubsubSchemaIO.schema().", "url": "https://github.com/apache/beam/pull/12090#discussion_r446584656", "createdAt": "2020-06-28T00:52:48Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/pubsub/PubsubIOJsonTable.java", "diffHunk": "@@ -122,14 +115,16 @@\n @Experimental\n class PubsubIOJsonTable extends BaseBeamTable implements Serializable {\n \n-  protected final PubsubIOTableConfiguration config;\n+  protected final SchemaIO pubsubSchemaIO;\n+  protected final Schema schema;\n \n-  private PubsubIOJsonTable(PubsubIOTableConfiguration config) {\n-    this.config = config;\n+  private PubsubIOJsonTable(SchemaIO pubsubSchemaIO, Schema schema) {\n+    this.pubsubSchemaIO = pubsubSchemaIO;\n+    this.schema = schema;\n   }\n \n-  static PubsubIOJsonTable withConfiguration(PubsubIOTableConfiguration config) {\n-    return new PubsubIOJsonTable(config);\n+  static PubsubIOJsonTable withConfiguration(SchemaIO pubsubSchemaIO, Schema schema) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0b1804967423a7d35cdbe99261133e44279bd5a3"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU4NDg4Nw==", "bodyText": "Nit: there is nothing wrong with this line, but usually we would write begin.apply(readerTransform) (same below)", "url": "https://github.com/apache/beam/pull/12090#discussion_r446584887", "createdAt": "2020-06-28T00:56:17Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/pubsub/PubsubIOJsonTable.java", "diffHunk": "@@ -139,65 +134,19 @@ static PubsubIOJsonTable withConfiguration(PubsubIOTableConfiguration config) {\n \n   @Override\n   public Schema getSchema() {\n-    return config.getSchema();\n+    return schema;\n   }\n \n   @Override\n   public PCollection<Row> buildIOReader(PBegin begin) {\n-    PCollectionTuple rowsWithDlq =\n-        begin\n-            .apply(\"ReadFromPubsub\", readMessagesWithAttributes())\n-            .apply(\n-                \"PubsubMessageToRow\",\n-                PubsubMessageToRow.builder()\n-                    .messageSchema(getSchema())\n-                    .useDlq(config.useDlq())\n-                    .useFlatSchema(config.getUseFlatSchema())\n-                    .build());\n-    rowsWithDlq.get(MAIN_TAG).setRowSchema(getSchema());\n-\n-    if (config.useDlq()) {\n-      rowsWithDlq.get(DLQ_TAG).apply(writeMessagesToDlq());\n-    }\n-\n-    return rowsWithDlq.get(MAIN_TAG);\n-  }\n-\n-  private PubsubIO.Read<PubsubMessage> readMessagesWithAttributes() {\n-    PubsubIO.Read<PubsubMessage> read =\n-        PubsubIO.readMessagesWithAttributes().fromTopic(config.getTopic());\n-\n-    return config.useTimestampAttribute()\n-        ? read.withTimestampAttribute(config.getTimestampAttribute())\n-        : read;\n-  }\n-\n-  private PubsubIO.Write<PubsubMessage> writeMessagesToDlq() {\n-    PubsubIO.Write<PubsubMessage> write = PubsubIO.writeMessages().to(config.getDeadLetterQueue());\n-\n-    return config.useTimestampAttribute()\n-        ? write.withTimestampAttribute(config.getTimestampAttribute())\n-        : write;\n+    PTransform<PBegin, PCollection<Row>> readerTransform = pubsubSchemaIO.buildReader();\n+    return readerTransform.expand(begin);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0b1804967423a7d35cdbe99261133e44279bd5a3"}, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU4NTI2Mw==", "bodyText": "This is the same as dataSchema.\nAlso, almost all the local variables defined here is used only once. Maybe moving them inline will make the function looks better.", "url": "https://github.com/apache/beam/pull/12090#discussion_r446585263", "createdAt": "2020-06-28T01:02:04Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/pubsub/PubsubJsonTableProvider.java", "diffHunk": "@@ -54,125 +47,29 @@ public String getTableType() {\n   }\n \n   @Override\n-  public BeamSqlTable buildBeamSqlTable(Table tableDefintion) {\n-    JSONObject tableProperties = tableDefintion.getProperties();\n+  public BeamSqlTable buildBeamSqlTable(Table tableDefinition) {\n+    JSONObject tableProperties = tableDefinition.getProperties();\n     String timestampAttributeKey = tableProperties.getString(\"timestampAttributeKey\");\n     String deadLetterQueue = tableProperties.getString(\"deadLetterQueue\");\n-    validateDlq(deadLetterQueue);\n-\n-    Schema schema = tableDefintion.getSchema();\n-    validateEventTimestamp(schema);\n-\n-    PubsubIOTableConfiguration config =\n-        PubsubIOTableConfiguration.builder()\n-            .setSchema(schema)\n-            .setTimestampAttribute(timestampAttributeKey)\n-            .setDeadLetterQueue(deadLetterQueue)\n-            .setTopic(tableDefintion.getLocation())\n-            .setUseFlatSchema(!definesAttributeAndPayload(schema))\n-            .build();\n-\n-    return PubsubIOJsonTable.withConfiguration(config);\n-  }\n-\n-  private void validateEventTimestamp(Schema schema) {\n-    if (!fieldPresent(schema, TIMESTAMP_FIELD, TIMESTAMP)) {\n-      throw new InvalidTableException(\n-          \"Unsupported schema specified for Pubsub source in CREATE TABLE.\"\n-              + \"CREATE TABLE for Pubsub topic must include at least 'event_timestamp' field of \"\n-              + \"type 'TIMESTAMP'\");\n-    }\n-  }\n-\n-  private boolean definesAttributeAndPayload(Schema schema) {\n-    return fieldPresent(\n-            schema, ATTRIBUTES_FIELD, Schema.FieldType.map(VARCHAR.withNullable(false), VARCHAR))\n-        && (schema.hasField(PAYLOAD_FIELD)\n-            && ROW.equals(schema.getField(PAYLOAD_FIELD).getType().getTypeName()));\n-  }\n-\n-  private boolean fieldPresent(Schema schema, String field, Schema.FieldType expectedType) {\n-    return schema.hasField(field)\n-        && expectedType.equivalent(\n-            schema.getField(field).getType(), Schema.EquivalenceNullablePolicy.IGNORE);\n-  }\n-\n-  private void validateDlq(String deadLetterQueue) {\n-    if (deadLetterQueue != null && deadLetterQueue.isEmpty()) {\n-      throw new InvalidTableException(\"Dead letter queue topic name is not specified\");\n-    }\n-  }\n-\n-  @AutoValue\n-  public abstract static class PubsubIOTableConfiguration implements Serializable {\n-    public boolean useDlq() {\n-      return getDeadLetterQueue() != null;\n-    }\n-\n-    public boolean useTimestampAttribute() {\n-      return getTimestampAttribute() != null;\n-    }\n-\n-    /** Determines whether or not the messages should be represented with a flattened schema. */\n-    abstract boolean getUseFlatSchema();\n-\n-    /**\n-     * Optional attribute key of the Pubsub message from which to extract the event timestamp.\n-     *\n-     * <p>This attribute has to conform to the same requirements as in {@link\n-     * PubsubIO.Read.Builder#withTimestampAttribute}.\n-     *\n-     * <p>Short version: it has to be either millis since epoch or string in RFC 3339 format.\n-     *\n-     * <p>If the attribute is specified then event timestamps will be extracted from the specified\n-     * attribute. If it is not specified then message publish timestamp will be used.\n-     */\n-    @Nullable\n-    abstract String getTimestampAttribute();\n-\n-    /**\n-     * Optional topic path which will be used as a dead letter queue.\n-     *\n-     * <p>Messages that cannot be processed will be sent to this topic. If it is not specified then\n-     * exception will be thrown for errors during processing causing the pipeline to crash.\n-     */\n-    @Nullable\n-    abstract String getDeadLetterQueue();\n \n-    /**\n-     * Pubsub topic name.\n-     *\n-     * <p>Topic is the only way to specify the Pubsub source. Explicitly specifying the subscription\n-     * is not supported at the moment. Subscriptions are automatically created (but not deleted).\n-     */\n-    abstract String getTopic();\n+    Schema schema = tableDefinition.getSchema();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0b1804967423a7d35cdbe99261133e44279bd5a3"}, "originalPosition": 128}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU4NTQ0MQ==", "bodyText": "I am not sure if we expect the table type here to be the same as PubsubSchemaCapableIOProvider.identifier(). WDYT Brian?", "url": "https://github.com/apache/beam/pull/12090#discussion_r446585441", "createdAt": "2020-06-28T01:05:02Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/pubsub/PubsubJsonTableProvider.java", "diffHunk": "@@ -54,125 +47,29 @@ public String getTableType() {\n   }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0b1804967423a7d35cdbe99261133e44279bd5a3"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU4NTkyNw==", "bodyText": "SchemaCapableIOProvider and SchemaIO are very important interfaces. Please add thorough class-level and method-level javadoc to explain what they are to help people better understand these concepts.", "url": "https://github.com/apache/beam/pull/12090#discussion_r446585927", "createdAt": "2020-06-28T01:12:05Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/io/SchemaIO.java", "diffHunk": "@@ -0,0 +1,33 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.schemas.io;\n+\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.POutput;\n+import org.apache.beam.sdk.values.Row;\n+\n+public interface SchemaIO {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0b1804967423a7d35cdbe99261133e44279bd5a3"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU4NjUwNA==", "bodyText": "How about adding validateConfiguration() here to make sure the configuration row matches configurationSchema?", "url": "https://github.com/apache/beam/pull/12090#discussion_r446586504", "createdAt": "2020-06-28T01:20:19Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsub/PubsubSchemaCapableIOProvider.java", "diffHunk": "@@ -0,0 +1,264 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsub;\n+\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.ATTRIBUTES_FIELD;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.DLQ_TAG;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.MAIN_TAG;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.PAYLOAD_FIELD;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.TIMESTAMP_FIELD;\n+import static org.apache.beam.sdk.schemas.Schema.TypeName.ROW;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+\n+import com.google.auto.service.AutoService;\n+import java.io.Serializable;\n+import java.nio.charset.StandardCharsets;\n+import org.apache.beam.sdk.annotations.Internal;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.schemas.Schema.FieldType;\n+import org.apache.beam.sdk.schemas.io.InvalidConfigurationException;\n+import org.apache.beam.sdk.schemas.io.SchemaCapableIOProvider;\n+import org.apache.beam.sdk.schemas.io.SchemaIO;\n+import org.apache.beam.sdk.schemas.transforms.DropFields;\n+import org.apache.beam.sdk.transforms.MapElements;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ToJson;\n+import org.apache.beam.sdk.transforms.WithTimestamps;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionTuple;\n+import org.apache.beam.sdk.values.POutput;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.sdk.values.TypeDescriptor;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * {@link org.apache.beam.sdk.schemas.io.SchemaCapableIOProvider} to create {@link PubsubSchemaIO}\n+ * that implements {@link org.apache.beam.sdk.schemas.io.SchemaIO}.\n+ */\n+@Internal\n+@AutoService(SchemaCapableIOProvider.class)\n+public class PubsubSchemaCapableIOProvider implements SchemaCapableIOProvider {\n+  public static final FieldType VARCHAR = FieldType.STRING;\n+  public static final FieldType TIMESTAMP = FieldType.DATETIME;\n+\n+  /** Returns an id that uniquely represents this IO. */\n+  @Override\n+  public String identifier() {\n+    return \"pubsub\";\n+  }\n+\n+  /**\n+   * Returns the expected schema of the configuration object. Note this is distinct from the schema\n+   * of the data source itself.\n+   */\n+  @Override\n+  public Schema configurationSchema() {\n+    return Schema.builder()\n+        .addNullableField(\"timestampAttributeKey\", FieldType.STRING)\n+        .addNullableField(\"deadLetterQueue\", FieldType.STRING)\n+        .build();\n+  }\n+\n+  /**\n+   * Produce a SchemaIO given a String representing the data's location, the schema of the data that\n+   * resides there, and some IO-specific configuration object.\n+   */\n+  @Override\n+  public PubsubSchemaIO from(String location, Row configuration, Schema dataSchema) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0b1804967423a7d35cdbe99261133e44279bd5a3"}, "originalPosition": 83}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU4Njc1MA==", "bodyText": "This static method is no longer necessary as the class became private. You can call the constructor directly from the outer class.", "url": "https://github.com/apache/beam/pull/12090#discussion_r446586750", "createdAt": "2020-06-28T01:24:20Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsub/PubsubSchemaCapableIOProvider.java", "diffHunk": "@@ -0,0 +1,264 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsub;\n+\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.ATTRIBUTES_FIELD;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.DLQ_TAG;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.MAIN_TAG;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.PAYLOAD_FIELD;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.TIMESTAMP_FIELD;\n+import static org.apache.beam.sdk.schemas.Schema.TypeName.ROW;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+\n+import com.google.auto.service.AutoService;\n+import java.io.Serializable;\n+import java.nio.charset.StandardCharsets;\n+import org.apache.beam.sdk.annotations.Internal;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.schemas.Schema.FieldType;\n+import org.apache.beam.sdk.schemas.io.InvalidConfigurationException;\n+import org.apache.beam.sdk.schemas.io.SchemaCapableIOProvider;\n+import org.apache.beam.sdk.schemas.io.SchemaIO;\n+import org.apache.beam.sdk.schemas.transforms.DropFields;\n+import org.apache.beam.sdk.transforms.MapElements;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ToJson;\n+import org.apache.beam.sdk.transforms.WithTimestamps;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionTuple;\n+import org.apache.beam.sdk.values.POutput;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.sdk.values.TypeDescriptor;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * {@link org.apache.beam.sdk.schemas.io.SchemaCapableIOProvider} to create {@link PubsubSchemaIO}\n+ * that implements {@link org.apache.beam.sdk.schemas.io.SchemaIO}.\n+ */\n+@Internal\n+@AutoService(SchemaCapableIOProvider.class)\n+public class PubsubSchemaCapableIOProvider implements SchemaCapableIOProvider {\n+  public static final FieldType VARCHAR = FieldType.STRING;\n+  public static final FieldType TIMESTAMP = FieldType.DATETIME;\n+\n+  /** Returns an id that uniquely represents this IO. */\n+  @Override\n+  public String identifier() {\n+    return \"pubsub\";\n+  }\n+\n+  /**\n+   * Returns the expected schema of the configuration object. Note this is distinct from the schema\n+   * of the data source itself.\n+   */\n+  @Override\n+  public Schema configurationSchema() {\n+    return Schema.builder()\n+        .addNullableField(\"timestampAttributeKey\", FieldType.STRING)\n+        .addNullableField(\"deadLetterQueue\", FieldType.STRING)\n+        .build();\n+  }\n+\n+  /**\n+   * Produce a SchemaIO given a String representing the data's location, the schema of the data that\n+   * resides there, and some IO-specific configuration object.\n+   */\n+  @Override\n+  public PubsubSchemaIO from(String location, Row configuration, Schema dataSchema) {\n+    validateDlq(configuration.getValue(\"deadLetterQueue\"));\n+    validateEventTimestamp(dataSchema);\n+    return PubsubSchemaIO.withConfiguration(location, configuration, dataSchema);\n+  }\n+\n+  private void validateEventTimestamp(Schema schema) {\n+    if (!PubsubSchemaIO.fieldPresent(schema, TIMESTAMP_FIELD, TIMESTAMP)) {\n+      throw new InvalidConfigurationException(\n+          \"Unsupported schema specified for Pubsub source in CREATE TABLE.\"\n+              + \"CREATE TABLE for Pubsub topic must include at least 'event_timestamp' field of \"\n+              + \"type 'TIMESTAMP'\");\n+    }\n+  }\n+\n+  private void validateDlq(String deadLetterQueue) {\n+    if (deadLetterQueue != null && deadLetterQueue.isEmpty()) {\n+      throw new InvalidConfigurationException(\"Dead letter queue topic name is not specified\");\n+    }\n+  }\n+\n+  /** An abstraction to create schema aware IOs. */\n+  @Internal\n+  private static class PubsubSchemaIO implements SchemaIO, Serializable {\n+    protected final Row config;\n+    protected final Schema dataSchema;\n+    protected final String location;\n+    protected final Boolean useFlatSchema;\n+\n+    private PubsubSchemaIO(String location, Row config, Schema dataSchema) {\n+      this.config = config;\n+      this.dataSchema = dataSchema;\n+      this.location = location;\n+      this.useFlatSchema = !definesAttributeAndPayload(dataSchema);\n+    }\n+\n+    static PubsubSchemaIO withConfiguration(String location, Row config, Schema dataSchema) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0b1804967423a7d35cdbe99261133e44279bd5a3"}, "originalPosition": 119}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU4NzE5OQ==", "bodyText": "Same here.", "url": "https://github.com/apache/beam/pull/12090#discussion_r446587199", "createdAt": "2020-06-28T01:30:50Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsub/PubsubSchemaCapableIOProvider.java", "diffHunk": "@@ -0,0 +1,264 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsub;\n+\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.ATTRIBUTES_FIELD;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.DLQ_TAG;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.MAIN_TAG;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.PAYLOAD_FIELD;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.TIMESTAMP_FIELD;\n+import static org.apache.beam.sdk.schemas.Schema.TypeName.ROW;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+\n+import com.google.auto.service.AutoService;\n+import java.io.Serializable;\n+import java.nio.charset.StandardCharsets;\n+import org.apache.beam.sdk.annotations.Internal;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.schemas.Schema.FieldType;\n+import org.apache.beam.sdk.schemas.io.InvalidConfigurationException;\n+import org.apache.beam.sdk.schemas.io.SchemaCapableIOProvider;\n+import org.apache.beam.sdk.schemas.io.SchemaIO;\n+import org.apache.beam.sdk.schemas.transforms.DropFields;\n+import org.apache.beam.sdk.transforms.MapElements;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ToJson;\n+import org.apache.beam.sdk.transforms.WithTimestamps;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionTuple;\n+import org.apache.beam.sdk.values.POutput;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.sdk.values.TypeDescriptor;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * {@link org.apache.beam.sdk.schemas.io.SchemaCapableIOProvider} to create {@link PubsubSchemaIO}\n+ * that implements {@link org.apache.beam.sdk.schemas.io.SchemaIO}.\n+ */\n+@Internal\n+@AutoService(SchemaCapableIOProvider.class)\n+public class PubsubSchemaCapableIOProvider implements SchemaCapableIOProvider {\n+  public static final FieldType VARCHAR = FieldType.STRING;\n+  public static final FieldType TIMESTAMP = FieldType.DATETIME;\n+\n+  /** Returns an id that uniquely represents this IO. */\n+  @Override\n+  public String identifier() {\n+    return \"pubsub\";\n+  }\n+\n+  /**\n+   * Returns the expected schema of the configuration object. Note this is distinct from the schema\n+   * of the data source itself.\n+   */\n+  @Override\n+  public Schema configurationSchema() {\n+    return Schema.builder()\n+        .addNullableField(\"timestampAttributeKey\", FieldType.STRING)\n+        .addNullableField(\"deadLetterQueue\", FieldType.STRING)\n+        .build();\n+  }\n+\n+  /**\n+   * Produce a SchemaIO given a String representing the data's location, the schema of the data that\n+   * resides there, and some IO-specific configuration object.\n+   */\n+  @Override\n+  public PubsubSchemaIO from(String location, Row configuration, Schema dataSchema) {\n+    validateDlq(configuration.getValue(\"deadLetterQueue\"));\n+    validateEventTimestamp(dataSchema);\n+    return PubsubSchemaIO.withConfiguration(location, configuration, dataSchema);\n+  }\n+\n+  private void validateEventTimestamp(Schema schema) {\n+    if (!PubsubSchemaIO.fieldPresent(schema, TIMESTAMP_FIELD, TIMESTAMP)) {\n+      throw new InvalidConfigurationException(\n+          \"Unsupported schema specified for Pubsub source in CREATE TABLE.\"\n+              + \"CREATE TABLE for Pubsub topic must include at least 'event_timestamp' field of \"\n+              + \"type 'TIMESTAMP'\");\n+    }\n+  }\n+\n+  private void validateDlq(String deadLetterQueue) {\n+    if (deadLetterQueue != null && deadLetterQueue.isEmpty()) {\n+      throw new InvalidConfigurationException(\"Dead letter queue topic name is not specified\");\n+    }\n+  }\n+\n+  /** An abstraction to create schema aware IOs. */\n+  @Internal\n+  private static class PubsubSchemaIO implements SchemaIO, Serializable {\n+    protected final Row config;\n+    protected final Schema dataSchema;\n+    protected final String location;\n+    protected final Boolean useFlatSchema;\n+\n+    private PubsubSchemaIO(String location, Row config, Schema dataSchema) {\n+      this.config = config;\n+      this.dataSchema = dataSchema;\n+      this.location = location;\n+      this.useFlatSchema = !definesAttributeAndPayload(dataSchema);\n+    }\n+\n+    static PubsubSchemaIO withConfiguration(String location, Row config, Schema dataSchema) {\n+      return new PubsubSchemaIO(location, config, dataSchema);\n+    }\n+\n+    @Override\n+    public Schema schema() {\n+      return dataSchema;\n+    }\n+\n+    @Override\n+    public PTransform<PBegin, PCollection<Row>> buildReader() {\n+      return new PTransform<PBegin, PCollection<Row>>() {\n+        @Override\n+        public PCollection<Row> expand(PBegin begin) {\n+          PCollectionTuple rowsWithDlq =\n+              begin\n+                  .apply(\"ReadFromPubsub\", readMessagesWithAttributes())\n+                  .apply(\n+                      \"PubsubMessageToRow\",\n+                      PubsubMessageToRow.builder()\n+                          .messageSchema(dataSchema)\n+                          .useDlq(useDlqCheck(config))\n+                          .useFlatSchema(useFlatSchema)\n+                          .build());\n+          rowsWithDlq.get(MAIN_TAG).setRowSchema(dataSchema);\n+\n+          if (useDlqCheck(config)) {\n+            rowsWithDlq.get(DLQ_TAG).apply(writeMessagesToDlq());\n+          }\n+\n+          return rowsWithDlq.get(MAIN_TAG);\n+        }\n+      };\n+    }\n+\n+    @Override\n+    public PTransform<PCollection<Row>, POutput> buildWriter() {\n+      if (!useFlatSchema) {\n+        throw new UnsupportedOperationException(\n+            \"Writing to a Pubsub topic is only supported for flattened schemas\");\n+      }\n+\n+      return new PTransform<PCollection<Row>, POutput>() {\n+        @Override\n+        public POutput expand(PCollection<Row> input) {\n+          return input\n+              .apply(RowToPubsubMessage.fromTableConfig(config, useFlatSchema))\n+              .apply(createPubsubMessageWrite());\n+        }\n+      };\n+    }\n+\n+    private PubsubIO.Read<PubsubMessage> readMessagesWithAttributes() {\n+      PubsubIO.Read<PubsubMessage> read = PubsubIO.readMessagesWithAttributes().fromTopic(location);\n+\n+      return useTimestampAttribute(config)\n+          ? read.withTimestampAttribute(config.getValue(\"timestampAttributeKey\"))\n+          : read;\n+    }\n+\n+    private PubsubIO.Write<PubsubMessage> createPubsubMessageWrite() {\n+      PubsubIO.Write<PubsubMessage> write = PubsubIO.writeMessages().to(location);\n+      if (useTimestampAttribute(config)) {\n+        write = write.withTimestampAttribute(config.getValue(\"timestampAttributeKey\"));\n+      }\n+      return write;\n+    }\n+\n+    private PubsubIO.Write<PubsubMessage> writeMessagesToDlq() {\n+      PubsubIO.Write<PubsubMessage> write =\n+          PubsubIO.writeMessages().to(config.getString(\"deadLetterQueue\"));\n+\n+      return useTimestampAttribute(config)\n+          ? write.withTimestampAttribute(config.getString(\"timestampAttributeKey\"))\n+          : write;\n+    }\n+\n+    private boolean useDlqCheck(Row config) {\n+      return config.getValue(\"deadLetterQueue\") != null;\n+    }\n+\n+    private boolean useTimestampAttribute(Row config) {\n+      return config.getValue(\"timestampAttributeKey\") != null;\n+    }\n+\n+    private boolean definesAttributeAndPayload(Schema schema) {\n+      return fieldPresent(\n+              schema, ATTRIBUTES_FIELD, Schema.FieldType.map(VARCHAR.withNullable(false), VARCHAR))\n+          && (schema.hasField(PAYLOAD_FIELD)\n+              && ROW.equals(schema.getField(PAYLOAD_FIELD).getType().getTypeName()));\n+    }\n+\n+    private static boolean fieldPresent(\n+        Schema schema, String field, Schema.FieldType expectedType) {\n+      return schema.hasField(field)\n+          && expectedType.equivalent(\n+              schema.getField(field).getType(), Schema.EquivalenceNullablePolicy.IGNORE);\n+    }\n+  }\n+\n+  /**\n+   * A {@link PTransform} to convert {@link Row} to {@link PubsubMessage} with JSON payload.\n+   *\n+   * <p>Currently only supports writing a flat schema into a JSON payload. This means that all Row\n+   * field values are written to the {@link PubsubMessage} JSON payload, except for {@code\n+   * event_timestamp}, which is either ignored or written to the message attributes, depending on\n+   * whether config.getValue(\"timestampAttributeKey\") is set.\n+   */\n+  private static class RowToPubsubMessage\n+      extends PTransform<PCollection<Row>, PCollection<PubsubMessage>> {\n+    private final Row config;\n+\n+    private RowToPubsubMessage(Row config, Boolean useFlatSchema) {\n+      checkArgument(useFlatSchema, \"RowToPubsubMessage is only supported for flattened schemas.\");\n+\n+      this.config = config;\n+    }\n+\n+    public static RowToPubsubMessage fromTableConfig(Row config, Boolean useFlatSchema) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0b1804967423a7d35cdbe99261133e44279bd5a3"}, "originalPosition": 237}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU4NzM4MQ==", "bodyText": "This constructor can just take 2 booleans instead (useTimestampAttribute and useFlatSchema), and the duplicate useTimestampAttribute() function at the end of the file can be removed.", "url": "https://github.com/apache/beam/pull/12090#discussion_r446587381", "createdAt": "2020-06-28T01:34:15Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsub/PubsubSchemaCapableIOProvider.java", "diffHunk": "@@ -0,0 +1,264 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsub;\n+\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.ATTRIBUTES_FIELD;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.DLQ_TAG;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.MAIN_TAG;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.PAYLOAD_FIELD;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.TIMESTAMP_FIELD;\n+import static org.apache.beam.sdk.schemas.Schema.TypeName.ROW;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+\n+import com.google.auto.service.AutoService;\n+import java.io.Serializable;\n+import java.nio.charset.StandardCharsets;\n+import org.apache.beam.sdk.annotations.Internal;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.schemas.Schema.FieldType;\n+import org.apache.beam.sdk.schemas.io.InvalidConfigurationException;\n+import org.apache.beam.sdk.schemas.io.SchemaCapableIOProvider;\n+import org.apache.beam.sdk.schemas.io.SchemaIO;\n+import org.apache.beam.sdk.schemas.transforms.DropFields;\n+import org.apache.beam.sdk.transforms.MapElements;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ToJson;\n+import org.apache.beam.sdk.transforms.WithTimestamps;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionTuple;\n+import org.apache.beam.sdk.values.POutput;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.sdk.values.TypeDescriptor;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * {@link org.apache.beam.sdk.schemas.io.SchemaCapableIOProvider} to create {@link PubsubSchemaIO}\n+ * that implements {@link org.apache.beam.sdk.schemas.io.SchemaIO}.\n+ */\n+@Internal\n+@AutoService(SchemaCapableIOProvider.class)\n+public class PubsubSchemaCapableIOProvider implements SchemaCapableIOProvider {\n+  public static final FieldType VARCHAR = FieldType.STRING;\n+  public static final FieldType TIMESTAMP = FieldType.DATETIME;\n+\n+  /** Returns an id that uniquely represents this IO. */\n+  @Override\n+  public String identifier() {\n+    return \"pubsub\";\n+  }\n+\n+  /**\n+   * Returns the expected schema of the configuration object. Note this is distinct from the schema\n+   * of the data source itself.\n+   */\n+  @Override\n+  public Schema configurationSchema() {\n+    return Schema.builder()\n+        .addNullableField(\"timestampAttributeKey\", FieldType.STRING)\n+        .addNullableField(\"deadLetterQueue\", FieldType.STRING)\n+        .build();\n+  }\n+\n+  /**\n+   * Produce a SchemaIO given a String representing the data's location, the schema of the data that\n+   * resides there, and some IO-specific configuration object.\n+   */\n+  @Override\n+  public PubsubSchemaIO from(String location, Row configuration, Schema dataSchema) {\n+    validateDlq(configuration.getValue(\"deadLetterQueue\"));\n+    validateEventTimestamp(dataSchema);\n+    return PubsubSchemaIO.withConfiguration(location, configuration, dataSchema);\n+  }\n+\n+  private void validateEventTimestamp(Schema schema) {\n+    if (!PubsubSchemaIO.fieldPresent(schema, TIMESTAMP_FIELD, TIMESTAMP)) {\n+      throw new InvalidConfigurationException(\n+          \"Unsupported schema specified for Pubsub source in CREATE TABLE.\"\n+              + \"CREATE TABLE for Pubsub topic must include at least 'event_timestamp' field of \"\n+              + \"type 'TIMESTAMP'\");\n+    }\n+  }\n+\n+  private void validateDlq(String deadLetterQueue) {\n+    if (deadLetterQueue != null && deadLetterQueue.isEmpty()) {\n+      throw new InvalidConfigurationException(\"Dead letter queue topic name is not specified\");\n+    }\n+  }\n+\n+  /** An abstraction to create schema aware IOs. */\n+  @Internal\n+  private static class PubsubSchemaIO implements SchemaIO, Serializable {\n+    protected final Row config;\n+    protected final Schema dataSchema;\n+    protected final String location;\n+    protected final Boolean useFlatSchema;\n+\n+    private PubsubSchemaIO(String location, Row config, Schema dataSchema) {\n+      this.config = config;\n+      this.dataSchema = dataSchema;\n+      this.location = location;\n+      this.useFlatSchema = !definesAttributeAndPayload(dataSchema);\n+    }\n+\n+    static PubsubSchemaIO withConfiguration(String location, Row config, Schema dataSchema) {\n+      return new PubsubSchemaIO(location, config, dataSchema);\n+    }\n+\n+    @Override\n+    public Schema schema() {\n+      return dataSchema;\n+    }\n+\n+    @Override\n+    public PTransform<PBegin, PCollection<Row>> buildReader() {\n+      return new PTransform<PBegin, PCollection<Row>>() {\n+        @Override\n+        public PCollection<Row> expand(PBegin begin) {\n+          PCollectionTuple rowsWithDlq =\n+              begin\n+                  .apply(\"ReadFromPubsub\", readMessagesWithAttributes())\n+                  .apply(\n+                      \"PubsubMessageToRow\",\n+                      PubsubMessageToRow.builder()\n+                          .messageSchema(dataSchema)\n+                          .useDlq(useDlqCheck(config))\n+                          .useFlatSchema(useFlatSchema)\n+                          .build());\n+          rowsWithDlq.get(MAIN_TAG).setRowSchema(dataSchema);\n+\n+          if (useDlqCheck(config)) {\n+            rowsWithDlq.get(DLQ_TAG).apply(writeMessagesToDlq());\n+          }\n+\n+          return rowsWithDlq.get(MAIN_TAG);\n+        }\n+      };\n+    }\n+\n+    @Override\n+    public PTransform<PCollection<Row>, POutput> buildWriter() {\n+      if (!useFlatSchema) {\n+        throw new UnsupportedOperationException(\n+            \"Writing to a Pubsub topic is only supported for flattened schemas\");\n+      }\n+\n+      return new PTransform<PCollection<Row>, POutput>() {\n+        @Override\n+        public POutput expand(PCollection<Row> input) {\n+          return input\n+              .apply(RowToPubsubMessage.fromTableConfig(config, useFlatSchema))\n+              .apply(createPubsubMessageWrite());\n+        }\n+      };\n+    }\n+\n+    private PubsubIO.Read<PubsubMessage> readMessagesWithAttributes() {\n+      PubsubIO.Read<PubsubMessage> read = PubsubIO.readMessagesWithAttributes().fromTopic(location);\n+\n+      return useTimestampAttribute(config)\n+          ? read.withTimestampAttribute(config.getValue(\"timestampAttributeKey\"))\n+          : read;\n+    }\n+\n+    private PubsubIO.Write<PubsubMessage> createPubsubMessageWrite() {\n+      PubsubIO.Write<PubsubMessage> write = PubsubIO.writeMessages().to(location);\n+      if (useTimestampAttribute(config)) {\n+        write = write.withTimestampAttribute(config.getValue(\"timestampAttributeKey\"));\n+      }\n+      return write;\n+    }\n+\n+    private PubsubIO.Write<PubsubMessage> writeMessagesToDlq() {\n+      PubsubIO.Write<PubsubMessage> write =\n+          PubsubIO.writeMessages().to(config.getString(\"deadLetterQueue\"));\n+\n+      return useTimestampAttribute(config)\n+          ? write.withTimestampAttribute(config.getString(\"timestampAttributeKey\"))\n+          : write;\n+    }\n+\n+    private boolean useDlqCheck(Row config) {\n+      return config.getValue(\"deadLetterQueue\") != null;\n+    }\n+\n+    private boolean useTimestampAttribute(Row config) {\n+      return config.getValue(\"timestampAttributeKey\") != null;\n+    }\n+\n+    private boolean definesAttributeAndPayload(Schema schema) {\n+      return fieldPresent(\n+              schema, ATTRIBUTES_FIELD, Schema.FieldType.map(VARCHAR.withNullable(false), VARCHAR))\n+          && (schema.hasField(PAYLOAD_FIELD)\n+              && ROW.equals(schema.getField(PAYLOAD_FIELD).getType().getTypeName()));\n+    }\n+\n+    private static boolean fieldPresent(\n+        Schema schema, String field, Schema.FieldType expectedType) {\n+      return schema.hasField(field)\n+          && expectedType.equivalent(\n+              schema.getField(field).getType(), Schema.EquivalenceNullablePolicy.IGNORE);\n+    }\n+  }\n+\n+  /**\n+   * A {@link PTransform} to convert {@link Row} to {@link PubsubMessage} with JSON payload.\n+   *\n+   * <p>Currently only supports writing a flat schema into a JSON payload. This means that all Row\n+   * field values are written to the {@link PubsubMessage} JSON payload, except for {@code\n+   * event_timestamp}, which is either ignored or written to the message attributes, depending on\n+   * whether config.getValue(\"timestampAttributeKey\") is set.\n+   */\n+  private static class RowToPubsubMessage\n+      extends PTransform<PCollection<Row>, PCollection<PubsubMessage>> {\n+    private final Row config;\n+\n+    private RowToPubsubMessage(Row config, Boolean useFlatSchema) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0b1804967423a7d35cdbe99261133e44279bd5a3"}, "originalPosition": 231}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU4NzQ1Nw==", "bodyText": "Consider defining a constant for event_timestamp?", "url": "https://github.com/apache/beam/pull/12090#discussion_r446587457", "createdAt": "2020-06-28T01:35:11Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsub/PubsubSchemaCapableIOProvider.java", "diffHunk": "@@ -0,0 +1,264 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsub;\n+\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.ATTRIBUTES_FIELD;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.DLQ_TAG;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.MAIN_TAG;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.PAYLOAD_FIELD;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.TIMESTAMP_FIELD;\n+import static org.apache.beam.sdk.schemas.Schema.TypeName.ROW;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+\n+import com.google.auto.service.AutoService;\n+import java.io.Serializable;\n+import java.nio.charset.StandardCharsets;\n+import org.apache.beam.sdk.annotations.Internal;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.schemas.Schema.FieldType;\n+import org.apache.beam.sdk.schemas.io.InvalidConfigurationException;\n+import org.apache.beam.sdk.schemas.io.SchemaCapableIOProvider;\n+import org.apache.beam.sdk.schemas.io.SchemaIO;\n+import org.apache.beam.sdk.schemas.transforms.DropFields;\n+import org.apache.beam.sdk.transforms.MapElements;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ToJson;\n+import org.apache.beam.sdk.transforms.WithTimestamps;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionTuple;\n+import org.apache.beam.sdk.values.POutput;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.sdk.values.TypeDescriptor;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * {@link org.apache.beam.sdk.schemas.io.SchemaCapableIOProvider} to create {@link PubsubSchemaIO}\n+ * that implements {@link org.apache.beam.sdk.schemas.io.SchemaIO}.\n+ */\n+@Internal\n+@AutoService(SchemaCapableIOProvider.class)\n+public class PubsubSchemaCapableIOProvider implements SchemaCapableIOProvider {\n+  public static final FieldType VARCHAR = FieldType.STRING;\n+  public static final FieldType TIMESTAMP = FieldType.DATETIME;\n+\n+  /** Returns an id that uniquely represents this IO. */\n+  @Override\n+  public String identifier() {\n+    return \"pubsub\";\n+  }\n+\n+  /**\n+   * Returns the expected schema of the configuration object. Note this is distinct from the schema\n+   * of the data source itself.\n+   */\n+  @Override\n+  public Schema configurationSchema() {\n+    return Schema.builder()\n+        .addNullableField(\"timestampAttributeKey\", FieldType.STRING)\n+        .addNullableField(\"deadLetterQueue\", FieldType.STRING)\n+        .build();\n+  }\n+\n+  /**\n+   * Produce a SchemaIO given a String representing the data's location, the schema of the data that\n+   * resides there, and some IO-specific configuration object.\n+   */\n+  @Override\n+  public PubsubSchemaIO from(String location, Row configuration, Schema dataSchema) {\n+    validateDlq(configuration.getValue(\"deadLetterQueue\"));\n+    validateEventTimestamp(dataSchema);\n+    return PubsubSchemaIO.withConfiguration(location, configuration, dataSchema);\n+  }\n+\n+  private void validateEventTimestamp(Schema schema) {\n+    if (!PubsubSchemaIO.fieldPresent(schema, TIMESTAMP_FIELD, TIMESTAMP)) {\n+      throw new InvalidConfigurationException(\n+          \"Unsupported schema specified for Pubsub source in CREATE TABLE.\"\n+              + \"CREATE TABLE for Pubsub topic must include at least 'event_timestamp' field of \"\n+              + \"type 'TIMESTAMP'\");\n+    }\n+  }\n+\n+  private void validateDlq(String deadLetterQueue) {\n+    if (deadLetterQueue != null && deadLetterQueue.isEmpty()) {\n+      throw new InvalidConfigurationException(\"Dead letter queue topic name is not specified\");\n+    }\n+  }\n+\n+  /** An abstraction to create schema aware IOs. */\n+  @Internal\n+  private static class PubsubSchemaIO implements SchemaIO, Serializable {\n+    protected final Row config;\n+    protected final Schema dataSchema;\n+    protected final String location;\n+    protected final Boolean useFlatSchema;\n+\n+    private PubsubSchemaIO(String location, Row config, Schema dataSchema) {\n+      this.config = config;\n+      this.dataSchema = dataSchema;\n+      this.location = location;\n+      this.useFlatSchema = !definesAttributeAndPayload(dataSchema);\n+    }\n+\n+    static PubsubSchemaIO withConfiguration(String location, Row config, Schema dataSchema) {\n+      return new PubsubSchemaIO(location, config, dataSchema);\n+    }\n+\n+    @Override\n+    public Schema schema() {\n+      return dataSchema;\n+    }\n+\n+    @Override\n+    public PTransform<PBegin, PCollection<Row>> buildReader() {\n+      return new PTransform<PBegin, PCollection<Row>>() {\n+        @Override\n+        public PCollection<Row> expand(PBegin begin) {\n+          PCollectionTuple rowsWithDlq =\n+              begin\n+                  .apply(\"ReadFromPubsub\", readMessagesWithAttributes())\n+                  .apply(\n+                      \"PubsubMessageToRow\",\n+                      PubsubMessageToRow.builder()\n+                          .messageSchema(dataSchema)\n+                          .useDlq(useDlqCheck(config))\n+                          .useFlatSchema(useFlatSchema)\n+                          .build());\n+          rowsWithDlq.get(MAIN_TAG).setRowSchema(dataSchema);\n+\n+          if (useDlqCheck(config)) {\n+            rowsWithDlq.get(DLQ_TAG).apply(writeMessagesToDlq());\n+          }\n+\n+          return rowsWithDlq.get(MAIN_TAG);\n+        }\n+      };\n+    }\n+\n+    @Override\n+    public PTransform<PCollection<Row>, POutput> buildWriter() {\n+      if (!useFlatSchema) {\n+        throw new UnsupportedOperationException(\n+            \"Writing to a Pubsub topic is only supported for flattened schemas\");\n+      }\n+\n+      return new PTransform<PCollection<Row>, POutput>() {\n+        @Override\n+        public POutput expand(PCollection<Row> input) {\n+          return input\n+              .apply(RowToPubsubMessage.fromTableConfig(config, useFlatSchema))\n+              .apply(createPubsubMessageWrite());\n+        }\n+      };\n+    }\n+\n+    private PubsubIO.Read<PubsubMessage> readMessagesWithAttributes() {\n+      PubsubIO.Read<PubsubMessage> read = PubsubIO.readMessagesWithAttributes().fromTopic(location);\n+\n+      return useTimestampAttribute(config)\n+          ? read.withTimestampAttribute(config.getValue(\"timestampAttributeKey\"))\n+          : read;\n+    }\n+\n+    private PubsubIO.Write<PubsubMessage> createPubsubMessageWrite() {\n+      PubsubIO.Write<PubsubMessage> write = PubsubIO.writeMessages().to(location);\n+      if (useTimestampAttribute(config)) {\n+        write = write.withTimestampAttribute(config.getValue(\"timestampAttributeKey\"));\n+      }\n+      return write;\n+    }\n+\n+    private PubsubIO.Write<PubsubMessage> writeMessagesToDlq() {\n+      PubsubIO.Write<PubsubMessage> write =\n+          PubsubIO.writeMessages().to(config.getString(\"deadLetterQueue\"));\n+\n+      return useTimestampAttribute(config)\n+          ? write.withTimestampAttribute(config.getString(\"timestampAttributeKey\"))\n+          : write;\n+    }\n+\n+    private boolean useDlqCheck(Row config) {\n+      return config.getValue(\"deadLetterQueue\") != null;\n+    }\n+\n+    private boolean useTimestampAttribute(Row config) {\n+      return config.getValue(\"timestampAttributeKey\") != null;\n+    }\n+\n+    private boolean definesAttributeAndPayload(Schema schema) {\n+      return fieldPresent(\n+              schema, ATTRIBUTES_FIELD, Schema.FieldType.map(VARCHAR.withNullable(false), VARCHAR))\n+          && (schema.hasField(PAYLOAD_FIELD)\n+              && ROW.equals(schema.getField(PAYLOAD_FIELD).getType().getTypeName()));\n+    }\n+\n+    private static boolean fieldPresent(\n+        Schema schema, String field, Schema.FieldType expectedType) {\n+      return schema.hasField(field)\n+          && expectedType.equivalent(\n+              schema.getField(field).getType(), Schema.EquivalenceNullablePolicy.IGNORE);\n+    }\n+  }\n+\n+  /**\n+   * A {@link PTransform} to convert {@link Row} to {@link PubsubMessage} with JSON payload.\n+   *\n+   * <p>Currently only supports writing a flat schema into a JSON payload. This means that all Row\n+   * field values are written to the {@link PubsubMessage} JSON payload, except for {@code\n+   * event_timestamp}, which is either ignored or written to the message attributes, depending on\n+   * whether config.getValue(\"timestampAttributeKey\") is set.\n+   */\n+  private static class RowToPubsubMessage\n+      extends PTransform<PCollection<Row>, PCollection<PubsubMessage>> {\n+    private final Row config;\n+\n+    private RowToPubsubMessage(Row config, Boolean useFlatSchema) {\n+      checkArgument(useFlatSchema, \"RowToPubsubMessage is only supported for flattened schemas.\");\n+\n+      this.config = config;\n+    }\n+\n+    public static RowToPubsubMessage fromTableConfig(Row config, Boolean useFlatSchema) {\n+      return new RowToPubsubMessage(config, useFlatSchema);\n+    }\n+\n+    @Override\n+    public PCollection<PubsubMessage> expand(PCollection<Row> input) {\n+      PCollection<Row> withTimestamp =\n+          (useTimestampAttribute(config))\n+              ? input.apply(\n+                  WithTimestamps.of((row) -> row.getDateTime(\"event_timestamp\").toInstant()))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0b1804967423a7d35cdbe99261133e44279bd5a3"}, "originalPosition": 246}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU4NzUzMw==", "bodyText": "Consider moving PubsubMessageToRow into this file as a inner class as well?", "url": "https://github.com/apache/beam/pull/12090#discussion_r446587533", "createdAt": "2020-06-28T01:36:31Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsub/PubsubSchemaCapableIOProvider.java", "diffHunk": "@@ -0,0 +1,264 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsub;\n+\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.ATTRIBUTES_FIELD;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.DLQ_TAG;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.MAIN_TAG;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.PAYLOAD_FIELD;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.TIMESTAMP_FIELD;\n+import static org.apache.beam.sdk.schemas.Schema.TypeName.ROW;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+\n+import com.google.auto.service.AutoService;\n+import java.io.Serializable;\n+import java.nio.charset.StandardCharsets;\n+import org.apache.beam.sdk.annotations.Internal;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.schemas.Schema.FieldType;\n+import org.apache.beam.sdk.schemas.io.InvalidConfigurationException;\n+import org.apache.beam.sdk.schemas.io.SchemaCapableIOProvider;\n+import org.apache.beam.sdk.schemas.io.SchemaIO;\n+import org.apache.beam.sdk.schemas.transforms.DropFields;\n+import org.apache.beam.sdk.transforms.MapElements;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ToJson;\n+import org.apache.beam.sdk.transforms.WithTimestamps;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionTuple;\n+import org.apache.beam.sdk.values.POutput;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.sdk.values.TypeDescriptor;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * {@link org.apache.beam.sdk.schemas.io.SchemaCapableIOProvider} to create {@link PubsubSchemaIO}\n+ * that implements {@link org.apache.beam.sdk.schemas.io.SchemaIO}.\n+ */\n+@Internal\n+@AutoService(SchemaCapableIOProvider.class)\n+public class PubsubSchemaCapableIOProvider implements SchemaCapableIOProvider {\n+  public static final FieldType VARCHAR = FieldType.STRING;\n+  public static final FieldType TIMESTAMP = FieldType.DATETIME;\n+\n+  /** Returns an id that uniquely represents this IO. */\n+  @Override\n+  public String identifier() {\n+    return \"pubsub\";\n+  }\n+\n+  /**\n+   * Returns the expected schema of the configuration object. Note this is distinct from the schema\n+   * of the data source itself.\n+   */\n+  @Override\n+  public Schema configurationSchema() {\n+    return Schema.builder()\n+        .addNullableField(\"timestampAttributeKey\", FieldType.STRING)\n+        .addNullableField(\"deadLetterQueue\", FieldType.STRING)\n+        .build();\n+  }\n+\n+  /**\n+   * Produce a SchemaIO given a String representing the data's location, the schema of the data that\n+   * resides there, and some IO-specific configuration object.\n+   */\n+  @Override\n+  public PubsubSchemaIO from(String location, Row configuration, Schema dataSchema) {\n+    validateDlq(configuration.getValue(\"deadLetterQueue\"));\n+    validateEventTimestamp(dataSchema);\n+    return PubsubSchemaIO.withConfiguration(location, configuration, dataSchema);\n+  }\n+\n+  private void validateEventTimestamp(Schema schema) {\n+    if (!PubsubSchemaIO.fieldPresent(schema, TIMESTAMP_FIELD, TIMESTAMP)) {\n+      throw new InvalidConfigurationException(\n+          \"Unsupported schema specified for Pubsub source in CREATE TABLE.\"\n+              + \"CREATE TABLE for Pubsub topic must include at least 'event_timestamp' field of \"\n+              + \"type 'TIMESTAMP'\");\n+    }\n+  }\n+\n+  private void validateDlq(String deadLetterQueue) {\n+    if (deadLetterQueue != null && deadLetterQueue.isEmpty()) {\n+      throw new InvalidConfigurationException(\"Dead letter queue topic name is not specified\");\n+    }\n+  }\n+\n+  /** An abstraction to create schema aware IOs. */\n+  @Internal\n+  private static class PubsubSchemaIO implements SchemaIO, Serializable {\n+    protected final Row config;\n+    protected final Schema dataSchema;\n+    protected final String location;\n+    protected final Boolean useFlatSchema;\n+\n+    private PubsubSchemaIO(String location, Row config, Schema dataSchema) {\n+      this.config = config;\n+      this.dataSchema = dataSchema;\n+      this.location = location;\n+      this.useFlatSchema = !definesAttributeAndPayload(dataSchema);\n+    }\n+\n+    static PubsubSchemaIO withConfiguration(String location, Row config, Schema dataSchema) {\n+      return new PubsubSchemaIO(location, config, dataSchema);\n+    }\n+\n+    @Override\n+    public Schema schema() {\n+      return dataSchema;\n+    }\n+\n+    @Override\n+    public PTransform<PBegin, PCollection<Row>> buildReader() {\n+      return new PTransform<PBegin, PCollection<Row>>() {\n+        @Override\n+        public PCollection<Row> expand(PBegin begin) {\n+          PCollectionTuple rowsWithDlq =\n+              begin\n+                  .apply(\"ReadFromPubsub\", readMessagesWithAttributes())\n+                  .apply(\n+                      \"PubsubMessageToRow\",\n+                      PubsubMessageToRow.builder()\n+                          .messageSchema(dataSchema)\n+                          .useDlq(useDlqCheck(config))\n+                          .useFlatSchema(useFlatSchema)\n+                          .build());\n+          rowsWithDlq.get(MAIN_TAG).setRowSchema(dataSchema);\n+\n+          if (useDlqCheck(config)) {\n+            rowsWithDlq.get(DLQ_TAG).apply(writeMessagesToDlq());\n+          }\n+\n+          return rowsWithDlq.get(MAIN_TAG);\n+        }\n+      };\n+    }\n+\n+    @Override\n+    public PTransform<PCollection<Row>, POutput> buildWriter() {\n+      if (!useFlatSchema) {\n+        throw new UnsupportedOperationException(\n+            \"Writing to a Pubsub topic is only supported for flattened schemas\");\n+      }\n+\n+      return new PTransform<PCollection<Row>, POutput>() {\n+        @Override\n+        public POutput expand(PCollection<Row> input) {\n+          return input\n+              .apply(RowToPubsubMessage.fromTableConfig(config, useFlatSchema))\n+              .apply(createPubsubMessageWrite());\n+        }\n+      };\n+    }\n+\n+    private PubsubIO.Read<PubsubMessage> readMessagesWithAttributes() {\n+      PubsubIO.Read<PubsubMessage> read = PubsubIO.readMessagesWithAttributes().fromTopic(location);\n+\n+      return useTimestampAttribute(config)\n+          ? read.withTimestampAttribute(config.getValue(\"timestampAttributeKey\"))\n+          : read;\n+    }\n+\n+    private PubsubIO.Write<PubsubMessage> createPubsubMessageWrite() {\n+      PubsubIO.Write<PubsubMessage> write = PubsubIO.writeMessages().to(location);\n+      if (useTimestampAttribute(config)) {\n+        write = write.withTimestampAttribute(config.getValue(\"timestampAttributeKey\"));\n+      }\n+      return write;\n+    }\n+\n+    private PubsubIO.Write<PubsubMessage> writeMessagesToDlq() {\n+      PubsubIO.Write<PubsubMessage> write =\n+          PubsubIO.writeMessages().to(config.getString(\"deadLetterQueue\"));\n+\n+      return useTimestampAttribute(config)\n+          ? write.withTimestampAttribute(config.getString(\"timestampAttributeKey\"))\n+          : write;\n+    }\n+\n+    private boolean useDlqCheck(Row config) {\n+      return config.getValue(\"deadLetterQueue\") != null;\n+    }\n+\n+    private boolean useTimestampAttribute(Row config) {\n+      return config.getValue(\"timestampAttributeKey\") != null;\n+    }\n+\n+    private boolean definesAttributeAndPayload(Schema schema) {\n+      return fieldPresent(\n+              schema, ATTRIBUTES_FIELD, Schema.FieldType.map(VARCHAR.withNullable(false), VARCHAR))\n+          && (schema.hasField(PAYLOAD_FIELD)\n+              && ROW.equals(schema.getField(PAYLOAD_FIELD).getType().getTypeName()));\n+    }\n+\n+    private static boolean fieldPresent(\n+        Schema schema, String field, Schema.FieldType expectedType) {\n+      return schema.hasField(field)\n+          && expectedType.equivalent(\n+              schema.getField(field).getType(), Schema.EquivalenceNullablePolicy.IGNORE);\n+    }\n+  }\n+\n+  /**\n+   * A {@link PTransform} to convert {@link Row} to {@link PubsubMessage} with JSON payload.\n+   *\n+   * <p>Currently only supports writing a flat schema into a JSON payload. This means that all Row\n+   * field values are written to the {@link PubsubMessage} JSON payload, except for {@code\n+   * event_timestamp}, which is either ignored or written to the message attributes, depending on\n+   * whether config.getValue(\"timestampAttributeKey\") is set.\n+   */\n+  private static class RowToPubsubMessage", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0b1804967423a7d35cdbe99261133e44279bd5a3"}, "originalPosition": 227}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM5NTc5MjI3", "url": "https://github.com/apache/beam/pull/12090#pullrequestreview-439579227", "createdAt": "2020-06-29T23:58:46Z", "commit": {"oid": "75f57c811b95325350f2bd278614759ede414a29"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yOVQyMzo1ODo0NlrOGqmnSQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yOVQyMzo1ODo0NlrOGqmnSQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NzMyNjAyNQ==", "bodyText": "This should have a meaningful message like \"Failed to re-parse TBLPROPERTIES JSON\", and it would be good to include the JSON string that caused the issue: tableProperties.toString()", "url": "https://github.com/apache/beam/pull/12090#discussion_r447326025", "createdAt": "2020-06-29T23:58:46Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/pubsub/PubsubJsonTableProvider.java", "diffHunk": "@@ -54,125 +52,27 @@ public String getTableType() {\n   }\n \n   @Override\n-  public BeamSqlTable buildBeamSqlTable(Table tableDefintion) {\n-    JSONObject tableProperties = tableDefintion.getProperties();\n-    String timestampAttributeKey = tableProperties.getString(\"timestampAttributeKey\");\n-    String deadLetterQueue = tableProperties.getString(\"deadLetterQueue\");\n-    validateDlq(deadLetterQueue);\n-\n-    Schema schema = tableDefintion.getSchema();\n-    validateEventTimestamp(schema);\n-\n-    PubsubIOTableConfiguration config =\n-        PubsubIOTableConfiguration.builder()\n-            .setSchema(schema)\n-            .setTimestampAttribute(timestampAttributeKey)\n-            .setDeadLetterQueue(deadLetterQueue)\n-            .setTopic(tableDefintion.getLocation())\n-            .setUseFlatSchema(!definesAttributeAndPayload(schema))\n-            .build();\n-\n-    return PubsubIOJsonTable.withConfiguration(config);\n-  }\n-\n-  private void validateEventTimestamp(Schema schema) {\n-    if (!fieldPresent(schema, TIMESTAMP_FIELD, TIMESTAMP)) {\n-      throw new InvalidTableException(\n-          \"Unsupported schema specified for Pubsub source in CREATE TABLE.\"\n-              + \"CREATE TABLE for Pubsub topic must include at least 'event_timestamp' field of \"\n-              + \"type 'TIMESTAMP'\");\n-    }\n-  }\n-\n-  private boolean definesAttributeAndPayload(Schema schema) {\n-    return fieldPresent(\n-            schema, ATTRIBUTES_FIELD, Schema.FieldType.map(VARCHAR.withNullable(false), VARCHAR))\n-        && (schema.hasField(PAYLOAD_FIELD)\n-            && ROW.equals(schema.getField(PAYLOAD_FIELD).getType().getTypeName()));\n-  }\n-\n-  private boolean fieldPresent(Schema schema, String field, Schema.FieldType expectedType) {\n-    return schema.hasField(field)\n-        && expectedType.equivalent(\n-            schema.getField(field).getType(), Schema.EquivalenceNullablePolicy.IGNORE);\n-  }\n-\n-  private void validateDlq(String deadLetterQueue) {\n-    if (deadLetterQueue != null && deadLetterQueue.isEmpty()) {\n-      throw new InvalidTableException(\"Dead letter queue topic name is not specified\");\n-    }\n-  }\n-\n-  @AutoValue\n-  public abstract static class PubsubIOTableConfiguration implements Serializable {\n-    public boolean useDlq() {\n-      return getDeadLetterQueue() != null;\n-    }\n-\n-    public boolean useTimestampAttribute() {\n-      return getTimestampAttribute() != null;\n-    }\n-\n-    /** Determines whether or not the messages should be represented with a flattened schema. */\n-    abstract boolean getUseFlatSchema();\n-\n-    /**\n-     * Optional attribute key of the Pubsub message from which to extract the event timestamp.\n-     *\n-     * <p>This attribute has to conform to the same requirements as in {@link\n-     * PubsubIO.Read.Builder#withTimestampAttribute}.\n-     *\n-     * <p>Short version: it has to be either millis since epoch or string in RFC 3339 format.\n-     *\n-     * <p>If the attribute is specified then event timestamps will be extracted from the specified\n-     * attribute. If it is not specified then message publish timestamp will be used.\n-     */\n-    @Nullable\n-    abstract String getTimestampAttribute();\n-\n-    /**\n-     * Optional topic path which will be used as a dead letter queue.\n-     *\n-     * <p>Messages that cannot be processed will be sent to this topic. If it is not specified then\n-     * exception will be thrown for errors during processing causing the pipeline to crash.\n-     */\n-    @Nullable\n-    abstract String getDeadLetterQueue();\n-\n-    /**\n-     * Pubsub topic name.\n-     *\n-     * <p>Topic is the only way to specify the Pubsub source. Explicitly specifying the subscription\n-     * is not supported at the moment. Subscriptions are automatically created (but not deleted).\n-     */\n-    abstract String getTopic();\n-\n-    /**\n-     * Table schema, describes Pubsub message schema.\n-     *\n-     * <p>If {@link #getUseFlatSchema()} is not set, schema must contain exactly fields\n-     * 'event_timestamp', 'attributes, and 'payload'. Else, it must contain just 'event_timestamp'.\n-     * See {@linkA PubsubMessageToRow} for details.\n-     */\n-    public abstract Schema getSchema();\n-\n-    static Builder builder() {\n-      return new AutoValue_PubsubJsonTableProvider_PubsubIOTableConfiguration.Builder();\n-    }\n-\n-    @AutoValue.Builder\n-    abstract static class Builder {\n-      abstract Builder setUseFlatSchema(boolean useFlatSchema);\n-\n-      abstract Builder setSchema(Schema schema);\n-\n-      abstract Builder setTimestampAttribute(String timestampAttribute);\n-\n-      abstract Builder setDeadLetterQueue(String deadLetterQueue);\n-\n-      abstract Builder setTopic(String topic);\n-\n-      abstract PubsubIOTableConfiguration build();\n+  public BeamSqlTable buildBeamSqlTable(Table tableDefinition) {\n+    JSONObject tableProperties = tableDefinition.getProperties();\n+    PubsubSchemaCapableIOProvider ioProvider = new PubsubSchemaCapableIOProvider();\n+\n+    try {\n+      RowJsonDeserializer deserializer =\n+          RowJsonDeserializer.forSchema(ioProvider.configurationSchema())\n+              .withMissingFieldBehavior(RowJsonDeserializer.MissingFieldBehavior.ALLOW_MISSING);\n+\n+      Row configurationRow =\n+          newObjectMapperWith(deserializer).readValue(tableProperties.toString(), Row.class);\n+\n+      SchemaIO pubsubSchemaIO =\n+          ioProvider.from(\n+              tableDefinition.getLocation(), configurationRow, tableDefinition.getSchema());\n+\n+      return PubsubIOJsonTable.fromSchemaIO(pubsubSchemaIO);\n+    } catch (InvalidConfigurationException | InvalidSchemaException e) {\n+      throw new InvalidTableException(e.getMessage());\n+    } catch (JsonProcessingException e) {\n+      throw new AssertionError();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "75f57c811b95325350f2bd278614759ede414a29"}, "originalPosition": 178}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "88989e9dfa196d2adb519b865816c1c29b18db6d", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/88989e9dfa196d2adb519b865816c1c29b18db6d", "committedDate": "2020-07-01T16:39:36Z", "message": "Added schema aware abstraction SchemaIO and implemented for pubsub"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "577e490e509620d5202a17216a044c1f8bc886a0", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/577e490e509620d5202a17216a044c1f8bc886a0", "committedDate": "2020-07-01T16:39:36Z", "message": "pubsubSchemaCapableIOProvider subclasses rather than external classes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fbad1e4ea46ccaada5e409125eb71ec8acf1e88e", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/fbad1e4ea46ccaada5e409125eb71ec8acf1e88e", "committedDate": "2020-07-01T16:39:37Z", "message": "spotless and checkstyle"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ae0b0f904ea6572d33d040b81d4b430bfca60529", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/ae0b0f904ea6572d33d040b81d4b430bfca60529", "committedDate": "2020-07-01T16:40:10Z", "message": "Added documentation for SchemaIO interfaces"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8f665fbaf6483be95952b4605808472dd6de0dcc", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/8f665fbaf6483be95952b4605808472dd6de0dcc", "committedDate": "2020-07-01T16:40:28Z", "message": "Removed hardcoded configuration details from PubsubJsonTableProvider"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ba6464fbe5175e7900cfc263e52067f1a46290a2", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/ba6464fbe5175e7900cfc263e52067f1a46290a2", "committedDate": "2020-07-01T16:40:29Z", "message": "Added description to PubsubJsonTableProvider JsonProcessingException"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "89fdf7a843a3a480f361a17b39aecdd36f388daf", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/89fdf7a843a3a480f361a17b39aecdd36f388daf", "committedDate": "2020-06-30T13:29:13Z", "message": "Added description to PubsubJsonTableProvider JsonProcessingException"}, "afterCommit": {"oid": "ba6464fbe5175e7900cfc263e52067f1a46290a2", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/ba6464fbe5175e7900cfc263e52067f1a46290a2", "committedDate": "2020-07-01T16:40:29Z", "message": "Added description to PubsubJsonTableProvider JsonProcessingException"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6ac8bf56fd2b229d2e7ad62b5594c8d754c36bc0", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/6ac8bf56fd2b229d2e7ad62b5594c8d754c36bc0", "committedDate": "2020-07-01T19:25:16Z", "message": "Resolved RowJsonDeserializer conflicts"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQxMjY1OTk0", "url": "https://github.com/apache/beam/pull/12090#pullrequestreview-441265994", "createdAt": "2020-07-01T23:58:08Z", "commit": {"oid": "6ac8bf56fd2b229d2e7ad62b5594c8d754c36bc0"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQyMzo1ODowOFrOGr4-bQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMlQwMDozODoyMVrOGr5ncw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODY3NTQzNw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            /** Unit tests for {@link org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow}. */\n          \n          \n            \n            /** Unit tests for {@link PubsubMessageToRow}. */\n          \n      \n    \n    \n  \n\nnit: IntelliJ probably did this automatically when PubsubMessageToRow was temporarily in a different package. Just the class name should be fine.", "url": "https://github.com/apache/beam/pull/12090#discussion_r448675437", "createdAt": "2020-07-01T23:58:08Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/io/gcp/pubsub/PubsubMessageToRowTest.java", "diffHunk": "@@ -48,7 +47,7 @@\n import org.junit.Rule;\n import org.junit.Test;\n \n-/** Unit tests for {@link PubsubMessageToRow}. */\n+/** Unit tests for {@link org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow}. */", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6ac8bf56fd2b229d2e7ad62b5594c8d754c36bc0"}, "originalPosition": 30}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODY3Njg1Mg==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n             * {@link SchemaCapableIOProvider} to create {@link PubsubSchemaIO} that implements {@link\n          \n          \n            \n             * SchemaIO}.\n          \n          \n            \n             * An implementation of {@link SchemaCapableIOProvider} for reading and writing JSON payloads\n          \n          \n            \n             * with {@link PubsubIO}.", "url": "https://github.com/apache/beam/pull/12090#discussion_r448676852", "createdAt": "2020-07-02T00:03:28Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsub/PubsubSchemaCapableIOProvider.java", "diffHunk": "@@ -0,0 +1,286 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsub;\n+\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.ATTRIBUTES_FIELD;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.DLQ_TAG;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.MAIN_TAG;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.PAYLOAD_FIELD;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.TIMESTAMP_FIELD;\n+import static org.apache.beam.sdk.schemas.Schema.TypeName.ROW;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+\n+import com.google.auto.service.AutoService;\n+import java.io.Serializable;\n+import java.nio.charset.StandardCharsets;\n+import org.apache.beam.sdk.annotations.Internal;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.schemas.Schema.FieldType;\n+import org.apache.beam.sdk.schemas.io.InvalidConfigurationException;\n+import org.apache.beam.sdk.schemas.io.InvalidSchemaException;\n+import org.apache.beam.sdk.schemas.io.SchemaCapableIOProvider;\n+import org.apache.beam.sdk.schemas.io.SchemaIO;\n+import org.apache.beam.sdk.schemas.transforms.DropFields;\n+import org.apache.beam.sdk.transforms.MapElements;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ToJson;\n+import org.apache.beam.sdk.transforms.WithTimestamps;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionTuple;\n+import org.apache.beam.sdk.values.POutput;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.sdk.values.TypeDescriptor;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * {@link SchemaCapableIOProvider} to create {@link PubsubSchemaIO} that implements {@link\n+ * SchemaIO}.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6ac8bf56fd2b229d2e7ad62b5594c8d754c36bc0"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODY3OTQ4MA==", "bodyText": "Yeah I think it makes sense to keep this separate and package-private, it will minimize the diff as well since it's just a file  rename.\nSorry for the churn Scott, could you move this back into it's own class?", "url": "https://github.com/apache/beam/pull/12090#discussion_r448679480", "createdAt": "2020-07-02T00:13:34Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsub/PubsubSchemaCapableIOProvider.java", "diffHunk": "@@ -0,0 +1,264 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsub;\n+\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.ATTRIBUTES_FIELD;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.DLQ_TAG;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.MAIN_TAG;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.PAYLOAD_FIELD;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.TIMESTAMP_FIELD;\n+import static org.apache.beam.sdk.schemas.Schema.TypeName.ROW;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+\n+import com.google.auto.service.AutoService;\n+import java.io.Serializable;\n+import java.nio.charset.StandardCharsets;\n+import org.apache.beam.sdk.annotations.Internal;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.schemas.Schema.FieldType;\n+import org.apache.beam.sdk.schemas.io.InvalidConfigurationException;\n+import org.apache.beam.sdk.schemas.io.SchemaCapableIOProvider;\n+import org.apache.beam.sdk.schemas.io.SchemaIO;\n+import org.apache.beam.sdk.schemas.transforms.DropFields;\n+import org.apache.beam.sdk.transforms.MapElements;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ToJson;\n+import org.apache.beam.sdk.transforms.WithTimestamps;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionTuple;\n+import org.apache.beam.sdk.values.POutput;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.sdk.values.TypeDescriptor;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * {@link org.apache.beam.sdk.schemas.io.SchemaCapableIOProvider} to create {@link PubsubSchemaIO}\n+ * that implements {@link org.apache.beam.sdk.schemas.io.SchemaIO}.\n+ */\n+@Internal\n+@AutoService(SchemaCapableIOProvider.class)\n+public class PubsubSchemaCapableIOProvider implements SchemaCapableIOProvider {\n+  public static final FieldType VARCHAR = FieldType.STRING;\n+  public static final FieldType TIMESTAMP = FieldType.DATETIME;\n+\n+  /** Returns an id that uniquely represents this IO. */\n+  @Override\n+  public String identifier() {\n+    return \"pubsub\";\n+  }\n+\n+  /**\n+   * Returns the expected schema of the configuration object. Note this is distinct from the schema\n+   * of the data source itself.\n+   */\n+  @Override\n+  public Schema configurationSchema() {\n+    return Schema.builder()\n+        .addNullableField(\"timestampAttributeKey\", FieldType.STRING)\n+        .addNullableField(\"deadLetterQueue\", FieldType.STRING)\n+        .build();\n+  }\n+\n+  /**\n+   * Produce a SchemaIO given a String representing the data's location, the schema of the data that\n+   * resides there, and some IO-specific configuration object.\n+   */\n+  @Override\n+  public PubsubSchemaIO from(String location, Row configuration, Schema dataSchema) {\n+    validateDlq(configuration.getValue(\"deadLetterQueue\"));\n+    validateEventTimestamp(dataSchema);\n+    return PubsubSchemaIO.withConfiguration(location, configuration, dataSchema);\n+  }\n+\n+  private void validateEventTimestamp(Schema schema) {\n+    if (!PubsubSchemaIO.fieldPresent(schema, TIMESTAMP_FIELD, TIMESTAMP)) {\n+      throw new InvalidConfigurationException(\n+          \"Unsupported schema specified for Pubsub source in CREATE TABLE.\"\n+              + \"CREATE TABLE for Pubsub topic must include at least 'event_timestamp' field of \"\n+              + \"type 'TIMESTAMP'\");\n+    }\n+  }\n+\n+  private void validateDlq(String deadLetterQueue) {\n+    if (deadLetterQueue != null && deadLetterQueue.isEmpty()) {\n+      throw new InvalidConfigurationException(\"Dead letter queue topic name is not specified\");\n+    }\n+  }\n+\n+  /** An abstraction to create schema aware IOs. */\n+  @Internal\n+  private static class PubsubSchemaIO implements SchemaIO, Serializable {\n+    protected final Row config;\n+    protected final Schema dataSchema;\n+    protected final String location;\n+    protected final Boolean useFlatSchema;\n+\n+    private PubsubSchemaIO(String location, Row config, Schema dataSchema) {\n+      this.config = config;\n+      this.dataSchema = dataSchema;\n+      this.location = location;\n+      this.useFlatSchema = !definesAttributeAndPayload(dataSchema);\n+    }\n+\n+    static PubsubSchemaIO withConfiguration(String location, Row config, Schema dataSchema) {\n+      return new PubsubSchemaIO(location, config, dataSchema);\n+    }\n+\n+    @Override\n+    public Schema schema() {\n+      return dataSchema;\n+    }\n+\n+    @Override\n+    public PTransform<PBegin, PCollection<Row>> buildReader() {\n+      return new PTransform<PBegin, PCollection<Row>>() {\n+        @Override\n+        public PCollection<Row> expand(PBegin begin) {\n+          PCollectionTuple rowsWithDlq =\n+              begin\n+                  .apply(\"ReadFromPubsub\", readMessagesWithAttributes())\n+                  .apply(\n+                      \"PubsubMessageToRow\",\n+                      PubsubMessageToRow.builder()\n+                          .messageSchema(dataSchema)\n+                          .useDlq(useDlqCheck(config))\n+                          .useFlatSchema(useFlatSchema)\n+                          .build());\n+          rowsWithDlq.get(MAIN_TAG).setRowSchema(dataSchema);\n+\n+          if (useDlqCheck(config)) {\n+            rowsWithDlq.get(DLQ_TAG).apply(writeMessagesToDlq());\n+          }\n+\n+          return rowsWithDlq.get(MAIN_TAG);\n+        }\n+      };\n+    }\n+\n+    @Override\n+    public PTransform<PCollection<Row>, POutput> buildWriter() {\n+      if (!useFlatSchema) {\n+        throw new UnsupportedOperationException(\n+            \"Writing to a Pubsub topic is only supported for flattened schemas\");\n+      }\n+\n+      return new PTransform<PCollection<Row>, POutput>() {\n+        @Override\n+        public POutput expand(PCollection<Row> input) {\n+          return input\n+              .apply(RowToPubsubMessage.fromTableConfig(config, useFlatSchema))\n+              .apply(createPubsubMessageWrite());\n+        }\n+      };\n+    }\n+\n+    private PubsubIO.Read<PubsubMessage> readMessagesWithAttributes() {\n+      PubsubIO.Read<PubsubMessage> read = PubsubIO.readMessagesWithAttributes().fromTopic(location);\n+\n+      return useTimestampAttribute(config)\n+          ? read.withTimestampAttribute(config.getValue(\"timestampAttributeKey\"))\n+          : read;\n+    }\n+\n+    private PubsubIO.Write<PubsubMessage> createPubsubMessageWrite() {\n+      PubsubIO.Write<PubsubMessage> write = PubsubIO.writeMessages().to(location);\n+      if (useTimestampAttribute(config)) {\n+        write = write.withTimestampAttribute(config.getValue(\"timestampAttributeKey\"));\n+      }\n+      return write;\n+    }\n+\n+    private PubsubIO.Write<PubsubMessage> writeMessagesToDlq() {\n+      PubsubIO.Write<PubsubMessage> write =\n+          PubsubIO.writeMessages().to(config.getString(\"deadLetterQueue\"));\n+\n+      return useTimestampAttribute(config)\n+          ? write.withTimestampAttribute(config.getString(\"timestampAttributeKey\"))\n+          : write;\n+    }\n+\n+    private boolean useDlqCheck(Row config) {\n+      return config.getValue(\"deadLetterQueue\") != null;\n+    }\n+\n+    private boolean useTimestampAttribute(Row config) {\n+      return config.getValue(\"timestampAttributeKey\") != null;\n+    }\n+\n+    private boolean definesAttributeAndPayload(Schema schema) {\n+      return fieldPresent(\n+              schema, ATTRIBUTES_FIELD, Schema.FieldType.map(VARCHAR.withNullable(false), VARCHAR))\n+          && (schema.hasField(PAYLOAD_FIELD)\n+              && ROW.equals(schema.getField(PAYLOAD_FIELD).getType().getTypeName()));\n+    }\n+\n+    private static boolean fieldPresent(\n+        Schema schema, String field, Schema.FieldType expectedType) {\n+      return schema.hasField(field)\n+          && expectedType.equivalent(\n+              schema.getField(field).getType(), Schema.EquivalenceNullablePolicy.IGNORE);\n+    }\n+  }\n+\n+  /**\n+   * A {@link PTransform} to convert {@link Row} to {@link PubsubMessage} with JSON payload.\n+   *\n+   * <p>Currently only supports writing a flat schema into a JSON payload. This means that all Row\n+   * field values are written to the {@link PubsubMessage} JSON payload, except for {@code\n+   * event_timestamp}, which is either ignored or written to the message attributes, depending on\n+   * whether config.getValue(\"timestampAttributeKey\") is set.\n+   */\n+  private static class RowToPubsubMessage", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU4NzUzMw=="}, "originalCommit": {"oid": "0b1804967423a7d35cdbe99261133e44279bd5a3"}, "originalPosition": 227}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODY4MjI0OA==", "bodyText": "This class doesn't actually have anything specific to pubsub in it anymore, it's just a generic wrapper that could be used for any SchemaIO. Could you rename it to something like SchemaIOTable and remove references to pubsub?\nThe javadoc for this class should also be removed and incorporate into the one for PubsubSchemaCapableIOProvider (but without the specific examples using SQL syntax).", "url": "https://github.com/apache/beam/pull/12090#discussion_r448682248", "createdAt": "2020-07-02T00:24:04Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/pubsub/PubsubIOJsonTable.java", "diffHunk": "@@ -122,14 +115,14 @@\n @Experimental\n class PubsubIOJsonTable extends BaseBeamTable implements Serializable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6ac8bf56fd2b229d2e7ad62b5594c8d754c36bc0"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODY4NDk1MA==", "bodyText": "PubsubSchemaIO.useFlatSchema is an implementation detail, this should instead be phrased like \"The data schema passed to from must take one of two forms: the \"nested\" style or the \"flat\" style ... \"\nThe javadoc for PubsubIOJsonTable has some good language about this that you could draw from.", "url": "https://github.com/apache/beam/pull/12090#discussion_r448684950", "createdAt": "2020-07-02T00:34:46Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsub/PubsubSchemaCapableIOProvider.java", "diffHunk": "@@ -0,0 +1,286 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsub;\n+\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.ATTRIBUTES_FIELD;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.DLQ_TAG;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.MAIN_TAG;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.PAYLOAD_FIELD;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.TIMESTAMP_FIELD;\n+import static org.apache.beam.sdk.schemas.Schema.TypeName.ROW;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+\n+import com.google.auto.service.AutoService;\n+import java.io.Serializable;\n+import java.nio.charset.StandardCharsets;\n+import org.apache.beam.sdk.annotations.Internal;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.schemas.Schema.FieldType;\n+import org.apache.beam.sdk.schemas.io.InvalidConfigurationException;\n+import org.apache.beam.sdk.schemas.io.InvalidSchemaException;\n+import org.apache.beam.sdk.schemas.io.SchemaCapableIOProvider;\n+import org.apache.beam.sdk.schemas.io.SchemaIO;\n+import org.apache.beam.sdk.schemas.transforms.DropFields;\n+import org.apache.beam.sdk.transforms.MapElements;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ToJson;\n+import org.apache.beam.sdk.transforms.WithTimestamps;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionTuple;\n+import org.apache.beam.sdk.values.POutput;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.sdk.values.TypeDescriptor;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * {@link SchemaCapableIOProvider} to create {@link PubsubSchemaIO} that implements {@link\n+ * SchemaIO}.\n+ *\n+ * <p>If useFlatSchema of {@link PubsubSchemaIO} is not set, schema must contain exactly fields\n+ * 'event_timestamp', 'attributes, and 'payload'. Else, it must contain just 'event_timestamp'. See\n+ * {@link PubsubMessageToRow} for details.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6ac8bf56fd2b229d2e7ad62b5594c8d754c36bc0"}, "originalPosition": 57}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODY4NTkzOQ==", "bodyText": "This feels a bit fractured now, It might help to give it a little structure with some headers and/or bulleted lists like we do in BigQueryIO (rendered).\nMaybe something like:\n<h2>Schema</h2>\n...\n<h2>Configuration</h2>\n...\n<h3>timestampAttributeKey</h3>\n...\n<h3>deadLetterQueueue</h3>\n...", "url": "https://github.com/apache/beam/pull/12090#discussion_r448685939", "createdAt": "2020-07-02T00:38:21Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsub/PubsubSchemaCapableIOProvider.java", "diffHunk": "@@ -0,0 +1,286 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsub;\n+\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.ATTRIBUTES_FIELD;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.DLQ_TAG;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.MAIN_TAG;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.PAYLOAD_FIELD;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.TIMESTAMP_FIELD;\n+import static org.apache.beam.sdk.schemas.Schema.TypeName.ROW;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+\n+import com.google.auto.service.AutoService;\n+import java.io.Serializable;\n+import java.nio.charset.StandardCharsets;\n+import org.apache.beam.sdk.annotations.Internal;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.schemas.Schema.FieldType;\n+import org.apache.beam.sdk.schemas.io.InvalidConfigurationException;\n+import org.apache.beam.sdk.schemas.io.InvalidSchemaException;\n+import org.apache.beam.sdk.schemas.io.SchemaCapableIOProvider;\n+import org.apache.beam.sdk.schemas.io.SchemaIO;\n+import org.apache.beam.sdk.schemas.transforms.DropFields;\n+import org.apache.beam.sdk.transforms.MapElements;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ToJson;\n+import org.apache.beam.sdk.transforms.WithTimestamps;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionTuple;\n+import org.apache.beam.sdk.values.POutput;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.sdk.values.TypeDescriptor;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * {@link SchemaCapableIOProvider} to create {@link PubsubSchemaIO} that implements {@link\n+ * SchemaIO}.\n+ *\n+ * <p>If useFlatSchema of {@link PubsubSchemaIO} is not set, schema must contain exactly fields\n+ * 'event_timestamp', 'attributes, and 'payload'. Else, it must contain just 'event_timestamp'. See\n+ * {@link PubsubMessageToRow} for details.\n+ *\n+ * <p>{@link #configurationSchema()} consists of two attributes, timestampAttributeKey and\n+ * deadLetterQueue.\n+ *\n+ * <p>timestampAttributeKey is an optional attribute key of the Pubsub message from which to extract\n+ * the event timestamp.\n+ *\n+ * <p>This attribute has to conform to the same requirements as in {@link\n+ * PubsubIO.Read.Builder#withTimestampAttribute}.\n+ *\n+ * <p>Short version: it has to be either millis since epoch or string in RFC 3339 format.\n+ *\n+ * <p>If the attribute is specified then event timestamps will be extracted from the specified\n+ * attribute. If it is not specified then message publish timestamp will be used.\n+ *\n+ * <p>deadLetterQueue is an optional topic path which will be used as a dead letter queue.\n+ *\n+ * <p>Messages that cannot be processed will be sent to this topic. If it is not specified then\n+ * exception will be thrown for errors during processing causing the pipeline to crash.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6ac8bf56fd2b229d2e7ad62b5594c8d754c36bc0"}, "originalPosition": 76}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c90136be1fc0601a8ca70a05f0847cec4810f538", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/c90136be1fc0601a8ca70a05f0847cec4810f538", "committedDate": "2020-07-06T20:04:26Z", "message": "Updated PubsubSchemaCapableIOProvider javadoc"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQzNDczODI5", "url": "https://github.com/apache/beam/pull/12090#pullrequestreview-443473829", "createdAt": "2020-07-06T23:47:13Z", "commit": {"oid": "c90136be1fc0601a8ca70a05f0847cec4810f538"}, "state": "APPROVED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wNlQyMzo0NzoxM1rOGtqgnQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wN1QwMDowNzo0MVrOGtq2sQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDUzNTU4MQ==", "bodyText": "Looks great, thank you!", "url": "https://github.com/apache/beam/pull/12090#discussion_r450535581", "createdAt": "2020-07-06T23:47:13Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/io/google-cloud-platform/src/main/java/org/apache/beam/sdk/io/gcp/pubsub/PubsubSchemaCapableIOProvider.java", "diffHunk": "@@ -0,0 +1,286 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.io.gcp.pubsub;\n+\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.ATTRIBUTES_FIELD;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.DLQ_TAG;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.MAIN_TAG;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.PAYLOAD_FIELD;\n+import static org.apache.beam.sdk.io.gcp.pubsub.PubsubMessageToRow.TIMESTAMP_FIELD;\n+import static org.apache.beam.sdk.schemas.Schema.TypeName.ROW;\n+import static org.apache.beam.vendor.guava.v26_0_jre.com.google.common.base.Preconditions.checkArgument;\n+\n+import com.google.auto.service.AutoService;\n+import java.io.Serializable;\n+import java.nio.charset.StandardCharsets;\n+import org.apache.beam.sdk.annotations.Internal;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.schemas.Schema.FieldType;\n+import org.apache.beam.sdk.schemas.io.InvalidConfigurationException;\n+import org.apache.beam.sdk.schemas.io.InvalidSchemaException;\n+import org.apache.beam.sdk.schemas.io.SchemaCapableIOProvider;\n+import org.apache.beam.sdk.schemas.io.SchemaIO;\n+import org.apache.beam.sdk.schemas.transforms.DropFields;\n+import org.apache.beam.sdk.transforms.MapElements;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.transforms.ToJson;\n+import org.apache.beam.sdk.transforms.WithTimestamps;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.PCollectionTuple;\n+import org.apache.beam.sdk.values.POutput;\n+import org.apache.beam.sdk.values.Row;\n+import org.apache.beam.sdk.values.TypeDescriptor;\n+import org.apache.beam.vendor.guava.v26_0_jre.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * {@link SchemaCapableIOProvider} to create {@link PubsubSchemaIO} that implements {@link\n+ * SchemaIO}.\n+ *\n+ * <p>If useFlatSchema of {@link PubsubSchemaIO} is not set, schema must contain exactly fields\n+ * 'event_timestamp', 'attributes, and 'payload'. Else, it must contain just 'event_timestamp'. See\n+ * {@link PubsubMessageToRow} for details.\n+ *\n+ * <p>{@link #configurationSchema()} consists of two attributes, timestampAttributeKey and\n+ * deadLetterQueue.\n+ *\n+ * <p>timestampAttributeKey is an optional attribute key of the Pubsub message from which to extract\n+ * the event timestamp.\n+ *\n+ * <p>This attribute has to conform to the same requirements as in {@link\n+ * PubsubIO.Read.Builder#withTimestampAttribute}.\n+ *\n+ * <p>Short version: it has to be either millis since epoch or string in RFC 3339 format.\n+ *\n+ * <p>If the attribute is specified then event timestamps will be extracted from the specified\n+ * attribute. If it is not specified then message publish timestamp will be used.\n+ *\n+ * <p>deadLetterQueue is an optional topic path which will be used as a dead letter queue.\n+ *\n+ * <p>Messages that cannot be processed will be sent to this topic. If it is not specified then\n+ * exception will be thrown for errors during processing causing the pipeline to crash.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODY4NTkzOQ=="}, "originalCommit": {"oid": "6ac8bf56fd2b229d2e7ad62b5594c8d754c36bc0"}, "originalPosition": 76}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDUzNjAyNg==", "bodyText": "Got it, SGTM. It'll probably be easier to verify when there's more than one implementation anyway :)", "url": "https://github.com/apache/beam/pull/12090#discussion_r450536026", "createdAt": "2020-07-06T23:48:59Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/pubsub/PubsubIOJsonTable.java", "diffHunk": "@@ -122,14 +115,14 @@\n @Experimental\n class PubsubIOJsonTable extends BaseBeamTable implements Serializable {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODY4MjI0OA=="}, "originalCommit": {"oid": "6ac8bf56fd2b229d2e7ad62b5594c8d754c36bc0"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDUzNjM2Mg==", "bodyText": "Beam java  is itself an SDK, so we should be clear this will enable IOs in other SDKs\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n             * <p>The interfaces can be implemented to enable IOs for SDKs in addition to Beam SQL.\n          \n          \n            \n             * <p>The interfaces can be implemented to make IOs available in other SDKs in addition to Beam SQL.", "url": "https://github.com/apache/beam/pull/12090#discussion_r450536362", "createdAt": "2020-07-06T23:50:02Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/io/SchemaIO.java", "diffHunk": "@@ -0,0 +1,42 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.schemas.io;\n+\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.transforms.PTransform;\n+import org.apache.beam.sdk.values.PBegin;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.POutput;\n+import org.apache.beam.sdk.values.Row;\n+\n+/**\n+ * An abstraction to create schema capable and aware IOs. The interface is intended to be used in\n+ * conjunction with the interface {@link SchemaCapableIOProvider}.\n+ *\n+ * <p>The interfaces can be implemented to enable IOs for SDKs in addition to Beam SQL.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c90136be1fc0601a8ca70a05f0847cec4810f538"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDU0MTIzMw==", "bodyText": "Sorry I should've brought this up before. We should add some disclaimers here and in SchemaIO (and the exceptions should at least get the annotations):\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            /** Provider to create {@link SchemaIO}. */\n          \n          \n            \n            public interface SchemaCapableIOProvider {\n          \n          \n            \n            /** \n          \n          \n            \n             * Provider to create {@link SchemaIO} instances for use in Beam SQL and other SDKs.\n          \n          \n            \n             *\n          \n          \n            \n             * <p><b>Internal only:</b> This interface is actively being worked on and it will likely change as we provide\n          \n          \n            \n             * implementations for more standard Beam IOs. We provide no backwards compatibility guarantees and\n          \n          \n            \n             * it should not be implemented outside of the Beam repository.\n          \n          \n            \n             */\n          \n          \n            \n            @Internal\n          \n          \n            \n            @Experimental(Kind.SCHEMAS)\n          \n          \n            \n            public interface SchemaCapableIOProvider {\n          \n      \n    \n    \n  \n\nI think it's very likely we'll make some changes to these interfaces (e.g. @tysonjh and @kennknowles have a good suggestion in the doc), so we don't want anyone other than us trying to implement them yet. Let's do this to make that clear.", "url": "https://github.com/apache/beam/pull/12090#discussion_r450541233", "createdAt": "2020-07-07T00:07:41Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/io/SchemaCapableIOProvider.java", "diffHunk": "@@ -0,0 +1,40 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.schemas.io;\n+\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.values.Row;\n+\n+/** Provider to create {@link SchemaIO}. */\n+public interface SchemaCapableIOProvider {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c90136be1fc0601a8ca70a05f0847cec4810f538"}, "originalPosition": 24}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d546ec5b1e6e6ce62c47234d212a04331c3c2e59", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/d546ec5b1e6e6ce62c47234d212a04331c3c2e59", "committedDate": "2020-07-07T14:22:11Z", "message": "Added experimental and internal annotations to schemaIO interfaces"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ0MTQwNzMy", "url": "https://github.com/apache/beam/pull/12090#pullrequestreview-444140732", "createdAt": "2020-07-07T18:19:52Z", "commit": {"oid": "d546ec5b1e6e6ce62c47234d212a04331c3c2e59"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3889, "cost": 1, "resetAt": "2021-10-28T16:48:13Z"}}}