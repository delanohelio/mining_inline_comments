{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTA3NzQzMDAx", "number": 13160, "reviewThreads": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQwMTo1NjoxMFrOEwkM6Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQyMjoxMzoxMFrOEw9p9g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE5MzYwMjMzOnYy", "diffSide": "RIGHT", "path": "website/www/site/content/en/documentation/programming-guide.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQwMTo1NjoxMFrOHmNxkg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQwMTo1NjoxMFrOHmNxkg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTgzMzYxOA==", "bodyText": "Note that rest.Size() is a convenience function added to offsetrange.Restriction specifically, it's not part of the SDF API. It might be better to replace it with rest.End - rest.Start to avoid the expectation that all restrictions will have a size method.", "url": "https://github.com/apache/beam/pull/13160#discussion_r509833618", "createdAt": "2020-10-22T01:56:10Z", "author": {"login": "youngoli"}, "path": "website/www/site/content/en/documentation/programming-guide.md", "diffHunk": "@@ -5143,3 +5143,282 @@ perUser.apply(ParDo.of(new DoFn<KV<String, ValueT>, OutputT>() {\n   }\n }));\n {{< /highlight >}}\n+\n+## 12 Splittable DoFns {#splittable-dofns}\n+\n+Splittable DoFns (SDFs) enable users to create modular components containing I/Os (and some advanced\n+[non I/O use cases](https://s.apache.org/splittable-do-fn#heading=h.5cep9s8k4fxv)). Having modular\n+I/O components that can be connected to each other simplify typical patterns that users want.\n+For example, a popular use case is to read filenames from a message queue followed by parsing those\n+files. Traditionally users were required to either write a single I/O connector that contained the\n+logic for the message queue and the file reader (increased complexity) or choose to reuse a message\n+queue I/O followed by a regular DoFn that read the file (decreased performance). With splittable DoFns,\n+we bring the richness of Apache Beam\u2019s I/O APIs to DoFns enabling modularity while maintaining the\n+performance of traditional I/O connectors.\n+\n+### 12.1 Splittable DoFn basics {#splittable-dofn-basics}\n+\n+At a high level, a splittable DoFn is responsible for processing element and restriction pairs. A\n+restriction represents a subset of work that would have been necessary to have been done when\n+processing the element.\n+\n+Executing a splittable DoFn follows the following steps:\n+\n+1. Each element is paired with a restriction (e.g. filename is paired with offset range representing the whole file).\n+2. Each element and restriction pair is split (e.g. offset ranges are broken up into smaller pieces).\n+3. The runner redistributes the element and restriction pairs to several workers.\n+4. Element and restriction pairs are processed in parallel (e.g. the file is read).\n+\n+![Diagram of steps that a splittable DoFn is composed of](/images/sdf_high_level_overview.svg)\n+\n+Within the last step, the element and restriction pair can pause its own processing and/or be split into\n+further element and restriction pairs. This last step is what enables I/O-like capabilities for DoFns.\n+\n+\n+#### 12.1.1 A basic splittable DoFn {#a-basic-splittable-dofn}\n+\n+A basic splittable DoFn is composed of three parts: a restriction, a restriction provider, and a\n+restriction tracker. The restriction is used to represent a subset of work for a given element.\n+The restriction provider lets SDF authors override default implementations for splitting, sizing,\n+watermark estimation, and so forth. In [Java](https://github.com/apache/beam/blob/f4c2734261396858e388ebef2eef50e7d48231a8/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/DoFn.java#L92)\n+and [Go](https://github.com/apache/beam/blob/0f466e6bcd4ac8677c2bd9ecc8e6af3836b7f3b8/sdks/go/pkg/beam/pardo.go#L226),\n+this is the DoFn. [Python](https://github.com/apache/beam/blob/f4c2734261396858e388ebef2eef50e7d48231a8/sdks/python/apache_beam/transforms/core.py#L213)\n+has a dedicated RestrictionProvider type. The restriction tracker is responsible for tracking\n+what subset of the restriction has been completed during processing.\n+\n+To define a splittable DoFn, you must choose whether the splittable DoFn is bounded (default) or\n+unbounded and define a way to initialize an initial restriction for an element.\n+\n+{{< highlight java >}}\n+{{< code_sample \"examples/java/src/main/java/org/apache/beam/examples/snippets/Snippets.java\" SDF_BasicExample >}}\n+{{< /highlight >}}\n+\n+{{< highlight py >}}\n+{{< code_sample \"sdks/python/apache_beam/examples/snippets/snippets.py\" SDF_BasicExample >}}\n+{{< /highlight >}}\n+\n+{{< highlight go >}}\n+func (fn *splittableDoFn) CreateInitialRestriction(filename string) offsetrange.Restriction {\n+\treturn offsetrange.Restriction{\n+\t\tStart: 0,\n+\t\tEnd:   getFileLength(filename),\n+\t}\n+}\n+\n+func (fn *splittableDoFn) CreateTracker(rest offsetrange.Restriction) *sdf.LockRTracker {\n+\treturn sdf.NewLockRTracker(offsetrange.NewTracker(rest))\n+}\n+\n+func (fn *splittableDoFn) ProcessElement(rt *sdf.LockRTracker, filename string, emit func(int)) error {\n+            file, err := os.Open(filename)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\toffset, err := seekToNextRecordBoundaryInFile(file, rt.GetRestriction().(offsetrange.Restriction).Start)\n+\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tfor rt.TryClaim(offset) {\n+\t\trecord, newOffset := readNextRecord(file)\n+\t\temit(record)\n+\t\toffset = newOffset\n+\t}\n+\treturn nil\n+}\n+{{< /highlight >}}\n+\n+At this point, we have a splittable DoFn that supports [runner-initiated splits](#runner-initiated-split)\n+enabling dynamic work rebalancing. To increase the rate at which initial parallelization of work occurs\n+or for those runners that do not support runner-initiated splitting, we recommend providing\n+a set of initial splits:\n+\n+{{< highlight java >}}\n+{{< code_sample \"examples/java/src/main/java/org/apache/beam/examples/snippets/Snippets.java\" SDF_BasicExampleWithSplitting >}}\n+{{< /highlight >}}\n+\n+{{< highlight py >}}\n+{{< code_sample \"sdks/python/apache_beam/examples/snippets/snippets.py\" SDF_BasicExampleWithSplitting >}}\n+{{< /highlight >}}\n+\n+{{< highlight go >}}\n+func (fn *splittableDoFn) SplitRestriction(filename string, rest offsetrange.Restriction) (splits []offsetrange.Restriction) {\n+\tsize := 64 * (1 << 20)\n+\ti := rest.Start\n+\tfor i < rest.End - size {\n+\t\t// Compute and output 64 MiB size ranges to process in parallel\n+\t\tend := i + size\n+     \t\tsplits = append(splits, offsetrange.Restriction{i, end})\n+\t\ti = end\n+\t}\n+\t// Output the last range\n+\tsplits = append(splits, offsetrange.Restriction{i, rest.End})\n+\treturn splits\n+}\n+{{< /highlight >}}\n+\n+### 12.2 Sizing and progress {#sizing-and-progress}\n+\n+Sizing and progress are used during execution of a splittable DoFn to inform runners so that they may\n+perform intelligent decisions about which restrictions to split and how to parallelize work.\n+\n+Before processing an element and restriction, an initial size may be used by a runner to choose\n+how and who processes the restrictions attempting to improve initial balancing and parallelization\n+of work. During the processing of an element and restriction, sizing and progress are used to choose\n+which restrictions to split and who should process them.\n+\n+By default, we use the restriction tracker\u2019s estimate for work remaining falling back to assuming\n+that all restrictions have an equal cost. To override the default, SDF authors can provide the\n+appropriate method within the restriction provider.\n+\n+{{< highlight java >}}\n+{{< code_sample \"examples/java/src/main/java/org/apache/beam/examples/snippets/Snippets.java\" SDF_GetSize >}}\n+{{< /highlight >}}\n+\n+{{< highlight py >}}\n+{{< code_sample \"sdks/python/apache_beam/examples/snippets/snippets.py\" SDF_GetSize >}}\n+{{< /highlight >}}\n+\n+{{< highlight go >}}\n+func (fn *splittableDoFn) RestrictionSize(filename string, rest offsetrange.Restriction) float64 {\n+\tweight := float64(1)\n+\tif strings.Contains(filename, \u201cexpensiveRecords\u201d) {\n+\t\tweight = 2\n+\t}\n+\treturn weight * rest.Size()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "626366b189b7dee572bd92fdefc7b11b6f7b2d51"}, "originalPosition": 146}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE5MzgyNDU0OnYy", "diffSide": "RIGHT", "path": "website/www/site/content/en/documentation/programming-guide.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQwNDowMDo1MlrOHmPw4A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQwNDowMDo1MlrOHmPw4A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwOTg2NjIwOA==", "bodyText": "Typo: \"As a splittable DoFn pr an element...\"", "url": "https://github.com/apache/beam/pull/13160#discussion_r509866208", "createdAt": "2020-10-22T04:00:52Z", "author": {"login": "youngoli"}, "path": "website/www/site/content/en/documentation/programming-guide.md", "diffHunk": "@@ -5143,3 +5143,282 @@ perUser.apply(ParDo.of(new DoFn<KV<String, ValueT>, OutputT>() {\n   }\n }));\n {{< /highlight >}}\n+\n+## 12 Splittable DoFns {#splittable-dofns}\n+\n+Splittable DoFns (SDFs) enable users to create modular components containing I/Os (and some advanced\n+[non I/O use cases](https://s.apache.org/splittable-do-fn#heading=h.5cep9s8k4fxv)). Having modular\n+I/O components that can be connected to each other simplify typical patterns that users want.\n+For example, a popular use case is to read filenames from a message queue followed by parsing those\n+files. Traditionally users were required to either write a single I/O connector that contained the\n+logic for the message queue and the file reader (increased complexity) or choose to reuse a message\n+queue I/O followed by a regular DoFn that read the file (decreased performance). With splittable DoFns,\n+we bring the richness of Apache Beam\u2019s I/O APIs to DoFns enabling modularity while maintaining the\n+performance of traditional I/O connectors.\n+\n+### 12.1 Splittable DoFn basics {#splittable-dofn-basics}\n+\n+At a high level, a splittable DoFn is responsible for processing element and restriction pairs. A\n+restriction represents a subset of work that would have been necessary to have been done when\n+processing the element.\n+\n+Executing a splittable DoFn follows the following steps:\n+\n+1. Each element is paired with a restriction (e.g. filename is paired with offset range representing the whole file).\n+2. Each element and restriction pair is split (e.g. offset ranges are broken up into smaller pieces).\n+3. The runner redistributes the element and restriction pairs to several workers.\n+4. Element and restriction pairs are processed in parallel (e.g. the file is read).\n+\n+![Diagram of steps that a splittable DoFn is composed of](/images/sdf_high_level_overview.svg)\n+\n+Within the last step, the element and restriction pair can pause its own processing and/or be split into\n+further element and restriction pairs. This last step is what enables I/O-like capabilities for DoFns.\n+\n+\n+#### 12.1.1 A basic splittable DoFn {#a-basic-splittable-dofn}\n+\n+A basic splittable DoFn is composed of three parts: a restriction, a restriction provider, and a\n+restriction tracker. The restriction is used to represent a subset of work for a given element.\n+The restriction provider lets SDF authors override default implementations for splitting, sizing,\n+watermark estimation, and so forth. In [Java](https://github.com/apache/beam/blob/f4c2734261396858e388ebef2eef50e7d48231a8/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/DoFn.java#L92)\n+and [Go](https://github.com/apache/beam/blob/0f466e6bcd4ac8677c2bd9ecc8e6af3836b7f3b8/sdks/go/pkg/beam/pardo.go#L226),\n+this is the DoFn. [Python](https://github.com/apache/beam/blob/f4c2734261396858e388ebef2eef50e7d48231a8/sdks/python/apache_beam/transforms/core.py#L213)\n+has a dedicated RestrictionProvider type. The restriction tracker is responsible for tracking\n+what subset of the restriction has been completed during processing.\n+\n+To define a splittable DoFn, you must choose whether the splittable DoFn is bounded (default) or\n+unbounded and define a way to initialize an initial restriction for an element.\n+\n+{{< highlight java >}}\n+{{< code_sample \"examples/java/src/main/java/org/apache/beam/examples/snippets/Snippets.java\" SDF_BasicExample >}}\n+{{< /highlight >}}\n+\n+{{< highlight py >}}\n+{{< code_sample \"sdks/python/apache_beam/examples/snippets/snippets.py\" SDF_BasicExample >}}\n+{{< /highlight >}}\n+\n+{{< highlight go >}}\n+func (fn *splittableDoFn) CreateInitialRestriction(filename string) offsetrange.Restriction {\n+\treturn offsetrange.Restriction{\n+\t\tStart: 0,\n+\t\tEnd:   getFileLength(filename),\n+\t}\n+}\n+\n+func (fn *splittableDoFn) CreateTracker(rest offsetrange.Restriction) *sdf.LockRTracker {\n+\treturn sdf.NewLockRTracker(offsetrange.NewTracker(rest))\n+}\n+\n+func (fn *splittableDoFn) ProcessElement(rt *sdf.LockRTracker, filename string, emit func(int)) error {\n+            file, err := os.Open(filename)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\toffset, err := seekToNextRecordBoundaryInFile(file, rt.GetRestriction().(offsetrange.Restriction).Start)\n+\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tfor rt.TryClaim(offset) {\n+\t\trecord, newOffset := readNextRecord(file)\n+\t\temit(record)\n+\t\toffset = newOffset\n+\t}\n+\treturn nil\n+}\n+{{< /highlight >}}\n+\n+At this point, we have a splittable DoFn that supports [runner-initiated splits](#runner-initiated-split)\n+enabling dynamic work rebalancing. To increase the rate at which initial parallelization of work occurs\n+or for those runners that do not support runner-initiated splitting, we recommend providing\n+a set of initial splits:\n+\n+{{< highlight java >}}\n+{{< code_sample \"examples/java/src/main/java/org/apache/beam/examples/snippets/Snippets.java\" SDF_BasicExampleWithSplitting >}}\n+{{< /highlight >}}\n+\n+{{< highlight py >}}\n+{{< code_sample \"sdks/python/apache_beam/examples/snippets/snippets.py\" SDF_BasicExampleWithSplitting >}}\n+{{< /highlight >}}\n+\n+{{< highlight go >}}\n+func (fn *splittableDoFn) SplitRestriction(filename string, rest offsetrange.Restriction) (splits []offsetrange.Restriction) {\n+\tsize := 64 * (1 << 20)\n+\ti := rest.Start\n+\tfor i < rest.End - size {\n+\t\t// Compute and output 64 MiB size ranges to process in parallel\n+\t\tend := i + size\n+     \t\tsplits = append(splits, offsetrange.Restriction{i, end})\n+\t\ti = end\n+\t}\n+\t// Output the last range\n+\tsplits = append(splits, offsetrange.Restriction{i, rest.End})\n+\treturn splits\n+}\n+{{< /highlight >}}\n+\n+### 12.2 Sizing and progress {#sizing-and-progress}\n+\n+Sizing and progress are used during execution of a splittable DoFn to inform runners so that they may\n+perform intelligent decisions about which restrictions to split and how to parallelize work.\n+\n+Before processing an element and restriction, an initial size may be used by a runner to choose\n+how and who processes the restrictions attempting to improve initial balancing and parallelization\n+of work. During the processing of an element and restriction, sizing and progress are used to choose\n+which restrictions to split and who should process them.\n+\n+By default, we use the restriction tracker\u2019s estimate for work remaining falling back to assuming\n+that all restrictions have an equal cost. To override the default, SDF authors can provide the\n+appropriate method within the restriction provider.\n+\n+{{< highlight java >}}\n+{{< code_sample \"examples/java/src/main/java/org/apache/beam/examples/snippets/Snippets.java\" SDF_GetSize >}}\n+{{< /highlight >}}\n+\n+{{< highlight py >}}\n+{{< code_sample \"sdks/python/apache_beam/examples/snippets/snippets.py\" SDF_GetSize >}}\n+{{< /highlight >}}\n+\n+{{< highlight go >}}\n+func (fn *splittableDoFn) RestrictionSize(filename string, rest offsetrange.Restriction) float64 {\n+\tweight := float64(1)\n+\tif strings.Contains(filename, \u201cexpensiveRecords\u201d) {\n+\t\tweight = 2\n+\t}\n+\treturn weight * rest.Size()\n+}\n+{{< /highlight >}}\n+\n+### 12.3 User initiated checkpoint {#user-initiated-checkpoint}\n+\n+Some I/Os cannot produce all of the data necessary to complete a restriction within the lifetime of a\n+single bundle. This typically happens with unbounded restrictions, but can also happen with bounded\n+restrictions. For example, there could be more data that needs to be ingested but is not available yet.\n+Another cause of this scenario is the source system throttling your data.\n+\n+Your splittable DoFn can signal to you that you are not done processing the current restriction. This\n+signal can suggest a time to resume at. While the runner tries to honor the resume time, this is not\n+guaranteed. This allows execution to continue on a restriction that has available work improving\n+resource utilization.\n+\n+{{< highlight java >}}\n+{{< code_sample \"examples/java/src/main/java/org/apache/beam/examples/snippets/Snippets.java\" SDF_UserInitiatedCheckpoint >}}\n+{{< /highlight >}}\n+\n+{{< highlight py >}}\n+{{< code_sample \"sdks/python/apache_beam/examples/snippets/snippets.py\" SDF_UserInitiatedCheckpoint >}}\n+{{< /highlight >}}\n+\n+### 12.4 Runner-initiated split {#runner-initiated-split}\n+\n+A runner at any time may attempt to split a restriction while it is being processed. This allows the\n+runner to either pause processing of the restriction so that other work may be done (common for\n+unbounded restrictions to limit the amount of output and/or improve latency) or split the restriction\n+into two pieces, increasing the available parallelism within the system. It is important to author a\n+splittable DoFn with this in mind since the end of the restriction may change. Thus when writing the\n+processing loop, it is important to use the result from trying to claim a piece of the restriction\n+instead of assuming one can process till the end.\n+\n+{{< highlight java >}}\n+{{< code_sample \"examples/java/src/main/java/org/apache/beam/examples/snippets/Snippets.java\" SDF_BadTryClaimLoop >}}\n+{{< /highlight >}}\n+\n+{{< highlight py >}}\n+{{< code_sample \"sdks/python/apache_beam/examples/snippets/snippets.py\" SDF_BadTryClaimLoop >}}\n+{{< /highlight >}}\n+\n+{{< highlight go >}}\n+func (fn *badTryClaimLoop) ProcessElement(rt *sdf.LockRTracker, filename string, emit func(int)) error {\n+            file, err := os.Open(filename)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\toffset, err := seekToNextRecordBoundaryInFile(file, rt.GetRestriction().(offsetrange.Restriction).Start)\n+\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\n+\t// The restriction tracker can be modified by another thread in parallel\n+\t// so storing state locally is ill advised.\n+\tend = rt.GetRestriction().(offsetrange.Restriction).End\n+\tfor offset < end {\n+\t\t// Only after successfully claiming should we produce any output and/or\n+\t\t// perform side effects.\n+    \trt.TryClaim(offset)\n+\t\trecord, newOffset := readNextRecord(file)\n+\t\temit(record)\n+\t\toffset = newOffset\n+\t}\n+\treturn nil\n+}\n+{{< /highlight >}}\n+\n+### 12.5 Watermark estimation {#watermark-estimation}\n+\n+The default watermark estimator does not produce a watermark estimate. Therefore, the output watermark\n+is solely computed by the minimum of upstream watermarks.\n+\n+As a splittable DoFn pr an element and restriction pair, it can advance the output watermark by specifying", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "626366b189b7dee572bd92fdefc7b11b6f7b2d51"}, "originalPosition": 220}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE5NjY5MzQ4OnYy", "diffSide": "RIGHT", "path": "website/www/site/content/en/documentation/programming-guide.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQxNjo1OTowMFrOHmrV-A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQxNzo0NDowMlrOHmtArQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDMxODA3Mg==", "bodyText": "The class DoFn should be in code font when it's within the text. I see that this is inconsistently applied in the programming guide, but let's make the changes in at least this section. https://developers.google.com/style/code-in-text", "url": "https://github.com/apache/beam/pull/13160#discussion_r510318072", "createdAt": "2020-10-22T16:59:00Z", "author": {"login": "rosetn"}, "path": "website/www/site/content/en/documentation/programming-guide.md", "diffHunk": "@@ -5143,3 +5143,282 @@ perUser.apply(ParDo.of(new DoFn<KV<String, ValueT>, OutputT>() {\n   }\n }));\n {{< /highlight >}}\n+\n+## 12 Splittable DoFns {#splittable-dofns}\n+\n+Splittable DoFns (SDFs) enable users to create modular components containing I/Os (and some advanced\n+[non I/O use cases](https://s.apache.org/splittable-do-fn#heading=h.5cep9s8k4fxv)). Having modular\n+I/O components that can be connected to each other simplify typical patterns that users want.\n+For example, a popular use case is to read filenames from a message queue followed by parsing those\n+files. Traditionally users were required to either write a single I/O connector that contained the\n+logic for the message queue and the file reader (increased complexity) or choose to reuse a message\n+queue I/O followed by a regular DoFn that read the file (decreased performance). With splittable DoFns,\n+we bring the richness of Apache Beam\u2019s I/O APIs to DoFns enabling modularity while maintaining the\n+performance of traditional I/O connectors.\n+\n+### 12.1 Splittable DoFn basics {#splittable-dofn-basics}\n+\n+At a high level, a splittable DoFn is responsible for processing element and restriction pairs. A\n+restriction represents a subset of work that would have been necessary to have been done when\n+processing the element.\n+\n+Executing a splittable DoFn follows the following steps:\n+\n+1. Each element is paired with a restriction (e.g. filename is paired with offset range representing the whole file).\n+2. Each element and restriction pair is split (e.g. offset ranges are broken up into smaller pieces).\n+3. The runner redistributes the element and restriction pairs to several workers.\n+4. Element and restriction pairs are processed in parallel (e.g. the file is read).\n+\n+![Diagram of steps that a splittable DoFn is composed of](/images/sdf_high_level_overview.svg)\n+\n+Within the last step, the element and restriction pair can pause its own processing and/or be split into\n+further element and restriction pairs. This last step is what enables I/O-like capabilities for DoFns.\n+\n+\n+#### 12.1.1 A basic splittable DoFn {#a-basic-splittable-dofn}\n+\n+A basic splittable DoFn is composed of three parts: a restriction, a restriction provider, and a", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "626366b189b7dee572bd92fdefc7b11b6f7b2d51"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDM0NTM4OQ==", "bodyText": "You can leave \"SDF\" in normal font", "url": "https://github.com/apache/beam/pull/13160#discussion_r510345389", "createdAt": "2020-10-22T17:44:02Z", "author": {"login": "rosetn"}, "path": "website/www/site/content/en/documentation/programming-guide.md", "diffHunk": "@@ -5143,3 +5143,282 @@ perUser.apply(ParDo.of(new DoFn<KV<String, ValueT>, OutputT>() {\n   }\n }));\n {{< /highlight >}}\n+\n+## 12 Splittable DoFns {#splittable-dofns}\n+\n+Splittable DoFns (SDFs) enable users to create modular components containing I/Os (and some advanced\n+[non I/O use cases](https://s.apache.org/splittable-do-fn#heading=h.5cep9s8k4fxv)). Having modular\n+I/O components that can be connected to each other simplify typical patterns that users want.\n+For example, a popular use case is to read filenames from a message queue followed by parsing those\n+files. Traditionally users were required to either write a single I/O connector that contained the\n+logic for the message queue and the file reader (increased complexity) or choose to reuse a message\n+queue I/O followed by a regular DoFn that read the file (decreased performance). With splittable DoFns,\n+we bring the richness of Apache Beam\u2019s I/O APIs to DoFns enabling modularity while maintaining the\n+performance of traditional I/O connectors.\n+\n+### 12.1 Splittable DoFn basics {#splittable-dofn-basics}\n+\n+At a high level, a splittable DoFn is responsible for processing element and restriction pairs. A\n+restriction represents a subset of work that would have been necessary to have been done when\n+processing the element.\n+\n+Executing a splittable DoFn follows the following steps:\n+\n+1. Each element is paired with a restriction (e.g. filename is paired with offset range representing the whole file).\n+2. Each element and restriction pair is split (e.g. offset ranges are broken up into smaller pieces).\n+3. The runner redistributes the element and restriction pairs to several workers.\n+4. Element and restriction pairs are processed in parallel (e.g. the file is read).\n+\n+![Diagram of steps that a splittable DoFn is composed of](/images/sdf_high_level_overview.svg)\n+\n+Within the last step, the element and restriction pair can pause its own processing and/or be split into\n+further element and restriction pairs. This last step is what enables I/O-like capabilities for DoFns.\n+\n+\n+#### 12.1.1 A basic splittable DoFn {#a-basic-splittable-dofn}\n+\n+A basic splittable DoFn is composed of three parts: a restriction, a restriction provider, and a", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDMxODA3Mg=="}, "originalCommit": {"oid": "626366b189b7dee572bd92fdefc7b11b6f7b2d51"}, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE5NjcxNTM0OnYy", "diffSide": "RIGHT", "path": "website/www/site/content/en/documentation/programming-guide.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQxNzowNDo1MFrOHmrj1w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQxNzo0NTo0MFrOHmtEsg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDMyMTYyMw==", "bodyText": "Missing period\n12. Splittable DoFns {#splittable-dofns}", "url": "https://github.com/apache/beam/pull/13160#discussion_r510321623", "createdAt": "2020-10-22T17:04:50Z", "author": {"login": "rosetn"}, "path": "website/www/site/content/en/documentation/programming-guide.md", "diffHunk": "@@ -5143,3 +5143,282 @@ perUser.apply(ParDo.of(new DoFn<KV<String, ValueT>, OutputT>() {\n   }\n }));\n {{< /highlight >}}\n+\n+## 12 Splittable DoFns {#splittable-dofns}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "626366b189b7dee572bd92fdefc7b11b6f7b2d51"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDM0NjQxOA==", "bodyText": "Also add them for each header. This stopped in the last two sections, but we can keep it consistent with the rest of the programming guide here.", "url": "https://github.com/apache/beam/pull/13160#discussion_r510346418", "createdAt": "2020-10-22T17:45:40Z", "author": {"login": "rosetn"}, "path": "website/www/site/content/en/documentation/programming-guide.md", "diffHunk": "@@ -5143,3 +5143,282 @@ perUser.apply(ParDo.of(new DoFn<KV<String, ValueT>, OutputT>() {\n   }\n }));\n {{< /highlight >}}\n+\n+## 12 Splittable DoFns {#splittable-dofns}", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDMyMTYyMw=="}, "originalCommit": {"oid": "626366b189b7dee572bd92fdefc7b11b6f7b2d51"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE5NjcyODY5OnYy", "diffSide": "RIGHT", "path": "website/www/site/content/en/documentation/programming-guide.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQxNzowODoxN1rOHmrsDg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQxNzowODoxN1rOHmrsDg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDMyMzcyNg==", "bodyText": "Add comma\nTraditionally, users", "url": "https://github.com/apache/beam/pull/13160#discussion_r510323726", "createdAt": "2020-10-22T17:08:17Z", "author": {"login": "rosetn"}, "path": "website/www/site/content/en/documentation/programming-guide.md", "diffHunk": "@@ -5143,3 +5143,282 @@ perUser.apply(ParDo.of(new DoFn<KV<String, ValueT>, OutputT>() {\n   }\n }));\n {{< /highlight >}}\n+\n+## 12 Splittable DoFns {#splittable-dofns}\n+\n+Splittable DoFns (SDFs) enable users to create modular components containing I/Os (and some advanced\n+[non I/O use cases](https://s.apache.org/splittable-do-fn#heading=h.5cep9s8k4fxv)). Having modular\n+I/O components that can be connected to each other simplify typical patterns that users want.\n+For example, a popular use case is to read filenames from a message queue followed by parsing those\n+files. Traditionally users were required to either write a single I/O connector that contained the", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "626366b189b7dee572bd92fdefc7b11b6f7b2d51"}, "originalPosition": 11}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE5Njg2MTY4OnYy", "diffSide": "RIGHT", "path": "website/www/site/content/en/documentation/programming-guide.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQxNzo0MzoyNFrOHms_Cg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQxOToxNToxNVrOHmwNug==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDM0NDk3MA==", "bodyText": "Can you add more explanation to the \"Checkpoint/split\" bubble in the diagram on this list?", "url": "https://github.com/apache/beam/pull/13160#discussion_r510344970", "createdAt": "2020-10-22T17:43:24Z", "author": {"login": "rosetn"}, "path": "website/www/site/content/en/documentation/programming-guide.md", "diffHunk": "@@ -5143,3 +5143,282 @@ perUser.apply(ParDo.of(new DoFn<KV<String, ValueT>, OutputT>() {\n   }\n }));\n {{< /highlight >}}\n+\n+## 12 Splittable DoFns {#splittable-dofns}\n+\n+Splittable DoFns (SDFs) enable users to create modular components containing I/Os (and some advanced\n+[non I/O use cases](https://s.apache.org/splittable-do-fn#heading=h.5cep9s8k4fxv)). Having modular\n+I/O components that can be connected to each other simplify typical patterns that users want.\n+For example, a popular use case is to read filenames from a message queue followed by parsing those\n+files. Traditionally users were required to either write a single I/O connector that contained the\n+logic for the message queue and the file reader (increased complexity) or choose to reuse a message\n+queue I/O followed by a regular DoFn that read the file (decreased performance). With splittable DoFns,\n+we bring the richness of Apache Beam\u2019s I/O APIs to DoFns enabling modularity while maintaining the\n+performance of traditional I/O connectors.\n+\n+### 12.1 Splittable DoFn basics {#splittable-dofn-basics}\n+\n+At a high level, a splittable DoFn is responsible for processing element and restriction pairs. A\n+restriction represents a subset of work that would have been necessary to have been done when\n+processing the element.\n+\n+Executing a splittable DoFn follows the following steps:\n+\n+1. Each element is paired with a restriction (e.g. filename is paired with offset range representing the whole file).\n+2. Each element and restriction pair is split (e.g. offset ranges are broken up into smaller pieces).\n+3. The runner redistributes the element and restriction pairs to several workers.\n+4. Element and restriction pairs are processed in parallel (e.g. the file is read).", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "626366b189b7dee572bd92fdefc7b11b6f7b2d51"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDM5Nzg4Mg==", "bodyText": "Below the diagram I have the explanation for the checkpoint/split. I moved it to be part of the list.", "url": "https://github.com/apache/beam/pull/13160#discussion_r510397882", "createdAt": "2020-10-22T19:15:15Z", "author": {"login": "lukecwik"}, "path": "website/www/site/content/en/documentation/programming-guide.md", "diffHunk": "@@ -5143,3 +5143,282 @@ perUser.apply(ParDo.of(new DoFn<KV<String, ValueT>, OutputT>() {\n   }\n }));\n {{< /highlight >}}\n+\n+## 12 Splittable DoFns {#splittable-dofns}\n+\n+Splittable DoFns (SDFs) enable users to create modular components containing I/Os (and some advanced\n+[non I/O use cases](https://s.apache.org/splittable-do-fn#heading=h.5cep9s8k4fxv)). Having modular\n+I/O components that can be connected to each other simplify typical patterns that users want.\n+For example, a popular use case is to read filenames from a message queue followed by parsing those\n+files. Traditionally users were required to either write a single I/O connector that contained the\n+logic for the message queue and the file reader (increased complexity) or choose to reuse a message\n+queue I/O followed by a regular DoFn that read the file (decreased performance). With splittable DoFns,\n+we bring the richness of Apache Beam\u2019s I/O APIs to DoFns enabling modularity while maintaining the\n+performance of traditional I/O connectors.\n+\n+### 12.1 Splittable DoFn basics {#splittable-dofn-basics}\n+\n+At a high level, a splittable DoFn is responsible for processing element and restriction pairs. A\n+restriction represents a subset of work that would have been necessary to have been done when\n+processing the element.\n+\n+Executing a splittable DoFn follows the following steps:\n+\n+1. Each element is paired with a restriction (e.g. filename is paired with offset range representing the whole file).\n+2. Each element and restriction pair is split (e.g. offset ranges are broken up into smaller pieces).\n+3. The runner redistributes the element and restriction pairs to several workers.\n+4. Element and restriction pairs are processed in parallel (e.g. the file is read).", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDM0NDk3MA=="}, "originalCommit": {"oid": "626366b189b7dee572bd92fdefc7b11b6f7b2d51"}, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE5Njg2Nzc0OnYy", "diffSide": "RIGHT", "path": "website/www/site/content/en/documentation/programming-guide.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQxNzo0NDo1MVrOHmtCpA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQxNzo0NDo1MVrOHmtCpA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDM0NTg5Mg==", "bodyText": "User-initiated", "url": "https://github.com/apache/beam/pull/13160#discussion_r510345892", "createdAt": "2020-10-22T17:44:51Z", "author": {"login": "rosetn"}, "path": "website/www/site/content/en/documentation/programming-guide.md", "diffHunk": "@@ -5143,3 +5143,282 @@ perUser.apply(ParDo.of(new DoFn<KV<String, ValueT>, OutputT>() {\n   }\n }));\n {{< /highlight >}}\n+\n+## 12 Splittable DoFns {#splittable-dofns}\n+\n+Splittable DoFns (SDFs) enable users to create modular components containing I/Os (and some advanced\n+[non I/O use cases](https://s.apache.org/splittable-do-fn#heading=h.5cep9s8k4fxv)). Having modular\n+I/O components that can be connected to each other simplify typical patterns that users want.\n+For example, a popular use case is to read filenames from a message queue followed by parsing those\n+files. Traditionally users were required to either write a single I/O connector that contained the\n+logic for the message queue and the file reader (increased complexity) or choose to reuse a message\n+queue I/O followed by a regular DoFn that read the file (decreased performance). With splittable DoFns,\n+we bring the richness of Apache Beam\u2019s I/O APIs to DoFns enabling modularity while maintaining the\n+performance of traditional I/O connectors.\n+\n+### 12.1 Splittable DoFn basics {#splittable-dofn-basics}\n+\n+At a high level, a splittable DoFn is responsible for processing element and restriction pairs. A\n+restriction represents a subset of work that would have been necessary to have been done when\n+processing the element.\n+\n+Executing a splittable DoFn follows the following steps:\n+\n+1. Each element is paired with a restriction (e.g. filename is paired with offset range representing the whole file).\n+2. Each element and restriction pair is split (e.g. offset ranges are broken up into smaller pieces).\n+3. The runner redistributes the element and restriction pairs to several workers.\n+4. Element and restriction pairs are processed in parallel (e.g. the file is read).\n+\n+![Diagram of steps that a splittable DoFn is composed of](/images/sdf_high_level_overview.svg)\n+\n+Within the last step, the element and restriction pair can pause its own processing and/or be split into\n+further element and restriction pairs. This last step is what enables I/O-like capabilities for DoFns.\n+\n+\n+#### 12.1.1 A basic splittable DoFn {#a-basic-splittable-dofn}\n+\n+A basic splittable DoFn is composed of three parts: a restriction, a restriction provider, and a\n+restriction tracker. The restriction is used to represent a subset of work for a given element.\n+The restriction provider lets SDF authors override default implementations for splitting, sizing,\n+watermark estimation, and so forth. In [Java](https://github.com/apache/beam/blob/f4c2734261396858e388ebef2eef50e7d48231a8/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/DoFn.java#L92)\n+and [Go](https://github.com/apache/beam/blob/0f466e6bcd4ac8677c2bd9ecc8e6af3836b7f3b8/sdks/go/pkg/beam/pardo.go#L226),\n+this is the DoFn. [Python](https://github.com/apache/beam/blob/f4c2734261396858e388ebef2eef50e7d48231a8/sdks/python/apache_beam/transforms/core.py#L213)\n+has a dedicated RestrictionProvider type. The restriction tracker is responsible for tracking\n+what subset of the restriction has been completed during processing.\n+\n+To define a splittable DoFn, you must choose whether the splittable DoFn is bounded (default) or\n+unbounded and define a way to initialize an initial restriction for an element.\n+\n+{{< highlight java >}}\n+{{< code_sample \"examples/java/src/main/java/org/apache/beam/examples/snippets/Snippets.java\" SDF_BasicExample >}}\n+{{< /highlight >}}\n+\n+{{< highlight py >}}\n+{{< code_sample \"sdks/python/apache_beam/examples/snippets/snippets.py\" SDF_BasicExample >}}\n+{{< /highlight >}}\n+\n+{{< highlight go >}}\n+func (fn *splittableDoFn) CreateInitialRestriction(filename string) offsetrange.Restriction {\n+\treturn offsetrange.Restriction{\n+\t\tStart: 0,\n+\t\tEnd:   getFileLength(filename),\n+\t}\n+}\n+\n+func (fn *splittableDoFn) CreateTracker(rest offsetrange.Restriction) *sdf.LockRTracker {\n+\treturn sdf.NewLockRTracker(offsetrange.NewTracker(rest))\n+}\n+\n+func (fn *splittableDoFn) ProcessElement(rt *sdf.LockRTracker, filename string, emit func(int)) error {\n+            file, err := os.Open(filename)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\toffset, err := seekToNextRecordBoundaryInFile(file, rt.GetRestriction().(offsetrange.Restriction).Start)\n+\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tfor rt.TryClaim(offset) {\n+\t\trecord, newOffset := readNextRecord(file)\n+\t\temit(record)\n+\t\toffset = newOffset\n+\t}\n+\treturn nil\n+}\n+{{< /highlight >}}\n+\n+At this point, we have a splittable DoFn that supports [runner-initiated splits](#runner-initiated-split)\n+enabling dynamic work rebalancing. To increase the rate at which initial parallelization of work occurs\n+or for those runners that do not support runner-initiated splitting, we recommend providing\n+a set of initial splits:\n+\n+{{< highlight java >}}\n+{{< code_sample \"examples/java/src/main/java/org/apache/beam/examples/snippets/Snippets.java\" SDF_BasicExampleWithSplitting >}}\n+{{< /highlight >}}\n+\n+{{< highlight py >}}\n+{{< code_sample \"sdks/python/apache_beam/examples/snippets/snippets.py\" SDF_BasicExampleWithSplitting >}}\n+{{< /highlight >}}\n+\n+{{< highlight go >}}\n+func (fn *splittableDoFn) SplitRestriction(filename string, rest offsetrange.Restriction) (splits []offsetrange.Restriction) {\n+\tsize := 64 * (1 << 20)\n+\ti := rest.Start\n+\tfor i < rest.End - size {\n+\t\t// Compute and output 64 MiB size ranges to process in parallel\n+\t\tend := i + size\n+     \t\tsplits = append(splits, offsetrange.Restriction{i, end})\n+\t\ti = end\n+\t}\n+\t// Output the last range\n+\tsplits = append(splits, offsetrange.Restriction{i, rest.End})\n+\treturn splits\n+}\n+{{< /highlight >}}\n+\n+### 12.2 Sizing and progress {#sizing-and-progress}\n+\n+Sizing and progress are used during execution of a splittable DoFn to inform runners so that they may\n+perform intelligent decisions about which restrictions to split and how to parallelize work.\n+\n+Before processing an element and restriction, an initial size may be used by a runner to choose\n+how and who processes the restrictions attempting to improve initial balancing and parallelization\n+of work. During the processing of an element and restriction, sizing and progress are used to choose\n+which restrictions to split and who should process them.\n+\n+By default, we use the restriction tracker\u2019s estimate for work remaining falling back to assuming\n+that all restrictions have an equal cost. To override the default, SDF authors can provide the\n+appropriate method within the restriction provider.\n+\n+{{< highlight java >}}\n+{{< code_sample \"examples/java/src/main/java/org/apache/beam/examples/snippets/Snippets.java\" SDF_GetSize >}}\n+{{< /highlight >}}\n+\n+{{< highlight py >}}\n+{{< code_sample \"sdks/python/apache_beam/examples/snippets/snippets.py\" SDF_GetSize >}}\n+{{< /highlight >}}\n+\n+{{< highlight go >}}\n+func (fn *splittableDoFn) RestrictionSize(filename string, rest offsetrange.Restriction) float64 {\n+\tweight := float64(1)\n+\tif strings.Contains(filename, \u201cexpensiveRecords\u201d) {\n+\t\tweight = 2\n+\t}\n+\treturn weight * rest.Size()\n+}\n+{{< /highlight >}}\n+\n+### 12.3 User initiated checkpoint {#user-initiated-checkpoint}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "626366b189b7dee572bd92fdefc7b11b6f7b2d51"}, "originalPosition": 150}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE5NzAzNzI4OnYy", "diffSide": "RIGHT", "path": "website/www/site/content/en/documentation/programming-guide.md", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQxODozMTozNVrOHmutNg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQyMzo1NTo1NFrOHm3uhg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDM3MzE3NA==", "bodyText": "Consider pointing out that with only the above example code, the restrictions don't currently do anything extra WRT the same DoFn without the restriction handling. It's a non-splittable-dofn with vestigial extras.  (there's probably a much better way to phrase this).", "url": "https://github.com/apache/beam/pull/13160#discussion_r510373174", "createdAt": "2020-10-22T18:31:35Z", "author": {"login": "lostluck"}, "path": "website/www/site/content/en/documentation/programming-guide.md", "diffHunk": "@@ -5143,3 +5143,282 @@ perUser.apply(ParDo.of(new DoFn<KV<String, ValueT>, OutputT>() {\n   }\n }));\n {{< /highlight >}}\n+\n+## 12 Splittable DoFns {#splittable-dofns}\n+\n+Splittable DoFns (SDFs) enable users to create modular components containing I/Os (and some advanced\n+[non I/O use cases](https://s.apache.org/splittable-do-fn#heading=h.5cep9s8k4fxv)). Having modular\n+I/O components that can be connected to each other simplify typical patterns that users want.\n+For example, a popular use case is to read filenames from a message queue followed by parsing those\n+files. Traditionally users were required to either write a single I/O connector that contained the\n+logic for the message queue and the file reader (increased complexity) or choose to reuse a message\n+queue I/O followed by a regular DoFn that read the file (decreased performance). With splittable DoFns,\n+we bring the richness of Apache Beam\u2019s I/O APIs to DoFns enabling modularity while maintaining the\n+performance of traditional I/O connectors.\n+\n+### 12.1 Splittable DoFn basics {#splittable-dofn-basics}\n+\n+At a high level, a splittable DoFn is responsible for processing element and restriction pairs. A\n+restriction represents a subset of work that would have been necessary to have been done when\n+processing the element.\n+\n+Executing a splittable DoFn follows the following steps:\n+\n+1. Each element is paired with a restriction (e.g. filename is paired with offset range representing the whole file).\n+2. Each element and restriction pair is split (e.g. offset ranges are broken up into smaller pieces).\n+3. The runner redistributes the element and restriction pairs to several workers.\n+4. Element and restriction pairs are processed in parallel (e.g. the file is read).\n+\n+![Diagram of steps that a splittable DoFn is composed of](/images/sdf_high_level_overview.svg)\n+\n+Within the last step, the element and restriction pair can pause its own processing and/or be split into\n+further element and restriction pairs. This last step is what enables I/O-like capabilities for DoFns.\n+\n+\n+#### 12.1.1 A basic splittable DoFn {#a-basic-splittable-dofn}\n+\n+A basic splittable DoFn is composed of three parts: a restriction, a restriction provider, and a\n+restriction tracker. The restriction is used to represent a subset of work for a given element.\n+The restriction provider lets SDF authors override default implementations for splitting, sizing,\n+watermark estimation, and so forth. In [Java](https://github.com/apache/beam/blob/f4c2734261396858e388ebef2eef50e7d48231a8/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/DoFn.java#L92)\n+and [Go](https://github.com/apache/beam/blob/0f466e6bcd4ac8677c2bd9ecc8e6af3836b7f3b8/sdks/go/pkg/beam/pardo.go#L226),\n+this is the DoFn. [Python](https://github.com/apache/beam/blob/f4c2734261396858e388ebef2eef50e7d48231a8/sdks/python/apache_beam/transforms/core.py#L213)\n+has a dedicated RestrictionProvider type. The restriction tracker is responsible for tracking\n+what subset of the restriction has been completed during processing.\n+\n+To define a splittable DoFn, you must choose whether the splittable DoFn is bounded (default) or\n+unbounded and define a way to initialize an initial restriction for an element.\n+\n+{{< highlight java >}}\n+{{< code_sample \"examples/java/src/main/java/org/apache/beam/examples/snippets/Snippets.java\" SDF_BasicExample >}}\n+{{< /highlight >}}\n+\n+{{< highlight py >}}\n+{{< code_sample \"sdks/python/apache_beam/examples/snippets/snippets.py\" SDF_BasicExample >}}\n+{{< /highlight >}}\n+\n+{{< highlight go >}}\n+func (fn *splittableDoFn) CreateInitialRestriction(filename string) offsetrange.Restriction {\n+\treturn offsetrange.Restriction{\n+\t\tStart: 0,\n+\t\tEnd:   getFileLength(filename),\n+\t}\n+}\n+\n+func (fn *splittableDoFn) CreateTracker(rest offsetrange.Restriction) *sdf.LockRTracker {\n+\treturn sdf.NewLockRTracker(offsetrange.NewTracker(rest))\n+}\n+\n+func (fn *splittableDoFn) ProcessElement(rt *sdf.LockRTracker, filename string, emit func(int)) error {\n+            file, err := os.Open(filename)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\toffset, err := seekToNextRecordBoundaryInFile(file, rt.GetRestriction().(offsetrange.Restriction).Start)\n+\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tfor rt.TryClaim(offset) {\n+\t\trecord, newOffset := readNextRecord(file)\n+\t\temit(record)\n+\t\toffset = newOffset\n+\t}\n+\treturn nil\n+}\n+{{< /highlight >}}\n+\n+At this point, we have a splittable DoFn that supports [runner-initiated splits](#runner-initiated-split)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "626366b189b7dee572bd92fdefc7b11b6f7b2d51"}, "originalPosition": 89}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDM5OTAzMA==", "bodyText": "I think we should deal with this in the follow-up about trySplit being implemented correctly within a restriction tracker and adding that to the runner initiated splits section then lumping it in now.", "url": "https://github.com/apache/beam/pull/13160#discussion_r510399030", "createdAt": "2020-10-22T19:17:27Z", "author": {"login": "lukecwik"}, "path": "website/www/site/content/en/documentation/programming-guide.md", "diffHunk": "@@ -5143,3 +5143,282 @@ perUser.apply(ParDo.of(new DoFn<KV<String, ValueT>, OutputT>() {\n   }\n }));\n {{< /highlight >}}\n+\n+## 12 Splittable DoFns {#splittable-dofns}\n+\n+Splittable DoFns (SDFs) enable users to create modular components containing I/Os (and some advanced\n+[non I/O use cases](https://s.apache.org/splittable-do-fn#heading=h.5cep9s8k4fxv)). Having modular\n+I/O components that can be connected to each other simplify typical patterns that users want.\n+For example, a popular use case is to read filenames from a message queue followed by parsing those\n+files. Traditionally users were required to either write a single I/O connector that contained the\n+logic for the message queue and the file reader (increased complexity) or choose to reuse a message\n+queue I/O followed by a regular DoFn that read the file (decreased performance). With splittable DoFns,\n+we bring the richness of Apache Beam\u2019s I/O APIs to DoFns enabling modularity while maintaining the\n+performance of traditional I/O connectors.\n+\n+### 12.1 Splittable DoFn basics {#splittable-dofn-basics}\n+\n+At a high level, a splittable DoFn is responsible for processing element and restriction pairs. A\n+restriction represents a subset of work that would have been necessary to have been done when\n+processing the element.\n+\n+Executing a splittable DoFn follows the following steps:\n+\n+1. Each element is paired with a restriction (e.g. filename is paired with offset range representing the whole file).\n+2. Each element and restriction pair is split (e.g. offset ranges are broken up into smaller pieces).\n+3. The runner redistributes the element and restriction pairs to several workers.\n+4. Element and restriction pairs are processed in parallel (e.g. the file is read).\n+\n+![Diagram of steps that a splittable DoFn is composed of](/images/sdf_high_level_overview.svg)\n+\n+Within the last step, the element and restriction pair can pause its own processing and/or be split into\n+further element and restriction pairs. This last step is what enables I/O-like capabilities for DoFns.\n+\n+\n+#### 12.1.1 A basic splittable DoFn {#a-basic-splittable-dofn}\n+\n+A basic splittable DoFn is composed of three parts: a restriction, a restriction provider, and a\n+restriction tracker. The restriction is used to represent a subset of work for a given element.\n+The restriction provider lets SDF authors override default implementations for splitting, sizing,\n+watermark estimation, and so forth. In [Java](https://github.com/apache/beam/blob/f4c2734261396858e388ebef2eef50e7d48231a8/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/DoFn.java#L92)\n+and [Go](https://github.com/apache/beam/blob/0f466e6bcd4ac8677c2bd9ecc8e6af3836b7f3b8/sdks/go/pkg/beam/pardo.go#L226),\n+this is the DoFn. [Python](https://github.com/apache/beam/blob/f4c2734261396858e388ebef2eef50e7d48231a8/sdks/python/apache_beam/transforms/core.py#L213)\n+has a dedicated RestrictionProvider type. The restriction tracker is responsible for tracking\n+what subset of the restriction has been completed during processing.\n+\n+To define a splittable DoFn, you must choose whether the splittable DoFn is bounded (default) or\n+unbounded and define a way to initialize an initial restriction for an element.\n+\n+{{< highlight java >}}\n+{{< code_sample \"examples/java/src/main/java/org/apache/beam/examples/snippets/Snippets.java\" SDF_BasicExample >}}\n+{{< /highlight >}}\n+\n+{{< highlight py >}}\n+{{< code_sample \"sdks/python/apache_beam/examples/snippets/snippets.py\" SDF_BasicExample >}}\n+{{< /highlight >}}\n+\n+{{< highlight go >}}\n+func (fn *splittableDoFn) CreateInitialRestriction(filename string) offsetrange.Restriction {\n+\treturn offsetrange.Restriction{\n+\t\tStart: 0,\n+\t\tEnd:   getFileLength(filename),\n+\t}\n+}\n+\n+func (fn *splittableDoFn) CreateTracker(rest offsetrange.Restriction) *sdf.LockRTracker {\n+\treturn sdf.NewLockRTracker(offsetrange.NewTracker(rest))\n+}\n+\n+func (fn *splittableDoFn) ProcessElement(rt *sdf.LockRTracker, filename string, emit func(int)) error {\n+            file, err := os.Open(filename)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\toffset, err := seekToNextRecordBoundaryInFile(file, rt.GetRestriction().(offsetrange.Restriction).Start)\n+\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tfor rt.TryClaim(offset) {\n+\t\trecord, newOffset := readNextRecord(file)\n+\t\temit(record)\n+\t\toffset = newOffset\n+\t}\n+\treturn nil\n+}\n+{{< /highlight >}}\n+\n+At this point, we have a splittable DoFn that supports [runner-initiated splits](#runner-initiated-split)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDM3MzE3NA=="}, "originalCommit": {"oid": "626366b189b7dee572bd92fdefc7b11b6f7b2d51"}, "originalPosition": 89}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDUyMDk2Ng==", "bodyText": "Ack SGTM.", "url": "https://github.com/apache/beam/pull/13160#discussion_r510520966", "createdAt": "2020-10-22T23:55:54Z", "author": {"login": "lostluck"}, "path": "website/www/site/content/en/documentation/programming-guide.md", "diffHunk": "@@ -5143,3 +5143,282 @@ perUser.apply(ParDo.of(new DoFn<KV<String, ValueT>, OutputT>() {\n   }\n }));\n {{< /highlight >}}\n+\n+## 12 Splittable DoFns {#splittable-dofns}\n+\n+Splittable DoFns (SDFs) enable users to create modular components containing I/Os (and some advanced\n+[non I/O use cases](https://s.apache.org/splittable-do-fn#heading=h.5cep9s8k4fxv)). Having modular\n+I/O components that can be connected to each other simplify typical patterns that users want.\n+For example, a popular use case is to read filenames from a message queue followed by parsing those\n+files. Traditionally users were required to either write a single I/O connector that contained the\n+logic for the message queue and the file reader (increased complexity) or choose to reuse a message\n+queue I/O followed by a regular DoFn that read the file (decreased performance). With splittable DoFns,\n+we bring the richness of Apache Beam\u2019s I/O APIs to DoFns enabling modularity while maintaining the\n+performance of traditional I/O connectors.\n+\n+### 12.1 Splittable DoFn basics {#splittable-dofn-basics}\n+\n+At a high level, a splittable DoFn is responsible for processing element and restriction pairs. A\n+restriction represents a subset of work that would have been necessary to have been done when\n+processing the element.\n+\n+Executing a splittable DoFn follows the following steps:\n+\n+1. Each element is paired with a restriction (e.g. filename is paired with offset range representing the whole file).\n+2. Each element and restriction pair is split (e.g. offset ranges are broken up into smaller pieces).\n+3. The runner redistributes the element and restriction pairs to several workers.\n+4. Element and restriction pairs are processed in parallel (e.g. the file is read).\n+\n+![Diagram of steps that a splittable DoFn is composed of](/images/sdf_high_level_overview.svg)\n+\n+Within the last step, the element and restriction pair can pause its own processing and/or be split into\n+further element and restriction pairs. This last step is what enables I/O-like capabilities for DoFns.\n+\n+\n+#### 12.1.1 A basic splittable DoFn {#a-basic-splittable-dofn}\n+\n+A basic splittable DoFn is composed of three parts: a restriction, a restriction provider, and a\n+restriction tracker. The restriction is used to represent a subset of work for a given element.\n+The restriction provider lets SDF authors override default implementations for splitting, sizing,\n+watermark estimation, and so forth. In [Java](https://github.com/apache/beam/blob/f4c2734261396858e388ebef2eef50e7d48231a8/sdks/java/core/src/main/java/org/apache/beam/sdk/transforms/DoFn.java#L92)\n+and [Go](https://github.com/apache/beam/blob/0f466e6bcd4ac8677c2bd9ecc8e6af3836b7f3b8/sdks/go/pkg/beam/pardo.go#L226),\n+this is the DoFn. [Python](https://github.com/apache/beam/blob/f4c2734261396858e388ebef2eef50e7d48231a8/sdks/python/apache_beam/transforms/core.py#L213)\n+has a dedicated RestrictionProvider type. The restriction tracker is responsible for tracking\n+what subset of the restriction has been completed during processing.\n+\n+To define a splittable DoFn, you must choose whether the splittable DoFn is bounded (default) or\n+unbounded and define a way to initialize an initial restriction for an element.\n+\n+{{< highlight java >}}\n+{{< code_sample \"examples/java/src/main/java/org/apache/beam/examples/snippets/Snippets.java\" SDF_BasicExample >}}\n+{{< /highlight >}}\n+\n+{{< highlight py >}}\n+{{< code_sample \"sdks/python/apache_beam/examples/snippets/snippets.py\" SDF_BasicExample >}}\n+{{< /highlight >}}\n+\n+{{< highlight go >}}\n+func (fn *splittableDoFn) CreateInitialRestriction(filename string) offsetrange.Restriction {\n+\treturn offsetrange.Restriction{\n+\t\tStart: 0,\n+\t\tEnd:   getFileLength(filename),\n+\t}\n+}\n+\n+func (fn *splittableDoFn) CreateTracker(rest offsetrange.Restriction) *sdf.LockRTracker {\n+\treturn sdf.NewLockRTracker(offsetrange.NewTracker(rest))\n+}\n+\n+func (fn *splittableDoFn) ProcessElement(rt *sdf.LockRTracker, filename string, emit func(int)) error {\n+            file, err := os.Open(filename)\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\toffset, err := seekToNextRecordBoundaryInFile(file, rt.GetRestriction().(offsetrange.Restriction).Start)\n+\n+\tif err != nil {\n+\t\treturn err\n+\t}\n+\tfor rt.TryClaim(offset) {\n+\t\trecord, newOffset := readNextRecord(file)\n+\t\temit(record)\n+\t\toffset = newOffset\n+\t}\n+\treturn nil\n+}\n+{{< /highlight >}}\n+\n+At this point, we have a splittable DoFn that supports [runner-initiated splits](#runner-initiated-split)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDM3MzE3NA=="}, "originalCommit": {"oid": "626366b189b7dee572bd92fdefc7b11b6f7b2d51"}, "originalPosition": 89}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE5Nzc3MjcwOnYy", "diffSide": "RIGHT", "path": "website/www/site/content/en/documentation/programming-guide.md", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQyMjoxMzoxMFrOHm1tXA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQyMjoxMzoxMFrOHm1tXA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDQ4NzkwMA==", "bodyText": "Let's make these \"an SDF\"", "url": "https://github.com/apache/beam/pull/13160#discussion_r510487900", "createdAt": "2020-10-22T22:13:10Z", "author": {"login": "rosetn"}, "path": "website/www/site/content/en/documentation/programming-guide.md", "diffHunk": "@@ -5143,3 +5143,281 @@ perUser.apply(ParDo.of(new DoFn<KV<String, ValueT>, OutputT>() {\n   }\n }));\n {{< /highlight >}}\n+\n+## 12. Splittable `DoFns` {#splittable-dofns}\n+\n+A Splittable `DoFn` (SDF) enables users to create modular components containing I/Os (and some advanced\n+[non I/O use cases](https://s.apache.org/splittable-do-fn#heading=h.5cep9s8k4fxv)). Having modular\n+I/O components that can be connected to each other simplify typical patterns that users want.\n+For example, a popular use case is to read filenames from a message queue followed by parsing those\n+files. Traditionally, users were required to either write a single I/O connector that contained the\n+logic for the message queue and the file reader (increased complexity) or choose to reuse a message\n+queue I/O followed by a regular `DoFn` that read the file (decreased performance). With SDF,\n+we bring the richness of Apache Beam\u2019s I/O APIs to a `DoFn` enabling modularity while maintaining the\n+performance of traditional I/O connectors.\n+\n+### 12.1. SDF basics {#sdf-basics}\n+\n+At a high level, a SDF is responsible for processing element and restriction pairs. A", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bf59970c4297e1721bc4eb5d93e09c5e2569b87c"}, "originalPosition": 19}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3049, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}