{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTA4NzExNjk4", "number": 13175, "title": "Adding performance improvements to ApproximateQuantiles.", "bodyText": "Improvements include:\n\nMoving min_val and max_val calculation to _QuantileBuffer level, so that unnecessary comparison is avoided most of the time.\nAdding fast _interpolate branch for buffers with the same level.\nCythonization of ApproximateQuantilesCombineFn components.\nAdding option to process batches of elements.\n\n\nThank you for your contribution! Follow this checklist to help us incorporate your contribution quickly and easily:\n\n Choose reviewer(s) and mention them in a comment (R: @username).\n Format the pull request title like [BEAM-XXX] Fixes bug in ApproximateQuantiles, where you replace BEAM-XXX with the appropriate JIRA issue, if applicable. This will automatically link the pull request to the issue.\n Update CHANGES.md with noteworthy changes.\n If this contribution is large, please file an Apache Individual Contributor License Agreement.\n\nSee the Contributor Guide for more tips on how to make review process smoother.\nPost-Commit Tests Status (on master branch)\n\n\n\nLang\nSDK\nDataflow\nFlink\nSamza\nSpark\nTwister2\n\n\n\n\nGo\n\n---\n\n---\n\n---\n\n\nJava\n\n\n\n\n\n\n\n\nPython\n\n\n\n---\n\n---\n\n\nXLang\n\n---\n\n---\n\n---\n\n\n\nPre-Commit Tests Status (on master branch)\n\n\n\n---\nJava\nPython\nGo\nWebsite\nWhitespace\nTypescript\n\n\n\n\nNon-portable\n\n \n\n\n\n\n\n\nPortable\n---\n\n---\n---\n---\n---\n\n\n\nSee .test-infra/jenkins/README for trigger phrase, status and link of all Jenkins jobs.\nGitHub Actions Tests Status (on master branch)\n\n\n\nSee CI.md for more information about GitHub Actions CI.", "createdAt": "2020-10-23T04:36:13Z", "url": "https://github.com/apache/beam/pull/13175", "merged": true, "mergeCommit": {"oid": "66a8a4c5e97f674f594c2194da736ad63a842dfe"}, "closed": true, "closedAt": "2021-02-19T06:50:04Z", "author": {"login": "iindyk"}, "timelineItems": {"totalCount": 18, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdVO4pDgH2gAyNTA4NzExNjk4OjI5ZTE4YTI2MGIwMzE0ZGY4ZmFkY2ZjMjU0MzZmMGJiMDYyMGYyZWQ=", "endCursor": "Y3Vyc29yOnYyOpPPAAABd7hDnZgFqTU5MzgyNDg0Mw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "29e18a260b0314df8fadcfc25436f0bb0620f2ed", "author": {"user": {"login": "iindyk", "name": "Ihor Indyk"}}, "url": "https://github.com/apache/beam/commit/29e18a260b0314df8fadcfc25436f0bb0620f2ed", "committedDate": "2020-10-23T04:30:11Z", "message": "Adding Cythonization and other performance improvements to ApproximateQuantiles."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cc7a48b4a4815ea9172b7db571fe6873612a82dc", "author": {"user": {"login": "iindyk", "name": "Ihor Indyk"}}, "url": "https://github.com/apache/beam/commit/cc7a48b4a4815ea9172b7db571fe6873612a82dc", "committedDate": "2020-10-23T15:55:00Z", "message": "Pickling and Lint fixes."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9f809cf45111b2b76ff6cc1237733ed28498325c", "author": {"user": {"login": "iindyk", "name": "Ihor Indyk"}}, "url": "https://github.com/apache/beam/commit/9f809cf45111b2b76ff6cc1237733ed28498325c", "committedDate": "2020-10-23T19:44:02Z", "message": "More fixes."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "717c4f4d9898dd438e8a2f5ee3f8a3c6e54fd70b", "author": {"user": {"login": "iindyk", "name": "Ihor Indyk"}}, "url": "https://github.com/apache/beam/commit/717c4f4d9898dd438e8a2f5ee3f8a3c6e54fd70b", "committedDate": "2020-10-23T20:56:49Z", "message": "More fixes."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "53aa529e754bcf34504a9f9ebecaf8a3ed7f2a3f", "author": {"user": {"login": "iindyk", "name": "Ihor Indyk"}}, "url": "https://github.com/apache/beam/commit/53aa529e754bcf34504a9f9ebecaf8a3ed7f2a3f", "committedDate": "2020-10-25T22:01:33Z", "message": "More fixes."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "14ff653440e7f6187fac6b7146561a3c16a21952", "author": {"user": {"login": "iindyk", "name": "Ihor Indyk"}}, "url": "https://github.com/apache/beam/commit/14ff653440e7f6187fac6b7146561a3c16a21952", "committedDate": "2020-10-26T14:30:21Z", "message": "Another pylint fix."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671", "author": {"user": {"login": "iindyk", "name": "Ihor Indyk"}}, "url": "https://github.com/apache/beam/commit/2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671", "committedDate": "2020-10-26T20:09:46Z", "message": "Finishing touch."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE4OTg5OTYw", "url": "https://github.com/apache/beam/pull/13175#pullrequestreview-518989960", "createdAt": "2020-10-28T18:56:15Z", "commit": {"oid": "2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671"}, "state": "COMMENTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxODo1NjoxNlrOHp5ChA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxOTowNjo0N1rOHp5ahQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY4ODE5Ng==", "bodyText": "Are there downsides to just making this a dependency?", "url": "https://github.com/apache/beam/pull/13175#discussion_r513688196", "createdAt": "2020-10-28T18:56:16Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -61,30 +58,34 @@\n K = typing.TypeVar('K')\n V = typing.TypeVar('V')\n \n+try:\n+  import mmh3  # pylint: disable=import-error\n \n-def _get_default_hash_fn():\n-  \"\"\"Returns either murmurhash or md5 based on installation.\"\"\"\n-  try:\n-    import mmh3  # pylint: disable=import-error\n+  def _mmh3_hash(value):\n+    # mmh3.hash64 returns two 64-bit unsigned integers\n+    return mmh3.hash64(value, seed=0, signed=False)[0]\n+\n+  _default_hash_fn = _mmh3_hash\n+  _default_hash_fn_type = 'mmh3'\n+except ImportError:\n \n-    def _mmh3_hash(value):\n-      # mmh3.hash64 returns two 64-bit unsigned integers\n-      return mmh3.hash64(value, seed=0, signed=False)[0]\n+  def _md5_hash(value):\n+    # md5 is a 128-bit hash, so we truncate the hexdigest (string of 32\n+    # hexadecimal digits) to 16 digits and convert to int to get the 64-bit\n+    # integer fingerprint.\n+    return int(hashlib.md5(value).hexdigest()[:16], 16)\n \n-    return _mmh3_hash\n+  _default_hash_fn = _md5_hash\n+  _default_hash_fn_type = 'md5'\n \n-  except ImportError:\n+\n+def _get_default_hash_fn():\n+  \"\"\"Returns either murmurhash or md5 based on installation.\"\"\"\n+  if _default_hash_fn_type == 'md5':\n     logging.warning(\n         'Couldn\\'t find murmurhash. Install mmh3 for a faster implementation of'", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY4OTc5Ng==", "bodyText": "Nit: it'd be easier to read if reverse and key is None rather than having the extra negation in there.", "url": "https://github.com/apache/beam/pull/13175#discussion_r513689796", "createdAt": "2020-10-28T18:58:59Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -368,82 +383,129 @@ class PerKey(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate\n+        multiple elements at a time more efficiently.\n     \"\"\"\n-    def __init__(self, num_quantiles, key=None, reverse=False, weighted=False):\n+    def __init__(\n+        self,\n+        num_quantiles,\n+        key=None,\n+        reverse=False,\n+        weighted=False,\n+        batch_input=False):\n       self._num_quantiles = num_quantiles\n       self._key = key\n       self._reverse = reverse\n       self._weighted = weighted\n+      self._batch_input = batch_input\n \n     def expand(self, pcoll):\n       return pcoll | CombinePerKey(\n           ApproximateQuantilesCombineFn.create(\n               num_quantiles=self._num_quantiles,\n               key=self._key,\n               reverse=self._reverse,\n-              weighted=self._weighted))\n+              weighted=self._weighted,\n+              batch_input=self._batch_input))\n \n     def display_data(self):\n       return ApproximateQuantiles._display_data(\n           num_quantiles=self._num_quantiles,\n           key=self._key,\n           reverse=self._reverse,\n-          weighted=self._weighted)\n+          weighted=self._weighted,\n+          batch_input=self._batch_input)\n+\n+\n+class _QuantileSpec(object):\n+  \"\"\"Quantiles computation specifications.\"\"\"\n+  def __init__(self, buffer_size, num_buffers, weighted, key, reverse):\n+    # type: (int, int, bool, Any, bool) -> None\n+    self.buffer_size = buffer_size\n+    self.num_buffers = num_buffers\n+    self.weighted = weighted\n+    self.key = key\n+    self.reverse = reverse\n+\n+    # Used to sort tuples of values and weights.\n+    self.weighted_key = None if key is None else (lambda x: key(x[0]))\n+\n+    # Used to compare values.\n+    if key is None and not reverse:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671"}, "originalPosition": 187}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY5MDM4Mw==", "bodyText": "I'm curious if it's faster to always have weights (by default 1) than introducing this indirection everywhere.", "url": "https://github.com/apache/beam/pull/13175#discussion_r513690383", "createdAt": "2020-10-28T19:00:00Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -368,82 +383,129 @@ class PerKey(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate\n+        multiple elements at a time more efficiently.\n     \"\"\"\n-    def __init__(self, num_quantiles, key=None, reverse=False, weighted=False):\n+    def __init__(\n+        self,\n+        num_quantiles,\n+        key=None,\n+        reverse=False,\n+        weighted=False,\n+        batch_input=False):\n       self._num_quantiles = num_quantiles\n       self._key = key\n       self._reverse = reverse\n       self._weighted = weighted\n+      self._batch_input = batch_input\n \n     def expand(self, pcoll):\n       return pcoll | CombinePerKey(\n           ApproximateQuantilesCombineFn.create(\n               num_quantiles=self._num_quantiles,\n               key=self._key,\n               reverse=self._reverse,\n-              weighted=self._weighted))\n+              weighted=self._weighted,\n+              batch_input=self._batch_input))\n \n     def display_data(self):\n       return ApproximateQuantiles._display_data(\n           num_quantiles=self._num_quantiles,\n           key=self._key,\n           reverse=self._reverse,\n-          weighted=self._weighted)\n+          weighted=self._weighted,\n+          batch_input=self._batch_input)\n+\n+\n+class _QuantileSpec(object):\n+  \"\"\"Quantiles computation specifications.\"\"\"\n+  def __init__(self, buffer_size, num_buffers, weighted, key, reverse):\n+    # type: (int, int, bool, Any, bool) -> None\n+    self.buffer_size = buffer_size\n+    self.num_buffers = num_buffers\n+    self.weighted = weighted\n+    self.key = key\n+    self.reverse = reverse\n+\n+    # Used to sort tuples of values and weights.\n+    self.weighted_key = None if key is None else (lambda x: key(x[0]))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671"}, "originalPosition": 184}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY5MDg3MQ==", "bodyText": "Can we doubly inherit to keep the type checking?", "url": "https://github.com/apache/beam/pull/13175#discussion_r513690871", "createdAt": "2020-10-28T19:00:50Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -368,82 +383,129 @@ class PerKey(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate\n+        multiple elements at a time more efficiently.\n     \"\"\"\n-    def __init__(self, num_quantiles, key=None, reverse=False, weighted=False):\n+    def __init__(\n+        self,\n+        num_quantiles,\n+        key=None,\n+        reverse=False,\n+        weighted=False,\n+        batch_input=False):\n       self._num_quantiles = num_quantiles\n       self._key = key\n       self._reverse = reverse\n       self._weighted = weighted\n+      self._batch_input = batch_input\n \n     def expand(self, pcoll):\n       return pcoll | CombinePerKey(\n           ApproximateQuantilesCombineFn.create(\n               num_quantiles=self._num_quantiles,\n               key=self._key,\n               reverse=self._reverse,\n-              weighted=self._weighted))\n+              weighted=self._weighted,\n+              batch_input=self._batch_input))\n \n     def display_data(self):\n       return ApproximateQuantiles._display_data(\n           num_quantiles=self._num_quantiles,\n           key=self._key,\n           reverse=self._reverse,\n-          weighted=self._weighted)\n+          weighted=self._weighted,\n+          batch_input=self._batch_input)\n+\n+\n+class _QuantileSpec(object):\n+  \"\"\"Quantiles computation specifications.\"\"\"\n+  def __init__(self, buffer_size, num_buffers, weighted, key, reverse):\n+    # type: (int, int, bool, Any, bool) -> None\n+    self.buffer_size = buffer_size\n+    self.num_buffers = num_buffers\n+    self.weighted = weighted\n+    self.key = key\n+    self.reverse = reverse\n+\n+    # Used to sort tuples of values and weights.\n+    self.weighted_key = None if key is None else (lambda x: key(x[0]))\n+\n+    # Used to compare values.\n+    if key is None and not reverse:\n+      self.less_than = lambda a, b: a < b\n+    elif key is None:\n+      self.less_than = lambda a, b: a > b\n+    elif not reverse:\n+      self.less_than = lambda a, b: key(a) < key(b)\n+    else:\n+      self.less_than = lambda a, b: key(a) > key(b)\n+\n+  def get_argsort_key(self, elements):\n+    # type: (List) -> Any\n+\n+    \"\"\"Returns a key for sorting indices of elements by element's value.\"\"\"\n+    if self.key is None:\n+      return elements.__getitem__\n+    else:\n+      return lambda idx: self.key(elements[idx])\n+\n+  def __reduce__(self):\n+    return (\n+        self.__class__,\n+        (\n+            self.buffer_size,\n+            self.num_buffers,\n+            self.weighted,\n+            self.key,\n+            self.reverse))\n \n \n-class _QuantileBuffer(Generic[T]):\n+class _QuantileBuffer(object):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671"}, "originalPosition": 217}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY5MzgxNA==", "bodyText": "This will break if it's called twice. Instead put the call to zip here.", "url": "https://github.com/apache/beam/pull/13175#discussion_r513693814", "createdAt": "2020-10-28T19:05:48Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -368,82 +383,129 @@ class PerKey(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate\n+        multiple elements at a time more efficiently.\n     \"\"\"\n-    def __init__(self, num_quantiles, key=None, reverse=False, weighted=False):\n+    def __init__(\n+        self,\n+        num_quantiles,\n+        key=None,\n+        reverse=False,\n+        weighted=False,\n+        batch_input=False):\n       self._num_quantiles = num_quantiles\n       self._key = key\n       self._reverse = reverse\n       self._weighted = weighted\n+      self._batch_input = batch_input\n \n     def expand(self, pcoll):\n       return pcoll | CombinePerKey(\n           ApproximateQuantilesCombineFn.create(\n               num_quantiles=self._num_quantiles,\n               key=self._key,\n               reverse=self._reverse,\n-              weighted=self._weighted))\n+              weighted=self._weighted,\n+              batch_input=self._batch_input))\n \n     def display_data(self):\n       return ApproximateQuantiles._display_data(\n           num_quantiles=self._num_quantiles,\n           key=self._key,\n           reverse=self._reverse,\n-          weighted=self._weighted)\n+          weighted=self._weighted,\n+          batch_input=self._batch_input)\n+\n+\n+class _QuantileSpec(object):\n+  \"\"\"Quantiles computation specifications.\"\"\"\n+  def __init__(self, buffer_size, num_buffers, weighted, key, reverse):\n+    # type: (int, int, bool, Any, bool) -> None\n+    self.buffer_size = buffer_size\n+    self.num_buffers = num_buffers\n+    self.weighted = weighted\n+    self.key = key\n+    self.reverse = reverse\n+\n+    # Used to sort tuples of values and weights.\n+    self.weighted_key = None if key is None else (lambda x: key(x[0]))\n+\n+    # Used to compare values.\n+    if key is None and not reverse:\n+      self.less_than = lambda a, b: a < b\n+    elif key is None:\n+      self.less_than = lambda a, b: a > b\n+    elif not reverse:\n+      self.less_than = lambda a, b: key(a) < key(b)\n+    else:\n+      self.less_than = lambda a, b: key(a) > key(b)\n+\n+  def get_argsort_key(self, elements):\n+    # type: (List) -> Any\n+\n+    \"\"\"Returns a key for sorting indices of elements by element's value.\"\"\"\n+    if self.key is None:\n+      return elements.__getitem__\n+    else:\n+      return lambda idx: self.key(elements[idx])\n+\n+  def __reduce__(self):\n+    return (\n+        self.__class__,\n+        (\n+            self.buffer_size,\n+            self.num_buffers,\n+            self.weighted,\n+            self.key,\n+            self.reverse))\n \n \n-class _QuantileBuffer(Generic[T]):\n+class _QuantileBuffer(object):\n   \"\"\"A single buffer in the sense of the referenced algorithm.\n   (see http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.6.6513&rep=rep1\n   &type=pdf and ApproximateQuantilesCombineFn for further information)\"\"\"\n-  def __init__(self, elements, weighted, level=0, weight=1):\n-    # type: (Sequence[T], bool, int, int) -> None\n-    # In case of weighted quantiles, elements are tuples of values and weights.\n+  def __init__(\n+      self, elements, weights, weighted, level=0, min_val=None, max_val=None):\n+    # type: (List, List, bool, int, Any, Any) -> None\n     self.elements = elements\n-    self.weighted = weighted\n+    self.weights = weights\n     self.level = level\n-    self.weight = weight\n-\n-  def __lt__(self, other):\n-    if self.weighted:\n-      return [element[0] for element in self.elements\n-              ] < [element[0] for element in other.elements]\n+    if min_val is None or max_val is None:\n+      # Buffer is always initialized with sorted elements.\n+      self.min_val = elements[0]\n+      self.max_val = elements[-1]\n     else:\n-      return self.elements < other.elements\n-\n-  def sized_iterator(self):\n-    class QuantileBufferIterator(object):\n-      def __init__(self, elem, weighted, weight):\n-        self._iter = iter(elem)\n-        self.weighted = weighted\n-        self.weight = weight\n-\n-      def __iter__(self):\n-        return self\n+      # Note that collapsed buffer may not contain min and max in the list of\n+      # elements.\n+      self.min_val = min_val\n+      self.max_val = max_val\n+    self._iter = zip(\n+        self.elements,\n+        self.weights if weighted else itertools.repeat(self.weights[0]))\n \n-      def __next__(self):\n-        if self.weighted:\n-          return next(self._iter)\n-        else:\n-          value = next(self._iter)\n-          return (value, self.weight)\n+  def __iter__(self):\n+    return self._iter", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671"}, "originalPosition": 268}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY5NDIyMQ==", "bodyText": "Python 2 support no longer needed.", "url": "https://github.com/apache/beam/pull/13175#discussion_r513694221", "createdAt": "2020-10-28T19:06:33Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -368,82 +383,129 @@ class PerKey(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate\n+        multiple elements at a time more efficiently.\n     \"\"\"\n-    def __init__(self, num_quantiles, key=None, reverse=False, weighted=False):\n+    def __init__(\n+        self,\n+        num_quantiles,\n+        key=None,\n+        reverse=False,\n+        weighted=False,\n+        batch_input=False):\n       self._num_quantiles = num_quantiles\n       self._key = key\n       self._reverse = reverse\n       self._weighted = weighted\n+      self._batch_input = batch_input\n \n     def expand(self, pcoll):\n       return pcoll | CombinePerKey(\n           ApproximateQuantilesCombineFn.create(\n               num_quantiles=self._num_quantiles,\n               key=self._key,\n               reverse=self._reverse,\n-              weighted=self._weighted))\n+              weighted=self._weighted,\n+              batch_input=self._batch_input))\n \n     def display_data(self):\n       return ApproximateQuantiles._display_data(\n           num_quantiles=self._num_quantiles,\n           key=self._key,\n           reverse=self._reverse,\n-          weighted=self._weighted)\n+          weighted=self._weighted,\n+          batch_input=self._batch_input)\n+\n+\n+class _QuantileSpec(object):\n+  \"\"\"Quantiles computation specifications.\"\"\"\n+  def __init__(self, buffer_size, num_buffers, weighted, key, reverse):\n+    # type: (int, int, bool, Any, bool) -> None\n+    self.buffer_size = buffer_size\n+    self.num_buffers = num_buffers\n+    self.weighted = weighted\n+    self.key = key\n+    self.reverse = reverse\n+\n+    # Used to sort tuples of values and weights.\n+    self.weighted_key = None if key is None else (lambda x: key(x[0]))\n+\n+    # Used to compare values.\n+    if key is None and not reverse:\n+      self.less_than = lambda a, b: a < b\n+    elif key is None:\n+      self.less_than = lambda a, b: a > b\n+    elif not reverse:\n+      self.less_than = lambda a, b: key(a) < key(b)\n+    else:\n+      self.less_than = lambda a, b: key(a) > key(b)\n+\n+  def get_argsort_key(self, elements):\n+    # type: (List) -> Any\n+\n+    \"\"\"Returns a key for sorting indices of elements by element's value.\"\"\"\n+    if self.key is None:\n+      return elements.__getitem__\n+    else:\n+      return lambda idx: self.key(elements[idx])\n+\n+  def __reduce__(self):\n+    return (\n+        self.__class__,\n+        (\n+            self.buffer_size,\n+            self.num_buffers,\n+            self.weighted,\n+            self.key,\n+            self.reverse))\n \n \n-class _QuantileBuffer(Generic[T]):\n+class _QuantileBuffer(object):\n   \"\"\"A single buffer in the sense of the referenced algorithm.\n   (see http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.6.6513&rep=rep1\n   &type=pdf and ApproximateQuantilesCombineFn for further information)\"\"\"\n-  def __init__(self, elements, weighted, level=0, weight=1):\n-    # type: (Sequence[T], bool, int, int) -> None\n-    # In case of weighted quantiles, elements are tuples of values and weights.\n+  def __init__(\n+      self, elements, weights, weighted, level=0, min_val=None, max_val=None):\n+    # type: (List, List, bool, int, Any, Any) -> None\n     self.elements = elements\n-    self.weighted = weighted\n+    self.weights = weights\n     self.level = level\n-    self.weight = weight\n-\n-  def __lt__(self, other):\n-    if self.weighted:\n-      return [element[0] for element in self.elements\n-              ] < [element[0] for element in other.elements]\n+    if min_val is None or max_val is None:\n+      # Buffer is always initialized with sorted elements.\n+      self.min_val = elements[0]\n+      self.max_val = elements[-1]\n     else:\n-      return self.elements < other.elements\n-\n-  def sized_iterator(self):\n-    class QuantileBufferIterator(object):\n-      def __init__(self, elem, weighted, weight):\n-        self._iter = iter(elem)\n-        self.weighted = weighted\n-        self.weight = weight\n-\n-      def __iter__(self):\n-        return self\n+      # Note that collapsed buffer may not contain min and max in the list of\n+      # elements.\n+      self.min_val = min_val\n+      self.max_val = max_val\n+    self._iter = zip(\n+        self.elements,\n+        self.weights if weighted else itertools.repeat(self.weights[0]))\n \n-      def __next__(self):\n-        if self.weighted:\n-          return next(self._iter)\n-        else:\n-          value = next(self._iter)\n-          return (value, self.weight)\n+  def __iter__(self):\n+    return self._iter\n \n-      next = __next__  # For Python 2\n+  def __next__(self):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671"}, "originalPosition": 271}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY5NDM0MQ==", "bodyText": "Same.", "url": "https://github.com/apache/beam/pull/13175#discussion_r513694341", "createdAt": "2020-10-28T19:06:47Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -368,82 +383,129 @@ class PerKey(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate\n+        multiple elements at a time more efficiently.\n     \"\"\"\n-    def __init__(self, num_quantiles, key=None, reverse=False, weighted=False):\n+    def __init__(\n+        self,\n+        num_quantiles,\n+        key=None,\n+        reverse=False,\n+        weighted=False,\n+        batch_input=False):\n       self._num_quantiles = num_quantiles\n       self._key = key\n       self._reverse = reverse\n       self._weighted = weighted\n+      self._batch_input = batch_input\n \n     def expand(self, pcoll):\n       return pcoll | CombinePerKey(\n           ApproximateQuantilesCombineFn.create(\n               num_quantiles=self._num_quantiles,\n               key=self._key,\n               reverse=self._reverse,\n-              weighted=self._weighted))\n+              weighted=self._weighted,\n+              batch_input=self._batch_input))\n \n     def display_data(self):\n       return ApproximateQuantiles._display_data(\n           num_quantiles=self._num_quantiles,\n           key=self._key,\n           reverse=self._reverse,\n-          weighted=self._weighted)\n+          weighted=self._weighted,\n+          batch_input=self._batch_input)\n+\n+\n+class _QuantileSpec(object):\n+  \"\"\"Quantiles computation specifications.\"\"\"\n+  def __init__(self, buffer_size, num_buffers, weighted, key, reverse):\n+    # type: (int, int, bool, Any, bool) -> None\n+    self.buffer_size = buffer_size\n+    self.num_buffers = num_buffers\n+    self.weighted = weighted\n+    self.key = key\n+    self.reverse = reverse\n+\n+    # Used to sort tuples of values and weights.\n+    self.weighted_key = None if key is None else (lambda x: key(x[0]))\n+\n+    # Used to compare values.\n+    if key is None and not reverse:\n+      self.less_than = lambda a, b: a < b\n+    elif key is None:\n+      self.less_than = lambda a, b: a > b\n+    elif not reverse:\n+      self.less_than = lambda a, b: key(a) < key(b)\n+    else:\n+      self.less_than = lambda a, b: key(a) > key(b)\n+\n+  def get_argsort_key(self, elements):\n+    # type: (List) -> Any\n+\n+    \"\"\"Returns a key for sorting indices of elements by element's value.\"\"\"\n+    if self.key is None:\n+      return elements.__getitem__\n+    else:\n+      return lambda idx: self.key(elements[idx])\n+\n+  def __reduce__(self):\n+    return (\n+        self.__class__,\n+        (\n+            self.buffer_size,\n+            self.num_buffers,\n+            self.weighted,\n+            self.key,\n+            self.reverse))\n \n \n-class _QuantileBuffer(Generic[T]):\n+class _QuantileBuffer(object):\n   \"\"\"A single buffer in the sense of the referenced algorithm.\n   (see http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.6.6513&rep=rep1\n   &type=pdf and ApproximateQuantilesCombineFn for further information)\"\"\"\n-  def __init__(self, elements, weighted, level=0, weight=1):\n-    # type: (Sequence[T], bool, int, int) -> None\n-    # In case of weighted quantiles, elements are tuples of values and weights.\n+  def __init__(\n+      self, elements, weights, weighted, level=0, min_val=None, max_val=None):\n+    # type: (List, List, bool, int, Any, Any) -> None\n     self.elements = elements\n-    self.weighted = weighted\n+    self.weights = weights\n     self.level = level\n-    self.weight = weight\n-\n-  def __lt__(self, other):\n-    if self.weighted:\n-      return [element[0] for element in self.elements\n-              ] < [element[0] for element in other.elements]\n+    if min_val is None or max_val is None:\n+      # Buffer is always initialized with sorted elements.\n+      self.min_val = elements[0]\n+      self.max_val = elements[-1]\n     else:\n-      return self.elements < other.elements\n-\n-  def sized_iterator(self):\n-    class QuantileBufferIterator(object):\n-      def __init__(self, elem, weighted, weight):\n-        self._iter = iter(elem)\n-        self.weighted = weighted\n-        self.weight = weight\n-\n-      def __iter__(self):\n-        return self\n+      # Note that collapsed buffer may not contain min and max in the list of\n+      # elements.\n+      self.min_val = min_val\n+      self.max_val = max_val\n+    self._iter = zip(\n+        self.elements,\n+        self.weights if weighted else itertools.repeat(self.weights[0]))\n \n-      def __next__(self):\n-        if self.weighted:\n-          return next(self._iter)\n-        else:\n-          value = next(self._iter)\n-          return (value, self.weight)\n+  def __iter__(self):\n+    return self._iter\n \n-      next = __next__  # For Python 2\n+  def __next__(self):\n+    return next(self._iter)\n \n-    return QuantileBufferIterator(self.elements, self.weighted, self.weight)\n+  def __lt__(self, other):\n+    return self.level < other.level\n \n \n-class _QuantileState(Generic[T]):\n+class _QuantileState(object):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671"}, "originalPosition": 280}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0f36b7d5baca732684e678ed7a5cb6cea381ab59", "author": {"user": {"login": "iindyk", "name": "Ihor Indyk"}}, "url": "https://github.com/apache/beam/commit/0f36b7d5baca732684e678ed7a5cb6cea381ab59", "committedDate": "2020-10-29T15:19:12Z", "message": "Addressing some comments."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3NzY3OTYx", "url": "https://github.com/apache/beam/pull/13175#pullrequestreview-527767961", "createdAt": "2020-11-11T00:58:16Z", "commit": {"oid": "0f36b7d5baca732684e678ed7a5cb6cea381ab59"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQwMDo1ODoxNlrOHw1syA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMVQwMDo1OTozNFrOHw1wOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDk3MzUxMg==", "bodyText": "Go ahead and put a trailing comma on this one too.", "url": "https://github.com/apache/beam/pull/13175#discussion_r520973512", "createdAt": "2020-11-11T00:58:16Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -299,15 +300,17 @@ class ApproximateQuantiles(object):\n     out: [0, 2, 5, 7, 100]\n   \"\"\"\n   @staticmethod\n-  def _display_data(num_quantiles, key, reverse, weighted):\n+  def _display_data(num_quantiles, key, reverse, weighted, batch_input):\n     return {\n         'num_quantiles': DisplayDataItem(num_quantiles, label='Quantile Count'),\n         'key': DisplayDataItem(\n             key.__name__\n             if hasattr(key, '__name__') else key.__class__.__name__,\n             label='Record Comparer Key'),\n         'reverse': DisplayDataItem(str(reverse), label='Is Reversed'),\n-        'weighted': DisplayDataItem(str(weighted), label='Is Weighted')\n+        'weighted': DisplayDataItem(str(weighted), label='Is Weighted'),\n+        'batch_input': DisplayDataItem(\n+            str(batch_input), label='Is Input Batched')", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0f36b7d5baca732684e678ed7a5cb6cea381ab59"}, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDk3Mzk1Nw==", "bodyText": "Ah, OK. Thanks for the info.", "url": "https://github.com/apache/beam/pull/13175#discussion_r520973957", "createdAt": "2020-11-11T00:58:58Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -368,82 +383,129 @@ class PerKey(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate\n+        multiple elements at a time more efficiently.\n     \"\"\"\n-    def __init__(self, num_quantiles, key=None, reverse=False, weighted=False):\n+    def __init__(\n+        self,\n+        num_quantiles,\n+        key=None,\n+        reverse=False,\n+        weighted=False,\n+        batch_input=False):\n       self._num_quantiles = num_quantiles\n       self._key = key\n       self._reverse = reverse\n       self._weighted = weighted\n+      self._batch_input = batch_input\n \n     def expand(self, pcoll):\n       return pcoll | CombinePerKey(\n           ApproximateQuantilesCombineFn.create(\n               num_quantiles=self._num_quantiles,\n               key=self._key,\n               reverse=self._reverse,\n-              weighted=self._weighted))\n+              weighted=self._weighted,\n+              batch_input=self._batch_input))\n \n     def display_data(self):\n       return ApproximateQuantiles._display_data(\n           num_quantiles=self._num_quantiles,\n           key=self._key,\n           reverse=self._reverse,\n-          weighted=self._weighted)\n+          weighted=self._weighted,\n+          batch_input=self._batch_input)\n+\n+\n+class _QuantileSpec(object):\n+  \"\"\"Quantiles computation specifications.\"\"\"\n+  def __init__(self, buffer_size, num_buffers, weighted, key, reverse):\n+    # type: (int, int, bool, Any, bool) -> None\n+    self.buffer_size = buffer_size\n+    self.num_buffers = num_buffers\n+    self.weighted = weighted\n+    self.key = key\n+    self.reverse = reverse\n+\n+    # Used to sort tuples of values and weights.\n+    self.weighted_key = None if key is None else (lambda x: key(x[0]))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY5MDM4Mw=="}, "originalCommit": {"oid": "2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671"}, "originalPosition": 184}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDk3NDM5Mw==", "bodyText": "You should be able to inherit rom both object and Generic[T].", "url": "https://github.com/apache/beam/pull/13175#discussion_r520974393", "createdAt": "2020-11-11T00:59:34Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -368,82 +383,129 @@ class PerKey(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate\n+        multiple elements at a time more efficiently.\n     \"\"\"\n-    def __init__(self, num_quantiles, key=None, reverse=False, weighted=False):\n+    def __init__(\n+        self,\n+        num_quantiles,\n+        key=None,\n+        reverse=False,\n+        weighted=False,\n+        batch_input=False):\n       self._num_quantiles = num_quantiles\n       self._key = key\n       self._reverse = reverse\n       self._weighted = weighted\n+      self._batch_input = batch_input\n \n     def expand(self, pcoll):\n       return pcoll | CombinePerKey(\n           ApproximateQuantilesCombineFn.create(\n               num_quantiles=self._num_quantiles,\n               key=self._key,\n               reverse=self._reverse,\n-              weighted=self._weighted))\n+              weighted=self._weighted,\n+              batch_input=self._batch_input))\n \n     def display_data(self):\n       return ApproximateQuantiles._display_data(\n           num_quantiles=self._num_quantiles,\n           key=self._key,\n           reverse=self._reverse,\n-          weighted=self._weighted)\n+          weighted=self._weighted,\n+          batch_input=self._batch_input)\n+\n+\n+class _QuantileSpec(object):\n+  \"\"\"Quantiles computation specifications.\"\"\"\n+  def __init__(self, buffer_size, num_buffers, weighted, key, reverse):\n+    # type: (int, int, bool, Any, bool) -> None\n+    self.buffer_size = buffer_size\n+    self.num_buffers = num_buffers\n+    self.weighted = weighted\n+    self.key = key\n+    self.reverse = reverse\n+\n+    # Used to sort tuples of values and weights.\n+    self.weighted_key = None if key is None else (lambda x: key(x[0]))\n+\n+    # Used to compare values.\n+    if key is None and not reverse:\n+      self.less_than = lambda a, b: a < b\n+    elif key is None:\n+      self.less_than = lambda a, b: a > b\n+    elif not reverse:\n+      self.less_than = lambda a, b: key(a) < key(b)\n+    else:\n+      self.less_than = lambda a, b: key(a) > key(b)\n+\n+  def get_argsort_key(self, elements):\n+    # type: (List) -> Any\n+\n+    \"\"\"Returns a key for sorting indices of elements by element's value.\"\"\"\n+    if self.key is None:\n+      return elements.__getitem__\n+    else:\n+      return lambda idx: self.key(elements[idx])\n+\n+  def __reduce__(self):\n+    return (\n+        self.__class__,\n+        (\n+            self.buffer_size,\n+            self.num_buffers,\n+            self.weighted,\n+            self.key,\n+            self.reverse))\n \n \n-class _QuantileBuffer(Generic[T]):\n+class _QuantileBuffer(object):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY5MDg3MQ=="}, "originalCommit": {"oid": "2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671"}, "originalPosition": 217}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8fff438793b622ac6ae2493d9fb24a581edc4264", "author": {"user": {"login": "iindyk", "name": "Ihor Indyk"}}, "url": "https://github.com/apache/beam/commit/8fff438793b622ac6ae2493d9fb24a581edc4264", "committedDate": "2020-11-11T15:21:12Z", "message": "Adding comma."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTc0NzE3Njc2", "url": "https://github.com/apache/beam/pull/13175#pullrequestreview-574717676", "createdAt": "2021-01-23T01:13:25Z", "commit": {"oid": "8fff438793b622ac6ae2493d9fb24a581edc4264"}, "state": "COMMENTED", "comments": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yM1QwMToxMzoyNVrOIY6bDw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0yN1QyMTozNToyNVrOIbcjnQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2Mjk5MzkzNQ==", "bodyText": "Re: line 766: could you please clarify what is N in the docstring\nAlso, can you please note that the algorithm referenced in the paper is generalized to compute weighted quantiles.", "url": "https://github.com/apache/beam/pull/13175#discussion_r562993935", "createdAt": "2021-01-23T01:13:25Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -501,6 +781,8 @@ class ApproximateQuantilesCombineFn(CombineFn, Generic[T]):\n     weighted: (optional) if set to True, the combiner produces weighted\n       quantiles. The input elements are then expected to be tuples of input\n       values with the corresponding weight.\n+    batch_input: (optional) if set to True, inputs are expected to be batches of", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8fff438793b622ac6ae2493d9fb24a581edc4264"}, "originalPosition": 541}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzQyNzYwMw==", "bodyText": "Can you please comment on the structure of a 'batch' here? in particular for the weighted case. Consider also adding an example to line 295.\n\n\nLooking at the tests, it seems that for weighted case with batches, we expect users to provide  elements and weights as separate lists. From API/usability standpoint, what is the rationale on providing weights as a separate list in as opposed to augmenting the weight to the element in a tuple, which is how elements are represented for non-batched case?", "url": "https://github.com/apache/beam/pull/13175#discussion_r563427603", "createdAt": "2021-01-25T02:09:27Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -327,27 +330,39 @@ class Globally(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8fff438793b622ac6ae2493d9fb24a581edc4264"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDg2MTM3MQ==", "bodyText": "One downside is that mmh3 has only source release, and does not release wheel files. Installing mmh3 requires certain c++ compiler/headers dependencies be present on the machine. It appears that the project is no longer maintained. I tried to contact the maintainer and did not receive a response... Note that sklearn has also implemented a python wrapper for murmurhash: https://scikit-learn.org/stable/modules/generated/sklearn.utils.murmurhash3_32.html. We could likewise incorporate murmurhash into Beam codebase, make a (maintainable) fork of mmh3 and release wheel files, use sklearn's implementation, or try to explore a different library for our hashing needs.", "url": "https://github.com/apache/beam/pull/13175#discussion_r564861371", "createdAt": "2021-01-26T21:57:14Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -61,30 +58,34 @@\n K = typing.TypeVar('K')\n V = typing.TypeVar('V')\n \n+try:\n+  import mmh3  # pylint: disable=import-error\n \n-def _get_default_hash_fn():\n-  \"\"\"Returns either murmurhash or md5 based on installation.\"\"\"\n-  try:\n-    import mmh3  # pylint: disable=import-error\n+  def _mmh3_hash(value):\n+    # mmh3.hash64 returns two 64-bit unsigned integers\n+    return mmh3.hash64(value, seed=0, signed=False)[0]\n+\n+  _default_hash_fn = _mmh3_hash\n+  _default_hash_fn_type = 'mmh3'\n+except ImportError:\n \n-    def _mmh3_hash(value):\n-      # mmh3.hash64 returns two 64-bit unsigned integers\n-      return mmh3.hash64(value, seed=0, signed=False)[0]\n+  def _md5_hash(value):\n+    # md5 is a 128-bit hash, so we truncate the hexdigest (string of 32\n+    # hexadecimal digits) to 16 digits and convert to int to get the 64-bit\n+    # integer fingerprint.\n+    return int(hashlib.md5(value).hexdigest()[:16], 16)\n \n-    return _mmh3_hash\n+  _default_hash_fn = _md5_hash\n+  _default_hash_fn_type = 'md5'\n \n-  except ImportError:\n+\n+def _get_default_hash_fn():\n+  \"\"\"Returns either murmurhash or md5 based on installation.\"\"\"\n+  if _default_hash_fn_type == 'md5':\n     logging.warning(\n         'Couldn\\'t find murmurhash. Install mmh3 for a faster implementation of'", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY4ODE5Ng=="}, "originalCommit": {"oid": "2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDg2MzE2MA==", "bodyText": "Looks like there is already a binary version: https://pypi.org/project/mmh3-binary/, with a somewhat recent release (Apr 2020, but only 3.6 wheels: https://pypi.org/project/mmh3-binary/#files).", "url": "https://github.com/apache/beam/pull/13175#discussion_r564863160", "createdAt": "2021-01-26T22:00:07Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -61,30 +58,34 @@\n K = typing.TypeVar('K')\n V = typing.TypeVar('V')\n \n+try:\n+  import mmh3  # pylint: disable=import-error\n \n-def _get_default_hash_fn():\n-  \"\"\"Returns either murmurhash or md5 based on installation.\"\"\"\n-  try:\n-    import mmh3  # pylint: disable=import-error\n+  def _mmh3_hash(value):\n+    # mmh3.hash64 returns two 64-bit unsigned integers\n+    return mmh3.hash64(value, seed=0, signed=False)[0]\n+\n+  _default_hash_fn = _mmh3_hash\n+  _default_hash_fn_type = 'mmh3'\n+except ImportError:\n \n-    def _mmh3_hash(value):\n-      # mmh3.hash64 returns two 64-bit unsigned integers\n-      return mmh3.hash64(value, seed=0, signed=False)[0]\n+  def _md5_hash(value):\n+    # md5 is a 128-bit hash, so we truncate the hexdigest (string of 32\n+    # hexadecimal digits) to 16 digits and convert to int to get the 64-bit\n+    # integer fingerprint.\n+    return int(hashlib.md5(value).hexdigest()[:16], 16)\n \n-    return _mmh3_hash\n+  _default_hash_fn = _md5_hash\n+  _default_hash_fn_type = 'md5'\n \n-  except ImportError:\n+\n+def _get_default_hash_fn():\n+  \"\"\"Returns either murmurhash or md5 based on installation.\"\"\"\n+  if _default_hash_fn_type == 'md5':\n     logging.warning(\n         'Couldn\\'t find murmurhash. Install mmh3 for a faster implementation of'", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY4ODE5Ng=="}, "originalCommit": {"oid": "2d399ac2c9dd83dd60e9a1b0f5cfea836b47e671"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDg2NTgxNA==", "bodyText": "wording suggestion: s/batch_input/input_batched  or inputs_batched, since the parameter refers to the input rather than the result (like in case of reverse).", "url": "https://github.com/apache/beam/pull/13175#discussion_r564865814", "createdAt": "2021-01-26T22:05:16Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -327,27 +330,39 @@ class Globally(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2MzQyNzYwMw=="}, "originalCommit": {"oid": "8fff438793b622ac6ae2493d9fb24a581edc4264"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDg3NTg5Mw==", "bodyText": "Please comment that in non-weighted case weights stores a single element - the weight of the buffer in the sense of the algorithm. In the generalized (weighted) case, it stores weights of individual elements.", "url": "https://github.com/apache/beam/pull/13175#discussion_r564875893", "createdAt": "2021-01-26T22:25:16Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -368,82 +383,126 @@ class PerKey(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate\n+        multiple elements at a time more efficiently.\n     \"\"\"\n-    def __init__(self, num_quantiles, key=None, reverse=False, weighted=False):\n+    def __init__(\n+        self,\n+        num_quantiles,\n+        key=None,\n+        reverse=False,\n+        weighted=False,\n+        batch_input=False):\n       self._num_quantiles = num_quantiles\n       self._key = key\n       self._reverse = reverse\n       self._weighted = weighted\n+      self._batch_input = batch_input\n \n     def expand(self, pcoll):\n       return pcoll | CombinePerKey(\n           ApproximateQuantilesCombineFn.create(\n               num_quantiles=self._num_quantiles,\n               key=self._key,\n               reverse=self._reverse,\n-              weighted=self._weighted))\n+              weighted=self._weighted,\n+              batch_input=self._batch_input))\n \n     def display_data(self):\n       return ApproximateQuantiles._display_data(\n           num_quantiles=self._num_quantiles,\n           key=self._key,\n           reverse=self._reverse,\n-          weighted=self._weighted)\n+          weighted=self._weighted,\n+          batch_input=self._batch_input)\n+\n+\n+class _QuantileSpec(object):\n+  \"\"\"Quantiles computation specifications.\"\"\"\n+  def __init__(self, buffer_size, num_buffers, weighted, key, reverse):\n+    # type: (int, int, bool, Any, bool) -> None\n+    self.buffer_size = buffer_size\n+    self.num_buffers = num_buffers\n+    self.weighted = weighted\n+    self.key = key\n+    self.reverse = reverse\n+\n+    # Used to sort tuples of values and weights.\n+    self.weighted_key = None if key is None else (lambda x: key(x[0]))\n+\n+    # Used to compare values.\n+    if reverse and key is None:\n+      self.less_than = lambda a, b: a > b\n+    elif reverse:\n+      self.less_than = lambda a, b: key(a) > key(b)\n+    elif key is None:\n+      self.less_than = lambda a, b: a < b\n+    else:\n+      self.less_than = lambda a, b: key(a) < key(b)\n+\n+  def get_argsort_key(self, elements):\n+    # type: (List) -> Any\n+\n+    \"\"\"Returns a key for sorting indices of elements by element's value.\"\"\"\n+    if self.key is None:\n+      return elements.__getitem__\n+    else:\n+      return lambda idx: self.key(elements[idx])\n+\n+  def __reduce__(self):\n+    return (\n+        self.__class__,\n+        (\n+            self.buffer_size,\n+            self.num_buffers,\n+            self.weighted,\n+            self.key,\n+            self.reverse))\n \n \n-class _QuantileBuffer(Generic[T]):\n+class _QuantileBuffer(object):\n   \"\"\"A single buffer in the sense of the referenced algorithm.\n   (see http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.6.6513&rep=rep1\n   &type=pdf and ApproximateQuantilesCombineFn for further information)\"\"\"\n-  def __init__(self, elements, weighted, level=0, weight=1):\n-    # type: (Sequence[T], bool, int, int) -> None\n-    # In case of weighted quantiles, elements are tuples of values and weights.\n+  def __init__(\n+      self, elements, weights, weighted, level=0, min_val=None, max_val=None):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8fff438793b622ac6ae2493d9fb24a581edc4264"}, "originalPosition": 225}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NDg4ODM4Nw==", "bodyText": "For my education, why was this required? Is there some internal state that gets in the way of pickling? Also, could you please add a comment?", "url": "https://github.com/apache/beam/pull/13175#discussion_r564888387", "createdAt": "2021-01-26T22:49:55Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -452,15 +511,236 @@ def __init__(self, buffer_size, num_buffers, unbuffered_elements, buffers):\n     # into new, full buffers and then take them into account when computing the\n     # final output.\n     self.unbuffered_elements = unbuffered_elements\n+    self.unbuffered_weights = unbuffered_weights\n+\n+  def __reduce__(self):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8fff438793b622ac6ae2493d9fb24a581edc4264"}, "originalPosition": 305}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTAzOTU3MA==", "bodyText": "Nit: self.add_input = self._add_inputs may be easier to read.", "url": "https://github.com/apache/beam/pull/13175#discussion_r565039570", "createdAt": "2021-01-27T05:34:56Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -523,29 +805,25 @@ def __init__(\n       num_buffers,  # type: int\n       key=None,\n       reverse=False,\n-      weighted=False):\n-    def _comparator(a, b):\n-      if key:\n-        a, b = key(a), key(b)\n-\n-      retval = int(a > b) - int(a < b)\n-\n-      if reverse:\n-        return -retval\n-\n-      return retval\n-\n-    self._comparator = _comparator\n-\n+      weighted=False,\n+      batch_input=False):\n     self._num_quantiles = num_quantiles\n-    self._buffer_size = buffer_size\n-    self._num_buffers = num_buffers\n-    if weighted:\n-      self._key = (lambda x: x[0]) if key is None else (lambda x: key(x[0]))\n-    else:\n-      self._key = key\n-    self._reverse = reverse\n-    self._weighted = weighted\n+    self._spec = _QuantileSpec(buffer_size, num_buffers, weighted, key, reverse)\n+    self._batch_input = batch_input\n+    if self._batch_input:\n+      setattr(self, 'add_input', self._add_inputs)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8fff438793b622ac6ae2493d9fb24a581edc4264"}, "originalPosition": 587}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTY0MTAxMQ==", "bodyText": "I am not sure how k, b are computed here (see line 872) - it seems that b follows the experimental evaluation suggested in sect. 4.3 of the paper, which corresponds to a 'Munro-Paterson algorithm', while the experimental evaluation for the 'new' algorithm is covered in 4.5. Looking at the Table1, the 'new' algorithm has lower values of k, b, perhaps it is worth to reexamine this logic.", "url": "https://github.com/apache/beam/pull/13175#discussion_r565641011", "createdAt": "2021-01-27T21:19:40Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -582,6 +861,8 @@ def create(\n       weighted: (optional) if set to True, the combiner produces weighted\n         quantiles. The input elements are then expected to be tuples of values\n         with the corresponding weight.\n+      batch_input: (optional) if set to True, inputs are expected to be batches\n+        of elements.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8fff438793b622ac6ae2493d9fb24a581edc4264"}, "originalPosition": 618}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTY0Njg4Mg==", "bodyText": "Would this hint work here ?\n# type: (List) -> Callable[[int], Any]", "url": "https://github.com/apache/beam/pull/13175#discussion_r565646882", "createdAt": "2021-01-27T21:29:13Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -368,82 +383,126 @@ class PerKey(PTransform):\n       weighted: (optional) if set to True, the transform returns weighted\n         quantiles. The input PCollection is then expected to contain tuples of\n         input values with the corresponding weight.\n+      batch_input: (optional) if set to True, the transform expects each element\n+        of input PCollection to be a batch. Provides a way to accumulate\n+        multiple elements at a time more efficiently.\n     \"\"\"\n-    def __init__(self, num_quantiles, key=None, reverse=False, weighted=False):\n+    def __init__(\n+        self,\n+        num_quantiles,\n+        key=None,\n+        reverse=False,\n+        weighted=False,\n+        batch_input=False):\n       self._num_quantiles = num_quantiles\n       self._key = key\n       self._reverse = reverse\n       self._weighted = weighted\n+      self._batch_input = batch_input\n \n     def expand(self, pcoll):\n       return pcoll | CombinePerKey(\n           ApproximateQuantilesCombineFn.create(\n               num_quantiles=self._num_quantiles,\n               key=self._key,\n               reverse=self._reverse,\n-              weighted=self._weighted))\n+              weighted=self._weighted,\n+              batch_input=self._batch_input))\n \n     def display_data(self):\n       return ApproximateQuantiles._display_data(\n           num_quantiles=self._num_quantiles,\n           key=self._key,\n           reverse=self._reverse,\n-          weighted=self._weighted)\n+          weighted=self._weighted,\n+          batch_input=self._batch_input)\n+\n+\n+class _QuantileSpec(object):\n+  \"\"\"Quantiles computation specifications.\"\"\"\n+  def __init__(self, buffer_size, num_buffers, weighted, key, reverse):\n+    # type: (int, int, bool, Any, bool) -> None\n+    self.buffer_size = buffer_size\n+    self.num_buffers = num_buffers\n+    self.weighted = weighted\n+    self.key = key\n+    self.reverse = reverse\n+\n+    # Used to sort tuples of values and weights.\n+    self.weighted_key = None if key is None else (lambda x: key(x[0]))\n+\n+    # Used to compare values.\n+    if reverse and key is None:\n+      self.less_than = lambda a, b: a > b\n+    elif reverse:\n+      self.less_than = lambda a, b: key(a) > key(b)\n+    elif key is None:\n+      self.less_than = lambda a, b: a < b\n+    else:\n+      self.less_than = lambda a, b: key(a) < key(b)\n+\n+  def get_argsort_key(self, elements):\n+    # type: (List) -> Any", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8fff438793b622ac6ae2493d9fb24a581edc4264"}, "originalPosition": 197}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTY0ODMzNw==", "bodyText": "would it make sense to make _collapse, _interpolate, _offset be methods of _QuantileState class ? Would that impact cythonization/performance?", "url": "https://github.com/apache/beam/pull/13175#discussion_r565648337", "createdAt": "2021-01-27T21:31:46Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/transforms/stats.py", "diffHunk": "@@ -636,132 +895,33 @@ def _offset(self, new_weight):\n       self._offset_jitter = 2 - self._offset_jitter\n       return (new_weight + self._offset_jitter) / 2\n \n-  def _collapse(self, buffers):\n-    # type: (Iterable[_QuantileBuffer[T]]) -> _QuantileBuffer[T]\n-    new_level = 0\n-    new_weight = 0\n-    for buffer_elem in buffers:\n-      # As presented in the paper, there should always be at least two\n-      # buffers of the same (minimal) level to collapse, but it is possible\n-      # to violate this condition when combining buffers from independently\n-      # computed shards.  If they differ we take the max.\n-      new_level = max([new_level, buffer_elem.level + 1])\n-      new_weight = new_weight + buffer_elem.weight\n-    if self._weighted:\n-      step = new_weight / (self._buffer_size - 1)\n-      offset = new_weight / (2 * self._buffer_size)\n-    else:\n-      step = new_weight\n-      offset = self._offset(new_weight)\n-    new_elements = self._interpolate(buffers, self._buffer_size, step, offset)\n-    return _QuantileBuffer(new_elements, self._weighted, new_level, new_weight)\n-\n-  def _collapse_if_needed(self, qs):\n-    # type: (_QuantileState) -> None\n-    while len(qs.buffers) > self._num_buffers:\n-      to_collapse = []\n-      to_collapse.append(heapq.heappop(qs.buffers))\n-      to_collapse.append(heapq.heappop(qs.buffers))\n-      min_level = to_collapse[1].level\n-\n-      while len(qs.buffers) > 0 and qs.buffers[0].level == min_level:\n-        to_collapse.append(heapq.heappop(qs.buffers))\n-\n-      heapq.heappush(qs.buffers, self._collapse(to_collapse))\n-\n-  def _interpolate(self, i_buffers, count, step, offset):\n-    \"\"\"\n-    Emulates taking the ordered union of all elements in buffers, repeated\n-    according to their weight, and picking out the (k * step + offset)-th\n-    elements of this list for `0 <= k < count`.\n-    \"\"\"\n-\n-    iterators = []\n-    new_elements = []\n-    compare_key = self._key\n-    if self._key and not self._weighted:\n-      compare_key = lambda x: self._key(x[0])\n-    for buffer_elem in i_buffers:\n-      iterators.append(buffer_elem.sized_iterator())\n-\n-    # Python 3 `heapq.merge` support key comparison and returns an iterator and\n-    # does not pull the data into memory all at once. Python 2 does not\n-    # support comparison on its `heapq.merge` api, so we use the itertools\n-    # which takes the `key` function for comparison and creates an iterator\n-    # from it.\n-    if sys.version_info[0] < 3:\n-      sorted_elem = iter(\n-          sorted(\n-              itertools.chain.from_iterable(iterators),\n-              key=compare_key,\n-              reverse=self._reverse))\n-    else:\n-      sorted_elem = heapq.merge(\n-          *iterators, key=compare_key, reverse=self._reverse)\n-\n-    weighted_element = next(sorted_elem)\n-    current = weighted_element[1]\n-    j = 0\n-    previous = 0\n-    while j < count:\n-      target = j * step + offset\n-      j = j + 1\n-      try:\n-        while current <= target:\n-          weighted_element = next(sorted_elem)\n-          current = current + weighted_element[1]\n-      except StopIteration:\n-        pass\n-      if self._weighted:\n-        new_elements.append((weighted_element[0], current - previous))\n-        previous = current\n-      else:\n-        new_elements.append(weighted_element[0])\n-    return new_elements\n-\n   # TODO(BEAM-7746): Signature incompatible with supertype\n   def create_accumulator(self):  # type: ignore[override]\n-    # type: () -> _QuantileState[T]\n+    # type: () -> _QuantileState\n     self._qs = _QuantileState(\n-        buffer_size=self._buffer_size,\n-        num_buffers=self._num_buffers,\n         unbuffered_elements=[],\n-        buffers=[])\n+        unbuffered_weights=[],\n+        buffers=[],\n+        spec=self._spec)\n     return self._qs\n \n   def add_input(self, quantile_state, element):\n     \"\"\"\n     Add a new element to the collection being summarized by quantile state.\n     \"\"\"\n-    value = element[0] if self._weighted else element\n-    if quantile_state.is_empty():\n-      quantile_state.min_val = quantile_state.max_val = value\n-    elif self._comparator(value, quantile_state.min_val) < 0:\n-      quantile_state.min_val = value\n-    elif self._comparator(value, quantile_state.max_val) > 0:\n-      quantile_state.max_val = value\n-    self._add_unbuffered(quantile_state, elements=[element])\n+    quantile_state.add_unbuffered([element], self._offset)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8fff438793b622ac6ae2493d9fb24a581edc4264"}, "originalPosition": 768}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU2NTY1MDMzMw==", "bodyText": "I have some concerns about test coverage of  ApproximateQuantiles.\n\nDo any of the tests exercise merging of accumulators?\nDo any of the tests exercise collapsing of multiple buffers, including buffers with same & different weights?", "url": "https://github.com/apache/beam/pull/13175#discussion_r565650333", "createdAt": "2021-01-27T21:35:25Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/transforms/stats_test.py", "diffHunk": "@@ -482,13 +482,74 @@ def test_alternate_quantiles(self):\n           equal_to([[\"ccccc\", \"aaa\", \"b\"]]),\n           label='checkWithKeyAndReversed')\n \n+  def test_batched_quantiles(self):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8fff438793b622ac6ae2493d9fb24a581edc4264"}, "originalPosition": 4}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "22a1c319e4b8815bf4983c54cb3789fe88a58a6c", "author": {"user": {"login": "iindyk", "name": "Ihor Indyk"}}, "url": "https://github.com/apache/beam/commit/22a1c319e4b8815bf4983c54cb3789fe88a58a6c", "committedDate": "2021-02-05T04:35:25Z", "message": "Added comments and renamed the parameter."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "06806b025c88f4145ccd26d01e7b5af7dd48f325", "author": {"user": {"login": "iindyk", "name": "Ihor Indyk"}}, "url": "https://github.com/apache/beam/commit/06806b025c88f4145ccd26d01e7b5af7dd48f325", "committedDate": "2021-02-05T04:52:25Z", "message": "Add another comment."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2f4aebf76867613718550229b10ad7816bf4984f", "author": {"user": {"login": "iindyk", "name": "Ihor Indyk"}}, "url": "https://github.com/apache/beam/commit/2f4aebf76867613718550229b10ad7816bf4984f", "committedDate": "2021-02-12T03:24:41Z", "message": "Added a test for buffers collapse and interpolation."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ad955568c0886e1348ddb8f9a9e6f6f36e8b2886", "author": {"user": {"login": "iindyk", "name": "Ihor Indyk"}}, "url": "https://github.com/apache/beam/commit/ad955568c0886e1348ddb8f9a9e6f6f36e8b2886", "committedDate": "2021-02-12T03:35:22Z", "message": "Changing direct method assignment to setattr."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "59b4d6a0ddaa6b82dcd40d1bb654250cb71e78eb", "author": {"user": {"login": "iindyk", "name": "Ihor Indyk"}}, "url": "https://github.com/apache/beam/commit/59b4d6a0ddaa6b82dcd40d1bb654250cb71e78eb", "committedDate": "2021-02-12T20:05:18Z", "message": "Fixing lint error."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTkzODI0ODQz", "url": "https://github.com/apache/beam/pull/13175#pullrequestreview-593824843", "createdAt": "2021-02-19T03:09:35Z", "commit": {"oid": "59b4d6a0ddaa6b82dcd40d1bb654250cb71e78eb"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4948, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}