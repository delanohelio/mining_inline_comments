{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDk5ODUxNTU2", "number": 13048, "reviewThreads": {"totalCount": 13, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xMlQwNDoxMzoyNFrOEsd1YQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQwMTozNzozN1rOE1dcLA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE1MDYxNjAxOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/transforms/core.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xMlQwNDoxMzoyNFrOHfufJA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xMlQxNDo1Mjo1NVrOHgCFCA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzAyOTU0MA==", "bodyText": "This alludes that  setup method is called once per entire collection. Wouldn't it be called per batch? Aggregation may happen on multiple workers, and I imagine that in such case each worker will call setup/teardown methods. Should we switch step 1 and 2?", "url": "https://github.com/apache/beam/pull/13048#discussion_r503029540", "createdAt": "2020-10-12T04:13:24Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/transforms/core.py", "diffHunk": "@@ -875,18 +875,20 @@ class CombineFn(WithTypeHints, HasDisplayData, urns.RunnerApiFn):\n   input argument, which is an instance of CombineFnProcessContext). The\n   combining process proceeds as follows:\n \n-  1. Input values are partitioned into one or more batches.\n-  2. For each batch, the create_accumulator method is invoked to create a fresh\n+  1. The setup method is invoked.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "44c1bd3509c81d9d4ce9e348575e39753b490cea"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzM1MDUzNg==", "bodyText": "It probably should be like this:\n1. Input values are partitioned into one or more batches.\n2. For each batch, the setup method is invoked.\n3. For each batch, the create_accumulator method is invoked...", "url": "https://github.com/apache/beam/pull/13048#discussion_r503350536", "createdAt": "2020-10-12T14:52:55Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/transforms/core.py", "diffHunk": "@@ -875,18 +875,20 @@ class CombineFn(WithTypeHints, HasDisplayData, urns.RunnerApiFn):\n   input argument, which is an instance of CombineFnProcessContext). The\n   combining process proceeds as follows:\n \n-  1. Input values are partitioned into one or more batches.\n-  2. For each batch, the create_accumulator method is invoked to create a fresh\n+  1. The setup method is invoked.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzAyOTU0MA=="}, "originalCommit": {"oid": "44c1bd3509c81d9d4ce9e348575e39753b490cea"}, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE1MDYyMDQyOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/transforms/core.py", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xMlQwNDoxNjo0OFrOHfuhmg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxMjozODozNlrOHgkk1w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzAzMDE3MA==", "bodyText": "What is the reason for a shallow copy here?", "url": "https://github.com/apache/beam/pull/13048#discussion_r503030170", "createdAt": "2020-10-12T04:16:48Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/transforms/core.py", "diffHunk": "@@ -1970,10 +1985,14 @@ def add_input_types(transform):\n       return combined\n \n     if self.has_defaults:\n-      combine_fn = (\n-          self.fn if isinstance(self.fn, CombineFn) else\n-          CombineFn.from_callable(self.fn))\n-      default_value = combine_fn.apply([], *self.args, **self.kwargs)\n+      combine_fn = copy.copy(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "44c1bd3509c81d9d4ce9e348575e39753b490cea"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzMzMjcwOQ==", "bodyText": "Better protection against potential side effects.\nIf using default values, CombineFn.apply is called at pipeline construction time. CombineFn.setup and CombineFn.teardown are called along with it. The same instance of CombineFn is then serialized and sent to runner. I think it would be better to perform initial CombineFn.apply on a copy, so that the state of the instance is not polluted.", "url": "https://github.com/apache/beam/pull/13048#discussion_r503332709", "createdAt": "2020-10-12T14:25:53Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/transforms/core.py", "diffHunk": "@@ -1970,10 +1985,14 @@ def add_input_types(transform):\n       return combined\n \n     if self.has_defaults:\n-      combine_fn = (\n-          self.fn if isinstance(self.fn, CombineFn) else\n-          CombineFn.from_callable(self.fn))\n-      default_value = combine_fn.apply([], *self.args, **self.kwargs)\n+      combine_fn = copy.copy(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzAzMDE3MA=="}, "originalCommit": {"oid": "44c1bd3509c81d9d4ce9e348575e39753b490cea"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzU4NTA3Mg==", "bodyText": "I see. I wonder if calling setup/teardown on during pipeline submission may be undesireable in some cases.\nOne option to offer flexibility is to use introduce default_value() method in CombineFn, and move the setup/teardown call in that method, trying this out in: #13081.", "url": "https://github.com/apache/beam/pull/13048#discussion_r503585072", "createdAt": "2020-10-12T23:34:10Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/transforms/core.py", "diffHunk": "@@ -1970,10 +1985,14 @@ def add_input_types(transform):\n       return combined\n \n     if self.has_defaults:\n-      combine_fn = (\n-          self.fn if isinstance(self.fn, CombineFn) else\n-          CombineFn.from_callable(self.fn))\n-      default_value = combine_fn.apply([], *self.args, **self.kwargs)\n+      combine_fn = copy.copy(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzAzMDE3MA=="}, "originalCommit": {"oid": "44c1bd3509c81d9d4ce9e348575e39753b490cea"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzkxNTczNQ==", "bodyText": "Left some comments over there", "url": "https://github.com/apache/beam/pull/13048#discussion_r503915735", "createdAt": "2020-10-13T12:38:36Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/transforms/core.py", "diffHunk": "@@ -1970,10 +1985,14 @@ def add_input_types(transform):\n       return combined\n \n     if self.has_defaults:\n-      combine_fn = (\n-          self.fn if isinstance(self.fn, CombineFn) else\n-          CombineFn.from_callable(self.fn))\n-      default_value = combine_fn.apply([], *self.args, **self.kwargs)\n+      combine_fn = copy.copy(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzAzMDE3MA=="}, "originalCommit": {"oid": "44c1bd3509c81d9d4ce9e348575e39753b490cea"}, "originalPosition": 61}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE1MDYzMDU0OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/transforms/combinefn_lifecycle_test.py", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xMlQwNDoyNDoyMVrOHfunpQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QxMjozNjozNlrOHgkfuA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzAzMTcxNw==", "bodyText": "Should we make  non-portable Dataflow runner detect usage of combiner initialization and alert the user that this functionality is unsupported?\ncc: @robertwb", "url": "https://github.com/apache/beam/pull/13048#discussion_r503031717", "createdAt": "2020-10-12T04:24:21Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/transforms/combinefn_lifecycle_test.py", "diffHunk": "@@ -0,0 +1,147 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"ValidatesRunner tests for CombineFn lifecycle and bundle methods.\"\"\"\n+\n+# pytype: skip-file\n+\n+import unittest\n+from weakref import WeakSet\n+\n+from nose.plugins.attrib import attr\n+\n+import apache_beam as beam\n+from apache_beam.options.pipeline_options import DebugOptions\n+from apache_beam.options.pipeline_options import StandardOptions\n+from apache_beam.runners.direct import direct_runner\n+from apache_beam.runners.portability import fn_api_runner\n+from apache_beam.testing.test_pipeline import TestPipeline\n+from apache_beam.testing.util import assert_that\n+from apache_beam.testing.util import equal_to\n+from apache_beam.transforms import trigger\n+from apache_beam.transforms import window\n+\n+\n+class CallSequenceEnforcingCombineFn(beam.CombineFn):\n+  instances = WeakSet()\n+\n+  def __init__(self):\n+    super(CallSequenceEnforcingCombineFn, self).__init__()\n+    self._setup_called = False\n+    self._accumulators_created = 0\n+    self._teardown_called = False\n+\n+  def setup(self):\n+    assert not self._setup_called, 'setup should not be called twice'\n+    assert not self._teardown_called, 'setup should be called before teardown'\n+    # Keep track of instances so that we can check if teardown is called\n+    # properly after pipeline execution.\n+    self.instances.add(self)\n+    self._setup_called = True\n+\n+  def create_accumulator(self):\n+    assert self._setup_called, 'setup should have been called'\n+    assert not self._teardown_called, 'teardown should not have been called'\n+    self._accumulators_created += 1\n+    return 0\n+\n+  def add_input(self, mutable_accumulator, element):\n+    assert self._setup_called, 'setup should have been called'\n+    assert self._accumulators_created > 0, \\\n+        'create_accumulator should have been called'\n+    assert not self._teardown_called, 'teardown should not have been called'\n+    mutable_accumulator += element\n+    return mutable_accumulator\n+\n+  def add_inputs(self, mutable_accumulator, elements):\n+    return self.add_input(mutable_accumulator, sum(elements))\n+\n+  def merge_accumulators(self, accumulators):\n+    assert self._setup_called, 'setup should have been called'\n+    assert not self._teardown_called, 'teardown should not have been called'\n+    return sum(accumulators)\n+\n+  def extract_output(self, accumulator):\n+    assert self._setup_called, 'setup should have been called'\n+    assert not self._teardown_called, 'teardown should not have been called'\n+    return accumulator\n+\n+  def teardown(self):\n+    assert self._setup_called, 'setup should have been called'\n+    assert not self._teardown_called, 'teardown should not be called twice'\n+    self._teardown_called = True\n+\n+\n+class BaseCombineFnLifecycleTest(unittest.TestCase):\n+  def start(self, pipeline, lift_combiners=True):\n+    with pipeline as p:\n+      pcoll = p | 'Start' >> beam.Create(range(5))\n+\n+      # Certain triggers, such as AfterCount, are incompatible with combiner\n+      # lifting. We can use that fact to prevent combiners from being lifted.\n+      if not lift_combiners:\n+        pcoll |= beam.WindowInto(\n+            window.GlobalWindows(),\n+            trigger=trigger.AfterCount(5),\n+            accumulation_mode=trigger.AccumulationMode.DISCARDING)\n+\n+      pcoll |= 'Do' >> beam.CombineGlobally(CallSequenceEnforcingCombineFn())\n+      assert_that(pcoll, equal_to([10]))\n+\n+    # Ensure that _teardown_called equals True for all CombineFns.\n+    for instance in CallSequenceEnforcingCombineFn.instances:\n+      self.assertTrue(instance._teardown_called)\n+\n+\n+@attr('ValidatesRunner')\n+class CombineFnLifecycleTest(BaseCombineFnLifecycleTest):\n+  def setUp(self):\n+    self.pipeline = TestPipeline(is_integration_test=True)\n+    options = self.pipeline.get_pipeline_options()\n+    standard_options = options.view_as(StandardOptions)\n+    experiments = options.view_as(DebugOptions).experiments or []\n+\n+    if 'DataflowRunner' in standard_options.runner and \\\n+       not standard_options.streaming and \\\n+       'beam_fn_api' not in experiments and 'use_runner_v2' not in experiments:\n+      self.skipTest(\n+          'Non-portable Dataflow batch worker does not support '", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "44c1bd3509c81d9d4ce9e348575e39753b490cea"}, "originalPosition": 122}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzMzNjAzMg==", "bodyText": "Yes, it's probably a good idea.\nShould we raise an exception and exit the program abnormally if user-provided setup and teardown are detected, or just inform the user that those methods won't be called?", "url": "https://github.com/apache/beam/pull/13048#discussion_r503336032", "createdAt": "2020-10-12T14:30:35Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/transforms/combinefn_lifecycle_test.py", "diffHunk": "@@ -0,0 +1,147 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"ValidatesRunner tests for CombineFn lifecycle and bundle methods.\"\"\"\n+\n+# pytype: skip-file\n+\n+import unittest\n+from weakref import WeakSet\n+\n+from nose.plugins.attrib import attr\n+\n+import apache_beam as beam\n+from apache_beam.options.pipeline_options import DebugOptions\n+from apache_beam.options.pipeline_options import StandardOptions\n+from apache_beam.runners.direct import direct_runner\n+from apache_beam.runners.portability import fn_api_runner\n+from apache_beam.testing.test_pipeline import TestPipeline\n+from apache_beam.testing.util import assert_that\n+from apache_beam.testing.util import equal_to\n+from apache_beam.transforms import trigger\n+from apache_beam.transforms import window\n+\n+\n+class CallSequenceEnforcingCombineFn(beam.CombineFn):\n+  instances = WeakSet()\n+\n+  def __init__(self):\n+    super(CallSequenceEnforcingCombineFn, self).__init__()\n+    self._setup_called = False\n+    self._accumulators_created = 0\n+    self._teardown_called = False\n+\n+  def setup(self):\n+    assert not self._setup_called, 'setup should not be called twice'\n+    assert not self._teardown_called, 'setup should be called before teardown'\n+    # Keep track of instances so that we can check if teardown is called\n+    # properly after pipeline execution.\n+    self.instances.add(self)\n+    self._setup_called = True\n+\n+  def create_accumulator(self):\n+    assert self._setup_called, 'setup should have been called'\n+    assert not self._teardown_called, 'teardown should not have been called'\n+    self._accumulators_created += 1\n+    return 0\n+\n+  def add_input(self, mutable_accumulator, element):\n+    assert self._setup_called, 'setup should have been called'\n+    assert self._accumulators_created > 0, \\\n+        'create_accumulator should have been called'\n+    assert not self._teardown_called, 'teardown should not have been called'\n+    mutable_accumulator += element\n+    return mutable_accumulator\n+\n+  def add_inputs(self, mutable_accumulator, elements):\n+    return self.add_input(mutable_accumulator, sum(elements))\n+\n+  def merge_accumulators(self, accumulators):\n+    assert self._setup_called, 'setup should have been called'\n+    assert not self._teardown_called, 'teardown should not have been called'\n+    return sum(accumulators)\n+\n+  def extract_output(self, accumulator):\n+    assert self._setup_called, 'setup should have been called'\n+    assert not self._teardown_called, 'teardown should not have been called'\n+    return accumulator\n+\n+  def teardown(self):\n+    assert self._setup_called, 'setup should have been called'\n+    assert not self._teardown_called, 'teardown should not be called twice'\n+    self._teardown_called = True\n+\n+\n+class BaseCombineFnLifecycleTest(unittest.TestCase):\n+  def start(self, pipeline, lift_combiners=True):\n+    with pipeline as p:\n+      pcoll = p | 'Start' >> beam.Create(range(5))\n+\n+      # Certain triggers, such as AfterCount, are incompatible with combiner\n+      # lifting. We can use that fact to prevent combiners from being lifted.\n+      if not lift_combiners:\n+        pcoll |= beam.WindowInto(\n+            window.GlobalWindows(),\n+            trigger=trigger.AfterCount(5),\n+            accumulation_mode=trigger.AccumulationMode.DISCARDING)\n+\n+      pcoll |= 'Do' >> beam.CombineGlobally(CallSequenceEnforcingCombineFn())\n+      assert_that(pcoll, equal_to([10]))\n+\n+    # Ensure that _teardown_called equals True for all CombineFns.\n+    for instance in CallSequenceEnforcingCombineFn.instances:\n+      self.assertTrue(instance._teardown_called)\n+\n+\n+@attr('ValidatesRunner')\n+class CombineFnLifecycleTest(BaseCombineFnLifecycleTest):\n+  def setUp(self):\n+    self.pipeline = TestPipeline(is_integration_test=True)\n+    options = self.pipeline.get_pipeline_options()\n+    standard_options = options.view_as(StandardOptions)\n+    experiments = options.view_as(DebugOptions).experiments or []\n+\n+    if 'DataflowRunner' in standard_options.runner and \\\n+       not standard_options.streaming and \\\n+       'beam_fn_api' not in experiments and 'use_runner_v2' not in experiments:\n+      self.skipTest(\n+          'Non-portable Dataflow batch worker does not support '", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzAzMTcxNw=="}, "originalCommit": {"oid": "44c1bd3509c81d9d4ce9e348575e39753b490cea"}, "originalPosition": 122}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzU4NTY5Ng==", "bodyText": "On BEAM-3736 the recommendation was to reject the job. It is more problematic with Java SDK, since there are a lot of runner. AFAIK with Python SDK, Dataflow is the only non-portable runner (not including direct runner).", "url": "https://github.com/apache/beam/pull/13048#discussion_r503585696", "createdAt": "2020-10-12T23:36:29Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/transforms/combinefn_lifecycle_test.py", "diffHunk": "@@ -0,0 +1,147 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"ValidatesRunner tests for CombineFn lifecycle and bundle methods.\"\"\"\n+\n+# pytype: skip-file\n+\n+import unittest\n+from weakref import WeakSet\n+\n+from nose.plugins.attrib import attr\n+\n+import apache_beam as beam\n+from apache_beam.options.pipeline_options import DebugOptions\n+from apache_beam.options.pipeline_options import StandardOptions\n+from apache_beam.runners.direct import direct_runner\n+from apache_beam.runners.portability import fn_api_runner\n+from apache_beam.testing.test_pipeline import TestPipeline\n+from apache_beam.testing.util import assert_that\n+from apache_beam.testing.util import equal_to\n+from apache_beam.transforms import trigger\n+from apache_beam.transforms import window\n+\n+\n+class CallSequenceEnforcingCombineFn(beam.CombineFn):\n+  instances = WeakSet()\n+\n+  def __init__(self):\n+    super(CallSequenceEnforcingCombineFn, self).__init__()\n+    self._setup_called = False\n+    self._accumulators_created = 0\n+    self._teardown_called = False\n+\n+  def setup(self):\n+    assert not self._setup_called, 'setup should not be called twice'\n+    assert not self._teardown_called, 'setup should be called before teardown'\n+    # Keep track of instances so that we can check if teardown is called\n+    # properly after pipeline execution.\n+    self.instances.add(self)\n+    self._setup_called = True\n+\n+  def create_accumulator(self):\n+    assert self._setup_called, 'setup should have been called'\n+    assert not self._teardown_called, 'teardown should not have been called'\n+    self._accumulators_created += 1\n+    return 0\n+\n+  def add_input(self, mutable_accumulator, element):\n+    assert self._setup_called, 'setup should have been called'\n+    assert self._accumulators_created > 0, \\\n+        'create_accumulator should have been called'\n+    assert not self._teardown_called, 'teardown should not have been called'\n+    mutable_accumulator += element\n+    return mutable_accumulator\n+\n+  def add_inputs(self, mutable_accumulator, elements):\n+    return self.add_input(mutable_accumulator, sum(elements))\n+\n+  def merge_accumulators(self, accumulators):\n+    assert self._setup_called, 'setup should have been called'\n+    assert not self._teardown_called, 'teardown should not have been called'\n+    return sum(accumulators)\n+\n+  def extract_output(self, accumulator):\n+    assert self._setup_called, 'setup should have been called'\n+    assert not self._teardown_called, 'teardown should not have been called'\n+    return accumulator\n+\n+  def teardown(self):\n+    assert self._setup_called, 'setup should have been called'\n+    assert not self._teardown_called, 'teardown should not be called twice'\n+    self._teardown_called = True\n+\n+\n+class BaseCombineFnLifecycleTest(unittest.TestCase):\n+  def start(self, pipeline, lift_combiners=True):\n+    with pipeline as p:\n+      pcoll = p | 'Start' >> beam.Create(range(5))\n+\n+      # Certain triggers, such as AfterCount, are incompatible with combiner\n+      # lifting. We can use that fact to prevent combiners from being lifted.\n+      if not lift_combiners:\n+        pcoll |= beam.WindowInto(\n+            window.GlobalWindows(),\n+            trigger=trigger.AfterCount(5),\n+            accumulation_mode=trigger.AccumulationMode.DISCARDING)\n+\n+      pcoll |= 'Do' >> beam.CombineGlobally(CallSequenceEnforcingCombineFn())\n+      assert_that(pcoll, equal_to([10]))\n+\n+    # Ensure that _teardown_called equals True for all CombineFns.\n+    for instance in CallSequenceEnforcingCombineFn.instances:\n+      self.assertTrue(instance._teardown_called)\n+\n+\n+@attr('ValidatesRunner')\n+class CombineFnLifecycleTest(BaseCombineFnLifecycleTest):\n+  def setUp(self):\n+    self.pipeline = TestPipeline(is_integration_test=True)\n+    options = self.pipeline.get_pipeline_options()\n+    standard_options = options.view_as(StandardOptions)\n+    experiments = options.view_as(DebugOptions).experiments or []\n+\n+    if 'DataflowRunner' in standard_options.runner and \\\n+       not standard_options.streaming and \\\n+       'beam_fn_api' not in experiments and 'use_runner_v2' not in experiments:\n+      self.skipTest(\n+          'Non-portable Dataflow batch worker does not support '", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzAzMTcxNw=="}, "originalCommit": {"oid": "44c1bd3509c81d9d4ce9e348575e39753b490cea"}, "originalPosition": 122}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzkxNDQyNA==", "bodyText": "I've added a code that rejects the job and provides clear information why it's rejected.", "url": "https://github.com/apache/beam/pull/13048#discussion_r503914424", "createdAt": "2020-10-13T12:36:36Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/transforms/combinefn_lifecycle_test.py", "diffHunk": "@@ -0,0 +1,147 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"ValidatesRunner tests for CombineFn lifecycle and bundle methods.\"\"\"\n+\n+# pytype: skip-file\n+\n+import unittest\n+from weakref import WeakSet\n+\n+from nose.plugins.attrib import attr\n+\n+import apache_beam as beam\n+from apache_beam.options.pipeline_options import DebugOptions\n+from apache_beam.options.pipeline_options import StandardOptions\n+from apache_beam.runners.direct import direct_runner\n+from apache_beam.runners.portability import fn_api_runner\n+from apache_beam.testing.test_pipeline import TestPipeline\n+from apache_beam.testing.util import assert_that\n+from apache_beam.testing.util import equal_to\n+from apache_beam.transforms import trigger\n+from apache_beam.transforms import window\n+\n+\n+class CallSequenceEnforcingCombineFn(beam.CombineFn):\n+  instances = WeakSet()\n+\n+  def __init__(self):\n+    super(CallSequenceEnforcingCombineFn, self).__init__()\n+    self._setup_called = False\n+    self._accumulators_created = 0\n+    self._teardown_called = False\n+\n+  def setup(self):\n+    assert not self._setup_called, 'setup should not be called twice'\n+    assert not self._teardown_called, 'setup should be called before teardown'\n+    # Keep track of instances so that we can check if teardown is called\n+    # properly after pipeline execution.\n+    self.instances.add(self)\n+    self._setup_called = True\n+\n+  def create_accumulator(self):\n+    assert self._setup_called, 'setup should have been called'\n+    assert not self._teardown_called, 'teardown should not have been called'\n+    self._accumulators_created += 1\n+    return 0\n+\n+  def add_input(self, mutable_accumulator, element):\n+    assert self._setup_called, 'setup should have been called'\n+    assert self._accumulators_created > 0, \\\n+        'create_accumulator should have been called'\n+    assert not self._teardown_called, 'teardown should not have been called'\n+    mutable_accumulator += element\n+    return mutable_accumulator\n+\n+  def add_inputs(self, mutable_accumulator, elements):\n+    return self.add_input(mutable_accumulator, sum(elements))\n+\n+  def merge_accumulators(self, accumulators):\n+    assert self._setup_called, 'setup should have been called'\n+    assert not self._teardown_called, 'teardown should not have been called'\n+    return sum(accumulators)\n+\n+  def extract_output(self, accumulator):\n+    assert self._setup_called, 'setup should have been called'\n+    assert not self._teardown_called, 'teardown should not have been called'\n+    return accumulator\n+\n+  def teardown(self):\n+    assert self._setup_called, 'setup should have been called'\n+    assert not self._teardown_called, 'teardown should not be called twice'\n+    self._teardown_called = True\n+\n+\n+class BaseCombineFnLifecycleTest(unittest.TestCase):\n+  def start(self, pipeline, lift_combiners=True):\n+    with pipeline as p:\n+      pcoll = p | 'Start' >> beam.Create(range(5))\n+\n+      # Certain triggers, such as AfterCount, are incompatible with combiner\n+      # lifting. We can use that fact to prevent combiners from being lifted.\n+      if not lift_combiners:\n+        pcoll |= beam.WindowInto(\n+            window.GlobalWindows(),\n+            trigger=trigger.AfterCount(5),\n+            accumulation_mode=trigger.AccumulationMode.DISCARDING)\n+\n+      pcoll |= 'Do' >> beam.CombineGlobally(CallSequenceEnforcingCombineFn())\n+      assert_that(pcoll, equal_to([10]))\n+\n+    # Ensure that _teardown_called equals True for all CombineFns.\n+    for instance in CallSequenceEnforcingCombineFn.instances:\n+      self.assertTrue(instance._teardown_called)\n+\n+\n+@attr('ValidatesRunner')\n+class CombineFnLifecycleTest(BaseCombineFnLifecycleTest):\n+  def setUp(self):\n+    self.pipeline = TestPipeline(is_integration_test=True)\n+    options = self.pipeline.get_pipeline_options()\n+    standard_options = options.view_as(StandardOptions)\n+    experiments = options.view_as(DebugOptions).experiments or []\n+\n+    if 'DataflowRunner' in standard_options.runner and \\\n+       not standard_options.streaming and \\\n+       'beam_fn_api' not in experiments and 'use_runner_v2' not in experiments:\n+      self.skipTest(\n+          'Non-portable Dataflow batch worker does not support '", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzAzMTcxNw=="}, "originalCommit": {"oid": "44c1bd3509c81d9d4ce9e348575e39753b490cea"}, "originalPosition": 122}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzE1MDY0MzgxOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/transforms/core.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xMlQwNDozMzoyNlrOHfuu6A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xMlQxNDozMjowNVrOHgBQSA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzAzMzU3Ng==", "bodyText": "nit: s/disposed/disposed of", "url": "https://github.com/apache/beam/pull/13048#discussion_r503033576", "createdAt": "2020-10-12T04:33:26Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/transforms/core.py", "diffHunk": "@@ -895,6 +897,15 @@ class CombineFn(WithTypeHints, HasDisplayData, urns.RunnerApiFn):\n   def default_label(self):\n     return self.__class__.__name__\n \n+  def setup(self):\n+    \"\"\"Called to prepare an instance for combining.\n+\n+    This method can be useful if there is some state that needs to be loaded\n+    before executing any of the other methods. The resources can then be\n+    disposed in ``CombineFn.teardown``.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "44c1bd3509c81d9d4ce9e348575e39753b490cea"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzMzNzAzMg==", "bodyText": "Thanks.", "url": "https://github.com/apache/beam/pull/13048#discussion_r503337032", "createdAt": "2020-10-12T14:32:05Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/transforms/core.py", "diffHunk": "@@ -895,6 +897,15 @@ class CombineFn(WithTypeHints, HasDisplayData, urns.RunnerApiFn):\n   def default_label(self):\n     return self.__class__.__name__\n \n+  def setup(self):\n+    \"\"\"Called to prepare an instance for combining.\n+\n+    This method can be useful if there is some state that needs to be loaded\n+    before executing any of the other methods. The resources can then be\n+    disposed in ``CombineFn.teardown``.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzAzMzU3Ng=="}, "originalCommit": {"oid": "44c1bd3509c81d9d4ce9e348575e39753b490cea"}, "originalPosition": 35}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxODI3NjUzOnYy", "diffSide": "RIGHT", "path": "CHANGES.md", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxNzoxNzoxOVrOHp1F0A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxNzoxNzoxOVrOHp1F0A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzYyMzUwNA==", "bodyText": "nit: 'a state' -> 'the CombineFn's state'", "url": "https://github.com/apache/beam/pull/13048#discussion_r513623504", "createdAt": "2020-10-28T17:17:19Z", "author": {"login": "yifanmai"}, "path": "CHANGES.md", "diffHunk": "@@ -62,6 +62,7 @@\n \n ## New Features / Improvements\n * Added support for avro payload format in Beam SQL Kafka Table ([BEAM-10885](https://issues.apache.org/jira/browse/BEAM-10885))\n+* Added CombineFn.setup and CombineFn.teardown to Python SDK. These methods let you initialize a state before any of the other methods of the CombineFn is executed and clean that state up later on. ([BEAM-3736](https://issues.apache.org/jira/browse/BEAM-3736))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6dd53adaa4186d0d79d79071b4bb6dea46e645eb"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxODI4NTI0OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/dataflow/dataflow_runner.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxNzoxOToyNVrOHp1LVA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOVQxNjoyNjowNlrOHqkLrg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzYyNDkxNg==", "bodyText": "Question: Is there any plan to support this in non-portable Dataflow Runner, or will this be a V2 feature only?", "url": "https://github.com/apache/beam/pull/13048#discussion_r513624916", "createdAt": "2020-10-28T17:19:25Z", "author": {"login": "yifanmai"}, "path": "sdks/python/apache_beam/runners/dataflow/dataflow_runner.py", "diffHunk": "@@ -411,6 +411,33 @@ def visit_transform(self, transform_node):\n \n     return FlattenInputVisitor()\n \n+  @staticmethod\n+  def combinefn_visitor():\n+    # Imported here to avoid circular dependencies.\n+    from apache_beam.pipeline import PipelineVisitor\n+    from apache_beam import core\n+\n+    class CombineFnVisitor(PipelineVisitor):\n+      \"\"\"Checks if `CombineFn` has non-default setup or teardown methods.\n+      If yes, raises `ValueError`.\n+      \"\"\"\n+      def visit_transform(self, applied_transform):\n+        transform = applied_transform.transform\n+        if isinstance(transform, core.ParDo) and isinstance(\n+            transform.fn, core.CombineValuesDoFn):\n+          if self._overrides_setup_or_teardown(transform.fn.combinefn):\n+            raise ValueError(\n+                'CombineFn.setup and CombineFn.teardown are '\n+                'not supported with non-portable Dataflow '\n+                'runner. Please use Dataflow Runner V2 instead.')", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6dd53adaa4186d0d79d79071b4bb6dea46e645eb"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDM5NTA1NA==", "bodyText": "I think the question is for Dataflow team. From my perspective, I think there's no such need to support this in non-portable Dataflow, given that new batch pipelines will start using Dataflow Runner V2 in a month (December 4).", "url": "https://github.com/apache/beam/pull/13048#discussion_r514395054", "createdAt": "2020-10-29T16:26:06Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/runners/dataflow/dataflow_runner.py", "diffHunk": "@@ -411,6 +411,33 @@ def visit_transform(self, transform_node):\n \n     return FlattenInputVisitor()\n \n+  @staticmethod\n+  def combinefn_visitor():\n+    # Imported here to avoid circular dependencies.\n+    from apache_beam.pipeline import PipelineVisitor\n+    from apache_beam import core\n+\n+    class CombineFnVisitor(PipelineVisitor):\n+      \"\"\"Checks if `CombineFn` has non-default setup or teardown methods.\n+      If yes, raises `ValueError`.\n+      \"\"\"\n+      def visit_transform(self, applied_transform):\n+        transform = applied_transform.transform\n+        if isinstance(transform, core.ParDo) and isinstance(\n+            transform.fn, core.CombineValuesDoFn):\n+          if self._overrides_setup_or_teardown(transform.fn.combinefn):\n+            raise ValueError(\n+                'CombineFn.setup and CombineFn.teardown are '\n+                'not supported with non-portable Dataflow '\n+                'runner. Please use Dataflow Runner V2 instead.')", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzYyNDkxNg=="}, "originalCommit": {"oid": "6dd53adaa4186d0d79d79071b4bb6dea46e645eb"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxODMzNjU0OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/transforms/combinefn_lifecycle_pipeline.py", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxNzozMDoxNlrOHp1q2g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxNzozMDoxNlrOHp1q2g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzYzMjk4Ng==", "bodyText": "nit: 'arythmetic' -> 'arithmetic'", "url": "https://github.com/apache/beam/pull/13048#discussion_r513632986", "createdAt": "2020-10-28T17:30:16Z", "author": {"login": "yifanmai"}, "path": "sdks/python/apache_beam/transforms/combinefn_lifecycle_pipeline.py", "diffHunk": "@@ -0,0 +1,131 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+# pytype: skip-file\n+\n+from typing import Set\n+from typing import Tuple\n+\n+import apache_beam as beam\n+from apache_beam.options.pipeline_options import TypeOptions\n+from apache_beam.testing.util import assert_that\n+from apache_beam.testing.util import equal_to\n+from apache_beam.transforms import combiners\n+from apache_beam.transforms import trigger\n+from apache_beam.transforms import userstate\n+from apache_beam.transforms import window\n+from apache_beam.typehints import with_input_types\n+from apache_beam.typehints import with_output_types\n+\n+\n+@with_input_types(int)\n+@with_output_types(int)\n+class CallSequenceEnforcingCombineFn(beam.CombineFn):\n+  instances = set()  # type: Set[CallSequenceEnforcingCombineFn]\n+\n+  def __init__(self):\n+    super(CallSequenceEnforcingCombineFn, self).__init__()\n+    self._setup_called = False\n+    self._teardown_called = False\n+\n+  def setup(self, *args, **kwargs):\n+    assert not self._setup_called, 'setup should not be called twice'\n+    assert not self._teardown_called, 'setup should be called before teardown'\n+    # Keep track of instances so that we can check if teardown is called\n+    # properly after pipeline execution.\n+    self.instances.add(self)\n+    self._setup_called = True\n+\n+  def create_accumulator(self, *args, **kwargs):\n+    assert self._setup_called, 'setup should have been called'\n+    assert not self._teardown_called, 'teardown should not have been called'\n+    return 0\n+\n+  def add_input(self, mutable_accumulator, element, *args, **kwargs):\n+    assert self._setup_called, 'setup should have been called'\n+    assert not self._teardown_called, 'teardown should not have been called'\n+    mutable_accumulator += element\n+    return mutable_accumulator\n+\n+  def add_inputs(self, mutable_accumulator, elements, *args, **kwargs):\n+    return self.add_input(mutable_accumulator, sum(elements))\n+\n+  def merge_accumulators(self, accumulators, *args, **kwargs):\n+    assert self._setup_called, 'setup should have been called'\n+    assert not self._teardown_called, 'teardown should not have been called'\n+    return sum(accumulators)\n+\n+  def extract_output(self, accumulator, *args, **kwargs):\n+    assert self._setup_called, 'setup should have been called'\n+    assert not self._teardown_called, 'teardown should not have been called'\n+    return accumulator\n+\n+  def teardown(self, *args, **kwargs):\n+    assert self._setup_called, 'setup should have been called'\n+    assert not self._teardown_called, 'teardown should not be called twice'\n+    self._teardown_called = True\n+\n+\n+@with_input_types(Tuple[None, str])\n+@with_output_types(Tuple[int, str])\n+class IndexAssigningDoFn(beam.DoFn):\n+  state_param = beam.DoFn.StateParam(\n+      userstate.CombiningValueStateSpec(\n+          'index', beam.coders.VarIntCoder(), CallSequenceEnforcingCombineFn()))\n+\n+  def process(self, element, state=state_param):\n+    _, value = element\n+    current_index = state.read()\n+    yield current_index, value\n+    state.add(1)\n+\n+\n+def run_combine(pipeline, input_elements=5, lift_combiners=True):\n+  # Calculate the excepted result, which is the sum of an arythmetic sequence.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6dd53adaa4186d0d79d79071b4bb6dea46e645eb"}, "originalPosition": 98}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxODQ2OTk4OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/transforms/core.py", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxODowMTowNlrOHp293Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxODowMTowNlrOHp293Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY1NDIzNw==", "bodyText": "nit: this can be copy.deepcopy(self.fn) if... i.e. copy is only needed in the first branch", "url": "https://github.com/apache/beam/pull/13048#discussion_r513654237", "createdAt": "2020-10-28T18:01:06Z", "author": {"login": "yifanmai"}, "path": "sdks/python/apache_beam/transforms/core.py", "diffHunk": "@@ -1975,10 +1990,14 @@ def add_input_types(transform):\n       return combined\n \n     if self.has_defaults:\n-      combine_fn = (\n-          self.fn if isinstance(self.fn, CombineFn) else\n-          CombineFn.from_callable(self.fn))\n-      default_value = combine_fn.apply([], *self.args, **self.kwargs)\n+      combine_fn = copy.deepcopy(\n+          self.fn if isinstance(self.fn, CombineFn) else CombineFn.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6dd53adaa4186d0d79d79071b4bb6dea46e645eb"}, "originalPosition": 60}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIxODU0NDA5OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/transforms/core.py", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQxODoxOTo0OVrOHp3smA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOVQxNzo0ODo0MlrOHqnsHw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY2NjIwMA==", "bodyText": "Question: What is the expected behavior if setup throws an exception? Should teardown still be called?", "url": "https://github.com/apache/beam/pull/13048#discussion_r513666200", "createdAt": "2020-10-28T18:19:49Z", "author": {"login": "yifanmai"}, "path": "sdks/python/apache_beam/transforms/core.py", "diffHunk": "@@ -877,17 +877,19 @@ class CombineFn(WithTypeHints, HasDisplayData, urns.RunnerApiFn):\n   combining process proceeds as follows:\n \n   1. Input values are partitioned into one or more batches.\n-  2. For each batch, the create_accumulator method is invoked to create a fresh\n+  2. For each batch, the setup method is invoked.\n+  3. For each batch, the create_accumulator method is invoked to create a fresh\n      initial \"accumulator\" value representing the combination of zero values.\n-  3. For each input value in the batch, the add_input method is invoked to\n+  4. For each input value in the batch, the add_input method is invoked to\n      combine more values with the accumulator for that batch.\n-  4. The merge_accumulators method is invoked to combine accumulators from\n+  5. The merge_accumulators method is invoked to combine accumulators from\n      separate batches into a single combined output accumulator value, once all\n      of the accumulators have had all the input value in their batches added to\n      them. This operation is invoked repeatedly, until there is only one\n      accumulator value left.\n-  5. The extract_output operation is invoked on the final accumulator to get\n+  6. The extract_output operation is invoked on the final accumulator to get\n      the output value.\n+  7. The teardown method is invoked.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6dd53adaa4186d0d79d79071b4bb6dea46e645eb"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDQwMjI3NQ==", "bodyText": "CombineFn's teardown is similar to DoFn's teardown, which does not guarantee that the call will happen. We should expect the same from CombineFn's teardown.", "url": "https://github.com/apache/beam/pull/13048#discussion_r514402275", "createdAt": "2020-10-29T16:35:55Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/transforms/core.py", "diffHunk": "@@ -877,17 +877,19 @@ class CombineFn(WithTypeHints, HasDisplayData, urns.RunnerApiFn):\n   combining process proceeds as follows:\n \n   1. Input values are partitioned into one or more batches.\n-  2. For each batch, the create_accumulator method is invoked to create a fresh\n+  2. For each batch, the setup method is invoked.\n+  3. For each batch, the create_accumulator method is invoked to create a fresh\n      initial \"accumulator\" value representing the combination of zero values.\n-  3. For each input value in the batch, the add_input method is invoked to\n+  4. For each input value in the batch, the add_input method is invoked to\n      combine more values with the accumulator for that batch.\n-  4. The merge_accumulators method is invoked to combine accumulators from\n+  5. The merge_accumulators method is invoked to combine accumulators from\n      separate batches into a single combined output accumulator value, once all\n      of the accumulators have had all the input value in their batches added to\n      them. This operation is invoked repeatedly, until there is only one\n      accumulator value left.\n-  5. The extract_output operation is invoked on the final accumulator to get\n+  6. The extract_output operation is invoked on the final accumulator to get\n      the output value.\n+  7. The teardown method is invoked.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY2NjIwMA=="}, "originalCommit": {"oid": "6dd53adaa4186d0d79d79071b4bb6dea46e645eb"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNDQ1MjUxMQ==", "bodyText": "SGTM.", "url": "https://github.com/apache/beam/pull/13048#discussion_r514452511", "createdAt": "2020-10-29T17:48:42Z", "author": {"login": "yifanmai"}, "path": "sdks/python/apache_beam/transforms/core.py", "diffHunk": "@@ -877,17 +877,19 @@ class CombineFn(WithTypeHints, HasDisplayData, urns.RunnerApiFn):\n   combining process proceeds as follows:\n \n   1. Input values are partitioned into one or more batches.\n-  2. For each batch, the create_accumulator method is invoked to create a fresh\n+  2. For each batch, the setup method is invoked.\n+  3. For each batch, the create_accumulator method is invoked to create a fresh\n      initial \"accumulator\" value representing the combination of zero values.\n-  3. For each input value in the batch, the add_input method is invoked to\n+  4. For each input value in the batch, the add_input method is invoked to\n      combine more values with the accumulator for that batch.\n-  4. The merge_accumulators method is invoked to combine accumulators from\n+  5. The merge_accumulators method is invoked to combine accumulators from\n      separate batches into a single combined output accumulator value, once all\n      of the accumulators have had all the input value in their batches added to\n      them. This operation is invoked repeatedly, until there is only one\n      accumulator value left.\n-  5. The extract_output operation is invoked on the final accumulator to get\n+  6. The extract_output operation is invoked on the final accumulator to get\n      the output value.\n+  7. The teardown method is invoked.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzY2NjIwMA=="}, "originalCommit": {"oid": "6dd53adaa4186d0d79d79071b4bb6dea46e645eb"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIzNjI4NDAxOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/transforms/core.py", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QwMjoyMToyOVrOHseSwA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QwMjoyMToyOVrOHseSwA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5NTcxMg==", "bodyText": "nit: prefer using () to line continuation token.", "url": "https://github.com/apache/beam/pull/13048#discussion_r516395712", "createdAt": "2020-11-03T02:21:29Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/transforms/core.py", "diffHunk": "@@ -1975,10 +1990,13 @@ def add_input_types(transform):\n       return combined\n \n     if self.has_defaults:\n-      combine_fn = (\n-          self.fn if isinstance(self.fn, CombineFn) else\n-          CombineFn.from_callable(self.fn))\n-      default_value = combine_fn.apply([], *self.args, **self.kwargs)\n+      combine_fn = copy.deepcopy(self.fn) if isinstance(self.fn, CombineFn) \\", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "31e5bc3985762e8b7ec7c0942531025a584a400f"}, "originalPosition": 59}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIzNjI5NTMwOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/transforms/userstate.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QwMjoyODo1MFrOHseZEw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNFQxODoxMDowNVrOHtj8Hg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5NzMzMQ==", "bodyText": "@robertwb do you see any concerns with adding a top level finalize method here?", "url": "https://github.com/apache/beam/pull/13048#discussion_r516397331", "createdAt": "2020-11-03T02:28:50Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/transforms/userstate.py", "diffHunk": "@@ -357,6 +357,10 @@ def prefetch(self):\n     # The default implementation here does nothing.\n     pass\n \n+  def finalize(self):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "31e5bc3985762e8b7ec7c0942531025a584a400f"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzUzNjc5OA==", "bodyText": "This is fine .", "url": "https://github.com/apache/beam/pull/13048#discussion_r517536798", "createdAt": "2020-11-04T18:10:05Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/transforms/userstate.py", "diffHunk": "@@ -357,6 +357,10 @@ def prefetch(self):\n     # The default implementation here does nothing.\n     pass\n \n+  def finalize(self):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5NzMzMQ=="}, "originalCommit": {"oid": "31e5bc3985762e8b7ec7c0942531025a584a400f"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzIzNjMwMTQ2OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/dataflow/dataflow_runner.py", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QwMjozMjozNlrOHseccw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QwMjozMjozNlrOHseccw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM5ODE5NQ==", "bodyText": "nit: prefer to use () instead of \\ .", "url": "https://github.com/apache/beam/pull/13048#discussion_r516398195", "createdAt": "2020-11-03T02:32:36Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/runners/dataflow/dataflow_runner.py", "diffHunk": "@@ -411,6 +411,33 @@ def visit_transform(self, transform_node):\n \n     return FlattenInputVisitor()\n \n+  @staticmethod\n+  def combinefn_visitor():\n+    # Imported here to avoid circular dependencies.\n+    from apache_beam.pipeline import PipelineVisitor\n+    from apache_beam import core\n+\n+    class CombineFnVisitor(PipelineVisitor):\n+      \"\"\"Checks if `CombineFn` has non-default setup or teardown methods.\n+      If yes, raises `ValueError`.\n+      \"\"\"\n+      def visit_transform(self, applied_transform):\n+        transform = applied_transform.transform\n+        if isinstance(transform, core.ParDo) and isinstance(\n+            transform.fn, core.CombineValuesDoFn):\n+          if self._overrides_setup_or_teardown(transform.fn.combinefn):\n+            raise ValueError(\n+                'CombineFn.setup and CombineFn.teardown are '\n+                'not supported with non-portable Dataflow '\n+                'runner. Please use Dataflow Runner V2 instead.')\n+\n+      @staticmethod\n+      def _overrides_setup_or_teardown(combinefn):\n+        return combinefn.__class__.setup is not core.CombineFn.setup or \\", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "31e5bc3985762e8b7ec7c0942531025a584a400f"}, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI0NDkyMzMyOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/transforms/combiners.py", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQwMTozNzozN1rOHtvzAg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNVQwMTozNzozN1rOHtvzAg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzczMTA3NA==", "bodyText": "I think this would fail the Dataflow V1 check as well.\nI thought of possible improvement of the check bad0a52 (#13267) and this call would cause an issue.", "url": "https://github.com/apache/beam/pull/13048#discussion_r517731074", "createdAt": "2020-11-05T01:37:37Z", "author": {"login": "tvalentyn"}, "path": "sdks/python/apache_beam/transforms/combiners.py", "diffHunk": "@@ -700,6 +700,9 @@ def __init__(self, n):\n     # helper instead.\n     self._top_combiner = TopCombineFn(n)\n \n+  def setup(self):\n+    self._top_combiner.setup()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e3326d1fd235dd80f00c65489dd7e1b31cf87ce1"}, "originalPosition": 5}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3151, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}