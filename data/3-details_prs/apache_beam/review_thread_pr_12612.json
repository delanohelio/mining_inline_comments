{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDY5NTI1MDcx", "number": 12612, "reviewThreads": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxNzoyNToyNlrOEbDDYA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxNzo0NzoxOFrOEbDcxw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2Nzk3MDI0OnYy", "diffSide": "RIGHT", "path": ".test-infra/jenkins/job_LoadTests_GBK_Python.groovy", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxNzoyNToyNlrOHE1Vbg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxNzoyNToyNlrOHE1Vbg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDgzMDE5MA==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    job_name             : 'load-tests-python-dataflow-${mode}-gbk-2-' + now,\n          \n          \n            \n                    job_name             : \"load-tests-python-dataflow-${mode}-gbk-2-${now}\",", "url": "https://github.com/apache/beam/pull/12612#discussion_r474830190", "createdAt": "2020-08-21T17:25:26Z", "author": {"login": "tysonjh"}, "path": ".test-infra/jenkins/job_LoadTests_GBK_Python.groovy", "diffHunk": "@@ -22,119 +22,138 @@ import InfluxDBCredentialsHelper\n \n def now = new Date().format(\"MMddHHmmss\", TimeZone.getTimeZone('UTC'))\n \n-def loadTestConfigurations = { datasetName ->\n+// TODO(BEAM-10774): Skipping some cases because they are too slow.\n+def STREAMING_TESTS_TO_SKIP = [1, 2, 4, 5]\n+\n+def loadTestConfigurations = { mode, datasetName ->\n   [\n     [\n       title          : 'GroupByKey Python Load test: 2GB of 10B records',\n       test           : 'apache_beam.testing.load_tests.group_by_key_test',\n       runner         : CommonTestProperties.Runner.DATAFLOW,\n       pipelineOptions: [\n-        job_name             : 'load-tests-python-dataflow-batch-gbk-1-' + now,\n+        job_name             : \"load-tests-python-dataflow-${mode}-gbk-1-${now}\",\n         project              : 'apache-beam-testing',\n         region               : 'us-central1',\n         temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n         publish_to_big_query : true,\n         metrics_dataset      : datasetName,\n-        metrics_table        : 'python_dataflow_batch_gbk_1',\n-        influx_measurement   : 'python_batch_gbk_1',\n+        metrics_table        : \"python_dataflow_${mode}_gbk_1\",\n+        influx_measurement   : \"python_${mode}_gbk_1\",\n         input_options        : '\\'{\"num_records\": 200000000,' +\n         '\"key_size\": 1,' +\n         '\"value_size\": 9}\\'',\n         iterations           : 1,\n         fanout               : 1,\n         num_workers          : 5,\n-        autoscaling_algorithm: \"NONE\"\n+        autoscaling_algorithm: 'NONE',\n       ]\n     ],\n     [\n       title          : 'GroupByKey Python Load test: 2GB of 100B records',\n       test           : 'apache_beam.testing.load_tests.group_by_key_test',\n       runner         : CommonTestProperties.Runner.DATAFLOW,\n       pipelineOptions: [\n-        job_name             : 'load-tests-python-dataflow-batch-gbk-2-' + now,\n+        job_name             : 'load-tests-python-dataflow-${mode}-gbk-2-' + now,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f67712b477f811e2fe61f5c816b58e1268db2e13"}, "originalPosition": 42}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2Nzk5MjY5OnYy", "diffSide": "RIGHT", "path": ".test-infra/jenkins/job_LoadTests_GBK_Python.groovy", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxNzozMzoxMFrOHE1jjg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxNTozODozOVrOHFq4DA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDgzMzgwNg==", "bodyText": "Can you add a comment to explain what these settings are? It's unexpected to see that 'streaming: null' or 'enable_streaming_engine: null' somehow enables streaming, or why 'use_runner_v2' is required.", "url": "https://github.com/apache/beam/pull/12612#discussion_r474833806", "createdAt": "2020-08-21T17:33:10Z", "author": {"login": "tysonjh"}, "path": ".test-infra/jenkins/job_LoadTests_GBK_Python.groovy", "diffHunk": "@@ -22,119 +22,138 @@ import InfluxDBCredentialsHelper\n \n def now = new Date().format(\"MMddHHmmss\", TimeZone.getTimeZone('UTC'))\n \n-def loadTestConfigurations = { datasetName ->\n+// TODO(BEAM-10774): Skipping some cases because they are too slow.\n+def STREAMING_TESTS_TO_SKIP = [1, 2, 4, 5]\n+\n+def loadTestConfigurations = { mode, datasetName ->\n   [\n     [\n       title          : 'GroupByKey Python Load test: 2GB of 10B records',\n       test           : 'apache_beam.testing.load_tests.group_by_key_test',\n       runner         : CommonTestProperties.Runner.DATAFLOW,\n       pipelineOptions: [\n-        job_name             : 'load-tests-python-dataflow-batch-gbk-1-' + now,\n+        job_name             : \"load-tests-python-dataflow-${mode}-gbk-1-${now}\",\n         project              : 'apache-beam-testing',\n         region               : 'us-central1',\n         temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n         publish_to_big_query : true,\n         metrics_dataset      : datasetName,\n-        metrics_table        : 'python_dataflow_batch_gbk_1',\n-        influx_measurement   : 'python_batch_gbk_1',\n+        metrics_table        : \"python_dataflow_${mode}_gbk_1\",\n+        influx_measurement   : \"python_${mode}_gbk_1\",\n         input_options        : '\\'{\"num_records\": 200000000,' +\n         '\"key_size\": 1,' +\n         '\"value_size\": 9}\\'',\n         iterations           : 1,\n         fanout               : 1,\n         num_workers          : 5,\n-        autoscaling_algorithm: \"NONE\"\n+        autoscaling_algorithm: 'NONE',\n       ]\n     ],\n     [\n       title          : 'GroupByKey Python Load test: 2GB of 100B records',\n       test           : 'apache_beam.testing.load_tests.group_by_key_test',\n       runner         : CommonTestProperties.Runner.DATAFLOW,\n       pipelineOptions: [\n-        job_name             : 'load-tests-python-dataflow-batch-gbk-2-' + now,\n+        job_name             : 'load-tests-python-dataflow-${mode}-gbk-2-' + now,\n         project              : 'apache-beam-testing',\n         region               : 'us-central1',\n         temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n         publish_to_big_query : true,\n         metrics_dataset      : datasetName,\n-        metrics_table        : 'python_dataflow_batch_gbk_2',\n-        influx_measurement   : 'python_batch_gbk_2',\n+        metrics_table        : 'python_dataflow_${mode}_gbk_2',\n+        influx_measurement   : 'python_${mode}_gbk_2',\n         input_options        : '\\'{\"num_records\": 20000000,' +\n         '\"key_size\": 10,' +\n         '\"value_size\": 90}\\'',\n         iterations           : 1,\n         fanout               : 1,\n         num_workers          : 5,\n-        autoscaling_algorithm: \"NONE\"\n+        autoscaling_algorithm: 'NONE',\n       ]\n     ],\n     [\n       title          : 'GroupByKey Python Load test: 2GB of 100kB records',\n       test           : 'apache_beam.testing.load_tests.group_by_key_test',\n       runner         : CommonTestProperties.Runner.DATAFLOW,\n       pipelineOptions: [\n-        job_name             : 'load-tests-python-dataflow-batch-gbk-3-' + now,\n+        job_name             : \"load-tests-python-dataflow-${mode}-gbk-3-${now}\",\n         project              : 'apache-beam-testing',\n         region               : 'us-central1',\n         temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n         publish_to_big_query : true,\n         metrics_dataset      : datasetName,\n-        metrics_table        : 'python_dataflow_batch_gbk_3',\n-        influx_measurement   : 'python_batch_gbk_3',\n+        metrics_table        : \"python_dataflow_${mode}_gbk_3\",\n+        influx_measurement   : \"python_${mode}_gbk_3\",\n         input_options        : '\\'{\"num_records\": 20000,' +\n         '\"key_size\": 10000,' +\n         '\"value_size\": 90000}\\'',\n         iterations           : 1,\n         fanout               : 1,\n         num_workers          : 5,\n-        autoscaling_algorithm: \"NONE\"\n+        autoscaling_algorithm: 'NONE',\n       ]\n     ],\n     [\n       title          : 'GroupByKey Python Load test: fanout 4 times with 2GB 10-byte records total',\n       test           : 'apache_beam.testing.load_tests.group_by_key_test',\n       runner         : CommonTestProperties.Runner.DATAFLOW,\n       pipelineOptions: [\n-        job_name             : 'load-tests-python-dataflow-batch-gbk-4-' + now,\n+        job_name             : \"load-tests-python-dataflow-${mode}-gbk-4-${now}\",\n         project              : 'apache-beam-testing',\n         region               : 'us-central1',\n         temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n         publish_to_big_query : true,\n         metrics_dataset      : datasetName,\n-        metrics_table        : 'python_dataflow_batch_gbk_4',\n-        influx_measurement   : 'python_batch_gbk_4',\n+        metrics_table        : \"python_dataflow_${mode}_gbk_4\",\n+        influx_measurement   : \"python_${mode}_gbk_4\",\n         input_options        : '\\'{\"num_records\": 5000000,' +\n         '\"key_size\": 10,' +\n         '\"value_size\": 90}\\'',\n         iterations           : 1,\n         fanout               : 4,\n-        num_workers          : 5,\n-        autoscaling_algorithm: \"NONE\"\n+        num_workers          : 16,\n+        autoscaling_algorithm: 'NONE',\n       ]\n     ],\n     [\n       title          : 'GroupByKey Python Load test: fanout 8 times with 2GB 10-byte records total',\n       test           : 'apache_beam.testing.load_tests.group_by_key_test',\n       runner         : CommonTestProperties.Runner.DATAFLOW,\n       pipelineOptions: [\n-        job_name             : 'load-tests-python-dataflow-batch-gbk-5-' + now,\n+        job_name             : \"load-tests-python-dataflow-${mode}-gbk-5-${now}\",\n         project              : 'apache-beam-testing',\n         region               : 'us-central1',\n         temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n         publish_to_big_query : true,\n         metrics_dataset      : datasetName,\n-        metrics_table        : 'python_dataflow_batch_gbk_5',\n-        influx_measurement   : 'python_batch_gbk_5',\n+        metrics_table        : \"python_dataflow_${mode}_gbk_5\",\n+        influx_measurement   : \"python_${mode}_gbk_5\",\n         input_options        : '\\'{\"num_records\": 2500000,' +\n         '\"key_size\": 10,' +\n         '\"value_size\": 90}\\'',\n         iterations           : 1,\n         fanout               : 8,\n-        num_workers          : 5,\n-        autoscaling_algorithm: \"NONE\"\n+        num_workers          : 16,\n+        autoscaling_algorithm: 'NONE',\n       ]\n     ],\n-  ].each { test -> test.pipelineOptions.putAll(additionalPipelineArgs) }\n+  ]\n+  .each { test -> test.pipelineOptions.putAll(additionalPipelineArgs) }\n+  .each { test -> (mode != 'streaming') ?: addStreamingOptions(test) }\n+  .withIndex().collectMany { test, i ->\n+    mode == 'streaming' && STREAMING_TESTS_TO_SKIP.contains(i + 1) ? []: [test]\n+  }\n+}\n+\n+def addStreamingOptions(test) {\n+  test.pipelineOptions << [streaming: null, experiments: 'use_runner_v2',\n+    enable_streaming_engine: null ]\n+}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f67712b477f811e2fe61f5c816b58e1268db2e13"}, "originalPosition": 154}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTcwNzQwNA==", "bodyText": "I removed --enable_streaming_engine, since it is now being added automatically when using use_runner_v2:  #12585", "url": "https://github.com/apache/beam/pull/12612#discussion_r475707404", "createdAt": "2020-08-24T15:38:39Z", "author": {"login": "kamilwu"}, "path": ".test-infra/jenkins/job_LoadTests_GBK_Python.groovy", "diffHunk": "@@ -22,119 +22,138 @@ import InfluxDBCredentialsHelper\n \n def now = new Date().format(\"MMddHHmmss\", TimeZone.getTimeZone('UTC'))\n \n-def loadTestConfigurations = { datasetName ->\n+// TODO(BEAM-10774): Skipping some cases because they are too slow.\n+def STREAMING_TESTS_TO_SKIP = [1, 2, 4, 5]\n+\n+def loadTestConfigurations = { mode, datasetName ->\n   [\n     [\n       title          : 'GroupByKey Python Load test: 2GB of 10B records',\n       test           : 'apache_beam.testing.load_tests.group_by_key_test',\n       runner         : CommonTestProperties.Runner.DATAFLOW,\n       pipelineOptions: [\n-        job_name             : 'load-tests-python-dataflow-batch-gbk-1-' + now,\n+        job_name             : \"load-tests-python-dataflow-${mode}-gbk-1-${now}\",\n         project              : 'apache-beam-testing',\n         region               : 'us-central1',\n         temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n         publish_to_big_query : true,\n         metrics_dataset      : datasetName,\n-        metrics_table        : 'python_dataflow_batch_gbk_1',\n-        influx_measurement   : 'python_batch_gbk_1',\n+        metrics_table        : \"python_dataflow_${mode}_gbk_1\",\n+        influx_measurement   : \"python_${mode}_gbk_1\",\n         input_options        : '\\'{\"num_records\": 200000000,' +\n         '\"key_size\": 1,' +\n         '\"value_size\": 9}\\'',\n         iterations           : 1,\n         fanout               : 1,\n         num_workers          : 5,\n-        autoscaling_algorithm: \"NONE\"\n+        autoscaling_algorithm: 'NONE',\n       ]\n     ],\n     [\n       title          : 'GroupByKey Python Load test: 2GB of 100B records',\n       test           : 'apache_beam.testing.load_tests.group_by_key_test',\n       runner         : CommonTestProperties.Runner.DATAFLOW,\n       pipelineOptions: [\n-        job_name             : 'load-tests-python-dataflow-batch-gbk-2-' + now,\n+        job_name             : 'load-tests-python-dataflow-${mode}-gbk-2-' + now,\n         project              : 'apache-beam-testing',\n         region               : 'us-central1',\n         temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n         publish_to_big_query : true,\n         metrics_dataset      : datasetName,\n-        metrics_table        : 'python_dataflow_batch_gbk_2',\n-        influx_measurement   : 'python_batch_gbk_2',\n+        metrics_table        : 'python_dataflow_${mode}_gbk_2',\n+        influx_measurement   : 'python_${mode}_gbk_2',\n         input_options        : '\\'{\"num_records\": 20000000,' +\n         '\"key_size\": 10,' +\n         '\"value_size\": 90}\\'',\n         iterations           : 1,\n         fanout               : 1,\n         num_workers          : 5,\n-        autoscaling_algorithm: \"NONE\"\n+        autoscaling_algorithm: 'NONE',\n       ]\n     ],\n     [\n       title          : 'GroupByKey Python Load test: 2GB of 100kB records',\n       test           : 'apache_beam.testing.load_tests.group_by_key_test',\n       runner         : CommonTestProperties.Runner.DATAFLOW,\n       pipelineOptions: [\n-        job_name             : 'load-tests-python-dataflow-batch-gbk-3-' + now,\n+        job_name             : \"load-tests-python-dataflow-${mode}-gbk-3-${now}\",\n         project              : 'apache-beam-testing',\n         region               : 'us-central1',\n         temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n         publish_to_big_query : true,\n         metrics_dataset      : datasetName,\n-        metrics_table        : 'python_dataflow_batch_gbk_3',\n-        influx_measurement   : 'python_batch_gbk_3',\n+        metrics_table        : \"python_dataflow_${mode}_gbk_3\",\n+        influx_measurement   : \"python_${mode}_gbk_3\",\n         input_options        : '\\'{\"num_records\": 20000,' +\n         '\"key_size\": 10000,' +\n         '\"value_size\": 90000}\\'',\n         iterations           : 1,\n         fanout               : 1,\n         num_workers          : 5,\n-        autoscaling_algorithm: \"NONE\"\n+        autoscaling_algorithm: 'NONE',\n       ]\n     ],\n     [\n       title          : 'GroupByKey Python Load test: fanout 4 times with 2GB 10-byte records total',\n       test           : 'apache_beam.testing.load_tests.group_by_key_test',\n       runner         : CommonTestProperties.Runner.DATAFLOW,\n       pipelineOptions: [\n-        job_name             : 'load-tests-python-dataflow-batch-gbk-4-' + now,\n+        job_name             : \"load-tests-python-dataflow-${mode}-gbk-4-${now}\",\n         project              : 'apache-beam-testing',\n         region               : 'us-central1',\n         temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n         publish_to_big_query : true,\n         metrics_dataset      : datasetName,\n-        metrics_table        : 'python_dataflow_batch_gbk_4',\n-        influx_measurement   : 'python_batch_gbk_4',\n+        metrics_table        : \"python_dataflow_${mode}_gbk_4\",\n+        influx_measurement   : \"python_${mode}_gbk_4\",\n         input_options        : '\\'{\"num_records\": 5000000,' +\n         '\"key_size\": 10,' +\n         '\"value_size\": 90}\\'',\n         iterations           : 1,\n         fanout               : 4,\n-        num_workers          : 5,\n-        autoscaling_algorithm: \"NONE\"\n+        num_workers          : 16,\n+        autoscaling_algorithm: 'NONE',\n       ]\n     ],\n     [\n       title          : 'GroupByKey Python Load test: fanout 8 times with 2GB 10-byte records total',\n       test           : 'apache_beam.testing.load_tests.group_by_key_test',\n       runner         : CommonTestProperties.Runner.DATAFLOW,\n       pipelineOptions: [\n-        job_name             : 'load-tests-python-dataflow-batch-gbk-5-' + now,\n+        job_name             : \"load-tests-python-dataflow-${mode}-gbk-5-${now}\",\n         project              : 'apache-beam-testing',\n         region               : 'us-central1',\n         temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n         publish_to_big_query : true,\n         metrics_dataset      : datasetName,\n-        metrics_table        : 'python_dataflow_batch_gbk_5',\n-        influx_measurement   : 'python_batch_gbk_5',\n+        metrics_table        : \"python_dataflow_${mode}_gbk_5\",\n+        influx_measurement   : \"python_${mode}_gbk_5\",\n         input_options        : '\\'{\"num_records\": 2500000,' +\n         '\"key_size\": 10,' +\n         '\"value_size\": 90}\\'',\n         iterations           : 1,\n         fanout               : 8,\n-        num_workers          : 5,\n-        autoscaling_algorithm: \"NONE\"\n+        num_workers          : 16,\n+        autoscaling_algorithm: 'NONE',\n       ]\n     ],\n-  ].each { test -> test.pipelineOptions.putAll(additionalPipelineArgs) }\n+  ]\n+  .each { test -> test.pipelineOptions.putAll(additionalPipelineArgs) }\n+  .each { test -> (mode != 'streaming') ?: addStreamingOptions(test) }\n+  .withIndex().collectMany { test, i ->\n+    mode == 'streaming' && STREAMING_TESTS_TO_SKIP.contains(i + 1) ? []: [test]\n+  }\n+}\n+\n+def addStreamingOptions(test) {\n+  test.pipelineOptions << [streaming: null, experiments: 'use_runner_v2',\n+    enable_streaming_engine: null ]\n+}", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDgzMzgwNg=="}, "originalCommit": {"oid": "f67712b477f811e2fe61f5c816b58e1268db2e13"}, "originalPosition": 154}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2Nzk5NjkxOnYy", "diffSide": "RIGHT", "path": ".test-infra/jenkins/job_LoadTests_GBK_Python_reiterate.groovy", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxNzozNDoyOFrOHE1mCw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxNzozNDoyOFrOHE1mCw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDgzNDQ0Mw==", "bodyText": "Same here, please add a comment.", "url": "https://github.com/apache/beam/pull/12612#discussion_r474834443", "createdAt": "2020-08-21T17:34:28Z", "author": {"login": "tysonjh"}, "path": ".test-infra/jenkins/job_LoadTests_GBK_Python_reiterate.groovy", "diffHunk": "@@ -58,43 +58,47 @@ def loadTestConfigurations = { datasetName ->\n       pipelineOptions: [\n         project              : 'apache-beam-testing',\n         region               : 'us-central1',\n-        job_name             : 'load-tests-python-dataflow-batch-gbk-7-' + now,\n+        job_name             : \"load-tests-python-dataflow-${mode}-gbk-7-${now}\",\n         temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n         publish_to_big_query : true,\n         metrics_dataset      : datasetName,\n-        metrics_table        : 'python_dataflow_batch_gbk_7',\n-        influx_measurement   : 'python_batch_gbk_7',\n+        metrics_table        : \"python_dataflow_${mode}_gbk_7\",\n+        influx_measurement   : \"python_${mode}_gbk_7\",\n         input_options        : '\\'{\"num_records\": 20000000,' +\n         '\"key_size\": 10,' +\n         '\"value_size\": 90,' +\n         '\"num_hot_keys\": 10,' +\n         '\"hot_key_fraction\": 1}\\'',\n-        fanout               : 1,\n         iterations           : 4,\n+        fanout               : 1,\n         num_workers          : 5,\n-        autoscaling_algorithm: 'NONE'\n+        autoscaling_algorithm: 'NONE',\n       ]\n     ]\n-  ].each { test -> test.pipelineOptions.putAll(additionalPipelineArgs) }\n+  ]\n+  .each { test -> test.pipelineOptions.putAll(additionalPipelineArgs) }\n+  .each { test -> (mode != 'streaming') ?: addStreamingOptions(test) }\n }\n \n-def batchLoadTestJob = { scope, triggeringContext ->\n-  scope.description('Runs Python GBK reiterate load tests on Dataflow runner in batch mode')\n-  commonJobProperties.setTopLevelMainJobProperties(scope, 'master', 240)\n+def addStreamingOptions(test) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f67712b477f811e2fe61f5c816b58e1268db2e13"}, "originalPosition": 71}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2Nzk5OTUwOnYy", "diffSide": "RIGHT", "path": ".test-infra/jenkins/job_LoadTests_GBK_Python_reiterate.groovy", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxNzozNTowOVrOHE1ngA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxMTowMTozNVrOHFffMg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDgzNDgxNg==", "bodyText": "What's the methodology for picking the time to trigger these? Is it documented anywhere?", "url": "https://github.com/apache/beam/pull/12612#discussion_r474834816", "createdAt": "2020-08-21T17:35:09Z", "author": {"login": "tysonjh"}, "path": ".test-infra/jenkins/job_LoadTests_GBK_Python_reiterate.groovy", "diffHunk": "@@ -58,43 +58,47 @@ def loadTestConfigurations = { datasetName ->\n       pipelineOptions: [\n         project              : 'apache-beam-testing',\n         region               : 'us-central1',\n-        job_name             : 'load-tests-python-dataflow-batch-gbk-7-' + now,\n+        job_name             : \"load-tests-python-dataflow-${mode}-gbk-7-${now}\",\n         temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n         publish_to_big_query : true,\n         metrics_dataset      : datasetName,\n-        metrics_table        : 'python_dataflow_batch_gbk_7',\n-        influx_measurement   : 'python_batch_gbk_7',\n+        metrics_table        : \"python_dataflow_${mode}_gbk_7\",\n+        influx_measurement   : \"python_${mode}_gbk_7\",\n         input_options        : '\\'{\"num_records\": 20000000,' +\n         '\"key_size\": 10,' +\n         '\"value_size\": 90,' +\n         '\"num_hot_keys\": 10,' +\n         '\"hot_key_fraction\": 1}\\'',\n-        fanout               : 1,\n         iterations           : 4,\n+        fanout               : 1,\n         num_workers          : 5,\n-        autoscaling_algorithm: 'NONE'\n+        autoscaling_algorithm: 'NONE',\n       ]\n     ]\n-  ].each { test -> test.pipelineOptions.putAll(additionalPipelineArgs) }\n+  ]\n+  .each { test -> test.pipelineOptions.putAll(additionalPipelineArgs) }\n+  .each { test -> (mode != 'streaming') ?: addStreamingOptions(test) }\n }\n \n-def batchLoadTestJob = { scope, triggeringContext ->\n-  scope.description('Runs Python GBK reiterate load tests on Dataflow runner in batch mode')\n-  commonJobProperties.setTopLevelMainJobProperties(scope, 'master', 240)\n+def addStreamingOptions(test) {\n+  test.pipelineOptions << [streaming: null, experiments: 'use_runner_v2',\n+    enable_streaming_engine: null ]\n+}\n \n+def loadTestJob = { scope, triggeringContext, mode ->\n   def datasetName = loadTestsBuilder.getBigQueryDataset('load_test', triggeringContext)\n-  for (testConfiguration in loadTestConfigurations(datasetName)) {\n-    loadTestsBuilder.loadTest(scope, testConfiguration.title, testConfiguration.runner, CommonTestProperties.SDK.PYTHON_37, testConfiguration.pipelineOptions, testConfiguration.test)\n-  }\n+  loadTestsBuilder.loadTests(scope, CommonTestProperties.SDK.PYTHON_37,\n+      loadTestConfigurations(mode, datasetName), 'GBK reiterate', mode)\n }\n \n-CronJobBuilder.cronJob('beam_LoadTests_Python_GBK_reiterate_Dataflow_Batch', 'H 14 * * *', this) {\n-  additionalPipelineArgs = [\n-    influx_db_name: InfluxDBCredentialsHelper.InfluxDBDatabaseName,\n-    influx_hostname: InfluxDBCredentialsHelper.InfluxDBHostname,\n-  ]\n-  batchLoadTestJob(delegate, CommonTestProperties.TriggeringContext.POST_COMMIT)\n-}\n+CronJobBuilder.cronJob('beam_LoadTests_Python_GBK_reiterate_Dataflow_Batch',\n+    'H 14 * * *', this) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f67712b477f811e2fe61f5c816b58e1268db2e13"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTUyMDgxOA==", "bodyText": "Ideally, each test suite (GBK, ParDo, IO tests, etc.) should has its own, unique time in order no to flood Jenkins with many tests that are triggered at the same time. When adding a new test suite, a contributor has to take a look at what time slots are already occupied and avoid using them.\nI think this is not documented. I'll add some information here: https://cwiki.apache.org/confluence/display/BEAM/Contribution+Testing+Guide#ContributionTestingGuide", "url": "https://github.com/apache/beam/pull/12612#discussion_r475520818", "createdAt": "2020-08-24T11:01:35Z", "author": {"login": "kamilwu"}, "path": ".test-infra/jenkins/job_LoadTests_GBK_Python_reiterate.groovy", "diffHunk": "@@ -58,43 +58,47 @@ def loadTestConfigurations = { datasetName ->\n       pipelineOptions: [\n         project              : 'apache-beam-testing',\n         region               : 'us-central1',\n-        job_name             : 'load-tests-python-dataflow-batch-gbk-7-' + now,\n+        job_name             : \"load-tests-python-dataflow-${mode}-gbk-7-${now}\",\n         temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n         publish_to_big_query : true,\n         metrics_dataset      : datasetName,\n-        metrics_table        : 'python_dataflow_batch_gbk_7',\n-        influx_measurement   : 'python_batch_gbk_7',\n+        metrics_table        : \"python_dataflow_${mode}_gbk_7\",\n+        influx_measurement   : \"python_${mode}_gbk_7\",\n         input_options        : '\\'{\"num_records\": 20000000,' +\n         '\"key_size\": 10,' +\n         '\"value_size\": 90,' +\n         '\"num_hot_keys\": 10,' +\n         '\"hot_key_fraction\": 1}\\'',\n-        fanout               : 1,\n         iterations           : 4,\n+        fanout               : 1,\n         num_workers          : 5,\n-        autoscaling_algorithm: 'NONE'\n+        autoscaling_algorithm: 'NONE',\n       ]\n     ]\n-  ].each { test -> test.pipelineOptions.putAll(additionalPipelineArgs) }\n+  ]\n+  .each { test -> test.pipelineOptions.putAll(additionalPipelineArgs) }\n+  .each { test -> (mode != 'streaming') ?: addStreamingOptions(test) }\n }\n \n-def batchLoadTestJob = { scope, triggeringContext ->\n-  scope.description('Runs Python GBK reiterate load tests on Dataflow runner in batch mode')\n-  commonJobProperties.setTopLevelMainJobProperties(scope, 'master', 240)\n+def addStreamingOptions(test) {\n+  test.pipelineOptions << [streaming: null, experiments: 'use_runner_v2',\n+    enable_streaming_engine: null ]\n+}\n \n+def loadTestJob = { scope, triggeringContext, mode ->\n   def datasetName = loadTestsBuilder.getBigQueryDataset('load_test', triggeringContext)\n-  for (testConfiguration in loadTestConfigurations(datasetName)) {\n-    loadTestsBuilder.loadTest(scope, testConfiguration.title, testConfiguration.runner, CommonTestProperties.SDK.PYTHON_37, testConfiguration.pipelineOptions, testConfiguration.test)\n-  }\n+  loadTestsBuilder.loadTests(scope, CommonTestProperties.SDK.PYTHON_37,\n+      loadTestConfigurations(mode, datasetName), 'GBK reiterate', mode)\n }\n \n-CronJobBuilder.cronJob('beam_LoadTests_Python_GBK_reiterate_Dataflow_Batch', 'H 14 * * *', this) {\n-  additionalPipelineArgs = [\n-    influx_db_name: InfluxDBCredentialsHelper.InfluxDBDatabaseName,\n-    influx_hostname: InfluxDBCredentialsHelper.InfluxDBHostname,\n-  ]\n-  batchLoadTestJob(delegate, CommonTestProperties.TriggeringContext.POST_COMMIT)\n-}\n+CronJobBuilder.cronJob('beam_LoadTests_Python_GBK_reiterate_Dataflow_Batch',\n+    'H 14 * * *', this) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDgzNDgxNg=="}, "originalCommit": {"oid": "f67712b477f811e2fe61f5c816b58e1268db2e13"}, "originalPosition": 93}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2ODAzNTI3OnYy", "diffSide": "RIGHT", "path": ".test-infra/jenkins/job_LoadTests_GBK_Python.groovy", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxNzo0NzoxOFrOHE190A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQwOTozMjowM1rOHFcNNw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDg0MDUyOA==", "bodyText": "@kkucharc made a good point here in PR#12435 about using indices for ignoring tests. I'm more inclined towards the approach @kkucharc is taking by excluding using the job_name.", "url": "https://github.com/apache/beam/pull/12612#discussion_r474840528", "createdAt": "2020-08-21T17:47:18Z", "author": {"login": "tysonjh"}, "path": ".test-infra/jenkins/job_LoadTests_GBK_Python.groovy", "diffHunk": "@@ -22,119 +22,138 @@ import InfluxDBCredentialsHelper\n \n def now = new Date().format(\"MMddHHmmss\", TimeZone.getTimeZone('UTC'))\n \n-def loadTestConfigurations = { datasetName ->\n+// TODO(BEAM-10774): Skipping some cases because they are too slow.\n+def STREAMING_TESTS_TO_SKIP = [1, 2, 4, 5]", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f67712b477f811e2fe61f5c816b58e1268db2e13"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTQ2NzA2Mw==", "bodyText": "Thanks, an argument that @kkucharc made in PR#12435 is convincing. I'll exclude those cases by using the job_name.", "url": "https://github.com/apache/beam/pull/12612#discussion_r475467063", "createdAt": "2020-08-24T09:32:03Z", "author": {"login": "kamilwu"}, "path": ".test-infra/jenkins/job_LoadTests_GBK_Python.groovy", "diffHunk": "@@ -22,119 +22,138 @@ import InfluxDBCredentialsHelper\n \n def now = new Date().format(\"MMddHHmmss\", TimeZone.getTimeZone('UTC'))\n \n-def loadTestConfigurations = { datasetName ->\n+// TODO(BEAM-10774): Skipping some cases because they are too slow.\n+def STREAMING_TESTS_TO_SKIP = [1, 2, 4, 5]", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDg0MDUyOA=="}, "originalCommit": {"oid": "f67712b477f811e2fe61f5c816b58e1268db2e13"}, "originalPosition": 6}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 511, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}