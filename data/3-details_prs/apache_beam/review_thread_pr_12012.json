{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDM0NjE2NDI0", "number": 12012, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQwMzozODoyM1rOEFxTig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQwMzozOTozNlrOEFxUEg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc0NDg2MTU0OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/worker/sdk_worker.py", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQwMzozODoyM1rOGkKIaA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQxNjoyNDo1OFrOGkjZBg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDU2NzkxMg==", "bodyText": "Why would extend be called in this case? Should this be an error?", "url": "https://github.com/apache/beam/pull/12012#discussion_r440567912", "createdAt": "2020-06-16T03:38:23Z", "author": {"login": "tweise"}, "path": "sdks/python/apache_beam/runners/worker/sdk_worker.py", "diffHunk": "@@ -941,15 +942,29 @@ def extend(self,\n              is_cached=False\n             ):\n     # type: (...) -> _Future\n+    # Make sure the input is a list of elements\n+    elements = list(elements)\n     cache_token = self._get_cache_token(state_key, is_cached)\n     if cache_token:\n       # Update the cache\n       cache_key = self._convert_to_cache_key(state_key)\n-      if self._state_cache.get(cache_key, cache_token) is None:\n-        # We have never cached this key before, first initialize cache\n-        self.blocking_get(state_key, coder, is_cached=True)\n-      # Now update the values in the cache\n-      self._state_cache.extend(cache_key, cache_token, elements)\n+      cached_value = self._state_cache.get(cache_key, cache_token)\n+      # Keep in mind that the state for this key can be evicted\n+      # while executing this function. Either read or write to the cache\n+      # but never do both here!\n+      if cached_value is None:\n+        # We have never cached this key before, first retrieve state\n+        cached_value = self.blocking_get(state_key, coder)\n+      # Just extend the already cached value\n+      if isinstance(cached_value, list):\n+        # The state is fully cached and can be extended\n+        cached_value.extend(elements)\n+      elif isinstance(cached_value, itertools.chain):\n+        # The state is too large to be fully cached (continuation token used),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "451ebe39f63c7a63d7a332d9b366323794fcd226"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDY0MzkwOQ==", "bodyText": "Extend is called when new state gets appended. In line 963 we know that the cache already contains the head of the state + an iterator which retrieves the rest from the runner due to the use of continuation tokens for large state. We don't want to cache further values, that's why we skip updating the cache and just send the new values to the Runner (below). When we retrieve this state from the cache, it will have the head cached and retrieve the rest from the Runner, including the appended values.\nShould it be an error? No, because we still want to be able to append to large state.", "url": "https://github.com/apache/beam/pull/12012#discussion_r440643909", "createdAt": "2020-06-16T07:33:07Z", "author": {"login": "mxm"}, "path": "sdks/python/apache_beam/runners/worker/sdk_worker.py", "diffHunk": "@@ -941,15 +942,29 @@ def extend(self,\n              is_cached=False\n             ):\n     # type: (...) -> _Future\n+    # Make sure the input is a list of elements\n+    elements = list(elements)\n     cache_token = self._get_cache_token(state_key, is_cached)\n     if cache_token:\n       # Update the cache\n       cache_key = self._convert_to_cache_key(state_key)\n-      if self._state_cache.get(cache_key, cache_token) is None:\n-        # We have never cached this key before, first initialize cache\n-        self.blocking_get(state_key, coder, is_cached=True)\n-      # Now update the values in the cache\n-      self._state_cache.extend(cache_key, cache_token, elements)\n+      cached_value = self._state_cache.get(cache_key, cache_token)\n+      # Keep in mind that the state for this key can be evicted\n+      # while executing this function. Either read or write to the cache\n+      # but never do both here!\n+      if cached_value is None:\n+        # We have never cached this key before, first retrieve state\n+        cached_value = self.blocking_get(state_key, coder)\n+      # Just extend the already cached value\n+      if isinstance(cached_value, list):\n+        # The state is fully cached and can be extended\n+        cached_value.extend(elements)\n+      elif isinstance(cached_value, itertools.chain):\n+        # The state is too large to be fully cached (continuation token used),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDU2NzkxMg=="}, "originalCommit": {"oid": "451ebe39f63c7a63d7a332d9b366323794fcd226"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDk4MTc2Ng==", "bodyText": "Makes sense, I missed that the new elements are still written to the state handler.", "url": "https://github.com/apache/beam/pull/12012#discussion_r440981766", "createdAt": "2020-06-16T16:24:58Z", "author": {"login": "tweise"}, "path": "sdks/python/apache_beam/runners/worker/sdk_worker.py", "diffHunk": "@@ -941,15 +942,29 @@ def extend(self,\n              is_cached=False\n             ):\n     # type: (...) -> _Future\n+    # Make sure the input is a list of elements\n+    elements = list(elements)\n     cache_token = self._get_cache_token(state_key, is_cached)\n     if cache_token:\n       # Update the cache\n       cache_key = self._convert_to_cache_key(state_key)\n-      if self._state_cache.get(cache_key, cache_token) is None:\n-        # We have never cached this key before, first initialize cache\n-        self.blocking_get(state_key, coder, is_cached=True)\n-      # Now update the values in the cache\n-      self._state_cache.extend(cache_key, cache_token, elements)\n+      cached_value = self._state_cache.get(cache_key, cache_token)\n+      # Keep in mind that the state for this key can be evicted\n+      # while executing this function. Either read or write to the cache\n+      # but never do both here!\n+      if cached_value is None:\n+        # We have never cached this key before, first retrieve state\n+        cached_value = self.blocking_get(state_key, coder)\n+      # Just extend the already cached value\n+      if isinstance(cached_value, list):\n+        # The state is fully cached and can be extended\n+        cached_value.extend(elements)\n+      elif isinstance(cached_value, itertools.chain):\n+        # The state is too large to be fully cached (continuation token used),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDU2NzkxMg=="}, "originalCommit": {"oid": "451ebe39f63c7a63d7a332d9b366323794fcd226"}, "originalPosition": 53}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc0NDg2MjkwOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/worker/sdk_worker.py", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQwMzozOTozNlrOGkKJSQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNlQxMDoyMjowOVrOGkU-uA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDU2ODEzNw==", "bodyText": "Isn't cached_value.extend(elements) the only place where this matters?", "url": "https://github.com/apache/beam/pull/12012#discussion_r440568137", "createdAt": "2020-06-16T03:39:36Z", "author": {"login": "tweise"}, "path": "sdks/python/apache_beam/runners/worker/sdk_worker.py", "diffHunk": "@@ -941,15 +942,29 @@ def extend(self,\n              is_cached=False\n             ):\n     # type: (...) -> _Future\n+    # Make sure the input is a list of elements\n+    elements = list(elements)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "451ebe39f63c7a63d7a332d9b366323794fcd226"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDY0NDMyMQ==", "bodyText": "Yes, though we will iterate twice over elements. 1) for the cache 2) for serializing the elements for the runner. Materializing to a list ensures that the results will be the same. An Iterable could theoretically return different results.", "url": "https://github.com/apache/beam/pull/12012#discussion_r440644321", "createdAt": "2020-06-16T07:33:45Z", "author": {"login": "mxm"}, "path": "sdks/python/apache_beam/runners/worker/sdk_worker.py", "diffHunk": "@@ -941,15 +942,29 @@ def extend(self,\n              is_cached=False\n             ):\n     # type: (...) -> _Future\n+    # Make sure the input is a list of elements\n+    elements = list(elements)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDU2ODEzNw=="}, "originalCommit": {"oid": "451ebe39f63c7a63d7a332d9b366323794fcd226"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDc0NTY1Ng==", "bodyText": "I've moved the call down to execute only when caching is enabled.", "url": "https://github.com/apache/beam/pull/12012#discussion_r440745656", "createdAt": "2020-06-16T10:22:09Z", "author": {"login": "mxm"}, "path": "sdks/python/apache_beam/runners/worker/sdk_worker.py", "diffHunk": "@@ -941,15 +942,29 @@ def extend(self,\n              is_cached=False\n             ):\n     # type: (...) -> _Future\n+    # Make sure the input is a list of elements\n+    elements = list(elements)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDU2ODEzNw=="}, "originalCommit": {"oid": "451ebe39f63c7a63d7a332d9b366323794fcd226"}, "originalPosition": 31}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3528, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}