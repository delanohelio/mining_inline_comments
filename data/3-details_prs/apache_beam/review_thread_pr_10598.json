{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzYzMjY3MjYz", "number": 10598, "reviewThreads": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QwMjozODowNFrODYswyQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMVQyMTo0MTowNVrODZpT1A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MjI1ODAxOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/test/utils.py", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QwMjozODowNFrOFetZQA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QwMjozODowNFrOFetZQA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc0NTM0NA==", "bodyText": "Let's add documentation and move it to sdks/python/apache_beam/testing/util.py", "url": "https://github.com/apache/beam/pull/10598#discussion_r367745344", "createdAt": "2020-01-17T02:38:04Z", "author": {"login": "angoenka"}, "path": "sdks/python/apache_beam/runners/test/utils.py", "diffHunk": "@@ -0,0 +1,49 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import absolute_import\n+\n+import sys\n+import threading\n+\n+from future.utils import raise_\n+\n+\n+def timeout(timeout_secs):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7cc279797f17fcf40f3baefa3479e2d4fc75af47"}, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MjI1OTcxOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/worker/sdk_worker.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QwMjozOTo0MFrOFetaWw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QxOTo0MToxNVrOFfDVlg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc0NTYyNw==", "bodyText": "Let's add it as the last entry to keep the ordering of the arguments same and backward compatible,", "url": "https://github.com/apache/beam/pull/10598#discussion_r367745627", "createdAt": "2020-01-17T02:39:40Z", "author": {"login": "angoenka"}, "path": "sdks/python/apache_beam/runners/worker/sdk_worker.py", "diffHunk": "@@ -73,6 +74,7 @@ class SdkHarness(object):\n \n   def __init__(self,\n                control_address,  # type: str\n+               status_address=None,  # type: Optional[str, unicode]", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7cc279797f17fcf40f3baefa3479e2d4fc75af47"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwNDg1NA==", "bodyText": "done.", "url": "https://github.com/apache/beam/pull/10598#discussion_r368104854", "createdAt": "2020-01-17T19:41:15Z", "author": {"login": "y1chi"}, "path": "sdks/python/apache_beam/runners/worker/sdk_worker.py", "diffHunk": "@@ -73,6 +74,7 @@ class SdkHarness(object):\n \n   def __init__(self,\n                control_address,  # type: str\n+               status_address=None,  # type: Optional[str, unicode]", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc0NTYyNw=="}, "originalCommit": {"oid": "7cc279797f17fcf40f3baefa3479e2d4fc75af47"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MjI2NTIyOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/worker/sdk_worker.py", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QwMjo0NDowMFrOFetdmw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMVQxOToxMToyNFrOFgFkgA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc0NjQ1OQ==", "bodyText": "Let's move it in sdk_worker_main where we keep other reporting related code.", "url": "https://github.com/apache/beam/pull/10598#discussion_r367746459", "createdAt": "2020-01-17T02:44:00Z", "author": {"login": "angoenka"}, "path": "sdks/python/apache_beam/runners/worker/sdk_worker.py", "diffHunk": "@@ -110,6 +112,15 @@ def __init__(self,\n         data_channel_factory=self._data_channel_factory,\n         fns=self._fns)\n \n+    if status_address:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7cc279797f17fcf40f3baefa3479e2d4fc75af47"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwNTYzOQ==", "bodyText": "I need to do the actual initialization inside sdk_worker since I want to pass the active bundle cache in sdk worker in order to report the dangling operation.", "url": "https://github.com/apache/beam/pull/10598#discussion_r368105639", "createdAt": "2020-01-17T19:43:16Z", "author": {"login": "y1chi"}, "path": "sdks/python/apache_beam/runners/worker/sdk_worker.py", "diffHunk": "@@ -110,6 +112,15 @@ def __init__(self,\n         data_channel_factory=self._data_channel_factory,\n         fns=self._fns)\n \n+    if status_address:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc0NjQ1OQ=="}, "originalCommit": {"oid": "7cc279797f17fcf40f3baefa3479e2d4fc75af47"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE5MDAxNg==", "bodyText": "Sounds good", "url": "https://github.com/apache/beam/pull/10598#discussion_r369190016", "createdAt": "2020-01-21T19:11:24Z", "author": {"login": "angoenka"}, "path": "sdks/python/apache_beam/runners/worker/sdk_worker.py", "diffHunk": "@@ -110,6 +112,15 @@ def __init__(self,\n         data_channel_factory=self._data_channel_factory,\n         fns=self._fns)\n \n+    if status_address:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc0NjQ1OQ=="}, "originalCommit": {"oid": "7cc279797f17fcf40f3baefa3479e2d4fc75af47"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MjI3ODgwOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/worker/worker_status.py", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QwMjo1NTo0MFrOFetl9g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMVQxOToyMTo1MVrOFgF4Kg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc0ODU5OA==", "bodyText": "We have thread dump code in sdk_worker_main.py under get_thread_dump.\nShall we reuse it or move it here.", "url": "https://github.com/apache/beam/pull/10598#discussion_r367748598", "createdAt": "2020-01-17T02:55:40Z", "author": {"login": "angoenka"}, "path": "sdks/python/apache_beam/runners/worker/worker_status.py", "diffHunk": "@@ -0,0 +1,139 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\"\"\"Worker status api handler for reporting SDK harness debug info.\"\"\"\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+\n+import queue\n+import sys\n+import threading\n+import traceback\n+from collections import defaultdict\n+\n+import grpc\n+\n+from apache_beam.portability.api import beam_fn_api_pb2\n+from apache_beam.portability.api import beam_fn_api_pb2_grpc\n+from apache_beam.runners.worker.channel_factory import GRPCChannelFactory\n+from apache_beam.runners.worker.worker_id_interceptor import WorkerIdInterceptor\n+\n+\n+def thread_dump():", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7cc279797f17fcf40f3baefa3479e2d4fc75af47"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwMjc2NA==", "bodyText": "I made few changes to the thread dump format. I'll reuse the function, I think eventually we probably won't need the status http server.", "url": "https://github.com/apache/beam/pull/10598#discussion_r368102764", "createdAt": "2020-01-17T19:36:08Z", "author": {"login": "y1chi"}, "path": "sdks/python/apache_beam/runners/worker/worker_status.py", "diffHunk": "@@ -0,0 +1,139 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\"\"\"Worker status api handler for reporting SDK harness debug info.\"\"\"\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+\n+import queue\n+import sys\n+import threading\n+import traceback\n+from collections import defaultdict\n+\n+import grpc\n+\n+from apache_beam.portability.api import beam_fn_api_pb2\n+from apache_beam.portability.api import beam_fn_api_pb2_grpc\n+from apache_beam.runners.worker.channel_factory import GRPCChannelFactory\n+from apache_beam.runners.worker.worker_id_interceptor import WorkerIdInterceptor\n+\n+\n+def thread_dump():", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc0ODU5OA=="}, "originalCommit": {"oid": "7cc279797f17fcf40f3baefa3479e2d4fc75af47"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODE5MzM5Mg==", "bodyText": "I agree, we can get rid of status http server.", "url": "https://github.com/apache/beam/pull/10598#discussion_r368193392", "createdAt": "2020-01-18T01:07:59Z", "author": {"login": "angoenka"}, "path": "sdks/python/apache_beam/runners/worker/worker_status.py", "diffHunk": "@@ -0,0 +1,139 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\"\"\"Worker status api handler for reporting SDK harness debug info.\"\"\"\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+\n+import queue\n+import sys\n+import threading\n+import traceback\n+from collections import defaultdict\n+\n+import grpc\n+\n+from apache_beam.portability.api import beam_fn_api_pb2\n+from apache_beam.portability.api import beam_fn_api_pb2_grpc\n+from apache_beam.runners.worker.channel_factory import GRPCChannelFactory\n+from apache_beam.runners.worker.worker_id_interceptor import WorkerIdInterceptor\n+\n+\n+def thread_dump():", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc0ODU5OA=="}, "originalCommit": {"oid": "7cc279797f17fcf40f3baefa3479e2d4fc75af47"}, "originalPosition": 36}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE5NTA1MA==", "bodyText": "As mentioned above, Lets add a jira to clean StatusServer in sdk_worker_main", "url": "https://github.com/apache/beam/pull/10598#discussion_r369195050", "createdAt": "2020-01-21T19:21:51Z", "author": {"login": "angoenka"}, "path": "sdks/python/apache_beam/runners/worker/worker_status.py", "diffHunk": "@@ -0,0 +1,139 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\"\"\"Worker status api handler for reporting SDK harness debug info.\"\"\"\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+\n+import queue\n+import sys\n+import threading\n+import traceback\n+from collections import defaultdict\n+\n+import grpc\n+\n+from apache_beam.portability.api import beam_fn_api_pb2\n+from apache_beam.portability.api import beam_fn_api_pb2_grpc\n+from apache_beam.runners.worker.channel_factory import GRPCChannelFactory\n+from apache_beam.runners.worker.worker_id_interceptor import WorkerIdInterceptor\n+\n+\n+def thread_dump():", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc0ODU5OA=="}, "originalCommit": {"oid": "7cc279797f17fcf40f3baefa3479e2d4fc75af47"}, "originalPosition": 36}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MjI5ODEzOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/worker/worker_status.py", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QwMzoxMzo0MFrOFetyBQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xOFQwMTowODoxN1rOFfIvow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc1MTY4NQ==", "bodyText": "We can also expose it over a http server on dynamic port.", "url": "https://github.com/apache/beam/pull/10598#discussion_r367751685", "createdAt": "2020-01-17T03:13:40Z", "author": {"login": "angoenka"}, "path": "sdks/python/apache_beam/runners/worker/worker_status.py", "diffHunk": "@@ -0,0 +1,139 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\"\"\"Worker status api handler for reporting SDK harness debug info.\"\"\"\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+\n+import queue\n+import sys\n+import threading\n+import traceback\n+from collections import defaultdict\n+\n+import grpc\n+\n+from apache_beam.portability.api import beam_fn_api_pb2\n+from apache_beam.portability.api import beam_fn_api_pb2_grpc\n+from apache_beam.runners.worker.channel_factory import GRPCChannelFactory\n+from apache_beam.runners.worker.worker_id_interceptor import WorkerIdInterceptor\n+\n+\n+def thread_dump():\n+  # deduplicate threads with same stack trace\n+  stack_traces = defaultdict(list)\n+  frames = sys._current_frames()  # pylint: disable=protected-access\n+\n+  for t in threading.enumerate():\n+    stack_trace = ''.join(traceback.format_stack(frames[t.ident]))\n+    thread_ident_name = (t.ident, t.name)\n+    stack_traces[stack_trace].append(thread_ident_name)\n+\n+  all_traces = ['=' * 10 + 'THREAD DUMP' + '=' * 10]\n+  for stack, identity in stack_traces.items():\n+    ident, name = identity[0]\n+    trace = '--- Thread #%s name: %s %s---\\n' % (\n+        ident, name, 'and other %d threads' %\n+        (len(identity) - 1) if len(identity) > 1 else '')\n+    if len(identity) > 1:\n+      trace += 'threads: %s\\n' % identity\n+    trace += stack\n+    all_traces.append(trace)\n+  all_traces.append('=' * 30)\n+  return '\\n'.join(x.encode('utf-8') for x in all_traces)\n+\n+\n+def active_processing_bundles_state(bundle_process_cache):\n+  active_bundles = ['=' * 10 + 'ACTIVE PROCESSING BUNDLES' + '=' * 10]\n+  if not bundle_process_cache.active_bundle_processors:\n+    active_bundles.append(\"No active processing bundles.\")\n+  else:\n+    cache = []\n+    for instruction in list(\n+        bundle_process_cache.active_bundle_processors.keys()):\n+      processor = bundle_process_cache.lookup(instruction)\n+      if processor:\n+        info = processor.state_sampler.get_info()\n+        cache.append((instruction,\n+                      processor.process_bundle_descriptor.id,\n+                      info.tracked_thread, info.time_since_transition))\n+    # reverse sort active bundle by time since last transition, keep top 10.\n+    cache.sort(key=lambda x: x[-1], reverse=True)\n+    for s in cache[:10]:\n+      state = '--- instruction %s ---\\n' % s[0]\n+      state += 'ProcessBundleDescriptorId: %s\\n' % s[1]\n+      state += \"tracked thread: %s\\n\" % s[2]\n+      state += \"time since transition: %.2f seconds\\n\" % (s[3] / 1e9)\n+      active_bundles.append(state)\n+\n+  active_bundles.append('=' * 30)\n+  return '\\n'.join(x.encode('utf-8') for x in active_bundles)\n+\n+\n+DONE = object()\n+\n+\n+class FnApiWorkerStatusHandler(object):\n+  def __init__(self, status_address, bundle_process_cache=None):\n+    self._alive = True\n+    self._bundle_process_cache = bundle_process_cache\n+    ch = GRPCChannelFactory.insecure_channel(status_address)\n+    grpc.channel_ready_future(ch).result(timeout=60)\n+    self._status_channel = grpc.intercept_channel(ch, WorkerIdInterceptor())\n+    self._status_stub = beam_fn_api_pb2_grpc.BeamFnWorkerStatusStub(\n+        self._status_channel)\n+    self._responses = queue.Queue()\n+    self._server = threading.Thread(target=lambda: self._serve(),\n+                                    name='fn_api_status_handler')\n+    self._server.daemon = True\n+    self._server.start()\n+\n+  def _get_responses(self):\n+    while True:\n+      response = self._responses.get()\n+      if response is DONE:\n+        self._alive = False\n+        return\n+      yield response\n+\n+  def _serve(self):\n+    while self._alive:\n+      for request in self._status_stub.WorkerStatus(self._get_responses()):\n+        try:\n+          response = self.generate_status_response()\n+        except Exception:\n+          traceback_string = traceback.format_exc()\n+          self._responses.put(\n+              beam_fn_api_pb2.WorkerStatusResponse(\n+                  id=request.id,\n+                  error=\"Exception encountered while generating \"\n+                  \"status page: %s\" % traceback_string))\n+          continue\n+\n+        self._responses.put(\n+            beam_fn_api_pb2.WorkerStatusResponse(id=request.id,\n+                                                 status_info=response))\n+\n+  def generate_status_response(self):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7cc279797f17fcf40f3baefa3479e2d4fc75af47"}, "originalPosition": 131}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwNjcwNg==", "bodyText": "it's possible but since eventually we'll be able to query the runner like localhost:port/sdk_status?id=<sdk_id>, it has same effect as exposing it individually.", "url": "https://github.com/apache/beam/pull/10598#discussion_r368106706", "createdAt": "2020-01-17T19:45:49Z", "author": {"login": "y1chi"}, "path": "sdks/python/apache_beam/runners/worker/worker_status.py", "diffHunk": "@@ -0,0 +1,139 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\"\"\"Worker status api handler for reporting SDK harness debug info.\"\"\"\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+\n+import queue\n+import sys\n+import threading\n+import traceback\n+from collections import defaultdict\n+\n+import grpc\n+\n+from apache_beam.portability.api import beam_fn_api_pb2\n+from apache_beam.portability.api import beam_fn_api_pb2_grpc\n+from apache_beam.runners.worker.channel_factory import GRPCChannelFactory\n+from apache_beam.runners.worker.worker_id_interceptor import WorkerIdInterceptor\n+\n+\n+def thread_dump():\n+  # deduplicate threads with same stack trace\n+  stack_traces = defaultdict(list)\n+  frames = sys._current_frames()  # pylint: disable=protected-access\n+\n+  for t in threading.enumerate():\n+    stack_trace = ''.join(traceback.format_stack(frames[t.ident]))\n+    thread_ident_name = (t.ident, t.name)\n+    stack_traces[stack_trace].append(thread_ident_name)\n+\n+  all_traces = ['=' * 10 + 'THREAD DUMP' + '=' * 10]\n+  for stack, identity in stack_traces.items():\n+    ident, name = identity[0]\n+    trace = '--- Thread #%s name: %s %s---\\n' % (\n+        ident, name, 'and other %d threads' %\n+        (len(identity) - 1) if len(identity) > 1 else '')\n+    if len(identity) > 1:\n+      trace += 'threads: %s\\n' % identity\n+    trace += stack\n+    all_traces.append(trace)\n+  all_traces.append('=' * 30)\n+  return '\\n'.join(x.encode('utf-8') for x in all_traces)\n+\n+\n+def active_processing_bundles_state(bundle_process_cache):\n+  active_bundles = ['=' * 10 + 'ACTIVE PROCESSING BUNDLES' + '=' * 10]\n+  if not bundle_process_cache.active_bundle_processors:\n+    active_bundles.append(\"No active processing bundles.\")\n+  else:\n+    cache = []\n+    for instruction in list(\n+        bundle_process_cache.active_bundle_processors.keys()):\n+      processor = bundle_process_cache.lookup(instruction)\n+      if processor:\n+        info = processor.state_sampler.get_info()\n+        cache.append((instruction,\n+                      processor.process_bundle_descriptor.id,\n+                      info.tracked_thread, info.time_since_transition))\n+    # reverse sort active bundle by time since last transition, keep top 10.\n+    cache.sort(key=lambda x: x[-1], reverse=True)\n+    for s in cache[:10]:\n+      state = '--- instruction %s ---\\n' % s[0]\n+      state += 'ProcessBundleDescriptorId: %s\\n' % s[1]\n+      state += \"tracked thread: %s\\n\" % s[2]\n+      state += \"time since transition: %.2f seconds\\n\" % (s[3] / 1e9)\n+      active_bundles.append(state)\n+\n+  active_bundles.append('=' * 30)\n+  return '\\n'.join(x.encode('utf-8') for x in active_bundles)\n+\n+\n+DONE = object()\n+\n+\n+class FnApiWorkerStatusHandler(object):\n+  def __init__(self, status_address, bundle_process_cache=None):\n+    self._alive = True\n+    self._bundle_process_cache = bundle_process_cache\n+    ch = GRPCChannelFactory.insecure_channel(status_address)\n+    grpc.channel_ready_future(ch).result(timeout=60)\n+    self._status_channel = grpc.intercept_channel(ch, WorkerIdInterceptor())\n+    self._status_stub = beam_fn_api_pb2_grpc.BeamFnWorkerStatusStub(\n+        self._status_channel)\n+    self._responses = queue.Queue()\n+    self._server = threading.Thread(target=lambda: self._serve(),\n+                                    name='fn_api_status_handler')\n+    self._server.daemon = True\n+    self._server.start()\n+\n+  def _get_responses(self):\n+    while True:\n+      response = self._responses.get()\n+      if response is DONE:\n+        self._alive = False\n+        return\n+      yield response\n+\n+  def _serve(self):\n+    while self._alive:\n+      for request in self._status_stub.WorkerStatus(self._get_responses()):\n+        try:\n+          response = self.generate_status_response()\n+        except Exception:\n+          traceback_string = traceback.format_exc()\n+          self._responses.put(\n+              beam_fn_api_pb2.WorkerStatusResponse(\n+                  id=request.id,\n+                  error=\"Exception encountered while generating \"\n+                  \"status page: %s\" % traceback_string))\n+          continue\n+\n+        self._responses.put(\n+            beam_fn_api_pb2.WorkerStatusResponse(id=request.id,\n+                                                 status_info=response))\n+\n+  def generate_status_response(self):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc1MTY4NQ=="}, "originalCommit": {"oid": "7cc279797f17fcf40f3baefa3479e2d4fc75af47"}, "originalPosition": 131}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODE5MzQ0Mw==", "bodyText": "Sounds reasonable.", "url": "https://github.com/apache/beam/pull/10598#discussion_r368193443", "createdAt": "2020-01-18T01:08:17Z", "author": {"login": "angoenka"}, "path": "sdks/python/apache_beam/runners/worker/worker_status.py", "diffHunk": "@@ -0,0 +1,139 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\"\"\"Worker status api handler for reporting SDK harness debug info.\"\"\"\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+\n+import queue\n+import sys\n+import threading\n+import traceback\n+from collections import defaultdict\n+\n+import grpc\n+\n+from apache_beam.portability.api import beam_fn_api_pb2\n+from apache_beam.portability.api import beam_fn_api_pb2_grpc\n+from apache_beam.runners.worker.channel_factory import GRPCChannelFactory\n+from apache_beam.runners.worker.worker_id_interceptor import WorkerIdInterceptor\n+\n+\n+def thread_dump():\n+  # deduplicate threads with same stack trace\n+  stack_traces = defaultdict(list)\n+  frames = sys._current_frames()  # pylint: disable=protected-access\n+\n+  for t in threading.enumerate():\n+    stack_trace = ''.join(traceback.format_stack(frames[t.ident]))\n+    thread_ident_name = (t.ident, t.name)\n+    stack_traces[stack_trace].append(thread_ident_name)\n+\n+  all_traces = ['=' * 10 + 'THREAD DUMP' + '=' * 10]\n+  for stack, identity in stack_traces.items():\n+    ident, name = identity[0]\n+    trace = '--- Thread #%s name: %s %s---\\n' % (\n+        ident, name, 'and other %d threads' %\n+        (len(identity) - 1) if len(identity) > 1 else '')\n+    if len(identity) > 1:\n+      trace += 'threads: %s\\n' % identity\n+    trace += stack\n+    all_traces.append(trace)\n+  all_traces.append('=' * 30)\n+  return '\\n'.join(x.encode('utf-8') for x in all_traces)\n+\n+\n+def active_processing_bundles_state(bundle_process_cache):\n+  active_bundles = ['=' * 10 + 'ACTIVE PROCESSING BUNDLES' + '=' * 10]\n+  if not bundle_process_cache.active_bundle_processors:\n+    active_bundles.append(\"No active processing bundles.\")\n+  else:\n+    cache = []\n+    for instruction in list(\n+        bundle_process_cache.active_bundle_processors.keys()):\n+      processor = bundle_process_cache.lookup(instruction)\n+      if processor:\n+        info = processor.state_sampler.get_info()\n+        cache.append((instruction,\n+                      processor.process_bundle_descriptor.id,\n+                      info.tracked_thread, info.time_since_transition))\n+    # reverse sort active bundle by time since last transition, keep top 10.\n+    cache.sort(key=lambda x: x[-1], reverse=True)\n+    for s in cache[:10]:\n+      state = '--- instruction %s ---\\n' % s[0]\n+      state += 'ProcessBundleDescriptorId: %s\\n' % s[1]\n+      state += \"tracked thread: %s\\n\" % s[2]\n+      state += \"time since transition: %.2f seconds\\n\" % (s[3] / 1e9)\n+      active_bundles.append(state)\n+\n+  active_bundles.append('=' * 30)\n+  return '\\n'.join(x.encode('utf-8') for x in active_bundles)\n+\n+\n+DONE = object()\n+\n+\n+class FnApiWorkerStatusHandler(object):\n+  def __init__(self, status_address, bundle_process_cache=None):\n+    self._alive = True\n+    self._bundle_process_cache = bundle_process_cache\n+    ch = GRPCChannelFactory.insecure_channel(status_address)\n+    grpc.channel_ready_future(ch).result(timeout=60)\n+    self._status_channel = grpc.intercept_channel(ch, WorkerIdInterceptor())\n+    self._status_stub = beam_fn_api_pb2_grpc.BeamFnWorkerStatusStub(\n+        self._status_channel)\n+    self._responses = queue.Queue()\n+    self._server = threading.Thread(target=lambda: self._serve(),\n+                                    name='fn_api_status_handler')\n+    self._server.daemon = True\n+    self._server.start()\n+\n+  def _get_responses(self):\n+    while True:\n+      response = self._responses.get()\n+      if response is DONE:\n+        self._alive = False\n+        return\n+      yield response\n+\n+  def _serve(self):\n+    while self._alive:\n+      for request in self._status_stub.WorkerStatus(self._get_responses()):\n+        try:\n+          response = self.generate_status_response()\n+        except Exception:\n+          traceback_string = traceback.format_exc()\n+          self._responses.put(\n+              beam_fn_api_pb2.WorkerStatusResponse(\n+                  id=request.id,\n+                  error=\"Exception encountered while generating \"\n+                  \"status page: %s\" % traceback_string))\n+          continue\n+\n+        self._responses.put(\n+            beam_fn_api_pb2.WorkerStatusResponse(id=request.id,\n+                                                 status_info=response))\n+\n+  def generate_status_response(self):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc1MTY4NQ=="}, "originalCommit": {"oid": "7cc279797f17fcf40f3baefa3479e2d4fc75af47"}, "originalPosition": 131}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MjMwNDYyOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/worker/worker_status.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QwMzoxODozMlrOFet1jA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QxOTo1MDo1MlrOFfDkhg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc1MjU4OA==", "bodyText": "We can move the response collection here and avoid continue later on to make code simple.\n\n  \n    \n  \n    \n\n  \n  This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                      response = self.generate_status_response()\n          \n          \n            \n                      self._responses.put(beam_fn_api_pb2.WorkerStatusResponse(id=request.id, status_info=self.generate_status_response()))", "url": "https://github.com/apache/beam/pull/10598#discussion_r367752588", "createdAt": "2020-01-17T03:18:32Z", "author": {"login": "angoenka"}, "path": "sdks/python/apache_beam/runners/worker/worker_status.py", "diffHunk": "@@ -0,0 +1,139 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\"\"\"Worker status api handler for reporting SDK harness debug info.\"\"\"\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+\n+import queue\n+import sys\n+import threading\n+import traceback\n+from collections import defaultdict\n+\n+import grpc\n+\n+from apache_beam.portability.api import beam_fn_api_pb2\n+from apache_beam.portability.api import beam_fn_api_pb2_grpc\n+from apache_beam.runners.worker.channel_factory import GRPCChannelFactory\n+from apache_beam.runners.worker.worker_id_interceptor import WorkerIdInterceptor\n+\n+\n+def thread_dump():\n+  # deduplicate threads with same stack trace\n+  stack_traces = defaultdict(list)\n+  frames = sys._current_frames()  # pylint: disable=protected-access\n+\n+  for t in threading.enumerate():\n+    stack_trace = ''.join(traceback.format_stack(frames[t.ident]))\n+    thread_ident_name = (t.ident, t.name)\n+    stack_traces[stack_trace].append(thread_ident_name)\n+\n+  all_traces = ['=' * 10 + 'THREAD DUMP' + '=' * 10]\n+  for stack, identity in stack_traces.items():\n+    ident, name = identity[0]\n+    trace = '--- Thread #%s name: %s %s---\\n' % (\n+        ident, name, 'and other %d threads' %\n+        (len(identity) - 1) if len(identity) > 1 else '')\n+    if len(identity) > 1:\n+      trace += 'threads: %s\\n' % identity\n+    trace += stack\n+    all_traces.append(trace)\n+  all_traces.append('=' * 30)\n+  return '\\n'.join(x.encode('utf-8') for x in all_traces)\n+\n+\n+def active_processing_bundles_state(bundle_process_cache):\n+  active_bundles = ['=' * 10 + 'ACTIVE PROCESSING BUNDLES' + '=' * 10]\n+  if not bundle_process_cache.active_bundle_processors:\n+    active_bundles.append(\"No active processing bundles.\")\n+  else:\n+    cache = []\n+    for instruction in list(\n+        bundle_process_cache.active_bundle_processors.keys()):\n+      processor = bundle_process_cache.lookup(instruction)\n+      if processor:\n+        info = processor.state_sampler.get_info()\n+        cache.append((instruction,\n+                      processor.process_bundle_descriptor.id,\n+                      info.tracked_thread, info.time_since_transition))\n+    # reverse sort active bundle by time since last transition, keep top 10.\n+    cache.sort(key=lambda x: x[-1], reverse=True)\n+    for s in cache[:10]:\n+      state = '--- instruction %s ---\\n' % s[0]\n+      state += 'ProcessBundleDescriptorId: %s\\n' % s[1]\n+      state += \"tracked thread: %s\\n\" % s[2]\n+      state += \"time since transition: %.2f seconds\\n\" % (s[3] / 1e9)\n+      active_bundles.append(state)\n+\n+  active_bundles.append('=' * 30)\n+  return '\\n'.join(x.encode('utf-8') for x in active_bundles)\n+\n+\n+DONE = object()\n+\n+\n+class FnApiWorkerStatusHandler(object):\n+  def __init__(self, status_address, bundle_process_cache=None):\n+    self._alive = True\n+    self._bundle_process_cache = bundle_process_cache\n+    ch = GRPCChannelFactory.insecure_channel(status_address)\n+    grpc.channel_ready_future(ch).result(timeout=60)\n+    self._status_channel = grpc.intercept_channel(ch, WorkerIdInterceptor())\n+    self._status_stub = beam_fn_api_pb2_grpc.BeamFnWorkerStatusStub(\n+        self._status_channel)\n+    self._responses = queue.Queue()\n+    self._server = threading.Thread(target=lambda: self._serve(),\n+                                    name='fn_api_status_handler')\n+    self._server.daemon = True\n+    self._server.start()\n+\n+  def _get_responses(self):\n+    while True:\n+      response = self._responses.get()\n+      if response is DONE:\n+        self._alive = False\n+        return\n+      yield response\n+\n+  def _serve(self):\n+    while self._alive:\n+      for request in self._status_stub.WorkerStatus(self._get_responses()):\n+        try:\n+          response = self.generate_status_response()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7cc279797f17fcf40f3baefa3479e2d4fc75af47"}, "originalPosition": 117}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwODY3OA==", "bodyText": "done.", "url": "https://github.com/apache/beam/pull/10598#discussion_r368108678", "createdAt": "2020-01-17T19:50:52Z", "author": {"login": "y1chi"}, "path": "sdks/python/apache_beam/runners/worker/worker_status.py", "diffHunk": "@@ -0,0 +1,139 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\"\"\"Worker status api handler for reporting SDK harness debug info.\"\"\"\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+\n+import queue\n+import sys\n+import threading\n+import traceback\n+from collections import defaultdict\n+\n+import grpc\n+\n+from apache_beam.portability.api import beam_fn_api_pb2\n+from apache_beam.portability.api import beam_fn_api_pb2_grpc\n+from apache_beam.runners.worker.channel_factory import GRPCChannelFactory\n+from apache_beam.runners.worker.worker_id_interceptor import WorkerIdInterceptor\n+\n+\n+def thread_dump():\n+  # deduplicate threads with same stack trace\n+  stack_traces = defaultdict(list)\n+  frames = sys._current_frames()  # pylint: disable=protected-access\n+\n+  for t in threading.enumerate():\n+    stack_trace = ''.join(traceback.format_stack(frames[t.ident]))\n+    thread_ident_name = (t.ident, t.name)\n+    stack_traces[stack_trace].append(thread_ident_name)\n+\n+  all_traces = ['=' * 10 + 'THREAD DUMP' + '=' * 10]\n+  for stack, identity in stack_traces.items():\n+    ident, name = identity[0]\n+    trace = '--- Thread #%s name: %s %s---\\n' % (\n+        ident, name, 'and other %d threads' %\n+        (len(identity) - 1) if len(identity) > 1 else '')\n+    if len(identity) > 1:\n+      trace += 'threads: %s\\n' % identity\n+    trace += stack\n+    all_traces.append(trace)\n+  all_traces.append('=' * 30)\n+  return '\\n'.join(x.encode('utf-8') for x in all_traces)\n+\n+\n+def active_processing_bundles_state(bundle_process_cache):\n+  active_bundles = ['=' * 10 + 'ACTIVE PROCESSING BUNDLES' + '=' * 10]\n+  if not bundle_process_cache.active_bundle_processors:\n+    active_bundles.append(\"No active processing bundles.\")\n+  else:\n+    cache = []\n+    for instruction in list(\n+        bundle_process_cache.active_bundle_processors.keys()):\n+      processor = bundle_process_cache.lookup(instruction)\n+      if processor:\n+        info = processor.state_sampler.get_info()\n+        cache.append((instruction,\n+                      processor.process_bundle_descriptor.id,\n+                      info.tracked_thread, info.time_since_transition))\n+    # reverse sort active bundle by time since last transition, keep top 10.\n+    cache.sort(key=lambda x: x[-1], reverse=True)\n+    for s in cache[:10]:\n+      state = '--- instruction %s ---\\n' % s[0]\n+      state += 'ProcessBundleDescriptorId: %s\\n' % s[1]\n+      state += \"tracked thread: %s\\n\" % s[2]\n+      state += \"time since transition: %.2f seconds\\n\" % (s[3] / 1e9)\n+      active_bundles.append(state)\n+\n+  active_bundles.append('=' * 30)\n+  return '\\n'.join(x.encode('utf-8') for x in active_bundles)\n+\n+\n+DONE = object()\n+\n+\n+class FnApiWorkerStatusHandler(object):\n+  def __init__(self, status_address, bundle_process_cache=None):\n+    self._alive = True\n+    self._bundle_process_cache = bundle_process_cache\n+    ch = GRPCChannelFactory.insecure_channel(status_address)\n+    grpc.channel_ready_future(ch).result(timeout=60)\n+    self._status_channel = grpc.intercept_channel(ch, WorkerIdInterceptor())\n+    self._status_stub = beam_fn_api_pb2_grpc.BeamFnWorkerStatusStub(\n+        self._status_channel)\n+    self._responses = queue.Queue()\n+    self._server = threading.Thread(target=lambda: self._serve(),\n+                                    name='fn_api_status_handler')\n+    self._server.daemon = True\n+    self._server.start()\n+\n+  def _get_responses(self):\n+    while True:\n+      response = self._responses.get()\n+      if response is DONE:\n+        self._alive = False\n+        return\n+      yield response\n+\n+  def _serve(self):\n+    while self._alive:\n+      for request in self._status_stub.WorkerStatus(self._get_responses()):\n+        try:\n+          response = self.generate_status_response()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc1MjU4OA=="}, "originalCommit": {"oid": "7cc279797f17fcf40f3baefa3479e2d4fc75af47"}, "originalPosition": 117}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3MjMwOTI3OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/worker/worker_status.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QwMzoyMjowOVrOFet4Lg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QxOTo1MDo0OFrOFfDkbA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc1MzI2Mg==", "bodyText": "We can remove this if we move addition of response above.", "url": "https://github.com/apache/beam/pull/10598#discussion_r367753262", "createdAt": "2020-01-17T03:22:09Z", "author": {"login": "angoenka"}, "path": "sdks/python/apache_beam/runners/worker/worker_status.py", "diffHunk": "@@ -0,0 +1,139 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\"\"\"Worker status api handler for reporting SDK harness debug info.\"\"\"\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+\n+import queue\n+import sys\n+import threading\n+import traceback\n+from collections import defaultdict\n+\n+import grpc\n+\n+from apache_beam.portability.api import beam_fn_api_pb2\n+from apache_beam.portability.api import beam_fn_api_pb2_grpc\n+from apache_beam.runners.worker.channel_factory import GRPCChannelFactory\n+from apache_beam.runners.worker.worker_id_interceptor import WorkerIdInterceptor\n+\n+\n+def thread_dump():\n+  # deduplicate threads with same stack trace\n+  stack_traces = defaultdict(list)\n+  frames = sys._current_frames()  # pylint: disable=protected-access\n+\n+  for t in threading.enumerate():\n+    stack_trace = ''.join(traceback.format_stack(frames[t.ident]))\n+    thread_ident_name = (t.ident, t.name)\n+    stack_traces[stack_trace].append(thread_ident_name)\n+\n+  all_traces = ['=' * 10 + 'THREAD DUMP' + '=' * 10]\n+  for stack, identity in stack_traces.items():\n+    ident, name = identity[0]\n+    trace = '--- Thread #%s name: %s %s---\\n' % (\n+        ident, name, 'and other %d threads' %\n+        (len(identity) - 1) if len(identity) > 1 else '')\n+    if len(identity) > 1:\n+      trace += 'threads: %s\\n' % identity\n+    trace += stack\n+    all_traces.append(trace)\n+  all_traces.append('=' * 30)\n+  return '\\n'.join(x.encode('utf-8') for x in all_traces)\n+\n+\n+def active_processing_bundles_state(bundle_process_cache):\n+  active_bundles = ['=' * 10 + 'ACTIVE PROCESSING BUNDLES' + '=' * 10]\n+  if not bundle_process_cache.active_bundle_processors:\n+    active_bundles.append(\"No active processing bundles.\")\n+  else:\n+    cache = []\n+    for instruction in list(\n+        bundle_process_cache.active_bundle_processors.keys()):\n+      processor = bundle_process_cache.lookup(instruction)\n+      if processor:\n+        info = processor.state_sampler.get_info()\n+        cache.append((instruction,\n+                      processor.process_bundle_descriptor.id,\n+                      info.tracked_thread, info.time_since_transition))\n+    # reverse sort active bundle by time since last transition, keep top 10.\n+    cache.sort(key=lambda x: x[-1], reverse=True)\n+    for s in cache[:10]:\n+      state = '--- instruction %s ---\\n' % s[0]\n+      state += 'ProcessBundleDescriptorId: %s\\n' % s[1]\n+      state += \"tracked thread: %s\\n\" % s[2]\n+      state += \"time since transition: %.2f seconds\\n\" % (s[3] / 1e9)\n+      active_bundles.append(state)\n+\n+  active_bundles.append('=' * 30)\n+  return '\\n'.join(x.encode('utf-8') for x in active_bundles)\n+\n+\n+DONE = object()\n+\n+\n+class FnApiWorkerStatusHandler(object):\n+  def __init__(self, status_address, bundle_process_cache=None):\n+    self._alive = True\n+    self._bundle_process_cache = bundle_process_cache\n+    ch = GRPCChannelFactory.insecure_channel(status_address)\n+    grpc.channel_ready_future(ch).result(timeout=60)\n+    self._status_channel = grpc.intercept_channel(ch, WorkerIdInterceptor())\n+    self._status_stub = beam_fn_api_pb2_grpc.BeamFnWorkerStatusStub(\n+        self._status_channel)\n+    self._responses = queue.Queue()\n+    self._server = threading.Thread(target=lambda: self._serve(),\n+                                    name='fn_api_status_handler')\n+    self._server.daemon = True\n+    self._server.start()\n+\n+  def _get_responses(self):\n+    while True:\n+      response = self._responses.get()\n+      if response is DONE:\n+        self._alive = False\n+        return\n+      yield response\n+\n+  def _serve(self):\n+    while self._alive:\n+      for request in self._status_stub.WorkerStatus(self._get_responses()):\n+        try:\n+          response = self.generate_status_response()\n+        except Exception:\n+          traceback_string = traceback.format_exc()\n+          self._responses.put(\n+              beam_fn_api_pb2.WorkerStatusResponse(\n+                  id=request.id,\n+                  error=\"Exception encountered while generating \"\n+                  \"status page: %s\" % traceback_string))\n+          continue\n+\n+        self._responses.put(\n+            beam_fn_api_pb2.WorkerStatusResponse(id=request.id,\n+                                                 status_info=response))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7cc279797f17fcf40f3baefa3479e2d4fc75af47"}, "originalPosition": 129}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODEwODY1Mg==", "bodyText": "done.", "url": "https://github.com/apache/beam/pull/10598#discussion_r368108652", "createdAt": "2020-01-17T19:50:48Z", "author": {"login": "y1chi"}, "path": "sdks/python/apache_beam/runners/worker/worker_status.py", "diffHunk": "@@ -0,0 +1,139 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\"\"\"Worker status api handler for reporting SDK harness debug info.\"\"\"\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+\n+import queue\n+import sys\n+import threading\n+import traceback\n+from collections import defaultdict\n+\n+import grpc\n+\n+from apache_beam.portability.api import beam_fn_api_pb2\n+from apache_beam.portability.api import beam_fn_api_pb2_grpc\n+from apache_beam.runners.worker.channel_factory import GRPCChannelFactory\n+from apache_beam.runners.worker.worker_id_interceptor import WorkerIdInterceptor\n+\n+\n+def thread_dump():\n+  # deduplicate threads with same stack trace\n+  stack_traces = defaultdict(list)\n+  frames = sys._current_frames()  # pylint: disable=protected-access\n+\n+  for t in threading.enumerate():\n+    stack_trace = ''.join(traceback.format_stack(frames[t.ident]))\n+    thread_ident_name = (t.ident, t.name)\n+    stack_traces[stack_trace].append(thread_ident_name)\n+\n+  all_traces = ['=' * 10 + 'THREAD DUMP' + '=' * 10]\n+  for stack, identity in stack_traces.items():\n+    ident, name = identity[0]\n+    trace = '--- Thread #%s name: %s %s---\\n' % (\n+        ident, name, 'and other %d threads' %\n+        (len(identity) - 1) if len(identity) > 1 else '')\n+    if len(identity) > 1:\n+      trace += 'threads: %s\\n' % identity\n+    trace += stack\n+    all_traces.append(trace)\n+  all_traces.append('=' * 30)\n+  return '\\n'.join(x.encode('utf-8') for x in all_traces)\n+\n+\n+def active_processing_bundles_state(bundle_process_cache):\n+  active_bundles = ['=' * 10 + 'ACTIVE PROCESSING BUNDLES' + '=' * 10]\n+  if not bundle_process_cache.active_bundle_processors:\n+    active_bundles.append(\"No active processing bundles.\")\n+  else:\n+    cache = []\n+    for instruction in list(\n+        bundle_process_cache.active_bundle_processors.keys()):\n+      processor = bundle_process_cache.lookup(instruction)\n+      if processor:\n+        info = processor.state_sampler.get_info()\n+        cache.append((instruction,\n+                      processor.process_bundle_descriptor.id,\n+                      info.tracked_thread, info.time_since_transition))\n+    # reverse sort active bundle by time since last transition, keep top 10.\n+    cache.sort(key=lambda x: x[-1], reverse=True)\n+    for s in cache[:10]:\n+      state = '--- instruction %s ---\\n' % s[0]\n+      state += 'ProcessBundleDescriptorId: %s\\n' % s[1]\n+      state += \"tracked thread: %s\\n\" % s[2]\n+      state += \"time since transition: %.2f seconds\\n\" % (s[3] / 1e9)\n+      active_bundles.append(state)\n+\n+  active_bundles.append('=' * 30)\n+  return '\\n'.join(x.encode('utf-8') for x in active_bundles)\n+\n+\n+DONE = object()\n+\n+\n+class FnApiWorkerStatusHandler(object):\n+  def __init__(self, status_address, bundle_process_cache=None):\n+    self._alive = True\n+    self._bundle_process_cache = bundle_process_cache\n+    ch = GRPCChannelFactory.insecure_channel(status_address)\n+    grpc.channel_ready_future(ch).result(timeout=60)\n+    self._status_channel = grpc.intercept_channel(ch, WorkerIdInterceptor())\n+    self._status_stub = beam_fn_api_pb2_grpc.BeamFnWorkerStatusStub(\n+        self._status_channel)\n+    self._responses = queue.Queue()\n+    self._server = threading.Thread(target=lambda: self._serve(),\n+                                    name='fn_api_status_handler')\n+    self._server.daemon = True\n+    self._server.start()\n+\n+  def _get_responses(self):\n+    while True:\n+      response = self._responses.get()\n+      if response is DONE:\n+        self._alive = False\n+        return\n+      yield response\n+\n+  def _serve(self):\n+    while self._alive:\n+      for request in self._status_stub.WorkerStatus(self._get_responses()):\n+        try:\n+          response = self.generate_status_response()\n+        except Exception:\n+          traceback_string = traceback.format_exc()\n+          self._responses.put(\n+              beam_fn_api_pb2.WorkerStatusResponse(\n+                  id=request.id,\n+                  error=\"Exception encountered while generating \"\n+                  \"status page: %s\" % traceback_string))\n+          continue\n+\n+        self._responses.put(\n+            beam_fn_api_pb2.WorkerStatusResponse(id=request.id,\n+                                                 status_info=response))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2Nzc1MzI2Mg=="}, "originalCommit": {"oid": "7cc279797f17fcf40f3baefa3479e2d4fc75af47"}, "originalPosition": 129}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI4MTc3OTgxOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/worker/sdk_worker.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMVQxOToxOToxN1rOFgFzYg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMVQyMDo1OTo0NVrOFgIncA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE5MzgyNg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    _LOGGER.info('Error creating worker status request handler, skipping '\n          \n          \n            \n                    _LOGGER.warn('Error creating worker status request handler, skipping '", "url": "https://github.com/apache/beam/pull/10598#discussion_r369193826", "createdAt": "2020-01-21T19:19:17Z", "author": {"login": "angoenka"}, "path": "sdks/python/apache_beam/runners/worker/sdk_worker.py", "diffHunk": "@@ -110,6 +112,15 @@ def __init__(self,\n         data_channel_factory=self._data_channel_factory,\n         fns=self._fns)\n \n+    if status_address:\n+      try:\n+        self._status_handler = FnApiWorkerStatusHandler(\n+            status_address, self._bundle_processor_cache)\n+      except Exception:\n+        traceback_string = traceback.format_exc()\n+        _LOGGER.info('Error creating worker status request handler, skipping '", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "20b8aac09c9d72c07b5c155b2afb9fc1dca351fa"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIzOTkyMA==", "bodyText": "done.", "url": "https://github.com/apache/beam/pull/10598#discussion_r369239920", "createdAt": "2020-01-21T20:59:45Z", "author": {"login": "y1chi"}, "path": "sdks/python/apache_beam/runners/worker/sdk_worker.py", "diffHunk": "@@ -110,6 +112,15 @@ def __init__(self,\n         data_channel_factory=self._data_channel_factory,\n         fns=self._fns)\n \n+    if status_address:\n+      try:\n+        self._status_handler = FnApiWorkerStatusHandler(\n+            status_address, self._bundle_processor_cache)\n+      except Exception:\n+        traceback_string = traceback.format_exc()\n+        _LOGGER.info('Error creating worker status request handler, skipping '", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE5MzgyNg=="}, "originalCommit": {"oid": "20b8aac09c9d72c07b5c155b2afb9fc1dca351fa"}, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI4MTc4Mzk4OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/worker/sdk_worker_main.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMVQxOToyMDo0N1rOFgF2Lw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMVQyMTozNjozNlrOFgJlhQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE5NDU0Mw==", "bodyText": "Lets add a jira to clean StatusServer from here completely once we have rolled out Debug capture.", "url": "https://github.com/apache/beam/pull/10598#discussion_r369194543", "createdAt": "2020-01-21T19:20:47Z", "author": {"login": "angoenka"}, "path": "sdks/python/apache_beam/runners/worker/sdk_worker_main.py", "diffHunk": "@@ -78,8 +67,7 @@ def do_GET(self):  # pylint: disable=invalid-name\n         self.send_header('Content-Type', 'text/plain')\n         self.end_headers()\n \n-        for line in StatusServer.get_thread_dump():\n-          self.wfile.write(line.encode('utf-8'))\n+        self.wfile.write(thread_dump())", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "20b8aac09c9d72c07b5c155b2afb9fc1dca351fa"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTI1NTgxMw==", "bodyText": "created https://issues.apache.org/jira/browse/BEAM-9165", "url": "https://github.com/apache/beam/pull/10598#discussion_r369255813", "createdAt": "2020-01-21T21:36:36Z", "author": {"login": "y1chi"}, "path": "sdks/python/apache_beam/runners/worker/sdk_worker_main.py", "diffHunk": "@@ -78,8 +67,7 @@ def do_GET(self):  # pylint: disable=invalid-name\n         self.send_header('Content-Type', 'text/plain')\n         self.end_headers()\n \n-        for line in StatusServer.get_thread_dump():\n-          self.wfile.write(line.encode('utf-8'))\n+        self.wfile.write(thread_dump())", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE5NDU0Mw=="}, "originalCommit": {"oid": "20b8aac09c9d72c07b5c155b2afb9fc1dca351fa"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI4MTc5NTg1OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/worker/worker_status.py", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMVQxOToyNDo0N1rOFgF93g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMVQyMToyOTowOFrOFgJYvg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE5NjUxMA==", "bodyText": "Let's add a jira to group threads which have same thread stack for easier analysis and reducing text size.\nThis can be a starter task for new beam contributors.", "url": "https://github.com/apache/beam/pull/10598#discussion_r369196510", "createdAt": "2020-01-21T19:24:47Z", "author": {"login": "angoenka"}, "path": "sdks/python/apache_beam/runners/worker/worker_status.py", "diffHunk": "@@ -0,0 +1,148 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\"\"\"Worker status api handler for reporting SDK harness debug info.\"\"\"\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+\n+import queue\n+import sys\n+import threading\n+import traceback\n+from collections import defaultdict\n+\n+import grpc\n+\n+from apache_beam.portability.api import beam_fn_api_pb2\n+from apache_beam.portability.api import beam_fn_api_pb2_grpc\n+from apache_beam.runners.worker.channel_factory import GRPCChannelFactory\n+from apache_beam.runners.worker.worker_id_interceptor import WorkerIdInterceptor\n+\n+\n+def thread_dump():\n+  \"\"\"Get a thread dump for the current SDK worker harness. \"\"\"\n+  # deduplicate threads with same stack trace\n+  stack_traces = defaultdict(list)\n+  frames = sys._current_frames()  # pylint: disable=protected-access\n+\n+  for t in threading.enumerate():\n+    stack_trace = ''.join(traceback.format_stack(frames[t.ident]))\n+    thread_ident_name = (t.ident, t.name)\n+    stack_traces[stack_trace].append(thread_ident_name)\n+\n+  all_traces = ['=' * 10 + 'THREAD DUMP' + '=' * 10]\n+  for stack, identity in stack_traces.items():", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "20b8aac09c9d72c07b5c155b2afb9fc1dca351fa"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTIzNzM3NA==", "bodyText": "isn't it already included in this PR?", "url": "https://github.com/apache/beam/pull/10598#discussion_r369237374", "createdAt": "2020-01-21T20:53:51Z", "author": {"login": "y1chi"}, "path": "sdks/python/apache_beam/runners/worker/worker_status.py", "diffHunk": "@@ -0,0 +1,148 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\"\"\"Worker status api handler for reporting SDK harness debug info.\"\"\"\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+\n+import queue\n+import sys\n+import threading\n+import traceback\n+from collections import defaultdict\n+\n+import grpc\n+\n+from apache_beam.portability.api import beam_fn_api_pb2\n+from apache_beam.portability.api import beam_fn_api_pb2_grpc\n+from apache_beam.runners.worker.channel_factory import GRPCChannelFactory\n+from apache_beam.runners.worker.worker_id_interceptor import WorkerIdInterceptor\n+\n+\n+def thread_dump():\n+  \"\"\"Get a thread dump for the current SDK worker harness. \"\"\"\n+  # deduplicate threads with same stack trace\n+  stack_traces = defaultdict(list)\n+  frames = sys._current_frames()  # pylint: disable=protected-access\n+\n+  for t in threading.enumerate():\n+    stack_trace = ''.join(traceback.format_stack(frames[t.ident]))\n+    thread_ident_name = (t.ident, t.name)\n+    stack_traces[stack_trace].append(thread_ident_name)\n+\n+  all_traces = ['=' * 10 + 'THREAD DUMP' + '=' * 10]\n+  for stack, identity in stack_traces.items():", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE5NjUxMA=="}, "originalCommit": {"oid": "20b8aac09c9d72c07b5c155b2afb9fc1dca351fa"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTI1MjU0Mg==", "bodyText": "You are right. It's already in this PR.\nWe can print names of all the threads along with count so that we don't miss any information.", "url": "https://github.com/apache/beam/pull/10598#discussion_r369252542", "createdAt": "2020-01-21T21:29:08Z", "author": {"login": "angoenka"}, "path": "sdks/python/apache_beam/runners/worker/worker_status.py", "diffHunk": "@@ -0,0 +1,148 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\"\"\"Worker status api handler for reporting SDK harness debug info.\"\"\"\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+\n+import queue\n+import sys\n+import threading\n+import traceback\n+from collections import defaultdict\n+\n+import grpc\n+\n+from apache_beam.portability.api import beam_fn_api_pb2\n+from apache_beam.portability.api import beam_fn_api_pb2_grpc\n+from apache_beam.runners.worker.channel_factory import GRPCChannelFactory\n+from apache_beam.runners.worker.worker_id_interceptor import WorkerIdInterceptor\n+\n+\n+def thread_dump():\n+  \"\"\"Get a thread dump for the current SDK worker harness. \"\"\"\n+  # deduplicate threads with same stack trace\n+  stack_traces = defaultdict(list)\n+  frames = sys._current_frames()  # pylint: disable=protected-access\n+\n+  for t in threading.enumerate():\n+    stack_trace = ''.join(traceback.format_stack(frames[t.ident]))\n+    thread_ident_name = (t.ident, t.name)\n+    stack_traces[stack_trace].append(thread_ident_name)\n+\n+  all_traces = ['=' * 10 + 'THREAD DUMP' + '=' * 10]\n+  for stack, identity in stack_traces.items():", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE5NjUxMA=="}, "originalCommit": {"oid": "20b8aac09c9d72c07b5c155b2afb9fc1dca351fa"}, "originalPosition": 48}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI4MTgwMzA2OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/worker/worker_status.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMVQxOToyNzowN1rOFgGCbg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMVQyMTozNjo1N1rOFgJmGg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE5NzY3OA==", "bodyText": "This can be private method.", "url": "https://github.com/apache/beam/pull/10598#discussion_r369197678", "createdAt": "2020-01-21T19:27:07Z", "author": {"login": "angoenka"}, "path": "sdks/python/apache_beam/runners/worker/worker_status.py", "diffHunk": "@@ -0,0 +1,148 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\"\"\"Worker status api handler for reporting SDK harness debug info.\"\"\"\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+\n+import queue\n+import sys\n+import threading\n+import traceback\n+from collections import defaultdict\n+\n+import grpc\n+\n+from apache_beam.portability.api import beam_fn_api_pb2\n+from apache_beam.portability.api import beam_fn_api_pb2_grpc\n+from apache_beam.runners.worker.channel_factory import GRPCChannelFactory\n+from apache_beam.runners.worker.worker_id_interceptor import WorkerIdInterceptor\n+\n+\n+def thread_dump():\n+  \"\"\"Get a thread dump for the current SDK worker harness. \"\"\"\n+  # deduplicate threads with same stack trace\n+  stack_traces = defaultdict(list)\n+  frames = sys._current_frames()  # pylint: disable=protected-access\n+\n+  for t in threading.enumerate():\n+    stack_trace = ''.join(traceback.format_stack(frames[t.ident]))\n+    thread_ident_name = (t.ident, t.name)\n+    stack_traces[stack_trace].append(thread_ident_name)\n+\n+  all_traces = ['=' * 10 + 'THREAD DUMP' + '=' * 10]\n+  for stack, identity in stack_traces.items():\n+    ident, name = identity[0]\n+    trace = '--- Thread #%s name: %s %s---\\n' % (\n+        ident, name, 'and other %d threads' %\n+        (len(identity) - 1) if len(identity) > 1 else '')\n+    if len(identity) > 1:\n+      trace += 'threads: %s\\n' % identity\n+    trace += stack\n+    all_traces.append(trace)\n+  all_traces.append('=' * 30)\n+  return '\\n'.join(x.encode('utf-8') for x in all_traces)\n+\n+\n+def active_processing_bundles_state(bundle_process_cache):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "20b8aac09c9d72c07b5c155b2afb9fc1dca351fa"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTI1NTk2Mg==", "bodyText": "done.", "url": "https://github.com/apache/beam/pull/10598#discussion_r369255962", "createdAt": "2020-01-21T21:36:57Z", "author": {"login": "y1chi"}, "path": "sdks/python/apache_beam/runners/worker/worker_status.py", "diffHunk": "@@ -0,0 +1,148 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\"\"\"Worker status api handler for reporting SDK harness debug info.\"\"\"\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+\n+import queue\n+import sys\n+import threading\n+import traceback\n+from collections import defaultdict\n+\n+import grpc\n+\n+from apache_beam.portability.api import beam_fn_api_pb2\n+from apache_beam.portability.api import beam_fn_api_pb2_grpc\n+from apache_beam.runners.worker.channel_factory import GRPCChannelFactory\n+from apache_beam.runners.worker.worker_id_interceptor import WorkerIdInterceptor\n+\n+\n+def thread_dump():\n+  \"\"\"Get a thread dump for the current SDK worker harness. \"\"\"\n+  # deduplicate threads with same stack trace\n+  stack_traces = defaultdict(list)\n+  frames = sys._current_frames()  # pylint: disable=protected-access\n+\n+  for t in threading.enumerate():\n+    stack_trace = ''.join(traceback.format_stack(frames[t.ident]))\n+    thread_ident_name = (t.ident, t.name)\n+    stack_traces[stack_trace].append(thread_ident_name)\n+\n+  all_traces = ['=' * 10 + 'THREAD DUMP' + '=' * 10]\n+  for stack, identity in stack_traces.items():\n+    ident, name = identity[0]\n+    trace = '--- Thread #%s name: %s %s---\\n' % (\n+        ident, name, 'and other %d threads' %\n+        (len(identity) - 1) if len(identity) > 1 else '')\n+    if len(identity) > 1:\n+      trace += 'threads: %s\\n' % identity\n+    trace += stack\n+    all_traces.append(trace)\n+  all_traces.append('=' * 30)\n+  return '\\n'.join(x.encode('utf-8') for x in all_traces)\n+\n+\n+def active_processing_bundles_state(bundle_process_cache):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTE5NzY3OA=="}, "originalCommit": {"oid": "20b8aac09c9d72c07b5c155b2afb9fc1dca351fa"}, "originalPosition": 61}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI4MjE3ODEyOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/worker/worker_status.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMVQyMTo0MTowNVrOFgJtLw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yMVQyMTo1NzoxOVrOFgKJQA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTI1Nzc3NQ==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                trace = '--- Thread #%s name: %s %s---\\n' % (\n          \n          \n            \n                trace = '--- Threads (%d) %s --- \\n' % (len(identity), [ident+':'+name for (ident, name) in identity])", "url": "https://github.com/apache/beam/pull/10598#discussion_r369257775", "createdAt": "2020-01-21T21:41:05Z", "author": {"login": "angoenka"}, "path": "sdks/python/apache_beam/runners/worker/worker_status.py", "diffHunk": "@@ -0,0 +1,148 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\"\"\"Worker status api handler for reporting SDK harness debug info.\"\"\"\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+\n+import queue\n+import sys\n+import threading\n+import traceback\n+from collections import defaultdict\n+\n+import grpc\n+\n+from apache_beam.portability.api import beam_fn_api_pb2\n+from apache_beam.portability.api import beam_fn_api_pb2_grpc\n+from apache_beam.runners.worker.channel_factory import GRPCChannelFactory\n+from apache_beam.runners.worker.worker_id_interceptor import WorkerIdInterceptor\n+\n+\n+def thread_dump():\n+  \"\"\"Get a thread dump for the current SDK worker harness. \"\"\"\n+  # deduplicate threads with same stack trace\n+  stack_traces = defaultdict(list)\n+  frames = sys._current_frames()  # pylint: disable=protected-access\n+\n+  for t in threading.enumerate():\n+    stack_trace = ''.join(traceback.format_stack(frames[t.ident]))\n+    thread_ident_name = (t.ident, t.name)\n+    stack_traces[stack_trace].append(thread_ident_name)\n+\n+  all_traces = ['=' * 10 + 'THREAD DUMP' + '=' * 10]\n+  for stack, identity in stack_traces.items():\n+    ident, name = identity[0]\n+    trace = '--- Thread #%s name: %s %s---\\n' % (", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "20b8aac09c9d72c07b5c155b2afb9fc1dca351fa"}, "originalPosition": 50}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTI2NDk2MA==", "bodyText": "this is already printed in a separated line below.", "url": "https://github.com/apache/beam/pull/10598#discussion_r369264960", "createdAt": "2020-01-21T21:57:19Z", "author": {"login": "y1chi"}, "path": "sdks/python/apache_beam/runners/worker/worker_status.py", "diffHunk": "@@ -0,0 +1,148 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\"\"\"Worker status api handler for reporting SDK harness debug info.\"\"\"\n+\n+from __future__ import absolute_import\n+from __future__ import division\n+\n+import queue\n+import sys\n+import threading\n+import traceback\n+from collections import defaultdict\n+\n+import grpc\n+\n+from apache_beam.portability.api import beam_fn_api_pb2\n+from apache_beam.portability.api import beam_fn_api_pb2_grpc\n+from apache_beam.runners.worker.channel_factory import GRPCChannelFactory\n+from apache_beam.runners.worker.worker_id_interceptor import WorkerIdInterceptor\n+\n+\n+def thread_dump():\n+  \"\"\"Get a thread dump for the current SDK worker harness. \"\"\"\n+  # deduplicate threads with same stack trace\n+  stack_traces = defaultdict(list)\n+  frames = sys._current_frames()  # pylint: disable=protected-access\n+\n+  for t in threading.enumerate():\n+    stack_trace = ''.join(traceback.format_stack(frames[t.ident]))\n+    thread_ident_name = (t.ident, t.name)\n+    stack_traces[stack_trace].append(thread_ident_name)\n+\n+  all_traces = ['=' * 10 + 'THREAD DUMP' + '=' * 10]\n+  for stack, identity in stack_traces.items():\n+    ident, name = identity[0]\n+    trace = '--- Thread #%s name: %s %s---\\n' % (", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2OTI1Nzc3NQ=="}, "originalCommit": {"oid": "20b8aac09c9d72c07b5c155b2afb9fc1dca351fa"}, "originalPosition": 50}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2377, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}