{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDA2MzIyMDgx", "number": 11469, "title": "Added a batch example with covid tracking data for interactive notebook.", "bodyText": "Please add a meaningful description for your change here\n\nThank you for your contribution! Follow this checklist to help us incorporate your contribution quickly and easily:\n\n Choose reviewer(s) and mention them in a comment (R: @username).\n Format the pull request title like [BEAM-XXX] Fixes bug in ApproximateQuantiles, where you replace BEAM-XXX with the appropriate JIRA issue, if applicable. This will automatically link the pull request to the issue.\n Update CHANGES.md with noteworthy changes.\n If this contribution is large, please file an Apache Individual Contributor License Agreement.\n\nSee the Contributor Guide for more tips on how to make review process smoother.\nPost-Commit Tests Status (on master branch)\n\n\n\nLang\nSDK\nApex\nDataflow\nFlink\nGearpump\nSamza\nSpark\n\n\n\n\nGo\n\n---\n---\n\n---\n---\n\n\n\nJava\n\n\n\n\n\n\n\n\n\nPython\n\n---\n\n\n---\n---\n\n\n\nXLang\n---\n---\n---\n\n---\n---\n\n\n\n\nPre-Commit Tests Status (on master branch)\n\n\n\n---\nJava\nPython\nGo\nWebsite\n\n\n\n\nNon-portable\n\n\n\n\n\n\nPortable\n---\n\n---\n---\n\n\n\nSee .test-infra/jenkins/README for trigger phrase, status and link of all Jenkins jobs.", "createdAt": "2020-04-20T21:52:30Z", "url": "https://github.com/apache/beam/pull/11469", "merged": true, "mergeCommit": {"oid": "24361d1b5981ef7d18e586a8e5deaf683f4329f1"}, "closed": true, "closedAt": "2020-04-24T17:58:08Z", "author": {"login": "KevinGG"}, "timelineItems": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcZmTWZgH2gAyNDA2MzIyMDgxOjZmODhmN2VmMmNlNDdlYzljYzU3Y2VlNDM2NjZjYjNjZTIxMGFjYzk=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcaMfF0AH2gAyNDA2MzIyMDgxOmU5ZWE0ZmM4YzQzZGI5NTcwNTFhMzA1ZTY4ZTcwMjM5Nzc2MWNlY2E=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "6f88f7ef2ce47ec9cc57cee43666cb3ce210acc9", "author": {"user": {"login": "KevinGG", "name": "Ning Kang"}}, "url": "https://github.com/apache/beam/commit/6f88f7ef2ce47ec9cc57cee43666cb3ce210acc9", "committedDate": "2020-04-20T21:51:43Z", "message": "Added a batch example with covid tracking data for interactive notebook."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk2ODc3MTUy", "url": "https://github.com/apache/beam/pull/11469#pullrequestreview-396877152", "createdAt": "2020-04-20T23:18:39Z", "commit": {"oid": "6f88f7ef2ce47ec9cc57cee43666cb3ce210acc9"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQyMzoxODozOVrOGIriOA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQyMzoxOToxMlrOGIri-g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTc1NTA2NA==", "bodyText": "Can we get this information from the data directly?", "url": "https://github.com/apache/beam/pull/11469#discussion_r411755064", "createdAt": "2020-04-20T23:18:39Z", "author": {"login": "aaltay"}, "path": "sdks/python/apache_beam/runners/interactive/examples/UsCovidDataExample.ipynb", "diffHunk": "@@ -0,0 +1,478 @@\n+{\n+ \"cells\": [\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"# Get data from covidtracking.com\\n\",\n+    \"The data set is relatively small and used as a demonstration of working with Beam in an interactive notebook environment.\\n\",\n+    \"\\n\",\n+    \"There are two ways to get the data:\\n\",\n+    \"\\n\",\n+    \"- Get json data from APIs.\\n\",\n+    \"- Download data in csv files directly.\\n\",\n+    \"\\n\",\n+    \"We'll have a batch Beam pipeline example utilizing either method.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"import json\\n\",\n+    \"import requests\\n\",\n+    \"\\n\",\n+    \"json_current='https://covidtracking.com/api/v1/states/current.json'\\n\",\n+    \"json_historical='https://covidtracking.com/api/v1/states/daily.json'\\n\",\n+    \"\\n\",\n+    \"def get_json_data(url):\\n\",\n+    \"  with requests.Session() as session:\\n\",\n+    \"    data = json.loads(session.get(url).text)\\n\",\n+    \"  return data\\n\",\n+    \"\\n\",\n+    \"csv_current = 'https://covidtracking.com/api/v1/states/current.csv'\\n\",\n+    \"csv_historical = 'https://covidtracking.com/api/v1/states/daily.csv'\\n\",\n+    \"\\n\",\n+    \"def download_csv(url, filename):\\n\",\n+    \"  if not filename.endswith('.csv'):\\n\",\n+    \"    filename = filename + '.csv'\\n\",\n+    \"  with requests.Session() as session:\\n\",\n+    \"    with open(filename, 'wb') as f:\\n\",\n+    \"      f.write(session.get(url).content)\\n\",\n+    \"  return filename\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"Below reads data into memory as json.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"current_data = get_json_data(json_current)\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"Below downloads data in csv format stored in files.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"csv_file_current = download_csv(csv_current, 'current')\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"Prepare some Apache Beam dependencies.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"import apache_beam as beam\\n\",\n+    \"from apache_beam.runners.interactive import interactive_beam as ib\\n\",\n+    \"from apache_beam.runners.interactive.interactive_runner import InteractiveRunner\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"Create a Beam pipeline.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"p = beam.Pipeline(runner=InteractiveRunner())\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"You can create a PCollection from either in-memory json data or data in files.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"current_data_from_json = p | 'Create PCollection from json' >> beam.Create(current_data)\\n\",\n+    \"current_data_from_files = p | 'Create PCollection from files' >> beam.io.ReadFromText(csv_file_current, skip_header_lines=1)\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"The in-memory json data is already structured.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"ib.show(current_data_from_json)\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"The data from files read as plain text is not structured, we'll have to handle it.\\n\",\n+    \"\\n\",\n+    \"For a batch pipeline reading files with huge content size, it's normal to read source data from files and let Beam handle the work load.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"ib.show(current_data_from_files)\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"We'll parse the plain texts into structured data with Beam SDK.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"current_data_headers = 'state,positive,positiveScore,negativeScore,negativeRegularScore,commercialScore,grade,score,negative,pending,hospitalizedCurrently,hospitalizedCumulative,inIcuCurrently,inIcuCumulative,onVentilatorCurrently,onVentilatorCumulative,recovered,lastUpdateEt,checkTimeEt,death,hospitalized,total,totalTestResults,posNeg,fips,dateModified,dateChecked,notes,hash_val'.split(',')\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6f88f7ef2ce47ec9cc57cee43666cb3ce210acc9"}, "originalPosition": 177}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTc1NTI1OA==", "bodyText": "How about pass state name as an argument and make this FilterbyState?", "url": "https://github.com/apache/beam/pull/11469#discussion_r411755258", "createdAt": "2020-04-20T23:19:12Z", "author": {"login": "aaltay"}, "path": "sdks/python/apache_beam/runners/interactive/examples/UsCovidDataExample.ipynb", "diffHunk": "@@ -0,0 +1,478 @@\n+{\n+ \"cells\": [\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"# Get data from covidtracking.com\\n\",\n+    \"The data set is relatively small and used as a demonstration of working with Beam in an interactive notebook environment.\\n\",\n+    \"\\n\",\n+    \"There are two ways to get the data:\\n\",\n+    \"\\n\",\n+    \"- Get json data from APIs.\\n\",\n+    \"- Download data in csv files directly.\\n\",\n+    \"\\n\",\n+    \"We'll have a batch Beam pipeline example utilizing either method.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"import json\\n\",\n+    \"import requests\\n\",\n+    \"\\n\",\n+    \"json_current='https://covidtracking.com/api/v1/states/current.json'\\n\",\n+    \"json_historical='https://covidtracking.com/api/v1/states/daily.json'\\n\",\n+    \"\\n\",\n+    \"def get_json_data(url):\\n\",\n+    \"  with requests.Session() as session:\\n\",\n+    \"    data = json.loads(session.get(url).text)\\n\",\n+    \"  return data\\n\",\n+    \"\\n\",\n+    \"csv_current = 'https://covidtracking.com/api/v1/states/current.csv'\\n\",\n+    \"csv_historical = 'https://covidtracking.com/api/v1/states/daily.csv'\\n\",\n+    \"\\n\",\n+    \"def download_csv(url, filename):\\n\",\n+    \"  if not filename.endswith('.csv'):\\n\",\n+    \"    filename = filename + '.csv'\\n\",\n+    \"  with requests.Session() as session:\\n\",\n+    \"    with open(filename, 'wb') as f:\\n\",\n+    \"      f.write(session.get(url).content)\\n\",\n+    \"  return filename\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"Below reads data into memory as json.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"current_data = get_json_data(json_current)\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"Below downloads data in csv format stored in files.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"csv_file_current = download_csv(csv_current, 'current')\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"Prepare some Apache Beam dependencies.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"import apache_beam as beam\\n\",\n+    \"from apache_beam.runners.interactive import interactive_beam as ib\\n\",\n+    \"from apache_beam.runners.interactive.interactive_runner import InteractiveRunner\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"Create a Beam pipeline.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"p = beam.Pipeline(runner=InteractiveRunner())\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"You can create a PCollection from either in-memory json data or data in files.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"current_data_from_json = p | 'Create PCollection from json' >> beam.Create(current_data)\\n\",\n+    \"current_data_from_files = p | 'Create PCollection from files' >> beam.io.ReadFromText(csv_file_current, skip_header_lines=1)\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"The in-memory json data is already structured.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"ib.show(current_data_from_json)\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"The data from files read as plain text is not structured, we'll have to handle it.\\n\",\n+    \"\\n\",\n+    \"For a batch pipeline reading files with huge content size, it's normal to read source data from files and let Beam handle the work load.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"ib.show(current_data_from_files)\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"We'll parse the plain texts into structured data with Beam SDK.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"current_data_headers = 'state,positive,positiveScore,negativeScore,negativeRegularScore,commercialScore,grade,score,negative,pending,hospitalizedCurrently,hospitalizedCumulative,inIcuCurrently,inIcuCumulative,onVentilatorCurrently,onVentilatorCumulative,recovered,lastUpdateEt,checkTimeEt,death,hospitalized,total,totalTestResults,posNeg,fips,dateModified,dateChecked,notes,hash_val'.split(',')\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"from collections import namedtuple\\n\",\n+    \"\\n\",\n+    \"UsCovidData = namedtuple('UsCovidData', current_data_headers)\\n\",\n+    \"\\n\",\n+    \"class UsCovidDataCsvReader(beam.DoFn):\\n\",\n+    \"  def __init__(self, schema):\\n\",\n+    \"    self._schema = schema\\n\",\n+    \"    \\n\",\n+    \"  def process(self, element):\\n\",\n+    \"    values = [int(val) if val.isdigit() else val for val in element.split(',')]\\n\",\n+    \"    return [self._schema(*values)]\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"current_data = current_data_from_files | 'Parse' >> beam.ParDo(UsCovidDataCsvReader(UsCovidData))\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"ib.show(current_data)\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"With Interactive Beam, you can collect a PCollection into a pandas dataframe. It's useful when you just want to play with small test data sets locally on a single machine.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"df = ib.collect(current_data)\\n\",\n+    \"df.describe()\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"Now let's take a deeper look into the data with the visualization feature of Interactive Beam and come up with some tasks.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"ib.show(current_data, visualize_data=True)\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"We can find out that NY currently has the most positive COVID cases with above facets visualization because the data set is small (for demo).\\n\",\n+    \"\\n\",\n+    \"Now we can write a beam transform to try to get that same conclusion of which state has the highest positive number currently.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"from functools import total_ordering\\n\",\n+    \"\\n\",\n+    \"@total_ordering\\n\",\n+    \"class UsCovidDataOrderByPositive:\\n\",\n+    \"  def __init__(self, data):\\n\",\n+    \"    self._data = data\\n\",\n+    \"  \\n\",\n+    \"  def __gt__(self, other):\\n\",\n+    \"    return self._data.positive > other._data.positive\\n\",\n+    \"\\n\",\n+    \"\\n\",\n+    \"def maximum(values):\\n\",\n+    \"  return max(values) if values else None\\n\",\n+    \"\\n\",\n+    \"max_positive = (current_data \\n\",\n+    \"                | 'Data OrderByPositive' >> beam.Map(lambda data: UsCovidDataOrderByPositive(data))\\n\",\n+    \"                | 'Find Maximum Positive' >> beam.CombineGlobally(maximum)\\n\",\n+    \"                | 'Convert Back to Data' >> beam.Map(lambda orderable_data: orderable_data._data))\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"ib.show(max_positive)\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"We can also try to come up with the total positive case number in the US.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"total_positive = (current_data\\n\",\n+    \"                  | 'Positive Per State' >> beam.Map(lambda data: data.positive)\\n\",\n+    \"                  | 'Total Positive' >> beam.CombineGlobally(sum))\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"ib.show(total_positive)\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"Now let's look at some more complicated data: the historical data.\\n\",\n+    \"\\n\",\n+    \"It contains similar data to current for each day until current day.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"csv_file_historical = download_csv(csv_historical, 'historical')\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"historical_data_from_files = p | 'Create PCollection for historical data from files' >> beam.io.ReadFromText(csv_file_historical, skip_header_lines=1)\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"ib.show(historical_data_from_files)\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"historical_data_headers = 'date,state,positive,negative,pending,hospitalizedCurrently,hospitalizedCumulative,inIcuCurrently,inIcuCumulative,onVentilatorCurrently,onVentilatorCumulative,recovered,hash,dateChecked,death,hospitalized,total,totalTestResults,posNeg,fips,deathIncrease,hospitalizedIncrease,negativeIncrease,positiveIncrease,totalTestResultsIncrease'.split(',')\\n\",\n+    \"\\n\",\n+    \"HistoricalUsCovidData = namedtuple('HistoricalUsCovidData', historical_data_headers)\\n\",\n+    \"\\n\",\n+    \"historical_data = historical_data_from_files | 'Parse' >> beam.ParDo(UsCovidDataCsvReader(HistoricalUsCovidData))\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"ib.show(historical_data)\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"markdown\",\n+   \"metadata\": {},\n+   \"source\": [\n+    \"For demostration, let's just take a look at NY throughout the timeline.\"\n+   ]\n+  },\n+  {\n+   \"cell_type\": \"code\",\n+   \"execution_count\": null,\n+   \"metadata\": {},\n+   \"outputs\": [],\n+   \"source\": [\n+    \"class FilterNy(beam.DoFn):\\n\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6f88f7ef2ce47ec9cc57cee43666cb3ce210acc9"}, "originalPosition": 392}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e0cd94a9d76e254f2a21fff49bdcb0f8d8a5f4ee", "author": {"user": {"login": "KevinGG", "name": "Ning Kang"}}, "url": "https://github.com/apache/beam/commit/e0cd94a9d76e254f2a21fff49bdcb0f8d8a5f4ee", "committedDate": "2020-04-21T20:05:27Z", "message": "Added read_headers utility and changed the filter to allow pass in a state."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk3NzkzNzk5", "url": "https://github.com/apache/beam/pull/11469#pullrequestreview-397793799", "createdAt": "2020-04-22T02:08:45Z", "commit": {"oid": "e0cd94a9d76e254f2a21fff49bdcb0f8d8a5f4ee"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e9ea4fc8c43db957051a305e68e702397761ceca", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/e9ea4fc8c43db957051a305e68e702397761ceca", "committedDate": "2020-04-22T18:20:56Z", "message": "Added apache 2.0 license to the example notebook.\n\nChange-Id: Ib15b9b05a915ce589b26603ddfe6a49af70c2383"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4337, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}