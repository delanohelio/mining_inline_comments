{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzk2MjY3OTcw", "number": 11274, "title": "[BEAM-9633] Add PubsubIO performance test", "bodyText": "Add PubsubIO performance test\n\nThank you for your contribution! Follow this checklist to help us incorporate your contribution quickly and easily:\n\n Choose reviewer(s) and mention them in a comment (R: @username).\n Format the pull request title like [BEAM-XXX] Fixes bug in ApproximateQuantiles, where you replace BEAM-XXX with the appropriate JIRA issue, if applicable. This will automatically link the pull request to the issue.\n Update CHANGES.md with noteworthy changes.\n If this contribution is large, please file an Apache Individual Contributor License Agreement.\n\nSee the Contributor Guide for more tips on how to make review process smoother.\nPost-Commit Tests Status (on master branch)\n\n\n\nLang\nSDK\nApex\nDataflow\nFlink\nGearpump\nSamza\nSpark\n\n\n\n\nGo\n\n---\n---\n\n---\n---\n\n\n\nJava\n\n\n\n\n\n\n\n\n\nPython\n\n---\n\n\n---\n---\n\n\n\nXLang\n---\n---\n---\n\n---\n---\n\n\n\n\nPre-Commit Tests Status (on master branch)\n\n\n\n---\nJava\nPython\nGo\nWebsite\n\n\n\n\nNon-portable\n\n\n\n\n\n\nPortable\n---\n\n---\n---\n\n\n\nSee .test-infra/jenkins/README for trigger phrase, status and link of all Jenkins jobs.", "createdAt": "2020-03-31T11:28:35Z", "url": "https://github.com/apache/beam/pull/11274", "merged": true, "mergeCommit": {"oid": "836d0ad5b190502ac2086b9c44f4a7e8f4f9625d"}, "closed": true, "closedAt": "2020-05-20T10:31:10Z", "author": {"login": "piotr-szuberski"}, "timelineItems": {"totalCount": 48, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcTDpfwgBqjMxODM0Nzc3NTc=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcizOxYABqjMzNTE0OTIwOTY=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "5045a6534a25abf67fec2d5a6b2cb2cbde51fa4f", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/5045a6534a25abf67fec2d5a6b2cb2cbde51fa4f", "committedDate": "2020-03-31T11:27:31Z", "message": "[BEAM-9633] [WIP] Add PubsubIO performance test"}, "afterCommit": {"oid": "78a7543b6e829c1322e718175e1780620e42dbe3", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/78a7543b6e829c1322e718175e1780620e42dbe3", "committedDate": "2020-03-31T14:05:22Z", "message": "[BEAM-9633] [WIP] Add PubsubIO performance test"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "78a7543b6e829c1322e718175e1780620e42dbe3", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/78a7543b6e829c1322e718175e1780620e42dbe3", "committedDate": "2020-03-31T14:05:22Z", "message": "[BEAM-9633] [WIP] Add PubsubIO performance test"}, "afterCommit": {"oid": "01b222d5e85d18c35fc6e2cbf3cac1ad0bcf634d", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/01b222d5e85d18c35fc6e2cbf3cac1ad0bcf634d", "committedDate": "2020-04-01T10:36:11Z", "message": "[BEAM-9633] [WIP] Add PubsubIO performance test"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "951c169753d1c5c55c17be7ee47c17b93c1f054b", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/951c169753d1c5c55c17be7ee47c17b93c1f054b", "committedDate": "2020-04-06T10:04:48Z", "message": "[BEAM-9633] [WIP] Add PubsubIO performance test"}, "afterCommit": {"oid": "318f95531eb4b74c0af583056bf93730ea7ac28c", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/318f95531eb4b74c0af583056bf93730ea7ac28c", "committedDate": "2020-04-06T10:09:25Z", "message": "[BEAM-9633] [WIP] Add PubsubIO performance test"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "318f95531eb4b74c0af583056bf93730ea7ac28c", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/318f95531eb4b74c0af583056bf93730ea7ac28c", "committedDate": "2020-04-06T10:09:25Z", "message": "[BEAM-9633] [WIP] Add PubsubIO performance test"}, "afterCommit": {"oid": "e9ed63c1e793ad2aa38aba296bd4d08edd076342", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/e9ed63c1e793ad2aa38aba296bd4d08edd076342", "committedDate": "2020-04-08T07:53:57Z", "message": "[BEAM-9633] [WIP] Add PubsubIO performance test"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e9ed63c1e793ad2aa38aba296bd4d08edd076342", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/e9ed63c1e793ad2aa38aba296bd4d08edd076342", "committedDate": "2020-04-08T07:53:57Z", "message": "[BEAM-9633] [WIP] Add PubsubIO performance test"}, "afterCommit": {"oid": "57de90dda2d75808cfb7dae55ba268d0059e1fca", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/57de90dda2d75808cfb7dae55ba268d0059e1fca", "committedDate": "2020-04-09T07:53:12Z", "message": "[BEAM-9633] [WIP] Add PubsubIO performance test"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "57de90dda2d75808cfb7dae55ba268d0059e1fca", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/57de90dda2d75808cfb7dae55ba268d0059e1fca", "committedDate": "2020-04-09T07:53:12Z", "message": "[BEAM-9633] [WIP] Add PubsubIO performance test"}, "afterCommit": {"oid": "de5c10d7375d5dbbc1ca6aa8564a12c637407853", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/de5c10d7375d5dbbc1ca6aa8564a12c637407853", "committedDate": "2020-04-10T13:43:52Z", "message": "[BEAM-9633] [WIP] Add PubsubIO performance test"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "de5c10d7375d5dbbc1ca6aa8564a12c637407853", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/de5c10d7375d5dbbc1ca6aa8564a12c637407853", "committedDate": "2020-04-10T13:43:52Z", "message": "[BEAM-9633] [WIP] Add PubsubIO performance test"}, "afterCommit": {"oid": "c6496475ac97b1e912d26c8b35fd1c94b53be075", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/c6496475ac97b1e912d26c8b35fd1c94b53be075", "committedDate": "2020-04-15T14:21:48Z", "message": "[BEAM-9633] [WIP] Add PubsubIO performance test"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c6496475ac97b1e912d26c8b35fd1c94b53be075", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/c6496475ac97b1e912d26c8b35fd1c94b53be075", "committedDate": "2020-04-15T14:21:48Z", "message": "[BEAM-9633] [WIP] Add PubsubIO performance test"}, "afterCommit": {"oid": "a1d10cdb1ac16fc4e4458dfdfaef5b54df62a49c", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/a1d10cdb1ac16fc4e4458dfdfaef5b54df62a49c", "committedDate": "2020-04-20T08:30:09Z", "message": "[BEAM-9633] [WIP] Add PubsubIO performance test"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a1d10cdb1ac16fc4e4458dfdfaef5b54df62a49c", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/a1d10cdb1ac16fc4e4458dfdfaef5b54df62a49c", "committedDate": "2020-04-20T08:30:09Z", "message": "[BEAM-9633] [WIP] Add PubsubIO performance test"}, "afterCommit": {"oid": "0982bedb6446a0f5bbe5aeb1385e41579f5df386", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/0982bedb6446a0f5bbe5aeb1385e41579f5df386", "committedDate": "2020-04-20T09:42:23Z", "message": "[BEAM-9633] [WIP] Add PubsubIO performance test"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0982bedb6446a0f5bbe5aeb1385e41579f5df386", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/0982bedb6446a0f5bbe5aeb1385e41579f5df386", "committedDate": "2020-04-20T09:42:23Z", "message": "[BEAM-9633] [WIP] Add PubsubIO performance test"}, "afterCommit": {"oid": "ce2685c80814f4efce2c759c317e103a14a7cd09", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/ce2685c80814f4efce2c759c317e103a14a7cd09", "committedDate": "2020-04-20T13:18:50Z", "message": "[BEAM-9633] [WIP] Add PubsubIO performance test"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "ce2685c80814f4efce2c759c317e103a14a7cd09", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/ce2685c80814f4efce2c759c317e103a14a7cd09", "committedDate": "2020-04-20T13:18:50Z", "message": "[BEAM-9633] [WIP] Add PubsubIO performance test"}, "afterCommit": {"oid": "8eae700ebc62a0a75d4c4dfa7d1552a39aa0e715", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/8eae700ebc62a0a75d4c4dfa7d1552a39aa0e715", "committedDate": "2020-04-20T13:24:10Z", "message": "[BEAM-9633] [WIP] Add PubsubIO performance test"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8eae700ebc62a0a75d4c4dfa7d1552a39aa0e715", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/8eae700ebc62a0a75d4c4dfa7d1552a39aa0e715", "committedDate": "2020-04-20T13:24:10Z", "message": "[BEAM-9633] [WIP] Add PubsubIO performance test"}, "afterCommit": {"oid": "b8dad6914c13c1b88693ebf09835b3dd223993eb", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/b8dad6914c13c1b88693ebf09835b3dd223993eb", "committedDate": "2020-04-20T13:26:27Z", "message": "[BEAM-9633] Add PubsubIO performance test"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b8dad6914c13c1b88693ebf09835b3dd223993eb", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/b8dad6914c13c1b88693ebf09835b3dd223993eb", "committedDate": "2020-04-20T13:26:27Z", "message": "[BEAM-9633] Add PubsubIO performance test"}, "afterCommit": {"oid": "5726e7a47102c8f19096dd3c9cb561a41fca3533", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/5726e7a47102c8f19096dd3c9cb561a41fca3533", "committedDate": "2020-04-20T13:30:06Z", "message": "[BEAM-9633] Add PubsubIO performance test"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "267f1f2f834057d977e133edf645506c0d241258", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/267f1f2f834057d977e133edf645506c0d241258", "committedDate": "2020-04-20T13:50:36Z", "message": "[BEAM-9633] Add PubsubIO performance test"}, "afterCommit": {"oid": "bcff91d95a4fdcdee3358ef0c51d5fe1b2f629b8", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/bcff91d95a4fdcdee3358ef0c51d5fe1b2f629b8", "committedDate": "2020-04-20T13:51:34Z", "message": "[BEAM-9633] Add PubsubIO performance test"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "92afcf13bc3845c308e52d22c85da0bb37994698", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/92afcf13bc3845c308e52d22c85da0bb37994698", "committedDate": "2020-04-20T15:13:32Z", "message": "[BEAM-9633] Refactor calling bytes(str().encode) to bytes(str, encode)"}, "afterCommit": {"oid": "a5de925d01b2ee328ff80a96e377103a9a93ed59", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/a5de925d01b2ee328ff80a96e377103a9a93ed59", "committedDate": "2020-04-20T16:16:51Z", "message": "[BEAM-9633] Add PubsubIO performance test"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a5de925d01b2ee328ff80a96e377103a9a93ed59", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/a5de925d01b2ee328ff80a96e377103a9a93ed59", "committedDate": "2020-04-20T16:16:51Z", "message": "[BEAM-9633] Add PubsubIO performance test"}, "afterCommit": {"oid": "db2ed59ed67eccc35569a2cd3e4e73ae411bb1c5", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/db2ed59ed67eccc35569a2cd3e4e73ae411bb1c5", "committedDate": "2020-04-20T16:23:45Z", "message": "[BEAM-9633] Add PubsubIO performance test"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk3MTA5MjM5", "url": "https://github.com/apache/beam/pull/11274#pullrequestreview-397109239", "createdAt": "2020-04-21T08:35:55Z", "commit": {"oid": "db2ed59ed67eccc35569a2cd3e4e73ae411bb1c5"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQwODozNTo1NlrOGI5rQg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQwOTo0NzowMFrOGI81zQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTk4Njc1NA==", "bodyText": "I believe BigQueryIO should be replaced by PubsubIO", "url": "https://github.com/apache/beam/pull/11274#discussion_r411986754", "createdAt": "2020-04-21T08:35:56Z", "author": {"login": "kamilwu"}, "path": ".test-infra/jenkins/job_PerformanceTests_PubsubIO_Python.groovy", "diffHunk": "@@ -0,0 +1,92 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+def now = new Date().format(\"MMddHHmmss\", TimeZone.getTimeZone('UTC'))\n+\n+def psio_read_test = [\n+        title          : 'PubsubIO Read Performance Test Python 100000 messages',\n+        test           : 'apache_beam.io.gcp.pubsub_read_perf_test',\n+        runner         : CommonTestProperties.Runner.DATAFLOW,\n+        pipelineOptions: [\n+                job_name             : 'performance-tests-psio-read-python-100000-msgs' + now,\n+                project              : 'apache-beam-testing',\n+                temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n+                publish_to_big_query : true,\n+                metrics_dataset      : 'beam_performance',\n+                metrics_table        : 'psio_read_100000msg_results',\n+                // Pubsub PublishRequest can have max 10'000'000 bytes\n+                input_options        : '\\'{\"num_records\": 100000}\\'',\n+                num_workers          : 5,\n+                autoscaling_algorithm: 'NONE',  // Disable autoscale the worker pool.\n+                timeout              : 3600,\n+        ]\n+]\n+\n+def psio_write_test = [\n+        title          : 'PubsubIO Write Performance Test Python 100000 messages',\n+        test           : 'apache_beam.io.gcp.pubsub_write_perf_test',\n+        runner         : CommonTestProperties.Runner.DATAFLOW,\n+        pipelineOptions: [\n+                job_name             : 'performance-tests-psio-write-python-100000-msgs' + now,\n+                project              : 'apache-beam-testing',\n+                temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n+                publish_to_big_query : true,\n+                metrics_dataset      : 'beam_performance',\n+                metrics_table        : 'psio_write_100000msg_results',\n+                // Pubsub PublishRequest can have max 10'000'000 bytes\n+                input_options        : '\\'{' +\n+                        '\"num_records\": 100000,' +\n+                        '\"key_size\": 1,' +\n+                        '\"value_size\": 16}\\'',\n+                num_workers          : 5,\n+                autoscaling_algorithm: 'NONE',  // Disable autoscale the worker pool.\n+                timeout              : 3600,\n+        ]\n+]\n+\n+def executeJob = { scope, testConfig ->\n+    commonJobProperties.setTopLevelMainJobProperties(scope, 'master', 240)\n+\n+    loadTestsBuilder.loadTest(scope, testConfig.title, testConfig.runner, CommonTestProperties.SDK.PYTHON, testConfig.pipelineOptions, testConfig.test)\n+}\n+\n+PhraseTriggeringPostCommitBuilder.postCommitJob(\n+        'beam_PubsubIO_Read_Performance_Test_Python',\n+        'Run PubsubIO Read Performance Test Python',\n+        'PubsubIO Read Performance Test Python',\n+        this\n+) {\n+    executeJob(delegate, psio_read_test)\n+}\n+\n+CronJobBuilder.cronJob('beam_PubsubIO_Read_Performance_Test_Python', 'H 15 * * *', this) {\n+    executeJob(delegate, psio_read_test)\n+}\n+\n+PhraseTriggeringPostCommitBuilder.postCommitJob(\n+        'beam_PubsubIO_Write_Performance_Test_Python',\n+        'Run PubsubIO Write Performance Test Python',\n+        'BigQueryIO Write Performance Test Python',", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db2ed59ed67eccc35569a2cd3e4e73ae411bb1c5"}, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTk5MDAyNw==", "bodyText": "You cannot import multiple objects from a module in a single line. Out pylint will complain. Split this into multiple lines or use something like this in your code: beam.io.ReadFromPubSub", "url": "https://github.com/apache/beam/pull/11274#discussion_r411990027", "createdAt": "2020-04-21T08:40:15Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_read_perf_test.py", "diffHunk": "@@ -0,0 +1,153 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Read operation.\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_read_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner\n+    --sdk_location=.../dist/apache-beam-x.x.x.dev0.tar.gz\n+    --project=<GCP_PROJECT_ID>\n+    --temp_location=gs://<BUCKET_NAME>/tmp\n+    --staging_location=gs://<BUCKET_NAME>/staging\n+    --timeout=<TIME_IN_SECONDS>\n+    --publish_to_big_query=<OPTIONAL><true/false>\n+    --metrics_dataset=<OPTIONAL>\n+    --metrics_table=<OPTIONAL>\n+    --dataflow_worker_jar=<OPTIONAL>\n+    --input_options='{\n+    \\\"num_records\\\": <SIZE_OF_INPUT>\n+    }'\"\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import argparse\n+import logging\n+import sys\n+import uuid\n+\n+from hamcrest import all_of\n+\n+import apache_beam as beam\n+from apache_beam.io import ReadFromPubSub, WriteToPubSub, PubsubMessage", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db2ed59ed67eccc35569a2cd3e4e73ae411bb1c5"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTk5NDExNg==", "bodyText": "Unless you need to, let's move this line to the beginning of the file.", "url": "https://github.com/apache/beam/pull/11274#discussion_r411994116", "createdAt": "2020-04-21T08:45:35Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_read_perf_test.py", "diffHunk": "@@ -0,0 +1,153 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Read operation.\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_read_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner\n+    --sdk_location=.../dist/apache-beam-x.x.x.dev0.tar.gz\n+    --project=<GCP_PROJECT_ID>\n+    --temp_location=gs://<BUCKET_NAME>/tmp\n+    --staging_location=gs://<BUCKET_NAME>/staging\n+    --timeout=<TIME_IN_SECONDS>\n+    --publish_to_big_query=<OPTIONAL><true/false>\n+    --metrics_dataset=<OPTIONAL>\n+    --metrics_table=<OPTIONAL>\n+    --dataflow_worker_jar=<OPTIONAL>\n+    --input_options='{\n+    \\\"num_records\\\": <SIZE_OF_INPUT>\n+    }'\"\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import argparse\n+import logging\n+import sys\n+import uuid\n+\n+from hamcrest import all_of\n+\n+import apache_beam as beam\n+from apache_beam.io import ReadFromPubSub, WriteToPubSub, PubsubMessage\n+from apache_beam.io.gcp.tests.pubsub_matcher import PubSubMessageMatcher\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.testing import test_utils\n+from apache_beam.testing.load_tests.load_test import LoadTest\n+from apache_beam.testing.load_tests.load_test_metrics_utils import MeasureTime\n+from apache_beam.testing.test_pipeline import TestPipeline\n+\n+PUBSUB_NAME = 'pubsub_read_performance'\n+\n+\n+class PubsubReadPerfTest(LoadTest):\n+\n+  def __init__(self):\n+    super(PubsubReadPerfTest, self).__init__()\n+    self._setup_env()\n+    self._setup_pubsub()\n+    self._setup_pipeline()\n+\n+  def test(self):\n+    (\n+        self.pipeline\n+        | 'Read from pubsub' >> ReadFromPubSub(\n+            subscription=self.subscription.name,\n+            with_attributes=True,\n+            id_label='ack_id')\n+        | 'Measure time' >> beam.ParDo(MeasureTime(self.metrics_namespace))\n+    )\n+\n+  def cleanup(self):\n+    test_utils.cleanup_subscriptions(\n+      self.sub_client, [self.subscription, self.matcher_subscription])\n+    test_utils.cleanup_topics(\n+      self.pub_client, [self.topic])\n+\n+  def _setup_env(self):\n+    if not self.pipeline.get_option('timeout'):\n+      logging.error('--timeout argument is required.')\n+      sys.exit(1)\n+\n+    self.num_of_messages = int(self.input_options.get('num_records'))\n+    self.timeout = int(self.pipeline.get_option('timeout'))\n+\n+  def _setup_pubsub(self):\n+    def init_input(number_of_messages):\n+      for n in range(number_of_messages):\n+        message = PubsubMessage(\n+          bytes(str(n), 'utf-8'),\n+          {'ack_id': bytes(str(n), 'utf-8')})\n+        bytes_message = WriteToPubSub.to_proto_str(message)\n+        self.pub_client.publish(self.topic.name, bytes_message)\n+\n+    from google.cloud import pubsub", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db2ed59ed67eccc35569a2cd3e4e73ae411bb1c5"}, "originalPosition": 104}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjAwMDY4OA==", "bodyText": "This will fail in Python 2.7, because bytes is an alias to str, and str() takes at most 1 argument.\nIf you need to convert string to bytes, use encode method which works both in Python 2.7 and 3.x", "url": "https://github.com/apache/beam/pull/11274#discussion_r412000688", "createdAt": "2020-04-21T08:54:00Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_read_perf_test.py", "diffHunk": "@@ -0,0 +1,153 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Read operation.\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_read_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner\n+    --sdk_location=.../dist/apache-beam-x.x.x.dev0.tar.gz\n+    --project=<GCP_PROJECT_ID>\n+    --temp_location=gs://<BUCKET_NAME>/tmp\n+    --staging_location=gs://<BUCKET_NAME>/staging\n+    --timeout=<TIME_IN_SECONDS>\n+    --publish_to_big_query=<OPTIONAL><true/false>\n+    --metrics_dataset=<OPTIONAL>\n+    --metrics_table=<OPTIONAL>\n+    --dataflow_worker_jar=<OPTIONAL>\n+    --input_options='{\n+    \\\"num_records\\\": <SIZE_OF_INPUT>\n+    }'\"\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import argparse\n+import logging\n+import sys\n+import uuid\n+\n+from hamcrest import all_of\n+\n+import apache_beam as beam\n+from apache_beam.io import ReadFromPubSub, WriteToPubSub, PubsubMessage\n+from apache_beam.io.gcp.tests.pubsub_matcher import PubSubMessageMatcher\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.testing import test_utils\n+from apache_beam.testing.load_tests.load_test import LoadTest\n+from apache_beam.testing.load_tests.load_test_metrics_utils import MeasureTime\n+from apache_beam.testing.test_pipeline import TestPipeline\n+\n+PUBSUB_NAME = 'pubsub_read_performance'\n+\n+\n+class PubsubReadPerfTest(LoadTest):\n+\n+  def __init__(self):\n+    super(PubsubReadPerfTest, self).__init__()\n+    self._setup_env()\n+    self._setup_pubsub()\n+    self._setup_pipeline()\n+\n+  def test(self):\n+    (\n+        self.pipeline\n+        | 'Read from pubsub' >> ReadFromPubSub(\n+            subscription=self.subscription.name,\n+            with_attributes=True,\n+            id_label='ack_id')\n+        | 'Measure time' >> beam.ParDo(MeasureTime(self.metrics_namespace))\n+    )\n+\n+  def cleanup(self):\n+    test_utils.cleanup_subscriptions(\n+      self.sub_client, [self.subscription, self.matcher_subscription])\n+    test_utils.cleanup_topics(\n+      self.pub_client, [self.topic])\n+\n+  def _setup_env(self):\n+    if not self.pipeline.get_option('timeout'):\n+      logging.error('--timeout argument is required.')\n+      sys.exit(1)\n+\n+    self.num_of_messages = int(self.input_options.get('num_records'))\n+    self.timeout = int(self.pipeline.get_option('timeout'))\n+\n+  def _setup_pubsub(self):\n+    def init_input(number_of_messages):\n+      for n in range(number_of_messages):\n+        message = PubsubMessage(\n+          bytes(str(n), 'utf-8'),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db2ed59ed67eccc35569a2cd3e4e73ae411bb1c5"}, "originalPosition": 99}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjAxODQ2Mw==", "bodyText": "You don't have to create PipelineOptions and ArgumentParser objects. This should be enough:\nargs = self.pipeline.get_full_options_as_args(**extra_opts)\nself.pipeline = TestPipeline(argv=args)", "url": "https://github.com/apache/beam/pull/11274#discussion_r412018463", "createdAt": "2020-04-21T09:18:31Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_read_perf_test.py", "diffHunk": "@@ -0,0 +1,153 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Read operation.\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_read_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner\n+    --sdk_location=.../dist/apache-beam-x.x.x.dev0.tar.gz\n+    --project=<GCP_PROJECT_ID>\n+    --temp_location=gs://<BUCKET_NAME>/tmp\n+    --staging_location=gs://<BUCKET_NAME>/staging\n+    --timeout=<TIME_IN_SECONDS>\n+    --publish_to_big_query=<OPTIONAL><true/false>\n+    --metrics_dataset=<OPTIONAL>\n+    --metrics_table=<OPTIONAL>\n+    --dataflow_worker_jar=<OPTIONAL>\n+    --input_options='{\n+    \\\"num_records\\\": <SIZE_OF_INPUT>\n+    }'\"\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import argparse\n+import logging\n+import sys\n+import uuid\n+\n+from hamcrest import all_of\n+\n+import apache_beam as beam\n+from apache_beam.io import ReadFromPubSub, WriteToPubSub, PubsubMessage\n+from apache_beam.io.gcp.tests.pubsub_matcher import PubSubMessageMatcher\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.testing import test_utils\n+from apache_beam.testing.load_tests.load_test import LoadTest\n+from apache_beam.testing.load_tests.load_test_metrics_utils import MeasureTime\n+from apache_beam.testing.test_pipeline import TestPipeline\n+\n+PUBSUB_NAME = 'pubsub_read_performance'\n+\n+\n+class PubsubReadPerfTest(LoadTest):\n+\n+  def __init__(self):\n+    super(PubsubReadPerfTest, self).__init__()\n+    self._setup_env()\n+    self._setup_pubsub()\n+    self._setup_pipeline()\n+\n+  def test(self):\n+    (\n+        self.pipeline\n+        | 'Read from pubsub' >> ReadFromPubSub(\n+            subscription=self.subscription.name,\n+            with_attributes=True,\n+            id_label='ack_id')\n+        | 'Measure time' >> beam.ParDo(MeasureTime(self.metrics_namespace))\n+    )\n+\n+  def cleanup(self):\n+    test_utils.cleanup_subscriptions(\n+      self.sub_client, [self.subscription, self.matcher_subscription])\n+    test_utils.cleanup_topics(\n+      self.pub_client, [self.topic])\n+\n+  def _setup_env(self):\n+    if not self.pipeline.get_option('timeout'):\n+      logging.error('--timeout argument is required.')\n+      sys.exit(1)\n+\n+    self.num_of_messages = int(self.input_options.get('num_records'))\n+    self.timeout = int(self.pipeline.get_option('timeout'))\n+\n+  def _setup_pubsub(self):\n+    def init_input(number_of_messages):\n+      for n in range(number_of_messages):\n+        message = PubsubMessage(\n+          bytes(str(n), 'utf-8'),\n+          {'ack_id': bytes(str(n), 'utf-8')})\n+        bytes_message = WriteToPubSub.to_proto_str(message)\n+        self.pub_client.publish(self.topic.name, bytes_message)\n+\n+    from google.cloud import pubsub\n+\n+    self.uuid = str(uuid.uuid4())\n+\n+    self.pub_client = pubsub.PublisherClient()\n+    self.topic = self.pub_client.create_topic(\n+      self.pub_client.topic_path(self.project_id, PUBSUB_NAME + self.uuid)\n+    )\n+\n+    self.sub_client = pubsub.SubscriberClient()\n+    self.subscription = self.sub_client.create_subscription(\n+      self.sub_client.subscription_path(self.project_id, PUBSUB_NAME + self.uuid),\n+      self.topic.name\n+    )\n+    self.matcher_subscription = self.sub_client.create_subscription(\n+      self.sub_client.subscription_path(self.project_id, PUBSUB_NAME + '_matcher_' + self.uuid),\n+      self.topic.name\n+    )\n+\n+    init_input(self.num_of_messages)\n+\n+\n+  def _setup_pipeline(self):\n+    pubsub_msg_verifier = PubSubMessageMatcher(\n+        self.project_id,\n+        self.matcher_subscription.name,\n+        expected_msg_len=self.num_of_messages,\n+        timeout=self.timeout\n+    )\n+\n+    self.extra_opts = {\n+        'on_success_matcher': all_of(pubsub_msg_verifier),\n+        'wait_until_finish_duration': self.timeout * 1000,\n+        'streaming': True,\n+        'save_main_session': True\n+    }\n+\n+    args = self.pipeline.get_full_options_as_args(**self.extra_opts)\n+\n+    parser = argparse.ArgumentParser()\n+    _, pipeline_args = parser.parse_known_args(args)\n+\n+    pipeline_options = PipelineOptions(pipeline_args)\n+\n+    self.pipeline = TestPipeline(options=pipeline_options)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db2ed59ed67eccc35569a2cd3e4e73ae411bb1c5"}, "originalPosition": 148}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjAyMDI3OQ==", "bodyText": "I think since we don't use self.extra_opts anywhere else, the assignment to self is redundant.", "url": "https://github.com/apache/beam/pull/11274#discussion_r412020279", "createdAt": "2020-04-21T09:21:10Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_read_perf_test.py", "diffHunk": "@@ -0,0 +1,153 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Read operation.\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_read_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner\n+    --sdk_location=.../dist/apache-beam-x.x.x.dev0.tar.gz\n+    --project=<GCP_PROJECT_ID>\n+    --temp_location=gs://<BUCKET_NAME>/tmp\n+    --staging_location=gs://<BUCKET_NAME>/staging\n+    --timeout=<TIME_IN_SECONDS>\n+    --publish_to_big_query=<OPTIONAL><true/false>\n+    --metrics_dataset=<OPTIONAL>\n+    --metrics_table=<OPTIONAL>\n+    --dataflow_worker_jar=<OPTIONAL>\n+    --input_options='{\n+    \\\"num_records\\\": <SIZE_OF_INPUT>\n+    }'\"\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import argparse\n+import logging\n+import sys\n+import uuid\n+\n+from hamcrest import all_of\n+\n+import apache_beam as beam\n+from apache_beam.io import ReadFromPubSub, WriteToPubSub, PubsubMessage\n+from apache_beam.io.gcp.tests.pubsub_matcher import PubSubMessageMatcher\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.testing import test_utils\n+from apache_beam.testing.load_tests.load_test import LoadTest\n+from apache_beam.testing.load_tests.load_test_metrics_utils import MeasureTime\n+from apache_beam.testing.test_pipeline import TestPipeline\n+\n+PUBSUB_NAME = 'pubsub_read_performance'\n+\n+\n+class PubsubReadPerfTest(LoadTest):\n+\n+  def __init__(self):\n+    super(PubsubReadPerfTest, self).__init__()\n+    self._setup_env()\n+    self._setup_pubsub()\n+    self._setup_pipeline()\n+\n+  def test(self):\n+    (\n+        self.pipeline\n+        | 'Read from pubsub' >> ReadFromPubSub(\n+            subscription=self.subscription.name,\n+            with_attributes=True,\n+            id_label='ack_id')\n+        | 'Measure time' >> beam.ParDo(MeasureTime(self.metrics_namespace))\n+    )\n+\n+  def cleanup(self):\n+    test_utils.cleanup_subscriptions(\n+      self.sub_client, [self.subscription, self.matcher_subscription])\n+    test_utils.cleanup_topics(\n+      self.pub_client, [self.topic])\n+\n+  def _setup_env(self):\n+    if not self.pipeline.get_option('timeout'):\n+      logging.error('--timeout argument is required.')\n+      sys.exit(1)\n+\n+    self.num_of_messages = int(self.input_options.get('num_records'))\n+    self.timeout = int(self.pipeline.get_option('timeout'))\n+\n+  def _setup_pubsub(self):\n+    def init_input(number_of_messages):\n+      for n in range(number_of_messages):\n+        message = PubsubMessage(\n+          bytes(str(n), 'utf-8'),\n+          {'ack_id': bytes(str(n), 'utf-8')})\n+        bytes_message = WriteToPubSub.to_proto_str(message)\n+        self.pub_client.publish(self.topic.name, bytes_message)\n+\n+    from google.cloud import pubsub\n+\n+    self.uuid = str(uuid.uuid4())\n+\n+    self.pub_client = pubsub.PublisherClient()\n+    self.topic = self.pub_client.create_topic(\n+      self.pub_client.topic_path(self.project_id, PUBSUB_NAME + self.uuid)\n+    )\n+\n+    self.sub_client = pubsub.SubscriberClient()\n+    self.subscription = self.sub_client.create_subscription(\n+      self.sub_client.subscription_path(self.project_id, PUBSUB_NAME + self.uuid),\n+      self.topic.name\n+    )\n+    self.matcher_subscription = self.sub_client.create_subscription(\n+      self.sub_client.subscription_path(self.project_id, PUBSUB_NAME + '_matcher_' + self.uuid),\n+      self.topic.name\n+    )\n+\n+    init_input(self.num_of_messages)\n+\n+\n+  def _setup_pipeline(self):\n+    pubsub_msg_verifier = PubSubMessageMatcher(\n+        self.project_id,\n+        self.matcher_subscription.name,\n+        expected_msg_len=self.num_of_messages,\n+        timeout=self.timeout\n+    )\n+\n+    self.extra_opts = {\n+        'on_success_matcher': all_of(pubsub_msg_verifier),\n+        'wait_until_finish_duration': self.timeout * 1000,\n+        'streaming': True,\n+        'save_main_session': True\n+    }\n+\n+    args = self.pipeline.get_full_options_as_args(**self.extra_opts)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db2ed59ed67eccc35569a2cd3e4e73ae411bb1c5"}, "originalPosition": 141}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjAyNDEwNQ==", "bodyText": "I would put emphasis on that the runner must be TestDataflowRunner, not DataflowRunner. This is very important information for anyone who would run this code.", "url": "https://github.com/apache/beam/pull/11274#discussion_r412024105", "createdAt": "2020-04-21T09:26:14Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_read_perf_test.py", "diffHunk": "@@ -0,0 +1,153 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Read operation.\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_read_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db2ed59ed67eccc35569a2cd3e4e73ae411bb1c5"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjAyNjA0MA==", "bodyText": "If you don't use a closure, I think you can make this function a top-level one. It would be easier to understand the program flow.", "url": "https://github.com/apache/beam/pull/11274#discussion_r412026040", "createdAt": "2020-04-21T09:28:49Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_read_perf_test.py", "diffHunk": "@@ -0,0 +1,153 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Read operation.\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_read_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner\n+    --sdk_location=.../dist/apache-beam-x.x.x.dev0.tar.gz\n+    --project=<GCP_PROJECT_ID>\n+    --temp_location=gs://<BUCKET_NAME>/tmp\n+    --staging_location=gs://<BUCKET_NAME>/staging\n+    --timeout=<TIME_IN_SECONDS>\n+    --publish_to_big_query=<OPTIONAL><true/false>\n+    --metrics_dataset=<OPTIONAL>\n+    --metrics_table=<OPTIONAL>\n+    --dataflow_worker_jar=<OPTIONAL>\n+    --input_options='{\n+    \\\"num_records\\\": <SIZE_OF_INPUT>\n+    }'\"\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import argparse\n+import logging\n+import sys\n+import uuid\n+\n+from hamcrest import all_of\n+\n+import apache_beam as beam\n+from apache_beam.io import ReadFromPubSub, WriteToPubSub, PubsubMessage\n+from apache_beam.io.gcp.tests.pubsub_matcher import PubSubMessageMatcher\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.testing import test_utils\n+from apache_beam.testing.load_tests.load_test import LoadTest\n+from apache_beam.testing.load_tests.load_test_metrics_utils import MeasureTime\n+from apache_beam.testing.test_pipeline import TestPipeline\n+\n+PUBSUB_NAME = 'pubsub_read_performance'\n+\n+\n+class PubsubReadPerfTest(LoadTest):\n+\n+  def __init__(self):\n+    super(PubsubReadPerfTest, self).__init__()\n+    self._setup_env()\n+    self._setup_pubsub()\n+    self._setup_pipeline()\n+\n+  def test(self):\n+    (\n+        self.pipeline\n+        | 'Read from pubsub' >> ReadFromPubSub(\n+            subscription=self.subscription.name,\n+            with_attributes=True,\n+            id_label='ack_id')\n+        | 'Measure time' >> beam.ParDo(MeasureTime(self.metrics_namespace))\n+    )\n+\n+  def cleanup(self):\n+    test_utils.cleanup_subscriptions(\n+      self.sub_client, [self.subscription, self.matcher_subscription])\n+    test_utils.cleanup_topics(\n+      self.pub_client, [self.topic])\n+\n+  def _setup_env(self):\n+    if not self.pipeline.get_option('timeout'):\n+      logging.error('--timeout argument is required.')\n+      sys.exit(1)\n+\n+    self.num_of_messages = int(self.input_options.get('num_records'))\n+    self.timeout = int(self.pipeline.get_option('timeout'))\n+\n+  def _setup_pubsub(self):\n+    def init_input(number_of_messages):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db2ed59ed67eccc35569a2cd3e4e73ae411bb1c5"}, "originalPosition": 96}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjAyODg1OQ==", "bodyText": "The same incompatibility error I mentioned earlier.", "url": "https://github.com/apache/beam/pull/11274#discussion_r412028859", "createdAt": "2020-04-21T09:32:49Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_write_perf_test.py", "diffHunk": "@@ -0,0 +1,153 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Write operation.\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_read_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner\n+    --sdk_location=.../dist/apache-beam-x.x.x.dev0.tar.gz\n+    --project=<GCP_PROJECT_ID>\n+    --temp_location=gs://<BUCKET_NAME>/tmp\n+    --staging_location=gs://<BUCKET_NAME>/staging\n+    --timeout=<TIME_IN_SECONDS>\n+    --publish_to_big_query=<OPTIONAL><true/false>\n+    --metrics_dataset=<OPTIONAL>\n+    --metrics_table=<OPTIONAL>\n+    --dataflow_worker_jar=<OPTIONAL>\n+    --input_options='{\n+    \\\"num_records\\\": <SIZE_OF_INPUT>,\n+    \\\"key_size\\\": 1,\n+    \\\"value_size\\\": <VALUE_SIZE>,\n+    }'\"\n+\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import argparse\n+import logging\n+import sys\n+import uuid\n+\n+from hamcrest import all_of\n+\n+import apache_beam as beam\n+from apache_beam.io import WriteToPubSub, PubsubMessage, Read\n+from apache_beam.io.gcp.tests.pubsub_matcher import PubSubMessageMatcher\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.runners import PipelineState\n+from apache_beam.testing import test_utils\n+from apache_beam.testing.load_tests.load_test import LoadTest\n+from apache_beam.testing.load_tests.load_test_metrics_utils import MeasureTime, CountMessages\n+from apache_beam.testing.pipeline_verifiers import PipelineStateMatcher\n+from apache_beam.testing.synthetic_pipeline import SyntheticSource\n+from apache_beam.testing.test_pipeline import TestPipeline\n+\n+PUBSUB_NAME = 'pubsub_write_performance'\n+\n+\n+class PubsubWritePerfTest(LoadTest):\n+\n+  def __init__(self):\n+    super(PubsubWritePerfTest, self).__init__()\n+    self._setup_env()\n+    self._setup_pubsub()\n+    self._setup_pipeline()\n+\n+  def test(self):\n+\n+    class ToPubsubMessage(beam.DoFn):\n+      counter = 0\n+\n+      def process(self, element):\n+        self.counter += 1\n+        from apache_beam.io import WriteToPubSub, PubsubMessage\n+        message = PubsubMessage(\n+          data=element[1],\n+          attributes={'ack_id': bytes(str(self.counter), 'utf-8')})", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db2ed59ed67eccc35569a2cd3e4e73ae411bb1c5"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjAzODYwNQ==", "bodyText": "For trivial DoFn's, you can also define a simple function instead of DoFn. Then, if it's a generator function, you can use a beam.FlatMap in the pipeline. Here are some examples: https://beam.apache.org/documentation/transforms/python/elementwise/flatmap/", "url": "https://github.com/apache/beam/pull/11274#discussion_r412038605", "createdAt": "2020-04-21T09:47:00Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_write_perf_test.py", "diffHunk": "@@ -0,0 +1,155 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Write operation.\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_read_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner\n+    --sdk_location=.../dist/apache-beam-x.x.x.dev0.tar.gz\n+    --project=<GCP_PROJECT_ID>\n+    --temp_location=gs://<BUCKET_NAME>/tmp\n+    --staging_location=gs://<BUCKET_NAME>/staging\n+    --timeout=<TIME_IN_SECONDS>\n+    --publish_to_big_query=<OPTIONAL><true/false>\n+    --metrics_dataset=<OPTIONAL>\n+    --metrics_table=<OPTIONAL>\n+    --dataflow_worker_jar=<OPTIONAL>\n+    --input_options='{\n+    \\\"num_records\\\": <SIZE_OF_INPUT>,\n+    \\\"key_size\\\": 1,\n+    \\\"value_size\\\": <VALUE_SIZE>,\n+    }'\"\n+\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import argparse\n+import logging\n+import sys\n+import uuid\n+\n+from hamcrest import all_of\n+\n+import apache_beam as beam\n+from apache_beam.io import WriteToPubSub, PubsubMessage, Read\n+from apache_beam.io.gcp.tests.pubsub_matcher import PubSubMessageMatcher\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.runners import PipelineState\n+from apache_beam.testing import test_utils\n+from apache_beam.testing.load_tests.load_test import LoadTest\n+from apache_beam.testing.load_tests.load_test_metrics_utils import MeasureTime, CountMessages\n+from apache_beam.testing.pipeline_verifiers import PipelineStateMatcher\n+from apache_beam.testing.synthetic_pipeline import SyntheticSource\n+from apache_beam.testing.test_pipeline import TestPipeline\n+\n+PUBSUB_NAME = 'pubsub_write_performance'\n+\n+\n+class PubsubWritePerfTest(LoadTest):\n+\n+  def __init__(self):\n+    super(PubsubWritePerfTest, self).__init__()\n+    self._setup_env()\n+    self._setup_pubsub()\n+    self._setup_pipeline()\n+\n+  def test(self):\n+\n+    class ToPubsubMessage(beam.DoFn):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "450da7a7dfb952310dffcdc35a7a95b6011144bf"}, "originalPosition": 79}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk3Mzk1MTQ5", "url": "https://github.com/apache/beam/pull/11274#pullrequestreview-397395149", "createdAt": "2020-04-21T14:36:16Z", "commit": {"oid": "4df286c34697ccf7e6139a2c593292d023ec80b8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQxNDozNjoxNlrOGJJOMA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQxNDozNjoxNlrOGJJOMA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjI0MTQ1Ng==", "bodyText": "Recently, we've migrated Load Tests and BigQuery perf tests to Python 3.7. It would be good to keep using Python 3.7 in PubSub perf tests as well.", "url": "https://github.com/apache/beam/pull/11274#discussion_r412241456", "createdAt": "2020-04-21T14:36:16Z", "author": {"login": "kamilwu"}, "path": ".test-infra/jenkins/job_PerformanceTests_PubsubIO_Python.groovy", "diffHunk": "@@ -0,0 +1,93 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+def now = new Date().format(\"MMddHHmmss\", TimeZone.getTimeZone('UTC'))\n+\n+def psio_read_test = [\n+        title          : 'PubsubIO Read Performance Test Python 900000 messages',\n+        test           : 'apache_beam.io.gcp.pubsub_read_perf_test',\n+        runner         : CommonTestProperties.Runner.DATAFLOW,\n+        pipelineOptions: [\n+                job_name             : 'performance-tests-psio-read-python-900000-msgs' + now,\n+                project              : 'apache-beam-testing',\n+                temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n+                publish_to_big_query : true,\n+                metrics_dataset      : 'beam_performance',\n+                metrics_table        : 'psio_read_900000msg_results',\n+                // Pubsub PublishRequest can have max 10'000'000 bytes\n+                input_options        : '\\'{\"num_records\": 900000}\\'',\n+                num_workers          : 5,\n+                autoscaling_algorithm: 'NONE',  // Disable autoscale the worker pool.\n+                timeout              : 3600,\n+        ]\n+]\n+\n+def psio_write_test = [\n+        title          : 'PubsubIO Write Performance Test Python 900000 messages',\n+        test           : 'apache_beam.io.gcp.pubsub_write_perf_test',\n+        runner         : CommonTestProperties.Runner.DATAFLOW,\n+        pipelineOptions: [\n+                job_name             : 'performance-tests-psio-write-python-900000-msgs' + now,\n+                project              : 'apache-beam-testing',\n+                temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n+                publish_to_big_query : true,\n+                metrics_dataset      : 'beam_performance',\n+                metrics_table        : 'psio_write_900000msg_results',\n+                // Pubsub PublishRequest can have max 10'000'000 bytes\n+                input_options        : '\\'{' +\n+                        '\"num_records\": 900000,' +\n+                        '\"key_size\": 1,' +\n+                        '\"value_size\": 1}\\'',\n+                num_workers          : 5,\n+                autoscaling_algorithm: 'NONE',  // Disable autoscale the worker pool.\n+                timeout              : 3600,\n+        ]\n+]\n+\n+def executeJob = { scope, testConfig ->\n+    commonJobProperties.setTopLevelMainJobProperties(scope, 'master', 240)\n+\n+    loadTestsBuilder.loadTest(scope, testConfig.title, testConfig.runner,\n+            CommonTestProperties.SDK.PYTHON, testConfig.pipelineOptions, testConfig.test)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4df286c34697ccf7e6139a2c593292d023ec80b8"}, "originalPosition": 66}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk3Mzk3ODM5", "url": "https://github.com/apache/beam/pull/11274#pullrequestreview-397397839", "createdAt": "2020-04-21T14:39:00Z", "commit": {"oid": "4df286c34697ccf7e6139a2c593292d023ec80b8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQxNDozOTowMFrOGJJXig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQxNDozOTowMFrOGJJXig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjI0Mzg1MA==", "bodyText": "We can rename this constant to DEFAULT_MAX_MESSAGES_IN_ONE_PULL and use as a default parameter value.", "url": "https://github.com/apache/beam/pull/11274#discussion_r412243850", "createdAt": "2020-04-21T14:39:00Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/tests/pubsub_matcher.py", "diffHunk": "@@ -38,7 +38,6 @@\n   pubsub = None\n \n DEFAULT_TIMEOUT = 5 * 60\n-MAX_MESSAGES_IN_ONE_PULL = 50", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4df286c34697ccf7e6139a2c593292d023ec80b8"}, "originalPosition": 4}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzk3Mzk5NDg3", "url": "https://github.com/apache/beam/pull/11274#pullrequestreview-397399487", "createdAt": "2020-04-21T14:40:43Z", "commit": {"oid": "4df286c34697ccf7e6139a2c593292d023ec80b8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQxNDo0MDo0M1rOGJJdCw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQxNDo0MDo0M1rOGJJdCw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMjI0NTI1OQ==", "bodyText": "I'm fine with additional parameters, but we need to update a docstring.", "url": "https://github.com/apache/beam/pull/11274#discussion_r412245259", "createdAt": "2020-04-21T14:40:43Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/tests/pubsub_matcher.py", "diffHunk": "@@ -57,7 +56,9 @@ def __init__(\n       expected_msg_len=None,\n       timeout=DEFAULT_TIMEOUT,\n       with_attributes=False,\n-      strip_attributes=None):\n+      strip_attributes=None,\n+      sleep_time=1,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4df286c34697ccf7e6139a2c593292d023ec80b8"}, "originalPosition": 14}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f914a2f3f54751812456b0faf7fdd72ffae5e9f1", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/f914a2f3f54751812456b0faf7fdd72ffae5e9f1", "committedDate": "2020-04-27T09:51:25Z", "message": "[BEAM-9633] Change pubsub performance tests input to 3GB"}, "afterCommit": {"oid": "23be9182f99feac7a3b0ff57ba1f6a1518edf106", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/23be9182f99feac7a3b0ff57ba1f6a1518edf106", "committedDate": "2020-04-27T09:53:10Z", "message": "[BEAM-9633] Change pubsub performance tests input to 3GB"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "78c4a8bb7caaaa93d4d6f783cb4036901a4edca2", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/78c4a8bb7caaaa93d4d6f783cb4036901a4edca2", "committedDate": "2020-04-27T14:12:45Z", "message": "[BEAM-9633] Remove time import"}, "afterCommit": {"oid": "0917cac63e304b2092eb26ec0a678af6401c6d2e", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/0917cac63e304b2092eb26ec0a678af6401c6d2e", "committedDate": "2020-04-27T14:56:13Z", "message": "[BEAM-9633] Wait for published messages ids after publishing instead of blindly sleep between publishes"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0917cac63e304b2092eb26ec0a678af6401c6d2e", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/0917cac63e304b2092eb26ec0a678af6401c6d2e", "committedDate": "2020-04-27T14:56:13Z", "message": "[BEAM-9633] Wait for published messages ids after publishing instead of blindly sleep between publishes"}, "afterCommit": {"oid": "e4cf9d3de3d666ae0f17030e4dcb5e2011d04a05", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/e4cf9d3de3d666ae0f17030e4dcb5e2011d04a05", "committedDate": "2020-04-27T19:54:17Z", "message": "[BEAM-9633] Wait for published messages ids after publishing instead of blindly sleep between publishes"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAyNTEyMDAx", "url": "https://github.com/apache/beam/pull/11274#pullrequestreview-402512001", "createdAt": "2020-04-29T09:43:00Z", "commit": {"oid": "bea3df016b63c2be50ca792e71f5538ac63ac44b"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQwOTo0MzowMFrOGN3UQA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQwOTo0MzowMFrOGN3UQA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzE5MDk3Ng==", "bodyText": "How about creating a subscription for reading messages in the read test? I'm\u00a0pretty sure the write test does not need it.", "url": "https://github.com/apache/beam/pull/11274#discussion_r417190976", "createdAt": "2020-04-29T09:43:00Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_write_perf_test.py", "diffHunk": "@@ -0,0 +1,104 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Write operation.\n+\n+Caution: only test runners (e.g. TestDataflowRunner) support matchers\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_read_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner\n+    --sdk_location=.../dist/apache-beam-x.x.x.dev0.tar.gz\n+    --project=<GCP_PROJECT_ID>\n+    --temp_location=gs://<BUCKET_NAME>/tmp\n+    --staging_location=gs://<BUCKET_NAME>/staging\n+    --timeout=<TIME_IN_SECONDS>\n+    --pubsub_name=<PUBSUB_NAME_TO_BE_CREATED>\n+    --publish_to_big_query=<OPTIONAL><true/false>\n+    --metrics_dataset=<OPTIONAL>\n+    --metrics_table=<OPTIONAL>\n+    --dataflow_worker_jar=<OPTIONAL>\n+    --input_options='{\n+    \\\"num_records\\\": <SIZE_OF_INPUT>,\n+    \\\"key_size\\\": 1,\n+    \\\"value_size\\\": <VALUE_SIZE>,\n+    }'\"\n+\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import logging\n+\n+import apache_beam as beam\n+from apache_beam.io import Read\n+from apache_beam.io.gcp.pubsub_perf_test import PubsubPerfTest\n+from apache_beam.testing.load_tests.load_test_metrics_utils import MeasureTime\n+from apache_beam.testing.synthetic_pipeline import SyntheticSource\n+\n+\n+class PubsubWritePerfTest(PubsubPerfTest):\n+  def __init__(self):\n+    super(PubsubWritePerfTest, self).__init__()\n+    self._setup_env()\n+    self._setup_pubsub()\n+    self._setup_pipeline(self.write_matcher_sub_name)\n+\n+  def test(self):\n+    def to_pubsub_message(element):\n+      import uuid\n+      from apache_beam.io import PubsubMessage\n+      return PubsubMessage(\n+          data=element[1],\n+          attributes={'id': str(uuid.uuid1()).encode('utf-8')},\n+      )\n+\n+    _ = (\n+        self.pipeline\n+        | 'Create input' >> Read(\n+            SyntheticSource(self.parse_synthetic_source_options()))\n+        | 'Format to pubsub message in bytes' >> beam.Map(to_pubsub_message)\n+        | 'Measure time' >> beam.ParDo(MeasureTime(self.metrics_namespace))\n+        | 'Write to Pubsub' >> beam.io.WriteToPubSub(\n+            self.topic_name, with_attributes=True, id_label='id'))\n+\n+  def _setup_pubsub(self):\n+    super(PubsubWritePerfTest, self)._setup_pubsub()\n+\n+    def make_subscription(sub_name):\n+      _ = self.sub_client.create_subscription(\n+          sub_name,\n+          self.topic_name,\n+          ack_deadline_seconds=300,\n+          timeout=1200,\n+          retain_acked_messages=True,\n+      )\n+\n+    _ = self.pub_client.create_topic(self.topic_name)\n+    make_subscription(self.write_matcher_sub_name)\n+    make_subscription(self.read_sub_name)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bea3df016b63c2be50ca792e71f5538ac63ac44b"}, "originalPosition": 98}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAyNTEzMjY3", "url": "https://github.com/apache/beam/pull/11274#pullrequestreview-402513267", "createdAt": "2020-04-29T09:44:51Z", "commit": {"oid": "bea3df016b63c2be50ca792e71f5538ac63ac44b"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQwOTo0NDo1MVrOGN3YRg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQwOTo0NDo1MVrOGN3YRg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzE5MjAwNg==", "bodyText": "The same situation as above.", "url": "https://github.com/apache/beam/pull/11274#discussion_r417192006", "createdAt": "2020-04-29T09:44:51Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_write_perf_test.py", "diffHunk": "@@ -0,0 +1,104 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Write operation.\n+\n+Caution: only test runners (e.g. TestDataflowRunner) support matchers\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_read_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner\n+    --sdk_location=.../dist/apache-beam-x.x.x.dev0.tar.gz\n+    --project=<GCP_PROJECT_ID>\n+    --temp_location=gs://<BUCKET_NAME>/tmp\n+    --staging_location=gs://<BUCKET_NAME>/staging\n+    --timeout=<TIME_IN_SECONDS>\n+    --pubsub_name=<PUBSUB_NAME_TO_BE_CREATED>\n+    --publish_to_big_query=<OPTIONAL><true/false>\n+    --metrics_dataset=<OPTIONAL>\n+    --metrics_table=<OPTIONAL>\n+    --dataflow_worker_jar=<OPTIONAL>\n+    --input_options='{\n+    \\\"num_records\\\": <SIZE_OF_INPUT>,\n+    \\\"key_size\\\": 1,\n+    \\\"value_size\\\": <VALUE_SIZE>,\n+    }'\"\n+\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import logging\n+\n+import apache_beam as beam\n+from apache_beam.io import Read\n+from apache_beam.io.gcp.pubsub_perf_test import PubsubPerfTest\n+from apache_beam.testing.load_tests.load_test_metrics_utils import MeasureTime\n+from apache_beam.testing.synthetic_pipeline import SyntheticSource\n+\n+\n+class PubsubWritePerfTest(PubsubPerfTest):\n+  def __init__(self):\n+    super(PubsubWritePerfTest, self).__init__()\n+    self._setup_env()\n+    self._setup_pubsub()\n+    self._setup_pipeline(self.write_matcher_sub_name)\n+\n+  def test(self):\n+    def to_pubsub_message(element):\n+      import uuid\n+      from apache_beam.io import PubsubMessage\n+      return PubsubMessage(\n+          data=element[1],\n+          attributes={'id': str(uuid.uuid1()).encode('utf-8')},\n+      )\n+\n+    _ = (\n+        self.pipeline\n+        | 'Create input' >> Read(\n+            SyntheticSource(self.parse_synthetic_source_options()))\n+        | 'Format to pubsub message in bytes' >> beam.Map(to_pubsub_message)\n+        | 'Measure time' >> beam.ParDo(MeasureTime(self.metrics_namespace))\n+        | 'Write to Pubsub' >> beam.io.WriteToPubSub(\n+            self.topic_name, with_attributes=True, id_label='id'))\n+\n+  def _setup_pubsub(self):\n+    super(PubsubWritePerfTest, self)._setup_pubsub()\n+\n+    def make_subscription(sub_name):\n+      _ = self.sub_client.create_subscription(\n+          sub_name,\n+          self.topic_name,\n+          ack_deadline_seconds=300,\n+          timeout=1200,\n+          retain_acked_messages=True,\n+      )\n+\n+    _ = self.pub_client.create_topic(self.topic_name)\n+    make_subscription(self.write_matcher_sub_name)\n+    make_subscription(self.read_sub_name)\n+    make_subscription(self.read_matcher_sub_name)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bea3df016b63c2be50ca792e71f5538ac63ac44b"}, "originalPosition": 99}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAyNTE3NzY1", "url": "https://github.com/apache/beam/pull/11274#pullrequestreview-402517765", "createdAt": "2020-04-29T09:51:28Z", "commit": {"oid": "bea3df016b63c2be50ca792e71f5538ac63ac44b"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQwOTo1MToyOVrOGN3mYw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQwOTo1MToyOVrOGN3mYw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzE5NTYxOQ==", "bodyText": "Can we shift the responsibility of cleaning up this subscription onto this test? Remember that both tests can be executed independently, without Jenkins.", "url": "https://github.com/apache/beam/pull/11274#discussion_r417195619", "createdAt": "2020-04-29T09:51:29Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_write_perf_test.py", "diffHunk": "@@ -0,0 +1,104 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Write operation.\n+\n+Caution: only test runners (e.g. TestDataflowRunner) support matchers\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_read_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner\n+    --sdk_location=.../dist/apache-beam-x.x.x.dev0.tar.gz\n+    --project=<GCP_PROJECT_ID>\n+    --temp_location=gs://<BUCKET_NAME>/tmp\n+    --staging_location=gs://<BUCKET_NAME>/staging\n+    --timeout=<TIME_IN_SECONDS>\n+    --pubsub_name=<PUBSUB_NAME_TO_BE_CREATED>\n+    --publish_to_big_query=<OPTIONAL><true/false>\n+    --metrics_dataset=<OPTIONAL>\n+    --metrics_table=<OPTIONAL>\n+    --dataflow_worker_jar=<OPTIONAL>\n+    --input_options='{\n+    \\\"num_records\\\": <SIZE_OF_INPUT>,\n+    \\\"key_size\\\": 1,\n+    \\\"value_size\\\": <VALUE_SIZE>,\n+    }'\"\n+\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import logging\n+\n+import apache_beam as beam\n+from apache_beam.io import Read\n+from apache_beam.io.gcp.pubsub_perf_test import PubsubPerfTest\n+from apache_beam.testing.load_tests.load_test_metrics_utils import MeasureTime\n+from apache_beam.testing.synthetic_pipeline import SyntheticSource\n+\n+\n+class PubsubWritePerfTest(PubsubPerfTest):\n+  def __init__(self):\n+    super(PubsubWritePerfTest, self).__init__()\n+    self._setup_env()\n+    self._setup_pubsub()\n+    self._setup_pipeline(self.write_matcher_sub_name)\n+\n+  def test(self):\n+    def to_pubsub_message(element):\n+      import uuid\n+      from apache_beam.io import PubsubMessage\n+      return PubsubMessage(\n+          data=element[1],\n+          attributes={'id': str(uuid.uuid1()).encode('utf-8')},\n+      )\n+\n+    _ = (\n+        self.pipeline\n+        | 'Create input' >> Read(\n+            SyntheticSource(self.parse_synthetic_source_options()))\n+        | 'Format to pubsub message in bytes' >> beam.Map(to_pubsub_message)\n+        | 'Measure time' >> beam.ParDo(MeasureTime(self.metrics_namespace))\n+        | 'Write to Pubsub' >> beam.io.WriteToPubSub(\n+            self.topic_name, with_attributes=True, id_label='id'))\n+\n+  def _setup_pubsub(self):\n+    super(PubsubWritePerfTest, self)._setup_pubsub()\n+\n+    def make_subscription(sub_name):\n+      _ = self.sub_client.create_subscription(\n+          sub_name,\n+          self.topic_name,\n+          ack_deadline_seconds=300,\n+          timeout=1200,\n+          retain_acked_messages=True,\n+      )\n+\n+    _ = self.pub_client.create_topic(self.topic_name)\n+    make_subscription(self.write_matcher_sub_name)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bea3df016b63c2be50ca792e71f5538ac63ac44b"}, "originalPosition": 97}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAyNTIwMDE4", "url": "https://github.com/apache/beam/pull/11274#pullrequestreview-402520018", "createdAt": "2020-04-29T09:54:47Z", "commit": {"oid": "bea3df016b63c2be50ca792e71f5538ac63ac44b"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQwOTo1NDo0N1rOGN3tIQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQwOTo1NDo0N1rOGN3tIQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzE5NzM0NQ==", "bodyText": "It would be good to notice that the input topic must already exist before executing the test.", "url": "https://github.com/apache/beam/pull/11274#discussion_r417197345", "createdAt": "2020-04-29T09:54:47Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_read_perf_test.py", "diffHunk": "@@ -0,0 +1,80 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Read operation.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bea3df016b63c2be50ca792e71f5538ac63ac44b"}, "originalPosition": 19}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAyNTI4MTA5", "url": "https://github.com/apache/beam/pull/11274#pullrequestreview-402528109", "createdAt": "2020-04-29T10:06:24Z", "commit": {"oid": "bea3df016b63c2be50ca792e71f5538ac63ac44b"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQxMDowNjoyNFrOGN4FXA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQxMDowNjoyNFrOGN4FXA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzIwMzU0OA==", "bodyText": "This parameter is not used. I think we can remove this. Please also remove the code that checks if --input_option is present at the base class.", "url": "https://github.com/apache/beam/pull/11274#discussion_r417203548", "createdAt": "2020-04-29T10:06:24Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_read_perf_test.py", "diffHunk": "@@ -0,0 +1,80 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Read operation.\n+\n+Caution: only test runners (e.g. TestDataflowRunner) support matchers\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_read_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner\n+    --sdk_location=.../dist/apache-beam-x.x.x.dev0.tar.gz\n+    --project=<GCP_PROJECT_ID>\n+    --temp_location=gs://<BUCKET_NAME>/tmp\n+    --staging_location=gs://<BUCKET_NAME>/staging\n+    --timeout=<TIME_IN_SECONDS>\n+    --pubsub_name=<PUBSUB_NAME_TO_BE_CREATED>\n+    --publish_to_big_query=<OPTIONAL><true/false>\n+    --metrics_dataset=<OPTIONAL>\n+    --metrics_table=<OPTIONAL>\n+    --dataflow_worker_jar=<OPTIONAL>\n+    --input_options='{", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bea3df016b63c2be50ca792e71f5538ac63ac44b"}, "originalPosition": 38}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDAyNTMxODg2", "url": "https://github.com/apache/beam/pull/11274#pullrequestreview-402531886", "createdAt": "2020-04-29T10:12:17Z", "commit": {"oid": "bea3df016b63c2be50ca792e71f5538ac63ac44b"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQxMDoxMjoxN1rOGN4RnQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yOVQxMDoxMjoxN1rOGN4RnQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzIwNjY4NQ==", "bodyText": "I like the idea of reusing output topic for the purpose of the read test. But, in that case, you have to make sure that the write test is executed first. At the moment, both tests start independently at the same hour ('H 15 * * *'), which can cause some issues.", "url": "https://github.com/apache/beam/pull/11274#discussion_r417206685", "createdAt": "2020-04-29T10:12:17Z", "author": {"login": "kamilwu"}, "path": ".test-infra/jenkins/job_PerformanceTests_PubsubIO_Python.groovy", "diffHunk": "@@ -0,0 +1,106 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+import CommonJobProperties as commonJobProperties\n+import LoadTestsBuilder as loadTestsBuilder\n+import PhraseTriggeringPostCommitBuilder\n+\n+import static java.util.UUID.randomUUID\n+\n+def now = new Date().format(\"MMddHHmmss\", TimeZone.getTimeZone('UTC'))\n+def timeout = 60 * 60\n+\n+def pubsubId = randomUUID()\n+def pubsubName = \"pubsub_io_performance_${pubsubId}\"\n+\n+def psio_write_test = [\n+        title          : 'PubsubIO Write Performance Test Python 2GB',\n+        test           : 'apache_beam.io.gcp.pubsub_write_perf_test',\n+        runner         : CommonTestProperties.Runner.DATAFLOW,\n+        pipelineOptions: [\n+                job_name             : 'performance-tests-psio-write-python-2gb' + now,\n+                project              : 'apache-beam-testing',\n+                temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n+                publish_to_big_query : true,\n+                metrics_dataset      : 'beam_performance',\n+                metrics_table        : 'psio_write_2GB_msg_results',\n+                input_options        : '\\'{' +\n+                        '\"num_records\": 2097152,' +\n+                        '\"key_size\": 1,' +\n+                        '\"value_size\": 1024}\\'',\n+                num_workers          : 5,\n+                autoscaling_algorithm: 'NONE',  // Disable autoscale the worker pool.\n+                pubsub_name          : pubsubName,\n+                timeout              : timeout,\n+        ]\n+]\n+\n+def psio_read_test = [\n+        title          : 'PubsubIO Read Performance Test Python 2GB',\n+        test           : 'apache_beam.io.gcp.pubsub_read_perf_test',\n+        runner         : CommonTestProperties.Runner.DATAFLOW,\n+        pipelineOptions: [\n+                job_name             : 'performance-tests-psio-read-python-2gb' + now,\n+                project              : 'apache-beam-testing',\n+                temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n+                publish_to_big_query : true,\n+                metrics_dataset      : 'beam_performance',\n+                metrics_table        : 'psio_read_2GB_msg_results',\n+                input_options        : '\\'{' +\n+                        '\"num_records\": 2097152,' +\n+                        '\"key_size\": 1,' +\n+                        '\"value_size\": 1024}\\'',\n+                num_workers          : 5,\n+                autoscaling_algorithm: 'NONE',  // Disable autoscale the worker pool.\n+                pubsub_name          : pubsubName,\n+                timeout              : timeout,\n+        ]\n+]\n+\n+def executeJob = { scope, testConfig ->\n+    commonJobProperties.setTopLevelMainJobProperties(scope, 'master', 240)\n+\n+    loadTestsBuilder.loadTest(scope, testConfig.title, testConfig.runner,\n+            CommonTestProperties.SDK.PYTHON_37, testConfig.pipelineOptions, testConfig.test)\n+}\n+\n+PhraseTriggeringPostCommitBuilder.postCommitJob(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "bea3df016b63c2be50ca792e71f5538ac63ac44b"}, "originalPosition": 82}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "64a0d2b53450ec4e6001630858d913914009d865", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/64a0d2b53450ec4e6001630858d913914009d865", "committedDate": "2020-05-04T14:42:55Z", "message": "[BEAM-9633] Move test classess to one file and rename the metrics for each test"}, "afterCommit": {"oid": "b4f5855fd873b86e87279d54aaac0e0876739273", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/b4f5855fd873b86e87279d54aaac0e0876739273", "committedDate": "2020-05-04T14:46:20Z", "message": "[BEAM-9633] Move test classess to one file and rename the metrics for each test"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA1NjA4NDEy", "url": "https://github.com/apache/beam/pull/11274#pullrequestreview-405608412", "createdAt": "2020-05-05T09:01:29Z", "commit": {"oid": "a155f9a1e2468adbd558cc1e9c80a58a3ba47139"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQwOTowMTozMFrOGQgfGg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQwOTowMTozMFrOGQgfGg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTk2MjY1MA==", "bodyText": "There are two spaces between PubsubIO and Performance. Could you fix that?", "url": "https://github.com/apache/beam/pull/11274#discussion_r419962650", "createdAt": "2020-05-05T09:01:30Z", "author": {"login": "kamilwu"}, "path": ".test-infra/jenkins/job_PerformanceTests_PubsubIO_Python.groovy", "diffHunk": "@@ -0,0 +1,72 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+import CommonJobProperties as commonJobProperties\n+import LoadTestsBuilder as loadTestsBuilder\n+import PhraseTriggeringPostCommitBuilder\n+\n+import static java.util.UUID.randomUUID\n+\n+def now = new Date().format(\"MMddHHmmss\", TimeZone.getTimeZone('UTC'))\n+def timeout = 60 * 60\n+\n+def pubsubId = randomUUID()\n+def pubsubName = \"pubsub_io_performance_${pubsubId}\"\n+\n+def psio_test = [\n+        title          : 'PubsubIO Write Performance Test Python 2GB',\n+        test           : 'apache_beam.io.gcp.pubsub_io_perf_test',\n+        runner         : CommonTestProperties.Runner.DATAFLOW,\n+        pipelineOptions: [\n+                job_name             : 'performance-tests-psio-python-2gb' + now,\n+                project              : 'apache-beam-testing',\n+                temp_location        : 'gs://temp-storage-for-perf-tests/loadtests',\n+                publish_to_big_query : true,\n+                metrics_dataset      : 'beam_performance',\n+                metrics_table        : 'psio_io_2GB_msg_results',\n+                input_options        : '\\'{' +\n+                        '\"num_records\": 2097152,' +\n+                        '\"key_size\": 1,' +\n+                        '\"value_size\": 1024}\\'',\n+                num_workers          : 5,\n+                autoscaling_algorithm: 'NONE',  // Disable autoscale the worker pool.\n+                pubsub_name          : pubsubName,\n+                timeout              : timeout,\n+        ]\n+]\n+\n+\n+def executeJob = { scope, testConfig ->\n+    commonJobProperties.setTopLevelMainJobProperties(scope, 'master', 240)\n+\n+    loadTestsBuilder.loadTest(scope, testConfig.title, testConfig.runner,\n+            CommonTestProperties.SDK.PYTHON_37, testConfig.pipelineOptions, testConfig.test)\n+}\n+\n+PhraseTriggeringPostCommitBuilder.postCommitJob(\n+        'beam_PubsubIO_Performance_Test_Python',\n+        'Run PubsubIO  Performance Test Python',", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a155f9a1e2468adbd558cc1e9c80a58a3ba47139"}, "originalPosition": 63}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA1NjEyNTMy", "url": "https://github.com/apache/beam/pull/11274#pullrequestreview-405612532", "createdAt": "2020-05-05T09:07:40Z", "commit": {"oid": "a155f9a1e2468adbd558cc1e9c80a58a3ba47139"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQwOTowNzo0MVrOGQgsCw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQwOTowNzo0MVrOGQgsCw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTk2NTk2Mw==", "bodyText": "It'd good to put emphasis on what is being created with this name. I suggest renaming this option to topic_name.", "url": "https://github.com/apache/beam/pull/11274#discussion_r419965963", "createdAt": "2020-05-05T09:07:41Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_io_perf_test.py", "diffHunk": "@@ -0,0 +1,195 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Write/Read operations.\n+\n+Caution: only test runners (e.g. TestDataflowRunner) support matchers\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_io_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner\n+    --sdk_location=.../dist/apache-beam-x.x.x.dev0.tar.gz\n+    --project=<GCP_PROJECT_ID>\n+    --temp_location=gs://<BUCKET_NAME>/tmp\n+    --staging_location=gs://<BUCKET_NAME>/staging\n+    --timeout=<TIME_IN_SECONDS>\n+    --pubsub_name=<PUBSUB_NAME_TO_BE_CREATED>\n+    --publish_to_big_query=<OPTIONAL><true/false>\n+    --metrics_dataset=<OPTIONAL>\n+    --metrics_table=<OPTIONAL>\n+    --dataflow_worker_jar=<OPTIONAL>\n+    --input_options='{\n+      \\\"num_records\\\": <SIZE_OF_INPUT>\n+      \\\"key_size\\\": 1\n+      \\\"value_size\\\": <SIZE_OF_EACH_MESSAGE>\n+    }'\"\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import logging\n+import sys\n+\n+from hamcrest import all_of\n+\n+import apache_beam as beam\n+from apache_beam.io import Read\n+from apache_beam.io import ReadFromPubSub\n+from apache_beam.io.gcp.tests.pubsub_matcher import PubSubMessageMatcher\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.testing.load_tests.load_test import LoadTest\n+from apache_beam.testing.load_tests.load_test_metrics_utils import MeasureTime\n+from apache_beam.testing.synthetic_pipeline import SyntheticSource\n+from apache_beam.testing.test_pipeline import TestPipeline\n+\n+# pylint: disable=wrong-import-order, wrong-import-position\n+try:\n+  from google.cloud import pubsub\n+except ImportError:\n+  pubsub = None\n+# pylint: enable=wrong-import-order, wrong-import-position\n+\n+\n+class PubsubIOPerfTest(LoadTest):\n+  def _setup_env(self):\n+    def check_option(name):\n+      if not self.pipeline.get_option(name):\n+        logging.error('--%s argument is required.', name)\n+        sys.exit(1)\n+\n+    check_option('timeout')\n+    check_option('pubsub_name')\n+\n+    self.num_of_messages = int(self.input_options.get('num_records'))\n+    self.size_of_messages = int(self.input_options.get('value_size'))\n+    self.timeout = int(self.pipeline.get_option('timeout'))\n+    self.pubsub_name = self.pipeline.get_option('pubsub_name')", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a155f9a1e2468adbd558cc1e9c80a58a3ba47139"}, "originalPosition": 85}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "bae44a05970794bc2f58e59ad0b3b85979eb6073", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/bae44a05970794bc2f58e59ad0b3b85979eb6073", "committedDate": "2020-05-05T09:30:34Z", "message": "[BEAM-9633] Rename pubsub_name to topic_name"}, "afterCommit": {"oid": "284add46fadf600883b198880781412cfc3f6d38", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/284add46fadf600883b198880781412cfc3f6d38", "committedDate": "2020-05-05T09:32:33Z", "message": "[BEAM-9633] Rename pubsub_name to topic_name"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA1NjMwMzkw", "url": "https://github.com/apache/beam/pull/11274#pullrequestreview-405630390", "createdAt": "2020-05-05T09:34:33Z", "commit": {"oid": "a155f9a1e2468adbd558cc1e9c80a58a3ba47139"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQwOTozNDozM1rOGQhmdg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNVQwOTozNDozM1rOGQhmdg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTk4MDkxOA==", "bodyText": "It's totally fine to write all metrics to the same BigQuery table. That's how all IO IT tests in Java SDK works, where we have two types of metric: \"read_time\" and \"write_time\". The only thing you have to do is to change the argument that MeasureTime's constructor takes (it's self.metrics_namespace now, which is BigQuery table, but you wanna change that to, say, 'read_time' in PubsubReadPerfTest and 'write_time' in PubsubWritePerfTest)", "url": "https://github.com/apache/beam/pull/11274#discussion_r419980918", "createdAt": "2020-05-05T09:34:33Z", "author": {"login": "kamilwu"}, "path": "sdks/python/apache_beam/io/gcp/pubsub_io_perf_test.py", "diffHunk": "@@ -0,0 +1,195 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"\n+Performance PubsubIO streaming test for Write/Read operations.\n+\n+Caution: only test runners (e.g. TestDataflowRunner) support matchers\n+\n+Example for TestDataflowRunner:\n+\n+python -m apache_beam.io.gcp.pubsub_io_perf_test \\\n+    --test-pipeline-options=\"\n+    --runner=TestDataflowRunner\n+    --sdk_location=.../dist/apache-beam-x.x.x.dev0.tar.gz\n+    --project=<GCP_PROJECT_ID>\n+    --temp_location=gs://<BUCKET_NAME>/tmp\n+    --staging_location=gs://<BUCKET_NAME>/staging\n+    --timeout=<TIME_IN_SECONDS>\n+    --pubsub_name=<PUBSUB_NAME_TO_BE_CREATED>\n+    --publish_to_big_query=<OPTIONAL><true/false>\n+    --metrics_dataset=<OPTIONAL>\n+    --metrics_table=<OPTIONAL>\n+    --dataflow_worker_jar=<OPTIONAL>\n+    --input_options='{\n+      \\\"num_records\\\": <SIZE_OF_INPUT>\n+      \\\"key_size\\\": 1\n+      \\\"value_size\\\": <SIZE_OF_EACH_MESSAGE>\n+    }'\"\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import logging\n+import sys\n+\n+from hamcrest import all_of\n+\n+import apache_beam as beam\n+from apache_beam.io import Read\n+from apache_beam.io import ReadFromPubSub\n+from apache_beam.io.gcp.tests.pubsub_matcher import PubSubMessageMatcher\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.testing.load_tests.load_test import LoadTest\n+from apache_beam.testing.load_tests.load_test_metrics_utils import MeasureTime\n+from apache_beam.testing.synthetic_pipeline import SyntheticSource\n+from apache_beam.testing.test_pipeline import TestPipeline\n+\n+# pylint: disable=wrong-import-order, wrong-import-position\n+try:\n+  from google.cloud import pubsub\n+except ImportError:\n+  pubsub = None\n+# pylint: enable=wrong-import-order, wrong-import-position\n+\n+\n+class PubsubIOPerfTest(LoadTest):\n+  def _setup_env(self):\n+    def check_option(name):\n+      if not self.pipeline.get_option(name):\n+        logging.error('--%s argument is required.', name)\n+        sys.exit(1)\n+\n+    check_option('timeout')\n+    check_option('pubsub_name')\n+\n+    self.num_of_messages = int(self.input_options.get('num_records'))\n+    self.size_of_messages = int(self.input_options.get('value_size'))\n+    self.timeout = int(self.pipeline.get_option('timeout'))\n+    self.pubsub_name = self.pipeline.get_option('pubsub_name')\n+\n+  def _setup_pubsub(self):\n+    self.pub_client = pubsub.PublisherClient()\n+    self.topic_name = self.pub_client.topic_path(\n+        self.project_id, self.pubsub_name)\n+\n+    self.sub_client = pubsub.SubscriberClient()\n+    self.read_sub_name = self.sub_client.subscription_path(\n+        self.project_id,\n+        self.pubsub_name + '_read',\n+    )\n+    self.read_matcher_sub_name = self.sub_client.subscription_path(\n+        self.project_id,\n+        self.pubsub_name + '_read_matcher',\n+    )\n+    self.write_matcher_sub_name = self.sub_client.subscription_path(\n+        self.project_id,\n+        self.pubsub_name + '_write_matcher',\n+    )\n+\n+  def _setup_pipeline(self, subscription_name):\n+    pubsub_msg_verifier = PubSubMessageMatcher(\n+        self.project_id,\n+        subscription_name,\n+        expected_msg_len=self.num_of_messages,\n+        timeout=self.timeout,\n+        sleep_time=0,\n+        max_messages_in_one_pull=1000,\n+        pull_timeout=1200)\n+\n+    extra_opts = {\n+        'on_success_matcher': all_of(pubsub_msg_verifier),\n+        'wait_until_finish_duration': self.timeout * 1000,\n+        'streaming': True,\n+        'save_main_session': True\n+    }\n+\n+    args = self.pipeline.get_full_options_as_args(**extra_opts)\n+    self.pipeline = TestPipeline(options=PipelineOptions(args))\n+\n+\n+class PubsubWritePerfTest(PubsubIOPerfTest):\n+  def __init__(self):\n+    super(PubsubWritePerfTest, self).__init__('_write')\n+    self._setup_env()\n+    self._setup_pubsub()\n+    self._setup_pipeline(self.write_matcher_sub_name)\n+\n+  def test(self):\n+    def to_pubsub_message(element):\n+      import uuid\n+      from apache_beam.io import PubsubMessage\n+      return PubsubMessage(\n+          data=element[1],\n+          attributes={'id': str(uuid.uuid1()).encode('utf-8')},\n+      )\n+\n+    _ = (\n+        self.pipeline\n+        | 'Create input' >> Read(\n+            SyntheticSource(self.parse_synthetic_source_options()))\n+        | 'Format to pubsub message in bytes' >> beam.Map(to_pubsub_message)\n+        | 'Measure time' >> beam.ParDo(MeasureTime(self.metrics_namespace))\n+        | 'Write to Pubsub' >> beam.io.WriteToPubSub(\n+            self.topic_name, with_attributes=True, id_label='id'))\n+\n+  def _setup_pubsub(self):\n+    super(PubsubWritePerfTest, self)._setup_pubsub()\n+\n+    def make_subscription(sub_name):\n+      _ = self.sub_client.create_subscription(\n+          sub_name,\n+          self.topic_name,\n+          ack_deadline_seconds=300,\n+          timeout=1200,\n+      )\n+\n+    _ = self.pub_client.create_topic(self.topic_name)\n+    make_subscription(self.write_matcher_sub_name)\n+    make_subscription(self.read_sub_name)\n+    make_subscription(self.read_matcher_sub_name)\n+\n+\n+class PubsubReadPerfTest(PubsubIOPerfTest):\n+  def __init__(self):\n+    super(PubsubReadPerfTest, self).__init__('_read')", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a155f9a1e2468adbd558cc1e9c80a58a3ba47139"}, "originalPosition": 171}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "8891b41315b7c4433e12d3274e3dcba30f62f135", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/8891b41315b7c4433e12d3274e3dcba30f62f135", "committedDate": "2020-05-05T13:15:06Z", "message": "[BEAM-9633] Add TestDataflowRunner to pipeline options"}, "afterCommit": {"oid": "f1e09a3906ee495d34d8e13ade82b52a88dfcb7d", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/f1e09a3906ee495d34d8e13ade82b52a88dfcb7d", "committedDate": "2020-05-05T13:35:39Z", "message": "[BEAM-9633] Add TestDataflowRunner to pipeline options"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "7ba07c9b75573e7b8fbffad33a6782c5a447cece", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/7ba07c9b75573e7b8fbffad33a6782c5a447cece", "committedDate": "2020-05-06T17:10:45Z", "message": "[BEAM-9633] Add namespace param to MetricsReader so it does not enforce to use bq_table as the namespace for the metrics"}, "afterCommit": {"oid": "4924121e9fb2f4d97c2897acfae0dc9e5dbadd13", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/4924121e9fb2f4d97c2897acfae0dc9e5dbadd13", "committedDate": "2020-05-06T17:18:14Z", "message": "[BEAM-9633] Add namespace param to MetricsReader so it does not enforce to use bq_table as the namespace for the metrics"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA3MzcwODE3", "url": "https://github.com/apache/beam/pull/11274#pullrequestreview-407370817", "createdAt": "2020-05-07T11:09:53Z", "commit": {"oid": "4924121e9fb2f4d97c2897acfae0dc9e5dbadd13"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e9047ddc6d1854426410cec847ba876f6ed49685", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/e9047ddc6d1854426410cec847ba876f6ed49685", "committedDate": "2020-05-08T13:51:27Z", "message": "[BEAM-9633] Add dataflow_worker_jar to the streaming load tests"}, "afterCommit": {"oid": "c05f2913f4b0e87d576f4fad4d9246cd555d4714", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/c05f2913f4b0e87d576f4fad4d9246cd555d4714", "committedDate": "2020-05-08T14:24:29Z", "message": "[BEAM-9633] Add dataflow_worker_jar to the streaming load tests"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c05f2913f4b0e87d576f4fad4d9246cd555d4714", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/c05f2913f4b0e87d576f4fad4d9246cd555d4714", "committedDate": "2020-05-08T14:24:29Z", "message": "[BEAM-9633] Add dataflow_worker_jar to the streaming load tests"}, "afterCommit": {"oid": "cd8c8cd6f8588b1fe4439c7e1f656657c9160de4", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/cd8c8cd6f8588b1fe4439c7e1f656657c9160de4", "committedDate": "2020-05-08T14:26:56Z", "message": "[BEAM-9633] Add dataflow_worker_jar to the streaming load tests"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA4Mjg4NTI1", "url": "https://github.com/apache/beam/pull/11274#pullrequestreview-408288525", "createdAt": "2020-05-08T14:42:07Z", "commit": {"oid": "cd8c8cd6f8588b1fe4439c7e1f656657c9160de4"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wOFQxNDo0MjowOFrOGSoAjA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wOFQxNDo0MjowOFrOGSoAjA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjE4MzA1Mg==", "bodyText": "Why did you remove that comma?", "url": "https://github.com/apache/beam/pull/11274#discussion_r422183052", "createdAt": "2020-05-08T14:42:08Z", "author": {"login": "kamilwu"}, "path": ".test-infra/jenkins/job_PerformanceTests_PubsubIO_Python.groovy", "diffHunk": "@@ -41,7 +42,7 @@ def psio_test = [\n                 metrics_dataset      : 'beam_performance',\n                 metrics_table        : 'psio_io_2GB_msg_results',\n                 input_options        : '\\'{' +\n-                        '\"num_records\": 2097152,' +\n+                        '\"num_records\": 2097152' +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cd8c8cd6f8588b1fe4439c7e1f656657c9160de4"}, "originalPosition": 13}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "cd8c8cd6f8588b1fe4439c7e1f656657c9160de4", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/cd8c8cd6f8588b1fe4439c7e1f656657c9160de4", "committedDate": "2020-05-08T14:26:56Z", "message": "[BEAM-9633] Add dataflow_worker_jar to the streaming load tests"}, "afterCommit": {"oid": "c3d1234997845593117d8a02938bf471eb73fad9", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/c3d1234997845593117d8a02938bf471eb73fad9", "committedDate": "2020-05-08T15:16:05Z", "message": "[BEAM-9633] Add dataflow_worker_jar to the streaming load tests"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "720605051846ea17b44819a1530b0606e2279bad", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/720605051846ea17b44819a1530b0606e2279bad", "committedDate": "2020-05-11T08:13:12Z", "message": "[BEAM-9633] Change worker jar flag like in postcommit suites"}, "afterCommit": {"oid": "b45b3c58954c7529b69a23fea43a18f862c46b49", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/b45b3c58954c7529b69a23fea43a18f862c46b49", "committedDate": "2020-05-11T08:26:43Z", "message": "[BEAM-9633] Add -- to dataflow_worker_jar"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "29fb96840d87c5f4a45beb7d71d3aaac1f584315", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/29fb96840d87c5f4a45beb7d71d3aaac1f584315", "committedDate": "2020-05-12T17:15:56Z", "message": "[BEAM-7774] Add sleep 1s to matcher, increase max_messages_in_one_pull and decrease timeout for pipeline"}, "afterCommit": {"oid": "992e3a6e402cef46ca5646e9d9d57095e432697d", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/992e3a6e402cef46ca5646e9d9d57095e432697d", "committedDate": "2020-05-12T17:17:49Z", "message": "[BEAM-7774] Add sleep 1s to matcher, increase max_messages_in_one_pull and decrease timeout for pipeline"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a9014b2e1dc9ff77e1b2b35d4a20780b8d89e2dc", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/a9014b2e1dc9ff77e1b2b35d4a20780b8d89e2dc", "committedDate": "2020-05-19T11:58:46Z", "message": "[BEAM-9633] Add namespace parameter to MetricReader"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7708c63ccd2d3043eda4efbcd4930191117ef99d", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/7708c63ccd2d3043eda4efbcd4930191117ef99d", "committedDate": "2020-05-19T11:59:25Z", "message": "[BEAM-9633] Add more parameters to pubsub matcher"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7525bdf50b888eaf02a0a71ef5e69b2ea50c803e", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/7525bdf50b888eaf02a0a71ef5e69b2ea50c803e", "committedDate": "2020-05-19T11:59:31Z", "message": "[BEAM-9633] Add pubsubio performance tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a355f6d31babe46f4eb2b49bb821f10a3a684cff", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/a355f6d31babe46f4eb2b49bb821f10a3a684cff", "committedDate": "2020-05-19T11:59:34Z", "message": "[BEAM-9633] Add jenkins job for python pubsubio tests"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "91e73b4015661fe03b801d51b7d62fcc1a24f97a", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/91e73b4015661fe03b801d51b7d62fcc1a24f97a", "committedDate": "2020-05-19T10:57:37Z", "message": "[BEAM-9633] Change the method of validating read from pulling all messages to counting them"}, "afterCommit": {"oid": "a355f6d31babe46f4eb2b49bb821f10a3a684cff", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/a355f6d31babe46f4eb2b49bb821f10a3a684cff", "committedDate": "2020-05-19T11:59:34Z", "message": "[BEAM-9633] Add jenkins job for python pubsubio tests"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4830, "cost": 1, "resetAt": "2021-10-28T17:48:14Z"}}}