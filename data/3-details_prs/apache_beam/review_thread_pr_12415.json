{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDU4NTk3NzEw", "number": 12415, "reviewThreads": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQyMzoyNTo1NVrOEZsZ-w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQwMDozMDo0MFrOEawCGg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk1Mzc3NDAzOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/interactive/interactive_runner.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQyMzoyNTo1NVrOHCqBdg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQwMDoxMzowN1rOHCq4pQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjU0NzcwMg==", "bodyText": "typo: doesn't", "url": "https://github.com/apache/beam/pull/12415#discussion_r472547702", "createdAt": "2020-08-18T23:25:55Z", "author": {"login": "davidyan74"}, "path": "sdks/python/apache_beam/runners/interactive/interactive_runner.py", "diffHunk": "@@ -152,7 +152,11 @@ def run_pipeline(self, pipeline, options):\n               user_pipeline)):\n         streaming_cache_manager = ie.current_env().get_cache_manager(\n             user_pipeline)\n-        if streaming_cache_manager:\n+\n+        # Only make the server if it doens't exist already.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13e0f36a97c867bc25d547f7b8d36782c877ca97"}, "originalPosition": 6}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjU2MTgyOQ==", "bodyText": "Done", "url": "https://github.com/apache/beam/pull/12415#discussion_r472561829", "createdAt": "2020-08-19T00:13:07Z", "author": {"login": "rohdesamuel"}, "path": "sdks/python/apache_beam/runners/interactive/interactive_runner.py", "diffHunk": "@@ -152,7 +152,11 @@ def run_pipeline(self, pipeline, options):\n               user_pipeline)):\n         streaming_cache_manager = ie.current_env().get_cache_manager(\n             user_pipeline)\n-        if streaming_cache_manager:\n+\n+        # Only make the server if it doens't exist already.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjU0NzcwMg=="}, "originalCommit": {"oid": "13e0f36a97c867bc25d547f7b8d36782c877ca97"}, "originalPosition": 6}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk1Mzc3OTA2OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/interactive/interactive_runner.py", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQyMzoyODowNlrOHCqEXg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQyMjoxNjoyNlrOHEVICg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjU0ODQ0Ng==", "bodyText": "Just wondering, what if the service controller has stopped? Is it possible?", "url": "https://github.com/apache/beam/pull/12415#discussion_r472548446", "createdAt": "2020-08-18T23:28:06Z", "author": {"login": "davidyan74"}, "path": "sdks/python/apache_beam/runners/interactive/interactive_runner.py", "diffHunk": "@@ -152,7 +152,11 @@ def run_pipeline(self, pipeline, options):\n               user_pipeline)):\n         streaming_cache_manager = ie.current_env().get_cache_manager(\n             user_pipeline)\n-        if streaming_cache_manager:\n+\n+        # Only make the server if it doens't exist already.\n+        if (streaming_cache_manager and\n+            not ie.current_env().get_test_stream_service_controller(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13e0f36a97c867bc25d547f7b8d36782c877ca97"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjU1ODAxMw==", "bodyText": "No, the server is \"one-time\" use. Once it stops it can't be started up again and this should be set None.", "url": "https://github.com/apache/beam/pull/12415#discussion_r472558013", "createdAt": "2020-08-18T23:59:21Z", "author": {"login": "rohdesamuel"}, "path": "sdks/python/apache_beam/runners/interactive/interactive_runner.py", "diffHunk": "@@ -152,7 +152,11 @@ def run_pipeline(self, pipeline, options):\n               user_pipeline)):\n         streaming_cache_manager = ie.current_env().get_cache_manager(\n             user_pipeline)\n-        if streaming_cache_manager:\n+\n+        # Only make the server if it doens't exist already.\n+        if (streaming_cache_manager and\n+            not ie.current_env().get_test_stream_service_controller(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjU0ODQ0Ng=="}, "originalCommit": {"oid": "13e0f36a97c867bc25d547f7b8d36782c877ca97"}, "originalPosition": 8}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDMwMjQ3NA==", "bodyText": "IIUC this change is fixing an unrelated issue, right?", "url": "https://github.com/apache/beam/pull/12415#discussion_r474302474", "createdAt": "2020-08-20T22:16:26Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/runners/interactive/interactive_runner.py", "diffHunk": "@@ -152,7 +152,11 @@ def run_pipeline(self, pipeline, options):\n               user_pipeline)):\n         streaming_cache_manager = ie.current_env().get_cache_manager(\n             user_pipeline)\n-        if streaming_cache_manager:\n+\n+        # Only make the server if it doens't exist already.\n+        if (streaming_cache_manager and\n+            not ie.current_env().get_test_stream_service_controller(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjU0ODQ0Ng=="}, "originalCommit": {"oid": "13e0f36a97c867bc25d547f7b8d36782c877ca97"}, "originalPosition": 8}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk1Mzc5MjQwOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/interactive/recording_manager.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQyMzozMzo1MlrOHCqL-A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQwMDoxMjo0NVrOHCq4OA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjU1MDM5Mg==", "bodyText": "This looks like busy waiting, which can hog the CPU. Can we do it another way? Or at least have a sleep in the while loop?", "url": "https://github.com/apache/beam/pull/12415#discussion_r472550392", "createdAt": "2020-08-18T23:33:52Z", "author": {"login": "davidyan74"}, "path": "sdks/python/apache_beam/runners/interactive/recording_manager.py", "diffHunk": "@@ -0,0 +1,330 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import absolute_import\n+\n+import logging\n+import threading\n+import time\n+import warnings\n+\n+import apache_beam as beam\n+from apache_beam.runners.interactive import background_caching_job as bcj\n+from apache_beam.runners.interactive import interactive_environment as ie\n+from apache_beam.runners.interactive import interactive_runner as ir\n+from apache_beam.runners.interactive import pipeline_fragment as pf\n+from apache_beam.runners.interactive import pipeline_instrument as pi\n+from apache_beam.runners.interactive import utils\n+from apache_beam.runners.interactive.options.capture_limiters import CountLimiter\n+from apache_beam.runners.interactive.options.capture_limiters import ProcessingTimeLimiter\n+\n+_LOGGER = logging.getLogger(__name__)\n+\n+PipelineState = beam.runners.runner.PipelineState\n+\n+\n+class ElementStream:\n+  \"\"\"A stream of elements from a given PCollection.\"\"\"\n+  def __init__(\n+      self,\n+      pcoll,  # type: beam.pvalue.PCollection\n+      var,  # type: str\n+      cache_key,  # type: str\n+      max_n,  # type: int\n+      max_duration_secs  # type: float\n+      ):\n+    self._pcoll = pcoll\n+    self._cache_key = cache_key\n+    self._pipeline = pcoll.pipeline\n+    self._var = var\n+    self._n = max_n\n+    self._duration_secs = max_duration_secs\n+\n+    # A small state variable that when True, indicates that no more new elements\n+    # will be yielded if read() is called again.\n+    self._done = False\n+\n+  def var(self):\n+    # type: () -> str\n+\n+    \"\"\"Returns the variable named that defined this PCollection.\"\"\"\n+    return self._var\n+\n+  def display_id(self, suffix):\n+    #Any type: (str) -> str\n+\n+    \"\"\"Returns a unique id able to be displayed in a web browser.\"\"\"\n+    return utils.obfuscate(self._cache_key, suffix)\n+\n+  def is_computed(self):\n+    # type: () -> boolean\n+\n+    \"\"\"Returns True if no more elements will be recorded.\"\"\"\n+    return self._pcoll in ie.current_env().computed_pcollections\n+\n+  def is_done(self):\n+    # type: () -> boolean\n+\n+    \"\"\"Returns True if no more new elements will be yielded.\"\"\"\n+    return self._done\n+\n+  def read(self, tail=True):\n+    # type: (boolean) -> Any\n+\n+    \"\"\"Reads the elements currently recorded.\"\"\"\n+\n+    # Get the cache manager and wait until the file exists.\n+    cache_manager = ie.current_env().get_cache_manager(self._pipeline)\n+    while not cache_manager.exists('full', self._cache_key):\n+      pass", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13e0f36a97c867bc25d547f7b8d36782c877ca97"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjU2MTcyMA==", "bodyText": "Ack added a sleep.", "url": "https://github.com/apache/beam/pull/12415#discussion_r472561720", "createdAt": "2020-08-19T00:12:45Z", "author": {"login": "rohdesamuel"}, "path": "sdks/python/apache_beam/runners/interactive/recording_manager.py", "diffHunk": "@@ -0,0 +1,330 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import absolute_import\n+\n+import logging\n+import threading\n+import time\n+import warnings\n+\n+import apache_beam as beam\n+from apache_beam.runners.interactive import background_caching_job as bcj\n+from apache_beam.runners.interactive import interactive_environment as ie\n+from apache_beam.runners.interactive import interactive_runner as ir\n+from apache_beam.runners.interactive import pipeline_fragment as pf\n+from apache_beam.runners.interactive import pipeline_instrument as pi\n+from apache_beam.runners.interactive import utils\n+from apache_beam.runners.interactive.options.capture_limiters import CountLimiter\n+from apache_beam.runners.interactive.options.capture_limiters import ProcessingTimeLimiter\n+\n+_LOGGER = logging.getLogger(__name__)\n+\n+PipelineState = beam.runners.runner.PipelineState\n+\n+\n+class ElementStream:\n+  \"\"\"A stream of elements from a given PCollection.\"\"\"\n+  def __init__(\n+      self,\n+      pcoll,  # type: beam.pvalue.PCollection\n+      var,  # type: str\n+      cache_key,  # type: str\n+      max_n,  # type: int\n+      max_duration_secs  # type: float\n+      ):\n+    self._pcoll = pcoll\n+    self._cache_key = cache_key\n+    self._pipeline = pcoll.pipeline\n+    self._var = var\n+    self._n = max_n\n+    self._duration_secs = max_duration_secs\n+\n+    # A small state variable that when True, indicates that no more new elements\n+    # will be yielded if read() is called again.\n+    self._done = False\n+\n+  def var(self):\n+    # type: () -> str\n+\n+    \"\"\"Returns the variable named that defined this PCollection.\"\"\"\n+    return self._var\n+\n+  def display_id(self, suffix):\n+    #Any type: (str) -> str\n+\n+    \"\"\"Returns a unique id able to be displayed in a web browser.\"\"\"\n+    return utils.obfuscate(self._cache_key, suffix)\n+\n+  def is_computed(self):\n+    # type: () -> boolean\n+\n+    \"\"\"Returns True if no more elements will be recorded.\"\"\"\n+    return self._pcoll in ie.current_env().computed_pcollections\n+\n+  def is_done(self):\n+    # type: () -> boolean\n+\n+    \"\"\"Returns True if no more new elements will be yielded.\"\"\"\n+    return self._done\n+\n+  def read(self, tail=True):\n+    # type: (boolean) -> Any\n+\n+    \"\"\"Reads the elements currently recorded.\"\"\"\n+\n+    # Get the cache manager and wait until the file exists.\n+    cache_manager = ie.current_env().get_cache_manager(self._pipeline)\n+    while not cache_manager.exists('full', self._cache_key):\n+      pass", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjU1MDM5Mg=="}, "originalCommit": {"oid": "13e0f36a97c867bc25d547f7b8d36782c877ca97"}, "originalPosition": 93}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk1MzgxNjUyOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/interactive/recording_manager.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQyMzo0NToyNFrOHCqZig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQwMDoxMjo0OVrOHCq4RA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjU1Mzg2Ng==", "bodyText": "This looks like a hack. Is it possible to add read_multiple to CacheManager itself and FileBasedCacheManager as well?", "url": "https://github.com/apache/beam/pull/12415#discussion_r472553866", "createdAt": "2020-08-18T23:45:24Z", "author": {"login": "davidyan74"}, "path": "sdks/python/apache_beam/runners/interactive/recording_manager.py", "diffHunk": "@@ -0,0 +1,330 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import absolute_import\n+\n+import logging\n+import threading\n+import time\n+import warnings\n+\n+import apache_beam as beam\n+from apache_beam.runners.interactive import background_caching_job as bcj\n+from apache_beam.runners.interactive import interactive_environment as ie\n+from apache_beam.runners.interactive import interactive_runner as ir\n+from apache_beam.runners.interactive import pipeline_fragment as pf\n+from apache_beam.runners.interactive import pipeline_instrument as pi\n+from apache_beam.runners.interactive import utils\n+from apache_beam.runners.interactive.options.capture_limiters import CountLimiter\n+from apache_beam.runners.interactive.options.capture_limiters import ProcessingTimeLimiter\n+\n+_LOGGER = logging.getLogger(__name__)\n+\n+PipelineState = beam.runners.runner.PipelineState\n+\n+\n+class ElementStream:\n+  \"\"\"A stream of elements from a given PCollection.\"\"\"\n+  def __init__(\n+      self,\n+      pcoll,  # type: beam.pvalue.PCollection\n+      var,  # type: str\n+      cache_key,  # type: str\n+      max_n,  # type: int\n+      max_duration_secs  # type: float\n+      ):\n+    self._pcoll = pcoll\n+    self._cache_key = cache_key\n+    self._pipeline = pcoll.pipeline\n+    self._var = var\n+    self._n = max_n\n+    self._duration_secs = max_duration_secs\n+\n+    # A small state variable that when True, indicates that no more new elements\n+    # will be yielded if read() is called again.\n+    self._done = False\n+\n+  def var(self):\n+    # type: () -> str\n+\n+    \"\"\"Returns the variable named that defined this PCollection.\"\"\"\n+    return self._var\n+\n+  def display_id(self, suffix):\n+    #Any type: (str) -> str\n+\n+    \"\"\"Returns a unique id able to be displayed in a web browser.\"\"\"\n+    return utils.obfuscate(self._cache_key, suffix)\n+\n+  def is_computed(self):\n+    # type: () -> boolean\n+\n+    \"\"\"Returns True if no more elements will be recorded.\"\"\"\n+    return self._pcoll in ie.current_env().computed_pcollections\n+\n+  def is_done(self):\n+    # type: () -> boolean\n+\n+    \"\"\"Returns True if no more new elements will be yielded.\"\"\"\n+    return self._done\n+\n+  def read(self, tail=True):\n+    # type: (boolean) -> Any\n+\n+    \"\"\"Reads the elements currently recorded.\"\"\"\n+\n+    # Get the cache manager and wait until the file exists.\n+    cache_manager = ie.current_env().get_cache_manager(self._pipeline)\n+    while not cache_manager.exists('full', self._cache_key):\n+      pass\n+\n+    # Retrieve the coder for the particular PCollection which will be used to\n+    # decode elements read from cache.\n+    coder = cache_manager.load_pcoder('full', self._cache_key)\n+\n+    # Read the elements from the cache.\n+    limiters = [\n+        CountLimiter(self._n), ProcessingTimeLimiter(self._duration_secs)\n+    ]\n+    if hasattr(cache_manager, 'read_multiple'):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13e0f36a97c867bc25d547f7b8d36782c877ca97"}, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjU2MTczMg==", "bodyText": "Actually, I forgot to remove this prototype. I added tail as an optional to read() in a previous PR so I can remove this.", "url": "https://github.com/apache/beam/pull/12415#discussion_r472561732", "createdAt": "2020-08-19T00:12:49Z", "author": {"login": "rohdesamuel"}, "path": "sdks/python/apache_beam/runners/interactive/recording_manager.py", "diffHunk": "@@ -0,0 +1,330 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import absolute_import\n+\n+import logging\n+import threading\n+import time\n+import warnings\n+\n+import apache_beam as beam\n+from apache_beam.runners.interactive import background_caching_job as bcj\n+from apache_beam.runners.interactive import interactive_environment as ie\n+from apache_beam.runners.interactive import interactive_runner as ir\n+from apache_beam.runners.interactive import pipeline_fragment as pf\n+from apache_beam.runners.interactive import pipeline_instrument as pi\n+from apache_beam.runners.interactive import utils\n+from apache_beam.runners.interactive.options.capture_limiters import CountLimiter\n+from apache_beam.runners.interactive.options.capture_limiters import ProcessingTimeLimiter\n+\n+_LOGGER = logging.getLogger(__name__)\n+\n+PipelineState = beam.runners.runner.PipelineState\n+\n+\n+class ElementStream:\n+  \"\"\"A stream of elements from a given PCollection.\"\"\"\n+  def __init__(\n+      self,\n+      pcoll,  # type: beam.pvalue.PCollection\n+      var,  # type: str\n+      cache_key,  # type: str\n+      max_n,  # type: int\n+      max_duration_secs  # type: float\n+      ):\n+    self._pcoll = pcoll\n+    self._cache_key = cache_key\n+    self._pipeline = pcoll.pipeline\n+    self._var = var\n+    self._n = max_n\n+    self._duration_secs = max_duration_secs\n+\n+    # A small state variable that when True, indicates that no more new elements\n+    # will be yielded if read() is called again.\n+    self._done = False\n+\n+  def var(self):\n+    # type: () -> str\n+\n+    \"\"\"Returns the variable named that defined this PCollection.\"\"\"\n+    return self._var\n+\n+  def display_id(self, suffix):\n+    #Any type: (str) -> str\n+\n+    \"\"\"Returns a unique id able to be displayed in a web browser.\"\"\"\n+    return utils.obfuscate(self._cache_key, suffix)\n+\n+  def is_computed(self):\n+    # type: () -> boolean\n+\n+    \"\"\"Returns True if no more elements will be recorded.\"\"\"\n+    return self._pcoll in ie.current_env().computed_pcollections\n+\n+  def is_done(self):\n+    # type: () -> boolean\n+\n+    \"\"\"Returns True if no more new elements will be yielded.\"\"\"\n+    return self._done\n+\n+  def read(self, tail=True):\n+    # type: (boolean) -> Any\n+\n+    \"\"\"Reads the elements currently recorded.\"\"\"\n+\n+    # Get the cache manager and wait until the file exists.\n+    cache_manager = ie.current_env().get_cache_manager(self._pipeline)\n+    while not cache_manager.exists('full', self._cache_key):\n+      pass\n+\n+    # Retrieve the coder for the particular PCollection which will be used to\n+    # decode elements read from cache.\n+    coder = cache_manager.load_pcoder('full', self._cache_key)\n+\n+    # Read the elements from the cache.\n+    limiters = [\n+        CountLimiter(self._n), ProcessingTimeLimiter(self._duration_secs)\n+    ]\n+    if hasattr(cache_manager, 'read_multiple'):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjU1Mzg2Ng=="}, "originalCommit": {"oid": "13e0f36a97c867bc25d547f7b8d36782c877ca97"}, "originalPosition": 103}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk1MzgyMTk4OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/interactive/recording_manager.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQyMzo0ODowOVrOHCqcjg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQwMDoxMjo1MlrOHCq4Ww==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjU1NDYzOA==", "bodyText": "This also looks like busy waiting.", "url": "https://github.com/apache/beam/pull/12415#discussion_r472554638", "createdAt": "2020-08-18T23:48:09Z", "author": {"login": "davidyan74"}, "path": "sdks/python/apache_beam/runners/interactive/recording_manager.py", "diffHunk": "@@ -0,0 +1,330 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import absolute_import\n+\n+import logging\n+import threading\n+import time\n+import warnings\n+\n+import apache_beam as beam\n+from apache_beam.runners.interactive import background_caching_job as bcj\n+from apache_beam.runners.interactive import interactive_environment as ie\n+from apache_beam.runners.interactive import interactive_runner as ir\n+from apache_beam.runners.interactive import pipeline_fragment as pf\n+from apache_beam.runners.interactive import pipeline_instrument as pi\n+from apache_beam.runners.interactive import utils\n+from apache_beam.runners.interactive.options.capture_limiters import CountLimiter\n+from apache_beam.runners.interactive.options.capture_limiters import ProcessingTimeLimiter\n+\n+_LOGGER = logging.getLogger(__name__)\n+\n+PipelineState = beam.runners.runner.PipelineState\n+\n+\n+class ElementStream:\n+  \"\"\"A stream of elements from a given PCollection.\"\"\"\n+  def __init__(\n+      self,\n+      pcoll,  # type: beam.pvalue.PCollection\n+      var,  # type: str\n+      cache_key,  # type: str\n+      max_n,  # type: int\n+      max_duration_secs  # type: float\n+      ):\n+    self._pcoll = pcoll\n+    self._cache_key = cache_key\n+    self._pipeline = pcoll.pipeline\n+    self._var = var\n+    self._n = max_n\n+    self._duration_secs = max_duration_secs\n+\n+    # A small state variable that when True, indicates that no more new elements\n+    # will be yielded if read() is called again.\n+    self._done = False\n+\n+  def var(self):\n+    # type: () -> str\n+\n+    \"\"\"Returns the variable named that defined this PCollection.\"\"\"\n+    return self._var\n+\n+  def display_id(self, suffix):\n+    #Any type: (str) -> str\n+\n+    \"\"\"Returns a unique id able to be displayed in a web browser.\"\"\"\n+    return utils.obfuscate(self._cache_key, suffix)\n+\n+  def is_computed(self):\n+    # type: () -> boolean\n+\n+    \"\"\"Returns True if no more elements will be recorded.\"\"\"\n+    return self._pcoll in ie.current_env().computed_pcollections\n+\n+  def is_done(self):\n+    # type: () -> boolean\n+\n+    \"\"\"Returns True if no more new elements will be yielded.\"\"\"\n+    return self._done\n+\n+  def read(self, tail=True):\n+    # type: (boolean) -> Any\n+\n+    \"\"\"Reads the elements currently recorded.\"\"\"\n+\n+    # Get the cache manager and wait until the file exists.\n+    cache_manager = ie.current_env().get_cache_manager(self._pipeline)\n+    while not cache_manager.exists('full', self._cache_key):\n+      pass\n+\n+    # Retrieve the coder for the particular PCollection which will be used to\n+    # decode elements read from cache.\n+    coder = cache_manager.load_pcoder('full', self._cache_key)\n+\n+    # Read the elements from the cache.\n+    limiters = [\n+        CountLimiter(self._n), ProcessingTimeLimiter(self._duration_secs)\n+    ]\n+    if hasattr(cache_manager, 'read_multiple'):\n+      reader = cache_manager.read_multiple([('full', self._cache_key)],\n+                                           limiters=limiters,\n+                                           tail=tail)\n+    else:\n+      reader, _ = cache_manager.read('full', self._cache_key, limiters=limiters)\n+\n+    # Because a single TestStreamFileRecord can yield multiple elements, we\n+    # limit the count again here in the to_element_list call.\n+    for e in utils.to_element_list(reader,\n+                                   coder,\n+                                   include_window_info=True,\n+                                   n=self._n):\n+      yield e\n+\n+    # A limiter being triggered means that we have fulfilled the user's request.\n+    # This implies that reading from the cache again won't yield any new\n+    # elements. WLOG, this applies to the user pipeline being terminated.\n+    if any(l.is_triggered()\n+           for l in limiters) or ie.current_env().is_terminated(self._pipeline):\n+      self._done = True\n+\n+\n+class Recording:\n+  \"\"\"A group of PCollections from a given pipeline run.\"\"\"\n+  def __init__(\n+      self,\n+      user_pipeline,  # type: beam.Pipeline\n+      pcolls,  # type: List[beam.pvalue.PCollection]\n+      result,  # type: beam.runner.PipelineResult\n+      pipeline_instrument,  # type: beam.runners.interactive.PipelineInstrument\n+      max_n,  # type: int\n+      max_duration_secs  # type: float\n+      ):\n+\n+    self._user_pipeline = user_pipeline\n+    self._result = result\n+    self._pcolls = pcolls\n+\n+    pcoll_var = lambda pcoll: pipeline_instrument.cacheable_var_by_pcoll_id(\n+        pipeline_instrument.pcolls_to_pcoll_id.get(str(pcoll), None))\n+\n+    self._streams = {\n+        pcoll: ElementStream(\n+            pcoll,\n+            pcoll_var(pcoll),\n+            pipeline_instrument.cache_key(pcoll),\n+            max_n,\n+            max_duration_secs)\n+        for pcoll in pcolls\n+    }\n+    self._start = time.time()\n+    self._duration_secs = max_duration_secs\n+    self._set_computed = bcj.is_cache_complete(str(id(user_pipeline)))\n+\n+    # Run a separate thread for marking the PCollections done. This is because\n+    # the pipeline run may be asynchronous.\n+    self._mark_computed = threading.Thread(target=self._mark_all_computed)\n+    self._mark_computed.daemon = True\n+    self._mark_computed.start()\n+\n+  def _mark_all_computed(self):\n+    # type: () -> None\n+\n+    \"\"\"Marks all the PCollections upon a successful pipeline run.\"\"\"\n+    if not self._result:\n+      return\n+\n+    while not PipelineState.is_terminal(self._result.state):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "13e0f36a97c867bc25d547f7b8d36782c877ca97"}, "originalPosition": 171}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjU2MTc1NQ==", "bodyText": "Ack added a sleep", "url": "https://github.com/apache/beam/pull/12415#discussion_r472561755", "createdAt": "2020-08-19T00:12:52Z", "author": {"login": "rohdesamuel"}, "path": "sdks/python/apache_beam/runners/interactive/recording_manager.py", "diffHunk": "@@ -0,0 +1,330 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import absolute_import\n+\n+import logging\n+import threading\n+import time\n+import warnings\n+\n+import apache_beam as beam\n+from apache_beam.runners.interactive import background_caching_job as bcj\n+from apache_beam.runners.interactive import interactive_environment as ie\n+from apache_beam.runners.interactive import interactive_runner as ir\n+from apache_beam.runners.interactive import pipeline_fragment as pf\n+from apache_beam.runners.interactive import pipeline_instrument as pi\n+from apache_beam.runners.interactive import utils\n+from apache_beam.runners.interactive.options.capture_limiters import CountLimiter\n+from apache_beam.runners.interactive.options.capture_limiters import ProcessingTimeLimiter\n+\n+_LOGGER = logging.getLogger(__name__)\n+\n+PipelineState = beam.runners.runner.PipelineState\n+\n+\n+class ElementStream:\n+  \"\"\"A stream of elements from a given PCollection.\"\"\"\n+  def __init__(\n+      self,\n+      pcoll,  # type: beam.pvalue.PCollection\n+      var,  # type: str\n+      cache_key,  # type: str\n+      max_n,  # type: int\n+      max_duration_secs  # type: float\n+      ):\n+    self._pcoll = pcoll\n+    self._cache_key = cache_key\n+    self._pipeline = pcoll.pipeline\n+    self._var = var\n+    self._n = max_n\n+    self._duration_secs = max_duration_secs\n+\n+    # A small state variable that when True, indicates that no more new elements\n+    # will be yielded if read() is called again.\n+    self._done = False\n+\n+  def var(self):\n+    # type: () -> str\n+\n+    \"\"\"Returns the variable named that defined this PCollection.\"\"\"\n+    return self._var\n+\n+  def display_id(self, suffix):\n+    #Any type: (str) -> str\n+\n+    \"\"\"Returns a unique id able to be displayed in a web browser.\"\"\"\n+    return utils.obfuscate(self._cache_key, suffix)\n+\n+  def is_computed(self):\n+    # type: () -> boolean\n+\n+    \"\"\"Returns True if no more elements will be recorded.\"\"\"\n+    return self._pcoll in ie.current_env().computed_pcollections\n+\n+  def is_done(self):\n+    # type: () -> boolean\n+\n+    \"\"\"Returns True if no more new elements will be yielded.\"\"\"\n+    return self._done\n+\n+  def read(self, tail=True):\n+    # type: (boolean) -> Any\n+\n+    \"\"\"Reads the elements currently recorded.\"\"\"\n+\n+    # Get the cache manager and wait until the file exists.\n+    cache_manager = ie.current_env().get_cache_manager(self._pipeline)\n+    while not cache_manager.exists('full', self._cache_key):\n+      pass\n+\n+    # Retrieve the coder for the particular PCollection which will be used to\n+    # decode elements read from cache.\n+    coder = cache_manager.load_pcoder('full', self._cache_key)\n+\n+    # Read the elements from the cache.\n+    limiters = [\n+        CountLimiter(self._n), ProcessingTimeLimiter(self._duration_secs)\n+    ]\n+    if hasattr(cache_manager, 'read_multiple'):\n+      reader = cache_manager.read_multiple([('full', self._cache_key)],\n+                                           limiters=limiters,\n+                                           tail=tail)\n+    else:\n+      reader, _ = cache_manager.read('full', self._cache_key, limiters=limiters)\n+\n+    # Because a single TestStreamFileRecord can yield multiple elements, we\n+    # limit the count again here in the to_element_list call.\n+    for e in utils.to_element_list(reader,\n+                                   coder,\n+                                   include_window_info=True,\n+                                   n=self._n):\n+      yield e\n+\n+    # A limiter being triggered means that we have fulfilled the user's request.\n+    # This implies that reading from the cache again won't yield any new\n+    # elements. WLOG, this applies to the user pipeline being terminated.\n+    if any(l.is_triggered()\n+           for l in limiters) or ie.current_env().is_terminated(self._pipeline):\n+      self._done = True\n+\n+\n+class Recording:\n+  \"\"\"A group of PCollections from a given pipeline run.\"\"\"\n+  def __init__(\n+      self,\n+      user_pipeline,  # type: beam.Pipeline\n+      pcolls,  # type: List[beam.pvalue.PCollection]\n+      result,  # type: beam.runner.PipelineResult\n+      pipeline_instrument,  # type: beam.runners.interactive.PipelineInstrument\n+      max_n,  # type: int\n+      max_duration_secs  # type: float\n+      ):\n+\n+    self._user_pipeline = user_pipeline\n+    self._result = result\n+    self._pcolls = pcolls\n+\n+    pcoll_var = lambda pcoll: pipeline_instrument.cacheable_var_by_pcoll_id(\n+        pipeline_instrument.pcolls_to_pcoll_id.get(str(pcoll), None))\n+\n+    self._streams = {\n+        pcoll: ElementStream(\n+            pcoll,\n+            pcoll_var(pcoll),\n+            pipeline_instrument.cache_key(pcoll),\n+            max_n,\n+            max_duration_secs)\n+        for pcoll in pcolls\n+    }\n+    self._start = time.time()\n+    self._duration_secs = max_duration_secs\n+    self._set_computed = bcj.is_cache_complete(str(id(user_pipeline)))\n+\n+    # Run a separate thread for marking the PCollections done. This is because\n+    # the pipeline run may be asynchronous.\n+    self._mark_computed = threading.Thread(target=self._mark_all_computed)\n+    self._mark_computed.daemon = True\n+    self._mark_computed.start()\n+\n+  def _mark_all_computed(self):\n+    # type: () -> None\n+\n+    \"\"\"Marks all the PCollections upon a successful pipeline run.\"\"\"\n+    if not self._result:\n+      return\n+\n+    while not PipelineState.is_terminal(self._result.state):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjU1NDYzOA=="}, "originalCommit": {"oid": "13e0f36a97c867bc25d547f7b8d36782c877ca97"}, "originalPosition": 171}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk1ODM1OTk4OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/interactive/recording_manager.py", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQyMDowNjo1OVrOHDXO6w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQyMTowMDo0OVrOHDY6UA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzI4ODQyNw==", "bodyText": "Trying to understand what's going on. If we get here, the for loop above would've exited. What would it mean if this condition was not met thus self._done was not set to True?", "url": "https://github.com/apache/beam/pull/12415#discussion_r473288427", "createdAt": "2020-08-19T20:06:59Z", "author": {"login": "davidyan74"}, "path": "sdks/python/apache_beam/runners/interactive/recording_manager.py", "diffHunk": "@@ -0,0 +1,329 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import absolute_import\n+\n+import logging\n+import threading\n+import time\n+import warnings\n+\n+import apache_beam as beam\n+from apache_beam.runners.interactive import background_caching_job as bcj\n+from apache_beam.runners.interactive import interactive_environment as ie\n+from apache_beam.runners.interactive import interactive_runner as ir\n+from apache_beam.runners.interactive import pipeline_fragment as pf\n+from apache_beam.runners.interactive import pipeline_instrument as pi\n+from apache_beam.runners.interactive import utils\n+from apache_beam.runners.interactive.options.capture_limiters import CountLimiter\n+from apache_beam.runners.interactive.options.capture_limiters import ProcessingTimeLimiter\n+\n+_LOGGER = logging.getLogger(__name__)\n+\n+PipelineState = beam.runners.runner.PipelineState\n+\n+\n+class ElementStream:\n+  \"\"\"A stream of elements from a given PCollection.\"\"\"\n+  def __init__(\n+      self,\n+      pcoll,  # type: beam.pvalue.PCollection\n+      var,  # type: str\n+      cache_key,  # type: str\n+      max_n,  # type: int\n+      max_duration_secs  # type: float\n+      ):\n+    self._pcoll = pcoll\n+    self._cache_key = cache_key\n+    self._pipeline = pcoll.pipeline\n+    self._var = var\n+    self._n = max_n\n+    self._duration_secs = max_duration_secs\n+\n+    # A small state variable that when True, indicates that no more new elements\n+    # will be yielded if read() is called again.\n+    self._done = False\n+\n+  def var(self):\n+    # type: () -> str\n+\n+    \"\"\"Returns the variable named that defined this PCollection.\"\"\"\n+    return self._var\n+\n+  def display_id(self, suffix):\n+    #Any type: (str) -> str\n+\n+    \"\"\"Returns a unique id able to be displayed in a web browser.\"\"\"\n+    return utils.obfuscate(self._cache_key, suffix)\n+\n+  def is_computed(self):\n+    # type: () -> boolean\n+\n+    \"\"\"Returns True if no more elements will be recorded.\"\"\"\n+    return self._pcoll in ie.current_env().computed_pcollections\n+\n+  def is_done(self):\n+    # type: () -> boolean\n+\n+    \"\"\"Returns True if no more new elements will be yielded.\"\"\"\n+    return self._done\n+\n+  def read(self, tail=True):\n+    # type: (boolean) -> Any\n+\n+    \"\"\"Reads the elements currently recorded.\"\"\"\n+\n+    # Get the cache manager and wait until the file exists.\n+    cache_manager = ie.current_env().get_cache_manager(self._pipeline)\n+    while not cache_manager.exists('full', self._cache_key):\n+      time.sleep(0.5)\n+\n+    # Retrieve the coder for the particular PCollection which will be used to\n+    # decode elements read from cache.\n+    coder = cache_manager.load_pcoder('full', self._cache_key)\n+\n+    # Read the elements from the cache.\n+    limiters = [\n+        CountLimiter(self._n), ProcessingTimeLimiter(self._duration_secs)\n+    ]\n+    reader, _ = cache_manager.read('full', self._cache_key,\n+                                   limiters=limiters,\n+                                   tail=tail)\n+\n+    # Because a single TestStreamFileRecord can yield multiple elements, we\n+    # limit the count again here in the to_element_list call.\n+    for e in utils.to_element_list(reader,\n+                                   coder,\n+                                   include_window_info=True,\n+                                   n=self._n):\n+      yield e\n+\n+    # A limiter being triggered means that we have fulfilled the user's request.\n+    # This implies that reading from the cache again won't yield any new\n+    # elements. WLOG, this applies to the user pipeline being terminated.\n+    if any(l.is_triggered()\n+           for l in limiters) or ie.current_env().is_terminated(self._pipeline):\n+      self._done = True", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "520f8f4f00c884db219ae282dff65769a0a47b8b"}, "originalPosition": 120}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzMwODAxMg==", "bodyText": "In that case, it means that there are still more elements to be read from the cache.\nIf the pipeline isn't finished (and the limiters aren't triggered), the cache will yield an incomplete set of data. Thus, if a user of the ElementStream were to read from the cache again, the cache would yield more results.\nThere are two ways to exit from reading from cache: limiters are triggered, or all elements in the cache have been read. Just because all the elements in the cache have been read doesn't imply that the pipeline is done nor that the limiters have been triggered.", "url": "https://github.com/apache/beam/pull/12415#discussion_r473308012", "createdAt": "2020-08-19T20:45:34Z", "author": {"login": "rohdesamuel"}, "path": "sdks/python/apache_beam/runners/interactive/recording_manager.py", "diffHunk": "@@ -0,0 +1,329 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import absolute_import\n+\n+import logging\n+import threading\n+import time\n+import warnings\n+\n+import apache_beam as beam\n+from apache_beam.runners.interactive import background_caching_job as bcj\n+from apache_beam.runners.interactive import interactive_environment as ie\n+from apache_beam.runners.interactive import interactive_runner as ir\n+from apache_beam.runners.interactive import pipeline_fragment as pf\n+from apache_beam.runners.interactive import pipeline_instrument as pi\n+from apache_beam.runners.interactive import utils\n+from apache_beam.runners.interactive.options.capture_limiters import CountLimiter\n+from apache_beam.runners.interactive.options.capture_limiters import ProcessingTimeLimiter\n+\n+_LOGGER = logging.getLogger(__name__)\n+\n+PipelineState = beam.runners.runner.PipelineState\n+\n+\n+class ElementStream:\n+  \"\"\"A stream of elements from a given PCollection.\"\"\"\n+  def __init__(\n+      self,\n+      pcoll,  # type: beam.pvalue.PCollection\n+      var,  # type: str\n+      cache_key,  # type: str\n+      max_n,  # type: int\n+      max_duration_secs  # type: float\n+      ):\n+    self._pcoll = pcoll\n+    self._cache_key = cache_key\n+    self._pipeline = pcoll.pipeline\n+    self._var = var\n+    self._n = max_n\n+    self._duration_secs = max_duration_secs\n+\n+    # A small state variable that when True, indicates that no more new elements\n+    # will be yielded if read() is called again.\n+    self._done = False\n+\n+  def var(self):\n+    # type: () -> str\n+\n+    \"\"\"Returns the variable named that defined this PCollection.\"\"\"\n+    return self._var\n+\n+  def display_id(self, suffix):\n+    #Any type: (str) -> str\n+\n+    \"\"\"Returns a unique id able to be displayed in a web browser.\"\"\"\n+    return utils.obfuscate(self._cache_key, suffix)\n+\n+  def is_computed(self):\n+    # type: () -> boolean\n+\n+    \"\"\"Returns True if no more elements will be recorded.\"\"\"\n+    return self._pcoll in ie.current_env().computed_pcollections\n+\n+  def is_done(self):\n+    # type: () -> boolean\n+\n+    \"\"\"Returns True if no more new elements will be yielded.\"\"\"\n+    return self._done\n+\n+  def read(self, tail=True):\n+    # type: (boolean) -> Any\n+\n+    \"\"\"Reads the elements currently recorded.\"\"\"\n+\n+    # Get the cache manager and wait until the file exists.\n+    cache_manager = ie.current_env().get_cache_manager(self._pipeline)\n+    while not cache_manager.exists('full', self._cache_key):\n+      time.sleep(0.5)\n+\n+    # Retrieve the coder for the particular PCollection which will be used to\n+    # decode elements read from cache.\n+    coder = cache_manager.load_pcoder('full', self._cache_key)\n+\n+    # Read the elements from the cache.\n+    limiters = [\n+        CountLimiter(self._n), ProcessingTimeLimiter(self._duration_secs)\n+    ]\n+    reader, _ = cache_manager.read('full', self._cache_key,\n+                                   limiters=limiters,\n+                                   tail=tail)\n+\n+    # Because a single TestStreamFileRecord can yield multiple elements, we\n+    # limit the count again here in the to_element_list call.\n+    for e in utils.to_element_list(reader,\n+                                   coder,\n+                                   include_window_info=True,\n+                                   n=self._n):\n+      yield e\n+\n+    # A limiter being triggered means that we have fulfilled the user's request.\n+    # This implies that reading from the cache again won't yield any new\n+    # elements. WLOG, this applies to the user pipeline being terminated.\n+    if any(l.is_triggered()\n+           for l in limiters) or ie.current_env().is_terminated(self._pipeline):\n+      self._done = True", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzI4ODQyNw=="}, "originalCommit": {"oid": "520f8f4f00c884db219ae282dff65769a0a47b8b"}, "originalPosition": 120}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzMxMTU3OA==", "bodyText": "Got it. Can you also add a comment in the code to explain that condition?", "url": "https://github.com/apache/beam/pull/12415#discussion_r473311578", "createdAt": "2020-08-19T20:52:22Z", "author": {"login": "davidyan74"}, "path": "sdks/python/apache_beam/runners/interactive/recording_manager.py", "diffHunk": "@@ -0,0 +1,329 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import absolute_import\n+\n+import logging\n+import threading\n+import time\n+import warnings\n+\n+import apache_beam as beam\n+from apache_beam.runners.interactive import background_caching_job as bcj\n+from apache_beam.runners.interactive import interactive_environment as ie\n+from apache_beam.runners.interactive import interactive_runner as ir\n+from apache_beam.runners.interactive import pipeline_fragment as pf\n+from apache_beam.runners.interactive import pipeline_instrument as pi\n+from apache_beam.runners.interactive import utils\n+from apache_beam.runners.interactive.options.capture_limiters import CountLimiter\n+from apache_beam.runners.interactive.options.capture_limiters import ProcessingTimeLimiter\n+\n+_LOGGER = logging.getLogger(__name__)\n+\n+PipelineState = beam.runners.runner.PipelineState\n+\n+\n+class ElementStream:\n+  \"\"\"A stream of elements from a given PCollection.\"\"\"\n+  def __init__(\n+      self,\n+      pcoll,  # type: beam.pvalue.PCollection\n+      var,  # type: str\n+      cache_key,  # type: str\n+      max_n,  # type: int\n+      max_duration_secs  # type: float\n+      ):\n+    self._pcoll = pcoll\n+    self._cache_key = cache_key\n+    self._pipeline = pcoll.pipeline\n+    self._var = var\n+    self._n = max_n\n+    self._duration_secs = max_duration_secs\n+\n+    # A small state variable that when True, indicates that no more new elements\n+    # will be yielded if read() is called again.\n+    self._done = False\n+\n+  def var(self):\n+    # type: () -> str\n+\n+    \"\"\"Returns the variable named that defined this PCollection.\"\"\"\n+    return self._var\n+\n+  def display_id(self, suffix):\n+    #Any type: (str) -> str\n+\n+    \"\"\"Returns a unique id able to be displayed in a web browser.\"\"\"\n+    return utils.obfuscate(self._cache_key, suffix)\n+\n+  def is_computed(self):\n+    # type: () -> boolean\n+\n+    \"\"\"Returns True if no more elements will be recorded.\"\"\"\n+    return self._pcoll in ie.current_env().computed_pcollections\n+\n+  def is_done(self):\n+    # type: () -> boolean\n+\n+    \"\"\"Returns True if no more new elements will be yielded.\"\"\"\n+    return self._done\n+\n+  def read(self, tail=True):\n+    # type: (boolean) -> Any\n+\n+    \"\"\"Reads the elements currently recorded.\"\"\"\n+\n+    # Get the cache manager and wait until the file exists.\n+    cache_manager = ie.current_env().get_cache_manager(self._pipeline)\n+    while not cache_manager.exists('full', self._cache_key):\n+      time.sleep(0.5)\n+\n+    # Retrieve the coder for the particular PCollection which will be used to\n+    # decode elements read from cache.\n+    coder = cache_manager.load_pcoder('full', self._cache_key)\n+\n+    # Read the elements from the cache.\n+    limiters = [\n+        CountLimiter(self._n), ProcessingTimeLimiter(self._duration_secs)\n+    ]\n+    reader, _ = cache_manager.read('full', self._cache_key,\n+                                   limiters=limiters,\n+                                   tail=tail)\n+\n+    # Because a single TestStreamFileRecord can yield multiple elements, we\n+    # limit the count again here in the to_element_list call.\n+    for e in utils.to_element_list(reader,\n+                                   coder,\n+                                   include_window_info=True,\n+                                   n=self._n):\n+      yield e\n+\n+    # A limiter being triggered means that we have fulfilled the user's request.\n+    # This implies that reading from the cache again won't yield any new\n+    # elements. WLOG, this applies to the user pipeline being terminated.\n+    if any(l.is_triggered()\n+           for l in limiters) or ie.current_env().is_terminated(self._pipeline):\n+      self._done = True", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzI4ODQyNw=="}, "originalCommit": {"oid": "520f8f4f00c884db219ae282dff65769a0a47b8b"}, "originalPosition": 120}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzMxNTkyMA==", "bodyText": "Done, added a comment to the loop for reading from cache.", "url": "https://github.com/apache/beam/pull/12415#discussion_r473315920", "createdAt": "2020-08-19T21:00:49Z", "author": {"login": "rohdesamuel"}, "path": "sdks/python/apache_beam/runners/interactive/recording_manager.py", "diffHunk": "@@ -0,0 +1,329 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import absolute_import\n+\n+import logging\n+import threading\n+import time\n+import warnings\n+\n+import apache_beam as beam\n+from apache_beam.runners.interactive import background_caching_job as bcj\n+from apache_beam.runners.interactive import interactive_environment as ie\n+from apache_beam.runners.interactive import interactive_runner as ir\n+from apache_beam.runners.interactive import pipeline_fragment as pf\n+from apache_beam.runners.interactive import pipeline_instrument as pi\n+from apache_beam.runners.interactive import utils\n+from apache_beam.runners.interactive.options.capture_limiters import CountLimiter\n+from apache_beam.runners.interactive.options.capture_limiters import ProcessingTimeLimiter\n+\n+_LOGGER = logging.getLogger(__name__)\n+\n+PipelineState = beam.runners.runner.PipelineState\n+\n+\n+class ElementStream:\n+  \"\"\"A stream of elements from a given PCollection.\"\"\"\n+  def __init__(\n+      self,\n+      pcoll,  # type: beam.pvalue.PCollection\n+      var,  # type: str\n+      cache_key,  # type: str\n+      max_n,  # type: int\n+      max_duration_secs  # type: float\n+      ):\n+    self._pcoll = pcoll\n+    self._cache_key = cache_key\n+    self._pipeline = pcoll.pipeline\n+    self._var = var\n+    self._n = max_n\n+    self._duration_secs = max_duration_secs\n+\n+    # A small state variable that when True, indicates that no more new elements\n+    # will be yielded if read() is called again.\n+    self._done = False\n+\n+  def var(self):\n+    # type: () -> str\n+\n+    \"\"\"Returns the variable named that defined this PCollection.\"\"\"\n+    return self._var\n+\n+  def display_id(self, suffix):\n+    #Any type: (str) -> str\n+\n+    \"\"\"Returns a unique id able to be displayed in a web browser.\"\"\"\n+    return utils.obfuscate(self._cache_key, suffix)\n+\n+  def is_computed(self):\n+    # type: () -> boolean\n+\n+    \"\"\"Returns True if no more elements will be recorded.\"\"\"\n+    return self._pcoll in ie.current_env().computed_pcollections\n+\n+  def is_done(self):\n+    # type: () -> boolean\n+\n+    \"\"\"Returns True if no more new elements will be yielded.\"\"\"\n+    return self._done\n+\n+  def read(self, tail=True):\n+    # type: (boolean) -> Any\n+\n+    \"\"\"Reads the elements currently recorded.\"\"\"\n+\n+    # Get the cache manager and wait until the file exists.\n+    cache_manager = ie.current_env().get_cache_manager(self._pipeline)\n+    while not cache_manager.exists('full', self._cache_key):\n+      time.sleep(0.5)\n+\n+    # Retrieve the coder for the particular PCollection which will be used to\n+    # decode elements read from cache.\n+    coder = cache_manager.load_pcoder('full', self._cache_key)\n+\n+    # Read the elements from the cache.\n+    limiters = [\n+        CountLimiter(self._n), ProcessingTimeLimiter(self._duration_secs)\n+    ]\n+    reader, _ = cache_manager.read('full', self._cache_key,\n+                                   limiters=limiters,\n+                                   tail=tail)\n+\n+    # Because a single TestStreamFileRecord can yield multiple elements, we\n+    # limit the count again here in the to_element_list call.\n+    for e in utils.to_element_list(reader,\n+                                   coder,\n+                                   include_window_info=True,\n+                                   n=self._n):\n+      yield e\n+\n+    # A limiter being triggered means that we have fulfilled the user's request.\n+    # This implies that reading from the cache again won't yield any new\n+    # elements. WLOG, this applies to the user pipeline being terminated.\n+    if any(l.is_triggered()\n+           for l in limiters) or ie.current_env().is_terminated(self._pipeline):\n+      self._done = True", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzI4ODQyNw=="}, "originalCommit": {"oid": "520f8f4f00c884db219ae282dff65769a0a47b8b"}, "originalPosition": 120}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk1ODkyMTI3OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/interactive/recording_manager.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQyMjoxODo1MFrOHDc3TA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQyMjozNDozNVrOHDdlmg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzM4MDY4NA==", "bodyText": "Should this be an elif, since you shouldn't need to cancel twice?", "url": "https://github.com/apache/beam/pull/12415#discussion_r473380684", "createdAt": "2020-08-19T22:18:50Z", "author": {"login": "davidyan74"}, "path": "sdks/python/apache_beam/runners/interactive/recording_manager.py", "diffHunk": "@@ -0,0 +1,334 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import absolute_import\n+\n+import logging\n+import threading\n+import time\n+import warnings\n+\n+import apache_beam as beam\n+from apache_beam.runners.interactive import background_caching_job as bcj\n+from apache_beam.runners.interactive import interactive_environment as ie\n+from apache_beam.runners.interactive import interactive_runner as ir\n+from apache_beam.runners.interactive import pipeline_fragment as pf\n+from apache_beam.runners.interactive import pipeline_instrument as pi\n+from apache_beam.runners.interactive import utils\n+from apache_beam.runners.interactive.options.capture_limiters import CountLimiter\n+from apache_beam.runners.interactive.options.capture_limiters import ProcessingTimeLimiter\n+\n+_LOGGER = logging.getLogger(__name__)\n+\n+PipelineState = beam.runners.runner.PipelineState\n+\n+\n+class ElementStream:\n+  \"\"\"A stream of elements from a given PCollection.\"\"\"\n+  def __init__(\n+      self,\n+      pcoll,  # type: beam.pvalue.PCollection\n+      var,  # type: str\n+      cache_key,  # type: str\n+      max_n,  # type: int\n+      max_duration_secs  # type: float\n+      ):\n+    self._pcoll = pcoll\n+    self._cache_key = cache_key\n+    self._pipeline = pcoll.pipeline\n+    self._var = var\n+    self._n = max_n\n+    self._duration_secs = max_duration_secs\n+\n+    # A small state variable that when True, indicates that no more new elements\n+    # will be yielded if read() is called again.\n+    self._done = False\n+\n+  def var(self):\n+    # type: () -> str\n+\n+    \"\"\"Returns the variable named that defined this PCollection.\"\"\"\n+    return self._var\n+\n+  def display_id(self, suffix):\n+    #Any type: (str) -> str\n+\n+    \"\"\"Returns a unique id able to be displayed in a web browser.\"\"\"\n+    return utils.obfuscate(self._cache_key, suffix)\n+\n+  def is_computed(self):\n+    # type: () -> boolean\n+\n+    \"\"\"Returns True if no more elements will be recorded.\"\"\"\n+    return self._pcoll in ie.current_env().computed_pcollections\n+\n+  def is_done(self):\n+    # type: () -> boolean\n+\n+    \"\"\"Returns True if no more new elements will be yielded.\"\"\"\n+    return self._done\n+\n+  def read(self, tail=True):\n+    # type: (boolean) -> Any\n+\n+    \"\"\"Reads the elements currently recorded.\"\"\"\n+\n+    # Get the cache manager and wait until the file exists.\n+    cache_manager = ie.current_env().get_cache_manager(self._pipeline)\n+    while not cache_manager.exists('full', self._cache_key):\n+      time.sleep(0.5)\n+\n+    # Retrieve the coder for the particular PCollection which will be used to\n+    # decode elements read from cache.\n+    coder = cache_manager.load_pcoder('full', self._cache_key)\n+\n+    # Read the elements from the cache.\n+    limiters = [\n+        CountLimiter(self._n), ProcessingTimeLimiter(self._duration_secs)\n+    ]\n+    reader, _ = cache_manager.read('full', self._cache_key,\n+                                   limiters=limiters,\n+                                   tail=tail)\n+\n+    # Because a single TestStreamFileRecord can yield multiple elements, we\n+    # limit the count again here in the to_element_list call.\n+    #\n+    # There are two ways of exiting this loop either a limiter was triggered or\n+    # all elements from the cache were read. In the latter situation, it may be\n+    # the case that the pipeline was still running. Thus, another invocation of\n+    # `read` will yield new elements.\n+    for e in utils.to_element_list(reader,\n+                                   coder,\n+                                   include_window_info=True,\n+                                   n=self._n):\n+      yield e\n+\n+    # A limiter being triggered means that we have fulfilled the user's request.\n+    # This implies that reading from the cache again won't yield any new\n+    # elements. WLOG, this applies to the user pipeline being terminated.\n+    if any(l.is_triggered()\n+           for l in limiters) or ie.current_env().is_terminated(self._pipeline):\n+      self._done = True\n+\n+\n+class Recording:\n+  \"\"\"A group of PCollections from a given pipeline run.\"\"\"\n+  def __init__(\n+      self,\n+      user_pipeline,  # type: beam.Pipeline\n+      pcolls,  # type: List[beam.pvalue.PCollection]\n+      result,  # type: beam.runner.PipelineResult\n+      pipeline_instrument,  # type: beam.runners.interactive.PipelineInstrument\n+      max_n,  # type: int\n+      max_duration_secs  # type: float\n+      ):\n+\n+    self._user_pipeline = user_pipeline\n+    self._result = result\n+    self._pcolls = pcolls\n+\n+    pcoll_var = lambda pcoll: pipeline_instrument.cacheable_var_by_pcoll_id(\n+        pipeline_instrument.pcolls_to_pcoll_id.get(str(pcoll), None))\n+\n+    self._streams = {\n+        pcoll: ElementStream(\n+            pcoll,\n+            pcoll_var(pcoll),\n+            pipeline_instrument.cache_key(pcoll),\n+            max_n,\n+            max_duration_secs)\n+        for pcoll in pcolls\n+    }\n+    self._start = time.time()\n+    self._duration_secs = max_duration_secs\n+    self._set_computed = bcj.is_cache_complete(str(id(user_pipeline)))\n+\n+    # Run a separate thread for marking the PCollections done. This is because\n+    # the pipeline run may be asynchronous.\n+    self._mark_computed = threading.Thread(target=self._mark_all_computed)\n+    self._mark_computed.daemon = True\n+    self._mark_computed.start()\n+\n+  def _mark_all_computed(self):\n+    # type: () -> None\n+\n+    \"\"\"Marks all the PCollections upon a successful pipeline run.\"\"\"\n+    if not self._result:\n+      return\n+\n+    while not PipelineState.is_terminal(self._result.state):\n+      if time.time() - self._start >= self._duration_secs:\n+        self._result.cancel()\n+        self._result.wait_until_finish()\n+\n+      if all(s.is_done() for s in self._streams.values()):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d2323128781bf20aa48a8558e0cb027ae4556562"}, "originalPosition": 178}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzM5MjUzOA==", "bodyText": "Cancel is an idempotent operation so I didn't really think about it. I can change it to elif though", "url": "https://github.com/apache/beam/pull/12415#discussion_r473392538", "createdAt": "2020-08-19T22:34:35Z", "author": {"login": "rohdesamuel"}, "path": "sdks/python/apache_beam/runners/interactive/recording_manager.py", "diffHunk": "@@ -0,0 +1,334 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import absolute_import\n+\n+import logging\n+import threading\n+import time\n+import warnings\n+\n+import apache_beam as beam\n+from apache_beam.runners.interactive import background_caching_job as bcj\n+from apache_beam.runners.interactive import interactive_environment as ie\n+from apache_beam.runners.interactive import interactive_runner as ir\n+from apache_beam.runners.interactive import pipeline_fragment as pf\n+from apache_beam.runners.interactive import pipeline_instrument as pi\n+from apache_beam.runners.interactive import utils\n+from apache_beam.runners.interactive.options.capture_limiters import CountLimiter\n+from apache_beam.runners.interactive.options.capture_limiters import ProcessingTimeLimiter\n+\n+_LOGGER = logging.getLogger(__name__)\n+\n+PipelineState = beam.runners.runner.PipelineState\n+\n+\n+class ElementStream:\n+  \"\"\"A stream of elements from a given PCollection.\"\"\"\n+  def __init__(\n+      self,\n+      pcoll,  # type: beam.pvalue.PCollection\n+      var,  # type: str\n+      cache_key,  # type: str\n+      max_n,  # type: int\n+      max_duration_secs  # type: float\n+      ):\n+    self._pcoll = pcoll\n+    self._cache_key = cache_key\n+    self._pipeline = pcoll.pipeline\n+    self._var = var\n+    self._n = max_n\n+    self._duration_secs = max_duration_secs\n+\n+    # A small state variable that when True, indicates that no more new elements\n+    # will be yielded if read() is called again.\n+    self._done = False\n+\n+  def var(self):\n+    # type: () -> str\n+\n+    \"\"\"Returns the variable named that defined this PCollection.\"\"\"\n+    return self._var\n+\n+  def display_id(self, suffix):\n+    #Any type: (str) -> str\n+\n+    \"\"\"Returns a unique id able to be displayed in a web browser.\"\"\"\n+    return utils.obfuscate(self._cache_key, suffix)\n+\n+  def is_computed(self):\n+    # type: () -> boolean\n+\n+    \"\"\"Returns True if no more elements will be recorded.\"\"\"\n+    return self._pcoll in ie.current_env().computed_pcollections\n+\n+  def is_done(self):\n+    # type: () -> boolean\n+\n+    \"\"\"Returns True if no more new elements will be yielded.\"\"\"\n+    return self._done\n+\n+  def read(self, tail=True):\n+    # type: (boolean) -> Any\n+\n+    \"\"\"Reads the elements currently recorded.\"\"\"\n+\n+    # Get the cache manager and wait until the file exists.\n+    cache_manager = ie.current_env().get_cache_manager(self._pipeline)\n+    while not cache_manager.exists('full', self._cache_key):\n+      time.sleep(0.5)\n+\n+    # Retrieve the coder for the particular PCollection which will be used to\n+    # decode elements read from cache.\n+    coder = cache_manager.load_pcoder('full', self._cache_key)\n+\n+    # Read the elements from the cache.\n+    limiters = [\n+        CountLimiter(self._n), ProcessingTimeLimiter(self._duration_secs)\n+    ]\n+    reader, _ = cache_manager.read('full', self._cache_key,\n+                                   limiters=limiters,\n+                                   tail=tail)\n+\n+    # Because a single TestStreamFileRecord can yield multiple elements, we\n+    # limit the count again here in the to_element_list call.\n+    #\n+    # There are two ways of exiting this loop either a limiter was triggered or\n+    # all elements from the cache were read. In the latter situation, it may be\n+    # the case that the pipeline was still running. Thus, another invocation of\n+    # `read` will yield new elements.\n+    for e in utils.to_element_list(reader,\n+                                   coder,\n+                                   include_window_info=True,\n+                                   n=self._n):\n+      yield e\n+\n+    # A limiter being triggered means that we have fulfilled the user's request.\n+    # This implies that reading from the cache again won't yield any new\n+    # elements. WLOG, this applies to the user pipeline being terminated.\n+    if any(l.is_triggered()\n+           for l in limiters) or ie.current_env().is_terminated(self._pipeline):\n+      self._done = True\n+\n+\n+class Recording:\n+  \"\"\"A group of PCollections from a given pipeline run.\"\"\"\n+  def __init__(\n+      self,\n+      user_pipeline,  # type: beam.Pipeline\n+      pcolls,  # type: List[beam.pvalue.PCollection]\n+      result,  # type: beam.runner.PipelineResult\n+      pipeline_instrument,  # type: beam.runners.interactive.PipelineInstrument\n+      max_n,  # type: int\n+      max_duration_secs  # type: float\n+      ):\n+\n+    self._user_pipeline = user_pipeline\n+    self._result = result\n+    self._pcolls = pcolls\n+\n+    pcoll_var = lambda pcoll: pipeline_instrument.cacheable_var_by_pcoll_id(\n+        pipeline_instrument.pcolls_to_pcoll_id.get(str(pcoll), None))\n+\n+    self._streams = {\n+        pcoll: ElementStream(\n+            pcoll,\n+            pcoll_var(pcoll),\n+            pipeline_instrument.cache_key(pcoll),\n+            max_n,\n+            max_duration_secs)\n+        for pcoll in pcolls\n+    }\n+    self._start = time.time()\n+    self._duration_secs = max_duration_secs\n+    self._set_computed = bcj.is_cache_complete(str(id(user_pipeline)))\n+\n+    # Run a separate thread for marking the PCollections done. This is because\n+    # the pipeline run may be asynchronous.\n+    self._mark_computed = threading.Thread(target=self._mark_all_computed)\n+    self._mark_computed.daemon = True\n+    self._mark_computed.start()\n+\n+  def _mark_all_computed(self):\n+    # type: () -> None\n+\n+    \"\"\"Marks all the PCollections upon a successful pipeline run.\"\"\"\n+    if not self._result:\n+      return\n+\n+    while not PipelineState.is_terminal(self._result.state):\n+      if time.time() - self._start >= self._duration_secs:\n+        self._result.cancel()\n+        self._result.wait_until_finish()\n+\n+      if all(s.is_done() for s in self._streams.values()):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzM4MDY4NA=="}, "originalCommit": {"oid": "d2323128781bf20aa48a8558e0cb027ae4556562"}, "originalPosition": 178}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk1OTE0MDcxOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/interactive/recording_manager.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQyMzowOTowMFrOHDfIYQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQxNzozNDoxOFrOHEMUPQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzQxNzgyNQ==", "bodyText": "Is the Any some special type hint or a typo?", "url": "https://github.com/apache/beam/pull/12415#discussion_r473417825", "createdAt": "2020-08-19T23:09:00Z", "author": {"login": "KevinGG"}, "path": "sdks/python/apache_beam/runners/interactive/recording_manager.py", "diffHunk": "@@ -0,0 +1,334 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import absolute_import\n+\n+import logging\n+import threading\n+import time\n+import warnings\n+\n+import apache_beam as beam\n+from apache_beam.runners.interactive import background_caching_job as bcj\n+from apache_beam.runners.interactive import interactive_environment as ie\n+from apache_beam.runners.interactive import interactive_runner as ir\n+from apache_beam.runners.interactive import pipeline_fragment as pf\n+from apache_beam.runners.interactive import pipeline_instrument as pi\n+from apache_beam.runners.interactive import utils\n+from apache_beam.runners.interactive.options.capture_limiters import CountLimiter\n+from apache_beam.runners.interactive.options.capture_limiters import ProcessingTimeLimiter\n+\n+_LOGGER = logging.getLogger(__name__)\n+\n+PipelineState = beam.runners.runner.PipelineState\n+\n+\n+class ElementStream:\n+  \"\"\"A stream of elements from a given PCollection.\"\"\"\n+  def __init__(\n+      self,\n+      pcoll,  # type: beam.pvalue.PCollection\n+      var,  # type: str\n+      cache_key,  # type: str\n+      max_n,  # type: int\n+      max_duration_secs  # type: float\n+      ):\n+    self._pcoll = pcoll\n+    self._cache_key = cache_key\n+    self._pipeline = pcoll.pipeline\n+    self._var = var\n+    self._n = max_n\n+    self._duration_secs = max_duration_secs\n+\n+    # A small state variable that when True, indicates that no more new elements\n+    # will be yielded if read() is called again.\n+    self._done = False\n+\n+  def var(self):\n+    # type: () -> str\n+\n+    \"\"\"Returns the variable named that defined this PCollection.\"\"\"\n+    return self._var\n+\n+  def display_id(self, suffix):\n+    #Any type: (str) -> str", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6ca2ed7fb62a6a1cbee67e947ff51e7ad397831b"}, "originalPosition": 68}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE1ODE0MQ==", "bodyText": "Typo, good catch!", "url": "https://github.com/apache/beam/pull/12415#discussion_r474158141", "createdAt": "2020-08-20T17:34:18Z", "author": {"login": "rohdesamuel"}, "path": "sdks/python/apache_beam/runners/interactive/recording_manager.py", "diffHunk": "@@ -0,0 +1,334 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import absolute_import\n+\n+import logging\n+import threading\n+import time\n+import warnings\n+\n+import apache_beam as beam\n+from apache_beam.runners.interactive import background_caching_job as bcj\n+from apache_beam.runners.interactive import interactive_environment as ie\n+from apache_beam.runners.interactive import interactive_runner as ir\n+from apache_beam.runners.interactive import pipeline_fragment as pf\n+from apache_beam.runners.interactive import pipeline_instrument as pi\n+from apache_beam.runners.interactive import utils\n+from apache_beam.runners.interactive.options.capture_limiters import CountLimiter\n+from apache_beam.runners.interactive.options.capture_limiters import ProcessingTimeLimiter\n+\n+_LOGGER = logging.getLogger(__name__)\n+\n+PipelineState = beam.runners.runner.PipelineState\n+\n+\n+class ElementStream:\n+  \"\"\"A stream of elements from a given PCollection.\"\"\"\n+  def __init__(\n+      self,\n+      pcoll,  # type: beam.pvalue.PCollection\n+      var,  # type: str\n+      cache_key,  # type: str\n+      max_n,  # type: int\n+      max_duration_secs  # type: float\n+      ):\n+    self._pcoll = pcoll\n+    self._cache_key = cache_key\n+    self._pipeline = pcoll.pipeline\n+    self._var = var\n+    self._n = max_n\n+    self._duration_secs = max_duration_secs\n+\n+    # A small state variable that when True, indicates that no more new elements\n+    # will be yielded if read() is called again.\n+    self._done = False\n+\n+  def var(self):\n+    # type: () -> str\n+\n+    \"\"\"Returns the variable named that defined this PCollection.\"\"\"\n+    return self._var\n+\n+  def display_id(self, suffix):\n+    #Any type: (str) -> str", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzQxNzgyNQ=="}, "originalCommit": {"oid": "6ca2ed7fb62a6a1cbee67e947ff51e7ad397831b"}, "originalPosition": 68}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2NDgyNDU4OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/interactive/recording_manager.py", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQwMDoxNDo0NlrOHEXV7w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQxNzowODo0N1rOHE01bQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDMzODc5OQ==", "bodyText": "Why aren't you importing this class like a normal one?", "url": "https://github.com/apache/beam/pull/12415#discussion_r474338799", "createdAt": "2020-08-21T00:14:46Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/runners/interactive/recording_manager.py", "diffHunk": "@@ -0,0 +1,334 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import absolute_import\n+\n+import logging\n+import threading\n+import time\n+import warnings\n+\n+import apache_beam as beam\n+from apache_beam.runners.interactive import background_caching_job as bcj\n+from apache_beam.runners.interactive import interactive_environment as ie\n+from apache_beam.runners.interactive import interactive_runner as ir\n+from apache_beam.runners.interactive import pipeline_fragment as pf\n+from apache_beam.runners.interactive import pipeline_instrument as pi\n+from apache_beam.runners.interactive import utils\n+from apache_beam.runners.interactive.options.capture_limiters import CountLimiter\n+from apache_beam.runners.interactive.options.capture_limiters import ProcessingTimeLimiter\n+\n+_LOGGER = logging.getLogger(__name__)\n+\n+PipelineState = beam.runners.runner.PipelineState", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62bd42e6df56f3248abcde6b50065c9127f13551"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDgyMTk5Nw==", "bodyText": "Just inadvertently being silly here, changed to an import", "url": "https://github.com/apache/beam/pull/12415#discussion_r474821997", "createdAt": "2020-08-21T17:08:47Z", "author": {"login": "rohdesamuel"}, "path": "sdks/python/apache_beam/runners/interactive/recording_manager.py", "diffHunk": "@@ -0,0 +1,334 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import absolute_import\n+\n+import logging\n+import threading\n+import time\n+import warnings\n+\n+import apache_beam as beam\n+from apache_beam.runners.interactive import background_caching_job as bcj\n+from apache_beam.runners.interactive import interactive_environment as ie\n+from apache_beam.runners.interactive import interactive_runner as ir\n+from apache_beam.runners.interactive import pipeline_fragment as pf\n+from apache_beam.runners.interactive import pipeline_instrument as pi\n+from apache_beam.runners.interactive import utils\n+from apache_beam.runners.interactive.options.capture_limiters import CountLimiter\n+from apache_beam.runners.interactive.options.capture_limiters import ProcessingTimeLimiter\n+\n+_LOGGER = logging.getLogger(__name__)\n+\n+PipelineState = beam.runners.runner.PipelineState", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDMzODc5OQ=="}, "originalCommit": {"oid": "62bd42e6df56f3248abcde6b50065c9127f13551"}, "originalPosition": 37}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2NDgzMjczOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/interactive/recording_manager.py", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQwMDoxOTowOVrOHEXaqg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxODowNDo1NlrOHFweWA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDM0MDAxMA==", "bodyText": "I remember sleeping gave us trouble earlier. Does it make sense to write a method in cache_manager to wait without sleeping? (maybe on a lock or some such thing?)", "url": "https://github.com/apache/beam/pull/12415#discussion_r474340010", "createdAt": "2020-08-21T00:19:09Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/runners/interactive/recording_manager.py", "diffHunk": "@@ -0,0 +1,334 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import absolute_import\n+\n+import logging\n+import threading\n+import time\n+import warnings\n+\n+import apache_beam as beam\n+from apache_beam.runners.interactive import background_caching_job as bcj\n+from apache_beam.runners.interactive import interactive_environment as ie\n+from apache_beam.runners.interactive import interactive_runner as ir\n+from apache_beam.runners.interactive import pipeline_fragment as pf\n+from apache_beam.runners.interactive import pipeline_instrument as pi\n+from apache_beam.runners.interactive import utils\n+from apache_beam.runners.interactive.options.capture_limiters import CountLimiter\n+from apache_beam.runners.interactive.options.capture_limiters import ProcessingTimeLimiter\n+\n+_LOGGER = logging.getLogger(__name__)\n+\n+PipelineState = beam.runners.runner.PipelineState\n+\n+\n+class ElementStream:\n+  \"\"\"A stream of elements from a given PCollection.\"\"\"\n+  def __init__(\n+      self,\n+      pcoll,  # type: beam.pvalue.PCollection\n+      var,  # type: str\n+      cache_key,  # type: str\n+      max_n,  # type: int\n+      max_duration_secs  # type: float\n+      ):\n+    self._pcoll = pcoll\n+    self._cache_key = cache_key\n+    self._pipeline = pcoll.pipeline\n+    self._var = var\n+    self._n = max_n\n+    self._duration_secs = max_duration_secs\n+\n+    # A small state variable that when True, indicates that no more new elements\n+    # will be yielded if read() is called again.\n+    self._done = False\n+\n+  def var(self):\n+    # type: () -> str\n+\n+    \"\"\"Returns the variable named that defined this PCollection.\"\"\"\n+    return self._var\n+\n+  def display_id(self, suffix):\n+    # type: (str) -> str\n+\n+    \"\"\"Returns a unique id able to be displayed in a web browser.\"\"\"\n+    return utils.obfuscate(self._cache_key, suffix)\n+\n+  def is_computed(self):\n+    # type: () -> boolean\n+\n+    \"\"\"Returns True if no more elements will be recorded.\"\"\"\n+    return self._pcoll in ie.current_env().computed_pcollections\n+\n+  def is_done(self):\n+    # type: () -> boolean\n+\n+    \"\"\"Returns True if no more new elements will be yielded.\"\"\"\n+    return self._done\n+\n+  def read(self, tail=True):\n+    # type: (boolean) -> Any\n+\n+    \"\"\"Reads the elements currently recorded.\"\"\"\n+\n+    # Get the cache manager and wait until the file exists.\n+    cache_manager = ie.current_env().get_cache_manager(self._pipeline)\n+    while not cache_manager.exists('full', self._cache_key):\n+      time.sleep(0.5)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62bd42e6df56f3248abcde6b50065c9127f13551"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDg0NzA3OA==", "bodyText": "I looked into the code a bit deeper and the underlying cache waits for the file to exist. Also, I did run all of the test in 100 simultaneous different processes before pushing the PR. That's usually the best way to simulate the Jenkins environment.", "url": "https://github.com/apache/beam/pull/12415#discussion_r474847078", "createdAt": "2020-08-21T18:00:41Z", "author": {"login": "rohdesamuel"}, "path": "sdks/python/apache_beam/runners/interactive/recording_manager.py", "diffHunk": "@@ -0,0 +1,334 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import absolute_import\n+\n+import logging\n+import threading\n+import time\n+import warnings\n+\n+import apache_beam as beam\n+from apache_beam.runners.interactive import background_caching_job as bcj\n+from apache_beam.runners.interactive import interactive_environment as ie\n+from apache_beam.runners.interactive import interactive_runner as ir\n+from apache_beam.runners.interactive import pipeline_fragment as pf\n+from apache_beam.runners.interactive import pipeline_instrument as pi\n+from apache_beam.runners.interactive import utils\n+from apache_beam.runners.interactive.options.capture_limiters import CountLimiter\n+from apache_beam.runners.interactive.options.capture_limiters import ProcessingTimeLimiter\n+\n+_LOGGER = logging.getLogger(__name__)\n+\n+PipelineState = beam.runners.runner.PipelineState\n+\n+\n+class ElementStream:\n+  \"\"\"A stream of elements from a given PCollection.\"\"\"\n+  def __init__(\n+      self,\n+      pcoll,  # type: beam.pvalue.PCollection\n+      var,  # type: str\n+      cache_key,  # type: str\n+      max_n,  # type: int\n+      max_duration_secs  # type: float\n+      ):\n+    self._pcoll = pcoll\n+    self._cache_key = cache_key\n+    self._pipeline = pcoll.pipeline\n+    self._var = var\n+    self._n = max_n\n+    self._duration_secs = max_duration_secs\n+\n+    # A small state variable that when True, indicates that no more new elements\n+    # will be yielded if read() is called again.\n+    self._done = False\n+\n+  def var(self):\n+    # type: () -> str\n+\n+    \"\"\"Returns the variable named that defined this PCollection.\"\"\"\n+    return self._var\n+\n+  def display_id(self, suffix):\n+    # type: (str) -> str\n+\n+    \"\"\"Returns a unique id able to be displayed in a web browser.\"\"\"\n+    return utils.obfuscate(self._cache_key, suffix)\n+\n+  def is_computed(self):\n+    # type: () -> boolean\n+\n+    \"\"\"Returns True if no more elements will be recorded.\"\"\"\n+    return self._pcoll in ie.current_env().computed_pcollections\n+\n+  def is_done(self):\n+    # type: () -> boolean\n+\n+    \"\"\"Returns True if no more new elements will be yielded.\"\"\"\n+    return self._done\n+\n+  def read(self, tail=True):\n+    # type: (boolean) -> Any\n+\n+    \"\"\"Reads the elements currently recorded.\"\"\"\n+\n+    # Get the cache manager and wait until the file exists.\n+    cache_manager = ie.current_env().get_cache_manager(self._pipeline)\n+    while not cache_manager.exists('full', self._cache_key):\n+      time.sleep(0.5)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDM0MDAxMA=="}, "originalCommit": {"oid": "62bd42e6df56f3248abcde6b50065c9127f13551"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTc5OTEyOA==", "bodyText": "sounds good", "url": "https://github.com/apache/beam/pull/12415#discussion_r475799128", "createdAt": "2020-08-24T18:04:56Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/runners/interactive/recording_manager.py", "diffHunk": "@@ -0,0 +1,334 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import absolute_import\n+\n+import logging\n+import threading\n+import time\n+import warnings\n+\n+import apache_beam as beam\n+from apache_beam.runners.interactive import background_caching_job as bcj\n+from apache_beam.runners.interactive import interactive_environment as ie\n+from apache_beam.runners.interactive import interactive_runner as ir\n+from apache_beam.runners.interactive import pipeline_fragment as pf\n+from apache_beam.runners.interactive import pipeline_instrument as pi\n+from apache_beam.runners.interactive import utils\n+from apache_beam.runners.interactive.options.capture_limiters import CountLimiter\n+from apache_beam.runners.interactive.options.capture_limiters import ProcessingTimeLimiter\n+\n+_LOGGER = logging.getLogger(__name__)\n+\n+PipelineState = beam.runners.runner.PipelineState\n+\n+\n+class ElementStream:\n+  \"\"\"A stream of elements from a given PCollection.\"\"\"\n+  def __init__(\n+      self,\n+      pcoll,  # type: beam.pvalue.PCollection\n+      var,  # type: str\n+      cache_key,  # type: str\n+      max_n,  # type: int\n+      max_duration_secs  # type: float\n+      ):\n+    self._pcoll = pcoll\n+    self._cache_key = cache_key\n+    self._pipeline = pcoll.pipeline\n+    self._var = var\n+    self._n = max_n\n+    self._duration_secs = max_duration_secs\n+\n+    # A small state variable that when True, indicates that no more new elements\n+    # will be yielded if read() is called again.\n+    self._done = False\n+\n+  def var(self):\n+    # type: () -> str\n+\n+    \"\"\"Returns the variable named that defined this PCollection.\"\"\"\n+    return self._var\n+\n+  def display_id(self, suffix):\n+    # type: (str) -> str\n+\n+    \"\"\"Returns a unique id able to be displayed in a web browser.\"\"\"\n+    return utils.obfuscate(self._cache_key, suffix)\n+\n+  def is_computed(self):\n+    # type: () -> boolean\n+\n+    \"\"\"Returns True if no more elements will be recorded.\"\"\"\n+    return self._pcoll in ie.current_env().computed_pcollections\n+\n+  def is_done(self):\n+    # type: () -> boolean\n+\n+    \"\"\"Returns True if no more new elements will be yielded.\"\"\"\n+    return self._done\n+\n+  def read(self, tail=True):\n+    # type: (boolean) -> Any\n+\n+    \"\"\"Reads the elements currently recorded.\"\"\"\n+\n+    # Get the cache manager and wait until the file exists.\n+    cache_manager = ie.current_env().get_cache_manager(self._pipeline)\n+    while not cache_manager.exists('full', self._cache_key):\n+      time.sleep(0.5)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDM0MDAxMA=="}, "originalCommit": {"oid": "62bd42e6df56f3248abcde6b50065c9127f13551"}, "originalPosition": 93}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2NDg1NDAyOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/runners/interactive/recording_manager_test.py", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMVQwMDozMDo0MFrOHEXmvQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxODowNToyMlrOHFwfQQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDM0MzEwMQ==", "bodyText": "I'm a little confused about this test. Where does the pipeline run here?", "url": "https://github.com/apache/beam/pull/12415#discussion_r474343101", "createdAt": "2020-08-21T00:30:40Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/runners/interactive/recording_manager_test.py", "diffHunk": "@@ -0,0 +1,301 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#  http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import absolute_import\n+\n+import sys\n+import unittest\n+\n+import apache_beam as beam\n+from apache_beam import coders\n+from apache_beam.portability.api.beam_interactive_api_pb2 import TestStreamFileRecord\n+from apache_beam.runners.interactive import background_caching_job as bcj\n+from apache_beam.runners.interactive import interactive_beam as ib\n+from apache_beam.runners.interactive import interactive_environment as ie\n+from apache_beam.runners.interactive import pipeline_instrument as pi\n+from apache_beam.runners.interactive.interactive_runner import InteractiveRunner\n+from apache_beam.runners.interactive.recording_manager import ElementStream\n+from apache_beam.runners.interactive.recording_manager import Recording\n+from apache_beam.runners.interactive.recording_manager import RecordingManager\n+from apache_beam.runners.interactive.testing.test_cache_manager import FileRecordsBuilder\n+from apache_beam.runners.interactive.testing.test_cache_manager import InMemoryCache\n+from apache_beam.transforms.window import GlobalWindow\n+from apache_beam.utils.timestamp import MIN_TIMESTAMP\n+from apache_beam.utils.windowed_value import WindowedValue\n+\n+PipelineState = beam.runners.runner.PipelineState\n+\n+\n+class MockPipelineResult(beam.runners.runner.PipelineResult):\n+  \"\"\"Mock class for controlling a PipelineResult.\"\"\"\n+  def __init__(self):\n+    self._state = PipelineState.RUNNING\n+\n+  def wait_until_finish(self):\n+    pass\n+\n+  def set_state(self, state):\n+    self._state = state\n+\n+  @property\n+  def state(self):\n+    return self._state\n+\n+  def cancel(self):\n+    self._state = PipelineState.CANCELLED\n+\n+\n+class ElementStreamTest(unittest.TestCase):\n+  def setUp(self):\n+    ie.new_env()\n+\n+    self.cache = InMemoryCache()\n+    self.p = beam.Pipeline()\n+    self.pcoll = self.p | beam.Create([])\n+    self.cache_key = str(pi.CacheKey('pcoll', '', '', ''))\n+\n+    # Create a MockPipelineResult to control the state of a fake run of the\n+    # pipeline.\n+    self.mock_result = MockPipelineResult()\n+    ie.current_env().track_user_pipelines()\n+    ie.current_env().set_pipeline_result(self.p, self.mock_result)\n+    ie.current_env().set_cache_manager(self.cache, self.p)\n+\n+  def test_read(self):\n+    \"\"\"Test reading and if a stream is done no more elements are returned.\"\"\"\n+\n+    self.mock_result.set_state(PipelineState.DONE)\n+    self.cache.write(['expected'], 'full', self.cache_key)\n+    self.cache.save_pcoder(None, 'full', self.cache_key)\n+\n+    stream = ElementStream(\n+        self.pcoll, '', self.cache_key, max_n=1, max_duration_secs=1)\n+\n+    self.assertFalse(stream.is_done())\n+    self.assertEqual(list(stream.read())[0], 'expected')\n+    self.assertTrue(stream.is_done())\n+\n+  def test_done_if_terminated(self):\n+    \"\"\"Test that terminating the job sets the stream as done.\"\"\"\n+\n+    self.cache.write(['expected'], 'full', self.cache_key)\n+    self.cache.save_pcoder(None, 'full', self.cache_key)\n+\n+    stream = ElementStream(\n+        self.pcoll, '', self.cache_key, max_n=100, max_duration_secs=10)\n+\n+    self.assertFalse(stream.is_done())\n+    self.assertEqual(list(stream.read(tail=False))[0], 'expected')\n+\n+    # The limiters were not reached, so the stream is not done yet.\n+    self.assertFalse(stream.is_done())\n+\n+    self.mock_result.set_state(PipelineState.DONE)\n+    self.assertEqual(list(stream.read(tail=False))[0], 'expected')\n+\n+    # The underlying pipeline is terminated, so the stream won't yield new\n+    # elements.\n+    self.assertTrue(stream.is_done())\n+\n+  def test_read_n(self):\n+    \"\"\"Test that the stream only reads 'n' elements.\"\"\"\n+\n+    self.mock_result.set_state(PipelineState.DONE)\n+    self.cache.write(list(range(5)), 'full', self.cache_key)\n+    self.cache.save_pcoder(None, 'full', self.cache_key)\n+\n+    stream = ElementStream(\n+        self.pcoll, '', self.cache_key, max_n=1, max_duration_secs=1)\n+    self.assertEqual(list(stream.read()), [0])\n+    self.assertTrue(stream.is_done())\n+\n+    stream = ElementStream(\n+        self.pcoll, '', self.cache_key, max_n=2, max_duration_secs=1)\n+    self.assertEqual(list(stream.read()), [0, 1])\n+    self.assertTrue(stream.is_done())\n+\n+    stream = ElementStream(\n+        self.pcoll, '', self.cache_key, max_n=5, max_duration_secs=1)\n+    self.assertEqual(list(stream.read()), list(range(5)))\n+    self.assertTrue(stream.is_done())\n+\n+    # Test that if the user asks for more than in the cache it still returns.\n+    stream = ElementStream(\n+        self.pcoll, '', self.cache_key, max_n=10, max_duration_secs=1)\n+    self.assertEqual(list(stream.read()), list(range(5)))\n+    self.assertTrue(stream.is_done())\n+\n+  def test_read_duration(self):\n+    \"\"\"Test that the stream only reads a 'duration' of elements.\"\"\"\n+\n+    values = (FileRecordsBuilder(tag=self.cache_key)\n+              .advance_processing_time(1)\n+              .add_element(element=0, event_time_secs=0)\n+              .advance_processing_time(1)\n+              .add_element(element=1, event_time_secs=1)\n+              .advance_processing_time(1)\n+              .add_element(element=2, event_time_secs=3)\n+              .advance_processing_time(1)\n+              .add_element(element=3, event_time_secs=4)\n+              .advance_processing_time(1)\n+              .add_element(element=4, event_time_secs=5)\n+              .build()) # yapf: disable\n+\n+    self.mock_result.set_state(PipelineState.DONE)\n+    self.cache.write(values, 'full', self.cache_key)\n+    self.cache.save_pcoder(None, 'full', self.cache_key)\n+\n+    # The elements read from the cache are TestStreamFileRecord instances and\n+    # have the underlying elements encoded. This method decodes the elements\n+    # from the TestStreamFileRecord.\n+    def get_elements(events):\n+      coder = coders.FastPrimitivesCoder()\n+      elements = []\n+      for e in events:\n+        if not isinstance(e, TestStreamFileRecord):\n+          continue\n+\n+        if e.recorded_event.element_event:\n+          elements += ([\n+              coder.decode(el.encoded_element)\n+              for el in e.recorded_event.element_event.elements\n+          ])\n+      return elements\n+\n+    # The following tests a progression of reading different durations from the\n+    # cache.\n+    stream = ElementStream(\n+        self.pcoll, '', self.cache_key, max_n=100, max_duration_secs=1)\n+    self.assertSequenceEqual(get_elements(stream.read()), [0])\n+\n+    stream = ElementStream(\n+        self.pcoll, '', self.cache_key, max_n=100, max_duration_secs=2)\n+    self.assertSequenceEqual(get_elements(stream.read()), [0, 1])\n+\n+    stream = ElementStream(\n+        self.pcoll, '', self.cache_key, max_n=100, max_duration_secs=10)\n+    self.assertSequenceEqual(get_elements(stream.read()), [0, 1, 2, 3, 4])\n+\n+\n+class RecordingTest(unittest.TestCase):\n+  def setUp(self):\n+    ie.new_env()\n+\n+  @unittest.skipIf(\n+      sys.version_info < (3, 6, 0),\n+      'This test requires at least Python 3.6 to work.')\n+  def test_computed(self):\n+    \"\"\"Tests that a PCollection is marked as computed only in a complete state.\n+\n+    Because the background caching job is now long-lived, repeated runs of a\n+    PipelineFragment may yield different results for the same PCollection.\n+    \"\"\"\n+\n+    p = beam.Pipeline(InteractiveRunner())\n+    elems = p | beam.Create([0, 1, 2])\n+\n+    ib.watch(locals())\n+\n+    # Create a MockPipelineResult to control the state of a fake run of the\n+    # pipeline.\n+    mock_result = MockPipelineResult()\n+    ie.current_env().track_user_pipelines()\n+    ie.current_env().set_pipeline_result(p, mock_result)\n+\n+    # Create a mock BackgroundCachingJob that will control whether to set the\n+    # PCollections as computed or not.\n+    bcj_mock_result = MockPipelineResult()\n+    background_caching_job = bcj.BackgroundCachingJob(bcj_mock_result, [])\n+\n+    # Create a recording.\n+    recording = Recording(\n+        p, [elems],\n+        mock_result,\n+        pi.PipelineInstrument(p),\n+        max_n=10,\n+        max_duration_secs=60)\n+\n+    # The background caching job and the recording isn't done yet so there may\n+    # be more elements to be recorded.\n+    self.assertFalse(recording.is_computed())\n+    self.assertFalse(recording.computed())\n+    self.assertTrue(recording.uncomputed())\n+\n+    # The recording is finished but the background caching job is not. There\n+    # may still be more elements to record, or the intermediate PCollection may\n+    # have stopped caching in an incomplete state, e.g. before a window could\n+    # fire.\n+    mock_result.set_state(PipelineState.DONE)\n+    recording.wait_until_finish()\n+\n+    self.assertFalse(recording.is_computed())\n+    self.assertFalse(recording.computed())\n+    self.assertTrue(recording.uncomputed())\n+\n+    # The background caching job finished before we started a recording which\n+    # is a sure signal that there will be no more elements.\n+    bcj_mock_result.set_state(PipelineState.DONE)\n+    ie.current_env().set_background_caching_job(p, background_caching_job)\n+    recording = Recording(\n+        p, [elems],\n+        mock_result,\n+        pi.PipelineInstrument(p),\n+        max_n=10,\n+        max_duration_secs=60)\n+    recording.wait_until_finish()\n+\n+    # There are no more elements and the recording finished, meaning that the\n+    # intermediate PCollections are in a complete state. They can now be marked\n+    # as computed.\n+    self.assertTrue(recording.is_computed())\n+    self.assertTrue(recording.computed())\n+    self.assertFalse(recording.uncomputed())\n+\n+\n+class RecordingManagerTest(unittest.TestCase):\n+  def setUp(self):\n+    ie.new_env()\n+\n+  @unittest.skipIf(\n+      sys.version_info < (3, 6, 0),\n+      'This test requires at least Python 3.6 to work.')\n+  def test_basic_wordcount(self):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "62bd42e6df56f3248abcde6b50065c9127f13551"}, "originalPosition": 276}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDgyMzc5OQ==", "bodyText": "The RecordingManager.record method starts a PipelineFragment from the given pipeline. I added comments to make it more clear.", "url": "https://github.com/apache/beam/pull/12415#discussion_r474823799", "createdAt": "2020-08-21T17:12:34Z", "author": {"login": "rohdesamuel"}, "path": "sdks/python/apache_beam/runners/interactive/recording_manager_test.py", "diffHunk": "@@ -0,0 +1,301 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#  http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import absolute_import\n+\n+import sys\n+import unittest\n+\n+import apache_beam as beam\n+from apache_beam import coders\n+from apache_beam.portability.api.beam_interactive_api_pb2 import TestStreamFileRecord\n+from apache_beam.runners.interactive import background_caching_job as bcj\n+from apache_beam.runners.interactive import interactive_beam as ib\n+from apache_beam.runners.interactive import interactive_environment as ie\n+from apache_beam.runners.interactive import pipeline_instrument as pi\n+from apache_beam.runners.interactive.interactive_runner import InteractiveRunner\n+from apache_beam.runners.interactive.recording_manager import ElementStream\n+from apache_beam.runners.interactive.recording_manager import Recording\n+from apache_beam.runners.interactive.recording_manager import RecordingManager\n+from apache_beam.runners.interactive.testing.test_cache_manager import FileRecordsBuilder\n+from apache_beam.runners.interactive.testing.test_cache_manager import InMemoryCache\n+from apache_beam.transforms.window import GlobalWindow\n+from apache_beam.utils.timestamp import MIN_TIMESTAMP\n+from apache_beam.utils.windowed_value import WindowedValue\n+\n+PipelineState = beam.runners.runner.PipelineState\n+\n+\n+class MockPipelineResult(beam.runners.runner.PipelineResult):\n+  \"\"\"Mock class for controlling a PipelineResult.\"\"\"\n+  def __init__(self):\n+    self._state = PipelineState.RUNNING\n+\n+  def wait_until_finish(self):\n+    pass\n+\n+  def set_state(self, state):\n+    self._state = state\n+\n+  @property\n+  def state(self):\n+    return self._state\n+\n+  def cancel(self):\n+    self._state = PipelineState.CANCELLED\n+\n+\n+class ElementStreamTest(unittest.TestCase):\n+  def setUp(self):\n+    ie.new_env()\n+\n+    self.cache = InMemoryCache()\n+    self.p = beam.Pipeline()\n+    self.pcoll = self.p | beam.Create([])\n+    self.cache_key = str(pi.CacheKey('pcoll', '', '', ''))\n+\n+    # Create a MockPipelineResult to control the state of a fake run of the\n+    # pipeline.\n+    self.mock_result = MockPipelineResult()\n+    ie.current_env().track_user_pipelines()\n+    ie.current_env().set_pipeline_result(self.p, self.mock_result)\n+    ie.current_env().set_cache_manager(self.cache, self.p)\n+\n+  def test_read(self):\n+    \"\"\"Test reading and if a stream is done no more elements are returned.\"\"\"\n+\n+    self.mock_result.set_state(PipelineState.DONE)\n+    self.cache.write(['expected'], 'full', self.cache_key)\n+    self.cache.save_pcoder(None, 'full', self.cache_key)\n+\n+    stream = ElementStream(\n+        self.pcoll, '', self.cache_key, max_n=1, max_duration_secs=1)\n+\n+    self.assertFalse(stream.is_done())\n+    self.assertEqual(list(stream.read())[0], 'expected')\n+    self.assertTrue(stream.is_done())\n+\n+  def test_done_if_terminated(self):\n+    \"\"\"Test that terminating the job sets the stream as done.\"\"\"\n+\n+    self.cache.write(['expected'], 'full', self.cache_key)\n+    self.cache.save_pcoder(None, 'full', self.cache_key)\n+\n+    stream = ElementStream(\n+        self.pcoll, '', self.cache_key, max_n=100, max_duration_secs=10)\n+\n+    self.assertFalse(stream.is_done())\n+    self.assertEqual(list(stream.read(tail=False))[0], 'expected')\n+\n+    # The limiters were not reached, so the stream is not done yet.\n+    self.assertFalse(stream.is_done())\n+\n+    self.mock_result.set_state(PipelineState.DONE)\n+    self.assertEqual(list(stream.read(tail=False))[0], 'expected')\n+\n+    # The underlying pipeline is terminated, so the stream won't yield new\n+    # elements.\n+    self.assertTrue(stream.is_done())\n+\n+  def test_read_n(self):\n+    \"\"\"Test that the stream only reads 'n' elements.\"\"\"\n+\n+    self.mock_result.set_state(PipelineState.DONE)\n+    self.cache.write(list(range(5)), 'full', self.cache_key)\n+    self.cache.save_pcoder(None, 'full', self.cache_key)\n+\n+    stream = ElementStream(\n+        self.pcoll, '', self.cache_key, max_n=1, max_duration_secs=1)\n+    self.assertEqual(list(stream.read()), [0])\n+    self.assertTrue(stream.is_done())\n+\n+    stream = ElementStream(\n+        self.pcoll, '', self.cache_key, max_n=2, max_duration_secs=1)\n+    self.assertEqual(list(stream.read()), [0, 1])\n+    self.assertTrue(stream.is_done())\n+\n+    stream = ElementStream(\n+        self.pcoll, '', self.cache_key, max_n=5, max_duration_secs=1)\n+    self.assertEqual(list(stream.read()), list(range(5)))\n+    self.assertTrue(stream.is_done())\n+\n+    # Test that if the user asks for more than in the cache it still returns.\n+    stream = ElementStream(\n+        self.pcoll, '', self.cache_key, max_n=10, max_duration_secs=1)\n+    self.assertEqual(list(stream.read()), list(range(5)))\n+    self.assertTrue(stream.is_done())\n+\n+  def test_read_duration(self):\n+    \"\"\"Test that the stream only reads a 'duration' of elements.\"\"\"\n+\n+    values = (FileRecordsBuilder(tag=self.cache_key)\n+              .advance_processing_time(1)\n+              .add_element(element=0, event_time_secs=0)\n+              .advance_processing_time(1)\n+              .add_element(element=1, event_time_secs=1)\n+              .advance_processing_time(1)\n+              .add_element(element=2, event_time_secs=3)\n+              .advance_processing_time(1)\n+              .add_element(element=3, event_time_secs=4)\n+              .advance_processing_time(1)\n+              .add_element(element=4, event_time_secs=5)\n+              .build()) # yapf: disable\n+\n+    self.mock_result.set_state(PipelineState.DONE)\n+    self.cache.write(values, 'full', self.cache_key)\n+    self.cache.save_pcoder(None, 'full', self.cache_key)\n+\n+    # The elements read from the cache are TestStreamFileRecord instances and\n+    # have the underlying elements encoded. This method decodes the elements\n+    # from the TestStreamFileRecord.\n+    def get_elements(events):\n+      coder = coders.FastPrimitivesCoder()\n+      elements = []\n+      for e in events:\n+        if not isinstance(e, TestStreamFileRecord):\n+          continue\n+\n+        if e.recorded_event.element_event:\n+          elements += ([\n+              coder.decode(el.encoded_element)\n+              for el in e.recorded_event.element_event.elements\n+          ])\n+      return elements\n+\n+    # The following tests a progression of reading different durations from the\n+    # cache.\n+    stream = ElementStream(\n+        self.pcoll, '', self.cache_key, max_n=100, max_duration_secs=1)\n+    self.assertSequenceEqual(get_elements(stream.read()), [0])\n+\n+    stream = ElementStream(\n+        self.pcoll, '', self.cache_key, max_n=100, max_duration_secs=2)\n+    self.assertSequenceEqual(get_elements(stream.read()), [0, 1])\n+\n+    stream = ElementStream(\n+        self.pcoll, '', self.cache_key, max_n=100, max_duration_secs=10)\n+    self.assertSequenceEqual(get_elements(stream.read()), [0, 1, 2, 3, 4])\n+\n+\n+class RecordingTest(unittest.TestCase):\n+  def setUp(self):\n+    ie.new_env()\n+\n+  @unittest.skipIf(\n+      sys.version_info < (3, 6, 0),\n+      'This test requires at least Python 3.6 to work.')\n+  def test_computed(self):\n+    \"\"\"Tests that a PCollection is marked as computed only in a complete state.\n+\n+    Because the background caching job is now long-lived, repeated runs of a\n+    PipelineFragment may yield different results for the same PCollection.\n+    \"\"\"\n+\n+    p = beam.Pipeline(InteractiveRunner())\n+    elems = p | beam.Create([0, 1, 2])\n+\n+    ib.watch(locals())\n+\n+    # Create a MockPipelineResult to control the state of a fake run of the\n+    # pipeline.\n+    mock_result = MockPipelineResult()\n+    ie.current_env().track_user_pipelines()\n+    ie.current_env().set_pipeline_result(p, mock_result)\n+\n+    # Create a mock BackgroundCachingJob that will control whether to set the\n+    # PCollections as computed or not.\n+    bcj_mock_result = MockPipelineResult()\n+    background_caching_job = bcj.BackgroundCachingJob(bcj_mock_result, [])\n+\n+    # Create a recording.\n+    recording = Recording(\n+        p, [elems],\n+        mock_result,\n+        pi.PipelineInstrument(p),\n+        max_n=10,\n+        max_duration_secs=60)\n+\n+    # The background caching job and the recording isn't done yet so there may\n+    # be more elements to be recorded.\n+    self.assertFalse(recording.is_computed())\n+    self.assertFalse(recording.computed())\n+    self.assertTrue(recording.uncomputed())\n+\n+    # The recording is finished but the background caching job is not. There\n+    # may still be more elements to record, or the intermediate PCollection may\n+    # have stopped caching in an incomplete state, e.g. before a window could\n+    # fire.\n+    mock_result.set_state(PipelineState.DONE)\n+    recording.wait_until_finish()\n+\n+    self.assertFalse(recording.is_computed())\n+    self.assertFalse(recording.computed())\n+    self.assertTrue(recording.uncomputed())\n+\n+    # The background caching job finished before we started a recording which\n+    # is a sure signal that there will be no more elements.\n+    bcj_mock_result.set_state(PipelineState.DONE)\n+    ie.current_env().set_background_caching_job(p, background_caching_job)\n+    recording = Recording(\n+        p, [elems],\n+        mock_result,\n+        pi.PipelineInstrument(p),\n+        max_n=10,\n+        max_duration_secs=60)\n+    recording.wait_until_finish()\n+\n+    # There are no more elements and the recording finished, meaning that the\n+    # intermediate PCollections are in a complete state. They can now be marked\n+    # as computed.\n+    self.assertTrue(recording.is_computed())\n+    self.assertTrue(recording.computed())\n+    self.assertFalse(recording.uncomputed())\n+\n+\n+class RecordingManagerTest(unittest.TestCase):\n+  def setUp(self):\n+    ie.new_env()\n+\n+  @unittest.skipIf(\n+      sys.version_info < (3, 6, 0),\n+      'This test requires at least Python 3.6 to work.')\n+  def test_basic_wordcount(self):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDM0MzEwMQ=="}, "originalCommit": {"oid": "62bd42e6df56f3248abcde6b50065c9127f13551"}, "originalPosition": 276}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTc5OTM2MQ==", "bodyText": "makes sense. Thanks Sam!", "url": "https://github.com/apache/beam/pull/12415#discussion_r475799361", "createdAt": "2020-08-24T18:05:22Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/runners/interactive/recording_manager_test.py", "diffHunk": "@@ -0,0 +1,301 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#  http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+from __future__ import absolute_import\n+\n+import sys\n+import unittest\n+\n+import apache_beam as beam\n+from apache_beam import coders\n+from apache_beam.portability.api.beam_interactive_api_pb2 import TestStreamFileRecord\n+from apache_beam.runners.interactive import background_caching_job as bcj\n+from apache_beam.runners.interactive import interactive_beam as ib\n+from apache_beam.runners.interactive import interactive_environment as ie\n+from apache_beam.runners.interactive import pipeline_instrument as pi\n+from apache_beam.runners.interactive.interactive_runner import InteractiveRunner\n+from apache_beam.runners.interactive.recording_manager import ElementStream\n+from apache_beam.runners.interactive.recording_manager import Recording\n+from apache_beam.runners.interactive.recording_manager import RecordingManager\n+from apache_beam.runners.interactive.testing.test_cache_manager import FileRecordsBuilder\n+from apache_beam.runners.interactive.testing.test_cache_manager import InMemoryCache\n+from apache_beam.transforms.window import GlobalWindow\n+from apache_beam.utils.timestamp import MIN_TIMESTAMP\n+from apache_beam.utils.windowed_value import WindowedValue\n+\n+PipelineState = beam.runners.runner.PipelineState\n+\n+\n+class MockPipelineResult(beam.runners.runner.PipelineResult):\n+  \"\"\"Mock class for controlling a PipelineResult.\"\"\"\n+  def __init__(self):\n+    self._state = PipelineState.RUNNING\n+\n+  def wait_until_finish(self):\n+    pass\n+\n+  def set_state(self, state):\n+    self._state = state\n+\n+  @property\n+  def state(self):\n+    return self._state\n+\n+  def cancel(self):\n+    self._state = PipelineState.CANCELLED\n+\n+\n+class ElementStreamTest(unittest.TestCase):\n+  def setUp(self):\n+    ie.new_env()\n+\n+    self.cache = InMemoryCache()\n+    self.p = beam.Pipeline()\n+    self.pcoll = self.p | beam.Create([])\n+    self.cache_key = str(pi.CacheKey('pcoll', '', '', ''))\n+\n+    # Create a MockPipelineResult to control the state of a fake run of the\n+    # pipeline.\n+    self.mock_result = MockPipelineResult()\n+    ie.current_env().track_user_pipelines()\n+    ie.current_env().set_pipeline_result(self.p, self.mock_result)\n+    ie.current_env().set_cache_manager(self.cache, self.p)\n+\n+  def test_read(self):\n+    \"\"\"Test reading and if a stream is done no more elements are returned.\"\"\"\n+\n+    self.mock_result.set_state(PipelineState.DONE)\n+    self.cache.write(['expected'], 'full', self.cache_key)\n+    self.cache.save_pcoder(None, 'full', self.cache_key)\n+\n+    stream = ElementStream(\n+        self.pcoll, '', self.cache_key, max_n=1, max_duration_secs=1)\n+\n+    self.assertFalse(stream.is_done())\n+    self.assertEqual(list(stream.read())[0], 'expected')\n+    self.assertTrue(stream.is_done())\n+\n+  def test_done_if_terminated(self):\n+    \"\"\"Test that terminating the job sets the stream as done.\"\"\"\n+\n+    self.cache.write(['expected'], 'full', self.cache_key)\n+    self.cache.save_pcoder(None, 'full', self.cache_key)\n+\n+    stream = ElementStream(\n+        self.pcoll, '', self.cache_key, max_n=100, max_duration_secs=10)\n+\n+    self.assertFalse(stream.is_done())\n+    self.assertEqual(list(stream.read(tail=False))[0], 'expected')\n+\n+    # The limiters were not reached, so the stream is not done yet.\n+    self.assertFalse(stream.is_done())\n+\n+    self.mock_result.set_state(PipelineState.DONE)\n+    self.assertEqual(list(stream.read(tail=False))[0], 'expected')\n+\n+    # The underlying pipeline is terminated, so the stream won't yield new\n+    # elements.\n+    self.assertTrue(stream.is_done())\n+\n+  def test_read_n(self):\n+    \"\"\"Test that the stream only reads 'n' elements.\"\"\"\n+\n+    self.mock_result.set_state(PipelineState.DONE)\n+    self.cache.write(list(range(5)), 'full', self.cache_key)\n+    self.cache.save_pcoder(None, 'full', self.cache_key)\n+\n+    stream = ElementStream(\n+        self.pcoll, '', self.cache_key, max_n=1, max_duration_secs=1)\n+    self.assertEqual(list(stream.read()), [0])\n+    self.assertTrue(stream.is_done())\n+\n+    stream = ElementStream(\n+        self.pcoll, '', self.cache_key, max_n=2, max_duration_secs=1)\n+    self.assertEqual(list(stream.read()), [0, 1])\n+    self.assertTrue(stream.is_done())\n+\n+    stream = ElementStream(\n+        self.pcoll, '', self.cache_key, max_n=5, max_duration_secs=1)\n+    self.assertEqual(list(stream.read()), list(range(5)))\n+    self.assertTrue(stream.is_done())\n+\n+    # Test that if the user asks for more than in the cache it still returns.\n+    stream = ElementStream(\n+        self.pcoll, '', self.cache_key, max_n=10, max_duration_secs=1)\n+    self.assertEqual(list(stream.read()), list(range(5)))\n+    self.assertTrue(stream.is_done())\n+\n+  def test_read_duration(self):\n+    \"\"\"Test that the stream only reads a 'duration' of elements.\"\"\"\n+\n+    values = (FileRecordsBuilder(tag=self.cache_key)\n+              .advance_processing_time(1)\n+              .add_element(element=0, event_time_secs=0)\n+              .advance_processing_time(1)\n+              .add_element(element=1, event_time_secs=1)\n+              .advance_processing_time(1)\n+              .add_element(element=2, event_time_secs=3)\n+              .advance_processing_time(1)\n+              .add_element(element=3, event_time_secs=4)\n+              .advance_processing_time(1)\n+              .add_element(element=4, event_time_secs=5)\n+              .build()) # yapf: disable\n+\n+    self.mock_result.set_state(PipelineState.DONE)\n+    self.cache.write(values, 'full', self.cache_key)\n+    self.cache.save_pcoder(None, 'full', self.cache_key)\n+\n+    # The elements read from the cache are TestStreamFileRecord instances and\n+    # have the underlying elements encoded. This method decodes the elements\n+    # from the TestStreamFileRecord.\n+    def get_elements(events):\n+      coder = coders.FastPrimitivesCoder()\n+      elements = []\n+      for e in events:\n+        if not isinstance(e, TestStreamFileRecord):\n+          continue\n+\n+        if e.recorded_event.element_event:\n+          elements += ([\n+              coder.decode(el.encoded_element)\n+              for el in e.recorded_event.element_event.elements\n+          ])\n+      return elements\n+\n+    # The following tests a progression of reading different durations from the\n+    # cache.\n+    stream = ElementStream(\n+        self.pcoll, '', self.cache_key, max_n=100, max_duration_secs=1)\n+    self.assertSequenceEqual(get_elements(stream.read()), [0])\n+\n+    stream = ElementStream(\n+        self.pcoll, '', self.cache_key, max_n=100, max_duration_secs=2)\n+    self.assertSequenceEqual(get_elements(stream.read()), [0, 1])\n+\n+    stream = ElementStream(\n+        self.pcoll, '', self.cache_key, max_n=100, max_duration_secs=10)\n+    self.assertSequenceEqual(get_elements(stream.read()), [0, 1, 2, 3, 4])\n+\n+\n+class RecordingTest(unittest.TestCase):\n+  def setUp(self):\n+    ie.new_env()\n+\n+  @unittest.skipIf(\n+      sys.version_info < (3, 6, 0),\n+      'This test requires at least Python 3.6 to work.')\n+  def test_computed(self):\n+    \"\"\"Tests that a PCollection is marked as computed only in a complete state.\n+\n+    Because the background caching job is now long-lived, repeated runs of a\n+    PipelineFragment may yield different results for the same PCollection.\n+    \"\"\"\n+\n+    p = beam.Pipeline(InteractiveRunner())\n+    elems = p | beam.Create([0, 1, 2])\n+\n+    ib.watch(locals())\n+\n+    # Create a MockPipelineResult to control the state of a fake run of the\n+    # pipeline.\n+    mock_result = MockPipelineResult()\n+    ie.current_env().track_user_pipelines()\n+    ie.current_env().set_pipeline_result(p, mock_result)\n+\n+    # Create a mock BackgroundCachingJob that will control whether to set the\n+    # PCollections as computed or not.\n+    bcj_mock_result = MockPipelineResult()\n+    background_caching_job = bcj.BackgroundCachingJob(bcj_mock_result, [])\n+\n+    # Create a recording.\n+    recording = Recording(\n+        p, [elems],\n+        mock_result,\n+        pi.PipelineInstrument(p),\n+        max_n=10,\n+        max_duration_secs=60)\n+\n+    # The background caching job and the recording isn't done yet so there may\n+    # be more elements to be recorded.\n+    self.assertFalse(recording.is_computed())\n+    self.assertFalse(recording.computed())\n+    self.assertTrue(recording.uncomputed())\n+\n+    # The recording is finished but the background caching job is not. There\n+    # may still be more elements to record, or the intermediate PCollection may\n+    # have stopped caching in an incomplete state, e.g. before a window could\n+    # fire.\n+    mock_result.set_state(PipelineState.DONE)\n+    recording.wait_until_finish()\n+\n+    self.assertFalse(recording.is_computed())\n+    self.assertFalse(recording.computed())\n+    self.assertTrue(recording.uncomputed())\n+\n+    # The background caching job finished before we started a recording which\n+    # is a sure signal that there will be no more elements.\n+    bcj_mock_result.set_state(PipelineState.DONE)\n+    ie.current_env().set_background_caching_job(p, background_caching_job)\n+    recording = Recording(\n+        p, [elems],\n+        mock_result,\n+        pi.PipelineInstrument(p),\n+        max_n=10,\n+        max_duration_secs=60)\n+    recording.wait_until_finish()\n+\n+    # There are no more elements and the recording finished, meaning that the\n+    # intermediate PCollections are in a complete state. They can now be marked\n+    # as computed.\n+    self.assertTrue(recording.is_computed())\n+    self.assertTrue(recording.computed())\n+    self.assertFalse(recording.uncomputed())\n+\n+\n+class RecordingManagerTest(unittest.TestCase):\n+  def setUp(self):\n+    ie.new_env()\n+\n+  @unittest.skipIf(\n+      sys.version_info < (3, 6, 0),\n+      'This test requires at least Python 3.6 to work.')\n+  def test_basic_wordcount(self):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDM0MzEwMQ=="}, "originalCommit": {"oid": "62bd42e6df56f3248abcde6b50065c9127f13551"}, "originalPosition": 276}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 737, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}