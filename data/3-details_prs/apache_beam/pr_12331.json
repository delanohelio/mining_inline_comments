{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDU0Nzc5MDE3", "number": 12331, "title": "[BEAM-10601] DICOM API Beam IO connector", "bodyText": "Create a new Apache Beam I/O connector that helps customers facilitate the reading and writing data to the DICOM Healthcare API, it has three components:\n\nAn Ptransform that takes QIDO request and output result metadata as pcollection.\nAn I/O sink that takes DICOM files and writes them to DICOM store via API.\nAn Ptransform that convert pubsub message to Qido search request..\n\n\nR:@pabloem,\nCC:@dranderson1117,@DanKotowski\nPost-Commit Tests Status (on master branch)\n\n\n\nLang\nSDK\nDataflow\nFlink\nSamza\nSpark\nTwister2\n\n\n\n\nGo\n\n---\n\n---\n\n---\n\n\nJava\n\n\n\n\n\n\n\n\nPython\n\n\n\n---\n\n---\n\n\nXLang\n\n---\n\n---\n\n---\n\n\n\nPre-Commit Tests Status (on master branch)\n\n\n\n---\nJava\nPython\nGo\nWebsite\n\n\n\n\nNon-portable\n\n\n\n\n\n\nPortable\n---\n\n---\n---\n\n\n\nSee .test-infra/jenkins/README for trigger phrase, status and link of all Jenkins jobs.", "createdAt": "2020-07-21T22:27:27Z", "url": "https://github.com/apache/beam/pull/12331", "merged": true, "mergeCommit": {"oid": "b87bb64a44c40114779b05ab742b91cbc20e2754"}, "closed": true, "closedAt": "2020-08-03T21:30:08Z", "author": {"login": "George-Wu"}, "timelineItems": {"totalCount": 52, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc3HG8NAH2gAyNDU0Nzc5MDE3OjJmYTFlNzhhYmJiZjNhZWQ1MTg3MDhlMTE2MDNlM2RmZTE0OWVlNDQ=", "endCursor": "Y3Vyc29yOnYyOpPPAAABc7YEsqAH2gAyNDU0Nzc5MDE3OjBjY2MyYzVlNzdiZjkzNGEyZDVhMWQzYmNhNzg0YThhMDA1NTc0ZWM=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "2fa1e78abbbf3aed518708e11603e3dfe149ee44", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/2fa1e78abbbf3aed518708e11603e3dfe149ee44", "committedDate": "2020-07-21T14:28:50Z", "message": "First commit, after modifying codes based on design doc feedbacks 7/20"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "816c63a7634fd3446f5e70b97ef0fdadb688c46f", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/816c63a7634fd3446f5e70b97ef0fdadb688c46f", "committedDate": "2020-07-21T14:45:19Z", "message": "fix some comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "66fcda5e6b9ec31054ac3bf25f2e2d42449ff980", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/66fcda5e6b9ec31054ac3bf25f2e2d42449ff980", "committedDate": "2020-07-21T22:09:55Z", "message": "Merge pull request #1 from George-Wu/working\n\nFirst commit, after modifying codes based on design doc feedbacks 7/20"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "29f7b02c2399110d45282138fe3ce540e07ca2e4", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/29f7b02c2399110d45282138fe3ce540e07ca2e4", "committedDate": "2020-07-21T23:20:08Z", "message": "fix style and add license"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7401988ea4aec35737e22512f1333f3fc7626c71", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/7401988ea4aec35737e22512f1333f3fc7626c71", "committedDate": "2020-07-21T23:21:49Z", "message": "Merge pull request #2 from George-Wu/working\n\nfix style and add license"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e5d825afbc0b829874bc667c36860848e6ba27cf", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/e5d825afbc0b829874bc667c36860848e6ba27cf", "committedDate": "2020-07-21T23:47:37Z", "message": "fix style lint"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e32bf7e1faae7599c3ffcd76dbbe0adf8e6ce9da", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/e32bf7e1faae7599c3ffcd76dbbe0adf8e6ce9da", "committedDate": "2020-07-21T23:48:45Z", "message": "Merge pull request #3 from George-Wu/working\n\nfix style lint"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fae3482d9dd65aed86dcab30c5ec805021af1a5f", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/fae3482d9dd65aed86dcab30c5ec805021af1a5f", "committedDate": "2020-07-22T01:30:45Z", "message": "minor fix"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0de3c2c11533494808af53267cbe04f6e4042bf8", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/0de3c2c11533494808af53267cbe04f6e4042bf8", "committedDate": "2020-07-22T13:44:56Z", "message": "add pagination support"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUzMzgyNzg0", "url": "https://github.com/apache/beam/pull/12331#pullrequestreview-453382784", "createdAt": "2020-07-22T14:37:57Z", "commit": {"oid": "7401988ea4aec35737e22512f1333f3fc7626c71"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxNDozNzo1N1rOG1lgBw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxNDo0NToyNlrOG1l2hA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODg0MjExOQ==", "bodyText": "Can you please add more descriptive comments for classes and methods.", "url": "https://github.com/apache/beam/pull/12331#discussion_r458842119", "createdAt": "2020-07-22T14:37:57Z", "author": {"login": "DanKotowski"}, "path": "sdks/python/apache_beam/io/gcp/dicomio.py", "diffHunk": "@@ -248,31 +268,31 @@ def __init__(self, destination_dict, credential=None):\n     self.destination_dict = destination_dict\n \n   def expand(self, pcoll):\n-    return pcoll | beam.ParDo(StoreInstanceBytes(self.destination_dict, self.credential))\n+    return pcoll | beam.ParDo(\n+        StoreInstanceBytes(self.destination_dict, self.credential))\n \n \n class StoreInstanceBytes(beam.DoFn):\n   \"\"\"A DoFn execute every file input.\"\"\"", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7401988ea4aec35737e22512f1333f3fc7626c71"}, "originalPosition": 182}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODg0NDk4MA==", "bodyText": "You are using a few magic numbers here can you please replace them with named constants.", "url": "https://github.com/apache/beam/pull/12331#discussion_r458844980", "createdAt": "2020-07-22T14:41:44Z", "author": {"login": "DanKotowski"}, "path": "sdks/python/apache_beam/io/gcp/dicomio.py", "diffHunk": "@@ -157,27 +172,33 @@ class ConvertPubsubToQido(beam.DoFn):\n   def process(self, element):\n     # Check if all required keys present.\n     required_keys = [\n-      'projects', 'locations', 'datasets', 'dicomStores', 'dicomWeb',\n-      'studies', 'series', 'instances'\n-      ]\n-    \n+        'projects',\n+        'locations',\n+        'datasets',\n+        'dicomStores',\n+        'dicomWeb',\n+        'studies',\n+        'series',\n+        'instances'\n+    ]\n+\n     entries = element.split('/')\n     valid = True\n-    \n+\n     if len(entries) != 15:\n       valid = False\n-    \n+\n     if valid:\n       # check if the position of keys are correct\n       for i in range(5):\n-        if required_keys[i] != entries[i*2]:\n-            valid = False\n-            break\n-      for i in range(5,8):\n-        if required_keys[i] != entries[i*2 - 1]:\n-            valid = False\n-            break\n-    \n+        if required_keys[i] != entries[i * 2]:\n+          valid = False\n+          break\n+      for i in range(5, 8):\n+        if required_keys[i] != entries[i * 2 - 1]:\n+          valid = False\n+          break\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7401988ea4aec35737e22512f1333f3fc7626c71"}, "originalPosition": 141}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODg0Nzg3Ng==", "bodyText": "You could probably convert this to an early exit instead of adding  the extra if valid check.", "url": "https://github.com/apache/beam/pull/12331#discussion_r458847876", "createdAt": "2020-07-22T14:45:26Z", "author": {"login": "DanKotowski"}, "path": "sdks/python/apache_beam/io/gcp/dicomio.py", "diffHunk": "@@ -157,27 +172,33 @@ class ConvertPubsubToQido(beam.DoFn):\n   def process(self, element):\n     # Check if all required keys present.\n     required_keys = [\n-      'projects', 'locations', 'datasets', 'dicomStores', 'dicomWeb',\n-      'studies', 'series', 'instances'\n-      ]\n-    \n+        'projects',\n+        'locations',\n+        'datasets',\n+        'dicomStores',\n+        'dicomWeb',\n+        'studies',\n+        'series',\n+        'instances'\n+    ]\n+\n     entries = element.split('/')\n     valid = True\n-    \n+\n     if len(entries) != 15:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7401988ea4aec35737e22512f1333f3fc7626c71"}, "originalPosition": 119}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "30e8ca1b89b1d59985ea29ccec69bd5cbd9b5218", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/30e8ca1b89b1d59985ea29ccec69bd5cbd9b5218", "committedDate": "2020-07-23T16:47:34Z", "message": "add file path support to storeinstance"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a0e1bcbe5245a3eb1db53b5b55b29d31872a21b0", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/a0e1bcbe5245a3eb1db53b5b55b29d31872a21b0", "committedDate": "2020-07-23T16:51:54Z", "message": "Merge pull request #4 from George-Wu/work2\n\nAdd path support to storeInstance, fix several style problems"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU0NDEzMjA1", "url": "https://github.com/apache/beam/pull/12331#pullrequestreview-454413205", "createdAt": "2020-07-23T18:59:07Z", "commit": {"oid": "7401988ea4aec35737e22512f1333f3fc7626c71"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QxODo1OTowN1rOG2Xm7g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QxODo1OTowN1rOG2Xm7g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTY2MzA4Ng==", "bodyText": "Is pagination going to be included in this PR\nIf not, maybe create Jira issue and link to comment", "url": "https://github.com/apache/beam/pull/12331#discussion_r459663086", "createdAt": "2020-07-23T18:59:07Z", "author": {"login": "dranderson1117"}, "path": "sdks/python/apache_beam/io/gcp/dicomclient.py", "diffHunk": "@@ -0,0 +1,94 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+import google.auth\n+import json\n+from google.auth.transport import requests\n+\n+\n+# Todo: add pagination support to client", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7401988ea4aec35737e22512f1333f3fc7626c71"}, "originalPosition": 23}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU0NDE0NTUw", "url": "https://github.com/apache/beam/pull/12331#pullrequestreview-454414550", "createdAt": "2020-07-23T19:01:04Z", "commit": {"oid": "7401988ea4aec35737e22512f1333f3fc7626c71"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QxOTowMTowNFrOG2XrBw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yM1QxOTowMTowNFrOG2XrBw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1OTY2NDEzNQ==", "bodyText": "hasfollowing -> has the following", "url": "https://github.com/apache/beam/pull/12331#discussion_r459664135", "createdAt": "2020-07-23T19:01:04Z", "author": {"login": "dranderson1117"}, "path": "sdks/python/apache_beam/io/gcp/dicomio.py", "diffHunk": "@@ -0,0 +1,300 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+import apache_beam as beam\n+import google.auth\n+import json\n+from dicomclient import DicomApiHttpClient\n+from apache_beam.options.pipeline_options import PipelineOptions\n+from apache_beam.transforms import PTransform\n+from apache_beam.io.filesystem import BeamIOError\n+\n+\n+class DicomSearch(PTransform):\n+  \"\"\"A ``PTransform`` for QIDO search metadata from Cloud DICOM api.\n+    It takes Pcollection of dicts as input and return a Pcollection \n+    of dict as results:\n+    INPUT:\n+    The input dict represents DICOM web path parameter, which hasfollowing ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7401988ea4aec35737e22512f1333f3fc7626c71"}, "originalPosition": 32}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5ba1a9b4bd863ab88f4ea0cebe265ad8b3b8e75c", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/5ba1a9b4bd863ab88f4ea0cebe265ad8b3b8e75c", "committedDate": "2020-07-23T19:44:42Z", "message": "fix some typos"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8986c5a8a8173246bd1efb3412e2c6d7db46214c", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/8986c5a8a8173246bd1efb3412e2c6d7db46214c", "committedDate": "2020-07-23T19:55:18Z", "message": "Merge pull request #5 from George-Wu/work2\n\nfix some typos"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "432480b9e4b313de5c2e6ad8a5e0c39f78a8275c", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/432480b9e4b313de5c2e6ad8a5e0c39f78a8275c", "committedDate": "2020-07-24T13:47:17Z", "message": "removed path support and added fileio supports"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9289cf5c195ce993eea97d85828870c355251625", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/9289cf5c195ce993eea97d85828870c355251625", "committedDate": "2020-07-24T13:49:32Z", "message": "Merge pull request #6 from George-Wu/work2\n\nremoved path support and added fileio supports"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "192ac8dec87753296796818c1f70feb967ecea44", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/192ac8dec87753296796818c1f70feb967ecea44", "committedDate": "2020-07-24T15:23:36Z", "message": "fix bug in client"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "045669b4c5a68db0df7625734160aabc6a652a63", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/045669b4c5a68db0df7625734160aabc6a652a63", "committedDate": "2020-07-27T14:38:11Z", "message": "add unit tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "46ff23589768a718e4eb367ef0706928f3721473", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/46ff23589768a718e4eb367ef0706928f3721473", "committedDate": "2020-07-27T14:39:53Z", "message": "Merge pull request #7 from George-Wu/work2\n\nAdd unit tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "60f96aae1634adbd12f306546ef43b4b96433a8f", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/60f96aae1634adbd12f306546ef43b4b96433a8f", "committedDate": "2020-07-27T14:43:14Z", "message": "Update dicomio_test.py\n\nfix typo"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a1621cb00a5f3036614daefdf1105b24aeb23d88", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/a1621cb00a5f3036614daefdf1105b24aeb23d88", "committedDate": "2020-07-27T21:12:59Z", "message": "fix patching"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "05d1ee20a7f30bb876cb41235b8d1bb058663aba", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/05d1ee20a7f30bb876cb41235b8d1bb058663aba", "committedDate": "2020-07-27T21:55:20Z", "message": "remove non-Non-ASCII character"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "803cfcb12ff35c26197a7f61a45305e99bdcbb4c", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/803cfcb12ff35c26197a7f61a45305e99bdcbb4c", "committedDate": "2020-07-27T22:52:29Z", "message": "add google.auth support and fix client"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "122383da59a65d3876290eb7b1519be9b7a030d4", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/122383da59a65d3876290eb7b1519be9b7a030d4", "committedDate": "2020-07-28T00:54:56Z", "message": "try inject dependency"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b1f8e9e8d9f75382bd20e5f9ea3af7869c3c2a3a", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/b1f8e9e8d9f75382bd20e5f9ea3af7869c3c2a3a", "committedDate": "2020-07-28T05:40:26Z", "message": "roll back injection"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fb42e317b529408cc5c926a159d2081f8c42a4a1", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/fb42e317b529408cc5c926a159d2081f8c42a4a1", "committedDate": "2020-07-28T19:12:51Z", "message": "add dependency"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "abf7600d697ffbd59ef7a7fdddea791843467715", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/abf7600d697ffbd59ef7a7fdddea791843467715", "committedDate": "2020-07-28T19:43:48Z", "message": "change place to inject"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5d664ebf7585f55abcc9b5a63334f186a1f2a6b1", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/5d664ebf7585f55abcc9b5a63334f186a1f2a6b1", "committedDate": "2020-07-28T21:40:58Z", "message": "change the order"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU3MDU0NzI0", "url": "https://github.com/apache/beam/pull/12331#pullrequestreview-457054724", "createdAt": "2020-07-28T21:51:47Z", "commit": {"oid": "5d664ebf7585f55abcc9b5a63334f186a1f2a6b1"}, "state": "COMMENTED", "comments": {"totalCount": 13, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQyMTo1MTo0N1rOG4gcvw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQyMzoxNTo1OFrOG4i-Jw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTkwNTA4Nw==", "bodyText": "several?", "url": "https://github.com/apache/beam/pull/12331#discussion_r461905087", "createdAt": "2020-07-28T21:51:47Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/dicomio.py", "diffHunk": "@@ -0,0 +1,419 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"DICOM io connector\n+This module implements serval tools to facilitate the interaction between", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5d664ebf7585f55abcc9b5a63334f186a1f2a6b1"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTkwNTIwNA==", "bodyText": "Capitalize 'Beam', please", "url": "https://github.com/apache/beam/pull/12331#discussion_r461905204", "createdAt": "2020-07-28T21:51:58Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/dicomio.py", "diffHunk": "@@ -0,0 +1,419 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"DICOM io connector\n+This module implements serval tools to facilitate the interaction between\n+a Google Cloud Healthcare DICOM store and a beam pipeline.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5d664ebf7585f55abcc9b5a63334f186a1f2a6b1"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTkwNTc1MA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            DICOM io connector can be used to search metadata or store DICOM files.\n          \n          \n            \n            The DICOM IO connector can be used to search metadata or write DICOM files to GCS.\n          \n      \n    \n    \n  \n\nWrite DICOM files to GCS - is that the right terminology?", "url": "https://github.com/apache/beam/pull/12331#discussion_r461905750", "createdAt": "2020-07-28T21:52:44Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/dicomio.py", "diffHunk": "@@ -0,0 +1,419 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"DICOM io connector\n+This module implements serval tools to facilitate the interaction between\n+a Google Cloud Healthcare DICOM store and a beam pipeline.\n+For more details on DICOM store and API:\n+https://cloud.google.com/healthcare/docs/how-tos/dicom\n+DICOM io connector can be used to search metadata or store DICOM files.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5d664ebf7585f55abcc9b5a63334f186a1f2a6b1"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTkyNjU2NA==", "bodyText": "Please replace Pcollection with PCollection throughout the documentation in this file.", "url": "https://github.com/apache/beam/pull/12331#discussion_r461926564", "createdAt": "2020-07-28T22:21:24Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/dicomio.py", "diffHunk": "@@ -0,0 +1,419 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"DICOM io connector\n+This module implements serval tools to facilitate the interaction between\n+a Google Cloud Healthcare DICOM store and a beam pipeline.\n+For more details on DICOM store and API:\n+https://cloud.google.com/healthcare/docs/how-tos/dicom\n+DICOM io connector can be used to search metadata or store DICOM files.\n+When used together with Google Pubsub message connector, a PTransform\n+implemented in this module can be used to convert pubsub messages to search\n+requests. Since Traceability is crucial for healthcare API users, every\n+input or error message will be recorded in the output of the DICOM io\n+connector. As a result, every PTransform in this module will return a\n+Pcollection of dict that encodes results and detailed error messages.\n+\n+Search instance's metadata (QIDO request)\n+===================================================\n+DicomSearch() wraps the QIDO request client and supports 3 levels of search.\n+Users should specify the level by setting the 'search_type' entry in the input\n+dict. They can also refine the search by adding tags to filter the results using\n+the 'params' entry. Here is a sample usage:\n+\n+  with Pipeline() as p:\n+    input_dict = p | beam.Create([\n+      {'project_id': 'abc123', 'type': 'instances',...},\n+      {'project_id': 'dicom_go', 'type': 'series',...}\n+    ])\n+    results = input_dict| io.gcp.DicomSearch()\n+    results | 'print successful search' >> beam.Map(\n+        lambda x: print(x['result'] if x['success'] else None))\n+    results | 'print failed search' >> beam.Map(\n+        lambda x: print(x['result'] if not x['success'] else None))\n+\n+In the example above, successful qido search results and error messages for\n+failed requests are printed. When used in real life, user can choose to filter\n+those data and output them to wherever they want.\n+\n+Convert DICOM Pubsub message to Qido search request\n+===================================================\n+Healthcare API users might use Beam's Pubsub streaming pipeline to monitor the\n+store operations (new DICOM file) in a DICOM storage. Pubsub message encodes\n+DICOM a web store path as well as instance ids. If users are interested in\n+getting new instance's metadata, they can use PubsubToQido() to convert the\n+message into Qido Search dict then use DicomSearch(). Here is a sample usage:\n+\n+  pipeline_options = PipelineOptions()\n+  pipeline_options.view_as(StandardOptions).streaming = True\n+  with beam.Pipeline(options=pipeline_options) as p:\n+    pubsub = p | beam.io.ReadStringFromPubsub(subscription='a_dicom_store')\n+    results = pubsub | PubsubToQido()\n+    success = results | 'filter message' >> beam.Filter(lambda x: x['success'])\n+    qido_dict = success | 'get qido request' >> beam.Map(lambda x: x['result'])\n+    metadata = qido_dict | DicomSearch()\n+\n+In the example above, the pipeline is listening to a pubsub topic and waiting\n+for messages from DICOM API. When a new DICOM file comes into the storage, the\n+pipeline will receive a pubsub message, convert it to a Qido request dict and\n+feed it to DicomSearch() PTransform. As a result, users can get the metadata for\n+every new DICOM file. Note that not every pubsub message received is from DICOM\n+API, so we to filter the results first.\n+\n+Store a DICOM file in a DICOM storage\n+===================================================\n+DicomStoreInstance() wraps store request API and users can use it to send a\n+DICOM file to a DICOM store. It supports two types of input: 1.file data in\n+byte[] 2.fileio object. Users should set the 'input_type' when initialzing\n+this PTransform. Here are the examples:\n+\n+  with Pipeline() as p:\n+    input_dict = {'project_id': 'abc123', 'type': 'instances',...}\n+    path = \"gcs://bucketname/something/a.dcm\"\n+    match = p | fileio.MatchFiles(path)\n+    fileio_obj = match | fileio.ReadAll()\n+    results = fileio_obj | DicomStoreInstance(input_dict, 'fileio')\n+\n+  with Pipeline() as p:\n+    input_dict = {'project_id': 'abc123', 'type': 'instances',...}\n+    f = open(\"abc.dcm\", \"rb\")\n+    dcm_file = f.read()\n+    byte_file = p | 'create byte file' >> beam.Create([dcm_file])\n+    results = byte_file | DicomStoreInstance(input_dict, 'bytes')\n+\n+The first example uses a PCollection of fileio objects as input.\n+DicomStoreInstance will read DICOM files from the objects and send them\n+to a DICOM storage.\n+The second example uses a PCollection of byte[] as input. DicomStoreInstance\n+will directly send those DICOM files to a DICOM storage.\n+Users can also get the operation results in the output PCollection if they want\n+to handle the failed store requests.\n+\"\"\"\n+\n+# pytype: skip-file\n+from __future__ import absolute_import\n+\n+import apache_beam as beam\n+from apache_beam.io.gcp.dicomclient import DicomApiHttpClient\n+from apache_beam.transforms import PTransform\n+\n+\n+class DicomSearch(PTransform):\n+  \"\"\"A PTransform used for retrieving DICOM instance metadata from Google\n+    Cloud DICOM store. It takes a Pcollection of dicts as input and return\n+    a Pcollection of dict as results:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5d664ebf7585f55abcc9b5a63334f186a1f2a6b1"}, "originalPosition": 118}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTkyNjgzNg==", "bodyText": "\"....in which the DICOM store is located.\"", "url": "https://github.com/apache/beam/pull/12331#discussion_r461926836", "createdAt": "2020-07-28T22:21:59Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/dicomio.py", "diffHunk": "@@ -0,0 +1,419 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"DICOM io connector\n+This module implements serval tools to facilitate the interaction between\n+a Google Cloud Healthcare DICOM store and a beam pipeline.\n+For more details on DICOM store and API:\n+https://cloud.google.com/healthcare/docs/how-tos/dicom\n+DICOM io connector can be used to search metadata or store DICOM files.\n+When used together with Google Pubsub message connector, a PTransform\n+implemented in this module can be used to convert pubsub messages to search\n+requests. Since Traceability is crucial for healthcare API users, every\n+input or error message will be recorded in the output of the DICOM io\n+connector. As a result, every PTransform in this module will return a\n+Pcollection of dict that encodes results and detailed error messages.\n+\n+Search instance's metadata (QIDO request)\n+===================================================\n+DicomSearch() wraps the QIDO request client and supports 3 levels of search.\n+Users should specify the level by setting the 'search_type' entry in the input\n+dict. They can also refine the search by adding tags to filter the results using\n+the 'params' entry. Here is a sample usage:\n+\n+  with Pipeline() as p:\n+    input_dict = p | beam.Create([\n+      {'project_id': 'abc123', 'type': 'instances',...},\n+      {'project_id': 'dicom_go', 'type': 'series',...}\n+    ])\n+    results = input_dict| io.gcp.DicomSearch()\n+    results | 'print successful search' >> beam.Map(\n+        lambda x: print(x['result'] if x['success'] else None))\n+    results | 'print failed search' >> beam.Map(\n+        lambda x: print(x['result'] if not x['success'] else None))\n+\n+In the example above, successful qido search results and error messages for\n+failed requests are printed. When used in real life, user can choose to filter\n+those data and output them to wherever they want.\n+\n+Convert DICOM Pubsub message to Qido search request\n+===================================================\n+Healthcare API users might use Beam's Pubsub streaming pipeline to monitor the\n+store operations (new DICOM file) in a DICOM storage. Pubsub message encodes\n+DICOM a web store path as well as instance ids. If users are interested in\n+getting new instance's metadata, they can use PubsubToQido() to convert the\n+message into Qido Search dict then use DicomSearch(). Here is a sample usage:\n+\n+  pipeline_options = PipelineOptions()\n+  pipeline_options.view_as(StandardOptions).streaming = True\n+  with beam.Pipeline(options=pipeline_options) as p:\n+    pubsub = p | beam.io.ReadStringFromPubsub(subscription='a_dicom_store')\n+    results = pubsub | PubsubToQido()\n+    success = results | 'filter message' >> beam.Filter(lambda x: x['success'])\n+    qido_dict = success | 'get qido request' >> beam.Map(lambda x: x['result'])\n+    metadata = qido_dict | DicomSearch()\n+\n+In the example above, the pipeline is listening to a pubsub topic and waiting\n+for messages from DICOM API. When a new DICOM file comes into the storage, the\n+pipeline will receive a pubsub message, convert it to a Qido request dict and\n+feed it to DicomSearch() PTransform. As a result, users can get the metadata for\n+every new DICOM file. Note that not every pubsub message received is from DICOM\n+API, so we to filter the results first.\n+\n+Store a DICOM file in a DICOM storage\n+===================================================\n+DicomStoreInstance() wraps store request API and users can use it to send a\n+DICOM file to a DICOM store. It supports two types of input: 1.file data in\n+byte[] 2.fileio object. Users should set the 'input_type' when initialzing\n+this PTransform. Here are the examples:\n+\n+  with Pipeline() as p:\n+    input_dict = {'project_id': 'abc123', 'type': 'instances',...}\n+    path = \"gcs://bucketname/something/a.dcm\"\n+    match = p | fileio.MatchFiles(path)\n+    fileio_obj = match | fileio.ReadAll()\n+    results = fileio_obj | DicomStoreInstance(input_dict, 'fileio')\n+\n+  with Pipeline() as p:\n+    input_dict = {'project_id': 'abc123', 'type': 'instances',...}\n+    f = open(\"abc.dcm\", \"rb\")\n+    dcm_file = f.read()\n+    byte_file = p | 'create byte file' >> beam.Create([dcm_file])\n+    results = byte_file | DicomStoreInstance(input_dict, 'bytes')\n+\n+The first example uses a PCollection of fileio objects as input.\n+DicomStoreInstance will read DICOM files from the objects and send them\n+to a DICOM storage.\n+The second example uses a PCollection of byte[] as input. DicomStoreInstance\n+will directly send those DICOM files to a DICOM storage.\n+Users can also get the operation results in the output PCollection if they want\n+to handle the failed store requests.\n+\"\"\"\n+\n+# pytype: skip-file\n+from __future__ import absolute_import\n+\n+import apache_beam as beam\n+from apache_beam.io.gcp.dicomclient import DicomApiHttpClient\n+from apache_beam.transforms import PTransform\n+\n+\n+class DicomSearch(PTransform):\n+  \"\"\"A PTransform used for retrieving DICOM instance metadata from Google\n+    Cloud DICOM store. It takes a Pcollection of dicts as input and return\n+    a Pcollection of dict as results:\n+    INPUT:\n+    The input dict represents DICOM web path parameters, which has the following\n+    string keys and values:\n+    {\n+      'project_id': str,\n+      'region': str,\n+      'dataset_id': str,\n+      'dicom_store_id': str,\n+      'search_type': str,\n+      'params': dict(str,str) (Optional),\n+    }\n+    Key-value pairs:\n+      project_id: Id of the project in which DICOM store locates. (Required)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5d664ebf7585f55abcc9b5a63334f186a1f2a6b1"}, "originalPosition": 131}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTkyNzMxMg==", "bodyText": "does the result dictionary also return the query object that we use? (with project_id, dataset_id, search_type, etc....) - it looks like it's the 'input' dictionary, but 'I'm not sure.", "url": "https://github.com/apache/beam/pull/12331#discussion_r461927312", "createdAt": "2020-07-28T22:23:15Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/dicomio.py", "diffHunk": "@@ -0,0 +1,419 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"DICOM io connector\n+This module implements serval tools to facilitate the interaction between\n+a Google Cloud Healthcare DICOM store and a beam pipeline.\n+For more details on DICOM store and API:\n+https://cloud.google.com/healthcare/docs/how-tos/dicom\n+DICOM io connector can be used to search metadata or store DICOM files.\n+When used together with Google Pubsub message connector, a PTransform\n+implemented in this module can be used to convert pubsub messages to search\n+requests. Since Traceability is crucial for healthcare API users, every\n+input or error message will be recorded in the output of the DICOM io\n+connector. As a result, every PTransform in this module will return a\n+Pcollection of dict that encodes results and detailed error messages.\n+\n+Search instance's metadata (QIDO request)\n+===================================================\n+DicomSearch() wraps the QIDO request client and supports 3 levels of search.\n+Users should specify the level by setting the 'search_type' entry in the input\n+dict. They can also refine the search by adding tags to filter the results using\n+the 'params' entry. Here is a sample usage:\n+\n+  with Pipeline() as p:\n+    input_dict = p | beam.Create([\n+      {'project_id': 'abc123', 'type': 'instances',...},\n+      {'project_id': 'dicom_go', 'type': 'series',...}\n+    ])\n+    results = input_dict| io.gcp.DicomSearch()\n+    results | 'print successful search' >> beam.Map(\n+        lambda x: print(x['result'] if x['success'] else None))\n+    results | 'print failed search' >> beam.Map(\n+        lambda x: print(x['result'] if not x['success'] else None))\n+\n+In the example above, successful qido search results and error messages for\n+failed requests are printed. When used in real life, user can choose to filter\n+those data and output them to wherever they want.\n+\n+Convert DICOM Pubsub message to Qido search request\n+===================================================\n+Healthcare API users might use Beam's Pubsub streaming pipeline to monitor the\n+store operations (new DICOM file) in a DICOM storage. Pubsub message encodes\n+DICOM a web store path as well as instance ids. If users are interested in\n+getting new instance's metadata, they can use PubsubToQido() to convert the\n+message into Qido Search dict then use DicomSearch(). Here is a sample usage:\n+\n+  pipeline_options = PipelineOptions()\n+  pipeline_options.view_as(StandardOptions).streaming = True\n+  with beam.Pipeline(options=pipeline_options) as p:\n+    pubsub = p | beam.io.ReadStringFromPubsub(subscription='a_dicom_store')\n+    results = pubsub | PubsubToQido()\n+    success = results | 'filter message' >> beam.Filter(lambda x: x['success'])\n+    qido_dict = success | 'get qido request' >> beam.Map(lambda x: x['result'])\n+    metadata = qido_dict | DicomSearch()\n+\n+In the example above, the pipeline is listening to a pubsub topic and waiting\n+for messages from DICOM API. When a new DICOM file comes into the storage, the\n+pipeline will receive a pubsub message, convert it to a Qido request dict and\n+feed it to DicomSearch() PTransform. As a result, users can get the metadata for\n+every new DICOM file. Note that not every pubsub message received is from DICOM\n+API, so we to filter the results first.\n+\n+Store a DICOM file in a DICOM storage\n+===================================================\n+DicomStoreInstance() wraps store request API and users can use it to send a\n+DICOM file to a DICOM store. It supports two types of input: 1.file data in\n+byte[] 2.fileio object. Users should set the 'input_type' when initialzing\n+this PTransform. Here are the examples:\n+\n+  with Pipeline() as p:\n+    input_dict = {'project_id': 'abc123', 'type': 'instances',...}\n+    path = \"gcs://bucketname/something/a.dcm\"\n+    match = p | fileio.MatchFiles(path)\n+    fileio_obj = match | fileio.ReadAll()\n+    results = fileio_obj | DicomStoreInstance(input_dict, 'fileio')\n+\n+  with Pipeline() as p:\n+    input_dict = {'project_id': 'abc123', 'type': 'instances',...}\n+    f = open(\"abc.dcm\", \"rb\")\n+    dcm_file = f.read()\n+    byte_file = p | 'create byte file' >> beam.Create([dcm_file])\n+    results = byte_file | DicomStoreInstance(input_dict, 'bytes')\n+\n+The first example uses a PCollection of fileio objects as input.\n+DicomStoreInstance will read DICOM files from the objects and send them\n+to a DICOM storage.\n+The second example uses a PCollection of byte[] as input. DicomStoreInstance\n+will directly send those DICOM files to a DICOM storage.\n+Users can also get the operation results in the output PCollection if they want\n+to handle the failed store requests.\n+\"\"\"\n+\n+# pytype: skip-file\n+from __future__ import absolute_import\n+\n+import apache_beam as beam\n+from apache_beam.io.gcp.dicomclient import DicomApiHttpClient\n+from apache_beam.transforms import PTransform\n+\n+\n+class DicomSearch(PTransform):\n+  \"\"\"A PTransform used for retrieving DICOM instance metadata from Google\n+    Cloud DICOM store. It takes a Pcollection of dicts as input and return\n+    a Pcollection of dict as results:\n+    INPUT:\n+    The input dict represents DICOM web path parameters, which has the following\n+    string keys and values:\n+    {\n+      'project_id': str,\n+      'region': str,\n+      'dataset_id': str,\n+      'dicom_store_id': str,\n+      'search_type': str,\n+      'params': dict(str,str) (Optional),\n+    }\n+    Key-value pairs:\n+      project_id: Id of the project in which DICOM store locates. (Required)\n+      region: Region where the DICOM store resides. (Required)\n+      dataset_id: Id of the dataset where DICOM store belongs to. (Required)\n+      dicom_store_id: Id of the dicom store. (Required)\n+      search_type: Which type of search it is, could only be one of the three\n+        values: 'instances', 'series', or 'studies'. (Required)\n+      params: A dict of str:str pairs used to refine QIDO search. (Optional)\n+        Supported tags in three categories:\n+          1. Studies:\n+            StudyInstanceUID\n+            PatientName\n+            PatientID\n+            AccessionNumber\n+            ReferringPhysicianName\n+            StudyDate\n+          2. Series: all study level search terms and\n+            SeriesInstanceUID\n+            Modality\n+          3. Instances: all study/series level search terms and\n+            SOPInstanceUID\n+        e.g. {\"StudyInstanceUID\":\"1\",\"SeriesInstanceUID\":\"2\"}\n+    OUTPUT:\n+    The output dict wraps results as well as error messages:\n+    {\n+      'result': a list of dicts in JSON style.\n+      'success': boolean value telling whether the operation is successful.\n+      'input': detail ids and dicomweb path for this retrieval.\n+      'status': status code from the server, used as error message.\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5d664ebf7585f55abcc9b5a63334f186a1f2a6b1"}, "originalPosition": 159}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk0NDAwNg==", "bodyText": "Performing these API calls is blocking. Because we're only issuing one call per thread, the workers will be blocked waiting for IO, and CPU will be wasted. You can improve this with a thread pool. You would do something like this:\nclass MyDoFn(DoFn):\n  def start_bundle(self):\n    self.buffer = []\n\n  def process(self, element, window=DoFn.WindowParam):\n    if validate_element(element):\n      self.buffer.append((element, window))\n    else:\n      yield build_output_with_error_message(element)\n\n  def _make_dicom_http_request(self, element):\n    # Element is validated.\n    result, status = DicomApiHttpClient().quido_search(.....)\n    ....\n\n  def finish_bundle(self):\n    thread_pool = ThreadPoolExecutor()\n    futures = [thread_pool.submit(_make_dicom_http_request, elm)  # Something like this\n                   for elm in self.buffer]\n    # Note that here you have to yield a WindowedElement, not just the plain element\n    # This is because one bundle can have elements belonging to multiple windows.\n    yield [f.get() for f in futures]\n\nThis is certainly not a blocker for the PR, but users will hit this issue 100% for sure, so it's worth doing now. Feel free to add a TODO (and get acknowledgement from your mentor), or to implement it.", "url": "https://github.com/apache/beam/pull/12331#discussion_r461944006", "createdAt": "2020-07-28T23:08:59Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/dicomio.py", "diffHunk": "@@ -0,0 +1,419 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"DICOM io connector\n+This module implements serval tools to facilitate the interaction between\n+a Google Cloud Healthcare DICOM store and a beam pipeline.\n+For more details on DICOM store and API:\n+https://cloud.google.com/healthcare/docs/how-tos/dicom\n+DICOM io connector can be used to search metadata or store DICOM files.\n+When used together with Google Pubsub message connector, a PTransform\n+implemented in this module can be used to convert pubsub messages to search\n+requests. Since Traceability is crucial for healthcare API users, every\n+input or error message will be recorded in the output of the DICOM io\n+connector. As a result, every PTransform in this module will return a\n+Pcollection of dict that encodes results and detailed error messages.\n+\n+Search instance's metadata (QIDO request)\n+===================================================\n+DicomSearch() wraps the QIDO request client and supports 3 levels of search.\n+Users should specify the level by setting the 'search_type' entry in the input\n+dict. They can also refine the search by adding tags to filter the results using\n+the 'params' entry. Here is a sample usage:\n+\n+  with Pipeline() as p:\n+    input_dict = p | beam.Create([\n+      {'project_id': 'abc123', 'type': 'instances',...},\n+      {'project_id': 'dicom_go', 'type': 'series',...}\n+    ])\n+    results = input_dict| io.gcp.DicomSearch()\n+    results | 'print successful search' >> beam.Map(\n+        lambda x: print(x['result'] if x['success'] else None))\n+    results | 'print failed search' >> beam.Map(\n+        lambda x: print(x['result'] if not x['success'] else None))\n+\n+In the example above, successful qido search results and error messages for\n+failed requests are printed. When used in real life, user can choose to filter\n+those data and output them to wherever they want.\n+\n+Convert DICOM Pubsub message to Qido search request\n+===================================================\n+Healthcare API users might use Beam's Pubsub streaming pipeline to monitor the\n+store operations (new DICOM file) in a DICOM storage. Pubsub message encodes\n+DICOM a web store path as well as instance ids. If users are interested in\n+getting new instance's metadata, they can use PubsubToQido() to convert the\n+message into Qido Search dict then use DicomSearch(). Here is a sample usage:\n+\n+  pipeline_options = PipelineOptions()\n+  pipeline_options.view_as(StandardOptions).streaming = True\n+  with beam.Pipeline(options=pipeline_options) as p:\n+    pubsub = p | beam.io.ReadStringFromPubsub(subscription='a_dicom_store')\n+    results = pubsub | PubsubToQido()\n+    success = results | 'filter message' >> beam.Filter(lambda x: x['success'])\n+    qido_dict = success | 'get qido request' >> beam.Map(lambda x: x['result'])\n+    metadata = qido_dict | DicomSearch()\n+\n+In the example above, the pipeline is listening to a pubsub topic and waiting\n+for messages from DICOM API. When a new DICOM file comes into the storage, the\n+pipeline will receive a pubsub message, convert it to a Qido request dict and\n+feed it to DicomSearch() PTransform. As a result, users can get the metadata for\n+every new DICOM file. Note that not every pubsub message received is from DICOM\n+API, so we to filter the results first.\n+\n+Store a DICOM file in a DICOM storage\n+===================================================\n+DicomStoreInstance() wraps store request API and users can use it to send a\n+DICOM file to a DICOM store. It supports two types of input: 1.file data in\n+byte[] 2.fileio object. Users should set the 'input_type' when initialzing\n+this PTransform. Here are the examples:\n+\n+  with Pipeline() as p:\n+    input_dict = {'project_id': 'abc123', 'type': 'instances',...}\n+    path = \"gcs://bucketname/something/a.dcm\"\n+    match = p | fileio.MatchFiles(path)\n+    fileio_obj = match | fileio.ReadAll()\n+    results = fileio_obj | DicomStoreInstance(input_dict, 'fileio')\n+\n+  with Pipeline() as p:\n+    input_dict = {'project_id': 'abc123', 'type': 'instances',...}\n+    f = open(\"abc.dcm\", \"rb\")\n+    dcm_file = f.read()\n+    byte_file = p | 'create byte file' >> beam.Create([dcm_file])\n+    results = byte_file | DicomStoreInstance(input_dict, 'bytes')\n+\n+The first example uses a PCollection of fileio objects as input.\n+DicomStoreInstance will read DICOM files from the objects and send them\n+to a DICOM storage.\n+The second example uses a PCollection of byte[] as input. DicomStoreInstance\n+will directly send those DICOM files to a DICOM storage.\n+Users can also get the operation results in the output PCollection if they want\n+to handle the failed store requests.\n+\"\"\"\n+\n+# pytype: skip-file\n+from __future__ import absolute_import\n+\n+import apache_beam as beam\n+from apache_beam.io.gcp.dicomclient import DicomApiHttpClient\n+from apache_beam.transforms import PTransform\n+\n+\n+class DicomSearch(PTransform):\n+  \"\"\"A PTransform used for retrieving DICOM instance metadata from Google\n+    Cloud DICOM store. It takes a Pcollection of dicts as input and return\n+    a Pcollection of dict as results:\n+    INPUT:\n+    The input dict represents DICOM web path parameters, which has the following\n+    string keys and values:\n+    {\n+      'project_id': str,\n+      'region': str,\n+      'dataset_id': str,\n+      'dicom_store_id': str,\n+      'search_type': str,\n+      'params': dict(str,str) (Optional),\n+    }\n+    Key-value pairs:\n+      project_id: Id of the project in which DICOM store locates. (Required)\n+      region: Region where the DICOM store resides. (Required)\n+      dataset_id: Id of the dataset where DICOM store belongs to. (Required)\n+      dicom_store_id: Id of the dicom store. (Required)\n+      search_type: Which type of search it is, could only be one of the three\n+        values: 'instances', 'series', or 'studies'. (Required)\n+      params: A dict of str:str pairs used to refine QIDO search. (Optional)\n+        Supported tags in three categories:\n+          1. Studies:\n+            StudyInstanceUID\n+            PatientName\n+            PatientID\n+            AccessionNumber\n+            ReferringPhysicianName\n+            StudyDate\n+          2. Series: all study level search terms and\n+            SeriesInstanceUID\n+            Modality\n+          3. Instances: all study/series level search terms and\n+            SOPInstanceUID\n+        e.g. {\"StudyInstanceUID\":\"1\",\"SeriesInstanceUID\":\"2\"}\n+    OUTPUT:\n+    The output dict wraps results as well as error messages:\n+    {\n+      'result': a list of dicts in JSON style.\n+      'success': boolean value telling whether the operation is successful.\n+      'input': detail ids and dicomweb path for this retrieval.\n+      'status': status code from the server, used as error message.\n+    }\n+  \"\"\"\n+  def __init__(self, credential=None):\n+    \"\"\"Initializes DicomSearch.\n+    Args:\n+      credential: # type: Google credential object, if it is specified, the\n+        Http client will use it to create sessions instead of the default.\n+    \"\"\"\n+    self.credential = credential\n+\n+  def expand(self, pcoll):\n+    return pcoll | beam.ParDo(_QidoSource(self.credential))\n+\n+\n+class _QidoSource(beam.DoFn):\n+  \"\"\"A DoFn for executing every qido query request.\"\"\"\n+  def __init__(self, credential=None):\n+    self.credential = credential\n+\n+  def process(self, element):\n+    # Check if all required keys present.\n+    required_keys = [\n+        'project_id', 'region', 'dataset_id', 'dicom_store_id', 'search_type'\n+    ]\n+\n+    error_message = None\n+\n+    for key in required_keys:\n+      if key not in element:\n+        error_message = 'Must have %s in the dict.' % (key)\n+        break\n+\n+    if not error_message:\n+      project_id = element['project_id']\n+      region = element['region']\n+      dataset_id = element['dataset_id']\n+      dicom_store_id = element['dicom_store_id']\n+      search_type = element['search_type']\n+      params = element['params'] if 'params' in element else None\n+\n+      # Call qido search http client\n+      if element['search_type'] in ['instances', \"studies\", \"series\"]:\n+        result, status_code = DicomApiHttpClient().qido_search(\n+          project_id, region, dataset_id, dicom_store_id,\n+          search_type, params, self.credential\n+        )\n+      else:\n+        error_message = (\n+            'Search type can only be \"studies\", '\n+            '\"instances\" or \"series\"')", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5d664ebf7585f55abcc9b5a63334f186a1f2a6b1"}, "originalPosition": 208}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk0NDI0OA==", "bodyText": "I'm also happy to clarify further on what the code snippet means if you'd like.", "url": "https://github.com/apache/beam/pull/12331#discussion_r461944248", "createdAt": "2020-07-28T23:09:39Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/dicomio.py", "diffHunk": "@@ -0,0 +1,419 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"DICOM io connector\n+This module implements serval tools to facilitate the interaction between\n+a Google Cloud Healthcare DICOM store and a beam pipeline.\n+For more details on DICOM store and API:\n+https://cloud.google.com/healthcare/docs/how-tos/dicom\n+DICOM io connector can be used to search metadata or store DICOM files.\n+When used together with Google Pubsub message connector, a PTransform\n+implemented in this module can be used to convert pubsub messages to search\n+requests. Since Traceability is crucial for healthcare API users, every\n+input or error message will be recorded in the output of the DICOM io\n+connector. As a result, every PTransform in this module will return a\n+Pcollection of dict that encodes results and detailed error messages.\n+\n+Search instance's metadata (QIDO request)\n+===================================================\n+DicomSearch() wraps the QIDO request client and supports 3 levels of search.\n+Users should specify the level by setting the 'search_type' entry in the input\n+dict. They can also refine the search by adding tags to filter the results using\n+the 'params' entry. Here is a sample usage:\n+\n+  with Pipeline() as p:\n+    input_dict = p | beam.Create([\n+      {'project_id': 'abc123', 'type': 'instances',...},\n+      {'project_id': 'dicom_go', 'type': 'series',...}\n+    ])\n+    results = input_dict| io.gcp.DicomSearch()\n+    results | 'print successful search' >> beam.Map(\n+        lambda x: print(x['result'] if x['success'] else None))\n+    results | 'print failed search' >> beam.Map(\n+        lambda x: print(x['result'] if not x['success'] else None))\n+\n+In the example above, successful qido search results and error messages for\n+failed requests are printed. When used in real life, user can choose to filter\n+those data and output them to wherever they want.\n+\n+Convert DICOM Pubsub message to Qido search request\n+===================================================\n+Healthcare API users might use Beam's Pubsub streaming pipeline to monitor the\n+store operations (new DICOM file) in a DICOM storage. Pubsub message encodes\n+DICOM a web store path as well as instance ids. If users are interested in\n+getting new instance's metadata, they can use PubsubToQido() to convert the\n+message into Qido Search dict then use DicomSearch(). Here is a sample usage:\n+\n+  pipeline_options = PipelineOptions()\n+  pipeline_options.view_as(StandardOptions).streaming = True\n+  with beam.Pipeline(options=pipeline_options) as p:\n+    pubsub = p | beam.io.ReadStringFromPubsub(subscription='a_dicom_store')\n+    results = pubsub | PubsubToQido()\n+    success = results | 'filter message' >> beam.Filter(lambda x: x['success'])\n+    qido_dict = success | 'get qido request' >> beam.Map(lambda x: x['result'])\n+    metadata = qido_dict | DicomSearch()\n+\n+In the example above, the pipeline is listening to a pubsub topic and waiting\n+for messages from DICOM API. When a new DICOM file comes into the storage, the\n+pipeline will receive a pubsub message, convert it to a Qido request dict and\n+feed it to DicomSearch() PTransform. As a result, users can get the metadata for\n+every new DICOM file. Note that not every pubsub message received is from DICOM\n+API, so we to filter the results first.\n+\n+Store a DICOM file in a DICOM storage\n+===================================================\n+DicomStoreInstance() wraps store request API and users can use it to send a\n+DICOM file to a DICOM store. It supports two types of input: 1.file data in\n+byte[] 2.fileio object. Users should set the 'input_type' when initialzing\n+this PTransform. Here are the examples:\n+\n+  with Pipeline() as p:\n+    input_dict = {'project_id': 'abc123', 'type': 'instances',...}\n+    path = \"gcs://bucketname/something/a.dcm\"\n+    match = p | fileio.MatchFiles(path)\n+    fileio_obj = match | fileio.ReadAll()\n+    results = fileio_obj | DicomStoreInstance(input_dict, 'fileio')\n+\n+  with Pipeline() as p:\n+    input_dict = {'project_id': 'abc123', 'type': 'instances',...}\n+    f = open(\"abc.dcm\", \"rb\")\n+    dcm_file = f.read()\n+    byte_file = p | 'create byte file' >> beam.Create([dcm_file])\n+    results = byte_file | DicomStoreInstance(input_dict, 'bytes')\n+\n+The first example uses a PCollection of fileio objects as input.\n+DicomStoreInstance will read DICOM files from the objects and send them\n+to a DICOM storage.\n+The second example uses a PCollection of byte[] as input. DicomStoreInstance\n+will directly send those DICOM files to a DICOM storage.\n+Users can also get the operation results in the output PCollection if they want\n+to handle the failed store requests.\n+\"\"\"\n+\n+# pytype: skip-file\n+from __future__ import absolute_import\n+\n+import apache_beam as beam\n+from apache_beam.io.gcp.dicomclient import DicomApiHttpClient\n+from apache_beam.transforms import PTransform\n+\n+\n+class DicomSearch(PTransform):\n+  \"\"\"A PTransform used for retrieving DICOM instance metadata from Google\n+    Cloud DICOM store. It takes a Pcollection of dicts as input and return\n+    a Pcollection of dict as results:\n+    INPUT:\n+    The input dict represents DICOM web path parameters, which has the following\n+    string keys and values:\n+    {\n+      'project_id': str,\n+      'region': str,\n+      'dataset_id': str,\n+      'dicom_store_id': str,\n+      'search_type': str,\n+      'params': dict(str,str) (Optional),\n+    }\n+    Key-value pairs:\n+      project_id: Id of the project in which DICOM store locates. (Required)\n+      region: Region where the DICOM store resides. (Required)\n+      dataset_id: Id of the dataset where DICOM store belongs to. (Required)\n+      dicom_store_id: Id of the dicom store. (Required)\n+      search_type: Which type of search it is, could only be one of the three\n+        values: 'instances', 'series', or 'studies'. (Required)\n+      params: A dict of str:str pairs used to refine QIDO search. (Optional)\n+        Supported tags in three categories:\n+          1. Studies:\n+            StudyInstanceUID\n+            PatientName\n+            PatientID\n+            AccessionNumber\n+            ReferringPhysicianName\n+            StudyDate\n+          2. Series: all study level search terms and\n+            SeriesInstanceUID\n+            Modality\n+          3. Instances: all study/series level search terms and\n+            SOPInstanceUID\n+        e.g. {\"StudyInstanceUID\":\"1\",\"SeriesInstanceUID\":\"2\"}\n+    OUTPUT:\n+    The output dict wraps results as well as error messages:\n+    {\n+      'result': a list of dicts in JSON style.\n+      'success': boolean value telling whether the operation is successful.\n+      'input': detail ids and dicomweb path for this retrieval.\n+      'status': status code from the server, used as error message.\n+    }\n+  \"\"\"\n+  def __init__(self, credential=None):\n+    \"\"\"Initializes DicomSearch.\n+    Args:\n+      credential: # type: Google credential object, if it is specified, the\n+        Http client will use it to create sessions instead of the default.\n+    \"\"\"\n+    self.credential = credential\n+\n+  def expand(self, pcoll):\n+    return pcoll | beam.ParDo(_QidoSource(self.credential))\n+\n+\n+class _QidoSource(beam.DoFn):\n+  \"\"\"A DoFn for executing every qido query request.\"\"\"\n+  def __init__(self, credential=None):\n+    self.credential = credential\n+\n+  def process(self, element):\n+    # Check if all required keys present.\n+    required_keys = [\n+        'project_id', 'region', 'dataset_id', 'dicom_store_id', 'search_type'\n+    ]\n+\n+    error_message = None\n+\n+    for key in required_keys:\n+      if key not in element:\n+        error_message = 'Must have %s in the dict.' % (key)\n+        break\n+\n+    if not error_message:\n+      project_id = element['project_id']\n+      region = element['region']\n+      dataset_id = element['dataset_id']\n+      dicom_store_id = element['dicom_store_id']\n+      search_type = element['search_type']\n+      params = element['params'] if 'params' in element else None\n+\n+      # Call qido search http client\n+      if element['search_type'] in ['instances', \"studies\", \"series\"]:\n+        result, status_code = DicomApiHttpClient().qido_search(\n+          project_id, region, dataset_id, dicom_store_id,\n+          search_type, params, self.credential\n+        )\n+      else:\n+        error_message = (\n+            'Search type can only be \"studies\", '\n+            '\"instances\" or \"series\"')", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk0NDAwNg=="}, "originalCommit": {"oid": "5d664ebf7585f55abcc9b5a63334f186a1f2a6b1"}, "originalPosition": 208}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk0NTMzNw==", "bodyText": "perhaps 'WriteToDicomStore'?", "url": "https://github.com/apache/beam/pull/12331#discussion_r461945337", "createdAt": "2020-07-28T23:12:48Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/dicomio.py", "diffHunk": "@@ -0,0 +1,419 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"DICOM io connector\n+This module implements serval tools to facilitate the interaction between\n+a Google Cloud Healthcare DICOM store and a beam pipeline.\n+For more details on DICOM store and API:\n+https://cloud.google.com/healthcare/docs/how-tos/dicom\n+DICOM io connector can be used to search metadata or store DICOM files.\n+When used together with Google Pubsub message connector, a PTransform\n+implemented in this module can be used to convert pubsub messages to search\n+requests. Since Traceability is crucial for healthcare API users, every\n+input or error message will be recorded in the output of the DICOM io\n+connector. As a result, every PTransform in this module will return a\n+Pcollection of dict that encodes results and detailed error messages.\n+\n+Search instance's metadata (QIDO request)\n+===================================================\n+DicomSearch() wraps the QIDO request client and supports 3 levels of search.\n+Users should specify the level by setting the 'search_type' entry in the input\n+dict. They can also refine the search by adding tags to filter the results using\n+the 'params' entry. Here is a sample usage:\n+\n+  with Pipeline() as p:\n+    input_dict = p | beam.Create([\n+      {'project_id': 'abc123', 'type': 'instances',...},\n+      {'project_id': 'dicom_go', 'type': 'series',...}\n+    ])\n+    results = input_dict| io.gcp.DicomSearch()\n+    results | 'print successful search' >> beam.Map(\n+        lambda x: print(x['result'] if x['success'] else None))\n+    results | 'print failed search' >> beam.Map(\n+        lambda x: print(x['result'] if not x['success'] else None))\n+\n+In the example above, successful qido search results and error messages for\n+failed requests are printed. When used in real life, user can choose to filter\n+those data and output them to wherever they want.\n+\n+Convert DICOM Pubsub message to Qido search request\n+===================================================\n+Healthcare API users might use Beam's Pubsub streaming pipeline to monitor the\n+store operations (new DICOM file) in a DICOM storage. Pubsub message encodes\n+DICOM a web store path as well as instance ids. If users are interested in\n+getting new instance's metadata, they can use PubsubToQido() to convert the\n+message into Qido Search dict then use DicomSearch(). Here is a sample usage:\n+\n+  pipeline_options = PipelineOptions()\n+  pipeline_options.view_as(StandardOptions).streaming = True\n+  with beam.Pipeline(options=pipeline_options) as p:\n+    pubsub = p | beam.io.ReadStringFromPubsub(subscription='a_dicom_store')\n+    results = pubsub | PubsubToQido()\n+    success = results | 'filter message' >> beam.Filter(lambda x: x['success'])\n+    qido_dict = success | 'get qido request' >> beam.Map(lambda x: x['result'])\n+    metadata = qido_dict | DicomSearch()\n+\n+In the example above, the pipeline is listening to a pubsub topic and waiting\n+for messages from DICOM API. When a new DICOM file comes into the storage, the\n+pipeline will receive a pubsub message, convert it to a Qido request dict and\n+feed it to DicomSearch() PTransform. As a result, users can get the metadata for\n+every new DICOM file. Note that not every pubsub message received is from DICOM\n+API, so we to filter the results first.\n+\n+Store a DICOM file in a DICOM storage\n+===================================================\n+DicomStoreInstance() wraps store request API and users can use it to send a\n+DICOM file to a DICOM store. It supports two types of input: 1.file data in\n+byte[] 2.fileio object. Users should set the 'input_type' when initialzing\n+this PTransform. Here are the examples:\n+\n+  with Pipeline() as p:\n+    input_dict = {'project_id': 'abc123', 'type': 'instances',...}\n+    path = \"gcs://bucketname/something/a.dcm\"\n+    match = p | fileio.MatchFiles(path)\n+    fileio_obj = match | fileio.ReadAll()\n+    results = fileio_obj | DicomStoreInstance(input_dict, 'fileio')\n+\n+  with Pipeline() as p:\n+    input_dict = {'project_id': 'abc123', 'type': 'instances',...}\n+    f = open(\"abc.dcm\", \"rb\")\n+    dcm_file = f.read()\n+    byte_file = p | 'create byte file' >> beam.Create([dcm_file])\n+    results = byte_file | DicomStoreInstance(input_dict, 'bytes')\n+\n+The first example uses a PCollection of fileio objects as input.\n+DicomStoreInstance will read DICOM files from the objects and send them\n+to a DICOM storage.\n+The second example uses a PCollection of byte[] as input. DicomStoreInstance\n+will directly send those DICOM files to a DICOM storage.\n+Users can also get the operation results in the output PCollection if they want\n+to handle the failed store requests.\n+\"\"\"\n+\n+# pytype: skip-file\n+from __future__ import absolute_import\n+\n+import apache_beam as beam\n+from apache_beam.io.gcp.dicomclient import DicomApiHttpClient\n+from apache_beam.transforms import PTransform\n+\n+\n+class DicomSearch(PTransform):\n+  \"\"\"A PTransform used for retrieving DICOM instance metadata from Google\n+    Cloud DICOM store. It takes a Pcollection of dicts as input and return\n+    a Pcollection of dict as results:\n+    INPUT:\n+    The input dict represents DICOM web path parameters, which has the following\n+    string keys and values:\n+    {\n+      'project_id': str,\n+      'region': str,\n+      'dataset_id': str,\n+      'dicom_store_id': str,\n+      'search_type': str,\n+      'params': dict(str,str) (Optional),\n+    }\n+    Key-value pairs:\n+      project_id: Id of the project in which DICOM store locates. (Required)\n+      region: Region where the DICOM store resides. (Required)\n+      dataset_id: Id of the dataset where DICOM store belongs to. (Required)\n+      dicom_store_id: Id of the dicom store. (Required)\n+      search_type: Which type of search it is, could only be one of the three\n+        values: 'instances', 'series', or 'studies'. (Required)\n+      params: A dict of str:str pairs used to refine QIDO search. (Optional)\n+        Supported tags in three categories:\n+          1. Studies:\n+            StudyInstanceUID\n+            PatientName\n+            PatientID\n+            AccessionNumber\n+            ReferringPhysicianName\n+            StudyDate\n+          2. Series: all study level search terms and\n+            SeriesInstanceUID\n+            Modality\n+          3. Instances: all study/series level search terms and\n+            SOPInstanceUID\n+        e.g. {\"StudyInstanceUID\":\"1\",\"SeriesInstanceUID\":\"2\"}\n+    OUTPUT:\n+    The output dict wraps results as well as error messages:\n+    {\n+      'result': a list of dicts in JSON style.\n+      'success': boolean value telling whether the operation is successful.\n+      'input': detail ids and dicomweb path for this retrieval.\n+      'status': status code from the server, used as error message.\n+    }\n+  \"\"\"\n+  def __init__(self, credential=None):\n+    \"\"\"Initializes DicomSearch.\n+    Args:\n+      credential: # type: Google credential object, if it is specified, the\n+        Http client will use it to create sessions instead of the default.\n+    \"\"\"\n+    self.credential = credential\n+\n+  def expand(self, pcoll):\n+    return pcoll | beam.ParDo(_QidoSource(self.credential))\n+\n+\n+class _QidoSource(beam.DoFn):\n+  \"\"\"A DoFn for executing every qido query request.\"\"\"\n+  def __init__(self, credential=None):\n+    self.credential = credential\n+\n+  def process(self, element):\n+    # Check if all required keys present.\n+    required_keys = [\n+        'project_id', 'region', 'dataset_id', 'dicom_store_id', 'search_type'\n+    ]\n+\n+    error_message = None\n+\n+    for key in required_keys:\n+      if key not in element:\n+        error_message = 'Must have %s in the dict.' % (key)\n+        break\n+\n+    if not error_message:\n+      project_id = element['project_id']\n+      region = element['region']\n+      dataset_id = element['dataset_id']\n+      dicom_store_id = element['dicom_store_id']\n+      search_type = element['search_type']\n+      params = element['params'] if 'params' in element else None\n+\n+      # Call qido search http client\n+      if element['search_type'] in ['instances', \"studies\", \"series\"]:\n+        result, status_code = DicomApiHttpClient().qido_search(\n+          project_id, region, dataset_id, dicom_store_id,\n+          search_type, params, self.credential\n+        )\n+      else:\n+        error_message = (\n+            'Search type can only be \"studies\", '\n+            '\"instances\" or \"series\"')\n+\n+      if not error_message:\n+        out = {}\n+        out['result'] = result\n+        out['status'] = status_code\n+        out['input'] = element\n+        out['success'] = (status_code == 200)\n+        return [out]\n+\n+    # Return this when the input dict dose not meet the requirements\n+    out = {}\n+    out['result'] = []\n+    out['status'] = error_message\n+    out['input'] = element\n+    out['success'] = False\n+    return [out]\n+\n+\n+class PubsubToQido(PTransform):\n+  \"\"\"A PTransform for converting pubsub messages into search input dict.\n+    Takes Pcollection of string as input and returns a Pcollection of dict as\n+    results. Note that some pubsub messages may not be from DICOM API, which\n+    will be recorded as failed conversions.\n+    INPUT:\n+    The input are normally strings from Pubsub topic:\n+      \"projects/PROJECT_ID/locations/LOCATION/datasets/DATASET_ID/\n+      dicomStores/DICOM_STORE_ID/dicomWeb/studies/STUDY_UID/\n+      series/SERIES_UID/instances/INSTANCE_UID\"\n+    OUTPUT:\n+    The output dict encodes results as well as error messages:\n+    {\n+      'result': a dict representing instance level qido search request.\n+      'success': boolean value telling whether the conversion is successful.\n+      'input': input pubsub message string.\n+    }\n+  \"\"\"\n+  def __init__(self, credential=None):\n+    \"\"\"Initializes PubsubToQido.\n+    Args:\n+      credential: # type: Google credential object, if it is specified, the\n+        Http client will use it instead of the default one.\n+    \"\"\"\n+    self.credential = credential\n+\n+  def expand(self, pcoll):\n+    return pcoll | beam.ParDo(_ConvertPubsubToQido())\n+\n+\n+class _ConvertPubsubToQido(beam.DoFn):\n+  \"\"\"A DoFn for converting pubsub string to qido search parameters.\"\"\"\n+  def process(self, element):\n+    # Some constants for DICOM pubsub message\n+    NUM_PUBSUB_STR_ENTRIES = 15\n+    NUM_DICOM_WEBPATH_PARAMETERS = 5\n+    NUM_TOTAL_PARAMETERS = 8\n+    INDEX_PROJECT_ID = 1\n+    INDEX_REGION = 3\n+    INDEX_DATASET_ID = 5\n+    INDEX_DICOMSTORE_ID = 7\n+    INDEX_STUDY_ID = 10\n+    INDEX_SERIE_ID = 12\n+    INDEX_INSTANCE_ID = 14\n+\n+    entries = element.split('/')\n+\n+    # Output dict with error message, used when\n+    # receiving invalid pubsub string.\n+    error_dict = {}\n+    error_dict['result'] = {}\n+    error_dict['input'] = element\n+    error_dict['success'] = False\n+\n+    if len(entries) != NUM_PUBSUB_STR_ENTRIES:\n+      return [error_dict]\n+\n+    required_keys = [\n+        'projects',\n+        'locations',\n+        'datasets',\n+        'dicomStores',\n+        'dicomWeb',\n+        'studies',\n+        'series',\n+        'instances'\n+    ]\n+\n+    # Check if the required keys present and\n+    # the positions of those keys are correct\n+    for i in range(NUM_DICOM_WEBPATH_PARAMETERS):\n+      if required_keys[i] != entries[i * 2]:\n+        return [error_dict]\n+    for i in range(NUM_DICOM_WEBPATH_PARAMETERS, NUM_TOTAL_PARAMETERS):\n+      if required_keys[i] != entries[i * 2 - 1]:\n+        return [error_dict]\n+\n+    # Compose dicom webpath parameters for qido search\n+    qido_dict = {}\n+    qido_dict['project_id'] = entries[INDEX_PROJECT_ID]\n+    qido_dict['region'] = entries[INDEX_REGION]\n+    qido_dict['dataset_id'] = entries[INDEX_DATASET_ID]\n+    qido_dict['dicom_store_id'] = entries[INDEX_DICOMSTORE_ID]\n+    qido_dict['search_type'] = 'instances'\n+\n+    # Compose instance level params for qido search\n+    params = {}\n+    params['StudyInstanceUID'] = entries[INDEX_STUDY_ID]\n+    params['SeriesInstanceUID'] = entries[INDEX_SERIE_ID]\n+    params['SOPInstanceUID'] = entries[INDEX_INSTANCE_ID]\n+    qido_dict['params'] = params\n+\n+    out = {}\n+    out['result'] = qido_dict\n+    out['input'] = element\n+    out['success'] = True\n+\n+    return [out]\n+\n+\n+class DicomStoreInstance(PTransform):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5d664ebf7585f55abcc9b5a63334f186a1f2a6b1"}, "originalPosition": 327}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk0NjEwNQ==", "bodyText": "In this case it's also worth buffering and performing the requests in parallel.", "url": "https://github.com/apache/beam/pull/12331#discussion_r461946105", "createdAt": "2020-07-28T23:15:05Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/dicomio.py", "diffHunk": "@@ -0,0 +1,419 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"DICOM io connector\n+This module implements serval tools to facilitate the interaction between\n+a Google Cloud Healthcare DICOM store and a beam pipeline.\n+For more details on DICOM store and API:\n+https://cloud.google.com/healthcare/docs/how-tos/dicom\n+DICOM io connector can be used to search metadata or store DICOM files.\n+When used together with Google Pubsub message connector, a PTransform\n+implemented in this module can be used to convert pubsub messages to search\n+requests. Since Traceability is crucial for healthcare API users, every\n+input or error message will be recorded in the output of the DICOM io\n+connector. As a result, every PTransform in this module will return a\n+Pcollection of dict that encodes results and detailed error messages.\n+\n+Search instance's metadata (QIDO request)\n+===================================================\n+DicomSearch() wraps the QIDO request client and supports 3 levels of search.\n+Users should specify the level by setting the 'search_type' entry in the input\n+dict. They can also refine the search by adding tags to filter the results using\n+the 'params' entry. Here is a sample usage:\n+\n+  with Pipeline() as p:\n+    input_dict = p | beam.Create([\n+      {'project_id': 'abc123', 'type': 'instances',...},\n+      {'project_id': 'dicom_go', 'type': 'series',...}\n+    ])\n+    results = input_dict| io.gcp.DicomSearch()\n+    results | 'print successful search' >> beam.Map(\n+        lambda x: print(x['result'] if x['success'] else None))\n+    results | 'print failed search' >> beam.Map(\n+        lambda x: print(x['result'] if not x['success'] else None))\n+\n+In the example above, successful qido search results and error messages for\n+failed requests are printed. When used in real life, user can choose to filter\n+those data and output them to wherever they want.\n+\n+Convert DICOM Pubsub message to Qido search request\n+===================================================\n+Healthcare API users might use Beam's Pubsub streaming pipeline to monitor the\n+store operations (new DICOM file) in a DICOM storage. Pubsub message encodes\n+DICOM a web store path as well as instance ids. If users are interested in\n+getting new instance's metadata, they can use PubsubToQido() to convert the\n+message into Qido Search dict then use DicomSearch(). Here is a sample usage:\n+\n+  pipeline_options = PipelineOptions()\n+  pipeline_options.view_as(StandardOptions).streaming = True\n+  with beam.Pipeline(options=pipeline_options) as p:\n+    pubsub = p | beam.io.ReadStringFromPubsub(subscription='a_dicom_store')\n+    results = pubsub | PubsubToQido()\n+    success = results | 'filter message' >> beam.Filter(lambda x: x['success'])\n+    qido_dict = success | 'get qido request' >> beam.Map(lambda x: x['result'])\n+    metadata = qido_dict | DicomSearch()\n+\n+In the example above, the pipeline is listening to a pubsub topic and waiting\n+for messages from DICOM API. When a new DICOM file comes into the storage, the\n+pipeline will receive a pubsub message, convert it to a Qido request dict and\n+feed it to DicomSearch() PTransform. As a result, users can get the metadata for\n+every new DICOM file. Note that not every pubsub message received is from DICOM\n+API, so we to filter the results first.\n+\n+Store a DICOM file in a DICOM storage\n+===================================================\n+DicomStoreInstance() wraps store request API and users can use it to send a\n+DICOM file to a DICOM store. It supports two types of input: 1.file data in\n+byte[] 2.fileio object. Users should set the 'input_type' when initialzing\n+this PTransform. Here are the examples:\n+\n+  with Pipeline() as p:\n+    input_dict = {'project_id': 'abc123', 'type': 'instances',...}\n+    path = \"gcs://bucketname/something/a.dcm\"\n+    match = p | fileio.MatchFiles(path)\n+    fileio_obj = match | fileio.ReadAll()\n+    results = fileio_obj | DicomStoreInstance(input_dict, 'fileio')\n+\n+  with Pipeline() as p:\n+    input_dict = {'project_id': 'abc123', 'type': 'instances',...}\n+    f = open(\"abc.dcm\", \"rb\")\n+    dcm_file = f.read()\n+    byte_file = p | 'create byte file' >> beam.Create([dcm_file])\n+    results = byte_file | DicomStoreInstance(input_dict, 'bytes')\n+\n+The first example uses a PCollection of fileio objects as input.\n+DicomStoreInstance will read DICOM files from the objects and send them\n+to a DICOM storage.\n+The second example uses a PCollection of byte[] as input. DicomStoreInstance\n+will directly send those DICOM files to a DICOM storage.\n+Users can also get the operation results in the output PCollection if they want\n+to handle the failed store requests.\n+\"\"\"\n+\n+# pytype: skip-file\n+from __future__ import absolute_import\n+\n+import apache_beam as beam\n+from apache_beam.io.gcp.dicomclient import DicomApiHttpClient\n+from apache_beam.transforms import PTransform\n+\n+\n+class DicomSearch(PTransform):\n+  \"\"\"A PTransform used for retrieving DICOM instance metadata from Google\n+    Cloud DICOM store. It takes a Pcollection of dicts as input and return\n+    a Pcollection of dict as results:\n+    INPUT:\n+    The input dict represents DICOM web path parameters, which has the following\n+    string keys and values:\n+    {\n+      'project_id': str,\n+      'region': str,\n+      'dataset_id': str,\n+      'dicom_store_id': str,\n+      'search_type': str,\n+      'params': dict(str,str) (Optional),\n+    }\n+    Key-value pairs:\n+      project_id: Id of the project in which DICOM store locates. (Required)\n+      region: Region where the DICOM store resides. (Required)\n+      dataset_id: Id of the dataset where DICOM store belongs to. (Required)\n+      dicom_store_id: Id of the dicom store. (Required)\n+      search_type: Which type of search it is, could only be one of the three\n+        values: 'instances', 'series', or 'studies'. (Required)\n+      params: A dict of str:str pairs used to refine QIDO search. (Optional)\n+        Supported tags in three categories:\n+          1. Studies:\n+            StudyInstanceUID\n+            PatientName\n+            PatientID\n+            AccessionNumber\n+            ReferringPhysicianName\n+            StudyDate\n+          2. Series: all study level search terms and\n+            SeriesInstanceUID\n+            Modality\n+          3. Instances: all study/series level search terms and\n+            SOPInstanceUID\n+        e.g. {\"StudyInstanceUID\":\"1\",\"SeriesInstanceUID\":\"2\"}\n+    OUTPUT:\n+    The output dict wraps results as well as error messages:\n+    {\n+      'result': a list of dicts in JSON style.\n+      'success': boolean value telling whether the operation is successful.\n+      'input': detail ids and dicomweb path for this retrieval.\n+      'status': status code from the server, used as error message.\n+    }\n+  \"\"\"\n+  def __init__(self, credential=None):\n+    \"\"\"Initializes DicomSearch.\n+    Args:\n+      credential: # type: Google credential object, if it is specified, the\n+        Http client will use it to create sessions instead of the default.\n+    \"\"\"\n+    self.credential = credential\n+\n+  def expand(self, pcoll):\n+    return pcoll | beam.ParDo(_QidoSource(self.credential))\n+\n+\n+class _QidoSource(beam.DoFn):\n+  \"\"\"A DoFn for executing every qido query request.\"\"\"\n+  def __init__(self, credential=None):\n+    self.credential = credential\n+\n+  def process(self, element):\n+    # Check if all required keys present.\n+    required_keys = [\n+        'project_id', 'region', 'dataset_id', 'dicom_store_id', 'search_type'\n+    ]\n+\n+    error_message = None\n+\n+    for key in required_keys:\n+      if key not in element:\n+        error_message = 'Must have %s in the dict.' % (key)\n+        break\n+\n+    if not error_message:\n+      project_id = element['project_id']\n+      region = element['region']\n+      dataset_id = element['dataset_id']\n+      dicom_store_id = element['dicom_store_id']\n+      search_type = element['search_type']\n+      params = element['params'] if 'params' in element else None\n+\n+      # Call qido search http client\n+      if element['search_type'] in ['instances', \"studies\", \"series\"]:\n+        result, status_code = DicomApiHttpClient().qido_search(\n+          project_id, region, dataset_id, dicom_store_id,\n+          search_type, params, self.credential\n+        )\n+      else:\n+        error_message = (\n+            'Search type can only be \"studies\", '\n+            '\"instances\" or \"series\"')\n+\n+      if not error_message:\n+        out = {}\n+        out['result'] = result\n+        out['status'] = status_code\n+        out['input'] = element\n+        out['success'] = (status_code == 200)\n+        return [out]\n+\n+    # Return this when the input dict dose not meet the requirements\n+    out = {}\n+    out['result'] = []\n+    out['status'] = error_message\n+    out['input'] = element\n+    out['success'] = False\n+    return [out]\n+\n+\n+class PubsubToQido(PTransform):\n+  \"\"\"A PTransform for converting pubsub messages into search input dict.\n+    Takes Pcollection of string as input and returns a Pcollection of dict as\n+    results. Note that some pubsub messages may not be from DICOM API, which\n+    will be recorded as failed conversions.\n+    INPUT:\n+    The input are normally strings from Pubsub topic:\n+      \"projects/PROJECT_ID/locations/LOCATION/datasets/DATASET_ID/\n+      dicomStores/DICOM_STORE_ID/dicomWeb/studies/STUDY_UID/\n+      series/SERIES_UID/instances/INSTANCE_UID\"\n+    OUTPUT:\n+    The output dict encodes results as well as error messages:\n+    {\n+      'result': a dict representing instance level qido search request.\n+      'success': boolean value telling whether the conversion is successful.\n+      'input': input pubsub message string.\n+    }\n+  \"\"\"\n+  def __init__(self, credential=None):\n+    \"\"\"Initializes PubsubToQido.\n+    Args:\n+      credential: # type: Google credential object, if it is specified, the\n+        Http client will use it instead of the default one.\n+    \"\"\"\n+    self.credential = credential\n+\n+  def expand(self, pcoll):\n+    return pcoll | beam.ParDo(_ConvertPubsubToQido())\n+\n+\n+class _ConvertPubsubToQido(beam.DoFn):\n+  \"\"\"A DoFn for converting pubsub string to qido search parameters.\"\"\"\n+  def process(self, element):\n+    # Some constants for DICOM pubsub message\n+    NUM_PUBSUB_STR_ENTRIES = 15\n+    NUM_DICOM_WEBPATH_PARAMETERS = 5\n+    NUM_TOTAL_PARAMETERS = 8\n+    INDEX_PROJECT_ID = 1\n+    INDEX_REGION = 3\n+    INDEX_DATASET_ID = 5\n+    INDEX_DICOMSTORE_ID = 7\n+    INDEX_STUDY_ID = 10\n+    INDEX_SERIE_ID = 12\n+    INDEX_INSTANCE_ID = 14\n+\n+    entries = element.split('/')\n+\n+    # Output dict with error message, used when\n+    # receiving invalid pubsub string.\n+    error_dict = {}\n+    error_dict['result'] = {}\n+    error_dict['input'] = element\n+    error_dict['success'] = False\n+\n+    if len(entries) != NUM_PUBSUB_STR_ENTRIES:\n+      return [error_dict]\n+\n+    required_keys = [\n+        'projects',\n+        'locations',\n+        'datasets',\n+        'dicomStores',\n+        'dicomWeb',\n+        'studies',\n+        'series',\n+        'instances'\n+    ]\n+\n+    # Check if the required keys present and\n+    # the positions of those keys are correct\n+    for i in range(NUM_DICOM_WEBPATH_PARAMETERS):\n+      if required_keys[i] != entries[i * 2]:\n+        return [error_dict]\n+    for i in range(NUM_DICOM_WEBPATH_PARAMETERS, NUM_TOTAL_PARAMETERS):\n+      if required_keys[i] != entries[i * 2 - 1]:\n+        return [error_dict]\n+\n+    # Compose dicom webpath parameters for qido search\n+    qido_dict = {}\n+    qido_dict['project_id'] = entries[INDEX_PROJECT_ID]\n+    qido_dict['region'] = entries[INDEX_REGION]\n+    qido_dict['dataset_id'] = entries[INDEX_DATASET_ID]\n+    qido_dict['dicom_store_id'] = entries[INDEX_DICOMSTORE_ID]\n+    qido_dict['search_type'] = 'instances'\n+\n+    # Compose instance level params for qido search\n+    params = {}\n+    params['StudyInstanceUID'] = entries[INDEX_STUDY_ID]\n+    params['SeriesInstanceUID'] = entries[INDEX_SERIE_ID]\n+    params['SOPInstanceUID'] = entries[INDEX_INSTANCE_ID]\n+    qido_dict['params'] = params\n+\n+    out = {}\n+    out['result'] = qido_dict\n+    out['input'] = element\n+    out['success'] = True\n+\n+    return [out]\n+\n+\n+class DicomStoreInstance(PTransform):\n+  \"\"\"A PTransform for storing instances to a DICOM store.\n+    Takes Pcollection of byte[] as input and return a Pcollection of dict as\n+    results. The inputs are normally DICOM file in bytes or str filename.\n+    INPUT:\n+      This PTransform supports two types of input:\n+        1. Byte[]: representing dicom file.\n+        2. Fileio object: stream file object.\n+    OUTPUT:\n+    The output dict encodes status as well as error messages:\n+    {\n+      'success': boolean value telling whether the store is successful\n+      'input': undeliverable data. Exactly the same as the input,\n+        only set if the operation is failed.\n+      'status': status code from the server, used as error messages.\n+    }\n+  \"\"\"\n+  def __init__(self, destination_dict, input_type, credential=None):\n+    \"\"\"Initializes DicomStoreInstance.\n+    Args:\n+      destination_dict: # type: python dict, encodes DICOM endpoint information:\n+        {\n+          'project_id': str,\n+          'region': str,\n+          'dataset_id': str,\n+          'dicom_store_id': str,\n+        }\n+        Key-value pairs:\n+          project_id: Id of the project in which DICOM store locates. (Required)\n+          region: Region where the DICOM store resides. (Required)\n+          dataset_id: Id of the dataset where DICOM store belongs to. (Required)\n+          dicom_store_id: Id of the dicom store. (Required)\n+      input_type: # type: string, could only be 'bytes' or 'fileio'\n+      credential: # type: Google credential object, if it is specified, the\n+        Http client will use it instead of the default one.\n+    \"\"\"\n+    self.credential = credential\n+    self.destination_dict = destination_dict\n+    # input_type pre-check\n+    if input_type not in ['bytes', 'fileio']:\n+      raise ValueError(\"input_type could only be 'bytes' or 'fileio'\")\n+    self.input_type = input_type\n+\n+  def expand(self, pcoll):\n+    return pcoll | beam.ParDo(\n+        _StoreInstance(self.destination_dict, self.input_type, self.credential))\n+\n+\n+class _StoreInstance(beam.DoFn):\n+  \"\"\"A DoFn read or fetch dicom files then push it to a dicom store.\"\"\"\n+  def __init__(self, destination_dict, input_type, credential=None):\n+    self.credential = credential\n+    # pre-check destination dict\n+    required_keys = ['project_id', 'region', 'dataset_id', 'dicom_store_id']\n+    for key in required_keys:\n+      if key not in destination_dict:\n+        raise ValueError('Must have %s in the dict.' % (key))\n+    self.destination_dict = destination_dict\n+    self.input_type = input_type\n+\n+  def process(self, element):\n+    project_id = self.destination_dict['project_id']\n+    region = self.destination_dict['region']\n+    dataset_id = self.destination_dict['dataset_id']\n+    dicom_store_id = self.destination_dict['dicom_store_id']\n+\n+    # Read the file based on different input. If the read fails ,return\n+    # an error dict which records input and error messages.\n+    dicom_file = None\n+    try:\n+      if self.input_type == 'fileio':\n+        f = element.open()\n+        dicom_file = f.read()\n+      else:\n+        dicom_file = element\n+    except Exception as error_message:\n+      error_out = {}\n+      error_out['status'] = error_message\n+      error_out['input'] = element\n+      error_out['success'] = False\n+      return [error_out]\n+\n+    # Feed the dicom file into store client\n+    _, status_code = DicomApiHttpClient().dicomweb_store_instance(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5d664ebf7585f55abcc9b5a63334f186a1f2a6b1"}, "originalPosition": 410}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk0NjIwNg==", "bodyText": "TODO(@pabloem) Reivew this class.", "url": "https://github.com/apache/beam/pull/12331#discussion_r461946206", "createdAt": "2020-07-28T23:15:22Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/dicomio.py", "diffHunk": "@@ -0,0 +1,419 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"DICOM io connector\n+This module implements serval tools to facilitate the interaction between\n+a Google Cloud Healthcare DICOM store and a beam pipeline.\n+For more details on DICOM store and API:\n+https://cloud.google.com/healthcare/docs/how-tos/dicom\n+DICOM io connector can be used to search metadata or store DICOM files.\n+When used together with Google Pubsub message connector, a PTransform\n+implemented in this module can be used to convert pubsub messages to search\n+requests. Since Traceability is crucial for healthcare API users, every\n+input or error message will be recorded in the output of the DICOM io\n+connector. As a result, every PTransform in this module will return a\n+Pcollection of dict that encodes results and detailed error messages.\n+\n+Search instance's metadata (QIDO request)\n+===================================================\n+DicomSearch() wraps the QIDO request client and supports 3 levels of search.\n+Users should specify the level by setting the 'search_type' entry in the input\n+dict. They can also refine the search by adding tags to filter the results using\n+the 'params' entry. Here is a sample usage:\n+\n+  with Pipeline() as p:\n+    input_dict = p | beam.Create([\n+      {'project_id': 'abc123', 'type': 'instances',...},\n+      {'project_id': 'dicom_go', 'type': 'series',...}\n+    ])\n+    results = input_dict| io.gcp.DicomSearch()\n+    results | 'print successful search' >> beam.Map(\n+        lambda x: print(x['result'] if x['success'] else None))\n+    results | 'print failed search' >> beam.Map(\n+        lambda x: print(x['result'] if not x['success'] else None))\n+\n+In the example above, successful qido search results and error messages for\n+failed requests are printed. When used in real life, user can choose to filter\n+those data and output them to wherever they want.\n+\n+Convert DICOM Pubsub message to Qido search request\n+===================================================\n+Healthcare API users might use Beam's Pubsub streaming pipeline to monitor the\n+store operations (new DICOM file) in a DICOM storage. Pubsub message encodes\n+DICOM a web store path as well as instance ids. If users are interested in\n+getting new instance's metadata, they can use PubsubToQido() to convert the\n+message into Qido Search dict then use DicomSearch(). Here is a sample usage:\n+\n+  pipeline_options = PipelineOptions()\n+  pipeline_options.view_as(StandardOptions).streaming = True\n+  with beam.Pipeline(options=pipeline_options) as p:\n+    pubsub = p | beam.io.ReadStringFromPubsub(subscription='a_dicom_store')\n+    results = pubsub | PubsubToQido()\n+    success = results | 'filter message' >> beam.Filter(lambda x: x['success'])\n+    qido_dict = success | 'get qido request' >> beam.Map(lambda x: x['result'])\n+    metadata = qido_dict | DicomSearch()\n+\n+In the example above, the pipeline is listening to a pubsub topic and waiting\n+for messages from DICOM API. When a new DICOM file comes into the storage, the\n+pipeline will receive a pubsub message, convert it to a Qido request dict and\n+feed it to DicomSearch() PTransform. As a result, users can get the metadata for\n+every new DICOM file. Note that not every pubsub message received is from DICOM\n+API, so we to filter the results first.\n+\n+Store a DICOM file in a DICOM storage\n+===================================================\n+DicomStoreInstance() wraps store request API and users can use it to send a\n+DICOM file to a DICOM store. It supports two types of input: 1.file data in\n+byte[] 2.fileio object. Users should set the 'input_type' when initialzing\n+this PTransform. Here are the examples:\n+\n+  with Pipeline() as p:\n+    input_dict = {'project_id': 'abc123', 'type': 'instances',...}\n+    path = \"gcs://bucketname/something/a.dcm\"\n+    match = p | fileio.MatchFiles(path)\n+    fileio_obj = match | fileio.ReadAll()\n+    results = fileio_obj | DicomStoreInstance(input_dict, 'fileio')\n+\n+  with Pipeline() as p:\n+    input_dict = {'project_id': 'abc123', 'type': 'instances',...}\n+    f = open(\"abc.dcm\", \"rb\")\n+    dcm_file = f.read()\n+    byte_file = p | 'create byte file' >> beam.Create([dcm_file])\n+    results = byte_file | DicomStoreInstance(input_dict, 'bytes')\n+\n+The first example uses a PCollection of fileio objects as input.\n+DicomStoreInstance will read DICOM files from the objects and send them\n+to a DICOM storage.\n+The second example uses a PCollection of byte[] as input. DicomStoreInstance\n+will directly send those DICOM files to a DICOM storage.\n+Users can also get the operation results in the output PCollection if they want\n+to handle the failed store requests.\n+\"\"\"\n+\n+# pytype: skip-file\n+from __future__ import absolute_import\n+\n+import apache_beam as beam\n+from apache_beam.io.gcp.dicomclient import DicomApiHttpClient\n+from apache_beam.transforms import PTransform\n+\n+\n+class DicomSearch(PTransform):\n+  \"\"\"A PTransform used for retrieving DICOM instance metadata from Google\n+    Cloud DICOM store. It takes a Pcollection of dicts as input and return\n+    a Pcollection of dict as results:\n+    INPUT:\n+    The input dict represents DICOM web path parameters, which has the following\n+    string keys and values:\n+    {\n+      'project_id': str,\n+      'region': str,\n+      'dataset_id': str,\n+      'dicom_store_id': str,\n+      'search_type': str,\n+      'params': dict(str,str) (Optional),\n+    }\n+    Key-value pairs:\n+      project_id: Id of the project in which DICOM store locates. (Required)\n+      region: Region where the DICOM store resides. (Required)\n+      dataset_id: Id of the dataset where DICOM store belongs to. (Required)\n+      dicom_store_id: Id of the dicom store. (Required)\n+      search_type: Which type of search it is, could only be one of the three\n+        values: 'instances', 'series', or 'studies'. (Required)\n+      params: A dict of str:str pairs used to refine QIDO search. (Optional)\n+        Supported tags in three categories:\n+          1. Studies:\n+            StudyInstanceUID\n+            PatientName\n+            PatientID\n+            AccessionNumber\n+            ReferringPhysicianName\n+            StudyDate\n+          2. Series: all study level search terms and\n+            SeriesInstanceUID\n+            Modality\n+          3. Instances: all study/series level search terms and\n+            SOPInstanceUID\n+        e.g. {\"StudyInstanceUID\":\"1\",\"SeriesInstanceUID\":\"2\"}\n+    OUTPUT:\n+    The output dict wraps results as well as error messages:\n+    {\n+      'result': a list of dicts in JSON style.\n+      'success': boolean value telling whether the operation is successful.\n+      'input': detail ids and dicomweb path for this retrieval.\n+      'status': status code from the server, used as error message.\n+    }\n+  \"\"\"\n+  def __init__(self, credential=None):\n+    \"\"\"Initializes DicomSearch.\n+    Args:\n+      credential: # type: Google credential object, if it is specified, the\n+        Http client will use it to create sessions instead of the default.\n+    \"\"\"\n+    self.credential = credential\n+\n+  def expand(self, pcoll):\n+    return pcoll | beam.ParDo(_QidoSource(self.credential))\n+\n+\n+class _QidoSource(beam.DoFn):\n+  \"\"\"A DoFn for executing every qido query request.\"\"\"\n+  def __init__(self, credential=None):\n+    self.credential = credential\n+\n+  def process(self, element):\n+    # Check if all required keys present.\n+    required_keys = [\n+        'project_id', 'region', 'dataset_id', 'dicom_store_id', 'search_type'\n+    ]\n+\n+    error_message = None\n+\n+    for key in required_keys:\n+      if key not in element:\n+        error_message = 'Must have %s in the dict.' % (key)\n+        break\n+\n+    if not error_message:\n+      project_id = element['project_id']\n+      region = element['region']\n+      dataset_id = element['dataset_id']\n+      dicom_store_id = element['dicom_store_id']\n+      search_type = element['search_type']\n+      params = element['params'] if 'params' in element else None\n+\n+      # Call qido search http client\n+      if element['search_type'] in ['instances', \"studies\", \"series\"]:\n+        result, status_code = DicomApiHttpClient().qido_search(\n+          project_id, region, dataset_id, dicom_store_id,\n+          search_type, params, self.credential\n+        )\n+      else:\n+        error_message = (\n+            'Search type can only be \"studies\", '\n+            '\"instances\" or \"series\"')\n+\n+      if not error_message:\n+        out = {}\n+        out['result'] = result\n+        out['status'] = status_code\n+        out['input'] = element\n+        out['success'] = (status_code == 200)\n+        return [out]\n+\n+    # Return this when the input dict dose not meet the requirements\n+    out = {}\n+    out['result'] = []\n+    out['status'] = error_message\n+    out['input'] = element\n+    out['success'] = False\n+    return [out]\n+\n+\n+class PubsubToQido(PTransform):\n+  \"\"\"A PTransform for converting pubsub messages into search input dict.\n+    Takes Pcollection of string as input and returns a Pcollection of dict as\n+    results. Note that some pubsub messages may not be from DICOM API, which\n+    will be recorded as failed conversions.\n+    INPUT:\n+    The input are normally strings from Pubsub topic:\n+      \"projects/PROJECT_ID/locations/LOCATION/datasets/DATASET_ID/\n+      dicomStores/DICOM_STORE_ID/dicomWeb/studies/STUDY_UID/\n+      series/SERIES_UID/instances/INSTANCE_UID\"\n+    OUTPUT:\n+    The output dict encodes results as well as error messages:\n+    {\n+      'result': a dict representing instance level qido search request.\n+      'success': boolean value telling whether the conversion is successful.\n+      'input': input pubsub message string.\n+    }\n+  \"\"\"\n+  def __init__(self, credential=None):\n+    \"\"\"Initializes PubsubToQido.\n+    Args:\n+      credential: # type: Google credential object, if it is specified, the\n+        Http client will use it instead of the default one.\n+    \"\"\"\n+    self.credential = credential\n+\n+  def expand(self, pcoll):\n+    return pcoll | beam.ParDo(_ConvertPubsubToQido())\n+\n+\n+class _ConvertPubsubToQido(beam.DoFn):\n+  \"\"\"A DoFn for converting pubsub string to qido search parameters.\"\"\"\n+  def process(self, element):\n+    # Some constants for DICOM pubsub message\n+    NUM_PUBSUB_STR_ENTRIES = 15\n+    NUM_DICOM_WEBPATH_PARAMETERS = 5\n+    NUM_TOTAL_PARAMETERS = 8\n+    INDEX_PROJECT_ID = 1\n+    INDEX_REGION = 3\n+    INDEX_DATASET_ID = 5\n+    INDEX_DICOMSTORE_ID = 7\n+    INDEX_STUDY_ID = 10\n+    INDEX_SERIE_ID = 12\n+    INDEX_INSTANCE_ID = 14\n+\n+    entries = element.split('/')\n+\n+    # Output dict with error message, used when\n+    # receiving invalid pubsub string.\n+    error_dict = {}\n+    error_dict['result'] = {}\n+    error_dict['input'] = element\n+    error_dict['success'] = False\n+\n+    if len(entries) != NUM_PUBSUB_STR_ENTRIES:\n+      return [error_dict]\n+\n+    required_keys = [\n+        'projects',\n+        'locations',\n+        'datasets',\n+        'dicomStores',\n+        'dicomWeb',\n+        'studies',\n+        'series',\n+        'instances'\n+    ]\n+\n+    # Check if the required keys present and\n+    # the positions of those keys are correct\n+    for i in range(NUM_DICOM_WEBPATH_PARAMETERS):\n+      if required_keys[i] != entries[i * 2]:\n+        return [error_dict]\n+    for i in range(NUM_DICOM_WEBPATH_PARAMETERS, NUM_TOTAL_PARAMETERS):\n+      if required_keys[i] != entries[i * 2 - 1]:\n+        return [error_dict]\n+\n+    # Compose dicom webpath parameters for qido search\n+    qido_dict = {}\n+    qido_dict['project_id'] = entries[INDEX_PROJECT_ID]\n+    qido_dict['region'] = entries[INDEX_REGION]\n+    qido_dict['dataset_id'] = entries[INDEX_DATASET_ID]\n+    qido_dict['dicom_store_id'] = entries[INDEX_DICOMSTORE_ID]\n+    qido_dict['search_type'] = 'instances'\n+\n+    # Compose instance level params for qido search\n+    params = {}\n+    params['StudyInstanceUID'] = entries[INDEX_STUDY_ID]\n+    params['SeriesInstanceUID'] = entries[INDEX_SERIE_ID]\n+    params['SOPInstanceUID'] = entries[INDEX_INSTANCE_ID]\n+    qido_dict['params'] = params\n+\n+    out = {}\n+    out['result'] = qido_dict\n+    out['input'] = element\n+    out['success'] = True\n+\n+    return [out]\n+\n+\n+class DicomStoreInstance(PTransform):\n+  \"\"\"A PTransform for storing instances to a DICOM store.\n+    Takes Pcollection of byte[] as input and return a Pcollection of dict as\n+    results. The inputs are normally DICOM file in bytes or str filename.\n+    INPUT:\n+      This PTransform supports two types of input:\n+        1. Byte[]: representing dicom file.\n+        2. Fileio object: stream file object.\n+    OUTPUT:\n+    The output dict encodes status as well as error messages:\n+    {\n+      'success': boolean value telling whether the store is successful\n+      'input': undeliverable data. Exactly the same as the input,\n+        only set if the operation is failed.\n+      'status': status code from the server, used as error messages.\n+    }\n+  \"\"\"\n+  def __init__(self, destination_dict, input_type, credential=None):\n+    \"\"\"Initializes DicomStoreInstance.\n+    Args:\n+      destination_dict: # type: python dict, encodes DICOM endpoint information:\n+        {\n+          'project_id': str,\n+          'region': str,\n+          'dataset_id': str,\n+          'dicom_store_id': str,\n+        }\n+        Key-value pairs:\n+          project_id: Id of the project in which DICOM store locates. (Required)\n+          region: Region where the DICOM store resides. (Required)\n+          dataset_id: Id of the dataset where DICOM store belongs to. (Required)\n+          dicom_store_id: Id of the dicom store. (Required)\n+      input_type: # type: string, could only be 'bytes' or 'fileio'\n+      credential: # type: Google credential object, if it is specified, the\n+        Http client will use it instead of the default one.\n+    \"\"\"\n+    self.credential = credential\n+    self.destination_dict = destination_dict\n+    # input_type pre-check\n+    if input_type not in ['bytes', 'fileio']:\n+      raise ValueError(\"input_type could only be 'bytes' or 'fileio'\")\n+    self.input_type = input_type\n+\n+  def expand(self, pcoll):\n+    return pcoll | beam.ParDo(\n+        _StoreInstance(self.destination_dict, self.input_type, self.credential))\n+\n+\n+class _StoreInstance(beam.DoFn):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5d664ebf7585f55abcc9b5a63334f186a1f2a6b1"}, "originalPosition": 375}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk0NjI4MQ==", "bodyText": "TODO(@pabloem) Reivew this file.", "url": "https://github.com/apache/beam/pull/12331#discussion_r461946281", "createdAt": "2020-07-28T23:15:37Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/dicomio_test.py", "diffHunk": "@@ -0,0 +1,368 @@\n+# coding=utf-8\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Unit tests for Dicom IO connectors.\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import json", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5d664ebf7585f55abcc9b5a63334f186a1f2a6b1"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk0NjQwNw==", "bodyText": "TODO(@pabloem) Reivew this section of the documentation", "url": "https://github.com/apache/beam/pull/12331#discussion_r461946407", "createdAt": "2020-07-28T23:15:58Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/dicomio.py", "diffHunk": "@@ -0,0 +1,419 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"DICOM io connector\n+This module implements serval tools to facilitate the interaction between\n+a Google Cloud Healthcare DICOM store and a beam pipeline.\n+For more details on DICOM store and API:\n+https://cloud.google.com/healthcare/docs/how-tos/dicom\n+DICOM io connector can be used to search metadata or store DICOM files.\n+When used together with Google Pubsub message connector, a PTransform\n+implemented in this module can be used to convert pubsub messages to search\n+requests. Since Traceability is crucial for healthcare API users, every", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5d664ebf7585f55abcc9b5a63334f186a1f2a6b1"}, "originalPosition": 26}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "04d37cdbcc823df38fcc5e71362143ae912972b2", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/04d37cdbcc823df38fcc5e71362143ae912972b2", "committedDate": "2020-07-29T13:12:13Z", "message": "fix typos and pydocs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4dde591a610f2c94c4bd46037343b11ad5285515", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/4dde591a610f2c94c4bd46037343b11ad5285515", "committedDate": "2020-07-29T13:30:08Z", "message": "Merge branch 'master' of github.com:apache/beam into master"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fb9bbd414f3b04939e797cfb63b29403a1eadb25", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/fb9bbd414f3b04939e797cfb63b29403a1eadb25", "committedDate": "2020-07-29T13:34:40Z", "message": "fix style"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3690b109da3395ee955af8484610cd32644011b2", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/3690b109da3395ee955af8484610cd32644011b2", "committedDate": "2020-07-29T14:17:31Z", "message": "fix annoying style"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "21fd738ec158d5d205d9ae21b8fbbf71bb48d3ca", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/21fd738ec158d5d205d9ae21b8fbbf71bb48d3ca", "committedDate": "2020-07-30T13:37:10Z", "message": "Add concurrent support"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU4NzY2NjM1", "url": "https://github.com/apache/beam/pull/12331#pullrequestreview-458766635", "createdAt": "2020-07-30T21:23:44Z", "commit": {"oid": "04d37cdbcc823df38fcc5e71362143ae912972b2"}, "state": "COMMENTED", "comments": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQyMToyMzo0NFrOG50VIA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMFQyMzoxMzo1MVrOG525Xg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzI3OTM5Mg==", "bodyText": "Was the indentantion causing issues here? It would be good to keep it to have some kind of formatting... perhaps you can use dashes to show formatting? LMK if we should research a bit together.", "url": "https://github.com/apache/beam/pull/12331#discussion_r463279392", "createdAt": "2020-07-30T21:23:44Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/dicomio.py", "diffHunk": "@@ -114,55 +115,60 @@\n \n class DicomSearch(PTransform):\n   \"\"\"A PTransform used for retrieving DICOM instance metadata from Google\n-    Cloud DICOM store. It takes a Pcollection of dicts as input and return\n-    a Pcollection of dict as results:\n+    Cloud DICOM store. It takes a PCollection of dicts as input and return\n+    a PCollection of dict as results:\n     INPUT:\n     The input dict represents DICOM web path parameters, which has the following\n     string keys and values:\n     {\n-      'project_id': str,\n-      'region': str,\n-      'dataset_id': str,\n-      'dicom_store_id': str,\n-      'search_type': str,\n-      'params': dict(str,str) (Optional),\n+    'project_id': str,\n+    'region': str,\n+    'dataset_id': str,\n+    'dicom_store_id': str,\n+    'search_type': str,\n+    'params': dict(str,str) (Optional),\n     }\n+\n     Key-value pairs:\n-      project_id: Id of the project in which DICOM store locates. (Required)\n+      project_id: Id of the project in which the DICOM store is\n+      located. (Required)\n       region: Region where the DICOM store resides. (Required)\n       dataset_id: Id of the dataset where DICOM store belongs to. (Required)\n       dicom_store_id: Id of the dicom store. (Required)\n       search_type: Which type of search it is, could only be one of the three\n-        values: 'instances', 'series', or 'studies'. (Required)\n+      values: 'instances', 'series', or 'studies'. (Required)\n       params: A dict of str:str pairs used to refine QIDO search. (Optional)\n-        Supported tags in three categories:\n-          1. Studies:\n-            StudyInstanceUID\n-            PatientName\n-            PatientID\n-            AccessionNumber\n-            ReferringPhysicianName\n-            StudyDate\n-          2. Series: all study level search terms and\n-            SeriesInstanceUID\n-            Modality\n-          3. Instances: all study/series level search terms and\n-            SOPInstanceUID\n-        e.g. {\"StudyInstanceUID\":\"1\",\"SeriesInstanceUID\":\"2\"}\n+      Supported tags in three categories:\n+      1.Studies:\n+      StudyInstanceUID,\n+      PatientName,\n+      PatientID,\n+      AccessionNumber,\n+      ReferringPhysicianName,\n+      StudyDate,\n+      2.Series: all study level search terms and\n+      SeriesInstanceUID,\n+      Modality,\n+      3.Instances: all study/series level search terms and\n+      SOPInstanceUID,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "04d37cdbcc823df38fcc5e71362143ae912972b2"}, "originalPosition": 135}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzI3OTk2MA==", "bodyText": "curious about the indentation here as well", "url": "https://github.com/apache/beam/pull/12331#discussion_r463279960", "createdAt": "2020-07-30T21:24:55Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/dicomio.py", "diffHunk": "@@ -324,41 +332,45 @@ def process(self, element):\n     return [out]\n \n \n-class DicomStoreInstance(PTransform):\n+class WriteToDicomStore(PTransform):\n   \"\"\"A PTransform for storing instances to a DICOM store.\n-    Takes Pcollection of byte[] as input and return a Pcollection of dict as\n+    Takes PCollection of byte[] as input and return a PCollection of dict as\n     results. The inputs are normally DICOM file in bytes or str filename.\n     INPUT:\n-      This PTransform supports two types of input:\n-        1. Byte[]: representing dicom file.\n-        2. Fileio object: stream file object.\n+    This PTransform supports two types of input:\n+    1. Byte[]: representing dicom file.\n+    2. Fileio object: stream file object.\n+    \n     OUTPUT:\n     The output dict encodes status as well as error messages:\n     {\n-      'success': boolean value telling whether the store is successful\n-      'input': undeliverable data. Exactly the same as the input,\n-        only set if the operation is failed.\n-      'status': status code from the server, used as error messages.\n+    'success': boolean value telling whether the store is successful.\n+    'input': undeliverable data. Exactly the same as the input,\n+    only set if the operation is failed.\n+    'status': status code from the server, used as error messages.\n     }\n+\n   \"\"\"\n   def __init__(self, destination_dict, input_type, credential=None):\n-    \"\"\"Initializes DicomStoreInstance.\n+    \"\"\"Initializes WriteToDicomStore.\n     Args:\n       destination_dict: # type: python dict, encodes DICOM endpoint information:\n-        {\n-          'project_id': str,\n-          'region': str,\n-          'dataset_id': str,\n-          'dicom_store_id': str,\n-        }\n-        Key-value pairs:\n-          project_id: Id of the project in which DICOM store locates. (Required)\n-          region: Region where the DICOM store resides. (Required)\n-          dataset_id: Id of the dataset where DICOM store belongs to. (Required)\n-          dicom_store_id: Id of the dicom store. (Required)\n+      {\n+      'project_id': str,\n+      'region': str,\n+      'dataset_id': str,\n+      'dicom_store_id': str,\n+      }\n+\n+      Key-value pairs:\n+      project_id: Id of the project in which DICOM store locates. (Required)\n+      region: Region where the DICOM store resides. (Required)\n+      dataset_id: Id of the dataset where DICOM store belongs to. (Required)\n+      dicom_store_id: Id of the dicom store. (Required)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "04d37cdbcc823df38fcc5e71362143ae912972b2"}, "originalPosition": 259}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzI4MDQ3OQ==", "bodyText": "this should be in GCP_REQUIREMENTS, not in REQUIRED_PACKAGES. Why do you find you need it here?", "url": "https://github.com/apache/beam/pull/12331#discussion_r463280479", "createdAt": "2020-07-30T21:25:56Z", "author": {"login": "pabloem"}, "path": "sdks/python/setup.py", "diffHunk": "@@ -128,6 +128,7 @@ def get_version():\n   cythonize = lambda *args, **kwargs: []\n \n REQUIRED_PACKAGES = [\n+    'google-auth>=1.18.0,<=1.20.0',", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "abf7600d697ffbd59ef7a7fdddea791843467715"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzI4MDYxNg==", "bodyText": "you can also be more liberal with the versions. Probably <2 should suffice.", "url": "https://github.com/apache/beam/pull/12331#discussion_r463280616", "createdAt": "2020-07-30T21:26:15Z", "author": {"login": "pabloem"}, "path": "sdks/python/setup.py", "diffHunk": "@@ -128,6 +128,7 @@ def get_version():\n   cythonize = lambda *args, **kwargs: []\n \n REQUIRED_PACKAGES = [\n+    'google-auth>=1.18.0,<=1.20.0',", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzI4MDQ3OQ=="}, "originalCommit": {"oid": "abf7600d697ffbd59ef7a7fdddea791843467715"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzI4MTQzNA==", "bodyText": "this is reasonable. Thanks!", "url": "https://github.com/apache/beam/pull/12331#discussion_r463281434", "createdAt": "2020-07-30T21:27:54Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/dicomio.py", "diffHunk": "@@ -0,0 +1,419 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"DICOM io connector\n+This module implements serval tools to facilitate the interaction between\n+a Google Cloud Healthcare DICOM store and a beam pipeline.\n+For more details on DICOM store and API:\n+https://cloud.google.com/healthcare/docs/how-tos/dicom\n+DICOM io connector can be used to search metadata or store DICOM files.\n+When used together with Google Pubsub message connector, a PTransform\n+implemented in this module can be used to convert pubsub messages to search\n+requests. Since Traceability is crucial for healthcare API users, every\n+input or error message will be recorded in the output of the DICOM io\n+connector. As a result, every PTransform in this module will return a\n+Pcollection of dict that encodes results and detailed error messages.\n+\n+Search instance's metadata (QIDO request)\n+===================================================\n+DicomSearch() wraps the QIDO request client and supports 3 levels of search.\n+Users should specify the level by setting the 'search_type' entry in the input\n+dict. They can also refine the search by adding tags to filter the results using\n+the 'params' entry. Here is a sample usage:\n+\n+  with Pipeline() as p:\n+    input_dict = p | beam.Create([\n+      {'project_id': 'abc123', 'type': 'instances',...},\n+      {'project_id': 'dicom_go', 'type': 'series',...}\n+    ])\n+    results = input_dict| io.gcp.DicomSearch()\n+    results | 'print successful search' >> beam.Map(\n+        lambda x: print(x['result'] if x['success'] else None))\n+    results | 'print failed search' >> beam.Map(\n+        lambda x: print(x['result'] if not x['success'] else None))\n+\n+In the example above, successful qido search results and error messages for\n+failed requests are printed. When used in real life, user can choose to filter\n+those data and output them to wherever they want.\n+\n+Convert DICOM Pubsub message to Qido search request\n+===================================================\n+Healthcare API users might use Beam's Pubsub streaming pipeline to monitor the\n+store operations (new DICOM file) in a DICOM storage. Pubsub message encodes\n+DICOM a web store path as well as instance ids. If users are interested in\n+getting new instance's metadata, they can use PubsubToQido() to convert the\n+message into Qido Search dict then use DicomSearch(). Here is a sample usage:\n+\n+  pipeline_options = PipelineOptions()\n+  pipeline_options.view_as(StandardOptions).streaming = True\n+  with beam.Pipeline(options=pipeline_options) as p:\n+    pubsub = p | beam.io.ReadStringFromPubsub(subscription='a_dicom_store')\n+    results = pubsub | PubsubToQido()\n+    success = results | 'filter message' >> beam.Filter(lambda x: x['success'])\n+    qido_dict = success | 'get qido request' >> beam.Map(lambda x: x['result'])\n+    metadata = qido_dict | DicomSearch()\n+\n+In the example above, the pipeline is listening to a pubsub topic and waiting\n+for messages from DICOM API. When a new DICOM file comes into the storage, the\n+pipeline will receive a pubsub message, convert it to a Qido request dict and\n+feed it to DicomSearch() PTransform. As a result, users can get the metadata for\n+every new DICOM file. Note that not every pubsub message received is from DICOM\n+API, so we to filter the results first.\n+\n+Store a DICOM file in a DICOM storage\n+===================================================\n+DicomStoreInstance() wraps store request API and users can use it to send a\n+DICOM file to a DICOM store. It supports two types of input: 1.file data in\n+byte[] 2.fileio object. Users should set the 'input_type' when initialzing\n+this PTransform. Here are the examples:\n+\n+  with Pipeline() as p:\n+    input_dict = {'project_id': 'abc123', 'type': 'instances',...}\n+    path = \"gcs://bucketname/something/a.dcm\"\n+    match = p | fileio.MatchFiles(path)\n+    fileio_obj = match | fileio.ReadAll()\n+    results = fileio_obj | DicomStoreInstance(input_dict, 'fileio')\n+\n+  with Pipeline() as p:\n+    input_dict = {'project_id': 'abc123', 'type': 'instances',...}\n+    f = open(\"abc.dcm\", \"rb\")\n+    dcm_file = f.read()\n+    byte_file = p | 'create byte file' >> beam.Create([dcm_file])\n+    results = byte_file | DicomStoreInstance(input_dict, 'bytes')\n+\n+The first example uses a PCollection of fileio objects as input.\n+DicomStoreInstance will read DICOM files from the objects and send them\n+to a DICOM storage.\n+The second example uses a PCollection of byte[] as input. DicomStoreInstance\n+will directly send those DICOM files to a DICOM storage.\n+Users can also get the operation results in the output PCollection if they want\n+to handle the failed store requests.\n+\"\"\"\n+\n+# pytype: skip-file\n+from __future__ import absolute_import\n+\n+import apache_beam as beam\n+from apache_beam.io.gcp.dicomclient import DicomApiHttpClient\n+from apache_beam.transforms import PTransform\n+\n+\n+class DicomSearch(PTransform):\n+  \"\"\"A PTransform used for retrieving DICOM instance metadata from Google\n+    Cloud DICOM store. It takes a Pcollection of dicts as input and return\n+    a Pcollection of dict as results:\n+    INPUT:\n+    The input dict represents DICOM web path parameters, which has the following\n+    string keys and values:\n+    {\n+      'project_id': str,\n+      'region': str,\n+      'dataset_id': str,\n+      'dicom_store_id': str,\n+      'search_type': str,\n+      'params': dict(str,str) (Optional),\n+    }\n+    Key-value pairs:\n+      project_id: Id of the project in which DICOM store locates. (Required)\n+      region: Region where the DICOM store resides. (Required)\n+      dataset_id: Id of the dataset where DICOM store belongs to. (Required)\n+      dicom_store_id: Id of the dicom store. (Required)\n+      search_type: Which type of search it is, could only be one of the three\n+        values: 'instances', 'series', or 'studies'. (Required)\n+      params: A dict of str:str pairs used to refine QIDO search. (Optional)\n+        Supported tags in three categories:\n+          1. Studies:\n+            StudyInstanceUID\n+            PatientName\n+            PatientID\n+            AccessionNumber\n+            ReferringPhysicianName\n+            StudyDate\n+          2. Series: all study level search terms and\n+            SeriesInstanceUID\n+            Modality\n+          3. Instances: all study/series level search terms and\n+            SOPInstanceUID\n+        e.g. {\"StudyInstanceUID\":\"1\",\"SeriesInstanceUID\":\"2\"}\n+    OUTPUT:\n+    The output dict wraps results as well as error messages:\n+    {\n+      'result': a list of dicts in JSON style.\n+      'success': boolean value telling whether the operation is successful.\n+      'input': detail ids and dicomweb path for this retrieval.\n+      'status': status code from the server, used as error message.\n+    }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTkyNzMxMg=="}, "originalCommit": {"oid": "5d664ebf7585f55abcc9b5a63334f186a1f2a6b1"}, "originalPosition": 159}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzI4MjM1MQ==", "bodyText": "you may need to return self._flush(), right?", "url": "https://github.com/apache/beam/pull/12331#discussion_r463282351", "createdAt": "2020-07-30T21:29:50Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/dicomio.py", "diffHunk": "@@ -372,52 +420,63 @@ def __init__(self, destination_dict, input_type, credential=None):\n       credential: # type: Google credential object, if it is specified, the\n       Http client will use it instead of the default one.\n     \"\"\"\n-    self.credential = credential\n     self.destination_dict = destination_dict\n     # input_type pre-check\n     if input_type not in ['bytes', 'fileio']:\n       raise ValueError(\"input_type could only be 'bytes' or 'fileio'\")\n     self.input_type = input_type\n+    self.buffer_size = buffer_size\n+    self.max_workers = max_workers\n+    self.credential = credential\n \n   def expand(self, pcoll):\n     return pcoll | beam.ParDo(\n-        _StoreInstance(self.destination_dict, self.input_type, self.credential))\n+        _StoreInstance(\n+            self.destination_dict,\n+            self.input_type,\n+            self.buffer_size,\n+            self.max_workers,\n+            self.credential))\n \n \n class _StoreInstance(beam.DoFn):\n   \"\"\"A DoFn read or fetch dicom files then push it to a dicom store.\"\"\"\n-  def __init__(self, destination_dict, input_type, credential=None):\n-    self.credential = credential\n+  def __init__(\n+      self,\n+      destination_dict,\n+      input_type,\n+      buffer_size,\n+      max_workers,\n+      credential=None):\n     # pre-check destination dict\n     required_keys = ['project_id', 'region', 'dataset_id', 'dicom_store_id']\n     for key in required_keys:\n       if key not in destination_dict:\n         raise ValueError('Must have %s in the dict.' % (key))\n     self.destination_dict = destination_dict\n     self.input_type = input_type\n+    self.buffer_size = buffer_size\n+    self.max_workers = max_workers\n+    self.credential = credential\n \n-  def process(self, element):\n+  def start_bundle(self):\n+    self.buffer = []\n+\n+  def finish_bundle(self):\n+    return self._flush()\n+\n+  def process(self, element, window=beam.DoFn.WindowParam):\n+    self.buffer.append((element, window))\n+    if len(self.buffer) >= self.buffer_size:\n+      self._flush()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "21fd738ec158d5d205d9ae21b8fbbf71bb48d3ca"}, "originalPosition": 232}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzI4MjYwNA==", "bodyText": "Are you able to add a test for this? a unittest should be fine, to make sure that data is returned appropriately?", "url": "https://github.com/apache/beam/pull/12331#discussion_r463282604", "createdAt": "2020-07-30T21:30:25Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/dicomio.py", "diffHunk": "@@ -372,52 +420,63 @@ def __init__(self, destination_dict, input_type, credential=None):\n       credential: # type: Google credential object, if it is specified, the\n       Http client will use it instead of the default one.\n     \"\"\"\n-    self.credential = credential\n     self.destination_dict = destination_dict\n     # input_type pre-check\n     if input_type not in ['bytes', 'fileio']:\n       raise ValueError(\"input_type could only be 'bytes' or 'fileio'\")\n     self.input_type = input_type\n+    self.buffer_size = buffer_size\n+    self.max_workers = max_workers\n+    self.credential = credential\n \n   def expand(self, pcoll):\n     return pcoll | beam.ParDo(\n-        _StoreInstance(self.destination_dict, self.input_type, self.credential))\n+        _StoreInstance(\n+            self.destination_dict,\n+            self.input_type,\n+            self.buffer_size,\n+            self.max_workers,\n+            self.credential))\n \n \n class _StoreInstance(beam.DoFn):\n   \"\"\"A DoFn read or fetch dicom files then push it to a dicom store.\"\"\"\n-  def __init__(self, destination_dict, input_type, credential=None):\n-    self.credential = credential\n+  def __init__(\n+      self,\n+      destination_dict,\n+      input_type,\n+      buffer_size,\n+      max_workers,\n+      credential=None):\n     # pre-check destination dict\n     required_keys = ['project_id', 'region', 'dataset_id', 'dicom_store_id']\n     for key in required_keys:\n       if key not in destination_dict:\n         raise ValueError('Must have %s in the dict.' % (key))\n     self.destination_dict = destination_dict\n     self.input_type = input_type\n+    self.buffer_size = buffer_size\n+    self.max_workers = max_workers\n+    self.credential = credential\n \n-  def process(self, element):\n+  def start_bundle(self):\n+    self.buffer = []\n+\n+  def finish_bundle(self):\n+    return self._flush()\n+\n+  def process(self, element, window=beam.DoFn.WindowParam):\n+    self.buffer.append((element, window))\n+    if len(self.buffer) >= self.buffer_size:\n+      self._flush()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzI4MjM1MQ=="}, "originalCommit": {"oid": "21fd738ec158d5d205d9ae21b8fbbf71bb48d3ca"}, "originalPosition": 232}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzMxOTc1NA==", "bodyText": "you may need to add the timestamp to the buffer as well, just to avoid losing the appropriate timestamp of your element (via DoFn.TimestampParam I believe)", "url": "https://github.com/apache/beam/pull/12331#discussion_r463319754", "createdAt": "2020-07-30T23:08:13Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/dicomio.py", "diffHunk": "@@ -426,6 +485,44 @@ def process(self, element):\n \n     out = {}\n     out['status'] = status_code\n-    out['input'] = None if status_code == 200 else element\n+    out['input'] = None if status_code == 200 else dicom_file\n     out['success'] = (status_code == 200)\n-    return [out]\n+    return out\n+\n+  def read_dicom_file(self, buffer_element):\n+    # Read the file based on different input. If the read fails ,return\n+    # an error dict which records input and error messages.\n+    try:\n+      if self.input_type == 'fileio':\n+        f = buffer_element.open()\n+        return True, f.read()\n+      else:\n+        return True, buffer_element\n+    except Exception as error_message:\n+      error_out = {}\n+      error_out['status'] = error_message\n+      error_out['input'] = buffer_element\n+      error_out['success'] = False\n+      return False, error_out\n+\n+  def process_buffer_element(self, buffer_element):\n+    # Thread job runner - each thread stores a DICOM file\n+    success, read_result = self.read_dicom_file(buffer_element[0])\n+    windows = [buffer_element[1]]\n+    value = None\n+    if success:\n+      value = self.make_request(read_result)\n+    else:\n+      value = read_result\n+    return beam.utils.windowed_value.WindowedValue(\n+        value=value, timestamp=0, windows=windows)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "21fd738ec158d5d205d9ae21b8fbbf71bb48d3ca"}, "originalPosition": 296}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzMyMDA0NQ==", "bodyText": "it may be that your elements don't have a timestamp assigned, but it may also be that users will have streaming pipeliness where the timestamps matter", "url": "https://github.com/apache/beam/pull/12331#discussion_r463320045", "createdAt": "2020-07-30T23:09:16Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/dicomio.py", "diffHunk": "@@ -426,6 +485,44 @@ def process(self, element):\n \n     out = {}\n     out['status'] = status_code\n-    out['input'] = None if status_code == 200 else element\n+    out['input'] = None if status_code == 200 else dicom_file\n     out['success'] = (status_code == 200)\n-    return [out]\n+    return out\n+\n+  def read_dicom_file(self, buffer_element):\n+    # Read the file based on different input. If the read fails ,return\n+    # an error dict which records input and error messages.\n+    try:\n+      if self.input_type == 'fileio':\n+        f = buffer_element.open()\n+        return True, f.read()\n+      else:\n+        return True, buffer_element\n+    except Exception as error_message:\n+      error_out = {}\n+      error_out['status'] = error_message\n+      error_out['input'] = buffer_element\n+      error_out['success'] = False\n+      return False, error_out\n+\n+  def process_buffer_element(self, buffer_element):\n+    # Thread job runner - each thread stores a DICOM file\n+    success, read_result = self.read_dicom_file(buffer_element[0])\n+    windows = [buffer_element[1]]\n+    value = None\n+    if success:\n+      value = self.make_request(read_result)\n+    else:\n+      value = read_result\n+    return beam.utils.windowed_value.WindowedValue(\n+        value=value, timestamp=0, windows=windows)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzMxOTc1NA=="}, "originalCommit": {"oid": "21fd738ec158d5d205d9ae21b8fbbf71bb48d3ca"}, "originalPosition": 296}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzMyMDYwOA==", "bodyText": "as part of a unittest, sometimes it's useful to give users the ability to override the DicomApiHttpClient with a mock or mock-like object. This is not required, but it may be useful to add unit tests.\nIf not, please create a JIRA issue to track this, and add a TODO around here", "url": "https://github.com/apache/beam/pull/12331#discussion_r463320608", "createdAt": "2020-07-30T23:10:59Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/dicomio.py", "diffHunk": "@@ -372,52 +420,63 @@ def __init__(self, destination_dict, input_type, credential=None):\n       credential: # type: Google credential object, if it is specified, the\n       Http client will use it instead of the default one.\n     \"\"\"\n-    self.credential = credential\n     self.destination_dict = destination_dict\n     # input_type pre-check\n     if input_type not in ['bytes', 'fileio']:\n       raise ValueError(\"input_type could only be 'bytes' or 'fileio'\")\n     self.input_type = input_type\n+    self.buffer_size = buffer_size\n+    self.max_workers = max_workers\n+    self.credential = credential\n \n   def expand(self, pcoll):\n     return pcoll | beam.ParDo(\n-        _StoreInstance(self.destination_dict, self.input_type, self.credential))\n+        _StoreInstance(\n+            self.destination_dict,\n+            self.input_type,\n+            self.buffer_size,\n+            self.max_workers,\n+            self.credential))\n \n \n class _StoreInstance(beam.DoFn):\n   \"\"\"A DoFn read or fetch dicom files then push it to a dicom store.\"\"\"\n-  def __init__(self, destination_dict, input_type, credential=None):\n-    self.credential = credential\n+  def __init__(\n+      self,\n+      destination_dict,\n+      input_type,\n+      buffer_size,\n+      max_workers,\n+      credential=None):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "21fd738ec158d5d205d9ae21b8fbbf71bb48d3ca"}, "originalPosition": 210}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzMyMDgyMg==", "bodyText": "you have to yield the output from the flush, right?", "url": "https://github.com/apache/beam/pull/12331#discussion_r463320822", "createdAt": "2020-07-30T23:11:46Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/dicomio.py", "diffHunk": "@@ -164,70 +167,109 @@ class DicomSearch(PTransform):\n     }\n \n   \"\"\"\n-  def __init__(self, credential=None):\n+  def __init__(self, buffer_size=8, max_workers=5, credential=None):\n     \"\"\"Initializes DicomSearch.\n     Args:\n       credential: # type: Google credential object, if it is specified, the\n       Http client will use it to create sessions instead of the default.\n     \"\"\"\n+    self.buffer_size = buffer_size\n+    self.max_workers = max_workers\n     self.credential = credential\n \n   def expand(self, pcoll):\n-    return pcoll | beam.ParDo(_QidoSource(self.credential))\n+    return pcoll | beam.ParDo(\n+        _QidoSource(self.buffer_size, self.max_workers, self.credential))\n \n \n class _QidoSource(beam.DoFn):\n   \"\"\"A DoFn for executing every qido query request.\"\"\"\n-  def __init__(self, credential=None):\n+  def __init__(self, buffer_size, max_workers, credential=None):\n+    self.buffer_size = buffer_size\n+    self.max_workers = max_workers\n     self.credential = credential\n \n-  def process(self, element):\n+  def start_bundle(self):\n+    self.buffer = []\n+\n+  def finish_bundle(self):\n+    return self._flush()\n+\n+  def validate_element(self, element):\n     # Check if all required keys present.\n     required_keys = [\n         'project_id', 'region', 'dataset_id', 'dicom_store_id', 'search_type'\n     ]\n \n-    error_message = None\n-\n     for key in required_keys:\n       if key not in element:\n         error_message = 'Must have %s in the dict.' % (key)\n-        break\n-\n-    if not error_message:\n-      project_id = element['project_id']\n-      region = element['region']\n-      dataset_id = element['dataset_id']\n-      dicom_store_id = element['dicom_store_id']\n-      search_type = element['search_type']\n-      params = element['params'] if 'params' in element else None\n-\n-      # Call qido search http client\n-      if element['search_type'] in ['instances', \"studies\", \"series\"]:\n-        result, status_code = DicomApiHttpClient().qido_search(\n-          project_id, region, dataset_id, dicom_store_id,\n-          search_type, params, self.credential\n-        )\n-      else:\n-        error_message = (\n-            'Search type can only be \"studies\", '\n-            '\"instances\" or \"series\"')\n-\n-      if not error_message:\n-        out = {}\n-        out['result'] = result\n-        out['status'] = status_code\n-        out['input'] = element\n-        out['success'] = (status_code == 200)\n-        return [out]\n-\n-    # Return this when the input dict dose not meet the requirements\n+        return False, error_message\n+\n+    # Check if return type is correct.\n+    if element['search_type'] in ['instances', \"studies\", \"series\"]:\n+      return True, None\n+    else:\n+      error_message = (\n+          'Search type can only be \"studies\", '\n+          '\"instances\" or \"series\"')\n+      return False, error_message\n+\n+  def process(self, element, window=beam.DoFn.WindowParam):\n+    # Check if the element is valid\n+    valid, error_message = self.validate_element(element)\n+\n+    if valid:\n+      self.buffer.append((element, window))\n+      if len(self.buffer) >= self.buffer_size:\n+        self._flush()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "21fd738ec158d5d205d9ae21b8fbbf71bb48d3ca"}, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzMyMDk3OA==", "bodyText": "again, it may be worth adding a test for this.", "url": "https://github.com/apache/beam/pull/12331#discussion_r463320978", "createdAt": "2020-07-30T23:12:16Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/dicomio.py", "diffHunk": "@@ -164,70 +167,109 @@ class DicomSearch(PTransform):\n     }\n \n   \"\"\"\n-  def __init__(self, credential=None):\n+  def __init__(self, buffer_size=8, max_workers=5, credential=None):\n     \"\"\"Initializes DicomSearch.\n     Args:\n       credential: # type: Google credential object, if it is specified, the\n       Http client will use it to create sessions instead of the default.\n     \"\"\"\n+    self.buffer_size = buffer_size\n+    self.max_workers = max_workers\n     self.credential = credential\n \n   def expand(self, pcoll):\n-    return pcoll | beam.ParDo(_QidoSource(self.credential))\n+    return pcoll | beam.ParDo(\n+        _QidoSource(self.buffer_size, self.max_workers, self.credential))\n \n \n class _QidoSource(beam.DoFn):\n   \"\"\"A DoFn for executing every qido query request.\"\"\"\n-  def __init__(self, credential=None):\n+  def __init__(self, buffer_size, max_workers, credential=None):\n+    self.buffer_size = buffer_size\n+    self.max_workers = max_workers\n     self.credential = credential\n \n-  def process(self, element):\n+  def start_bundle(self):\n+    self.buffer = []\n+\n+  def finish_bundle(self):\n+    return self._flush()\n+\n+  def validate_element(self, element):\n     # Check if all required keys present.\n     required_keys = [\n         'project_id', 'region', 'dataset_id', 'dicom_store_id', 'search_type'\n     ]\n \n-    error_message = None\n-\n     for key in required_keys:\n       if key not in element:\n         error_message = 'Must have %s in the dict.' % (key)\n-        break\n-\n-    if not error_message:\n-      project_id = element['project_id']\n-      region = element['region']\n-      dataset_id = element['dataset_id']\n-      dicom_store_id = element['dicom_store_id']\n-      search_type = element['search_type']\n-      params = element['params'] if 'params' in element else None\n-\n-      # Call qido search http client\n-      if element['search_type'] in ['instances', \"studies\", \"series\"]:\n-        result, status_code = DicomApiHttpClient().qido_search(\n-          project_id, region, dataset_id, dicom_store_id,\n-          search_type, params, self.credential\n-        )\n-      else:\n-        error_message = (\n-            'Search type can only be \"studies\", '\n-            '\"instances\" or \"series\"')\n-\n-      if not error_message:\n-        out = {}\n-        out['result'] = result\n-        out['status'] = status_code\n-        out['input'] = element\n-        out['success'] = (status_code == 200)\n-        return [out]\n-\n-    # Return this when the input dict dose not meet the requirements\n+        return False, error_message\n+\n+    # Check if return type is correct.\n+    if element['search_type'] in ['instances', \"studies\", \"series\"]:\n+      return True, None\n+    else:\n+      error_message = (\n+          'Search type can only be \"studies\", '\n+          '\"instances\" or \"series\"')\n+      return False, error_message\n+\n+  def process(self, element, window=beam.DoFn.WindowParam):\n+    # Check if the element is valid\n+    valid, error_message = self.validate_element(element)\n+\n+    if valid:\n+      self.buffer.append((element, window))\n+      if len(self.buffer) >= self.buffer_size:\n+        self._flush()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzMyMDgyMg=="}, "originalCommit": {"oid": "21fd738ec158d5d205d9ae21b8fbbf71bb48d3ca"}, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzMyMTE2Ng==", "bodyText": "it may be good to rename this class to _QuidoReadFn? That's because Source is another class type in Beam.", "url": "https://github.com/apache/beam/pull/12331#discussion_r463321166", "createdAt": "2020-07-30T23:12:56Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/dicomio.py", "diffHunk": "@@ -164,70 +167,109 @@ class DicomSearch(PTransform):\n     }\n \n   \"\"\"\n-  def __init__(self, credential=None):\n+  def __init__(self, buffer_size=8, max_workers=5, credential=None):\n     \"\"\"Initializes DicomSearch.\n     Args:\n       credential: # type: Google credential object, if it is specified, the\n       Http client will use it to create sessions instead of the default.\n     \"\"\"\n+    self.buffer_size = buffer_size\n+    self.max_workers = max_workers\n     self.credential = credential\n \n   def expand(self, pcoll):\n-    return pcoll | beam.ParDo(_QidoSource(self.credential))\n+    return pcoll | beam.ParDo(\n+        _QidoSource(self.buffer_size, self.max_workers, self.credential))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "21fd738ec158d5d205d9ae21b8fbbf71bb48d3ca"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzMyMTQzOA==", "bodyText": "and also, it may be good to enable users to override the DicomHttpApiClient here", "url": "https://github.com/apache/beam/pull/12331#discussion_r463321438", "createdAt": "2020-07-30T23:13:51Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/dicomio.py", "diffHunk": "@@ -164,70 +167,109 @@ class DicomSearch(PTransform):\n     }\n \n   \"\"\"\n-  def __init__(self, credential=None):\n+  def __init__(self, buffer_size=8, max_workers=5, credential=None):\n     \"\"\"Initializes DicomSearch.\n     Args:\n       credential: # type: Google credential object, if it is specified, the\n       Http client will use it to create sessions instead of the default.\n     \"\"\"\n+    self.buffer_size = buffer_size\n+    self.max_workers = max_workers", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "21fd738ec158d5d205d9ae21b8fbbf71bb48d3ca"}, "originalPosition": 22}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "51294ea66221644dd275bc67ed8aaea998b78ee6", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/51294ea66221644dd275bc67ed8aaea998b78ee6", "committedDate": "2020-07-31T03:34:14Z", "message": "fixed bugs and docs style, added custom client supports, timestamp recording,  and flush tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "73ffeb9511a9ded59f0eed7dd383349315dd1bfd", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/73ffeb9511a9ded59f0eed7dd383349315dd1bfd", "committedDate": "2020-07-31T05:47:02Z", "message": "fix py2 support issues"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "593692d44c06929fb034c4da62d9159a9a72e4e8", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/593692d44c06929fb034c4da62d9159a9a72e4e8", "committedDate": "2020-07-31T14:05:27Z", "message": "fix some minor bugs"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU5NDA2MTIy", "url": "https://github.com/apache/beam/pull/12331#pullrequestreview-459406122", "createdAt": "2020-07-31T19:21:13Z", "commit": {"oid": "51294ea66221644dd275bc67ed8aaea998b78ee6"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQxOToyMToxM1rOG6TZwA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0zMVQxOToyNDo1NlrOG6TgBQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzc4ODQ4MA==", "bodyText": "it's not that important, but you can do self.client = client or DicomApiHttpClient()\nFeel free to add it if you have the time.", "url": "https://github.com/apache/beam/pull/12331#discussion_r463788480", "createdAt": "2020-07-31T19:21:13Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/dicomio.py", "diffHunk": "@@ -167,33 +167,40 @@ class DicomSearch(PTransform):\n     }\n \n   \"\"\"\n-  def __init__(self, buffer_size=8, max_workers=5, credential=None):\n+  def __init__(\n+      self, buffer_size=8, max_workers=5, client=None, credential=None):\n     \"\"\"Initializes DicomSearch.\n     Args:\n       credential: # type: Google credential object, if it is specified, the\n       Http client will use it to create sessions instead of the default.\n     \"\"\"\n     self.buffer_size = buffer_size\n     self.max_workers = max_workers\n+    if not client:\n+      self.client = DicomApiHttpClient()\n+    else:\n+      self.client = client", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "51294ea66221644dd275bc67ed8aaea998b78ee6"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2Mzc5MDA4NQ==", "bodyText": "ah that's right. You need to skip the test when GCP dependencies are missing. Check how we do it for gcs filesystem:\nhttps://github.com/apache/beam/blob/master/sdks/python/apache_beam/io/gcp/gcsfilesystem_test.py#L39-L47", "url": "https://github.com/apache/beam/pull/12331#discussion_r463790085", "createdAt": "2020-07-31T19:24:56Z", "author": {"login": "pabloem"}, "path": "sdks/python/setup.py", "diffHunk": "@@ -128,6 +128,7 @@ def get_version():\n   cythonize = lambda *args, **kwargs: []\n \n REQUIRED_PACKAGES = [\n+    'google-auth>=1.18.0,<=1.20.0',", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzI4MDQ3OQ=="}, "originalCommit": {"oid": "abf7600d697ffbd59ef7a7fdddea791843467715"}, "originalPosition": 4}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU5NDEyMDA3", "url": "https://github.com/apache/beam/pull/12331#pullrequestreview-459412007", "createdAt": "2020-07-31T19:26:45Z", "commit": {"oid": "593692d44c06929fb034c4da62d9159a9a72e4e8"}, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ad6c49e635f7b4d893d208376e86c2c924a97e57", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/ad6c49e635f7b4d893d208376e86c2c924a97e57", "committedDate": "2020-07-31T20:02:57Z", "message": "fix style and modify tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a19ecd1cad080e1bf4afe0b802caa9b084003111", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/a19ecd1cad080e1bf4afe0b802caa9b084003111", "committedDate": "2020-07-31T20:07:00Z", "message": "fix format"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a2706ddf270afb9b4d7ebc36e153423b3ea211f6", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/a2706ddf270afb9b4d7ebc36e153423b3ea211f6", "committedDate": "2020-07-31T21:56:30Z", "message": "fix test skip"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b5a018b23de35ca1cb082c0ae97e60bce6a0146a", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/b5a018b23de35ca1cb082c0ae97e60bce6a0146a", "committedDate": "2020-08-03T15:01:47Z", "message": "Merge branch 'master' into master"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDYwMjkzMDky", "url": "https://github.com/apache/beam/pull/12331#pullrequestreview-460293092", "createdAt": "2020-08-03T19:42:46Z", "commit": {"oid": "b5a018b23de35ca1cb082c0ae97e60bce6a0146a"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QxOTo0Mjo0N1rOG7GZhQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QxOTo1NTowN1rOG7Gu3A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDYyNDAwNQ==", "bodyText": "add an extra line between 20 and 21? To separate the paragraphs.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            For more details on DICOM store and API:\n          \n          \n            \n            \n          \n          \n            \n            For more details on DICOM store and API:", "url": "https://github.com/apache/beam/pull/12331#discussion_r464624005", "createdAt": "2020-08-03T19:42:47Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/dicomio.py", "diffHunk": "@@ -0,0 +1,572 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"DICOM IO connector\n+This module implements several tools to facilitate the interaction between\n+a Google Cloud Healthcare DICOM store and a Beam pipeline.\n+For more details on DICOM store and API:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b5a018b23de35ca1cb082c0ae97e60bce6a0146a"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDYyNDE0Ng==", "bodyText": "extra line as well to separate the paragraphs.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            The DICOM IO connector can be used to search metadata or write DICOM files\n          \n          \n            \n            \n          \n          \n            \n            The DICOM IO connector can be used to search metadata or write DICOM files", "url": "https://github.com/apache/beam/pull/12331#discussion_r464624146", "createdAt": "2020-08-03T19:43:09Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/dicomio.py", "diffHunk": "@@ -0,0 +1,572 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"DICOM IO connector\n+This module implements several tools to facilitate the interaction between\n+a Google Cloud Healthcare DICOM store and a Beam pipeline.\n+For more details on DICOM store and API:\n+https://cloud.google.com/healthcare/docs/how-tos/dicom\n+The DICOM IO connector can be used to search metadata or write DICOM files", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b5a018b23de35ca1cb082c0ae97e60bce6a0146a"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDYyNzI3Mw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            to DICOM store. When used together with Google Pubsub message connector,\n          \n          \n            \n            a PTransform implemented in this module can be used to convert pubsub\n          \n          \n            \n            messages to search requests. Since Traceability is crucial for healthcare\n          \n          \n            \n            API users, every input or error message will be recorded in the output of\n          \n          \n            \n            the DICOM IO connector. As a result, every PTransform in this module will\n          \n          \n            \n            return a PCollection of dict that encodes results and detailed error messages.\n          \n          \n            \n            to DICOM store. \n          \n          \n            \n            \n          \n          \n            \n            When used together with Google Pubsub message connector, the \n          \n          \n            \n            `PubsubToQuido` PTransform implemented in this module can be used\n          \n          \n            \n            to convert Pubsub messages to search requests. \n          \n          \n            \n            \n          \n          \n            \n            Since Traceability is crucial for healthcare\n          \n          \n            \n            API users, every input or error message will be recorded in the output of\n          \n          \n            \n            the DICOM IO connector. As a result, every PTransform in this module will\n          \n          \n            \n            return a PCollection of dict that encodes results and detailed error messages.", "url": "https://github.com/apache/beam/pull/12331#discussion_r464627273", "createdAt": "2020-08-03T19:50:23Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/dicomio.py", "diffHunk": "@@ -0,0 +1,572 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"DICOM IO connector\n+This module implements several tools to facilitate the interaction between\n+a Google Cloud Healthcare DICOM store and a Beam pipeline.\n+For more details on DICOM store and API:\n+https://cloud.google.com/healthcare/docs/how-tos/dicom\n+The DICOM IO connector can be used to search metadata or write DICOM files\n+to DICOM store. When used together with Google Pubsub message connector,\n+a PTransform implemented in this module can be used to convert pubsub\n+messages to search requests. Since Traceability is crucial for healthcare\n+API users, every input or error message will be recorded in the output of\n+the DICOM IO connector. As a result, every PTransform in this module will\n+return a PCollection of dict that encodes results and detailed error messages.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b5a018b23de35ca1cb082c0ae97e60bce6a0146a"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDYyNzc2Ng==", "bodyText": "actually I wonder if the transform should be called FormatToQuido instead of PubsubToQuido is it possible to receive the same data from sources other than pubsub?", "url": "https://github.com/apache/beam/pull/12331#discussion_r464627766", "createdAt": "2020-08-03T19:51:35Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/dicomio.py", "diffHunk": "@@ -0,0 +1,572 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"DICOM IO connector\n+This module implements several tools to facilitate the interaction between\n+a Google Cloud Healthcare DICOM store and a Beam pipeline.\n+For more details on DICOM store and API:\n+https://cloud.google.com/healthcare/docs/how-tos/dicom\n+The DICOM IO connector can be used to search metadata or write DICOM files\n+to DICOM store. When used together with Google Pubsub message connector,\n+a PTransform implemented in this module can be used to convert pubsub\n+messages to search requests. Since Traceability is crucial for healthcare\n+API users, every input or error message will be recorded in the output of\n+the DICOM IO connector. As a result, every PTransform in this module will\n+return a PCollection of dict that encodes results and detailed error messages.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDYyNzI3Mw=="}, "originalCommit": {"oid": "b5a018b23de35ca1cb082c0ae97e60bce6a0146a"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDYyODM2Mg==", "bodyText": "Should this be called WriteFileToDicomStore? or perhaps UploadToDicom instead of DicomStoreInstance?", "url": "https://github.com/apache/beam/pull/12331#discussion_r464628362", "createdAt": "2020-08-03T19:52:47Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/dicomio.py", "diffHunk": "@@ -0,0 +1,572 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"DICOM IO connector\n+This module implements several tools to facilitate the interaction between\n+a Google Cloud Healthcare DICOM store and a Beam pipeline.\n+For more details on DICOM store and API:\n+https://cloud.google.com/healthcare/docs/how-tos/dicom\n+The DICOM IO connector can be used to search metadata or write DICOM files\n+to DICOM store. When used together with Google Pubsub message connector,\n+a PTransform implemented in this module can be used to convert pubsub\n+messages to search requests. Since Traceability is crucial for healthcare\n+API users, every input or error message will be recorded in the output of\n+the DICOM IO connector. As a result, every PTransform in this module will\n+return a PCollection of dict that encodes results and detailed error messages.\n+\n+Search instance's metadata (QIDO request)\n+===================================================\n+DicomSearch() wraps the QIDO request client and supports 3 levels of search.\n+Users should specify the level by setting the 'search_type' entry in the input\n+dict. They can also refine the search by adding tags to filter the results using\n+the 'params' entry. Here is a sample usage:\n+\n+  with Pipeline() as p:\n+    input_dict = p | beam.Create(\n+      [{'project_id': 'abc123', 'type': 'instances',...},\n+      {'project_id': 'dicom_go', 'type': 'series',...}])\n+\n+    results = input_dict | io.gcp.DicomSearch()\n+    results | 'print successful search' >> beam.Map(\n+    lambda x: print(x['result'] if x['success'] else None))\n+\n+    results | 'print failed search' >> beam.Map(\n+    lambda x: print(x['result'] if not x['success'] else None))\n+\n+In the example above, successful qido search results and error messages for\n+failed requests are printed. When used in real life, user can choose to filter\n+those data and output them to wherever they want.\n+\n+Convert DICOM Pubsub message to Qido search request\n+===================================================\n+Healthcare API users might use Beam's Pubsub streaming pipeline to monitor the\n+store operations (new DICOM file) in a DICOM storage. Pubsub message encodes\n+DICOM a web store path as well as instance ids. If users are interested in\n+getting new instance's metadata, they can use PubsubToQido() to convert the\n+message into Qido Search dict then use DicomSearch(). Here is a sample usage:\n+\n+  pipeline_options = PipelineOptions()\n+  pipeline_options.view_as(StandardOptions).streaming = True\n+  p =  beam.Pipeline(options=pipeline_options)\n+  pubsub = p | beam.io.ReadStringFromPubsub(subscription='a_dicom_store')\n+  results = pubsub | PubsubToQido()\n+  success = results | 'filter message' >> beam.Filter(lambda x: x['success'])\n+  qido_dict = success | 'get qido request' >> beam.Map(lambda x: x['result'])\n+  metadata = qido_dict | DicomSearch()\n+\n+In the example above, the pipeline is listening to a pubsub topic and waiting\n+for messages from DICOM API. When a new DICOM file comes into the storage, the\n+pipeline will receive a pubsub message, convert it to a Qido request dict and\n+feed it to DicomSearch() PTransform. As a result, users can get the metadata for\n+every new DICOM file. Note that not every pubsub message received is from DICOM\n+API, so we to filter the results first.\n+\n+Store a DICOM file in a DICOM storage\n+===================================================\n+DicomStoreInstance() wraps store request API and users can use it to send a\n+DICOM file to a DICOM store. It supports two types of input: 1.file data in\n+byte[] 2.fileio object. Users should set the 'input_type' when initialzing\n+this PTransform. Here are the examples:\n+\n+  with Pipeline() as p:\n+    input_dict = {'project_id': 'abc123', 'type': 'instances',...}\n+    path = \"gcs://bucketname/something/a.dcm\"\n+    match = p | fileio.MatchFiles(path)\n+    fileio_obj = match | fileio.ReadAll()\n+    results = fileio_obj | DicomStoreInstance(input_dict, 'fileio')", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b5a018b23de35ca1cb082c0ae97e60bce6a0146a"}, "originalPosition": 90}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDYyOTQ2OA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n            Healthcare API users might use Beam's Pubsub streaming pipeline to monitor the\n          \n          \n            \n            store operations (new DICOM file) in a DICOM storage. Pubsub message encodes\n          \n          \n            \n            DICOM a web store path as well as instance ids. If users are interested in\n          \n          \n            \n            getting new instance's metadata, they can use PubsubToQido() to convert the\n          \n          \n            \n            message into Qido Search dict then use DicomSearch(). Here is a sample usage:\n          \n          \n            \n            Healthcare API users might read messages from Pubsub to monitor the store\n          \n          \n            \n            operations (e.g. new file) in a DICOM storage. Pubsub message encode\n          \n          \n            \n            DICOM as a web store path as well as instance ids. If users are interested in\n          \n          \n            \n            getting new instance's metadata, they can use the `PubsubToQido` transform\n          \n          \n            \n            to convert the message into Qido Search dict then use the `DicomSearch`\n          \n          \n            \n            transform. Here is a sample usage:", "url": "https://github.com/apache/beam/pull/12331#discussion_r464629468", "createdAt": "2020-08-03T19:55:07Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/gcp/dicomio.py", "diffHunk": "@@ -0,0 +1,572 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"DICOM IO connector\n+This module implements several tools to facilitate the interaction between\n+a Google Cloud Healthcare DICOM store and a Beam pipeline.\n+For more details on DICOM store and API:\n+https://cloud.google.com/healthcare/docs/how-tos/dicom\n+The DICOM IO connector can be used to search metadata or write DICOM files\n+to DICOM store. When used together with Google Pubsub message connector,\n+a PTransform implemented in this module can be used to convert pubsub\n+messages to search requests. Since Traceability is crucial for healthcare\n+API users, every input or error message will be recorded in the output of\n+the DICOM IO connector. As a result, every PTransform in this module will\n+return a PCollection of dict that encodes results and detailed error messages.\n+\n+Search instance's metadata (QIDO request)\n+===================================================\n+DicomSearch() wraps the QIDO request client and supports 3 levels of search.\n+Users should specify the level by setting the 'search_type' entry in the input\n+dict. They can also refine the search by adding tags to filter the results using\n+the 'params' entry. Here is a sample usage:\n+\n+  with Pipeline() as p:\n+    input_dict = p | beam.Create(\n+      [{'project_id': 'abc123', 'type': 'instances',...},\n+      {'project_id': 'dicom_go', 'type': 'series',...}])\n+\n+    results = input_dict | io.gcp.DicomSearch()\n+    results | 'print successful search' >> beam.Map(\n+    lambda x: print(x['result'] if x['success'] else None))\n+\n+    results | 'print failed search' >> beam.Map(\n+    lambda x: print(x['result'] if not x['success'] else None))\n+\n+In the example above, successful qido search results and error messages for\n+failed requests are printed. When used in real life, user can choose to filter\n+those data and output them to wherever they want.\n+\n+Convert DICOM Pubsub message to Qido search request\n+===================================================\n+Healthcare API users might use Beam's Pubsub streaming pipeline to monitor the\n+store operations (new DICOM file) in a DICOM storage. Pubsub message encodes\n+DICOM a web store path as well as instance ids. If users are interested in\n+getting new instance's metadata, they can use PubsubToQido() to convert the\n+message into Qido Search dict then use DicomSearch(). Here is a sample usage:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b5a018b23de35ca1cb082c0ae97e60bce6a0146a"}, "originalPosition": 60}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "37375db6f31ab141a63fe7230af4176356665a0d", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/37375db6f31ab141a63fe7230af4176356665a0d", "committedDate": "2020-08-03T19:59:30Z", "message": "Update sdks/python/apache_beam/io/gcp/dicomio.py\n\nCo-authored-by: Pablo <pabloem@users.noreply.github.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "91d9516063f510793c48f3e820c0eb0e3b9f0021", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/91d9516063f510793c48f3e820c0eb0e3b9f0021", "committedDate": "2020-08-03T19:59:42Z", "message": "Update sdks/python/apache_beam/io/gcp/dicomio.py\n\nCo-authored-by: Pablo <pabloem@users.noreply.github.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ff2fc3c029f1e1e118cd2488dfad516df20d5d7a", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/ff2fc3c029f1e1e118cd2488dfad516df20d5d7a", "committedDate": "2020-08-03T20:00:39Z", "message": "Update sdks/python/apache_beam/io/gcp/dicomio.py\n\nCo-authored-by: Pablo <pabloem@users.noreply.github.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ff07e98f07c160c3297dff2aa781bd299b3ef0de", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/ff07e98f07c160c3297dff2aa781bd299b3ef0de", "committedDate": "2020-08-03T20:12:38Z", "message": "Update sdks/python/apache_beam/io/gcp/dicomio.py\n\nCo-authored-by: Pablo <pabloem@users.noreply.github.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0ccc2c5e77bf934a2d5a1d3bca784a8a005574ec", "author": {"user": {"login": "George-Wu", "name": "JIahao wu"}}, "url": "https://github.com/apache/beam/commit/0ccc2c5e77bf934a2d5a1d3bca784a8a005574ec", "committedDate": "2020-08-03T20:30:28Z", "message": "function name change"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3864, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}