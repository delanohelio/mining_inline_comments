{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDcxNDUyNTk4", "number": 12657, "title": "[BEAM-10777] Add two blog posts detailing changes to the type hints module of the Python SDK", "bodyText": "Please add a meaningful description for your change here\n\nThank you for your contribution! Follow this checklist to help us incorporate your contribution quickly and easily:\n\n Choose reviewer(s) and mention them in a comment (R: @username).\n Format the pull request title like [BEAM-XXX] Fixes bug in ApproximateQuantiles, where you replace BEAM-XXX with the appropriate JIRA issue, if applicable. This will automatically link the pull request to the issue.\n Update CHANGES.md with noteworthy changes.\n If this contribution is large, please file an Apache Individual Contributor License Agreement.\n\nSee the Contributor Guide for more tips on how to make review process smoother.\nPost-Commit Tests Status (on master branch)\n\n\n\nLang\nSDK\nDataflow\nFlink\nSamza\nSpark\nTwister2\n\n\n\n\nGo\n\n---\n\n---\n\n---\n\n\nJava\n\n\n\n\n\n\n\n\nPython\n\n\n\n---\n\n---\n\n\nXLang\n\n---\n\n---\n\n---\n\n\n\nPre-Commit Tests Status (on master branch)\n\n\n\n---\nJava\nPython\nGo\nWebsite\n\n\n\n\nNon-portable\n\n \n\n\n\n\nPortable\n---\n\n---\n---\n\n\n\nSee .test-infra/jenkins/README for trigger phrase, status and link of all Jenkins jobs.\nGitHub Actions Tests Status (on master branch)\n\n\nSee CI.md for more information about GitHub Actions CI.", "createdAt": "2020-08-21T06:53:21Z", "url": "https://github.com/apache/beam/pull/12657", "merged": true, "mergeCommit": {"oid": "ab1112cd8febd6f15069b6f6d4537eeb1c972756"}, "closed": true, "closedAt": "2020-08-25T04:53:03Z", "author": {"login": "saavannanavati"}, "timelineItems": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdA6EaegH2gAyNDcxNDUyNTk4OjlhMDRiYTkyNmUzNmUxYmExNWM0NTZjNjZmNGI0MWMwMTQzYjFjNTA=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdCP2GUgFqTQ3NDEzMzIzMw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "9a04ba926e36e1ba15c456c66f4b41c0143b1c50", "author": {"user": {"login": "saavannanavati", "name": "Saavan Nanavati"}}, "url": "https://github.com/apache/beam/commit/9a04ba926e36e1ba15c456c66f4b41c0143b1c50", "committedDate": "2020-08-21T00:56:33Z", "message": "Add myself to authors"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b7a52b2f5467348fb468b2e34f176410546bfd8b", "author": {"user": {"login": "saavannanavati", "name": "Saavan Nanavati"}}, "url": "https://github.com/apache/beam/commit/b7a52b2f5467348fb468b2e34f176410546bfd8b", "committedDate": "2020-08-21T03:06:08Z", "message": "Add blog post #1: improved annotation support"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "22e5d46d0ae7069f17c7c0cff41c90a96681b65c", "author": {"user": {"login": "saavannanavati", "name": "Saavan Nanavati"}}, "url": "https://github.com/apache/beam/commit/22e5d46d0ae7069f17c7c0cff41c90a96681b65c", "committedDate": "2020-08-21T04:16:57Z", "message": "Add draft of blog post #2: performance runtime type checking"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f9973aafc15a5a0b396ceb22abbcc715e2b0d962", "author": {"user": {"login": "Saavan-Nanavati", "name": null}}, "url": "https://github.com/apache/beam/commit/f9973aafc15a5a0b396ceb22abbcc715e2b0d962", "committedDate": "2020-08-21T06:51:46Z", "message": "Finish blog post #2"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDcyODg1Nzcz", "url": "https://github.com/apache/beam/pull/12657#pullrequestreview-472885773", "createdAt": "2020-08-22T01:23:46Z", "commit": {"oid": "f9973aafc15a5a0b396ceb22abbcc715e2b0d962"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQwMToyMzo0NlrOHFBd_Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMlQwMjowNDoyOVrOHFBtsA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTAyODk4OQ==", "bodyText": "Capitalize Any", "url": "https://github.com/apache/beam/pull/12657#discussion_r475028989", "createdAt": "2020-08-22T01:23:46Z", "author": {"login": "udim"}, "path": "website/www/site/content/en/blog/python-improved-annotations.md", "diffHunk": "@@ -0,0 +1,109 @@\n+---\n+layout: post\n+title:  \"Improved Annotation Support for the Python SDK\"\n+date:   2020-08-21 00:00:01 -0800\n+categories:\n+  - blog \n+  - python \n+  - typing\n+authors:\n+  - saavan\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+The importance of static type checking in a dynamically \n+typed language like Python is not up for debate. Type hints \n+allow developers to leverage a strong typing system to:\n+ - write better code, \n+ - self-document ambiguous programming logic, and \n+ - inform intelligent code completion in IDEs like PyCharm.\n+\n+This is why we're excited to announce upcoming improvements to \n+the `typehints` module of Beam's Python SDK, including support \n+for typed PCollections and Python 3 style annotations on PTransforms.\n+\n+# Improved Annotations\n+Today, you have the option to declare type hints on PTransforms using either\n+class decorators or inline functions.\n+\n+For instance, a PTransform with decorated type hints might look like this:\n+```\n+@beam.typehints.with_input_types(int)\n+@beam.typehints.with_output_types(str)\n+class IntToStr(beam.PTransform):\n+    def expand(self, pcoll):\n+        return pcoll | beam.Map(lambda num: str(num))\n+\n+strings = numbers | beam.ParDo(IntToStr())\n+```\n+\n+Using inline functions instead, the same transform would look like this:\n+```\n+class IntToStr(beam.PTransform):\n+    def expand(self, pcoll):\n+        return pcoll | beam.Map(lambda num: str(num))\n+\n+strings = numbers | beam.ParDo(IntToStr()).with_input_types(int).with_output_types(str)\n+```\n+\n+Both methods have problems. Class decorators are syntax-heavy, \n+requiring two additional lines of code, whereas inline functions provide type hints \n+that aren't reusable across other instances of the same transform. Additionally, both \n+methods are incompatible with static type checkers like MyPy.\n+\n+With Python 3 annotations however, we can subvert these problems to provide a \n+clean and reusable type hint experience. Our previous transform now looks like this:\n+```\n+class IntToStr(beam.PTransform):\n+    def expand(self, pcoll: PCollection[int]) -> PCollection[str]:\n+        return pcoll | beam.Map(lambda num: str(num))\n+\n+strings = numbers | beam.ParDo(IntToStr())\n+```\n+\n+These type hints will actively hook into the internal Beam typing system to\n+play a role in pipeline type checking, and runtime type checking. \n+\n+So how does this work?\n+\n+## Typed PCollections\n+You guessed it! The PCollection class inherits from `typing.Generic`, allowing it to be \n+parameterized with either zero types (denoted `PCollection`) or one type (denoted `PCollection[T]`). \n+- A PCollection with zero types is implicitly converted to `PCollection[any]`.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f9973aafc15a5a0b396ceb22abbcc715e2b0d962"}, "originalPosition": 84}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTAyOTI2Nw==", "bodyText": "\"These are generally used for PTransforms that begin or end with an I/O operation.\"\nAlso, I think we can omit PDone since we prefer None if I'm not mistaken.", "url": "https://github.com/apache/beam/pull/12657#discussion_r475029267", "createdAt": "2020-08-22T01:26:07Z", "author": {"login": "udim"}, "path": "website/www/site/content/en/blog/python-improved-annotations.md", "diffHunk": "@@ -0,0 +1,109 @@\n+---\n+layout: post\n+title:  \"Improved Annotation Support for the Python SDK\"\n+date:   2020-08-21 00:00:01 -0800\n+categories:\n+  - blog \n+  - python \n+  - typing\n+authors:\n+  - saavan\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+The importance of static type checking in a dynamically \n+typed language like Python is not up for debate. Type hints \n+allow developers to leverage a strong typing system to:\n+ - write better code, \n+ - self-document ambiguous programming logic, and \n+ - inform intelligent code completion in IDEs like PyCharm.\n+\n+This is why we're excited to announce upcoming improvements to \n+the `typehints` module of Beam's Python SDK, including support \n+for typed PCollections and Python 3 style annotations on PTransforms.\n+\n+# Improved Annotations\n+Today, you have the option to declare type hints on PTransforms using either\n+class decorators or inline functions.\n+\n+For instance, a PTransform with decorated type hints might look like this:\n+```\n+@beam.typehints.with_input_types(int)\n+@beam.typehints.with_output_types(str)\n+class IntToStr(beam.PTransform):\n+    def expand(self, pcoll):\n+        return pcoll | beam.Map(lambda num: str(num))\n+\n+strings = numbers | beam.ParDo(IntToStr())\n+```\n+\n+Using inline functions instead, the same transform would look like this:\n+```\n+class IntToStr(beam.PTransform):\n+    def expand(self, pcoll):\n+        return pcoll | beam.Map(lambda num: str(num))\n+\n+strings = numbers | beam.ParDo(IntToStr()).with_input_types(int).with_output_types(str)\n+```\n+\n+Both methods have problems. Class decorators are syntax-heavy, \n+requiring two additional lines of code, whereas inline functions provide type hints \n+that aren't reusable across other instances of the same transform. Additionally, both \n+methods are incompatible with static type checkers like MyPy.\n+\n+With Python 3 annotations however, we can subvert these problems to provide a \n+clean and reusable type hint experience. Our previous transform now looks like this:\n+```\n+class IntToStr(beam.PTransform):\n+    def expand(self, pcoll: PCollection[int]) -> PCollection[str]:\n+        return pcoll | beam.Map(lambda num: str(num))\n+\n+strings = numbers | beam.ParDo(IntToStr())\n+```\n+\n+These type hints will actively hook into the internal Beam typing system to\n+play a role in pipeline type checking, and runtime type checking. \n+\n+So how does this work?\n+\n+## Typed PCollections\n+You guessed it! The PCollection class inherits from `typing.Generic`, allowing it to be \n+parameterized with either zero types (denoted `PCollection`) or one type (denoted `PCollection[T]`). \n+- A PCollection with zero types is implicitly converted to `PCollection[any]`.\n+- A PCollection with one type can have any nested type (e.g. `Union[int, str]`).\n+\n+Internally, Beam's typing system makes these annotations compatible with other \n+type hints by removing the outer PCollection container.\n+\n+## PBegin, PDone, None\n+Finally, besides PCollection, a valid annotation on the `expand(...)` method of a PTransform is\n+`PBegin`, `PDone`, and `None`. These are generally used for I/O operations.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f9973aafc15a5a0b396ceb22abbcc715e2b0d962"}, "originalPosition": 92}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTAyOTMzNw==", "bodyText": "Awesome post!", "url": "https://github.com/apache/beam/pull/12657#discussion_r475029337", "createdAt": "2020-08-22T01:26:40Z", "author": {"login": "udim"}, "path": "website/www/site/content/en/blog/python-improved-annotations.md", "diffHunk": "@@ -0,0 +1,109 @@\n+---\n+layout: post\n+title:  \"Improved Annotation Support for the Python SDK\"\n+date:   2020-08-21 00:00:01 -0800\n+categories:\n+  - blog \n+  - python \n+  - typing\n+authors:\n+  - saavan\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+The importance of static type checking in a dynamically \n+typed language like Python is not up for debate. Type hints \n+allow developers to leverage a strong typing system to:\n+ - write better code, \n+ - self-document ambiguous programming logic, and \n+ - inform intelligent code completion in IDEs like PyCharm.\n+\n+This is why we're excited to announce upcoming improvements to \n+the `typehints` module of Beam's Python SDK, including support \n+for typed PCollections and Python 3 style annotations on PTransforms.\n+\n+# Improved Annotations\n+Today, you have the option to declare type hints on PTransforms using either\n+class decorators or inline functions.\n+\n+For instance, a PTransform with decorated type hints might look like this:\n+```\n+@beam.typehints.with_input_types(int)\n+@beam.typehints.with_output_types(str)\n+class IntToStr(beam.PTransform):\n+    def expand(self, pcoll):\n+        return pcoll | beam.Map(lambda num: str(num))\n+\n+strings = numbers | beam.ParDo(IntToStr())\n+```\n+\n+Using inline functions instead, the same transform would look like this:\n+```\n+class IntToStr(beam.PTransform):\n+    def expand(self, pcoll):\n+        return pcoll | beam.Map(lambda num: str(num))\n+\n+strings = numbers | beam.ParDo(IntToStr()).with_input_types(int).with_output_types(str)\n+```\n+\n+Both methods have problems. Class decorators are syntax-heavy, \n+requiring two additional lines of code, whereas inline functions provide type hints \n+that aren't reusable across other instances of the same transform. Additionally, both \n+methods are incompatible with static type checkers like MyPy.\n+\n+With Python 3 annotations however, we can subvert these problems to provide a \n+clean and reusable type hint experience. Our previous transform now looks like this:\n+```\n+class IntToStr(beam.PTransform):\n+    def expand(self, pcoll: PCollection[int]) -> PCollection[str]:\n+        return pcoll | beam.Map(lambda num: str(num))\n+\n+strings = numbers | beam.ParDo(IntToStr())\n+```\n+\n+These type hints will actively hook into the internal Beam typing system to\n+play a role in pipeline type checking, and runtime type checking. \n+\n+So how does this work?\n+\n+## Typed PCollections\n+You guessed it! The PCollection class inherits from `typing.Generic`, allowing it to be \n+parameterized with either zero types (denoted `PCollection`) or one type (denoted `PCollection[T]`). \n+- A PCollection with zero types is implicitly converted to `PCollection[any]`.\n+- A PCollection with one type can have any nested type (e.g. `Union[int, str]`).\n+\n+Internally, Beam's typing system makes these annotations compatible with other \n+type hints by removing the outer PCollection container.\n+\n+## PBegin, PDone, None\n+Finally, besides PCollection, a valid annotation on the `expand(...)` method of a PTransform is\n+`PBegin`, `PDone`, and `None`. These are generally used for I/O operations.\n+\n+For instance, when saving data, your transform's output type should be `None`.\n+```\n+class SaveResults(beam.PTransform):\n+    def expand(self, pcoll: PCollection[str]) -> None:\n+        return pcoll | beam.io.WriteToBigQuery(...)\n+```\n+\n+# Next Steps\n+What are you waiting for.. start using annotations on your transforms!\n+\n+For more background on type hints in Python, see:\n+[Ensuring Python Type Safety](https://beam.apache.org/documentation/sdks/python-type-safety/). \n+\n+Finally, please ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f9973aafc15a5a0b396ceb22abbcc715e2b0d962"}, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTAzMTQwNQ==", "bodyText": "I would write something like:\n\"... database, and the output data type is not known before the pipeline starts running?\"\nor\n\"is only known at runtime\"", "url": "https://github.com/apache/beam/pull/12657#discussion_r475031405", "createdAt": "2020-08-22T01:47:46Z", "author": {"login": "udim"}, "path": "website/www/site/content/en/blog/python-performance-runtime-type-checking.md", "diffHunk": "@@ -0,0 +1,154 @@\n+---\n+layout: post\n+title:  \"Performance-Driven Runtime Type Checking for the Python SDK\"\n+date:   2020-08-21 00:00:01 -0800\n+categories:\n+  - blog \n+  - python \n+  - typing\n+authors:\n+  - saavan\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+In this blog post, we're announcing the upcoming release of a new, opt-in \n+runtime type checking system for Beam's Python SDK that's optimized for performance \n+in both development and production environments.\n+\n+But let's take a step back - why do we even care about runtime type checking \n+in the first place? Let's look at an example.\n+\n+```\n+class MultiplyNumberByTwo(beam.DoFn):\n+    def process(self, element: int):\n+        return element * 2\n+\n+p = Pipeline()\n+p | beam.Create(['1', '2'] | beam.ParDo(MultiplyNumberByTwo())\n+```\n+\n+In this code, we passed a list of strings to a DoFn that's clearly intended for use with\n+integers. Luckily, this code will throw an error during pipeline construction because\n+the inferred output type of `beam.Create(['1', '2'])` is `str` which is incompatible with\n+the declared input type hint of `MultiplyNumberByTwo.process` which is `int`.\n+\n+However, what if we turned the pipeline type check off using the `no_pipeline_type_check` \n+flag? Or more realistically, what if the input PCollection to MultiplyNumberByTwo came \n+from a database, preventing inference of the output data type?", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f9973aafc15a5a0b396ceb22abbcc715e2b0d962"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTAzMjYxMw==", "bodyText": "That is a very broad claim. :) This feature only helps with debugging typing issues.", "url": "https://github.com/apache/beam/pull/12657#discussion_r475032613", "createdAt": "2020-08-22T02:00:00Z", "author": {"login": "udim"}, "path": "website/www/site/content/en/blog/python-performance-runtime-type-checking.md", "diffHunk": "@@ -0,0 +1,154 @@\n+---\n+layout: post\n+title:  \"Performance-Driven Runtime Type Checking for the Python SDK\"\n+date:   2020-08-21 00:00:01 -0800\n+categories:\n+  - blog \n+  - python \n+  - typing\n+authors:\n+  - saavan\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+In this blog post, we're announcing the upcoming release of a new, opt-in \n+runtime type checking system for Beam's Python SDK that's optimized for performance \n+in both development and production environments.\n+\n+But let's take a step back - why do we even care about runtime type checking \n+in the first place? Let's look at an example.\n+\n+```\n+class MultiplyNumberByTwo(beam.DoFn):\n+    def process(self, element: int):\n+        return element * 2\n+\n+p = Pipeline()\n+p | beam.Create(['1', '2'] | beam.ParDo(MultiplyNumberByTwo())\n+```\n+\n+In this code, we passed a list of strings to a DoFn that's clearly intended for use with\n+integers. Luckily, this code will throw an error during pipeline construction because\n+the inferred output type of `beam.Create(['1', '2'])` is `str` which is incompatible with\n+the declared input type hint of `MultiplyNumberByTwo.process` which is `int`.\n+\n+However, what if we turned the pipeline type check off using the `no_pipeline_type_check` \n+flag? Or more realistically, what if the input PCollection to MultiplyNumberByTwo came \n+from a database, preventing inference of the output data type?\n+\n+In either case, no error would be thrown during pipeline construction. \n+And even at runtime, this code works. Each string would be multiplied by 2, \n+yielding a result of `['11', '22']`, but that's certainly not the outcome we want.\n+\n+So how do you debug this breed of \"hidden\" errors? More broadly speaking, how do you\n+debug any error message in Beam that's complex or confusing (e.g. serialization errors)?", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f9973aafc15a5a0b396ceb22abbcc715e2b0d962"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTAzMjg5OA==", "bodyText": "I think the term \"wrappers\" is more apt than \"decorators\" here.", "url": "https://github.com/apache/beam/pull/12657#discussion_r475032898", "createdAt": "2020-08-22T02:03:14Z", "author": {"login": "udim"}, "path": "website/www/site/content/en/blog/python-performance-runtime-type-checking.md", "diffHunk": "@@ -0,0 +1,154 @@\n+---\n+layout: post\n+title:  \"Performance-Driven Runtime Type Checking for the Python SDK\"\n+date:   2020-08-21 00:00:01 -0800\n+categories:\n+  - blog \n+  - python \n+  - typing\n+authors:\n+  - saavan\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+In this blog post, we're announcing the upcoming release of a new, opt-in \n+runtime type checking system for Beam's Python SDK that's optimized for performance \n+in both development and production environments.\n+\n+But let's take a step back - why do we even care about runtime type checking \n+in the first place? Let's look at an example.\n+\n+```\n+class MultiplyNumberByTwo(beam.DoFn):\n+    def process(self, element: int):\n+        return element * 2\n+\n+p = Pipeline()\n+p | beam.Create(['1', '2'] | beam.ParDo(MultiplyNumberByTwo())\n+```\n+\n+In this code, we passed a list of strings to a DoFn that's clearly intended for use with\n+integers. Luckily, this code will throw an error during pipeline construction because\n+the inferred output type of `beam.Create(['1', '2'])` is `str` which is incompatible with\n+the declared input type hint of `MultiplyNumberByTwo.process` which is `int`.\n+\n+However, what if we turned the pipeline type check off using the `no_pipeline_type_check` \n+flag? Or more realistically, what if the input PCollection to MultiplyNumberByTwo came \n+from a database, preventing inference of the output data type?\n+\n+In either case, no error would be thrown during pipeline construction. \n+And even at runtime, this code works. Each string would be multiplied by 2, \n+yielding a result of `['11', '22']`, but that's certainly not the outcome we want.\n+\n+So how do you debug this breed of \"hidden\" errors? More broadly speaking, how do you\n+debug any error message in Beam that's complex or confusing (e.g. serialization errors)?\n+\n+The answer is to use runtime type checking.\n+\n+# Runtime Type Checking (RTC)\n+This feature works by checking that actual input and output values satisfy the declared\n+type constraints during pipeline execution. If you ran the code from before with \n+`runtime_type_check` on, you would receive the following error message:\n+\n+```\n+Type hint violation for 'ParDo(MultiplyByTwo)': requires <class 'int'> but got <class 'str'> for element\n+```\n+\n+This is an actionable error message - it tells you that either your code has a bug \n+or that your declared type hints are incorrect. Sounds simple enough, so what's the catch?\n+\n+_It is soooo slowwwwww._ See for yourself.\n+\n+\n+| Element Size | Normal Pipeline | Runtime Type Checking Pipeline\n+| ------------ | --------------- | ------------------------------\n+| 1            | 5.3 sec         | 5.6 sec\n+| 2,001        | 9.4 sec         | 57.2 sec\n+| 10,001       | 24.5 sec        | 259.8 sec\n+| 18,001       | 38.7 sec        | 450.5 sec\n+\n+In this micro-benchmark, the pipeline with runtime type checking was over 10x slower, \n+with the gap only increasing as our input PCollection increased in size.\n+\n+So, is there any production-friendly alternative?\n+\n+# Performance Runtime Type Check\n+There is! We developed a new flag called `performance_runtime_type_check` that\n+minimizes its footprint on the pipeline's time complexity using a combination of\n+- efficient Cython code,\n+- smart sampling techniques, and\n+- optimized mega type-hints.\n+\n+So what do the new numbers look like?\n+\n+| Element Size | Normal    | RTC        | Performance RTC\n+| -----------  | --------- | ---------- | ---------------\n+| 1            | 5.3 sec   | 5.6 sec    | 5.4 sec\n+| 2,001        | 9.4 sec   | 57.2 sec   | 11.2 sec\n+| 10,001       | 24.5 sec  | 259.8 sec  | 25.5 sec\n+| 18,001       | 38.7 sec  | 450.5 sec  | 39.4 sec\n+\n+On average, the new Performance RTC is 4.4% slower than a normal pipeline whereas the old RTC\n+is over 900% slower! Additionally, as the size of the input PCollection increases, the fixed cost\n+of setting up the Performance RTC system is spread across each element, decreasing the relative\n+impact on the overall pipeline. With 18,001 elements, the difference is less than 1 second.\n+\n+## How does it work?\n+There are three key factors responsible for this upgrade in performance.\n+\n+1. Instead of type checking all values, we only type check a subset of values, known as\n+a sample in statistics. Initially, we sample a substantial number of elements, but as our \n+confidence that the element type won't change over time increases, we reduce our \n+sampling rate (up to a fixed minimum).\n+\n+2. Whereas the old RTC system used heavy decorators to perform the type check, the new RTC system", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f9973aafc15a5a0b396ceb22abbcc715e2b0d962"}, "originalPosition": 116}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTAzMzAwOA==", "bodyText": "Any", "url": "https://github.com/apache/beam/pull/12657#discussion_r475033008", "createdAt": "2020-08-22T02:04:29Z", "author": {"login": "udim"}, "path": "website/www/site/content/en/blog/python-performance-runtime-type-checking.md", "diffHunk": "@@ -0,0 +1,154 @@\n+---\n+layout: post\n+title:  \"Performance-Driven Runtime Type Checking for the Python SDK\"\n+date:   2020-08-21 00:00:01 -0800\n+categories:\n+  - blog \n+  - python \n+  - typing\n+authors:\n+  - saavan\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+In this blog post, we're announcing the upcoming release of a new, opt-in \n+runtime type checking system for Beam's Python SDK that's optimized for performance \n+in both development and production environments.\n+\n+But let's take a step back - why do we even care about runtime type checking \n+in the first place? Let's look at an example.\n+\n+```\n+class MultiplyNumberByTwo(beam.DoFn):\n+    def process(self, element: int):\n+        return element * 2\n+\n+p = Pipeline()\n+p | beam.Create(['1', '2'] | beam.ParDo(MultiplyNumberByTwo())\n+```\n+\n+In this code, we passed a list of strings to a DoFn that's clearly intended for use with\n+integers. Luckily, this code will throw an error during pipeline construction because\n+the inferred output type of `beam.Create(['1', '2'])` is `str` which is incompatible with\n+the declared input type hint of `MultiplyNumberByTwo.process` which is `int`.\n+\n+However, what if we turned the pipeline type check off using the `no_pipeline_type_check` \n+flag? Or more realistically, what if the input PCollection to MultiplyNumberByTwo came \n+from a database, preventing inference of the output data type?\n+\n+In either case, no error would be thrown during pipeline construction. \n+And even at runtime, this code works. Each string would be multiplied by 2, \n+yielding a result of `['11', '22']`, but that's certainly not the outcome we want.\n+\n+So how do you debug this breed of \"hidden\" errors? More broadly speaking, how do you\n+debug any error message in Beam that's complex or confusing (e.g. serialization errors)?\n+\n+The answer is to use runtime type checking.\n+\n+# Runtime Type Checking (RTC)\n+This feature works by checking that actual input and output values satisfy the declared\n+type constraints during pipeline execution. If you ran the code from before with \n+`runtime_type_check` on, you would receive the following error message:\n+\n+```\n+Type hint violation for 'ParDo(MultiplyByTwo)': requires <class 'int'> but got <class 'str'> for element\n+```\n+\n+This is an actionable error message - it tells you that either your code has a bug \n+or that your declared type hints are incorrect. Sounds simple enough, so what's the catch?\n+\n+_It is soooo slowwwwww._ See for yourself.\n+\n+\n+| Element Size | Normal Pipeline | Runtime Type Checking Pipeline\n+| ------------ | --------------- | ------------------------------\n+| 1            | 5.3 sec         | 5.6 sec\n+| 2,001        | 9.4 sec         | 57.2 sec\n+| 10,001       | 24.5 sec        | 259.8 sec\n+| 18,001       | 38.7 sec        | 450.5 sec\n+\n+In this micro-benchmark, the pipeline with runtime type checking was over 10x slower, \n+with the gap only increasing as our input PCollection increased in size.\n+\n+So, is there any production-friendly alternative?\n+\n+# Performance Runtime Type Check\n+There is! We developed a new flag called `performance_runtime_type_check` that\n+minimizes its footprint on the pipeline's time complexity using a combination of\n+- efficient Cython code,\n+- smart sampling techniques, and\n+- optimized mega type-hints.\n+\n+So what do the new numbers look like?\n+\n+| Element Size | Normal    | RTC        | Performance RTC\n+| -----------  | --------- | ---------- | ---------------\n+| 1            | 5.3 sec   | 5.6 sec    | 5.4 sec\n+| 2,001        | 9.4 sec   | 57.2 sec   | 11.2 sec\n+| 10,001       | 24.5 sec  | 259.8 sec  | 25.5 sec\n+| 18,001       | 38.7 sec  | 450.5 sec  | 39.4 sec\n+\n+On average, the new Performance RTC is 4.4% slower than a normal pipeline whereas the old RTC\n+is over 900% slower! Additionally, as the size of the input PCollection increases, the fixed cost\n+of setting up the Performance RTC system is spread across each element, decreasing the relative\n+impact on the overall pipeline. With 18,001 elements, the difference is less than 1 second.\n+\n+## How does it work?\n+There are three key factors responsible for this upgrade in performance.\n+\n+1. Instead of type checking all values, we only type check a subset of values, known as\n+a sample in statistics. Initially, we sample a substantial number of elements, but as our \n+confidence that the element type won't change over time increases, we reduce our \n+sampling rate (up to a fixed minimum).\n+\n+2. Whereas the old RTC system used heavy decorators to perform the type check, the new RTC system\n+moves the type check to a Cython-optimized, non-decorated portion of the codebase. For reference, \n+Cython is a programming language that gives C-like performance to Python code.\n+\n+3. Finally, we use a single mega type hint to type-check only the output values of transforms\n+instead of type-checking both the input and output values separately. This mega typehint is composed of\n+the original transform's output type constraints along with all consumer transforms' input type \n+constraints. Using this mega type hint allows us to reduce overhead while simultaneously allowing\n+us to throw _more actionable errors_. For instance, consider the following error (which was \n+generated from the old RTC system):\n+```\n+Runtime type violation detected within ParDo(DownstreamDoFn): Type-hint for argument: 'element' violated. Expected an instance of <class \u2018str\u2019>, instead found 9, an instance of <class \u2018int\u2019>.\n+```\n+\n+This error tells us that the `DownstreamDoFn` received an `int` when it was expecting a `str`, but doesn't tell us\n+who created that `int` in the first place. Who is the offending upstream transform that's responsible for\n+this `int`? Presumably, _that_ transform's output type hints were too expansive (e.g. `any`) or otherwise non-existent because", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f9973aafc15a5a0b396ceb22abbcc715e2b0d962"}, "originalPosition": 132}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "587a20ab0b7a2097399ad4cd336c0ab1514096da", "author": {"user": {"login": "Saavan-Nanavati", "name": null}}, "url": "https://github.com/apache/beam/commit/587a20ab0b7a2097399ad4cd336c0ab1514096da", "committedDate": "2020-08-22T19:23:14Z", "message": "Remove white space"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "58bbad910c12bbb2285a0963d0fc5510f03c1455", "author": {"user": {"login": "Saavan-Nanavati", "name": null}}, "url": "https://github.com/apache/beam/commit/58bbad910c12bbb2285a0963d0fc5510f03c1455", "committedDate": "2020-08-22T19:39:56Z", "message": "Resolve PR comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDc0MTMzMjMz", "url": "https://github.com/apache/beam/pull/12657#pullrequestreview-474133233", "createdAt": "2020-08-25T04:52:45Z", "commit": {"oid": "58bbad910c12bbb2285a0963d0fc5510f03c1455"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4858, "cost": 1, "resetAt": "2021-10-28T16:48:13Z"}}}