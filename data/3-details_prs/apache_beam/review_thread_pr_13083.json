{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTAyMTg5OTg4", "number": 13083, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQyMzo1NjozNFrOE4aJGg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQyMzo1NjozNFrOE4aJGg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI3NTg0MDI2OnYy", "diffSide": "RIGHT", "path": "examples/java/src/main/java/org/apache/beam/examples/snippets/transforms/io/gcp/bigquery/BigQueryReadFromQueryWithBigQueryStorageAPI.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMlQyMzo1NjozNFrOHyT2jA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yMFQyMjowMTowMlrOH3iMxg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjUxNjEwOA==", "bodyText": "I would avoid using readTableRows in an example snippet, both for the storage API and also for the existing export-based model -- this involves a needless conversion from Avro to JSON, where customers should instead be able to consume the Avro GenericRecords directly.", "url": "https://github.com/apache/beam/pull/13083#discussion_r522516108", "createdAt": "2020-11-12T23:56:34Z", "author": {"login": "kmjung"}, "path": "examples/java/src/main/java/org/apache/beam/examples/snippets/transforms/io/gcp/bigquery/BigQueryReadFromQueryWithBigQueryStorageAPI.java", "diffHunk": "@@ -0,0 +1,75 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.examples.snippets.transforms.io.gcp.bigquery;\n+\n+// [START bigquery_read_from_query_with_bigquery_storage_api]\n+\n+import java.util.Arrays;\n+import org.apache.beam.examples.snippets.transforms.io.gcp.bigquery.BigQueryMyData.MyData;\n+import org.apache.beam.sdk.Pipeline;\n+import org.apache.beam.sdk.io.gcp.bigquery.BigQueryIO;\n+import org.apache.beam.sdk.io.gcp.bigquery.BigQueryIO.TypedRead.Method;\n+import org.apache.beam.sdk.transforms.MapElements;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.TypeDescriptor;\n+\n+class BigQueryReadFromQueryWithBigQueryStorageAPI {\n+  public static PCollection<MyData> readFromQueryWithBigQueryStorageAPI(\n+          String project, String dataset, String table, String query, Pipeline pipeline) {\n+\n+    // String project = \"my-project-id\";\n+    // String dataset = \"my_bigquery_dataset_id\";\n+    // String table = \"my_bigquery_table_id\";\n+\n+    // Pipeline pipeline = Pipeline.create();\n+\n+    /*\n+    String query = String.format(\"SELECT\\n\" +\n+        \"  string_field,\\n\" +\n+        \"  int64_field,\\n\" +\n+        \"  float64_field,\\n\" +\n+        \"  numeric_field,\\n\" +\n+        \"  bool_field,\\n\" +\n+        \"  bytes_field,\\n\" +\n+        \"  date_field,\\n\" +\n+        \"  datetime_field,\\n\" +\n+        \"  time_field,\\n\" +\n+        \"  timestamp_field,\\n\" +\n+        \"  geography_field,\\n\" +\n+        \"  array_field,\\n\" +\n+        \"  struct_field\\n\" +\n+        \"FROM\\n\" +\n+        \"  `%s:%s.%s`\", project, dataset, table)\n+    */\n+\n+    PCollection<MyData> rows =\n+        pipeline\n+            .apply(\n+                \"Read from BigQuery table\",\n+                BigQueryIO.readTableRows()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "393bbdeef9148266082b0211f87869656213a942"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzM4OTc3Mw==", "bodyText": "Okay, agree. What would be prefered way to continue with this then?\n\nFinish this PR with using TableRows to have all 3 read examples using the same undesired readTableRows() call\nrefactor this example only to use read<T>(SerializableFunction<SchemaAndRecord, T> f) as a part of this PR\nrefactor all 3 examples using the preferred read<T>(SerializableFunction<SchemaAndRecord, T> f)?\n\nReading from a table\nReading with a query string\nUsing the BigQuery Storage API", "url": "https://github.com/apache/beam/pull/13083#discussion_r527389773", "createdAt": "2020-11-20T04:27:48Z", "author": {"login": "fpopic"}, "path": "examples/java/src/main/java/org/apache/beam/examples/snippets/transforms/io/gcp/bigquery/BigQueryReadFromQueryWithBigQueryStorageAPI.java", "diffHunk": "@@ -0,0 +1,75 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.examples.snippets.transforms.io.gcp.bigquery;\n+\n+// [START bigquery_read_from_query_with_bigquery_storage_api]\n+\n+import java.util.Arrays;\n+import org.apache.beam.examples.snippets.transforms.io.gcp.bigquery.BigQueryMyData.MyData;\n+import org.apache.beam.sdk.Pipeline;\n+import org.apache.beam.sdk.io.gcp.bigquery.BigQueryIO;\n+import org.apache.beam.sdk.io.gcp.bigquery.BigQueryIO.TypedRead.Method;\n+import org.apache.beam.sdk.transforms.MapElements;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.TypeDescriptor;\n+\n+class BigQueryReadFromQueryWithBigQueryStorageAPI {\n+  public static PCollection<MyData> readFromQueryWithBigQueryStorageAPI(\n+          String project, String dataset, String table, String query, Pipeline pipeline) {\n+\n+    // String project = \"my-project-id\";\n+    // String dataset = \"my_bigquery_dataset_id\";\n+    // String table = \"my_bigquery_table_id\";\n+\n+    // Pipeline pipeline = Pipeline.create();\n+\n+    /*\n+    String query = String.format(\"SELECT\\n\" +\n+        \"  string_field,\\n\" +\n+        \"  int64_field,\\n\" +\n+        \"  float64_field,\\n\" +\n+        \"  numeric_field,\\n\" +\n+        \"  bool_field,\\n\" +\n+        \"  bytes_field,\\n\" +\n+        \"  date_field,\\n\" +\n+        \"  datetime_field,\\n\" +\n+        \"  time_field,\\n\" +\n+        \"  timestamp_field,\\n\" +\n+        \"  geography_field,\\n\" +\n+        \"  array_field,\\n\" +\n+        \"  struct_field\\n\" +\n+        \"FROM\\n\" +\n+        \"  `%s:%s.%s`\", project, dataset, table)\n+    */\n+\n+    PCollection<MyData> rows =\n+        pipeline\n+            .apply(\n+                \"Read from BigQuery table\",\n+                BigQueryIO.readTableRows()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjUxNjEwOA=="}, "originalCommit": {"oid": "393bbdeef9148266082b0211f87869656213a942"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzg0MjI2Ng==", "bodyText": "If you have the cycles, let's do (3). Otherwise, you can go ahead with (1) and I will take care of updating them when you're done.", "url": "https://github.com/apache/beam/pull/13083#discussion_r527842266", "createdAt": "2020-11-20T17:20:06Z", "author": {"login": "kmjung"}, "path": "examples/java/src/main/java/org/apache/beam/examples/snippets/transforms/io/gcp/bigquery/BigQueryReadFromQueryWithBigQueryStorageAPI.java", "diffHunk": "@@ -0,0 +1,75 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.examples.snippets.transforms.io.gcp.bigquery;\n+\n+// [START bigquery_read_from_query_with_bigquery_storage_api]\n+\n+import java.util.Arrays;\n+import org.apache.beam.examples.snippets.transforms.io.gcp.bigquery.BigQueryMyData.MyData;\n+import org.apache.beam.sdk.Pipeline;\n+import org.apache.beam.sdk.io.gcp.bigquery.BigQueryIO;\n+import org.apache.beam.sdk.io.gcp.bigquery.BigQueryIO.TypedRead.Method;\n+import org.apache.beam.sdk.transforms.MapElements;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.TypeDescriptor;\n+\n+class BigQueryReadFromQueryWithBigQueryStorageAPI {\n+  public static PCollection<MyData> readFromQueryWithBigQueryStorageAPI(\n+          String project, String dataset, String table, String query, Pipeline pipeline) {\n+\n+    // String project = \"my-project-id\";\n+    // String dataset = \"my_bigquery_dataset_id\";\n+    // String table = \"my_bigquery_table_id\";\n+\n+    // Pipeline pipeline = Pipeline.create();\n+\n+    /*\n+    String query = String.format(\"SELECT\\n\" +\n+        \"  string_field,\\n\" +\n+        \"  int64_field,\\n\" +\n+        \"  float64_field,\\n\" +\n+        \"  numeric_field,\\n\" +\n+        \"  bool_field,\\n\" +\n+        \"  bytes_field,\\n\" +\n+        \"  date_field,\\n\" +\n+        \"  datetime_field,\\n\" +\n+        \"  time_field,\\n\" +\n+        \"  timestamp_field,\\n\" +\n+        \"  geography_field,\\n\" +\n+        \"  array_field,\\n\" +\n+        \"  struct_field\\n\" +\n+        \"FROM\\n\" +\n+        \"  `%s:%s.%s`\", project, dataset, table)\n+    */\n+\n+    PCollection<MyData> rows =\n+        pipeline\n+            .apply(\n+                \"Read from BigQuery table\",\n+                BigQueryIO.readTableRows()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjUxNjEwOA=="}, "originalCommit": {"oid": "393bbdeef9148266082b0211f87869656213a942"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNzk5NDA1NA==", "bodyText": "Then let's merge this, and next week I can refactor all 3 examples.", "url": "https://github.com/apache/beam/pull/13083#discussion_r527994054", "createdAt": "2020-11-20T22:01:02Z", "author": {"login": "fpopic"}, "path": "examples/java/src/main/java/org/apache/beam/examples/snippets/transforms/io/gcp/bigquery/BigQueryReadFromQueryWithBigQueryStorageAPI.java", "diffHunk": "@@ -0,0 +1,75 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.examples.snippets.transforms.io.gcp.bigquery;\n+\n+// [START bigquery_read_from_query_with_bigquery_storage_api]\n+\n+import java.util.Arrays;\n+import org.apache.beam.examples.snippets.transforms.io.gcp.bigquery.BigQueryMyData.MyData;\n+import org.apache.beam.sdk.Pipeline;\n+import org.apache.beam.sdk.io.gcp.bigquery.BigQueryIO;\n+import org.apache.beam.sdk.io.gcp.bigquery.BigQueryIO.TypedRead.Method;\n+import org.apache.beam.sdk.transforms.MapElements;\n+import org.apache.beam.sdk.values.PCollection;\n+import org.apache.beam.sdk.values.TypeDescriptor;\n+\n+class BigQueryReadFromQueryWithBigQueryStorageAPI {\n+  public static PCollection<MyData> readFromQueryWithBigQueryStorageAPI(\n+          String project, String dataset, String table, String query, Pipeline pipeline) {\n+\n+    // String project = \"my-project-id\";\n+    // String dataset = \"my_bigquery_dataset_id\";\n+    // String table = \"my_bigquery_table_id\";\n+\n+    // Pipeline pipeline = Pipeline.create();\n+\n+    /*\n+    String query = String.format(\"SELECT\\n\" +\n+        \"  string_field,\\n\" +\n+        \"  int64_field,\\n\" +\n+        \"  float64_field,\\n\" +\n+        \"  numeric_field,\\n\" +\n+        \"  bool_field,\\n\" +\n+        \"  bytes_field,\\n\" +\n+        \"  date_field,\\n\" +\n+        \"  datetime_field,\\n\" +\n+        \"  time_field,\\n\" +\n+        \"  timestamp_field,\\n\" +\n+        \"  geography_field,\\n\" +\n+        \"  array_field,\\n\" +\n+        \"  struct_field\\n\" +\n+        \"FROM\\n\" +\n+        \"  `%s:%s.%s`\", project, dataset, table)\n+    */\n+\n+    PCollection<MyData> rows =\n+        pipeline\n+            .apply(\n+                \"Read from BigQuery table\",\n+                BigQueryIO.readTableRows()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMjUxNjEwOA=="}, "originalCommit": {"oid": "393bbdeef9148266082b0211f87869656213a942"}, "originalPosition": 64}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2960, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}