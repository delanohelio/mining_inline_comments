{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzY0MjI2ODk0", "number": 10629, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QxNzoyOTozOVrODY4zUw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QxNzoyOTozOVrODY4zUw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjI3NDIzMDU5OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/io/hdfs_integration_test/Dockerfile", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QxNzoyOTozOVrOFfAF_w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0xN1QxNzozNDowMVrOFfAMwA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA1MTcxMQ==", "bodyText": "so our goal is to install grpcio-tools (and therefore protobuf, one of its deps) into the same python environment where sdist is run, before the tests run.  This is easier said than done.\nInstalling build-requirements.txt here in the dockerfile affects the environment where tox is installed and runs, but i'm not sure if it affects the environments where tox runs sdist, especially if tox is trying to create a temp env to run sdist (which I know it does when it's operating in pep517 mode).\nAdding build-requirements.txt to the deps in tox.ini I think only affects the environment where the tests run, but not where tox runs sdist.\ngen_protos.py also does its own attempt to install build-requirements.txt if it detects grpcio-tools is not installed, but it does it in a weird way with a target install directory, which I think might not be reliable for the google .pth file that makes protobufs importable in python2 (see earlier discussion about site dirs).\nSo, I've got 2 ideas left for how to hack this together without going full pep517:\n\nrun python setup.py sdist here in dockerland, after installing build-requirements, and pass the sdist to tox.  That should guarantee that sdist is run in an env where protobuf is properly installed where the google .pth file will work, since we're installing it into the site-packages of the python interpreter running here, and not some temp dir.\nchange the logic in gen_protos where it installs build-requirements to also ensure that the directory it installs into is added as a site dir, by calling site.addsitedir() on that directory from the environment where we want to be able to import google.protobuf.", "url": "https://github.com/apache/beam/pull/10629#discussion_r368051711", "createdAt": "2020-01-17T17:29:39Z", "author": {"login": "chadrik"}, "path": "sdks/python/apache_beam/io/hdfs_integration_test/Dockerfile", "diffHunk": "@@ -24,22 +24,13 @@ FROM $BASE_IMAGE\n \n WORKDIR /app\n ENV HDFSCLI_CONFIG /app/sdks/python/apache_beam/io/hdfs_integration_test/hdfscli.cfg\n-RUN pip install --no-cache-dir holdup gsutil\n-RUN gsutil cp gs://dataflow-samples/shakespeare/kinglear.txt .\n \n-# Install Beam and dependencies.\n-ADD sdks/python /app/sdks/python\n-ADD model /app/model\n-RUN cd sdks/python && \\\n-    python setup.py sdist && \\\n-    pip install --no-cache-dir $(ls dist/apache-beam-*.tar.gz | tail -n1)[gcp]\n+# Add Beam SDK sources.\n+COPY sdks/python /app/sdks/python\n+COPY model /app/model\n+\n+# This step should look like setupVirtualenv minus virtualenv creation.\n+RUN pip install --no-cache-dir tox==3.11.1 -r sdks/python/build-requirements.txt", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "86a29197f9285bdbd10cbeecd3166d90e1c17a61"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA1MzQ0MA==", "bodyText": "Ah, I wrote my comment on the previous version of this.  Glad to see that adding the build-requirements here worked.  Like I said I wasn't sure if that would affect how tox runs sdist, since when I was testing with pyproject.toml, it did not, because it was using an isolated build environment.", "url": "https://github.com/apache/beam/pull/10629#discussion_r368053440", "createdAt": "2020-01-17T17:34:01Z", "author": {"login": "chadrik"}, "path": "sdks/python/apache_beam/io/hdfs_integration_test/Dockerfile", "diffHunk": "@@ -24,22 +24,13 @@ FROM $BASE_IMAGE\n \n WORKDIR /app\n ENV HDFSCLI_CONFIG /app/sdks/python/apache_beam/io/hdfs_integration_test/hdfscli.cfg\n-RUN pip install --no-cache-dir holdup gsutil\n-RUN gsutil cp gs://dataflow-samples/shakespeare/kinglear.txt .\n \n-# Install Beam and dependencies.\n-ADD sdks/python /app/sdks/python\n-ADD model /app/model\n-RUN cd sdks/python && \\\n-    python setup.py sdist && \\\n-    pip install --no-cache-dir $(ls dist/apache-beam-*.tar.gz | tail -n1)[gcp]\n+# Add Beam SDK sources.\n+COPY sdks/python /app/sdks/python\n+COPY model /app/model\n+\n+# This step should look like setupVirtualenv minus virtualenv creation.\n+RUN pip install --no-cache-dir tox==3.11.1 -r sdks/python/build-requirements.txt", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM2ODA1MTcxMQ=="}, "originalCommit": {"oid": "86a29197f9285bdbd10cbeecd3166d90e1c17a61"}, "originalPosition": 18}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2212, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}