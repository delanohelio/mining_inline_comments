{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDMyNjk0MzAz", "number": 11974, "title": "[BEAM-9547] Add more methods to deferred dataframes.", "bodyText": "A significant portion of the tests now pass. They are not all, however, optimally parallelized.\nThank you for your contribution! Follow this checklist to help us incorporate your contribution quickly and easily:\n\n Choose reviewer(s) and mention them in a comment (R: @username).\n Format the pull request title like [BEAM-XXX] Fixes bug in ApproximateQuantiles, where you replace BEAM-XXX with the appropriate JIRA issue, if applicable. This will automatically link the pull request to the issue.\n Update CHANGES.md with noteworthy changes.\n If this contribution is large, please file an Apache Individual Contributor License Agreement.\n\nSee the Contributor Guide for more tips on how to make review process smoother.\nPost-Commit Tests Status (on master branch)\n\n\n\nLang\nSDK\nApex\nDataflow\nFlink\nSamza\nSpark\n\n\n\n\nGo\n\n---\n---\n\n---\n\n\n\nJava\n\n\n\n\n\n\n\n\nPython\n\n---\n\n\n---\n\n\n\nXLang\n---\n---\n---\n\n---\n---\n\n\n\nPre-Commit Tests Status (on master branch)\n\n\n\n---\nJava\nPython\nGo\nWebsite\n\n\n\n\nNon-portable\n\n\n\n\n\n\nPortable\n---\n\n---\n---\n\n\n\nSee .test-infra/jenkins/README for trigger phrase, status and link of all Jenkins jobs.", "createdAt": "2020-06-10T20:49:44Z", "url": "https://github.com/apache/beam/pull/11974", "merged": true, "mergeCommit": {"oid": "2496fc40bc746dfc8dab41b7030592630f9ce253"}, "closed": true, "closedAt": "2020-07-29T21:25:42Z", "author": {"login": "robertwb"}, "timelineItems": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc13affgH2gAyNDMyNjk0MzAzOjM2ZGM3NjUwYmE2YmJmMjkyMzc3MTA2OTAxOWE5NmQ0Y2M0NDFmOTk=", "endCursor": "Y3Vyc29yOnYyOpPPAAABc5v7jUgBqjM2MDA0NTIxMTM=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "36dc7650ba6bbf2923771069019a96d4cc441f99", "author": {"user": {"login": "robertwb", "name": "Robert Bradshaw"}}, "url": "https://github.com/apache/beam/commit/36dc7650ba6bbf2923771069019a96d4cc441f99", "committedDate": "2020-07-17T17:37:47Z", "message": "Extend elementwise to generic proxy fn."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ce5d75b1fdccc672977da155fbebec12ccc6afee", "author": {"user": {"login": "robertwb", "name": "Robert Bradshaw"}}, "url": "https://github.com/apache/beam/commit/ce5d75b1fdccc672977da155fbebec12ccc6afee", "committedDate": "2020-07-17T18:31:43Z", "message": "Add a more methods to dataframes."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "2b5f49d6aa0e455a0eef1bbbc9056479f5e75e70", "author": {"user": {"login": "robertwb", "name": "Robert Bradshaw"}}, "url": "https://github.com/apache/beam/commit/2b5f49d6aa0e455a0eef1bbbc9056479f5e75e70", "committedDate": "2020-06-10T20:46:10Z", "message": "support scalar values"}, "afterCommit": {"oid": "24effc3a1e056727ca755e7494070da2a368b602", "author": {"user": {"login": "robertwb", "name": "Robert Bradshaw"}}, "url": "https://github.com/apache/beam/commit/24effc3a1e056727ca755e7494070da2a368b602", "committedDate": "2020-07-17T18:42:35Z", "message": "More dataframes methods and test filters."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a37170e5c6210d56a54b53b54a6044f62dac4626", "author": {"user": {"login": "robertwb", "name": "Robert Bradshaw"}}, "url": "https://github.com/apache/beam/commit/a37170e5c6210d56a54b53b54a6044f62dac4626", "committedDate": "2020-07-17T22:28:26Z", "message": "Add support for dataframe scalar values."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8b08bf2f46477cf1f960a4fa3b9cb68b21d49498", "author": {"user": {"login": "robertwb", "name": "Robert Bradshaw"}}, "url": "https://github.com/apache/beam/commit/8b08bf2f46477cf1f960a4fa3b9cb68b21d49498", "committedDate": "2020-07-17T22:28:26Z", "message": "More dataframes methods and test filters."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "24effc3a1e056727ca755e7494070da2a368b602", "author": {"user": {"login": "robertwb", "name": "Robert Bradshaw"}}, "url": "https://github.com/apache/beam/commit/24effc3a1e056727ca755e7494070da2a368b602", "committedDate": "2020-07-17T18:42:35Z", "message": "More dataframes methods and test filters."}, "afterCommit": {"oid": "8b08bf2f46477cf1f960a4fa3b9cb68b21d49498", "author": {"user": {"login": "robertwb", "name": "Robert Bradshaw"}}, "url": "https://github.com/apache/beam/commit/8b08bf2f46477cf1f960a4fa3b9cb68b21d49498", "committedDate": "2020-07-17T22:28:26Z", "message": "More dataframes methods and test filters."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU3MDg4MDk4", "url": "https://github.com/apache/beam/pull/11974#pullrequestreview-457088098", "createdAt": "2020-07-28T23:04:48Z", "commit": {"oid": "8b08bf2f46477cf1f960a4fa3b9cb68b21d49498"}, "state": "APPROVED", "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQyMzowNDo0OFrOG4ivdQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQwMDowNjozMlrOG4j9cA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk0MjY0NQ==", "bodyText": "Doesn't need to happen in this PR, but it could be preferable to have different types/modes of skip. e.g.\n\nallow_wont_implement: passes if WontImplementError is thrown.\nallow_error: passes if any other exception is thrown\nalllow_error_or_wrong_answer: passes if an exception is thrown or if Beam is producing the wrong answer.\n\nThat way it'll be clearly documented which ops we don't intend to implement, and which ones can produce incorrect data and should be avoided.", "url": "https://github.com/apache/beam/pull/11974#discussion_r461942645", "createdAt": "2020-07-28T23:04:48Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/pandas_doctests_test.py", "diffHunk": "@@ -34,77 +34,54 @@ def test_dataframe_tests(self):\n             'pandas.core.frame.DataFrame.T': ['*'],\n             'pandas.core.frame.DataFrame.agg': ['*'],\n             'pandas.core.frame.DataFrame.aggregate': ['*'],\n-            'pandas.core.frame.DataFrame.all': ['*'],\n-            'pandas.core.frame.DataFrame.any': ['*'],\n             'pandas.core.frame.DataFrame.append': ['*'],\n             'pandas.core.frame.DataFrame.apply': ['*'],\n-            'pandas.core.frame.DataFrame.applymap': ['*'],\n+            'pandas.core.frame.DataFrame.applymap': ['df ** 2'],\n             'pandas.core.frame.DataFrame.assign': ['*'],\n             'pandas.core.frame.DataFrame.axes': ['*'],\n             'pandas.core.frame.DataFrame.combine': ['*'],\n             'pandas.core.frame.DataFrame.combine_first': ['*'],\n             'pandas.core.frame.DataFrame.corr': ['*'],\n             'pandas.core.frame.DataFrame.count': ['*'],\n             'pandas.core.frame.DataFrame.cov': ['*'],\n-            'pandas.core.frame.DataFrame.cummax': ['*'],\n-            'pandas.core.frame.DataFrame.cummin': ['*'],\n-            'pandas.core.frame.DataFrame.cumprod': ['*'],\n-            'pandas.core.frame.DataFrame.cumsum': ['*'],\n-            'pandas.core.frame.DataFrame.diff': ['*'],\n             'pandas.core.frame.DataFrame.dot': ['*'],\n             'pandas.core.frame.DataFrame.drop': ['*'],\n-            'pandas.core.frame.DataFrame.dropna': ['*'],\n             'pandas.core.frame.DataFrame.eval': ['*'],\n             'pandas.core.frame.DataFrame.explode': ['*'],\n             'pandas.core.frame.DataFrame.fillna': ['*'],\n             'pandas.core.frame.DataFrame.info': ['*'],\n             'pandas.core.frame.DataFrame.isin': ['*'],\n-            'pandas.core.frame.DataFrame.isna': ['*'],\n-            'pandas.core.frame.DataFrame.isnull': ['*'],\n-            'pandas.core.frame.DataFrame.items': ['*'],\n-            'pandas.core.frame.DataFrame.iteritems': ['*'],\n-            'pandas.core.frame.DataFrame.iterrows': ['*'],\n-            'pandas.core.frame.DataFrame.itertuples': ['*'],\n+            'pandas.core.frame.DataFrame.iterrows': [\"print(df['int'].dtype)\"],\n             'pandas.core.frame.DataFrame.join': ['*'],\n-            'pandas.core.frame.DataFrame.max': ['*'],\n             'pandas.core.frame.DataFrame.melt': ['*'],\n             'pandas.core.frame.DataFrame.memory_usage': ['*'],\n             'pandas.core.frame.DataFrame.merge': ['*'],\n-            'pandas.core.frame.DataFrame.min': ['*'],\n-            'pandas.core.frame.DataFrame.mode': ['*'],\n+            # Not equal to df.agg('mode', axis='columns', numeric_only=True)\n+            'pandas.core.frame.DataFrame.mode': [\n+                \"df.mode(axis='columns', numeric_only=True)\"\n+            ],\n             'pandas.core.frame.DataFrame.nlargest': ['*'],\n-            'pandas.core.frame.DataFrame.notna': ['*'],\n-            'pandas.core.frame.DataFrame.notnull': ['*'],\n             'pandas.core.frame.DataFrame.nsmallest': ['*'],\n             'pandas.core.frame.DataFrame.nunique': ['*'],\n             'pandas.core.frame.DataFrame.pivot': ['*'],\n             'pandas.core.frame.DataFrame.pivot_table': ['*'],\n-            'pandas.core.frame.DataFrame.prod': ['*'],\n-            'pandas.core.frame.DataFrame.product': ['*'],\n-            'pandas.core.frame.DataFrame.quantile': ['*'],\n             'pandas.core.frame.DataFrame.query': ['*'],\n             'pandas.core.frame.DataFrame.reindex': ['*'],\n             'pandas.core.frame.DataFrame.reindex_axis': ['*'],\n             'pandas.core.frame.DataFrame.rename': ['*'],\n-            'pandas.core.frame.DataFrame.replace': ['*'],\n-            'pandas.core.frame.DataFrame.reset_index': ['*'],\n+            # Raises right exception, but testing framework has matching issues.\n+            'pandas.core.frame.DataFrame.replace': [\n+                \"df.replace({'a string': 'new value', True: False})  # raises\"\n+            ],\n+            # Uses unseeded np.random.\n             'pandas.core.frame.DataFrame.round': ['*'],\n-            'pandas.core.frame.DataFrame.select_dtypes': ['*'],\n             'pandas.core.frame.DataFrame.set_index': ['*'],\n-            'pandas.core.frame.DataFrame.shape': ['*'],\n-            'pandas.core.frame.DataFrame.shift': ['*'],\n-            'pandas.core.frame.DataFrame.sort_values': ['*'],\n-            'pandas.core.frame.DataFrame.stack': ['*'],\n-            'pandas.core.frame.DataFrame.sum': ['*'],\n-            'pandas.core.frame.DataFrame.to_dict': ['*'],\n-            'pandas.core.frame.DataFrame.to_numpy': ['*'],\n+            'pandas.core.frame.DataFrame.transpose': [\n+                'df1_transposed.dtypes', 'df2_transposed.dtypes'\n+            ],\n+            'pandas.core.frame.DataFrame.to_sparse': ['type(df)'],\n+            # Uses df.index", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b08bf2f46477cf1f960a4fa3b9cb68b21d49498"}, "originalPosition": 83}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk1MTc4Ng==", "bodyText": "Looks like this can be 'columns' as well: https://pandas.pydata.org/pandas-docs/version/0.24.2/reference/api/pandas.DataFrame.shift.html?highlight=shift#pandas.DataFrame.shift\nWe should check for that  throughout so we don't end up using Singleton partitioning unnecessarily.\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                if axis == 1:\n          \n          \n            \n                if axis == 1 or axis == 'columns':", "url": "https://github.com/apache/beam/pull/11974#discussion_r461951786", "createdAt": "2020-07-28T23:31:53Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/frames.py", "diffHunk": "@@ -111,19 +164,181 @@ def at(self, *args, **kwargs):\n   def loc(self):\n     return _DeferredLoc(self)\n \n-  def aggregate(self, func, axis=0, *args, **kwargs):\n-    if axis != 0:\n-      raise NotImplementedError()\n+  def aggregate(self, *args, **kwargs):\n+    if 'axis' in kwargs and kwargs['axis'] is None:\n+      return self.agg(*args, **dict(kwargs, axis=1)).agg(\n+          *args, **dict(kwargs, axis=0))\n     return frame_base.DeferredFrame.wrap(\n         expressions.ComputedExpression(\n             'aggregate',\n-            lambda df: df.agg(func, axis, *args, **kwargs),\n+            lambda df: df.agg(*args, **kwargs),\n             [self._expr],\n             # TODO(robertwb): Sub-aggregate when possible.\n             requires_partition_by=partitionings.Singleton()))\n \n   agg = aggregate\n \n+  applymap = frame_base._elementwise_method('applymap')\n+\n+  def memory_usage(self):\n+    raise frame_base.WontImplementError()\n+\n+  all = frame_base._associative_agg_method('all')\n+  any = frame_base._associative_agg_method('any')\n+\n+  cummax = cummin = cumsum = cumprod = frame_base.wont_implement_method(\n+      'order-sensitive')\n+  diff = frame_base.wont_implement_method('order-sensitive')\n+\n+  max = frame_base._associative_agg_method('max')\n+  min = frame_base._associative_agg_method('min')\n+  mode = frame_base._agg_method('mode')\n+\n+  def dropna(self, axis=0, how='any', thresh=None, subset=None, inplace=False, *args, **kwargs):\n+    # TODO(robertwb): This is a common pattern. Generalize?\n+    if axis == 1:\n+      requires_partition_by = partitionings.Singleton()\n+    else:\n+      requires_partition_by = partitionings.Nothing()\n+    result = frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'dropna',\n+            lambda df: df.dropna(axis, how, thresh, subset, False, *args, **kwargs),\n+            [self._expr],\n+            preserves_partition_by=partitionings.Singleton(),\n+            requires_partition_by=requires_partition_by))\n+    if inplace:\n+      self._expr = result._expr\n+    else:\n+      return result\n+\n+  items = itertuples = iterrows = iteritems = frame_base.wont_implement_method(\n+      'non-lazy')\n+\n+  isna = frame_base._elementwise_method('isna')\n+  notnull = notna = frame_base._elementwise_method('notna')\n+\n+  prod = product = frame_base._associative_agg_method('prod')\n+\n+  def quantile(self, q=0.5, axis=0, *args, **kwargs):\n+    if axis != 0:\n+      raise frame_base.WontImplementError('non-deferred column values')\n+    return frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'quantile',\n+            lambda df: df.quantile(q, axis, *args, **kwargs),\n+            [self._expr],\n+            #TODO(robertwb): Approximate quantiles?\n+            requires_partition_by=partitionings.Singleton(),\n+            preserves_partition_by=partitionings.Singleton()))\n+\n+  query = frame_base._elementwise_method('query')\n+\n+  def replace(self, to_replace=None,\n+      value=None,\n+      inplace=False,\n+      limit=None, *args, **kwargs):\n+    if limit is None:\n+      requires_partition_by = partitionings.Nothing()\n+    else:\n+      requires_partition_by = partitionings.Singleton()\n+    result = frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'replace',\n+            lambda df: df.replace(to_replace, value, False, limit, *args, **kwargs),\n+            [self._expr],\n+            preserves_partition_by=partitionings.Singleton(),\n+            requires_partition_by=requires_partition_by))\n+    if inplace:\n+      self._expr = result._expr\n+    else:\n+      return result\n+\n+  def reset_index(self, level=None, drop=False, inplace=False, *args, **kwargs):\n+    if level is not None and not isinstance(level, (tuple, list)):\n+      level = [level]\n+    if level is None or len(level) == len(self._expr.proxy().index.levels):\n+      # TODO: Could do distributed re-index with offsets.\n+      requires_partition_by = partitionings.Singleton()\n+    else:\n+      requires_partition_by = partitionings.Nothing()\n+    result = frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'reset_index',\n+            lambda df: df.reset_index(level, drop, False, *args, **kwargs),\n+            [self._expr],\n+            preserves_partition_by=partitionings.Singleton(),\n+            requires_partition_by=requires_partition_by))\n+    if inplace:\n+      self._expr = result._expr\n+    else:\n+      return result\n+\n+  round = frame_base._elementwise_method('round')\n+  select_dtypes = frame_base._elementwise_method('select_dtypes')\n+\n+  def shift(self, periods=1, freq=None, axis=0, *args, **kwargs):\n+    if axis == 1:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b08bf2f46477cf1f960a4fa3b9cb68b21d49498"}, "originalPosition": 189}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk1Mjc4Nw==", "bodyText": "nit: should this be scalar?", "url": "https://github.com/apache/beam/pull/11974#discussion_r461952787", "createdAt": "2020-07-28T23:34:50Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/frame_base.py", "diffHunk": "@@ -41,16 +42,34 @@ def wrapper(deferred_type):\n \n   @classmethod\n   def wrap(cls, expr):\n-    return cls._pandas_type_map[type(expr.proxy())](expr)\n+    proxy_type = type(expr.proxy())\n+    if proxy_type in cls._pandas_type_map:\n+      wrapper_type = cls._pandas_type_map[proxy_type]\n+    else:\n+      if expr.requires_partition_by() != partitionings.Singleton():\n+        raise ValueError(\n+            'Scalar expression %s partitoned by non-singleton %s' %\n+            (expr, expr.requires_partition_by()))\n+      wrapper_type = _DeferredScaler\n+    return wrapper_type(expr)\n \n   def _elementwise(self, func, name=None, other_args=(), inplace=False):\n     return _elementwise_function(func, name, inplace=inplace)(self, *other_args)\n \n+\n+class DeferredFrame(DeferredBase):\n   @property\n   def dtypes(self):\n     return self._expr.proxy().dtypes\n \n \n+class _DeferredScaler(DeferredBase):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b08bf2f46477cf1f960a4fa3b9cb68b21d49498"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk1NzQzMQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              def to_string(self, *args, **kwargs):\n          \n          \n            \n                raise frame_base.WontImplementError('non-deferred value')\n          \n          \n            \n            \n          \n          \n            \n              to_records = to_dict = to_numpy = to_string\n          \n          \n            \n              to_records = to_dict = to_numpy = to_string = frame_base.wont_implement_method('non-deferred value')\n          \n      \n    \n    \n  \n\nnit: I think we should prefer wont_implement_method instead of def and raise", "url": "https://github.com/apache/beam/pull/11974#discussion_r461957431", "createdAt": "2020-07-28T23:49:33Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/frames.py", "diffHunk": "@@ -111,19 +164,181 @@ def at(self, *args, **kwargs):\n   def loc(self):\n     return _DeferredLoc(self)\n \n-  def aggregate(self, func, axis=0, *args, **kwargs):\n-    if axis != 0:\n-      raise NotImplementedError()\n+  def aggregate(self, *args, **kwargs):\n+    if 'axis' in kwargs and kwargs['axis'] is None:\n+      return self.agg(*args, **dict(kwargs, axis=1)).agg(\n+          *args, **dict(kwargs, axis=0))\n     return frame_base.DeferredFrame.wrap(\n         expressions.ComputedExpression(\n             'aggregate',\n-            lambda df: df.agg(func, axis, *args, **kwargs),\n+            lambda df: df.agg(*args, **kwargs),\n             [self._expr],\n             # TODO(robertwb): Sub-aggregate when possible.\n             requires_partition_by=partitionings.Singleton()))\n \n   agg = aggregate\n \n+  applymap = frame_base._elementwise_method('applymap')\n+\n+  def memory_usage(self):\n+    raise frame_base.WontImplementError()\n+\n+  all = frame_base._associative_agg_method('all')\n+  any = frame_base._associative_agg_method('any')\n+\n+  cummax = cummin = cumsum = cumprod = frame_base.wont_implement_method(\n+      'order-sensitive')\n+  diff = frame_base.wont_implement_method('order-sensitive')\n+\n+  max = frame_base._associative_agg_method('max')\n+  min = frame_base._associative_agg_method('min')\n+  mode = frame_base._agg_method('mode')\n+\n+  def dropna(self, axis=0, how='any', thresh=None, subset=None, inplace=False, *args, **kwargs):\n+    # TODO(robertwb): This is a common pattern. Generalize?\n+    if axis == 1:\n+      requires_partition_by = partitionings.Singleton()\n+    else:\n+      requires_partition_by = partitionings.Nothing()\n+    result = frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'dropna',\n+            lambda df: df.dropna(axis, how, thresh, subset, False, *args, **kwargs),\n+            [self._expr],\n+            preserves_partition_by=partitionings.Singleton(),\n+            requires_partition_by=requires_partition_by))\n+    if inplace:\n+      self._expr = result._expr\n+    else:\n+      return result\n+\n+  items = itertuples = iterrows = iteritems = frame_base.wont_implement_method(\n+      'non-lazy')\n+\n+  isna = frame_base._elementwise_method('isna')\n+  notnull = notna = frame_base._elementwise_method('notna')\n+\n+  prod = product = frame_base._associative_agg_method('prod')\n+\n+  def quantile(self, q=0.5, axis=0, *args, **kwargs):\n+    if axis != 0:\n+      raise frame_base.WontImplementError('non-deferred column values')\n+    return frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'quantile',\n+            lambda df: df.quantile(q, axis, *args, **kwargs),\n+            [self._expr],\n+            #TODO(robertwb): Approximate quantiles?\n+            requires_partition_by=partitionings.Singleton(),\n+            preserves_partition_by=partitionings.Singleton()))\n+\n+  query = frame_base._elementwise_method('query')\n+\n+  def replace(self, to_replace=None,\n+      value=None,\n+      inplace=False,\n+      limit=None, *args, **kwargs):\n+    if limit is None:\n+      requires_partition_by = partitionings.Nothing()\n+    else:\n+      requires_partition_by = partitionings.Singleton()\n+    result = frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'replace',\n+            lambda df: df.replace(to_replace, value, False, limit, *args, **kwargs),\n+            [self._expr],\n+            preserves_partition_by=partitionings.Singleton(),\n+            requires_partition_by=requires_partition_by))\n+    if inplace:\n+      self._expr = result._expr\n+    else:\n+      return result\n+\n+  def reset_index(self, level=None, drop=False, inplace=False, *args, **kwargs):\n+    if level is not None and not isinstance(level, (tuple, list)):\n+      level = [level]\n+    if level is None or len(level) == len(self._expr.proxy().index.levels):\n+      # TODO: Could do distributed re-index with offsets.\n+      requires_partition_by = partitionings.Singleton()\n+    else:\n+      requires_partition_by = partitionings.Nothing()\n+    result = frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'reset_index',\n+            lambda df: df.reset_index(level, drop, False, *args, **kwargs),\n+            [self._expr],\n+            preserves_partition_by=partitionings.Singleton(),\n+            requires_partition_by=requires_partition_by))\n+    if inplace:\n+      self._expr = result._expr\n+    else:\n+      return result\n+\n+  round = frame_base._elementwise_method('round')\n+  select_dtypes = frame_base._elementwise_method('select_dtypes')\n+\n+  def shift(self, periods=1, freq=None, axis=0, *args, **kwargs):\n+    if axis == 1:\n+      requires_partition_by = partitionings.Nothing()\n+    else:\n+      requires_partition_by = partitionings.Singleton()\n+    return frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'shift',\n+            lambda df: df.shift(periods, freq, axis, *args, **kwargs),\n+            [self._expr],\n+            preserves_partition_by=partitionings.Singleton(),\n+            requires_partition_by=requires_partition_by))\n+\n+  @property\n+  def shape(self):\n+    raise frame_base.WontImplementError('scalar value')\n+\n+  def sort_values(self, by, axis=0, ascending=True, inplace=False, *args, **kwargs):\n+    if axis == 1:\n+      requires_partition_by = partitionings.Nothing()\n+    else:\n+      requires_partition_by = partitionings.Singleton()\n+    result = frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'sort_values',\n+            lambda df: df.sort_values(by, axis, ascending, False, *args, **kwargs),\n+            [self._expr],\n+            preserves_partition_by=partitionings.Singleton(),\n+            requires_partition_by=requires_partition_by))\n+    if inplace:\n+      self._expr = result._expr\n+    else:\n+      return result\n+\n+  stack = frame_base._elementwise_method('stack')\n+\n+  sum = frame_base._associative_agg_method('sum')\n+\n+  def to_string(self, *args, **kwargs):\n+    raise frame_base.WontImplementError('non-deferred value')\n+\n+  to_records = to_dict = to_numpy = to_string", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b08bf2f46477cf1f960a4fa3b9cb68b21d49498"}, "originalPosition": 229}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk1ODc0Ng==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                        'pandas.core.frame.DataFrame.agg': ['*'],\n          \n          \n            \n                        'pandas.core.frame.DataFrame.aggregate': ['*'],\n          \n      \n    \n    \n  \n\nThese should be supported right (also for Series)? Looks like the tests pass for me locally with these unskipped.", "url": "https://github.com/apache/beam/pull/11974#discussion_r461958746", "createdAt": "2020-07-28T23:53:45Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/pandas_doctests_test.py", "diffHunk": "@@ -34,77 +34,54 @@ def test_dataframe_tests(self):\n             'pandas.core.frame.DataFrame.T': ['*'],\n             'pandas.core.frame.DataFrame.agg': ['*'],\n             'pandas.core.frame.DataFrame.aggregate': ['*'],", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b08bf2f46477cf1f960a4fa3b9cb68b21d49498"}, "originalPosition": 3}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk2MDczMQ==", "bodyText": "Any thoughts on how we should communicate to the user that Singleton partitioning is happening and it's bad?\nMaybe we should refuse to apply operations that require singleton partitioning by default unless a user opts in?", "url": "https://github.com/apache/beam/pull/11974#discussion_r461960731", "createdAt": "2020-07-29T00:00:16Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/frames.py", "diffHunk": "@@ -111,19 +164,181 @@ def at(self, *args, **kwargs):\n   def loc(self):\n     return _DeferredLoc(self)\n \n-  def aggregate(self, func, axis=0, *args, **kwargs):\n-    if axis != 0:\n-      raise NotImplementedError()\n+  def aggregate(self, *args, **kwargs):\n+    if 'axis' in kwargs and kwargs['axis'] is None:\n+      return self.agg(*args, **dict(kwargs, axis=1)).agg(\n+          *args, **dict(kwargs, axis=0))\n     return frame_base.DeferredFrame.wrap(\n         expressions.ComputedExpression(\n             'aggregate',\n-            lambda df: df.agg(func, axis, *args, **kwargs),\n+            lambda df: df.agg(*args, **kwargs),\n             [self._expr],\n             # TODO(robertwb): Sub-aggregate when possible.\n             requires_partition_by=partitionings.Singleton()))\n \n   agg = aggregate\n \n+  applymap = frame_base._elementwise_method('applymap')\n+\n+  def memory_usage(self):\n+    raise frame_base.WontImplementError()\n+\n+  all = frame_base._associative_agg_method('all')\n+  any = frame_base._associative_agg_method('any')\n+\n+  cummax = cummin = cumsum = cumprod = frame_base.wont_implement_method(\n+      'order-sensitive')\n+  diff = frame_base.wont_implement_method('order-sensitive')\n+\n+  max = frame_base._associative_agg_method('max')\n+  min = frame_base._associative_agg_method('min')\n+  mode = frame_base._agg_method('mode')\n+\n+  def dropna(self, axis=0, how='any', thresh=None, subset=None, inplace=False, *args, **kwargs):\n+    # TODO(robertwb): This is a common pattern. Generalize?\n+    if axis == 1:\n+      requires_partition_by = partitionings.Singleton()\n+    else:\n+      requires_partition_by = partitionings.Nothing()\n+    result = frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'dropna',\n+            lambda df: df.dropna(axis, how, thresh, subset, False, *args, **kwargs),\n+            [self._expr],\n+            preserves_partition_by=partitionings.Singleton(),\n+            requires_partition_by=requires_partition_by))\n+    if inplace:\n+      self._expr = result._expr\n+    else:\n+      return result\n+\n+  items = itertuples = iterrows = iteritems = frame_base.wont_implement_method(\n+      'non-lazy')\n+\n+  isna = frame_base._elementwise_method('isna')\n+  notnull = notna = frame_base._elementwise_method('notna')\n+\n+  prod = product = frame_base._associative_agg_method('prod')\n+\n+  def quantile(self, q=0.5, axis=0, *args, **kwargs):\n+    if axis != 0:\n+      raise frame_base.WontImplementError('non-deferred column values')\n+    return frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'quantile',\n+            lambda df: df.quantile(q, axis, *args, **kwargs),\n+            [self._expr],\n+            #TODO(robertwb): Approximate quantiles?\n+            requires_partition_by=partitionings.Singleton(),\n+            preserves_partition_by=partitionings.Singleton()))\n+\n+  query = frame_base._elementwise_method('query')\n+\n+  def replace(self, to_replace=None,\n+      value=None,\n+      inplace=False,\n+      limit=None, *args, **kwargs):\n+    if limit is None:\n+      requires_partition_by = partitionings.Nothing()\n+    else:\n+      requires_partition_by = partitionings.Singleton()\n+    result = frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'replace',\n+            lambda df: df.replace(to_replace, value, False, limit, *args, **kwargs),\n+            [self._expr],\n+            preserves_partition_by=partitionings.Singleton(),\n+            requires_partition_by=requires_partition_by))\n+    if inplace:\n+      self._expr = result._expr\n+    else:\n+      return result\n+\n+  def reset_index(self, level=None, drop=False, inplace=False, *args, **kwargs):\n+    if level is not None and not isinstance(level, (tuple, list)):\n+      level = [level]\n+    if level is None or len(level) == len(self._expr.proxy().index.levels):\n+      # TODO: Could do distributed re-index with offsets.\n+      requires_partition_by = partitionings.Singleton()\n+    else:\n+      requires_partition_by = partitionings.Nothing()\n+    result = frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'reset_index',\n+            lambda df: df.reset_index(level, drop, False, *args, **kwargs),\n+            [self._expr],\n+            preserves_partition_by=partitionings.Singleton(),\n+            requires_partition_by=requires_partition_by))\n+    if inplace:\n+      self._expr = result._expr\n+    else:\n+      return result\n+\n+  round = frame_base._elementwise_method('round')\n+  select_dtypes = frame_base._elementwise_method('select_dtypes')\n+\n+  def shift(self, periods=1, freq=None, axis=0, *args, **kwargs):\n+    if axis == 1:\n+      requires_partition_by = partitionings.Nothing()\n+    else:\n+      requires_partition_by = partitionings.Singleton()\n+    return frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'shift',\n+            lambda df: df.shift(periods, freq, axis, *args, **kwargs),\n+            [self._expr],\n+            preserves_partition_by=partitionings.Singleton(),\n+            requires_partition_by=requires_partition_by))\n+\n+  @property\n+  def shape(self):\n+    raise frame_base.WontImplementError('scalar value')\n+\n+  def sort_values(self, by, axis=0, ascending=True, inplace=False, *args, **kwargs):\n+    if axis == 1:\n+      requires_partition_by = partitionings.Nothing()\n+    else:\n+      requires_partition_by = partitionings.Singleton()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b08bf2f46477cf1f960a4fa3b9cb68b21d49498"}, "originalPosition": 209}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk2MjYwOA==", "bodyText": "This should accept *args, **kwargs:\n\n  \n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n              def memory_usage(self):\n          \n          \n            \n                raise frame_base.WontImplementError()\n          \n          \n            \n              memory_usage = frame_base.wont_implement_method('scalar value')\n          \n      \n    \n    \n  \n\nIt looks like this still can't be un-skipped after that change though because the test uses df.head()", "url": "https://github.com/apache/beam/pull/11974#discussion_r461962608", "createdAt": "2020-07-29T00:06:32Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/frames.py", "diffHunk": "@@ -111,19 +164,181 @@ def at(self, *args, **kwargs):\n   def loc(self):\n     return _DeferredLoc(self)\n \n-  def aggregate(self, func, axis=0, *args, **kwargs):\n-    if axis != 0:\n-      raise NotImplementedError()\n+  def aggregate(self, *args, **kwargs):\n+    if 'axis' in kwargs and kwargs['axis'] is None:\n+      return self.agg(*args, **dict(kwargs, axis=1)).agg(\n+          *args, **dict(kwargs, axis=0))\n     return frame_base.DeferredFrame.wrap(\n         expressions.ComputedExpression(\n             'aggregate',\n-            lambda df: df.agg(func, axis, *args, **kwargs),\n+            lambda df: df.agg(*args, **kwargs),\n             [self._expr],\n             # TODO(robertwb): Sub-aggregate when possible.\n             requires_partition_by=partitionings.Singleton()))\n \n   agg = aggregate\n \n+  applymap = frame_base._elementwise_method('applymap')\n+\n+  def memory_usage(self):\n+    raise frame_base.WontImplementError()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b08bf2f46477cf1f960a4fa3b9cb68b21d49498"}, "originalPosition": 92}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b365608fe67d757f283dd59ca2b98c0e0642dc14", "author": {"user": {"login": "robertwb", "name": "Robert Bradshaw"}}, "url": "https://github.com/apache/beam/commit/b365608fe67d757f283dd59ca2b98c0e0642dc14", "committedDate": "2020-07-29T17:16:56Z", "message": "Reviewer comments."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDU3NzEwOTM4", "url": "https://github.com/apache/beam/pull/11974#pullrequestreview-457710938", "createdAt": "2020-07-29T16:54:04Z", "commit": {"oid": "8b08bf2f46477cf1f960a4fa3b9cb68b21d49498"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxNjo1NDowNVrOG5Ba3A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQxNzowMjoxOFrOG5BvBA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQ0NTI3Ng==", "bodyText": "Yes, thanks.", "url": "https://github.com/apache/beam/pull/11974#discussion_r462445276", "createdAt": "2020-07-29T16:54:05Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/frame_base.py", "diffHunk": "@@ -41,16 +42,34 @@ def wrapper(deferred_type):\n \n   @classmethod\n   def wrap(cls, expr):\n-    return cls._pandas_type_map[type(expr.proxy())](expr)\n+    proxy_type = type(expr.proxy())\n+    if proxy_type in cls._pandas_type_map:\n+      wrapper_type = cls._pandas_type_map[proxy_type]\n+    else:\n+      if expr.requires_partition_by() != partitionings.Singleton():\n+        raise ValueError(\n+            'Scalar expression %s partitoned by non-singleton %s' %\n+            (expr, expr.requires_partition_by()))\n+      wrapper_type = _DeferredScaler\n+    return wrapper_type(expr)\n \n   def _elementwise(self, func, name=None, other_args=(), inplace=False):\n     return _elementwise_function(func, name, inplace=inplace)(self, *other_args)\n \n+\n+class DeferredFrame(DeferredBase):\n   @property\n   def dtypes(self):\n     return self._expr.proxy().dtypes\n \n \n+class _DeferredScaler(DeferredBase):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk1Mjc4Nw=="}, "originalCommit": {"oid": "8b08bf2f46477cf1f960a4fa3b9cb68b21d49498"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQ0NjYyMA==", "bodyText": "Yeah. Done.", "url": "https://github.com/apache/beam/pull/11974#discussion_r462446620", "createdAt": "2020-07-29T16:56:09Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/frames.py", "diffHunk": "@@ -111,19 +164,181 @@ def at(self, *args, **kwargs):\n   def loc(self):\n     return _DeferredLoc(self)\n \n-  def aggregate(self, func, axis=0, *args, **kwargs):\n-    if axis != 0:\n-      raise NotImplementedError()\n+  def aggregate(self, *args, **kwargs):\n+    if 'axis' in kwargs and kwargs['axis'] is None:\n+      return self.agg(*args, **dict(kwargs, axis=1)).agg(\n+          *args, **dict(kwargs, axis=0))\n     return frame_base.DeferredFrame.wrap(\n         expressions.ComputedExpression(\n             'aggregate',\n-            lambda df: df.agg(func, axis, *args, **kwargs),\n+            lambda df: df.agg(*args, **kwargs),\n             [self._expr],\n             # TODO(robertwb): Sub-aggregate when possible.\n             requires_partition_by=partitionings.Singleton()))\n \n   agg = aggregate\n \n+  applymap = frame_base._elementwise_method('applymap')\n+\n+  def memory_usage(self):\n+    raise frame_base.WontImplementError()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk2MjYwOA=="}, "originalCommit": {"oid": "8b08bf2f46477cf1f960a4fa3b9cb68b21d49498"}, "originalPosition": 92}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQ0NzQ0NA==", "bodyText": "Fixed several occurrences.", "url": "https://github.com/apache/beam/pull/11974#discussion_r462447444", "createdAt": "2020-07-29T16:57:30Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/frames.py", "diffHunk": "@@ -111,19 +164,181 @@ def at(self, *args, **kwargs):\n   def loc(self):\n     return _DeferredLoc(self)\n \n-  def aggregate(self, func, axis=0, *args, **kwargs):\n-    if axis != 0:\n-      raise NotImplementedError()\n+  def aggregate(self, *args, **kwargs):\n+    if 'axis' in kwargs and kwargs['axis'] is None:\n+      return self.agg(*args, **dict(kwargs, axis=1)).agg(\n+          *args, **dict(kwargs, axis=0))\n     return frame_base.DeferredFrame.wrap(\n         expressions.ComputedExpression(\n             'aggregate',\n-            lambda df: df.agg(func, axis, *args, **kwargs),\n+            lambda df: df.agg(*args, **kwargs),\n             [self._expr],\n             # TODO(robertwb): Sub-aggregate when possible.\n             requires_partition_by=partitionings.Singleton()))\n \n   agg = aggregate\n \n+  applymap = frame_base._elementwise_method('applymap')\n+\n+  def memory_usage(self):\n+    raise frame_base.WontImplementError()\n+\n+  all = frame_base._associative_agg_method('all')\n+  any = frame_base._associative_agg_method('any')\n+\n+  cummax = cummin = cumsum = cumprod = frame_base.wont_implement_method(\n+      'order-sensitive')\n+  diff = frame_base.wont_implement_method('order-sensitive')\n+\n+  max = frame_base._associative_agg_method('max')\n+  min = frame_base._associative_agg_method('min')\n+  mode = frame_base._agg_method('mode')\n+\n+  def dropna(self, axis=0, how='any', thresh=None, subset=None, inplace=False, *args, **kwargs):\n+    # TODO(robertwb): This is a common pattern. Generalize?\n+    if axis == 1:\n+      requires_partition_by = partitionings.Singleton()\n+    else:\n+      requires_partition_by = partitionings.Nothing()\n+    result = frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'dropna',\n+            lambda df: df.dropna(axis, how, thresh, subset, False, *args, **kwargs),\n+            [self._expr],\n+            preserves_partition_by=partitionings.Singleton(),\n+            requires_partition_by=requires_partition_by))\n+    if inplace:\n+      self._expr = result._expr\n+    else:\n+      return result\n+\n+  items = itertuples = iterrows = iteritems = frame_base.wont_implement_method(\n+      'non-lazy')\n+\n+  isna = frame_base._elementwise_method('isna')\n+  notnull = notna = frame_base._elementwise_method('notna')\n+\n+  prod = product = frame_base._associative_agg_method('prod')\n+\n+  def quantile(self, q=0.5, axis=0, *args, **kwargs):\n+    if axis != 0:\n+      raise frame_base.WontImplementError('non-deferred column values')\n+    return frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'quantile',\n+            lambda df: df.quantile(q, axis, *args, **kwargs),\n+            [self._expr],\n+            #TODO(robertwb): Approximate quantiles?\n+            requires_partition_by=partitionings.Singleton(),\n+            preserves_partition_by=partitionings.Singleton()))\n+\n+  query = frame_base._elementwise_method('query')\n+\n+  def replace(self, to_replace=None,\n+      value=None,\n+      inplace=False,\n+      limit=None, *args, **kwargs):\n+    if limit is None:\n+      requires_partition_by = partitionings.Nothing()\n+    else:\n+      requires_partition_by = partitionings.Singleton()\n+    result = frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'replace',\n+            lambda df: df.replace(to_replace, value, False, limit, *args, **kwargs),\n+            [self._expr],\n+            preserves_partition_by=partitionings.Singleton(),\n+            requires_partition_by=requires_partition_by))\n+    if inplace:\n+      self._expr = result._expr\n+    else:\n+      return result\n+\n+  def reset_index(self, level=None, drop=False, inplace=False, *args, **kwargs):\n+    if level is not None and not isinstance(level, (tuple, list)):\n+      level = [level]\n+    if level is None or len(level) == len(self._expr.proxy().index.levels):\n+      # TODO: Could do distributed re-index with offsets.\n+      requires_partition_by = partitionings.Singleton()\n+    else:\n+      requires_partition_by = partitionings.Nothing()\n+    result = frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'reset_index',\n+            lambda df: df.reset_index(level, drop, False, *args, **kwargs),\n+            [self._expr],\n+            preserves_partition_by=partitionings.Singleton(),\n+            requires_partition_by=requires_partition_by))\n+    if inplace:\n+      self._expr = result._expr\n+    else:\n+      return result\n+\n+  round = frame_base._elementwise_method('round')\n+  select_dtypes = frame_base._elementwise_method('select_dtypes')\n+\n+  def shift(self, periods=1, freq=None, axis=0, *args, **kwargs):\n+    if axis == 1:", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk1MTc4Ng=="}, "originalCommit": {"oid": "8b08bf2f46477cf1f960a4fa3b9cb68b21d49498"}, "originalPosition": 189}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQ0Nzg3Mg==", "bodyText": "Yes, I was thinking of using context managers to allow/disallow this. (Future PR.)", "url": "https://github.com/apache/beam/pull/11974#discussion_r462447872", "createdAt": "2020-07-29T16:58:11Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/frames.py", "diffHunk": "@@ -111,19 +164,181 @@ def at(self, *args, **kwargs):\n   def loc(self):\n     return _DeferredLoc(self)\n \n-  def aggregate(self, func, axis=0, *args, **kwargs):\n-    if axis != 0:\n-      raise NotImplementedError()\n+  def aggregate(self, *args, **kwargs):\n+    if 'axis' in kwargs and kwargs['axis'] is None:\n+      return self.agg(*args, **dict(kwargs, axis=1)).agg(\n+          *args, **dict(kwargs, axis=0))\n     return frame_base.DeferredFrame.wrap(\n         expressions.ComputedExpression(\n             'aggregate',\n-            lambda df: df.agg(func, axis, *args, **kwargs),\n+            lambda df: df.agg(*args, **kwargs),\n             [self._expr],\n             # TODO(robertwb): Sub-aggregate when possible.\n             requires_partition_by=partitionings.Singleton()))\n \n   agg = aggregate\n \n+  applymap = frame_base._elementwise_method('applymap')\n+\n+  def memory_usage(self):\n+    raise frame_base.WontImplementError()\n+\n+  all = frame_base._associative_agg_method('all')\n+  any = frame_base._associative_agg_method('any')\n+\n+  cummax = cummin = cumsum = cumprod = frame_base.wont_implement_method(\n+      'order-sensitive')\n+  diff = frame_base.wont_implement_method('order-sensitive')\n+\n+  max = frame_base._associative_agg_method('max')\n+  min = frame_base._associative_agg_method('min')\n+  mode = frame_base._agg_method('mode')\n+\n+  def dropna(self, axis=0, how='any', thresh=None, subset=None, inplace=False, *args, **kwargs):\n+    # TODO(robertwb): This is a common pattern. Generalize?\n+    if axis == 1:\n+      requires_partition_by = partitionings.Singleton()\n+    else:\n+      requires_partition_by = partitionings.Nothing()\n+    result = frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'dropna',\n+            lambda df: df.dropna(axis, how, thresh, subset, False, *args, **kwargs),\n+            [self._expr],\n+            preserves_partition_by=partitionings.Singleton(),\n+            requires_partition_by=requires_partition_by))\n+    if inplace:\n+      self._expr = result._expr\n+    else:\n+      return result\n+\n+  items = itertuples = iterrows = iteritems = frame_base.wont_implement_method(\n+      'non-lazy')\n+\n+  isna = frame_base._elementwise_method('isna')\n+  notnull = notna = frame_base._elementwise_method('notna')\n+\n+  prod = product = frame_base._associative_agg_method('prod')\n+\n+  def quantile(self, q=0.5, axis=0, *args, **kwargs):\n+    if axis != 0:\n+      raise frame_base.WontImplementError('non-deferred column values')\n+    return frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'quantile',\n+            lambda df: df.quantile(q, axis, *args, **kwargs),\n+            [self._expr],\n+            #TODO(robertwb): Approximate quantiles?\n+            requires_partition_by=partitionings.Singleton(),\n+            preserves_partition_by=partitionings.Singleton()))\n+\n+  query = frame_base._elementwise_method('query')\n+\n+  def replace(self, to_replace=None,\n+      value=None,\n+      inplace=False,\n+      limit=None, *args, **kwargs):\n+    if limit is None:\n+      requires_partition_by = partitionings.Nothing()\n+    else:\n+      requires_partition_by = partitionings.Singleton()\n+    result = frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'replace',\n+            lambda df: df.replace(to_replace, value, False, limit, *args, **kwargs),\n+            [self._expr],\n+            preserves_partition_by=partitionings.Singleton(),\n+            requires_partition_by=requires_partition_by))\n+    if inplace:\n+      self._expr = result._expr\n+    else:\n+      return result\n+\n+  def reset_index(self, level=None, drop=False, inplace=False, *args, **kwargs):\n+    if level is not None and not isinstance(level, (tuple, list)):\n+      level = [level]\n+    if level is None or len(level) == len(self._expr.proxy().index.levels):\n+      # TODO: Could do distributed re-index with offsets.\n+      requires_partition_by = partitionings.Singleton()\n+    else:\n+      requires_partition_by = partitionings.Nothing()\n+    result = frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'reset_index',\n+            lambda df: df.reset_index(level, drop, False, *args, **kwargs),\n+            [self._expr],\n+            preserves_partition_by=partitionings.Singleton(),\n+            requires_partition_by=requires_partition_by))\n+    if inplace:\n+      self._expr = result._expr\n+    else:\n+      return result\n+\n+  round = frame_base._elementwise_method('round')\n+  select_dtypes = frame_base._elementwise_method('select_dtypes')\n+\n+  def shift(self, periods=1, freq=None, axis=0, *args, **kwargs):\n+    if axis == 1:\n+      requires_partition_by = partitionings.Nothing()\n+    else:\n+      requires_partition_by = partitionings.Singleton()\n+    return frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'shift',\n+            lambda df: df.shift(periods, freq, axis, *args, **kwargs),\n+            [self._expr],\n+            preserves_partition_by=partitionings.Singleton(),\n+            requires_partition_by=requires_partition_by))\n+\n+  @property\n+  def shape(self):\n+    raise frame_base.WontImplementError('scalar value')\n+\n+  def sort_values(self, by, axis=0, ascending=True, inplace=False, *args, **kwargs):\n+    if axis == 1:\n+      requires_partition_by = partitionings.Nothing()\n+    else:\n+      requires_partition_by = partitionings.Singleton()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk2MDczMQ=="}, "originalCommit": {"oid": "8b08bf2f46477cf1f960a4fa3b9cb68b21d49498"}, "originalPosition": 209}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQ0ODMzMg==", "bodyText": "Agreed. (I added this helper later.)", "url": "https://github.com/apache/beam/pull/11974#discussion_r462448332", "createdAt": "2020-07-29T16:58:58Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/frames.py", "diffHunk": "@@ -111,19 +164,181 @@ def at(self, *args, **kwargs):\n   def loc(self):\n     return _DeferredLoc(self)\n \n-  def aggregate(self, func, axis=0, *args, **kwargs):\n-    if axis != 0:\n-      raise NotImplementedError()\n+  def aggregate(self, *args, **kwargs):\n+    if 'axis' in kwargs and kwargs['axis'] is None:\n+      return self.agg(*args, **dict(kwargs, axis=1)).agg(\n+          *args, **dict(kwargs, axis=0))\n     return frame_base.DeferredFrame.wrap(\n         expressions.ComputedExpression(\n             'aggregate',\n-            lambda df: df.agg(func, axis, *args, **kwargs),\n+            lambda df: df.agg(*args, **kwargs),\n             [self._expr],\n             # TODO(robertwb): Sub-aggregate when possible.\n             requires_partition_by=partitionings.Singleton()))\n \n   agg = aggregate\n \n+  applymap = frame_base._elementwise_method('applymap')\n+\n+  def memory_usage(self):\n+    raise frame_base.WontImplementError()\n+\n+  all = frame_base._associative_agg_method('all')\n+  any = frame_base._associative_agg_method('any')\n+\n+  cummax = cummin = cumsum = cumprod = frame_base.wont_implement_method(\n+      'order-sensitive')\n+  diff = frame_base.wont_implement_method('order-sensitive')\n+\n+  max = frame_base._associative_agg_method('max')\n+  min = frame_base._associative_agg_method('min')\n+  mode = frame_base._agg_method('mode')\n+\n+  def dropna(self, axis=0, how='any', thresh=None, subset=None, inplace=False, *args, **kwargs):\n+    # TODO(robertwb): This is a common pattern. Generalize?\n+    if axis == 1:\n+      requires_partition_by = partitionings.Singleton()\n+    else:\n+      requires_partition_by = partitionings.Nothing()\n+    result = frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'dropna',\n+            lambda df: df.dropna(axis, how, thresh, subset, False, *args, **kwargs),\n+            [self._expr],\n+            preserves_partition_by=partitionings.Singleton(),\n+            requires_partition_by=requires_partition_by))\n+    if inplace:\n+      self._expr = result._expr\n+    else:\n+      return result\n+\n+  items = itertuples = iterrows = iteritems = frame_base.wont_implement_method(\n+      'non-lazy')\n+\n+  isna = frame_base._elementwise_method('isna')\n+  notnull = notna = frame_base._elementwise_method('notna')\n+\n+  prod = product = frame_base._associative_agg_method('prod')\n+\n+  def quantile(self, q=0.5, axis=0, *args, **kwargs):\n+    if axis != 0:\n+      raise frame_base.WontImplementError('non-deferred column values')\n+    return frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'quantile',\n+            lambda df: df.quantile(q, axis, *args, **kwargs),\n+            [self._expr],\n+            #TODO(robertwb): Approximate quantiles?\n+            requires_partition_by=partitionings.Singleton(),\n+            preserves_partition_by=partitionings.Singleton()))\n+\n+  query = frame_base._elementwise_method('query')\n+\n+  def replace(self, to_replace=None,\n+      value=None,\n+      inplace=False,\n+      limit=None, *args, **kwargs):\n+    if limit is None:\n+      requires_partition_by = partitionings.Nothing()\n+    else:\n+      requires_partition_by = partitionings.Singleton()\n+    result = frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'replace',\n+            lambda df: df.replace(to_replace, value, False, limit, *args, **kwargs),\n+            [self._expr],\n+            preserves_partition_by=partitionings.Singleton(),\n+            requires_partition_by=requires_partition_by))\n+    if inplace:\n+      self._expr = result._expr\n+    else:\n+      return result\n+\n+  def reset_index(self, level=None, drop=False, inplace=False, *args, **kwargs):\n+    if level is not None and not isinstance(level, (tuple, list)):\n+      level = [level]\n+    if level is None or len(level) == len(self._expr.proxy().index.levels):\n+      # TODO: Could do distributed re-index with offsets.\n+      requires_partition_by = partitionings.Singleton()\n+    else:\n+      requires_partition_by = partitionings.Nothing()\n+    result = frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'reset_index',\n+            lambda df: df.reset_index(level, drop, False, *args, **kwargs),\n+            [self._expr],\n+            preserves_partition_by=partitionings.Singleton(),\n+            requires_partition_by=requires_partition_by))\n+    if inplace:\n+      self._expr = result._expr\n+    else:\n+      return result\n+\n+  round = frame_base._elementwise_method('round')\n+  select_dtypes = frame_base._elementwise_method('select_dtypes')\n+\n+  def shift(self, periods=1, freq=None, axis=0, *args, **kwargs):\n+    if axis == 1:\n+      requires_partition_by = partitionings.Nothing()\n+    else:\n+      requires_partition_by = partitionings.Singleton()\n+    return frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'shift',\n+            lambda df: df.shift(periods, freq, axis, *args, **kwargs),\n+            [self._expr],\n+            preserves_partition_by=partitionings.Singleton(),\n+            requires_partition_by=requires_partition_by))\n+\n+  @property\n+  def shape(self):\n+    raise frame_base.WontImplementError('scalar value')\n+\n+  def sort_values(self, by, axis=0, ascending=True, inplace=False, *args, **kwargs):\n+    if axis == 1:\n+      requires_partition_by = partitionings.Nothing()\n+    else:\n+      requires_partition_by = partitionings.Singleton()\n+    result = frame_base.DeferredFrame.wrap(\n+        expressions.ComputedExpression(\n+            'sort_values',\n+            lambda df: df.sort_values(by, axis, ascending, False, *args, **kwargs),\n+            [self._expr],\n+            preserves_partition_by=partitionings.Singleton(),\n+            requires_partition_by=requires_partition_by))\n+    if inplace:\n+      self._expr = result._expr\n+    else:\n+      return result\n+\n+  stack = frame_base._elementwise_method('stack')\n+\n+  sum = frame_base._associative_agg_method('sum')\n+\n+  def to_string(self, *args, **kwargs):\n+    raise frame_base.WontImplementError('non-deferred value')\n+\n+  to_records = to_dict = to_numpy = to_string", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk1NzQzMQ=="}, "originalCommit": {"oid": "8b08bf2f46477cf1f960a4fa3b9cb68b21d49498"}, "originalPosition": 229}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjQ1MDQzNg==", "bodyText": "Good idea. (One unfortunate thing is that each of these actually implements multiple tests, but that just means the declarations might be overly broad.)", "url": "https://github.com/apache/beam/pull/11974#discussion_r462450436", "createdAt": "2020-07-29T17:02:18Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/pandas_doctests_test.py", "diffHunk": "@@ -34,77 +34,54 @@ def test_dataframe_tests(self):\n             'pandas.core.frame.DataFrame.T': ['*'],\n             'pandas.core.frame.DataFrame.agg': ['*'],\n             'pandas.core.frame.DataFrame.aggregate': ['*'],\n-            'pandas.core.frame.DataFrame.all': ['*'],\n-            'pandas.core.frame.DataFrame.any': ['*'],\n             'pandas.core.frame.DataFrame.append': ['*'],\n             'pandas.core.frame.DataFrame.apply': ['*'],\n-            'pandas.core.frame.DataFrame.applymap': ['*'],\n+            'pandas.core.frame.DataFrame.applymap': ['df ** 2'],\n             'pandas.core.frame.DataFrame.assign': ['*'],\n             'pandas.core.frame.DataFrame.axes': ['*'],\n             'pandas.core.frame.DataFrame.combine': ['*'],\n             'pandas.core.frame.DataFrame.combine_first': ['*'],\n             'pandas.core.frame.DataFrame.corr': ['*'],\n             'pandas.core.frame.DataFrame.count': ['*'],\n             'pandas.core.frame.DataFrame.cov': ['*'],\n-            'pandas.core.frame.DataFrame.cummax': ['*'],\n-            'pandas.core.frame.DataFrame.cummin': ['*'],\n-            'pandas.core.frame.DataFrame.cumprod': ['*'],\n-            'pandas.core.frame.DataFrame.cumsum': ['*'],\n-            'pandas.core.frame.DataFrame.diff': ['*'],\n             'pandas.core.frame.DataFrame.dot': ['*'],\n             'pandas.core.frame.DataFrame.drop': ['*'],\n-            'pandas.core.frame.DataFrame.dropna': ['*'],\n             'pandas.core.frame.DataFrame.eval': ['*'],\n             'pandas.core.frame.DataFrame.explode': ['*'],\n             'pandas.core.frame.DataFrame.fillna': ['*'],\n             'pandas.core.frame.DataFrame.info': ['*'],\n             'pandas.core.frame.DataFrame.isin': ['*'],\n-            'pandas.core.frame.DataFrame.isna': ['*'],\n-            'pandas.core.frame.DataFrame.isnull': ['*'],\n-            'pandas.core.frame.DataFrame.items': ['*'],\n-            'pandas.core.frame.DataFrame.iteritems': ['*'],\n-            'pandas.core.frame.DataFrame.iterrows': ['*'],\n-            'pandas.core.frame.DataFrame.itertuples': ['*'],\n+            'pandas.core.frame.DataFrame.iterrows': [\"print(df['int'].dtype)\"],\n             'pandas.core.frame.DataFrame.join': ['*'],\n-            'pandas.core.frame.DataFrame.max': ['*'],\n             'pandas.core.frame.DataFrame.melt': ['*'],\n             'pandas.core.frame.DataFrame.memory_usage': ['*'],\n             'pandas.core.frame.DataFrame.merge': ['*'],\n-            'pandas.core.frame.DataFrame.min': ['*'],\n-            'pandas.core.frame.DataFrame.mode': ['*'],\n+            # Not equal to df.agg('mode', axis='columns', numeric_only=True)\n+            'pandas.core.frame.DataFrame.mode': [\n+                \"df.mode(axis='columns', numeric_only=True)\"\n+            ],\n             'pandas.core.frame.DataFrame.nlargest': ['*'],\n-            'pandas.core.frame.DataFrame.notna': ['*'],\n-            'pandas.core.frame.DataFrame.notnull': ['*'],\n             'pandas.core.frame.DataFrame.nsmallest': ['*'],\n             'pandas.core.frame.DataFrame.nunique': ['*'],\n             'pandas.core.frame.DataFrame.pivot': ['*'],\n             'pandas.core.frame.DataFrame.pivot_table': ['*'],\n-            'pandas.core.frame.DataFrame.prod': ['*'],\n-            'pandas.core.frame.DataFrame.product': ['*'],\n-            'pandas.core.frame.DataFrame.quantile': ['*'],\n             'pandas.core.frame.DataFrame.query': ['*'],\n             'pandas.core.frame.DataFrame.reindex': ['*'],\n             'pandas.core.frame.DataFrame.reindex_axis': ['*'],\n             'pandas.core.frame.DataFrame.rename': ['*'],\n-            'pandas.core.frame.DataFrame.replace': ['*'],\n-            'pandas.core.frame.DataFrame.reset_index': ['*'],\n+            # Raises right exception, but testing framework has matching issues.\n+            'pandas.core.frame.DataFrame.replace': [\n+                \"df.replace({'a string': 'new value', True: False})  # raises\"\n+            ],\n+            # Uses unseeded np.random.\n             'pandas.core.frame.DataFrame.round': ['*'],\n-            'pandas.core.frame.DataFrame.select_dtypes': ['*'],\n             'pandas.core.frame.DataFrame.set_index': ['*'],\n-            'pandas.core.frame.DataFrame.shape': ['*'],\n-            'pandas.core.frame.DataFrame.shift': ['*'],\n-            'pandas.core.frame.DataFrame.sort_values': ['*'],\n-            'pandas.core.frame.DataFrame.stack': ['*'],\n-            'pandas.core.frame.DataFrame.sum': ['*'],\n-            'pandas.core.frame.DataFrame.to_dict': ['*'],\n-            'pandas.core.frame.DataFrame.to_numpy': ['*'],\n+            'pandas.core.frame.DataFrame.transpose': [\n+                'df1_transposed.dtypes', 'df2_transposed.dtypes'\n+            ],\n+            'pandas.core.frame.DataFrame.to_sparse': ['type(df)'],\n+            # Uses df.index", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk0MjY0NQ=="}, "originalCommit": {"oid": "8b08bf2f46477cf1f960a4fa3b9cb68b21d49498"}, "originalPosition": 83}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "de7fa96d05d9c570c36ba94f7122ac3a9a307fe4", "author": {"user": {"login": "robertwb", "name": "Robert Bradshaw"}}, "url": "https://github.com/apache/beam/commit/de7fa96d05d9c570c36ba94f7122ac3a9a307fe4", "committedDate": "2020-07-29T19:10:05Z", "message": "Skip dict-order-sensitive tests on 3.5."}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b0fa1f0440de97ba5c623698ef55eb495ad12603", "author": {"user": {"login": "robertwb", "name": "Robert Bradshaw"}}, "url": "https://github.com/apache/beam/commit/b0fa1f0440de97ba5c623698ef55eb495ad12603", "committedDate": "2020-07-29T18:12:39Z", "message": "Skip dict-order-sensitive tests on 3.5."}, "afterCommit": {"oid": "de7fa96d05d9c570c36ba94f7122ac3a9a307fe4", "author": {"user": {"login": "robertwb", "name": "Robert Bradshaw"}}, "url": "https://github.com/apache/beam/commit/de7fa96d05d9c570c36ba94f7122ac3a9a307fe4", "committedDate": "2020-07-29T19:10:05Z", "message": "Skip dict-order-sensitive tests on 3.5."}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4198, "cost": 1, "resetAt": "2021-10-28T16:48:13Z"}}}