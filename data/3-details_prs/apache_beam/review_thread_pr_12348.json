{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDU1NDYyMzAx", "number": 12348, "reviewThreads": {"totalCount": 24, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQyMToxMjowNFrOES_p-Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQyMjo1MjowN1rOEVMfjA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4MzUyNzYxOnYy", "diffSide": "RIGHT", "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/logicaltypes/DateTime.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQyMToxMjowNFrOG4fD_w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMDoxNToxOFrOG5IgEA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTg4MjM2Nw==", "bodyText": "This should be a constant (make static and use upper-case name like DATETIME_SCHEMA)", "url": "https://github.com/apache/beam/pull/12348#discussion_r461882367", "createdAt": "2020-07-28T21:12:04Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/logicaltypes/DateTime.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.schemas.logicaltypes;\n+\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.values.Row;\n+\n+/**\n+ * A datetime without a time-zone.\n+ *\n+ * <p>It cannot represent an instant on the time-line without additional information such as an\n+ * offset or time-zone.\n+ *\n+ * <p>Its input type is a {@link LocalDateTime}, and base type is a {@link Row} containing Date\n+ * field and Time field. Date field is a Long that represents incrementing count of days where day 0\n+ * is 1970-01-01 (ISO). Time field is a Long that represents a count of time in nanoseconds.\n+ */\n+public class DateTime implements Schema.LogicalType<LocalDateTime, Row> {\n+  private final Schema schema =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU2MTI5Ng==", "bodyText": "Thanks. Done.", "url": "https://github.com/apache/beam/pull/12348#discussion_r462561296", "createdAt": "2020-07-29T20:15:18Z", "author": {"login": "ZijieSong946"}, "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/logicaltypes/DateTime.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.schemas.logicaltypes;\n+\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.values.Row;\n+\n+/**\n+ * A datetime without a time-zone.\n+ *\n+ * <p>It cannot represent an instant on the time-line without additional information such as an\n+ * offset or time-zone.\n+ *\n+ * <p>Its input type is a {@link LocalDateTime}, and base type is a {@link Row} containing Date\n+ * field and Time field. Date field is a Long that represents incrementing count of days where day 0\n+ * is 1970-01-01 (ISO). Time field is a Long that represents a count of time in nanoseconds.\n+ */\n+public class DateTime implements Schema.LogicalType<LocalDateTime, Row> {\n+  private final Schema schema =", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTg4MjM2Nw=="}, "originalCommit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d"}, "originalPosition": 37}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4MzU0MDc0OnYy", "diffSide": "RIGHT", "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/logicaltypes/DateTime.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQyMToxNjowMVrOG4fLzg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMDoxNToyOVrOG5Igcg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTg4NDM2Ng==", "bodyText": "\"Date\" and \"Time\" are also used below. We should make them constants as well.", "url": "https://github.com/apache/beam/pull/12348#discussion_r461884366", "createdAt": "2020-07-28T21:16:01Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/logicaltypes/DateTime.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.schemas.logicaltypes;\n+\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.values.Row;\n+\n+/**\n+ * A datetime without a time-zone.\n+ *\n+ * <p>It cannot represent an instant on the time-line without additional information such as an\n+ * offset or time-zone.\n+ *\n+ * <p>Its input type is a {@link LocalDateTime}, and base type is a {@link Row} containing Date\n+ * field and Time field. Date field is a Long that represents incrementing count of days where day 0\n+ * is 1970-01-01 (ISO). Time field is a Long that represents a count of time in nanoseconds.\n+ */\n+public class DateTime implements Schema.LogicalType<LocalDateTime, Row> {\n+  private final Schema schema =\n+      Schema.builder().addInt64Field(\"Date\").addInt64Field(\"Time\").build();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU2MTM5NA==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/12348#discussion_r462561394", "createdAt": "2020-07-29T20:15:29Z", "author": {"login": "ZijieSong946"}, "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/logicaltypes/DateTime.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.schemas.logicaltypes;\n+\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.values.Row;\n+\n+/**\n+ * A datetime without a time-zone.\n+ *\n+ * <p>It cannot represent an instant on the time-line without additional information such as an\n+ * offset or time-zone.\n+ *\n+ * <p>Its input type is a {@link LocalDateTime}, and base type is a {@link Row} containing Date\n+ * field and Time field. Date field is a Long that represents incrementing count of days where day 0\n+ * is 1970-01-01 (ISO). Time field is a Long that represents a count of time in nanoseconds.\n+ */\n+public class DateTime implements Schema.LogicalType<LocalDateTime, Row> {\n+  private final Schema schema =\n+      Schema.builder().addInt64Field(\"Date\").addInt64Field(\"Time\").build();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTg4NDM2Ng=="}, "originalCommit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d"}, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4MzU0NzIxOnYy", "diffSide": "RIGHT", "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/logicaltypes/DateTime.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQyMToxODowM1rOG4fPsw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMDoxNTo0NFrOG5IhCg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTg4NTM2Mw==", "bodyText": "I would mention these 2 longs are the same as the base types of Date and Time.", "url": "https://github.com/apache/beam/pull/12348#discussion_r461885363", "createdAt": "2020-07-28T21:18:03Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/logicaltypes/DateTime.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.schemas.logicaltypes;\n+\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.values.Row;\n+\n+/**\n+ * A datetime without a time-zone.\n+ *\n+ * <p>It cannot represent an instant on the time-line without additional information such as an\n+ * offset or time-zone.\n+ *\n+ * <p>Its input type is a {@link LocalDateTime}, and base type is a {@link Row} containing Date\n+ * field and Time field. Date field is a Long that represents incrementing count of days where day 0\n+ * is 1970-01-01 (ISO). Time field is a Long that represents a count of time in nanoseconds.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU2MTU0Ng==", "bodyText": "Make sense. Done.", "url": "https://github.com/apache/beam/pull/12348#discussion_r462561546", "createdAt": "2020-07-29T20:15:44Z", "author": {"login": "ZijieSong946"}, "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/logicaltypes/DateTime.java", "diffHunk": "@@ -0,0 +1,79 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.schemas.logicaltypes;\n+\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.values.Row;\n+\n+/**\n+ * A datetime without a time-zone.\n+ *\n+ * <p>It cannot represent an instant on the time-line without additional information such as an\n+ * offset or time-zone.\n+ *\n+ * <p>Its input type is a {@link LocalDateTime}, and base type is a {@link Row} containing Date\n+ * field and Time field. Date field is a Long that represents incrementing count of days where day 0\n+ * is 1970-01-01 (ISO). Time field is a Long that represents a count of time in nanoseconds.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTg4NTM2Mw=="}, "originalCommit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d"}, "originalPosition": 34}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4MzgxOTcyOnYy", "diffSide": "RIGHT", "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/logicaltypes/SqlTypes.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQyMjoyMjoxMlrOG4hyAA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMDoxNTo1NlrOG5IhgQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTkyNjkxMg==", "bodyText": "CalciteSQL does not have a DATETIME type. I think we don't need to mention CalciteSQL here.", "url": "https://github.com/apache/beam/pull/12348#discussion_r461926912", "createdAt": "2020-07-28T22:22:12Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/logicaltypes/SqlTypes.java", "diffHunk": "@@ -31,4 +33,7 @@ private SqlTypes() {}\n \n   /** Beam LogicalType corresponding to ZetaSQL/CalciteSQL TIME type. */\n   public static final LogicalType<LocalTime, Long> TIME = new Time();\n+\n+  /** Beam LogicalType corresponding to ZetaSQL/CalciteSQL DATETIME type. */", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU2MTY2NQ==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/12348#discussion_r462561665", "createdAt": "2020-07-29T20:15:56Z", "author": {"login": "ZijieSong946"}, "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/logicaltypes/SqlTypes.java", "diffHunk": "@@ -31,4 +33,7 @@ private SqlTypes() {}\n \n   /** Beam LogicalType corresponding to ZetaSQL/CalciteSQL TIME type. */\n   public static final LogicalType<LocalTime, Long> TIME = new Time();\n+\n+  /** Beam LogicalType corresponding to ZetaSQL/CalciteSQL DATETIME type. */", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTkyNjkxMg=="}, "originalCommit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d"}, "originalPosition": 16}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4Mzg0MTUzOnYy", "diffSide": "RIGHT", "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/SupportedZetaSqlBuiltinFunctions.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQyMjozMTowNVrOG4h_FQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMDoxNjoxNlrOG5IiSg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTkzMDI2MQ==", "bodyText": "Could you implement the support for this and add a test as well?", "url": "https://github.com/apache/beam/pull/12348#discussion_r461930261", "createdAt": "2020-07-28T22:31:05Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/SupportedZetaSqlBuiltinFunctions.java", "diffHunk": "@@ -258,23 +257,23 @@\n \n           // Signatures specific to extracting the DATE date part from a DATETIME or a\n           // TIMESTAMP.\n-          // FunctionSignatureId.FN_EXTRACT_DATE_FROM_DATETIME, // $extract_date\n+          FunctionSignatureId.FN_EXTRACT_DATE_FROM_DATETIME, // $extract_date\n           FunctionSignatureId.FN_EXTRACT_DATE_FROM_TIMESTAMP, // $extract_date\n \n           // Signatures specific to extracting the TIME date part from a DATETIME or a\n           // TIMESTAMP.\n-          // FunctionSignatureId.FN_EXTRACT_TIME_FROM_DATETIME, // $extract_time\n+          FunctionSignatureId.FN_EXTRACT_TIME_FROM_DATETIME, // $extract_time\n           FunctionSignatureId.FN_EXTRACT_TIME_FROM_TIMESTAMP, // $extract_time\n \n           // Signature specific to extracting the DATETIME date part from a TIMESTAMP.\n           // FunctionSignatureId.FN_EXTRACT_DATETIME_FROM_TIMESTAMP, // $extract_datetime", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU2MTg2Ng==", "bodyText": "Test cases added and passed.", "url": "https://github.com/apache/beam/pull/12348#discussion_r462561866", "createdAt": "2020-07-29T20:16:16Z", "author": {"login": "ZijieSong946"}, "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/SupportedZetaSqlBuiltinFunctions.java", "diffHunk": "@@ -258,23 +257,23 @@\n \n           // Signatures specific to extracting the DATE date part from a DATETIME or a\n           // TIMESTAMP.\n-          // FunctionSignatureId.FN_EXTRACT_DATE_FROM_DATETIME, // $extract_date\n+          FunctionSignatureId.FN_EXTRACT_DATE_FROM_DATETIME, // $extract_date\n           FunctionSignatureId.FN_EXTRACT_DATE_FROM_TIMESTAMP, // $extract_date\n \n           // Signatures specific to extracting the TIME date part from a DATETIME or a\n           // TIMESTAMP.\n-          // FunctionSignatureId.FN_EXTRACT_TIME_FROM_DATETIME, // $extract_time\n+          FunctionSignatureId.FN_EXTRACT_TIME_FROM_DATETIME, // $extract_time\n           FunctionSignatureId.FN_EXTRACT_TIME_FROM_TIMESTAMP, // $extract_time\n \n           // Signature specific to extracting the DATETIME date part from a TIMESTAMP.\n           // FunctionSignatureId.FN_EXTRACT_DATETIME_FROM_TIMESTAMP, // $extract_datetime", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTkzMDI2MQ=="}, "originalCommit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d"}, "originalPosition": 71}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4Mzg5NTQ3OnYy", "diffSide": "RIGHT", "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/ZetaSqlBeamTranslationUtils.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQyMjo1Mjo0NFrOG4ifIQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQyMDo0NDoxNFrOG7w03w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTkzODQ2NQ==", "bodyText": "Internally we have a Value.createDatetimeValue() method that takes a Java LocalDateTime. I think that is what we want here. But we don't have it now because it has not been open-sourced to ZetaSQL.\n(This is not a comment, but a note to ourselves.)", "url": "https://github.com/apache/beam/pull/12348#discussion_r461938465", "createdAt": "2020-07-28T22:52:44Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/ZetaSqlBeamTranslationUtils.java", "diffHunk": "@@ -184,6 +188,19 @@ private static Value beamLogicalObjectToZetaSqlValue(Object object, String ident\n       } else { // input type\n         return Value.createTimeValue(CivilTimeEncoder.encodePacked64TimeNanos((LocalTime) object));\n       }\n+    } else if (SqlTypes.DATETIME.getIdentifier().equals(identifier)) {\n+      // DateTime value\n+      LocalDateTime datetime;\n+      if (object instanceof Row) { // base type\n+        datetime =\n+            LocalDateTime.of(\n+                LocalDate.ofEpochDay(((Row) object).getValue(\"Date\")),\n+                LocalTime.ofNanoOfDay(((Row) object).getValue(\"Time\")));\n+      } else { // input type\n+        datetime = (LocalDateTime) object;\n+      }\n+      return Value.createDatetimeValue(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU2NDQ3NQ==", "bodyText": "Yes. It would be far more convenient to have a method creating a ZetaSQL DateTime value directly based on Java LocalDateTime object. Currently we have to extract bitFieldDatetimeSeconds and nanos from LocalDateTime object first.", "url": "https://github.com/apache/beam/pull/12348#discussion_r462564475", "createdAt": "2020-07-29T20:21:06Z", "author": {"login": "ZijieSong946"}, "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/ZetaSqlBeamTranslationUtils.java", "diffHunk": "@@ -184,6 +188,19 @@ private static Value beamLogicalObjectToZetaSqlValue(Object object, String ident\n       } else { // input type\n         return Value.createTimeValue(CivilTimeEncoder.encodePacked64TimeNanos((LocalTime) object));\n       }\n+    } else if (SqlTypes.DATETIME.getIdentifier().equals(identifier)) {\n+      // DateTime value\n+      LocalDateTime datetime;\n+      if (object instanceof Row) { // base type\n+        datetime =\n+            LocalDateTime.of(\n+                LocalDate.ofEpochDay(((Row) object).getValue(\"Date\")),\n+                LocalTime.ofNanoOfDay(((Row) object).getValue(\"Time\")));\n+      } else { // input type\n+        datetime = (LocalDateTime) object;\n+      }\n+      return Value.createDatetimeValue(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTkzODQ2NQ=="}, "originalCommit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzI4NjQyNw==", "bodyText": "I created a JIRA for this: https://issues.apache.org/jira/browse/BEAM-10611\nPlease add a TODO here such that we can make improvement on this in the future.", "url": "https://github.com/apache/beam/pull/12348#discussion_r463286427", "createdAt": "2020-07-30T21:38:54Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/ZetaSqlBeamTranslationUtils.java", "diffHunk": "@@ -184,6 +188,19 @@ private static Value beamLogicalObjectToZetaSqlValue(Object object, String ident\n       } else { // input type\n         return Value.createTimeValue(CivilTimeEncoder.encodePacked64TimeNanos((LocalTime) object));\n       }\n+    } else if (SqlTypes.DATETIME.getIdentifier().equals(identifier)) {\n+      // DateTime value\n+      LocalDateTime datetime;\n+      if (object instanceof Row) { // base type\n+        datetime =\n+            LocalDateTime.of(\n+                LocalDate.ofEpochDay(((Row) object).getValue(\"Date\")),\n+                LocalTime.ofNanoOfDay(((Row) object).getValue(\"Time\")));\n+      } else { // input type\n+        datetime = (LocalDateTime) object;\n+      }\n+      return Value.createDatetimeValue(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTkzODQ2NQ=="}, "originalCommit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MzM3NTA2NA==", "bodyText": "Ack.", "url": "https://github.com/apache/beam/pull/12348#discussion_r463375064", "createdAt": "2020-07-31T02:36:42Z", "author": {"login": "ZijieSong946"}, "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/ZetaSqlBeamTranslationUtils.java", "diffHunk": "@@ -184,6 +188,19 @@ private static Value beamLogicalObjectToZetaSqlValue(Object object, String ident\n       } else { // input type\n         return Value.createTimeValue(CivilTimeEncoder.encodePacked64TimeNanos((LocalTime) object));\n       }\n+    } else if (SqlTypes.DATETIME.getIdentifier().equals(identifier)) {\n+      // DateTime value\n+      LocalDateTime datetime;\n+      if (object instanceof Row) { // base type\n+        datetime =\n+            LocalDateTime.of(\n+                LocalDate.ofEpochDay(((Row) object).getValue(\"Date\")),\n+                LocalTime.ofNanoOfDay(((Row) object).getValue(\"Time\")));\n+      } else { // input type\n+        datetime = (LocalDateTime) object;\n+      }\n+      return Value.createDatetimeValue(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTkzODQ2NQ=="}, "originalCommit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTMxOTEzNQ==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/12348#discussion_r465319135", "createdAt": "2020-08-04T20:44:14Z", "author": {"login": "ZijieSong946"}, "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/ZetaSqlBeamTranslationUtils.java", "diffHunk": "@@ -184,6 +188,19 @@ private static Value beamLogicalObjectToZetaSqlValue(Object object, String ident\n       } else { // input type\n         return Value.createTimeValue(CivilTimeEncoder.encodePacked64TimeNanos((LocalTime) object));\n       }\n+    } else if (SqlTypes.DATETIME.getIdentifier().equals(identifier)) {\n+      // DateTime value\n+      LocalDateTime datetime;\n+      if (object instanceof Row) { // base type\n+        datetime =\n+            LocalDateTime.of(\n+                LocalDate.ofEpochDay(((Row) object).getValue(\"Date\")),\n+                LocalTime.ofNanoOfDay(((Row) object).getValue(\"Time\")));\n+      } else { // input type\n+        datetime = (LocalDateTime) object;\n+      }\n+      return Value.createDatetimeValue(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTkzODQ2NQ=="}, "originalCommit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4MzkxNDQ3OnYy", "diffSide": "RIGHT", "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/translation/ExpressionConverter.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQyMzowMTowMVrOG4iqsw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMDoyMToyMFrOG5ItDg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk0MTQyNw==", "bodyText": "You don't need to create a list here. I think there is another overload of this function that takes a single operand.", "url": "https://github.com/apache/beam/pull/12348#discussion_r461941427", "createdAt": "2020-07-28T23:01:01Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/translation/ExpressionConverter.java", "diffHunk": "@@ -850,6 +852,38 @@ private RexNode convertSimpleValueToRexNode(TypeKind kind, Value value) {\n         // TODO: Doing micro to mills truncation, need to throw exception.\n         ret = rexBuilder().makeLiteral(convertTimeValueToTimeString(value), timeType, false);\n         break;\n+      case TYPE_DATETIME:\n+        // Cannot simply call makeTimestampWithLocalTimeZoneLiteral() for ZetaSQL DATETIME type\n+        // because later it will be unparsed to the string representation of timestamp (e.g. \"SELECT\n+        // DATETIME '2008-12-25 15:30:00'\" will be unparsed to \"SELECT TIMESTAMP '2008-12-25\n+        // 15:30:00:000000'\"). So we create a wrapper function here such that we can later recognize\n+        // it and customize its unparsing in BeamBigQuerySqlDialect.\n+        LocalDateTime dateTime =\n+            CivilTimeEncoder.decodePacked96DatetimeNanosAsJavaTime(value.getDatetimeValue());\n+        TimestampString tsString =\n+            new TimestampString(\n+                    dateTime.getYear(),\n+                    dateTime.getMonthValue(),\n+                    dateTime.getDayOfMonth(),\n+                    dateTime.getHour(),\n+                    dateTime.getMinute(),\n+                    dateTime.getSecond())\n+                .withNanos(dateTime.getNano());\n+\n+        ret =\n+            rexBuilder()\n+                .makeCall(\n+                    SqlOperators.createZetaSqlFunction(\n+                        BeamBigQuerySqlDialect.DATETIME_LITERAL_FUNCTION,\n+                        ZetaSqlCalciteTranslationUtils.toCalciteTypeName(kind)),\n+                    ImmutableList.of(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU2NDYyMg==", "bodyText": "Got it. Done.", "url": "https://github.com/apache/beam/pull/12348#discussion_r462564622", "createdAt": "2020-07-29T20:21:20Z", "author": {"login": "ZijieSong946"}, "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/translation/ExpressionConverter.java", "diffHunk": "@@ -850,6 +852,38 @@ private RexNode convertSimpleValueToRexNode(TypeKind kind, Value value) {\n         // TODO: Doing micro to mills truncation, need to throw exception.\n         ret = rexBuilder().makeLiteral(convertTimeValueToTimeString(value), timeType, false);\n         break;\n+      case TYPE_DATETIME:\n+        // Cannot simply call makeTimestampWithLocalTimeZoneLiteral() for ZetaSQL DATETIME type\n+        // because later it will be unparsed to the string representation of timestamp (e.g. \"SELECT\n+        // DATETIME '2008-12-25 15:30:00'\" will be unparsed to \"SELECT TIMESTAMP '2008-12-25\n+        // 15:30:00:000000'\"). So we create a wrapper function here such that we can later recognize\n+        // it and customize its unparsing in BeamBigQuerySqlDialect.\n+        LocalDateTime dateTime =\n+            CivilTimeEncoder.decodePacked96DatetimeNanosAsJavaTime(value.getDatetimeValue());\n+        TimestampString tsString =\n+            new TimestampString(\n+                    dateTime.getYear(),\n+                    dateTime.getMonthValue(),\n+                    dateTime.getDayOfMonth(),\n+                    dateTime.getHour(),\n+                    dateTime.getMinute(),\n+                    dateTime.getSecond())\n+                .withNanos(dateTime.getNano());\n+\n+        ret =\n+            rexBuilder()\n+                .makeCall(\n+                    SqlOperators.createZetaSqlFunction(\n+                        BeamBigQuerySqlDialect.DATETIME_LITERAL_FUNCTION,\n+                        ZetaSqlCalciteTranslationUtils.toCalciteTypeName(kind)),\n+                    ImmutableList.of(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk0MTQyNw=="}, "originalCommit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d"}, "originalPosition": 62}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4MzkyNjI5OnYy", "diffSide": "RIGHT", "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/translation/ExpressionConverter.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQyMzowNjozNFrOG4ixxw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMDoyMTozN1rOG5IttQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk0MzIzOQ==", "bodyText": "Could you make a convertDateTimeValueToTimeString helper method in DateTimeUtils like we did for Date and Time?", "url": "https://github.com/apache/beam/pull/12348#discussion_r461943239", "createdAt": "2020-07-28T23:06:34Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/translation/ExpressionConverter.java", "diffHunk": "@@ -850,6 +852,38 @@ private RexNode convertSimpleValueToRexNode(TypeKind kind, Value value) {\n         // TODO: Doing micro to mills truncation, need to throw exception.\n         ret = rexBuilder().makeLiteral(convertTimeValueToTimeString(value), timeType, false);\n         break;\n+      case TYPE_DATETIME:\n+        // Cannot simply call makeTimestampWithLocalTimeZoneLiteral() for ZetaSQL DATETIME type\n+        // because later it will be unparsed to the string representation of timestamp (e.g. \"SELECT\n+        // DATETIME '2008-12-25 15:30:00'\" will be unparsed to \"SELECT TIMESTAMP '2008-12-25\n+        // 15:30:00:000000'\"). So we create a wrapper function here such that we can later recognize\n+        // it and customize its unparsing in BeamBigQuerySqlDialect.\n+        LocalDateTime dateTime =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU2NDc4OQ==", "bodyText": "Helper method added.", "url": "https://github.com/apache/beam/pull/12348#discussion_r462564789", "createdAt": "2020-07-29T20:21:37Z", "author": {"login": "ZijieSong946"}, "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/translation/ExpressionConverter.java", "diffHunk": "@@ -850,6 +852,38 @@ private RexNode convertSimpleValueToRexNode(TypeKind kind, Value value) {\n         // TODO: Doing micro to mills truncation, need to throw exception.\n         ret = rexBuilder().makeLiteral(convertTimeValueToTimeString(value), timeType, false);\n         break;\n+      case TYPE_DATETIME:\n+        // Cannot simply call makeTimestampWithLocalTimeZoneLiteral() for ZetaSQL DATETIME type\n+        // because later it will be unparsed to the string representation of timestamp (e.g. \"SELECT\n+        // DATETIME '2008-12-25 15:30:00'\" will be unparsed to \"SELECT TIMESTAMP '2008-12-25\n+        // 15:30:00:000000'\"). So we create a wrapper function here such that we can later recognize\n+        // it and customize its unparsing in BeamBigQuerySqlDialect.\n+        LocalDateTime dateTime =", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk0MzIzOQ=="}, "originalCommit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d"}, "originalPosition": 44}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4Mzk0MDY1OnYy", "diffSide": "RIGHT", "path": "sdks/java/extensions/sql/zetasql/src/test/java/org/apache/beam/sdk/extensions/sql/zetasql/TestInput.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQyMzoxMjo1NFrOG4i6FA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMDoxNjozMFrOG5Ii0A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk0NTM2NA==", "bodyText": "Could you please rename all WTH with WITH by the way? Thanks!", "url": "https://github.com/apache/beam/pull/12348#discussion_r461945364", "createdAt": "2020-07-28T23:12:54Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/zetasql/src/test/java/org/apache/beam/sdk/extensions/sql/zetasql/TestInput.java", "diffHunk": "@@ -260,12 +261,24 @@\n \n   private static final Schema TABLE_WTH_NUMERIC_SCHEMA =\n       Schema.builder().addDecimalField(\"numeric_field\").addStringField(\"str_field\").build();\n+\n   public static final TestBoundedTable TABLE_WITH_NUMERIC =\n       TestBoundedTable.of(TABLE_WTH_NUMERIC_SCHEMA)\n           .addRows(ZetaSqlTypesUtils.bigDecimalAsNumeric(\"123.4567\"), \"str1\")\n           .addRows(ZetaSqlTypesUtils.bigDecimalAsNumeric(\"765.4321\"), \"str2\")\n           .addRows(ZetaSqlTypesUtils.bigDecimalAsNumeric(\"-555.5555\"), \"str3\");\n \n+  private static final Schema TABLE_WTH_DATETIME_SCHEMA =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d"}, "originalPosition": 19}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU2MjAwMA==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/12348#discussion_r462562000", "createdAt": "2020-07-29T20:16:30Z", "author": {"login": "ZijieSong946"}, "path": "sdks/java/extensions/sql/zetasql/src/test/java/org/apache/beam/sdk/extensions/sql/zetasql/TestInput.java", "diffHunk": "@@ -260,12 +261,24 @@\n \n   private static final Schema TABLE_WTH_NUMERIC_SCHEMA =\n       Schema.builder().addDecimalField(\"numeric_field\").addStringField(\"str_field\").build();\n+\n   public static final TestBoundedTable TABLE_WITH_NUMERIC =\n       TestBoundedTable.of(TABLE_WTH_NUMERIC_SCHEMA)\n           .addRows(ZetaSqlTypesUtils.bigDecimalAsNumeric(\"123.4567\"), \"str1\")\n           .addRows(ZetaSqlTypesUtils.bigDecimalAsNumeric(\"765.4321\"), \"str2\")\n           .addRows(ZetaSqlTypesUtils.bigDecimalAsNumeric(\"-555.5555\"), \"str3\");\n \n+  private static final Schema TABLE_WTH_DATETIME_SCHEMA =", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk0NTM2NA=="}, "originalCommit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d"}, "originalPosition": 19}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4Mzk0NDYwOnYy", "diffSide": "RIGHT", "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/bigquery/BeamBigQuerySqlDialect.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQyMzoxNDo0N1rOG4i8eA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMDoyMTo0N1rOG5IuFw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk0NTk3Ng==", "bodyText": "else if to be consistent?", "url": "https://github.com/apache/beam/pull/12348#discussion_r461945976", "createdAt": "2020-07-28T23:14:47Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/bigquery/BeamBigQuerySqlDialect.java", "diffHunk": "@@ -166,6 +168,12 @@ public void unparseCall(\n         break;\n       case OTHER_FUNCTION:\n         String funName = call.getOperator().getName();\n+        if (DATETIME_LITERAL_FUNCTION.equals(funName)) {\n+          // self-designed function dealing with the unparsing of ZetaSQL DATETIME literal, to\n+          // differentiate it from ZetaSQL TIMESTAMP literal\n+          unparseDateTimeLiteralWrapperFunction(writer, call, leftPrec, rightPrec);\n+          break;\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d"}, "originalPosition": 18}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU2NDg4Nw==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/12348#discussion_r462564887", "createdAt": "2020-07-29T20:21:47Z", "author": {"login": "ZijieSong946"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/bigquery/BeamBigQuerySqlDialect.java", "diffHunk": "@@ -166,6 +168,12 @@ public void unparseCall(\n         break;\n       case OTHER_FUNCTION:\n         String funName = call.getOperator().getName();\n+        if (DATETIME_LITERAL_FUNCTION.equals(funName)) {\n+          // self-designed function dealing with the unparsing of ZetaSQL DATETIME literal, to\n+          // differentiate it from ZetaSQL TIMESTAMP literal\n+          unparseDateTimeLiteralWrapperFunction(writer, call, leftPrec, rightPrec);\n+          break;\n+        }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk0NTk3Ng=="}, "originalCommit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d"}, "originalPosition": 18}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4Mzk1MTUyOnYy", "diffSide": "RIGHT", "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/bigquery/BeamBigQuerySqlDialect.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQyMzoxNzo1OVrOG4jAqQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMDoyMjowNFrOG5Iuqw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk0NzA0OQ==", "bodyText": "I would recommend using replace (replace TIMESTAMP with DATETIME) here instead of substring. I think that's more readable.", "url": "https://github.com/apache/beam/pull/12348#discussion_r461947049", "createdAt": "2020-07-28T23:17:59Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/bigquery/BeamBigQuerySqlDialect.java", "diffHunk": "@@ -253,6 +261,12 @@ private void unparseTrim(SqlWriter writer, SqlCall call, int leftPrec, int right\n     writer.endFunCall(trimFrame);\n   }\n \n+  private void unparseDateTimeLiteralWrapperFunction(\n+      SqlWriter writer, SqlCall call, int leftPrec, int rightPrec) {\n+    writer.literal(\"DATETIME\");\n+    writer.literal(call.operand(0).toString().substring(DATETIME_LITERAL_OFFSET));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU2NTAzNQ==", "bodyText": "Make sense. Done.", "url": "https://github.com/apache/beam/pull/12348#discussion_r462565035", "createdAt": "2020-07-29T20:22:04Z", "author": {"login": "ZijieSong946"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/bigquery/BeamBigQuerySqlDialect.java", "diffHunk": "@@ -253,6 +261,12 @@ private void unparseTrim(SqlWriter writer, SqlCall call, int leftPrec, int right\n     writer.endFunCall(trimFrame);\n   }\n \n+  private void unparseDateTimeLiteralWrapperFunction(\n+      SqlWriter writer, SqlCall call, int leftPrec, int rightPrec) {\n+    writer.literal(\"DATETIME\");\n+    writer.literal(call.operand(0).toString().substring(DATETIME_LITERAL_OFFSET));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk0NzA0OQ=="}, "originalCommit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d"}, "originalPosition": 29}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4Mzk1NDQ4OnYy", "diffSide": "RIGHT", "path": "sdks/java/extensions/sql/zetasql/src/test/java/org/apache/beam/sdk/extensions/sql/zetasql/ZetaSqlTimeFunctionsTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQyMzoxOToyNlrOG4jCeg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMDoyMjoxMlrOG5Iu8w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk0NzUxNA==", "bodyText": "Use DATETIME with micro-second component to be more generic (same below)?", "url": "https://github.com/apache/beam/pull/12348#discussion_r461947514", "createdAt": "2020-07-28T23:19:26Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/zetasql/src/test/java/org/apache/beam/sdk/extensions/sql/zetasql/ZetaSqlTimeFunctionsTest.java", "diffHunk": "@@ -218,6 +219,22 @@ public void testDateFromTimestamp() {\n     pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n   }\n \n+  @Test\n+  public void testDateFromDateTime() {\n+    String sql = \"SELECT DATE(DATETIME '2008-12-25 15:30:00')\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d"}, "originalPosition": 26}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU2NTEwNw==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/12348#discussion_r462565107", "createdAt": "2020-07-29T20:22:12Z", "author": {"login": "ZijieSong946"}, "path": "sdks/java/extensions/sql/zetasql/src/test/java/org/apache/beam/sdk/extensions/sql/zetasql/ZetaSqlTimeFunctionsTest.java", "diffHunk": "@@ -218,6 +219,22 @@ public void testDateFromTimestamp() {\n     pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n   }\n \n+  @Test\n+  public void testDateFromDateTime() {\n+    String sql = \"SELECT DATE(DATETIME '2008-12-25 15:30:00')\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk0NzUxNA=="}, "originalCommit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d"}, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4Mzk1ODgxOnYy", "diffSide": "RIGHT", "path": "sdks/java/extensions/sql/zetasql/src/test/java/org/apache/beam/sdk/extensions/sql/zetasql/ZetaSqlTimeFunctionsTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOFQyMzoyMToyM1rOG4jFFQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMDoyMjoxOVrOG5IvLw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk0ODE4MQ==", "bodyText": "Choose time component here to format as well?", "url": "https://github.com/apache/beam/pull/12348#discussion_r461948181", "createdAt": "2020-07-28T23:21:23Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/zetasql/src/test/java/org/apache/beam/sdk/extensions/sql/zetasql/ZetaSqlTimeFunctionsTest.java", "diffHunk": "@@ -753,13 +786,415 @@ public void testParseTime() {\n   /////////////////////////////////////////////////////////////////////////////\n \n   @Test\n-  @Ignore(\"Does not support Datetime literal.\")\n-  public void testDatetimeLiteral() {\n-    String sql = \"SELECT DATETIME '2018-01-01 05:30:00.334'\";\n+  public void testDateTimeLiteral() {\n+    String sql = \"SELECT DATETIME '2008-12-25 15:30:00'\";\n+\n     ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n-    thrown.expect(RuntimeException.class);\n-    thrown.expectMessage(\"Unsupported ResolvedLiteral type: DATETIME\");\n-    zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(\n+                    Schema.builder().addLogicalTypeField(\"f_datetime\", SqlTypes.DATETIME).build())\n+                .addValues(LocalDateTime.of(2008, 12, 25, 15, 30, 0))\n+                .build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testDateTimeColumn() {\n+    String sql = \"SELECT FORMAT_DATETIME('%b-%d-%Y', datetime_field) FROM table_with_datetime\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU2NTE2Nw==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/12348#discussion_r462565167", "createdAt": "2020-07-29T20:22:19Z", "author": {"login": "ZijieSong946"}, "path": "sdks/java/extensions/sql/zetasql/src/test/java/org/apache/beam/sdk/extensions/sql/zetasql/ZetaSqlTimeFunctionsTest.java", "diffHunk": "@@ -753,13 +786,415 @@ public void testParseTime() {\n   /////////////////////////////////////////////////////////////////////////////\n \n   @Test\n-  @Ignore(\"Does not support Datetime literal.\")\n-  public void testDatetimeLiteral() {\n-    String sql = \"SELECT DATETIME '2018-01-01 05:30:00.334'\";\n+  public void testDateTimeLiteral() {\n+    String sql = \"SELECT DATETIME '2008-12-25 15:30:00'\";\n+\n     ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n-    thrown.expect(RuntimeException.class);\n-    thrown.expectMessage(\"Unsupported ResolvedLiteral type: DATETIME\");\n-    zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(\n+                    Schema.builder().addLogicalTypeField(\"f_datetime\", SqlTypes.DATETIME).build())\n+                .addValues(LocalDateTime.of(2008, 12, 25, 15, 30, 0))\n+                .build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testDateTimeColumn() {\n+    String sql = \"SELECT FORMAT_DATETIME('%b-%d-%Y', datetime_field) FROM table_with_datetime\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MTk0ODE4MQ=="}, "originalCommit": {"oid": "2d28bf0299f8a2e920311da06c3c936d311c605d"}, "originalPosition": 94}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4NzkzNTk1OnYy", "diffSide": "LEFT", "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/SupportedZetaSqlBuiltinFunctions.java", "isResolved": true, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMDoyOTowN1rOG5I9cg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMTowNTo0M1rOG5KK0Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU2ODgxOA==", "bodyText": "This empty line is accidentally removed. Could you add it back? Thanks!", "url": "https://github.com/apache/beam/pull/12348#discussion_r462568818", "createdAt": "2020-07-29T20:29:07Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/SupportedZetaSqlBuiltinFunctions.java", "diffHunk": "@@ -258,23 +257,22 @@\n \n           // Signatures specific to extracting the DATE date part from a DATETIME or a\n           // TIMESTAMP.\n-          // FunctionSignatureId.FN_EXTRACT_DATE_FROM_DATETIME, // $extract_date\n+          FunctionSignatureId.FN_EXTRACT_DATE_FROM_DATETIME, // $extract_date\n           FunctionSignatureId.FN_EXTRACT_DATE_FROM_TIMESTAMP, // $extract_date\n \n           // Signatures specific to extracting the TIME date part from a DATETIME or a\n           // TIMESTAMP.\n-          // FunctionSignatureId.FN_EXTRACT_TIME_FROM_DATETIME, // $extract_time\n+          FunctionSignatureId.FN_EXTRACT_TIME_FROM_DATETIME, // $extract_time\n           FunctionSignatureId.FN_EXTRACT_TIME_FROM_TIMESTAMP, // $extract_time\n \n           // Signature specific to extracting the DATETIME date part from a TIMESTAMP.\n-          // FunctionSignatureId.FN_EXTRACT_DATETIME_FROM_TIMESTAMP, // $extract_datetime\n-", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a180cf2573ae9a35fe0c58167cdf5bcb4a33da2d"}, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU3MjI1NQ==", "bodyText": "Added back.", "url": "https://github.com/apache/beam/pull/12348#discussion_r462572255", "createdAt": "2020-07-29T20:35:22Z", "author": {"login": "ZijieSong946"}, "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/SupportedZetaSqlBuiltinFunctions.java", "diffHunk": "@@ -258,23 +257,22 @@\n \n           // Signatures specific to extracting the DATE date part from a DATETIME or a\n           // TIMESTAMP.\n-          // FunctionSignatureId.FN_EXTRACT_DATE_FROM_DATETIME, // $extract_date\n+          FunctionSignatureId.FN_EXTRACT_DATE_FROM_DATETIME, // $extract_date\n           FunctionSignatureId.FN_EXTRACT_DATE_FROM_TIMESTAMP, // $extract_date\n \n           // Signatures specific to extracting the TIME date part from a DATETIME or a\n           // TIMESTAMP.\n-          // FunctionSignatureId.FN_EXTRACT_TIME_FROM_DATETIME, // $extract_time\n+          FunctionSignatureId.FN_EXTRACT_TIME_FROM_DATETIME, // $extract_time\n           FunctionSignatureId.FN_EXTRACT_TIME_FROM_TIMESTAMP, // $extract_time\n \n           // Signature specific to extracting the DATETIME date part from a TIMESTAMP.\n-          // FunctionSignatureId.FN_EXTRACT_DATETIME_FROM_TIMESTAMP, // $extract_datetime\n-", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU2ODgxOA=="}, "originalCommit": {"oid": "a180cf2573ae9a35fe0c58167cdf5bcb4a33da2d"}, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU3MzA5OA==", "bodyText": "But it would fail when running SpotlessCheck and SpotlessApply will automatically delete that line.", "url": "https://github.com/apache/beam/pull/12348#discussion_r462573098", "createdAt": "2020-07-29T20:37:00Z", "author": {"login": "ZijieSong946"}, "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/SupportedZetaSqlBuiltinFunctions.java", "diffHunk": "@@ -258,23 +257,22 @@\n \n           // Signatures specific to extracting the DATE date part from a DATETIME or a\n           // TIMESTAMP.\n-          // FunctionSignatureId.FN_EXTRACT_DATE_FROM_DATETIME, // $extract_date\n+          FunctionSignatureId.FN_EXTRACT_DATE_FROM_DATETIME, // $extract_date\n           FunctionSignatureId.FN_EXTRACT_DATE_FROM_TIMESTAMP, // $extract_date\n \n           // Signatures specific to extracting the TIME date part from a DATETIME or a\n           // TIMESTAMP.\n-          // FunctionSignatureId.FN_EXTRACT_TIME_FROM_DATETIME, // $extract_time\n+          FunctionSignatureId.FN_EXTRACT_TIME_FROM_DATETIME, // $extract_time\n           FunctionSignatureId.FN_EXTRACT_TIME_FROM_TIMESTAMP, // $extract_time\n \n           // Signature specific to extracting the DATETIME date part from a TIMESTAMP.\n-          // FunctionSignatureId.FN_EXTRACT_DATETIME_FROM_TIMESTAMP, // $extract_datetime\n-", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU2ODgxOA=="}, "originalCommit": {"oid": "a180cf2573ae9a35fe0c58167cdf5bcb4a33da2d"}, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU3ODM2Mw==", "bodyText": "Then I think adding a comment line here will help prevent this:\n// Signature for formatting and parsing", "url": "https://github.com/apache/beam/pull/12348#discussion_r462578363", "createdAt": "2020-07-29T20:46:49Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/SupportedZetaSqlBuiltinFunctions.java", "diffHunk": "@@ -258,23 +257,22 @@\n \n           // Signatures specific to extracting the DATE date part from a DATETIME or a\n           // TIMESTAMP.\n-          // FunctionSignatureId.FN_EXTRACT_DATE_FROM_DATETIME, // $extract_date\n+          FunctionSignatureId.FN_EXTRACT_DATE_FROM_DATETIME, // $extract_date\n           FunctionSignatureId.FN_EXTRACT_DATE_FROM_TIMESTAMP, // $extract_date\n \n           // Signatures specific to extracting the TIME date part from a DATETIME or a\n           // TIMESTAMP.\n-          // FunctionSignatureId.FN_EXTRACT_TIME_FROM_DATETIME, // $extract_time\n+          FunctionSignatureId.FN_EXTRACT_TIME_FROM_DATETIME, // $extract_time\n           FunctionSignatureId.FN_EXTRACT_TIME_FROM_TIMESTAMP, // $extract_time\n \n           // Signature specific to extracting the DATETIME date part from a TIMESTAMP.\n-          // FunctionSignatureId.FN_EXTRACT_DATETIME_FROM_TIMESTAMP, // $extract_datetime\n-", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU2ODgxOA=="}, "originalCommit": {"oid": "a180cf2573ae9a35fe0c58167cdf5bcb4a33da2d"}, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU3ODYwNw==", "bodyText": "The empty line above is ok to be removed.", "url": "https://github.com/apache/beam/pull/12348#discussion_r462578607", "createdAt": "2020-07-29T20:47:18Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/SupportedZetaSqlBuiltinFunctions.java", "diffHunk": "@@ -258,23 +257,22 @@\n \n           // Signatures specific to extracting the DATE date part from a DATETIME or a\n           // TIMESTAMP.\n-          // FunctionSignatureId.FN_EXTRACT_DATE_FROM_DATETIME, // $extract_date\n+          FunctionSignatureId.FN_EXTRACT_DATE_FROM_DATETIME, // $extract_date\n           FunctionSignatureId.FN_EXTRACT_DATE_FROM_TIMESTAMP, // $extract_date\n \n           // Signatures specific to extracting the TIME date part from a DATETIME or a\n           // TIMESTAMP.\n-          // FunctionSignatureId.FN_EXTRACT_TIME_FROM_DATETIME, // $extract_time\n+          FunctionSignatureId.FN_EXTRACT_TIME_FROM_DATETIME, // $extract_time\n           FunctionSignatureId.FN_EXTRACT_TIME_FROM_TIMESTAMP, // $extract_time\n \n           // Signature specific to extracting the DATETIME date part from a TIMESTAMP.\n-          // FunctionSignatureId.FN_EXTRACT_DATETIME_FROM_TIMESTAMP, // $extract_datetime\n-", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU2ODgxOA=="}, "originalCommit": {"oid": "a180cf2573ae9a35fe0c58167cdf5bcb4a33da2d"}, "originalPosition": 72}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU4ODYyNQ==", "bodyText": "Good idea. Comments Added.", "url": "https://github.com/apache/beam/pull/12348#discussion_r462588625", "createdAt": "2020-07-29T21:05:43Z", "author": {"login": "ZijieSong946"}, "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/SupportedZetaSqlBuiltinFunctions.java", "diffHunk": "@@ -258,23 +257,22 @@\n \n           // Signatures specific to extracting the DATE date part from a DATETIME or a\n           // TIMESTAMP.\n-          // FunctionSignatureId.FN_EXTRACT_DATE_FROM_DATETIME, // $extract_date\n+          FunctionSignatureId.FN_EXTRACT_DATE_FROM_DATETIME, // $extract_date\n           FunctionSignatureId.FN_EXTRACT_DATE_FROM_TIMESTAMP, // $extract_date\n \n           // Signatures specific to extracting the TIME date part from a DATETIME or a\n           // TIMESTAMP.\n-          // FunctionSignatureId.FN_EXTRACT_TIME_FROM_DATETIME, // $extract_time\n+          FunctionSignatureId.FN_EXTRACT_TIME_FROM_DATETIME, // $extract_time\n           FunctionSignatureId.FN_EXTRACT_TIME_FROM_TIMESTAMP, // $extract_time\n \n           // Signature specific to extracting the DATETIME date part from a TIMESTAMP.\n-          // FunctionSignatureId.FN_EXTRACT_DATETIME_FROM_TIMESTAMP, // $extract_datetime\n-", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU2ODgxOA=="}, "originalCommit": {"oid": "a180cf2573ae9a35fe0c58167cdf5bcb4a33da2d"}, "originalPosition": 72}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4Nzk4MTc1OnYy", "diffSide": "RIGHT", "path": "sdks/java/extensions/sql/zetasql/src/test/java/org/apache/beam/sdk/extensions/sql/zetasql/ZetaSqlTimeFunctionsTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMDo0Mjo0MVrOG5JZ7A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMTowNToxMlrOG5KJmQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU3NjEwOA==", "bodyText": "Could you also add micro-second component here and below?", "url": "https://github.com/apache/beam/pull/12348#discussion_r462576108", "createdAt": "2020-07-29T20:42:41Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/zetasql/src/test/java/org/apache/beam/sdk/extensions/sql/zetasql/ZetaSqlTimeFunctionsTest.java", "diffHunk": "@@ -753,13 +786,416 @@ public void testParseTime() {\n   /////////////////////////////////////////////////////////////////////////////\n \n   @Test\n-  @Ignore(\"Does not support Datetime literal.\")\n-  public void testDatetimeLiteral() {\n-    String sql = \"SELECT DATETIME '2018-01-01 05:30:00.334'\";\n+  public void testDateTimeLiteral() {\n+    String sql = \"SELECT DATETIME '2008-12-25 15:30:00.123456'\";\n+\n     ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n-    thrown.expect(RuntimeException.class);\n-    thrown.expectMessage(\"Unsupported ResolvedLiteral type: DATETIME\");\n-    zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(\n+                    Schema.builder().addLogicalTypeField(\"f_datetime\", SqlTypes.DATETIME).build())\n+                .addValues(LocalDateTime.of(2008, 12, 25, 15, 30, 0).withNano(123456000))\n+                .build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testDateTimeColumn() {\n+    String sql = \"SELECT FORMAT_DATETIME('%D %T', datetime_field) FROM table_with_datetime\";\n+\n+    ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(Schema.builder().addStringField(\"f_datetime_str\").build())\n+                .addValues(\"12/25/08 15:30:00\")\n+                .build(),\n+            Row.withSchema(Schema.builder().addStringField(\"f_datetime_str\").build())\n+                .addValues(\"10/06/12 11:45:00\")\n+                .build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testGroupByDateTime() {\n+    String sql = \"SELECT datetime_field, COUNT(*) FROM table_with_datetime GROUP BY datetime_field\";\n+\n+    ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    final Schema schema =\n+        Schema.builder()\n+            .addLogicalTypeField(\"datetime_field\", SqlTypes.DATETIME)\n+            .addInt64Field(\"count\")\n+            .build();\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(schema).addValues(LocalDateTime.of(2008, 12, 25, 15, 30, 0), 1L).build(),\n+            Row.withSchema(schema).addValues(LocalDateTime.of(2012, 10, 6, 11, 45, 0), 1L).build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testAggregateOnDateTime() {\n+    String sql = \"SELECT MAX(datetime_field) FROM table_with_datetime GROUP BY str_field\";\n+\n+    ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(\n+                    Schema.builder()\n+                        .addLogicalTypeField(\"datetime_field\", SqlTypes.DATETIME)\n+                        .build())\n+                .addValues(LocalDateTime.of(2012, 10, 6, 11, 45, 0))\n+                .build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  // TODO[BEAM-9166]: Add a test for CURRENT_DATETIME function (\"SELECT CURRENT_DATETIME()\")\n+\n+  @Test\n+  public void testExtractFromDateTime() {\n+    String sql =\n+        \"SELECT \"\n+            + \"EXTRACT(YEAR FROM DATETIME '2008-12-25 15:30:00') as year, \"\n+            + \"EXTRACT(QUARTER FROM DATETIME '2008-12-25 15:30:00') as quarter, \"\n+            + \"EXTRACT(MONTH FROM DATETIME '2008-12-25 15:30:00') as month, \"\n+            // TODO[BEAM-9178]: Add tests for DATETIME_TRUNC and EXTRACT with \"week with weekday\"\n+            //  date parts once they are supported\n+            // + \"EXTRACT(WEEK FROM DATETIME '2008-12-25 15:30:00') as week, \"\n+            + \"EXTRACT(DAY FROM DATETIME '2008-12-25 15:30:00') as day, \"\n+            + \"EXTRACT(DAYOFWEEK FROM DATETIME '2008-12-25 15:30:00') as dayofweek, \"\n+            + \"EXTRACT(DAYOFYEAR FROM DATETIME '2008-12-25 15:30:00') as dayofyear, \"\n+            + \"EXTRACT(HOUR FROM DATETIME '2008-12-25 15:30:00.123456') as hour, \"\n+            + \"EXTRACT(MINUTE FROM DATETIME '2008-12-25 15:30:00.123456') as minute, \"\n+            + \"EXTRACT(SECOND FROM DATETIME '2008-12-25 15:30:00.123456') as second, \"\n+            + \"EXTRACT(MILLISECOND FROM DATETIME '2008-12-25 15:30:00.123456') as millisecond, \"\n+            + \"EXTRACT(MICROSECOND FROM DATETIME '2008-12-25 15:30:00.123456') as microsecond, \"\n+            + \"EXTRACT(DATE FROM DATETIME '2008-12-25 15:30:00.123456') as date, \"\n+            + \"EXTRACT(TIME FROM DATETIME '2008-12-25 15:30:00.123456') as time \";\n+\n+    ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    final Schema schema =\n+        Schema.builder()\n+            .addInt64Field(\"year\")\n+            .addInt64Field(\"quarter\")\n+            .addInt64Field(\"month\")\n+            // .addInt64Field(\"week\")\n+            .addInt64Field(\"day\")\n+            .addInt64Field(\"dayofweek\")\n+            .addInt64Field(\"dayofyear\")\n+            .addInt64Field(\"hour\")\n+            .addInt64Field(\"minute\")\n+            .addInt64Field(\"second\")\n+            .addInt64Field(\"millisecond\")\n+            .addInt64Field(\"microsecond\")\n+            .addLogicalTypeField(\"date\", SqlTypes.DATE)\n+            .addLogicalTypeField(\"time\", SqlTypes.TIME)\n+            .build();\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(schema)\n+                .addValues(\n+                    2008L,\n+                    4L,\n+                    12L,\n+                    // 52L,\n+                    25L,\n+                    5L,\n+                    360L,\n+                    15L,\n+                    30L,\n+                    0L,\n+                    123L,\n+                    123456L,\n+                    LocalDate.of(2008, 12, 25),\n+                    LocalTime.of(15, 30, 0, 123456000))\n+                .build());\n+\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testDateTimeFromDateAndTime() {\n+    String sql = \"SELECT DATETIME(DATE '2008-12-25', TIME '15:30:00.123456')\";\n+\n+    ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(\n+                    Schema.builder().addLogicalTypeField(\"f_datetime\", SqlTypes.DATETIME).build())\n+                .addValues(LocalDateTime.of(2008, 12, 25, 15, 30, 0).withNano(123456000))\n+                .build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testDateTimeFromDate() {\n+    String sql = \"SELECT DATETIME(DATE '2008-12-25')\";\n+\n+    ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(\n+                    Schema.builder().addLogicalTypeField(\"f_datetime\", SqlTypes.DATETIME).build())\n+                .addValues(LocalDateTime.of(2008, 12, 25, 0, 0, 0))\n+                .build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testDateTimeFromYearMonthDayHourMinuteSecond() {\n+    String sql = \"SELECT DATETIME(2008, 12, 25, 15, 30, 0)\";\n+\n+    ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(\n+                    Schema.builder().addLogicalTypeField(\"f_datetime\", SqlTypes.DATETIME).build())\n+                .addValues(LocalDateTime.of(2008, 12, 25, 15, 30, 0))\n+                .build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testDateTimeFromTimestamp() {\n+    String sql = \"SELECT DATETIME(TIMESTAMP '2008-12-25 15:30:00+08', 'America/Los_Angeles')\";\n+\n+    ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(\n+                    Schema.builder().addLogicalTypeField(\"f_datetime\", SqlTypes.DATETIME).build())\n+                .addValues(LocalDateTime.of(2008, 12, 24, 23, 30, 0))\n+                .build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testDateTimeAdd() {\n+    String sql =\n+        \"SELECT \"\n+            + \"DATETIME_ADD(DATETIME '2008-12-25 15:30:00', INTERVAL 10 MICROSECOND), \"\n+            + \"DATETIME_ADD(DATETIME '2008-12-25 15:30:00', INTERVAL 10 MILLISECOND), \"\n+            + \"DATETIME_ADD(DATETIME '2008-12-25 15:30:00', INTERVAL 10 SECOND), \"\n+            + \"DATETIME_ADD(DATETIME '2008-12-25 15:30:00', INTERVAL 10 MINUTE), \"\n+            + \"DATETIME_ADD(DATETIME '2008-12-25 15:30:00', INTERVAL 10 HOUR), \"\n+            + \"DATETIME_ADD(DATETIME '2008-12-25 15:30:00', INTERVAL 10 DAY), \"\n+            + \"DATETIME_ADD(DATETIME '2008-12-25 15:30:00', INTERVAL 10 MONTH), \"\n+            + \"DATETIME_ADD(DATETIME '2008-12-25 15:30:00', INTERVAL 10 QUARTER), \"\n+            + \"DATETIME_ADD(DATETIME '2008-12-25 15:30:00', INTERVAL 10 YEAR) \";\n+\n+    ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(\n+                    Schema.builder()\n+                        .addLogicalTypeField(\"f_time1\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time2\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time3\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time4\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time5\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time6\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time7\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time8\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time9\", SqlTypes.DATETIME)\n+                        .build())\n+                .addValues(\n+                    LocalDateTime.of(2008, 12, 25, 15, 30, 0).withNano(10000),\n+                    LocalDateTime.of(2008, 12, 25, 15, 30, 0).withNano(10000000),\n+                    LocalDateTime.of(2008, 12, 25, 15, 30, 10),\n+                    LocalDateTime.of(2008, 12, 25, 15, 40, 0),\n+                    LocalDateTime.of(2008, 12, 26, 1, 30, 0),\n+                    LocalDateTime.of(2009, 1, 4, 15, 30, 0),\n+                    LocalDateTime.of(2009, 10, 25, 15, 30, 0),\n+                    LocalDateTime.of(2011, 6, 25, 15, 30, 0),\n+                    LocalDateTime.of(2018, 12, 25, 15, 30, 0))\n+                .build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testDateTimeAddWithParameter() {\n+    String sql = \"SELECT DATETIME_ADD(@p0, INTERVAL @p1 HOUR)\";\n+\n+    LocalDateTime datetime = LocalDateTime.of(2008, 12, 25, 15, 30, 00).withNano(123456000);\n+    ImmutableMap<String, Value> params =\n+        ImmutableMap.of(\n+            \"p0\",\n+                Value.createDatetimeValue(\n+                    CivilTimeEncoder.encodePacked64DatetimeSeconds(datetime), datetime.getNano()),\n+            \"p1\", Value.createInt64Value(3L));\n+\n+    ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql, params);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(\n+                    Schema.builder().addLogicalTypeField(\"f_datetime\", SqlTypes.DATETIME).build())\n+                .addValues(LocalDateTime.of(2008, 12, 25, 18, 30, 00).withNano(123456000))\n+                .build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testDateTimeSub() {\n+    String sql =\n+        \"SELECT \"\n+            + \"DATETIME_SUB(DATETIME '2008-12-25 15:30:00', INTERVAL 10 MICROSECOND), \"\n+            + \"DATETIME_SUB(DATETIME '2008-12-25 15:30:00', INTERVAL 10 MILLISECOND), \"\n+            + \"DATETIME_SUB(DATETIME '2008-12-25 15:30:00', INTERVAL 10 SECOND), \"\n+            + \"DATETIME_SUB(DATETIME '2008-12-25 15:30:00', INTERVAL 10 MINUTE), \"\n+            + \"DATETIME_SUB(DATETIME '2008-12-25 15:30:00', INTERVAL 10 HOUR), \"\n+            + \"DATETIME_SUB(DATETIME '2008-12-25 15:30:00', INTERVAL 10 DAY), \"\n+            + \"DATETIME_SUB(DATETIME '2008-12-25 15:30:00', INTERVAL 10 MONTH), \"\n+            + \"DATETIME_SUB(DATETIME '2008-12-25 15:30:00', INTERVAL 10 QUARTER), \"\n+            + \"DATETIME_SUB(DATETIME '2008-12-25 15:30:00', INTERVAL 10 YEAR) \";\n+\n+    ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(\n+                    Schema.builder()\n+                        .addLogicalTypeField(\"f_time1\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time2\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time3\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time4\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time5\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time6\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time7\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time8\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time9\", SqlTypes.DATETIME)\n+                        .build())\n+                .addValues(\n+                    LocalDateTime.of(2008, 12, 25, 15, 29, 59).withNano(999990000),\n+                    LocalDateTime.of(2008, 12, 25, 15, 29, 59).withNano(990000000),\n+                    LocalDateTime.of(2008, 12, 25, 15, 29, 50),\n+                    LocalDateTime.of(2008, 12, 25, 15, 20, 0),\n+                    LocalDateTime.of(2008, 12, 25, 5, 30, 0),\n+                    LocalDateTime.of(2008, 12, 15, 15, 30, 0),\n+                    LocalDateTime.of(2008, 2, 25, 15, 30, 0),\n+                    LocalDateTime.of(2006, 6, 25, 15, 30, 0),\n+                    LocalDateTime.of(1998, 12, 25, 15, 30, 0))\n+                .build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testDateTimeDiff() {\n+    String sql =\n+        \"SELECT DATETIME_DIFF(DATETIME '2008-12-25 15:30:00', DATETIME '2008-10-25 15:30:00', DAY)\";\n+\n+    ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(Schema.builder().addInt64Field(\"f_datetime_diff\").build())\n+                .addValues(61L)\n+                .build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testDateTimeDiffNegativeResult() {\n+    String sql =\n+        \"SELECT DATETIME_DIFF(DATETIME '2008-10-25 15:30:00', DATETIME '2008-12-25 15:30:00', DAY)\";\n+\n+    ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(Schema.builder().addInt64Field(\"f_datetime_diff\").build())\n+                .addValues(-61L)\n+                .build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testDateTimeTrunc() {\n+    String sql = \"SELECT DATETIME_TRUNC(DATETIME '2008-12-25 15:30:00', HOUR)\";\n+\n+    ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(\n+                    Schema.builder()\n+                        .addLogicalTypeField(\"f_datetime_trunc\", SqlTypes.DATETIME)\n+                        .build())\n+                .addValues(LocalDateTime.of(2008, 12, 25, 15, 0, 0))\n+                .build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testFormatDateTime() {\n+    String sql = \"SELECT FORMAT_DATETIME('%D %T', DATETIME '2008-12-25 15:30:00')\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f7fcb6bdc71d1ea6335aaab0fb4fbb363ff02e3a"}, "originalPosition": 457}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU4ODMxMw==", "bodyText": "Added.", "url": "https://github.com/apache/beam/pull/12348#discussion_r462588313", "createdAt": "2020-07-29T21:05:12Z", "author": {"login": "ZijieSong946"}, "path": "sdks/java/extensions/sql/zetasql/src/test/java/org/apache/beam/sdk/extensions/sql/zetasql/ZetaSqlTimeFunctionsTest.java", "diffHunk": "@@ -753,13 +786,416 @@ public void testParseTime() {\n   /////////////////////////////////////////////////////////////////////////////\n \n   @Test\n-  @Ignore(\"Does not support Datetime literal.\")\n-  public void testDatetimeLiteral() {\n-    String sql = \"SELECT DATETIME '2018-01-01 05:30:00.334'\";\n+  public void testDateTimeLiteral() {\n+    String sql = \"SELECT DATETIME '2008-12-25 15:30:00.123456'\";\n+\n     ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n-    thrown.expect(RuntimeException.class);\n-    thrown.expectMessage(\"Unsupported ResolvedLiteral type: DATETIME\");\n-    zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(\n+                    Schema.builder().addLogicalTypeField(\"f_datetime\", SqlTypes.DATETIME).build())\n+                .addValues(LocalDateTime.of(2008, 12, 25, 15, 30, 0).withNano(123456000))\n+                .build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testDateTimeColumn() {\n+    String sql = \"SELECT FORMAT_DATETIME('%D %T', datetime_field) FROM table_with_datetime\";\n+\n+    ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(Schema.builder().addStringField(\"f_datetime_str\").build())\n+                .addValues(\"12/25/08 15:30:00\")\n+                .build(),\n+            Row.withSchema(Schema.builder().addStringField(\"f_datetime_str\").build())\n+                .addValues(\"10/06/12 11:45:00\")\n+                .build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testGroupByDateTime() {\n+    String sql = \"SELECT datetime_field, COUNT(*) FROM table_with_datetime GROUP BY datetime_field\";\n+\n+    ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    final Schema schema =\n+        Schema.builder()\n+            .addLogicalTypeField(\"datetime_field\", SqlTypes.DATETIME)\n+            .addInt64Field(\"count\")\n+            .build();\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(schema).addValues(LocalDateTime.of(2008, 12, 25, 15, 30, 0), 1L).build(),\n+            Row.withSchema(schema).addValues(LocalDateTime.of(2012, 10, 6, 11, 45, 0), 1L).build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testAggregateOnDateTime() {\n+    String sql = \"SELECT MAX(datetime_field) FROM table_with_datetime GROUP BY str_field\";\n+\n+    ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(\n+                    Schema.builder()\n+                        .addLogicalTypeField(\"datetime_field\", SqlTypes.DATETIME)\n+                        .build())\n+                .addValues(LocalDateTime.of(2012, 10, 6, 11, 45, 0))\n+                .build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  // TODO[BEAM-9166]: Add a test for CURRENT_DATETIME function (\"SELECT CURRENT_DATETIME()\")\n+\n+  @Test\n+  public void testExtractFromDateTime() {\n+    String sql =\n+        \"SELECT \"\n+            + \"EXTRACT(YEAR FROM DATETIME '2008-12-25 15:30:00') as year, \"\n+            + \"EXTRACT(QUARTER FROM DATETIME '2008-12-25 15:30:00') as quarter, \"\n+            + \"EXTRACT(MONTH FROM DATETIME '2008-12-25 15:30:00') as month, \"\n+            // TODO[BEAM-9178]: Add tests for DATETIME_TRUNC and EXTRACT with \"week with weekday\"\n+            //  date parts once they are supported\n+            // + \"EXTRACT(WEEK FROM DATETIME '2008-12-25 15:30:00') as week, \"\n+            + \"EXTRACT(DAY FROM DATETIME '2008-12-25 15:30:00') as day, \"\n+            + \"EXTRACT(DAYOFWEEK FROM DATETIME '2008-12-25 15:30:00') as dayofweek, \"\n+            + \"EXTRACT(DAYOFYEAR FROM DATETIME '2008-12-25 15:30:00') as dayofyear, \"\n+            + \"EXTRACT(HOUR FROM DATETIME '2008-12-25 15:30:00.123456') as hour, \"\n+            + \"EXTRACT(MINUTE FROM DATETIME '2008-12-25 15:30:00.123456') as minute, \"\n+            + \"EXTRACT(SECOND FROM DATETIME '2008-12-25 15:30:00.123456') as second, \"\n+            + \"EXTRACT(MILLISECOND FROM DATETIME '2008-12-25 15:30:00.123456') as millisecond, \"\n+            + \"EXTRACT(MICROSECOND FROM DATETIME '2008-12-25 15:30:00.123456') as microsecond, \"\n+            + \"EXTRACT(DATE FROM DATETIME '2008-12-25 15:30:00.123456') as date, \"\n+            + \"EXTRACT(TIME FROM DATETIME '2008-12-25 15:30:00.123456') as time \";\n+\n+    ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    final Schema schema =\n+        Schema.builder()\n+            .addInt64Field(\"year\")\n+            .addInt64Field(\"quarter\")\n+            .addInt64Field(\"month\")\n+            // .addInt64Field(\"week\")\n+            .addInt64Field(\"day\")\n+            .addInt64Field(\"dayofweek\")\n+            .addInt64Field(\"dayofyear\")\n+            .addInt64Field(\"hour\")\n+            .addInt64Field(\"minute\")\n+            .addInt64Field(\"second\")\n+            .addInt64Field(\"millisecond\")\n+            .addInt64Field(\"microsecond\")\n+            .addLogicalTypeField(\"date\", SqlTypes.DATE)\n+            .addLogicalTypeField(\"time\", SqlTypes.TIME)\n+            .build();\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(schema)\n+                .addValues(\n+                    2008L,\n+                    4L,\n+                    12L,\n+                    // 52L,\n+                    25L,\n+                    5L,\n+                    360L,\n+                    15L,\n+                    30L,\n+                    0L,\n+                    123L,\n+                    123456L,\n+                    LocalDate.of(2008, 12, 25),\n+                    LocalTime.of(15, 30, 0, 123456000))\n+                .build());\n+\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testDateTimeFromDateAndTime() {\n+    String sql = \"SELECT DATETIME(DATE '2008-12-25', TIME '15:30:00.123456')\";\n+\n+    ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(\n+                    Schema.builder().addLogicalTypeField(\"f_datetime\", SqlTypes.DATETIME).build())\n+                .addValues(LocalDateTime.of(2008, 12, 25, 15, 30, 0).withNano(123456000))\n+                .build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testDateTimeFromDate() {\n+    String sql = \"SELECT DATETIME(DATE '2008-12-25')\";\n+\n+    ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(\n+                    Schema.builder().addLogicalTypeField(\"f_datetime\", SqlTypes.DATETIME).build())\n+                .addValues(LocalDateTime.of(2008, 12, 25, 0, 0, 0))\n+                .build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testDateTimeFromYearMonthDayHourMinuteSecond() {\n+    String sql = \"SELECT DATETIME(2008, 12, 25, 15, 30, 0)\";\n+\n+    ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(\n+                    Schema.builder().addLogicalTypeField(\"f_datetime\", SqlTypes.DATETIME).build())\n+                .addValues(LocalDateTime.of(2008, 12, 25, 15, 30, 0))\n+                .build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testDateTimeFromTimestamp() {\n+    String sql = \"SELECT DATETIME(TIMESTAMP '2008-12-25 15:30:00+08', 'America/Los_Angeles')\";\n+\n+    ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(\n+                    Schema.builder().addLogicalTypeField(\"f_datetime\", SqlTypes.DATETIME).build())\n+                .addValues(LocalDateTime.of(2008, 12, 24, 23, 30, 0))\n+                .build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testDateTimeAdd() {\n+    String sql =\n+        \"SELECT \"\n+            + \"DATETIME_ADD(DATETIME '2008-12-25 15:30:00', INTERVAL 10 MICROSECOND), \"\n+            + \"DATETIME_ADD(DATETIME '2008-12-25 15:30:00', INTERVAL 10 MILLISECOND), \"\n+            + \"DATETIME_ADD(DATETIME '2008-12-25 15:30:00', INTERVAL 10 SECOND), \"\n+            + \"DATETIME_ADD(DATETIME '2008-12-25 15:30:00', INTERVAL 10 MINUTE), \"\n+            + \"DATETIME_ADD(DATETIME '2008-12-25 15:30:00', INTERVAL 10 HOUR), \"\n+            + \"DATETIME_ADD(DATETIME '2008-12-25 15:30:00', INTERVAL 10 DAY), \"\n+            + \"DATETIME_ADD(DATETIME '2008-12-25 15:30:00', INTERVAL 10 MONTH), \"\n+            + \"DATETIME_ADD(DATETIME '2008-12-25 15:30:00', INTERVAL 10 QUARTER), \"\n+            + \"DATETIME_ADD(DATETIME '2008-12-25 15:30:00', INTERVAL 10 YEAR) \";\n+\n+    ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(\n+                    Schema.builder()\n+                        .addLogicalTypeField(\"f_time1\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time2\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time3\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time4\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time5\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time6\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time7\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time8\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time9\", SqlTypes.DATETIME)\n+                        .build())\n+                .addValues(\n+                    LocalDateTime.of(2008, 12, 25, 15, 30, 0).withNano(10000),\n+                    LocalDateTime.of(2008, 12, 25, 15, 30, 0).withNano(10000000),\n+                    LocalDateTime.of(2008, 12, 25, 15, 30, 10),\n+                    LocalDateTime.of(2008, 12, 25, 15, 40, 0),\n+                    LocalDateTime.of(2008, 12, 26, 1, 30, 0),\n+                    LocalDateTime.of(2009, 1, 4, 15, 30, 0),\n+                    LocalDateTime.of(2009, 10, 25, 15, 30, 0),\n+                    LocalDateTime.of(2011, 6, 25, 15, 30, 0),\n+                    LocalDateTime.of(2018, 12, 25, 15, 30, 0))\n+                .build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testDateTimeAddWithParameter() {\n+    String sql = \"SELECT DATETIME_ADD(@p0, INTERVAL @p1 HOUR)\";\n+\n+    LocalDateTime datetime = LocalDateTime.of(2008, 12, 25, 15, 30, 00).withNano(123456000);\n+    ImmutableMap<String, Value> params =\n+        ImmutableMap.of(\n+            \"p0\",\n+                Value.createDatetimeValue(\n+                    CivilTimeEncoder.encodePacked64DatetimeSeconds(datetime), datetime.getNano()),\n+            \"p1\", Value.createInt64Value(3L));\n+\n+    ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql, params);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(\n+                    Schema.builder().addLogicalTypeField(\"f_datetime\", SqlTypes.DATETIME).build())\n+                .addValues(LocalDateTime.of(2008, 12, 25, 18, 30, 00).withNano(123456000))\n+                .build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testDateTimeSub() {\n+    String sql =\n+        \"SELECT \"\n+            + \"DATETIME_SUB(DATETIME '2008-12-25 15:30:00', INTERVAL 10 MICROSECOND), \"\n+            + \"DATETIME_SUB(DATETIME '2008-12-25 15:30:00', INTERVAL 10 MILLISECOND), \"\n+            + \"DATETIME_SUB(DATETIME '2008-12-25 15:30:00', INTERVAL 10 SECOND), \"\n+            + \"DATETIME_SUB(DATETIME '2008-12-25 15:30:00', INTERVAL 10 MINUTE), \"\n+            + \"DATETIME_SUB(DATETIME '2008-12-25 15:30:00', INTERVAL 10 HOUR), \"\n+            + \"DATETIME_SUB(DATETIME '2008-12-25 15:30:00', INTERVAL 10 DAY), \"\n+            + \"DATETIME_SUB(DATETIME '2008-12-25 15:30:00', INTERVAL 10 MONTH), \"\n+            + \"DATETIME_SUB(DATETIME '2008-12-25 15:30:00', INTERVAL 10 QUARTER), \"\n+            + \"DATETIME_SUB(DATETIME '2008-12-25 15:30:00', INTERVAL 10 YEAR) \";\n+\n+    ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(\n+                    Schema.builder()\n+                        .addLogicalTypeField(\"f_time1\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time2\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time3\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time4\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time5\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time6\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time7\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time8\", SqlTypes.DATETIME)\n+                        .addLogicalTypeField(\"f_time9\", SqlTypes.DATETIME)\n+                        .build())\n+                .addValues(\n+                    LocalDateTime.of(2008, 12, 25, 15, 29, 59).withNano(999990000),\n+                    LocalDateTime.of(2008, 12, 25, 15, 29, 59).withNano(990000000),\n+                    LocalDateTime.of(2008, 12, 25, 15, 29, 50),\n+                    LocalDateTime.of(2008, 12, 25, 15, 20, 0),\n+                    LocalDateTime.of(2008, 12, 25, 5, 30, 0),\n+                    LocalDateTime.of(2008, 12, 15, 15, 30, 0),\n+                    LocalDateTime.of(2008, 2, 25, 15, 30, 0),\n+                    LocalDateTime.of(2006, 6, 25, 15, 30, 0),\n+                    LocalDateTime.of(1998, 12, 25, 15, 30, 0))\n+                .build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testDateTimeDiff() {\n+    String sql =\n+        \"SELECT DATETIME_DIFF(DATETIME '2008-12-25 15:30:00', DATETIME '2008-10-25 15:30:00', DAY)\";\n+\n+    ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(Schema.builder().addInt64Field(\"f_datetime_diff\").build())\n+                .addValues(61L)\n+                .build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testDateTimeDiffNegativeResult() {\n+    String sql =\n+        \"SELECT DATETIME_DIFF(DATETIME '2008-10-25 15:30:00', DATETIME '2008-12-25 15:30:00', DAY)\";\n+\n+    ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(Schema.builder().addInt64Field(\"f_datetime_diff\").build())\n+                .addValues(-61L)\n+                .build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testDateTimeTrunc() {\n+    String sql = \"SELECT DATETIME_TRUNC(DATETIME '2008-12-25 15:30:00', HOUR)\";\n+\n+    ZetaSQLQueryPlanner zetaSQLQueryPlanner = new ZetaSQLQueryPlanner(config);\n+    BeamRelNode beamRelNode = zetaSQLQueryPlanner.convertToBeamRel(sql);\n+    PCollection<Row> stream = BeamSqlRelUtils.toPCollection(pipeline, beamRelNode);\n+\n+    PAssert.that(stream)\n+        .containsInAnyOrder(\n+            Row.withSchema(\n+                    Schema.builder()\n+                        .addLogicalTypeField(\"f_datetime_trunc\", SqlTypes.DATETIME)\n+                        .build())\n+                .addValues(LocalDateTime.of(2008, 12, 25, 15, 0, 0))\n+                .build());\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(PIPELINE_EXECUTION_WAITTIME_MINUTES));\n+  }\n+\n+  @Test\n+  public void testFormatDateTime() {\n+    String sql = \"SELECT FORMAT_DATETIME('%D %T', DATETIME '2008-12-25 15:30:00')\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU3NjEwOA=="}, "originalCommit": {"oid": "f7fcb6bdc71d1ea6335aaab0fb4fbb363ff02e3a"}, "originalPosition": 457}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg4Nzk4NDgxOnYy", "diffSide": "RIGHT", "path": "sdks/java/extensions/sql/zetasql/src/test/java/org/apache/beam/sdk/extensions/sql/zetasql/TestInput.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMDo0MzozMVrOG5JbwA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yOVQyMTowNToyMFrOG5KKCA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU3NjU3Ng==", "bodyText": "I would add micro-second components for column as well.", "url": "https://github.com/apache/beam/pull/12348#discussion_r462576576", "createdAt": "2020-07-29T20:43:31Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/zetasql/src/test/java/org/apache/beam/sdk/extensions/sql/zetasql/TestInput.java", "diffHunk": "@@ -225,47 +226,59 @@\n   public static final TestBoundedTable TABLE_EMPTY =\n       TestBoundedTable.of(Schema.builder().addInt64Field(\"ColId\").addStringField(\"Value\").build());\n \n-  private static final Schema TABLE_WTH_MAP_SCHEMA =\n+  private static final Schema TABLE_WITH_MAP_SCHEMA =\n       Schema.builder()\n           .addMapField(\"map_field\", FieldType.STRING, FieldType.STRING)\n           .addRowField(\"row_field\", structSchema)\n           .build();\n   public static final TestBoundedTable TABLE_WITH_MAP =\n-      TestBoundedTable.of(TABLE_WTH_MAP_SCHEMA)\n+      TestBoundedTable.of(TABLE_WITH_MAP_SCHEMA)\n           .addRows(\n               ImmutableMap.of(\"MAP_KEY_1\", \"MAP_VALUE_1\"),\n               Row.withSchema(structSchema).addValues(1L, \"data1\").build());\n \n-  private static final Schema TABLE_WTH_DATE_SCHEMA =\n+  private static final Schema TABLE_WITH_DATE_SCHEMA =\n       Schema.builder()\n           .addLogicalTypeField(\"date_field\", SqlTypes.DATE)\n           .addStringField(\"str_field\")\n           .build();\n \n   public static final TestBoundedTable TABLE_WITH_DATE =\n-      TestBoundedTable.of(TABLE_WTH_DATE_SCHEMA)\n+      TestBoundedTable.of(TABLE_WITH_DATE_SCHEMA)\n           .addRows(LocalDate.of(2008, 12, 25), \"s\")\n           .addRows(LocalDate.of(2020, 4, 7), \"s\");\n \n-  private static final Schema TABLE_WTH_TIME_SCHEMA =\n+  private static final Schema TABLE_WITH_TIME_SCHEMA =\n       Schema.builder()\n           .addLogicalTypeField(\"time_field\", SqlTypes.TIME)\n           .addStringField(\"str_field\")\n           .build();\n \n   public static final TestBoundedTable TABLE_WITH_TIME =\n-      TestBoundedTable.of(TABLE_WTH_TIME_SCHEMA)\n+      TestBoundedTable.of(TABLE_WITH_TIME_SCHEMA)\n           .addRows(LocalTime.of(15, 30, 0), \"s\")\n           .addRows(LocalTime.of(23, 35, 59), \"s\");\n \n-  private static final Schema TABLE_WTH_NUMERIC_SCHEMA =\n+  private static final Schema TABLE_WITH_NUMERIC_SCHEMA =\n       Schema.builder().addDecimalField(\"numeric_field\").addStringField(\"str_field\").build();\n+\n   public static final TestBoundedTable TABLE_WITH_NUMERIC =\n-      TestBoundedTable.of(TABLE_WTH_NUMERIC_SCHEMA)\n+      TestBoundedTable.of(TABLE_WITH_NUMERIC_SCHEMA)\n           .addRows(ZetaSqlTypesUtils.bigDecimalAsNumeric(\"123.4567\"), \"str1\")\n           .addRows(ZetaSqlTypesUtils.bigDecimalAsNumeric(\"765.4321\"), \"str2\")\n           .addRows(ZetaSqlTypesUtils.bigDecimalAsNumeric(\"-555.5555\"), \"str3\");\n \n+  private static final Schema TABLE_WITH_DATETIME_SCHEMA =\n+      Schema.builder()\n+          .addLogicalTypeField(\"datetime_field\", SqlTypes.DATETIME)\n+          .addStringField(\"str_field\")\n+          .build();\n+\n+  public static final TestBoundedTable TABLE_WITH_DATETIME =\n+      TestBoundedTable.of(TABLE_WITH_DATETIME_SCHEMA)\n+          .addRows(LocalDateTime.of(2008, 12, 25, 15, 30, 0), \"s\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "db928fd8ea88d09d0d0457efd253b56072da9672"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU4ODQyNA==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/12348#discussion_r462588424", "createdAt": "2020-07-29T21:05:20Z", "author": {"login": "ZijieSong946"}, "path": "sdks/java/extensions/sql/zetasql/src/test/java/org/apache/beam/sdk/extensions/sql/zetasql/TestInput.java", "diffHunk": "@@ -225,47 +226,59 @@\n   public static final TestBoundedTable TABLE_EMPTY =\n       TestBoundedTable.of(Schema.builder().addInt64Field(\"ColId\").addStringField(\"Value\").build());\n \n-  private static final Schema TABLE_WTH_MAP_SCHEMA =\n+  private static final Schema TABLE_WITH_MAP_SCHEMA =\n       Schema.builder()\n           .addMapField(\"map_field\", FieldType.STRING, FieldType.STRING)\n           .addRowField(\"row_field\", structSchema)\n           .build();\n   public static final TestBoundedTable TABLE_WITH_MAP =\n-      TestBoundedTable.of(TABLE_WTH_MAP_SCHEMA)\n+      TestBoundedTable.of(TABLE_WITH_MAP_SCHEMA)\n           .addRows(\n               ImmutableMap.of(\"MAP_KEY_1\", \"MAP_VALUE_1\"),\n               Row.withSchema(structSchema).addValues(1L, \"data1\").build());\n \n-  private static final Schema TABLE_WTH_DATE_SCHEMA =\n+  private static final Schema TABLE_WITH_DATE_SCHEMA =\n       Schema.builder()\n           .addLogicalTypeField(\"date_field\", SqlTypes.DATE)\n           .addStringField(\"str_field\")\n           .build();\n \n   public static final TestBoundedTable TABLE_WITH_DATE =\n-      TestBoundedTable.of(TABLE_WTH_DATE_SCHEMA)\n+      TestBoundedTable.of(TABLE_WITH_DATE_SCHEMA)\n           .addRows(LocalDate.of(2008, 12, 25), \"s\")\n           .addRows(LocalDate.of(2020, 4, 7), \"s\");\n \n-  private static final Schema TABLE_WTH_TIME_SCHEMA =\n+  private static final Schema TABLE_WITH_TIME_SCHEMA =\n       Schema.builder()\n           .addLogicalTypeField(\"time_field\", SqlTypes.TIME)\n           .addStringField(\"str_field\")\n           .build();\n \n   public static final TestBoundedTable TABLE_WITH_TIME =\n-      TestBoundedTable.of(TABLE_WTH_TIME_SCHEMA)\n+      TestBoundedTable.of(TABLE_WITH_TIME_SCHEMA)\n           .addRows(LocalTime.of(15, 30, 0), \"s\")\n           .addRows(LocalTime.of(23, 35, 59), \"s\");\n \n-  private static final Schema TABLE_WTH_NUMERIC_SCHEMA =\n+  private static final Schema TABLE_WITH_NUMERIC_SCHEMA =\n       Schema.builder().addDecimalField(\"numeric_field\").addStringField(\"str_field\").build();\n+\n   public static final TestBoundedTable TABLE_WITH_NUMERIC =\n-      TestBoundedTable.of(TABLE_WTH_NUMERIC_SCHEMA)\n+      TestBoundedTable.of(TABLE_WITH_NUMERIC_SCHEMA)\n           .addRows(ZetaSqlTypesUtils.bigDecimalAsNumeric(\"123.4567\"), \"str1\")\n           .addRows(ZetaSqlTypesUtils.bigDecimalAsNumeric(\"765.4321\"), \"str2\")\n           .addRows(ZetaSqlTypesUtils.bigDecimalAsNumeric(\"-555.5555\"), \"str3\");\n \n+  private static final Schema TABLE_WITH_DATETIME_SCHEMA =\n+      Schema.builder()\n+          .addLogicalTypeField(\"datetime_field\", SqlTypes.DATETIME)\n+          .addStringField(\"str_field\")\n+          .build();\n+\n+  public static final TestBoundedTable TABLE_WITH_DATETIME =\n+      TestBoundedTable.of(TABLE_WITH_DATETIME_SCHEMA)\n+          .addRows(LocalDateTime.of(2008, 12, 25, 15, 30, 0), \"s\")", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2MjU3NjU3Ng=="}, "originalCommit": {"oid": "db928fd8ea88d09d0d0457efd253b56072da9672"}, "originalPosition": 70}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwNTY4MTkzOnYy", "diffSide": "RIGHT", "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/logicaltypes/DateTime.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQxNzo1NzoyMFrOG7rW1g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQyMDo0NDoyNFrOG7w1Pg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTIyOTUyNg==", "bodyText": "Now these fields are all public, I think it makes sense to give them more precise names, like \"DATE_FIELD_NAME\" and \"TIME_FIELD_NAME\"?", "url": "https://github.com/apache/beam/pull/12348#discussion_r465229526", "createdAt": "2020-08-04T17:57:20Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/logicaltypes/DateTime.java", "diffHunk": "@@ -0,0 +1,83 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.schemas.logicaltypes;\n+\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.values.Row;\n+\n+/**\n+ * A datetime without a time-zone.\n+ *\n+ * <p>It cannot represent an instant on the time-line without additional information such as an\n+ * offset or time-zone.\n+ *\n+ * <p>Its input type is a {@link LocalDateTime}, and base type is a {@link Row} containing Date\n+ * field and Time field. Date field is the same as the base type of {@link Date}, which is a Long\n+ * that represents incrementing count of days where day 0 is 1970-01-01 (ISO). Time field is the\n+ * same as the base type of {@link Time}, which is a Long that represents a count of time in\n+ * nanoseconds.\n+ */\n+public class DateTime implements Schema.LogicalType<LocalDateTime, Row> {\n+  public static final String DATE_FIELD = \"Date\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9da6738f63fcb336a0210d411cf34b6e0f6a8730"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTMxOTIzMA==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/12348#discussion_r465319230", "createdAt": "2020-08-04T20:44:24Z", "author": {"login": "ZijieSong946"}, "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/logicaltypes/DateTime.java", "diffHunk": "@@ -0,0 +1,83 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.schemas.logicaltypes;\n+\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.values.Row;\n+\n+/**\n+ * A datetime without a time-zone.\n+ *\n+ * <p>It cannot represent an instant on the time-line without additional information such as an\n+ * offset or time-zone.\n+ *\n+ * <p>Its input type is a {@link LocalDateTime}, and base type is a {@link Row} containing Date\n+ * field and Time field. Date field is the same as the base type of {@link Date}, which is a Long\n+ * that represents incrementing count of days where day 0 is 1970-01-01 (ISO). Time field is the\n+ * same as the base type of {@link Time}, which is a Long that represents a count of time in\n+ * nanoseconds.\n+ */\n+public class DateTime implements Schema.LogicalType<LocalDateTime, Row> {\n+  public static final String DATE_FIELD = \"Date\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTIyOTUyNg=="}, "originalCommit": {"oid": "9da6738f63fcb336a0210d411cf34b6e0f6a8730"}, "originalPosition": 39}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwNTY4OTM4OnYy", "diffSide": "RIGHT", "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/impl/schema/BeamSqlRowCoderTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQxNzo1OToyOFrOG7rblA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQyMDo0NDozNFrOG7w1nQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTIzMDc0MA==", "bodyText": "Let's not use the name \"datetime\" here. I think it should be \"timestamp_with_local_time_zone\"? See other column names above, they all use the Calcite name.", "url": "https://github.com/apache/beam/pull/12348#discussion_r465230740", "createdAt": "2020-08-04T17:59:28Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/impl/schema/BeamSqlRowCoderTest.java", "diffHunk": "@@ -51,6 +52,7 @@ public void encodeAndDecode() throws Exception {\n             .add(\"col_string_varchar\", SqlTypeName.VARCHAR)\n             .add(\"col_time\", SqlTypeName.TIME)\n             .add(\"col_date\", SqlTypeName.DATE)\n+            .add(\"col_datetime\", SqlTypeName.TIMESTAMP_WITH_LOCAL_TIME_ZONE)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9da6738f63fcb336a0210d411cf34b6e0f6a8730"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTMxOTMyNQ==", "bodyText": "OK. Done.", "url": "https://github.com/apache/beam/pull/12348#discussion_r465319325", "createdAt": "2020-08-04T20:44:34Z", "author": {"login": "ZijieSong946"}, "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/impl/schema/BeamSqlRowCoderTest.java", "diffHunk": "@@ -51,6 +52,7 @@ public void encodeAndDecode() throws Exception {\n             .add(\"col_string_varchar\", SqlTypeName.VARCHAR)\n             .add(\"col_time\", SqlTypeName.TIME)\n             .add(\"col_date\", SqlTypeName.DATE)\n+            .add(\"col_datetime\", SqlTypeName.TIMESTAMP_WITH_LOCAL_TIME_ZONE)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTIzMDc0MA=="}, "originalCommit": {"oid": "9da6738f63fcb336a0210d411cf34b6e0f6a8730"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwNTgzOTA4OnYy", "diffSide": "RIGHT", "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/BeamComplexTypeTest.java", "isResolved": true, "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQxODo0MjozMlrOG7s4Fw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQwNjowNTozN1rOG77c-A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTI1NDQyMw==", "bodyText": "Add some tests on \"nullableDateTimeField\" as well, like above?", "url": "https://github.com/apache/beam/pull/12348#discussion_r465254423", "createdAt": "2020-08-04T18:42:32Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/BeamComplexTypeTest.java", "diffHunk": "@@ -412,32 +398,141 @@ public void testNullDatetimeFields() {\n             .addNullableField(\"year_with_null\", FieldType.INT64)\n             .addField(\"mm\", FieldType.INT64)\n             .addNullableField(\"month_with_null\", FieldType.INT64)\n+            .build();\n+\n+    PAssert.that(outputRow)\n+        .containsInAnyOrder(\n+            Row.withSchema(outputRowSchema).addValues(2019L, null, 06L, null).build());\n+\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(2));\n+  }\n+\n+  @Test\n+  public void testNullSqlLogicalTypeDateFields() {\n+    Schema dateTimeFieldSchema =\n+        Schema.builder()\n+            .addField(\"dateTypeField\", FieldType.logicalType(SqlTypes.DATE))\n+            .addNullableField(\"nullableDateTypeField\", FieldType.logicalType(SqlTypes.DATE))\n+            .build();\n+\n+    Row dateRow =\n+        Row.withSchema(dateTimeFieldSchema).addValues(LocalDate.of(2019, 6, 27), null).build();\n+\n+    PCollection<Row> outputRow =\n+        pipeline\n+            .apply(Create.of(dateRow))\n+            .setRowSchema(dateTimeFieldSchema)\n+            .apply(\n+                SqlTransform.query(\n+                    \"select EXTRACT(DAY from dateTypeField) as dd, \"\n+                        + \" EXTRACT(DAY from nullableDateTypeField) as day_with_null, \"\n+                        + \" dateTypeField + interval '1' day as date_with_day_added, \"\n+                        + \" nullableDateTypeField + interval '1' day as day_added_with_null \"\n+                        + \" from PCOLLECTION\"));\n+\n+    Schema outputRowSchema =\n+        Schema.builder()\n+            .addField(\"dd\", FieldType.INT64)\n+            .addNullableField(\"day_with_null\", FieldType.INT64)\n+            .addField(\"date_with_day_added\", FieldType.logicalType(SqlTypes.DATE))\n+            .addNullableField(\"day_added_with_null\", FieldType.logicalType(SqlTypes.DATE))\n+            .build();\n+\n+    PAssert.that(outputRow)\n+        .containsInAnyOrder(\n+            Row.withSchema(outputRowSchema)\n+                .addValues(27L, null, LocalDate.of(2019, 6, 28), null)\n+                .build());\n+\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(2));\n+  }\n+\n+  @Test\n+  public void testNullSqlLogicalTypeTimeFields() {\n+    Schema dateTimeFieldSchema =\n+        Schema.builder()\n+            .addField(\"timeTypeField\", FieldType.logicalType(SqlTypes.TIME))\n+            .addNullableField(\"nullableTimeTypeField\", FieldType.logicalType(SqlTypes.TIME))\n+            .build();\n+\n+    Row timeRow =\n+        Row.withSchema(dateTimeFieldSchema).addValues(LocalTime.of(1, 0, 0), null).build();\n+\n+    PCollection<Row> outputRow =\n+        pipeline\n+            .apply(Create.of(timeRow))\n+            .setRowSchema(dateTimeFieldSchema)\n+            .apply(\n+                SqlTransform.query(\n+                    \"select timeTypeField + interval '1' hour as time_with_hour_added, \"\n+                        + \" nullableTimeTypeField + interval '1' hour as hour_added_with_null, \"\n+                        + \" timeTypeField - INTERVAL '60' SECOND as time_with_seconds_added, \"\n+                        + \" nullableTimeTypeField - INTERVAL '60' SECOND as seconds_added_with_null \"\n+                        + \" from PCOLLECTION\"));\n+\n+    Schema outputRowSchema =\n+        Schema.builder()\n             .addField(\"time_with_hour_added\", FieldType.logicalType(SqlTypes.TIME))\n             .addNullableField(\"hour_added_with_null\", FieldType.logicalType(SqlTypes.TIME))\n             .addField(\"time_with_seconds_added\", FieldType.logicalType(SqlTypes.TIME))\n             .addNullableField(\"seconds_added_with_null\", FieldType.logicalType(SqlTypes.TIME))\n+            .build();\n+\n+    PAssert.that(outputRow)\n+        .containsInAnyOrder(\n+            Row.withSchema(outputRowSchema)\n+                .addValues(LocalTime.of(2, 0, 0), null, LocalTime.of(0, 59, 0), null)\n+                .build());\n+\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(2));\n+  }\n+\n+  @Test\n+  public void testSqlLogicalTypeDatetimeFields() {\n+    Schema dateTimeFieldSchema =\n+        Schema.builder()\n+            .addField(\"dateTimeField\", FieldType.logicalType(SqlTypes.DATETIME))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9da6738f63fcb336a0210d411cf34b6e0f6a8730"}, "originalPosition": 140}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTI2ODM0OQ==", "bodyText": "I planned to do that but Calcite do not have NULLABLE_TIMESTAMP_WITH_LOCAL_TZ type corresponding to TIMESTAMP_WITH_LOCAL_TZ.", "url": "https://github.com/apache/beam/pull/12348#discussion_r465268349", "createdAt": "2020-08-04T19:08:55Z", "author": {"login": "ZijieSong946"}, "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/BeamComplexTypeTest.java", "diffHunk": "@@ -412,32 +398,141 @@ public void testNullDatetimeFields() {\n             .addNullableField(\"year_with_null\", FieldType.INT64)\n             .addField(\"mm\", FieldType.INT64)\n             .addNullableField(\"month_with_null\", FieldType.INT64)\n+            .build();\n+\n+    PAssert.that(outputRow)\n+        .containsInAnyOrder(\n+            Row.withSchema(outputRowSchema).addValues(2019L, null, 06L, null).build());\n+\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(2));\n+  }\n+\n+  @Test\n+  public void testNullSqlLogicalTypeDateFields() {\n+    Schema dateTimeFieldSchema =\n+        Schema.builder()\n+            .addField(\"dateTypeField\", FieldType.logicalType(SqlTypes.DATE))\n+            .addNullableField(\"nullableDateTypeField\", FieldType.logicalType(SqlTypes.DATE))\n+            .build();\n+\n+    Row dateRow =\n+        Row.withSchema(dateTimeFieldSchema).addValues(LocalDate.of(2019, 6, 27), null).build();\n+\n+    PCollection<Row> outputRow =\n+        pipeline\n+            .apply(Create.of(dateRow))\n+            .setRowSchema(dateTimeFieldSchema)\n+            .apply(\n+                SqlTransform.query(\n+                    \"select EXTRACT(DAY from dateTypeField) as dd, \"\n+                        + \" EXTRACT(DAY from nullableDateTypeField) as day_with_null, \"\n+                        + \" dateTypeField + interval '1' day as date_with_day_added, \"\n+                        + \" nullableDateTypeField + interval '1' day as day_added_with_null \"\n+                        + \" from PCOLLECTION\"));\n+\n+    Schema outputRowSchema =\n+        Schema.builder()\n+            .addField(\"dd\", FieldType.INT64)\n+            .addNullableField(\"day_with_null\", FieldType.INT64)\n+            .addField(\"date_with_day_added\", FieldType.logicalType(SqlTypes.DATE))\n+            .addNullableField(\"day_added_with_null\", FieldType.logicalType(SqlTypes.DATE))\n+            .build();\n+\n+    PAssert.that(outputRow)\n+        .containsInAnyOrder(\n+            Row.withSchema(outputRowSchema)\n+                .addValues(27L, null, LocalDate.of(2019, 6, 28), null)\n+                .build());\n+\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(2));\n+  }\n+\n+  @Test\n+  public void testNullSqlLogicalTypeTimeFields() {\n+    Schema dateTimeFieldSchema =\n+        Schema.builder()\n+            .addField(\"timeTypeField\", FieldType.logicalType(SqlTypes.TIME))\n+            .addNullableField(\"nullableTimeTypeField\", FieldType.logicalType(SqlTypes.TIME))\n+            .build();\n+\n+    Row timeRow =\n+        Row.withSchema(dateTimeFieldSchema).addValues(LocalTime.of(1, 0, 0), null).build();\n+\n+    PCollection<Row> outputRow =\n+        pipeline\n+            .apply(Create.of(timeRow))\n+            .setRowSchema(dateTimeFieldSchema)\n+            .apply(\n+                SqlTransform.query(\n+                    \"select timeTypeField + interval '1' hour as time_with_hour_added, \"\n+                        + \" nullableTimeTypeField + interval '1' hour as hour_added_with_null, \"\n+                        + \" timeTypeField - INTERVAL '60' SECOND as time_with_seconds_added, \"\n+                        + \" nullableTimeTypeField - INTERVAL '60' SECOND as seconds_added_with_null \"\n+                        + \" from PCOLLECTION\"));\n+\n+    Schema outputRowSchema =\n+        Schema.builder()\n             .addField(\"time_with_hour_added\", FieldType.logicalType(SqlTypes.TIME))\n             .addNullableField(\"hour_added_with_null\", FieldType.logicalType(SqlTypes.TIME))\n             .addField(\"time_with_seconds_added\", FieldType.logicalType(SqlTypes.TIME))\n             .addNullableField(\"seconds_added_with_null\", FieldType.logicalType(SqlTypes.TIME))\n+            .build();\n+\n+    PAssert.that(outputRow)\n+        .containsInAnyOrder(\n+            Row.withSchema(outputRowSchema)\n+                .addValues(LocalTime.of(2, 0, 0), null, LocalTime.of(0, 59, 0), null)\n+                .build());\n+\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(2));\n+  }\n+\n+  @Test\n+  public void testSqlLogicalTypeDatetimeFields() {\n+    Schema dateTimeFieldSchema =\n+        Schema.builder()\n+            .addField(\"dateTimeField\", FieldType.logicalType(SqlTypes.DATETIME))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTI1NDQyMw=="}, "originalCommit": {"oid": "9da6738f63fcb336a0210d411cf34b6e0f6a8730"}, "originalPosition": 140}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTI5MzQxMA==", "bodyText": "I don't think we need a NULLABLE_TIMESTAMP_WITH_LOCAL_TZ in Calcite. Like in the test above, Calcite does not define a NULLABLE_DATE either.\nIf we add .addNullableField(\"nullableDateTimeField\", FieldType.logicalType(SqlTypes.DATETIME)), does that not work?", "url": "https://github.com/apache/beam/pull/12348#discussion_r465293410", "createdAt": "2020-08-04T19:53:22Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/BeamComplexTypeTest.java", "diffHunk": "@@ -412,32 +398,141 @@ public void testNullDatetimeFields() {\n             .addNullableField(\"year_with_null\", FieldType.INT64)\n             .addField(\"mm\", FieldType.INT64)\n             .addNullableField(\"month_with_null\", FieldType.INT64)\n+            .build();\n+\n+    PAssert.that(outputRow)\n+        .containsInAnyOrder(\n+            Row.withSchema(outputRowSchema).addValues(2019L, null, 06L, null).build());\n+\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(2));\n+  }\n+\n+  @Test\n+  public void testNullSqlLogicalTypeDateFields() {\n+    Schema dateTimeFieldSchema =\n+        Schema.builder()\n+            .addField(\"dateTypeField\", FieldType.logicalType(SqlTypes.DATE))\n+            .addNullableField(\"nullableDateTypeField\", FieldType.logicalType(SqlTypes.DATE))\n+            .build();\n+\n+    Row dateRow =\n+        Row.withSchema(dateTimeFieldSchema).addValues(LocalDate.of(2019, 6, 27), null).build();\n+\n+    PCollection<Row> outputRow =\n+        pipeline\n+            .apply(Create.of(dateRow))\n+            .setRowSchema(dateTimeFieldSchema)\n+            .apply(\n+                SqlTransform.query(\n+                    \"select EXTRACT(DAY from dateTypeField) as dd, \"\n+                        + \" EXTRACT(DAY from nullableDateTypeField) as day_with_null, \"\n+                        + \" dateTypeField + interval '1' day as date_with_day_added, \"\n+                        + \" nullableDateTypeField + interval '1' day as day_added_with_null \"\n+                        + \" from PCOLLECTION\"));\n+\n+    Schema outputRowSchema =\n+        Schema.builder()\n+            .addField(\"dd\", FieldType.INT64)\n+            .addNullableField(\"day_with_null\", FieldType.INT64)\n+            .addField(\"date_with_day_added\", FieldType.logicalType(SqlTypes.DATE))\n+            .addNullableField(\"day_added_with_null\", FieldType.logicalType(SqlTypes.DATE))\n+            .build();\n+\n+    PAssert.that(outputRow)\n+        .containsInAnyOrder(\n+            Row.withSchema(outputRowSchema)\n+                .addValues(27L, null, LocalDate.of(2019, 6, 28), null)\n+                .build());\n+\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(2));\n+  }\n+\n+  @Test\n+  public void testNullSqlLogicalTypeTimeFields() {\n+    Schema dateTimeFieldSchema =\n+        Schema.builder()\n+            .addField(\"timeTypeField\", FieldType.logicalType(SqlTypes.TIME))\n+            .addNullableField(\"nullableTimeTypeField\", FieldType.logicalType(SqlTypes.TIME))\n+            .build();\n+\n+    Row timeRow =\n+        Row.withSchema(dateTimeFieldSchema).addValues(LocalTime.of(1, 0, 0), null).build();\n+\n+    PCollection<Row> outputRow =\n+        pipeline\n+            .apply(Create.of(timeRow))\n+            .setRowSchema(dateTimeFieldSchema)\n+            .apply(\n+                SqlTransform.query(\n+                    \"select timeTypeField + interval '1' hour as time_with_hour_added, \"\n+                        + \" nullableTimeTypeField + interval '1' hour as hour_added_with_null, \"\n+                        + \" timeTypeField - INTERVAL '60' SECOND as time_with_seconds_added, \"\n+                        + \" nullableTimeTypeField - INTERVAL '60' SECOND as seconds_added_with_null \"\n+                        + \" from PCOLLECTION\"));\n+\n+    Schema outputRowSchema =\n+        Schema.builder()\n             .addField(\"time_with_hour_added\", FieldType.logicalType(SqlTypes.TIME))\n             .addNullableField(\"hour_added_with_null\", FieldType.logicalType(SqlTypes.TIME))\n             .addField(\"time_with_seconds_added\", FieldType.logicalType(SqlTypes.TIME))\n             .addNullableField(\"seconds_added_with_null\", FieldType.logicalType(SqlTypes.TIME))\n+            .build();\n+\n+    PAssert.that(outputRow)\n+        .containsInAnyOrder(\n+            Row.withSchema(outputRowSchema)\n+                .addValues(LocalTime.of(2, 0, 0), null, LocalTime.of(0, 59, 0), null)\n+                .build());\n+\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(2));\n+  }\n+\n+  @Test\n+  public void testSqlLogicalTypeDatetimeFields() {\n+    Schema dateTimeFieldSchema =\n+        Schema.builder()\n+            .addField(\"dateTimeField\", FieldType.logicalType(SqlTypes.DATETIME))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTI1NDQyMw=="}, "originalCommit": {"oid": "9da6738f63fcb336a0210d411cf34b6e0f6a8730"}, "originalPosition": 140}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTMwODA1MQ==", "bodyText": "No. I think its because NULLABLE_DATE could be recognized but NULLABLE_TIMESTAMP_WITH_LOCAL_TZ could not. (\n  \n    \n      beam/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/utils/CalciteUtils.java\n    \n    \n        Lines 115 to 125\n      in\n      5e0e798\n    \n    \n    \n    \n\n        \n          \n           public static final FieldType NULLABLE_DATE = \n        \n\n        \n          \n               FieldType.logicalType(SqlTypes.DATE).withNullable(true); \n        \n\n        \n          \n           public static final FieldType TIME = FieldType.logicalType(SqlTypes.TIME); \n        \n\n        \n          \n           public static final FieldType NULLABLE_TIME = \n        \n\n        \n          \n               FieldType.logicalType(SqlTypes.TIME).withNullable(true); \n        \n\n        \n          \n           public static final FieldType TIME_WITH_LOCAL_TZ = \n        \n\n        \n          \n               FieldType.logicalType(new TimeWithLocalTzType()); \n        \n\n        \n          \n           public static final FieldType TIMESTAMP = FieldType.DATETIME; \n        \n\n        \n          \n           public static final FieldType NULLABLE_TIMESTAMP = FieldType.DATETIME.withNullable(true); \n        \n\n        \n          \n           public static final FieldType TIMESTAMP_WITH_LOCAL_TZ = \n        \n\n        \n          \n               FieldType.logicalType(new TimestampWithLocalTzType()); \n        \n    \n  \n\n)", "url": "https://github.com/apache/beam/pull/12348#discussion_r465308051", "createdAt": "2020-08-04T20:22:10Z", "author": {"login": "ZijieSong946"}, "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/BeamComplexTypeTest.java", "diffHunk": "@@ -412,32 +398,141 @@ public void testNullDatetimeFields() {\n             .addNullableField(\"year_with_null\", FieldType.INT64)\n             .addField(\"mm\", FieldType.INT64)\n             .addNullableField(\"month_with_null\", FieldType.INT64)\n+            .build();\n+\n+    PAssert.that(outputRow)\n+        .containsInAnyOrder(\n+            Row.withSchema(outputRowSchema).addValues(2019L, null, 06L, null).build());\n+\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(2));\n+  }\n+\n+  @Test\n+  public void testNullSqlLogicalTypeDateFields() {\n+    Schema dateTimeFieldSchema =\n+        Schema.builder()\n+            .addField(\"dateTypeField\", FieldType.logicalType(SqlTypes.DATE))\n+            .addNullableField(\"nullableDateTypeField\", FieldType.logicalType(SqlTypes.DATE))\n+            .build();\n+\n+    Row dateRow =\n+        Row.withSchema(dateTimeFieldSchema).addValues(LocalDate.of(2019, 6, 27), null).build();\n+\n+    PCollection<Row> outputRow =\n+        pipeline\n+            .apply(Create.of(dateRow))\n+            .setRowSchema(dateTimeFieldSchema)\n+            .apply(\n+                SqlTransform.query(\n+                    \"select EXTRACT(DAY from dateTypeField) as dd, \"\n+                        + \" EXTRACT(DAY from nullableDateTypeField) as day_with_null, \"\n+                        + \" dateTypeField + interval '1' day as date_with_day_added, \"\n+                        + \" nullableDateTypeField + interval '1' day as day_added_with_null \"\n+                        + \" from PCOLLECTION\"));\n+\n+    Schema outputRowSchema =\n+        Schema.builder()\n+            .addField(\"dd\", FieldType.INT64)\n+            .addNullableField(\"day_with_null\", FieldType.INT64)\n+            .addField(\"date_with_day_added\", FieldType.logicalType(SqlTypes.DATE))\n+            .addNullableField(\"day_added_with_null\", FieldType.logicalType(SqlTypes.DATE))\n+            .build();\n+\n+    PAssert.that(outputRow)\n+        .containsInAnyOrder(\n+            Row.withSchema(outputRowSchema)\n+                .addValues(27L, null, LocalDate.of(2019, 6, 28), null)\n+                .build());\n+\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(2));\n+  }\n+\n+  @Test\n+  public void testNullSqlLogicalTypeTimeFields() {\n+    Schema dateTimeFieldSchema =\n+        Schema.builder()\n+            .addField(\"timeTypeField\", FieldType.logicalType(SqlTypes.TIME))\n+            .addNullableField(\"nullableTimeTypeField\", FieldType.logicalType(SqlTypes.TIME))\n+            .build();\n+\n+    Row timeRow =\n+        Row.withSchema(dateTimeFieldSchema).addValues(LocalTime.of(1, 0, 0), null).build();\n+\n+    PCollection<Row> outputRow =\n+        pipeline\n+            .apply(Create.of(timeRow))\n+            .setRowSchema(dateTimeFieldSchema)\n+            .apply(\n+                SqlTransform.query(\n+                    \"select timeTypeField + interval '1' hour as time_with_hour_added, \"\n+                        + \" nullableTimeTypeField + interval '1' hour as hour_added_with_null, \"\n+                        + \" timeTypeField - INTERVAL '60' SECOND as time_with_seconds_added, \"\n+                        + \" nullableTimeTypeField - INTERVAL '60' SECOND as seconds_added_with_null \"\n+                        + \" from PCOLLECTION\"));\n+\n+    Schema outputRowSchema =\n+        Schema.builder()\n             .addField(\"time_with_hour_added\", FieldType.logicalType(SqlTypes.TIME))\n             .addNullableField(\"hour_added_with_null\", FieldType.logicalType(SqlTypes.TIME))\n             .addField(\"time_with_seconds_added\", FieldType.logicalType(SqlTypes.TIME))\n             .addNullableField(\"seconds_added_with_null\", FieldType.logicalType(SqlTypes.TIME))\n+            .build();\n+\n+    PAssert.that(outputRow)\n+        .containsInAnyOrder(\n+            Row.withSchema(outputRowSchema)\n+                .addValues(LocalTime.of(2, 0, 0), null, LocalTime.of(0, 59, 0), null)\n+                .build());\n+\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(2));\n+  }\n+\n+  @Test\n+  public void testSqlLogicalTypeDatetimeFields() {\n+    Schema dateTimeFieldSchema =\n+        Schema.builder()\n+            .addField(\"dateTimeField\", FieldType.logicalType(SqlTypes.DATETIME))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTI1NDQyMw=="}, "originalCommit": {"oid": "9da6738f63fcb336a0210d411cf34b6e0f6a8730"}, "originalPosition": 140}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTMwOTE5Nw==", "bodyText": "Actually is beam type FieldType.logicalType(sqlTypes.DATETIME).withNullable(true) could not be recognized.\nThere is no label for that. Do we need to create it?", "url": "https://github.com/apache/beam/pull/12348#discussion_r465309197", "createdAt": "2020-08-04T20:24:30Z", "author": {"login": "ZijieSong946"}, "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/BeamComplexTypeTest.java", "diffHunk": "@@ -412,32 +398,141 @@ public void testNullDatetimeFields() {\n             .addNullableField(\"year_with_null\", FieldType.INT64)\n             .addField(\"mm\", FieldType.INT64)\n             .addNullableField(\"month_with_null\", FieldType.INT64)\n+            .build();\n+\n+    PAssert.that(outputRow)\n+        .containsInAnyOrder(\n+            Row.withSchema(outputRowSchema).addValues(2019L, null, 06L, null).build());\n+\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(2));\n+  }\n+\n+  @Test\n+  public void testNullSqlLogicalTypeDateFields() {\n+    Schema dateTimeFieldSchema =\n+        Schema.builder()\n+            .addField(\"dateTypeField\", FieldType.logicalType(SqlTypes.DATE))\n+            .addNullableField(\"nullableDateTypeField\", FieldType.logicalType(SqlTypes.DATE))\n+            .build();\n+\n+    Row dateRow =\n+        Row.withSchema(dateTimeFieldSchema).addValues(LocalDate.of(2019, 6, 27), null).build();\n+\n+    PCollection<Row> outputRow =\n+        pipeline\n+            .apply(Create.of(dateRow))\n+            .setRowSchema(dateTimeFieldSchema)\n+            .apply(\n+                SqlTransform.query(\n+                    \"select EXTRACT(DAY from dateTypeField) as dd, \"\n+                        + \" EXTRACT(DAY from nullableDateTypeField) as day_with_null, \"\n+                        + \" dateTypeField + interval '1' day as date_with_day_added, \"\n+                        + \" nullableDateTypeField + interval '1' day as day_added_with_null \"\n+                        + \" from PCOLLECTION\"));\n+\n+    Schema outputRowSchema =\n+        Schema.builder()\n+            .addField(\"dd\", FieldType.INT64)\n+            .addNullableField(\"day_with_null\", FieldType.INT64)\n+            .addField(\"date_with_day_added\", FieldType.logicalType(SqlTypes.DATE))\n+            .addNullableField(\"day_added_with_null\", FieldType.logicalType(SqlTypes.DATE))\n+            .build();\n+\n+    PAssert.that(outputRow)\n+        .containsInAnyOrder(\n+            Row.withSchema(outputRowSchema)\n+                .addValues(27L, null, LocalDate.of(2019, 6, 28), null)\n+                .build());\n+\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(2));\n+  }\n+\n+  @Test\n+  public void testNullSqlLogicalTypeTimeFields() {\n+    Schema dateTimeFieldSchema =\n+        Schema.builder()\n+            .addField(\"timeTypeField\", FieldType.logicalType(SqlTypes.TIME))\n+            .addNullableField(\"nullableTimeTypeField\", FieldType.logicalType(SqlTypes.TIME))\n+            .build();\n+\n+    Row timeRow =\n+        Row.withSchema(dateTimeFieldSchema).addValues(LocalTime.of(1, 0, 0), null).build();\n+\n+    PCollection<Row> outputRow =\n+        pipeline\n+            .apply(Create.of(timeRow))\n+            .setRowSchema(dateTimeFieldSchema)\n+            .apply(\n+                SqlTransform.query(\n+                    \"select timeTypeField + interval '1' hour as time_with_hour_added, \"\n+                        + \" nullableTimeTypeField + interval '1' hour as hour_added_with_null, \"\n+                        + \" timeTypeField - INTERVAL '60' SECOND as time_with_seconds_added, \"\n+                        + \" nullableTimeTypeField - INTERVAL '60' SECOND as seconds_added_with_null \"\n+                        + \" from PCOLLECTION\"));\n+\n+    Schema outputRowSchema =\n+        Schema.builder()\n             .addField(\"time_with_hour_added\", FieldType.logicalType(SqlTypes.TIME))\n             .addNullableField(\"hour_added_with_null\", FieldType.logicalType(SqlTypes.TIME))\n             .addField(\"time_with_seconds_added\", FieldType.logicalType(SqlTypes.TIME))\n             .addNullableField(\"seconds_added_with_null\", FieldType.logicalType(SqlTypes.TIME))\n+            .build();\n+\n+    PAssert.that(outputRow)\n+        .containsInAnyOrder(\n+            Row.withSchema(outputRowSchema)\n+                .addValues(LocalTime.of(2, 0, 0), null, LocalTime.of(0, 59, 0), null)\n+                .build());\n+\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(2));\n+  }\n+\n+  @Test\n+  public void testSqlLogicalTypeDatetimeFields() {\n+    Schema dateTimeFieldSchema =\n+        Schema.builder()\n+            .addField(\"dateTimeField\", FieldType.logicalType(SqlTypes.DATETIME))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTI1NDQyMw=="}, "originalCommit": {"oid": "9da6738f63fcb336a0210d411cf34b6e0f6a8730"}, "originalPosition": 140}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM5MDM5Mg==", "bodyText": "Yeah it makes sense to be in here as well. Thanks for catching this.", "url": "https://github.com/apache/beam/pull/12348#discussion_r465390392", "createdAt": "2020-08-04T23:44:33Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/BeamComplexTypeTest.java", "diffHunk": "@@ -412,32 +398,141 @@ public void testNullDatetimeFields() {\n             .addNullableField(\"year_with_null\", FieldType.INT64)\n             .addField(\"mm\", FieldType.INT64)\n             .addNullableField(\"month_with_null\", FieldType.INT64)\n+            .build();\n+\n+    PAssert.that(outputRow)\n+        .containsInAnyOrder(\n+            Row.withSchema(outputRowSchema).addValues(2019L, null, 06L, null).build());\n+\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(2));\n+  }\n+\n+  @Test\n+  public void testNullSqlLogicalTypeDateFields() {\n+    Schema dateTimeFieldSchema =\n+        Schema.builder()\n+            .addField(\"dateTypeField\", FieldType.logicalType(SqlTypes.DATE))\n+            .addNullableField(\"nullableDateTypeField\", FieldType.logicalType(SqlTypes.DATE))\n+            .build();\n+\n+    Row dateRow =\n+        Row.withSchema(dateTimeFieldSchema).addValues(LocalDate.of(2019, 6, 27), null).build();\n+\n+    PCollection<Row> outputRow =\n+        pipeline\n+            .apply(Create.of(dateRow))\n+            .setRowSchema(dateTimeFieldSchema)\n+            .apply(\n+                SqlTransform.query(\n+                    \"select EXTRACT(DAY from dateTypeField) as dd, \"\n+                        + \" EXTRACT(DAY from nullableDateTypeField) as day_with_null, \"\n+                        + \" dateTypeField + interval '1' day as date_with_day_added, \"\n+                        + \" nullableDateTypeField + interval '1' day as day_added_with_null \"\n+                        + \" from PCOLLECTION\"));\n+\n+    Schema outputRowSchema =\n+        Schema.builder()\n+            .addField(\"dd\", FieldType.INT64)\n+            .addNullableField(\"day_with_null\", FieldType.INT64)\n+            .addField(\"date_with_day_added\", FieldType.logicalType(SqlTypes.DATE))\n+            .addNullableField(\"day_added_with_null\", FieldType.logicalType(SqlTypes.DATE))\n+            .build();\n+\n+    PAssert.that(outputRow)\n+        .containsInAnyOrder(\n+            Row.withSchema(outputRowSchema)\n+                .addValues(27L, null, LocalDate.of(2019, 6, 28), null)\n+                .build());\n+\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(2));\n+  }\n+\n+  @Test\n+  public void testNullSqlLogicalTypeTimeFields() {\n+    Schema dateTimeFieldSchema =\n+        Schema.builder()\n+            .addField(\"timeTypeField\", FieldType.logicalType(SqlTypes.TIME))\n+            .addNullableField(\"nullableTimeTypeField\", FieldType.logicalType(SqlTypes.TIME))\n+            .build();\n+\n+    Row timeRow =\n+        Row.withSchema(dateTimeFieldSchema).addValues(LocalTime.of(1, 0, 0), null).build();\n+\n+    PCollection<Row> outputRow =\n+        pipeline\n+            .apply(Create.of(timeRow))\n+            .setRowSchema(dateTimeFieldSchema)\n+            .apply(\n+                SqlTransform.query(\n+                    \"select timeTypeField + interval '1' hour as time_with_hour_added, \"\n+                        + \" nullableTimeTypeField + interval '1' hour as hour_added_with_null, \"\n+                        + \" timeTypeField - INTERVAL '60' SECOND as time_with_seconds_added, \"\n+                        + \" nullableTimeTypeField - INTERVAL '60' SECOND as seconds_added_with_null \"\n+                        + \" from PCOLLECTION\"));\n+\n+    Schema outputRowSchema =\n+        Schema.builder()\n             .addField(\"time_with_hour_added\", FieldType.logicalType(SqlTypes.TIME))\n             .addNullableField(\"hour_added_with_null\", FieldType.logicalType(SqlTypes.TIME))\n             .addField(\"time_with_seconds_added\", FieldType.logicalType(SqlTypes.TIME))\n             .addNullableField(\"seconds_added_with_null\", FieldType.logicalType(SqlTypes.TIME))\n+            .build();\n+\n+    PAssert.that(outputRow)\n+        .containsInAnyOrder(\n+            Row.withSchema(outputRowSchema)\n+                .addValues(LocalTime.of(2, 0, 0), null, LocalTime.of(0, 59, 0), null)\n+                .build());\n+\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(2));\n+  }\n+\n+  @Test\n+  public void testSqlLogicalTypeDatetimeFields() {\n+    Schema dateTimeFieldSchema =\n+        Schema.builder()\n+            .addField(\"dateTimeField\", FieldType.logicalType(SqlTypes.DATETIME))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTI1NDQyMw=="}, "originalCommit": {"oid": "9da6738f63fcb336a0210d411cf34b6e0f6a8730"}, "originalPosition": 140}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTQ5MzI0MA==", "bodyText": "NULLABLE_TIMESTAMP_WITH_LOCAL_TZ and corresponding tests added. It works now.", "url": "https://github.com/apache/beam/pull/12348#discussion_r465493240", "createdAt": "2020-08-05T06:05:37Z", "author": {"login": "ZijieSong946"}, "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/BeamComplexTypeTest.java", "diffHunk": "@@ -412,32 +398,141 @@ public void testNullDatetimeFields() {\n             .addNullableField(\"year_with_null\", FieldType.INT64)\n             .addField(\"mm\", FieldType.INT64)\n             .addNullableField(\"month_with_null\", FieldType.INT64)\n+            .build();\n+\n+    PAssert.that(outputRow)\n+        .containsInAnyOrder(\n+            Row.withSchema(outputRowSchema).addValues(2019L, null, 06L, null).build());\n+\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(2));\n+  }\n+\n+  @Test\n+  public void testNullSqlLogicalTypeDateFields() {\n+    Schema dateTimeFieldSchema =\n+        Schema.builder()\n+            .addField(\"dateTypeField\", FieldType.logicalType(SqlTypes.DATE))\n+            .addNullableField(\"nullableDateTypeField\", FieldType.logicalType(SqlTypes.DATE))\n+            .build();\n+\n+    Row dateRow =\n+        Row.withSchema(dateTimeFieldSchema).addValues(LocalDate.of(2019, 6, 27), null).build();\n+\n+    PCollection<Row> outputRow =\n+        pipeline\n+            .apply(Create.of(dateRow))\n+            .setRowSchema(dateTimeFieldSchema)\n+            .apply(\n+                SqlTransform.query(\n+                    \"select EXTRACT(DAY from dateTypeField) as dd, \"\n+                        + \" EXTRACT(DAY from nullableDateTypeField) as day_with_null, \"\n+                        + \" dateTypeField + interval '1' day as date_with_day_added, \"\n+                        + \" nullableDateTypeField + interval '1' day as day_added_with_null \"\n+                        + \" from PCOLLECTION\"));\n+\n+    Schema outputRowSchema =\n+        Schema.builder()\n+            .addField(\"dd\", FieldType.INT64)\n+            .addNullableField(\"day_with_null\", FieldType.INT64)\n+            .addField(\"date_with_day_added\", FieldType.logicalType(SqlTypes.DATE))\n+            .addNullableField(\"day_added_with_null\", FieldType.logicalType(SqlTypes.DATE))\n+            .build();\n+\n+    PAssert.that(outputRow)\n+        .containsInAnyOrder(\n+            Row.withSchema(outputRowSchema)\n+                .addValues(27L, null, LocalDate.of(2019, 6, 28), null)\n+                .build());\n+\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(2));\n+  }\n+\n+  @Test\n+  public void testNullSqlLogicalTypeTimeFields() {\n+    Schema dateTimeFieldSchema =\n+        Schema.builder()\n+            .addField(\"timeTypeField\", FieldType.logicalType(SqlTypes.TIME))\n+            .addNullableField(\"nullableTimeTypeField\", FieldType.logicalType(SqlTypes.TIME))\n+            .build();\n+\n+    Row timeRow =\n+        Row.withSchema(dateTimeFieldSchema).addValues(LocalTime.of(1, 0, 0), null).build();\n+\n+    PCollection<Row> outputRow =\n+        pipeline\n+            .apply(Create.of(timeRow))\n+            .setRowSchema(dateTimeFieldSchema)\n+            .apply(\n+                SqlTransform.query(\n+                    \"select timeTypeField + interval '1' hour as time_with_hour_added, \"\n+                        + \" nullableTimeTypeField + interval '1' hour as hour_added_with_null, \"\n+                        + \" timeTypeField - INTERVAL '60' SECOND as time_with_seconds_added, \"\n+                        + \" nullableTimeTypeField - INTERVAL '60' SECOND as seconds_added_with_null \"\n+                        + \" from PCOLLECTION\"));\n+\n+    Schema outputRowSchema =\n+        Schema.builder()\n             .addField(\"time_with_hour_added\", FieldType.logicalType(SqlTypes.TIME))\n             .addNullableField(\"hour_added_with_null\", FieldType.logicalType(SqlTypes.TIME))\n             .addField(\"time_with_seconds_added\", FieldType.logicalType(SqlTypes.TIME))\n             .addNullableField(\"seconds_added_with_null\", FieldType.logicalType(SqlTypes.TIME))\n+            .build();\n+\n+    PAssert.that(outputRow)\n+        .containsInAnyOrder(\n+            Row.withSchema(outputRowSchema)\n+                .addValues(LocalTime.of(2, 0, 0), null, LocalTime.of(0, 59, 0), null)\n+                .build());\n+\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(2));\n+  }\n+\n+  @Test\n+  public void testSqlLogicalTypeDatetimeFields() {\n+    Schema dateTimeFieldSchema =\n+        Schema.builder()\n+            .addField(\"dateTimeField\", FieldType.logicalType(SqlTypes.DATETIME))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTI1NDQyMw=="}, "originalCommit": {"oid": "9da6738f63fcb336a0210d411cf34b6e0f6a8730"}, "originalPosition": 140}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwNTg0ODQ3OnYy", "diffSide": "RIGHT", "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/BeamComplexTypeTest.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQxODo0NToyMlrOG7s92A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQyMDo0NDo0M1rOG7w12A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTI1NTg5Ng==", "bodyText": "Thanks for splitting these tests. Now its much easier to read.\nCould you remove the \"Null\" from this test name (and above)? I think all tests have a non-null field and a nullable field now.", "url": "https://github.com/apache/beam/pull/12348#discussion_r465255896", "createdAt": "2020-08-04T18:45:22Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/BeamComplexTypeTest.java", "diffHunk": "@@ -412,32 +398,141 @@ public void testNullDatetimeFields() {\n             .addNullableField(\"year_with_null\", FieldType.INT64)\n             .addField(\"mm\", FieldType.INT64)\n             .addNullableField(\"month_with_null\", FieldType.INT64)\n+            .build();\n+\n+    PAssert.that(outputRow)\n+        .containsInAnyOrder(\n+            Row.withSchema(outputRowSchema).addValues(2019L, null, 06L, null).build());\n+\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(2));\n+  }\n+\n+  @Test\n+  public void testNullSqlLogicalTypeDateFields() {\n+    Schema dateTimeFieldSchema =\n+        Schema.builder()\n+            .addField(\"dateTypeField\", FieldType.logicalType(SqlTypes.DATE))\n+            .addNullableField(\"nullableDateTypeField\", FieldType.logicalType(SqlTypes.DATE))\n+            .build();\n+\n+    Row dateRow =\n+        Row.withSchema(dateTimeFieldSchema).addValues(LocalDate.of(2019, 6, 27), null).build();\n+\n+    PCollection<Row> outputRow =\n+        pipeline\n+            .apply(Create.of(dateRow))\n+            .setRowSchema(dateTimeFieldSchema)\n+            .apply(\n+                SqlTransform.query(\n+                    \"select EXTRACT(DAY from dateTypeField) as dd, \"\n+                        + \" EXTRACT(DAY from nullableDateTypeField) as day_with_null, \"\n+                        + \" dateTypeField + interval '1' day as date_with_day_added, \"\n+                        + \" nullableDateTypeField + interval '1' day as day_added_with_null \"\n+                        + \" from PCOLLECTION\"));\n+\n+    Schema outputRowSchema =\n+        Schema.builder()\n+            .addField(\"dd\", FieldType.INT64)\n+            .addNullableField(\"day_with_null\", FieldType.INT64)\n+            .addField(\"date_with_day_added\", FieldType.logicalType(SqlTypes.DATE))\n+            .addNullableField(\"day_added_with_null\", FieldType.logicalType(SqlTypes.DATE))\n+            .build();\n+\n+    PAssert.that(outputRow)\n+        .containsInAnyOrder(\n+            Row.withSchema(outputRowSchema)\n+                .addValues(27L, null, LocalDate.of(2019, 6, 28), null)\n+                .build());\n+\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(2));\n+  }\n+\n+  @Test\n+  public void testNullSqlLogicalTypeTimeFields() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9da6738f63fcb336a0210d411cf34b6e0f6a8730"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTMxOTM4NA==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/12348#discussion_r465319384", "createdAt": "2020-08-04T20:44:43Z", "author": {"login": "ZijieSong946"}, "path": "sdks/java/extensions/sql/src/test/java/org/apache/beam/sdk/extensions/sql/BeamComplexTypeTest.java", "diffHunk": "@@ -412,32 +398,141 @@ public void testNullDatetimeFields() {\n             .addNullableField(\"year_with_null\", FieldType.INT64)\n             .addField(\"mm\", FieldType.INT64)\n             .addNullableField(\"month_with_null\", FieldType.INT64)\n+            .build();\n+\n+    PAssert.that(outputRow)\n+        .containsInAnyOrder(\n+            Row.withSchema(outputRowSchema).addValues(2019L, null, 06L, null).build());\n+\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(2));\n+  }\n+\n+  @Test\n+  public void testNullSqlLogicalTypeDateFields() {\n+    Schema dateTimeFieldSchema =\n+        Schema.builder()\n+            .addField(\"dateTypeField\", FieldType.logicalType(SqlTypes.DATE))\n+            .addNullableField(\"nullableDateTypeField\", FieldType.logicalType(SqlTypes.DATE))\n+            .build();\n+\n+    Row dateRow =\n+        Row.withSchema(dateTimeFieldSchema).addValues(LocalDate.of(2019, 6, 27), null).build();\n+\n+    PCollection<Row> outputRow =\n+        pipeline\n+            .apply(Create.of(dateRow))\n+            .setRowSchema(dateTimeFieldSchema)\n+            .apply(\n+                SqlTransform.query(\n+                    \"select EXTRACT(DAY from dateTypeField) as dd, \"\n+                        + \" EXTRACT(DAY from nullableDateTypeField) as day_with_null, \"\n+                        + \" dateTypeField + interval '1' day as date_with_day_added, \"\n+                        + \" nullableDateTypeField + interval '1' day as day_added_with_null \"\n+                        + \" from PCOLLECTION\"));\n+\n+    Schema outputRowSchema =\n+        Schema.builder()\n+            .addField(\"dd\", FieldType.INT64)\n+            .addNullableField(\"day_with_null\", FieldType.INT64)\n+            .addField(\"date_with_day_added\", FieldType.logicalType(SqlTypes.DATE))\n+            .addNullableField(\"day_added_with_null\", FieldType.logicalType(SqlTypes.DATE))\n+            .build();\n+\n+    PAssert.that(outputRow)\n+        .containsInAnyOrder(\n+            Row.withSchema(outputRowSchema)\n+                .addValues(27L, null, LocalDate.of(2019, 6, 28), null)\n+                .build());\n+\n+    pipeline.run().waitUntilFinish(Duration.standardMinutes(2));\n+  }\n+\n+  @Test\n+  public void testNullSqlLogicalTypeTimeFields() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTI1NTg5Ng=="}, "originalCommit": {"oid": "9da6738f63fcb336a0210d411cf34b6e0f6a8730"}, "originalPosition": 97}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwNjQ4MTU4OnYy", "diffSide": "RIGHT", "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/logicaltypes/DateTime.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQyMjowMzoyNlrOG7zDzA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQwNjowNzowNlrOG77e5A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM1NTcyNA==", "bodyText": "Instead of getValue(), use getInt64() as we expect this to always be Int64.\nnit:getInt64(DATE_FIELD_INDEX) is probably a better choice than getInt64(DATE_FIELD_NAME) if there is a fixed schema.", "url": "https://github.com/apache/beam/pull/12348#discussion_r465355724", "createdAt": "2020-08-04T22:03:26Z", "author": {"login": "apilloud"}, "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/logicaltypes/DateTime.java", "diffHunk": "@@ -0,0 +1,83 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.schemas.logicaltypes;\n+\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.values.Row;\n+\n+/**\n+ * A datetime without a time-zone.\n+ *\n+ * <p>It cannot represent an instant on the time-line without additional information such as an\n+ * offset or time-zone.\n+ *\n+ * <p>Its input type is a {@link LocalDateTime}, and base type is a {@link Row} containing Date\n+ * field and Time field. Date field is the same as the base type of {@link Date}, which is a Long\n+ * that represents incrementing count of days where day 0 is 1970-01-01 (ISO). Time field is the\n+ * same as the base type of {@link Time}, which is a Long that represents a count of time in\n+ * nanoseconds.\n+ */\n+public class DateTime implements Schema.LogicalType<LocalDateTime, Row> {\n+  public static final String DATE_FIELD_NAME = \"Date\";\n+  public static final String TIME_FIELD_NAME = \"Time\";\n+  public static final Schema DATETIME_SCHEMA =\n+      Schema.builder().addInt64Field(DATE_FIELD_NAME).addInt64Field(TIME_FIELD_NAME).build();\n+\n+  @Override\n+  public String getIdentifier() {\n+    return \"beam:logical_type:datetime:v1\";\n+  }\n+\n+  // unused\n+  @Override\n+  public Schema.FieldType getArgumentType() {\n+    return Schema.FieldType.STRING;\n+  }\n+\n+  // unused\n+  @Override\n+  public String getArgument() {\n+    return \"\";\n+  }\n+\n+  @Override\n+  public Schema.FieldType getBaseType() {\n+    return Schema.FieldType.row(DATETIME_SCHEMA);\n+  }\n+\n+  @Override\n+  public Row toBaseType(LocalDateTime input) {\n+    return input == null\n+        ? null\n+        : Row.withSchema(DATETIME_SCHEMA)\n+            .addValues(input.toLocalDate().toEpochDay(), input.toLocalTime().toNanoOfDay())\n+            .build();\n+  }\n+\n+  @Override\n+  public LocalDateTime toInputType(Row base) {\n+    return base == null\n+        ? null\n+        : LocalDateTime.of(\n+            LocalDate.ofEpochDay(base.getValue(DATE_FIELD_NAME)),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f8502c8139821d281b766ce7ee8392b465fa856"}, "originalPosition": 80}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTQ5MzczMg==", "bodyText": "That's a great idea. It can also avoid type casting in BeamCalcRel.java. Done.", "url": "https://github.com/apache/beam/pull/12348#discussion_r465493732", "createdAt": "2020-08-05T06:07:06Z", "author": {"login": "ZijieSong946"}, "path": "sdks/java/core/src/main/java/org/apache/beam/sdk/schemas/logicaltypes/DateTime.java", "diffHunk": "@@ -0,0 +1,83 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.apache.beam.sdk.schemas.logicaltypes;\n+\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import org.apache.beam.sdk.schemas.Schema;\n+import org.apache.beam.sdk.values.Row;\n+\n+/**\n+ * A datetime without a time-zone.\n+ *\n+ * <p>It cannot represent an instant on the time-line without additional information such as an\n+ * offset or time-zone.\n+ *\n+ * <p>Its input type is a {@link LocalDateTime}, and base type is a {@link Row} containing Date\n+ * field and Time field. Date field is the same as the base type of {@link Date}, which is a Long\n+ * that represents incrementing count of days where day 0 is 1970-01-01 (ISO). Time field is the\n+ * same as the base type of {@link Time}, which is a Long that represents a count of time in\n+ * nanoseconds.\n+ */\n+public class DateTime implements Schema.LogicalType<LocalDateTime, Row> {\n+  public static final String DATE_FIELD_NAME = \"Date\";\n+  public static final String TIME_FIELD_NAME = \"Time\";\n+  public static final Schema DATETIME_SCHEMA =\n+      Schema.builder().addInt64Field(DATE_FIELD_NAME).addInt64Field(TIME_FIELD_NAME).build();\n+\n+  @Override\n+  public String getIdentifier() {\n+    return \"beam:logical_type:datetime:v1\";\n+  }\n+\n+  // unused\n+  @Override\n+  public Schema.FieldType getArgumentType() {\n+    return Schema.FieldType.STRING;\n+  }\n+\n+  // unused\n+  @Override\n+  public String getArgument() {\n+    return \"\";\n+  }\n+\n+  @Override\n+  public Schema.FieldType getBaseType() {\n+    return Schema.FieldType.row(DATETIME_SCHEMA);\n+  }\n+\n+  @Override\n+  public Row toBaseType(LocalDateTime input) {\n+    return input == null\n+        ? null\n+        : Row.withSchema(DATETIME_SCHEMA)\n+            .addValues(input.toLocalDate().toEpochDay(), input.toLocalTime().toNanoOfDay())\n+            .build();\n+  }\n+\n+  @Override\n+  public LocalDateTime toInputType(Row base) {\n+    return base == null\n+        ? null\n+        : LocalDateTime.of(\n+            LocalDate.ofEpochDay(base.getValue(DATE_FIELD_NAME)),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM1NTcyNA=="}, "originalCommit": {"oid": "3f8502c8139821d281b766ce7ee8392b465fa856"}, "originalPosition": 80}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwNjUwNzk2OnYy", "diffSide": "RIGHT", "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamCalcRel.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQyMjoxMzowNVrOG7zTxg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNVQwNjowNzo0M1rOG77fsw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM1OTgxNA==", "bodyText": "getInt64 returns a Long, so I believe that will allow you to remove the castIfNecessary?", "url": "https://github.com/apache/beam/pull/12348#discussion_r465359814", "createdAt": "2020-08-04T22:13:05Z", "author": {"login": "apilloud"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamCalcRel.java", "diffHunk": "@@ -442,6 +455,20 @@ private static Expression value(Expression value, Schema.FieldType type) {\n               value, Expressions.divide(value, Expressions.constant(NANOS_PER_MILLISECOND)));\n         } else if (SqlTypes.DATE.getIdentifier().equals(logicalId)) {\n           return value;\n+        } else if (SqlTypes.DATETIME.getIdentifier().equals(logicalId)) {\n+          Expression dateValue =\n+              Expressions.call(value, \"getValue\", Expressions.constant(DateTime.DATE_FIELD_NAME));\n+          Expression timeValue =\n+              Expressions.call(value, \"getValue\", Expressions.constant(DateTime.TIME_FIELD_NAME));\n+          Expression returnValue =\n+              Expressions.add(\n+                  Expressions.multiply(\n+                      Types.castIfNecessary(long.class, dateValue),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f8502c8139821d281b766ce7ee8392b465fa856"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM4Nzc1Nw==", "bodyText": "+1. Let's try this.", "url": "https://github.com/apache/beam/pull/12348#discussion_r465387757", "createdAt": "2020-08-04T23:35:30Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamCalcRel.java", "diffHunk": "@@ -442,6 +455,20 @@ private static Expression value(Expression value, Schema.FieldType type) {\n               value, Expressions.divide(value, Expressions.constant(NANOS_PER_MILLISECOND)));\n         } else if (SqlTypes.DATE.getIdentifier().equals(logicalId)) {\n           return value;\n+        } else if (SqlTypes.DATETIME.getIdentifier().equals(logicalId)) {\n+          Expression dateValue =\n+              Expressions.call(value, \"getValue\", Expressions.constant(DateTime.DATE_FIELD_NAME));\n+          Expression timeValue =\n+              Expressions.call(value, \"getValue\", Expressions.constant(DateTime.TIME_FIELD_NAME));\n+          Expression returnValue =\n+              Expressions.add(\n+                  Expressions.multiply(\n+                      Types.castIfNecessary(long.class, dateValue),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM1OTgxNA=="}, "originalCommit": {"oid": "3f8502c8139821d281b766ce7ee8392b465fa856"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTQ5MzkzOQ==", "bodyText": "Done. It's much better now.", "url": "https://github.com/apache/beam/pull/12348#discussion_r465493939", "createdAt": "2020-08-05T06:07:43Z", "author": {"login": "ZijieSong946"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/impl/rel/BeamCalcRel.java", "diffHunk": "@@ -442,6 +455,20 @@ private static Expression value(Expression value, Schema.FieldType type) {\n               value, Expressions.divide(value, Expressions.constant(NANOS_PER_MILLISECOND)));\n         } else if (SqlTypes.DATE.getIdentifier().equals(logicalId)) {\n           return value;\n+        } else if (SqlTypes.DATETIME.getIdentifier().equals(logicalId)) {\n+          Expression dateValue =\n+              Expressions.call(value, \"getValue\", Expressions.constant(DateTime.DATE_FIELD_NAME));\n+          Expression timeValue =\n+              Expressions.call(value, \"getValue\", Expressions.constant(DateTime.TIME_FIELD_NAME));\n+          Expression returnValue =\n+              Expressions.add(\n+                  Expressions.multiply(\n+                      Types.castIfNecessary(long.class, dateValue),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM1OTgxNA=="}, "originalCommit": {"oid": "3f8502c8139821d281b766ce7ee8392b465fa856"}, "originalPosition": 65}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwNjU3ODg4OnYy", "diffSide": "RIGHT", "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/bigquery/BeamBigQuerySqlDialect.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQyMjo0MjowNlrOG7z9Eg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQxNjo1ODo1MVrOG88K0g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM3MDM4Ng==", "bodyText": "I'm not a fan of using replace here. I believe the operand(0) will be a SqlTimestampLiteral? If so, you can call toFormattedString instead: https://github.com/apache/calcite/blob/52a57078ba081b24b9d086ed363c715485d1a519/core/src/main/java/org/apache/calcite/sql/SqlTimestampLiteral.java#L54", "url": "https://github.com/apache/beam/pull/12348#discussion_r465370386", "createdAt": "2020-08-04T22:42:06Z", "author": {"login": "apilloud"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/bigquery/BeamBigQuerySqlDialect.java", "diffHunk": "@@ -253,6 +259,11 @@ private void unparseTrim(SqlWriter writer, SqlCall call, int leftPrec, int right\n     writer.endFunCall(trimFrame);\n   }\n \n+  private void unparseDateTimeLiteralWrapperFunction(\n+      SqlWriter writer, SqlCall call, int leftPrec, int rightPrec) {\n+    writer.literal(call.operand(0).toString().replace(\"TIMESTAMP\", \"DATETIME\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f8502c8139821d281b766ce7ee8392b465fa856"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM4ODc2Mg==", "bodyText": "It's a SqlAbstractDateTimeLiteral, a super class of SqlTimestampLiteral, but we can cast here because we know what the real type is. I am ok with either approach.", "url": "https://github.com/apache/beam/pull/12348#discussion_r465388762", "createdAt": "2020-08-04T23:38:54Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/bigquery/BeamBigQuerySqlDialect.java", "diffHunk": "@@ -253,6 +259,11 @@ private void unparseTrim(SqlWriter writer, SqlCall call, int leftPrec, int right\n     writer.endFunCall(trimFrame);\n   }\n \n+  private void unparseDateTimeLiteralWrapperFunction(\n+      SqlWriter writer, SqlCall call, int leftPrec, int rightPrec) {\n+    writer.literal(call.operand(0).toString().replace(\"TIMESTAMP\", \"DATETIME\"));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM3MDM4Ng=="}, "originalCommit": {"oid": "3f8502c8139821d281b766ce7ee8392b465fa856"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTQ5NDQ4MA==", "bodyText": "Ack.", "url": "https://github.com/apache/beam/pull/12348#discussion_r465494480", "createdAt": "2020-08-05T06:09:13Z", "author": {"login": "ZijieSong946"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/bigquery/BeamBigQuerySqlDialect.java", "diffHunk": "@@ -253,6 +259,11 @@ private void unparseTrim(SqlWriter writer, SqlCall call, int leftPrec, int right\n     writer.endFunCall(trimFrame);\n   }\n \n+  private void unparseDateTimeLiteralWrapperFunction(\n+      SqlWriter writer, SqlCall call, int leftPrec, int rightPrec) {\n+    writer.literal(call.operand(0).toString().replace(\"TIMESTAMP\", \"DATETIME\"));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM3MDM4Ng=="}, "originalCommit": {"oid": "3f8502c8139821d281b766ce7ee8392b465fa856"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjU1MzU1NA==", "bodyText": "Done.", "url": "https://github.com/apache/beam/pull/12348#discussion_r466553554", "createdAt": "2020-08-06T16:58:51Z", "author": {"login": "ZijieSong946"}, "path": "sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/bigquery/BeamBigQuerySqlDialect.java", "diffHunk": "@@ -253,6 +259,11 @@ private void unparseTrim(SqlWriter writer, SqlCall call, int leftPrec, int right\n     writer.endFunCall(trimFrame);\n   }\n \n+  private void unparseDateTimeLiteralWrapperFunction(\n+      SqlWriter writer, SqlCall call, int leftPrec, int rightPrec) {\n+    writer.literal(call.operand(0).toString().replace(\"TIMESTAMP\", \"DATETIME\"));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM3MDM4Ng=="}, "originalCommit": {"oid": "3f8502c8139821d281b766ce7ee8392b465fa856"}, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkwNjYwMjM2OnYy", "diffSide": "RIGHT", "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/translation/ExpressionConverter.java", "isResolved": false, "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNFQyMjo1MjowN1rOG70K7Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wNlQxNjo1OTowMlrOG88LKg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM3MzkzMw==", "bodyText": "Instead of wrapping with a function here, it looks like you can do the same thing by creating a class overloading SqlTimestampLiteral.toString() and wrapping it in BeamSqlUnparseContext? This would reduce the complexity at the Rel layer.\n\n  \n    \n      beam/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/bigquery/BeamSqlUnparseContext.java\n    \n    \n         Line 70\n      in\n      6fdde4f\n    \n    \n    \n    \n\n        \n          \n           if (rex.getKind().equals(SqlKind.LITERAL)) {", "url": "https://github.com/apache/beam/pull/12348#discussion_r465373933", "createdAt": "2020-08-04T22:52:07Z", "author": {"login": "apilloud"}, "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/translation/ExpressionConverter.java", "diffHunk": "@@ -850,6 +848,25 @@ private RexNode convertSimpleValueToRexNode(TypeKind kind, Value value) {\n         // TODO: Doing micro to mills truncation, need to throw exception.\n         ret = rexBuilder().makeLiteral(convertTimeValueToTimeString(value), timeType, false);\n         break;\n+      case TYPE_DATETIME:\n+        // Cannot simply call makeTimestampWithLocalTimeZoneLiteral() for ZetaSQL DATETIME type\n+        // because later it will be unparsed to the string representation of timestamp (e.g. \"SELECT\n+        // DATETIME '2008-12-25 15:30:00'\" will be unparsed to \"SELECT TIMESTAMP '2008-12-25\n+        // 15:30:00:000000'\"). So we create a wrapper function here such that we can later recognize\n+        // it and customize its unparsing in BeamBigQuerySqlDialect.\n+        ret =\n+            rexBuilder()\n+                .makeCall(\n+                    SqlOperators.createZetaSqlFunction(\n+                        BeamBigQuerySqlDialect.DATETIME_LITERAL_FUNCTION,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3f8502c8139821d281b766ce7ee8392b465fa856"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTQ5NDM3NQ==", "bodyText": "Ack. It sounds great. I will try it this way.", "url": "https://github.com/apache/beam/pull/12348#discussion_r465494375", "createdAt": "2020-08-05T06:08:59Z", "author": {"login": "ZijieSong946"}, "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/translation/ExpressionConverter.java", "diffHunk": "@@ -850,6 +848,25 @@ private RexNode convertSimpleValueToRexNode(TypeKind kind, Value value) {\n         // TODO: Doing micro to mills truncation, need to throw exception.\n         ret = rexBuilder().makeLiteral(convertTimeValueToTimeString(value), timeType, false);\n         break;\n+      case TYPE_DATETIME:\n+        // Cannot simply call makeTimestampWithLocalTimeZoneLiteral() for ZetaSQL DATETIME type\n+        // because later it will be unparsed to the string representation of timestamp (e.g. \"SELECT\n+        // DATETIME '2008-12-25 15:30:00'\" will be unparsed to \"SELECT TIMESTAMP '2008-12-25\n+        // 15:30:00:000000'\"). So we create a wrapper function here such that we can later recognize\n+        // it and customize its unparsing in BeamBigQuerySqlDialect.\n+        ret =\n+            rexBuilder()\n+                .makeCall(\n+                    SqlOperators.createZetaSqlFunction(\n+                        BeamBigQuerySqlDialect.DATETIME_LITERAL_FUNCTION,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM3MzkzMw=="}, "originalCommit": {"oid": "3f8502c8139821d281b766ce7ee8392b465fa856"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjExMTcyMA==", "bodyText": "We could not create a class extending SqlTimeStampLiteral because its constructor is private.\nhttps://github.com/apache/calcite/blob/2088488ac8327b19512a76a122cae2961fc551c3/core/src/main/java/org/apache/calcite/sql/SqlTimestampLiteral.java#L34", "url": "https://github.com/apache/beam/pull/12348#discussion_r466111720", "createdAt": "2020-08-06T02:40:05Z", "author": {"login": "ZijieSong946"}, "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/translation/ExpressionConverter.java", "diffHunk": "@@ -850,6 +848,25 @@ private RexNode convertSimpleValueToRexNode(TypeKind kind, Value value) {\n         // TODO: Doing micro to mills truncation, need to throw exception.\n         ret = rexBuilder().makeLiteral(convertTimeValueToTimeString(value), timeType, false);\n         break;\n+      case TYPE_DATETIME:\n+        // Cannot simply call makeTimestampWithLocalTimeZoneLiteral() for ZetaSQL DATETIME type\n+        // because later it will be unparsed to the string representation of timestamp (e.g. \"SELECT\n+        // DATETIME '2008-12-25 15:30:00'\" will be unparsed to \"SELECT TIMESTAMP '2008-12-25\n+        // 15:30:00:000000'\"). So we create a wrapper function here such that we can later recognize\n+        // it and customize its unparsing in BeamBigQuerySqlDialect.\n+        ret =\n+            rexBuilder()\n+                .makeCall(\n+                    SqlOperators.createZetaSqlFunction(\n+                        BeamBigQuerySqlDialect.DATETIME_LITERAL_FUNCTION,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM3MzkzMw=="}, "originalCommit": {"oid": "3f8502c8139821d281b766ce7ee8392b465fa856"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjExOTc3Mg==", "bodyText": "We don't have to extend SqlTimestampLiteral. You can extend SqlLiteral directly, like in \n  \n    \n      beam/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/bigquery/BeamSqlUnparseContext.java\n    \n    \n         Line 95\n      in\n      6fdde4f\n    \n    \n    \n    \n\n        \n          \n           private static class SqlByteStringLiteral extends SqlLiteral {", "url": "https://github.com/apache/beam/pull/12348#discussion_r466119772", "createdAt": "2020-08-06T03:12:38Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/translation/ExpressionConverter.java", "diffHunk": "@@ -850,6 +848,25 @@ private RexNode convertSimpleValueToRexNode(TypeKind kind, Value value) {\n         // TODO: Doing micro to mills truncation, need to throw exception.\n         ret = rexBuilder().makeLiteral(convertTimeValueToTimeString(value), timeType, false);\n         break;\n+      case TYPE_DATETIME:\n+        // Cannot simply call makeTimestampWithLocalTimeZoneLiteral() for ZetaSQL DATETIME type\n+        // because later it will be unparsed to the string representation of timestamp (e.g. \"SELECT\n+        // DATETIME '2008-12-25 15:30:00'\" will be unparsed to \"SELECT TIMESTAMP '2008-12-25\n+        // 15:30:00:000000'\"). So we create a wrapper function here such that we can later recognize\n+        // it and customize its unparsing in BeamBigQuerySqlDialect.\n+        ret =\n+            rexBuilder()\n+                .makeCall(\n+                    SqlOperators.createZetaSqlFunction(\n+                        BeamBigQuerySqlDialect.DATETIME_LITERAL_FUNCTION,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM3MzkzMw=="}, "originalCommit": {"oid": "3f8502c8139821d281b766ce7ee8392b465fa856"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjEyMjQ4Mg==", "bodyText": "To make it clearer, you can get the TimestampString value from the RexLiteral like \n  \n    \n      beam/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/bigquery/BeamSqlUnparseContext.java\n    \n    \n         Line 74\n      in\n      6fdde4f\n    \n    \n    \n    \n\n        \n          \n           ByteString byteString = literal.getValueAs(ByteString.class); \n        \n    \n  \n\n, and then use it to create your own SqlDateTimeLiteral.", "url": "https://github.com/apache/beam/pull/12348#discussion_r466122482", "createdAt": "2020-08-06T03:23:39Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/translation/ExpressionConverter.java", "diffHunk": "@@ -850,6 +848,25 @@ private RexNode convertSimpleValueToRexNode(TypeKind kind, Value value) {\n         // TODO: Doing micro to mills truncation, need to throw exception.\n         ret = rexBuilder().makeLiteral(convertTimeValueToTimeString(value), timeType, false);\n         break;\n+      case TYPE_DATETIME:\n+        // Cannot simply call makeTimestampWithLocalTimeZoneLiteral() for ZetaSQL DATETIME type\n+        // because later it will be unparsed to the string representation of timestamp (e.g. \"SELECT\n+        // DATETIME '2008-12-25 15:30:00'\" will be unparsed to \"SELECT TIMESTAMP '2008-12-25\n+        // 15:30:00:000000'\"). So we create a wrapper function here such that we can later recognize\n+        // it and customize its unparsing in BeamBigQuerySqlDialect.\n+        ret =\n+            rexBuilder()\n+                .makeCall(\n+                    SqlOperators.createZetaSqlFunction(\n+                        BeamBigQuerySqlDialect.DATETIME_LITERAL_FUNCTION,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM3MzkzMw=="}, "originalCommit": {"oid": "3f8502c8139821d281b766ce7ee8392b465fa856"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjE3NTg0MQ==", "bodyText": "It's wired that the override toString() has never been called.", "url": "https://github.com/apache/beam/pull/12348#discussion_r466175841", "createdAt": "2020-08-06T06:34:40Z", "author": {"login": "ZijieSong946"}, "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/translation/ExpressionConverter.java", "diffHunk": "@@ -850,6 +848,25 @@ private RexNode convertSimpleValueToRexNode(TypeKind kind, Value value) {\n         // TODO: Doing micro to mills truncation, need to throw exception.\n         ret = rexBuilder().makeLiteral(convertTimeValueToTimeString(value), timeType, false);\n         break;\n+      case TYPE_DATETIME:\n+        // Cannot simply call makeTimestampWithLocalTimeZoneLiteral() for ZetaSQL DATETIME type\n+        // because later it will be unparsed to the string representation of timestamp (e.g. \"SELECT\n+        // DATETIME '2008-12-25 15:30:00'\" will be unparsed to \"SELECT TIMESTAMP '2008-12-25\n+        // 15:30:00:000000'\"). So we create a wrapper function here such that we can later recognize\n+        // it and customize its unparsing in BeamBigQuerySqlDialect.\n+        ret =\n+            rexBuilder()\n+                .makeCall(\n+                    SqlOperators.createZetaSqlFunction(\n+                        BeamBigQuerySqlDialect.DATETIME_LITERAL_FUNCTION,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM3MzkzMw=="}, "originalCommit": {"oid": "3f8502c8139821d281b766ce7ee8392b465fa856"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjE4ODYxMw==", "bodyText": "We do not expect toString() to be called. You need to override unparse().\nYou can look at other similar overriding classes in that file and see how it works. Like \n  \n    \n      beam/sdks/java/extensions/sql/src/main/java/org/apache/beam/sdk/extensions/sql/meta/provider/bigquery/BeamSqlUnparseContext.java\n    \n    \n         Line 107\n      in\n      6fdde4f\n    \n    \n    \n    \n\n        \n          \n           public void unparse(SqlWriter writer, int leftPrec, int rightPrec) {", "url": "https://github.com/apache/beam/pull/12348#discussion_r466188613", "createdAt": "2020-08-06T07:04:24Z", "author": {"login": "robinyqiu"}, "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/translation/ExpressionConverter.java", "diffHunk": "@@ -850,6 +848,25 @@ private RexNode convertSimpleValueToRexNode(TypeKind kind, Value value) {\n         // TODO: Doing micro to mills truncation, need to throw exception.\n         ret = rexBuilder().makeLiteral(convertTimeValueToTimeString(value), timeType, false);\n         break;\n+      case TYPE_DATETIME:\n+        // Cannot simply call makeTimestampWithLocalTimeZoneLiteral() for ZetaSQL DATETIME type\n+        // because later it will be unparsed to the string representation of timestamp (e.g. \"SELECT\n+        // DATETIME '2008-12-25 15:30:00'\" will be unparsed to \"SELECT TIMESTAMP '2008-12-25\n+        // 15:30:00:000000'\"). So we create a wrapper function here such that we can later recognize\n+        // it and customize its unparsing in BeamBigQuerySqlDialect.\n+        ret =\n+            rexBuilder()\n+                .makeCall(\n+                    SqlOperators.createZetaSqlFunction(\n+                        BeamBigQuerySqlDialect.DATETIME_LITERAL_FUNCTION,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM3MzkzMw=="}, "originalCommit": {"oid": "3f8502c8139821d281b766ce7ee8392b465fa856"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NjU1MzY0Mg==", "bodyText": "Got it. Done.", "url": "https://github.com/apache/beam/pull/12348#discussion_r466553642", "createdAt": "2020-08-06T16:59:02Z", "author": {"login": "ZijieSong946"}, "path": "sdks/java/extensions/sql/zetasql/src/main/java/org/apache/beam/sdk/extensions/sql/zetasql/translation/ExpressionConverter.java", "diffHunk": "@@ -850,6 +848,25 @@ private RexNode convertSimpleValueToRexNode(TypeKind kind, Value value) {\n         // TODO: Doing micro to mills truncation, need to throw exception.\n         ret = rexBuilder().makeLiteral(convertTimeValueToTimeString(value), timeType, false);\n         break;\n+      case TYPE_DATETIME:\n+        // Cannot simply call makeTimestampWithLocalTimeZoneLiteral() for ZetaSQL DATETIME type\n+        // because later it will be unparsed to the string representation of timestamp (e.g. \"SELECT\n+        // DATETIME '2008-12-25 15:30:00'\" will be unparsed to \"SELECT TIMESTAMP '2008-12-25\n+        // 15:30:00:000000'\"). So we create a wrapper function here such that we can later recognize\n+        // it and customize its unparsing in BeamBigQuerySqlDialect.\n+        ret =\n+            rexBuilder()\n+                .makeCall(\n+                    SqlOperators.createZetaSqlFunction(\n+                        BeamBigQuerySqlDialect.DATETIME_LITERAL_FUNCTION,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NTM3MzkzMw=="}, "originalCommit": {"oid": "3f8502c8139821d281b766ce7ee8392b465fa856"}, "originalPosition": 69}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 922, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}