{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDMyNzU0NDk1", "number": 11980, "reviewThreads": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQyMDoyNjo1MVrOEYm5Ag==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQxNjowNjowN1rOEZjUcg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk0MjM4NDY2OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/convert.py", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQyMDoyNjo1MVrOHBCZ5Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQyMDoyNjo1MVrOHBCZ5Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1MDAyMQ==", "bodyText": "Woo hoo!", "url": "https://github.com/apache/beam/pull/11980#discussion_r470850021", "createdAt": "2020-08-14T20:26:51Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/convert.py", "diffHunk": "@@ -36,7 +37,7 @@\n # TODO: Or should this be called as_dataframe?\n def to_dataframe(\n     pcoll,  # type: pvalue.PCollection\n-    proxy,  # type: pandas.core.generic.NDFrame\n+    proxy=None,  # type: pandas.core.generic.NDFrame", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk0MjM5NzUyOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/schemas.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQyMDozMTo1OFrOHBChsQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQxNjowMTo1NVrOHCbaeg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1MjAxNw==", "bodyText": "Rather than subclassing, it would probably be cleaner to make this just a PTransform whose expand method returns\n`pcoll | BatchElements(...) | Pardo(...)`.\n\nIf you want to accept all the parameter from BatchElements, you could construct the BatchElements instance in your constructor.", "url": "https://github.com/apache/beam/pull/11980#discussion_r470852017", "createdAt": "2020-08-14T20:31:58Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/schemas.py", "diffHunk": "@@ -0,0 +1,82 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Utilities for relating schema-aware PCollections and dataframe transforms.\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+from typing import NamedTuple\n+from typing import TypeVar\n+\n+import pandas as pd\n+\n+from apache_beam import typehints\n+from apache_beam.transforms.core import DoFn\n+from apache_beam.transforms.core import ParDo\n+from apache_beam.transforms.util import BatchElements\n+from apache_beam.typehints.schemas import named_fields_from_element_type\n+\n+__all__ = ('BatchRowsAsDataFrame', 'generate_proxy')\n+\n+T = TypeVar('T', bound=NamedTuple)\n+\n+\n+@typehints.with_input_types(T)\n+@typehints.with_output_types(pd.DataFrame)\n+class BatchRowsAsDataFrame(BatchElements):\n+  \"\"\"A transform that batches schema-aware PCollection elements into DataFrames\n+\n+  Batching parameters are inherited from\n+  :class:`~apache_beam.transforms.util.BatchElements`.\n+  \"\"\"\n+  def __init__(self, *args, **kwargs):\n+    super(BatchRowsAsDataFrame, self).__init__(*args, **kwargs)\n+    self._batch_elements_transform = BatchElements(*args, **kwargs)\n+\n+  def expand(self, pcoll):\n+    return super(BatchRowsAsDataFrame, self).expand(pcoll) | ParDo(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539"}, "originalPosition": 54}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjMwODM0Ng==", "bodyText": "Done! Looks like I actually started to do it that way with the unused self._batch_elements_transform but then changed my mind", "url": "https://github.com/apache/beam/pull/11980#discussion_r472308346", "createdAt": "2020-08-18T16:01:55Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/schemas.py", "diffHunk": "@@ -0,0 +1,82 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Utilities for relating schema-aware PCollections and dataframe transforms.\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+from typing import NamedTuple\n+from typing import TypeVar\n+\n+import pandas as pd\n+\n+from apache_beam import typehints\n+from apache_beam.transforms.core import DoFn\n+from apache_beam.transforms.core import ParDo\n+from apache_beam.transforms.util import BatchElements\n+from apache_beam.typehints.schemas import named_fields_from_element_type\n+\n+__all__ = ('BatchRowsAsDataFrame', 'generate_proxy')\n+\n+T = TypeVar('T', bound=NamedTuple)\n+\n+\n+@typehints.with_input_types(T)\n+@typehints.with_output_types(pd.DataFrame)\n+class BatchRowsAsDataFrame(BatchElements):\n+  \"\"\"A transform that batches schema-aware PCollection elements into DataFrames\n+\n+  Batching parameters are inherited from\n+  :class:`~apache_beam.transforms.util.BatchElements`.\n+  \"\"\"\n+  def __init__(self, *args, **kwargs):\n+    super(BatchRowsAsDataFrame, self).__init__(*args, **kwargs)\n+    self._batch_elements_transform = BatchElements(*args, **kwargs)\n+\n+  def expand(self, pcoll):\n+    return super(BatchRowsAsDataFrame, self).expand(pcoll) | ParDo(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1MjAxNw=="}, "originalCommit": {"oid": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539"}, "originalPosition": 54}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk0MjQwMTU5OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/schemas.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQyMDozMzo0OVrOHBCkZA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQxNjowMDo0OVrOHCbXpQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1MjcwOA==", "bodyText": "Rather than letting this be a full DoFn, you could just let columns be a local variable in the map above, and then write\n... | Map(lambda batch: pd.DataFrame.from_records(batch, columns))", "url": "https://github.com/apache/beam/pull/11980#discussion_r470852708", "createdAt": "2020-08-14T20:33:49Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/schemas.py", "diffHunk": "@@ -0,0 +1,82 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Utilities for relating schema-aware PCollections and dataframe transforms.\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+from typing import NamedTuple\n+from typing import TypeVar\n+\n+import pandas as pd\n+\n+from apache_beam import typehints\n+from apache_beam.transforms.core import DoFn\n+from apache_beam.transforms.core import ParDo\n+from apache_beam.transforms.util import BatchElements\n+from apache_beam.typehints.schemas import named_fields_from_element_type\n+\n+__all__ = ('BatchRowsAsDataFrame', 'generate_proxy')\n+\n+T = TypeVar('T', bound=NamedTuple)\n+\n+\n+@typehints.with_input_types(T)\n+@typehints.with_output_types(pd.DataFrame)\n+class BatchRowsAsDataFrame(BatchElements):\n+  \"\"\"A transform that batches schema-aware PCollection elements into DataFrames\n+\n+  Batching parameters are inherited from\n+  :class:`~apache_beam.transforms.util.BatchElements`.\n+  \"\"\"\n+  def __init__(self, *args, **kwargs):\n+    super(BatchRowsAsDataFrame, self).__init__(*args, **kwargs)\n+    self._batch_elements_transform = BatchElements(*args, **kwargs)\n+\n+  def expand(self, pcoll):\n+    return super(BatchRowsAsDataFrame, self).expand(pcoll) | ParDo(\n+        _RowBatchToDataFrameDoFn(pcoll.element_type))\n+\n+\n+class _RowBatchToDataFrameDoFn(DoFn):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539"}, "originalPosition": 58}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjMwNzYyMQ==", "bodyText": "Done", "url": "https://github.com/apache/beam/pull/11980#discussion_r472307621", "createdAt": "2020-08-18T16:00:49Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/schemas.py", "diffHunk": "@@ -0,0 +1,82 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Utilities for relating schema-aware PCollections and dataframe transforms.\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+from typing import NamedTuple\n+from typing import TypeVar\n+\n+import pandas as pd\n+\n+from apache_beam import typehints\n+from apache_beam.transforms.core import DoFn\n+from apache_beam.transforms.core import ParDo\n+from apache_beam.transforms.util import BatchElements\n+from apache_beam.typehints.schemas import named_fields_from_element_type\n+\n+__all__ = ('BatchRowsAsDataFrame', 'generate_proxy')\n+\n+T = TypeVar('T', bound=NamedTuple)\n+\n+\n+@typehints.with_input_types(T)\n+@typehints.with_output_types(pd.DataFrame)\n+class BatchRowsAsDataFrame(BatchElements):\n+  \"\"\"A transform that batches schema-aware PCollection elements into DataFrames\n+\n+  Batching parameters are inherited from\n+  :class:`~apache_beam.transforms.util.BatchElements`.\n+  \"\"\"\n+  def __init__(self, *args, **kwargs):\n+    super(BatchRowsAsDataFrame, self).__init__(*args, **kwargs)\n+    self._batch_elements_transform = BatchElements(*args, **kwargs)\n+\n+  def expand(self, pcoll):\n+    return super(BatchRowsAsDataFrame, self).expand(pcoll) | ParDo(\n+        _RowBatchToDataFrameDoFn(pcoll.element_type))\n+\n+\n+class _RowBatchToDataFrameDoFn(DoFn):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1MjcwOA=="}, "originalCommit": {"oid": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539"}, "originalPosition": 58}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk0MjQwNzA5OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/schemas.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQyMDozNjowNVrOHBCnvw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQxNjowMjowMlrOHCbavA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1MzU2Nw==", "bodyText": "Nit. We typically have the style of importing modules, and then using qualified names (which results in less churn and makes it a bit easier to figure out where things come from). Instead of core, it's typical to do import apache_beam as beam and use beam.DoFn, etc.", "url": "https://github.com/apache/beam/pull/11980#discussion_r470853567", "createdAt": "2020-08-14T20:36:05Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/schemas.py", "diffHunk": "@@ -0,0 +1,82 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Utilities for relating schema-aware PCollections and dataframe transforms.\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+from typing import NamedTuple\n+from typing import TypeVar\n+\n+import pandas as pd\n+\n+from apache_beam import typehints\n+from apache_beam.transforms.core import DoFn", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjMwODQxMg==", "bodyText": "Done", "url": "https://github.com/apache/beam/pull/11980#discussion_r472308412", "createdAt": "2020-08-18T16:02:02Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/schemas.py", "diffHunk": "@@ -0,0 +1,82 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Utilities for relating schema-aware PCollections and dataframe transforms.\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+from typing import NamedTuple\n+from typing import TypeVar\n+\n+import pandas as pd\n+\n+from apache_beam import typehints\n+from apache_beam.transforms.core import DoFn", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1MzU2Nw=="}, "originalCommit": {"oid": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk0MjQxMDkxOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/schemas_test.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQyMDozNzo1M1rOHBCqMQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QyMzoyNToxNVrOHB-Fsw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1NDE5Mw==", "bodyText": "Can we get rid of this one too? (Or at least drop a TODO to do it in a subsequent PR?)", "url": "https://github.com/apache/beam/pull/11980#discussion_r470854193", "createdAt": "2020-08-14T20:37:53Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/schemas_test.py", "diffHunk": "@@ -0,0 +1,110 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Tests for schemas.\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import unittest\n+from typing import NamedTuple\n+\n+import future.tests.base  # pylint: disable=unused-import\n+# patches unittest.testcase to be python3 compatible\n+import pandas as pd\n+from past.builtins import unicode\n+\n+import apache_beam as beam\n+from apache_beam.coders import RowCoder\n+from apache_beam.coders.typecoders import registry as coders_registry\n+from apache_beam.dataframe import schemas\n+from apache_beam.dataframe import transforms\n+from apache_beam.testing.test_pipeline import TestPipeline\n+from apache_beam.testing.util import assert_that\n+\n+Simple = NamedTuple(\n+    'Simple', [('name', unicode), ('id', int), ('height', float)])\n+coders_registry.register_coder(Simple, RowCoder)\n+Animal = NamedTuple('Animal', [('animal', unicode), ('max_speed', float)])\n+coders_registry.register_coder(Animal, RowCoder)\n+\n+\n+def matches_df(expected):\n+  def check_df_pcoll_equal(actual):\n+    actual = pd.concat(actual)\n+    sorted_actual = actual.sort_values(by=list(actual.columns)).reset_index(\n+        drop=True)\n+    sorted_expected = expected.sort_values(\n+        by=list(expected.columns)).reset_index(drop=True)\n+    if not sorted_actual.equals(sorted_expected):\n+      raise AssertionError(\n+          'Dataframes not equal: \\n\\nActual:\\n%s\\n\\nExpected:\\n%s' %\n+          (sorted_actual, sorted_expected))\n+\n+  return check_df_pcoll_equal\n+\n+\n+class SchemasTest(unittest.TestCase):\n+  def test_simple_df(self):\n+    expected = pd.DataFrame({\n+        'name': list(unicode(i) for i in range(5)),\n+        'id': list(range(5)),\n+        'height': list(float(i) for i in range(5))\n+    },\n+                            columns=['name', 'id', 'height'])\n+\n+    with TestPipeline() as p:\n+      res = (\n+          p\n+          | beam.Create([\n+              Simple(name=unicode(i), id=i, height=float(i)) for i in range(5)\n+          ])\n+          | schemas.BatchRowsAsDataFrame(min_batch_size=10, max_batch_size=10))\n+      assert_that(res, matches_df(expected))\n+\n+  def test_generate_proxy(self):\n+    expected = pd.DataFrame({\n+        'animal': pd.Series(dtype=unicode), 'max_speed': pd.Series(dtype=float)\n+    })\n+\n+    self.assertTrue(schemas.generate_proxy(Animal).equals(expected))\n+\n+  def test_batch_with_df_transform(self):\n+    with TestPipeline() as p:\n+      res = (\n+          p\n+          | beam.Create([\n+              Animal('Falcon', 380.0),\n+              Animal('Falcon', 370.0),\n+              Animal('Parrot', 24.0),\n+              Animal('Parrot', 26.0)\n+          ])\n+          | schemas.BatchRowsAsDataFrame()\n+          | transforms.DataframeTransform(\n+              lambda df: df.groupby('animal').mean(),\n+              proxy=schemas.generate_proxy(Animal)))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539"}, "originalPosition": 100}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTgyNzg5MQ==", "bodyText": "Added a TODO for now. I guess we'd need to store some type information on a PCollection[DataFrame], should we just store a proxy object when we know it?", "url": "https://github.com/apache/beam/pull/11980#discussion_r471827891", "createdAt": "2020-08-17T23:25:15Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/schemas_test.py", "diffHunk": "@@ -0,0 +1,110 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Tests for schemas.\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import unittest\n+from typing import NamedTuple\n+\n+import future.tests.base  # pylint: disable=unused-import\n+# patches unittest.testcase to be python3 compatible\n+import pandas as pd\n+from past.builtins import unicode\n+\n+import apache_beam as beam\n+from apache_beam.coders import RowCoder\n+from apache_beam.coders.typecoders import registry as coders_registry\n+from apache_beam.dataframe import schemas\n+from apache_beam.dataframe import transforms\n+from apache_beam.testing.test_pipeline import TestPipeline\n+from apache_beam.testing.util import assert_that\n+\n+Simple = NamedTuple(\n+    'Simple', [('name', unicode), ('id', int), ('height', float)])\n+coders_registry.register_coder(Simple, RowCoder)\n+Animal = NamedTuple('Animal', [('animal', unicode), ('max_speed', float)])\n+coders_registry.register_coder(Animal, RowCoder)\n+\n+\n+def matches_df(expected):\n+  def check_df_pcoll_equal(actual):\n+    actual = pd.concat(actual)\n+    sorted_actual = actual.sort_values(by=list(actual.columns)).reset_index(\n+        drop=True)\n+    sorted_expected = expected.sort_values(\n+        by=list(expected.columns)).reset_index(drop=True)\n+    if not sorted_actual.equals(sorted_expected):\n+      raise AssertionError(\n+          'Dataframes not equal: \\n\\nActual:\\n%s\\n\\nExpected:\\n%s' %\n+          (sorted_actual, sorted_expected))\n+\n+  return check_df_pcoll_equal\n+\n+\n+class SchemasTest(unittest.TestCase):\n+  def test_simple_df(self):\n+    expected = pd.DataFrame({\n+        'name': list(unicode(i) for i in range(5)),\n+        'id': list(range(5)),\n+        'height': list(float(i) for i in range(5))\n+    },\n+                            columns=['name', 'id', 'height'])\n+\n+    with TestPipeline() as p:\n+      res = (\n+          p\n+          | beam.Create([\n+              Simple(name=unicode(i), id=i, height=float(i)) for i in range(5)\n+          ])\n+          | schemas.BatchRowsAsDataFrame(min_batch_size=10, max_batch_size=10))\n+      assert_that(res, matches_df(expected))\n+\n+  def test_generate_proxy(self):\n+    expected = pd.DataFrame({\n+        'animal': pd.Series(dtype=unicode), 'max_speed': pd.Series(dtype=float)\n+    })\n+\n+    self.assertTrue(schemas.generate_proxy(Animal).equals(expected))\n+\n+  def test_batch_with_df_transform(self):\n+    with TestPipeline() as p:\n+      res = (\n+          p\n+          | beam.Create([\n+              Animal('Falcon', 380.0),\n+              Animal('Falcon', 370.0),\n+              Animal('Parrot', 24.0),\n+              Animal('Parrot', 26.0)\n+          ])\n+          | schemas.BatchRowsAsDataFrame()\n+          | transforms.DataframeTransform(\n+              lambda df: df.groupby('animal').mean(),\n+              proxy=schemas.generate_proxy(Animal)))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1NDE5Mw=="}, "originalCommit": {"oid": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539"}, "originalPosition": 100}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk0MjQxMjUzOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/schemas_test.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQyMDozODozMFrOHBCrIQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQxNjowMjoxM1rOHCbbNw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1NDQzMw==", "bodyText": "Maybe do a test using to_dataframe?", "url": "https://github.com/apache/beam/pull/11980#discussion_r470854433", "createdAt": "2020-08-14T20:38:30Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/schemas_test.py", "diffHunk": "@@ -0,0 +1,110 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Tests for schemas.\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import unittest\n+from typing import NamedTuple\n+\n+import future.tests.base  # pylint: disable=unused-import\n+# patches unittest.testcase to be python3 compatible\n+import pandas as pd\n+from past.builtins import unicode\n+\n+import apache_beam as beam\n+from apache_beam.coders import RowCoder\n+from apache_beam.coders.typecoders import registry as coders_registry\n+from apache_beam.dataframe import schemas\n+from apache_beam.dataframe import transforms\n+from apache_beam.testing.test_pipeline import TestPipeline\n+from apache_beam.testing.util import assert_that\n+\n+Simple = NamedTuple(\n+    'Simple', [('name', unicode), ('id', int), ('height', float)])\n+coders_registry.register_coder(Simple, RowCoder)\n+Animal = NamedTuple('Animal', [('animal', unicode), ('max_speed', float)])\n+coders_registry.register_coder(Animal, RowCoder)\n+\n+\n+def matches_df(expected):\n+  def check_df_pcoll_equal(actual):\n+    actual = pd.concat(actual)\n+    sorted_actual = actual.sort_values(by=list(actual.columns)).reset_index(\n+        drop=True)\n+    sorted_expected = expected.sort_values(\n+        by=list(expected.columns)).reset_index(drop=True)\n+    if not sorted_actual.equals(sorted_expected):\n+      raise AssertionError(\n+          'Dataframes not equal: \\n\\nActual:\\n%s\\n\\nExpected:\\n%s' %\n+          (sorted_actual, sorted_expected))\n+\n+  return check_df_pcoll_equal\n+\n+\n+class SchemasTest(unittest.TestCase):\n+  def test_simple_df(self):\n+    expected = pd.DataFrame({\n+        'name': list(unicode(i) for i in range(5)),\n+        'id': list(range(5)),\n+        'height': list(float(i) for i in range(5))\n+    },\n+                            columns=['name', 'id', 'height'])\n+\n+    with TestPipeline() as p:\n+      res = (\n+          p\n+          | beam.Create([\n+              Simple(name=unicode(i), id=i, height=float(i)) for i in range(5)\n+          ])\n+          | schemas.BatchRowsAsDataFrame(min_batch_size=10, max_batch_size=10))\n+      assert_that(res, matches_df(expected))\n+\n+  def test_generate_proxy(self):\n+    expected = pd.DataFrame({\n+        'animal': pd.Series(dtype=unicode), 'max_speed': pd.Series(dtype=float)\n+    })\n+\n+    self.assertTrue(schemas.generate_proxy(Animal).equals(expected))\n+\n+  def test_batch_with_df_transform(self):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539"}, "originalPosition": 87}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjMwODUzNQ==", "bodyText": "I added a test using to_dataframe in transforms_test: test_batching_beam_row_to_dataframe.\nI intended for these tests to just test schemas.py, while transforms_test verifies the integration with DataframeTransform. The one below was a stepping stone to integrating, we could even remove it now.", "url": "https://github.com/apache/beam/pull/11980#discussion_r472308535", "createdAt": "2020-08-18T16:02:13Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/schemas_test.py", "diffHunk": "@@ -0,0 +1,110 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Tests for schemas.\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import unittest\n+from typing import NamedTuple\n+\n+import future.tests.base  # pylint: disable=unused-import\n+# patches unittest.testcase to be python3 compatible\n+import pandas as pd\n+from past.builtins import unicode\n+\n+import apache_beam as beam\n+from apache_beam.coders import RowCoder\n+from apache_beam.coders.typecoders import registry as coders_registry\n+from apache_beam.dataframe import schemas\n+from apache_beam.dataframe import transforms\n+from apache_beam.testing.test_pipeline import TestPipeline\n+from apache_beam.testing.util import assert_that\n+\n+Simple = NamedTuple(\n+    'Simple', [('name', unicode), ('id', int), ('height', float)])\n+coders_registry.register_coder(Simple, RowCoder)\n+Animal = NamedTuple('Animal', [('animal', unicode), ('max_speed', float)])\n+coders_registry.register_coder(Animal, RowCoder)\n+\n+\n+def matches_df(expected):\n+  def check_df_pcoll_equal(actual):\n+    actual = pd.concat(actual)\n+    sorted_actual = actual.sort_values(by=list(actual.columns)).reset_index(\n+        drop=True)\n+    sorted_expected = expected.sort_values(\n+        by=list(expected.columns)).reset_index(drop=True)\n+    if not sorted_actual.equals(sorted_expected):\n+      raise AssertionError(\n+          'Dataframes not equal: \\n\\nActual:\\n%s\\n\\nExpected:\\n%s' %\n+          (sorted_actual, sorted_expected))\n+\n+  return check_df_pcoll_equal\n+\n+\n+class SchemasTest(unittest.TestCase):\n+  def test_simple_df(self):\n+    expected = pd.DataFrame({\n+        'name': list(unicode(i) for i in range(5)),\n+        'id': list(range(5)),\n+        'height': list(float(i) for i in range(5))\n+    },\n+                            columns=['name', 'id', 'height'])\n+\n+    with TestPipeline() as p:\n+      res = (\n+          p\n+          | beam.Create([\n+              Simple(name=unicode(i), id=i, height=float(i)) for i in range(5)\n+          ])\n+          | schemas.BatchRowsAsDataFrame(min_batch_size=10, max_batch_size=10))\n+      assert_that(res, matches_df(expected))\n+\n+  def test_generate_proxy(self):\n+    expected = pd.DataFrame({\n+        'animal': pd.Series(dtype=unicode), 'max_speed': pd.Series(dtype=float)\n+    })\n+\n+    self.assertTrue(schemas.generate_proxy(Animal).equals(expected))\n+\n+  def test_batch_with_df_transform(self):", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1NDQzMw=="}, "originalCommit": {"oid": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539"}, "originalPosition": 87}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk0MjQzNTQ1OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/transforms_test.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQyMDo0ODoxMlrOHBC49g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQxNjowNzoxN1rOHCbn_g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1Nzk3NA==", "bodyText": "This threw me because I was expecting the result to be ['Aardvark', 'Ant']. I see now that it's filtering down to the column names that start with A, but perhaps the filter could be written a bit differently to make it more obvious (e.g. filter on the values, let the regex be 'Anim*', or use another operation).", "url": "https://github.com/apache/beam/pull/11980#discussion_r470857974", "createdAt": "2020-08-14T20:48:12Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/dataframe/transforms_test.py", "diffHunk": "@@ -112,6 +133,64 @@ def test_scalar(self):\n       self.run_scenario(\n           df, lambda df: df.groupby('key').sum().val / df.val.agg(sum))\n \n+  def test_batching_named_tuple_input(self):\n+    with beam.Pipeline() as p:\n+      result = (\n+          p | beam.Create([\n+              AnimalSpeed('Aardvark', 5),\n+              AnimalSpeed('Ant', 2),\n+              AnimalSpeed('Elephant', 35),\n+              AnimalSpeed('Zebra', 40)\n+          ]).with_output_types(AnimalSpeed)\n+          | transforms.DataframeTransform(lambda df: df.filter(regex='A.*')))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539"}, "originalPosition": 123}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjMxMTgwNg==", "bodyText": "You and me both :) I just reused the operation from test_filter above. Changed it to Anim.* in both places", "url": "https://github.com/apache/beam/pull/11980#discussion_r472311806", "createdAt": "2020-08-18T16:07:17Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/transforms_test.py", "diffHunk": "@@ -112,6 +133,64 @@ def test_scalar(self):\n       self.run_scenario(\n           df, lambda df: df.groupby('key').sum().val / df.val.agg(sum))\n \n+  def test_batching_named_tuple_input(self):\n+    with beam.Pipeline() as p:\n+      result = (\n+          p | beam.Create([\n+              AnimalSpeed('Aardvark', 5),\n+              AnimalSpeed('Ant', 2),\n+              AnimalSpeed('Elephant', 35),\n+              AnimalSpeed('Zebra', 40)\n+          ]).with_output_types(AnimalSpeed)\n+          | transforms.DataframeTransform(lambda df: df.filter(regex='A.*')))", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1Nzk3NA=="}, "originalCommit": {"oid": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539"}, "originalPosition": 123}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk0MjQ0MDg4OnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/pvalue.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQyMDo1MDoyMlrOHBC8MQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQxNjoxMjoyOFrOHCb0rQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1ODgwMQ==", "bodyText": "Or a type constraint. (Not all our type hints are types.)", "url": "https://github.com/apache/beam/pull/11980#discussion_r470858801", "createdAt": "2020-08-14T20:50:22Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/pvalue.py", "diffHunk": "@@ -88,7 +88,7 @@ class PValue(object):\n   def __init__(self,\n                pipeline,  # type: Pipeline\n                tag=None,  # type: Optional[str]\n-               element_type=None,  # type: Optional[object]\n+               element_type=None,  # type: Optional[type]", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjMxNTA1Mw==", "bodyText": "Done", "url": "https://github.com/apache/beam/pull/11980#discussion_r472315053", "createdAt": "2020-08-18T16:12:28Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/pvalue.py", "diffHunk": "@@ -88,7 +88,7 @@ class PValue(object):\n   def __init__(self,\n                pipeline,  # type: Pipeline\n                tag=None,  # type: Optional[str]\n-               element_type=None,  # type: Optional[object]\n+               element_type=None,  # type: Optional[type]", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1ODgwMQ=="}, "originalCommit": {"oid": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk0MjQ0MjYxOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/typehints/schemas.py", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQyMDo1MDo1OFrOHBC9MQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQwMDo0NToxMFrOHB_dCg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1OTA1Nw==", "bodyText": "Is this worth a JIRA?", "url": "https://github.com/apache/beam/pull/11980#discussion_r470859057", "createdAt": "2020-08-14T20:50:58Z", "author": {"login": "robertwb"}, "path": "sdks/python/apache_beam/typehints/schemas.py", "diffHunk": "@@ -251,3 +258,23 @@ def named_tuple_from_schema(schema):\n \n def named_tuple_to_schema(named_tuple):\n   return typing_to_runner_api(named_tuple).row_type.schema\n+\n+\n+def schema_from_element_type(element_type):  # (type) -> schema_pb2.Schema\n+  \"\"\"Get a schema for the given PCollection element_type.\n+\n+  Returns schema as a list of (name, python_type) tuples\"\"\"\n+  if isinstance(element_type, row_type.RowTypeConstraint):\n+    # TODO: Make sure beam.Row generated schemas are registered and de-duped", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTg1MDI1MA==", "bodyText": "Filed BEAM-10722 for this", "url": "https://github.com/apache/beam/pull/11980#discussion_r471850250", "createdAt": "2020-08-18T00:45:10Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/typehints/schemas.py", "diffHunk": "@@ -251,3 +258,23 @@ def named_tuple_from_schema(schema):\n \n def named_tuple_to_schema(named_tuple):\n   return typing_to_runner_api(named_tuple).row_type.schema\n+\n+\n+def schema_from_element_type(element_type):  # (type) -> schema_pb2.Schema\n+  \"\"\"Get a schema for the given PCollection element_type.\n+\n+  Returns schema as a list of (name, python_type) tuples\"\"\"\n+  if isinstance(element_type, row_type.RowTypeConstraint):\n+    # TODO: Make sure beam.Row generated schemas are registered and de-duped", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDg1OTA1Nw=="}, "originalCommit": {"oid": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539"}, "originalPosition": 32}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk1MjI4NTMwOnYy", "diffSide": "RIGHT", "path": "sdks/python/apache_beam/dataframe/transforms_test.py", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQxNjowNjowN1rOHCbk7w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQxNjowNjowN1rOHCbk7w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjMxMTAyMw==", "bodyText": "Note there's actually a diff here from the original check_correct. It sorts by value and resets the index rather than sorting by index.  I had to do this because the concatenated indices of the batches (e.g. [0,1,2,0,1,0,]) wouldn't match the index in my expected df (e.g. [0,1,2,3,4,5]).", "url": "https://github.com/apache/beam/pull/11980#discussion_r472311023", "createdAt": "2020-08-18T16:06:07Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/dataframe/transforms_test.py", "diffHunk": "@@ -17,17 +17,61 @@\n from __future__ import absolute_import\n from __future__ import division\n \n+import typing\n import unittest\n \n import pandas as pd\n+from past.builtins import unicode\n \n import apache_beam as beam\n+from apache_beam import coders\n from apache_beam.dataframe import expressions\n from apache_beam.dataframe import frame_base\n from apache_beam.dataframe import transforms\n from apache_beam.testing.util import assert_that\n \n \n+def sort_by_value_and_drop_index(df):\n+  if isinstance(df, pd.DataFrame):\n+    sorted_df = df.sort_values(by=list(df.columns))\n+  else:\n+    sorted_df = df.sort_values()\n+  return sorted_df.reset_index(drop=True)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a1f9a2b4bbcca04c5f46b53edbfdae2f930a2539"}, "originalPosition": 23}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3669, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}