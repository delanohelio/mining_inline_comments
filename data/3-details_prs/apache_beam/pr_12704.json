{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDc0ODkxODc3", "number": 12704, "title": "[BEAM-10603] Implement the new Large Source Recording API.", "bodyText": "Change-Id: I660b98ac7cd562eb03aab6d15d829eae8726ebad\nThe following API changes the way that the Interactive Runner caches\ndata from unbounded sources. Previously, a user-configurable duration\nwould run a \"Background Caching Job\" that would cache all elements from\nunbounded source. Then, the user pipeline would run by reading from\nthat cache after completion. Now, there is a long lived \"Background\nRecording Job\". This replaces the caching job with a background pipeline\nthat records elements from the unbounded sources and most importantly\ndoes not block user pipeline execution.\nThe following APIs have changed:\nshow(*pcolls, include_window_info=False, visualize_data=False) -->\nshow(*pcolls, n='inf', duration='inf', include_window_info=False, visualize_data=False)\nThe show() command was modified to include a max number of elements and\na max duration of elements to read. The show() command will end when\neither of the limiters gets triggered, whichever comes first. If a\nlimiter is not supplied it is assumed to be infinite. For example,\nshow(pcoll, n=5000) will read and block until 5000 elements are read.\ncollect(pcoll, include_window_info=False) -->\ncollect(pcoll, n='inf', duration='inf', include_window_info=False)\nThe collect() command was modified to include a max number of elements and\na max duration of elements to read. The collect() command will end when\neither of the limiters gets triggered, whichever comes first. If a\nlimiter is not supplied it is assumed to be infinite. For example,\nshow(pcoll, n=5000) will read and block until 5000 elements are read.\nhead() was removed.\n\nThank you for your contribution! Follow this checklist to help us incorporate your contribution quickly and easily:\n\n Choose reviewer(s) and mention them in a comment (R: @username).\n Format the pull request title like [BEAM-XXX] Fixes bug in ApproximateQuantiles, where you replace BEAM-XXX with the appropriate JIRA issue, if applicable. This will automatically link the pull request to the issue.\n Update CHANGES.md with noteworthy changes.\n If this contribution is large, please file an Apache Individual Contributor License Agreement.\n\nSee the Contributor Guide for more tips on how to make review process smoother.\nPost-Commit Tests Status (on master branch)\n\n\n\nLang\nSDK\nDataflow\nFlink\nSamza\nSpark\nTwister2\n\n\n\n\nGo\n\n---\n\n---\n\n---\n\n\nJava\n\n\n\n\n\n\n\n\nPython\n\n\n\n---\n\n---\n\n\nXLang\n\n---\n\n---\n\n---\n\n\n\nPre-Commit Tests Status (on master branch)\n\n\n\n---\nJava\nPython\nGo\nWebsite\nWhitespace\n\n\n\n\nNon-portable\n\n \n\n\n\n\n\nPortable\n---\n\n---\n---\n---\n\n\n\nSee .test-infra/jenkins/README for trigger phrase, status and link of all Jenkins jobs.\nGitHub Actions Tests Status (on master branch)\n\n\n\nSee CI.md for more information about GitHub Actions CI.", "createdAt": "2020-08-27T19:01:38Z", "url": "https://github.com/apache/beam/pull/12704", "merged": true, "mergeCommit": {"oid": "4b03a1126681199ae8c78a2c89b5c1469d02d799"}, "closed": true, "closedAt": "2020-09-15T14:20:02Z", "author": {"login": "rohdesamuel"}, "timelineItems": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdG7TzygBqjM3NDIxMjM1MzI=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdJ0XJbAFqTQ5MDgyNTY0NQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "7b47b05024fc0baa945130b2134ca8ffecafa5c7", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/7b47b05024fc0baa945130b2134ca8ffecafa5c7", "committedDate": "2020-08-27T18:59:05Z", "message": "Implement the new Large Source Recording API.\n\n    The following API changes the way that the Interactive Runner caches\n    data from unbounded sources. Previously, a user-configurable duration\n    would run a \"Background Caching Job\" that would cache all elements from\n    unbounded source. Then, the user pipeline would run by reading from\n    that cache after completion. Now, there is a long lived \"Background\n    Recording Job\". This replaces the caching job with a background pipeline\n    that records elements from the unbounded sources and most importantly\n    does not block user pipeline execution.\n\n    The following APIs have changed:\n    show(*pcolls, include_window_info=False, visualize_data=False) -->\n    show(*pcolls, n='inf', duration='inf', include_window_info=False, visualize_data=False)\n\n    The show() command was modified to include a max number of elements and\n    a max duration of elements to read. The show() command will end when\n    either of the limiters gets triggered, whichever comes first. If a\n    limiter is not supplied it is assumed to be infinite. For example,\n    show(pcoll, n=5000) will read and block until 5000 elements are read.\n\n    collect(pcoll, include_window_info=False) -->\n    collect(pcoll, n='inf', duration='inf', include_window_info=False)\n\n    The collect() command was modified to include a max number of elements and\n    a max duration of elements to read. The collect() command will end when\n    either of the limiters gets triggered, whichever comes first. If a\n    limiter is not supplied it is assumed to be infinite. For example,\n    show(pcoll, n=5000) will read and block until 5000 elements are read.\n\n    head() was removed.\n\nChange-Id: I660b98ac7cd562eb03aab6d15d829eae8726ebad"}, "afterCommit": {"oid": "a6fb4693348fae2513b421c1177cae86dc76eaf6", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/a6fb4693348fae2513b421c1177cae86dc76eaf6", "committedDate": "2020-09-08T17:46:10Z", "message": "Implement the new Large Source Recording API.\n\n    The following API changes the way that the Interactive Runner caches\n    data from unbounded sources. Previously, a user-configurable duration\n    would run a \"Background Caching Job\" that would cache all elements from\n    unbounded source. Then, the user pipeline would run by reading from\n    that cache after completion. Now, there is a long lived \"Background\n    Recording Job\". This replaces the caching job with a background pipeline\n    that records elements from the unbounded sources and most importantly\n    does not block user pipeline execution.\n\n    The following APIs have changed:\n    show(*pcolls, include_window_info=False, visualize_data=False) -->\n    show(*pcolls, n='inf', duration='inf', include_window_info=False, visualize_data=False)\n\n    The show() command was modified to include a max number of elements and\n    a max duration of elements to read. The show() command will end when\n    either of the limiters gets triggered, whichever comes first. If a\n    limiter is not supplied it is assumed to be infinite. For example,\n    show(pcoll, n=5000) will read and block until 5000 elements are read.\n\n    collect(pcoll, include_window_info=False) -->\n    collect(pcoll, n='inf', duration='inf', include_window_info=False)\n\n    The collect() command was modified to include a max number of elements and\n    a max duration of elements to read. The collect() command will end when\n    either of the limiters gets triggered, whichever comes first. If a\n    limiter is not supplied it is assumed to be infinite. For example,\n    show(pcoll, n=5000) will read and block until 5000 elements are read.\n\n    head() was removed.\n\nChange-Id: I660b98ac7cd562eb03aab6d15d829eae8726ebad"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a6fb4693348fae2513b421c1177cae86dc76eaf6", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/a6fb4693348fae2513b421c1177cae86dc76eaf6", "committedDate": "2020-09-08T17:46:10Z", "message": "Implement the new Large Source Recording API.\n\n    The following API changes the way that the Interactive Runner caches\n    data from unbounded sources. Previously, a user-configurable duration\n    would run a \"Background Caching Job\" that would cache all elements from\n    unbounded source. Then, the user pipeline would run by reading from\n    that cache after completion. Now, there is a long lived \"Background\n    Recording Job\". This replaces the caching job with a background pipeline\n    that records elements from the unbounded sources and most importantly\n    does not block user pipeline execution.\n\n    The following APIs have changed:\n    show(*pcolls, include_window_info=False, visualize_data=False) -->\n    show(*pcolls, n='inf', duration='inf', include_window_info=False, visualize_data=False)\n\n    The show() command was modified to include a max number of elements and\n    a max duration of elements to read. The show() command will end when\n    either of the limiters gets triggered, whichever comes first. If a\n    limiter is not supplied it is assumed to be infinite. For example,\n    show(pcoll, n=5000) will read and block until 5000 elements are read.\n\n    collect(pcoll, include_window_info=False) -->\n    collect(pcoll, n='inf', duration='inf', include_window_info=False)\n\n    The collect() command was modified to include a max number of elements and\n    a max duration of elements to read. The collect() command will end when\n    either of the limiters gets triggered, whichever comes first. If a\n    limiter is not supplied it is assumed to be infinite. For example,\n    show(pcoll, n=5000) will read and block until 5000 elements are read.\n\n    head() was removed.\n\nChange-Id: I660b98ac7cd562eb03aab6d15d829eae8726ebad"}, "afterCommit": {"oid": "332aa62b01d2f2ab8a83150ee3ccf7f16a4b58a5", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/332aa62b01d2f2ab8a83150ee3ccf7f16a4b58a5", "committedDate": "2020-09-08T17:59:47Z", "message": "Implement the new Large Source Recording API.\n\n    The following API changes the way that the Interactive Runner caches\n    data from unbounded sources. Previously, a user-configurable duration\n    would run a \"Background Caching Job\" that would cache all elements from\n    unbounded source. Then, the user pipeline would run by reading from\n    that cache after completion. Now, there is a long lived \"Background\n    Recording Job\". This replaces the caching job with a background pipeline\n    that records elements from the unbounded sources and most importantly\n    does not block user pipeline execution.\n\n    The following APIs have changed:\n    show(*pcolls, include_window_info=False, visualize_data=False) -->\n    show(*pcolls, n='inf', duration='inf', include_window_info=False, visualize_data=False)\n\n    The show() command was modified to include a max number of elements and\n    a max duration of elements to read. The show() command will end when\n    either of the limiters gets triggered, whichever comes first. If a\n    limiter is not supplied it is assumed to be infinite. For example,\n    show(pcoll, n=5000) will read and block until 5000 elements are read.\n\n    collect(pcoll, include_window_info=False) -->\n    collect(pcoll, n='inf', duration='inf', include_window_info=False)\n\n    The collect() command was modified to include a max number of elements and\n    a max duration of elements to read. The collect() command will end when\n    either of the limiters gets triggered, whichever comes first. If a\n    limiter is not supplied it is assumed to be infinite. For example,\n    show(pcoll, n=5000) will read and block until 5000 elements are read.\n\n    head() was removed.\n\nChange-Id: I660b98ac7cd562eb03aab6d15d829eae8726ebad"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "332aa62b01d2f2ab8a83150ee3ccf7f16a4b58a5", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/332aa62b01d2f2ab8a83150ee3ccf7f16a4b58a5", "committedDate": "2020-09-08T17:59:47Z", "message": "Implement the new Large Source Recording API.\n\n    The following API changes the way that the Interactive Runner caches\n    data from unbounded sources. Previously, a user-configurable duration\n    would run a \"Background Caching Job\" that would cache all elements from\n    unbounded source. Then, the user pipeline would run by reading from\n    that cache after completion. Now, there is a long lived \"Background\n    Recording Job\". This replaces the caching job with a background pipeline\n    that records elements from the unbounded sources and most importantly\n    does not block user pipeline execution.\n\n    The following APIs have changed:\n    show(*pcolls, include_window_info=False, visualize_data=False) -->\n    show(*pcolls, n='inf', duration='inf', include_window_info=False, visualize_data=False)\n\n    The show() command was modified to include a max number of elements and\n    a max duration of elements to read. The show() command will end when\n    either of the limiters gets triggered, whichever comes first. If a\n    limiter is not supplied it is assumed to be infinite. For example,\n    show(pcoll, n=5000) will read and block until 5000 elements are read.\n\n    collect(pcoll, include_window_info=False) -->\n    collect(pcoll, n='inf', duration='inf', include_window_info=False)\n\n    The collect() command was modified to include a max number of elements and\n    a max duration of elements to read. The collect() command will end when\n    either of the limiters gets triggered, whichever comes first. If a\n    limiter is not supplied it is assumed to be infinite. For example,\n    show(pcoll, n=5000) will read and block until 5000 elements are read.\n\n    head() was removed.\n\nChange-Id: I660b98ac7cd562eb03aab6d15d829eae8726ebad"}, "afterCommit": {"oid": "a2301e17cb687ae55338240db984d5f480b0940d", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/a2301e17cb687ae55338240db984d5f480b0940d", "committedDate": "2020-09-09T17:34:37Z", "message": "Implement the new Large Source Recording API.\n\n    The following API changes the way that the Interactive Runner caches\n    data from unbounded sources. Previously, a user-configurable duration\n    would run a \"Background Caching Job\" that would cache all elements from\n    unbounded source. Then, the user pipeline would run by reading from\n    that cache after completion. Now, there is a long lived \"Background\n    Recording Job\". This replaces the caching job with a background pipeline\n    that records elements from the unbounded sources and most importantly\n    does not block user pipeline execution.\n\n    The following APIs have changed:\n    show(*pcolls, include_window_info=False, visualize_data=False) -->\n    show(*pcolls, n='inf', duration='inf', include_window_info=False, visualize_data=False)\n\n    The show() command was modified to include a max number of elements and\n    a max duration of elements to read. The show() command will end when\n    either of the limiters gets triggered, whichever comes first. If a\n    limiter is not supplied it is assumed to be infinite. For example,\n    show(pcoll, n=5000) will read and block until 5000 elements are read.\n\n    collect(pcoll, include_window_info=False) -->\n    collect(pcoll, n='inf', duration='inf', include_window_info=False)\n\n    The collect() command was modified to include a max number of elements and\n    a max duration of elements to read. The collect() command will end when\n    either of the limiters gets triggered, whichever comes first. If a\n    limiter is not supplied it is assumed to be infinite. For example,\n    show(pcoll, n=5000) will read and block until 5000 elements are read.\n\n    head() was removed.\n\nChange-Id: I660b98ac7cd562eb03aab6d15d829eae8726ebad"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "a2301e17cb687ae55338240db984d5f480b0940d", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/a2301e17cb687ae55338240db984d5f480b0940d", "committedDate": "2020-09-09T17:34:37Z", "message": "Implement the new Large Source Recording API.\n\n    The following API changes the way that the Interactive Runner caches\n    data from unbounded sources. Previously, a user-configurable duration\n    would run a \"Background Caching Job\" that would cache all elements from\n    unbounded source. Then, the user pipeline would run by reading from\n    that cache after completion. Now, there is a long lived \"Background\n    Recording Job\". This replaces the caching job with a background pipeline\n    that records elements from the unbounded sources and most importantly\n    does not block user pipeline execution.\n\n    The following APIs have changed:\n    show(*pcolls, include_window_info=False, visualize_data=False) -->\n    show(*pcolls, n='inf', duration='inf', include_window_info=False, visualize_data=False)\n\n    The show() command was modified to include a max number of elements and\n    a max duration of elements to read. The show() command will end when\n    either of the limiters gets triggered, whichever comes first. If a\n    limiter is not supplied it is assumed to be infinite. For example,\n    show(pcoll, n=5000) will read and block until 5000 elements are read.\n\n    collect(pcoll, include_window_info=False) -->\n    collect(pcoll, n='inf', duration='inf', include_window_info=False)\n\n    The collect() command was modified to include a max number of elements and\n    a max duration of elements to read. The collect() command will end when\n    either of the limiters gets triggered, whichever comes first. If a\n    limiter is not supplied it is assumed to be infinite. For example,\n    show(pcoll, n=5000) will read and block until 5000 elements are read.\n\n    head() was removed.\n\nChange-Id: I660b98ac7cd562eb03aab6d15d829eae8726ebad"}, "afterCommit": {"oid": "d78dee09b4907485c52011263186b6c446e3dded", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/d78dee09b4907485c52011263186b6c446e3dded", "committedDate": "2020-09-10T17:18:36Z", "message": "Implement the new Large Source Recording API.\n\n    The following API changes the way that the Interactive Runner caches\n    data from unbounded sources. Previously, a user-configurable duration\n    would run a \"Background Caching Job\" that would cache all elements from\n    unbounded source. Then, the user pipeline would run by reading from\n    that cache after completion. Now, there is a long lived \"Background\n    Recording Job\". This replaces the caching job with a background pipeline\n    that records elements from the unbounded sources and most importantly\n    does not block user pipeline execution.\n\n    The following APIs have changed:\n    show(*pcolls, include_window_info=False, visualize_data=False) -->\n    show(*pcolls, n='inf', duration='inf', include_window_info=False, visualize_data=False)\n\n    The show() command was modified to include a max number of elements and\n    a max duration of elements to read. The show() command will end when\n    either of the limiters gets triggered, whichever comes first. If a\n    limiter is not supplied it is assumed to be infinite. For example,\n    show(pcoll, n=5000) will read and block until 5000 elements are read.\n\n    collect(pcoll, include_window_info=False) -->\n    collect(pcoll, n='inf', duration='inf', include_window_info=False)\n\n    The collect() command was modified to include a max number of elements and\n    a max duration of elements to read. The collect() command will end when\n    either of the limiters gets triggered, whichever comes first. If a\n    limiter is not supplied it is assumed to be infinite. For example,\n    show(pcoll, n=5000) will read and block until 5000 elements are read.\n\n    head() was removed.\n\nChange-Id: I660b98ac7cd562eb03aab6d15d829eae8726ebad"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg2MTU2NzQz", "url": "https://github.com/apache/beam/pull/12704#pullrequestreview-486156743", "createdAt": "2020-09-10T17:28:34Z", "commit": {"oid": "d78dee09b4907485c52011263186b6c446e3dded"}, "state": "APPROVED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQxNzoyODozNFrOHP-a0g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQxNzo0MDozNFrOHP-2aw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjUxMzM2Mg==", "bodyText": "Nit: how about merging these configurations in the docstrings.\nSomething like:\nThere are 4 configurations: \n  #. include_window_info=<True/False>. If True, windowing information of the\n       data will be visualized too. Default is false.\n  #. visualize_data=<True/False>. By default, the visualization contains data\n       tables rendering data from given pcolls separately as if they are\n       converted into dataframes. If visualize_data is True, there will be a\n       more dive-in widget and statistically overview widget of the data.\n       Otherwise, those 2 data visualization widgets will not be displayed.\n  #. n=<int>. Max number of elements to visualize. Default 'inf'.\n  #. duration=<int>. Max duration of elements to read. Default 'inf'.", "url": "https://github.com/apache/beam/pull/12704#discussion_r486513362", "createdAt": "2020-09-10T17:28:34Z", "author": {"login": "KevinGG"}, "path": "sdks/python/apache_beam/runners/interactive/interactive_beam.py", "diffHunk": "@@ -273,6 +270,10 @@ def show(*pcolls, **configs):\n   The given pcolls can be dictionary of PCollections (as values), or iterable\n   of PCollections or plain PCollection values.\n \n+  The user can specify either the max number of elements with `n` to read\n+  or the maximum duration of elements to read with `duration`. When a limiter is\n+  not supplied, it is assumed to be infinite.\n+\n   There are 2 boolean configurations:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d78dee09b4907485c52011263186b6c446e3dded"}, "originalPosition": 32}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjUxNDEwNQ==", "bodyText": "Include the new configs n and duration.", "url": "https://github.com/apache/beam/pull/12704#discussion_r486514105", "createdAt": "2020-09-10T17:29:48Z", "author": {"login": "KevinGG"}, "path": "sdks/python/apache_beam/runners/interactive/interactive_beam.py", "diffHunk": "@@ -342,121 +343,79 @@ def show(*pcolls, **configs):\n     assert isinstance(pcoll, beam.pvalue.PCollection), (\n         '{} is not an apache_beam.pvalue.PCollection.'.format(pcoll))\n   user_pipeline = pcolls[0].pipeline\n-  for pcoll in pcolls:\n-    assert pcoll.pipeline is user_pipeline, (\n-        '{} belongs to a different user-defined pipeline ({}) than that of'\n-        ' other PCollections ({}).'.format(\n-            pcoll, pcoll.pipeline, user_pipeline))\n+\n   # TODO(BEAM-8288): Remove below pops and assertion once Python 2 is\n   # deprecated from Beam.\n   include_window_info = configs.pop('include_window_info', False)\n   visualize_data = configs.pop('visualize_data', False)\n+  n = configs.pop('n', 'inf')\n+  duration = configs.pop('duration', 'inf')\n+\n+  if n == 'inf':\n+    n = float('inf')\n+\n+  if duration == 'inf':\n+    duration = float('inf')\n+\n   # This assertion is to protect the backward compatibility for function\n   # signature change after Python 2 deprecation.\n   assert not configs, (\n       'The only configs supported are include_window_info and '\n       'visualize_data.')", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d78dee09b4907485c52011263186b6c446e3dded"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjUxNjc4Mg==", "bodyText": "Do we need any assertion in the future? Like n needs to be a positive integer. And duration will be a string such as 1h2m3s.", "url": "https://github.com/apache/beam/pull/12704#discussion_r486516782", "createdAt": "2020-09-10T17:34:36Z", "author": {"login": "KevinGG"}, "path": "sdks/python/apache_beam/runners/interactive/interactive_beam.py", "diffHunk": "@@ -342,121 +343,79 @@ def show(*pcolls, **configs):\n     assert isinstance(pcoll, beam.pvalue.PCollection), (\n         '{} is not an apache_beam.pvalue.PCollection.'.format(pcoll))\n   user_pipeline = pcolls[0].pipeline\n-  for pcoll in pcolls:\n-    assert pcoll.pipeline is user_pipeline, (\n-        '{} belongs to a different user-defined pipeline ({}) than that of'\n-        ' other PCollections ({}).'.format(\n-            pcoll, pcoll.pipeline, user_pipeline))\n+\n   # TODO(BEAM-8288): Remove below pops and assertion once Python 2 is\n   # deprecated from Beam.\n   include_window_info = configs.pop('include_window_info', False)\n   visualize_data = configs.pop('visualize_data', False)\n+  n = configs.pop('n', 'inf')\n+  duration = configs.pop('duration', 'inf')\n+\n+  if n == 'inf':\n+    n = float('inf')\n+\n+  if duration == 'inf':\n+    duration = float('inf')", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d78dee09b4907485c52011263186b6c446e3dded"}, "originalPosition": 56}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjUyMDQyNw==", "bodyText": "I assume you've verified that, when the recording is not computed, this (static) and below (with dynamic_plotting_interval) visualize statements will update the same visualization. Is it because you are generating a consistent display_id from the recording manager?", "url": "https://github.com/apache/beam/pull/12704#discussion_r486520427", "createdAt": "2020-09-10T17:40:34Z", "author": {"login": "KevinGG"}, "path": "sdks/python/apache_beam/runners/interactive/interactive_beam.py", "diffHunk": "@@ -342,121 +343,79 @@ def show(*pcolls, **configs):\n     assert isinstance(pcoll, beam.pvalue.PCollection), (\n         '{} is not an apache_beam.pvalue.PCollection.'.format(pcoll))\n   user_pipeline = pcolls[0].pipeline\n-  for pcoll in pcolls:\n-    assert pcoll.pipeline is user_pipeline, (\n-        '{} belongs to a different user-defined pipeline ({}) than that of'\n-        ' other PCollections ({}).'.format(\n-            pcoll, pcoll.pipeline, user_pipeline))\n+\n   # TODO(BEAM-8288): Remove below pops and assertion once Python 2 is\n   # deprecated from Beam.\n   include_window_info = configs.pop('include_window_info', False)\n   visualize_data = configs.pop('visualize_data', False)\n+  n = configs.pop('n', 'inf')\n+  duration = configs.pop('duration', 'inf')\n+\n+  if n == 'inf':\n+    n = float('inf')\n+\n+  if duration == 'inf':\n+    duration = float('inf')\n+\n   # This assertion is to protect the backward compatibility for function\n   # signature change after Python 2 deprecation.\n   assert not configs, (\n       'The only configs supported are include_window_info and '\n       'visualize_data.')\n-  runner = user_pipeline.runner\n-  if isinstance(runner, ir.InteractiveRunner):\n-    runner = runner._underlying_runner\n-\n-  # Make sure that sources without a user reference are still cached.\n-  pi.watch_sources(user_pipeline)\n-\n-  # Make sure that all PCollections to be shown are watched. If a PCollection\n-  # has not been watched, make up a variable name for that PCollection and watch\n-  # it. No validation is needed here because the watch logic can handle\n-  # arbitrary variables.\n-  watched_pcollections = set()\n-  for watching in ie.current_env().watching():\n-    for _, val in watching:\n-      if hasattr(val, '__class__') and isinstance(val, beam.pvalue.PCollection):\n-        watched_pcollections.add(val)\n-  for pcoll in pcolls:\n-    if pcoll not in watched_pcollections:\n-      watch({'anonymous_pcollection_{}'.format(id(pcoll)): pcoll})\n-\n-  if ie.current_env().is_in_ipython:\n-    warnings.filterwarnings(\n-        'ignore',\n-        'options is deprecated since First stable release. References to '\n-        '<pipeline>.options will not be supported',\n-        category=DeprecationWarning)\n-  # Attempt to run background caching job since we have the reference to the\n-  # user-defined pipeline.\n-  bcj.attempt_to_run_background_caching_job(\n-      runner, user_pipeline, user_pipeline.options)\n-\n-  pcolls = set(pcolls)\n-  computed_pcolls = set()\n-  for pcoll in pcolls:\n-    if pcoll in ie.current_env().computed_pcollections:\n-      computed_pcolls.add(pcoll)\n-  pcolls = pcolls.difference(computed_pcolls)\n-  # If in notebook, static plotting computed pcolls as computation is done.\n-  if ie.current_env().is_in_notebook:\n-    for pcoll in computed_pcolls:\n-      visualize(\n-          pcoll,\n-          include_window_info=include_window_info,\n-          display_facets=visualize_data)\n-  elif ie.current_env().is_in_ipython:\n-    for pcoll in computed_pcolls:\n-      visualize(pcoll, include_window_info=include_window_info)\n-\n-  if not pcolls:\n-    return\n-\n-  # Build a pipeline fragment for the PCollections and run it.\n-  result = pf.PipelineFragment(list(pcolls), user_pipeline.options).run()\n-  ie.current_env().set_pipeline_result(user_pipeline, result)\n-\n-  # If in notebook, dynamic plotting as computation goes.\n-  if ie.current_env().is_in_notebook:\n-    for pcoll in pcolls:\n-      visualize(\n-          pcoll,\n-          dynamic_plotting_interval=1,\n-          include_window_info=include_window_info,\n-          display_facets=visualize_data)\n-\n-  # Invoke wait_until_finish to ensure the blocking nature of this API without\n-  # relying on the run to be blocking.\n-  result.wait_until_finish()\n-\n-  # If just in ipython shell, plotting once when the computation is completed.\n-  if ie.current_env().is_in_ipython and not ie.current_env().is_in_notebook:\n-    for pcoll in pcolls:\n-      visualize(pcoll, include_window_info=include_window_info)\n-\n-  # If the pipeline execution is successful at this stage, mark the computation\n-  # completeness for the given PCollections so that when further `show`\n-  # invocation occurs, Interactive Beam wouldn't need to re-compute them.\n-  if result.state is beam.runners.runner.PipelineState.DONE:\n-    ie.current_env().mark_pcollection_computed(pcolls)\n-\n-\n-def collect(pcoll, include_window_info=False):\n-  \"\"\"Materializes all of the elements from a PCollection into a Dataframe.\n \n-  For example::\n+  recording_manager = RecordingManager(user_pipeline)\n+  recording = recording_manager.record(\n+      pcolls, max_n=n, max_duration_secs=duration)\n+\n+  # Catch a KeyboardInterrupt to gracefully cancel the recording and\n+  # visualizations.\n+  try:\n+    # If in notebook, static plotting computed pcolls as computation is done.\n+    if ie.current_env().is_in_notebook:\n+      for stream in recording.computed().values():\n+        visualize(\n+            stream,\n+            include_window_info=include_window_info,\n+            display_facets=visualize_data)\n+    elif ie.current_env().is_in_ipython:\n+      for stream in recording.computed().values():\n+        visualize(stream, include_window_info=include_window_info)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d78dee09b4907485c52011263186b6c446e3dded"}, "originalPosition": 163}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3fd7148989aa9145df65bad29bc32e12b8f557d9", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/3fd7148989aa9145df65bad29bc32e12b8f557d9", "committedDate": "2020-09-10T20:12:47Z", "message": "Implement the new Large Source Recording API.\n\n    The following API changes the way that the Interactive Runner caches\n    data from unbounded sources. Previously, a user-configurable duration\n    would run a \"Background Caching Job\" that would cache all elements from\n    unbounded source. Then, the user pipeline would run by reading from\n    that cache after completion. Now, there is a long lived \"Background\n    Recording Job\". This replaces the caching job with a background pipeline\n    that records elements from the unbounded sources and most importantly\n    does not block user pipeline execution.\n\n    The following APIs have changed:\n    show(*pcolls, include_window_info=False, visualize_data=False) -->\n    show(*pcolls, n='inf', duration='inf', include_window_info=False, visualize_data=False)\n\n    The show() command was modified to include a max number of elements and\n    a max duration of elements to read. The show() command will end when\n    either of the limiters gets triggered, whichever comes first. If a\n    limiter is not supplied it is assumed to be infinite. For example,\n    show(pcoll, n=5000) will read and block until 5000 elements are read.\n\n    collect(pcoll, include_window_info=False) -->\n    collect(pcoll, n='inf', duration='inf', include_window_info=False)\n\n    The collect() command was modified to include a max number of elements and\n    a max duration of elements to read. The collect() command will end when\n    either of the limiters gets triggered, whichever comes first. If a\n    limiter is not supplied it is assumed to be infinite. For example,\n    show(pcoll, n=5000) will read and block until 5000 elements are read.\n\n    head() was removed.\n\nChange-Id: I660b98ac7cd562eb03aab6d15d829eae8726ebad"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6e0837bafdd323416d1b34af210b2f42443f4964", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/6e0837bafdd323416d1b34af210b2f42443f4964", "committedDate": "2020-09-10T20:12:52Z", "message": "Add assertions to 'n' and 'duration' in ib\n\nChange-Id: Ib2f7c2ae0f7ff5afa8e0118bdeee07c9a56019a1"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "71d4a90a40f281b7fe7fe91d820c157b6f7f7273", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/71d4a90a40f281b7fe7fe91d820c157b6f7f7273", "committedDate": "2020-09-10T20:12:53Z", "message": "Improve doc strings for collect and show\n\nChange-Id: I15e137430842d4aaa59676eb680296174faf14ee"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "79a72ba3b762f356a6f74f06ad0f207a7d43fd94", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/79a72ba3b762f356a6f74f06ad0f207a7d43fd94", "committedDate": "2020-09-10T18:54:21Z", "message": "Improve doc strings for collect and show\n\nChange-Id: I15e137430842d4aaa59676eb680296174faf14ee"}, "afterCommit": {"oid": "71d4a90a40f281b7fe7fe91d820c157b6f7f7273", "author": {"user": null}, "url": "https://github.com/apache/beam/commit/71d4a90a40f281b7fe7fe91d820c157b6f7f7273", "committedDate": "2020-09-10T20:12:53Z", "message": "Improve doc strings for collect and show\n\nChange-Id: I15e137430842d4aaa59676eb680296174faf14ee"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDkwODI1NjQ1", "url": "https://github.com/apache/beam/pull/12704#pullrequestreview-490825645", "createdAt": "2020-09-17T17:22:54Z", "commit": {"oid": "71d4a90a40f281b7fe7fe91d820c157b6f7f7273"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QxNzoyMjo1NFrOHTtjjQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QxNzoyMjo1NFrOHTtjjQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDQzMTM3Mw==", "bodyText": "This looks like a likely culprit, the error message in the flakes references a full directory in the cache:\nE                   PermissionError: [WinError 32] The process cannot access the file because it is being used by another process: 'D:\\\\a\\\\beam\\\\beam\\\\sdks\\\\python\\\\target\\\\.tox\\\\py35-win\\\\tmp\\\\it-8vh2z7pi2021914046928\\\\full\\\\ac8879590f-2021876280456-2021876278608-2021914046928'", "url": "https://github.com/apache/beam/pull/12704#discussion_r490431373", "createdAt": "2020-09-17T17:22:54Z", "author": {"login": "TheNeuralBit"}, "path": "sdks/python/apache_beam/runners/interactive/display/pcoll_visualization.py", "diffHunk": "@@ -407,13 +392,7 @@ def _display_dataframe(self, data, update=None):\n           self._is_datatable_empty = False\n \n   def _to_dataframe(self):\n-    results = []\n-    cache_manager = ie.current_env().get_cache_manager(self._pcoll.pipeline)\n-    if cache_manager.exists('full', self._cache_key):\n-      coder = cache_manager.load_pcoder('full', self._cache_key)\n-      reader, _ = cache_manager.read('full', self._cache_key)\n-      results = list(to_element_list(reader, coder, include_window_info=True))\n-", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "71d4a90a40f281b7fe7fe91d820c157b6f7f7273"}, "originalPosition": 113}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4494, "cost": 1, "resetAt": "2021-10-28T16:48:13Z"}}}