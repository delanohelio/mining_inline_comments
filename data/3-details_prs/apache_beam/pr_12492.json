{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDY0MzUwMTE4", "number": 12492, "title": "[BEAM-6807] Implement an Azure blobstore filesystem for Python SDK", "bodyText": "Please add a meaningful description for your change here\n\nThank you for your contribution! Follow this checklist to help us incorporate your contribution quickly and easily:\n\n Choose reviewer(s) and mention them in a comment (R: @username).\n Format the pull request title like [BEAM-XXX] Fixes bug in ApproximateQuantiles, where you replace BEAM-XXX with the appropriate JIRA issue, if applicable. This will automatically link the pull request to the issue.\n Update CHANGES.md with noteworthy changes.\n If this contribution is large, please file an Apache Individual Contributor License Agreement.\n\nSee the Contributor Guide for more tips on how to make review process smoother.\nPost-Commit Tests Status (on master branch)\n\n\n\nLang\nSDK\nDataflow\nFlink\nSamza\nSpark\nTwister2\n\n\n\n\nGo\n\n---\n\n---\n\n---\n\n\nJava\n\n\n\n\n\n\n\n\nPython\n\n\n\n---\n\n---\n\n\nXLang\n\n---\n\n---\n\n---\n\n\n\nPre-Commit Tests Status (on master branch)\n\n\n\n---\nJava\nPython\nGo\nWebsite\n\n\n\n\nNon-portable\n\n\n\n\n\n\nPortable\n---\n\n---\n---\n\n\n\nSee .test-infra/jenkins/README for trigger phrase, status and link of all Jenkins jobs.\nGitHub Actions Tests Status (on master branch)\n\nSee CI.md for more information about GitHub Actions CI.", "createdAt": "2020-08-07T02:14:25Z", "url": "https://github.com/apache/beam/pull/12492", "merged": true, "mergeCommit": {"oid": "bae1e7b0e350958a90e843e53c7a5779c1e598fa"}, "closed": true, "closedAt": "2020-08-28T03:11:31Z", "author": {"login": "AldairCoronel"}, "timelineItems": {"totalCount": 136, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc98ZSLgH2gAyNDY0MzUwMTE4OmQ0YjRiZWUzYjFmNGY4MzJjYzA5MzU5ZjBlOWNlYWJlNzAwYmRmZDE=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdDIg0rAH2gAyNDY0MzUwMTE4OjM4ODQ1MjczNWJjODdjMGZlOGFjMDRjZmNjZGZlZTQzNjVmNTAzZmQ=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "d4b4bee3b1f4f832cc09359f0e9ceabe700bdfd1", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/d4b4bee3b1f4f832cc09359f0e9ceabe700bdfd1", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add scheme, mkdirs and has_dirs methods"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ea2adc3696520045a8b5dd29b8de7a37a12b70de", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/ea2adc3696520045a8b5dd29b8de7a37a12b70de", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add blobstoragefilesystem_test file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b36a5c03b27cacee13227641893efad23b39773a", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/b36a5c03b27cacee13227641893efad23b39773a", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add blobstorageio file to interact with Azure"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f93614fd5f3c97310293856ddb90d30ef3cf499c", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/f93614fd5f3c97310293856ddb90d30ef3cf499c", "committedDate": "2020-08-11T19:57:23Z", "message": "test: parse_azfs_path method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ef86ece23455cf36fad5ee9835d1c069e2f9b3bb", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/ef86ece23455cf36fad5ee9835d1c069e2f9b3bb", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add list_prefix method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e7f0199dcdcdaad72bae28f18adb0578dfa1d68d", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/e7f0199dcdcdaad72bae28f18adb0578dfa1d68d", "committedDate": "2020-08-11T19:57:23Z", "message": "test: list_prefix (progress)"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "aebd55ed426363627634839da9a9ed7be5bd9613", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/aebd55ed426363627634839da9a9ed7be5bd9613", "committedDate": "2020-08-11T19:57:23Z", "message": "test: list_prefix method works with local account"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fa7b44158acb2a548c2fb3c3eb662e2d97cb98c8", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/fa7b44158acb2a548c2fb3c3eb662e2d97cb98c8", "committedDate": "2020-08-11T19:57:23Z", "message": "test: test_math_multiples"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e4c609ebd134c7f8015b2f78b93c969cc90fc9d1", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/e4c609ebd134c7f8015b2f78b93c969cc90fc9d1", "committedDate": "2020-08-11T19:57:23Z", "message": "test: math multiples limit"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b4e9e8014ad453269afa4d95a58cc7b297281820", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/b4e9e8014ad453269afa4d95a58cc7b297281820", "committedDate": "2020-08-11T19:57:23Z", "message": "test: match multiple patterns"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f2a8c917e1b04d80b35b1686b0302b7e5813aa4b", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/f2a8c917e1b04d80b35b1686b0302b7e5813aa4b", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add open method to the io class"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "df8ec9bd7064378f5a2f3a86fb31b737142ee325", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/df8ec9bd7064378f5a2f3a86fb31b737142ee325", "committedDate": "2020-08-11T19:57:23Z", "message": "test: file mode"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dc87bba06b7fd443314272edbc91900ae3e964e2", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/dc87bba06b7fd443314272edbc91900ae3e964e2", "committedDate": "2020-08-11T19:57:23Z", "message": "test: copy method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b9f3771cfcbb5dc6b649c5cb937f1eef9fc5c1ba", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/b9f3771cfcbb5dc6b649c5cb937f1eef9fc5c1ba", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add copy single blob method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dd25245e50eec2487e3fdb1da46e84ec4524504e", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/dd25245e50eec2487e3fdb1da46e84ec4524504e", "committedDate": "2020-08-11T19:57:23Z", "message": "test: file write"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ce03578276190fbf9af356387a7685ff15836174", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/ce03578276190fbf9af356387a7685ff15836174", "committedDate": "2020-08-11T19:57:23Z", "message": "test: delete batch"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c734950461fd481f40e8d366896c01e8d9f7b226", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/c734950461fd481f40e8d366896c01e8d9f7b226", "committedDate": "2020-08-11T19:57:23Z", "message": "fix: delete method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f6e3c399dedda4e2874b26d808015b6c4e2b8ed2", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/f6e3c399dedda4e2874b26d808015b6c4e2b8ed2", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add BlobStorageUploader"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d990de2e8fa48fa4e6f46c87cd3dc79af366e575", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/d990de2e8fa48fa4e6f46c87cd3dc79af366e575", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add insert random file method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b3bcae8273f8442df86bb3042b8deeb3f1edded5", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/b3bcae8273f8442df86bb3042b8deeb3f1edded5", "committedDate": "2020-08-11T19:57:23Z", "message": "fix: delete method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "adfd97e0c794b04c1cc3d9267adea862bd73d762", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/adfd97e0c794b04c1cc3d9267adea862bd73d762", "committedDate": "2020-08-11T19:57:23Z", "message": "test: size"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d4df28ca0c91d4819ae6c73b0dd8827166da434d", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/d4df28ca0c91d4819ae6c73b0dd8827166da434d", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add size method to filesystem"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d934c798edb71c572e7ced590796f80ddf1b9793", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/d934c798edb71c572e7ced590796f80ddf1b9793", "committedDate": "2020-08-11T19:57:23Z", "message": "test: last updated"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d2eacf312436a078c044fae15716dc9ca018d198", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/d2eacf312436a078c044fae15716dc9ca018d198", "committedDate": "2020-08-11T19:57:23Z", "message": "test: (WIP) checksum"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ff08ccb59fe533af96c9a93ddf7478e069a61b6a", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/ff08ccb59fe533af96c9a93ddf7478e069a61b6a", "committedDate": "2020-08-11T19:57:23Z", "message": "test: (WIP) checksum (now is working)"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b4e7e70a56fb837183a0f59306234b5a95a56216", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/b4e7e70a56fb837183a0f59306234b5a95a56216", "committedDate": "2020-08-11T19:57:23Z", "message": "test: checksum"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b7fbffa5983d1bf76667e2a8a5026cab1aac6c0c", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/b7fbffa5983d1bf76667e2a8a5026cab1aac6c0c", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add create method to filesystem"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d82f8dfe280879b6de19b434a3816f5432ae8075", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/d82f8dfe280879b6de19b434a3816f5432ae8075", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add open method to filesystem"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c0c1788597ed009933fc66d2eb02ec4fc7b70d82", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/c0c1788597ed009933fc66d2eb02ec4fc7b70d82", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add copy paths method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b83043c487c5c415f45060e789163e3088fed370", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/b83043c487c5c415f45060e789163e3088fed370", "committedDate": "2020-08-11T19:57:23Z", "message": "test: copy file error"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cccd598c3fae4892441de0802b81a499c28e4121", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/cccd598c3fae4892441de0802b81a499c28e4121", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add delete paths method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ef7ece7909be4896ee5fcd3134efefa502e4382f", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/ef7ece7909be4896ee5fcd3134efefa502e4382f", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add delete tree method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c8a7a3ba5e0fa72095972e41df260dd84e346d4e", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/c8a7a3ba5e0fa72095972e41df260dd84e346d4e", "committedDate": "2020-08-11T19:57:23Z", "message": "test: delete tree"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "aebb0adc8a1e5a112a048f137e73b5848afdbc2a", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/aebb0adc8a1e5a112a048f137e73b5848afdbc2a", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add delete batch helper method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cb79ce922905e50f6aabd0f61ad7c39542f0fcdd", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/cb79ce922905e50f6aabd0f61ad7c39542f0fcdd", "committedDate": "2020-08-11T19:57:23Z", "message": "fix: delete methods"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cf7ae74667e9ff0ff9c60c08aa27ba040d09bb49", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/cf7ae74667e9ff0ff9c60c08aa27ba040d09bb49", "committedDate": "2020-08-11T19:57:23Z", "message": "test: delete files"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d074c338dc8823b090f12cacc424224f9f0cec51", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/d074c338dc8823b090f12cacc424224f9f0cec51", "committedDate": "2020-08-11T19:57:23Z", "message": "test: delete files with errors"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b286ff51d76a342a896b62a64cb5912a6fa22b7e", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/b286ff51d76a342a896b62a64cb5912a6fa22b7e", "committedDate": "2020-08-11T19:57:23Z", "message": "refactor: general code clean up"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f8dd237d7309b068bcd60b357371e88d292ace05", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/f8dd237d7309b068bcd60b357371e88d292ace05", "committedDate": "2020-08-11T19:57:23Z", "message": "test: Add delete files functionality to copy paths"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f0caa88620869020cfc753d219205fd43387ed98", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/f0caa88620869020cfc753d219205fd43387ed98", "committedDate": "2020-08-11T19:57:23Z", "message": "test: rename directory error"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b2e0ac429c83d65ded3a680e327940f3ecc51a0f", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/b2e0ac429c83d65ded3a680e327940f3ecc51a0f", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Skip if there are no dependencies"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "38fde3f86c20ab9447e7da867eec524ead17f1cf", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/38fde3f86c20ab9447e7da867eec524ead17f1cf", "committedDate": "2020-08-11T16:21:42Z", "message": "feat: Skip if there are no dependencies"}, "afterCommit": {"oid": "b2e0ac429c83d65ded3a680e327940f3ecc51a0f", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/b2e0ac429c83d65ded3a680e327940f3ecc51a0f", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Skip if there are no dependencies"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY1NDQ0Mjc0", "url": "https://github.com/apache/beam/pull/12492#pullrequestreview-465444274", "createdAt": "2020-08-11T21:32:43Z", "commit": {"oid": "b2e0ac429c83d65ded3a680e327940f3ecc51a0f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQyMTozMjo0M1rOG_KAAg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQyMTozMjo0M1rOG_KAAg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODg3NzMxNA==", "bodyText": "the import error occurs here, so you should move this import to line 40", "url": "https://github.com/apache/beam/pull/12492#discussion_r468877314", "createdAt": "2020-08-11T21:32:43Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/azure/blobstoragefilesystem_test.py", "diffHunk": "@@ -0,0 +1,315 @@\n+# -*- coding: utf-8 -*-\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Unit tests for Azure Blob Storage File System.\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import logging\n+import unittest\n+\n+# patches unittest.TestCase to be python3 compatible.\n+import future.tests.base  # pylint: disable=unused-import\n+import mock\n+\n+from apache_beam.io.azure import blobstorageio", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b2e0ac429c83d65ded3a680e327940f3ecc51a0f"}, "originalPosition": 32}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY1NDQ2MzIw", "url": "https://github.com/apache/beam/pull/12492#pullrequestreview-465446320", "createdAt": "2020-08-11T21:36:32Z", "commit": {"oid": "b2e0ac429c83d65ded3a680e327940f3ecc51a0f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQyMTozNjozMlrOG_KGUg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xMVQyMTozNjozMlrOG_KGUg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2ODg3ODkzMA==", "bodyText": "there's also an import error happening here. you need to catch it and skip the test", "url": "https://github.com/apache/beam/pull/12492#discussion_r468878930", "createdAt": "2020-08-11T21:36:32Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/azure/blobstorageio_test.py", "diffHunk": "@@ -0,0 +1,86 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Tests for Azure Blob Storage client.\n+\"\"\"\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import logging\n+import unittest\n+\n+from apache_beam.io.azure import blobstorageio", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b2e0ac429c83d65ded3a680e327940f3ecc51a0f"}, "originalPosition": 27}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7018fdff617e805f8616b51279168a7cf7236956", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/7018fdff617e805f8616b51279168a7cf7236956", "committedDate": "2020-08-11T22:01:00Z", "message": "feat: Fix import errors"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fd0df0255672a09cff65c30869253d89521c7d4d", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/fd0df0255672a09cff65c30869253d89521c7d4d", "committedDate": "2020-08-11T22:23:16Z", "message": "fix: minor type errors"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4bf78b253f8a983d2bc3ee853e50e687a3872188", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/4bf78b253f8a983d2bc3ee853e50e687a3872188", "committedDate": "2020-08-11T22:33:11Z", "message": "feat: Add pylint stuff"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8d3e8d7bfc130bdaef72259db21c311c38a0edc0", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/8d3e8d7bfc130bdaef72259db21c311c38a0edc0", "committedDate": "2020-08-11T22:46:37Z", "message": "fix: Remove space"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d38aa593f791f440a1bf9f724b0f3da0d2067cc4", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/d38aa593f791f440a1bf9f724b0f3da0d2067cc4", "committedDate": "2020-08-11T23:26:53Z", "message": "feat: Add new line"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "408568ff5d8e5d455d25c5e69ab03a54b3fc6c8e", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/408568ff5d8e5d455d25c5e69ab03a54b3fc6c8e", "committedDate": "2020-08-12T00:26:57Z", "message": "fix: comparison"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8e42d8560987d0c78aa845159240a6b49fa5aae5", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/8e42d8560987d0c78aa845159240a6b49fa5aae5", "committedDate": "2020-08-13T17:47:08Z", "message": "docs: Fix little things"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "67094500a2745ce58fb213a3c6dec534588798dc", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/67094500a2745ce58fb213a3c6dec534588798dc", "committedDate": "2020-08-13T18:32:14Z", "message": "feat: remove trailing whitespaces"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "519fbaf79f88a1102908a1c669c711286597119a", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/519fbaf79f88a1102908a1c669c711286597119a", "committedDate": "2020-08-13T20:58:44Z", "message": "feat: Add message"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4c5ab4ca7b4f137dce5f65a6349e0f8f1aefecb5", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/4c5ab4ca7b4f137dce5f65a6349e0f8f1aefecb5", "committedDate": "2020-08-14T03:56:48Z", "message": "feat: minor changes in comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDc0OTMxMTE5", "url": "https://github.com/apache/beam/pull/12492#pullrequestreview-474931119", "createdAt": "2020-08-25T21:37:19Z", "commit": {"oid": "4c5ab4ca7b4f137dce5f65a6349e0f8f1aefecb5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNVQyMTozNzoxOVrOHGrHjg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNVQyMTozNzoxOVrOHGrHjg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njc1OTk1MA==", "bodyText": "I recall an issue related to very large files. What happens when we're trying to upload a large file?", "url": "https://github.com/apache/beam/pull/12492#discussion_r476759950", "createdAt": "2020-08-25T21:37:19Z", "author": {"login": "pabloem"}, "path": "sdks/python/apache_beam/io/azure/blobstorageio.py", "diffHunk": "@@ -0,0 +1,664 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Azure Blob Storage client.\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import errno\n+import io\n+import logging\n+import os\n+import re\n+import tempfile\n+import time\n+from builtins import object\n+\n+from apache_beam.io.filesystemio import Downloader\n+from apache_beam.io.filesystemio import DownloaderStream\n+from apache_beam.io.filesystemio import Uploader\n+from apache_beam.io.filesystemio import UploaderStream\n+from apache_beam.utils import retry\n+\n+_LOGGER = logging.getLogger(__name__)\n+\n+try:\n+  # pylint: disable=wrong-import-order, wrong-import-position\n+  # pylint: disable=ungrouped-imports\n+  from azure.core.exceptions import ResourceNotFoundError\n+  from azure.storage.blob import (\n+      BlobServiceClient,\n+      ContentSettings,\n+  )\n+  AZURE_DEPS_INSTALLED = True\n+except ImportError:\n+  AZURE_DEPS_INSTALLED = False\n+\n+DEFAULT_READ_BUFFER_SIZE = 16 * 1024 * 1024\n+\n+MAX_BATCH_OPERATION_SIZE = 100\n+\n+\n+def parse_azfs_path(azfs_path, blob_optional=False, get_account=False):\n+  \"\"\"Return the storage account, the container and\n+  blob names of the given azfs:// path.\n+  \"\"\"\n+  match = re.match(\n+      '^azfs://([a-z0-9]{3,24})/([a-z0-9](?![a-z0-9-]*--[a-z0-9-]*)'\n+      '[a-z0-9-]{1,61}[a-z0-9])/(.*)$',\n+      azfs_path)\n+  if match is None or (match.group(3) == '' and not blob_optional):\n+    raise ValueError(\n+        'Azure Blob Storage path must be in the form '\n+        'azfs://<storage-account>/<container>/<path>.')\n+  result = None\n+  if get_account:\n+    result = match.group(1), match.group(2), match.group(3)\n+  else:\n+    result = match.group(2), match.group(3)\n+  return result\n+\n+\n+def get_azfs_url(storage_account, container, blob=''):\n+  \"\"\"Returns the url in the form of\n+   https://account.blob.core.windows.net/container/blob-name\n+  \"\"\"\n+  return 'https://' + storage_account + '.blob.core.windows.net/' + \\\n+          container + '/' + blob\n+\n+\n+class Blob():\n+  \"\"\"A Blob in Azure Blob Storage.\"\"\"\n+  def __init__(self, etag, name, last_updated, size, mime_type):\n+    self.etag = etag\n+    self.name = name\n+    self.last_updated = last_updated\n+    self.size = size\n+    self.mime_type = mime_type\n+\n+\n+class BlobStorageIOError(IOError, retry.PermanentException):\n+  \"\"\"Blob Strorage IO error that should not be retried.\"\"\"\n+  pass\n+\n+\n+class BlobStorageError(Exception):\n+  \"\"\"Blob Storage client error.\"\"\"\n+  def __init__(self, message=None, code=None):\n+    self.message = message\n+    self.code = code\n+\n+\n+class BlobStorageIO(object):\n+  \"\"\"Azure Blob Storage I/O client.\"\"\"\n+  def __init__(self, client=None):\n+    connect_str = os.getenv('AZURE_STORAGE_CONNECTION_STRING')\n+    if client is None:\n+      self.client = BlobServiceClient.from_connection_string(connect_str)\n+    else:\n+      self.client = client\n+    if not AZURE_DEPS_INSTALLED:\n+      raise RuntimeError('Azure dependencies are not installed. Unable to run.')\n+\n+  def open(\n+      self,\n+      filename,\n+      mode='r',\n+      read_buffer_size=DEFAULT_READ_BUFFER_SIZE,\n+      mime_type='application/octet-stream'):\n+    \"\"\"Open an Azure Blob Storage file path for reading or writing.\n+\n+    Args:\n+      filename (str): Azure Blob Storage file path in the form\n+                      ``azfs://<storage-account>/<container>/<path>``.\n+      mode (str): ``'r'`` for reading or ``'w'`` for writing.\n+      read_buffer_size (int): Buffer size to use during read operations.\n+      mime_type (str): Mime type to set for write operations.\n+\n+    Returns:\n+      Azure Blob Storage file object.\n+    Raises:\n+      ValueError: Invalid open file mode.\n+    \"\"\"\n+    if mode == 'r' or mode == 'rb':\n+      downloader = BlobStorageDownloader(\n+          self.client, filename, buffer_size=read_buffer_size)\n+      return io.BufferedReader(\n+          DownloaderStream(\n+              downloader, read_buffer_size=read_buffer_size, mode=mode),\n+          buffer_size=read_buffer_size)\n+    elif mode == 'w' or mode == 'wb':\n+      uploader = BlobStorageUploader(self.client, filename, mime_type)\n+      return io.BufferedWriter(\n+          UploaderStream(uploader, mode=mode), buffer_size=128 * 1024)\n+    else:\n+      raise ValueError('Invalid file open mode: %s.' % mode)\n+\n+  @retry.with_exponential_backoff(\n+      retry_filter=retry.retry_on_beam_io_error_filter)\n+  def copy(self, src, dest):\n+    \"\"\"Copies a single Azure Blob Storage blob from src to dest.\n+\n+    Args:\n+      src: Blob Storage file path pattern in the form\n+           azfs://<storage-account>/<container>/[name].\n+      dest: Blob Storage file path pattern in the form\n+            azfs://<storage-account>/<container>/[name].\n+\n+    Raises:\n+      TimeoutError: on timeout.\n+    \"\"\"\n+    src_storage_account, src_container, src_blob = parse_azfs_path(\n+        src, get_account=True)\n+    dest_container, dest_blob = parse_azfs_path(dest)\n+\n+    source_blob = get_azfs_url(src_storage_account, src_container, src_blob)\n+    copied_blob = self.client.get_blob_client(dest_container, dest_blob)\n+\n+    try:\n+      copied_blob.start_copy_from_url(source_blob)\n+    except ResourceNotFoundError as e:\n+      message = e.reason\n+      code = e.status_code\n+      raise BlobStorageError(message, code)\n+\n+  # We intentionally do not decorate this method with a retry, since the\n+  # underlying copy operation is already an idempotent operation protected\n+  # by retry decorators.\n+  def copy_tree(self, src, dest):\n+    \"\"\"Renames the given Azure Blob storage directory and its contents\n+    recursively from src to dest.\n+\n+    Args:\n+      src: Blob Storage file path pattern in the form\n+           azfs://<storage-account>/<container>/[name].\n+      dest: Blob Storage file path pattern in the form\n+            azfs://<storage-account>/<container>/[name].\n+\n+    Returns:\n+      List of tuples of (src, dest, exception) where exception is None if the\n+      operation succeeded or the relevant exception if the operation failed.\n+    \"\"\"\n+    assert src.endswith('/')\n+    assert dest.endswith('/')\n+\n+    results = []\n+    for entry in self.list_prefix(src):\n+      rel_path = entry[len(src):]\n+      try:\n+        self.copy(entry, dest + rel_path)\n+        results.append((entry, dest + rel_path, None))\n+      except BlobStorageError as e:\n+        results.append((entry, dest + rel_path, e))\n+\n+    return results\n+\n+  # We intentionally do not decorate this method with a retry, since the\n+  # underlying copy operation is already an idempotent operation protected\n+  # by retry decorators.\n+  def copy_paths(self, src_dest_pairs):\n+    \"\"\"Copies the given Azure Blob Storage blobs from src to dest. This can\n+    handle directory or file paths.\n+\n+    Args:\n+      src_dest_pairs: List of (src, dest) tuples of\n+                      azfs://<storage-account>/<container>/[name] file paths\n+                      to copy from src to dest.\n+\n+    Returns:\n+      List of tuples of (src, dest, exception) in the same order as the\n+      src_dest_pairs argument, where exception is None if the operation\n+      succeeded or the relevant exception if the operation failed.\n+    \"\"\"\n+    if not src_dest_pairs:\n+      return []\n+\n+    results = []\n+\n+    for src_path, dest_path in src_dest_pairs:\n+      # Case 1. They are directories.\n+      if src_path.endswith('/') and dest_path.endswith('/'):\n+        try:\n+          results += self.copy_tree(src_path, dest_path)\n+        except BlobStorageError as e:\n+          results.append((src_path, dest_path, e))\n+\n+      # Case 2. They are individual blobs.\n+      elif not src_path.endswith('/') and not dest_path.endswith('/'):\n+        try:\n+          self.copy(src_path, dest_path)\n+          results.append((src_path, dest_path, None))\n+        except BlobStorageError as e:\n+          results.append((src_path, dest_path, e))\n+\n+      # Mismatched paths (one directory, one non-directory) get an error.\n+      else:\n+        e = BlobStorageError(\n+            \"Unable to copy mismatched paths\" +\n+            \"(directory, non-directory): %s, %s\" % (src_path, dest_path),\n+            400)\n+        results.append((src_path, dest_path, e))\n+\n+    return results\n+\n+  # We intentionally do not decorate this method with a retry, since the\n+  # underlying copy and delete operations are already idempotent operations\n+  # protected by retry decorators.\n+  def rename(self, src, dest):\n+    \"\"\"Renames the given Azure Blob Storage blob from src to dest.\n+\n+    Args:\n+      src: Blob Storage file path pattern in the form\n+           azfs://<storage-account>/<container>/[name].\n+      dest: Blob Storage file path pattern in the form\n+            azfs://<storage-account>/<container>/[name].\n+    \"\"\"\n+    self.copy(src, dest)\n+    self.delete(src)\n+\n+  # We intentionally do not decorate this method with a retry, since the\n+  # underlying copy and delete operations are already idempotent operations\n+  # protected by retry decorators.\n+  def rename_files(self, src_dest_pairs):\n+    \"\"\"Renames the given Azure Blob Storage blobs from src to dest.\n+\n+    Args:\n+      src_dest_pairs: List of (src, dest) tuples of\n+                      azfs://<storage-account>/<container>/[name]\n+                      file paths to rename from src to dest.\n+    Returns: List of tuples of (src, dest, exception) in the same order as the\n+             src_dest_pairs argument, where exception is None if the operation\n+             succeeded or the relevant exception if the operation failed.\n+    \"\"\"\n+    if not src_dest_pairs:\n+      return []\n+\n+    for src, dest in src_dest_pairs:\n+      if src.endswith('/') or dest.endswith('/'):\n+        raise ValueError('Unable to rename a directory.')\n+\n+    # Results from copy operation.\n+    copy_results = self.copy_paths(src_dest_pairs)\n+    paths_to_delete = \\\n+        [src for (src, _, error) in copy_results if error is None]\n+    # Results from delete operation.\n+    delete_results = self.delete_files(paths_to_delete)\n+\n+    # Get rename file results (list of tuples).\n+    results = []\n+\n+    # Using a dictionary will make the operation faster.\n+    delete_results_dict = {src: error for (src, error) in delete_results}\n+\n+    for src, dest, error in copy_results:\n+      # If there was an error in the copy operation.\n+      if error is not None:\n+        results.append((src, dest, error))\n+      # If there was an error in the delete operation.\n+      elif delete_results_dict[src] is not None:\n+        results.append((src, dest, delete_results_dict[src]))\n+      # If there was no error in the operations.\n+      else:\n+        results.append((src, dest, None))\n+\n+    return results\n+\n+  @retry.with_exponential_backoff(\n+      retry_filter=retry.retry_on_beam_io_error_filter)\n+  def exists(self, path):\n+    \"\"\"Returns whether the given Azure Blob Storage blob exists.\n+\n+    Args:\n+      path: Azure Blob Storage file path pattern in the form\n+            azfs://<storage-account>/<container>/[name].\n+    \"\"\"\n+    container, blob = parse_azfs_path(path)\n+    blob_to_check = self.client.get_blob_client(container, blob)\n+    try:\n+      blob_to_check.get_blob_properties()\n+      return True\n+    except ResourceNotFoundError as e:\n+      if e.status_code == 404:\n+        # HTTP 404 indicates that the file did not exist.\n+        return False\n+      else:\n+        # We re-raise all other exceptions.\n+        raise\n+\n+  @retry.with_exponential_backoff(\n+      retry_filter=retry.retry_on_beam_io_error_filter)\n+  def size(self, path):\n+    \"\"\"Returns the size of a single Blob Storage blob.\n+\n+    This method does not perform glob expansion. Hence the\n+    given path must be for a single Blob Storage blob.\n+\n+    Returns: size of the Blob Storage blob in bytes.\n+    \"\"\"\n+    container, blob = parse_azfs_path(path)\n+    blob_to_check = self.client.get_blob_client(container, blob)\n+    try:\n+      properties = blob_to_check.get_blob_properties()\n+    except ResourceNotFoundError as e:\n+      message = e.reason\n+      code = e.status_code\n+      raise BlobStorageError(message, code)\n+\n+    return properties.size\n+\n+  @retry.with_exponential_backoff(\n+      retry_filter=retry.retry_on_beam_io_error_filter)\n+  def last_updated(self, path):\n+    \"\"\"Returns the last updated epoch time of a single\n+    Azure Blob Storage blob.\n+\n+    This method does not perform glob expansion. Hence the\n+    given path must be for a single Azure Blob Storage blob.\n+\n+    Returns: last updated time of the Azure Blob Storage blob\n+    in seconds.\n+    \"\"\"\n+    container, blob = parse_azfs_path(path)\n+    blob_to_check = self.client.get_blob_client(container, blob)\n+    try:\n+      properties = blob_to_check.get_blob_properties()\n+    except ResourceNotFoundError as e:\n+      message = e.reason\n+      code = e.status_code\n+      raise BlobStorageError(message, code)\n+\n+    datatime = properties.last_modified\n+    return (\n+        time.mktime(datatime.timetuple()) - time.timezone +\n+        datatime.microsecond / 1000000.0)\n+\n+  @retry.with_exponential_backoff(\n+      retry_filter=retry.retry_on_beam_io_error_filter)\n+  def checksum(self, path):\n+    \"\"\"Looks up the checksum of an Azure Blob Storage blob.\n+\n+    Args:\n+      path: Azure Blob Storage file path pattern in the form\n+            azfs://<storage-account>/<container>/[name].\n+    \"\"\"\n+    container, blob = parse_azfs_path(path)\n+    blob_to_check = self.client.get_blob_client(container, blob)\n+    try:\n+      properties = blob_to_check.get_blob_properties()\n+    except ResourceNotFoundError as e:\n+      message = e.reason\n+      code = e.status_code\n+      raise BlobStorageError(message, code)\n+\n+    return properties.etag\n+\n+  @retry.with_exponential_backoff(\n+      retry_filter=retry.retry_on_beam_io_error_filter)\n+  def delete(self, path):\n+    \"\"\"Deletes a single blob at the given Azure Blob Storage path.\n+\n+    Args:\n+      path: Azure Blob Storage file path pattern in the form\n+            azfs://<storage-account>/<container>/[name].\n+    \"\"\"\n+    container, blob = parse_azfs_path(path)\n+    blob_to_delete = self.client.get_blob_client(container, blob)\n+    try:\n+      blob_to_delete.delete_blob()\n+    except ResourceNotFoundError as e:\n+      if e.status_code == 404:\n+        # Return success when the file doesn't exist anymore for idempotency.\n+        return\n+      else:\n+        logging.error('HTTP error while deleting file %s', path)\n+        raise e\n+\n+  # We intentionally do not decorate this method with a retry, since the\n+  # underlying copy and delete operations are already idempotent operations\n+  # protected by retry decorators.\n+  def delete_paths(self, paths):\n+    \"\"\"Deletes the given Azure Blob Storage blobs from src to dest.\n+    This can handle directory or file paths.\n+\n+    Args:\n+      paths: list of Azure Blob Storage paths in the form\n+             azfs://<storage-account>/<container>/[name] that give the\n+             file blobs to be deleted.\n+\n+    Returns:\n+      List of tuples of (src, dest, exception) in the same order as the\n+      src_dest_pairs argument, where exception is 202 if the operation\n+      succeeded or the relevant exception if the operation failed.\n+    \"\"\"\n+    directories, blobs = [], []\n+\n+    # Retrieve directories and not directories.\n+    for path in paths:\n+      if path.endswith('/'):\n+        directories.append(path)\n+      else:\n+        blobs.append(path)\n+\n+    results = {}\n+\n+    for directory in directories:\n+      directory_result = dict(self.delete_tree(directory))\n+      results.update(directory_result)\n+\n+    blobs_results = dict(self.delete_files(blobs))\n+    results.update(blobs_results)\n+\n+    return results\n+\n+  # We intentionally do not decorate this method with a retry, since the\n+  # underlying copy and delete operations are already idempotent operations\n+  # protected by retry decorators.\n+  def delete_tree(self, root):\n+    \"\"\"Deletes all blobs under the given Azure BlobStorage virtual\n+    directory.\n+\n+    Args:\n+      path: Azure Blob Storage file path pattern in the form\n+            azfs://<storage-account>/<container>/[name]\n+            (ending with a \"/\").\n+\n+    Returns:\n+      List of tuples of (path, exception), where each path is a blob\n+      under the given root. exception is 202 if the operation succeeded\n+      or the relevant exception if the operation failed.\n+    \"\"\"\n+    assert root.endswith('/')\n+\n+    # Get the blob under the root directory.\n+    paths_to_delete = self.list_prefix(root)\n+\n+    return self.delete_files(paths_to_delete)\n+\n+  # We intentionally do not decorate this method with a retry, since the\n+  # underlying copy and delete operations are already idempotent operations\n+  # protected by retry decorators.\n+  def delete_files(self, paths):\n+    \"\"\"Deletes the given Azure Blob Storage blobs from src to dest.\n+\n+    Args:\n+      paths: list of Azure Blob Storage paths in the form\n+             azfs://<storage-account>/<container>/[name] that give the\n+             file blobs to be deleted.\n+\n+    Returns:\n+      List of tuples of (src, dest, exception) in the same order as the\n+      src_dest_pairs argument, where exception is 202 if the operation\n+      succeeded or the relevant exception if the operation failed.\n+    \"\"\"\n+    if not paths:\n+      return []\n+\n+    # Group blobs into containers.\n+    containers, blobs = zip(*[parse_azfs_path(path, get_account=False) \\\n+        for path in paths])\n+\n+    grouped_blobs = {container: [] for container in containers}\n+\n+    # Fill dictionary.\n+    for container, blob in zip(containers, blobs):\n+      grouped_blobs[container].append(blob)\n+\n+    results = {}\n+\n+    # Delete minibatches of blobs for each container.\n+    for container, blobs in grouped_blobs.items():\n+      for i in range(0, len(blobs), MAX_BATCH_OPERATION_SIZE):\n+        blobs_to_delete = blobs[i:i + MAX_BATCH_OPERATION_SIZE]\n+        results.update(self._delete_batch(container, blobs_to_delete))\n+\n+    final_results = \\\n+        [(path, results[parse_azfs_path(path, get_account=False)]) \\\n+        for path in paths]\n+\n+    return final_results\n+\n+  @retry.with_exponential_backoff(\n+      retry_filter=retry.retry_on_beam_io_error_filter)\n+  def _delete_batch(self, container, blobs):\n+    \"\"\"A helper method. Azure Blob Storage Python Client allows batch\n+    deletions for blobs within the same container.\n+\n+    Args:\n+      container: container name.\n+      blobs: list of blobs to be deleted.\n+\n+    Returns:\n+      Dictionary of the form {(container, blob): error}, where error is\n+      202 if the operation succeeded.\n+    \"\"\"\n+    container_client = self.client.get_container_client(container)\n+    results = {}\n+\n+    try:\n+      response = container_client.delete_blobs(\n+          *blobs, raise_on_any_failure=False)\n+\n+      for blob, error in zip(blobs, response):\n+        results[(container, blob)] = error.status_code\n+\n+    except BlobStorageError as e:\n+      for blob in blobs:\n+        results[(container, blob)] = e.message\n+\n+    return results\n+\n+  @retry.with_exponential_backoff(\n+      retry_filter=retry.retry_on_beam_io_error_filter)\n+  def list_prefix(self, path):\n+    \"\"\"Lists files matching the prefix.\n+\n+    Args:\n+      path: Azure Blob Storage file path pattern in the form\n+            azfs://<storage-account>/<container>/[name].\n+\n+    Returns:\n+      Dictionary of file name -> size.\n+    \"\"\"\n+    storage_account, container, blob = parse_azfs_path(\n+        path, blob_optional=True, get_account=True)\n+    file_sizes = {}\n+    counter = 0\n+    start_time = time.time()\n+\n+    logging.info(\"Starting the size estimation of the input\")\n+    container_client = self.client.get_container_client(container)\n+\n+    while True:\n+      response = container_client.list_blobs(name_starts_with=blob)\n+      for item in response:\n+        file_name = \"azfs://%s/%s/%s\" % (storage_account, container, item.name)\n+        file_sizes[file_name] = item.size\n+        counter += 1\n+        if counter % 10000 == 0:\n+          logging.info(\"Finished computing size of: %s files\", len(file_sizes))\n+      break\n+\n+    logging.info(\n+        \"Finished listing %s files in %s seconds.\",\n+        counter,\n+        time.time() - start_time)\n+    return file_sizes\n+\n+\n+class BlobStorageDownloader(Downloader):\n+  def __init__(self, client, path, buffer_size):\n+    self._client = client\n+    self._path = path\n+    self._container, self._blob = parse_azfs_path(path)\n+    self._buffer_size = buffer_size\n+\n+    self._blob_to_download = self._client.get_blob_client(\n+        self._container, self._blob)\n+\n+    try:\n+      properties = self._get_object_properties()\n+    except ResourceNotFoundError as http_error:\n+      if http_error.status_code == 404:\n+        raise IOError(errno.ENOENT, 'Not found: %s' % self._path)\n+      else:\n+        _LOGGER.error(\n+            'HTTP error while requesting file %s: %s', self._path, http_error)\n+        raise\n+\n+    self._size = properties.size\n+\n+  @retry.with_exponential_backoff(\n+      retry_filter=retry.retry_on_beam_io_error_filter)\n+  def _get_object_properties(self):\n+    return self._blob_to_download.get_blob_properties()\n+\n+  @property\n+  def size(self):\n+    return self._size\n+\n+  def get_range(self, start, end):\n+    # Download_blob first parameter is offset and second is length (exclusive).\n+    blob_data = self._blob_to_download.download_blob(start, end - start)\n+    # Returns the content as bytes.\n+    return blob_data.readall()\n+\n+\n+class BlobStorageUploader(Uploader):\n+  def __init__(self, client, path, mime_type='application/octet-stream'):\n+    self._client = client\n+    self._path = path\n+    self._container, self._blob = parse_azfs_path(path)\n+    self._content_settings = ContentSettings(mime_type)\n+\n+    self._blob_to_upload = self._client.get_blob_client(\n+        self._container, self._blob)\n+\n+    # Temporary file.\n+    self._temporary_file = tempfile.NamedTemporaryFile()\n+\n+  def put(self, data):\n+    self._temporary_file.write(data.tobytes())\n+\n+  def finish(self):\n+    self._temporary_file.seek(0)\n+    # The temporary file is deleted immediately after the operation.\n+    with open(self._temporary_file.name, \"rb\") as f:\n+      self._blob_to_upload.upload_blob(\n+          f.read(), overwrite=True, content_settings=self._content_settings)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4c5ab4ca7b4f137dce5f65a6349e0f8f1aefecb5"}, "originalPosition": 664}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDc0OTQwMjMw", "url": "https://github.com/apache/beam/pull/12492#pullrequestreview-474940230", "createdAt": "2020-08-25T21:54:39Z", "commit": {"oid": "4c5ab4ca7b4f137dce5f65a6349e0f8f1aefecb5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNVQyMTo1NDozOVrOHGsAJg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNVQyMTo1NDozOVrOHGsAJg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njc3NDQzOA==", "bodyText": "@AldairCoronel not sure if you've faced this issue when testing yourself, but when I tried using this code in my own project, I ran into this error: Azure/azure-sdk-for-python#13183\nI had to work around it by calling delete_blob instead of delete_blobs: codalab/codalab-worksheets@1e3dd30.\nNot sure if you faced a similar issue, but adding this here in case it's helpful.", "url": "https://github.com/apache/beam/pull/12492#discussion_r476774438", "createdAt": "2020-08-25T21:54:39Z", "author": {"login": "epicfaace"}, "path": "sdks/python/apache_beam/io/azure/blobstorageio.py", "diffHunk": "@@ -0,0 +1,664 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Azure Blob Storage client.\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import errno\n+import io\n+import logging\n+import os\n+import re\n+import tempfile\n+import time\n+from builtins import object\n+\n+from apache_beam.io.filesystemio import Downloader\n+from apache_beam.io.filesystemio import DownloaderStream\n+from apache_beam.io.filesystemio import Uploader\n+from apache_beam.io.filesystemio import UploaderStream\n+from apache_beam.utils import retry\n+\n+_LOGGER = logging.getLogger(__name__)\n+\n+try:\n+  # pylint: disable=wrong-import-order, wrong-import-position\n+  # pylint: disable=ungrouped-imports\n+  from azure.core.exceptions import ResourceNotFoundError\n+  from azure.storage.blob import (\n+      BlobServiceClient,\n+      ContentSettings,\n+  )\n+  AZURE_DEPS_INSTALLED = True\n+except ImportError:\n+  AZURE_DEPS_INSTALLED = False\n+\n+DEFAULT_READ_BUFFER_SIZE = 16 * 1024 * 1024\n+\n+MAX_BATCH_OPERATION_SIZE = 100\n+\n+\n+def parse_azfs_path(azfs_path, blob_optional=False, get_account=False):\n+  \"\"\"Return the storage account, the container and\n+  blob names of the given azfs:// path.\n+  \"\"\"\n+  match = re.match(\n+      '^azfs://([a-z0-9]{3,24})/([a-z0-9](?![a-z0-9-]*--[a-z0-9-]*)'\n+      '[a-z0-9-]{1,61}[a-z0-9])/(.*)$',\n+      azfs_path)\n+  if match is None or (match.group(3) == '' and not blob_optional):\n+    raise ValueError(\n+        'Azure Blob Storage path must be in the form '\n+        'azfs://<storage-account>/<container>/<path>.')\n+  result = None\n+  if get_account:\n+    result = match.group(1), match.group(2), match.group(3)\n+  else:\n+    result = match.group(2), match.group(3)\n+  return result\n+\n+\n+def get_azfs_url(storage_account, container, blob=''):\n+  \"\"\"Returns the url in the form of\n+   https://account.blob.core.windows.net/container/blob-name\n+  \"\"\"\n+  return 'https://' + storage_account + '.blob.core.windows.net/' + \\\n+          container + '/' + blob\n+\n+\n+class Blob():\n+  \"\"\"A Blob in Azure Blob Storage.\"\"\"\n+  def __init__(self, etag, name, last_updated, size, mime_type):\n+    self.etag = etag\n+    self.name = name\n+    self.last_updated = last_updated\n+    self.size = size\n+    self.mime_type = mime_type\n+\n+\n+class BlobStorageIOError(IOError, retry.PermanentException):\n+  \"\"\"Blob Strorage IO error that should not be retried.\"\"\"\n+  pass\n+\n+\n+class BlobStorageError(Exception):\n+  \"\"\"Blob Storage client error.\"\"\"\n+  def __init__(self, message=None, code=None):\n+    self.message = message\n+    self.code = code\n+\n+\n+class BlobStorageIO(object):\n+  \"\"\"Azure Blob Storage I/O client.\"\"\"\n+  def __init__(self, client=None):\n+    connect_str = os.getenv('AZURE_STORAGE_CONNECTION_STRING')\n+    if client is None:\n+      self.client = BlobServiceClient.from_connection_string(connect_str)\n+    else:\n+      self.client = client\n+    if not AZURE_DEPS_INSTALLED:\n+      raise RuntimeError('Azure dependencies are not installed. Unable to run.')\n+\n+  def open(\n+      self,\n+      filename,\n+      mode='r',\n+      read_buffer_size=DEFAULT_READ_BUFFER_SIZE,\n+      mime_type='application/octet-stream'):\n+    \"\"\"Open an Azure Blob Storage file path for reading or writing.\n+\n+    Args:\n+      filename (str): Azure Blob Storage file path in the form\n+                      ``azfs://<storage-account>/<container>/<path>``.\n+      mode (str): ``'r'`` for reading or ``'w'`` for writing.\n+      read_buffer_size (int): Buffer size to use during read operations.\n+      mime_type (str): Mime type to set for write operations.\n+\n+    Returns:\n+      Azure Blob Storage file object.\n+    Raises:\n+      ValueError: Invalid open file mode.\n+    \"\"\"\n+    if mode == 'r' or mode == 'rb':\n+      downloader = BlobStorageDownloader(\n+          self.client, filename, buffer_size=read_buffer_size)\n+      return io.BufferedReader(\n+          DownloaderStream(\n+              downloader, read_buffer_size=read_buffer_size, mode=mode),\n+          buffer_size=read_buffer_size)\n+    elif mode == 'w' or mode == 'wb':\n+      uploader = BlobStorageUploader(self.client, filename, mime_type)\n+      return io.BufferedWriter(\n+          UploaderStream(uploader, mode=mode), buffer_size=128 * 1024)\n+    else:\n+      raise ValueError('Invalid file open mode: %s.' % mode)\n+\n+  @retry.with_exponential_backoff(\n+      retry_filter=retry.retry_on_beam_io_error_filter)\n+  def copy(self, src, dest):\n+    \"\"\"Copies a single Azure Blob Storage blob from src to dest.\n+\n+    Args:\n+      src: Blob Storage file path pattern in the form\n+           azfs://<storage-account>/<container>/[name].\n+      dest: Blob Storage file path pattern in the form\n+            azfs://<storage-account>/<container>/[name].\n+\n+    Raises:\n+      TimeoutError: on timeout.\n+    \"\"\"\n+    src_storage_account, src_container, src_blob = parse_azfs_path(\n+        src, get_account=True)\n+    dest_container, dest_blob = parse_azfs_path(dest)\n+\n+    source_blob = get_azfs_url(src_storage_account, src_container, src_blob)\n+    copied_blob = self.client.get_blob_client(dest_container, dest_blob)\n+\n+    try:\n+      copied_blob.start_copy_from_url(source_blob)\n+    except ResourceNotFoundError as e:\n+      message = e.reason\n+      code = e.status_code\n+      raise BlobStorageError(message, code)\n+\n+  # We intentionally do not decorate this method with a retry, since the\n+  # underlying copy operation is already an idempotent operation protected\n+  # by retry decorators.\n+  def copy_tree(self, src, dest):\n+    \"\"\"Renames the given Azure Blob storage directory and its contents\n+    recursively from src to dest.\n+\n+    Args:\n+      src: Blob Storage file path pattern in the form\n+           azfs://<storage-account>/<container>/[name].\n+      dest: Blob Storage file path pattern in the form\n+            azfs://<storage-account>/<container>/[name].\n+\n+    Returns:\n+      List of tuples of (src, dest, exception) where exception is None if the\n+      operation succeeded or the relevant exception if the operation failed.\n+    \"\"\"\n+    assert src.endswith('/')\n+    assert dest.endswith('/')\n+\n+    results = []\n+    for entry in self.list_prefix(src):\n+      rel_path = entry[len(src):]\n+      try:\n+        self.copy(entry, dest + rel_path)\n+        results.append((entry, dest + rel_path, None))\n+      except BlobStorageError as e:\n+        results.append((entry, dest + rel_path, e))\n+\n+    return results\n+\n+  # We intentionally do not decorate this method with a retry, since the\n+  # underlying copy operation is already an idempotent operation protected\n+  # by retry decorators.\n+  def copy_paths(self, src_dest_pairs):\n+    \"\"\"Copies the given Azure Blob Storage blobs from src to dest. This can\n+    handle directory or file paths.\n+\n+    Args:\n+      src_dest_pairs: List of (src, dest) tuples of\n+                      azfs://<storage-account>/<container>/[name] file paths\n+                      to copy from src to dest.\n+\n+    Returns:\n+      List of tuples of (src, dest, exception) in the same order as the\n+      src_dest_pairs argument, where exception is None if the operation\n+      succeeded or the relevant exception if the operation failed.\n+    \"\"\"\n+    if not src_dest_pairs:\n+      return []\n+\n+    results = []\n+\n+    for src_path, dest_path in src_dest_pairs:\n+      # Case 1. They are directories.\n+      if src_path.endswith('/') and dest_path.endswith('/'):\n+        try:\n+          results += self.copy_tree(src_path, dest_path)\n+        except BlobStorageError as e:\n+          results.append((src_path, dest_path, e))\n+\n+      # Case 2. They are individual blobs.\n+      elif not src_path.endswith('/') and not dest_path.endswith('/'):\n+        try:\n+          self.copy(src_path, dest_path)\n+          results.append((src_path, dest_path, None))\n+        except BlobStorageError as e:\n+          results.append((src_path, dest_path, e))\n+\n+      # Mismatched paths (one directory, one non-directory) get an error.\n+      else:\n+        e = BlobStorageError(\n+            \"Unable to copy mismatched paths\" +\n+            \"(directory, non-directory): %s, %s\" % (src_path, dest_path),\n+            400)\n+        results.append((src_path, dest_path, e))\n+\n+    return results\n+\n+  # We intentionally do not decorate this method with a retry, since the\n+  # underlying copy and delete operations are already idempotent operations\n+  # protected by retry decorators.\n+  def rename(self, src, dest):\n+    \"\"\"Renames the given Azure Blob Storage blob from src to dest.\n+\n+    Args:\n+      src: Blob Storage file path pattern in the form\n+           azfs://<storage-account>/<container>/[name].\n+      dest: Blob Storage file path pattern in the form\n+            azfs://<storage-account>/<container>/[name].\n+    \"\"\"\n+    self.copy(src, dest)\n+    self.delete(src)\n+\n+  # We intentionally do not decorate this method with a retry, since the\n+  # underlying copy and delete operations are already idempotent operations\n+  # protected by retry decorators.\n+  def rename_files(self, src_dest_pairs):\n+    \"\"\"Renames the given Azure Blob Storage blobs from src to dest.\n+\n+    Args:\n+      src_dest_pairs: List of (src, dest) tuples of\n+                      azfs://<storage-account>/<container>/[name]\n+                      file paths to rename from src to dest.\n+    Returns: List of tuples of (src, dest, exception) in the same order as the\n+             src_dest_pairs argument, where exception is None if the operation\n+             succeeded or the relevant exception if the operation failed.\n+    \"\"\"\n+    if not src_dest_pairs:\n+      return []\n+\n+    for src, dest in src_dest_pairs:\n+      if src.endswith('/') or dest.endswith('/'):\n+        raise ValueError('Unable to rename a directory.')\n+\n+    # Results from copy operation.\n+    copy_results = self.copy_paths(src_dest_pairs)\n+    paths_to_delete = \\\n+        [src for (src, _, error) in copy_results if error is None]\n+    # Results from delete operation.\n+    delete_results = self.delete_files(paths_to_delete)\n+\n+    # Get rename file results (list of tuples).\n+    results = []\n+\n+    # Using a dictionary will make the operation faster.\n+    delete_results_dict = {src: error for (src, error) in delete_results}\n+\n+    for src, dest, error in copy_results:\n+      # If there was an error in the copy operation.\n+      if error is not None:\n+        results.append((src, dest, error))\n+      # If there was an error in the delete operation.\n+      elif delete_results_dict[src] is not None:\n+        results.append((src, dest, delete_results_dict[src]))\n+      # If there was no error in the operations.\n+      else:\n+        results.append((src, dest, None))\n+\n+    return results\n+\n+  @retry.with_exponential_backoff(\n+      retry_filter=retry.retry_on_beam_io_error_filter)\n+  def exists(self, path):\n+    \"\"\"Returns whether the given Azure Blob Storage blob exists.\n+\n+    Args:\n+      path: Azure Blob Storage file path pattern in the form\n+            azfs://<storage-account>/<container>/[name].\n+    \"\"\"\n+    container, blob = parse_azfs_path(path)\n+    blob_to_check = self.client.get_blob_client(container, blob)\n+    try:\n+      blob_to_check.get_blob_properties()\n+      return True\n+    except ResourceNotFoundError as e:\n+      if e.status_code == 404:\n+        # HTTP 404 indicates that the file did not exist.\n+        return False\n+      else:\n+        # We re-raise all other exceptions.\n+        raise\n+\n+  @retry.with_exponential_backoff(\n+      retry_filter=retry.retry_on_beam_io_error_filter)\n+  def size(self, path):\n+    \"\"\"Returns the size of a single Blob Storage blob.\n+\n+    This method does not perform glob expansion. Hence the\n+    given path must be for a single Blob Storage blob.\n+\n+    Returns: size of the Blob Storage blob in bytes.\n+    \"\"\"\n+    container, blob = parse_azfs_path(path)\n+    blob_to_check = self.client.get_blob_client(container, blob)\n+    try:\n+      properties = blob_to_check.get_blob_properties()\n+    except ResourceNotFoundError as e:\n+      message = e.reason\n+      code = e.status_code\n+      raise BlobStorageError(message, code)\n+\n+    return properties.size\n+\n+  @retry.with_exponential_backoff(\n+      retry_filter=retry.retry_on_beam_io_error_filter)\n+  def last_updated(self, path):\n+    \"\"\"Returns the last updated epoch time of a single\n+    Azure Blob Storage blob.\n+\n+    This method does not perform glob expansion. Hence the\n+    given path must be for a single Azure Blob Storage blob.\n+\n+    Returns: last updated time of the Azure Blob Storage blob\n+    in seconds.\n+    \"\"\"\n+    container, blob = parse_azfs_path(path)\n+    blob_to_check = self.client.get_blob_client(container, blob)\n+    try:\n+      properties = blob_to_check.get_blob_properties()\n+    except ResourceNotFoundError as e:\n+      message = e.reason\n+      code = e.status_code\n+      raise BlobStorageError(message, code)\n+\n+    datatime = properties.last_modified\n+    return (\n+        time.mktime(datatime.timetuple()) - time.timezone +\n+        datatime.microsecond / 1000000.0)\n+\n+  @retry.with_exponential_backoff(\n+      retry_filter=retry.retry_on_beam_io_error_filter)\n+  def checksum(self, path):\n+    \"\"\"Looks up the checksum of an Azure Blob Storage blob.\n+\n+    Args:\n+      path: Azure Blob Storage file path pattern in the form\n+            azfs://<storage-account>/<container>/[name].\n+    \"\"\"\n+    container, blob = parse_azfs_path(path)\n+    blob_to_check = self.client.get_blob_client(container, blob)\n+    try:\n+      properties = blob_to_check.get_blob_properties()\n+    except ResourceNotFoundError as e:\n+      message = e.reason\n+      code = e.status_code\n+      raise BlobStorageError(message, code)\n+\n+    return properties.etag\n+\n+  @retry.with_exponential_backoff(\n+      retry_filter=retry.retry_on_beam_io_error_filter)\n+  def delete(self, path):\n+    \"\"\"Deletes a single blob at the given Azure Blob Storage path.\n+\n+    Args:\n+      path: Azure Blob Storage file path pattern in the form\n+            azfs://<storage-account>/<container>/[name].\n+    \"\"\"\n+    container, blob = parse_azfs_path(path)\n+    blob_to_delete = self.client.get_blob_client(container, blob)\n+    try:\n+      blob_to_delete.delete_blob()\n+    except ResourceNotFoundError as e:\n+      if e.status_code == 404:\n+        # Return success when the file doesn't exist anymore for idempotency.\n+        return\n+      else:\n+        logging.error('HTTP error while deleting file %s', path)\n+        raise e\n+\n+  # We intentionally do not decorate this method with a retry, since the\n+  # underlying copy and delete operations are already idempotent operations\n+  # protected by retry decorators.\n+  def delete_paths(self, paths):", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4c5ab4ca7b4f137dce5f65a6349e0f8f1aefecb5"}, "originalPosition": 436}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDc0OTQxOTE4", "url": "https://github.com/apache/beam/pull/12492#pullrequestreview-474941918", "createdAt": "2020-08-25T21:57:43Z", "commit": {"oid": "4c5ab4ca7b4f137dce5f65a6349e0f8f1aefecb5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNVQyMTo1Nzo0M1rOHGsKIg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNVQyMTo1Nzo0M1rOHGsKIg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3Njc3Njk5NA==", "bodyText": "I think you should handle both BlobStorageError and PartialBatchErrorException on all blob storage operations (PartialBatchErrorException is raised in, for example, Azure/azure-sdk-for-python#13183) -- otherwise, what ends up happening is that only the status code from PartialBatchErrorException is retrieved, but the message is silenced and not logged at all.", "url": "https://github.com/apache/beam/pull/12492#discussion_r476776994", "createdAt": "2020-08-25T21:57:43Z", "author": {"login": "epicfaace"}, "path": "sdks/python/apache_beam/io/azure/blobstorageio.py", "diffHunk": "@@ -0,0 +1,664 @@\n+#\n+# Licensed to the Apache Software Foundation (ASF) under one or more\n+# contributor license agreements.  See the NOTICE file distributed with\n+# this work for additional information regarding copyright ownership.\n+# The ASF licenses this file to You under the Apache License, Version 2.0\n+# (the \"License\"); you may not use this file except in compliance with\n+# the License.  You may obtain a copy of the License at\n+#\n+#    http://www.apache.org/licenses/LICENSE-2.0\n+#\n+# Unless required by applicable law or agreed to in writing, software\n+# distributed under the License is distributed on an \"AS IS\" BASIS,\n+# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+# See the License for the specific language governing permissions and\n+# limitations under the License.\n+#\n+\n+\"\"\"Azure Blob Storage client.\n+\"\"\"\n+\n+# pytype: skip-file\n+\n+from __future__ import absolute_import\n+\n+import errno\n+import io\n+import logging\n+import os\n+import re\n+import tempfile\n+import time\n+from builtins import object\n+\n+from apache_beam.io.filesystemio import Downloader\n+from apache_beam.io.filesystemio import DownloaderStream\n+from apache_beam.io.filesystemio import Uploader\n+from apache_beam.io.filesystemio import UploaderStream\n+from apache_beam.utils import retry\n+\n+_LOGGER = logging.getLogger(__name__)\n+\n+try:\n+  # pylint: disable=wrong-import-order, wrong-import-position\n+  # pylint: disable=ungrouped-imports\n+  from azure.core.exceptions import ResourceNotFoundError\n+  from azure.storage.blob import (\n+      BlobServiceClient,\n+      ContentSettings,\n+  )\n+  AZURE_DEPS_INSTALLED = True\n+except ImportError:\n+  AZURE_DEPS_INSTALLED = False\n+\n+DEFAULT_READ_BUFFER_SIZE = 16 * 1024 * 1024\n+\n+MAX_BATCH_OPERATION_SIZE = 100\n+\n+\n+def parse_azfs_path(azfs_path, blob_optional=False, get_account=False):\n+  \"\"\"Return the storage account, the container and\n+  blob names of the given azfs:// path.\n+  \"\"\"\n+  match = re.match(\n+      '^azfs://([a-z0-9]{3,24})/([a-z0-9](?![a-z0-9-]*--[a-z0-9-]*)'\n+      '[a-z0-9-]{1,61}[a-z0-9])/(.*)$',\n+      azfs_path)\n+  if match is None or (match.group(3) == '' and not blob_optional):\n+    raise ValueError(\n+        'Azure Blob Storage path must be in the form '\n+        'azfs://<storage-account>/<container>/<path>.')\n+  result = None\n+  if get_account:\n+    result = match.group(1), match.group(2), match.group(3)\n+  else:\n+    result = match.group(2), match.group(3)\n+  return result\n+\n+\n+def get_azfs_url(storage_account, container, blob=''):\n+  \"\"\"Returns the url in the form of\n+   https://account.blob.core.windows.net/container/blob-name\n+  \"\"\"\n+  return 'https://' + storage_account + '.blob.core.windows.net/' + \\\n+          container + '/' + blob\n+\n+\n+class Blob():\n+  \"\"\"A Blob in Azure Blob Storage.\"\"\"\n+  def __init__(self, etag, name, last_updated, size, mime_type):\n+    self.etag = etag\n+    self.name = name\n+    self.last_updated = last_updated\n+    self.size = size\n+    self.mime_type = mime_type\n+\n+\n+class BlobStorageIOError(IOError, retry.PermanentException):\n+  \"\"\"Blob Strorage IO error that should not be retried.\"\"\"\n+  pass\n+\n+\n+class BlobStorageError(Exception):\n+  \"\"\"Blob Storage client error.\"\"\"\n+  def __init__(self, message=None, code=None):\n+    self.message = message\n+    self.code = code\n+\n+\n+class BlobStorageIO(object):\n+  \"\"\"Azure Blob Storage I/O client.\"\"\"\n+  def __init__(self, client=None):\n+    connect_str = os.getenv('AZURE_STORAGE_CONNECTION_STRING')\n+    if client is None:\n+      self.client = BlobServiceClient.from_connection_string(connect_str)\n+    else:\n+      self.client = client\n+    if not AZURE_DEPS_INSTALLED:\n+      raise RuntimeError('Azure dependencies are not installed. Unable to run.')\n+\n+  def open(\n+      self,\n+      filename,\n+      mode='r',\n+      read_buffer_size=DEFAULT_READ_BUFFER_SIZE,\n+      mime_type='application/octet-stream'):\n+    \"\"\"Open an Azure Blob Storage file path for reading or writing.\n+\n+    Args:\n+      filename (str): Azure Blob Storage file path in the form\n+                      ``azfs://<storage-account>/<container>/<path>``.\n+      mode (str): ``'r'`` for reading or ``'w'`` for writing.\n+      read_buffer_size (int): Buffer size to use during read operations.\n+      mime_type (str): Mime type to set for write operations.\n+\n+    Returns:\n+      Azure Blob Storage file object.\n+    Raises:\n+      ValueError: Invalid open file mode.\n+    \"\"\"\n+    if mode == 'r' or mode == 'rb':\n+      downloader = BlobStorageDownloader(\n+          self.client, filename, buffer_size=read_buffer_size)\n+      return io.BufferedReader(\n+          DownloaderStream(\n+              downloader, read_buffer_size=read_buffer_size, mode=mode),\n+          buffer_size=read_buffer_size)\n+    elif mode == 'w' or mode == 'wb':\n+      uploader = BlobStorageUploader(self.client, filename, mime_type)\n+      return io.BufferedWriter(\n+          UploaderStream(uploader, mode=mode), buffer_size=128 * 1024)\n+    else:\n+      raise ValueError('Invalid file open mode: %s.' % mode)\n+\n+  @retry.with_exponential_backoff(\n+      retry_filter=retry.retry_on_beam_io_error_filter)\n+  def copy(self, src, dest):\n+    \"\"\"Copies a single Azure Blob Storage blob from src to dest.\n+\n+    Args:\n+      src: Blob Storage file path pattern in the form\n+           azfs://<storage-account>/<container>/[name].\n+      dest: Blob Storage file path pattern in the form\n+            azfs://<storage-account>/<container>/[name].\n+\n+    Raises:\n+      TimeoutError: on timeout.\n+    \"\"\"\n+    src_storage_account, src_container, src_blob = parse_azfs_path(\n+        src, get_account=True)\n+    dest_container, dest_blob = parse_azfs_path(dest)\n+\n+    source_blob = get_azfs_url(src_storage_account, src_container, src_blob)\n+    copied_blob = self.client.get_blob_client(dest_container, dest_blob)\n+\n+    try:\n+      copied_blob.start_copy_from_url(source_blob)\n+    except ResourceNotFoundError as e:\n+      message = e.reason\n+      code = e.status_code\n+      raise BlobStorageError(message, code)\n+\n+  # We intentionally do not decorate this method with a retry, since the\n+  # underlying copy operation is already an idempotent operation protected\n+  # by retry decorators.\n+  def copy_tree(self, src, dest):\n+    \"\"\"Renames the given Azure Blob storage directory and its contents\n+    recursively from src to dest.\n+\n+    Args:\n+      src: Blob Storage file path pattern in the form\n+           azfs://<storage-account>/<container>/[name].\n+      dest: Blob Storage file path pattern in the form\n+            azfs://<storage-account>/<container>/[name].\n+\n+    Returns:\n+      List of tuples of (src, dest, exception) where exception is None if the\n+      operation succeeded or the relevant exception if the operation failed.\n+    \"\"\"\n+    assert src.endswith('/')\n+    assert dest.endswith('/')\n+\n+    results = []\n+    for entry in self.list_prefix(src):\n+      rel_path = entry[len(src):]\n+      try:\n+        self.copy(entry, dest + rel_path)\n+        results.append((entry, dest + rel_path, None))\n+      except BlobStorageError as e:\n+        results.append((entry, dest + rel_path, e))\n+\n+    return results\n+\n+  # We intentionally do not decorate this method with a retry, since the\n+  # underlying copy operation is already an idempotent operation protected\n+  # by retry decorators.\n+  def copy_paths(self, src_dest_pairs):\n+    \"\"\"Copies the given Azure Blob Storage blobs from src to dest. This can\n+    handle directory or file paths.\n+\n+    Args:\n+      src_dest_pairs: List of (src, dest) tuples of\n+                      azfs://<storage-account>/<container>/[name] file paths\n+                      to copy from src to dest.\n+\n+    Returns:\n+      List of tuples of (src, dest, exception) in the same order as the\n+      src_dest_pairs argument, where exception is None if the operation\n+      succeeded or the relevant exception if the operation failed.\n+    \"\"\"\n+    if not src_dest_pairs:\n+      return []\n+\n+    results = []\n+\n+    for src_path, dest_path in src_dest_pairs:\n+      # Case 1. They are directories.\n+      if src_path.endswith('/') and dest_path.endswith('/'):\n+        try:\n+          results += self.copy_tree(src_path, dest_path)\n+        except BlobStorageError as e:\n+          results.append((src_path, dest_path, e))\n+\n+      # Case 2. They are individual blobs.\n+      elif not src_path.endswith('/') and not dest_path.endswith('/'):\n+        try:\n+          self.copy(src_path, dest_path)\n+          results.append((src_path, dest_path, None))\n+        except BlobStorageError as e:\n+          results.append((src_path, dest_path, e))\n+\n+      # Mismatched paths (one directory, one non-directory) get an error.\n+      else:\n+        e = BlobStorageError(\n+            \"Unable to copy mismatched paths\" +\n+            \"(directory, non-directory): %s, %s\" % (src_path, dest_path),\n+            400)\n+        results.append((src_path, dest_path, e))\n+\n+    return results\n+\n+  # We intentionally do not decorate this method with a retry, since the\n+  # underlying copy and delete operations are already idempotent operations\n+  # protected by retry decorators.\n+  def rename(self, src, dest):\n+    \"\"\"Renames the given Azure Blob Storage blob from src to dest.\n+\n+    Args:\n+      src: Blob Storage file path pattern in the form\n+           azfs://<storage-account>/<container>/[name].\n+      dest: Blob Storage file path pattern in the form\n+            azfs://<storage-account>/<container>/[name].\n+    \"\"\"\n+    self.copy(src, dest)\n+    self.delete(src)\n+\n+  # We intentionally do not decorate this method with a retry, since the\n+  # underlying copy and delete operations are already idempotent operations\n+  # protected by retry decorators.\n+  def rename_files(self, src_dest_pairs):\n+    \"\"\"Renames the given Azure Blob Storage blobs from src to dest.\n+\n+    Args:\n+      src_dest_pairs: List of (src, dest) tuples of\n+                      azfs://<storage-account>/<container>/[name]\n+                      file paths to rename from src to dest.\n+    Returns: List of tuples of (src, dest, exception) in the same order as the\n+             src_dest_pairs argument, where exception is None if the operation\n+             succeeded or the relevant exception if the operation failed.\n+    \"\"\"\n+    if not src_dest_pairs:\n+      return []\n+\n+    for src, dest in src_dest_pairs:\n+      if src.endswith('/') or dest.endswith('/'):\n+        raise ValueError('Unable to rename a directory.')\n+\n+    # Results from copy operation.\n+    copy_results = self.copy_paths(src_dest_pairs)\n+    paths_to_delete = \\\n+        [src for (src, _, error) in copy_results if error is None]\n+    # Results from delete operation.\n+    delete_results = self.delete_files(paths_to_delete)\n+\n+    # Get rename file results (list of tuples).\n+    results = []\n+\n+    # Using a dictionary will make the operation faster.\n+    delete_results_dict = {src: error for (src, error) in delete_results}\n+\n+    for src, dest, error in copy_results:\n+      # If there was an error in the copy operation.\n+      if error is not None:\n+        results.append((src, dest, error))\n+      # If there was an error in the delete operation.\n+      elif delete_results_dict[src] is not None:\n+        results.append((src, dest, delete_results_dict[src]))\n+      # If there was no error in the operations.\n+      else:\n+        results.append((src, dest, None))\n+\n+    return results\n+\n+  @retry.with_exponential_backoff(\n+      retry_filter=retry.retry_on_beam_io_error_filter)\n+  def exists(self, path):\n+    \"\"\"Returns whether the given Azure Blob Storage blob exists.\n+\n+    Args:\n+      path: Azure Blob Storage file path pattern in the form\n+            azfs://<storage-account>/<container>/[name].\n+    \"\"\"\n+    container, blob = parse_azfs_path(path)\n+    blob_to_check = self.client.get_blob_client(container, blob)\n+    try:\n+      blob_to_check.get_blob_properties()\n+      return True\n+    except ResourceNotFoundError as e:\n+      if e.status_code == 404:\n+        # HTTP 404 indicates that the file did not exist.\n+        return False\n+      else:\n+        # We re-raise all other exceptions.\n+        raise\n+\n+  @retry.with_exponential_backoff(\n+      retry_filter=retry.retry_on_beam_io_error_filter)\n+  def size(self, path):\n+    \"\"\"Returns the size of a single Blob Storage blob.\n+\n+    This method does not perform glob expansion. Hence the\n+    given path must be for a single Blob Storage blob.\n+\n+    Returns: size of the Blob Storage blob in bytes.\n+    \"\"\"\n+    container, blob = parse_azfs_path(path)\n+    blob_to_check = self.client.get_blob_client(container, blob)\n+    try:\n+      properties = blob_to_check.get_blob_properties()\n+    except ResourceNotFoundError as e:\n+      message = e.reason\n+      code = e.status_code\n+      raise BlobStorageError(message, code)\n+\n+    return properties.size\n+\n+  @retry.with_exponential_backoff(\n+      retry_filter=retry.retry_on_beam_io_error_filter)\n+  def last_updated(self, path):\n+    \"\"\"Returns the last updated epoch time of a single\n+    Azure Blob Storage blob.\n+\n+    This method does not perform glob expansion. Hence the\n+    given path must be for a single Azure Blob Storage blob.\n+\n+    Returns: last updated time of the Azure Blob Storage blob\n+    in seconds.\n+    \"\"\"\n+    container, blob = parse_azfs_path(path)\n+    blob_to_check = self.client.get_blob_client(container, blob)\n+    try:\n+      properties = blob_to_check.get_blob_properties()\n+    except ResourceNotFoundError as e:\n+      message = e.reason\n+      code = e.status_code\n+      raise BlobStorageError(message, code)\n+\n+    datatime = properties.last_modified\n+    return (\n+        time.mktime(datatime.timetuple()) - time.timezone +\n+        datatime.microsecond / 1000000.0)\n+\n+  @retry.with_exponential_backoff(\n+      retry_filter=retry.retry_on_beam_io_error_filter)\n+  def checksum(self, path):\n+    \"\"\"Looks up the checksum of an Azure Blob Storage blob.\n+\n+    Args:\n+      path: Azure Blob Storage file path pattern in the form\n+            azfs://<storage-account>/<container>/[name].\n+    \"\"\"\n+    container, blob = parse_azfs_path(path)\n+    blob_to_check = self.client.get_blob_client(container, blob)\n+    try:\n+      properties = blob_to_check.get_blob_properties()\n+    except ResourceNotFoundError as e:\n+      message = e.reason\n+      code = e.status_code\n+      raise BlobStorageError(message, code)\n+\n+    return properties.etag\n+\n+  @retry.with_exponential_backoff(\n+      retry_filter=retry.retry_on_beam_io_error_filter)\n+  def delete(self, path):\n+    \"\"\"Deletes a single blob at the given Azure Blob Storage path.\n+\n+    Args:\n+      path: Azure Blob Storage file path pattern in the form\n+            azfs://<storage-account>/<container>/[name].\n+    \"\"\"\n+    container, blob = parse_azfs_path(path)\n+    blob_to_delete = self.client.get_blob_client(container, blob)\n+    try:\n+      blob_to_delete.delete_blob()\n+    except ResourceNotFoundError as e:\n+      if e.status_code == 404:\n+        # Return success when the file doesn't exist anymore for idempotency.\n+        return\n+      else:\n+        logging.error('HTTP error while deleting file %s', path)\n+        raise e\n+\n+  # We intentionally do not decorate this method with a retry, since the\n+  # underlying copy and delete operations are already idempotent operations\n+  # protected by retry decorators.\n+  def delete_paths(self, paths):\n+    \"\"\"Deletes the given Azure Blob Storage blobs from src to dest.\n+    This can handle directory or file paths.\n+\n+    Args:\n+      paths: list of Azure Blob Storage paths in the form\n+             azfs://<storage-account>/<container>/[name] that give the\n+             file blobs to be deleted.\n+\n+    Returns:\n+      List of tuples of (src, dest, exception) in the same order as the\n+      src_dest_pairs argument, where exception is 202 if the operation\n+      succeeded or the relevant exception if the operation failed.\n+    \"\"\"\n+    directories, blobs = [], []\n+\n+    # Retrieve directories and not directories.\n+    for path in paths:\n+      if path.endswith('/'):\n+        directories.append(path)\n+      else:\n+        blobs.append(path)\n+\n+    results = {}\n+\n+    for directory in directories:\n+      directory_result = dict(self.delete_tree(directory))\n+      results.update(directory_result)\n+\n+    blobs_results = dict(self.delete_files(blobs))\n+    results.update(blobs_results)\n+\n+    return results\n+\n+  # We intentionally do not decorate this method with a retry, since the\n+  # underlying copy and delete operations are already idempotent operations\n+  # protected by retry decorators.\n+  def delete_tree(self, root):\n+    \"\"\"Deletes all blobs under the given Azure BlobStorage virtual\n+    directory.\n+\n+    Args:\n+      path: Azure Blob Storage file path pattern in the form\n+            azfs://<storage-account>/<container>/[name]\n+            (ending with a \"/\").\n+\n+    Returns:\n+      List of tuples of (path, exception), where each path is a blob\n+      under the given root. exception is 202 if the operation succeeded\n+      or the relevant exception if the operation failed.\n+    \"\"\"\n+    assert root.endswith('/')\n+\n+    # Get the blob under the root directory.\n+    paths_to_delete = self.list_prefix(root)\n+\n+    return self.delete_files(paths_to_delete)\n+\n+  # We intentionally do not decorate this method with a retry, since the\n+  # underlying copy and delete operations are already idempotent operations\n+  # protected by retry decorators.\n+  def delete_files(self, paths):\n+    \"\"\"Deletes the given Azure Blob Storage blobs from src to dest.\n+\n+    Args:\n+      paths: list of Azure Blob Storage paths in the form\n+             azfs://<storage-account>/<container>/[name] that give the\n+             file blobs to be deleted.\n+\n+    Returns:\n+      List of tuples of (src, dest, exception) in the same order as the\n+      src_dest_pairs argument, where exception is 202 if the operation\n+      succeeded or the relevant exception if the operation failed.\n+    \"\"\"\n+    if not paths:\n+      return []\n+\n+    # Group blobs into containers.\n+    containers, blobs = zip(*[parse_azfs_path(path, get_account=False) \\\n+        for path in paths])\n+\n+    grouped_blobs = {container: [] for container in containers}\n+\n+    # Fill dictionary.\n+    for container, blob in zip(containers, blobs):\n+      grouped_blobs[container].append(blob)\n+\n+    results = {}\n+\n+    # Delete minibatches of blobs for each container.\n+    for container, blobs in grouped_blobs.items():\n+      for i in range(0, len(blobs), MAX_BATCH_OPERATION_SIZE):\n+        blobs_to_delete = blobs[i:i + MAX_BATCH_OPERATION_SIZE]\n+        results.update(self._delete_batch(container, blobs_to_delete))\n+\n+    final_results = \\\n+        [(path, results[parse_azfs_path(path, get_account=False)]) \\\n+        for path in paths]\n+\n+    return final_results\n+\n+  @retry.with_exponential_backoff(\n+      retry_filter=retry.retry_on_beam_io_error_filter)\n+  def _delete_batch(self, container, blobs):\n+    \"\"\"A helper method. Azure Blob Storage Python Client allows batch\n+    deletions for blobs within the same container.\n+\n+    Args:\n+      container: container name.\n+      blobs: list of blobs to be deleted.\n+\n+    Returns:\n+      Dictionary of the form {(container, blob): error}, where error is\n+      202 if the operation succeeded.\n+    \"\"\"\n+    container_client = self.client.get_container_client(container)\n+    results = {}\n+\n+    try:\n+      response = container_client.delete_blobs(\n+          *blobs, raise_on_any_failure=False)\n+\n+      for blob, error in zip(blobs, response):\n+        results[(container, blob)] = error.status_code\n+\n+    except BlobStorageError as e:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "4c5ab4ca7b4f137dce5f65a6349e0f8f1aefecb5"}, "originalPosition": 561}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "388452735bc87c0fe8ac04cfccdfee4365f503fd", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/388452735bc87c0fe8ac04cfccdfee4365f503fd", "committedDate": "2020-08-27T22:54:06Z", "message": "feat: Change delete_blobs to delete_blob"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "088303f6b5cab8179e109dda97fb747f07c65edf", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/088303f6b5cab8179e109dda97fb747f07c65edf", "committedDate": "2020-08-11T19:57:23Z", "message": "Initial commit"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "48014f0bb9b9e74941f6ebc3affd96feabf43b85", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/48014f0bb9b9e74941f6ebc3affd96feabf43b85", "committedDate": "2020-08-11T19:57:23Z", "message": "Create client wrapper files"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "08769ed25ea195146ff8dae19761c92ae15f02a0", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/08769ed25ea195146ff8dae19761c92ae15f02a0", "committedDate": "2020-08-11T19:57:23Z", "message": "Add azure requirements"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "33afe4aed04765263d2f81b997bdcf030755da36", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/33afe4aed04765263d2f81b997bdcf030755da36", "committedDate": "2020-08-11T19:57:23Z", "message": "Add blobstoragefilesystem file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "09a8c20e17a9456509f499ea637c5170736e86a4", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/09a8c20e17a9456509f499ea637c5170736e86a4", "committedDate": "2020-08-11T19:57:23Z", "message": "Add BlobStorageFileSystem as an official file system"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5e127f77265f1b5feeedf2180447a2ed0b1e55d2", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/5e127f77265f1b5feeedf2180447a2ed0b1e55d2", "committedDate": "2020-08-11T19:57:23Z", "message": "Add BlobStorageFileSystem class method definitions"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "45713eb0fff85915d7a7f8d68b2da7be71a74771", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/45713eb0fff85915d7a7f8d68b2da7be71a74771", "committedDate": "2020-08-11T19:57:23Z", "message": "Clean client wrapper class"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d4b4bee3b1f4f832cc09359f0e9ceabe700bdfd1", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/d4b4bee3b1f4f832cc09359f0e9ceabe700bdfd1", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add scheme, mkdirs and has_dirs methods"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9287649d56205d72c32b5260dad183bfd2116afb", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/9287649d56205d72c32b5260dad183bfd2116afb", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add join method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ea2adc3696520045a8b5dd29b8de7a37a12b70de", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/ea2adc3696520045a8b5dd29b8de7a37a12b70de", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add blobstoragefilesystem_test file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8c210efa970dfb465c78be2f11c70398eb33b00b", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/8c210efa970dfb465c78be2f11c70398eb33b00b", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add the signature of all methods in azbs file system class"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "25f4a536ab1d3044d4d9469045e933a2ce50e23d", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/25f4a536ab1d3044d4d9469045e933a2ce50e23d", "committedDate": "2020-08-11T19:57:23Z", "message": "test: scheme and join method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "917e6c04f47838629d213665d9821795db24d030", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/917e6c04f47838629d213665d9821795db24d030", "committedDate": "2020-08-11T19:57:23Z", "message": "test: split method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b36a5c03b27cacee13227641893efad23b39773a", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/b36a5c03b27cacee13227641893efad23b39773a", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add blobstorageio file to interact with Azure"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8288599038088f6ad77bdbbe2328420606d26259", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/8288599038088f6ad77bdbbe2328420606d26259", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add parse_azfs_path method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4db2c7e933b81b0524bce721c18b4ac3c11f11f7", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/4db2c7e933b81b0524bce721c18b4ac3c11f11f7", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add blobstorageio_test file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f93614fd5f3c97310293856ddb90d30ef3cf499c", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/f93614fd5f3c97310293856ddb90d30ef3cf499c", "committedDate": "2020-08-11T19:57:23Z", "message": "test: parse_azfs_path method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "78e52893c54ed1effa7db832b09c42ff74ae1913", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/78e52893c54ed1effa7db832b09c42ff74ae1913", "committedDate": "2020-08-11T19:57:23Z", "message": "test: extra test cases for parse_azfs_path method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ef86ece23455cf36fad5ee9835d1c069e2f9b3bb", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/ef86ece23455cf36fad5ee9835d1c069e2f9b3bb", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add list_prefix method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e7f0199dcdcdaad72bae28f18adb0578dfa1d68d", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/e7f0199dcdcdaad72bae28f18adb0578dfa1d68d", "committedDate": "2020-08-11T19:57:23Z", "message": "test: list_prefix (progress)"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "aebd55ed426363627634839da9a9ed7be5bd9613", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/aebd55ed426363627634839da9a9ed7be5bd9613", "committedDate": "2020-08-11T19:57:23Z", "message": "test: list_prefix method works with local account"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "542f4c595f68354bdbb93d7a9bbd64a9f7822a0d", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/542f4c595f68354bdbb93d7a9bbd64a9f7822a0d", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add _list method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fa7b44158acb2a548c2fb3c3eb662e2d97cb98c8", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/fa7b44158acb2a548c2fb3c3eb662e2d97cb98c8", "committedDate": "2020-08-11T19:57:23Z", "message": "test: test_math_multiples"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e4c609ebd134c7f8015b2f78b93c969cc90fc9d1", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/e4c609ebd134c7f8015b2f78b93c969cc90fc9d1", "committedDate": "2020-08-11T19:57:23Z", "message": "test: math multiples limit"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "287d83681b1de3a914ff8919ff8ac3515818e79e", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/287d83681b1de3a914ff8919ff8ac3515818e79e", "committedDate": "2020-08-11T19:57:23Z", "message": "test: match multiples error"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b4e9e8014ad453269afa4d95a58cc7b297281820", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/b4e9e8014ad453269afa4d95a58cc7b297281820", "committedDate": "2020-08-11T19:57:23Z", "message": "test: match multiple patterns"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f2a8c917e1b04d80b35b1686b0302b7e5813aa4b", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/f2a8c917e1b04d80b35b1686b0302b7e5813aa4b", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add open method to the io class"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "df8ec9bd7064378f5a2f3a86fb31b737142ee325", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/df8ec9bd7064378f5a2f3a86fb31b737142ee325", "committedDate": "2020-08-11T19:57:23Z", "message": "test: file mode"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dc87bba06b7fd443314272edbc91900ae3e964e2", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/dc87bba06b7fd443314272edbc91900ae3e964e2", "committedDate": "2020-08-11T19:57:23Z", "message": "test: copy method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6d4a0be3145c19fcc5c924fe8490ef4c095351c5", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/6d4a0be3145c19fcc5c924fe8490ef4c095351c5", "committedDate": "2020-08-11T19:57:23Z", "message": "fix: remove unnecessary code"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b9f3771cfcbb5dc6b649c5cb937f1eef9fc5c1ba", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/b9f3771cfcbb5dc6b649c5cb937f1eef9fc5c1ba", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add copy single blob method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6cac8f55f28450484fb37956cab8d2b2e74fe4e9", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/6cac8f55f28450484fb37956cab8d2b2e74fe4e9", "committedDate": "2020-08-11T19:57:23Z", "message": "test: delete a single file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5428b515594c43de15b43013b42a977f54179c85", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/5428b515594c43de15b43013b42a977f54179c85", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add delete a single blob method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9cbe131ef8c9d34c649c633781ca27530a18cb5e", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/9cbe131ef8c9d34c649c633781ca27530a18cb5e", "committedDate": "2020-08-11T19:57:23Z", "message": "test: exists method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1000991814fd92595c3a88a38b9eb643e93fe4ca", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/1000991814fd92595c3a88a38b9eb643e93fe4ca", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add exists method to wrapper"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "84dbcc36b37597061c2c732118c7b776e06cb94c", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/84dbcc36b37597061c2c732118c7b776e06cb94c", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add exists method to filesystem"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "962fb8cce2588dd9cc9e805b37bbf0b0fa0f3eaa", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/962fb8cce2588dd9cc9e805b37bbf0b0fa0f3eaa", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add BloStorageDownloader"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4356b564a11968010e0f42623978e892ec4a2d99", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/4356b564a11968010e0f42623978e892ec4a2d99", "committedDate": "2020-08-11T19:57:23Z", "message": "test: file full file read"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dd25245e50eec2487e3fdb1da46e84ec4524504e", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/dd25245e50eec2487e3fdb1da46e84ec4524504e", "committedDate": "2020-08-11T19:57:23Z", "message": "test: file write"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ce03578276190fbf9af356387a7685ff15836174", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/ce03578276190fbf9af356387a7685ff15836174", "committedDate": "2020-08-11T19:57:23Z", "message": "test: delete batch"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c734950461fd481f40e8d366896c01e8d9f7b226", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/c734950461fd481f40e8d366896c01e8d9f7b226", "committedDate": "2020-08-11T19:57:23Z", "message": "fix: delete method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "67dea5d21ed542ef1fa22ea7b9c788c6f03e957e", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/67dea5d21ed542ef1fa22ea7b9c788c6f03e957e", "committedDate": "2020-08-11T19:57:23Z", "message": "test: (WIP) checksum"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f6e3c399dedda4e2874b26d808015b6c4e2b8ed2", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/f6e3c399dedda4e2874b26d808015b6c4e2b8ed2", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add BlobStorageUploader"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9c50ae2f4a83eac5ebd8433466e8252036712995", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/9c50ae2f4a83eac5ebd8433466e8252036712995", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add content_type support to BlosStorageUploader"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d990de2e8fa48fa4e6f46c87cd3dc79af366e575", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/d990de2e8fa48fa4e6f46c87cd3dc79af366e575", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add insert random file method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "24a64afdef377a5782931f3f943e0d807945e869", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/24a64afdef377a5782931f3f943e0d807945e869", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add overwrite support when uploading blobs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "abc93c0d9ff273df11a0b9017c7e6a77f49cbcec", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/abc93c0d9ff273df11a0b9017c7e6a77f49cbcec", "committedDate": "2020-08-11T19:57:23Z", "message": "test: Add insert_random_file functionality to list prefix"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6085fe5637a5bca4e416cb6b818343eeaaae73d3", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/6085fe5637a5bca4e416cb6b818343eeaaae73d3", "committedDate": "2020-08-11T19:57:23Z", "message": "test: Add insert_random_file functionality to copy"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4ca76677f5b831101fa5240f47d7b8914879ee14", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/4ca76677f5b831101fa5240f47d7b8914879ee14", "committedDate": "2020-08-11T19:57:23Z", "message": "test: (WIP) copy non existent files"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4ad492071b92ff3ee2e15b44fa0020dc944197fa", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/4ad492071b92ff3ee2e15b44fa0020dc944197fa", "committedDate": "2020-08-11T19:57:23Z", "message": "fix: delete method exception handling"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1339c2fa2900325e2e946016d03883abf6b1cf25", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/1339c2fa2900325e2e946016d03883abf6b1cf25", "committedDate": "2020-08-11T19:57:23Z", "message": "test: Add insert_random_file functionality to delete"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b3bcae8273f8442df86bb3042b8deeb3f1edded5", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/b3bcae8273f8442df86bb3042b8deeb3f1edded5", "committedDate": "2020-08-11T19:57:23Z", "message": "fix: delete method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3f32935031fea1cae23eec973d39069d01bab5f2", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/3f32935031fea1cae23eec973d39069d01bab5f2", "committedDate": "2020-08-11T19:57:23Z", "message": "test: Add insert_random_file functionality to exists"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5a7938fa4b72681fe5cddaabe8d4a9b00da75758", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/5a7938fa4b72681fe5cddaabe8d4a9b00da75758", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add FakeFile class"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6464ad9ba80dc21e0de890626c860a516e9b5cb6", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/6464ad9ba80dc21e0de890626c860a516e9b5cb6", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add FakeFile to insert_random_file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2e8ba9fa8db95bc1342995e52890ce8c5f930b36", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/2e8ba9fa8db95bc1342995e52890ce8c5f930b36", "committedDate": "2020-08-11T19:57:23Z", "message": "format: Change FakeFile name to fake_file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "01eaf24caf4d44f835131ba3ed186b6e2a1e4fcd", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/01eaf24caf4d44f835131ba3ed186b6e2a1e4fcd", "committedDate": "2020-08-11T19:57:23Z", "message": "test: Add insert_random_file functionality to full file read"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "399d90cb44ed64dd06e9cf77331dd9e56a1e2cf9", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/399d90cb44ed64dd06e9cf77331dd9e56a1e2cf9", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Remove unnecesary files"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "551e3ffea2f2a9236a3b32463044991b0d989513", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/551e3ffea2f2a9236a3b32463044991b0d989513", "committedDate": "2020-08-11T19:57:23Z", "message": "chore: Add formatting"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "79a37997040999e518e4d3d2364a81496d686d2a", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/79a37997040999e518e4d3d2364a81496d686d2a", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add size method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "051f4f989df1228f4fa0ec62d6e48ad57691be85", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/051f4f989df1228f4fa0ec62d6e48ad57691be85", "committedDate": "2020-08-11T19:57:23Z", "message": "fix: size method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "adfd97e0c794b04c1cc3d9267adea862bd73d762", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/adfd97e0c794b04c1cc3d9267adea862bd73d762", "committedDate": "2020-08-11T19:57:23Z", "message": "test: size"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d4df28ca0c91d4819ae6c73b0dd8827166da434d", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/d4df28ca0c91d4819ae6c73b0dd8827166da434d", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add size method to filesystem"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6dea1b2031bc71897b3314d67dda30d6c95d737a", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/6dea1b2031bc71897b3314d67dda30d6c95d737a", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add last updated method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d934c798edb71c572e7ced590796f80ddf1b9793", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/d934c798edb71c572e7ced590796f80ddf1b9793", "committedDate": "2020-08-11T19:57:23Z", "message": "test: last updated"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8bdf861a8d065e0da0911cd0e35175f84136fbc0", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/8bdf861a8d065e0da0911cd0e35175f84136fbc0", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add last updated method to filesystem"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "318e49bbb611c4ce53da3c8c08d69a78209137c9", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/318e49bbb611c4ce53da3c8c08d69a78209137c9", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add checksum method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d2eacf312436a078c044fae15716dc9ca018d198", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/d2eacf312436a078c044fae15716dc9ca018d198", "committedDate": "2020-08-11T19:57:23Z", "message": "test: (WIP) checksum"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ff08ccb59fe533af96c9a93ddf7478e069a61b6a", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/ff08ccb59fe533af96c9a93ddf7478e069a61b6a", "committedDate": "2020-08-11T19:57:23Z", "message": "test: (WIP) checksum (now is working)"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9cc97107329dbe06989a44bdf7cc739b005126a4", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/9cc97107329dbe06989a44bdf7cc739b005126a4", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add checksum method to filesystem"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b4e7e70a56fb837183a0f59306234b5a95a56216", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/b4e7e70a56fb837183a0f59306234b5a95a56216", "committedDate": "2020-08-11T19:57:23Z", "message": "test: checksum"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "84a185e5b0679f1a698bd22507168ab8eb9f93f5", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/84a185e5b0679f1a698bd22507168ab8eb9f93f5", "committedDate": "2020-08-11T19:57:23Z", "message": "refactor: general code clean up"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "58a11a359f56da697c38268c98d13dbafa7a56f5", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/58a11a359f56da697c38268c98d13dbafa7a56f5", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add rename method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2b2ec57cf4156f4cf1aa07f56d6e5b01dc869a13", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/2b2ec57cf4156f4cf1aa07f56d6e5b01dc869a13", "committedDate": "2020-08-11T19:57:23Z", "message": "test: rename"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "556172b8e5e60216dc630b622cb505bcea36c096", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/556172b8e5e60216dc630b622cb505bcea36c096", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add path open auxiliary method to filesystem"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b7fbffa5983d1bf76667e2a8a5026cab1aac6c0c", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/b7fbffa5983d1bf76667e2a8a5026cab1aac6c0c", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add create method to filesystem"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8556fda94cbb0fd59fbdc1db0d4af27fbeb87c2a", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/8556fda94cbb0fd59fbdc1db0d4af27fbeb87c2a", "committedDate": "2020-08-11T19:57:23Z", "message": "test: create"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d82f8dfe280879b6de19b434a3816f5432ae8075", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/d82f8dfe280879b6de19b434a3816f5432ae8075", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add open method to filesystem"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9bfdd36e80f2080743c069fb1b7d5200edbc6596", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/9bfdd36e80f2080743c069fb1b7d5200edbc6596", "committedDate": "2020-08-11T19:57:23Z", "message": "test: create"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "665e1edb91525377bda9a548d2af1a75f1cea78a", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/665e1edb91525377bda9a548d2af1a75f1cea78a", "committedDate": "2020-08-11T19:57:23Z", "message": "test: open"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6011b3c0f0a540b25d44704e4d2e5467bebd0e44", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/6011b3c0f0a540b25d44704e4d2e5467bebd0e44", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add copy tree"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3b9d74ca09c4ad9a58cb10d494963131418b0531", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/3b9d74ca09c4ad9a58cb10d494963131418b0531", "committedDate": "2020-08-11T19:57:23Z", "message": "test: copy tree"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c0c1788597ed009933fc66d2eb02ec4fc7b70d82", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/c0c1788597ed009933fc66d2eb02ec4fc7b70d82", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add copy paths method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8d221decc1b9ac5de9daef44a59e0863e4b6092f", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/8d221decc1b9ac5de9daef44a59e0863e4b6092f", "committedDate": "2020-08-11T19:57:23Z", "message": "test: copy paths"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "720c02b2991760a369e2e995ab5c44b617516efc", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/720c02b2991760a369e2e995ab5c44b617516efc", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add copy method to filesystem"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "68b7a0b3b8a0c5ea1a5443791b2b6466c9c9c4a1", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/68b7a0b3b8a0c5ea1a5443791b2b6466c9c9c4a1", "committedDate": "2020-08-11T19:57:23Z", "message": "test: copy file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b83043c487c5c415f45060e789163e3088fed370", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/b83043c487c5c415f45060e789163e3088fed370", "committedDate": "2020-08-11T19:57:23Z", "message": "test: copy file error"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "96e39b4fa2b13e4b389cb7fd5b2c3d96ef9be972", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/96e39b4fa2b13e4b389cb7fd5b2c3d96ef9be972", "committedDate": "2020-08-11T19:57:23Z", "message": "test: delete paths"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cccd598c3fae4892441de0802b81a499c28e4121", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/cccd598c3fae4892441de0802b81a499c28e4121", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add delete paths method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ef7ece7909be4896ee5fcd3134efefa502e4382f", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/ef7ece7909be4896ee5fcd3134efefa502e4382f", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add delete tree method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c8a7a3ba5e0fa72095972e41df260dd84e346d4e", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/c8a7a3ba5e0fa72095972e41df260dd84e346d4e", "committedDate": "2020-08-11T19:57:23Z", "message": "test: delete tree"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0a469180132ec22b758b490c717ecb1e39bdcc74", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/0a469180132ec22b758b490c717ecb1e39bdcc74", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add delete files method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "aebb0adc8a1e5a112a048f137e73b5848afdbc2a", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/aebb0adc8a1e5a112a048f137e73b5848afdbc2a", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add delete batch helper method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cb79ce922905e50f6aabd0f61ad7c39542f0fcdd", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/cb79ce922905e50f6aabd0f61ad7c39542f0fcdd", "committedDate": "2020-08-11T19:57:23Z", "message": "fix: delete methods"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cf7ae74667e9ff0ff9c60c08aa27ba040d09bb49", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/cf7ae74667e9ff0ff9c60c08aa27ba040d09bb49", "committedDate": "2020-08-11T19:57:23Z", "message": "test: delete files"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d074c338dc8823b090f12cacc424224f9f0cec51", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/d074c338dc8823b090f12cacc424224f9f0cec51", "committedDate": "2020-08-11T19:57:23Z", "message": "test: delete files with errors"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b286ff51d76a342a896b62a64cb5912a6fa22b7e", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/b286ff51d76a342a896b62a64cb5912a6fa22b7e", "committedDate": "2020-08-11T19:57:23Z", "message": "refactor: general code clean up"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0bb5eb5de843ca09ca8ed23eb57e450bf5a75b29", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/0bb5eb5de843ca09ca8ed23eb57e450bf5a75b29", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add get_account kwarg in parse azfs method"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4fef996cc48a4b69a0025d35d676be74652a0443", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/4fef996cc48a4b69a0025d35d676be74652a0443", "committedDate": "2020-08-11T19:57:23Z", "message": "feat: Add delete method to filesystem"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "adf72432096da01a14c6d7c881f5ae4d511c5adb", "author": {"user": {"login": "AldairCoronel", "name": "Aldair Coronel"}}, "url": "https://github.com/apache/beam/commit/adf72432096da01a14c6d7c881f5ae4d511c5adb", "committedDate": "2020-08-11T19:57:23Z", "message": "test: delete in filesystem"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3791, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}