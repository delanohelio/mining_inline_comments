{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTQwODI4NjU5", "number": 13561, "title": "Add DataFrame Preview announcment blog post", "bodyText": "Post-Commit Tests Status (on master branch)\n\n\n\nLang\nSDK\nDataflow\nFlink\nSamza\nSpark\nTwister2\n\n\n\n\nGo\n\n---\n\n---\n\n---\n\n\nJava\n\n\n\n\n\n\n\n\nPython\n\n\n\n---\n\n---\n\n\nXLang\n\n\n\n---\n\n---\n\n\n\nPre-Commit Tests Status (on master branch)\n\n\n\n---\nJava\nPython\nGo\nWebsite\nWhitespace\nTypescript\n\n\n\n\nNon-portable\n\n \n\n\n\n\n\n\nPortable\n---\n\n---\n---\n---\n---\n\n\n\nSee .test-infra/jenkins/README for trigger phrase, status and link of all Jenkins jobs.\nGitHub Actions Tests Status (on master branch)\n\n\n\nSee CI.md for more information about GitHub Actions CI.", "createdAt": "2020-12-16T01:36:50Z", "url": "https://github.com/apache/beam/pull/13561", "merged": true, "mergeCommit": {"oid": "9732fa37e256960186346bcc37392b3e83b30d6a"}, "closed": true, "closedAt": "2020-12-18T00:58:24Z", "author": {"login": "TheNeuralBit"}, "timelineItems": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdmkwn7gH2gAyNTQwODI4NjU5OjA0MDdjNzUyMmE0NTJlMWVmZTNhZTUyYjJiZWZkNzE0ZDY5NDJhMmE=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdnM9ssAH2gAyNTQwODI4NjU5OmQyNmFiMTgyNzE4ZjkzOTlkZDA5MDkxODc5NWU3NGVmZmVkMTNjNjc=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "0407c7522a452e1efe3ae52b2befd714d6942a2a", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/0407c7522a452e1efe3ae52b2befd714d6942a2a", "committedDate": "2020-12-16T01:36:03Z", "message": "Add Dataframe announcment blog post"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b19e82f3eede75b4e4e79b8e6dcdfbc53232ed80", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/b19e82f3eede75b4e4e79b8e6dcdfbc53232ed80", "committedDate": "2020-12-16T01:49:25Z", "message": "Update dataframe-api-preview-available.md"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d19e0d62f46fb3e372d4d7b0eee834afbf6c47e2", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/d19e0d62f46fb3e372d4d7b0eee834afbf6c47e2", "committedDate": "2020-12-16T18:09:53Z", "message": "Fix all the things"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1121982c73430bddfcc7c733a20826597f9508d1", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/1121982c73430bddfcc7c733a20826597f9508d1", "committedDate": "2020-12-16T18:10:51Z", "message": "Merge branch 'master' into dataframe-blog"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU0NjkyMTAz", "url": "https://github.com/apache/beam/pull/13561#pullrequestreview-554692103", "createdAt": "2020-12-17T15:06:25Z", "commit": {"oid": "1121982c73430bddfcc7c733a20826597f9508d1"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QxNTowNjoyNVrOIH5-3g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QxNjoyMjo0MVrOIH9ohw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTE2MDkyNg==", "bodyText": "Dataframe -> DataFrame", "url": "https://github.com/apache/beam/pull/13561#discussion_r545160926", "createdAt": "2020-12-17T15:06:25Z", "author": {"login": "pcoet"}, "path": "website/www/site/content/en/blog/dataframe-api-preview-available.md", "diffHunk": "@@ -0,0 +1,178 @@\n+---\n+title:  \"DataFrame API Preview now Available!\"\n+date: \"2020-12-16T09:09:41-08:00\"\n+categories:\n+  - blog\n+authors:\n+  - bhulette\n+  - robertwb\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+We are proud to announce that a preview of the Beam Python SDK's new DataFrame\n+API is now available in [Beam\n+2.26.0](https://beam.apache.org/blog/beam-2.26.0/). Much like SqlTransform\n+([Java](https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/extensions/sql/SqlTransform.html),\n+[Python](https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.sql.html#apache_beam.transforms.sql.SqlTransform)),\n+the DataFrame API gives Beam users a way to express complex\n+relational logic much more concisely than previously possible.\n+<!--more-->\n+\n+## A more expressive API\n+Beam's new Dataframe API aims to be compatible with the well known", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1121982c73430bddfcc7c733a20826597f9508d1"}, "originalPosition": 34}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTE2MzY4NA==", "bodyText": "Maybe something like, \"We're excited to announce ....\"", "url": "https://github.com/apache/beam/pull/13561#discussion_r545163684", "createdAt": "2020-12-17T15:09:59Z", "author": {"login": "pcoet"}, "path": "website/www/site/content/en/blog/dataframe-api-preview-available.md", "diffHunk": "@@ -0,0 +1,178 @@\n+---\n+title:  \"DataFrame API Preview now Available!\"\n+date: \"2020-12-16T09:09:41-08:00\"\n+categories:\n+  - blog\n+authors:\n+  - bhulette\n+  - robertwb\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+We are proud to announce that a preview of the Beam Python SDK's new DataFrame", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1121982c73430bddfcc7c733a20826597f9508d1"}, "originalPosition": 24}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTIyMDc0Mw==", "bodyText": "\"operations, we\u2019re\" -> \"operations. We\u2019re\"", "url": "https://github.com/apache/beam/pull/13561#discussion_r545220743", "createdAt": "2020-12-17T16:22:41Z", "author": {"login": "pcoet"}, "path": "website/www/site/content/en/blog/dataframe-api-preview-available.md", "diffHunk": "@@ -0,0 +1,178 @@\n+---\n+title:  \"DataFrame API Preview now Available!\"\n+date: \"2020-12-16T09:09:41-08:00\"\n+categories:\n+  - blog\n+authors:\n+  - bhulette\n+  - robertwb\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+We are proud to announce that a preview of the Beam Python SDK's new DataFrame\n+API is now available in [Beam\n+2.26.0](https://beam.apache.org/blog/beam-2.26.0/). Much like SqlTransform\n+([Java](https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/extensions/sql/SqlTransform.html),\n+[Python](https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.sql.html#apache_beam.transforms.sql.SqlTransform)),\n+the DataFrame API gives Beam users a way to express complex\n+relational logic much more concisely than previously possible.\n+<!--more-->\n+\n+## A more expressive API\n+Beam's new Dataframe API aims to be compatible with the well known\n+[Pandas](https://pandas.pydata.org/pandas-docs/stable/index.html)\n+DataFrame API, with a few caveats detailed below. With this new API a simple\n+pipeline that reads NYC taxiride data from a CSV, performs a grouped\n+aggregation, and writes the output to CSV, can be expressed very concisely:\n+\n+```\n+from apache_beam.dataframe.io import read_csv\n+\n+with beam.Pipeline() as p:\n+  df = p | read_csv(\"gs://apache-beam-samples/nyc_taxi/2019/*.csv\",\n+                    use_ncols=['passenger_count' , 'DOLocationID'])\n+  # Count the number of passengers dropped off per LocationID\n+  agg = df.groupby('DOLocationID').sum()\n+  agg.to_csv(output)\n+```\n+\n+Compare this to the same logic implemented as a conventional Beam python\n+pipeline with a `CombinePerKey`:\n+\n+```\n+with beam.Pipeline() as p:\n+  (p | beam.io.ReadFromText(\"gs://apache-beam-samples/nyc_taxi/2019/*.csv\",\n+                            skip_header_lines=1)\n+     | beam.Map(lambda line: line.split(','))\n+     # Parse CSV, create key - value pairs\n+     | beam.Map(lambda splits: (int(splits[8] or 0),  # DOLocationID\n+                                int(splits[3] or 0))) # passenger_count\n+     # Sum values per key\n+     | beam.CombinePerKey(sum)\n+     | beam.MapTuple(lambda loc_id, pc: f'{loc_id}: {pc}')\n+     | beam.io.WriteToText(known_args.output))\n+```\n+\n+The DataFrame example is much easier to quickly inspect and understand, as it\n+allows you to concisely express grouped aggregations without using the low-level\n+`CombinePerKey`.\n+\n+In addition to being more expressive and concise, a pipeline written with the\n+DataFrame API can often be more efficient than a conventional Beam pipeline.\n+This is because the DataFrame API defers to the very efficient, columnar Pandas\n+implementation as much as possible.\n+\n+## DataFrames as a DSL\n+You may already be aware of [Beam\n+SQL](https://beam.apache.org/documentation/dsls/sql/overview/), which is\n+a Domain-Specific Language (DSL) built with Beam's Java SDK. SQL is\n+considered a DSL because it's possible to express a full pipeline, including IOs\n+and complex operations, entirely with SQL.\u00a0\n+\n+Similarly, the DataFrame API is a DSL built with the Python SDK. You can see\n+that the above example is written without traditional Beam constructs like IOs,\n+ParDo, or CombinePerKey. In fact the only traditional Beam type is the Pipeline\n+instance! Otherwise this pipeline is written completely using the DataFrame API.\n+This is possible because the DataFrame API doesn't just implement Pandas'\n+computation operations, it also includes IOs based on the Pandas native\n+implementations (`pd.read_{csv,parquet,...}` and `pd.DataFrame.to_{csv,parquet,...}`).\n+\n+Like SQL, it\u2019s also possible to embed the DataFrame API into a larger pipeline\n+by using\n+[schemas](https://beam.apache.org/documentation/programming-guide/#what-is-a-schema).\n+A schema-aware PCollection can be converted to a DataFrame, processed, and the\n+result converted back to another schema-aware PCollection.  For example, if you\n+wanted to use traditional Beam IOs rather than one of the DataFrame IOs you\n+could rewrite the above pipeline like this:\n+\n+```\n+from apache_beam.dataframe.convert import to_dataframe\n+from apache_beam.dataframe.convert import to_pcollection\n+\n+with beam.Pipeline() as p:\n+  ...\n+  schema_pc = (p | beam.ReadFromText(..)\n+                 # Use beam.Select to assign a schema\n+                 | beam.Select(DOLocationID=lambda line: int(...),\n+                               passenger_count=lambda line: int(...)))\n+  df = to_dataframe(schema_pc)\n+  agg = df.groupby('DOLocationID').sum()\n+  agg_pc = to_pcollection(pc)\n+\n+  # agg_pc has a schema based on the structure of agg\n+  (agg_pc | beam.Map(lambda row: f'{row.DOLocationID}: {row.passenger_count}')\n+          | beam.WriteToText(..))\n+```\n+\n+It\u2019s also possible to use the DataFrame API by passing a function to\n+[`DataframeTransform`](https://beam.apache.org/releases/pydoc/current/apache_beam.dataframe.transforms.html#apache_beam.dataframe.transforms.DataframeTransform):\n+\n+```\n+from apache_beam.dataframe.transforms import DataframeTransform\n+\n+with beam.Pipeline() as p:\n+  ...\n+  | beam.Select(DOLocationID=lambda line: int(..),\n+                passenger_count=lambda line: int(..))\n+  | DataframeTransform(lambda df: df.groupby('DOLocationID').sum())\n+  | beam.Map(lambda row: f'{row.DOLocationID}: {row.passenger_count}')\n+  ...\n+```\n+\n+## Caveats\n+As hinted above, there are some differences between Beam's DataFrame API and the\n+Pandas API. The most significant difference is that the Beam  DataFrame API is\n+*deferred*, just like the rest of the Beam API. This means that you can't\n+`print()` a DataFrame instance in order to inspect the data, because we haven't\n+computed the data yet! The computation doesn't take place until the pipeline is\n+`run()`.  Before that, we only know about the shape/schema of the result (i.e.\n+the names and types of the columns), and not the result itself.\n+\n+There are a few common exceptions you will likely see when attempting to use\n+certain Pandas operations:\n+\n+- **NotImplementedError:** Indicates this is an operation or argument that we\n+  haven't had time to look at yet. We've tried to make as many Pandas operations\n+  as possible available in the Preview offering of this new API, but there's\n+  still a long tail of operations to go.\n+- **WontImplementError:** Indicates this is an operation or argument we do not\n+  intend to support in the near-term because it's incompatible with the Beam\n+  model. The largest class of operations that raise this error are those that\n+  are order sensitive (e.g. shift, cummax, cummin, head, tail, etc..). These\n+  cannot be trivially mapped to Beam because PCollections, representing\n+  distributed datasets, are unordered. Note that even some of these operations\n+  *may* get implemented in the future - we actually have some ideas for how we\n+  might support order sensitive operations - but it's a ways off.\n+\n+Finally, it's important to note that this is a preview of a new feature that\n+will get hardened over the next few Beam releases. We would love for you to try\n+it out now and give us some feedback, but we do not yet recommend it for use in\n+production workloads.\n+\n+## How to get involved\n+The easiest way to get involved with this effort is to try out DataFrames and\n+let us know what you think! You can send questions to user@beam.apache.org, or\n+file bug reports and feature requests in [jira](https://issues.apache.org/jira).\n+In particular, it would be really helpful to know if there\u2019s an operation we\n+haven\u2019t implemented yet that you\u2019d find useful, so that we can prioritize it.\n+\n+If you\u2019d like to learn more about how the DataFrame API works under the hood and\n+get involved with the development we recommend you take a look at the\n+[design doc](http://s.apache.org/beam-dataframes)\n+and our [Beam summit\n+presentation](https://2020.beamsummit.org/sessions/simpler-python-pipelines/).\n+From there the best way to help is to knock out some of those not implemented\n+operations, we\u2019re coordinating that work in", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1121982c73430bddfcc7c733a20826597f9508d1"}, "originalPosition": 177}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8573eaba6b7076a2978f40012798fda01d557a83", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/8573eaba6b7076a2978f40012798fda01d557a83", "committedDate": "2020-12-17T21:44:01Z", "message": "minor fixes"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1MDY5ODQ0", "url": "https://github.com/apache/beam/pull/13561#pullrequestreview-555069844", "createdAt": "2020-12-17T23:29:39Z", "commit": {"oid": "8573eaba6b7076a2978f40012798fda01d557a83"}, "state": "APPROVED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMzoyOTozOVrOIINBvQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMzoyOTozOVrOIINBvQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTQ3Mjk1Nw==", "bodyText": "Should this be a comma rather than \": \" so it's 1:1 the same result?", "url": "https://github.com/apache/beam/pull/13561#discussion_r545472957", "createdAt": "2020-12-17T23:29:39Z", "author": {"login": "robertwb"}, "path": "website/www/site/content/en/blog/dataframe-api-preview-available.md", "diffHunk": "@@ -0,0 +1,178 @@\n+---\n+title:  \"DataFrame API Preview now Available!\"\n+date: \"2020-12-16T09:09:41-08:00\"\n+categories:\n+  - blog\n+authors:\n+  - bhulette\n+  - robertwb\n+---\n+<!--\n+Licensed under the Apache License, Version 2.0 (the \"License\");\n+you may not use this file except in compliance with the License.\n+You may obtain a copy of the License at\n+\n+http://www.apache.org/licenses/LICENSE-2.0\n+\n+Unless required by applicable law or agreed to in writing, software\n+distributed under the License is distributed on an \"AS IS\" BASIS,\n+WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+See the License for the specific language governing permissions and\n+limitations under the License.\n+-->\n+\n+We're excited to announce that a preview of the Beam Python SDK's new DataFrame\n+API is now available in [Beam\n+2.26.0](https://beam.apache.org/blog/beam-2.26.0/). Much like `SqlTransform`\n+([Java](https://beam.apache.org/releases/javadoc/current/org/apache/beam/sdk/extensions/sql/SqlTransform.html),\n+[Python](https://beam.apache.org/releases/pydoc/current/apache_beam.transforms.sql.html#apache_beam.transforms.sql.SqlTransform)),\n+the DataFrame API gives Beam users a way to express complex\n+relational logic much more concisely than previously possible.\n+<!--more-->\n+\n+## A more expressive API\n+Beam's new DataFrame API aims to be compatible with the well known\n+[Pandas](https://pandas.pydata.org/pandas-docs/stable/index.html)\n+DataFrame API, with a few caveats detailed below. With this new API a simple\n+pipeline that reads NYC taxiride data from a CSV, performs a grouped\n+aggregation, and writes the output to CSV, can be expressed very concisely:\n+\n+```\n+from apache_beam.dataframe.io import read_csv\n+\n+with beam.Pipeline() as p:\n+  df = p | read_csv(\"gs://apache-beam-samples/nyc_taxi/2019/*.csv\",\n+                    use_ncols=['passenger_count' , 'DOLocationID'])\n+  # Count the number of passengers dropped off per LocationID\n+  agg = df.groupby('DOLocationID').sum()\n+  agg.to_csv(output)\n+```\n+\n+Compare this to the same logic implemented as a conventional Beam python\n+pipeline with a `CombinePerKey`:\n+\n+```\n+with beam.Pipeline() as p:\n+  (p | beam.io.ReadFromText(\"gs://apache-beam-samples/nyc_taxi/2019/*.csv\",\n+                            skip_header_lines=1)\n+     | beam.Map(lambda line: line.split(','))\n+     # Parse CSV, create key - value pairs\n+     | beam.Map(lambda splits: (int(splits[8] or 0),  # DOLocationID\n+                                int(splits[3] or 0))) # passenger_count\n+     # Sum values per key\n+     | beam.CombinePerKey(sum)\n+     | beam.MapTuple(lambda loc_id, pc: f'{loc_id}: {pc}')", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8573eaba6b7076a2978f40012798fda01d557a83"}, "originalPosition": 64}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d26ab182718f9399dd090918795e74effed13c67", "author": {"user": {"login": "TheNeuralBit", "name": "Brian Hulette"}}, "url": "https://github.com/apache/beam/commit/d26ab182718f9399dd090918795e74effed13c67", "committedDate": "2020-12-18T00:26:32Z", "message": "Update dataframe-api-preview-available.md\n\nMake generated strings create valid CSV"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4451, "cost": 1, "resetAt": "2021-10-28T18:00:02Z"}}}