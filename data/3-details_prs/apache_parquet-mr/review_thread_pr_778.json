{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzk4MTY4MjMw", "number": 778, "reviewThreads": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wMlQxNjo0NTozNlrOD4rIhw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wMlQxNzo1MToyOFrOD4rgLA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYwNzUzNTQzOnYy", "diffSide": "RIGHT", "path": "parquet-column/src/main/java/org/apache/parquet/schema/LogicalTypeAnnotation.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wMlQxNjo0NTozNlrOGPkhCw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQyMDo0Mzo0MlrOGcrfsg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODk4MDEwNw==", "bodyText": "Why there is no implementation for hasCode() and equal()?", "url": "https://github.com/apache/parquet-mr/pull/778#discussion_r418980107", "createdAt": "2020-05-02T16:45:36Z", "author": {"login": "shangxinli"}, "path": "parquet-column/src/main/java/org/apache/parquet/schema/LogicalTypeAnnotation.java", "diffHunk": "@@ -861,6 +871,36 @@ PrimitiveStringifier valueStringifier(PrimitiveType primitiveType) {\n     }\n   }\n \n+  public static class UUIDLogicalTypeAnnotation extends LogicalTypeAnnotation {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b7dc3f94d1f2e382ae5f263cbaff7bf935d26959"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTM2ODg1MA==", "bodyText": "As this is a singleton the default implementation of equals(Object) and hashCode() fits perfectly.", "url": "https://github.com/apache/parquet-mr/pull/778#discussion_r421368850", "createdAt": "2020-05-07T09:30:42Z", "author": {"login": "gszadovszky"}, "path": "parquet-column/src/main/java/org/apache/parquet/schema/LogicalTypeAnnotation.java", "diffHunk": "@@ -861,6 +871,36 @@ PrimitiveStringifier valueStringifier(PrimitiveType primitiveType) {\n     }\n   }\n \n+  public static class UUIDLogicalTypeAnnotation extends LogicalTypeAnnotation {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODk4MDEwNw=="}, "originalCommit": {"oid": "b7dc3f94d1f2e382ae5f263cbaff7bf935d26959"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjcyNTkzOA==", "bodyText": "Sounds good!", "url": "https://github.com/apache/parquet-mr/pull/778#discussion_r432725938", "createdAt": "2020-05-29T20:43:42Z", "author": {"login": "shangxinli"}, "path": "parquet-column/src/main/java/org/apache/parquet/schema/LogicalTypeAnnotation.java", "diffHunk": "@@ -861,6 +871,36 @@ PrimitiveStringifier valueStringifier(PrimitiveType primitiveType) {\n     }\n   }\n \n+  public static class UUIDLogicalTypeAnnotation extends LogicalTypeAnnotation {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODk4MDEwNw=="}, "originalCommit": {"oid": "b7dc3f94d1f2e382ae5f263cbaff7bf935d26959"}, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYwNzU0OTcwOnYy", "diffSide": "RIGHT", "path": "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveStringifier.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wMlQxNzowMDo1MFrOGPkn1Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQyMDo0MzoyOVrOGcrfSw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODk4MTg0NQ==", "bodyText": "Do you want to make 'bytes' final since you are calling getBytesUnsafe()?", "url": "https://github.com/apache/parquet-mr/pull/778#discussion_r418981845", "createdAt": "2020-05-02T17:00:50Z", "author": {"login": "shangxinli"}, "path": "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveStringifier.java", "diffHunk": "@@ -421,4 +422,30 @@ private String stringifyWithScale(BigInteger i) {\n       }\n     };\n   }\n+\n+  static final PrimitiveStringifier UUID_STRINGIFIER = new PrimitiveStringifier(\"UUID_STRINGIFIER\") {\n+    private final char[] digit = \"0123456789abcdef\".toCharArray();\n+    @Override\n+    public String stringify(Binary value) {\n+      byte[] bytes = value.getBytesUnsafe();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b7dc3f94d1f2e382ae5f263cbaff7bf935d26959"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTM3MjM4OQ==", "bodyText": "final would protect the reference only and not the values of the array. Making a reference final in a local scope is usually required in situations where it is accessed from e.g. lambda closures.", "url": "https://github.com/apache/parquet-mr/pull/778#discussion_r421372389", "createdAt": "2020-05-07T09:36:30Z", "author": {"login": "gszadovszky"}, "path": "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveStringifier.java", "diffHunk": "@@ -421,4 +422,30 @@ private String stringifyWithScale(BigInteger i) {\n       }\n     };\n   }\n+\n+  static final PrimitiveStringifier UUID_STRINGIFIER = new PrimitiveStringifier(\"UUID_STRINGIFIER\") {\n+    private final char[] digit = \"0123456789abcdef\".toCharArray();\n+    @Override\n+    public String stringify(Binary value) {\n+      byte[] bytes = value.getBytesUnsafe();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODk4MTg0NQ=="}, "originalCommit": {"oid": "b7dc3f94d1f2e382ae5f263cbaff7bf935d26959"}, "originalPosition": 17}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjcyNTgzNQ==", "bodyText": "Sounds good!", "url": "https://github.com/apache/parquet-mr/pull/778#discussion_r432725835", "createdAt": "2020-05-29T20:43:29Z", "author": {"login": "shangxinli"}, "path": "parquet-column/src/main/java/org/apache/parquet/schema/PrimitiveStringifier.java", "diffHunk": "@@ -421,4 +422,30 @@ private String stringifyWithScale(BigInteger i) {\n       }\n     };\n   }\n+\n+  static final PrimitiveStringifier UUID_STRINGIFIER = new PrimitiveStringifier(\"UUID_STRINGIFIER\") {\n+    private final char[] digit = \"0123456789abcdef\".toCharArray();\n+    @Override\n+    public String stringify(Binary value) {\n+      byte[] bytes = value.getBytesUnsafe();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODk4MTg0NQ=="}, "originalCommit": {"oid": "b7dc3f94d1f2e382ae5f263cbaff7bf935d26959"}, "originalPosition": 17}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYwNzU2ODk3OnYy", "diffSide": "RIGHT", "path": "parquet-column/src/test/java/org/apache/parquet/schema/TestPrimitiveStringifier.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wMlQxNzoyMToyM1rOGPkw-A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wMlQwNzo0MzowM1rOGdl0Qw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODk4NDE4NA==", "bodyText": "Are the 3 test data are randomly chosen? It seems duplicate coverage.\nCould you add some negative tests like incorrect length uuids, invalid characters etc.", "url": "https://github.com/apache/parquet-mr/pull/778#discussion_r418984184", "createdAt": "2020-05-02T17:21:23Z", "author": {"login": "shangxinli"}, "path": "parquet-column/src/test/java/org/apache/parquet/schema/TestPrimitiveStringifier.java", "diffHunk": "@@ -309,6 +308,35 @@ public void testDecimalStringifier() {\n     checkThrowingUnsupportedException(stringifier, Integer.TYPE, Long.TYPE, Binary.class);\n   }\n \n+  @Test\n+  public void testUUIDStringifier() {\n+    PrimitiveStringifier stringifier = PrimitiveStringifier.UUID_STRINGIFIER;\n+\n+    assertEquals(\"00112233-4455-6677-8899-aabbccddeeff\", stringifier.stringify(\n+        toBinary(0x00, 0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, 0x88, 0x99, 0xaa, 0xbb, 0xcc, 0xdd, 0xee, 0xff)));\n+    assertEquals(\"00000000-0000-0000-0000-000000000000\", stringifier.stringify(\n+        toBinary(0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00)));\n+    assertEquals(\"ffffffff-ffff-ffff-ffff-ffffffffffff\", stringifier.stringify(\n+        toBinary(0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff)));\n+\n+    assertEquals(\"0eb1497c-19b6-42bc-b028-b4b612bed141\", stringifier.stringify(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b7dc3f94d1f2e382ae5f263cbaff7bf935d26959"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTM4MTExMg==", "bodyText": "The idea is to have 3 kind-of corner cases and 3 common (random but constant) values. What do you mean by duplicate coverage? (I think, we do not need exhaustive testing for the stringifiers because they only used by our tools for debugging purposes.)\nThe stringifiers do not validate the data they get because of performance reasons. So, if the array is longer than 16 it would simply stringify the first 16 and skip the others. In case of the length is too short then an ArrayIndexOutOfBoundsException would be thrown. Do you think we should test these cases? They would not reach any additional branches in the parquet code.\nInvalid characters are not possible. The full set of values of the 16 bytes array is covered in UUID.", "url": "https://github.com/apache/parquet-mr/pull/778#discussion_r421381112", "createdAt": "2020-05-07T09:50:41Z", "author": {"login": "gszadovszky"}, "path": "parquet-column/src/test/java/org/apache/parquet/schema/TestPrimitiveStringifier.java", "diffHunk": "@@ -309,6 +308,35 @@ public void testDecimalStringifier() {\n     checkThrowingUnsupportedException(stringifier, Integer.TYPE, Long.TYPE, Binary.class);\n   }\n \n+  @Test\n+  public void testUUIDStringifier() {\n+    PrimitiveStringifier stringifier = PrimitiveStringifier.UUID_STRINGIFIER;\n+\n+    assertEquals(\"00112233-4455-6677-8899-aabbccddeeff\", stringifier.stringify(\n+        toBinary(0x00, 0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, 0x88, 0x99, 0xaa, 0xbb, 0xcc, 0xdd, 0xee, 0xff)));\n+    assertEquals(\"00000000-0000-0000-0000-000000000000\", stringifier.stringify(\n+        toBinary(0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00)));\n+    assertEquals(\"ffffffff-ffff-ffff-ffff-ffffffffffff\", stringifier.stringify(\n+        toBinary(0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff)));\n+\n+    assertEquals(\"0eb1497c-19b6-42bc-b028-b4b612bed141\", stringifier.stringify(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODk4NDE4NA=="}, "originalCommit": {"oid": "b7dc3f94d1f2e382ae5f263cbaff7bf935d26959"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjU2NDIwMA==", "bodyText": "By duplicate coverage, I meant the #2, #3 tests seems repeating the same test as #1. The value is different, but when the test executes, they would execute the same code path. So I think they won't provide extra coverage.\nFrom test perspective, negative test does provide values. In this case, we can test the exception is thrown as expected if it is too short.\nFor \"if the array is longer than 16 it would simply stringify the first 16 and skip the others\", that could cause silent errors, right?", "url": "https://github.com/apache/parquet-mr/pull/778#discussion_r422564200", "createdAt": "2020-05-10T00:25:44Z", "author": {"login": "shangxinli"}, "path": "parquet-column/src/test/java/org/apache/parquet/schema/TestPrimitiveStringifier.java", "diffHunk": "@@ -309,6 +308,35 @@ public void testDecimalStringifier() {\n     checkThrowingUnsupportedException(stringifier, Integer.TYPE, Long.TYPE, Binary.class);\n   }\n \n+  @Test\n+  public void testUUIDStringifier() {\n+    PrimitiveStringifier stringifier = PrimitiveStringifier.UUID_STRINGIFIER;\n+\n+    assertEquals(\"00112233-4455-6677-8899-aabbccddeeff\", stringifier.stringify(\n+        toBinary(0x00, 0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, 0x88, 0x99, 0xaa, 0xbb, 0xcc, 0xdd, 0xee, 0xff)));\n+    assertEquals(\"00000000-0000-0000-0000-000000000000\", stringifier.stringify(\n+        toBinary(0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00)));\n+    assertEquals(\"ffffffff-ffff-ffff-ffff-ffffffffffff\", stringifier.stringify(\n+        toBinary(0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff)));\n+\n+    assertEquals(\"0eb1497c-19b6-42bc-b028-b4b612bed141\", stringifier.stringify(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODk4NDE4NA=="}, "originalCommit": {"oid": "b7dc3f94d1f2e382ae5f263cbaff7bf935d26959"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzY4MTQ3NQ==", "bodyText": "I'm happy to add tests for the edge cases like too short or too long inputs. Though, I would not implement additional validations because of performance issues. A stringify method would be invoked on each values; an additional check would highly impact performance even if it is only used from the tools and not really in production. A Stringifier is associated to the value at schema level which means it shall never happen that the value is invalid. That's why the Stringifier implementations do not validate the values.", "url": "https://github.com/apache/parquet-mr/pull/778#discussion_r433681475", "createdAt": "2020-06-02T07:43:03Z", "author": {"login": "gszadovszky"}, "path": "parquet-column/src/test/java/org/apache/parquet/schema/TestPrimitiveStringifier.java", "diffHunk": "@@ -309,6 +308,35 @@ public void testDecimalStringifier() {\n     checkThrowingUnsupportedException(stringifier, Integer.TYPE, Long.TYPE, Binary.class);\n   }\n \n+  @Test\n+  public void testUUIDStringifier() {\n+    PrimitiveStringifier stringifier = PrimitiveStringifier.UUID_STRINGIFIER;\n+\n+    assertEquals(\"00112233-4455-6677-8899-aabbccddeeff\", stringifier.stringify(\n+        toBinary(0x00, 0x11, 0x22, 0x33, 0x44, 0x55, 0x66, 0x77, 0x88, 0x99, 0xaa, 0xbb, 0xcc, 0xdd, 0xee, 0xff)));\n+    assertEquals(\"00000000-0000-0000-0000-000000000000\", stringifier.stringify(\n+        toBinary(0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00, 0x00)));\n+    assertEquals(\"ffffffff-ffff-ffff-ffff-ffffffffffff\", stringifier.stringify(\n+        toBinary(0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff, 0xff)));\n+\n+    assertEquals(\"0eb1497c-19b6-42bc-b028-b4b612bed141\", stringifier.stringify(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODk4NDE4NA=="}, "originalCommit": {"oid": "b7dc3f94d1f2e382ae5f263cbaff7bf935d26959"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYwNzU3NTk5OnYy", "diffSide": "RIGHT", "path": "parquet-avro/README.md", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wMlQxNzoyOToxNFrOGPk0Yg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yOVQyMDo0MzoxOVrOGcrfAg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODk4NTA1OA==", "bodyText": "Should we add it using separate jira?", "url": "https://github.com/apache/parquet-mr/pull/778#discussion_r418985058", "createdAt": "2020-05-02T17:29:14Z", "author": {"login": "shangxinli"}, "path": "parquet-avro/README.md", "diffHunk": "@@ -0,0 +1,44 @@\n+<!--", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b7dc3f94d1f2e382ae5f263cbaff7bf935d26959"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTM4NDExOQ==", "bodyText": "Usually we separate jiras in similar cases to not make cherry-picking hard in case of the related changed needs to be on another branch as well. In this case this is only a documentation so should not cause any troubles. It would be cleaner if this documentation would have already been existed and I've had to add the docs of the new keys only (which would clearly be part of this change).\nIf you have a strong opinion to separate this to another change I'm happy to do so, though.", "url": "https://github.com/apache/parquet-mr/pull/778#discussion_r421384119", "createdAt": "2020-05-07T09:55:45Z", "author": {"login": "gszadovszky"}, "path": "parquet-avro/README.md", "diffHunk": "@@ -0,0 +1,44 @@\n+<!--", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODk4NTA1OA=="}, "originalCommit": {"oid": "b7dc3f94d1f2e382ae5f263cbaff7bf935d26959"}, "originalPosition": 1}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjcyNTc2Mg==", "bodyText": "Sounds good", "url": "https://github.com/apache/parquet-mr/pull/778#discussion_r432725762", "createdAt": "2020-05-29T20:43:19Z", "author": {"login": "shangxinli"}, "path": "parquet-avro/README.md", "diffHunk": "@@ -0,0 +1,44 @@\n+<!--", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODk4NTA1OA=="}, "originalCommit": {"oid": "b7dc3f94d1f2e382ae5f263cbaff7bf935d26959"}, "originalPosition": 1}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYwNzU5NTk2OnYy", "diffSide": "RIGHT", "path": "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java", "isResolved": false, "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wMlQxNzo1MToyOFrOGPk-Hg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0wM1QxNDo1Njo1MVrOGef0ZQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODk4NzU1MA==", "bodyText": "Can we have checkReaderWriterCompatibility() to verify if the parquet and avro schema are compatible for UUID?\nThere are issues like PARQUET-1681 for avro schema and parquet schema conversion for other types.", "url": "https://github.com/apache/parquet-mr/pull/778#discussion_r418987550", "createdAt": "2020-05-02T17:51:28Z", "author": {"login": "shangxinli"}, "path": "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java", "diffHunk": "@@ -766,6 +768,33 @@ public void testReuseNameInNestedStructureAtSameLevel() throws Exception {\n     testParquetToAvroConversion(NEW_BEHAVIOR, schema, parquetSchema);\n   }\n \n+  @Test\n+  public void testUUIDType() throws Exception {\n+    Schema fromAvro = Schema.createRecord(\"myrecord\", null, null, false,\n+        Arrays.asList(new Schema.Field(\"uuid\", LogicalTypes.uuid().addToSchema(Schema.create(STRING)), null, null)));\n+    String parquet = \"message myrecord {\\n\" +\n+        \"  required binary uuid (STRING);\\n\" +\n+        \"}\\n\";\n+    Schema toAvro = Schema.createRecord(\"myrecord\", null, null, false,\n+        Arrays.asList(new Schema.Field(\"uuid\", Schema.create(STRING), null, null)));\n+\n+    testAvroToParquetConversion(fromAvro, parquet);\n+    testParquetToAvroConversion(toAvro, parquet);\n+  }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b7dc3f94d1f2e382ae5f263cbaff7bf935d26959"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTM4OTU3NQ==", "bodyText": "To be honest I am not too familiar with parquet-avro. I've made the changes based on the implementation/test of other logical types. Could you explain it in more details what you would test exactly?", "url": "https://github.com/apache/parquet-mr/pull/778#discussion_r421389575", "createdAt": "2020-05-07T10:04:59Z", "author": {"login": "gszadovszky"}, "path": "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java", "diffHunk": "@@ -766,6 +768,33 @@ public void testReuseNameInNestedStructureAtSameLevel() throws Exception {\n     testParquetToAvroConversion(NEW_BEHAVIOR, schema, parquetSchema);\n   }\n \n+  @Test\n+  public void testUUIDType() throws Exception {\n+    Schema fromAvro = Schema.createRecord(\"myrecord\", null, null, false,\n+        Arrays.asList(new Schema.Field(\"uuid\", LogicalTypes.uuid().addToSchema(Schema.create(STRING)), null, null)));\n+    String parquet = \"message myrecord {\\n\" +\n+        \"  required binary uuid (STRING);\\n\" +\n+        \"}\\n\";\n+    Schema toAvro = Schema.createRecord(\"myrecord\", null, null, false,\n+        Arrays.asList(new Schema.Field(\"uuid\", Schema.create(STRING), null, null)));\n+\n+    testAvroToParquetConversion(fromAvro, parquet);\n+    testParquetToAvroConversion(toAvro, parquet);\n+  }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODk4NzU1MA=="}, "originalCommit": {"oid": "b7dc3f94d1f2e382ae5f263cbaff7bf935d26959"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjU2MzEwOA==", "bodyText": "Basically we found some type of avro schema is not compatible with the parquet schema which it is converted to. This caused problem that the data cannot be read. I have a test here (shangxinli@f80469f#diff-536ca67880a7870cf8df8f95143bd7d7R814) that reproduce the issue for a nested schema. I know likely UUID type won't have this issue but it better to have a test for it. It is pretty easy to add also.", "url": "https://github.com/apache/parquet-mr/pull/778#discussion_r422563108", "createdAt": "2020-05-10T00:12:24Z", "author": {"login": "shangxinli"}, "path": "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java", "diffHunk": "@@ -766,6 +768,33 @@ public void testReuseNameInNestedStructureAtSameLevel() throws Exception {\n     testParquetToAvroConversion(NEW_BEHAVIOR, schema, parquetSchema);\n   }\n \n+  @Test\n+  public void testUUIDType() throws Exception {\n+    Schema fromAvro = Schema.createRecord(\"myrecord\", null, null, false,\n+        Arrays.asList(new Schema.Field(\"uuid\", LogicalTypes.uuid().addToSchema(Schema.create(STRING)), null, null)));\n+    String parquet = \"message myrecord {\\n\" +\n+        \"  required binary uuid (STRING);\\n\" +\n+        \"}\\n\";\n+    Schema toAvro = Schema.createRecord(\"myrecord\", null, null, false,\n+        Arrays.asList(new Schema.Field(\"uuid\", Schema.create(STRING), null, null)));\n+\n+    testAvroToParquetConversion(fromAvro, parquet);\n+    testParquetToAvroConversion(toAvro, parquet);\n+  }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODk4NzU1MA=="}, "originalCommit": {"oid": "b7dc3f94d1f2e382ae5f263cbaff7bf935d26959"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMjcyNTY2MQ==", "bodyText": "If it is too much effort for doing this, it is OK not to do it. It is a lower priority.", "url": "https://github.com/apache/parquet-mr/pull/778#discussion_r432725661", "createdAt": "2020-05-29T20:43:05Z", "author": {"login": "shangxinli"}, "path": "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java", "diffHunk": "@@ -766,6 +768,33 @@ public void testReuseNameInNestedStructureAtSameLevel() throws Exception {\n     testParquetToAvroConversion(NEW_BEHAVIOR, schema, parquetSchema);\n   }\n \n+  @Test\n+  public void testUUIDType() throws Exception {\n+    Schema fromAvro = Schema.createRecord(\"myrecord\", null, null, false,\n+        Arrays.asList(new Schema.Field(\"uuid\", LogicalTypes.uuid().addToSchema(Schema.create(STRING)), null, null)));\n+    String parquet = \"message myrecord {\\n\" +\n+        \"  required binary uuid (STRING);\\n\" +\n+        \"}\\n\";\n+    Schema toAvro = Schema.createRecord(\"myrecord\", null, null, false,\n+        Arrays.asList(new Schema.Field(\"uuid\", Schema.create(STRING), null, null)));\n+\n+    testAvroToParquetConversion(fromAvro, parquet);\n+    testParquetToAvroConversion(toAvro, parquet);\n+  }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODk4NzU1MA=="}, "originalCommit": {"oid": "b7dc3f94d1f2e382ae5f263cbaff7bf935d26959"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzMzY3ODQ3Mw==", "bodyText": "I'll look into this just did not have time to work on this PR. Thanks a lot for reviewing. :)", "url": "https://github.com/apache/parquet-mr/pull/778#discussion_r433678473", "createdAt": "2020-06-02T07:37:19Z", "author": {"login": "gszadovszky"}, "path": "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java", "diffHunk": "@@ -766,6 +768,33 @@ public void testReuseNameInNestedStructureAtSameLevel() throws Exception {\n     testParquetToAvroConversion(NEW_BEHAVIOR, schema, parquetSchema);\n   }\n \n+  @Test\n+  public void testUUIDType() throws Exception {\n+    Schema fromAvro = Schema.createRecord(\"myrecord\", null, null, false,\n+        Arrays.asList(new Schema.Field(\"uuid\", LogicalTypes.uuid().addToSchema(Schema.create(STRING)), null, null)));\n+    String parquet = \"message myrecord {\\n\" +\n+        \"  required binary uuid (STRING);\\n\" +\n+        \"}\\n\";\n+    Schema toAvro = Schema.createRecord(\"myrecord\", null, null, false,\n+        Arrays.asList(new Schema.Field(\"uuid\", Schema.create(STRING), null, null)));\n+\n+    testAvroToParquetConversion(fromAvro, parquet);\n+    testParquetToAvroConversion(toAvro, parquet);\n+  }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODk4NzU1MA=="}, "originalCommit": {"oid": "b7dc3f94d1f2e382ae5f263cbaff7bf935d26959"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDU1MDA3OA==", "bodyText": "The testRoundTripConversion I'm using in testUUIDTypeWithParquetUUID is actually stronger than the one you suggested: it checks for equality (in two phases) of the initial and the result avro schemas (and not only for compatibility). For testUUIDType, though it is a good idea to check the compatibility of the avro schemas.", "url": "https://github.com/apache/parquet-mr/pull/778#discussion_r434550078", "createdAt": "2020-06-03T13:04:14Z", "author": {"login": "gszadovszky"}, "path": "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java", "diffHunk": "@@ -766,6 +768,33 @@ public void testReuseNameInNestedStructureAtSameLevel() throws Exception {\n     testParquetToAvroConversion(NEW_BEHAVIOR, schema, parquetSchema);\n   }\n \n+  @Test\n+  public void testUUIDType() throws Exception {\n+    Schema fromAvro = Schema.createRecord(\"myrecord\", null, null, false,\n+        Arrays.asList(new Schema.Field(\"uuid\", LogicalTypes.uuid().addToSchema(Schema.create(STRING)), null, null)));\n+    String parquet = \"message myrecord {\\n\" +\n+        \"  required binary uuid (STRING);\\n\" +\n+        \"}\\n\";\n+    Schema toAvro = Schema.createRecord(\"myrecord\", null, null, false,\n+        Arrays.asList(new Schema.Field(\"uuid\", Schema.create(STRING), null, null)));\n+\n+    testAvroToParquetConversion(fromAvro, parquet);\n+    testParquetToAvroConversion(toAvro, parquet);\n+  }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODk4NzU1MA=="}, "originalCommit": {"oid": "b7dc3f94d1f2e382ae5f263cbaff7bf935d26959"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzNDYzMTc4MQ==", "bodyText": "Sounds good", "url": "https://github.com/apache/parquet-mr/pull/778#discussion_r434631781", "createdAt": "2020-06-03T14:56:51Z", "author": {"login": "shangxinli"}, "path": "parquet-avro/src/test/java/org/apache/parquet/avro/TestAvroSchemaConverter.java", "diffHunk": "@@ -766,6 +768,33 @@ public void testReuseNameInNestedStructureAtSameLevel() throws Exception {\n     testParquetToAvroConversion(NEW_BEHAVIOR, schema, parquetSchema);\n   }\n \n+  @Test\n+  public void testUUIDType() throws Exception {\n+    Schema fromAvro = Schema.createRecord(\"myrecord\", null, null, false,\n+        Arrays.asList(new Schema.Field(\"uuid\", LogicalTypes.uuid().addToSchema(Schema.create(STRING)), null, null)));\n+    String parquet = \"message myrecord {\\n\" +\n+        \"  required binary uuid (STRING);\\n\" +\n+        \"}\\n\";\n+    Schema toAvro = Schema.createRecord(\"myrecord\", null, null, false,\n+        Arrays.asList(new Schema.Field(\"uuid\", Schema.create(STRING), null, null)));\n+\n+    testAvroToParquetConversion(fromAvro, parquet);\n+    testParquetToAvroConversion(toAvro, parquet);\n+  }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODk4NzU1MA=="}, "originalCommit": {"oid": "b7dc3f94d1f2e382ae5f263cbaff7bf935d26959"}, "originalPosition": 29}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4757, "cost": 1, "resetAt": "2021-11-11T21:28:48Z"}}}