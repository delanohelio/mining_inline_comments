{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDU4MDU3MzQ5", "number": 315, "reviewThreads": {"totalCount": 48, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQwMToxMjoxMFrOEYTVfg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQwMTo0NzoxNFrOEh6s8Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkzOTE4MDc4OnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/PerformanceAnalyzerApp.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQwMToxMjoxMFrOHAkYTg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNVQwMjo0MDoyNlrOHGCBDw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM1ODA5NA==", "bodyText": "Please change the README accordingly to document the new url and details for this", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r470358094", "createdAt": "2020-08-14T01:12:10Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/PerformanceAnalyzerApp.java", "diffHunk": "@@ -66,6 +67,7 @@\n \n   private static final int EXCEPTION_QUEUE_LENGTH = 1;\n   public static final String QUERY_URL = \"/_opendistro/_performanceanalyzer/metrics\";\n+  public static final String BATCH_METRICS_URL = \"/_opendistro/_performanceanalyzer/batch\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjA4NjU0Mw==", "bodyText": "Agreed, documentation has been added to the README in the performance-analyzer repository.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r476086543", "createdAt": "2020-08-25T02:40:26Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/PerformanceAnalyzerApp.java", "diffHunk": "@@ -66,6 +67,7 @@\n \n   private static final int EXCEPTION_QUEUE_LENGTH = 1;\n   public static final String QUERY_URL = \"/_opendistro/_performanceanalyzer/metrics\";\n+  public static final String BATCH_METRICS_URL = \"/_opendistro/_performanceanalyzer/batch\";", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM1ODA5NA=="}, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkzOTE4MzQ3OnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/config/PluginSettings.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQwMToxMzoyMVrOHAkaAg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxNzoxNTowNFrOHFupPQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM1ODUzMA==", "bodyText": "Can we add the time unit in the variable name such as\nBATCH_METRICS_RETENTION_PERIOD_DEFAULT_MINS and so on ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r470358530", "createdAt": "2020-08-14T01:13:21Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/config/PluginSettings.java", "diffHunk": "@@ -44,6 +45,9 @@\n   private static final int DELETION_INTERVAL_MAX = 60;\n   private static final String HTTPS_ENABLED = \"https-enabled\";\n   private static final String WRITER_QUEUE_SIZE = \"writer-queue-size\";\n+  private static final String BATCH_METRICS_RETENTION_PERIOD = \"batch-metrics-retention-period\";\n+  private static final long BATCH_METRICS_RETENTION_PERIOD_DEFAULT = 7;  // 7 minutes of metrics\n+  private static final long BATCH_METRICS_RETENTION_PERIOD_LIMIT = 60;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTc2OTE0OQ==", "bodyText": "Yes, that would be a good idea.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r475769149", "createdAt": "2020-08-24T17:15:04Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/config/PluginSettings.java", "diffHunk": "@@ -44,6 +45,9 @@\n   private static final int DELETION_INTERVAL_MAX = 60;\n   private static final String HTTPS_ENABLED = \"https-enabled\";\n   private static final String WRITER_QUEUE_SIZE = \"writer-queue-size\";\n+  private static final String BATCH_METRICS_RETENTION_PERIOD = \"batch-metrics-retention-period\";\n+  private static final long BATCH_METRICS_RETENTION_PERIOD_DEFAULT = 7;  // 7 minutes of metrics\n+  private static final long BATCH_METRICS_RETENTION_PERIOD_LIMIT = 60;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM1ODUzMA=="}, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkzOTE4NDQ4OnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/config/PluginSettings.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQwMToxNDowMFrOHAkahw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxNzoxNDoyN1rOHFunxA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM1ODY2Mw==", "bodyText": "Also can we add javadoc comments describing the variables ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r470358663", "createdAt": "2020-08-14T01:14:00Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/config/PluginSettings.java", "diffHunk": "@@ -44,6 +45,9 @@\n   private static final int DELETION_INTERVAL_MAX = 60;\n   private static final String HTTPS_ENABLED = \"https-enabled\";\n   private static final String WRITER_QUEUE_SIZE = \"writer-queue-size\";\n+  private static final String BATCH_METRICS_RETENTION_PERIOD = \"batch-metrics-retention-period\";\n+  private static final long BATCH_METRICS_RETENTION_PERIOD_DEFAULT = 7;  // 7 minutes of metrics", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTc2ODc3Mg==", "bodyText": "Will add this documentation to the batchMetricsRetentionPeriod variable (this is what was done for the other parameters also).", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r475768772", "createdAt": "2020-08-24T17:14:27Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/config/PluginSettings.java", "diffHunk": "@@ -44,6 +45,9 @@\n   private static final int DELETION_INTERVAL_MAX = 60;\n   private static final String HTTPS_ENABLED = \"https-enabled\";\n   private static final String WRITER_QUEUE_SIZE = \"writer-queue-size\";\n+  private static final String BATCH_METRICS_RETENTION_PERIOD = \"batch-metrics-retention-period\";\n+  private static final long BATCH_METRICS_RETENTION_PERIOD_DEFAULT = 7;  // 7 minutes of metrics", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM1ODY2Mw=="}, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkzOTE4NTAyOnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/config/PluginSettings.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQwMToxNDoyMlrOHAkazg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxNzoxNjo0NFrOHFusog==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM1ODczNA==", "bodyText": "Please add the timeunit as the variable name", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r470358734", "createdAt": "2020-08-14T01:14:22Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/config/PluginSettings.java", "diffHunk": "@@ -59,6 +63,8 @@\n   private Properties settings;\n   private final String configFilePath;\n \n+  private long batchMetricsRetentionPeriod;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTc3MDAxOA==", "bodyText": "Yes", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r475770018", "createdAt": "2020-08-24T17:16:44Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/config/PluginSettings.java", "diffHunk": "@@ -59,6 +63,8 @@\n   private Properties settings;\n   private final String configFilePath;\n \n+  private long batchMetricsRetentionPeriod;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM1ODczNA=="}, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkzOTE4NzQxOnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/config/PluginSettings.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQwMToxNTozNFrOHAkcBA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxNzoxNzowOVrOHFutjw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM1OTA0NA==", "bodyText": "Let's add the unit here as well, so that it is reflected in the logs", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r470359044", "createdAt": "2020-08-14T01:15:34Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/config/PluginSettings.java", "diffHunk": "@@ -156,11 +178,12 @@ private PluginSettings(String cfPath) {\n     }\n     LOG.info(\n         \"Config: metricsLocation: {}, metricsDeletionInterval: {}, httpsEnabled: {},\"\n-            + \" cleanup-metrics-db-files: {}\",\n+            + \" cleanup-metrics-db-files: {}, batch-metrics-retention-period: {}\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 73}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTc3MDI1NQ==", "bodyText": "Yes", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r475770255", "createdAt": "2020-08-24T17:17:09Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/config/PluginSettings.java", "diffHunk": "@@ -156,11 +178,12 @@ private PluginSettings(String cfPath) {\n     }\n     LOG.info(\n         \"Config: metricsLocation: {}, metricsDeletionInterval: {}, httpsEnabled: {},\"\n-            + \" cleanup-metrics-db-files: {}\",\n+            + \" cleanup-metrics-db-files: {}, batch-metrics-retention-period: {}\",", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM1OTA0NA=="}, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 73}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkzOTIwMTcwOnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/config/PluginSettings.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQwMToyNDo1MVrOHAkkUw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQyMjozNjowNFrOHF4mLA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM2MTE3MQ==", "bodyText": "We are throwing an exception here but maybe we should just log an error and use default values ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r470361171", "createdAt": "2020-08-14T01:24:51Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/config/PluginSettings.java", "diffHunk": "@@ -271,4 +294,26 @@ private void loadMetricsDBFilesCleanupEnabled() {\n       shouldCleanupMetricsDBFiles = true;\n     }\n   }\n+\n+  private void loadBatchMetricsRetentionPeriodFromConfig() {\n+    if (!settings.containsKey(BATCH_METRICS_RETENTION_PERIOD)) {\n+      return;\n+    }\n+\n+    long parsedRetentionPeriod;\n+    try {\n+      parsedRetentionPeriod = Long.parseLong(settings.getProperty(BATCH_METRICS_RETENTION_PERIOD));\n+      if (parsedRetentionPeriod <= 0 || parsedRetentionPeriod > BATCH_METRICS_RETENTION_PERIOD_LIMIT) {\n+        throw new InvalidParameterException();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE1NTc5Ng==", "bodyText": "Sruti has a PR out,#389 that prevents the Reader from starting if the parsed config is invalid. You can set this to 0 and call ConfigStatus.INSTANCE.setConfigurationInvalid()", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r474155796", "createdAt": "2020-08-20T17:30:00Z", "author": {"login": "sidheart"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/config/PluginSettings.java", "diffHunk": "@@ -271,4 +294,26 @@ private void loadMetricsDBFilesCleanupEnabled() {\n       shouldCleanupMetricsDBFiles = true;\n     }\n   }\n+\n+  private void loadBatchMetricsRetentionPeriodFromConfig() {\n+    if (!settings.containsKey(BATCH_METRICS_RETENTION_PERIOD)) {\n+      return;\n+    }\n+\n+    long parsedRetentionPeriod;\n+    try {\n+      parsedRetentionPeriod = Long.parseLong(settings.getProperty(BATCH_METRICS_RETENTION_PERIOD));\n+      if (parsedRetentionPeriod <= 0 || parsedRetentionPeriod > BATCH_METRICS_RETENTION_PERIOD_LIMIT) {\n+        throw new InvalidParameterException();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM2MTE3MQ=="}, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTkzMTQxMw==", "bodyText": "Joydeep, if any exception is thrown here, the batchMetricsRetentionPeriodMinutes value will not have been modified (since it is in the last line of the try block), and so the default value will be retained. Additionally, the method itself catches the thrown Exception and logs it.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r475931413", "createdAt": "2020-08-24T22:33:53Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/config/PluginSettings.java", "diffHunk": "@@ -271,4 +294,26 @@ private void loadMetricsDBFilesCleanupEnabled() {\n       shouldCleanupMetricsDBFiles = true;\n     }\n   }\n+\n+  private void loadBatchMetricsRetentionPeriodFromConfig() {\n+    if (!settings.containsKey(BATCH_METRICS_RETENTION_PERIOD)) {\n+      return;\n+    }\n+\n+    long parsedRetentionPeriod;\n+    try {\n+      parsedRetentionPeriod = Long.parseLong(settings.getProperty(BATCH_METRICS_RETENTION_PERIOD));\n+      if (parsedRetentionPeriod <= 0 || parsedRetentionPeriod > BATCH_METRICS_RETENTION_PERIOD_LIMIT) {\n+        throw new InvalidParameterException();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM2MTE3MQ=="}, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTkzMjIwNA==", "bodyText": "Sid, Sruti's pr is only about disabling the reader if the config file cannot be found. It was not about disabling the reader if values cannot be correctly parsed from the config file -- using the default value for these cases is the desired behavior.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r475932204", "createdAt": "2020-08-24T22:36:04Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/config/PluginSettings.java", "diffHunk": "@@ -271,4 +294,26 @@ private void loadMetricsDBFilesCleanupEnabled() {\n       shouldCleanupMetricsDBFiles = true;\n     }\n   }\n+\n+  private void loadBatchMetricsRetentionPeriodFromConfig() {\n+    if (!settings.containsKey(BATCH_METRICS_RETENTION_PERIOD)) {\n+      return;\n+    }\n+\n+    long parsedRetentionPeriod;\n+    try {\n+      parsedRetentionPeriod = Long.parseLong(settings.getProperty(BATCH_METRICS_RETENTION_PERIOD));\n+      if (parsedRetentionPeriod <= 0 || parsedRetentionPeriod > BATCH_METRICS_RETENTION_PERIOD_LIMIT) {\n+        throw new InvalidParameterException();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM2MTE3MQ=="}, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 97}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkzOTIwNDc1OnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/config/PluginSettings.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQwMToyNjo0MFrOHAkmGg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNVQwMzo0NTozN1rOHGEeTg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM2MTYyNg==", "bodyText": "same here. Log error and then we should just use the defaults.\nAlso you can log error simply as:\nLOG.error(\"my error message: {}\", myParam)", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r470361626", "createdAt": "2020-08-14T01:26:40Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/config/PluginSettings.java", "diffHunk": "@@ -271,4 +294,26 @@ private void loadMetricsDBFilesCleanupEnabled() {\n       shouldCleanupMetricsDBFiles = true;\n     }\n   }\n+\n+  private void loadBatchMetricsRetentionPeriodFromConfig() {\n+    if (!settings.containsKey(BATCH_METRICS_RETENTION_PERIOD)) {\n+      return;\n+    }\n+\n+    long parsedRetentionPeriod;\n+    try {\n+      parsedRetentionPeriod = Long.parseLong(settings.getProperty(BATCH_METRICS_RETENTION_PERIOD));\n+      if (parsedRetentionPeriod <= 0 || parsedRetentionPeriod > BATCH_METRICS_RETENTION_PERIOD_LIMIT) {\n+        throw new InvalidParameterException();\n+      }\n+      batchMetricsRetentionPeriod = parsedRetentionPeriod;\n+    } catch (NumberFormatException | InvalidParameterException e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"Invalid batch-metrics-retention-period. Using default value {}.\", batchMetricsRetentionPeriod),\n+              e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 106}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE1NjkzNQ==", "bodyText": "^ but LOG.error(\"my error message: {}\", myParam, e) so that you get the exception stacktrace (note that the stacktrace doesn't need a {} string)", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r474156935", "createdAt": "2020-08-20T17:32:07Z", "author": {"login": "sidheart"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/config/PluginSettings.java", "diffHunk": "@@ -271,4 +294,26 @@ private void loadMetricsDBFilesCleanupEnabled() {\n       shouldCleanupMetricsDBFiles = true;\n     }\n   }\n+\n+  private void loadBatchMetricsRetentionPeriodFromConfig() {\n+    if (!settings.containsKey(BATCH_METRICS_RETENTION_PERIOD)) {\n+      return;\n+    }\n+\n+    long parsedRetentionPeriod;\n+    try {\n+      parsedRetentionPeriod = Long.parseLong(settings.getProperty(BATCH_METRICS_RETENTION_PERIOD));\n+      if (parsedRetentionPeriod <= 0 || parsedRetentionPeriod > BATCH_METRICS_RETENTION_PERIOD_LIMIT) {\n+        throw new InvalidParameterException();\n+      }\n+      batchMetricsRetentionPeriod = parsedRetentionPeriod;\n+    } catch (NumberFormatException | InvalidParameterException e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"Invalid batch-metrics-retention-period. Using default value {}.\", batchMetricsRetentionPeriod),\n+              e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM2MTYyNg=="}, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 106}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NjEyNjc5OA==", "bodyText": "Agreed, updated the error logging call.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r476126798", "createdAt": "2020-08-25T03:45:37Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/config/PluginSettings.java", "diffHunk": "@@ -271,4 +294,26 @@ private void loadMetricsDBFilesCleanupEnabled() {\n       shouldCleanupMetricsDBFiles = true;\n     }\n   }\n+\n+  private void loadBatchMetricsRetentionPeriodFromConfig() {\n+    if (!settings.containsKey(BATCH_METRICS_RETENTION_PERIOD)) {\n+      return;\n+    }\n+\n+    long parsedRetentionPeriod;\n+    try {\n+      parsedRetentionPeriod = Long.parseLong(settings.getProperty(BATCH_METRICS_RETENTION_PERIOD));\n+      if (parsedRetentionPeriod <= 0 || parsedRetentionPeriod > BATCH_METRICS_RETENTION_PERIOD_LIMIT) {\n+        throw new InvalidParameterException();\n+      }\n+      batchMetricsRetentionPeriod = parsedRetentionPeriod;\n+    } catch (NumberFormatException | InvalidParameterException e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"Invalid batch-metrics-retention-period. Using default value {}.\", batchMetricsRetentionPeriod),\n+              e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM2MTYyNg=="}, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 106}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkzOTIxNzI1OnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQwMTozNDo0M1rOHAktew==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQyMDowNzoyMlrOHF0bbA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM2MzUxNQ==", "bodyText": "The new changes should not crash the system. we should handle this gracefully.\nAlso, can we add javadoc comments to public methods ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r470363515", "createdAt": "2020-08-14T01:34:43Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -84,6 +85,15 @@ public MetricsDB(long windowStartTime) throws Exception {\n     create = DSL.using(conn, SQLDialect.SQLITE);\n   }\n \n+  public static MetricsDB fetchExisting(long windowStartTime) throws Exception {\n+    String filePath = PluginSettings.instance()\n+            .getSettingValue(DB_FILE_PREFIX_PATH_CONF_NAME, DB_FILE_PREFIX_PATH_DEFAULT) + windowStartTime;\n+    if (!(new File(filePath)).exists()) {\n+      throw new FileNotFoundException(String.format(\"MetricsDB file %s could not be found.\", filePath));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTc4NTU2OQ==", "bodyText": "This change would not crash the system. The QueryBatchRequestHandler (the only place where this is used) catches it exception and handles it appropriately. Also, this code here isn't introducing any new error cases -- it has the same abstraction of throwing an error if there is any issue accessing the file or creating a jdbc connection to it as the MetricsDB constructor.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r475785569", "createdAt": "2020-08-24T17:40:23Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -84,6 +85,15 @@ public MetricsDB(long windowStartTime) throws Exception {\n     create = DSL.using(conn, SQLDialect.SQLITE);\n   }\n \n+  public static MetricsDB fetchExisting(long windowStartTime) throws Exception {\n+    String filePath = PluginSettings.instance()\n+            .getSettingValue(DB_FILE_PREFIX_PATH_CONF_NAME, DB_FILE_PREFIX_PATH_DEFAULT) + windowStartTime;\n+    if (!(new File(filePath)).exists()) {\n+      throw new FileNotFoundException(String.format(\"MetricsDB file %s could not be found.\", filePath));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM2MzUxNQ=="}, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTg2MzkxNg==", "bodyText": "Agreed about the javadocs.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r475863916", "createdAt": "2020-08-24T20:07:22Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -84,6 +85,15 @@ public MetricsDB(long windowStartTime) throws Exception {\n     create = DSL.using(conn, SQLDialect.SQLITE);\n   }\n \n+  public static MetricsDB fetchExisting(long windowStartTime) throws Exception {\n+    String filePath = PluginSettings.instance()\n+            .getSettingValue(DB_FILE_PREFIX_PATH_CONF_NAME, DB_FILE_PREFIX_PATH_DEFAULT) + windowStartTime;\n+    if (!(new File(filePath)).exists()) {\n+      throw new FileNotFoundException(String.format(\"MetricsDB file %s could not be found.\", filePath));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM2MzUxNQ=="}, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 31}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkzOTIxODc3OnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQwMTozNTozOVrOHAkuWg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQyMzoyMTo1NVrOHCp8fg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM2MzczOA==", "bodyText": "Can we return empty Object instead of null ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r470363738", "createdAt": "2020-08-14T01:35:39Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -239,6 +249,21 @@ public void putMetric(Metric<Double> metric, Dimensions dimensions, long windowS\n     return create.select().from(DSL.table(metric)).fetch();\n   }\n \n+  public Result<Record> queryMetric(String metric, Collection<String> dimensions, int limit) {\n+    if (!DBUtils.checkIfTableExists(create, metric)) {\n+      return null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjU0NjQzMA==", "bodyText": "We return a null here to stay consistent with the other queryMetric method:\npublic Result queryMetric(List metrics, List aggregations, List dimensions) throws Exception", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r472546430", "createdAt": "2020-08-18T23:21:55Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -239,6 +249,21 @@ public void putMetric(Metric<Double> metric, Dimensions dimensions, long windowS\n     return create.select().from(DSL.table(metric)).fetch();\n   }\n \n+  public Result<Record> queryMetric(String metric, Collection<String> dimensions, int limit) {\n+    if (!DBUtils.checkIfTableExists(create, metric)) {\n+      return null;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM2MzczOA=="}, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 45}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkzOTIyMDE3OnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQwMTozNjozOFrOHAkvLQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQyMzoxNToyNlrOHCp0SA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM2Mzk0OQ==", "bodyText": "This is too late to validate if the limit is negative. Maybe we should do it up in the call handling stack ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r470363949", "createdAt": "2020-08-14T01:36:38Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -239,6 +249,21 @@ public void putMetric(Metric<Double> metric, Dimensions dimensions, long windowS\n     return create.select().from(DSL.table(metric)).fetch();\n   }\n \n+  public Result<Record> queryMetric(String metric, Collection<String> dimensions, int limit) {\n+    if (!DBUtils.checkIfTableExists(create, metric)) {\n+      return null;\n+    }\n+    if (limit < 0) {\n+      throw new IllegalArgumentException(\"Limit must be non-negative\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MjU0NDMyOA==", "bodyText": "Such a check is enforced multiple times in QueryBatchRequestHandler. The check is also included here in MetricsDB since adding this function expands the API of MetricsDB, and such a check is required for the new expanded API.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r472544328", "createdAt": "2020-08-18T23:15:26Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -239,6 +249,21 @@ public void putMetric(Metric<Double> metric, Dimensions dimensions, long windowS\n     return create.select().from(DSL.table(metric)).fetch();\n   }\n \n+  public Result<Record> queryMetric(String metric, Collection<String> dimensions, int limit) {\n+    if (!DBUtils.checkIfTableExists(create, metric)) {\n+      return null;\n+    }\n+    if (limit < 0) {\n+      throw new IllegalArgumentException(\"Limit must be non-negative\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM2Mzk0OQ=="}, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 48}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjkzOTIzMTU1OnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQwMTo0NDowM1rOHAk1sw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQxODowMDowOFrOHPToFg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM2NTYxOQ==", "bodyText": "Looks like this is only being called from methods that are themselves marked as VisibleForTesting. Can we mark this as such as well ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r470365619", "createdAt": "2020-08-14T01:44:03Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -84,6 +85,15 @@ public MetricsDB(long windowStartTime) throws Exception {\n     create = DSL.using(conn, SQLDialect.SQLITE);\n   }\n \n+  public static MetricsDB fetchExisting(long windowStartTime) throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg2MjQyOQ==", "bodyText": "We only marked those other callers as \"VisibleForTesting\" because we expanded their visibility from private to public simply for the sake of testing. However, even if they were private, this method would have to have public visibility for them to be able to access it.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483862429", "createdAt": "2020-09-04T22:04:09Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -84,6 +85,15 @@ public MetricsDB(long windowStartTime) throws Exception {\n     create = DSL.using(conn, SQLDialect.SQLITE);\n   }\n \n+  public static MetricsDB fetchExisting(long windowStartTime) throws Exception {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM2NTYxOQ=="}, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA3OTIyNg==", "bodyText": "That might be misleading. That method should not be called from anywhere in the code other than tests. For your usecase, you can make that protected and then have a wrapper Test class that exposes it over a public interface for tests only ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485079226", "createdAt": "2020-09-08T17:20:48Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -84,6 +85,15 @@ public MetricsDB(long windowStartTime) throws Exception {\n     create = DSL.using(conn, SQLDialect.SQLITE);\n   }\n \n+  public static MetricsDB fetchExisting(long windowStartTime) throws Exception {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM2NTYxOQ=="}, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTgxMjI0Ng==", "bodyText": "Will address this by making the target methods private and exposing them via VisibleForTesting shims.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485812246", "createdAt": "2020-09-09T18:00:08Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -84,6 +85,15 @@ public MetricsDB(long windowStartTime) throws Exception {\n     create = DSL.using(conn, SQLDialect.SQLITE);\n   }\n \n+  public static MetricsDB fetchExisting(long windowStartTime) throws Exception {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM2NTYxOQ=="}, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 27}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2MzY3MjAxOnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQxNzozMzoyN1rOHEMSag==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMVQyMjoxMDozN1rOHLKAWw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE1NzY3NA==", "bodyText": "call getDBFilePath()", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r474157674", "createdAt": "2020-08-20T17:33:27Z", "author": {"login": "sidheart"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -84,6 +85,15 @@ public MetricsDB(long windowStartTime) throws Exception {\n     create = DSL.using(conn, SQLDialect.SQLITE);\n   }\n \n+  public static MetricsDB fetchExisting(long windowStartTime) throws Exception {\n+    String filePath = PluginSettings.instance()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTc4MTY3Mw==", "bodyText": "getDBFilePath can't be called from a static context -- it's an instance method that depends on the windowStartTime field.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r475781673", "createdAt": "2020-08-24T17:32:56Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -84,6 +85,15 @@ public MetricsDB(long windowStartTime) throws Exception {\n     create = DSL.using(conn, SQLDialect.SQLITE);\n   }\n \n+  public static MetricsDB fetchExisting(long windowStartTime) throws Exception {\n+    String filePath = PluginSettings.instance()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE1NzY3NA=="}, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQzNjA3NA==", "bodyText": "The way you have it now, the same logic is in 2 different places. Change getDBFilePath to call a function like\nstatic String getActualFilePath(long windowStartTime) {\n// PluginSettings.instance().getSettingValue(...)\n}\nhave getDBFilePath and fetchExisting call this method", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r479436074", "createdAt": "2020-08-28T17:17:32Z", "author": {"login": "sidheart"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -84,6 +85,15 @@ public MetricsDB(long windowStartTime) throws Exception {\n     create = DSL.using(conn, SQLDialect.SQLITE);\n   }\n \n+  public static MetricsDB fetchExisting(long windowStartTime) throws Exception {\n+    String filePath = PluginSettings.instance()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE1NzY3NA=="}, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQ2MDMxNQ==", "bodyText": "Sounds reasonable", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r481460315", "createdAt": "2020-09-01T22:10:37Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -84,6 +85,15 @@ public MetricsDB(long windowStartTime) throws Exception {\n     create = DSL.using(conn, SQLDialect.SQLITE);\n   }\n \n+  public static MetricsDB fetchExisting(long windowStartTime) throws Exception {\n+    String filePath = PluginSettings.instance()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE1NzY3NA=="}, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 28}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2MzY4NTA3OnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQxNzozNjo1OFrOHEMaYw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxNzoxOTo1OVrOHJOh-A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE1OTcxNQ==", "bodyText": "getDBFilePath()", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r474159715", "createdAt": "2020-08-20T17:36:58Z", "author": {"login": "sidheart"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -259,6 +284,19 @@ public void deleteOnDiskFile() {\n     }\n   }\n \n+  public static void deleteOnDiskFile(long windowStartTime) {\n+    String dbFilePath = PluginSettings.instance()\n+            .getSettingValue(DB_FILE_PREFIX_PATH_CONF_NAME, DB_FILE_PREFIX_PATH_DEFAULT) + windowStartTime;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 67}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTc4NjE1Nw==", "bodyText": "getDBFilePath can't be called from a static context -- it's an instance method that depends on the windowStartTime field.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r475786157", "createdAt": "2020-08-24T17:41:27Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -259,6 +284,19 @@ public void deleteOnDiskFile() {\n     }\n   }\n \n+  public static void deleteOnDiskFile(long windowStartTime) {\n+    String dbFilePath = PluginSettings.instance()\n+            .getSettingValue(DB_FILE_PREFIX_PATH_CONF_NAME, DB_FILE_PREFIX_PATH_DEFAULT) + windowStartTime;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE1OTcxNQ=="}, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 67}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQzNzMwNA==", "bodyText": "See above", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r479437304", "createdAt": "2020-08-28T17:19:59Z", "author": {"login": "sidheart"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -259,6 +284,19 @@ public void deleteOnDiskFile() {\n     }\n   }\n \n+  public static void deleteOnDiskFile(long windowStartTime) {\n+    String dbFilePath = PluginSettings.instance()\n+            .getSettingValue(DB_FILE_PREFIX_PATH_CONF_NAME, DB_FILE_PREFIX_PATH_DEFAULT) + windowStartTime;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE1OTcxNQ=="}, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 67}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2Mzc0NzQ0OnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQxNzo1NToxOVrOHENBTg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQxNzo1NToxOVrOHENBTg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE2OTY3OA==", "bodyText": "Just initialize batchMetricsEnabled to false instead of having 2 variables", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r474169678", "createdAt": "2020-08-20T17:55:19Z", "author": {"login": "sidheart"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -71,6 +82,11 @@\n   private final AppContext appContext;\n   private final ConfigOverridesApplier configOverridesApplier;\n \n+  public static final String BATCH_METRICS_ENABLED_CONF_FILE = \"batch_metrics_enabled.conf\";\n+  private boolean batchMetricsEnabled;\n+  private boolean defaultBatchMetricsEnabled = false;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 39}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2Mzc3NDA0OnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQxODowMjo1OFrOHENRuQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxNzo0NjoyMlrOHFv11g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE3Mzg4MQ==", "bodyText": "by lowest do you mean oldest?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r474173881", "createdAt": "2020-08-20T18:02:58Z", "author": {"login": "sidheart"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -201,8 +219,41 @@ public void trimOldSnapshots() throws Exception {\n     trimMap(shardRqMetricsMap, RQ_SNAPSHOTS);\n     trimMap(httpRqMetricsMap, HTTP_RQ_SNAPSHOTS);\n     trimMap(masterEventMetricsMap, MASTER_EVENT_SNAPSHOTS);\n-    trimDatabases(\n-        metricsDBMap, MAX_DATABASES, PluginSettings.instance().shouldCleanupMetricsDBFiles());\n+\n+    boolean deleteDBFiles = PluginSettings.instance().shouldCleanupMetricsDBFiles();\n+    if (metricsDBMap.size() > MAX_DATABASES) {\n+      Map.Entry<Long, MetricsDB> lowestEntry = metricsDBMap.pollFirstEntry();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTc4ODc1OA==", "bodyText": "Yes, will change the variable names to reflect this.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r475788758", "createdAt": "2020-08-24T17:46:22Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -201,8 +219,41 @@ public void trimOldSnapshots() throws Exception {\n     trimMap(shardRqMetricsMap, RQ_SNAPSHOTS);\n     trimMap(httpRqMetricsMap, HTTP_RQ_SNAPSHOTS);\n     trimMap(masterEventMetricsMap, MASTER_EVENT_SNAPSHOTS);\n-    trimDatabases(\n-        metricsDBMap, MAX_DATABASES, PluginSettings.instance().shouldCleanupMetricsDBFiles());\n+\n+    boolean deleteDBFiles = PluginSettings.instance().shouldCleanupMetricsDBFiles();\n+    if (metricsDBMap.size() > MAX_DATABASES) {\n+      Map.Entry<Long, MetricsDB> lowestEntry = metricsDBMap.pollFirstEntry();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE3Mzg4MQ=="}, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 63}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2MzgxNjIwOnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQxODoxNTozMFrOHENr2w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxNzo1NToxMFrOHFwJGg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE4MDU3MQ==", "bodyText": "This logic should be placed into the trimDatabases function", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r474180571", "createdAt": "2020-08-20T18:15:30Z", "author": {"login": "sidheart"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -201,8 +219,41 @@ public void trimOldSnapshots() throws Exception {\n     trimMap(shardRqMetricsMap, RQ_SNAPSHOTS);\n     trimMap(httpRqMetricsMap, HTTP_RQ_SNAPSHOTS);\n     trimMap(masterEventMetricsMap, MASTER_EVENT_SNAPSHOTS);\n-    trimDatabases(\n-        metricsDBMap, MAX_DATABASES, PluginSettings.instance().shouldCleanupMetricsDBFiles());\n+\n+    boolean deleteDBFiles = PluginSettings.instance().shouldCleanupMetricsDBFiles();\n+    if (metricsDBMap.size() > MAX_DATABASES) {\n+      Map.Entry<Long, MetricsDB> lowestEntry = metricsDBMap.pollFirstEntry();\n+      if (lowestEntry != null) {\n+        Long key = lowestEntry.getKey();\n+        MetricsDB value = lowestEntry.getValue();\n+        value.remove();\n+        if (deleteDBFiles && !batchMetricsDBSet.contains(key)) {\n+          value.deleteOnDiskFile();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTc5MzY5MA==", "bodyText": "trimDatabases currently doesn't accept a parameter that would allow us to retain the db if it is in batchMetricsDBSet. trimDatabases could be modified to include such logic. However, such a change wouldn't really contribute much, as trimDatabases is only used in timOldSnapshots. Moving it out of trimOldSnapshots would also not even help with testing, as there are two other different trimming-related procedures in trimOldSnapshots.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r475793690", "createdAt": "2020-08-24T17:55:10Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -201,8 +219,41 @@ public void trimOldSnapshots() throws Exception {\n     trimMap(shardRqMetricsMap, RQ_SNAPSHOTS);\n     trimMap(httpRqMetricsMap, HTTP_RQ_SNAPSHOTS);\n     trimMap(masterEventMetricsMap, MASTER_EVENT_SNAPSHOTS);\n-    trimDatabases(\n-        metricsDBMap, MAX_DATABASES, PluginSettings.instance().shouldCleanupMetricsDBFiles());\n+\n+    boolean deleteDBFiles = PluginSettings.instance().shouldCleanupMetricsDBFiles();\n+    if (metricsDBMap.size() > MAX_DATABASES) {\n+      Map.Entry<Long, MetricsDB> lowestEntry = metricsDBMap.pollFirstEntry();\n+      if (lowestEntry != null) {\n+        Long key = lowestEntry.getKey();\n+        MetricsDB value = lowestEntry.getValue();\n+        value.remove();\n+        if (deleteDBFiles && !batchMetricsDBSet.contains(key)) {\n+          value.deleteOnDiskFile();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE4MDU3MQ=="}, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 69}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2Mzg0MjEwOnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQxODoyMjo1OFrOHEN7qA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxODoxMjozN1rOHFwuOA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE4NDYxNg==", "bodyText": "Add a comment about why you're using 12 b/c of the 5s snapshots. Also make it evident that the retention period is in minutes", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r474184616", "createdAt": "2020-08-20T18:22:58Z", "author": {"login": "sidheart"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -696,6 +750,24 @@ public void deleteDBs() throws Exception {\n     }\n   }\n \n+  /**\n+   * This is called by operations outside of the ReaderMetricsProcessor.\n+   *\n+   * @return A list of the timestamps associated with MetricsDB files. The oldest of the MetricsDB files typically\n+   *     have a lifetime of ~SAMPLING_INTERVAL seconds (no less than SAMPLING_INTERVAL/2 seconds). Null if batch\n+   *     metrics is disabled.\n+   */\n+  public NavigableSet<Long> getBatchMetrics() {\n+    if (batchMetricsEnabled) {\n+      TreeSet<Long> batchMetricsDBSetCopy = new TreeSet<>(batchMetricsDBSet.clone());\n+      while (batchMetricsDBSetCopy.size() > PluginSettings.instance().getBatchMetricsRetentionPeriod() * 12) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 122}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTgwMzE5Mg==", "bodyText": "An understanding of the 5s snapshots should be known to the reader of this code. The connection to the 12 should be pretty readily understood.\nAgreed on the minutes unit for the retention period -- the method itself will be renamed to say \"Minutes\". This should further make the connection for the first part obvious.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r475803192", "createdAt": "2020-08-24T18:12:37Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -696,6 +750,24 @@ public void deleteDBs() throws Exception {\n     }\n   }\n \n+  /**\n+   * This is called by operations outside of the ReaderMetricsProcessor.\n+   *\n+   * @return A list of the timestamps associated with MetricsDB files. The oldest of the MetricsDB files typically\n+   *     have a lifetime of ~SAMPLING_INTERVAL seconds (no less than SAMPLING_INTERVAL/2 seconds). Null if batch\n+   *     metrics is disabled.\n+   */\n+  public NavigableSet<Long> getBatchMetrics() {\n+    if (batchMetricsEnabled) {\n+      TreeSet<Long> batchMetricsDBSetCopy = new TreeSet<>(batchMetricsDBSet.clone());\n+      while (batchMetricsDBSetCopy.size() > PluginSettings.instance().getBatchMetricsRetentionPeriod() * 12) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE4NDYxNg=="}, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 122}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2Mzg1NTM3OnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQxODoyNjo0NVrOHEOD5g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxNzo1Nzo1NVrOHFwPRQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE4NjcyNg==", "bodyText": "This should be a while loop", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r474186726", "createdAt": "2020-08-20T18:26:45Z", "author": {"login": "sidheart"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -201,8 +219,41 @@ public void trimOldSnapshots() throws Exception {\n     trimMap(shardRqMetricsMap, RQ_SNAPSHOTS);\n     trimMap(httpRqMetricsMap, HTTP_RQ_SNAPSHOTS);\n     trimMap(masterEventMetricsMap, MASTER_EVENT_SNAPSHOTS);\n-    trimDatabases(\n-        metricsDBMap, MAX_DATABASES, PluginSettings.instance().shouldCleanupMetricsDBFiles());\n+\n+    boolean deleteDBFiles = PluginSettings.instance().shouldCleanupMetricsDBFiles();\n+    if (metricsDBMap.size() > MAX_DATABASES) {\n+      Map.Entry<Long, MetricsDB> lowestEntry = metricsDBMap.pollFirstEntry();\n+      if (lowestEntry != null) {\n+        Long key = lowestEntry.getKey();\n+        MetricsDB value = lowestEntry.getValue();\n+        value.remove();\n+        if (deleteDBFiles && !batchMetricsDBSet.contains(key)) {\n+          value.deleteOnDiskFile();\n+        }\n+      }\n+    }\n+    // Flush any tracking batch metrics if batch metrics is disabled. Note, in order to ensure that batch metrics\n+    // consumers have had at least one cycle to use any metrics they may be holding, this flush is done before\n+    // re-reading the config file to update the state of the batch metrics feature.\n+    if (!batchMetricsEnabled && !batchMetricsDBSet.isEmpty()) {\n+      if (deleteDBFiles) {\n+        for (Long timestamp : batchMetricsDBSet) {\n+          if (!metricsDBMap.containsKey(timestamp)) {\n+            MetricsDB.deleteOnDiskFile(timestamp);\n+          }\n+        }\n+      }\n+      batchMetricsDBSet.clear();\n+    }\n+    readBatchMetricsEnabledFromConf();\n+    // The (retentionPeriod * 12 + 1)'th database can be safely removed, since getBatchMetrics never returns more than\n+    // the (retentionPeriod * 12) freshest metrics files.\n+    if (batchMetricsDBSet.size() > PluginSettings.instance().getBatchMetricsRetentionPeriod() * 12 + 1) {\n+      Long timestamp = batchMetricsDBSet.pollFirst();\n+      if (deleteDBFiles && !metricsDBMap.containsKey(timestamp)) {\n+        MetricsDB.deleteOnDiskFile(timestamp);\n+      }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTc5NTI2OQ==", "bodyText": "Agreed", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r475795269", "createdAt": "2020-08-24T17:57:55Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -201,8 +219,41 @@ public void trimOldSnapshots() throws Exception {\n     trimMap(shardRqMetricsMap, RQ_SNAPSHOTS);\n     trimMap(httpRqMetricsMap, HTTP_RQ_SNAPSHOTS);\n     trimMap(masterEventMetricsMap, MASTER_EVENT_SNAPSHOTS);\n-    trimDatabases(\n-        metricsDBMap, MAX_DATABASES, PluginSettings.instance().shouldCleanupMetricsDBFiles());\n+\n+    boolean deleteDBFiles = PluginSettings.instance().shouldCleanupMetricsDBFiles();\n+    if (metricsDBMap.size() > MAX_DATABASES) {\n+      Map.Entry<Long, MetricsDB> lowestEntry = metricsDBMap.pollFirstEntry();\n+      if (lowestEntry != null) {\n+        Long key = lowestEntry.getKey();\n+        MetricsDB value = lowestEntry.getValue();\n+        value.remove();\n+        if (deleteDBFiles && !batchMetricsDBSet.contains(key)) {\n+          value.deleteOnDiskFile();\n+        }\n+      }\n+    }\n+    // Flush any tracking batch metrics if batch metrics is disabled. Note, in order to ensure that batch metrics\n+    // consumers have had at least one cycle to use any metrics they may be holding, this flush is done before\n+    // re-reading the config file to update the state of the batch metrics feature.\n+    if (!batchMetricsEnabled && !batchMetricsDBSet.isEmpty()) {\n+      if (deleteDBFiles) {\n+        for (Long timestamp : batchMetricsDBSet) {\n+          if (!metricsDBMap.containsKey(timestamp)) {\n+            MetricsDB.deleteOnDiskFile(timestamp);\n+          }\n+        }\n+      }\n+      batchMetricsDBSet.clear();\n+    }\n+    readBatchMetricsEnabledFromConf();\n+    // The (retentionPeriod * 12 + 1)'th database can be safely removed, since getBatchMetrics never returns more than\n+    // the (retentionPeriod * 12) freshest metrics files.\n+    if (batchMetricsDBSet.size() > PluginSettings.instance().getBatchMetricsRetentionPeriod() * 12 + 1) {\n+      Long timestamp = batchMetricsDBSet.pollFirst();\n+      if (deleteDBFiles && !metricsDBMap.containsKey(timestamp)) {\n+        MetricsDB.deleteOnDiskFile(timestamp);\n+      }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE4NjcyNg=="}, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 93}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk2Mzg1NzMyOnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQxODoyNzoxNVrOHEOFBg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yNFQxNzo1Nzo0NFrOHFwO4w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE4NzAxNA==", "bodyText": "This should be a while loop", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r474187014", "createdAt": "2020-08-20T18:27:15Z", "author": {"login": "sidheart"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -201,8 +219,41 @@ public void trimOldSnapshots() throws Exception {\n     trimMap(shardRqMetricsMap, RQ_SNAPSHOTS);\n     trimMap(httpRqMetricsMap, HTTP_RQ_SNAPSHOTS);\n     trimMap(masterEventMetricsMap, MASTER_EVENT_SNAPSHOTS);\n-    trimDatabases(\n-        metricsDBMap, MAX_DATABASES, PluginSettings.instance().shouldCleanupMetricsDBFiles());\n+\n+    boolean deleteDBFiles = PluginSettings.instance().shouldCleanupMetricsDBFiles();\n+    if (metricsDBMap.size() > MAX_DATABASES) {\n+      Map.Entry<Long, MetricsDB> lowestEntry = metricsDBMap.pollFirstEntry();\n+      if (lowestEntry != null) {\n+        Long key = lowestEntry.getKey();\n+        MetricsDB value = lowestEntry.getValue();\n+        value.remove();\n+        if (deleteDBFiles && !batchMetricsDBSet.contains(key)) {\n+          value.deleteOnDiskFile();\n+        }\n+      }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NTc5NTE3MQ==", "bodyText": "Agreed", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r475795171", "createdAt": "2020-08-24T17:57:44Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -201,8 +219,41 @@ public void trimOldSnapshots() throws Exception {\n     trimMap(shardRqMetricsMap, RQ_SNAPSHOTS);\n     trimMap(httpRqMetricsMap, HTTP_RQ_SNAPSHOTS);\n     trimMap(masterEventMetricsMap, MASTER_EVENT_SNAPSHOTS);\n-    trimDatabases(\n-        metricsDBMap, MAX_DATABASES, PluginSettings.instance().shouldCleanupMetricsDBFiles());\n+\n+    boolean deleteDBFiles = PluginSettings.instance().shouldCleanupMetricsDBFiles();\n+    if (metricsDBMap.size() > MAX_DATABASES) {\n+      Map.Entry<Long, MetricsDB> lowestEntry = metricsDBMap.pollFirstEntry();\n+      if (lowestEntry != null) {\n+        Long key = lowestEntry.getKey();\n+        MetricsDB value = lowestEntry.getValue();\n+        value.remove();\n+        if (deleteDBFiles && !batchMetricsDBSet.contains(key)) {\n+          value.deleteOnDiskFile();\n+        }\n+      }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE4NzAxNA=="}, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 71}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5NzI0MjUwOnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandler.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxNzo1NToyNFrOHJPj_Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQwMzoxMjoyN1rOHM-BIg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ1NDIwNQ==", "bodyText": "Your documentation says we round down, but this is rounding up right? I don't care which you go with, but make it consistent.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r479454205", "createdAt": "2020-08-28T17:55:24Z", "author": {"login": "sidheart"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandler.java", "diffHunk": "@@ -0,0 +1,309 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rest;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatExceptionCode;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatsCollector;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.config.PluginSettings;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metrics.MetricsRestUtil;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.model.MetricsModel;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.net.NetClient;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ReaderMetricsProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.sun.net.httpserver.HttpExchange;\n+import com.sun.net.httpserver.HttpHandler;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.net.HttpURLConnection;\n+import java.security.InvalidParameterException;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.NavigableSet;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.logging.log4j.util.Supplier;\n+import org.jooq.Record;\n+import org.jooq.Result;\n+\n+/**\n+ * Request handler that supports querying batch metrics from an EC2 instance\n+ *\n+ * <p>Return 1 minute of CPU_Utilization metrics sampled at a 5s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization&starttime=1566413975000&endtime=1566413980000\"\n+ *\n+ * <p>Return 1 minute of CPU_Utilization and Latency metrics sampled at a 10s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization,Latency&starttime=1566413975000&endtime=1566413980000&samplingperiod=10\"\n+ *\n+ * <p>Return format:\n+ * {\n+ *   \"1594412650000\": {\n+ *     \"CPU_Utilization\": {\n+ *       \"fields\": [\n+ *         {\n+ *           \"name: \"IndexName\",\n+ *           \"type\": \"VARCHAR\"\n+ *         },\n+ *         <...>\n+ *       ]\n+ *       \"records\": [\n+ *         [\n+ *           \"pmc\",\n+ *           <...>\n+ *         ],\n+ *         <...>\n+ *       ]\n+ *     }\n+ *   }\n+ * }\n+ */\n+public class QueryBatchRequestHandler extends MetricsHandler implements HttpHandler {\n+\n+  private static final Logger LOG = LogManager.getLogger(QueryBatchRequestHandler.class);\n+\n+  private static final int TIME_OUT_VALUE = 2;\n+  private static final TimeUnit TIME_OUT_UNIT = TimeUnit.SECONDS;\n+  private NetClient netClient;\n+  MetricsRestUtil metricsRestUtil;\n+\n+  public static final int DEFAULT_MAX_DATAPOINTS = 100800;  // Must be non-negative\n+  public static final long DEFAULT_SAMPLING_PERIOD = 5000;  // Must be a multiple of 5000\n+\n+  public QueryBatchRequestHandler(NetClient netClient, MetricsRestUtil metricsRestUtil) {\n+    this.netClient = netClient;\n+    this.metricsRestUtil = metricsRestUtil;\n+  }\n+\n+  @Override\n+  public void handle(HttpExchange exchange) throws IOException {\n+    String requestMethod = exchange.getRequestMethod();\n+    if (!requestMethod.equalsIgnoreCase(\"GET\")) {\n+      exchange.sendResponseHeaders(HttpURLConnection.HTTP_NOT_FOUND, -1);\n+      exchange.close();\n+      return;\n+    }\n+\n+    ReaderMetricsProcessor mp = ReaderMetricsProcessor.getInstance();\n+    if (mp == null) {\n+      sendResponse(\n+          exchange,\n+          \"{\\\"error\\\":\\\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\\\"}\",\n+          HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    NavigableSet<Long> batchMetrics = mp.getBatchMetrics();\n+    long currentTime = System.currentTimeMillis();\n+    if (batchMetrics == null) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"The batch metrics api has not been enabled for this node.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"The batch metrics api has not been enabled for this node.\");\n+      return;\n+    }\n+    if (batchMetrics.isEmpty()) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"There are no metrics databases. The reader has run into an issue or has just started.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"There are no metrics databases. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    exchange.getResponseHeaders().set(\"Content-Type\", \"application/json\");\n+\n+    Map<String, String> params = getParamsMap(exchange.getRequestURI().getQuery());\n+\n+    try {\n+      // Parse and validate parameters\n+      String[] validParamsTmp = {\"\", \"metrics\", \"starttime\", \"endtime\", \"samplingperiod\", \"maxdatapoints\"};\n+      Set<String> validParams = new HashSet<>(Arrays.asList(validParamsTmp));\n+      for (String param : params.keySet()) {\n+        if (!validParams.contains(param)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid parameter\", param));\n+        }\n+      }\n+\n+      List<String> metrics = metricsRestUtil.parseArrayParam(params, \"metrics\", false);\n+      String startTimeParam = params.get(\"starttime\");\n+      String endTimeParam = params.get(\"endtime\");\n+      String samplingPeriodParam = params.get(\"samplingperiod\");\n+\n+      for (String metric : metrics) {\n+        if (!MetricsModel.ALL_METRICS.containsKey(metric)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid metric\", metric));\n+        }\n+      }\n+\n+      if (startTimeParam == null || startTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"starttime parameter must be set\");\n+      }\n+      long startTime;\n+      try {\n+        startTime = Long.parseUnsignedLong(startTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid starttime\", startTimeParam));\n+      }\n+\n+      if (endTimeParam == null || endTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"endtime parameter must be set\");\n+      }\n+      long endTime;\n+      try {\n+        endTime = Long.parseUnsignedLong(endTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid endtime\", endTimeParam));\n+      }\n+\n+      long samplingPeriod = DEFAULT_SAMPLING_PERIOD;\n+      if (samplingPeriodParam != null && !samplingPeriodParam.isEmpty()) {\n+        samplingPeriod = Long.parseLong(samplingPeriodParam);\n+        if (samplingPeriod < 5 || samplingPeriod % 5 != 0) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid sampling period\", samplingPeriodParam));\n+        }\n+        if (samplingPeriod >= PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60) {\n+          throw new InvalidParameterException(\"sampling period must be less than the retention period\");\n+        }\n+        samplingPeriod *= 1000;\n+      }\n+\n+      if (startTime >= endTime) {\n+        throw new InvalidParameterException(\"starttime must be less than the endtime\");\n+      }\n+      startTime -= startTime % samplingPeriod;\n+      endTime -= endTime % samplingPeriod;\n+      if (startTime == endTime) {\n+        throw new InvalidParameterException(\"starttime and endtime cannot be equal when rounded down to the nearest sampling period\");\n+      }\n+      if (endTime > currentTime) {\n+        throw new InvalidParameterException(\"endtime can be no greater than the system time at the node\");\n+      }\n+      if (startTime < currentTime - PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60 * 1000) {\n+        throw new InvalidParameterException(\"starttime must be within the retention period\");\n+      }\n+\n+      String queryResponse = queryFromBatchMetrics(batchMetrics, metrics, startTime, endTime, samplingPeriod,\n+              DEFAULT_MAX_DATAPOINTS);\n+      sendResponse(exchange, queryResponse, HttpURLConnection.HTTP_OK);\n+    } catch (InvalidParameterException e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.getMessage() + \".\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_BAD_REQUEST);\n+    } catch (Exception e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.toString() + \"\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_INTERNAL_ERROR);\n+    }\n+  }\n+\n+  @VisibleForTesting\n+  public int appendMetrics(Long timestamp, List<String> metrics, StringBuilder builder, int maxDatapoints) throws Exception {\n+    maxDatapoints += 1;\n+    builder.append(\"\\\"\");\n+    builder.append(timestamp);\n+    builder.append(\"\\\":{\");\n+    MetricsDB db = MetricsDB.fetchExisting(timestamp);\n+    for (int metricIndex = 0, numMetrics = metrics.size(); metricIndex < numMetrics; metricIndex++) {\n+      String metric = metrics.get(metricIndex);\n+      Result<Record> results = db.queryMetric(metric, MetricsModel.ALL_METRICS.get(metric).dimensionNames, maxDatapoints);\n+      if (results != null) {\n+        maxDatapoints -= results.size();\n+        if (maxDatapoints == 0) {\n+          throw new InvalidParameterException(String.format(\"requested data exceeds the %d datapoints limit\", DEFAULT_MAX_DATAPOINTS));\n+        }\n+        builder.append(\"\\\"\");\n+        builder.append(metric);\n+        builder.append(\"\\\":\");\n+        builder.append(results.formatJSON());\n+        for (metricIndex += 1; metricIndex < numMetrics; metricIndex++) {\n+          metric = metrics.get(metricIndex);\n+          results = db.queryMetric(metric, MetricsModel.ALL_METRICS.get(metric).dimensionNames, maxDatapoints);\n+          if (results != null) {\n+            maxDatapoints -= results.size();\n+            if (maxDatapoints == 0) {\n+              throw new InvalidParameterException(String.format(\"requested data exceeds the %d datapoints limit\", DEFAULT_MAX_DATAPOINTS));\n+            }\n+            builder.append(\",\\\"\");\n+            builder.append(metric);\n+            builder.append(\"\\\":\");\n+            builder.append(results.formatJSON());\n+          }\n+        }\n+      }\n+    }\n+    builder.append(\"}\");\n+    db.remove();\n+    return maxDatapoints - 1;\n+  }\n+\n+  /**\n+   * Requires non-empty batchMetrics, valid non-empty metrics, valid startTime, valid endTime,\n+   * valid samplingPeriod (in milliseconds), and non-negative maxDatapoints.\n+   */\n+  @VisibleForTesting\n+  public String queryFromBatchMetrics(NavigableSet<Long> batchMetrics, List<String> metrics, long startTime,\n+                                      long endTime, long samplingPeriod, int maxDatapoints) throws Exception {\n+    StringBuilder responseJson = new StringBuilder();\n+    responseJson.append(\"{\");\n+    Long metricsTimestamp = batchMetrics.ceiling(startTime);\n+    if (metricsTimestamp != null && metricsTimestamp < endTime) {\n+      maxDatapoints = appendMetrics(metricsTimestamp, metrics, responseJson, maxDatapoints);\n+      metricsTimestamp = metricsTimestamp - metricsTimestamp % samplingPeriod + samplingPeriod;\n+      metricsTimestamp = batchMetrics.ceiling(metricsTimestamp);\n+      while (metricsTimestamp != null && metricsTimestamp < endTime) {\n+        responseJson.append(\",\");\n+        maxDatapoints = appendMetrics(metricsTimestamp, metrics, responseJson, maxDatapoints);\n+        metricsTimestamp = metricsTimestamp - metricsTimestamp % samplingPeriod + samplingPeriod;\n+        metricsTimestamp = batchMetrics.ceiling(metricsTimestamp);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2f856bf687d4749dc4d3ebec026aa0a6b06c2ef"}, "originalPosition": 293}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQ2OTE1OA==", "bodyText": "This is round down.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r481469158", "createdAt": "2020-09-01T22:33:53Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandler.java", "diffHunk": "@@ -0,0 +1,309 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rest;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatExceptionCode;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatsCollector;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.config.PluginSettings;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metrics.MetricsRestUtil;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.model.MetricsModel;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.net.NetClient;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ReaderMetricsProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.sun.net.httpserver.HttpExchange;\n+import com.sun.net.httpserver.HttpHandler;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.net.HttpURLConnection;\n+import java.security.InvalidParameterException;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.NavigableSet;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.logging.log4j.util.Supplier;\n+import org.jooq.Record;\n+import org.jooq.Result;\n+\n+/**\n+ * Request handler that supports querying batch metrics from an EC2 instance\n+ *\n+ * <p>Return 1 minute of CPU_Utilization metrics sampled at a 5s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization&starttime=1566413975000&endtime=1566413980000\"\n+ *\n+ * <p>Return 1 minute of CPU_Utilization and Latency metrics sampled at a 10s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization,Latency&starttime=1566413975000&endtime=1566413980000&samplingperiod=10\"\n+ *\n+ * <p>Return format:\n+ * {\n+ *   \"1594412650000\": {\n+ *     \"CPU_Utilization\": {\n+ *       \"fields\": [\n+ *         {\n+ *           \"name: \"IndexName\",\n+ *           \"type\": \"VARCHAR\"\n+ *         },\n+ *         <...>\n+ *       ]\n+ *       \"records\": [\n+ *         [\n+ *           \"pmc\",\n+ *           <...>\n+ *         ],\n+ *         <...>\n+ *       ]\n+ *     }\n+ *   }\n+ * }\n+ */\n+public class QueryBatchRequestHandler extends MetricsHandler implements HttpHandler {\n+\n+  private static final Logger LOG = LogManager.getLogger(QueryBatchRequestHandler.class);\n+\n+  private static final int TIME_OUT_VALUE = 2;\n+  private static final TimeUnit TIME_OUT_UNIT = TimeUnit.SECONDS;\n+  private NetClient netClient;\n+  MetricsRestUtil metricsRestUtil;\n+\n+  public static final int DEFAULT_MAX_DATAPOINTS = 100800;  // Must be non-negative\n+  public static final long DEFAULT_SAMPLING_PERIOD = 5000;  // Must be a multiple of 5000\n+\n+  public QueryBatchRequestHandler(NetClient netClient, MetricsRestUtil metricsRestUtil) {\n+    this.netClient = netClient;\n+    this.metricsRestUtil = metricsRestUtil;\n+  }\n+\n+  @Override\n+  public void handle(HttpExchange exchange) throws IOException {\n+    String requestMethod = exchange.getRequestMethod();\n+    if (!requestMethod.equalsIgnoreCase(\"GET\")) {\n+      exchange.sendResponseHeaders(HttpURLConnection.HTTP_NOT_FOUND, -1);\n+      exchange.close();\n+      return;\n+    }\n+\n+    ReaderMetricsProcessor mp = ReaderMetricsProcessor.getInstance();\n+    if (mp == null) {\n+      sendResponse(\n+          exchange,\n+          \"{\\\"error\\\":\\\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\\\"}\",\n+          HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    NavigableSet<Long> batchMetrics = mp.getBatchMetrics();\n+    long currentTime = System.currentTimeMillis();\n+    if (batchMetrics == null) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"The batch metrics api has not been enabled for this node.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"The batch metrics api has not been enabled for this node.\");\n+      return;\n+    }\n+    if (batchMetrics.isEmpty()) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"There are no metrics databases. The reader has run into an issue or has just started.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"There are no metrics databases. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    exchange.getResponseHeaders().set(\"Content-Type\", \"application/json\");\n+\n+    Map<String, String> params = getParamsMap(exchange.getRequestURI().getQuery());\n+\n+    try {\n+      // Parse and validate parameters\n+      String[] validParamsTmp = {\"\", \"metrics\", \"starttime\", \"endtime\", \"samplingperiod\", \"maxdatapoints\"};\n+      Set<String> validParams = new HashSet<>(Arrays.asList(validParamsTmp));\n+      for (String param : params.keySet()) {\n+        if (!validParams.contains(param)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid parameter\", param));\n+        }\n+      }\n+\n+      List<String> metrics = metricsRestUtil.parseArrayParam(params, \"metrics\", false);\n+      String startTimeParam = params.get(\"starttime\");\n+      String endTimeParam = params.get(\"endtime\");\n+      String samplingPeriodParam = params.get(\"samplingperiod\");\n+\n+      for (String metric : metrics) {\n+        if (!MetricsModel.ALL_METRICS.containsKey(metric)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid metric\", metric));\n+        }\n+      }\n+\n+      if (startTimeParam == null || startTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"starttime parameter must be set\");\n+      }\n+      long startTime;\n+      try {\n+        startTime = Long.parseUnsignedLong(startTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid starttime\", startTimeParam));\n+      }\n+\n+      if (endTimeParam == null || endTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"endtime parameter must be set\");\n+      }\n+      long endTime;\n+      try {\n+        endTime = Long.parseUnsignedLong(endTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid endtime\", endTimeParam));\n+      }\n+\n+      long samplingPeriod = DEFAULT_SAMPLING_PERIOD;\n+      if (samplingPeriodParam != null && !samplingPeriodParam.isEmpty()) {\n+        samplingPeriod = Long.parseLong(samplingPeriodParam);\n+        if (samplingPeriod < 5 || samplingPeriod % 5 != 0) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid sampling period\", samplingPeriodParam));\n+        }\n+        if (samplingPeriod >= PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60) {\n+          throw new InvalidParameterException(\"sampling period must be less than the retention period\");\n+        }\n+        samplingPeriod *= 1000;\n+      }\n+\n+      if (startTime >= endTime) {\n+        throw new InvalidParameterException(\"starttime must be less than the endtime\");\n+      }\n+      startTime -= startTime % samplingPeriod;\n+      endTime -= endTime % samplingPeriod;\n+      if (startTime == endTime) {\n+        throw new InvalidParameterException(\"starttime and endtime cannot be equal when rounded down to the nearest sampling period\");\n+      }\n+      if (endTime > currentTime) {\n+        throw new InvalidParameterException(\"endtime can be no greater than the system time at the node\");\n+      }\n+      if (startTime < currentTime - PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60 * 1000) {\n+        throw new InvalidParameterException(\"starttime must be within the retention period\");\n+      }\n+\n+      String queryResponse = queryFromBatchMetrics(batchMetrics, metrics, startTime, endTime, samplingPeriod,\n+              DEFAULT_MAX_DATAPOINTS);\n+      sendResponse(exchange, queryResponse, HttpURLConnection.HTTP_OK);\n+    } catch (InvalidParameterException e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.getMessage() + \".\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_BAD_REQUEST);\n+    } catch (Exception e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.toString() + \"\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_INTERNAL_ERROR);\n+    }\n+  }\n+\n+  @VisibleForTesting\n+  public int appendMetrics(Long timestamp, List<String> metrics, StringBuilder builder, int maxDatapoints) throws Exception {\n+    maxDatapoints += 1;\n+    builder.append(\"\\\"\");\n+    builder.append(timestamp);\n+    builder.append(\"\\\":{\");\n+    MetricsDB db = MetricsDB.fetchExisting(timestamp);\n+    for (int metricIndex = 0, numMetrics = metrics.size(); metricIndex < numMetrics; metricIndex++) {\n+      String metric = metrics.get(metricIndex);\n+      Result<Record> results = db.queryMetric(metric, MetricsModel.ALL_METRICS.get(metric).dimensionNames, maxDatapoints);\n+      if (results != null) {\n+        maxDatapoints -= results.size();\n+        if (maxDatapoints == 0) {\n+          throw new InvalidParameterException(String.format(\"requested data exceeds the %d datapoints limit\", DEFAULT_MAX_DATAPOINTS));\n+        }\n+        builder.append(\"\\\"\");\n+        builder.append(metric);\n+        builder.append(\"\\\":\");\n+        builder.append(results.formatJSON());\n+        for (metricIndex += 1; metricIndex < numMetrics; metricIndex++) {\n+          metric = metrics.get(metricIndex);\n+          results = db.queryMetric(metric, MetricsModel.ALL_METRICS.get(metric).dimensionNames, maxDatapoints);\n+          if (results != null) {\n+            maxDatapoints -= results.size();\n+            if (maxDatapoints == 0) {\n+              throw new InvalidParameterException(String.format(\"requested data exceeds the %d datapoints limit\", DEFAULT_MAX_DATAPOINTS));\n+            }\n+            builder.append(\",\\\"\");\n+            builder.append(metric);\n+            builder.append(\"\\\":\");\n+            builder.append(results.formatJSON());\n+          }\n+        }\n+      }\n+    }\n+    builder.append(\"}\");\n+    db.remove();\n+    return maxDatapoints - 1;\n+  }\n+\n+  /**\n+   * Requires non-empty batchMetrics, valid non-empty metrics, valid startTime, valid endTime,\n+   * valid samplingPeriod (in milliseconds), and non-negative maxDatapoints.\n+   */\n+  @VisibleForTesting\n+  public String queryFromBatchMetrics(NavigableSet<Long> batchMetrics, List<String> metrics, long startTime,\n+                                      long endTime, long samplingPeriod, int maxDatapoints) throws Exception {\n+    StringBuilder responseJson = new StringBuilder();\n+    responseJson.append(\"{\");\n+    Long metricsTimestamp = batchMetrics.ceiling(startTime);\n+    if (metricsTimestamp != null && metricsTimestamp < endTime) {\n+      maxDatapoints = appendMetrics(metricsTimestamp, metrics, responseJson, maxDatapoints);\n+      metricsTimestamp = metricsTimestamp - metricsTimestamp % samplingPeriod + samplingPeriod;\n+      metricsTimestamp = batchMetrics.ceiling(metricsTimestamp);\n+      while (metricsTimestamp != null && metricsTimestamp < endTime) {\n+        responseJson.append(\",\");\n+        maxDatapoints = appendMetrics(metricsTimestamp, metrics, responseJson, maxDatapoints);\n+        metricsTimestamp = metricsTimestamp - metricsTimestamp % samplingPeriod + samplingPeriod;\n+        metricsTimestamp = batchMetrics.ceiling(metricsTimestamp);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ1NDIwNQ=="}, "originalCommit": {"oid": "e2f856bf687d4749dc4d3ebec026aa0a6b06c2ef"}, "originalPosition": 293}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTUyODI5OA==", "bodyText": "If metricsTimestamp is 1 with a samplingPeriod of 5 then the new metricsTimestamp becomes 5 and you return all metrics with a timestamp bigger than 5. How is that rounding down? Is this what you intended?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r481528298", "createdAt": "2020-09-02T01:29:43Z", "author": {"login": "sidheart"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandler.java", "diffHunk": "@@ -0,0 +1,309 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rest;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatExceptionCode;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatsCollector;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.config.PluginSettings;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metrics.MetricsRestUtil;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.model.MetricsModel;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.net.NetClient;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ReaderMetricsProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.sun.net.httpserver.HttpExchange;\n+import com.sun.net.httpserver.HttpHandler;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.net.HttpURLConnection;\n+import java.security.InvalidParameterException;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.NavigableSet;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.logging.log4j.util.Supplier;\n+import org.jooq.Record;\n+import org.jooq.Result;\n+\n+/**\n+ * Request handler that supports querying batch metrics from an EC2 instance\n+ *\n+ * <p>Return 1 minute of CPU_Utilization metrics sampled at a 5s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization&starttime=1566413975000&endtime=1566413980000\"\n+ *\n+ * <p>Return 1 minute of CPU_Utilization and Latency metrics sampled at a 10s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization,Latency&starttime=1566413975000&endtime=1566413980000&samplingperiod=10\"\n+ *\n+ * <p>Return format:\n+ * {\n+ *   \"1594412650000\": {\n+ *     \"CPU_Utilization\": {\n+ *       \"fields\": [\n+ *         {\n+ *           \"name: \"IndexName\",\n+ *           \"type\": \"VARCHAR\"\n+ *         },\n+ *         <...>\n+ *       ]\n+ *       \"records\": [\n+ *         [\n+ *           \"pmc\",\n+ *           <...>\n+ *         ],\n+ *         <...>\n+ *       ]\n+ *     }\n+ *   }\n+ * }\n+ */\n+public class QueryBatchRequestHandler extends MetricsHandler implements HttpHandler {\n+\n+  private static final Logger LOG = LogManager.getLogger(QueryBatchRequestHandler.class);\n+\n+  private static final int TIME_OUT_VALUE = 2;\n+  private static final TimeUnit TIME_OUT_UNIT = TimeUnit.SECONDS;\n+  private NetClient netClient;\n+  MetricsRestUtil metricsRestUtil;\n+\n+  public static final int DEFAULT_MAX_DATAPOINTS = 100800;  // Must be non-negative\n+  public static final long DEFAULT_SAMPLING_PERIOD = 5000;  // Must be a multiple of 5000\n+\n+  public QueryBatchRequestHandler(NetClient netClient, MetricsRestUtil metricsRestUtil) {\n+    this.netClient = netClient;\n+    this.metricsRestUtil = metricsRestUtil;\n+  }\n+\n+  @Override\n+  public void handle(HttpExchange exchange) throws IOException {\n+    String requestMethod = exchange.getRequestMethod();\n+    if (!requestMethod.equalsIgnoreCase(\"GET\")) {\n+      exchange.sendResponseHeaders(HttpURLConnection.HTTP_NOT_FOUND, -1);\n+      exchange.close();\n+      return;\n+    }\n+\n+    ReaderMetricsProcessor mp = ReaderMetricsProcessor.getInstance();\n+    if (mp == null) {\n+      sendResponse(\n+          exchange,\n+          \"{\\\"error\\\":\\\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\\\"}\",\n+          HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    NavigableSet<Long> batchMetrics = mp.getBatchMetrics();\n+    long currentTime = System.currentTimeMillis();\n+    if (batchMetrics == null) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"The batch metrics api has not been enabled for this node.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"The batch metrics api has not been enabled for this node.\");\n+      return;\n+    }\n+    if (batchMetrics.isEmpty()) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"There are no metrics databases. The reader has run into an issue or has just started.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"There are no metrics databases. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    exchange.getResponseHeaders().set(\"Content-Type\", \"application/json\");\n+\n+    Map<String, String> params = getParamsMap(exchange.getRequestURI().getQuery());\n+\n+    try {\n+      // Parse and validate parameters\n+      String[] validParamsTmp = {\"\", \"metrics\", \"starttime\", \"endtime\", \"samplingperiod\", \"maxdatapoints\"};\n+      Set<String> validParams = new HashSet<>(Arrays.asList(validParamsTmp));\n+      for (String param : params.keySet()) {\n+        if (!validParams.contains(param)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid parameter\", param));\n+        }\n+      }\n+\n+      List<String> metrics = metricsRestUtil.parseArrayParam(params, \"metrics\", false);\n+      String startTimeParam = params.get(\"starttime\");\n+      String endTimeParam = params.get(\"endtime\");\n+      String samplingPeriodParam = params.get(\"samplingperiod\");\n+\n+      for (String metric : metrics) {\n+        if (!MetricsModel.ALL_METRICS.containsKey(metric)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid metric\", metric));\n+        }\n+      }\n+\n+      if (startTimeParam == null || startTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"starttime parameter must be set\");\n+      }\n+      long startTime;\n+      try {\n+        startTime = Long.parseUnsignedLong(startTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid starttime\", startTimeParam));\n+      }\n+\n+      if (endTimeParam == null || endTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"endtime parameter must be set\");\n+      }\n+      long endTime;\n+      try {\n+        endTime = Long.parseUnsignedLong(endTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid endtime\", endTimeParam));\n+      }\n+\n+      long samplingPeriod = DEFAULT_SAMPLING_PERIOD;\n+      if (samplingPeriodParam != null && !samplingPeriodParam.isEmpty()) {\n+        samplingPeriod = Long.parseLong(samplingPeriodParam);\n+        if (samplingPeriod < 5 || samplingPeriod % 5 != 0) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid sampling period\", samplingPeriodParam));\n+        }\n+        if (samplingPeriod >= PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60) {\n+          throw new InvalidParameterException(\"sampling period must be less than the retention period\");\n+        }\n+        samplingPeriod *= 1000;\n+      }\n+\n+      if (startTime >= endTime) {\n+        throw new InvalidParameterException(\"starttime must be less than the endtime\");\n+      }\n+      startTime -= startTime % samplingPeriod;\n+      endTime -= endTime % samplingPeriod;\n+      if (startTime == endTime) {\n+        throw new InvalidParameterException(\"starttime and endtime cannot be equal when rounded down to the nearest sampling period\");\n+      }\n+      if (endTime > currentTime) {\n+        throw new InvalidParameterException(\"endtime can be no greater than the system time at the node\");\n+      }\n+      if (startTime < currentTime - PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60 * 1000) {\n+        throw new InvalidParameterException(\"starttime must be within the retention period\");\n+      }\n+\n+      String queryResponse = queryFromBatchMetrics(batchMetrics, metrics, startTime, endTime, samplingPeriod,\n+              DEFAULT_MAX_DATAPOINTS);\n+      sendResponse(exchange, queryResponse, HttpURLConnection.HTTP_OK);\n+    } catch (InvalidParameterException e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.getMessage() + \".\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_BAD_REQUEST);\n+    } catch (Exception e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.toString() + \"\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_INTERNAL_ERROR);\n+    }\n+  }\n+\n+  @VisibleForTesting\n+  public int appendMetrics(Long timestamp, List<String> metrics, StringBuilder builder, int maxDatapoints) throws Exception {\n+    maxDatapoints += 1;\n+    builder.append(\"\\\"\");\n+    builder.append(timestamp);\n+    builder.append(\"\\\":{\");\n+    MetricsDB db = MetricsDB.fetchExisting(timestamp);\n+    for (int metricIndex = 0, numMetrics = metrics.size(); metricIndex < numMetrics; metricIndex++) {\n+      String metric = metrics.get(metricIndex);\n+      Result<Record> results = db.queryMetric(metric, MetricsModel.ALL_METRICS.get(metric).dimensionNames, maxDatapoints);\n+      if (results != null) {\n+        maxDatapoints -= results.size();\n+        if (maxDatapoints == 0) {\n+          throw new InvalidParameterException(String.format(\"requested data exceeds the %d datapoints limit\", DEFAULT_MAX_DATAPOINTS));\n+        }\n+        builder.append(\"\\\"\");\n+        builder.append(metric);\n+        builder.append(\"\\\":\");\n+        builder.append(results.formatJSON());\n+        for (metricIndex += 1; metricIndex < numMetrics; metricIndex++) {\n+          metric = metrics.get(metricIndex);\n+          results = db.queryMetric(metric, MetricsModel.ALL_METRICS.get(metric).dimensionNames, maxDatapoints);\n+          if (results != null) {\n+            maxDatapoints -= results.size();\n+            if (maxDatapoints == 0) {\n+              throw new InvalidParameterException(String.format(\"requested data exceeds the %d datapoints limit\", DEFAULT_MAX_DATAPOINTS));\n+            }\n+            builder.append(\",\\\"\");\n+            builder.append(metric);\n+            builder.append(\"\\\":\");\n+            builder.append(results.formatJSON());\n+          }\n+        }\n+      }\n+    }\n+    builder.append(\"}\");\n+    db.remove();\n+    return maxDatapoints - 1;\n+  }\n+\n+  /**\n+   * Requires non-empty batchMetrics, valid non-empty metrics, valid startTime, valid endTime,\n+   * valid samplingPeriod (in milliseconds), and non-negative maxDatapoints.\n+   */\n+  @VisibleForTesting\n+  public String queryFromBatchMetrics(NavigableSet<Long> batchMetrics, List<String> metrics, long startTime,\n+                                      long endTime, long samplingPeriod, int maxDatapoints) throws Exception {\n+    StringBuilder responseJson = new StringBuilder();\n+    responseJson.append(\"{\");\n+    Long metricsTimestamp = batchMetrics.ceiling(startTime);\n+    if (metricsTimestamp != null && metricsTimestamp < endTime) {\n+      maxDatapoints = appendMetrics(metricsTimestamp, metrics, responseJson, maxDatapoints);\n+      metricsTimestamp = metricsTimestamp - metricsTimestamp % samplingPeriod + samplingPeriod;\n+      metricsTimestamp = batchMetrics.ceiling(metricsTimestamp);\n+      while (metricsTimestamp != null && metricsTimestamp < endTime) {\n+        responseJson.append(\",\");\n+        maxDatapoints = appendMetrics(metricsTimestamp, metrics, responseJson, maxDatapoints);\n+        metricsTimestamp = metricsTimestamp - metricsTimestamp % samplingPeriod + samplingPeriod;\n+        metricsTimestamp = batchMetrics.ceiling(metricsTimestamp);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ1NDIwNQ=="}, "originalCommit": {"oid": "e2f856bf687d4749dc4d3ebec026aa0a6b06c2ef"}, "originalPosition": 293}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzM2MTA1OA==", "bodyText": "The starttime and enddtime's supplied by the user are rounded down in line 193-194. The code here is for when you're calculating all the timestamps you want to collect data from.\nThis is what the code here does:\n\nmetricsTimestamp = 0, samplingperiod = 30\nLine 292 -> metricsTimestamp = 30\nLine 293 -> metricsTimestamp = 65 (imagine the data between 30-60 is missing).\nNext cycle\nLine 292 -> metricsTimestamp = 90\n...", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483361058", "createdAt": "2020-09-04T03:12:27Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandler.java", "diffHunk": "@@ -0,0 +1,309 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rest;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatExceptionCode;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatsCollector;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.config.PluginSettings;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metrics.MetricsRestUtil;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.model.MetricsModel;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.net.NetClient;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ReaderMetricsProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.sun.net.httpserver.HttpExchange;\n+import com.sun.net.httpserver.HttpHandler;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.net.HttpURLConnection;\n+import java.security.InvalidParameterException;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.NavigableSet;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.logging.log4j.util.Supplier;\n+import org.jooq.Record;\n+import org.jooq.Result;\n+\n+/**\n+ * Request handler that supports querying batch metrics from an EC2 instance\n+ *\n+ * <p>Return 1 minute of CPU_Utilization metrics sampled at a 5s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization&starttime=1566413975000&endtime=1566413980000\"\n+ *\n+ * <p>Return 1 minute of CPU_Utilization and Latency metrics sampled at a 10s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization,Latency&starttime=1566413975000&endtime=1566413980000&samplingperiod=10\"\n+ *\n+ * <p>Return format:\n+ * {\n+ *   \"1594412650000\": {\n+ *     \"CPU_Utilization\": {\n+ *       \"fields\": [\n+ *         {\n+ *           \"name: \"IndexName\",\n+ *           \"type\": \"VARCHAR\"\n+ *         },\n+ *         <...>\n+ *       ]\n+ *       \"records\": [\n+ *         [\n+ *           \"pmc\",\n+ *           <...>\n+ *         ],\n+ *         <...>\n+ *       ]\n+ *     }\n+ *   }\n+ * }\n+ */\n+public class QueryBatchRequestHandler extends MetricsHandler implements HttpHandler {\n+\n+  private static final Logger LOG = LogManager.getLogger(QueryBatchRequestHandler.class);\n+\n+  private static final int TIME_OUT_VALUE = 2;\n+  private static final TimeUnit TIME_OUT_UNIT = TimeUnit.SECONDS;\n+  private NetClient netClient;\n+  MetricsRestUtil metricsRestUtil;\n+\n+  public static final int DEFAULT_MAX_DATAPOINTS = 100800;  // Must be non-negative\n+  public static final long DEFAULT_SAMPLING_PERIOD = 5000;  // Must be a multiple of 5000\n+\n+  public QueryBatchRequestHandler(NetClient netClient, MetricsRestUtil metricsRestUtil) {\n+    this.netClient = netClient;\n+    this.metricsRestUtil = metricsRestUtil;\n+  }\n+\n+  @Override\n+  public void handle(HttpExchange exchange) throws IOException {\n+    String requestMethod = exchange.getRequestMethod();\n+    if (!requestMethod.equalsIgnoreCase(\"GET\")) {\n+      exchange.sendResponseHeaders(HttpURLConnection.HTTP_NOT_FOUND, -1);\n+      exchange.close();\n+      return;\n+    }\n+\n+    ReaderMetricsProcessor mp = ReaderMetricsProcessor.getInstance();\n+    if (mp == null) {\n+      sendResponse(\n+          exchange,\n+          \"{\\\"error\\\":\\\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\\\"}\",\n+          HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    NavigableSet<Long> batchMetrics = mp.getBatchMetrics();\n+    long currentTime = System.currentTimeMillis();\n+    if (batchMetrics == null) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"The batch metrics api has not been enabled for this node.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"The batch metrics api has not been enabled for this node.\");\n+      return;\n+    }\n+    if (batchMetrics.isEmpty()) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"There are no metrics databases. The reader has run into an issue or has just started.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"There are no metrics databases. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    exchange.getResponseHeaders().set(\"Content-Type\", \"application/json\");\n+\n+    Map<String, String> params = getParamsMap(exchange.getRequestURI().getQuery());\n+\n+    try {\n+      // Parse and validate parameters\n+      String[] validParamsTmp = {\"\", \"metrics\", \"starttime\", \"endtime\", \"samplingperiod\", \"maxdatapoints\"};\n+      Set<String> validParams = new HashSet<>(Arrays.asList(validParamsTmp));\n+      for (String param : params.keySet()) {\n+        if (!validParams.contains(param)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid parameter\", param));\n+        }\n+      }\n+\n+      List<String> metrics = metricsRestUtil.parseArrayParam(params, \"metrics\", false);\n+      String startTimeParam = params.get(\"starttime\");\n+      String endTimeParam = params.get(\"endtime\");\n+      String samplingPeriodParam = params.get(\"samplingperiod\");\n+\n+      for (String metric : metrics) {\n+        if (!MetricsModel.ALL_METRICS.containsKey(metric)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid metric\", metric));\n+        }\n+      }\n+\n+      if (startTimeParam == null || startTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"starttime parameter must be set\");\n+      }\n+      long startTime;\n+      try {\n+        startTime = Long.parseUnsignedLong(startTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid starttime\", startTimeParam));\n+      }\n+\n+      if (endTimeParam == null || endTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"endtime parameter must be set\");\n+      }\n+      long endTime;\n+      try {\n+        endTime = Long.parseUnsignedLong(endTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid endtime\", endTimeParam));\n+      }\n+\n+      long samplingPeriod = DEFAULT_SAMPLING_PERIOD;\n+      if (samplingPeriodParam != null && !samplingPeriodParam.isEmpty()) {\n+        samplingPeriod = Long.parseLong(samplingPeriodParam);\n+        if (samplingPeriod < 5 || samplingPeriod % 5 != 0) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid sampling period\", samplingPeriodParam));\n+        }\n+        if (samplingPeriod >= PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60) {\n+          throw new InvalidParameterException(\"sampling period must be less than the retention period\");\n+        }\n+        samplingPeriod *= 1000;\n+      }\n+\n+      if (startTime >= endTime) {\n+        throw new InvalidParameterException(\"starttime must be less than the endtime\");\n+      }\n+      startTime -= startTime % samplingPeriod;\n+      endTime -= endTime % samplingPeriod;\n+      if (startTime == endTime) {\n+        throw new InvalidParameterException(\"starttime and endtime cannot be equal when rounded down to the nearest sampling period\");\n+      }\n+      if (endTime > currentTime) {\n+        throw new InvalidParameterException(\"endtime can be no greater than the system time at the node\");\n+      }\n+      if (startTime < currentTime - PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60 * 1000) {\n+        throw new InvalidParameterException(\"starttime must be within the retention period\");\n+      }\n+\n+      String queryResponse = queryFromBatchMetrics(batchMetrics, metrics, startTime, endTime, samplingPeriod,\n+              DEFAULT_MAX_DATAPOINTS);\n+      sendResponse(exchange, queryResponse, HttpURLConnection.HTTP_OK);\n+    } catch (InvalidParameterException e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.getMessage() + \".\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_BAD_REQUEST);\n+    } catch (Exception e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.toString() + \"\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_INTERNAL_ERROR);\n+    }\n+  }\n+\n+  @VisibleForTesting\n+  public int appendMetrics(Long timestamp, List<String> metrics, StringBuilder builder, int maxDatapoints) throws Exception {\n+    maxDatapoints += 1;\n+    builder.append(\"\\\"\");\n+    builder.append(timestamp);\n+    builder.append(\"\\\":{\");\n+    MetricsDB db = MetricsDB.fetchExisting(timestamp);\n+    for (int metricIndex = 0, numMetrics = metrics.size(); metricIndex < numMetrics; metricIndex++) {\n+      String metric = metrics.get(metricIndex);\n+      Result<Record> results = db.queryMetric(metric, MetricsModel.ALL_METRICS.get(metric).dimensionNames, maxDatapoints);\n+      if (results != null) {\n+        maxDatapoints -= results.size();\n+        if (maxDatapoints == 0) {\n+          throw new InvalidParameterException(String.format(\"requested data exceeds the %d datapoints limit\", DEFAULT_MAX_DATAPOINTS));\n+        }\n+        builder.append(\"\\\"\");\n+        builder.append(metric);\n+        builder.append(\"\\\":\");\n+        builder.append(results.formatJSON());\n+        for (metricIndex += 1; metricIndex < numMetrics; metricIndex++) {\n+          metric = metrics.get(metricIndex);\n+          results = db.queryMetric(metric, MetricsModel.ALL_METRICS.get(metric).dimensionNames, maxDatapoints);\n+          if (results != null) {\n+            maxDatapoints -= results.size();\n+            if (maxDatapoints == 0) {\n+              throw new InvalidParameterException(String.format(\"requested data exceeds the %d datapoints limit\", DEFAULT_MAX_DATAPOINTS));\n+            }\n+            builder.append(\",\\\"\");\n+            builder.append(metric);\n+            builder.append(\"\\\":\");\n+            builder.append(results.formatJSON());\n+          }\n+        }\n+      }\n+    }\n+    builder.append(\"}\");\n+    db.remove();\n+    return maxDatapoints - 1;\n+  }\n+\n+  /**\n+   * Requires non-empty batchMetrics, valid non-empty metrics, valid startTime, valid endTime,\n+   * valid samplingPeriod (in milliseconds), and non-negative maxDatapoints.\n+   */\n+  @VisibleForTesting\n+  public String queryFromBatchMetrics(NavigableSet<Long> batchMetrics, List<String> metrics, long startTime,\n+                                      long endTime, long samplingPeriod, int maxDatapoints) throws Exception {\n+    StringBuilder responseJson = new StringBuilder();\n+    responseJson.append(\"{\");\n+    Long metricsTimestamp = batchMetrics.ceiling(startTime);\n+    if (metricsTimestamp != null && metricsTimestamp < endTime) {\n+      maxDatapoints = appendMetrics(metricsTimestamp, metrics, responseJson, maxDatapoints);\n+      metricsTimestamp = metricsTimestamp - metricsTimestamp % samplingPeriod + samplingPeriod;\n+      metricsTimestamp = batchMetrics.ceiling(metricsTimestamp);\n+      while (metricsTimestamp != null && metricsTimestamp < endTime) {\n+        responseJson.append(\",\");\n+        maxDatapoints = appendMetrics(metricsTimestamp, metrics, responseJson, maxDatapoints);\n+        metricsTimestamp = metricsTimestamp - metricsTimestamp % samplingPeriod + samplingPeriod;\n+        metricsTimestamp = batchMetrics.ceiling(metricsTimestamp);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ1NDIwNQ=="}, "originalCommit": {"oid": "e2f856bf687d4749dc4d3ebec026aa0a6b06c2ef"}, "originalPosition": 293}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjk5Nzc4OTM2OnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandler.java", "isResolved": false, "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQyMToxODo0OVrOHJUvUw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQxNTo0OTo0OFrOHPN4_w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTUzOTAyNw==", "bodyText": "I've already commented on this to Ricardo. I think it's better to avoid tight coupling between the JSON response construction and the actual sampling and querying of the metrics.\nHowever, since today there are no components that would actually need the batching logic outside of the REST layer, and since this is an L0 solution, I've said that I'd note my concern here and +1.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r479539027", "createdAt": "2020-08-28T21:18:49Z", "author": {"login": "sidheart"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandler.java", "diffHunk": "@@ -0,0 +1,309 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rest;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatExceptionCode;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatsCollector;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.config.PluginSettings;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metrics.MetricsRestUtil;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.model.MetricsModel;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.net.NetClient;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ReaderMetricsProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.sun.net.httpserver.HttpExchange;\n+import com.sun.net.httpserver.HttpHandler;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.net.HttpURLConnection;\n+import java.security.InvalidParameterException;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.NavigableSet;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.logging.log4j.util.Supplier;\n+import org.jooq.Record;\n+import org.jooq.Result;\n+\n+/**\n+ * Request handler that supports querying batch metrics from an EC2 instance\n+ *\n+ * <p>Return 1 minute of CPU_Utilization metrics sampled at a 5s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization&starttime=1566413975000&endtime=1566413980000\"\n+ *\n+ * <p>Return 1 minute of CPU_Utilization and Latency metrics sampled at a 10s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization,Latency&starttime=1566413975000&endtime=1566413980000&samplingperiod=10\"\n+ *\n+ * <p>Return format:\n+ * {\n+ *   \"1594412650000\": {\n+ *     \"CPU_Utilization\": {\n+ *       \"fields\": [\n+ *         {\n+ *           \"name: \"IndexName\",\n+ *           \"type\": \"VARCHAR\"\n+ *         },\n+ *         <...>\n+ *       ]\n+ *       \"records\": [\n+ *         [\n+ *           \"pmc\",\n+ *           <...>\n+ *         ],\n+ *         <...>\n+ *       ]\n+ *     }\n+ *   }\n+ * }\n+ */\n+public class QueryBatchRequestHandler extends MetricsHandler implements HttpHandler {\n+\n+  private static final Logger LOG = LogManager.getLogger(QueryBatchRequestHandler.class);\n+\n+  private static final int TIME_OUT_VALUE = 2;\n+  private static final TimeUnit TIME_OUT_UNIT = TimeUnit.SECONDS;\n+  private NetClient netClient;\n+  MetricsRestUtil metricsRestUtil;\n+\n+  public static final int DEFAULT_MAX_DATAPOINTS = 100800;  // Must be non-negative\n+  public static final long DEFAULT_SAMPLING_PERIOD = 5000;  // Must be a multiple of 5000\n+\n+  public QueryBatchRequestHandler(NetClient netClient, MetricsRestUtil metricsRestUtil) {\n+    this.netClient = netClient;\n+    this.metricsRestUtil = metricsRestUtil;\n+  }\n+\n+  @Override\n+  public void handle(HttpExchange exchange) throws IOException {\n+    String requestMethod = exchange.getRequestMethod();\n+    if (!requestMethod.equalsIgnoreCase(\"GET\")) {\n+      exchange.sendResponseHeaders(HttpURLConnection.HTTP_NOT_FOUND, -1);\n+      exchange.close();\n+      return;\n+    }\n+\n+    ReaderMetricsProcessor mp = ReaderMetricsProcessor.getInstance();\n+    if (mp == null) {\n+      sendResponse(\n+          exchange,\n+          \"{\\\"error\\\":\\\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\\\"}\",\n+          HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    NavigableSet<Long> batchMetrics = mp.getBatchMetrics();\n+    long currentTime = System.currentTimeMillis();\n+    if (batchMetrics == null) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"The batch metrics api has not been enabled for this node.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"The batch metrics api has not been enabled for this node.\");\n+      return;\n+    }\n+    if (batchMetrics.isEmpty()) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"There are no metrics databases. The reader has run into an issue or has just started.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"There are no metrics databases. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    exchange.getResponseHeaders().set(\"Content-Type\", \"application/json\");\n+\n+    Map<String, String> params = getParamsMap(exchange.getRequestURI().getQuery());\n+\n+    try {\n+      // Parse and validate parameters\n+      String[] validParamsTmp = {\"\", \"metrics\", \"starttime\", \"endtime\", \"samplingperiod\", \"maxdatapoints\"};\n+      Set<String> validParams = new HashSet<>(Arrays.asList(validParamsTmp));\n+      for (String param : params.keySet()) {\n+        if (!validParams.contains(param)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid parameter\", param));\n+        }\n+      }\n+\n+      List<String> metrics = metricsRestUtil.parseArrayParam(params, \"metrics\", false);\n+      String startTimeParam = params.get(\"starttime\");\n+      String endTimeParam = params.get(\"endtime\");\n+      String samplingPeriodParam = params.get(\"samplingperiod\");\n+\n+      for (String metric : metrics) {\n+        if (!MetricsModel.ALL_METRICS.containsKey(metric)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid metric\", metric));\n+        }\n+      }\n+\n+      if (startTimeParam == null || startTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"starttime parameter must be set\");\n+      }\n+      long startTime;\n+      try {\n+        startTime = Long.parseUnsignedLong(startTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid starttime\", startTimeParam));\n+      }\n+\n+      if (endTimeParam == null || endTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"endtime parameter must be set\");\n+      }\n+      long endTime;\n+      try {\n+        endTime = Long.parseUnsignedLong(endTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid endtime\", endTimeParam));\n+      }\n+\n+      long samplingPeriod = DEFAULT_SAMPLING_PERIOD;\n+      if (samplingPeriodParam != null && !samplingPeriodParam.isEmpty()) {\n+        samplingPeriod = Long.parseLong(samplingPeriodParam);\n+        if (samplingPeriod < 5 || samplingPeriod % 5 != 0) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid sampling period\", samplingPeriodParam));\n+        }\n+        if (samplingPeriod >= PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60) {\n+          throw new InvalidParameterException(\"sampling period must be less than the retention period\");\n+        }\n+        samplingPeriod *= 1000;\n+      }\n+\n+      if (startTime >= endTime) {\n+        throw new InvalidParameterException(\"starttime must be less than the endtime\");\n+      }\n+      startTime -= startTime % samplingPeriod;\n+      endTime -= endTime % samplingPeriod;\n+      if (startTime == endTime) {\n+        throw new InvalidParameterException(\"starttime and endtime cannot be equal when rounded down to the nearest sampling period\");\n+      }\n+      if (endTime > currentTime) {\n+        throw new InvalidParameterException(\"endtime can be no greater than the system time at the node\");\n+      }\n+      if (startTime < currentTime - PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60 * 1000) {\n+        throw new InvalidParameterException(\"starttime must be within the retention period\");\n+      }\n+\n+      String queryResponse = queryFromBatchMetrics(batchMetrics, metrics, startTime, endTime, samplingPeriod,\n+              DEFAULT_MAX_DATAPOINTS);\n+      sendResponse(exchange, queryResponse, HttpURLConnection.HTTP_OK);\n+    } catch (InvalidParameterException e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.getMessage() + \".\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_BAD_REQUEST);\n+    } catch (Exception e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.toString() + \"\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_INTERNAL_ERROR);\n+    }\n+  }\n+\n+  @VisibleForTesting\n+  public int appendMetrics(Long timestamp, List<String> metrics, StringBuilder builder, int maxDatapoints) throws Exception {\n+    maxDatapoints += 1;\n+    builder.append(\"\\\"\");\n+    builder.append(timestamp);\n+    builder.append(\"\\\":{\");\n+    MetricsDB db = MetricsDB.fetchExisting(timestamp);\n+    for (int metricIndex = 0, numMetrics = metrics.size(); metricIndex < numMetrics; metricIndex++) {\n+      String metric = metrics.get(metricIndex);\n+      Result<Record> results = db.queryMetric(metric, MetricsModel.ALL_METRICS.get(metric).dimensionNames, maxDatapoints);\n+      if (results != null) {\n+        maxDatapoints -= results.size();\n+        if (maxDatapoints == 0) {\n+          throw new InvalidParameterException(String.format(\"requested data exceeds the %d datapoints limit\", DEFAULT_MAX_DATAPOINTS));\n+        }\n+        builder.append(\"\\\"\");\n+        builder.append(metric);\n+        builder.append(\"\\\":\");\n+        builder.append(results.formatJSON());\n+        for (metricIndex += 1; metricIndex < numMetrics; metricIndex++) {\n+          metric = metrics.get(metricIndex);\n+          results = db.queryMetric(metric, MetricsModel.ALL_METRICS.get(metric).dimensionNames, maxDatapoints);\n+          if (results != null) {\n+            maxDatapoints -= results.size();\n+            if (maxDatapoints == 0) {\n+              throw new InvalidParameterException(String.format(\"requested data exceeds the %d datapoints limit\", DEFAULT_MAX_DATAPOINTS));\n+            }\n+            builder.append(\",\\\"\");\n+            builder.append(metric);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2f856bf687d4749dc4d3ebec026aa0a6b06c2ef"}, "originalPosition": 263}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTUzOTE1NA==", "bodyText": "Does anyone else have a strong opinion on this? @yojs @vigyasharma", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r479539154", "createdAt": "2020-08-28T21:19:11Z", "author": {"login": "sidheart"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandler.java", "diffHunk": "@@ -0,0 +1,309 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rest;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatExceptionCode;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatsCollector;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.config.PluginSettings;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metrics.MetricsRestUtil;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.model.MetricsModel;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.net.NetClient;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ReaderMetricsProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.sun.net.httpserver.HttpExchange;\n+import com.sun.net.httpserver.HttpHandler;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.net.HttpURLConnection;\n+import java.security.InvalidParameterException;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.NavigableSet;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.logging.log4j.util.Supplier;\n+import org.jooq.Record;\n+import org.jooq.Result;\n+\n+/**\n+ * Request handler that supports querying batch metrics from an EC2 instance\n+ *\n+ * <p>Return 1 minute of CPU_Utilization metrics sampled at a 5s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization&starttime=1566413975000&endtime=1566413980000\"\n+ *\n+ * <p>Return 1 minute of CPU_Utilization and Latency metrics sampled at a 10s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization,Latency&starttime=1566413975000&endtime=1566413980000&samplingperiod=10\"\n+ *\n+ * <p>Return format:\n+ * {\n+ *   \"1594412650000\": {\n+ *     \"CPU_Utilization\": {\n+ *       \"fields\": [\n+ *         {\n+ *           \"name: \"IndexName\",\n+ *           \"type\": \"VARCHAR\"\n+ *         },\n+ *         <...>\n+ *       ]\n+ *       \"records\": [\n+ *         [\n+ *           \"pmc\",\n+ *           <...>\n+ *         ],\n+ *         <...>\n+ *       ]\n+ *     }\n+ *   }\n+ * }\n+ */\n+public class QueryBatchRequestHandler extends MetricsHandler implements HttpHandler {\n+\n+  private static final Logger LOG = LogManager.getLogger(QueryBatchRequestHandler.class);\n+\n+  private static final int TIME_OUT_VALUE = 2;\n+  private static final TimeUnit TIME_OUT_UNIT = TimeUnit.SECONDS;\n+  private NetClient netClient;\n+  MetricsRestUtil metricsRestUtil;\n+\n+  public static final int DEFAULT_MAX_DATAPOINTS = 100800;  // Must be non-negative\n+  public static final long DEFAULT_SAMPLING_PERIOD = 5000;  // Must be a multiple of 5000\n+\n+  public QueryBatchRequestHandler(NetClient netClient, MetricsRestUtil metricsRestUtil) {\n+    this.netClient = netClient;\n+    this.metricsRestUtil = metricsRestUtil;\n+  }\n+\n+  @Override\n+  public void handle(HttpExchange exchange) throws IOException {\n+    String requestMethod = exchange.getRequestMethod();\n+    if (!requestMethod.equalsIgnoreCase(\"GET\")) {\n+      exchange.sendResponseHeaders(HttpURLConnection.HTTP_NOT_FOUND, -1);\n+      exchange.close();\n+      return;\n+    }\n+\n+    ReaderMetricsProcessor mp = ReaderMetricsProcessor.getInstance();\n+    if (mp == null) {\n+      sendResponse(\n+          exchange,\n+          \"{\\\"error\\\":\\\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\\\"}\",\n+          HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    NavigableSet<Long> batchMetrics = mp.getBatchMetrics();\n+    long currentTime = System.currentTimeMillis();\n+    if (batchMetrics == null) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"The batch metrics api has not been enabled for this node.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"The batch metrics api has not been enabled for this node.\");\n+      return;\n+    }\n+    if (batchMetrics.isEmpty()) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"There are no metrics databases. The reader has run into an issue or has just started.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"There are no metrics databases. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    exchange.getResponseHeaders().set(\"Content-Type\", \"application/json\");\n+\n+    Map<String, String> params = getParamsMap(exchange.getRequestURI().getQuery());\n+\n+    try {\n+      // Parse and validate parameters\n+      String[] validParamsTmp = {\"\", \"metrics\", \"starttime\", \"endtime\", \"samplingperiod\", \"maxdatapoints\"};\n+      Set<String> validParams = new HashSet<>(Arrays.asList(validParamsTmp));\n+      for (String param : params.keySet()) {\n+        if (!validParams.contains(param)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid parameter\", param));\n+        }\n+      }\n+\n+      List<String> metrics = metricsRestUtil.parseArrayParam(params, \"metrics\", false);\n+      String startTimeParam = params.get(\"starttime\");\n+      String endTimeParam = params.get(\"endtime\");\n+      String samplingPeriodParam = params.get(\"samplingperiod\");\n+\n+      for (String metric : metrics) {\n+        if (!MetricsModel.ALL_METRICS.containsKey(metric)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid metric\", metric));\n+        }\n+      }\n+\n+      if (startTimeParam == null || startTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"starttime parameter must be set\");\n+      }\n+      long startTime;\n+      try {\n+        startTime = Long.parseUnsignedLong(startTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid starttime\", startTimeParam));\n+      }\n+\n+      if (endTimeParam == null || endTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"endtime parameter must be set\");\n+      }\n+      long endTime;\n+      try {\n+        endTime = Long.parseUnsignedLong(endTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid endtime\", endTimeParam));\n+      }\n+\n+      long samplingPeriod = DEFAULT_SAMPLING_PERIOD;\n+      if (samplingPeriodParam != null && !samplingPeriodParam.isEmpty()) {\n+        samplingPeriod = Long.parseLong(samplingPeriodParam);\n+        if (samplingPeriod < 5 || samplingPeriod % 5 != 0) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid sampling period\", samplingPeriodParam));\n+        }\n+        if (samplingPeriod >= PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60) {\n+          throw new InvalidParameterException(\"sampling period must be less than the retention period\");\n+        }\n+        samplingPeriod *= 1000;\n+      }\n+\n+      if (startTime >= endTime) {\n+        throw new InvalidParameterException(\"starttime must be less than the endtime\");\n+      }\n+      startTime -= startTime % samplingPeriod;\n+      endTime -= endTime % samplingPeriod;\n+      if (startTime == endTime) {\n+        throw new InvalidParameterException(\"starttime and endtime cannot be equal when rounded down to the nearest sampling period\");\n+      }\n+      if (endTime > currentTime) {\n+        throw new InvalidParameterException(\"endtime can be no greater than the system time at the node\");\n+      }\n+      if (startTime < currentTime - PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60 * 1000) {\n+        throw new InvalidParameterException(\"starttime must be within the retention period\");\n+      }\n+\n+      String queryResponse = queryFromBatchMetrics(batchMetrics, metrics, startTime, endTime, samplingPeriod,\n+              DEFAULT_MAX_DATAPOINTS);\n+      sendResponse(exchange, queryResponse, HttpURLConnection.HTTP_OK);\n+    } catch (InvalidParameterException e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.getMessage() + \".\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_BAD_REQUEST);\n+    } catch (Exception e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.toString() + \"\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_INTERNAL_ERROR);\n+    }\n+  }\n+\n+  @VisibleForTesting\n+  public int appendMetrics(Long timestamp, List<String> metrics, StringBuilder builder, int maxDatapoints) throws Exception {\n+    maxDatapoints += 1;\n+    builder.append(\"\\\"\");\n+    builder.append(timestamp);\n+    builder.append(\"\\\":{\");\n+    MetricsDB db = MetricsDB.fetchExisting(timestamp);\n+    for (int metricIndex = 0, numMetrics = metrics.size(); metricIndex < numMetrics; metricIndex++) {\n+      String metric = metrics.get(metricIndex);\n+      Result<Record> results = db.queryMetric(metric, MetricsModel.ALL_METRICS.get(metric).dimensionNames, maxDatapoints);\n+      if (results != null) {\n+        maxDatapoints -= results.size();\n+        if (maxDatapoints == 0) {\n+          throw new InvalidParameterException(String.format(\"requested data exceeds the %d datapoints limit\", DEFAULT_MAX_DATAPOINTS));\n+        }\n+        builder.append(\"\\\"\");\n+        builder.append(metric);\n+        builder.append(\"\\\":\");\n+        builder.append(results.formatJSON());\n+        for (metricIndex += 1; metricIndex < numMetrics; metricIndex++) {\n+          metric = metrics.get(metricIndex);\n+          results = db.queryMetric(metric, MetricsModel.ALL_METRICS.get(metric).dimensionNames, maxDatapoints);\n+          if (results != null) {\n+            maxDatapoints -= results.size();\n+            if (maxDatapoints == 0) {\n+              throw new InvalidParameterException(String.format(\"requested data exceeds the %d datapoints limit\", DEFAULT_MAX_DATAPOINTS));\n+            }\n+            builder.append(\",\\\"\");\n+            builder.append(metric);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTUzOTAyNw=="}, "originalCommit": {"oid": "e2f856bf687d4749dc4d3ebec026aa0a6b06c2ef"}, "originalPosition": 263}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDIyNjAzOQ==", "bodyText": "+1. why do we have to manually construct the json? Can't we just have a Batch Metrics Response object and use libraries to parse it into json strings?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r480226039", "createdAt": "2020-08-31T15:55:50Z", "author": {"login": "vigyasharma"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandler.java", "diffHunk": "@@ -0,0 +1,309 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rest;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatExceptionCode;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatsCollector;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.config.PluginSettings;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metrics.MetricsRestUtil;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.model.MetricsModel;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.net.NetClient;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ReaderMetricsProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.sun.net.httpserver.HttpExchange;\n+import com.sun.net.httpserver.HttpHandler;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.net.HttpURLConnection;\n+import java.security.InvalidParameterException;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.NavigableSet;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.logging.log4j.util.Supplier;\n+import org.jooq.Record;\n+import org.jooq.Result;\n+\n+/**\n+ * Request handler that supports querying batch metrics from an EC2 instance\n+ *\n+ * <p>Return 1 minute of CPU_Utilization metrics sampled at a 5s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization&starttime=1566413975000&endtime=1566413980000\"\n+ *\n+ * <p>Return 1 minute of CPU_Utilization and Latency metrics sampled at a 10s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization,Latency&starttime=1566413975000&endtime=1566413980000&samplingperiod=10\"\n+ *\n+ * <p>Return format:\n+ * {\n+ *   \"1594412650000\": {\n+ *     \"CPU_Utilization\": {\n+ *       \"fields\": [\n+ *         {\n+ *           \"name: \"IndexName\",\n+ *           \"type\": \"VARCHAR\"\n+ *         },\n+ *         <...>\n+ *       ]\n+ *       \"records\": [\n+ *         [\n+ *           \"pmc\",\n+ *           <...>\n+ *         ],\n+ *         <...>\n+ *       ]\n+ *     }\n+ *   }\n+ * }\n+ */\n+public class QueryBatchRequestHandler extends MetricsHandler implements HttpHandler {\n+\n+  private static final Logger LOG = LogManager.getLogger(QueryBatchRequestHandler.class);\n+\n+  private static final int TIME_OUT_VALUE = 2;\n+  private static final TimeUnit TIME_OUT_UNIT = TimeUnit.SECONDS;\n+  private NetClient netClient;\n+  MetricsRestUtil metricsRestUtil;\n+\n+  public static final int DEFAULT_MAX_DATAPOINTS = 100800;  // Must be non-negative\n+  public static final long DEFAULT_SAMPLING_PERIOD = 5000;  // Must be a multiple of 5000\n+\n+  public QueryBatchRequestHandler(NetClient netClient, MetricsRestUtil metricsRestUtil) {\n+    this.netClient = netClient;\n+    this.metricsRestUtil = metricsRestUtil;\n+  }\n+\n+  @Override\n+  public void handle(HttpExchange exchange) throws IOException {\n+    String requestMethod = exchange.getRequestMethod();\n+    if (!requestMethod.equalsIgnoreCase(\"GET\")) {\n+      exchange.sendResponseHeaders(HttpURLConnection.HTTP_NOT_FOUND, -1);\n+      exchange.close();\n+      return;\n+    }\n+\n+    ReaderMetricsProcessor mp = ReaderMetricsProcessor.getInstance();\n+    if (mp == null) {\n+      sendResponse(\n+          exchange,\n+          \"{\\\"error\\\":\\\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\\\"}\",\n+          HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    NavigableSet<Long> batchMetrics = mp.getBatchMetrics();\n+    long currentTime = System.currentTimeMillis();\n+    if (batchMetrics == null) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"The batch metrics api has not been enabled for this node.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"The batch metrics api has not been enabled for this node.\");\n+      return;\n+    }\n+    if (batchMetrics.isEmpty()) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"There are no metrics databases. The reader has run into an issue or has just started.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"There are no metrics databases. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    exchange.getResponseHeaders().set(\"Content-Type\", \"application/json\");\n+\n+    Map<String, String> params = getParamsMap(exchange.getRequestURI().getQuery());\n+\n+    try {\n+      // Parse and validate parameters\n+      String[] validParamsTmp = {\"\", \"metrics\", \"starttime\", \"endtime\", \"samplingperiod\", \"maxdatapoints\"};\n+      Set<String> validParams = new HashSet<>(Arrays.asList(validParamsTmp));\n+      for (String param : params.keySet()) {\n+        if (!validParams.contains(param)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid parameter\", param));\n+        }\n+      }\n+\n+      List<String> metrics = metricsRestUtil.parseArrayParam(params, \"metrics\", false);\n+      String startTimeParam = params.get(\"starttime\");\n+      String endTimeParam = params.get(\"endtime\");\n+      String samplingPeriodParam = params.get(\"samplingperiod\");\n+\n+      for (String metric : metrics) {\n+        if (!MetricsModel.ALL_METRICS.containsKey(metric)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid metric\", metric));\n+        }\n+      }\n+\n+      if (startTimeParam == null || startTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"starttime parameter must be set\");\n+      }\n+      long startTime;\n+      try {\n+        startTime = Long.parseUnsignedLong(startTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid starttime\", startTimeParam));\n+      }\n+\n+      if (endTimeParam == null || endTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"endtime parameter must be set\");\n+      }\n+      long endTime;\n+      try {\n+        endTime = Long.parseUnsignedLong(endTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid endtime\", endTimeParam));\n+      }\n+\n+      long samplingPeriod = DEFAULT_SAMPLING_PERIOD;\n+      if (samplingPeriodParam != null && !samplingPeriodParam.isEmpty()) {\n+        samplingPeriod = Long.parseLong(samplingPeriodParam);\n+        if (samplingPeriod < 5 || samplingPeriod % 5 != 0) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid sampling period\", samplingPeriodParam));\n+        }\n+        if (samplingPeriod >= PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60) {\n+          throw new InvalidParameterException(\"sampling period must be less than the retention period\");\n+        }\n+        samplingPeriod *= 1000;\n+      }\n+\n+      if (startTime >= endTime) {\n+        throw new InvalidParameterException(\"starttime must be less than the endtime\");\n+      }\n+      startTime -= startTime % samplingPeriod;\n+      endTime -= endTime % samplingPeriod;\n+      if (startTime == endTime) {\n+        throw new InvalidParameterException(\"starttime and endtime cannot be equal when rounded down to the nearest sampling period\");\n+      }\n+      if (endTime > currentTime) {\n+        throw new InvalidParameterException(\"endtime can be no greater than the system time at the node\");\n+      }\n+      if (startTime < currentTime - PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60 * 1000) {\n+        throw new InvalidParameterException(\"starttime must be within the retention period\");\n+      }\n+\n+      String queryResponse = queryFromBatchMetrics(batchMetrics, metrics, startTime, endTime, samplingPeriod,\n+              DEFAULT_MAX_DATAPOINTS);\n+      sendResponse(exchange, queryResponse, HttpURLConnection.HTTP_OK);\n+    } catch (InvalidParameterException e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.getMessage() + \".\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_BAD_REQUEST);\n+    } catch (Exception e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.toString() + \"\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_INTERNAL_ERROR);\n+    }\n+  }\n+\n+  @VisibleForTesting\n+  public int appendMetrics(Long timestamp, List<String> metrics, StringBuilder builder, int maxDatapoints) throws Exception {\n+    maxDatapoints += 1;\n+    builder.append(\"\\\"\");\n+    builder.append(timestamp);\n+    builder.append(\"\\\":{\");\n+    MetricsDB db = MetricsDB.fetchExisting(timestamp);\n+    for (int metricIndex = 0, numMetrics = metrics.size(); metricIndex < numMetrics; metricIndex++) {\n+      String metric = metrics.get(metricIndex);\n+      Result<Record> results = db.queryMetric(metric, MetricsModel.ALL_METRICS.get(metric).dimensionNames, maxDatapoints);\n+      if (results != null) {\n+        maxDatapoints -= results.size();\n+        if (maxDatapoints == 0) {\n+          throw new InvalidParameterException(String.format(\"requested data exceeds the %d datapoints limit\", DEFAULT_MAX_DATAPOINTS));\n+        }\n+        builder.append(\"\\\"\");\n+        builder.append(metric);\n+        builder.append(\"\\\":\");\n+        builder.append(results.formatJSON());\n+        for (metricIndex += 1; metricIndex < numMetrics; metricIndex++) {\n+          metric = metrics.get(metricIndex);\n+          results = db.queryMetric(metric, MetricsModel.ALL_METRICS.get(metric).dimensionNames, maxDatapoints);\n+          if (results != null) {\n+            maxDatapoints -= results.size();\n+            if (maxDatapoints == 0) {\n+              throw new InvalidParameterException(String.format(\"requested data exceeds the %d datapoints limit\", DEFAULT_MAX_DATAPOINTS));\n+            }\n+            builder.append(\",\\\"\");\n+            builder.append(metric);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTUzOTAyNw=="}, "originalCommit": {"oid": "e2f856bf687d4749dc4d3ebec026aa0a6b06c2ef"}, "originalPosition": 263}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQ3Mjg5MA==", "bodyText": "If we find a use for such decoupling, perhaps we can modify the implementation with such changes. However, for now, this approach will work, and it removes the need for additional investigation (for example, this would increase processing time, and stringifying a Batch Metrics Response object would double the peak memory usage of this component).", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r481472890", "createdAt": "2020-09-01T22:44:32Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandler.java", "diffHunk": "@@ -0,0 +1,309 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rest;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatExceptionCode;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatsCollector;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.config.PluginSettings;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metrics.MetricsRestUtil;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.model.MetricsModel;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.net.NetClient;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ReaderMetricsProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.sun.net.httpserver.HttpExchange;\n+import com.sun.net.httpserver.HttpHandler;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.net.HttpURLConnection;\n+import java.security.InvalidParameterException;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.NavigableSet;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.logging.log4j.util.Supplier;\n+import org.jooq.Record;\n+import org.jooq.Result;\n+\n+/**\n+ * Request handler that supports querying batch metrics from an EC2 instance\n+ *\n+ * <p>Return 1 minute of CPU_Utilization metrics sampled at a 5s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization&starttime=1566413975000&endtime=1566413980000\"\n+ *\n+ * <p>Return 1 minute of CPU_Utilization and Latency metrics sampled at a 10s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization,Latency&starttime=1566413975000&endtime=1566413980000&samplingperiod=10\"\n+ *\n+ * <p>Return format:\n+ * {\n+ *   \"1594412650000\": {\n+ *     \"CPU_Utilization\": {\n+ *       \"fields\": [\n+ *         {\n+ *           \"name: \"IndexName\",\n+ *           \"type\": \"VARCHAR\"\n+ *         },\n+ *         <...>\n+ *       ]\n+ *       \"records\": [\n+ *         [\n+ *           \"pmc\",\n+ *           <...>\n+ *         ],\n+ *         <...>\n+ *       ]\n+ *     }\n+ *   }\n+ * }\n+ */\n+public class QueryBatchRequestHandler extends MetricsHandler implements HttpHandler {\n+\n+  private static final Logger LOG = LogManager.getLogger(QueryBatchRequestHandler.class);\n+\n+  private static final int TIME_OUT_VALUE = 2;\n+  private static final TimeUnit TIME_OUT_UNIT = TimeUnit.SECONDS;\n+  private NetClient netClient;\n+  MetricsRestUtil metricsRestUtil;\n+\n+  public static final int DEFAULT_MAX_DATAPOINTS = 100800;  // Must be non-negative\n+  public static final long DEFAULT_SAMPLING_PERIOD = 5000;  // Must be a multiple of 5000\n+\n+  public QueryBatchRequestHandler(NetClient netClient, MetricsRestUtil metricsRestUtil) {\n+    this.netClient = netClient;\n+    this.metricsRestUtil = metricsRestUtil;\n+  }\n+\n+  @Override\n+  public void handle(HttpExchange exchange) throws IOException {\n+    String requestMethod = exchange.getRequestMethod();\n+    if (!requestMethod.equalsIgnoreCase(\"GET\")) {\n+      exchange.sendResponseHeaders(HttpURLConnection.HTTP_NOT_FOUND, -1);\n+      exchange.close();\n+      return;\n+    }\n+\n+    ReaderMetricsProcessor mp = ReaderMetricsProcessor.getInstance();\n+    if (mp == null) {\n+      sendResponse(\n+          exchange,\n+          \"{\\\"error\\\":\\\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\\\"}\",\n+          HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    NavigableSet<Long> batchMetrics = mp.getBatchMetrics();\n+    long currentTime = System.currentTimeMillis();\n+    if (batchMetrics == null) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"The batch metrics api has not been enabled for this node.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"The batch metrics api has not been enabled for this node.\");\n+      return;\n+    }\n+    if (batchMetrics.isEmpty()) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"There are no metrics databases. The reader has run into an issue or has just started.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"There are no metrics databases. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    exchange.getResponseHeaders().set(\"Content-Type\", \"application/json\");\n+\n+    Map<String, String> params = getParamsMap(exchange.getRequestURI().getQuery());\n+\n+    try {\n+      // Parse and validate parameters\n+      String[] validParamsTmp = {\"\", \"metrics\", \"starttime\", \"endtime\", \"samplingperiod\", \"maxdatapoints\"};\n+      Set<String> validParams = new HashSet<>(Arrays.asList(validParamsTmp));\n+      for (String param : params.keySet()) {\n+        if (!validParams.contains(param)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid parameter\", param));\n+        }\n+      }\n+\n+      List<String> metrics = metricsRestUtil.parseArrayParam(params, \"metrics\", false);\n+      String startTimeParam = params.get(\"starttime\");\n+      String endTimeParam = params.get(\"endtime\");\n+      String samplingPeriodParam = params.get(\"samplingperiod\");\n+\n+      for (String metric : metrics) {\n+        if (!MetricsModel.ALL_METRICS.containsKey(metric)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid metric\", metric));\n+        }\n+      }\n+\n+      if (startTimeParam == null || startTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"starttime parameter must be set\");\n+      }\n+      long startTime;\n+      try {\n+        startTime = Long.parseUnsignedLong(startTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid starttime\", startTimeParam));\n+      }\n+\n+      if (endTimeParam == null || endTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"endtime parameter must be set\");\n+      }\n+      long endTime;\n+      try {\n+        endTime = Long.parseUnsignedLong(endTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid endtime\", endTimeParam));\n+      }\n+\n+      long samplingPeriod = DEFAULT_SAMPLING_PERIOD;\n+      if (samplingPeriodParam != null && !samplingPeriodParam.isEmpty()) {\n+        samplingPeriod = Long.parseLong(samplingPeriodParam);\n+        if (samplingPeriod < 5 || samplingPeriod % 5 != 0) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid sampling period\", samplingPeriodParam));\n+        }\n+        if (samplingPeriod >= PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60) {\n+          throw new InvalidParameterException(\"sampling period must be less than the retention period\");\n+        }\n+        samplingPeriod *= 1000;\n+      }\n+\n+      if (startTime >= endTime) {\n+        throw new InvalidParameterException(\"starttime must be less than the endtime\");\n+      }\n+      startTime -= startTime % samplingPeriod;\n+      endTime -= endTime % samplingPeriod;\n+      if (startTime == endTime) {\n+        throw new InvalidParameterException(\"starttime and endtime cannot be equal when rounded down to the nearest sampling period\");\n+      }\n+      if (endTime > currentTime) {\n+        throw new InvalidParameterException(\"endtime can be no greater than the system time at the node\");\n+      }\n+      if (startTime < currentTime - PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60 * 1000) {\n+        throw new InvalidParameterException(\"starttime must be within the retention period\");\n+      }\n+\n+      String queryResponse = queryFromBatchMetrics(batchMetrics, metrics, startTime, endTime, samplingPeriod,\n+              DEFAULT_MAX_DATAPOINTS);\n+      sendResponse(exchange, queryResponse, HttpURLConnection.HTTP_OK);\n+    } catch (InvalidParameterException e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.getMessage() + \".\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_BAD_REQUEST);\n+    } catch (Exception e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.toString() + \"\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_INTERNAL_ERROR);\n+    }\n+  }\n+\n+  @VisibleForTesting\n+  public int appendMetrics(Long timestamp, List<String> metrics, StringBuilder builder, int maxDatapoints) throws Exception {\n+    maxDatapoints += 1;\n+    builder.append(\"\\\"\");\n+    builder.append(timestamp);\n+    builder.append(\"\\\":{\");\n+    MetricsDB db = MetricsDB.fetchExisting(timestamp);\n+    for (int metricIndex = 0, numMetrics = metrics.size(); metricIndex < numMetrics; metricIndex++) {\n+      String metric = metrics.get(metricIndex);\n+      Result<Record> results = db.queryMetric(metric, MetricsModel.ALL_METRICS.get(metric).dimensionNames, maxDatapoints);\n+      if (results != null) {\n+        maxDatapoints -= results.size();\n+        if (maxDatapoints == 0) {\n+          throw new InvalidParameterException(String.format(\"requested data exceeds the %d datapoints limit\", DEFAULT_MAX_DATAPOINTS));\n+        }\n+        builder.append(\"\\\"\");\n+        builder.append(metric);\n+        builder.append(\"\\\":\");\n+        builder.append(results.formatJSON());\n+        for (metricIndex += 1; metricIndex < numMetrics; metricIndex++) {\n+          metric = metrics.get(metricIndex);\n+          results = db.queryMetric(metric, MetricsModel.ALL_METRICS.get(metric).dimensionNames, maxDatapoints);\n+          if (results != null) {\n+            maxDatapoints -= results.size();\n+            if (maxDatapoints == 0) {\n+              throw new InvalidParameterException(String.format(\"requested data exceeds the %d datapoints limit\", DEFAULT_MAX_DATAPOINTS));\n+            }\n+            builder.append(\",\\\"\");\n+            builder.append(metric);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTUzOTAyNw=="}, "originalCommit": {"oid": "e2f856bf687d4749dc4d3ebec026aa0a6b06c2ef"}, "originalPosition": 263}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA3NjM3NQ==", "bodyText": "Constructing Json by hand is tedious and error prone. Maybe you can look at HotNodeSummary::toJson() to get a feel for the library that can help you do it much easily.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485076375", "createdAt": "2020-09-08T17:15:42Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandler.java", "diffHunk": "@@ -0,0 +1,309 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rest;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatExceptionCode;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatsCollector;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.config.PluginSettings;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metrics.MetricsRestUtil;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.model.MetricsModel;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.net.NetClient;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ReaderMetricsProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.sun.net.httpserver.HttpExchange;\n+import com.sun.net.httpserver.HttpHandler;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.net.HttpURLConnection;\n+import java.security.InvalidParameterException;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.NavigableSet;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.logging.log4j.util.Supplier;\n+import org.jooq.Record;\n+import org.jooq.Result;\n+\n+/**\n+ * Request handler that supports querying batch metrics from an EC2 instance\n+ *\n+ * <p>Return 1 minute of CPU_Utilization metrics sampled at a 5s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization&starttime=1566413975000&endtime=1566413980000\"\n+ *\n+ * <p>Return 1 minute of CPU_Utilization and Latency metrics sampled at a 10s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization,Latency&starttime=1566413975000&endtime=1566413980000&samplingperiod=10\"\n+ *\n+ * <p>Return format:\n+ * {\n+ *   \"1594412650000\": {\n+ *     \"CPU_Utilization\": {\n+ *       \"fields\": [\n+ *         {\n+ *           \"name: \"IndexName\",\n+ *           \"type\": \"VARCHAR\"\n+ *         },\n+ *         <...>\n+ *       ]\n+ *       \"records\": [\n+ *         [\n+ *           \"pmc\",\n+ *           <...>\n+ *         ],\n+ *         <...>\n+ *       ]\n+ *     }\n+ *   }\n+ * }\n+ */\n+public class QueryBatchRequestHandler extends MetricsHandler implements HttpHandler {\n+\n+  private static final Logger LOG = LogManager.getLogger(QueryBatchRequestHandler.class);\n+\n+  private static final int TIME_OUT_VALUE = 2;\n+  private static final TimeUnit TIME_OUT_UNIT = TimeUnit.SECONDS;\n+  private NetClient netClient;\n+  MetricsRestUtil metricsRestUtil;\n+\n+  public static final int DEFAULT_MAX_DATAPOINTS = 100800;  // Must be non-negative\n+  public static final long DEFAULT_SAMPLING_PERIOD = 5000;  // Must be a multiple of 5000\n+\n+  public QueryBatchRequestHandler(NetClient netClient, MetricsRestUtil metricsRestUtil) {\n+    this.netClient = netClient;\n+    this.metricsRestUtil = metricsRestUtil;\n+  }\n+\n+  @Override\n+  public void handle(HttpExchange exchange) throws IOException {\n+    String requestMethod = exchange.getRequestMethod();\n+    if (!requestMethod.equalsIgnoreCase(\"GET\")) {\n+      exchange.sendResponseHeaders(HttpURLConnection.HTTP_NOT_FOUND, -1);\n+      exchange.close();\n+      return;\n+    }\n+\n+    ReaderMetricsProcessor mp = ReaderMetricsProcessor.getInstance();\n+    if (mp == null) {\n+      sendResponse(\n+          exchange,\n+          \"{\\\"error\\\":\\\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\\\"}\",\n+          HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    NavigableSet<Long> batchMetrics = mp.getBatchMetrics();\n+    long currentTime = System.currentTimeMillis();\n+    if (batchMetrics == null) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"The batch metrics api has not been enabled for this node.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"The batch metrics api has not been enabled for this node.\");\n+      return;\n+    }\n+    if (batchMetrics.isEmpty()) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"There are no metrics databases. The reader has run into an issue or has just started.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"There are no metrics databases. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    exchange.getResponseHeaders().set(\"Content-Type\", \"application/json\");\n+\n+    Map<String, String> params = getParamsMap(exchange.getRequestURI().getQuery());\n+\n+    try {\n+      // Parse and validate parameters\n+      String[] validParamsTmp = {\"\", \"metrics\", \"starttime\", \"endtime\", \"samplingperiod\", \"maxdatapoints\"};\n+      Set<String> validParams = new HashSet<>(Arrays.asList(validParamsTmp));\n+      for (String param : params.keySet()) {\n+        if (!validParams.contains(param)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid parameter\", param));\n+        }\n+      }\n+\n+      List<String> metrics = metricsRestUtil.parseArrayParam(params, \"metrics\", false);\n+      String startTimeParam = params.get(\"starttime\");\n+      String endTimeParam = params.get(\"endtime\");\n+      String samplingPeriodParam = params.get(\"samplingperiod\");\n+\n+      for (String metric : metrics) {\n+        if (!MetricsModel.ALL_METRICS.containsKey(metric)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid metric\", metric));\n+        }\n+      }\n+\n+      if (startTimeParam == null || startTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"starttime parameter must be set\");\n+      }\n+      long startTime;\n+      try {\n+        startTime = Long.parseUnsignedLong(startTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid starttime\", startTimeParam));\n+      }\n+\n+      if (endTimeParam == null || endTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"endtime parameter must be set\");\n+      }\n+      long endTime;\n+      try {\n+        endTime = Long.parseUnsignedLong(endTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid endtime\", endTimeParam));\n+      }\n+\n+      long samplingPeriod = DEFAULT_SAMPLING_PERIOD;\n+      if (samplingPeriodParam != null && !samplingPeriodParam.isEmpty()) {\n+        samplingPeriod = Long.parseLong(samplingPeriodParam);\n+        if (samplingPeriod < 5 || samplingPeriod % 5 != 0) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid sampling period\", samplingPeriodParam));\n+        }\n+        if (samplingPeriod >= PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60) {\n+          throw new InvalidParameterException(\"sampling period must be less than the retention period\");\n+        }\n+        samplingPeriod *= 1000;\n+      }\n+\n+      if (startTime >= endTime) {\n+        throw new InvalidParameterException(\"starttime must be less than the endtime\");\n+      }\n+      startTime -= startTime % samplingPeriod;\n+      endTime -= endTime % samplingPeriod;\n+      if (startTime == endTime) {\n+        throw new InvalidParameterException(\"starttime and endtime cannot be equal when rounded down to the nearest sampling period\");\n+      }\n+      if (endTime > currentTime) {\n+        throw new InvalidParameterException(\"endtime can be no greater than the system time at the node\");\n+      }\n+      if (startTime < currentTime - PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60 * 1000) {\n+        throw new InvalidParameterException(\"starttime must be within the retention period\");\n+      }\n+\n+      String queryResponse = queryFromBatchMetrics(batchMetrics, metrics, startTime, endTime, samplingPeriod,\n+              DEFAULT_MAX_DATAPOINTS);\n+      sendResponse(exchange, queryResponse, HttpURLConnection.HTTP_OK);\n+    } catch (InvalidParameterException e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.getMessage() + \".\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_BAD_REQUEST);\n+    } catch (Exception e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.toString() + \"\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_INTERNAL_ERROR);\n+    }\n+  }\n+\n+  @VisibleForTesting\n+  public int appendMetrics(Long timestamp, List<String> metrics, StringBuilder builder, int maxDatapoints) throws Exception {\n+    maxDatapoints += 1;\n+    builder.append(\"\\\"\");\n+    builder.append(timestamp);\n+    builder.append(\"\\\":{\");\n+    MetricsDB db = MetricsDB.fetchExisting(timestamp);\n+    for (int metricIndex = 0, numMetrics = metrics.size(); metricIndex < numMetrics; metricIndex++) {\n+      String metric = metrics.get(metricIndex);\n+      Result<Record> results = db.queryMetric(metric, MetricsModel.ALL_METRICS.get(metric).dimensionNames, maxDatapoints);\n+      if (results != null) {\n+        maxDatapoints -= results.size();\n+        if (maxDatapoints == 0) {\n+          throw new InvalidParameterException(String.format(\"requested data exceeds the %d datapoints limit\", DEFAULT_MAX_DATAPOINTS));\n+        }\n+        builder.append(\"\\\"\");\n+        builder.append(metric);\n+        builder.append(\"\\\":\");\n+        builder.append(results.formatJSON());\n+        for (metricIndex += 1; metricIndex < numMetrics; metricIndex++) {\n+          metric = metrics.get(metricIndex);\n+          results = db.queryMetric(metric, MetricsModel.ALL_METRICS.get(metric).dimensionNames, maxDatapoints);\n+          if (results != null) {\n+            maxDatapoints -= results.size();\n+            if (maxDatapoints == 0) {\n+              throw new InvalidParameterException(String.format(\"requested data exceeds the %d datapoints limit\", DEFAULT_MAX_DATAPOINTS));\n+            }\n+            builder.append(\",\\\"\");\n+            builder.append(metric);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTUzOTAyNw=="}, "originalCommit": {"oid": "e2f856bf687d4749dc4d3ebec026aa0a6b06c2ef"}, "originalPosition": 263}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTIzMDI1OQ==", "bodyText": "I agree with joydeep and sid. There are standard tested libraries that we should leverage. Can move to a separate PR as a follow up.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485230259", "createdAt": "2020-09-08T22:29:57Z", "author": {"login": "vigyasharma"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandler.java", "diffHunk": "@@ -0,0 +1,309 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rest;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatExceptionCode;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatsCollector;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.config.PluginSettings;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metrics.MetricsRestUtil;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.model.MetricsModel;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.net.NetClient;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ReaderMetricsProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.sun.net.httpserver.HttpExchange;\n+import com.sun.net.httpserver.HttpHandler;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.net.HttpURLConnection;\n+import java.security.InvalidParameterException;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.NavigableSet;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.logging.log4j.util.Supplier;\n+import org.jooq.Record;\n+import org.jooq.Result;\n+\n+/**\n+ * Request handler that supports querying batch metrics from an EC2 instance\n+ *\n+ * <p>Return 1 minute of CPU_Utilization metrics sampled at a 5s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization&starttime=1566413975000&endtime=1566413980000\"\n+ *\n+ * <p>Return 1 minute of CPU_Utilization and Latency metrics sampled at a 10s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization,Latency&starttime=1566413975000&endtime=1566413980000&samplingperiod=10\"\n+ *\n+ * <p>Return format:\n+ * {\n+ *   \"1594412650000\": {\n+ *     \"CPU_Utilization\": {\n+ *       \"fields\": [\n+ *         {\n+ *           \"name: \"IndexName\",\n+ *           \"type\": \"VARCHAR\"\n+ *         },\n+ *         <...>\n+ *       ]\n+ *       \"records\": [\n+ *         [\n+ *           \"pmc\",\n+ *           <...>\n+ *         ],\n+ *         <...>\n+ *       ]\n+ *     }\n+ *   }\n+ * }\n+ */\n+public class QueryBatchRequestHandler extends MetricsHandler implements HttpHandler {\n+\n+  private static final Logger LOG = LogManager.getLogger(QueryBatchRequestHandler.class);\n+\n+  private static final int TIME_OUT_VALUE = 2;\n+  private static final TimeUnit TIME_OUT_UNIT = TimeUnit.SECONDS;\n+  private NetClient netClient;\n+  MetricsRestUtil metricsRestUtil;\n+\n+  public static final int DEFAULT_MAX_DATAPOINTS = 100800;  // Must be non-negative\n+  public static final long DEFAULT_SAMPLING_PERIOD = 5000;  // Must be a multiple of 5000\n+\n+  public QueryBatchRequestHandler(NetClient netClient, MetricsRestUtil metricsRestUtil) {\n+    this.netClient = netClient;\n+    this.metricsRestUtil = metricsRestUtil;\n+  }\n+\n+  @Override\n+  public void handle(HttpExchange exchange) throws IOException {\n+    String requestMethod = exchange.getRequestMethod();\n+    if (!requestMethod.equalsIgnoreCase(\"GET\")) {\n+      exchange.sendResponseHeaders(HttpURLConnection.HTTP_NOT_FOUND, -1);\n+      exchange.close();\n+      return;\n+    }\n+\n+    ReaderMetricsProcessor mp = ReaderMetricsProcessor.getInstance();\n+    if (mp == null) {\n+      sendResponse(\n+          exchange,\n+          \"{\\\"error\\\":\\\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\\\"}\",\n+          HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    NavigableSet<Long> batchMetrics = mp.getBatchMetrics();\n+    long currentTime = System.currentTimeMillis();\n+    if (batchMetrics == null) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"The batch metrics api has not been enabled for this node.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"The batch metrics api has not been enabled for this node.\");\n+      return;\n+    }\n+    if (batchMetrics.isEmpty()) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"There are no metrics databases. The reader has run into an issue or has just started.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"There are no metrics databases. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    exchange.getResponseHeaders().set(\"Content-Type\", \"application/json\");\n+\n+    Map<String, String> params = getParamsMap(exchange.getRequestURI().getQuery());\n+\n+    try {\n+      // Parse and validate parameters\n+      String[] validParamsTmp = {\"\", \"metrics\", \"starttime\", \"endtime\", \"samplingperiod\", \"maxdatapoints\"};\n+      Set<String> validParams = new HashSet<>(Arrays.asList(validParamsTmp));\n+      for (String param : params.keySet()) {\n+        if (!validParams.contains(param)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid parameter\", param));\n+        }\n+      }\n+\n+      List<String> metrics = metricsRestUtil.parseArrayParam(params, \"metrics\", false);\n+      String startTimeParam = params.get(\"starttime\");\n+      String endTimeParam = params.get(\"endtime\");\n+      String samplingPeriodParam = params.get(\"samplingperiod\");\n+\n+      for (String metric : metrics) {\n+        if (!MetricsModel.ALL_METRICS.containsKey(metric)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid metric\", metric));\n+        }\n+      }\n+\n+      if (startTimeParam == null || startTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"starttime parameter must be set\");\n+      }\n+      long startTime;\n+      try {\n+        startTime = Long.parseUnsignedLong(startTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid starttime\", startTimeParam));\n+      }\n+\n+      if (endTimeParam == null || endTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"endtime parameter must be set\");\n+      }\n+      long endTime;\n+      try {\n+        endTime = Long.parseUnsignedLong(endTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid endtime\", endTimeParam));\n+      }\n+\n+      long samplingPeriod = DEFAULT_SAMPLING_PERIOD;\n+      if (samplingPeriodParam != null && !samplingPeriodParam.isEmpty()) {\n+        samplingPeriod = Long.parseLong(samplingPeriodParam);\n+        if (samplingPeriod < 5 || samplingPeriod % 5 != 0) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid sampling period\", samplingPeriodParam));\n+        }\n+        if (samplingPeriod >= PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60) {\n+          throw new InvalidParameterException(\"sampling period must be less than the retention period\");\n+        }\n+        samplingPeriod *= 1000;\n+      }\n+\n+      if (startTime >= endTime) {\n+        throw new InvalidParameterException(\"starttime must be less than the endtime\");\n+      }\n+      startTime -= startTime % samplingPeriod;\n+      endTime -= endTime % samplingPeriod;\n+      if (startTime == endTime) {\n+        throw new InvalidParameterException(\"starttime and endtime cannot be equal when rounded down to the nearest sampling period\");\n+      }\n+      if (endTime > currentTime) {\n+        throw new InvalidParameterException(\"endtime can be no greater than the system time at the node\");\n+      }\n+      if (startTime < currentTime - PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60 * 1000) {\n+        throw new InvalidParameterException(\"starttime must be within the retention period\");\n+      }\n+\n+      String queryResponse = queryFromBatchMetrics(batchMetrics, metrics, startTime, endTime, samplingPeriod,\n+              DEFAULT_MAX_DATAPOINTS);\n+      sendResponse(exchange, queryResponse, HttpURLConnection.HTTP_OK);\n+    } catch (InvalidParameterException e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.getMessage() + \".\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_BAD_REQUEST);\n+    } catch (Exception e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.toString() + \"\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_INTERNAL_ERROR);\n+    }\n+  }\n+\n+  @VisibleForTesting\n+  public int appendMetrics(Long timestamp, List<String> metrics, StringBuilder builder, int maxDatapoints) throws Exception {\n+    maxDatapoints += 1;\n+    builder.append(\"\\\"\");\n+    builder.append(timestamp);\n+    builder.append(\"\\\":{\");\n+    MetricsDB db = MetricsDB.fetchExisting(timestamp);\n+    for (int metricIndex = 0, numMetrics = metrics.size(); metricIndex < numMetrics; metricIndex++) {\n+      String metric = metrics.get(metricIndex);\n+      Result<Record> results = db.queryMetric(metric, MetricsModel.ALL_METRICS.get(metric).dimensionNames, maxDatapoints);\n+      if (results != null) {\n+        maxDatapoints -= results.size();\n+        if (maxDatapoints == 0) {\n+          throw new InvalidParameterException(String.format(\"requested data exceeds the %d datapoints limit\", DEFAULT_MAX_DATAPOINTS));\n+        }\n+        builder.append(\"\\\"\");\n+        builder.append(metric);\n+        builder.append(\"\\\":\");\n+        builder.append(results.formatJSON());\n+        for (metricIndex += 1; metricIndex < numMetrics; metricIndex++) {\n+          metric = metrics.get(metricIndex);\n+          results = db.queryMetric(metric, MetricsModel.ALL_METRICS.get(metric).dimensionNames, maxDatapoints);\n+          if (results != null) {\n+            maxDatapoints -= results.size();\n+            if (maxDatapoints == 0) {\n+              throw new InvalidParameterException(String.format(\"requested data exceeds the %d datapoints limit\", DEFAULT_MAX_DATAPOINTS));\n+            }\n+            builder.append(\",\\\"\");\n+            builder.append(metric);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTUzOTAyNw=="}, "originalCommit": {"oid": "e2f856bf687d4749dc4d3ebec026aa0a6b06c2ef"}, "originalPosition": 263}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTcxODI3MQ==", "bodyText": "Sure, will raise a new enhancement issue about it #416", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485718271", "createdAt": "2020-09-09T15:49:48Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandler.java", "diffHunk": "@@ -0,0 +1,309 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rest;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatExceptionCode;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatsCollector;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.config.PluginSettings;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metrics.MetricsRestUtil;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.model.MetricsModel;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.net.NetClient;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ReaderMetricsProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.sun.net.httpserver.HttpExchange;\n+import com.sun.net.httpserver.HttpHandler;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.net.HttpURLConnection;\n+import java.security.InvalidParameterException;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.NavigableSet;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.logging.log4j.util.Supplier;\n+import org.jooq.Record;\n+import org.jooq.Result;\n+\n+/**\n+ * Request handler that supports querying batch metrics from an EC2 instance\n+ *\n+ * <p>Return 1 minute of CPU_Utilization metrics sampled at a 5s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization&starttime=1566413975000&endtime=1566413980000\"\n+ *\n+ * <p>Return 1 minute of CPU_Utilization and Latency metrics sampled at a 10s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization,Latency&starttime=1566413975000&endtime=1566413980000&samplingperiod=10\"\n+ *\n+ * <p>Return format:\n+ * {\n+ *   \"1594412650000\": {\n+ *     \"CPU_Utilization\": {\n+ *       \"fields\": [\n+ *         {\n+ *           \"name: \"IndexName\",\n+ *           \"type\": \"VARCHAR\"\n+ *         },\n+ *         <...>\n+ *       ]\n+ *       \"records\": [\n+ *         [\n+ *           \"pmc\",\n+ *           <...>\n+ *         ],\n+ *         <...>\n+ *       ]\n+ *     }\n+ *   }\n+ * }\n+ */\n+public class QueryBatchRequestHandler extends MetricsHandler implements HttpHandler {\n+\n+  private static final Logger LOG = LogManager.getLogger(QueryBatchRequestHandler.class);\n+\n+  private static final int TIME_OUT_VALUE = 2;\n+  private static final TimeUnit TIME_OUT_UNIT = TimeUnit.SECONDS;\n+  private NetClient netClient;\n+  MetricsRestUtil metricsRestUtil;\n+\n+  public static final int DEFAULT_MAX_DATAPOINTS = 100800;  // Must be non-negative\n+  public static final long DEFAULT_SAMPLING_PERIOD = 5000;  // Must be a multiple of 5000\n+\n+  public QueryBatchRequestHandler(NetClient netClient, MetricsRestUtil metricsRestUtil) {\n+    this.netClient = netClient;\n+    this.metricsRestUtil = metricsRestUtil;\n+  }\n+\n+  @Override\n+  public void handle(HttpExchange exchange) throws IOException {\n+    String requestMethod = exchange.getRequestMethod();\n+    if (!requestMethod.equalsIgnoreCase(\"GET\")) {\n+      exchange.sendResponseHeaders(HttpURLConnection.HTTP_NOT_FOUND, -1);\n+      exchange.close();\n+      return;\n+    }\n+\n+    ReaderMetricsProcessor mp = ReaderMetricsProcessor.getInstance();\n+    if (mp == null) {\n+      sendResponse(\n+          exchange,\n+          \"{\\\"error\\\":\\\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\\\"}\",\n+          HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    NavigableSet<Long> batchMetrics = mp.getBatchMetrics();\n+    long currentTime = System.currentTimeMillis();\n+    if (batchMetrics == null) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"The batch metrics api has not been enabled for this node.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"The batch metrics api has not been enabled for this node.\");\n+      return;\n+    }\n+    if (batchMetrics.isEmpty()) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"There are no metrics databases. The reader has run into an issue or has just started.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"There are no metrics databases. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    exchange.getResponseHeaders().set(\"Content-Type\", \"application/json\");\n+\n+    Map<String, String> params = getParamsMap(exchange.getRequestURI().getQuery());\n+\n+    try {\n+      // Parse and validate parameters\n+      String[] validParamsTmp = {\"\", \"metrics\", \"starttime\", \"endtime\", \"samplingperiod\", \"maxdatapoints\"};\n+      Set<String> validParams = new HashSet<>(Arrays.asList(validParamsTmp));\n+      for (String param : params.keySet()) {\n+        if (!validParams.contains(param)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid parameter\", param));\n+        }\n+      }\n+\n+      List<String> metrics = metricsRestUtil.parseArrayParam(params, \"metrics\", false);\n+      String startTimeParam = params.get(\"starttime\");\n+      String endTimeParam = params.get(\"endtime\");\n+      String samplingPeriodParam = params.get(\"samplingperiod\");\n+\n+      for (String metric : metrics) {\n+        if (!MetricsModel.ALL_METRICS.containsKey(metric)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid metric\", metric));\n+        }\n+      }\n+\n+      if (startTimeParam == null || startTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"starttime parameter must be set\");\n+      }\n+      long startTime;\n+      try {\n+        startTime = Long.parseUnsignedLong(startTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid starttime\", startTimeParam));\n+      }\n+\n+      if (endTimeParam == null || endTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"endtime parameter must be set\");\n+      }\n+      long endTime;\n+      try {\n+        endTime = Long.parseUnsignedLong(endTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid endtime\", endTimeParam));\n+      }\n+\n+      long samplingPeriod = DEFAULT_SAMPLING_PERIOD;\n+      if (samplingPeriodParam != null && !samplingPeriodParam.isEmpty()) {\n+        samplingPeriod = Long.parseLong(samplingPeriodParam);\n+        if (samplingPeriod < 5 || samplingPeriod % 5 != 0) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid sampling period\", samplingPeriodParam));\n+        }\n+        if (samplingPeriod >= PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60) {\n+          throw new InvalidParameterException(\"sampling period must be less than the retention period\");\n+        }\n+        samplingPeriod *= 1000;\n+      }\n+\n+      if (startTime >= endTime) {\n+        throw new InvalidParameterException(\"starttime must be less than the endtime\");\n+      }\n+      startTime -= startTime % samplingPeriod;\n+      endTime -= endTime % samplingPeriod;\n+      if (startTime == endTime) {\n+        throw new InvalidParameterException(\"starttime and endtime cannot be equal when rounded down to the nearest sampling period\");\n+      }\n+      if (endTime > currentTime) {\n+        throw new InvalidParameterException(\"endtime can be no greater than the system time at the node\");\n+      }\n+      if (startTime < currentTime - PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60 * 1000) {\n+        throw new InvalidParameterException(\"starttime must be within the retention period\");\n+      }\n+\n+      String queryResponse = queryFromBatchMetrics(batchMetrics, metrics, startTime, endTime, samplingPeriod,\n+              DEFAULT_MAX_DATAPOINTS);\n+      sendResponse(exchange, queryResponse, HttpURLConnection.HTTP_OK);\n+    } catch (InvalidParameterException e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.getMessage() + \".\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_BAD_REQUEST);\n+    } catch (Exception e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.toString() + \"\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_INTERNAL_ERROR);\n+    }\n+  }\n+\n+  @VisibleForTesting\n+  public int appendMetrics(Long timestamp, List<String> metrics, StringBuilder builder, int maxDatapoints) throws Exception {\n+    maxDatapoints += 1;\n+    builder.append(\"\\\"\");\n+    builder.append(timestamp);\n+    builder.append(\"\\\":{\");\n+    MetricsDB db = MetricsDB.fetchExisting(timestamp);\n+    for (int metricIndex = 0, numMetrics = metrics.size(); metricIndex < numMetrics; metricIndex++) {\n+      String metric = metrics.get(metricIndex);\n+      Result<Record> results = db.queryMetric(metric, MetricsModel.ALL_METRICS.get(metric).dimensionNames, maxDatapoints);\n+      if (results != null) {\n+        maxDatapoints -= results.size();\n+        if (maxDatapoints == 0) {\n+          throw new InvalidParameterException(String.format(\"requested data exceeds the %d datapoints limit\", DEFAULT_MAX_DATAPOINTS));\n+        }\n+        builder.append(\"\\\"\");\n+        builder.append(metric);\n+        builder.append(\"\\\":\");\n+        builder.append(results.formatJSON());\n+        for (metricIndex += 1; metricIndex < numMetrics; metricIndex++) {\n+          metric = metrics.get(metricIndex);\n+          results = db.queryMetric(metric, MetricsModel.ALL_METRICS.get(metric).dimensionNames, maxDatapoints);\n+          if (results != null) {\n+            maxDatapoints -= results.size();\n+            if (maxDatapoints == 0) {\n+              throw new InvalidParameterException(String.format(\"requested data exceeds the %d datapoints limit\", DEFAULT_MAX_DATAPOINTS));\n+            }\n+            builder.append(\",\\\"\");\n+            builder.append(metric);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTUzOTAyNw=="}, "originalCommit": {"oid": "e2f856bf687d4749dc4d3ebec026aa0a6b06c2ef"}, "originalPosition": 263}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAwMjc0NDMzOnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandler.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQxNTo0Njo1OFrOHJ-WMw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wMVQyMjo0NzozN1rOHLK1TA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDIyMDcyMw==", "bodyText": "nit: indicate this is in millis", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r480220723", "createdAt": "2020-08-31T15:46:58Z", "author": {"login": "vigyasharma"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandler.java", "diffHunk": "@@ -0,0 +1,309 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rest;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatExceptionCode;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatsCollector;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.config.PluginSettings;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metrics.MetricsRestUtil;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.model.MetricsModel;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.net.NetClient;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ReaderMetricsProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.sun.net.httpserver.HttpExchange;\n+import com.sun.net.httpserver.HttpHandler;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.net.HttpURLConnection;\n+import java.security.InvalidParameterException;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.NavigableSet;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.logging.log4j.util.Supplier;\n+import org.jooq.Record;\n+import org.jooq.Result;\n+\n+/**\n+ * Request handler that supports querying batch metrics from an EC2 instance\n+ *\n+ * <p>Return 1 minute of CPU_Utilization metrics sampled at a 5s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization&starttime=1566413975000&endtime=1566413980000\"\n+ *\n+ * <p>Return 1 minute of CPU_Utilization and Latency metrics sampled at a 10s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization,Latency&starttime=1566413975000&endtime=1566413980000&samplingperiod=10\"\n+ *\n+ * <p>Return format:\n+ * {\n+ *   \"1594412650000\": {\n+ *     \"CPU_Utilization\": {\n+ *       \"fields\": [\n+ *         {\n+ *           \"name: \"IndexName\",\n+ *           \"type\": \"VARCHAR\"\n+ *         },\n+ *         <...>\n+ *       ]\n+ *       \"records\": [\n+ *         [\n+ *           \"pmc\",\n+ *           <...>\n+ *         ],\n+ *         <...>\n+ *       ]\n+ *     }\n+ *   }\n+ * }\n+ */\n+public class QueryBatchRequestHandler extends MetricsHandler implements HttpHandler {\n+\n+  private static final Logger LOG = LogManager.getLogger(QueryBatchRequestHandler.class);\n+\n+  private static final int TIME_OUT_VALUE = 2;\n+  private static final TimeUnit TIME_OUT_UNIT = TimeUnit.SECONDS;\n+  private NetClient netClient;\n+  MetricsRestUtil metricsRestUtil;\n+\n+  public static final int DEFAULT_MAX_DATAPOINTS = 100800;  // Must be non-negative\n+  public static final long DEFAULT_SAMPLING_PERIOD = 5000;  // Must be a multiple of 5000", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2f856bf687d4749dc4d3ebec026aa0a6b06c2ef"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQ3Mzg2OA==", "bodyText": "Sure", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r481473868", "createdAt": "2020-09-01T22:47:37Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandler.java", "diffHunk": "@@ -0,0 +1,309 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rest;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatExceptionCode;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatsCollector;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.config.PluginSettings;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metrics.MetricsRestUtil;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.model.MetricsModel;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.net.NetClient;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ReaderMetricsProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.sun.net.httpserver.HttpExchange;\n+import com.sun.net.httpserver.HttpHandler;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.net.HttpURLConnection;\n+import java.security.InvalidParameterException;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.NavigableSet;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.logging.log4j.util.Supplier;\n+import org.jooq.Record;\n+import org.jooq.Result;\n+\n+/**\n+ * Request handler that supports querying batch metrics from an EC2 instance\n+ *\n+ * <p>Return 1 minute of CPU_Utilization metrics sampled at a 5s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization&starttime=1566413975000&endtime=1566413980000\"\n+ *\n+ * <p>Return 1 minute of CPU_Utilization and Latency metrics sampled at a 10s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization,Latency&starttime=1566413975000&endtime=1566413980000&samplingperiod=10\"\n+ *\n+ * <p>Return format:\n+ * {\n+ *   \"1594412650000\": {\n+ *     \"CPU_Utilization\": {\n+ *       \"fields\": [\n+ *         {\n+ *           \"name: \"IndexName\",\n+ *           \"type\": \"VARCHAR\"\n+ *         },\n+ *         <...>\n+ *       ]\n+ *       \"records\": [\n+ *         [\n+ *           \"pmc\",\n+ *           <...>\n+ *         ],\n+ *         <...>\n+ *       ]\n+ *     }\n+ *   }\n+ * }\n+ */\n+public class QueryBatchRequestHandler extends MetricsHandler implements HttpHandler {\n+\n+  private static final Logger LOG = LogManager.getLogger(QueryBatchRequestHandler.class);\n+\n+  private static final int TIME_OUT_VALUE = 2;\n+  private static final TimeUnit TIME_OUT_UNIT = TimeUnit.SECONDS;\n+  private NetClient netClient;\n+  MetricsRestUtil metricsRestUtil;\n+\n+  public static final int DEFAULT_MAX_DATAPOINTS = 100800;  // Must be non-negative\n+  public static final long DEFAULT_SAMPLING_PERIOD = 5000;  // Must be a multiple of 5000", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDIyMDcyMw=="}, "originalCommit": {"oid": "e2f856bf687d4749dc4d3ebec026aa0a6b06c2ef"}, "originalPosition": 88}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAwMjc3MDU4OnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandler.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQxNTo1MzozNlrOHJ-l2A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQyMzo0MToxMlrOHOxiLg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDIyNDcyOA==", "bodyText": "Can results.size() be > maxDatapoints ? Can DEFAULT_MAX_DATAPOINTS be overridden by any config (in which case we should use the derived limit in msg or simply maxDatapoints) ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r480224728", "createdAt": "2020-08-31T15:53:36Z", "author": {"login": "vigyasharma"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandler.java", "diffHunk": "@@ -0,0 +1,309 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rest;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatExceptionCode;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatsCollector;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.config.PluginSettings;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metrics.MetricsRestUtil;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.model.MetricsModel;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.net.NetClient;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ReaderMetricsProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.sun.net.httpserver.HttpExchange;\n+import com.sun.net.httpserver.HttpHandler;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.net.HttpURLConnection;\n+import java.security.InvalidParameterException;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.NavigableSet;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.logging.log4j.util.Supplier;\n+import org.jooq.Record;\n+import org.jooq.Result;\n+\n+/**\n+ * Request handler that supports querying batch metrics from an EC2 instance\n+ *\n+ * <p>Return 1 minute of CPU_Utilization metrics sampled at a 5s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization&starttime=1566413975000&endtime=1566413980000\"\n+ *\n+ * <p>Return 1 minute of CPU_Utilization and Latency metrics sampled at a 10s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization,Latency&starttime=1566413975000&endtime=1566413980000&samplingperiod=10\"\n+ *\n+ * <p>Return format:\n+ * {\n+ *   \"1594412650000\": {\n+ *     \"CPU_Utilization\": {\n+ *       \"fields\": [\n+ *         {\n+ *           \"name: \"IndexName\",\n+ *           \"type\": \"VARCHAR\"\n+ *         },\n+ *         <...>\n+ *       ]\n+ *       \"records\": [\n+ *         [\n+ *           \"pmc\",\n+ *           <...>\n+ *         ],\n+ *         <...>\n+ *       ]\n+ *     }\n+ *   }\n+ * }\n+ */\n+public class QueryBatchRequestHandler extends MetricsHandler implements HttpHandler {\n+\n+  private static final Logger LOG = LogManager.getLogger(QueryBatchRequestHandler.class);\n+\n+  private static final int TIME_OUT_VALUE = 2;\n+  private static final TimeUnit TIME_OUT_UNIT = TimeUnit.SECONDS;\n+  private NetClient netClient;\n+  MetricsRestUtil metricsRestUtil;\n+\n+  public static final int DEFAULT_MAX_DATAPOINTS = 100800;  // Must be non-negative\n+  public static final long DEFAULT_SAMPLING_PERIOD = 5000;  // Must be a multiple of 5000\n+\n+  public QueryBatchRequestHandler(NetClient netClient, MetricsRestUtil metricsRestUtil) {\n+    this.netClient = netClient;\n+    this.metricsRestUtil = metricsRestUtil;\n+  }\n+\n+  @Override\n+  public void handle(HttpExchange exchange) throws IOException {\n+    String requestMethod = exchange.getRequestMethod();\n+    if (!requestMethod.equalsIgnoreCase(\"GET\")) {\n+      exchange.sendResponseHeaders(HttpURLConnection.HTTP_NOT_FOUND, -1);\n+      exchange.close();\n+      return;\n+    }\n+\n+    ReaderMetricsProcessor mp = ReaderMetricsProcessor.getInstance();\n+    if (mp == null) {\n+      sendResponse(\n+          exchange,\n+          \"{\\\"error\\\":\\\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\\\"}\",\n+          HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    NavigableSet<Long> batchMetrics = mp.getBatchMetrics();\n+    long currentTime = System.currentTimeMillis();\n+    if (batchMetrics == null) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"The batch metrics api has not been enabled for this node.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"The batch metrics api has not been enabled for this node.\");\n+      return;\n+    }\n+    if (batchMetrics.isEmpty()) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"There are no metrics databases. The reader has run into an issue or has just started.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"There are no metrics databases. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    exchange.getResponseHeaders().set(\"Content-Type\", \"application/json\");\n+\n+    Map<String, String> params = getParamsMap(exchange.getRequestURI().getQuery());\n+\n+    try {\n+      // Parse and validate parameters\n+      String[] validParamsTmp = {\"\", \"metrics\", \"starttime\", \"endtime\", \"samplingperiod\", \"maxdatapoints\"};\n+      Set<String> validParams = new HashSet<>(Arrays.asList(validParamsTmp));\n+      for (String param : params.keySet()) {\n+        if (!validParams.contains(param)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid parameter\", param));\n+        }\n+      }\n+\n+      List<String> metrics = metricsRestUtil.parseArrayParam(params, \"metrics\", false);\n+      String startTimeParam = params.get(\"starttime\");\n+      String endTimeParam = params.get(\"endtime\");\n+      String samplingPeriodParam = params.get(\"samplingperiod\");\n+\n+      for (String metric : metrics) {\n+        if (!MetricsModel.ALL_METRICS.containsKey(metric)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid metric\", metric));\n+        }\n+      }\n+\n+      if (startTimeParam == null || startTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"starttime parameter must be set\");\n+      }\n+      long startTime;\n+      try {\n+        startTime = Long.parseUnsignedLong(startTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid starttime\", startTimeParam));\n+      }\n+\n+      if (endTimeParam == null || endTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"endtime parameter must be set\");\n+      }\n+      long endTime;\n+      try {\n+        endTime = Long.parseUnsignedLong(endTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid endtime\", endTimeParam));\n+      }\n+\n+      long samplingPeriod = DEFAULT_SAMPLING_PERIOD;\n+      if (samplingPeriodParam != null && !samplingPeriodParam.isEmpty()) {\n+        samplingPeriod = Long.parseLong(samplingPeriodParam);\n+        if (samplingPeriod < 5 || samplingPeriod % 5 != 0) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid sampling period\", samplingPeriodParam));\n+        }\n+        if (samplingPeriod >= PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60) {\n+          throw new InvalidParameterException(\"sampling period must be less than the retention period\");\n+        }\n+        samplingPeriod *= 1000;\n+      }\n+\n+      if (startTime >= endTime) {\n+        throw new InvalidParameterException(\"starttime must be less than the endtime\");\n+      }\n+      startTime -= startTime % samplingPeriod;\n+      endTime -= endTime % samplingPeriod;\n+      if (startTime == endTime) {\n+        throw new InvalidParameterException(\"starttime and endtime cannot be equal when rounded down to the nearest sampling period\");\n+      }\n+      if (endTime > currentTime) {\n+        throw new InvalidParameterException(\"endtime can be no greater than the system time at the node\");\n+      }\n+      if (startTime < currentTime - PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60 * 1000) {\n+        throw new InvalidParameterException(\"starttime must be within the retention period\");\n+      }\n+\n+      String queryResponse = queryFromBatchMetrics(batchMetrics, metrics, startTime, endTime, samplingPeriod,\n+              DEFAULT_MAX_DATAPOINTS);\n+      sendResponse(exchange, queryResponse, HttpURLConnection.HTTP_OK);\n+    } catch (InvalidParameterException e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.getMessage() + \".\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_BAD_REQUEST);\n+    } catch (Exception e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.toString() + \"\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_INTERNAL_ERROR);\n+    }\n+  }\n+\n+  @VisibleForTesting\n+  public int appendMetrics(Long timestamp, List<String> metrics, StringBuilder builder, int maxDatapoints) throws Exception {\n+    maxDatapoints += 1;\n+    builder.append(\"\\\"\");\n+    builder.append(timestamp);\n+    builder.append(\"\\\":{\");\n+    MetricsDB db = MetricsDB.fetchExisting(timestamp);\n+    for (int metricIndex = 0, numMetrics = metrics.size(); metricIndex < numMetrics; metricIndex++) {\n+      String metric = metrics.get(metricIndex);\n+      Result<Record> results = db.queryMetric(metric, MetricsModel.ALL_METRICS.get(metric).dimensionNames, maxDatapoints);\n+      if (results != null) {\n+        maxDatapoints -= results.size();\n+        if (maxDatapoints == 0) {\n+          throw new InvalidParameterException(String.format(\"requested data exceeds the %d datapoints limit\", DEFAULT_MAX_DATAPOINTS));\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2f856bf687d4749dc4d3ebec026aa0a6b06c2ef"}, "originalPosition": 249}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MTQ3ODE3Ng==", "bodyText": "results.size() cannot be  cannot be > maxDatapoints, since maxDatapoints is supplied as the limit when invoking db.queryMetric.\nDEFAULT_MAX_DATAPOINTS cannot be overridden. It is an internal safeguard to ensure that the user does not break their system by exceeding a memory limit. Even if we allowed the user to configure the max datapoints, we would still need an internal limit to ensure no excessive values are supplied. Until more clear internal limits are identified, we ought to leave configurability off the table in favor of safety. Additionally, these changes may further be obviated if pagination is introduced in the future.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r481478176", "createdAt": "2020-09-01T23:00:36Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandler.java", "diffHunk": "@@ -0,0 +1,309 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rest;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatExceptionCode;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatsCollector;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.config.PluginSettings;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metrics.MetricsRestUtil;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.model.MetricsModel;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.net.NetClient;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ReaderMetricsProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.sun.net.httpserver.HttpExchange;\n+import com.sun.net.httpserver.HttpHandler;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.net.HttpURLConnection;\n+import java.security.InvalidParameterException;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.NavigableSet;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.logging.log4j.util.Supplier;\n+import org.jooq.Record;\n+import org.jooq.Result;\n+\n+/**\n+ * Request handler that supports querying batch metrics from an EC2 instance\n+ *\n+ * <p>Return 1 minute of CPU_Utilization metrics sampled at a 5s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization&starttime=1566413975000&endtime=1566413980000\"\n+ *\n+ * <p>Return 1 minute of CPU_Utilization and Latency metrics sampled at a 10s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization,Latency&starttime=1566413975000&endtime=1566413980000&samplingperiod=10\"\n+ *\n+ * <p>Return format:\n+ * {\n+ *   \"1594412650000\": {\n+ *     \"CPU_Utilization\": {\n+ *       \"fields\": [\n+ *         {\n+ *           \"name: \"IndexName\",\n+ *           \"type\": \"VARCHAR\"\n+ *         },\n+ *         <...>\n+ *       ]\n+ *       \"records\": [\n+ *         [\n+ *           \"pmc\",\n+ *           <...>\n+ *         ],\n+ *         <...>\n+ *       ]\n+ *     }\n+ *   }\n+ * }\n+ */\n+public class QueryBatchRequestHandler extends MetricsHandler implements HttpHandler {\n+\n+  private static final Logger LOG = LogManager.getLogger(QueryBatchRequestHandler.class);\n+\n+  private static final int TIME_OUT_VALUE = 2;\n+  private static final TimeUnit TIME_OUT_UNIT = TimeUnit.SECONDS;\n+  private NetClient netClient;\n+  MetricsRestUtil metricsRestUtil;\n+\n+  public static final int DEFAULT_MAX_DATAPOINTS = 100800;  // Must be non-negative\n+  public static final long DEFAULT_SAMPLING_PERIOD = 5000;  // Must be a multiple of 5000\n+\n+  public QueryBatchRequestHandler(NetClient netClient, MetricsRestUtil metricsRestUtil) {\n+    this.netClient = netClient;\n+    this.metricsRestUtil = metricsRestUtil;\n+  }\n+\n+  @Override\n+  public void handle(HttpExchange exchange) throws IOException {\n+    String requestMethod = exchange.getRequestMethod();\n+    if (!requestMethod.equalsIgnoreCase(\"GET\")) {\n+      exchange.sendResponseHeaders(HttpURLConnection.HTTP_NOT_FOUND, -1);\n+      exchange.close();\n+      return;\n+    }\n+\n+    ReaderMetricsProcessor mp = ReaderMetricsProcessor.getInstance();\n+    if (mp == null) {\n+      sendResponse(\n+          exchange,\n+          \"{\\\"error\\\":\\\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\\\"}\",\n+          HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    NavigableSet<Long> batchMetrics = mp.getBatchMetrics();\n+    long currentTime = System.currentTimeMillis();\n+    if (batchMetrics == null) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"The batch metrics api has not been enabled for this node.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"The batch metrics api has not been enabled for this node.\");\n+      return;\n+    }\n+    if (batchMetrics.isEmpty()) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"There are no metrics databases. The reader has run into an issue or has just started.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"There are no metrics databases. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    exchange.getResponseHeaders().set(\"Content-Type\", \"application/json\");\n+\n+    Map<String, String> params = getParamsMap(exchange.getRequestURI().getQuery());\n+\n+    try {\n+      // Parse and validate parameters\n+      String[] validParamsTmp = {\"\", \"metrics\", \"starttime\", \"endtime\", \"samplingperiod\", \"maxdatapoints\"};\n+      Set<String> validParams = new HashSet<>(Arrays.asList(validParamsTmp));\n+      for (String param : params.keySet()) {\n+        if (!validParams.contains(param)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid parameter\", param));\n+        }\n+      }\n+\n+      List<String> metrics = metricsRestUtil.parseArrayParam(params, \"metrics\", false);\n+      String startTimeParam = params.get(\"starttime\");\n+      String endTimeParam = params.get(\"endtime\");\n+      String samplingPeriodParam = params.get(\"samplingperiod\");\n+\n+      for (String metric : metrics) {\n+        if (!MetricsModel.ALL_METRICS.containsKey(metric)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid metric\", metric));\n+        }\n+      }\n+\n+      if (startTimeParam == null || startTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"starttime parameter must be set\");\n+      }\n+      long startTime;\n+      try {\n+        startTime = Long.parseUnsignedLong(startTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid starttime\", startTimeParam));\n+      }\n+\n+      if (endTimeParam == null || endTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"endtime parameter must be set\");\n+      }\n+      long endTime;\n+      try {\n+        endTime = Long.parseUnsignedLong(endTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid endtime\", endTimeParam));\n+      }\n+\n+      long samplingPeriod = DEFAULT_SAMPLING_PERIOD;\n+      if (samplingPeriodParam != null && !samplingPeriodParam.isEmpty()) {\n+        samplingPeriod = Long.parseLong(samplingPeriodParam);\n+        if (samplingPeriod < 5 || samplingPeriod % 5 != 0) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid sampling period\", samplingPeriodParam));\n+        }\n+        if (samplingPeriod >= PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60) {\n+          throw new InvalidParameterException(\"sampling period must be less than the retention period\");\n+        }\n+        samplingPeriod *= 1000;\n+      }\n+\n+      if (startTime >= endTime) {\n+        throw new InvalidParameterException(\"starttime must be less than the endtime\");\n+      }\n+      startTime -= startTime % samplingPeriod;\n+      endTime -= endTime % samplingPeriod;\n+      if (startTime == endTime) {\n+        throw new InvalidParameterException(\"starttime and endtime cannot be equal when rounded down to the nearest sampling period\");\n+      }\n+      if (endTime > currentTime) {\n+        throw new InvalidParameterException(\"endtime can be no greater than the system time at the node\");\n+      }\n+      if (startTime < currentTime - PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60 * 1000) {\n+        throw new InvalidParameterException(\"starttime must be within the retention period\");\n+      }\n+\n+      String queryResponse = queryFromBatchMetrics(batchMetrics, metrics, startTime, endTime, samplingPeriod,\n+              DEFAULT_MAX_DATAPOINTS);\n+      sendResponse(exchange, queryResponse, HttpURLConnection.HTTP_OK);\n+    } catch (InvalidParameterException e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.getMessage() + \".\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_BAD_REQUEST);\n+    } catch (Exception e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.toString() + \"\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_INTERNAL_ERROR);\n+    }\n+  }\n+\n+  @VisibleForTesting\n+  public int appendMetrics(Long timestamp, List<String> metrics, StringBuilder builder, int maxDatapoints) throws Exception {\n+    maxDatapoints += 1;\n+    builder.append(\"\\\"\");\n+    builder.append(timestamp);\n+    builder.append(\"\\\":{\");\n+    MetricsDB db = MetricsDB.fetchExisting(timestamp);\n+    for (int metricIndex = 0, numMetrics = metrics.size(); metricIndex < numMetrics; metricIndex++) {\n+      String metric = metrics.get(metricIndex);\n+      Result<Record> results = db.queryMetric(metric, MetricsModel.ALL_METRICS.get(metric).dimensionNames, maxDatapoints);\n+      if (results != null) {\n+        maxDatapoints -= results.size();\n+        if (maxDatapoints == 0) {\n+          throw new InvalidParameterException(String.format(\"requested data exceeds the %d datapoints limit\", DEFAULT_MAX_DATAPOINTS));\n+        }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDIyNDcyOA=="}, "originalCommit": {"oid": "e2f856bf687d4749dc4d3ebec026aa0a6b06c2ef"}, "originalPosition": 249}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTIyOTI0Ng==", "bodyText": "What I meant was that if (maxDatapoints == 0) is a very exact check. We might want <= instead?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485229246", "createdAt": "2020-09-08T22:26:57Z", "author": {"login": "vigyasharma"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandler.java", "diffHunk": "@@ -0,0 +1,309 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rest;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatExceptionCode;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatsCollector;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.config.PluginSettings;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metrics.MetricsRestUtil;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.model.MetricsModel;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.net.NetClient;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ReaderMetricsProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.sun.net.httpserver.HttpExchange;\n+import com.sun.net.httpserver.HttpHandler;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.net.HttpURLConnection;\n+import java.security.InvalidParameterException;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.NavigableSet;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.logging.log4j.util.Supplier;\n+import org.jooq.Record;\n+import org.jooq.Result;\n+\n+/**\n+ * Request handler that supports querying batch metrics from an EC2 instance\n+ *\n+ * <p>Return 1 minute of CPU_Utilization metrics sampled at a 5s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization&starttime=1566413975000&endtime=1566413980000\"\n+ *\n+ * <p>Return 1 minute of CPU_Utilization and Latency metrics sampled at a 10s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization,Latency&starttime=1566413975000&endtime=1566413980000&samplingperiod=10\"\n+ *\n+ * <p>Return format:\n+ * {\n+ *   \"1594412650000\": {\n+ *     \"CPU_Utilization\": {\n+ *       \"fields\": [\n+ *         {\n+ *           \"name: \"IndexName\",\n+ *           \"type\": \"VARCHAR\"\n+ *         },\n+ *         <...>\n+ *       ]\n+ *       \"records\": [\n+ *         [\n+ *           \"pmc\",\n+ *           <...>\n+ *         ],\n+ *         <...>\n+ *       ]\n+ *     }\n+ *   }\n+ * }\n+ */\n+public class QueryBatchRequestHandler extends MetricsHandler implements HttpHandler {\n+\n+  private static final Logger LOG = LogManager.getLogger(QueryBatchRequestHandler.class);\n+\n+  private static final int TIME_OUT_VALUE = 2;\n+  private static final TimeUnit TIME_OUT_UNIT = TimeUnit.SECONDS;\n+  private NetClient netClient;\n+  MetricsRestUtil metricsRestUtil;\n+\n+  public static final int DEFAULT_MAX_DATAPOINTS = 100800;  // Must be non-negative\n+  public static final long DEFAULT_SAMPLING_PERIOD = 5000;  // Must be a multiple of 5000\n+\n+  public QueryBatchRequestHandler(NetClient netClient, MetricsRestUtil metricsRestUtil) {\n+    this.netClient = netClient;\n+    this.metricsRestUtil = metricsRestUtil;\n+  }\n+\n+  @Override\n+  public void handle(HttpExchange exchange) throws IOException {\n+    String requestMethod = exchange.getRequestMethod();\n+    if (!requestMethod.equalsIgnoreCase(\"GET\")) {\n+      exchange.sendResponseHeaders(HttpURLConnection.HTTP_NOT_FOUND, -1);\n+      exchange.close();\n+      return;\n+    }\n+\n+    ReaderMetricsProcessor mp = ReaderMetricsProcessor.getInstance();\n+    if (mp == null) {\n+      sendResponse(\n+          exchange,\n+          \"{\\\"error\\\":\\\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\\\"}\",\n+          HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    NavigableSet<Long> batchMetrics = mp.getBatchMetrics();\n+    long currentTime = System.currentTimeMillis();\n+    if (batchMetrics == null) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"The batch metrics api has not been enabled for this node.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"The batch metrics api has not been enabled for this node.\");\n+      return;\n+    }\n+    if (batchMetrics.isEmpty()) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"There are no metrics databases. The reader has run into an issue or has just started.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"There are no metrics databases. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    exchange.getResponseHeaders().set(\"Content-Type\", \"application/json\");\n+\n+    Map<String, String> params = getParamsMap(exchange.getRequestURI().getQuery());\n+\n+    try {\n+      // Parse and validate parameters\n+      String[] validParamsTmp = {\"\", \"metrics\", \"starttime\", \"endtime\", \"samplingperiod\", \"maxdatapoints\"};\n+      Set<String> validParams = new HashSet<>(Arrays.asList(validParamsTmp));\n+      for (String param : params.keySet()) {\n+        if (!validParams.contains(param)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid parameter\", param));\n+        }\n+      }\n+\n+      List<String> metrics = metricsRestUtil.parseArrayParam(params, \"metrics\", false);\n+      String startTimeParam = params.get(\"starttime\");\n+      String endTimeParam = params.get(\"endtime\");\n+      String samplingPeriodParam = params.get(\"samplingperiod\");\n+\n+      for (String metric : metrics) {\n+        if (!MetricsModel.ALL_METRICS.containsKey(metric)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid metric\", metric));\n+        }\n+      }\n+\n+      if (startTimeParam == null || startTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"starttime parameter must be set\");\n+      }\n+      long startTime;\n+      try {\n+        startTime = Long.parseUnsignedLong(startTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid starttime\", startTimeParam));\n+      }\n+\n+      if (endTimeParam == null || endTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"endtime parameter must be set\");\n+      }\n+      long endTime;\n+      try {\n+        endTime = Long.parseUnsignedLong(endTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid endtime\", endTimeParam));\n+      }\n+\n+      long samplingPeriod = DEFAULT_SAMPLING_PERIOD;\n+      if (samplingPeriodParam != null && !samplingPeriodParam.isEmpty()) {\n+        samplingPeriod = Long.parseLong(samplingPeriodParam);\n+        if (samplingPeriod < 5 || samplingPeriod % 5 != 0) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid sampling period\", samplingPeriodParam));\n+        }\n+        if (samplingPeriod >= PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60) {\n+          throw new InvalidParameterException(\"sampling period must be less than the retention period\");\n+        }\n+        samplingPeriod *= 1000;\n+      }\n+\n+      if (startTime >= endTime) {\n+        throw new InvalidParameterException(\"starttime must be less than the endtime\");\n+      }\n+      startTime -= startTime % samplingPeriod;\n+      endTime -= endTime % samplingPeriod;\n+      if (startTime == endTime) {\n+        throw new InvalidParameterException(\"starttime and endtime cannot be equal when rounded down to the nearest sampling period\");\n+      }\n+      if (endTime > currentTime) {\n+        throw new InvalidParameterException(\"endtime can be no greater than the system time at the node\");\n+      }\n+      if (startTime < currentTime - PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60 * 1000) {\n+        throw new InvalidParameterException(\"starttime must be within the retention period\");\n+      }\n+\n+      String queryResponse = queryFromBatchMetrics(batchMetrics, metrics, startTime, endTime, samplingPeriod,\n+              DEFAULT_MAX_DATAPOINTS);\n+      sendResponse(exchange, queryResponse, HttpURLConnection.HTTP_OK);\n+    } catch (InvalidParameterException e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.getMessage() + \".\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_BAD_REQUEST);\n+    } catch (Exception e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.toString() + \"\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_INTERNAL_ERROR);\n+    }\n+  }\n+\n+  @VisibleForTesting\n+  public int appendMetrics(Long timestamp, List<String> metrics, StringBuilder builder, int maxDatapoints) throws Exception {\n+    maxDatapoints += 1;\n+    builder.append(\"\\\"\");\n+    builder.append(timestamp);\n+    builder.append(\"\\\":{\");\n+    MetricsDB db = MetricsDB.fetchExisting(timestamp);\n+    for (int metricIndex = 0, numMetrics = metrics.size(); metricIndex < numMetrics; metricIndex++) {\n+      String metric = metrics.get(metricIndex);\n+      Result<Record> results = db.queryMetric(metric, MetricsModel.ALL_METRICS.get(metric).dimensionNames, maxDatapoints);\n+      if (results != null) {\n+        maxDatapoints -= results.size();\n+        if (maxDatapoints == 0) {\n+          throw new InvalidParameterException(String.format(\"requested data exceeds the %d datapoints limit\", DEFAULT_MAX_DATAPOINTS));\n+        }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDIyNDcyOA=="}, "originalCommit": {"oid": "e2f856bf687d4749dc4d3ebec026aa0a6b06c2ef"}, "originalPosition": 249}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTI1MzY3OA==", "bodyText": "Logically, maxDatapoints should never be less than zero. But, sure.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485253678", "createdAt": "2020-09-08T23:41:12Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandler.java", "diffHunk": "@@ -0,0 +1,309 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rest;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatExceptionCode;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatsCollector;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.config.PluginSettings;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metrics.MetricsRestUtil;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.model.MetricsModel;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.net.NetClient;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ReaderMetricsProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.sun.net.httpserver.HttpExchange;\n+import com.sun.net.httpserver.HttpHandler;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.net.HttpURLConnection;\n+import java.security.InvalidParameterException;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.NavigableSet;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.logging.log4j.util.Supplier;\n+import org.jooq.Record;\n+import org.jooq.Result;\n+\n+/**\n+ * Request handler that supports querying batch metrics from an EC2 instance\n+ *\n+ * <p>Return 1 minute of CPU_Utilization metrics sampled at a 5s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization&starttime=1566413975000&endtime=1566413980000\"\n+ *\n+ * <p>Return 1 minute of CPU_Utilization and Latency metrics sampled at a 10s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization,Latency&starttime=1566413975000&endtime=1566413980000&samplingperiod=10\"\n+ *\n+ * <p>Return format:\n+ * {\n+ *   \"1594412650000\": {\n+ *     \"CPU_Utilization\": {\n+ *       \"fields\": [\n+ *         {\n+ *           \"name: \"IndexName\",\n+ *           \"type\": \"VARCHAR\"\n+ *         },\n+ *         <...>\n+ *       ]\n+ *       \"records\": [\n+ *         [\n+ *           \"pmc\",\n+ *           <...>\n+ *         ],\n+ *         <...>\n+ *       ]\n+ *     }\n+ *   }\n+ * }\n+ */\n+public class QueryBatchRequestHandler extends MetricsHandler implements HttpHandler {\n+\n+  private static final Logger LOG = LogManager.getLogger(QueryBatchRequestHandler.class);\n+\n+  private static final int TIME_OUT_VALUE = 2;\n+  private static final TimeUnit TIME_OUT_UNIT = TimeUnit.SECONDS;\n+  private NetClient netClient;\n+  MetricsRestUtil metricsRestUtil;\n+\n+  public static final int DEFAULT_MAX_DATAPOINTS = 100800;  // Must be non-negative\n+  public static final long DEFAULT_SAMPLING_PERIOD = 5000;  // Must be a multiple of 5000\n+\n+  public QueryBatchRequestHandler(NetClient netClient, MetricsRestUtil metricsRestUtil) {\n+    this.netClient = netClient;\n+    this.metricsRestUtil = metricsRestUtil;\n+  }\n+\n+  @Override\n+  public void handle(HttpExchange exchange) throws IOException {\n+    String requestMethod = exchange.getRequestMethod();\n+    if (!requestMethod.equalsIgnoreCase(\"GET\")) {\n+      exchange.sendResponseHeaders(HttpURLConnection.HTTP_NOT_FOUND, -1);\n+      exchange.close();\n+      return;\n+    }\n+\n+    ReaderMetricsProcessor mp = ReaderMetricsProcessor.getInstance();\n+    if (mp == null) {\n+      sendResponse(\n+          exchange,\n+          \"{\\\"error\\\":\\\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\\\"}\",\n+          HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    NavigableSet<Long> batchMetrics = mp.getBatchMetrics();\n+    long currentTime = System.currentTimeMillis();\n+    if (batchMetrics == null) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"The batch metrics api has not been enabled for this node.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"The batch metrics api has not been enabled for this node.\");\n+      return;\n+    }\n+    if (batchMetrics.isEmpty()) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"There are no metrics databases. The reader has run into an issue or has just started.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"There are no metrics databases. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    exchange.getResponseHeaders().set(\"Content-Type\", \"application/json\");\n+\n+    Map<String, String> params = getParamsMap(exchange.getRequestURI().getQuery());\n+\n+    try {\n+      // Parse and validate parameters\n+      String[] validParamsTmp = {\"\", \"metrics\", \"starttime\", \"endtime\", \"samplingperiod\", \"maxdatapoints\"};\n+      Set<String> validParams = new HashSet<>(Arrays.asList(validParamsTmp));\n+      for (String param : params.keySet()) {\n+        if (!validParams.contains(param)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid parameter\", param));\n+        }\n+      }\n+\n+      List<String> metrics = metricsRestUtil.parseArrayParam(params, \"metrics\", false);\n+      String startTimeParam = params.get(\"starttime\");\n+      String endTimeParam = params.get(\"endtime\");\n+      String samplingPeriodParam = params.get(\"samplingperiod\");\n+\n+      for (String metric : metrics) {\n+        if (!MetricsModel.ALL_METRICS.containsKey(metric)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid metric\", metric));\n+        }\n+      }\n+\n+      if (startTimeParam == null || startTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"starttime parameter must be set\");\n+      }\n+      long startTime;\n+      try {\n+        startTime = Long.parseUnsignedLong(startTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid starttime\", startTimeParam));\n+      }\n+\n+      if (endTimeParam == null || endTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"endtime parameter must be set\");\n+      }\n+      long endTime;\n+      try {\n+        endTime = Long.parseUnsignedLong(endTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid endtime\", endTimeParam));\n+      }\n+\n+      long samplingPeriod = DEFAULT_SAMPLING_PERIOD;\n+      if (samplingPeriodParam != null && !samplingPeriodParam.isEmpty()) {\n+        samplingPeriod = Long.parseLong(samplingPeriodParam);\n+        if (samplingPeriod < 5 || samplingPeriod % 5 != 0) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid sampling period\", samplingPeriodParam));\n+        }\n+        if (samplingPeriod >= PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60) {\n+          throw new InvalidParameterException(\"sampling period must be less than the retention period\");\n+        }\n+        samplingPeriod *= 1000;\n+      }\n+\n+      if (startTime >= endTime) {\n+        throw new InvalidParameterException(\"starttime must be less than the endtime\");\n+      }\n+      startTime -= startTime % samplingPeriod;\n+      endTime -= endTime % samplingPeriod;\n+      if (startTime == endTime) {\n+        throw new InvalidParameterException(\"starttime and endtime cannot be equal when rounded down to the nearest sampling period\");\n+      }\n+      if (endTime > currentTime) {\n+        throw new InvalidParameterException(\"endtime can be no greater than the system time at the node\");\n+      }\n+      if (startTime < currentTime - PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60 * 1000) {\n+        throw new InvalidParameterException(\"starttime must be within the retention period\");\n+      }\n+\n+      String queryResponse = queryFromBatchMetrics(batchMetrics, metrics, startTime, endTime, samplingPeriod,\n+              DEFAULT_MAX_DATAPOINTS);\n+      sendResponse(exchange, queryResponse, HttpURLConnection.HTTP_OK);\n+    } catch (InvalidParameterException e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.getMessage() + \".\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_BAD_REQUEST);\n+    } catch (Exception e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.toString() + \"\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_INTERNAL_ERROR);\n+    }\n+  }\n+\n+  @VisibleForTesting\n+  public int appendMetrics(Long timestamp, List<String> metrics, StringBuilder builder, int maxDatapoints) throws Exception {\n+    maxDatapoints += 1;\n+    builder.append(\"\\\"\");\n+    builder.append(timestamp);\n+    builder.append(\"\\\":{\");\n+    MetricsDB db = MetricsDB.fetchExisting(timestamp);\n+    for (int metricIndex = 0, numMetrics = metrics.size(); metricIndex < numMetrics; metricIndex++) {\n+      String metric = metrics.get(metricIndex);\n+      Result<Record> results = db.queryMetric(metric, MetricsModel.ALL_METRICS.get(metric).dimensionNames, maxDatapoints);\n+      if (results != null) {\n+        maxDatapoints -= results.size();\n+        if (maxDatapoints == 0) {\n+          throw new InvalidParameterException(String.format(\"requested data exceeds the %d datapoints limit\", DEFAULT_MAX_DATAPOINTS));\n+        }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDIyNDcyOA=="}, "originalCommit": {"oid": "e2f856bf687d4749dc4d3ebec026aa0a6b06c2ef"}, "originalPosition": 249}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNTMyNjU4OnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/config/PluginSettings.java", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQyMDo0MzozMFrOHNbBmw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxODoyMjo0NlrOHOo7lQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzgzNjMxNQ==", "bodyText": "I think that we should log error and use the default in this case. I would think of it as should I bail out of PA if someone configures a wrong value for batch metric retention period ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483836315", "createdAt": "2020-09-04T20:43:30Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/config/PluginSettings.java", "diffHunk": "@@ -271,4 +295,21 @@ private void loadMetricsDBFilesCleanupEnabled() {\n       shouldCleanupMetricsDBFiles = true;\n     }\n   }\n+\n+  private void loadBatchMetricsRetentionPeriodMinutesFromConfig() {\n+    if (!settings.containsKey(BATCH_METRICS_RETENTION_PERIOD_MINUTES)) {\n+      return;\n+    }\n+\n+    try {\n+      long parsedRetentionPeriod = Long.parseLong(settings.getProperty(BATCH_METRICS_RETENTION_PERIOD_MINUTES));\n+      if (parsedRetentionPeriod <= 0 || parsedRetentionPeriod > BATCH_METRICS_RETENTION_PERIOD_MINUTES_LIMIT) {\n+        throw new InvalidParameterException();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg2MjkzMA==", "bodyText": "That is what this code does. batchMetricsRetentionPeriodMinutes was assigned a default value in the ctor. The code here only updates that value if it was able to properly parse a new valid value from the properties file.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483862930", "createdAt": "2020-09-04T22:06:17Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/config/PluginSettings.java", "diffHunk": "@@ -271,4 +295,21 @@ private void loadMetricsDBFilesCleanupEnabled() {\n       shouldCleanupMetricsDBFiles = true;\n     }\n   }\n+\n+  private void loadBatchMetricsRetentionPeriodMinutesFromConfig() {\n+    if (!settings.containsKey(BATCH_METRICS_RETENTION_PERIOD_MINUTES)) {\n+      return;\n+    }\n+\n+    try {\n+      long parsedRetentionPeriod = Long.parseLong(settings.getProperty(BATCH_METRICS_RETENTION_PERIOD_MINUTES));\n+      if (parsedRetentionPeriod <= 0 || parsedRetentionPeriod > BATCH_METRICS_RETENTION_PERIOD_MINUTES_LIMIT) {\n+        throw new InvalidParameterException();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzgzNjMxNQ=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA4MDU2OA==", "bodyText": "Right, so you don't need to throw a InvalidParameterException, you can simple return ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485080568", "createdAt": "2020-09-08T17:23:08Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/config/PluginSettings.java", "diffHunk": "@@ -271,4 +295,21 @@ private void loadMetricsDBFilesCleanupEnabled() {\n       shouldCleanupMetricsDBFiles = true;\n     }\n   }\n+\n+  private void loadBatchMetricsRetentionPeriodMinutesFromConfig() {\n+    if (!settings.containsKey(BATCH_METRICS_RETENTION_PERIOD_MINUTES)) {\n+      return;\n+    }\n+\n+    try {\n+      long parsedRetentionPeriod = Long.parseLong(settings.getProperty(BATCH_METRICS_RETENTION_PERIOD_MINUTES));\n+      if (parsedRetentionPeriod <= 0 || parsedRetentionPeriod > BATCH_METRICS_RETENTION_PERIOD_MINUTES_LIMIT) {\n+        throw new InvalidParameterException();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzgzNjMxNQ=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA5OTg1NA==", "bodyText": "I am throwing an InvalidParameterException so I can catch it (along with the NumberFormatException that may be thrown by Long.parseLong) and log the error.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485099854", "createdAt": "2020-09-08T17:58:40Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/config/PluginSettings.java", "diffHunk": "@@ -271,4 +295,21 @@ private void loadMetricsDBFilesCleanupEnabled() {\n       shouldCleanupMetricsDBFiles = true;\n     }\n   }\n+\n+  private void loadBatchMetricsRetentionPeriodMinutesFromConfig() {\n+    if (!settings.containsKey(BATCH_METRICS_RETENTION_PERIOD_MINUTES)) {\n+      return;\n+    }\n+\n+    try {\n+      long parsedRetentionPeriod = Long.parseLong(settings.getProperty(BATCH_METRICS_RETENTION_PERIOD_MINUTES));\n+      if (parsedRetentionPeriod <= 0 || parsedRetentionPeriod > BATCH_METRICS_RETENTION_PERIOD_MINUTES_LIMIT) {\n+        throw new InvalidParameterException();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzgzNjMxNQ=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTExMjcyNQ==", "bodyText": "But yeah, it seems like it might be more appropriate to just give more user-friendly information about the value being out of range, like loadMetricsDeletionIntervalFromConfig is.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485112725", "createdAt": "2020-09-08T18:22:46Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/config/PluginSettings.java", "diffHunk": "@@ -271,4 +295,21 @@ private void loadMetricsDBFilesCleanupEnabled() {\n       shouldCleanupMetricsDBFiles = true;\n     }\n   }\n+\n+  private void loadBatchMetricsRetentionPeriodMinutesFromConfig() {\n+    if (!settings.containsKey(BATCH_METRICS_RETENTION_PERIOD_MINUTES)) {\n+      return;\n+    }\n+\n+    try {\n+      long parsedRetentionPeriod = Long.parseLong(settings.getProperty(BATCH_METRICS_RETENTION_PERIOD_MINUTES));\n+      if (parsedRetentionPeriod <= 0 || parsedRetentionPeriod > BATCH_METRICS_RETENTION_PERIOD_MINUTES_LIMIT) {\n+        throw new InvalidParameterException();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzgzNjMxNQ=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 97}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNTM3MjgzOnYy", "diffSide": "RIGHT", "path": "src/test/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandlerTest.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQyMTowNDozMlrOHNbdGQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQyMjowOTowN1rOHNcsXQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg0MzM1Mw==", "bodyText": "can we please make all method names camelCase ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483843353", "createdAt": "2020-09-04T21:04:32Z", "author": {"login": "yojs"}, "path": "src/test/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandlerTest.java", "diffHunk": "@@ -0,0 +1,516 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rest;\n+\n+import static com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ReaderMetricsProcessor.BATCH_METRICS_ENABLED_CONF_FILE;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.config.PluginSettings;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.core.Util;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metrics.MetricsConfiguration;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metrics.MetricsRestUtil;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.Dimensions;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.Metric;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.model.MetricsModel;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ReaderMetricsProcessor;\n+import com.sun.net.httpserver.Headers;\n+import com.sun.net.httpserver.HttpExchange;\n+\n+import java.io.File;\n+import java.io.FilenameFilter;\n+import java.io.IOException;\n+import java.net.HttpURLConnection;\n+import java.net.URI;\n+import java.nio.file.Files;\n+import java.nio.file.Paths;\n+import java.security.InvalidParameterException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.NavigableSet;\n+import java.util.TreeSet;\n+\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import org.mockito.ArgumentMatchers;\n+import org.mockito.Mockito;\n+\n+public class QueryBatchRequestHandlerTest {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg2MzY0NQ==", "bodyText": "The naming here makes use of the conventions outlined here:\nhttps://google.github.io/styleguide/javaguide.html#s5.2.3-method-names\nThere is also precedence here:\nhttps://github.com/opendistro-for-elasticsearch/performance-analyzer/blob/master/src/test/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/http_action/config/PerformanceAnalyzerResourceProviderTest.java", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483863645", "createdAt": "2020-09-04T22:09:07Z", "author": {"login": "ricardolstephen"}, "path": "src/test/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandlerTest.java", "diffHunk": "@@ -0,0 +1,516 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rest;\n+\n+import static com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ReaderMetricsProcessor.BATCH_METRICS_ENABLED_CONF_FILE;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.config.PluginSettings;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.core.Util;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metrics.MetricsConfiguration;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metrics.MetricsRestUtil;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.Dimensions;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.Metric;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.model.MetricsModel;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ReaderMetricsProcessor;\n+import com.sun.net.httpserver.Headers;\n+import com.sun.net.httpserver.HttpExchange;\n+\n+import java.io.File;\n+import java.io.FilenameFilter;\n+import java.io.IOException;\n+import java.net.HttpURLConnection;\n+import java.net.URI;\n+import java.nio.file.Files;\n+import java.nio.file.Paths;\n+import java.security.InvalidParameterException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.NavigableSet;\n+import java.util.TreeSet;\n+\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import org.mockito.ArgumentMatchers;\n+import org.mockito.Mockito;\n+\n+public class QueryBatchRequestHandlerTest {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg0MzM1Mw=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 53}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNTQzMzQxOnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQyMTozMzo0MVrOHNb_yQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQyMjoyOTo0NVrOHNc_JA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1MjIzMw==", "bodyText": "Will calling it the latest metricDB file be more appropriate ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483852233", "createdAt": "2020-09-04T21:33:41Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -84,6 +89,21 @@ public MetricsDB(long windowStartTime) throws Exception {\n     create = DSL.using(conn, SQLDialect.SQLITE);\n   }\n \n+  /**\n+   * Returns a MetricsDB handle associated with an existing metricsdb file.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg2ODQ1Mg==", "bodyText": "It would not. There may be 30 metricsdb files on disk. The user would call this method with the timestamp associated with one of them, and this method would return a MetricsDB handle to that file.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483868452", "createdAt": "2020-09-04T22:29:45Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -84,6 +89,21 @@ public MetricsDB(long windowStartTime) throws Exception {\n     create = DSL.using(conn, SQLDialect.SQLITE);\n   }\n \n+  /**\n+   * Returns a MetricsDB handle associated with an existing metricsdb file.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1MjIzMw=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 35}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNTQzNzk4OnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQyMTozNTo0OFrOHNcCUw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQyMjozMDo0OVrOHNdAHQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1Mjg4Mw==", "bodyText": "It might be more appropriate to say throws FileNotFoundException instead of throws Exception. Thoughts ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483852883", "createdAt": "2020-09-04T21:35:48Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -84,6 +89,21 @@ public MetricsDB(long windowStartTime) throws Exception {\n     create = DSL.using(conn, SQLDialect.SQLITE);\n   }\n \n+  /**\n+   * Returns a MetricsDB handle associated with an existing metricsdb file.\n+   *\n+   * @param windowStartTime the timestamp associated with an existing metricsdb file\n+   * @return a MetricsDB handle associated with the metricsdb file\n+   * @throws Exception if the metricsdb file does not exist or is invalid\n+   */\n+  public static MetricsDB fetchExisting(long windowStartTime) throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg2ODcwMQ==", "bodyText": "It would not. This method makes use of the MetricsDB ctor, which throws an Exception if there is some issue creating a connection to that file (like if the file is corrupt or something).", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483868701", "createdAt": "2020-09-04T22:30:49Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -84,6 +89,21 @@ public MetricsDB(long windowStartTime) throws Exception {\n     create = DSL.using(conn, SQLDialect.SQLITE);\n   }\n \n+  /**\n+   * Returns a MetricsDB handle associated with an existing metricsdb file.\n+   *\n+   * @param windowStartTime the timestamp associated with an existing metricsdb file\n+   * @return a MetricsDB handle associated with the metricsdb file\n+   * @throws Exception if the metricsdb file does not exist or is invalid\n+   */\n+  public static MetricsDB fetchExisting(long windowStartTime) throws Exception {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1Mjg4Mw=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNTQ0MDM1OnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQyMTozNjo1MFrOHNcDpA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQyMzozMDo0NlrOHNdtbA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1MzIyMA==", "bodyText": "All SQLite queries can throw DataExcessException. We might want to add it to the method signature ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483853220", "createdAt": "2020-09-04T21:36:50Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -235,10 +255,39 @@ public void putMetric(Metric<Double> metric, Dimensions dimensions, long windowS\n     return create.select(allFields).from(finalTable).groupBy(groupByFields).fetch();\n   }\n \n+  /**\n+   * Queries all the data associated with the given metric.\n+   *\n+   * @param metric the desired metric\n+   * @return the result of the query\n+   */\n   public Result<Record> queryMetric(String metric) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg4MDMwMA==", "bodyText": "That method is not part of this PR. Just some additional documentation was added. Will open a new ticket about it: #412", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483880300", "createdAt": "2020-09-04T23:30:46Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -235,10 +255,39 @@ public void putMetric(Metric<Double> metric, Dimensions dimensions, long windowS\n     return create.select(allFields).from(finalTable).groupBy(groupByFields).fetch();\n   }\n \n+  /**\n+   * Queries all the data associated with the given metric.\n+   *\n+   * @param metric the desired metric\n+   * @return the result of the query\n+   */\n   public Result<Record> queryMetric(String metric) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1MzIyMA=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 62}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNTQ0MTY1OnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQyMTozNzozOFrOHNcEcA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQyMzozMTo0N1rOHNduJg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1MzQyNA==", "bodyText": "In this case we might want to also check before querying the SQL if the metric is a valid metric name.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483853424", "createdAt": "2020-09-04T21:37:38Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -235,10 +255,39 @@ public void putMetric(Metric<Double> metric, Dimensions dimensions, long windowS\n     return create.select(allFields).from(finalTable).groupBy(groupByFields).fetch();\n   }\n \n+  /**\n+   * Queries all the data associated with the given metric.\n+   *\n+   * @param metric the desired metric\n+   * @return the result of the query\n+   */\n   public Result<Record> queryMetric(String metric) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg4MDQ4Ng==", "bodyText": "That method is not part of this PR. Just some additional documentation was added. Will open a new ticket about it: #412", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483880486", "createdAt": "2020-09-04T23:31:47Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -235,10 +255,39 @@ public void putMetric(Metric<Double> metric, Dimensions dimensions, long windowS\n     return create.select(allFields).from(finalTable).groupBy(groupByFields).fetch();\n   }\n \n+  /**\n+   * Queries all the data associated with the given metric.\n+   *\n+   * @param metric the desired metric\n+   * @return the result of the query\n+   */\n   public Result<Record> queryMetric(String metric) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1MzQyNA=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 62}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNTQ0NDk0OnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQyMTozOToxOVrOHNcGQA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQyMzozMzozNFrOHNdvRA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1Mzg4OA==", "bodyText": "throws DataAccessException ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483853888", "createdAt": "2020-09-04T21:39:19Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -235,10 +255,39 @@ public void putMetric(Metric<Double> metric, Dimensions dimensions, long windowS\n     return create.select(allFields).from(finalTable).groupBy(groupByFields).fetch();\n   }\n \n+  /**\n+   * Queries all the data associated with the given metric.\n+   *\n+   * @param metric the desired metric\n+   * @return the result of the query\n+   */\n   public Result<Record> queryMetric(String metric) {\n     return create.select().from(DSL.table(metric)).fetch();\n   }\n \n+  /**\n+   * Queries all the data associated with a given metric.\n+   *\n+   * @param metric the desired metric\n+   * @param dimensions the dimensions we want to return for the given metric\n+   * @param limit the maximum number of records to return\n+   * @return the result of the query\n+   */\n+  public Result<Record> queryMetric(String metric, Collection<String> dimensions, int limit) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg4MDc3Mg==", "bodyText": "Agreed.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483880772", "createdAt": "2020-09-04T23:33:34Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -235,10 +255,39 @@ public void putMetric(Metric<Double> metric, Dimensions dimensions, long windowS\n     return create.select(allFields).from(finalTable).groupBy(groupByFields).fetch();\n   }\n \n+  /**\n+   * Queries all the data associated with the given metric.\n+   *\n+   * @param metric the desired metric\n+   * @return the result of the query\n+   */\n   public Result<Record> queryMetric(String metric) {\n     return create.select().from(DSL.table(metric)).fetch();\n   }\n \n+  /**\n+   * Queries all the data associated with a given metric.\n+   *\n+   * @param metric the desired metric\n+   * @param dimensions the dimensions we want to return for the given metric\n+   * @param limit the maximum number of records to return\n+   * @return the result of the query\n+   */\n+  public Result<Record> queryMetric(String metric, Collection<String> dimensions, int limit) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1Mzg4OA=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 74}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNTQ1Mzk1OnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "isResolved": false, "comments": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQyMTo0NDoxNFrOHNcLlA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQwMDoxMjo0NFrOHPeZzQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1NTI1Mg==", "bodyText": "Before calling delete, it might be good idea to check for the existence of the file itself or we can call deleteIfExists?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483855252", "createdAt": "2020-09-04T21:44:14Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -259,6 +308,23 @@ public void deleteOnDiskFile() {\n     }\n   }\n \n+  /**\n+   * Deletes the metricsdb file associated with the given timestamp if it exists.\n+   *\n+   * @param windowStartTime the timestamp associated with an existing metricsdb file\n+   */\n+  public static void deleteOnDiskFile(long windowStartTime) {\n+    String dbFilePath = getDBFilePath(windowStartTime);\n+    File dbFile = new File(dbFilePath);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg4MTgxMQ==", "bodyText": "Such a check for the existence of the file is unnecessary -- perhaps after the check the file may not be there. That is why the delete operation itself takes care of all of that.\nWe should keep it's name as \"deleteOnDiskFile\" to stay consistent with current \"deleteOnDiskFile\". Both files to do the same thing, it's just this new version is static and accepts a windowStartTime argument.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483881811", "createdAt": "2020-09-04T23:39:53Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -259,6 +308,23 @@ public void deleteOnDiskFile() {\n     }\n   }\n \n+  /**\n+   * Deletes the metricsdb file associated with the given timestamp if it exists.\n+   *\n+   * @param windowStartTime the timestamp associated with an existing metricsdb file\n+   */\n+  public static void deleteOnDiskFile(long windowStartTime) {\n+    String dbFilePath = getDBFilePath(windowStartTime);\n+    File dbFile = new File(dbFilePath);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1NTI1Mg=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA4NTg3OA==", "bodyText": "In that case use Files.delete() and catch the exception if one is thrown  for understanding why it could not be deleted. The error message here is not helpful", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485085878", "createdAt": "2020-09-08T17:32:33Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -259,6 +308,23 @@ public void deleteOnDiskFile() {\n     }\n   }\n \n+  /**\n+   * Deletes the metricsdb file associated with the given timestamp if it exists.\n+   *\n+   * @param windowStartTime the timestamp associated with an existing metricsdb file\n+   */\n+  public static void deleteOnDiskFile(long windowStartTime) {\n+    String dbFilePath = getDBFilePath(windowStartTime);\n+    File dbFile = new File(dbFilePath);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1NTI1Mg=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTEwODMwNQ==", "bodyText": "Files.delete() is the preferred method in the new IO APIs", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485108305", "createdAt": "2020-09-08T18:14:28Z", "author": {"login": "vigyasharma"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -259,6 +308,23 @@ public void deleteOnDiskFile() {\n     }\n   }\n \n+  /**\n+   * Deletes the metricsdb file associated with the given timestamp if it exists.\n+   *\n+   * @param windowStartTime the timestamp associated with an existing metricsdb file\n+   */\n+  public static void deleteOnDiskFile(long windowStartTime) {\n+    String dbFilePath = getDBFilePath(windowStartTime);\n+    File dbFile = new File(dbFilePath);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1NTI1Mg=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTE1ODM2NQ==", "bodyText": "Sure", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485158365", "createdAt": "2020-09-08T19:49:46Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -259,6 +308,23 @@ public void deleteOnDiskFile() {\n     }\n   }\n \n+  /**\n+   * Deletes the metricsdb file associated with the given timestamp if it exists.\n+   *\n+   * @param windowStartTime the timestamp associated with an existing metricsdb file\n+   */\n+  public static void deleteOnDiskFile(long windowStartTime) {\n+    String dbFilePath = getDBFilePath(windowStartTime);\n+    File dbFile = new File(dbFilePath);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1NTI1Mg=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTIzMTM4OQ==", "bodyText": "it's just this new version is static and accepts a windowStartTime argument.\n\nwhy do we need a separate static instance of the same method, instead of overloading public void deleteOnDiskFile() ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485231389", "createdAt": "2020-09-08T22:33:05Z", "author": {"login": "vigyasharma"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -259,6 +308,23 @@ public void deleteOnDiskFile() {\n     }\n   }\n \n+  /**\n+   * Deletes the metricsdb file associated with the given timestamp if it exists.\n+   *\n+   * @param windowStartTime the timestamp associated with an existing metricsdb file\n+   */\n+  public static void deleteOnDiskFile(long windowStartTime) {\n+    String dbFilePath = getDBFilePath(windowStartTime);\n+    File dbFile = new File(dbFilePath);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1NTI1Mg=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTk4ODgxMw==", "bodyText": "There's two separate abstractions we want. 1. Given a MetricsDB instance, we want to be able to delete it's on-disk file (the non-static version). 2. We want to be able to able to delete arbitrary metrcsdb files without creating an instance (the static version). Creating an instance would have the cost of setting up a sql connection to it... which itself could actually fail (that's why the ctor throws an Exception).", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485988813", "createdAt": "2020-09-10T00:12:44Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -259,6 +308,23 @@ public void deleteOnDiskFile() {\n     }\n   }\n \n+  /**\n+   * Deletes the metricsdb file associated with the given timestamp if it exists.\n+   *\n+   * @param windowStartTime the timestamp associated with an existing metricsdb file\n+   */\n+  public static void deleteOnDiskFile(long windowStartTime) {\n+    String dbFilePath = getDBFilePath(windowStartTime);\n+    File dbFile = new File(dbFilePath);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1NTI1Mg=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 103}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNTQ1NjQ3OnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQyMTo0NTozMFrOHNcNCg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQyMTo1ODo1M1rOHOvbNA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1NTYyNg==", "bodyText": "can we make this final ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483855626", "createdAt": "2020-09-04T21:45:30Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -71,6 +82,11 @@\n   private final AppContext appContext;\n   private final ConfigOverridesApplier configOverridesApplier;\n \n+  public static final String BATCH_METRICS_ENABLED_CONF_FILE = \"batch_metrics_enabled.conf\";\n+  private boolean batchMetricsEnabled;\n+  private boolean defaultBatchMetricsEnabled = false;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg4MjE1MA==", "bodyText": "We should keep it as-is to remain consistent with rcaEnabledDefaultValue. Additionally, this value might change, so we shouldn't make it final.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483882150", "createdAt": "2020-09-04T23:41:49Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -71,6 +82,11 @@\n   private final AppContext appContext;\n   private final ConfigOverridesApplier configOverridesApplier;\n \n+  public static final String BATCH_METRICS_ENABLED_CONF_FILE = \"batch_metrics_enabled.conf\";\n+  private boolean batchMetricsEnabled;\n+  private boolean defaultBatchMetricsEnabled = false;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1NTYyNg=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA4NzE3MQ==", "bodyText": "Can you explain how can a default change ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485087171", "createdAt": "2020-09-08T17:35:01Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -71,6 +82,11 @@\n   private final AppContext appContext;\n   private final ConfigOverridesApplier configOverridesApplier;\n \n+  public static final String BATCH_METRICS_ENABLED_CONF_FILE = \"batch_metrics_enabled.conf\";\n+  private boolean batchMetricsEnabled;\n+  private boolean defaultBatchMetricsEnabled = false;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1NTYyNg=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTEwOTA5NA==", "bodyText": "Why don't we go with default = enabled?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485109094", "createdAt": "2020-09-08T18:15:55Z", "author": {"login": "vigyasharma"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -71,6 +82,11 @@\n   private final AppContext appContext;\n   private final ConfigOverridesApplier configOverridesApplier;\n \n+  public static final String BATCH_METRICS_ENABLED_CONF_FILE = \"batch_metrics_enabled.conf\";\n+  private boolean batchMetricsEnabled;\n+  private boolean defaultBatchMetricsEnabled = false;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1NTYyNg=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTIxOTEyNA==", "bodyText": "When I mentioned \"this value might change\", I meant that we may choose to make it true by default. But yeah, since this comment, my notion of constants has changed. Will change it to be private static final.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485219124", "createdAt": "2020-09-08T21:58:53Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -71,6 +82,11 @@\n   private final AppContext appContext;\n   private final ConfigOverridesApplier configOverridesApplier;\n \n+  public static final String BATCH_METRICS_ENABLED_CONF_FILE = \"batch_metrics_enabled.conf\";\n+  private boolean batchMetricsEnabled;\n+  private boolean defaultBatchMetricsEnabled = false;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1NTYyNg=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 39}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNTQ4MjU2OnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQyMTo1Mjo0NVrOHNccHA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQxNzoyMTo1M1rOHPSTpw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1OTQ4NA==", "bodyText": "We should keep methods marked as VisiableForTesting restricted to getters and setters. Anything else that is required should be done in a test helper method.\nin this case though, this method is called from within trimOldSnapshots. So we should not have the annotation ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483859484", "createdAt": "2020-09-04T21:52:45Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -754,6 +828,28 @@ public void emitNodeMetrics(long currWindowStartTime, MetricsDB metricsDB) throw\n     }\n   }\n \n+  @VisibleForTesting\n+  public void readBatchMetricsEnabledFromConf() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 140}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg4MjgwNw==", "bodyText": "VisibleForTesting \"Annotates a program element that exists, or is more widely visible than otherwise necessary, only for use in test code\". This method would be private if we only needed it in trimOldSnapshots. However, we need it for testing purposes, so we make it VisibleForTesting.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483882807", "createdAt": "2020-09-04T23:45:54Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -754,6 +828,28 @@ public void emitNodeMetrics(long currWindowStartTime, MetricsDB metricsDB) throw\n     }\n   }\n \n+  @VisibleForTesting\n+  public void readBatchMetricsEnabledFromConf() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1OTQ4NA=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 140}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA5NDUwMA==", "bodyText": "One of the ways to avoid it, if we at all want to test private methods, would be to encapsulate all such methods, in a wrapper class of your own. Then make the methods inside the wrapper as public and hence testable. The wrapper can be used in the main class as private or its getters/setters as visible for testing.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485094500", "createdAt": "2020-09-08T17:48:39Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -754,6 +828,28 @@ public void emitNodeMetrics(long currWindowStartTime, MetricsDB metricsDB) throw\n     }\n   }\n \n+  @VisibleForTesting\n+  public void readBatchMetricsEnabledFromConf() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1OTQ4NA=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 140}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTc5MDYzMQ==", "bodyText": "Will address this by making the target methods private and exposing them via VisibleForTesting shims.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485790631", "createdAt": "2020-09-09T17:21:53Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -754,6 +828,28 @@ public void emitNodeMetrics(long currWindowStartTime, MetricsDB metricsDB) throw\n     }\n   }\n \n+  @VisibleForTesting\n+  public void readBatchMetricsEnabledFromConf() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1OTQ4NA=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 140}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNTQ4Mzg1OnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQyMTo1MzozNVrOHNcc6Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQyMTo0NjozOFrOHOvH_w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1OTY4OQ==", "bodyText": "We are already logging the error, so e.printStackTrace(); can be removed ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483859689", "createdAt": "2020-09-04T21:53:35Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -754,6 +828,28 @@ public void emitNodeMetrics(long currWindowStartTime, MetricsDB metricsDB) throw\n     }\n   }\n \n+  @VisibleForTesting\n+  public void readBatchMetricsEnabledFromConf() {\n+    Path filePath = Paths.get(Util.DATA_DIR, BATCH_METRICS_ENABLED_CONF_FILE);\n+\n+    Util.invokePrivileged(\n+            () -> {\n+              try (Scanner sc = new Scanner(filePath)) {\n+                String nextLine = sc.nextLine();\n+                boolean oldValue = batchMetricsEnabled;\n+                boolean newValue = Boolean.parseBoolean(nextLine);\n+                if (oldValue != newValue) {\n+                  batchMetricsEnabled = newValue;\n+                  LOG.info(\"Batch metrics enabled changed from {} to {}\", oldValue, newValue);\n+                }\n+              } catch (IOException e) {\n+                LOG.error(\"Error reading file '{}': {}\", filePath.toString(), e);\n+                e.printStackTrace();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 155}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg4Mjk3MA==", "bodyText": "We should keep this as-is to stay consistent with readRcaEnabledFromConf.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483882970", "createdAt": "2020-09-04T23:47:04Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -754,6 +828,28 @@ public void emitNodeMetrics(long currWindowStartTime, MetricsDB metricsDB) throw\n     }\n   }\n \n+  @VisibleForTesting\n+  public void readBatchMetricsEnabledFromConf() {\n+    Path filePath = Paths.get(Util.DATA_DIR, BATCH_METRICS_ENABLED_CONF_FILE);\n+\n+    Util.invokePrivileged(\n+            () -> {\n+              try (Scanner sc = new Scanner(filePath)) {\n+                String nextLine = sc.nextLine();\n+                boolean oldValue = batchMetricsEnabled;\n+                boolean newValue = Boolean.parseBoolean(nextLine);\n+                if (oldValue != newValue) {\n+                  batchMetricsEnabled = newValue;\n+                  LOG.info(\"Batch metrics enabled changed from {} to {}\", oldValue, newValue);\n+                }\n+              } catch (IOException e) {\n+                LOG.error(\"Error reading file '{}': {}\", filePath.toString(), e);\n+                e.printStackTrace();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1OTY4OQ=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 155}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA5NTQ5MQ==", "bodyText": "We may not want to do everything for consistency as much as we want to do the right thing. :) This may be redundant as the stack will already be captured in the logs.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485095491", "createdAt": "2020-09-08T17:50:25Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -754,6 +828,28 @@ public void emitNodeMetrics(long currWindowStartTime, MetricsDB metricsDB) throw\n     }\n   }\n \n+  @VisibleForTesting\n+  public void readBatchMetricsEnabledFromConf() {\n+    Path filePath = Paths.get(Util.DATA_DIR, BATCH_METRICS_ENABLED_CONF_FILE);\n+\n+    Util.invokePrivileged(\n+            () -> {\n+              try (Scanner sc = new Scanner(filePath)) {\n+                String nextLine = sc.nextLine();\n+                boolean oldValue = batchMetricsEnabled;\n+                boolean newValue = Boolean.parseBoolean(nextLine);\n+                if (oldValue != newValue) {\n+                  batchMetricsEnabled = newValue;\n+                  LOG.info(\"Batch metrics enabled changed from {} to {}\", oldValue, newValue);\n+                }\n+              } catch (IOException e) {\n+                LOG.error(\"Error reading file '{}': {}\", filePath.toString(), e);\n+                e.printStackTrace();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1OTY4OQ=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 155}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTIxNDIwNw==", "bodyText": "Sure, will just remove it.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485214207", "createdAt": "2020-09-08T21:46:38Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -754,6 +828,28 @@ public void emitNodeMetrics(long currWindowStartTime, MetricsDB metricsDB) throw\n     }\n   }\n \n+  @VisibleForTesting\n+  public void readBatchMetricsEnabledFromConf() {\n+    Path filePath = Paths.get(Util.DATA_DIR, BATCH_METRICS_ENABLED_CONF_FILE);\n+\n+    Util.invokePrivileged(\n+            () -> {\n+              try (Scanner sc = new Scanner(filePath)) {\n+                String nextLine = sc.nextLine();\n+                boolean oldValue = batchMetricsEnabled;\n+                boolean newValue = Boolean.parseBoolean(nextLine);\n+                if (oldValue != newValue) {\n+                  batchMetricsEnabled = newValue;\n+                  LOG.info(\"Batch metrics enabled changed from {} to {}\", oldValue, newValue);\n+                }\n+              } catch (IOException e) {\n+                LOG.error(\"Error reading file '{}': {}\", filePath.toString(), e);\n+                e.printStackTrace();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1OTY4OQ=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 155}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNTQ5NDQ0OnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "isResolved": true, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQyMTo1OTo0MFrOHNcjHg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQyMTo1MjoyOFrOHOvRdA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg2MTI3OA==", "bodyText": "If we delete the trimDatabases above, then the method definition is no longer required and the method can be removed ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483861278", "createdAt": "2020-09-04T21:59:40Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -201,8 +219,43 @@ public void trimOldSnapshots() throws Exception {\n     trimMap(shardRqMetricsMap, RQ_SNAPSHOTS);\n     trimMap(httpRqMetricsMap, HTTP_RQ_SNAPSHOTS);\n     trimMap(masterEventMetricsMap, MASTER_EVENT_SNAPSHOTS);\n-    trimDatabases(\n-        metricsDBMap, MAX_DATABASES, PluginSettings.instance().shouldCleanupMetricsDBFiles());\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg2MTU3NQ==", "bodyText": "The better way might be to move lines 223 to 258 in the trimDatabase method. what do you think ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483861575", "createdAt": "2020-09-04T22:00:41Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -201,8 +219,43 @@ public void trimOldSnapshots() throws Exception {\n     trimMap(shardRqMetricsMap, RQ_SNAPSHOTS);\n     trimMap(httpRqMetricsMap, HTTP_RQ_SNAPSHOTS);\n     trimMap(masterEventMetricsMap, MASTER_EVENT_SNAPSHOTS);\n-    trimDatabases(\n-        metricsDBMap, MAX_DATABASES, PluginSettings.instance().shouldCleanupMetricsDBFiles());\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg2MTI3OA=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg4MzU0Mw==", "bodyText": "We should keep trimDatabases for now. It's been pretty well tested and it is public. The codebase itself can use some cleanup, so this can be taken care of with that. However, we should retain the code for now in case we want to make use of it down the road.\nSee #315 (comment)", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483883543", "createdAt": "2020-09-04T23:50:47Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -201,8 +219,43 @@ public void trimOldSnapshots() throws Exception {\n     trimMap(shardRqMetricsMap, RQ_SNAPSHOTS);\n     trimMap(httpRqMetricsMap, HTTP_RQ_SNAPSHOTS);\n     trimMap(masterEventMetricsMap, MASTER_EVENT_SNAPSHOTS);\n-    trimDatabases(\n-        metricsDBMap, MAX_DATABASES, PluginSettings.instance().shouldCleanupMetricsDBFiles());\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg2MTI3OA=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA4ODUzMA==", "bodyText": "If we are removing the usage in the code, we should remove the method. Git takes care of preserving history. So, if it is required in future, we can resurrect it.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485088530", "createdAt": "2020-09-08T17:37:32Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -201,8 +219,43 @@ public void trimOldSnapshots() throws Exception {\n     trimMap(shardRqMetricsMap, RQ_SNAPSHOTS);\n     trimMap(httpRqMetricsMap, HTTP_RQ_SNAPSHOTS);\n     trimMap(masterEventMetricsMap, MASTER_EVENT_SNAPSHOTS);\n-    trimDatabases(\n-        metricsDBMap, MAX_DATABASES, PluginSettings.instance().shouldCleanupMetricsDBFiles());\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg2MTI3OA=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTIxNjYyOA==", "bodyText": "Sure, will remove it.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485216628", "createdAt": "2020-09-08T21:52:28Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -201,8 +219,43 @@ public void trimOldSnapshots() throws Exception {\n     trimMap(shardRqMetricsMap, RQ_SNAPSHOTS);\n     trimMap(httpRqMetricsMap, HTTP_RQ_SNAPSHOTS);\n     trimMap(masterEventMetricsMap, MASTER_EVENT_SNAPSHOTS);\n-    trimDatabases(\n-        metricsDBMap, MAX_DATABASES, PluginSettings.instance().shouldCleanupMetricsDBFiles());\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg2MTI3OA=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 60}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNTUxMzA2OnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQyMjoxMDoyMVrOHNctrA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNVQwMDowNzo1OVrOHNeDJg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg2Mzk4MA==", "bodyText": "Above we have gone through all the metricsDBMap and would have deleted all files but the two most recent ones. Can you add code comment explaining why are we doing this again ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483863980", "createdAt": "2020-09-04T22:10:21Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -201,8 +219,43 @@ public void trimOldSnapshots() throws Exception {\n     trimMap(shardRqMetricsMap, RQ_SNAPSHOTS);\n     trimMap(httpRqMetricsMap, HTTP_RQ_SNAPSHOTS);\n     trimMap(masterEventMetricsMap, MASTER_EVENT_SNAPSHOTS);\n-    trimDatabases(\n-        metricsDBMap, MAX_DATABASES, PluginSettings.instance().shouldCleanupMetricsDBFiles());\n+\n+    boolean deleteDBFiles = PluginSettings.instance().shouldCleanupMetricsDBFiles();\n+    while (metricsDBMap.size() > MAX_DATABASES) {\n+      Map.Entry<Long, MetricsDB> oldestEntry = metricsDBMap.pollFirstEntry();\n+      if (oldestEntry != null) {\n+        Long key = oldestEntry.getKey();\n+        MetricsDB value = oldestEntry.getValue();\n+        value.remove();\n+        if (deleteDBFiles && !batchMetricsDBSet.contains(key)) {\n+          value.deleteOnDiskFile();\n+        }\n+      }\n+    }\n+    // Flush any tracking batch metrics if batch metrics is disabled. Note, in order to ensure that batch metrics\n+    // consumers have had at least one cycle to use any metrics they may be holding, this flush is done before\n+    // re-reading the config file to update the state of the batch metrics feature.\n+    if (!batchMetricsEnabled && !batchMetricsDBSet.isEmpty()) {\n+      if (deleteDBFiles) {\n+        for (Long timestamp : batchMetricsDBSet) {\n+          if (!metricsDBMap.containsKey(timestamp)) {\n+            MetricsDB.deleteOnDiskFile(timestamp);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 80}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg4NTg2Mg==", "bodyText": "Sure", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483885862", "createdAt": "2020-09-05T00:07:59Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -201,8 +219,43 @@ public void trimOldSnapshots() throws Exception {\n     trimMap(shardRqMetricsMap, RQ_SNAPSHOTS);\n     trimMap(httpRqMetricsMap, HTTP_RQ_SNAPSHOTS);\n     trimMap(masterEventMetricsMap, MASTER_EVENT_SNAPSHOTS);\n-    trimDatabases(\n-        metricsDBMap, MAX_DATABASES, PluginSettings.instance().shouldCleanupMetricsDBFiles());\n+\n+    boolean deleteDBFiles = PluginSettings.instance().shouldCleanupMetricsDBFiles();\n+    while (metricsDBMap.size() > MAX_DATABASES) {\n+      Map.Entry<Long, MetricsDB> oldestEntry = metricsDBMap.pollFirstEntry();\n+      if (oldestEntry != null) {\n+        Long key = oldestEntry.getKey();\n+        MetricsDB value = oldestEntry.getValue();\n+        value.remove();\n+        if (deleteDBFiles && !batchMetricsDBSet.contains(key)) {\n+          value.deleteOnDiskFile();\n+        }\n+      }\n+    }\n+    // Flush any tracking batch metrics if batch metrics is disabled. Note, in order to ensure that batch metrics\n+    // consumers have had at least one cycle to use any metrics they may be holding, this flush is done before\n+    // re-reading the config file to update the state of the batch metrics feature.\n+    if (!batchMetricsEnabled && !batchMetricsDBSet.isEmpty()) {\n+      if (deleteDBFiles) {\n+        for (Long timestamp : batchMetricsDBSet) {\n+          if (!metricsDBMap.containsKey(timestamp)) {\n+            MetricsDB.deleteOnDiskFile(timestamp);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg2Mzk4MA=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 80}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNTUxNTc1OnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "isResolved": true, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQyMjoxMTo0OVrOHNcvIg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQxODowMTo1NlrOHPTsOg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg2NDM1NA==", "bodyText": "This sounds like this call may not belong here or the name of the enclosing method trimOldSnapshots might be changed to something more relevant indicating that the config is re-read here ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483864354", "createdAt": "2020-09-04T22:11:49Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -201,8 +219,43 @@ public void trimOldSnapshots() throws Exception {\n     trimMap(shardRqMetricsMap, RQ_SNAPSHOTS);\n     trimMap(httpRqMetricsMap, HTTP_RQ_SNAPSHOTS);\n     trimMap(masterEventMetricsMap, MASTER_EVENT_SNAPSHOTS);\n-    trimDatabases(\n-        metricsDBMap, MAX_DATABASES, PluginSettings.instance().shouldCleanupMetricsDBFiles());\n+\n+    boolean deleteDBFiles = PluginSettings.instance().shouldCleanupMetricsDBFiles();\n+    while (metricsDBMap.size() > MAX_DATABASES) {\n+      Map.Entry<Long, MetricsDB> oldestEntry = metricsDBMap.pollFirstEntry();\n+      if (oldestEntry != null) {\n+        Long key = oldestEntry.getKey();\n+        MetricsDB value = oldestEntry.getValue();\n+        value.remove();\n+        if (deleteDBFiles && !batchMetricsDBSet.contains(key)) {\n+          value.deleteOnDiskFile();\n+        }\n+      }\n+    }\n+    // Flush any tracking batch metrics if batch metrics is disabled. Note, in order to ensure that batch metrics\n+    // consumers have had at least one cycle to use any metrics they may be holding, this flush is done before\n+    // re-reading the config file to update the state of the batch metrics feature.\n+    if (!batchMetricsEnabled && !batchMetricsDBSet.isEmpty()) {\n+      if (deleteDBFiles) {\n+        for (Long timestamp : batchMetricsDBSet) {\n+          if (!metricsDBMap.containsKey(timestamp)) {\n+            MetricsDB.deleteOnDiskFile(timestamp);\n+          }\n+        }\n+      }\n+      batchMetricsDBSet.clear();\n+    }\n+    readBatchMetricsEnabledFromConf();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 86}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg4NDkyNw==", "bodyText": "This call does belong here (see the comment above it). The method name does not need to be renamed -- the same abstraction is achieved at the end. Additionally, this is complexity that cannot be avoided. The comments are here to help explain the complexity to the reader.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483884927", "createdAt": "2020-09-05T00:00:28Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -201,8 +219,43 @@ public void trimOldSnapshots() throws Exception {\n     trimMap(shardRqMetricsMap, RQ_SNAPSHOTS);\n     trimMap(httpRqMetricsMap, HTTP_RQ_SNAPSHOTS);\n     trimMap(masterEventMetricsMap, MASTER_EVENT_SNAPSHOTS);\n-    trimDatabases(\n-        metricsDBMap, MAX_DATABASES, PluginSettings.instance().shouldCleanupMetricsDBFiles());\n+\n+    boolean deleteDBFiles = PluginSettings.instance().shouldCleanupMetricsDBFiles();\n+    while (metricsDBMap.size() > MAX_DATABASES) {\n+      Map.Entry<Long, MetricsDB> oldestEntry = metricsDBMap.pollFirstEntry();\n+      if (oldestEntry != null) {\n+        Long key = oldestEntry.getKey();\n+        MetricsDB value = oldestEntry.getValue();\n+        value.remove();\n+        if (deleteDBFiles && !batchMetricsDBSet.contains(key)) {\n+          value.deleteOnDiskFile();\n+        }\n+      }\n+    }\n+    // Flush any tracking batch metrics if batch metrics is disabled. Note, in order to ensure that batch metrics\n+    // consumers have had at least one cycle to use any metrics they may be holding, this flush is done before\n+    // re-reading the config file to update the state of the batch metrics feature.\n+    if (!batchMetricsEnabled && !batchMetricsDBSet.isEmpty()) {\n+      if (deleteDBFiles) {\n+        for (Long timestamp : batchMetricsDBSet) {\n+          if (!metricsDBMap.containsKey(timestamp)) {\n+            MetricsDB.deleteOnDiskFile(timestamp);\n+          }\n+        }\n+      }\n+      batchMetricsDBSet.clear();\n+    }\n+    readBatchMetricsEnabledFromConf();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg2NDM1NA=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 86}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA5MDEzNg==", "bodyText": "Sorry, for the confusion, by not belong here, I meant in terms of the name of the method. So please change the name to reflect that ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485090136", "createdAt": "2020-09-08T17:40:30Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -201,8 +219,43 @@ public void trimOldSnapshots() throws Exception {\n     trimMap(shardRqMetricsMap, RQ_SNAPSHOTS);\n     trimMap(httpRqMetricsMap, HTTP_RQ_SNAPSHOTS);\n     trimMap(masterEventMetricsMap, MASTER_EVENT_SNAPSHOTS);\n-    trimDatabases(\n-        metricsDBMap, MAX_DATABASES, PluginSettings.instance().shouldCleanupMetricsDBFiles());\n+\n+    boolean deleteDBFiles = PluginSettings.instance().shouldCleanupMetricsDBFiles();\n+    while (metricsDBMap.size() > MAX_DATABASES) {\n+      Map.Entry<Long, MetricsDB> oldestEntry = metricsDBMap.pollFirstEntry();\n+      if (oldestEntry != null) {\n+        Long key = oldestEntry.getKey();\n+        MetricsDB value = oldestEntry.getValue();\n+        value.remove();\n+        if (deleteDBFiles && !batchMetricsDBSet.contains(key)) {\n+          value.deleteOnDiskFile();\n+        }\n+      }\n+    }\n+    // Flush any tracking batch metrics if batch metrics is disabled. Note, in order to ensure that batch metrics\n+    // consumers have had at least one cycle to use any metrics they may be holding, this flush is done before\n+    // re-reading the config file to update the state of the batch metrics feature.\n+    if (!batchMetricsEnabled && !batchMetricsDBSet.isEmpty()) {\n+      if (deleteDBFiles) {\n+        for (Long timestamp : batchMetricsDBSet) {\n+          if (!metricsDBMap.containsKey(timestamp)) {\n+            MetricsDB.deleteOnDiskFile(timestamp);\n+          }\n+        }\n+      }\n+      batchMetricsDBSet.clear();\n+    }\n+    readBatchMetricsEnabledFromConf();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg2NDM1NA=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 86}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTgxMzMwNg==", "bodyText": "Sure, will separate out into a trimOldSnapshots method and a trimOldMetricsDBFiles method.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485813306", "createdAt": "2020-09-09T18:01:56Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -201,8 +219,43 @@ public void trimOldSnapshots() throws Exception {\n     trimMap(shardRqMetricsMap, RQ_SNAPSHOTS);\n     trimMap(httpRqMetricsMap, HTTP_RQ_SNAPSHOTS);\n     trimMap(masterEventMetricsMap, MASTER_EVENT_SNAPSHOTS);\n-    trimDatabases(\n-        metricsDBMap, MAX_DATABASES, PluginSettings.instance().shouldCleanupMetricsDBFiles());\n+\n+    boolean deleteDBFiles = PluginSettings.instance().shouldCleanupMetricsDBFiles();\n+    while (metricsDBMap.size() > MAX_DATABASES) {\n+      Map.Entry<Long, MetricsDB> oldestEntry = metricsDBMap.pollFirstEntry();\n+      if (oldestEntry != null) {\n+        Long key = oldestEntry.getKey();\n+        MetricsDB value = oldestEntry.getValue();\n+        value.remove();\n+        if (deleteDBFiles && !batchMetricsDBSet.contains(key)) {\n+          value.deleteOnDiskFile();\n+        }\n+      }\n+    }\n+    // Flush any tracking batch metrics if batch metrics is disabled. Note, in order to ensure that batch metrics\n+    // consumers have had at least one cycle to use any metrics they may be holding, this flush is done before\n+    // re-reading the config file to update the state of the batch metrics feature.\n+    if (!batchMetricsEnabled && !batchMetricsDBSet.isEmpty()) {\n+      if (deleteDBFiles) {\n+        for (Long timestamp : batchMetricsDBSet) {\n+          if (!metricsDBMap.containsKey(timestamp)) {\n+            MetricsDB.deleteOnDiskFile(timestamp);\n+          }\n+        }\n+      }\n+      batchMetricsDBSet.clear();\n+    }\n+    readBatchMetricsEnabledFromConf();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg2NDM1NA=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 86}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAyNTUzMjI4OnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQyMjoyMjoyMVrOHNc4ww==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQyMzo1NzoyMFrOHNd96w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg2NjgxOQ==", "bodyText": "SO we store the snapshot everytime we emit metrics, at query time we clone the snapshot (so we double the snapshot) and then we trim it. This is very memory intensive. We might just want to read the files directly from disk when the API is called ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483866819", "createdAt": "2020-09-04T22:22:21Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -289,6 +342,9 @@ private void emitMetrics(long currWindowStartTime) throws Exception {\n \n     metricsDB.commit();\n     metricsDBMap.put(prevWindowStartTime, metricsDB);\n+    if (batchMetricsEnabled) {\n+      batchMetricsDBSet.add(prevWindowStartTime);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg2Nzg3OA==", "bodyText": "We do not clone the snapshot at query time. We read the file itself. We use the batchMetricsDBSet to keep track of the timestamps of all the available dbs we have on disk, and then when we want to make use of these files during query handling, we call MetricsDB.fetchExisting, which simply creates a new connection to that on-disk database.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483867878", "createdAt": "2020-09-04T22:27:08Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -289,6 +342,9 @@ private void emitMetrics(long currWindowStartTime) throws Exception {\n \n     metricsDB.commit();\n     metricsDBMap.put(prevWindowStartTime, metricsDB);\n+    if (batchMetricsEnabled) {\n+      batchMetricsDBSet.add(prevWindowStartTime);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg2NjgxOQ=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 105}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg4NDUyMw==", "bodyText": "This is not what we do. We add just the timestamp to a set. Then, the query handler uses the timestamps from this set to call fetchExisting. fetchExisting creates an additional connection to an already existing database (we do not clone the snapshot), and we access the data via that connection.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483884523", "createdAt": "2020-09-04T23:57:20Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -289,6 +342,9 @@ private void emitMetrics(long currWindowStartTime) throws Exception {\n \n     metricsDB.commit();\n     metricsDBMap.put(prevWindowStartTime, metricsDB);\n+    if (batchMetricsEnabled) {\n+      batchMetricsDBSet.add(prevWindowStartTime);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg2NjgxOQ=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 105}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAzNDAwNDE3OnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/config/PluginSettings.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxNzoyNDo0NlrOHOnBhQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxODoyMzoyNFrOHOo8-g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA4MTQ3Nw==", "bodyText": "Do we need the stack trace here ?\nAnd as this is logged for both NumberFormatException and InvalidParameterException, it might make sense to print (settings.getProperty(BATCH_METRICS_RETENTION_PERIOD_MINUTES) to understand which of the two it was by just looking at the logs ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485081477", "createdAt": "2020-09-08T17:24:46Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/config/PluginSettings.java", "diffHunk": "@@ -271,4 +295,21 @@ private void loadMetricsDBFilesCleanupEnabled() {\n       shouldCleanupMetricsDBFiles = true;\n     }\n   }\n+\n+  private void loadBatchMetricsRetentionPeriodMinutesFromConfig() {\n+    if (!settings.containsKey(BATCH_METRICS_RETENTION_PERIOD_MINUTES)) {\n+      return;\n+    }\n+\n+    try {\n+      long parsedRetentionPeriod = Long.parseLong(settings.getProperty(BATCH_METRICS_RETENTION_PERIOD_MINUTES));\n+      if (parsedRetentionPeriod <= 0 || parsedRetentionPeriod > BATCH_METRICS_RETENTION_PERIOD_MINUTES_LIMIT) {\n+        throw new InvalidParameterException();\n+      }\n+      batchMetricsRetentionPeriodMinutes = parsedRetentionPeriod;\n+    } catch (NumberFormatException | InvalidParameterException e) {\n+      LOG.error(\"Invalid batch-metrics-retention-period-minutes. Using default value {}.\",\n+              batchMetricsRetentionPeriodMinutes, e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTEwMjQ1NA==", "bodyText": "Wouldn't Log.error have the stack trace to help identify the exception raised?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485102454", "createdAt": "2020-09-08T18:03:35Z", "author": {"login": "vigyasharma"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/config/PluginSettings.java", "diffHunk": "@@ -271,4 +295,21 @@ private void loadMetricsDBFilesCleanupEnabled() {\n       shouldCleanupMetricsDBFiles = true;\n     }\n   }\n+\n+  private void loadBatchMetricsRetentionPeriodMinutesFromConfig() {\n+    if (!settings.containsKey(BATCH_METRICS_RETENTION_PERIOD_MINUTES)) {\n+      return;\n+    }\n+\n+    try {\n+      long parsedRetentionPeriod = Long.parseLong(settings.getProperty(BATCH_METRICS_RETENTION_PERIOD_MINUTES));\n+      if (parsedRetentionPeriod <= 0 || parsedRetentionPeriod > BATCH_METRICS_RETENTION_PERIOD_MINUTES_LIMIT) {\n+        throw new InvalidParameterException();\n+      }\n+      batchMetricsRetentionPeriodMinutes = parsedRetentionPeriod;\n+    } catch (NumberFormatException | InvalidParameterException e) {\n+      LOG.error(\"Invalid batch-metrics-retention-period-minutes. Using default value {}.\",\n+              batchMetricsRetentionPeriodMinutes, e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA4MTQ3Nw=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTExMzA4Mg==", "bodyText": "Sure will get rid of the exception log and doing something like this.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485113082", "createdAt": "2020-09-08T18:23:24Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/config/PluginSettings.java", "diffHunk": "@@ -271,4 +295,21 @@ private void loadMetricsDBFilesCleanupEnabled() {\n       shouldCleanupMetricsDBFiles = true;\n     }\n   }\n+\n+  private void loadBatchMetricsRetentionPeriodMinutesFromConfig() {\n+    if (!settings.containsKey(BATCH_METRICS_RETENTION_PERIOD_MINUTES)) {\n+      return;\n+    }\n+\n+    try {\n+      long parsedRetentionPeriod = Long.parseLong(settings.getProperty(BATCH_METRICS_RETENTION_PERIOD_MINUTES));\n+      if (parsedRetentionPeriod <= 0 || parsedRetentionPeriod > BATCH_METRICS_RETENTION_PERIOD_MINUTES_LIMIT) {\n+        throw new InvalidParameterException();\n+      }\n+      batchMetricsRetentionPeriodMinutes = parsedRetentionPeriod;\n+    } catch (NumberFormatException | InvalidParameterException e) {\n+      LOG.error(\"Invalid batch-metrics-retention-period-minutes. Using default value {}.\",\n+              batchMetricsRetentionPeriodMinutes, e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA4MTQ3Nw=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 102}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAzNDgyMTY1OnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQyMTozNTowN1rOHOuz_Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQxNjo1OTo1OFrOHPRhYQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTIwOTA4NQ==", "bodyText": "We have a few things going on here:\n\ncleaning up in-memory snapshots\ncleaning up on-disk files if batch metrics is disabled.\nre-reading config\nAnd cleaning up metrics db files so that we always have a fixed number of them around.\n\nLet's move the in-memory cleanup and on disk cleanups into separate methods of their own", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485209085", "createdAt": "2020-09-08T21:35:07Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -201,8 +219,46 @@ public void trimOldSnapshots() throws Exception {\n     trimMap(shardRqMetricsMap, RQ_SNAPSHOTS);\n     trimMap(httpRqMetricsMap, HTTP_RQ_SNAPSHOTS);\n     trimMap(masterEventMetricsMap, MASTER_EVENT_SNAPSHOTS);\n-    trimDatabases(\n-        metricsDBMap, MAX_DATABASES, PluginSettings.instance().shouldCleanupMetricsDBFiles());\n+\n+    boolean deleteDBFiles = PluginSettings.instance().shouldCleanupMetricsDBFiles();\n+    // Cleanup all but the 2 most recent metricsDB files from metricsDBMap. The most recent metricsDB files needs to be\n+    // retained for future metrics query handling, the second most recent metricsDB file needs to be retained in case", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ce9e155ff2cf4984d791844dda3dac4261e1baf7"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTc3Nzc2MQ==", "bodyText": "Sure", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485777761", "createdAt": "2020-09-09T16:59:58Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -201,8 +219,46 @@ public void trimOldSnapshots() throws Exception {\n     trimMap(shardRqMetricsMap, RQ_SNAPSHOTS);\n     trimMap(httpRqMetricsMap, HTTP_RQ_SNAPSHOTS);\n     trimMap(masterEventMetricsMap, MASTER_EVENT_SNAPSHOTS);\n-    trimDatabases(\n-        metricsDBMap, MAX_DATABASES, PluginSettings.instance().shouldCleanupMetricsDBFiles());\n+\n+    boolean deleteDBFiles = PluginSettings.instance().shouldCleanupMetricsDBFiles();\n+    // Cleanup all but the 2 most recent metricsDB files from metricsDBMap. The most recent metricsDB files needs to be\n+    // retained for future metrics query handling, the second most recent metricsDB file needs to be retained in case", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTIwOTA4NQ=="}, "originalCommit": {"oid": "ce9e155ff2cf4984d791844dda3dac4261e1baf7"}, "originalPosition": 63}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAzNDgzMTA0OnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQyMTozODoyNVrOHOu5hw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQxNjowNTowNFrOHPOl7w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTIxMDUwMw==", "bodyText": "Although we are playing safe here by not reading the config before, but I don't think we are completely avoiding the race here. Say, if reading all the files in the retention period is taking too long, (multiple iterations of this call), then there is still a chance that the API read thread tries to read a file that has been deleted. So, we should definitely handle that exception, in any case.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485210503", "createdAt": "2020-09-08T21:38:25Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -201,8 +219,46 @@ public void trimOldSnapshots() throws Exception {\n     trimMap(shardRqMetricsMap, RQ_SNAPSHOTS);\n     trimMap(httpRqMetricsMap, HTTP_RQ_SNAPSHOTS);\n     trimMap(masterEventMetricsMap, MASTER_EVENT_SNAPSHOTS);\n-    trimDatabases(\n-        metricsDBMap, MAX_DATABASES, PluginSettings.instance().shouldCleanupMetricsDBFiles());\n+\n+    boolean deleteDBFiles = PluginSettings.instance().shouldCleanupMetricsDBFiles();\n+    // Cleanup all but the 2 most recent metricsDB files from metricsDBMap. The most recent metricsDB files needs to be\n+    // retained for future metrics query handling, the second most recent metricsDB file needs to be retained in case\n+    // any metrics query handler just got access to it right before the most recent metricsDB file was available.\n+    while (metricsDBMap.size() > MAX_DATABASES) {\n+      Map.Entry<Long, MetricsDB> oldestEntry = metricsDBMap.pollFirstEntry();\n+      if (oldestEntry != null) {\n+        Long key = oldestEntry.getKey();\n+        MetricsDB value = oldestEntry.getValue();\n+        value.remove();\n+        if (deleteDBFiles && !batchMetricsDBSet.contains(key)) {\n+          value.deleteOnDiskFile();\n+        }\n+      }\n+    }\n+    // Flush any tracking batch metrics if batch metrics is disabled. Note, in order to ensure that batch metrics\n+    // consumers have had at least one cycle to use any metrics they may be holding, this flush is done before\n+    // re-reading the config file to update the state of the batch metrics feature.\n+    if (!batchMetricsEnabled && !batchMetricsDBSet.isEmpty()) {\n+      if (deleteDBFiles) {\n+        for (Long timestamp : batchMetricsDBSet) {\n+          if (!metricsDBMap.containsKey(timestamp)) {\n+            MetricsDB.deleteOnDiskFile(timestamp);\n+          }\n+        }\n+      }\n+      batchMetricsDBSet.clear();\n+    }\n+    readBatchMetricsEnabledFromConf();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ce9e155ff2cf4984d791844dda3dac4261e1baf7"}, "originalPosition": 89}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTcyOTc3NQ==", "bodyText": "Right, the metrics processor code gives the query handler's a ~5s grace period before deleting stale metricsdb files (see the javadoc on getBatchMetrics). For the typical case (when batch metrics is not about to be disabled), this will not be an issue since the batch metrics query handler reads data from the older files first. For the case when batch metrics is about to be disabled, even newer files are at risk of deletion. However, this disabling of batch metrics is not expected to be a use case, there is a 100,800 datapoints limit on the query handler, there's not much data to say that this grace period will be an issue given the datapoint limit, and the query handler properly handles missing files.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485729775", "createdAt": "2020-09-09T16:05:04Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -201,8 +219,46 @@ public void trimOldSnapshots() throws Exception {\n     trimMap(shardRqMetricsMap, RQ_SNAPSHOTS);\n     trimMap(httpRqMetricsMap, HTTP_RQ_SNAPSHOTS);\n     trimMap(masterEventMetricsMap, MASTER_EVENT_SNAPSHOTS);\n-    trimDatabases(\n-        metricsDBMap, MAX_DATABASES, PluginSettings.instance().shouldCleanupMetricsDBFiles());\n+\n+    boolean deleteDBFiles = PluginSettings.instance().shouldCleanupMetricsDBFiles();\n+    // Cleanup all but the 2 most recent metricsDB files from metricsDBMap. The most recent metricsDB files needs to be\n+    // retained for future metrics query handling, the second most recent metricsDB file needs to be retained in case\n+    // any metrics query handler just got access to it right before the most recent metricsDB file was available.\n+    while (metricsDBMap.size() > MAX_DATABASES) {\n+      Map.Entry<Long, MetricsDB> oldestEntry = metricsDBMap.pollFirstEntry();\n+      if (oldestEntry != null) {\n+        Long key = oldestEntry.getKey();\n+        MetricsDB value = oldestEntry.getValue();\n+        value.remove();\n+        if (deleteDBFiles && !batchMetricsDBSet.contains(key)) {\n+          value.deleteOnDiskFile();\n+        }\n+      }\n+    }\n+    // Flush any tracking batch metrics if batch metrics is disabled. Note, in order to ensure that batch metrics\n+    // consumers have had at least one cycle to use any metrics they may be holding, this flush is done before\n+    // re-reading the config file to update the state of the batch metrics feature.\n+    if (!batchMetricsEnabled && !batchMetricsDBSet.isEmpty()) {\n+      if (deleteDBFiles) {\n+        for (Long timestamp : batchMetricsDBSet) {\n+          if (!metricsDBMap.containsKey(timestamp)) {\n+            MetricsDB.deleteOnDiskFile(timestamp);\n+          }\n+        }\n+      }\n+      batchMetricsDBSet.clear();\n+    }\n+    readBatchMetricsEnabledFromConf();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTIxMDUwMw=="}, "originalCommit": {"oid": "ce9e155ff2cf4984d791844dda3dac4261e1baf7"}, "originalPosition": 89}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAzNDg1MzQwOnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQyMTo0NjowNFrOHOvHHA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQyMzoxMjoyNFrOHOw_zA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTIxMzk4MA==", "bodyText": "PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 12\nThis is a call we are making on each iteration of the loop. Can we store it in a local variable as it does not change over the loop iterations ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485213980", "createdAt": "2020-09-08T21:46:04Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -696,6 +755,24 @@ public void deleteDBs() throws Exception {\n     }\n   }\n \n+  /**\n+   * This is called by operations outside of the ReaderMetricsProcessor.\n+   *\n+   * @return A list of the timestamps associated with MetricsDB files. The oldest of the MetricsDB files typically\n+   *     have a lifetime of ~SAMPLING_INTERVAL seconds (no less than SAMPLING_INTERVAL/2 seconds). Null if batch\n+   *     metrics is disabled.\n+   */\n+  public NavigableSet<Long> getBatchMetrics() {\n+    if (batchMetricsEnabled) {\n+      TreeSet<Long> batchMetricsDBSetCopy = new TreeSet<>(batchMetricsDBSet.clone());\n+      while (batchMetricsDBSetCopy.size() > PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 12) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ce9e155ff2cf4984d791844dda3dac4261e1baf7"}, "originalPosition": 127}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTI0NDg3Ng==", "bodyText": "Sure", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485244876", "createdAt": "2020-09-08T23:12:24Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -696,6 +755,24 @@ public void deleteDBs() throws Exception {\n     }\n   }\n \n+  /**\n+   * This is called by operations outside of the ReaderMetricsProcessor.\n+   *\n+   * @return A list of the timestamps associated with MetricsDB files. The oldest of the MetricsDB files typically\n+   *     have a lifetime of ~SAMPLING_INTERVAL seconds (no less than SAMPLING_INTERVAL/2 seconds). Null if batch\n+   *     metrics is disabled.\n+   */\n+  public NavigableSet<Long> getBatchMetrics() {\n+    if (batchMetricsEnabled) {\n+      TreeSet<Long> batchMetricsDBSetCopy = new TreeSet<>(batchMetricsDBSet.clone());\n+      while (batchMetricsDBSetCopy.size() > PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 12) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTIxMzk4MA=="}, "originalCommit": {"oid": "ce9e155ff2cf4984d791844dda3dac4261e1baf7"}, "originalPosition": 127}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAzNDg2MDkxOnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQyMTo0ODo1OFrOHOvLww==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQyMjo1Nzo1OFrOHOwt_Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTIxNTE3MQ==", "bodyText": "Let's add a comment here saying that this datastructure can be modified by the writer/cleanup thread while being read by the other thread trying to batch metrics. And therefore, it needs to be ConcurrentSkipListSet", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485215171", "createdAt": "2020-09-08T21:48:58Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -71,6 +82,11 @@\n   private final AppContext appContext;\n   private final ConfigOverridesApplier configOverridesApplier;\n \n+  public static final String BATCH_METRICS_ENABLED_CONF_FILE = \"batch_metrics_enabled.conf\";\n+  private boolean batchMetricsEnabled;\n+  private boolean defaultBatchMetricsEnabled = false;\n+  private ConcurrentSkipListSet<Long> batchMetricsDBSet;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ce9e155ff2cf4984d791844dda3dac4261e1baf7"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTI0MDMxNw==", "bodyText": "Sure", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485240317", "createdAt": "2020-09-08T22:57:58Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -71,6 +82,11 @@\n   private final AppContext appContext;\n   private final ConfigOverridesApplier configOverridesApplier;\n \n+  public static final String BATCH_METRICS_ENABLED_CONF_FILE = \"batch_metrics_enabled.conf\";\n+  private boolean batchMetricsEnabled;\n+  private boolean defaultBatchMetricsEnabled = false;\n+  private ConcurrentSkipListSet<Long> batchMetricsDBSet;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTIxNTE3MQ=="}, "originalCommit": {"oid": "ce9e155ff2cf4984d791844dda3dac4261e1baf7"}, "originalPosition": 40}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAzNDg2ODg1OnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandler.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQyMTo1MTo0OVrOHOvQcg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQyMjoxNTozNVrOHOvzPw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTIxNjM3MA==", "bodyText": "Let's also add the reason for the numbers here ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485216370", "createdAt": "2020-09-08T21:51:49Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandler.java", "diffHunk": "@@ -0,0 +1,309 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rest;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatExceptionCode;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatsCollector;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.config.PluginSettings;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metrics.MetricsRestUtil;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.model.MetricsModel;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.net.NetClient;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ReaderMetricsProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.sun.net.httpserver.HttpExchange;\n+import com.sun.net.httpserver.HttpHandler;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.net.HttpURLConnection;\n+import java.security.InvalidParameterException;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.NavigableSet;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.logging.log4j.util.Supplier;\n+import org.jooq.Record;\n+import org.jooq.Result;\n+\n+/**\n+ * Request handler that supports querying batch metrics from an EC2 instance\n+ *\n+ * <p>Return 1 minute of CPU_Utilization metrics sampled at a 5s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization&starttime=1566413975000&endtime=1566413980000\"\n+ *\n+ * <p>Return 1 minute of CPU_Utilization and Latency metrics sampled at a 10s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization,Latency&starttime=1566413975000&endtime=1566413980000&samplingperiod=10\"\n+ *\n+ * <p>Return format:\n+ * {\n+ *   \"1594412650000\": {\n+ *     \"CPU_Utilization\": {\n+ *       \"fields\": [\n+ *         {\n+ *           \"name: \"IndexName\",\n+ *           \"type\": \"VARCHAR\"\n+ *         },\n+ *         <...>\n+ *       ]\n+ *       \"records\": [\n+ *         [\n+ *           \"pmc\",\n+ *           <...>\n+ *         ],\n+ *         <...>\n+ *       ]\n+ *     }\n+ *   }\n+ * }\n+ */\n+public class QueryBatchRequestHandler extends MetricsHandler implements HttpHandler {\n+\n+  private static final Logger LOG = LogManager.getLogger(QueryBatchRequestHandler.class);\n+\n+  private static final int TIME_OUT_VALUE = 2;\n+  private static final TimeUnit TIME_OUT_UNIT = TimeUnit.SECONDS;\n+  private NetClient netClient;\n+  MetricsRestUtil metricsRestUtil;\n+\n+  public static final int DEFAULT_MAX_DATAPOINTS = 100800;  // Must be non-negative\n+  public static final long DEFAULT_SAMPLING_PERIOD_MILLIS = 5000;  // Must be a multiple of 5000", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ce9e155ff2cf4984d791844dda3dac4261e1baf7"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTIyNTI3OQ==", "bodyText": "Max datapoints was capped to prevent excessive memory consumption. Will note that in README and design docs. However, I don't see the need to note anything about DEFAULT_SAMPLING_PERIOD_MILLIS.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485225279", "createdAt": "2020-09-08T22:15:35Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandler.java", "diffHunk": "@@ -0,0 +1,309 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rest;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatExceptionCode;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatsCollector;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.config.PluginSettings;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metrics.MetricsRestUtil;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.model.MetricsModel;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.net.NetClient;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ReaderMetricsProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.sun.net.httpserver.HttpExchange;\n+import com.sun.net.httpserver.HttpHandler;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.net.HttpURLConnection;\n+import java.security.InvalidParameterException;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.NavigableSet;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.logging.log4j.util.Supplier;\n+import org.jooq.Record;\n+import org.jooq.Result;\n+\n+/**\n+ * Request handler that supports querying batch metrics from an EC2 instance\n+ *\n+ * <p>Return 1 minute of CPU_Utilization metrics sampled at a 5s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization&starttime=1566413975000&endtime=1566413980000\"\n+ *\n+ * <p>Return 1 minute of CPU_Utilization and Latency metrics sampled at a 10s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization,Latency&starttime=1566413975000&endtime=1566413980000&samplingperiod=10\"\n+ *\n+ * <p>Return format:\n+ * {\n+ *   \"1594412650000\": {\n+ *     \"CPU_Utilization\": {\n+ *       \"fields\": [\n+ *         {\n+ *           \"name: \"IndexName\",\n+ *           \"type\": \"VARCHAR\"\n+ *         },\n+ *         <...>\n+ *       ]\n+ *       \"records\": [\n+ *         [\n+ *           \"pmc\",\n+ *           <...>\n+ *         ],\n+ *         <...>\n+ *       ]\n+ *     }\n+ *   }\n+ * }\n+ */\n+public class QueryBatchRequestHandler extends MetricsHandler implements HttpHandler {\n+\n+  private static final Logger LOG = LogManager.getLogger(QueryBatchRequestHandler.class);\n+\n+  private static final int TIME_OUT_VALUE = 2;\n+  private static final TimeUnit TIME_OUT_UNIT = TimeUnit.SECONDS;\n+  private NetClient netClient;\n+  MetricsRestUtil metricsRestUtil;\n+\n+  public static final int DEFAULT_MAX_DATAPOINTS = 100800;  // Must be non-negative\n+  public static final long DEFAULT_SAMPLING_PERIOD_MILLIS = 5000;  // Must be a multiple of 5000", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTIxNjM3MA=="}, "originalCommit": {"oid": "ce9e155ff2cf4984d791844dda3dac4261e1baf7"}, "originalPosition": 88}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAzNDg4Mjg3OnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "isResolved": false, "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQyMTo1NzoyMVrOHOvY0Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQwMDowNzo0MlrOHPeUfA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTIxODUxMw==", "bodyText": "batchMetricsDBSet holds the key to the castle and it is an in-memory structure. In case PA starts crashing say every 15 seconds, or so. So, we will not be cleaning up files that were generated in the last run as this structure is always initialized to an empty set !", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485218513", "createdAt": "2020-09-08T21:57:21Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -71,6 +82,11 @@\n   private final AppContext appContext;\n   private final ConfigOverridesApplier configOverridesApplier;\n \n+  public static final String BATCH_METRICS_ENABLED_CONF_FILE = \"batch_metrics_enabled.conf\";\n+  private boolean batchMetricsEnabled;\n+  private boolean defaultBatchMetricsEnabled = false;\n+  private ConcurrentSkipListSet<Long> batchMetricsDBSet;\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ce9e155ff2cf4984d791844dda3dac4261e1baf7"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTcwOTYyOA==", "bodyText": "This is true. Will file this as an enhancement. #415", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485709628", "createdAt": "2020-09-09T15:37:41Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -71,6 +82,11 @@\n   private final AppContext appContext;\n   private final ConfigOverridesApplier configOverridesApplier;\n \n+  public static final String BATCH_METRICS_ENABLED_CONF_FILE = \"batch_metrics_enabled.conf\";\n+  private boolean batchMetricsEnabled;\n+  private boolean defaultBatchMetricsEnabled = false;\n+  private ConcurrentSkipListSet<Long> batchMetricsDBSet;\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTIxODUxMw=="}, "originalCommit": {"oid": "ce9e155ff2cf4984d791844dda3dac4261e1baf7"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTgwMTY2OQ==", "bodyText": "So, if the reader keeps crashing every 15 seconds, there will not be much impact since the rmp waits for a I believe ~30s or longer before actually producing metricsDB files. However, I believe the issue you mention actually raises the bigger concern that metricsdb files are never cleaned up -- whether they are collected for metrics or batch metrics. As a result, if the reader crashes with the same periodicity as the metricsdb retention period (10s with just metrics processing and no batch metrics, or a peak of 60min with batch metrics) then the cluster will just accumulate a large number of metricsdb files that aren't cleaned up.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485801669", "createdAt": "2020-09-09T17:41:06Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -71,6 +82,11 @@\n   private final AppContext appContext;\n   private final ConfigOverridesApplier configOverridesApplier;\n \n+  public static final String BATCH_METRICS_ENABLED_CONF_FILE = \"batch_metrics_enabled.conf\";\n+  private boolean batchMetricsEnabled;\n+  private boolean defaultBatchMetricsEnabled = false;\n+  private ConcurrentSkipListSet<Long> batchMetricsDBSet;\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTIxODUxMw=="}, "originalCommit": {"oid": "ce9e155ff2cf4984d791844dda3dac4261e1baf7"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTkxODg1NA==", "bodyText": "yes, 15 or whatever is just a number, I was hinting at the edge case of the disk resident files not being cleaned at all and accumulating over time.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485918854", "createdAt": "2020-09-09T20:59:59Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -71,6 +82,11 @@\n   private final AppContext appContext;\n   private final ConfigOverridesApplier configOverridesApplier;\n \n+  public static final String BATCH_METRICS_ENABLED_CONF_FILE = \"batch_metrics_enabled.conf\";\n+  private boolean batchMetricsEnabled;\n+  private boolean defaultBatchMetricsEnabled = false;\n+  private ConcurrentSkipListSet<Long> batchMetricsDBSet;\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTIxODUxMw=="}, "originalCommit": {"oid": "ce9e155ff2cf4984d791844dda3dac4261e1baf7"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTk4NzQ1Mg==", "bodyText": "For this initial pr, we can just cleanup any files that were found. However, we will only close ticket #415 once we've implemented initializing the batch metrics set with the available files found on startup.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485987452", "createdAt": "2020-09-10T00:07:42Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -71,6 +82,11 @@\n   private final AppContext appContext;\n   private final ConfigOverridesApplier configOverridesApplier;\n \n+  public static final String BATCH_METRICS_ENABLED_CONF_FILE = \"batch_metrics_enabled.conf\";\n+  private boolean batchMetricsEnabled;\n+  private boolean defaultBatchMetricsEnabled = false;\n+  private ConcurrentSkipListSet<Long> batchMetricsDBSet;\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTIxODUxMw=="}, "originalCommit": {"oid": "ce9e155ff2cf4984d791844dda3dac4261e1baf7"}, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAzNDkzOTk3OnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandler.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQyMjoyMToyN1rOHOv62A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQyMzoyNjoxOFrOHOxQYQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTIyNzIyNA==", "bodyText": "nit: should we reword as something on the lines of - \"Start time and end time should be at least sampling period apart\".? It may be confusing in its current form.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485227224", "createdAt": "2020-09-08T22:21:27Z", "author": {"login": "vigyasharma"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandler.java", "diffHunk": "@@ -0,0 +1,309 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rest;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatExceptionCode;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatsCollector;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.config.PluginSettings;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metrics.MetricsRestUtil;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.model.MetricsModel;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.net.NetClient;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ReaderMetricsProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.sun.net.httpserver.HttpExchange;\n+import com.sun.net.httpserver.HttpHandler;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.net.HttpURLConnection;\n+import java.security.InvalidParameterException;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.NavigableSet;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.logging.log4j.util.Supplier;\n+import org.jooq.Record;\n+import org.jooq.Result;\n+\n+/**\n+ * Request handler that supports querying batch metrics from an EC2 instance\n+ *\n+ * <p>Return 1 minute of CPU_Utilization metrics sampled at a 5s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization&starttime=1566413975000&endtime=1566413980000\"\n+ *\n+ * <p>Return 1 minute of CPU_Utilization and Latency metrics sampled at a 10s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization,Latency&starttime=1566413975000&endtime=1566413980000&samplingperiod=10\"\n+ *\n+ * <p>Return format:\n+ * {\n+ *   \"1594412650000\": {\n+ *     \"CPU_Utilization\": {\n+ *       \"fields\": [\n+ *         {\n+ *           \"name: \"IndexName\",\n+ *           \"type\": \"VARCHAR\"\n+ *         },\n+ *         <...>\n+ *       ]\n+ *       \"records\": [\n+ *         [\n+ *           \"pmc\",\n+ *           <...>\n+ *         ],\n+ *         <...>\n+ *       ]\n+ *     }\n+ *   }\n+ * }\n+ */\n+public class QueryBatchRequestHandler extends MetricsHandler implements HttpHandler {\n+\n+  private static final Logger LOG = LogManager.getLogger(QueryBatchRequestHandler.class);\n+\n+  private static final int TIME_OUT_VALUE = 2;\n+  private static final TimeUnit TIME_OUT_UNIT = TimeUnit.SECONDS;\n+  private NetClient netClient;\n+  MetricsRestUtil metricsRestUtil;\n+\n+  public static final int DEFAULT_MAX_DATAPOINTS = 100800;  // Must be non-negative\n+  public static final long DEFAULT_SAMPLING_PERIOD_MILLIS = 5000;  // Must be a multiple of 5000\n+\n+  public QueryBatchRequestHandler(NetClient netClient, MetricsRestUtil metricsRestUtil) {\n+    this.netClient = netClient;\n+    this.metricsRestUtil = metricsRestUtil;\n+  }\n+\n+  @Override\n+  public void handle(HttpExchange exchange) throws IOException {\n+    String requestMethod = exchange.getRequestMethod();\n+    if (!requestMethod.equalsIgnoreCase(\"GET\")) {\n+      exchange.sendResponseHeaders(HttpURLConnection.HTTP_NOT_FOUND, -1);\n+      exchange.close();\n+      return;\n+    }\n+\n+    ReaderMetricsProcessor mp = ReaderMetricsProcessor.getInstance();\n+    if (mp == null) {\n+      sendResponse(\n+          exchange,\n+          \"{\\\"error\\\":\\\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\\\"}\",\n+          HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    NavigableSet<Long> batchMetrics = mp.getBatchMetrics();\n+    long currentTime = System.currentTimeMillis();\n+    if (batchMetrics == null) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"The batch metrics api has not been enabled for this node.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"The batch metrics api has not been enabled for this node.\");\n+      return;\n+    }\n+    if (batchMetrics.isEmpty()) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"There are no metrics databases. The reader has run into an issue or has just started.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"There are no metrics databases. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    exchange.getResponseHeaders().set(\"Content-Type\", \"application/json\");\n+\n+    Map<String, String> params = getParamsMap(exchange.getRequestURI().getQuery());\n+\n+    try {\n+      // Parse and validate parameters\n+      String[] validParamsTmp = {\"\", \"metrics\", \"starttime\", \"endtime\", \"samplingperiod\"};\n+      Set<String> validParams = new HashSet<>(Arrays.asList(validParamsTmp));\n+      for (String param : params.keySet()) {\n+        if (!validParams.contains(param)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid parameter\", param));\n+        }\n+      }\n+\n+      List<String> metrics = metricsRestUtil.parseArrayParam(params, \"metrics\", false);\n+      String startTimeParam = params.get(\"starttime\");\n+      String endTimeParam = params.get(\"endtime\");\n+      String samplingPeriodParam = params.get(\"samplingperiod\");\n+\n+      for (String metric : metrics) {\n+        if (!MetricsModel.ALL_METRICS.containsKey(metric)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid metric\", metric));\n+        }\n+      }\n+\n+      if (startTimeParam == null || startTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"starttime parameter must be set\");\n+      }\n+      long startTime;\n+      try {\n+        startTime = Long.parseUnsignedLong(startTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid starttime\", startTimeParam));\n+      }\n+\n+      if (endTimeParam == null || endTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"endtime parameter must be set\");\n+      }\n+      long endTime;\n+      try {\n+        endTime = Long.parseUnsignedLong(endTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid endtime\", endTimeParam));\n+      }\n+\n+      long samplingPeriod = DEFAULT_SAMPLING_PERIOD_MILLIS;\n+      if (samplingPeriodParam != null && !samplingPeriodParam.isEmpty()) {\n+        samplingPeriod = Long.parseLong(samplingPeriodParam);\n+        if (samplingPeriod < 5 || samplingPeriod % 5 != 0) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid sampling period\", samplingPeriodParam));\n+        }\n+        if (samplingPeriod >= PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60) {\n+          throw new InvalidParameterException(\"sampling period must be less than the retention period\");\n+        }\n+        samplingPeriod *= 1000;\n+      }\n+\n+      if (startTime >= endTime) {\n+        throw new InvalidParameterException(\"starttime must be less than the endtime\");\n+      }\n+      startTime -= startTime % samplingPeriod;\n+      endTime -= endTime % samplingPeriod;\n+      if (startTime == endTime) {\n+        throw new InvalidParameterException(\"starttime and endtime cannot be equal when rounded down to the nearest sampling period\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ce9e155ff2cf4984d791844dda3dac4261e1baf7"}, "originalPosition": 196}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTI0OTEyMQ==", "bodyText": "Agreed", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485249121", "createdAt": "2020-09-08T23:26:18Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandler.java", "diffHunk": "@@ -0,0 +1,309 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rest;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatExceptionCode;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatsCollector;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.config.PluginSettings;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metrics.MetricsRestUtil;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.model.MetricsModel;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.net.NetClient;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ReaderMetricsProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.sun.net.httpserver.HttpExchange;\n+import com.sun.net.httpserver.HttpHandler;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.net.HttpURLConnection;\n+import java.security.InvalidParameterException;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.NavigableSet;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.logging.log4j.util.Supplier;\n+import org.jooq.Record;\n+import org.jooq.Result;\n+\n+/**\n+ * Request handler that supports querying batch metrics from an EC2 instance\n+ *\n+ * <p>Return 1 minute of CPU_Utilization metrics sampled at a 5s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization&starttime=1566413975000&endtime=1566413980000\"\n+ *\n+ * <p>Return 1 minute of CPU_Utilization and Latency metrics sampled at a 10s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization,Latency&starttime=1566413975000&endtime=1566413980000&samplingperiod=10\"\n+ *\n+ * <p>Return format:\n+ * {\n+ *   \"1594412650000\": {\n+ *     \"CPU_Utilization\": {\n+ *       \"fields\": [\n+ *         {\n+ *           \"name: \"IndexName\",\n+ *           \"type\": \"VARCHAR\"\n+ *         },\n+ *         <...>\n+ *       ]\n+ *       \"records\": [\n+ *         [\n+ *           \"pmc\",\n+ *           <...>\n+ *         ],\n+ *         <...>\n+ *       ]\n+ *     }\n+ *   }\n+ * }\n+ */\n+public class QueryBatchRequestHandler extends MetricsHandler implements HttpHandler {\n+\n+  private static final Logger LOG = LogManager.getLogger(QueryBatchRequestHandler.class);\n+\n+  private static final int TIME_OUT_VALUE = 2;\n+  private static final TimeUnit TIME_OUT_UNIT = TimeUnit.SECONDS;\n+  private NetClient netClient;\n+  MetricsRestUtil metricsRestUtil;\n+\n+  public static final int DEFAULT_MAX_DATAPOINTS = 100800;  // Must be non-negative\n+  public static final long DEFAULT_SAMPLING_PERIOD_MILLIS = 5000;  // Must be a multiple of 5000\n+\n+  public QueryBatchRequestHandler(NetClient netClient, MetricsRestUtil metricsRestUtil) {\n+    this.netClient = netClient;\n+    this.metricsRestUtil = metricsRestUtil;\n+  }\n+\n+  @Override\n+  public void handle(HttpExchange exchange) throws IOException {\n+    String requestMethod = exchange.getRequestMethod();\n+    if (!requestMethod.equalsIgnoreCase(\"GET\")) {\n+      exchange.sendResponseHeaders(HttpURLConnection.HTTP_NOT_FOUND, -1);\n+      exchange.close();\n+      return;\n+    }\n+\n+    ReaderMetricsProcessor mp = ReaderMetricsProcessor.getInstance();\n+    if (mp == null) {\n+      sendResponse(\n+          exchange,\n+          \"{\\\"error\\\":\\\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\\\"}\",\n+          HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    NavigableSet<Long> batchMetrics = mp.getBatchMetrics();\n+    long currentTime = System.currentTimeMillis();\n+    if (batchMetrics == null) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"The batch metrics api has not been enabled for this node.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"The batch metrics api has not been enabled for this node.\");\n+      return;\n+    }\n+    if (batchMetrics.isEmpty()) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"There are no metrics databases. The reader has run into an issue or has just started.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"There are no metrics databases. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    exchange.getResponseHeaders().set(\"Content-Type\", \"application/json\");\n+\n+    Map<String, String> params = getParamsMap(exchange.getRequestURI().getQuery());\n+\n+    try {\n+      // Parse and validate parameters\n+      String[] validParamsTmp = {\"\", \"metrics\", \"starttime\", \"endtime\", \"samplingperiod\"};\n+      Set<String> validParams = new HashSet<>(Arrays.asList(validParamsTmp));\n+      for (String param : params.keySet()) {\n+        if (!validParams.contains(param)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid parameter\", param));\n+        }\n+      }\n+\n+      List<String> metrics = metricsRestUtil.parseArrayParam(params, \"metrics\", false);\n+      String startTimeParam = params.get(\"starttime\");\n+      String endTimeParam = params.get(\"endtime\");\n+      String samplingPeriodParam = params.get(\"samplingperiod\");\n+\n+      for (String metric : metrics) {\n+        if (!MetricsModel.ALL_METRICS.containsKey(metric)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid metric\", metric));\n+        }\n+      }\n+\n+      if (startTimeParam == null || startTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"starttime parameter must be set\");\n+      }\n+      long startTime;\n+      try {\n+        startTime = Long.parseUnsignedLong(startTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid starttime\", startTimeParam));\n+      }\n+\n+      if (endTimeParam == null || endTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"endtime parameter must be set\");\n+      }\n+      long endTime;\n+      try {\n+        endTime = Long.parseUnsignedLong(endTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid endtime\", endTimeParam));\n+      }\n+\n+      long samplingPeriod = DEFAULT_SAMPLING_PERIOD_MILLIS;\n+      if (samplingPeriodParam != null && !samplingPeriodParam.isEmpty()) {\n+        samplingPeriod = Long.parseLong(samplingPeriodParam);\n+        if (samplingPeriod < 5 || samplingPeriod % 5 != 0) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid sampling period\", samplingPeriodParam));\n+        }\n+        if (samplingPeriod >= PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60) {\n+          throw new InvalidParameterException(\"sampling period must be less than the retention period\");\n+        }\n+        samplingPeriod *= 1000;\n+      }\n+\n+      if (startTime >= endTime) {\n+        throw new InvalidParameterException(\"starttime must be less than the endtime\");\n+      }\n+      startTime -= startTime % samplingPeriod;\n+      endTime -= endTime % samplingPeriod;\n+      if (startTime == endTime) {\n+        throw new InvalidParameterException(\"starttime and endtime cannot be equal when rounded down to the nearest sampling period\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTIyNzIyNA=="}, "originalCommit": {"oid": "ce9e155ff2cf4984d791844dda3dac4261e1baf7"}, "originalPosition": 196}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzAzNDk0MjY3OnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandler.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQyMjoyMjozNlrOHOv8YA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQyMzozOToxNlrOHOxfjA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTIyNzYxNg==", "bodyText": "Minor: System time at node should not matter, right? Since startTime and endTime are provided as utc epoch timestamp values. We can just mention something like expected value is utc seconds since epoch timestamp and provided value is in future.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485227616", "createdAt": "2020-09-08T22:22:36Z", "author": {"login": "vigyasharma"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandler.java", "diffHunk": "@@ -0,0 +1,309 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rest;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatExceptionCode;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatsCollector;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.config.PluginSettings;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metrics.MetricsRestUtil;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.model.MetricsModel;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.net.NetClient;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ReaderMetricsProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.sun.net.httpserver.HttpExchange;\n+import com.sun.net.httpserver.HttpHandler;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.net.HttpURLConnection;\n+import java.security.InvalidParameterException;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.NavigableSet;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.logging.log4j.util.Supplier;\n+import org.jooq.Record;\n+import org.jooq.Result;\n+\n+/**\n+ * Request handler that supports querying batch metrics from an EC2 instance\n+ *\n+ * <p>Return 1 minute of CPU_Utilization metrics sampled at a 5s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization&starttime=1566413975000&endtime=1566413980000\"\n+ *\n+ * <p>Return 1 minute of CPU_Utilization and Latency metrics sampled at a 10s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization,Latency&starttime=1566413975000&endtime=1566413980000&samplingperiod=10\"\n+ *\n+ * <p>Return format:\n+ * {\n+ *   \"1594412650000\": {\n+ *     \"CPU_Utilization\": {\n+ *       \"fields\": [\n+ *         {\n+ *           \"name: \"IndexName\",\n+ *           \"type\": \"VARCHAR\"\n+ *         },\n+ *         <...>\n+ *       ]\n+ *       \"records\": [\n+ *         [\n+ *           \"pmc\",\n+ *           <...>\n+ *         ],\n+ *         <...>\n+ *       ]\n+ *     }\n+ *   }\n+ * }\n+ */\n+public class QueryBatchRequestHandler extends MetricsHandler implements HttpHandler {\n+\n+  private static final Logger LOG = LogManager.getLogger(QueryBatchRequestHandler.class);\n+\n+  private static final int TIME_OUT_VALUE = 2;\n+  private static final TimeUnit TIME_OUT_UNIT = TimeUnit.SECONDS;\n+  private NetClient netClient;\n+  MetricsRestUtil metricsRestUtil;\n+\n+  public static final int DEFAULT_MAX_DATAPOINTS = 100800;  // Must be non-negative\n+  public static final long DEFAULT_SAMPLING_PERIOD_MILLIS = 5000;  // Must be a multiple of 5000\n+\n+  public QueryBatchRequestHandler(NetClient netClient, MetricsRestUtil metricsRestUtil) {\n+    this.netClient = netClient;\n+    this.metricsRestUtil = metricsRestUtil;\n+  }\n+\n+  @Override\n+  public void handle(HttpExchange exchange) throws IOException {\n+    String requestMethod = exchange.getRequestMethod();\n+    if (!requestMethod.equalsIgnoreCase(\"GET\")) {\n+      exchange.sendResponseHeaders(HttpURLConnection.HTTP_NOT_FOUND, -1);\n+      exchange.close();\n+      return;\n+    }\n+\n+    ReaderMetricsProcessor mp = ReaderMetricsProcessor.getInstance();\n+    if (mp == null) {\n+      sendResponse(\n+          exchange,\n+          \"{\\\"error\\\":\\\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\\\"}\",\n+          HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    NavigableSet<Long> batchMetrics = mp.getBatchMetrics();\n+    long currentTime = System.currentTimeMillis();\n+    if (batchMetrics == null) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"The batch metrics api has not been enabled for this node.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"The batch metrics api has not been enabled for this node.\");\n+      return;\n+    }\n+    if (batchMetrics.isEmpty()) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"There are no metrics databases. The reader has run into an issue or has just started.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"There are no metrics databases. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    exchange.getResponseHeaders().set(\"Content-Type\", \"application/json\");\n+\n+    Map<String, String> params = getParamsMap(exchange.getRequestURI().getQuery());\n+\n+    try {\n+      // Parse and validate parameters\n+      String[] validParamsTmp = {\"\", \"metrics\", \"starttime\", \"endtime\", \"samplingperiod\"};\n+      Set<String> validParams = new HashSet<>(Arrays.asList(validParamsTmp));\n+      for (String param : params.keySet()) {\n+        if (!validParams.contains(param)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid parameter\", param));\n+        }\n+      }\n+\n+      List<String> metrics = metricsRestUtil.parseArrayParam(params, \"metrics\", false);\n+      String startTimeParam = params.get(\"starttime\");\n+      String endTimeParam = params.get(\"endtime\");\n+      String samplingPeriodParam = params.get(\"samplingperiod\");\n+\n+      for (String metric : metrics) {\n+        if (!MetricsModel.ALL_METRICS.containsKey(metric)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid metric\", metric));\n+        }\n+      }\n+\n+      if (startTimeParam == null || startTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"starttime parameter must be set\");\n+      }\n+      long startTime;\n+      try {\n+        startTime = Long.parseUnsignedLong(startTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid starttime\", startTimeParam));\n+      }\n+\n+      if (endTimeParam == null || endTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"endtime parameter must be set\");\n+      }\n+      long endTime;\n+      try {\n+        endTime = Long.parseUnsignedLong(endTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid endtime\", endTimeParam));\n+      }\n+\n+      long samplingPeriod = DEFAULT_SAMPLING_PERIOD_MILLIS;\n+      if (samplingPeriodParam != null && !samplingPeriodParam.isEmpty()) {\n+        samplingPeriod = Long.parseLong(samplingPeriodParam);\n+        if (samplingPeriod < 5 || samplingPeriod % 5 != 0) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid sampling period\", samplingPeriodParam));\n+        }\n+        if (samplingPeriod >= PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60) {\n+          throw new InvalidParameterException(\"sampling period must be less than the retention period\");\n+        }\n+        samplingPeriod *= 1000;\n+      }\n+\n+      if (startTime >= endTime) {\n+        throw new InvalidParameterException(\"starttime must be less than the endtime\");\n+      }\n+      startTime -= startTime % samplingPeriod;\n+      endTime -= endTime % samplingPeriod;\n+      if (startTime == endTime) {\n+        throw new InvalidParameterException(\"starttime and endtime cannot be equal when rounded down to the nearest sampling period\");\n+      }\n+      if (endTime > currentTime) {\n+        throw new InvalidParameterException(\"endtime can be no greater than the system time at the node\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ce9e155ff2cf4984d791844dda3dac4261e1baf7"}, "originalPosition": 199}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTI1MzAwNA==", "bodyText": "I use the phrase \"system time\" because we determine current time using System.currentTimeMillis, which in turn uses methods from the operating system. And I believe machines can be setup to indicate whatever timestamp the owner wants -- like, I could setup a computer today with a current time of January 1, 1970. So, I expose this additional detail in the error message to help anyone who might be having problems, while keeping the readme and design doc at the abstraction of utc for the standard use case.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485253004", "createdAt": "2020-09-08T23:39:16Z", "author": {"login": "ricardolstephen"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandler.java", "diffHunk": "@@ -0,0 +1,309 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rest;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatExceptionCode;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatsCollector;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.config.PluginSettings;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metrics.MetricsRestUtil;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.model.MetricsModel;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.net.NetClient;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ReaderMetricsProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.sun.net.httpserver.HttpExchange;\n+import com.sun.net.httpserver.HttpHandler;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.net.HttpURLConnection;\n+import java.security.InvalidParameterException;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.NavigableSet;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.logging.log4j.util.Supplier;\n+import org.jooq.Record;\n+import org.jooq.Result;\n+\n+/**\n+ * Request handler that supports querying batch metrics from an EC2 instance\n+ *\n+ * <p>Return 1 minute of CPU_Utilization metrics sampled at a 5s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization&starttime=1566413975000&endtime=1566413980000\"\n+ *\n+ * <p>Return 1 minute of CPU_Utilization and Latency metrics sampled at a 10s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization,Latency&starttime=1566413975000&endtime=1566413980000&samplingperiod=10\"\n+ *\n+ * <p>Return format:\n+ * {\n+ *   \"1594412650000\": {\n+ *     \"CPU_Utilization\": {\n+ *       \"fields\": [\n+ *         {\n+ *           \"name: \"IndexName\",\n+ *           \"type\": \"VARCHAR\"\n+ *         },\n+ *         <...>\n+ *       ]\n+ *       \"records\": [\n+ *         [\n+ *           \"pmc\",\n+ *           <...>\n+ *         ],\n+ *         <...>\n+ *       ]\n+ *     }\n+ *   }\n+ * }\n+ */\n+public class QueryBatchRequestHandler extends MetricsHandler implements HttpHandler {\n+\n+  private static final Logger LOG = LogManager.getLogger(QueryBatchRequestHandler.class);\n+\n+  private static final int TIME_OUT_VALUE = 2;\n+  private static final TimeUnit TIME_OUT_UNIT = TimeUnit.SECONDS;\n+  private NetClient netClient;\n+  MetricsRestUtil metricsRestUtil;\n+\n+  public static final int DEFAULT_MAX_DATAPOINTS = 100800;  // Must be non-negative\n+  public static final long DEFAULT_SAMPLING_PERIOD_MILLIS = 5000;  // Must be a multiple of 5000\n+\n+  public QueryBatchRequestHandler(NetClient netClient, MetricsRestUtil metricsRestUtil) {\n+    this.netClient = netClient;\n+    this.metricsRestUtil = metricsRestUtil;\n+  }\n+\n+  @Override\n+  public void handle(HttpExchange exchange) throws IOException {\n+    String requestMethod = exchange.getRequestMethod();\n+    if (!requestMethod.equalsIgnoreCase(\"GET\")) {\n+      exchange.sendResponseHeaders(HttpURLConnection.HTTP_NOT_FOUND, -1);\n+      exchange.close();\n+      return;\n+    }\n+\n+    ReaderMetricsProcessor mp = ReaderMetricsProcessor.getInstance();\n+    if (mp == null) {\n+      sendResponse(\n+          exchange,\n+          \"{\\\"error\\\":\\\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\\\"}\",\n+          HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    NavigableSet<Long> batchMetrics = mp.getBatchMetrics();\n+    long currentTime = System.currentTimeMillis();\n+    if (batchMetrics == null) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"The batch metrics api has not been enabled for this node.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"The batch metrics api has not been enabled for this node.\");\n+      return;\n+    }\n+    if (batchMetrics.isEmpty()) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"There are no metrics databases. The reader has run into an issue or has just started.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"There are no metrics databases. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    exchange.getResponseHeaders().set(\"Content-Type\", \"application/json\");\n+\n+    Map<String, String> params = getParamsMap(exchange.getRequestURI().getQuery());\n+\n+    try {\n+      // Parse and validate parameters\n+      String[] validParamsTmp = {\"\", \"metrics\", \"starttime\", \"endtime\", \"samplingperiod\"};\n+      Set<String> validParams = new HashSet<>(Arrays.asList(validParamsTmp));\n+      for (String param : params.keySet()) {\n+        if (!validParams.contains(param)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid parameter\", param));\n+        }\n+      }\n+\n+      List<String> metrics = metricsRestUtil.parseArrayParam(params, \"metrics\", false);\n+      String startTimeParam = params.get(\"starttime\");\n+      String endTimeParam = params.get(\"endtime\");\n+      String samplingPeriodParam = params.get(\"samplingperiod\");\n+\n+      for (String metric : metrics) {\n+        if (!MetricsModel.ALL_METRICS.containsKey(metric)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid metric\", metric));\n+        }\n+      }\n+\n+      if (startTimeParam == null || startTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"starttime parameter must be set\");\n+      }\n+      long startTime;\n+      try {\n+        startTime = Long.parseUnsignedLong(startTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid starttime\", startTimeParam));\n+      }\n+\n+      if (endTimeParam == null || endTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"endtime parameter must be set\");\n+      }\n+      long endTime;\n+      try {\n+        endTime = Long.parseUnsignedLong(endTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid endtime\", endTimeParam));\n+      }\n+\n+      long samplingPeriod = DEFAULT_SAMPLING_PERIOD_MILLIS;\n+      if (samplingPeriodParam != null && !samplingPeriodParam.isEmpty()) {\n+        samplingPeriod = Long.parseLong(samplingPeriodParam);\n+        if (samplingPeriod < 5 || samplingPeriod % 5 != 0) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid sampling period\", samplingPeriodParam));\n+        }\n+        if (samplingPeriod >= PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60) {\n+          throw new InvalidParameterException(\"sampling period must be less than the retention period\");\n+        }\n+        samplingPeriod *= 1000;\n+      }\n+\n+      if (startTime >= endTime) {\n+        throw new InvalidParameterException(\"starttime must be less than the endtime\");\n+      }\n+      startTime -= startTime % samplingPeriod;\n+      endTime -= endTime % samplingPeriod;\n+      if (startTime == endTime) {\n+        throw new InvalidParameterException(\"starttime and endtime cannot be equal when rounded down to the nearest sampling period\");\n+      }\n+      if (endTime > currentTime) {\n+        throw new InvalidParameterException(\"endtime can be no greater than the system time at the node\");", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTIyNzYxNg=="}, "originalCommit": {"oid": "ce9e155ff2cf4984d791844dda3dac4261e1baf7"}, "originalPosition": 199}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA0MDAwMjQxOnYy", "diffSide": "RIGHT", "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQwMTo0NzoxNFrOHPf8pg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQwMTo0NzoxNFrOHPf8pg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjAxNDExOA==", "bodyText": "We might skip the overhead of regex compiling by stripping off the parentPath from the prefix -  the remainder is what we are looking for in the directory.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r486014118", "createdAt": "2020-09-10T01:47:14Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -327,6 +331,36 @@ public static void deleteOnDiskFile(long windowStartTime) {\n     }\n   }\n \n+  /**\n+   * Returns the timestamps associated with on-disk files.\n+   *\n+   * @return the timestamps associated with on-disk files\n+   */\n+  public static Set<Long> listOnDiskFiles() {\n+    String prefix = PluginSettings.instance().getSettingValue(DB_FILE_PREFIX_PATH_CONF_NAME, DB_FILE_PREFIX_PATH_DEFAULT);\n+    Path prefixPath = Paths.get(prefix);\n+    Path parentPath = prefixPath.getParent();\n+    Set<Long> found = new HashSet<Long>();\n+    try (Stream<Path> paths = Files.list(parentPath)) {\n+      PathMatcher matcher = FileSystems.getDefault().getPathMatcher(\"regex:\" + prefix + \"\\\\d+\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0f935aead0f2bab3dbd912328d3f4a63ccbabae1"}, "originalPosition": 36}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2304, "cost": 1, "resetAt": "2021-11-12T20:44:06Z"}}}