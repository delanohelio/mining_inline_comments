{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDU4MDU3MzQ5", "number": 315, "title": "Batch Metrics API", "bodyText": "Issue #:\n#335\nDescription of changes:\nBatch Metrics API implementation\nAssociated PA change: opendistro-for-elasticsearch/performance-analyzer#159\nTests:\n\nTest config and cluster config requests\nTest no batch metrics files when disabled\nTest 85 metrics files when batch metrics enabled\nTest querying 5min of data\nTest querying into the future fails\nTest querying past the retention period fails\nTest with sampling periods of 5s, 10s, 20s\nTest that metricsdb files older than the retention period are cleaned up\nTest that files are cleaned up when batch metrics is disabled\nTest another enable-disable cycle\nTest that the max datapoints value (100800) is respected\nTest that invalid \"batch-metrics-retention-period-minutes\" values (0, 61) are rejected and valid values (1, 60) are accepted.\nTest that metricsdb files are not cleaned up if \"cleanup-metrics-db-files\" is disabled (verify this across multiple enable-disable cycles)\nTest that querying past the retention period fails even when \"cleanup-metrics-db-files\" is disabled\nTest that nodes with and without the batch metrics feature can co-exist in a cluster:\n\nTest that nodes with batch metrics can join the cluster and correctly enable and disable it from the cluster state.\nTest that both types of nodes can correctly enable and disable rca and logging from the cluster state without affecting the state of batch metrics\n\n\nTest that missing or corrupt metricsdb files result in the appropriate error messages.\n\nBy submitting this pull request, I confirm that my contribution is made under the terms of the Apache 2.0 license.", "createdAt": "2020-07-28T21:12:09Z", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315", "merged": true, "mergeCommit": {"oid": "7c1021c30a8bc1fe8402542784dbbe16c385230f"}, "closed": true, "closedAt": "2020-09-10T04:41:53Z", "author": {"login": "ricardolstephen"}, "timelineItems": {"totalCount": 59, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc7ujodABqjM2MjIyODQwMTI=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdHYjnsAFqTQ4NTU0NjE2Nw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "929c22686b488a46b7b18550ca81f6d2652d4bb7", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/929c22686b488a46b7b18550ca81f6d2652d4bb7", "committedDate": "2020-08-03T22:48:05Z", "message": "Fix spotbugs issues"}, "afterCommit": {"oid": "d4e6c36398e80875424d9b3e81dca19e72f35dec", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/d4e6c36398e80875424d9b3e81dca19e72f35dec", "committedDate": "2020-08-04T22:41:24Z", "message": "Fix spotbugs issues"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "089b60e7139f51d858a1e45c688e6659879f2582", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/089b60e7139f51d858a1e45c688e6659879f2582", "committedDate": "2020-08-11T17:58:51Z", "message": "Intermediate save"}, "afterCommit": {"oid": "4d6c11e5fa86b5b26cd3db950d9de1bae1ac34a6", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/4d6c11e5fa86b5b26cd3db950d9de1bae1ac34a6", "committedDate": "2020-08-13T17:18:19Z", "message": "Add unit tests and associated code changes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6e19eceb8c42f5bde9277943873dba8445105e1f", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/6e19eceb8c42f5bde9277943873dba8445105e1f", "committedDate": "2020-08-13T20:19:22Z", "message": "Add batch metrics api (untested)"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8ff9c24bd8b2ac5997af87ba13e8a673572054d6", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/8ff9c24bd8b2ac5997af87ba13e8a673572054d6", "committedDate": "2020-08-13T20:19:22Z", "message": "Read retention period from settings file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "96b327d1f2fc7abb387deaf2e345b7a9edebe4f7", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/96b327d1f2fc7abb387deaf2e345b7a9edebe4f7", "committedDate": "2020-08-13T20:19:22Z", "message": "Handle empty batch metrics set"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a3b273e474fc6556aeb867897c657fd960f10682", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/a3b273e474fc6556aeb867897c657fd960f10682", "committedDate": "2020-08-13T20:19:22Z", "message": "Remove table name from batch metrics fields"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b4f0bd6cc79d8eb5bbd954864d42b7896a4e7407", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/b4f0bd6cc79d8eb5bbd954864d42b7896a4e7407", "committedDate": "2020-08-13T20:19:22Z", "message": "Retain an extra metricsdb file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "003f8b20ebd21fa8cd24e97a60e6ecf6c159bb3d", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/003f8b20ebd21fa8cd24e97a60e6ecf6c159bb3d", "committedDate": "2020-08-13T20:19:22Z", "message": "Store retention period as minutes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f129ae0ffc68bae4689d1913b3a2f673a39b12f2", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/f129ae0ffc68bae4689d1913b3a2f673a39b12f2", "committedDate": "2020-08-13T20:19:22Z", "message": "Update starttime and endtime use\n\n- Reverse the role of starttime and endttime.\n- Check that starttime and endtime are within the retention period."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f0380d056decd22b74b6d30da98820c53f3dafe3", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/f0380d056decd22b74b6d30da98820c53f3dafe3", "committedDate": "2020-08-13T20:19:22Z", "message": "Rename period to samplingperiod"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "748a3adfef319703c4aea8bc540eb3d287c53bb4", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/748a3adfef319703c4aea8bc540eb3d287c53bb4", "committedDate": "2020-08-13T20:19:22Z", "message": "Remove maxdatapoints parameter"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f03684f47ce3e995e6b5a89098eb20278e1b2a2a", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/f03684f47ce3e995e6b5a89098eb20278e1b2a2a", "committedDate": "2020-08-13T20:19:22Z", "message": "Limit batch metrics retention period"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "158bac0adf3319d0b165c30cf9568e36b5e87608", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/158bac0adf3319d0b165c30cf9568e36b5e87608", "committedDate": "2020-08-13T20:19:22Z", "message": "Limit batch metrics sampling period"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4b11c98ff0f3fa61d532fc7e70d65584619b74a1", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/4b11c98ff0f3fa61d532fc7e70d65584619b74a1", "committedDate": "2020-08-13T20:19:22Z", "message": "Remove unnecessary exception catching"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "01eec9c933ac3b4d7c908f1f32a005475c2b947e", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/01eec9c933ac3b4d7c908f1f32a005475c2b947e", "committedDate": "2020-08-13T20:19:22Z", "message": "Fix spotbugs issues"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f46b43eb6d28543a7f2840b1cd7496939b15d642", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/f46b43eb6d28543a7f2840b1cd7496939b15d642", "committedDate": "2020-08-13T20:19:22Z", "message": "Fix checkstyle issues"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/74933f9a57ce33f391fdaedac0875c5058587995", "committedDate": "2020-08-13T20:19:22Z", "message": "Add unit tests and associated code changes"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "4d6c11e5fa86b5b26cd3db950d9de1bae1ac34a6", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/4d6c11e5fa86b5b26cd3db950d9de1bae1ac34a6", "committedDate": "2020-08-13T17:18:19Z", "message": "Add unit tests and associated code changes"}, "afterCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/74933f9a57ce33f391fdaedac0875c5058587995", "committedDate": "2020-08-13T20:19:22Z", "message": "Add unit tests and associated code changes"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY3MjQ5Mzk1", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#pullrequestreview-467249395", "createdAt": "2020-08-14T01:12:09Z", "commit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "state": "COMMENTED", "comments": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQwMToxMjoxMFrOHAkYTg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQwMTozNjozOFrOHAkvLQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM1ODA5NA==", "bodyText": "Please change the README accordingly to document the new url and details for this", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r470358094", "createdAt": "2020-08-14T01:12:10Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/PerformanceAnalyzerApp.java", "diffHunk": "@@ -66,6 +67,7 @@\n \n   private static final int EXCEPTION_QUEUE_LENGTH = 1;\n   public static final String QUERY_URL = \"/_opendistro/_performanceanalyzer/metrics\";\n+  public static final String BATCH_METRICS_URL = \"/_opendistro/_performanceanalyzer/batch\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM1ODUzMA==", "bodyText": "Can we add the time unit in the variable name such as\nBATCH_METRICS_RETENTION_PERIOD_DEFAULT_MINS and so on ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r470358530", "createdAt": "2020-08-14T01:13:21Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/config/PluginSettings.java", "diffHunk": "@@ -44,6 +45,9 @@\n   private static final int DELETION_INTERVAL_MAX = 60;\n   private static final String HTTPS_ENABLED = \"https-enabled\";\n   private static final String WRITER_QUEUE_SIZE = \"writer-queue-size\";\n+  private static final String BATCH_METRICS_RETENTION_PERIOD = \"batch-metrics-retention-period\";\n+  private static final long BATCH_METRICS_RETENTION_PERIOD_DEFAULT = 7;  // 7 minutes of metrics\n+  private static final long BATCH_METRICS_RETENTION_PERIOD_LIMIT = 60;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM1ODY2Mw==", "bodyText": "Also can we add javadoc comments describing the variables ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r470358663", "createdAt": "2020-08-14T01:14:00Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/config/PluginSettings.java", "diffHunk": "@@ -44,6 +45,9 @@\n   private static final int DELETION_INTERVAL_MAX = 60;\n   private static final String HTTPS_ENABLED = \"https-enabled\";\n   private static final String WRITER_QUEUE_SIZE = \"writer-queue-size\";\n+  private static final String BATCH_METRICS_RETENTION_PERIOD = \"batch-metrics-retention-period\";\n+  private static final long BATCH_METRICS_RETENTION_PERIOD_DEFAULT = 7;  // 7 minutes of metrics", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM1ODczNA==", "bodyText": "Please add the timeunit as the variable name", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r470358734", "createdAt": "2020-08-14T01:14:22Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/config/PluginSettings.java", "diffHunk": "@@ -59,6 +63,8 @@\n   private Properties settings;\n   private final String configFilePath;\n \n+  private long batchMetricsRetentionPeriod;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM1OTA0NA==", "bodyText": "Let's add the unit here as well, so that it is reflected in the logs", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r470359044", "createdAt": "2020-08-14T01:15:34Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/config/PluginSettings.java", "diffHunk": "@@ -156,11 +178,12 @@ private PluginSettings(String cfPath) {\n     }\n     LOG.info(\n         \"Config: metricsLocation: {}, metricsDeletionInterval: {}, httpsEnabled: {},\"\n-            + \" cleanup-metrics-db-files: {}\",\n+            + \" cleanup-metrics-db-files: {}, batch-metrics-retention-period: {}\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 73}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM2MTE3MQ==", "bodyText": "We are throwing an exception here but maybe we should just log an error and use default values ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r470361171", "createdAt": "2020-08-14T01:24:51Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/config/PluginSettings.java", "diffHunk": "@@ -271,4 +294,26 @@ private void loadMetricsDBFilesCleanupEnabled() {\n       shouldCleanupMetricsDBFiles = true;\n     }\n   }\n+\n+  private void loadBatchMetricsRetentionPeriodFromConfig() {\n+    if (!settings.containsKey(BATCH_METRICS_RETENTION_PERIOD)) {\n+      return;\n+    }\n+\n+    long parsedRetentionPeriod;\n+    try {\n+      parsedRetentionPeriod = Long.parseLong(settings.getProperty(BATCH_METRICS_RETENTION_PERIOD));\n+      if (parsedRetentionPeriod <= 0 || parsedRetentionPeriod > BATCH_METRICS_RETENTION_PERIOD_LIMIT) {\n+        throw new InvalidParameterException();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM2MTYyNg==", "bodyText": "same here. Log error and then we should just use the defaults.\nAlso you can log error simply as:\nLOG.error(\"my error message: {}\", myParam)", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r470361626", "createdAt": "2020-08-14T01:26:40Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/config/PluginSettings.java", "diffHunk": "@@ -271,4 +294,26 @@ private void loadMetricsDBFilesCleanupEnabled() {\n       shouldCleanupMetricsDBFiles = true;\n     }\n   }\n+\n+  private void loadBatchMetricsRetentionPeriodFromConfig() {\n+    if (!settings.containsKey(BATCH_METRICS_RETENTION_PERIOD)) {\n+      return;\n+    }\n+\n+    long parsedRetentionPeriod;\n+    try {\n+      parsedRetentionPeriod = Long.parseLong(settings.getProperty(BATCH_METRICS_RETENTION_PERIOD));\n+      if (parsedRetentionPeriod <= 0 || parsedRetentionPeriod > BATCH_METRICS_RETENTION_PERIOD_LIMIT) {\n+        throw new InvalidParameterException();\n+      }\n+      batchMetricsRetentionPeriod = parsedRetentionPeriod;\n+    } catch (NumberFormatException | InvalidParameterException e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"Invalid batch-metrics-retention-period. Using default value {}.\", batchMetricsRetentionPeriod),\n+              e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 106}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM2MzUxNQ==", "bodyText": "The new changes should not crash the system. we should handle this gracefully.\nAlso, can we add javadoc comments to public methods ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r470363515", "createdAt": "2020-08-14T01:34:43Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -84,6 +85,15 @@ public MetricsDB(long windowStartTime) throws Exception {\n     create = DSL.using(conn, SQLDialect.SQLITE);\n   }\n \n+  public static MetricsDB fetchExisting(long windowStartTime) throws Exception {\n+    String filePath = PluginSettings.instance()\n+            .getSettingValue(DB_FILE_PREFIX_PATH_CONF_NAME, DB_FILE_PREFIX_PATH_DEFAULT) + windowStartTime;\n+    if (!(new File(filePath)).exists()) {\n+      throw new FileNotFoundException(String.format(\"MetricsDB file %s could not be found.\", filePath));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 31}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM2MzczOA==", "bodyText": "Can we return empty Object instead of null ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r470363738", "createdAt": "2020-08-14T01:35:39Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -239,6 +249,21 @@ public void putMetric(Metric<Double> metric, Dimensions dimensions, long windowS\n     return create.select().from(DSL.table(metric)).fetch();\n   }\n \n+  public Result<Record> queryMetric(String metric, Collection<String> dimensions, int limit) {\n+    if (!DBUtils.checkIfTableExists(create, metric)) {\n+      return null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM2Mzk0OQ==", "bodyText": "This is too late to validate if the limit is negative. Maybe we should do it up in the call handling stack ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r470363949", "createdAt": "2020-08-14T01:36:38Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -239,6 +249,21 @@ public void putMetric(Metric<Double> metric, Dimensions dimensions, long windowS\n     return create.select().from(DSL.table(metric)).fetch();\n   }\n \n+  public Result<Record> queryMetric(String metric, Collection<String> dimensions, int limit) {\n+    if (!DBUtils.checkIfTableExists(create, metric)) {\n+      return null;\n+    }\n+    if (limit < 0) {\n+      throw new IllegalArgumentException(\"Limit must be non-negative\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 48}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDcxODM1NTk2", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#pullrequestreview-471835596", "createdAt": "2020-08-20T17:30:00Z", "commit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQxNzozMDowMFrOHEMLFA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yMFQxODoyNzoxNVrOHEOFBg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE1NTc5Ng==", "bodyText": "Sruti has a PR out,#389 that prevents the Reader from starting if the parsed config is invalid. You can set this to 0 and call ConfigStatus.INSTANCE.setConfigurationInvalid()", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r474155796", "createdAt": "2020-08-20T17:30:00Z", "author": {"login": "sidheart"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/config/PluginSettings.java", "diffHunk": "@@ -271,4 +294,26 @@ private void loadMetricsDBFilesCleanupEnabled() {\n       shouldCleanupMetricsDBFiles = true;\n     }\n   }\n+\n+  private void loadBatchMetricsRetentionPeriodFromConfig() {\n+    if (!settings.containsKey(BATCH_METRICS_RETENTION_PERIOD)) {\n+      return;\n+    }\n+\n+    long parsedRetentionPeriod;\n+    try {\n+      parsedRetentionPeriod = Long.parseLong(settings.getProperty(BATCH_METRICS_RETENTION_PERIOD));\n+      if (parsedRetentionPeriod <= 0 || parsedRetentionPeriod > BATCH_METRICS_RETENTION_PERIOD_LIMIT) {\n+        throw new InvalidParameterException();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM2MTE3MQ=="}, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE1NjkzNQ==", "bodyText": "^ but LOG.error(\"my error message: {}\", myParam, e) so that you get the exception stacktrace (note that the stacktrace doesn't need a {} string)", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r474156935", "createdAt": "2020-08-20T17:32:07Z", "author": {"login": "sidheart"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/config/PluginSettings.java", "diffHunk": "@@ -271,4 +294,26 @@ private void loadMetricsDBFilesCleanupEnabled() {\n       shouldCleanupMetricsDBFiles = true;\n     }\n   }\n+\n+  private void loadBatchMetricsRetentionPeriodFromConfig() {\n+    if (!settings.containsKey(BATCH_METRICS_RETENTION_PERIOD)) {\n+      return;\n+    }\n+\n+    long parsedRetentionPeriod;\n+    try {\n+      parsedRetentionPeriod = Long.parseLong(settings.getProperty(BATCH_METRICS_RETENTION_PERIOD));\n+      if (parsedRetentionPeriod <= 0 || parsedRetentionPeriod > BATCH_METRICS_RETENTION_PERIOD_LIMIT) {\n+        throw new InvalidParameterException();\n+      }\n+      batchMetricsRetentionPeriod = parsedRetentionPeriod;\n+    } catch (NumberFormatException | InvalidParameterException e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"Invalid batch-metrics-retention-period. Using default value {}.\", batchMetricsRetentionPeriod),\n+              e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM2MTYyNg=="}, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 106}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE1NzY3NA==", "bodyText": "call getDBFilePath()", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r474157674", "createdAt": "2020-08-20T17:33:27Z", "author": {"login": "sidheart"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -84,6 +85,15 @@ public MetricsDB(long windowStartTime) throws Exception {\n     create = DSL.using(conn, SQLDialect.SQLITE);\n   }\n \n+  public static MetricsDB fetchExisting(long windowStartTime) throws Exception {\n+    String filePath = PluginSettings.instance()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE1OTcxNQ==", "bodyText": "getDBFilePath()", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r474159715", "createdAt": "2020-08-20T17:36:58Z", "author": {"login": "sidheart"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -259,6 +284,19 @@ public void deleteOnDiskFile() {\n     }\n   }\n \n+  public static void deleteOnDiskFile(long windowStartTime) {\n+    String dbFilePath = PluginSettings.instance()\n+            .getSettingValue(DB_FILE_PREFIX_PATH_CONF_NAME, DB_FILE_PREFIX_PATH_DEFAULT) + windowStartTime;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 67}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE2OTY3OA==", "bodyText": "Just initialize batchMetricsEnabled to false instead of having 2 variables", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r474169678", "createdAt": "2020-08-20T17:55:19Z", "author": {"login": "sidheart"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -71,6 +82,11 @@\n   private final AppContext appContext;\n   private final ConfigOverridesApplier configOverridesApplier;\n \n+  public static final String BATCH_METRICS_ENABLED_CONF_FILE = \"batch_metrics_enabled.conf\";\n+  private boolean batchMetricsEnabled;\n+  private boolean defaultBatchMetricsEnabled = false;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE3Mzg4MQ==", "bodyText": "by lowest do you mean oldest?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r474173881", "createdAt": "2020-08-20T18:02:58Z", "author": {"login": "sidheart"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -201,8 +219,41 @@ public void trimOldSnapshots() throws Exception {\n     trimMap(shardRqMetricsMap, RQ_SNAPSHOTS);\n     trimMap(httpRqMetricsMap, HTTP_RQ_SNAPSHOTS);\n     trimMap(masterEventMetricsMap, MASTER_EVENT_SNAPSHOTS);\n-    trimDatabases(\n-        metricsDBMap, MAX_DATABASES, PluginSettings.instance().shouldCleanupMetricsDBFiles());\n+\n+    boolean deleteDBFiles = PluginSettings.instance().shouldCleanupMetricsDBFiles();\n+    if (metricsDBMap.size() > MAX_DATABASES) {\n+      Map.Entry<Long, MetricsDB> lowestEntry = metricsDBMap.pollFirstEntry();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE4MDU3MQ==", "bodyText": "This logic should be placed into the trimDatabases function", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r474180571", "createdAt": "2020-08-20T18:15:30Z", "author": {"login": "sidheart"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -201,8 +219,41 @@ public void trimOldSnapshots() throws Exception {\n     trimMap(shardRqMetricsMap, RQ_SNAPSHOTS);\n     trimMap(httpRqMetricsMap, HTTP_RQ_SNAPSHOTS);\n     trimMap(masterEventMetricsMap, MASTER_EVENT_SNAPSHOTS);\n-    trimDatabases(\n-        metricsDBMap, MAX_DATABASES, PluginSettings.instance().shouldCleanupMetricsDBFiles());\n+\n+    boolean deleteDBFiles = PluginSettings.instance().shouldCleanupMetricsDBFiles();\n+    if (metricsDBMap.size() > MAX_DATABASES) {\n+      Map.Entry<Long, MetricsDB> lowestEntry = metricsDBMap.pollFirstEntry();\n+      if (lowestEntry != null) {\n+        Long key = lowestEntry.getKey();\n+        MetricsDB value = lowestEntry.getValue();\n+        value.remove();\n+        if (deleteDBFiles && !batchMetricsDBSet.contains(key)) {\n+          value.deleteOnDiskFile();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE4NDYxNg==", "bodyText": "Add a comment about why you're using 12 b/c of the 5s snapshots. Also make it evident that the retention period is in minutes", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r474184616", "createdAt": "2020-08-20T18:22:58Z", "author": {"login": "sidheart"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -696,6 +750,24 @@ public void deleteDBs() throws Exception {\n     }\n   }\n \n+  /**\n+   * This is called by operations outside of the ReaderMetricsProcessor.\n+   *\n+   * @return A list of the timestamps associated with MetricsDB files. The oldest of the MetricsDB files typically\n+   *     have a lifetime of ~SAMPLING_INTERVAL seconds (no less than SAMPLING_INTERVAL/2 seconds). Null if batch\n+   *     metrics is disabled.\n+   */\n+  public NavigableSet<Long> getBatchMetrics() {\n+    if (batchMetricsEnabled) {\n+      TreeSet<Long> batchMetricsDBSetCopy = new TreeSet<>(batchMetricsDBSet.clone());\n+      while (batchMetricsDBSetCopy.size() > PluginSettings.instance().getBatchMetricsRetentionPeriod() * 12) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 122}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE4NjcyNg==", "bodyText": "This should be a while loop", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r474186726", "createdAt": "2020-08-20T18:26:45Z", "author": {"login": "sidheart"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -201,8 +219,41 @@ public void trimOldSnapshots() throws Exception {\n     trimMap(shardRqMetricsMap, RQ_SNAPSHOTS);\n     trimMap(httpRqMetricsMap, HTTP_RQ_SNAPSHOTS);\n     trimMap(masterEventMetricsMap, MASTER_EVENT_SNAPSHOTS);\n-    trimDatabases(\n-        metricsDBMap, MAX_DATABASES, PluginSettings.instance().shouldCleanupMetricsDBFiles());\n+\n+    boolean deleteDBFiles = PluginSettings.instance().shouldCleanupMetricsDBFiles();\n+    if (metricsDBMap.size() > MAX_DATABASES) {\n+      Map.Entry<Long, MetricsDB> lowestEntry = metricsDBMap.pollFirstEntry();\n+      if (lowestEntry != null) {\n+        Long key = lowestEntry.getKey();\n+        MetricsDB value = lowestEntry.getValue();\n+        value.remove();\n+        if (deleteDBFiles && !batchMetricsDBSet.contains(key)) {\n+          value.deleteOnDiskFile();\n+        }\n+      }\n+    }\n+    // Flush any tracking batch metrics if batch metrics is disabled. Note, in order to ensure that batch metrics\n+    // consumers have had at least one cycle to use any metrics they may be holding, this flush is done before\n+    // re-reading the config file to update the state of the batch metrics feature.\n+    if (!batchMetricsEnabled && !batchMetricsDBSet.isEmpty()) {\n+      if (deleteDBFiles) {\n+        for (Long timestamp : batchMetricsDBSet) {\n+          if (!metricsDBMap.containsKey(timestamp)) {\n+            MetricsDB.deleteOnDiskFile(timestamp);\n+          }\n+        }\n+      }\n+      batchMetricsDBSet.clear();\n+    }\n+    readBatchMetricsEnabledFromConf();\n+    // The (retentionPeriod * 12 + 1)'th database can be safely removed, since getBatchMetrics never returns more than\n+    // the (retentionPeriod * 12) freshest metrics files.\n+    if (batchMetricsDBSet.size() > PluginSettings.instance().getBatchMetricsRetentionPeriod() * 12 + 1) {\n+      Long timestamp = batchMetricsDBSet.pollFirst();\n+      if (deleteDBFiles && !metricsDBMap.containsKey(timestamp)) {\n+        MetricsDB.deleteOnDiskFile(timestamp);\n+      }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 93}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE4NzAxNA==", "bodyText": "This should be a while loop", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r474187014", "createdAt": "2020-08-20T18:27:15Z", "author": {"login": "sidheart"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -201,8 +219,41 @@ public void trimOldSnapshots() throws Exception {\n     trimMap(shardRqMetricsMap, RQ_SNAPSHOTS);\n     trimMap(httpRqMetricsMap, HTTP_RQ_SNAPSHOTS);\n     trimMap(masterEventMetricsMap, MASTER_EVENT_SNAPSHOTS);\n-    trimDatabases(\n-        metricsDBMap, MAX_DATABASES, PluginSettings.instance().shouldCleanupMetricsDBFiles());\n+\n+    boolean deleteDBFiles = PluginSettings.instance().shouldCleanupMetricsDBFiles();\n+    if (metricsDBMap.size() > MAX_DATABASES) {\n+      Map.Entry<Long, MetricsDB> lowestEntry = metricsDBMap.pollFirstEntry();\n+      if (lowestEntry != null) {\n+        Long key = lowestEntry.getKey();\n+        MetricsDB value = lowestEntry.getValue();\n+        value.remove();\n+        if (deleteDBFiles && !batchMetricsDBSet.contains(key)) {\n+          value.deleteOnDiskFile();\n+        }\n+      }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 71}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "078693bb1f3744c0d1d7e2f1eec5cb6a9002c5ed", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/078693bb1f3744c0d1d7e2f1eec5cb6a9002c5ed", "committedDate": "2020-08-24T17:22:27Z", "message": "Add time unit to the batch-metrics-retention-period variable"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dc1e23735ec9dde2468070dd47cd24891718eb29", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/dc1e23735ec9dde2468070dd47cd24891718eb29", "committedDate": "2020-08-24T20:05:09Z", "message": "Add more documentation"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "23d3e1c35c47104b2b90dedad5f2dfae903d22c7", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/23d3e1c35c47104b2b90dedad5f2dfae903d22c7", "committedDate": "2020-08-24T20:05:42Z", "message": "Use while loops in trimOldSnapshots"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f732e1398fddf965273b61ed7704fed0544f567a", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/f732e1398fddf965273b61ed7704fed0544f567a", "committedDate": "2020-08-24T22:24:01Z", "message": "Use default batch metrics enabled value if unable to read the conf file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8ae238206d3db960c8d4ce28c1dfa6ef2fdeaeaf", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/8ae238206d3db960c8d4ce28c1dfa6ef2fdeaeaf", "committedDate": "2020-08-24T22:30:46Z", "message": "Cleanup declaration of parsedRetentionPeriod"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9bc6a141d7bc7f68957da3016a175a924a67f263", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/9bc6a141d7bc7f68957da3016a175a924a67f263", "committedDate": "2020-08-25T02:56:54Z", "message": "Fix error string for when max datapoints is exceeded"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e2f856bf687d4749dc4d3ebec026aa0a6b06c2ef", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/e2f856bf687d4749dc4d3ebec026aa0a6b06c2ef", "committedDate": "2020-08-25T03:44:39Z", "message": "Cleanup error logging call"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDc3ODk5NDg0", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#pullrequestreview-477899484", "createdAt": "2020-08-28T17:17:31Z", "commit": {"oid": "e2f856bf687d4749dc4d3ebec026aa0a6b06c2ef"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxNzoxNzozMlrOHJOdKg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxNzoxOTo1OVrOHJOh-A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQzNjA3NA==", "bodyText": "The way you have it now, the same logic is in 2 different places. Change getDBFilePath to call a function like\nstatic String getActualFilePath(long windowStartTime) {\n// PluginSettings.instance().getSettingValue(...)\n}\nhave getDBFilePath and fetchExisting call this method", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r479436074", "createdAt": "2020-08-28T17:17:32Z", "author": {"login": "sidheart"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -84,6 +85,15 @@ public MetricsDB(long windowStartTime) throws Exception {\n     create = DSL.using(conn, SQLDialect.SQLITE);\n   }\n \n+  public static MetricsDB fetchExisting(long windowStartTime) throws Exception {\n+    String filePath = PluginSettings.instance()", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE1NzY3NA=="}, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 28}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQzNzMwNA==", "bodyText": "See above", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r479437304", "createdAt": "2020-08-28T17:19:59Z", "author": {"login": "sidheart"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -259,6 +284,19 @@ public void deleteOnDiskFile() {\n     }\n   }\n \n+  public static void deleteOnDiskFile(long windowStartTime) {\n+    String dbFilePath = PluginSettings.instance()\n+            .getSettingValue(DB_FILE_PREFIX_PATH_CONF_NAME, DB_FILE_PREFIX_PATH_DEFAULT) + windowStartTime;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3NDE1OTcxNQ=="}, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 67}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDc3OTIyNTU0", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#pullrequestreview-477922554", "createdAt": "2020-08-28T17:55:24Z", "commit": {"oid": "e2f856bf687d4749dc4d3ebec026aa0a6b06c2ef"}, "state": "DISMISSED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQxNzo1NToyNFrOHJPj_Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOFQyMToxOToxMVrOHJUv0g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTQ1NDIwNQ==", "bodyText": "Your documentation says we round down, but this is rounding up right? I don't care which you go with, but make it consistent.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r479454205", "createdAt": "2020-08-28T17:55:24Z", "author": {"login": "sidheart"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandler.java", "diffHunk": "@@ -0,0 +1,309 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rest;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatExceptionCode;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatsCollector;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.config.PluginSettings;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metrics.MetricsRestUtil;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.model.MetricsModel;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.net.NetClient;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ReaderMetricsProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.sun.net.httpserver.HttpExchange;\n+import com.sun.net.httpserver.HttpHandler;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.net.HttpURLConnection;\n+import java.security.InvalidParameterException;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.NavigableSet;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.logging.log4j.util.Supplier;\n+import org.jooq.Record;\n+import org.jooq.Result;\n+\n+/**\n+ * Request handler that supports querying batch metrics from an EC2 instance\n+ *\n+ * <p>Return 1 minute of CPU_Utilization metrics sampled at a 5s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization&starttime=1566413975000&endtime=1566413980000\"\n+ *\n+ * <p>Return 1 minute of CPU_Utilization and Latency metrics sampled at a 10s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization,Latency&starttime=1566413975000&endtime=1566413980000&samplingperiod=10\"\n+ *\n+ * <p>Return format:\n+ * {\n+ *   \"1594412650000\": {\n+ *     \"CPU_Utilization\": {\n+ *       \"fields\": [\n+ *         {\n+ *           \"name: \"IndexName\",\n+ *           \"type\": \"VARCHAR\"\n+ *         },\n+ *         <...>\n+ *       ]\n+ *       \"records\": [\n+ *         [\n+ *           \"pmc\",\n+ *           <...>\n+ *         ],\n+ *         <...>\n+ *       ]\n+ *     }\n+ *   }\n+ * }\n+ */\n+public class QueryBatchRequestHandler extends MetricsHandler implements HttpHandler {\n+\n+  private static final Logger LOG = LogManager.getLogger(QueryBatchRequestHandler.class);\n+\n+  private static final int TIME_OUT_VALUE = 2;\n+  private static final TimeUnit TIME_OUT_UNIT = TimeUnit.SECONDS;\n+  private NetClient netClient;\n+  MetricsRestUtil metricsRestUtil;\n+\n+  public static final int DEFAULT_MAX_DATAPOINTS = 100800;  // Must be non-negative\n+  public static final long DEFAULT_SAMPLING_PERIOD = 5000;  // Must be a multiple of 5000\n+\n+  public QueryBatchRequestHandler(NetClient netClient, MetricsRestUtil metricsRestUtil) {\n+    this.netClient = netClient;\n+    this.metricsRestUtil = metricsRestUtil;\n+  }\n+\n+  @Override\n+  public void handle(HttpExchange exchange) throws IOException {\n+    String requestMethod = exchange.getRequestMethod();\n+    if (!requestMethod.equalsIgnoreCase(\"GET\")) {\n+      exchange.sendResponseHeaders(HttpURLConnection.HTTP_NOT_FOUND, -1);\n+      exchange.close();\n+      return;\n+    }\n+\n+    ReaderMetricsProcessor mp = ReaderMetricsProcessor.getInstance();\n+    if (mp == null) {\n+      sendResponse(\n+          exchange,\n+          \"{\\\"error\\\":\\\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\\\"}\",\n+          HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    NavigableSet<Long> batchMetrics = mp.getBatchMetrics();\n+    long currentTime = System.currentTimeMillis();\n+    if (batchMetrics == null) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"The batch metrics api has not been enabled for this node.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"The batch metrics api has not been enabled for this node.\");\n+      return;\n+    }\n+    if (batchMetrics.isEmpty()) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"There are no metrics databases. The reader has run into an issue or has just started.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"There are no metrics databases. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    exchange.getResponseHeaders().set(\"Content-Type\", \"application/json\");\n+\n+    Map<String, String> params = getParamsMap(exchange.getRequestURI().getQuery());\n+\n+    try {\n+      // Parse and validate parameters\n+      String[] validParamsTmp = {\"\", \"metrics\", \"starttime\", \"endtime\", \"samplingperiod\", \"maxdatapoints\"};\n+      Set<String> validParams = new HashSet<>(Arrays.asList(validParamsTmp));\n+      for (String param : params.keySet()) {\n+        if (!validParams.contains(param)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid parameter\", param));\n+        }\n+      }\n+\n+      List<String> metrics = metricsRestUtil.parseArrayParam(params, \"metrics\", false);\n+      String startTimeParam = params.get(\"starttime\");\n+      String endTimeParam = params.get(\"endtime\");\n+      String samplingPeriodParam = params.get(\"samplingperiod\");\n+\n+      for (String metric : metrics) {\n+        if (!MetricsModel.ALL_METRICS.containsKey(metric)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid metric\", metric));\n+        }\n+      }\n+\n+      if (startTimeParam == null || startTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"starttime parameter must be set\");\n+      }\n+      long startTime;\n+      try {\n+        startTime = Long.parseUnsignedLong(startTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid starttime\", startTimeParam));\n+      }\n+\n+      if (endTimeParam == null || endTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"endtime parameter must be set\");\n+      }\n+      long endTime;\n+      try {\n+        endTime = Long.parseUnsignedLong(endTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid endtime\", endTimeParam));\n+      }\n+\n+      long samplingPeriod = DEFAULT_SAMPLING_PERIOD;\n+      if (samplingPeriodParam != null && !samplingPeriodParam.isEmpty()) {\n+        samplingPeriod = Long.parseLong(samplingPeriodParam);\n+        if (samplingPeriod < 5 || samplingPeriod % 5 != 0) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid sampling period\", samplingPeriodParam));\n+        }\n+        if (samplingPeriod >= PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60) {\n+          throw new InvalidParameterException(\"sampling period must be less than the retention period\");\n+        }\n+        samplingPeriod *= 1000;\n+      }\n+\n+      if (startTime >= endTime) {\n+        throw new InvalidParameterException(\"starttime must be less than the endtime\");\n+      }\n+      startTime -= startTime % samplingPeriod;\n+      endTime -= endTime % samplingPeriod;\n+      if (startTime == endTime) {\n+        throw new InvalidParameterException(\"starttime and endtime cannot be equal when rounded down to the nearest sampling period\");\n+      }\n+      if (endTime > currentTime) {\n+        throw new InvalidParameterException(\"endtime can be no greater than the system time at the node\");\n+      }\n+      if (startTime < currentTime - PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60 * 1000) {\n+        throw new InvalidParameterException(\"starttime must be within the retention period\");\n+      }\n+\n+      String queryResponse = queryFromBatchMetrics(batchMetrics, metrics, startTime, endTime, samplingPeriod,\n+              DEFAULT_MAX_DATAPOINTS);\n+      sendResponse(exchange, queryResponse, HttpURLConnection.HTTP_OK);\n+    } catch (InvalidParameterException e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.getMessage() + \".\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_BAD_REQUEST);\n+    } catch (Exception e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.toString() + \"\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_INTERNAL_ERROR);\n+    }\n+  }\n+\n+  @VisibleForTesting\n+  public int appendMetrics(Long timestamp, List<String> metrics, StringBuilder builder, int maxDatapoints) throws Exception {\n+    maxDatapoints += 1;\n+    builder.append(\"\\\"\");\n+    builder.append(timestamp);\n+    builder.append(\"\\\":{\");\n+    MetricsDB db = MetricsDB.fetchExisting(timestamp);\n+    for (int metricIndex = 0, numMetrics = metrics.size(); metricIndex < numMetrics; metricIndex++) {\n+      String metric = metrics.get(metricIndex);\n+      Result<Record> results = db.queryMetric(metric, MetricsModel.ALL_METRICS.get(metric).dimensionNames, maxDatapoints);\n+      if (results != null) {\n+        maxDatapoints -= results.size();\n+        if (maxDatapoints == 0) {\n+          throw new InvalidParameterException(String.format(\"requested data exceeds the %d datapoints limit\", DEFAULT_MAX_DATAPOINTS));\n+        }\n+        builder.append(\"\\\"\");\n+        builder.append(metric);\n+        builder.append(\"\\\":\");\n+        builder.append(results.formatJSON());\n+        for (metricIndex += 1; metricIndex < numMetrics; metricIndex++) {\n+          metric = metrics.get(metricIndex);\n+          results = db.queryMetric(metric, MetricsModel.ALL_METRICS.get(metric).dimensionNames, maxDatapoints);\n+          if (results != null) {\n+            maxDatapoints -= results.size();\n+            if (maxDatapoints == 0) {\n+              throw new InvalidParameterException(String.format(\"requested data exceeds the %d datapoints limit\", DEFAULT_MAX_DATAPOINTS));\n+            }\n+            builder.append(\",\\\"\");\n+            builder.append(metric);\n+            builder.append(\"\\\":\");\n+            builder.append(results.formatJSON());\n+          }\n+        }\n+      }\n+    }\n+    builder.append(\"}\");\n+    db.remove();\n+    return maxDatapoints - 1;\n+  }\n+\n+  /**\n+   * Requires non-empty batchMetrics, valid non-empty metrics, valid startTime, valid endTime,\n+   * valid samplingPeriod (in milliseconds), and non-negative maxDatapoints.\n+   */\n+  @VisibleForTesting\n+  public String queryFromBatchMetrics(NavigableSet<Long> batchMetrics, List<String> metrics, long startTime,\n+                                      long endTime, long samplingPeriod, int maxDatapoints) throws Exception {\n+    StringBuilder responseJson = new StringBuilder();\n+    responseJson.append(\"{\");\n+    Long metricsTimestamp = batchMetrics.ceiling(startTime);\n+    if (metricsTimestamp != null && metricsTimestamp < endTime) {\n+      maxDatapoints = appendMetrics(metricsTimestamp, metrics, responseJson, maxDatapoints);\n+      metricsTimestamp = metricsTimestamp - metricsTimestamp % samplingPeriod + samplingPeriod;\n+      metricsTimestamp = batchMetrics.ceiling(metricsTimestamp);\n+      while (metricsTimestamp != null && metricsTimestamp < endTime) {\n+        responseJson.append(\",\");\n+        maxDatapoints = appendMetrics(metricsTimestamp, metrics, responseJson, maxDatapoints);\n+        metricsTimestamp = metricsTimestamp - metricsTimestamp % samplingPeriod + samplingPeriod;\n+        metricsTimestamp = batchMetrics.ceiling(metricsTimestamp);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2f856bf687d4749dc4d3ebec026aa0a6b06c2ef"}, "originalPosition": 293}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTUzOTAyNw==", "bodyText": "I've already commented on this to Ricardo. I think it's better to avoid tight coupling between the JSON response construction and the actual sampling and querying of the metrics.\nHowever, since today there are no components that would actually need the batching logic outside of the REST layer, and since this is an L0 solution, I've said that I'd note my concern here and +1.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r479539027", "createdAt": "2020-08-28T21:18:49Z", "author": {"login": "sidheart"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandler.java", "diffHunk": "@@ -0,0 +1,309 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rest;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatExceptionCode;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatsCollector;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.config.PluginSettings;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metrics.MetricsRestUtil;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.model.MetricsModel;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.net.NetClient;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ReaderMetricsProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.sun.net.httpserver.HttpExchange;\n+import com.sun.net.httpserver.HttpHandler;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.net.HttpURLConnection;\n+import java.security.InvalidParameterException;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.NavigableSet;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.logging.log4j.util.Supplier;\n+import org.jooq.Record;\n+import org.jooq.Result;\n+\n+/**\n+ * Request handler that supports querying batch metrics from an EC2 instance\n+ *\n+ * <p>Return 1 minute of CPU_Utilization metrics sampled at a 5s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization&starttime=1566413975000&endtime=1566413980000\"\n+ *\n+ * <p>Return 1 minute of CPU_Utilization and Latency metrics sampled at a 10s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization,Latency&starttime=1566413975000&endtime=1566413980000&samplingperiod=10\"\n+ *\n+ * <p>Return format:\n+ * {\n+ *   \"1594412650000\": {\n+ *     \"CPU_Utilization\": {\n+ *       \"fields\": [\n+ *         {\n+ *           \"name: \"IndexName\",\n+ *           \"type\": \"VARCHAR\"\n+ *         },\n+ *         <...>\n+ *       ]\n+ *       \"records\": [\n+ *         [\n+ *           \"pmc\",\n+ *           <...>\n+ *         ],\n+ *         <...>\n+ *       ]\n+ *     }\n+ *   }\n+ * }\n+ */\n+public class QueryBatchRequestHandler extends MetricsHandler implements HttpHandler {\n+\n+  private static final Logger LOG = LogManager.getLogger(QueryBatchRequestHandler.class);\n+\n+  private static final int TIME_OUT_VALUE = 2;\n+  private static final TimeUnit TIME_OUT_UNIT = TimeUnit.SECONDS;\n+  private NetClient netClient;\n+  MetricsRestUtil metricsRestUtil;\n+\n+  public static final int DEFAULT_MAX_DATAPOINTS = 100800;  // Must be non-negative\n+  public static final long DEFAULT_SAMPLING_PERIOD = 5000;  // Must be a multiple of 5000\n+\n+  public QueryBatchRequestHandler(NetClient netClient, MetricsRestUtil metricsRestUtil) {\n+    this.netClient = netClient;\n+    this.metricsRestUtil = metricsRestUtil;\n+  }\n+\n+  @Override\n+  public void handle(HttpExchange exchange) throws IOException {\n+    String requestMethod = exchange.getRequestMethod();\n+    if (!requestMethod.equalsIgnoreCase(\"GET\")) {\n+      exchange.sendResponseHeaders(HttpURLConnection.HTTP_NOT_FOUND, -1);\n+      exchange.close();\n+      return;\n+    }\n+\n+    ReaderMetricsProcessor mp = ReaderMetricsProcessor.getInstance();\n+    if (mp == null) {\n+      sendResponse(\n+          exchange,\n+          \"{\\\"error\\\":\\\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\\\"}\",\n+          HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    NavigableSet<Long> batchMetrics = mp.getBatchMetrics();\n+    long currentTime = System.currentTimeMillis();\n+    if (batchMetrics == null) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"The batch metrics api has not been enabled for this node.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"The batch metrics api has not been enabled for this node.\");\n+      return;\n+    }\n+    if (batchMetrics.isEmpty()) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"There are no metrics databases. The reader has run into an issue or has just started.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"There are no metrics databases. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    exchange.getResponseHeaders().set(\"Content-Type\", \"application/json\");\n+\n+    Map<String, String> params = getParamsMap(exchange.getRequestURI().getQuery());\n+\n+    try {\n+      // Parse and validate parameters\n+      String[] validParamsTmp = {\"\", \"metrics\", \"starttime\", \"endtime\", \"samplingperiod\", \"maxdatapoints\"};\n+      Set<String> validParams = new HashSet<>(Arrays.asList(validParamsTmp));\n+      for (String param : params.keySet()) {\n+        if (!validParams.contains(param)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid parameter\", param));\n+        }\n+      }\n+\n+      List<String> metrics = metricsRestUtil.parseArrayParam(params, \"metrics\", false);\n+      String startTimeParam = params.get(\"starttime\");\n+      String endTimeParam = params.get(\"endtime\");\n+      String samplingPeriodParam = params.get(\"samplingperiod\");\n+\n+      for (String metric : metrics) {\n+        if (!MetricsModel.ALL_METRICS.containsKey(metric)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid metric\", metric));\n+        }\n+      }\n+\n+      if (startTimeParam == null || startTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"starttime parameter must be set\");\n+      }\n+      long startTime;\n+      try {\n+        startTime = Long.parseUnsignedLong(startTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid starttime\", startTimeParam));\n+      }\n+\n+      if (endTimeParam == null || endTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"endtime parameter must be set\");\n+      }\n+      long endTime;\n+      try {\n+        endTime = Long.parseUnsignedLong(endTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid endtime\", endTimeParam));\n+      }\n+\n+      long samplingPeriod = DEFAULT_SAMPLING_PERIOD;\n+      if (samplingPeriodParam != null && !samplingPeriodParam.isEmpty()) {\n+        samplingPeriod = Long.parseLong(samplingPeriodParam);\n+        if (samplingPeriod < 5 || samplingPeriod % 5 != 0) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid sampling period\", samplingPeriodParam));\n+        }\n+        if (samplingPeriod >= PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60) {\n+          throw new InvalidParameterException(\"sampling period must be less than the retention period\");\n+        }\n+        samplingPeriod *= 1000;\n+      }\n+\n+      if (startTime >= endTime) {\n+        throw new InvalidParameterException(\"starttime must be less than the endtime\");\n+      }\n+      startTime -= startTime % samplingPeriod;\n+      endTime -= endTime % samplingPeriod;\n+      if (startTime == endTime) {\n+        throw new InvalidParameterException(\"starttime and endtime cannot be equal when rounded down to the nearest sampling period\");\n+      }\n+      if (endTime > currentTime) {\n+        throw new InvalidParameterException(\"endtime can be no greater than the system time at the node\");\n+      }\n+      if (startTime < currentTime - PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60 * 1000) {\n+        throw new InvalidParameterException(\"starttime must be within the retention period\");\n+      }\n+\n+      String queryResponse = queryFromBatchMetrics(batchMetrics, metrics, startTime, endTime, samplingPeriod,\n+              DEFAULT_MAX_DATAPOINTS);\n+      sendResponse(exchange, queryResponse, HttpURLConnection.HTTP_OK);\n+    } catch (InvalidParameterException e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.getMessage() + \".\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_BAD_REQUEST);\n+    } catch (Exception e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.toString() + \"\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_INTERNAL_ERROR);\n+    }\n+  }\n+\n+  @VisibleForTesting\n+  public int appendMetrics(Long timestamp, List<String> metrics, StringBuilder builder, int maxDatapoints) throws Exception {\n+    maxDatapoints += 1;\n+    builder.append(\"\\\"\");\n+    builder.append(timestamp);\n+    builder.append(\"\\\":{\");\n+    MetricsDB db = MetricsDB.fetchExisting(timestamp);\n+    for (int metricIndex = 0, numMetrics = metrics.size(); metricIndex < numMetrics; metricIndex++) {\n+      String metric = metrics.get(metricIndex);\n+      Result<Record> results = db.queryMetric(metric, MetricsModel.ALL_METRICS.get(metric).dimensionNames, maxDatapoints);\n+      if (results != null) {\n+        maxDatapoints -= results.size();\n+        if (maxDatapoints == 0) {\n+          throw new InvalidParameterException(String.format(\"requested data exceeds the %d datapoints limit\", DEFAULT_MAX_DATAPOINTS));\n+        }\n+        builder.append(\"\\\"\");\n+        builder.append(metric);\n+        builder.append(\"\\\":\");\n+        builder.append(results.formatJSON());\n+        for (metricIndex += 1; metricIndex < numMetrics; metricIndex++) {\n+          metric = metrics.get(metricIndex);\n+          results = db.queryMetric(metric, MetricsModel.ALL_METRICS.get(metric).dimensionNames, maxDatapoints);\n+          if (results != null) {\n+            maxDatapoints -= results.size();\n+            if (maxDatapoints == 0) {\n+              throw new InvalidParameterException(String.format(\"requested data exceeds the %d datapoints limit\", DEFAULT_MAX_DATAPOINTS));\n+            }\n+            builder.append(\",\\\"\");\n+            builder.append(metric);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2f856bf687d4749dc4d3ebec026aa0a6b06c2ef"}, "originalPosition": 263}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTUzOTE1NA==", "bodyText": "Does anyone else have a strong opinion on this? @yojs @vigyasharma", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r479539154", "createdAt": "2020-08-28T21:19:11Z", "author": {"login": "sidheart"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandler.java", "diffHunk": "@@ -0,0 +1,309 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rest;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatExceptionCode;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatsCollector;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.config.PluginSettings;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metrics.MetricsRestUtil;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.model.MetricsModel;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.net.NetClient;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ReaderMetricsProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.sun.net.httpserver.HttpExchange;\n+import com.sun.net.httpserver.HttpHandler;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.net.HttpURLConnection;\n+import java.security.InvalidParameterException;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.NavigableSet;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.logging.log4j.util.Supplier;\n+import org.jooq.Record;\n+import org.jooq.Result;\n+\n+/**\n+ * Request handler that supports querying batch metrics from an EC2 instance\n+ *\n+ * <p>Return 1 minute of CPU_Utilization metrics sampled at a 5s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization&starttime=1566413975000&endtime=1566413980000\"\n+ *\n+ * <p>Return 1 minute of CPU_Utilization and Latency metrics sampled at a 10s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization,Latency&starttime=1566413975000&endtime=1566413980000&samplingperiod=10\"\n+ *\n+ * <p>Return format:\n+ * {\n+ *   \"1594412650000\": {\n+ *     \"CPU_Utilization\": {\n+ *       \"fields\": [\n+ *         {\n+ *           \"name: \"IndexName\",\n+ *           \"type\": \"VARCHAR\"\n+ *         },\n+ *         <...>\n+ *       ]\n+ *       \"records\": [\n+ *         [\n+ *           \"pmc\",\n+ *           <...>\n+ *         ],\n+ *         <...>\n+ *       ]\n+ *     }\n+ *   }\n+ * }\n+ */\n+public class QueryBatchRequestHandler extends MetricsHandler implements HttpHandler {\n+\n+  private static final Logger LOG = LogManager.getLogger(QueryBatchRequestHandler.class);\n+\n+  private static final int TIME_OUT_VALUE = 2;\n+  private static final TimeUnit TIME_OUT_UNIT = TimeUnit.SECONDS;\n+  private NetClient netClient;\n+  MetricsRestUtil metricsRestUtil;\n+\n+  public static final int DEFAULT_MAX_DATAPOINTS = 100800;  // Must be non-negative\n+  public static final long DEFAULT_SAMPLING_PERIOD = 5000;  // Must be a multiple of 5000\n+\n+  public QueryBatchRequestHandler(NetClient netClient, MetricsRestUtil metricsRestUtil) {\n+    this.netClient = netClient;\n+    this.metricsRestUtil = metricsRestUtil;\n+  }\n+\n+  @Override\n+  public void handle(HttpExchange exchange) throws IOException {\n+    String requestMethod = exchange.getRequestMethod();\n+    if (!requestMethod.equalsIgnoreCase(\"GET\")) {\n+      exchange.sendResponseHeaders(HttpURLConnection.HTTP_NOT_FOUND, -1);\n+      exchange.close();\n+      return;\n+    }\n+\n+    ReaderMetricsProcessor mp = ReaderMetricsProcessor.getInstance();\n+    if (mp == null) {\n+      sendResponse(\n+          exchange,\n+          \"{\\\"error\\\":\\\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\\\"}\",\n+          HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    NavigableSet<Long> batchMetrics = mp.getBatchMetrics();\n+    long currentTime = System.currentTimeMillis();\n+    if (batchMetrics == null) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"The batch metrics api has not been enabled for this node.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"The batch metrics api has not been enabled for this node.\");\n+      return;\n+    }\n+    if (batchMetrics.isEmpty()) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"There are no metrics databases. The reader has run into an issue or has just started.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"There are no metrics databases. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    exchange.getResponseHeaders().set(\"Content-Type\", \"application/json\");\n+\n+    Map<String, String> params = getParamsMap(exchange.getRequestURI().getQuery());\n+\n+    try {\n+      // Parse and validate parameters\n+      String[] validParamsTmp = {\"\", \"metrics\", \"starttime\", \"endtime\", \"samplingperiod\", \"maxdatapoints\"};\n+      Set<String> validParams = new HashSet<>(Arrays.asList(validParamsTmp));\n+      for (String param : params.keySet()) {\n+        if (!validParams.contains(param)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid parameter\", param));\n+        }\n+      }\n+\n+      List<String> metrics = metricsRestUtil.parseArrayParam(params, \"metrics\", false);\n+      String startTimeParam = params.get(\"starttime\");\n+      String endTimeParam = params.get(\"endtime\");\n+      String samplingPeriodParam = params.get(\"samplingperiod\");\n+\n+      for (String metric : metrics) {\n+        if (!MetricsModel.ALL_METRICS.containsKey(metric)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid metric\", metric));\n+        }\n+      }\n+\n+      if (startTimeParam == null || startTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"starttime parameter must be set\");\n+      }\n+      long startTime;\n+      try {\n+        startTime = Long.parseUnsignedLong(startTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid starttime\", startTimeParam));\n+      }\n+\n+      if (endTimeParam == null || endTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"endtime parameter must be set\");\n+      }\n+      long endTime;\n+      try {\n+        endTime = Long.parseUnsignedLong(endTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid endtime\", endTimeParam));\n+      }\n+\n+      long samplingPeriod = DEFAULT_SAMPLING_PERIOD;\n+      if (samplingPeriodParam != null && !samplingPeriodParam.isEmpty()) {\n+        samplingPeriod = Long.parseLong(samplingPeriodParam);\n+        if (samplingPeriod < 5 || samplingPeriod % 5 != 0) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid sampling period\", samplingPeriodParam));\n+        }\n+        if (samplingPeriod >= PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60) {\n+          throw new InvalidParameterException(\"sampling period must be less than the retention period\");\n+        }\n+        samplingPeriod *= 1000;\n+      }\n+\n+      if (startTime >= endTime) {\n+        throw new InvalidParameterException(\"starttime must be less than the endtime\");\n+      }\n+      startTime -= startTime % samplingPeriod;\n+      endTime -= endTime % samplingPeriod;\n+      if (startTime == endTime) {\n+        throw new InvalidParameterException(\"starttime and endtime cannot be equal when rounded down to the nearest sampling period\");\n+      }\n+      if (endTime > currentTime) {\n+        throw new InvalidParameterException(\"endtime can be no greater than the system time at the node\");\n+      }\n+      if (startTime < currentTime - PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60 * 1000) {\n+        throw new InvalidParameterException(\"starttime must be within the retention period\");\n+      }\n+\n+      String queryResponse = queryFromBatchMetrics(batchMetrics, metrics, startTime, endTime, samplingPeriod,\n+              DEFAULT_MAX_DATAPOINTS);\n+      sendResponse(exchange, queryResponse, HttpURLConnection.HTTP_OK);\n+    } catch (InvalidParameterException e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.getMessage() + \".\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_BAD_REQUEST);\n+    } catch (Exception e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.toString() + \"\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_INTERNAL_ERROR);\n+    }\n+  }\n+\n+  @VisibleForTesting\n+  public int appendMetrics(Long timestamp, List<String> metrics, StringBuilder builder, int maxDatapoints) throws Exception {\n+    maxDatapoints += 1;\n+    builder.append(\"\\\"\");\n+    builder.append(timestamp);\n+    builder.append(\"\\\":{\");\n+    MetricsDB db = MetricsDB.fetchExisting(timestamp);\n+    for (int metricIndex = 0, numMetrics = metrics.size(); metricIndex < numMetrics; metricIndex++) {\n+      String metric = metrics.get(metricIndex);\n+      Result<Record> results = db.queryMetric(metric, MetricsModel.ALL_METRICS.get(metric).dimensionNames, maxDatapoints);\n+      if (results != null) {\n+        maxDatapoints -= results.size();\n+        if (maxDatapoints == 0) {\n+          throw new InvalidParameterException(String.format(\"requested data exceeds the %d datapoints limit\", DEFAULT_MAX_DATAPOINTS));\n+        }\n+        builder.append(\"\\\"\");\n+        builder.append(metric);\n+        builder.append(\"\\\":\");\n+        builder.append(results.formatJSON());\n+        for (metricIndex += 1; metricIndex < numMetrics; metricIndex++) {\n+          metric = metrics.get(metricIndex);\n+          results = db.queryMetric(metric, MetricsModel.ALL_METRICS.get(metric).dimensionNames, maxDatapoints);\n+          if (results != null) {\n+            maxDatapoints -= results.size();\n+            if (maxDatapoints == 0) {\n+              throw new InvalidParameterException(String.format(\"requested data exceeds the %d datapoints limit\", DEFAULT_MAX_DATAPOINTS));\n+            }\n+            builder.append(\",\\\"\");\n+            builder.append(metric);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTUzOTAyNw=="}, "originalCommit": {"oid": "e2f856bf687d4749dc4d3ebec026aa0a6b06c2ef"}, "originalPosition": 263}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDc4NzMyMTI2", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#pullrequestreview-478732126", "createdAt": "2020-08-31T15:46:57Z", "commit": {"oid": "e2f856bf687d4749dc4d3ebec026aa0a6b06c2ef"}, "state": "DISMISSED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQxNTo0Njo1OFrOHJ-WMw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0zMVQxNTo1NTo1MFrOHJ-q9w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDIyMDcyMw==", "bodyText": "nit: indicate this is in millis", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r480220723", "createdAt": "2020-08-31T15:46:58Z", "author": {"login": "vigyasharma"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandler.java", "diffHunk": "@@ -0,0 +1,309 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rest;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatExceptionCode;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatsCollector;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.config.PluginSettings;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metrics.MetricsRestUtil;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.model.MetricsModel;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.net.NetClient;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ReaderMetricsProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.sun.net.httpserver.HttpExchange;\n+import com.sun.net.httpserver.HttpHandler;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.net.HttpURLConnection;\n+import java.security.InvalidParameterException;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.NavigableSet;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.logging.log4j.util.Supplier;\n+import org.jooq.Record;\n+import org.jooq.Result;\n+\n+/**\n+ * Request handler that supports querying batch metrics from an EC2 instance\n+ *\n+ * <p>Return 1 minute of CPU_Utilization metrics sampled at a 5s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization&starttime=1566413975000&endtime=1566413980000\"\n+ *\n+ * <p>Return 1 minute of CPU_Utilization and Latency metrics sampled at a 10s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization,Latency&starttime=1566413975000&endtime=1566413980000&samplingperiod=10\"\n+ *\n+ * <p>Return format:\n+ * {\n+ *   \"1594412650000\": {\n+ *     \"CPU_Utilization\": {\n+ *       \"fields\": [\n+ *         {\n+ *           \"name: \"IndexName\",\n+ *           \"type\": \"VARCHAR\"\n+ *         },\n+ *         <...>\n+ *       ]\n+ *       \"records\": [\n+ *         [\n+ *           \"pmc\",\n+ *           <...>\n+ *         ],\n+ *         <...>\n+ *       ]\n+ *     }\n+ *   }\n+ * }\n+ */\n+public class QueryBatchRequestHandler extends MetricsHandler implements HttpHandler {\n+\n+  private static final Logger LOG = LogManager.getLogger(QueryBatchRequestHandler.class);\n+\n+  private static final int TIME_OUT_VALUE = 2;\n+  private static final TimeUnit TIME_OUT_UNIT = TimeUnit.SECONDS;\n+  private NetClient netClient;\n+  MetricsRestUtil metricsRestUtil;\n+\n+  public static final int DEFAULT_MAX_DATAPOINTS = 100800;  // Must be non-negative\n+  public static final long DEFAULT_SAMPLING_PERIOD = 5000;  // Must be a multiple of 5000", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2f856bf687d4749dc4d3ebec026aa0a6b06c2ef"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDIyNDcyOA==", "bodyText": "Can results.size() be > maxDatapoints ? Can DEFAULT_MAX_DATAPOINTS be overridden by any config (in which case we should use the derived limit in msg or simply maxDatapoints) ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r480224728", "createdAt": "2020-08-31T15:53:36Z", "author": {"login": "vigyasharma"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandler.java", "diffHunk": "@@ -0,0 +1,309 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rest;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatExceptionCode;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatsCollector;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.config.PluginSettings;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metrics.MetricsRestUtil;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.model.MetricsModel;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.net.NetClient;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ReaderMetricsProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.sun.net.httpserver.HttpExchange;\n+import com.sun.net.httpserver.HttpHandler;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.net.HttpURLConnection;\n+import java.security.InvalidParameterException;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.NavigableSet;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.logging.log4j.util.Supplier;\n+import org.jooq.Record;\n+import org.jooq.Result;\n+\n+/**\n+ * Request handler that supports querying batch metrics from an EC2 instance\n+ *\n+ * <p>Return 1 minute of CPU_Utilization metrics sampled at a 5s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization&starttime=1566413975000&endtime=1566413980000\"\n+ *\n+ * <p>Return 1 minute of CPU_Utilization and Latency metrics sampled at a 10s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization,Latency&starttime=1566413975000&endtime=1566413980000&samplingperiod=10\"\n+ *\n+ * <p>Return format:\n+ * {\n+ *   \"1594412650000\": {\n+ *     \"CPU_Utilization\": {\n+ *       \"fields\": [\n+ *         {\n+ *           \"name: \"IndexName\",\n+ *           \"type\": \"VARCHAR\"\n+ *         },\n+ *         <...>\n+ *       ]\n+ *       \"records\": [\n+ *         [\n+ *           \"pmc\",\n+ *           <...>\n+ *         ],\n+ *         <...>\n+ *       ]\n+ *     }\n+ *   }\n+ * }\n+ */\n+public class QueryBatchRequestHandler extends MetricsHandler implements HttpHandler {\n+\n+  private static final Logger LOG = LogManager.getLogger(QueryBatchRequestHandler.class);\n+\n+  private static final int TIME_OUT_VALUE = 2;\n+  private static final TimeUnit TIME_OUT_UNIT = TimeUnit.SECONDS;\n+  private NetClient netClient;\n+  MetricsRestUtil metricsRestUtil;\n+\n+  public static final int DEFAULT_MAX_DATAPOINTS = 100800;  // Must be non-negative\n+  public static final long DEFAULT_SAMPLING_PERIOD = 5000;  // Must be a multiple of 5000\n+\n+  public QueryBatchRequestHandler(NetClient netClient, MetricsRestUtil metricsRestUtil) {\n+    this.netClient = netClient;\n+    this.metricsRestUtil = metricsRestUtil;\n+  }\n+\n+  @Override\n+  public void handle(HttpExchange exchange) throws IOException {\n+    String requestMethod = exchange.getRequestMethod();\n+    if (!requestMethod.equalsIgnoreCase(\"GET\")) {\n+      exchange.sendResponseHeaders(HttpURLConnection.HTTP_NOT_FOUND, -1);\n+      exchange.close();\n+      return;\n+    }\n+\n+    ReaderMetricsProcessor mp = ReaderMetricsProcessor.getInstance();\n+    if (mp == null) {\n+      sendResponse(\n+          exchange,\n+          \"{\\\"error\\\":\\\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\\\"}\",\n+          HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    NavigableSet<Long> batchMetrics = mp.getBatchMetrics();\n+    long currentTime = System.currentTimeMillis();\n+    if (batchMetrics == null) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"The batch metrics api has not been enabled for this node.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"The batch metrics api has not been enabled for this node.\");\n+      return;\n+    }\n+    if (batchMetrics.isEmpty()) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"There are no metrics databases. The reader has run into an issue or has just started.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"There are no metrics databases. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    exchange.getResponseHeaders().set(\"Content-Type\", \"application/json\");\n+\n+    Map<String, String> params = getParamsMap(exchange.getRequestURI().getQuery());\n+\n+    try {\n+      // Parse and validate parameters\n+      String[] validParamsTmp = {\"\", \"metrics\", \"starttime\", \"endtime\", \"samplingperiod\", \"maxdatapoints\"};\n+      Set<String> validParams = new HashSet<>(Arrays.asList(validParamsTmp));\n+      for (String param : params.keySet()) {\n+        if (!validParams.contains(param)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid parameter\", param));\n+        }\n+      }\n+\n+      List<String> metrics = metricsRestUtil.parseArrayParam(params, \"metrics\", false);\n+      String startTimeParam = params.get(\"starttime\");\n+      String endTimeParam = params.get(\"endtime\");\n+      String samplingPeriodParam = params.get(\"samplingperiod\");\n+\n+      for (String metric : metrics) {\n+        if (!MetricsModel.ALL_METRICS.containsKey(metric)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid metric\", metric));\n+        }\n+      }\n+\n+      if (startTimeParam == null || startTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"starttime parameter must be set\");\n+      }\n+      long startTime;\n+      try {\n+        startTime = Long.parseUnsignedLong(startTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid starttime\", startTimeParam));\n+      }\n+\n+      if (endTimeParam == null || endTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"endtime parameter must be set\");\n+      }\n+      long endTime;\n+      try {\n+        endTime = Long.parseUnsignedLong(endTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid endtime\", endTimeParam));\n+      }\n+\n+      long samplingPeriod = DEFAULT_SAMPLING_PERIOD;\n+      if (samplingPeriodParam != null && !samplingPeriodParam.isEmpty()) {\n+        samplingPeriod = Long.parseLong(samplingPeriodParam);\n+        if (samplingPeriod < 5 || samplingPeriod % 5 != 0) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid sampling period\", samplingPeriodParam));\n+        }\n+        if (samplingPeriod >= PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60) {\n+          throw new InvalidParameterException(\"sampling period must be less than the retention period\");\n+        }\n+        samplingPeriod *= 1000;\n+      }\n+\n+      if (startTime >= endTime) {\n+        throw new InvalidParameterException(\"starttime must be less than the endtime\");\n+      }\n+      startTime -= startTime % samplingPeriod;\n+      endTime -= endTime % samplingPeriod;\n+      if (startTime == endTime) {\n+        throw new InvalidParameterException(\"starttime and endtime cannot be equal when rounded down to the nearest sampling period\");\n+      }\n+      if (endTime > currentTime) {\n+        throw new InvalidParameterException(\"endtime can be no greater than the system time at the node\");\n+      }\n+      if (startTime < currentTime - PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60 * 1000) {\n+        throw new InvalidParameterException(\"starttime must be within the retention period\");\n+      }\n+\n+      String queryResponse = queryFromBatchMetrics(batchMetrics, metrics, startTime, endTime, samplingPeriod,\n+              DEFAULT_MAX_DATAPOINTS);\n+      sendResponse(exchange, queryResponse, HttpURLConnection.HTTP_OK);\n+    } catch (InvalidParameterException e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.getMessage() + \".\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_BAD_REQUEST);\n+    } catch (Exception e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.toString() + \"\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_INTERNAL_ERROR);\n+    }\n+  }\n+\n+  @VisibleForTesting\n+  public int appendMetrics(Long timestamp, List<String> metrics, StringBuilder builder, int maxDatapoints) throws Exception {\n+    maxDatapoints += 1;\n+    builder.append(\"\\\"\");\n+    builder.append(timestamp);\n+    builder.append(\"\\\":{\");\n+    MetricsDB db = MetricsDB.fetchExisting(timestamp);\n+    for (int metricIndex = 0, numMetrics = metrics.size(); metricIndex < numMetrics; metricIndex++) {\n+      String metric = metrics.get(metricIndex);\n+      Result<Record> results = db.queryMetric(metric, MetricsModel.ALL_METRICS.get(metric).dimensionNames, maxDatapoints);\n+      if (results != null) {\n+        maxDatapoints -= results.size();\n+        if (maxDatapoints == 0) {\n+          throw new InvalidParameterException(String.format(\"requested data exceeds the %d datapoints limit\", DEFAULT_MAX_DATAPOINTS));\n+        }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e2f856bf687d4749dc4d3ebec026aa0a6b06c2ef"}, "originalPosition": 249}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDIyNjAzOQ==", "bodyText": "+1. why do we have to manually construct the json? Can't we just have a Batch Metrics Response object and use libraries to parse it into json strings?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r480226039", "createdAt": "2020-08-31T15:55:50Z", "author": {"login": "vigyasharma"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandler.java", "diffHunk": "@@ -0,0 +1,309 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rest;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatExceptionCode;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatsCollector;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.config.PluginSettings;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metrics.MetricsRestUtil;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.model.MetricsModel;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.net.NetClient;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ReaderMetricsProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.sun.net.httpserver.HttpExchange;\n+import com.sun.net.httpserver.HttpHandler;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.net.HttpURLConnection;\n+import java.security.InvalidParameterException;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.NavigableSet;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.logging.log4j.util.Supplier;\n+import org.jooq.Record;\n+import org.jooq.Result;\n+\n+/**\n+ * Request handler that supports querying batch metrics from an EC2 instance\n+ *\n+ * <p>Return 1 minute of CPU_Utilization metrics sampled at a 5s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization&starttime=1566413975000&endtime=1566413980000\"\n+ *\n+ * <p>Return 1 minute of CPU_Utilization and Latency metrics sampled at a 10s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization,Latency&starttime=1566413975000&endtime=1566413980000&samplingperiod=10\"\n+ *\n+ * <p>Return format:\n+ * {\n+ *   \"1594412650000\": {\n+ *     \"CPU_Utilization\": {\n+ *       \"fields\": [\n+ *         {\n+ *           \"name: \"IndexName\",\n+ *           \"type\": \"VARCHAR\"\n+ *         },\n+ *         <...>\n+ *       ]\n+ *       \"records\": [\n+ *         [\n+ *           \"pmc\",\n+ *           <...>\n+ *         ],\n+ *         <...>\n+ *       ]\n+ *     }\n+ *   }\n+ * }\n+ */\n+public class QueryBatchRequestHandler extends MetricsHandler implements HttpHandler {\n+\n+  private static final Logger LOG = LogManager.getLogger(QueryBatchRequestHandler.class);\n+\n+  private static final int TIME_OUT_VALUE = 2;\n+  private static final TimeUnit TIME_OUT_UNIT = TimeUnit.SECONDS;\n+  private NetClient netClient;\n+  MetricsRestUtil metricsRestUtil;\n+\n+  public static final int DEFAULT_MAX_DATAPOINTS = 100800;  // Must be non-negative\n+  public static final long DEFAULT_SAMPLING_PERIOD = 5000;  // Must be a multiple of 5000\n+\n+  public QueryBatchRequestHandler(NetClient netClient, MetricsRestUtil metricsRestUtil) {\n+    this.netClient = netClient;\n+    this.metricsRestUtil = metricsRestUtil;\n+  }\n+\n+  @Override\n+  public void handle(HttpExchange exchange) throws IOException {\n+    String requestMethod = exchange.getRequestMethod();\n+    if (!requestMethod.equalsIgnoreCase(\"GET\")) {\n+      exchange.sendResponseHeaders(HttpURLConnection.HTTP_NOT_FOUND, -1);\n+      exchange.close();\n+      return;\n+    }\n+\n+    ReaderMetricsProcessor mp = ReaderMetricsProcessor.getInstance();\n+    if (mp == null) {\n+      sendResponse(\n+          exchange,\n+          \"{\\\"error\\\":\\\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\\\"}\",\n+          HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    NavigableSet<Long> batchMetrics = mp.getBatchMetrics();\n+    long currentTime = System.currentTimeMillis();\n+    if (batchMetrics == null) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"The batch metrics api has not been enabled for this node.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"The batch metrics api has not been enabled for this node.\");\n+      return;\n+    }\n+    if (batchMetrics.isEmpty()) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"There are no metrics databases. The reader has run into an issue or has just started.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"There are no metrics databases. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    exchange.getResponseHeaders().set(\"Content-Type\", \"application/json\");\n+\n+    Map<String, String> params = getParamsMap(exchange.getRequestURI().getQuery());\n+\n+    try {\n+      // Parse and validate parameters\n+      String[] validParamsTmp = {\"\", \"metrics\", \"starttime\", \"endtime\", \"samplingperiod\", \"maxdatapoints\"};\n+      Set<String> validParams = new HashSet<>(Arrays.asList(validParamsTmp));\n+      for (String param : params.keySet()) {\n+        if (!validParams.contains(param)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid parameter\", param));\n+        }\n+      }\n+\n+      List<String> metrics = metricsRestUtil.parseArrayParam(params, \"metrics\", false);\n+      String startTimeParam = params.get(\"starttime\");\n+      String endTimeParam = params.get(\"endtime\");\n+      String samplingPeriodParam = params.get(\"samplingperiod\");\n+\n+      for (String metric : metrics) {\n+        if (!MetricsModel.ALL_METRICS.containsKey(metric)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid metric\", metric));\n+        }\n+      }\n+\n+      if (startTimeParam == null || startTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"starttime parameter must be set\");\n+      }\n+      long startTime;\n+      try {\n+        startTime = Long.parseUnsignedLong(startTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid starttime\", startTimeParam));\n+      }\n+\n+      if (endTimeParam == null || endTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"endtime parameter must be set\");\n+      }\n+      long endTime;\n+      try {\n+        endTime = Long.parseUnsignedLong(endTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid endtime\", endTimeParam));\n+      }\n+\n+      long samplingPeriod = DEFAULT_SAMPLING_PERIOD;\n+      if (samplingPeriodParam != null && !samplingPeriodParam.isEmpty()) {\n+        samplingPeriod = Long.parseLong(samplingPeriodParam);\n+        if (samplingPeriod < 5 || samplingPeriod % 5 != 0) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid sampling period\", samplingPeriodParam));\n+        }\n+        if (samplingPeriod >= PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60) {\n+          throw new InvalidParameterException(\"sampling period must be less than the retention period\");\n+        }\n+        samplingPeriod *= 1000;\n+      }\n+\n+      if (startTime >= endTime) {\n+        throw new InvalidParameterException(\"starttime must be less than the endtime\");\n+      }\n+      startTime -= startTime % samplingPeriod;\n+      endTime -= endTime % samplingPeriod;\n+      if (startTime == endTime) {\n+        throw new InvalidParameterException(\"starttime and endtime cannot be equal when rounded down to the nearest sampling period\");\n+      }\n+      if (endTime > currentTime) {\n+        throw new InvalidParameterException(\"endtime can be no greater than the system time at the node\");\n+      }\n+      if (startTime < currentTime - PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60 * 1000) {\n+        throw new InvalidParameterException(\"starttime must be within the retention period\");\n+      }\n+\n+      String queryResponse = queryFromBatchMetrics(batchMetrics, metrics, startTime, endTime, samplingPeriod,\n+              DEFAULT_MAX_DATAPOINTS);\n+      sendResponse(exchange, queryResponse, HttpURLConnection.HTTP_OK);\n+    } catch (InvalidParameterException e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.getMessage() + \".\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_BAD_REQUEST);\n+    } catch (Exception e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.toString() + \"\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_INTERNAL_ERROR);\n+    }\n+  }\n+\n+  @VisibleForTesting\n+  public int appendMetrics(Long timestamp, List<String> metrics, StringBuilder builder, int maxDatapoints) throws Exception {\n+    maxDatapoints += 1;\n+    builder.append(\"\\\"\");\n+    builder.append(timestamp);\n+    builder.append(\"\\\":{\");\n+    MetricsDB db = MetricsDB.fetchExisting(timestamp);\n+    for (int metricIndex = 0, numMetrics = metrics.size(); metricIndex < numMetrics; metricIndex++) {\n+      String metric = metrics.get(metricIndex);\n+      Result<Record> results = db.queryMetric(metric, MetricsModel.ALL_METRICS.get(metric).dimensionNames, maxDatapoints);\n+      if (results != null) {\n+        maxDatapoints -= results.size();\n+        if (maxDatapoints == 0) {\n+          throw new InvalidParameterException(String.format(\"requested data exceeds the %d datapoints limit\", DEFAULT_MAX_DATAPOINTS));\n+        }\n+        builder.append(\"\\\"\");\n+        builder.append(metric);\n+        builder.append(\"\\\":\");\n+        builder.append(results.formatJSON());\n+        for (metricIndex += 1; metricIndex < numMetrics; metricIndex++) {\n+          metric = metrics.get(metricIndex);\n+          results = db.queryMetric(metric, MetricsModel.ALL_METRICS.get(metric).dimensionNames, maxDatapoints);\n+          if (results != null) {\n+            maxDatapoints -= results.size();\n+            if (maxDatapoints == 0) {\n+              throw new InvalidParameterException(String.format(\"requested data exceeds the %d datapoints limit\", DEFAULT_MAX_DATAPOINTS));\n+            }\n+            builder.append(\",\\\"\");\n+            builder.append(metric);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTUzOTAyNw=="}, "originalCommit": {"oid": "e2f856bf687d4749dc4d3ebec026aa0a6b06c2ef"}, "originalPosition": 263}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f1008f0ef3b58433b9fd77ab95e3c4a8a70fae31", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/f1008f0ef3b58433b9fd77ab95e3c4a8a70fae31", "committedDate": "2020-09-01T22:16:55Z", "message": "Add a common method for getting MetricsDB file paths"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e687a8cddadaea9f70b700688d18e9b9360eae51", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/e687a8cddadaea9f70b700688d18e9b9360eae51", "committedDate": "2020-09-01T22:47:25Z", "message": "Rename DEFAULT_SAMPLING_PERIOD to include MILLIS"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/563905e58200952a10e150dc5956112d2a502fe6", "committedDate": "2020-09-04T02:15:40Z", "message": "Remove maxdatapoints query parameter"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY3MjU3Njg1", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#pullrequestreview-467257685", "createdAt": "2020-08-14T01:44:03Z", "commit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "state": "COMMENTED", "comments": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQwMTo0NDowM1rOHAk1sw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQyMTo1MzozNVrOHNcc6Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDM2NTYxOQ==", "bodyText": "Looks like this is only being called from methods that are themselves marked as VisibleForTesting. Can we mark this as such as well ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r470365619", "createdAt": "2020-08-14T01:44:03Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -84,6 +85,15 @@ public MetricsDB(long windowStartTime) throws Exception {\n     create = DSL.using(conn, SQLDialect.SQLITE);\n   }\n \n+  public static MetricsDB fetchExisting(long windowStartTime) throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "74933f9a57ce33f391fdaedac0875c5058587995"}, "originalPosition": 27}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzgzNjMxNQ==", "bodyText": "I think that we should log error and use the default in this case. I would think of it as should I bail out of PA if someone configures a wrong value for batch metric retention period ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483836315", "createdAt": "2020-09-04T20:43:30Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/config/PluginSettings.java", "diffHunk": "@@ -271,4 +295,21 @@ private void loadMetricsDBFilesCleanupEnabled() {\n       shouldCleanupMetricsDBFiles = true;\n     }\n   }\n+\n+  private void loadBatchMetricsRetentionPeriodMinutesFromConfig() {\n+    if (!settings.containsKey(BATCH_METRICS_RETENTION_PERIOD_MINUTES)) {\n+      return;\n+    }\n+\n+    try {\n+      long parsedRetentionPeriod = Long.parseLong(settings.getProperty(BATCH_METRICS_RETENTION_PERIOD_MINUTES));\n+      if (parsedRetentionPeriod <= 0 || parsedRetentionPeriod > BATCH_METRICS_RETENTION_PERIOD_MINUTES_LIMIT) {\n+        throw new InvalidParameterException();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg0MzM1Mw==", "bodyText": "can we please make all method names camelCase ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483843353", "createdAt": "2020-09-04T21:04:32Z", "author": {"login": "yojs"}, "path": "src/test/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandlerTest.java", "diffHunk": "@@ -0,0 +1,516 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rest;\n+\n+import static com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ReaderMetricsProcessor.BATCH_METRICS_ENABLED_CONF_FILE;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.config.PluginSettings;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.core.Util;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metrics.MetricsConfiguration;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metrics.MetricsRestUtil;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.Dimensions;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.Metric;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.model.MetricsModel;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ReaderMetricsProcessor;\n+import com.sun.net.httpserver.Headers;\n+import com.sun.net.httpserver.HttpExchange;\n+\n+import java.io.File;\n+import java.io.FilenameFilter;\n+import java.io.IOException;\n+import java.net.HttpURLConnection;\n+import java.net.URI;\n+import java.nio.file.Files;\n+import java.nio.file.Paths;\n+import java.security.InvalidParameterException;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.NavigableSet;\n+import java.util.TreeSet;\n+\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import org.mockito.ArgumentMatchers;\n+import org.mockito.Mockito;\n+\n+public class QueryBatchRequestHandlerTest {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1MjIzMw==", "bodyText": "Will calling it the latest metricDB file be more appropriate ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483852233", "createdAt": "2020-09-04T21:33:41Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -84,6 +89,21 @@ public MetricsDB(long windowStartTime) throws Exception {\n     create = DSL.using(conn, SQLDialect.SQLITE);\n   }\n \n+  /**\n+   * Returns a MetricsDB handle associated with an existing metricsdb file.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1Mjg4Mw==", "bodyText": "It might be more appropriate to say throws FileNotFoundException instead of throws Exception. Thoughts ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483852883", "createdAt": "2020-09-04T21:35:48Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -84,6 +89,21 @@ public MetricsDB(long windowStartTime) throws Exception {\n     create = DSL.using(conn, SQLDialect.SQLITE);\n   }\n \n+  /**\n+   * Returns a MetricsDB handle associated with an existing metricsdb file.\n+   *\n+   * @param windowStartTime the timestamp associated with an existing metricsdb file\n+   * @return a MetricsDB handle associated with the metricsdb file\n+   * @throws Exception if the metricsdb file does not exist or is invalid\n+   */\n+  public static MetricsDB fetchExisting(long windowStartTime) throws Exception {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1MzIyMA==", "bodyText": "All SQLite queries can throw DataExcessException. We might want to add it to the method signature ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483853220", "createdAt": "2020-09-04T21:36:50Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -235,10 +255,39 @@ public void putMetric(Metric<Double> metric, Dimensions dimensions, long windowS\n     return create.select(allFields).from(finalTable).groupBy(groupByFields).fetch();\n   }\n \n+  /**\n+   * Queries all the data associated with the given metric.\n+   *\n+   * @param metric the desired metric\n+   * @return the result of the query\n+   */\n   public Result<Record> queryMetric(String metric) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1MzQyNA==", "bodyText": "In this case we might want to also check before querying the SQL if the metric is a valid metric name.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483853424", "createdAt": "2020-09-04T21:37:38Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -235,10 +255,39 @@ public void putMetric(Metric<Double> metric, Dimensions dimensions, long windowS\n     return create.select(allFields).from(finalTable).groupBy(groupByFields).fetch();\n   }\n \n+  /**\n+   * Queries all the data associated with the given metric.\n+   *\n+   * @param metric the desired metric\n+   * @return the result of the query\n+   */\n   public Result<Record> queryMetric(String metric) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1Mzg4OA==", "bodyText": "throws DataAccessException ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483853888", "createdAt": "2020-09-04T21:39:19Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -235,10 +255,39 @@ public void putMetric(Metric<Double> metric, Dimensions dimensions, long windowS\n     return create.select(allFields).from(finalTable).groupBy(groupByFields).fetch();\n   }\n \n+  /**\n+   * Queries all the data associated with the given metric.\n+   *\n+   * @param metric the desired metric\n+   * @return the result of the query\n+   */\n   public Result<Record> queryMetric(String metric) {\n     return create.select().from(DSL.table(metric)).fetch();\n   }\n \n+  /**\n+   * Queries all the data associated with a given metric.\n+   *\n+   * @param metric the desired metric\n+   * @param dimensions the dimensions we want to return for the given metric\n+   * @param limit the maximum number of records to return\n+   * @return the result of the query\n+   */\n+  public Result<Record> queryMetric(String metric, Collection<String> dimensions, int limit) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 74}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1NTI1Mg==", "bodyText": "Before calling delete, it might be good idea to check for the existence of the file itself or we can call deleteIfExists?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483855252", "createdAt": "2020-09-04T21:44:14Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -259,6 +308,23 @@ public void deleteOnDiskFile() {\n     }\n   }\n \n+  /**\n+   * Deletes the metricsdb file associated with the given timestamp if it exists.\n+   *\n+   * @param windowStartTime the timestamp associated with an existing metricsdb file\n+   */\n+  public static void deleteOnDiskFile(long windowStartTime) {\n+    String dbFilePath = getDBFilePath(windowStartTime);\n+    File dbFile = new File(dbFilePath);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1NTYyNg==", "bodyText": "can we make this final ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483855626", "createdAt": "2020-09-04T21:45:30Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -71,6 +82,11 @@\n   private final AppContext appContext;\n   private final ConfigOverridesApplier configOverridesApplier;\n \n+  public static final String BATCH_METRICS_ENABLED_CONF_FILE = \"batch_metrics_enabled.conf\";\n+  private boolean batchMetricsEnabled;\n+  private boolean defaultBatchMetricsEnabled = false;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1OTQ4NA==", "bodyText": "We should keep methods marked as VisiableForTesting restricted to getters and setters. Anything else that is required should be done in a test helper method.\nin this case though, this method is called from within trimOldSnapshots. So we should not have the annotation ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483859484", "createdAt": "2020-09-04T21:52:45Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -754,6 +828,28 @@ public void emitNodeMetrics(long currWindowStartTime, MetricsDB metricsDB) throw\n     }\n   }\n \n+  @VisibleForTesting\n+  public void readBatchMetricsEnabledFromConf() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 140}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1OTY4OQ==", "bodyText": "We are already logging the error, so e.printStackTrace(); can be removed ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483859689", "createdAt": "2020-09-04T21:53:35Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -754,6 +828,28 @@ public void emitNodeMetrics(long currWindowStartTime, MetricsDB metricsDB) throw\n     }\n   }\n \n+  @VisibleForTesting\n+  public void readBatchMetricsEnabledFromConf() {\n+    Path filePath = Paths.get(Util.DATA_DIR, BATCH_METRICS_ENABLED_CONF_FILE);\n+\n+    Util.invokePrivileged(\n+            () -> {\n+              try (Scanner sc = new Scanner(filePath)) {\n+                String nextLine = sc.nextLine();\n+                boolean oldValue = batchMetricsEnabled;\n+                boolean newValue = Boolean.parseBoolean(nextLine);\n+                if (oldValue != newValue) {\n+                  batchMetricsEnabled = newValue;\n+                  LOG.info(\"Batch metrics enabled changed from {} to {}\", oldValue, newValue);\n+                }\n+              } catch (IOException e) {\n+                LOG.error(\"Error reading file '{}': {}\", filePath.toString(), e);\n+                e.printStackTrace();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 155}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDgyOTg2Nzcx", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#pullrequestreview-482986771", "createdAt": "2020-09-04T21:59:40Z", "commit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQyMTo1OTo0MFrOHNcjHg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wNFQyMjoyMjoyMVrOHNc4ww==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg2MTI3OA==", "bodyText": "If we delete the trimDatabases above, then the method definition is no longer required and the method can be removed ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483861278", "createdAt": "2020-09-04T21:59:40Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -201,8 +219,43 @@ public void trimOldSnapshots() throws Exception {\n     trimMap(shardRqMetricsMap, RQ_SNAPSHOTS);\n     trimMap(httpRqMetricsMap, HTTP_RQ_SNAPSHOTS);\n     trimMap(masterEventMetricsMap, MASTER_EVENT_SNAPSHOTS);\n-    trimDatabases(\n-        metricsDBMap, MAX_DATABASES, PluginSettings.instance().shouldCleanupMetricsDBFiles());\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg2MTU3NQ==", "bodyText": "The better way might be to move lines 223 to 258 in the trimDatabase method. what do you think ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483861575", "createdAt": "2020-09-04T22:00:41Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -201,8 +219,43 @@ public void trimOldSnapshots() throws Exception {\n     trimMap(shardRqMetricsMap, RQ_SNAPSHOTS);\n     trimMap(httpRqMetricsMap, HTTP_RQ_SNAPSHOTS);\n     trimMap(masterEventMetricsMap, MASTER_EVENT_SNAPSHOTS);\n-    trimDatabases(\n-        metricsDBMap, MAX_DATABASES, PluginSettings.instance().shouldCleanupMetricsDBFiles());\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg2MTI3OA=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg2Mzk4MA==", "bodyText": "Above we have gone through all the metricsDBMap and would have deleted all files but the two most recent ones. Can you add code comment explaining why are we doing this again ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483863980", "createdAt": "2020-09-04T22:10:21Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -201,8 +219,43 @@ public void trimOldSnapshots() throws Exception {\n     trimMap(shardRqMetricsMap, RQ_SNAPSHOTS);\n     trimMap(httpRqMetricsMap, HTTP_RQ_SNAPSHOTS);\n     trimMap(masterEventMetricsMap, MASTER_EVENT_SNAPSHOTS);\n-    trimDatabases(\n-        metricsDBMap, MAX_DATABASES, PluginSettings.instance().shouldCleanupMetricsDBFiles());\n+\n+    boolean deleteDBFiles = PluginSettings.instance().shouldCleanupMetricsDBFiles();\n+    while (metricsDBMap.size() > MAX_DATABASES) {\n+      Map.Entry<Long, MetricsDB> oldestEntry = metricsDBMap.pollFirstEntry();\n+      if (oldestEntry != null) {\n+        Long key = oldestEntry.getKey();\n+        MetricsDB value = oldestEntry.getValue();\n+        value.remove();\n+        if (deleteDBFiles && !batchMetricsDBSet.contains(key)) {\n+          value.deleteOnDiskFile();\n+        }\n+      }\n+    }\n+    // Flush any tracking batch metrics if batch metrics is disabled. Note, in order to ensure that batch metrics\n+    // consumers have had at least one cycle to use any metrics they may be holding, this flush is done before\n+    // re-reading the config file to update the state of the batch metrics feature.\n+    if (!batchMetricsEnabled && !batchMetricsDBSet.isEmpty()) {\n+      if (deleteDBFiles) {\n+        for (Long timestamp : batchMetricsDBSet) {\n+          if (!metricsDBMap.containsKey(timestamp)) {\n+            MetricsDB.deleteOnDiskFile(timestamp);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 80}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg2NDM1NA==", "bodyText": "This sounds like this call may not belong here or the name of the enclosing method trimOldSnapshots might be changed to something more relevant indicating that the config is re-read here ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483864354", "createdAt": "2020-09-04T22:11:49Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -201,8 +219,43 @@ public void trimOldSnapshots() throws Exception {\n     trimMap(shardRqMetricsMap, RQ_SNAPSHOTS);\n     trimMap(httpRqMetricsMap, HTTP_RQ_SNAPSHOTS);\n     trimMap(masterEventMetricsMap, MASTER_EVENT_SNAPSHOTS);\n-    trimDatabases(\n-        metricsDBMap, MAX_DATABASES, PluginSettings.instance().shouldCleanupMetricsDBFiles());\n+\n+    boolean deleteDBFiles = PluginSettings.instance().shouldCleanupMetricsDBFiles();\n+    while (metricsDBMap.size() > MAX_DATABASES) {\n+      Map.Entry<Long, MetricsDB> oldestEntry = metricsDBMap.pollFirstEntry();\n+      if (oldestEntry != null) {\n+        Long key = oldestEntry.getKey();\n+        MetricsDB value = oldestEntry.getValue();\n+        value.remove();\n+        if (deleteDBFiles && !batchMetricsDBSet.contains(key)) {\n+          value.deleteOnDiskFile();\n+        }\n+      }\n+    }\n+    // Flush any tracking batch metrics if batch metrics is disabled. Note, in order to ensure that batch metrics\n+    // consumers have had at least one cycle to use any metrics they may be holding, this flush is done before\n+    // re-reading the config file to update the state of the batch metrics feature.\n+    if (!batchMetricsEnabled && !batchMetricsDBSet.isEmpty()) {\n+      if (deleteDBFiles) {\n+        for (Long timestamp : batchMetricsDBSet) {\n+          if (!metricsDBMap.containsKey(timestamp)) {\n+            MetricsDB.deleteOnDiskFile(timestamp);\n+          }\n+        }\n+      }\n+      batchMetricsDBSet.clear();\n+    }\n+    readBatchMetricsEnabledFromConf();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 86}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg2NjgxOQ==", "bodyText": "SO we store the snapshot everytime we emit metrics, at query time we clone the snapshot (so we double the snapshot) and then we trim it. This is very memory intensive. We might just want to read the files directly from disk when the API is called ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r483866819", "createdAt": "2020-09-04T22:22:21Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -289,6 +342,9 @@ private void emitMetrics(long currWindowStartTime) throws Exception {\n \n     metricsDB.commit();\n     metricsDBMap.put(prevWindowStartTime, metricsDB);\n+    if (batchMetricsEnabled) {\n+      batchMetricsDBSet.add(prevWindowStartTime);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 105}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1e744b8e637292e9e3277e28d1ec9e9bd53bf705", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/1e744b8e637292e9e3277e28d1ec9e9bd53bf705", "committedDate": "2020-09-04T23:35:42Z", "message": "Add DataAccessException to queryMetric signature"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "89f1e2d6ecb059e9ef0968028d5826664d373a32", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/89f1e2d6ecb059e9ef0968028d5826664d373a32", "committedDate": "2020-09-05T00:07:37Z", "message": "Add documentation to trimOldSnapshots"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ce9e155ff2cf4984d791844dda3dac4261e1baf7", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/ce9e155ff2cf4984d791844dda3dac4261e1baf7", "committedDate": "2020-09-07T04:24:15Z", "message": "Merge branch 'master' into batch-metrics-api-v3"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg0MzQ3NTU5", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#pullrequestreview-484347559", "createdAt": "2020-09-08T17:23:08Z", "commit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "state": "COMMENTED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxNzoyMzowOFrOHOm9-A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxNzo1MDoyNVrOHOn4Qw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA4MDU2OA==", "bodyText": "Right, so you don't need to throw a InvalidParameterException, you can simple return ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485080568", "createdAt": "2020-09-08T17:23:08Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/config/PluginSettings.java", "diffHunk": "@@ -271,4 +295,21 @@ private void loadMetricsDBFilesCleanupEnabled() {\n       shouldCleanupMetricsDBFiles = true;\n     }\n   }\n+\n+  private void loadBatchMetricsRetentionPeriodMinutesFromConfig() {\n+    if (!settings.containsKey(BATCH_METRICS_RETENTION_PERIOD_MINUTES)) {\n+      return;\n+    }\n+\n+    try {\n+      long parsedRetentionPeriod = Long.parseLong(settings.getProperty(BATCH_METRICS_RETENTION_PERIOD_MINUTES));\n+      if (parsedRetentionPeriod <= 0 || parsedRetentionPeriod > BATCH_METRICS_RETENTION_PERIOD_MINUTES_LIMIT) {\n+        throw new InvalidParameterException();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MzgzNjMxNQ=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 97}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA4MTQ3Nw==", "bodyText": "Do we need the stack trace here ?\nAnd as this is logged for both NumberFormatException and InvalidParameterException, it might make sense to print (settings.getProperty(BATCH_METRICS_RETENTION_PERIOD_MINUTES) to understand which of the two it was by just looking at the logs ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485081477", "createdAt": "2020-09-08T17:24:46Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/config/PluginSettings.java", "diffHunk": "@@ -271,4 +295,21 @@ private void loadMetricsDBFilesCleanupEnabled() {\n       shouldCleanupMetricsDBFiles = true;\n     }\n   }\n+\n+  private void loadBatchMetricsRetentionPeriodMinutesFromConfig() {\n+    if (!settings.containsKey(BATCH_METRICS_RETENTION_PERIOD_MINUTES)) {\n+      return;\n+    }\n+\n+    try {\n+      long parsedRetentionPeriod = Long.parseLong(settings.getProperty(BATCH_METRICS_RETENTION_PERIOD_MINUTES));\n+      if (parsedRetentionPeriod <= 0 || parsedRetentionPeriod > BATCH_METRICS_RETENTION_PERIOD_MINUTES_LIMIT) {\n+        throw new InvalidParameterException();\n+      }\n+      batchMetricsRetentionPeriodMinutes = parsedRetentionPeriod;\n+    } catch (NumberFormatException | InvalidParameterException e) {\n+      LOG.error(\"Invalid batch-metrics-retention-period-minutes. Using default value {}.\",\n+              batchMetricsRetentionPeriodMinutes, e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA4NTg3OA==", "bodyText": "In that case use Files.delete() and catch the exception if one is thrown  for understanding why it could not be deleted. The error message here is not helpful", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485085878", "createdAt": "2020-09-08T17:32:33Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -259,6 +308,23 @@ public void deleteOnDiskFile() {\n     }\n   }\n \n+  /**\n+   * Deletes the metricsdb file associated with the given timestamp if it exists.\n+   *\n+   * @param windowStartTime the timestamp associated with an existing metricsdb file\n+   */\n+  public static void deleteOnDiskFile(long windowStartTime) {\n+    String dbFilePath = getDBFilePath(windowStartTime);\n+    File dbFile = new File(dbFilePath);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1NTI1Mg=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA4NzE3MQ==", "bodyText": "Can you explain how can a default change ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485087171", "createdAt": "2020-09-08T17:35:01Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -71,6 +82,11 @@\n   private final AppContext appContext;\n   private final ConfigOverridesApplier configOverridesApplier;\n \n+  public static final String BATCH_METRICS_ENABLED_CONF_FILE = \"batch_metrics_enabled.conf\";\n+  private boolean batchMetricsEnabled;\n+  private boolean defaultBatchMetricsEnabled = false;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1NTYyNg=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA4ODUzMA==", "bodyText": "If we are removing the usage in the code, we should remove the method. Git takes care of preserving history. So, if it is required in future, we can resurrect it.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485088530", "createdAt": "2020-09-08T17:37:32Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -201,8 +219,43 @@ public void trimOldSnapshots() throws Exception {\n     trimMap(shardRqMetricsMap, RQ_SNAPSHOTS);\n     trimMap(httpRqMetricsMap, HTTP_RQ_SNAPSHOTS);\n     trimMap(masterEventMetricsMap, MASTER_EVENT_SNAPSHOTS);\n-    trimDatabases(\n-        metricsDBMap, MAX_DATABASES, PluginSettings.instance().shouldCleanupMetricsDBFiles());\n+", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg2MTI3OA=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA5MDEzNg==", "bodyText": "Sorry, for the confusion, by not belong here, I meant in terms of the name of the method. So please change the name to reflect that ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485090136", "createdAt": "2020-09-08T17:40:30Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -201,8 +219,43 @@ public void trimOldSnapshots() throws Exception {\n     trimMap(shardRqMetricsMap, RQ_SNAPSHOTS);\n     trimMap(httpRqMetricsMap, HTTP_RQ_SNAPSHOTS);\n     trimMap(masterEventMetricsMap, MASTER_EVENT_SNAPSHOTS);\n-    trimDatabases(\n-        metricsDBMap, MAX_DATABASES, PluginSettings.instance().shouldCleanupMetricsDBFiles());\n+\n+    boolean deleteDBFiles = PluginSettings.instance().shouldCleanupMetricsDBFiles();\n+    while (metricsDBMap.size() > MAX_DATABASES) {\n+      Map.Entry<Long, MetricsDB> oldestEntry = metricsDBMap.pollFirstEntry();\n+      if (oldestEntry != null) {\n+        Long key = oldestEntry.getKey();\n+        MetricsDB value = oldestEntry.getValue();\n+        value.remove();\n+        if (deleteDBFiles && !batchMetricsDBSet.contains(key)) {\n+          value.deleteOnDiskFile();\n+        }\n+      }\n+    }\n+    // Flush any tracking batch metrics if batch metrics is disabled. Note, in order to ensure that batch metrics\n+    // consumers have had at least one cycle to use any metrics they may be holding, this flush is done before\n+    // re-reading the config file to update the state of the batch metrics feature.\n+    if (!batchMetricsEnabled && !batchMetricsDBSet.isEmpty()) {\n+      if (deleteDBFiles) {\n+        for (Long timestamp : batchMetricsDBSet) {\n+          if (!metricsDBMap.containsKey(timestamp)) {\n+            MetricsDB.deleteOnDiskFile(timestamp);\n+          }\n+        }\n+      }\n+      batchMetricsDBSet.clear();\n+    }\n+    readBatchMetricsEnabledFromConf();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg2NDM1NA=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 86}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA5NDUwMA==", "bodyText": "One of the ways to avoid it, if we at all want to test private methods, would be to encapsulate all such methods, in a wrapper class of your own. Then make the methods inside the wrapper as public and hence testable. The wrapper can be used in the main class as private or its getters/setters as visible for testing.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485094500", "createdAt": "2020-09-08T17:48:39Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -754,6 +828,28 @@ public void emitNodeMetrics(long currWindowStartTime, MetricsDB metricsDB) throw\n     }\n   }\n \n+  @VisibleForTesting\n+  public void readBatchMetricsEnabledFromConf() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1OTQ4NA=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 140}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA5NTQ5MQ==", "bodyText": "We may not want to do everything for consistency as much as we want to do the right thing. :) This may be redundant as the stack will already be captured in the logs.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485095491", "createdAt": "2020-09-08T17:50:25Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -754,6 +828,28 @@ public void emitNodeMetrics(long currWindowStartTime, MetricsDB metricsDB) throw\n     }\n   }\n \n+  @VisibleForTesting\n+  public void readBatchMetricsEnabledFromConf() {\n+    Path filePath = Paths.get(Util.DATA_DIR, BATCH_METRICS_ENABLED_CONF_FILE);\n+\n+    Util.invokePrivileged(\n+            () -> {\n+              try (Scanner sc = new Scanner(filePath)) {\n+                String nextLine = sc.nextLine();\n+                boolean oldValue = batchMetricsEnabled;\n+                boolean newValue = Boolean.parseBoolean(nextLine);\n+                if (oldValue != newValue) {\n+                  batchMetricsEnabled = newValue;\n+                  LOG.info(\"Batch metrics enabled changed from {} to {}\", oldValue, newValue);\n+                }\n+              } catch (IOException e) {\n+                LOG.error(\"Error reading file '{}': {}\", filePath.toString(), e);\n+                e.printStackTrace();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1OTY4OQ=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 155}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "79be926a5095b441c840ab3c6c5b9dc9870d1b39", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/79be926a5095b441c840ab3c6c5b9dc9870d1b39", "committedDate": "2020-09-08T18:20:28Z", "message": "More user-friendly handling of invalid batch metrics retention period"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0a45e2d74e021b678e50e4f7933bc513fc444668", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/0a45e2d74e021b678e50e4f7933bc513fc444668", "committedDate": "2020-09-08T19:48:21Z", "message": "Use more helpful error logging in deleteOnDiskFile"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "17142723fe88bec83f7b89a6e5c2a82fcd49c0a2", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/17142723fe88bec83f7b89a6e5c2a82fcd49c0a2", "committedDate": "2020-09-08T21:48:09Z", "message": "Removing unnecessary print stack trace"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dbf4cccbae28b3b78140012b2b8076c12931dfbd", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/dbf4cccbae28b3b78140012b2b8076c12931dfbd", "committedDate": "2020-09-08T21:51:15Z", "message": "Remove stale trimDatabases method"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg0NTA4Njg5", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#pullrequestreview-484508689", "createdAt": "2020-09-08T21:35:07Z", "commit": {"oid": "ce9e155ff2cf4984d791844dda3dac4261e1baf7"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQyMTozNTowN1rOHOuz_Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQyMTo1NzoyMVrOHOvY0Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTIwOTA4NQ==", "bodyText": "We have a few things going on here:\n\ncleaning up in-memory snapshots\ncleaning up on-disk files if batch metrics is disabled.\nre-reading config\nAnd cleaning up metrics db files so that we always have a fixed number of them around.\n\nLet's move the in-memory cleanup and on disk cleanups into separate methods of their own", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485209085", "createdAt": "2020-09-08T21:35:07Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -201,8 +219,46 @@ public void trimOldSnapshots() throws Exception {\n     trimMap(shardRqMetricsMap, RQ_SNAPSHOTS);\n     trimMap(httpRqMetricsMap, HTTP_RQ_SNAPSHOTS);\n     trimMap(masterEventMetricsMap, MASTER_EVENT_SNAPSHOTS);\n-    trimDatabases(\n-        metricsDBMap, MAX_DATABASES, PluginSettings.instance().shouldCleanupMetricsDBFiles());\n+\n+    boolean deleteDBFiles = PluginSettings.instance().shouldCleanupMetricsDBFiles();\n+    // Cleanup all but the 2 most recent metricsDB files from metricsDBMap. The most recent metricsDB files needs to be\n+    // retained for future metrics query handling, the second most recent metricsDB file needs to be retained in case", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ce9e155ff2cf4984d791844dda3dac4261e1baf7"}, "originalPosition": 63}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTIxMDUwMw==", "bodyText": "Although we are playing safe here by not reading the config before, but I don't think we are completely avoiding the race here. Say, if reading all the files in the retention period is taking too long, (multiple iterations of this call), then there is still a chance that the API read thread tries to read a file that has been deleted. So, we should definitely handle that exception, in any case.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485210503", "createdAt": "2020-09-08T21:38:25Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -201,8 +219,46 @@ public void trimOldSnapshots() throws Exception {\n     trimMap(shardRqMetricsMap, RQ_SNAPSHOTS);\n     trimMap(httpRqMetricsMap, HTTP_RQ_SNAPSHOTS);\n     trimMap(masterEventMetricsMap, MASTER_EVENT_SNAPSHOTS);\n-    trimDatabases(\n-        metricsDBMap, MAX_DATABASES, PluginSettings.instance().shouldCleanupMetricsDBFiles());\n+\n+    boolean deleteDBFiles = PluginSettings.instance().shouldCleanupMetricsDBFiles();\n+    // Cleanup all but the 2 most recent metricsDB files from metricsDBMap. The most recent metricsDB files needs to be\n+    // retained for future metrics query handling, the second most recent metricsDB file needs to be retained in case\n+    // any metrics query handler just got access to it right before the most recent metricsDB file was available.\n+    while (metricsDBMap.size() > MAX_DATABASES) {\n+      Map.Entry<Long, MetricsDB> oldestEntry = metricsDBMap.pollFirstEntry();\n+      if (oldestEntry != null) {\n+        Long key = oldestEntry.getKey();\n+        MetricsDB value = oldestEntry.getValue();\n+        value.remove();\n+        if (deleteDBFiles && !batchMetricsDBSet.contains(key)) {\n+          value.deleteOnDiskFile();\n+        }\n+      }\n+    }\n+    // Flush any tracking batch metrics if batch metrics is disabled. Note, in order to ensure that batch metrics\n+    // consumers have had at least one cycle to use any metrics they may be holding, this flush is done before\n+    // re-reading the config file to update the state of the batch metrics feature.\n+    if (!batchMetricsEnabled && !batchMetricsDBSet.isEmpty()) {\n+      if (deleteDBFiles) {\n+        for (Long timestamp : batchMetricsDBSet) {\n+          if (!metricsDBMap.containsKey(timestamp)) {\n+            MetricsDB.deleteOnDiskFile(timestamp);\n+          }\n+        }\n+      }\n+      batchMetricsDBSet.clear();\n+    }\n+    readBatchMetricsEnabledFromConf();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ce9e155ff2cf4984d791844dda3dac4261e1baf7"}, "originalPosition": 89}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTIxMzk4MA==", "bodyText": "PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 12\nThis is a call we are making on each iteration of the loop. Can we store it in a local variable as it does not change over the loop iterations ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485213980", "createdAt": "2020-09-08T21:46:04Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -696,6 +755,24 @@ public void deleteDBs() throws Exception {\n     }\n   }\n \n+  /**\n+   * This is called by operations outside of the ReaderMetricsProcessor.\n+   *\n+   * @return A list of the timestamps associated with MetricsDB files. The oldest of the MetricsDB files typically\n+   *     have a lifetime of ~SAMPLING_INTERVAL seconds (no less than SAMPLING_INTERVAL/2 seconds). Null if batch\n+   *     metrics is disabled.\n+   */\n+  public NavigableSet<Long> getBatchMetrics() {\n+    if (batchMetricsEnabled) {\n+      TreeSet<Long> batchMetricsDBSetCopy = new TreeSet<>(batchMetricsDBSet.clone());\n+      while (batchMetricsDBSetCopy.size() > PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 12) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ce9e155ff2cf4984d791844dda3dac4261e1baf7"}, "originalPosition": 127}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTIxNTE3MQ==", "bodyText": "Let's add a comment here saying that this datastructure can be modified by the writer/cleanup thread while being read by the other thread trying to batch metrics. And therefore, it needs to be ConcurrentSkipListSet", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485215171", "createdAt": "2020-09-08T21:48:58Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -71,6 +82,11 @@\n   private final AppContext appContext;\n   private final ConfigOverridesApplier configOverridesApplier;\n \n+  public static final String BATCH_METRICS_ENABLED_CONF_FILE = \"batch_metrics_enabled.conf\";\n+  private boolean batchMetricsEnabled;\n+  private boolean defaultBatchMetricsEnabled = false;\n+  private ConcurrentSkipListSet<Long> batchMetricsDBSet;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ce9e155ff2cf4984d791844dda3dac4261e1baf7"}, "originalPosition": 40}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTIxNjM3MA==", "bodyText": "Let's also add the reason for the numbers here ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485216370", "createdAt": "2020-09-08T21:51:49Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandler.java", "diffHunk": "@@ -0,0 +1,309 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rest;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatExceptionCode;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatsCollector;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.config.PluginSettings;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metrics.MetricsRestUtil;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.model.MetricsModel;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.net.NetClient;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ReaderMetricsProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.sun.net.httpserver.HttpExchange;\n+import com.sun.net.httpserver.HttpHandler;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.net.HttpURLConnection;\n+import java.security.InvalidParameterException;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.NavigableSet;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.logging.log4j.util.Supplier;\n+import org.jooq.Record;\n+import org.jooq.Result;\n+\n+/**\n+ * Request handler that supports querying batch metrics from an EC2 instance\n+ *\n+ * <p>Return 1 minute of CPU_Utilization metrics sampled at a 5s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization&starttime=1566413975000&endtime=1566413980000\"\n+ *\n+ * <p>Return 1 minute of CPU_Utilization and Latency metrics sampled at a 10s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization,Latency&starttime=1566413975000&endtime=1566413980000&samplingperiod=10\"\n+ *\n+ * <p>Return format:\n+ * {\n+ *   \"1594412650000\": {\n+ *     \"CPU_Utilization\": {\n+ *       \"fields\": [\n+ *         {\n+ *           \"name: \"IndexName\",\n+ *           \"type\": \"VARCHAR\"\n+ *         },\n+ *         <...>\n+ *       ]\n+ *       \"records\": [\n+ *         [\n+ *           \"pmc\",\n+ *           <...>\n+ *         ],\n+ *         <...>\n+ *       ]\n+ *     }\n+ *   }\n+ * }\n+ */\n+public class QueryBatchRequestHandler extends MetricsHandler implements HttpHandler {\n+\n+  private static final Logger LOG = LogManager.getLogger(QueryBatchRequestHandler.class);\n+\n+  private static final int TIME_OUT_VALUE = 2;\n+  private static final TimeUnit TIME_OUT_UNIT = TimeUnit.SECONDS;\n+  private NetClient netClient;\n+  MetricsRestUtil metricsRestUtil;\n+\n+  public static final int DEFAULT_MAX_DATAPOINTS = 100800;  // Must be non-negative\n+  public static final long DEFAULT_SAMPLING_PERIOD_MILLIS = 5000;  // Must be a multiple of 5000", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ce9e155ff2cf4984d791844dda3dac4261e1baf7"}, "originalPosition": 88}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTIxODUxMw==", "bodyText": "batchMetricsDBSet holds the key to the castle and it is an in-memory structure. In case PA starts crashing say every 15 seconds, or so. So, we will not be cleaning up files that were generated in the last run as this structure is always initialized to an empty set !", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485218513", "createdAt": "2020-09-08T21:57:21Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -71,6 +82,11 @@\n   private final AppContext appContext;\n   private final ConfigOverridesApplier configOverridesApplier;\n \n+  public static final String BATCH_METRICS_ENABLED_CONF_FILE = \"batch_metrics_enabled.conf\";\n+  private boolean batchMetricsEnabled;\n+  private boolean defaultBatchMetricsEnabled = false;\n+  private ConcurrentSkipListSet<Long> batchMetricsDBSet;\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ce9e155ff2cf4984d791844dda3dac4261e1baf7"}, "originalPosition": 41}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4c2ce23d8560591005e5a79ccfca6cb41e695ab0", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/4c2ce23d8560591005e5a79ccfca6cb41e695ab0", "committedDate": "2020-09-08T21:59:45Z", "message": "Make defaultBatchMetricsEnabled private static final"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg0Mzc1Nzk1", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#pullrequestreview-484375795", "createdAt": "2020-09-08T18:03:35Z", "commit": {"oid": "ce9e155ff2cf4984d791844dda3dac4261e1baf7"}, "state": "COMMENTED", "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxODowMzozNVrOHOoTdg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQyMjozMzowNVrOHOwLHQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTEwMjQ1NA==", "bodyText": "Wouldn't Log.error have the stack trace to help identify the exception raised?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485102454", "createdAt": "2020-09-08T18:03:35Z", "author": {"login": "vigyasharma"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/config/PluginSettings.java", "diffHunk": "@@ -271,4 +295,21 @@ private void loadMetricsDBFilesCleanupEnabled() {\n       shouldCleanupMetricsDBFiles = true;\n     }\n   }\n+\n+  private void loadBatchMetricsRetentionPeriodMinutesFromConfig() {\n+    if (!settings.containsKey(BATCH_METRICS_RETENTION_PERIOD_MINUTES)) {\n+      return;\n+    }\n+\n+    try {\n+      long parsedRetentionPeriod = Long.parseLong(settings.getProperty(BATCH_METRICS_RETENTION_PERIOD_MINUTES));\n+      if (parsedRetentionPeriod <= 0 || parsedRetentionPeriod > BATCH_METRICS_RETENTION_PERIOD_MINUTES_LIMIT) {\n+        throw new InvalidParameterException();\n+      }\n+      batchMetricsRetentionPeriodMinutes = parsedRetentionPeriod;\n+    } catch (NumberFormatException | InvalidParameterException e) {\n+      LOG.error(\"Invalid batch-metrics-retention-period-minutes. Using default value {}.\",\n+              batchMetricsRetentionPeriodMinutes, e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTA4MTQ3Nw=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTEwODMwNQ==", "bodyText": "Files.delete() is the preferred method in the new IO APIs", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485108305", "createdAt": "2020-09-08T18:14:28Z", "author": {"login": "vigyasharma"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -259,6 +308,23 @@ public void deleteOnDiskFile() {\n     }\n   }\n \n+  /**\n+   * Deletes the metricsdb file associated with the given timestamp if it exists.\n+   *\n+   * @param windowStartTime the timestamp associated with an existing metricsdb file\n+   */\n+  public static void deleteOnDiskFile(long windowStartTime) {\n+    String dbFilePath = getDBFilePath(windowStartTime);\n+    File dbFile = new File(dbFilePath);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1NTI1Mg=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 103}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTEwOTA5NA==", "bodyText": "Why don't we go with default = enabled?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485109094", "createdAt": "2020-09-08T18:15:55Z", "author": {"login": "vigyasharma"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/reader/ReaderMetricsProcessor.java", "diffHunk": "@@ -71,6 +82,11 @@\n   private final AppContext appContext;\n   private final ConfigOverridesApplier configOverridesApplier;\n \n+  public static final String BATCH_METRICS_ENABLED_CONF_FILE = \"batch_metrics_enabled.conf\";\n+  private boolean batchMetricsEnabled;\n+  private boolean defaultBatchMetricsEnabled = false;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1NTYyNg=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTIyNzIyNA==", "bodyText": "nit: should we reword as something on the lines of - \"Start time and end time should be at least sampling period apart\".? It may be confusing in its current form.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485227224", "createdAt": "2020-09-08T22:21:27Z", "author": {"login": "vigyasharma"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandler.java", "diffHunk": "@@ -0,0 +1,309 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rest;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatExceptionCode;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatsCollector;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.config.PluginSettings;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metrics.MetricsRestUtil;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.model.MetricsModel;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.net.NetClient;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ReaderMetricsProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.sun.net.httpserver.HttpExchange;\n+import com.sun.net.httpserver.HttpHandler;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.net.HttpURLConnection;\n+import java.security.InvalidParameterException;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.NavigableSet;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.logging.log4j.util.Supplier;\n+import org.jooq.Record;\n+import org.jooq.Result;\n+\n+/**\n+ * Request handler that supports querying batch metrics from an EC2 instance\n+ *\n+ * <p>Return 1 minute of CPU_Utilization metrics sampled at a 5s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization&starttime=1566413975000&endtime=1566413980000\"\n+ *\n+ * <p>Return 1 minute of CPU_Utilization and Latency metrics sampled at a 10s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization,Latency&starttime=1566413975000&endtime=1566413980000&samplingperiod=10\"\n+ *\n+ * <p>Return format:\n+ * {\n+ *   \"1594412650000\": {\n+ *     \"CPU_Utilization\": {\n+ *       \"fields\": [\n+ *         {\n+ *           \"name: \"IndexName\",\n+ *           \"type\": \"VARCHAR\"\n+ *         },\n+ *         <...>\n+ *       ]\n+ *       \"records\": [\n+ *         [\n+ *           \"pmc\",\n+ *           <...>\n+ *         ],\n+ *         <...>\n+ *       ]\n+ *     }\n+ *   }\n+ * }\n+ */\n+public class QueryBatchRequestHandler extends MetricsHandler implements HttpHandler {\n+\n+  private static final Logger LOG = LogManager.getLogger(QueryBatchRequestHandler.class);\n+\n+  private static final int TIME_OUT_VALUE = 2;\n+  private static final TimeUnit TIME_OUT_UNIT = TimeUnit.SECONDS;\n+  private NetClient netClient;\n+  MetricsRestUtil metricsRestUtil;\n+\n+  public static final int DEFAULT_MAX_DATAPOINTS = 100800;  // Must be non-negative\n+  public static final long DEFAULT_SAMPLING_PERIOD_MILLIS = 5000;  // Must be a multiple of 5000\n+\n+  public QueryBatchRequestHandler(NetClient netClient, MetricsRestUtil metricsRestUtil) {\n+    this.netClient = netClient;\n+    this.metricsRestUtil = metricsRestUtil;\n+  }\n+\n+  @Override\n+  public void handle(HttpExchange exchange) throws IOException {\n+    String requestMethod = exchange.getRequestMethod();\n+    if (!requestMethod.equalsIgnoreCase(\"GET\")) {\n+      exchange.sendResponseHeaders(HttpURLConnection.HTTP_NOT_FOUND, -1);\n+      exchange.close();\n+      return;\n+    }\n+\n+    ReaderMetricsProcessor mp = ReaderMetricsProcessor.getInstance();\n+    if (mp == null) {\n+      sendResponse(\n+          exchange,\n+          \"{\\\"error\\\":\\\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\\\"}\",\n+          HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    NavigableSet<Long> batchMetrics = mp.getBatchMetrics();\n+    long currentTime = System.currentTimeMillis();\n+    if (batchMetrics == null) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"The batch metrics api has not been enabled for this node.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"The batch metrics api has not been enabled for this node.\");\n+      return;\n+    }\n+    if (batchMetrics.isEmpty()) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"There are no metrics databases. The reader has run into an issue or has just started.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"There are no metrics databases. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    exchange.getResponseHeaders().set(\"Content-Type\", \"application/json\");\n+\n+    Map<String, String> params = getParamsMap(exchange.getRequestURI().getQuery());\n+\n+    try {\n+      // Parse and validate parameters\n+      String[] validParamsTmp = {\"\", \"metrics\", \"starttime\", \"endtime\", \"samplingperiod\"};\n+      Set<String> validParams = new HashSet<>(Arrays.asList(validParamsTmp));\n+      for (String param : params.keySet()) {\n+        if (!validParams.contains(param)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid parameter\", param));\n+        }\n+      }\n+\n+      List<String> metrics = metricsRestUtil.parseArrayParam(params, \"metrics\", false);\n+      String startTimeParam = params.get(\"starttime\");\n+      String endTimeParam = params.get(\"endtime\");\n+      String samplingPeriodParam = params.get(\"samplingperiod\");\n+\n+      for (String metric : metrics) {\n+        if (!MetricsModel.ALL_METRICS.containsKey(metric)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid metric\", metric));\n+        }\n+      }\n+\n+      if (startTimeParam == null || startTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"starttime parameter must be set\");\n+      }\n+      long startTime;\n+      try {\n+        startTime = Long.parseUnsignedLong(startTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid starttime\", startTimeParam));\n+      }\n+\n+      if (endTimeParam == null || endTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"endtime parameter must be set\");\n+      }\n+      long endTime;\n+      try {\n+        endTime = Long.parseUnsignedLong(endTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid endtime\", endTimeParam));\n+      }\n+\n+      long samplingPeriod = DEFAULT_SAMPLING_PERIOD_MILLIS;\n+      if (samplingPeriodParam != null && !samplingPeriodParam.isEmpty()) {\n+        samplingPeriod = Long.parseLong(samplingPeriodParam);\n+        if (samplingPeriod < 5 || samplingPeriod % 5 != 0) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid sampling period\", samplingPeriodParam));\n+        }\n+        if (samplingPeriod >= PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60) {\n+          throw new InvalidParameterException(\"sampling period must be less than the retention period\");\n+        }\n+        samplingPeriod *= 1000;\n+      }\n+\n+      if (startTime >= endTime) {\n+        throw new InvalidParameterException(\"starttime must be less than the endtime\");\n+      }\n+      startTime -= startTime % samplingPeriod;\n+      endTime -= endTime % samplingPeriod;\n+      if (startTime == endTime) {\n+        throw new InvalidParameterException(\"starttime and endtime cannot be equal when rounded down to the nearest sampling period\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ce9e155ff2cf4984d791844dda3dac4261e1baf7"}, "originalPosition": 196}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTIyNzYxNg==", "bodyText": "Minor: System time at node should not matter, right? Since startTime and endTime are provided as utc epoch timestamp values. We can just mention something like expected value is utc seconds since epoch timestamp and provided value is in future.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485227616", "createdAt": "2020-09-08T22:22:36Z", "author": {"login": "vigyasharma"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandler.java", "diffHunk": "@@ -0,0 +1,309 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rest;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatExceptionCode;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatsCollector;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.config.PluginSettings;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metrics.MetricsRestUtil;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.model.MetricsModel;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.net.NetClient;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ReaderMetricsProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.sun.net.httpserver.HttpExchange;\n+import com.sun.net.httpserver.HttpHandler;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.net.HttpURLConnection;\n+import java.security.InvalidParameterException;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.NavigableSet;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.logging.log4j.util.Supplier;\n+import org.jooq.Record;\n+import org.jooq.Result;\n+\n+/**\n+ * Request handler that supports querying batch metrics from an EC2 instance\n+ *\n+ * <p>Return 1 minute of CPU_Utilization metrics sampled at a 5s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization&starttime=1566413975000&endtime=1566413980000\"\n+ *\n+ * <p>Return 1 minute of CPU_Utilization and Latency metrics sampled at a 10s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization,Latency&starttime=1566413975000&endtime=1566413980000&samplingperiod=10\"\n+ *\n+ * <p>Return format:\n+ * {\n+ *   \"1594412650000\": {\n+ *     \"CPU_Utilization\": {\n+ *       \"fields\": [\n+ *         {\n+ *           \"name: \"IndexName\",\n+ *           \"type\": \"VARCHAR\"\n+ *         },\n+ *         <...>\n+ *       ]\n+ *       \"records\": [\n+ *         [\n+ *           \"pmc\",\n+ *           <...>\n+ *         ],\n+ *         <...>\n+ *       ]\n+ *     }\n+ *   }\n+ * }\n+ */\n+public class QueryBatchRequestHandler extends MetricsHandler implements HttpHandler {\n+\n+  private static final Logger LOG = LogManager.getLogger(QueryBatchRequestHandler.class);\n+\n+  private static final int TIME_OUT_VALUE = 2;\n+  private static final TimeUnit TIME_OUT_UNIT = TimeUnit.SECONDS;\n+  private NetClient netClient;\n+  MetricsRestUtil metricsRestUtil;\n+\n+  public static final int DEFAULT_MAX_DATAPOINTS = 100800;  // Must be non-negative\n+  public static final long DEFAULT_SAMPLING_PERIOD_MILLIS = 5000;  // Must be a multiple of 5000\n+\n+  public QueryBatchRequestHandler(NetClient netClient, MetricsRestUtil metricsRestUtil) {\n+    this.netClient = netClient;\n+    this.metricsRestUtil = metricsRestUtil;\n+  }\n+\n+  @Override\n+  public void handle(HttpExchange exchange) throws IOException {\n+    String requestMethod = exchange.getRequestMethod();\n+    if (!requestMethod.equalsIgnoreCase(\"GET\")) {\n+      exchange.sendResponseHeaders(HttpURLConnection.HTTP_NOT_FOUND, -1);\n+      exchange.close();\n+      return;\n+    }\n+\n+    ReaderMetricsProcessor mp = ReaderMetricsProcessor.getInstance();\n+    if (mp == null) {\n+      sendResponse(\n+          exchange,\n+          \"{\\\"error\\\":\\\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\\\"}\",\n+          HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    NavigableSet<Long> batchMetrics = mp.getBatchMetrics();\n+    long currentTime = System.currentTimeMillis();\n+    if (batchMetrics == null) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"The batch metrics api has not been enabled for this node.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"The batch metrics api has not been enabled for this node.\");\n+      return;\n+    }\n+    if (batchMetrics.isEmpty()) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"There are no metrics databases. The reader has run into an issue or has just started.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"There are no metrics databases. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    exchange.getResponseHeaders().set(\"Content-Type\", \"application/json\");\n+\n+    Map<String, String> params = getParamsMap(exchange.getRequestURI().getQuery());\n+\n+    try {\n+      // Parse and validate parameters\n+      String[] validParamsTmp = {\"\", \"metrics\", \"starttime\", \"endtime\", \"samplingperiod\"};\n+      Set<String> validParams = new HashSet<>(Arrays.asList(validParamsTmp));\n+      for (String param : params.keySet()) {\n+        if (!validParams.contains(param)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid parameter\", param));\n+        }\n+      }\n+\n+      List<String> metrics = metricsRestUtil.parseArrayParam(params, \"metrics\", false);\n+      String startTimeParam = params.get(\"starttime\");\n+      String endTimeParam = params.get(\"endtime\");\n+      String samplingPeriodParam = params.get(\"samplingperiod\");\n+\n+      for (String metric : metrics) {\n+        if (!MetricsModel.ALL_METRICS.containsKey(metric)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid metric\", metric));\n+        }\n+      }\n+\n+      if (startTimeParam == null || startTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"starttime parameter must be set\");\n+      }\n+      long startTime;\n+      try {\n+        startTime = Long.parseUnsignedLong(startTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid starttime\", startTimeParam));\n+      }\n+\n+      if (endTimeParam == null || endTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"endtime parameter must be set\");\n+      }\n+      long endTime;\n+      try {\n+        endTime = Long.parseUnsignedLong(endTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid endtime\", endTimeParam));\n+      }\n+\n+      long samplingPeriod = DEFAULT_SAMPLING_PERIOD_MILLIS;\n+      if (samplingPeriodParam != null && !samplingPeriodParam.isEmpty()) {\n+        samplingPeriod = Long.parseLong(samplingPeriodParam);\n+        if (samplingPeriod < 5 || samplingPeriod % 5 != 0) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid sampling period\", samplingPeriodParam));\n+        }\n+        if (samplingPeriod >= PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60) {\n+          throw new InvalidParameterException(\"sampling period must be less than the retention period\");\n+        }\n+        samplingPeriod *= 1000;\n+      }\n+\n+      if (startTime >= endTime) {\n+        throw new InvalidParameterException(\"starttime must be less than the endtime\");\n+      }\n+      startTime -= startTime % samplingPeriod;\n+      endTime -= endTime % samplingPeriod;\n+      if (startTime == endTime) {\n+        throw new InvalidParameterException(\"starttime and endtime cannot be equal when rounded down to the nearest sampling period\");\n+      }\n+      if (endTime > currentTime) {\n+        throw new InvalidParameterException(\"endtime can be no greater than the system time at the node\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ce9e155ff2cf4984d791844dda3dac4261e1baf7"}, "originalPosition": 199}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTIyOTI0Ng==", "bodyText": "What I meant was that if (maxDatapoints == 0) is a very exact check. We might want <= instead?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485229246", "createdAt": "2020-09-08T22:26:57Z", "author": {"login": "vigyasharma"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandler.java", "diffHunk": "@@ -0,0 +1,309 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rest;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatExceptionCode;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatsCollector;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.config.PluginSettings;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metrics.MetricsRestUtil;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.model.MetricsModel;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.net.NetClient;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ReaderMetricsProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.sun.net.httpserver.HttpExchange;\n+import com.sun.net.httpserver.HttpHandler;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.net.HttpURLConnection;\n+import java.security.InvalidParameterException;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.NavigableSet;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.logging.log4j.util.Supplier;\n+import org.jooq.Record;\n+import org.jooq.Result;\n+\n+/**\n+ * Request handler that supports querying batch metrics from an EC2 instance\n+ *\n+ * <p>Return 1 minute of CPU_Utilization metrics sampled at a 5s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization&starttime=1566413975000&endtime=1566413980000\"\n+ *\n+ * <p>Return 1 minute of CPU_Utilization and Latency metrics sampled at a 10s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization,Latency&starttime=1566413975000&endtime=1566413980000&samplingperiod=10\"\n+ *\n+ * <p>Return format:\n+ * {\n+ *   \"1594412650000\": {\n+ *     \"CPU_Utilization\": {\n+ *       \"fields\": [\n+ *         {\n+ *           \"name: \"IndexName\",\n+ *           \"type\": \"VARCHAR\"\n+ *         },\n+ *         <...>\n+ *       ]\n+ *       \"records\": [\n+ *         [\n+ *           \"pmc\",\n+ *           <...>\n+ *         ],\n+ *         <...>\n+ *       ]\n+ *     }\n+ *   }\n+ * }\n+ */\n+public class QueryBatchRequestHandler extends MetricsHandler implements HttpHandler {\n+\n+  private static final Logger LOG = LogManager.getLogger(QueryBatchRequestHandler.class);\n+\n+  private static final int TIME_OUT_VALUE = 2;\n+  private static final TimeUnit TIME_OUT_UNIT = TimeUnit.SECONDS;\n+  private NetClient netClient;\n+  MetricsRestUtil metricsRestUtil;\n+\n+  public static final int DEFAULT_MAX_DATAPOINTS = 100800;  // Must be non-negative\n+  public static final long DEFAULT_SAMPLING_PERIOD = 5000;  // Must be a multiple of 5000\n+\n+  public QueryBatchRequestHandler(NetClient netClient, MetricsRestUtil metricsRestUtil) {\n+    this.netClient = netClient;\n+    this.metricsRestUtil = metricsRestUtil;\n+  }\n+\n+  @Override\n+  public void handle(HttpExchange exchange) throws IOException {\n+    String requestMethod = exchange.getRequestMethod();\n+    if (!requestMethod.equalsIgnoreCase(\"GET\")) {\n+      exchange.sendResponseHeaders(HttpURLConnection.HTTP_NOT_FOUND, -1);\n+      exchange.close();\n+      return;\n+    }\n+\n+    ReaderMetricsProcessor mp = ReaderMetricsProcessor.getInstance();\n+    if (mp == null) {\n+      sendResponse(\n+          exchange,\n+          \"{\\\"error\\\":\\\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\\\"}\",\n+          HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    NavigableSet<Long> batchMetrics = mp.getBatchMetrics();\n+    long currentTime = System.currentTimeMillis();\n+    if (batchMetrics == null) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"The batch metrics api has not been enabled for this node.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"The batch metrics api has not been enabled for this node.\");\n+      return;\n+    }\n+    if (batchMetrics.isEmpty()) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"There are no metrics databases. The reader has run into an issue or has just started.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"There are no metrics databases. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    exchange.getResponseHeaders().set(\"Content-Type\", \"application/json\");\n+\n+    Map<String, String> params = getParamsMap(exchange.getRequestURI().getQuery());\n+\n+    try {\n+      // Parse and validate parameters\n+      String[] validParamsTmp = {\"\", \"metrics\", \"starttime\", \"endtime\", \"samplingperiod\", \"maxdatapoints\"};\n+      Set<String> validParams = new HashSet<>(Arrays.asList(validParamsTmp));\n+      for (String param : params.keySet()) {\n+        if (!validParams.contains(param)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid parameter\", param));\n+        }\n+      }\n+\n+      List<String> metrics = metricsRestUtil.parseArrayParam(params, \"metrics\", false);\n+      String startTimeParam = params.get(\"starttime\");\n+      String endTimeParam = params.get(\"endtime\");\n+      String samplingPeriodParam = params.get(\"samplingperiod\");\n+\n+      for (String metric : metrics) {\n+        if (!MetricsModel.ALL_METRICS.containsKey(metric)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid metric\", metric));\n+        }\n+      }\n+\n+      if (startTimeParam == null || startTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"starttime parameter must be set\");\n+      }\n+      long startTime;\n+      try {\n+        startTime = Long.parseUnsignedLong(startTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid starttime\", startTimeParam));\n+      }\n+\n+      if (endTimeParam == null || endTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"endtime parameter must be set\");\n+      }\n+      long endTime;\n+      try {\n+        endTime = Long.parseUnsignedLong(endTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid endtime\", endTimeParam));\n+      }\n+\n+      long samplingPeriod = DEFAULT_SAMPLING_PERIOD;\n+      if (samplingPeriodParam != null && !samplingPeriodParam.isEmpty()) {\n+        samplingPeriod = Long.parseLong(samplingPeriodParam);\n+        if (samplingPeriod < 5 || samplingPeriod % 5 != 0) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid sampling period\", samplingPeriodParam));\n+        }\n+        if (samplingPeriod >= PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60) {\n+          throw new InvalidParameterException(\"sampling period must be less than the retention period\");\n+        }\n+        samplingPeriod *= 1000;\n+      }\n+\n+      if (startTime >= endTime) {\n+        throw new InvalidParameterException(\"starttime must be less than the endtime\");\n+      }\n+      startTime -= startTime % samplingPeriod;\n+      endTime -= endTime % samplingPeriod;\n+      if (startTime == endTime) {\n+        throw new InvalidParameterException(\"starttime and endtime cannot be equal when rounded down to the nearest sampling period\");\n+      }\n+      if (endTime > currentTime) {\n+        throw new InvalidParameterException(\"endtime can be no greater than the system time at the node\");\n+      }\n+      if (startTime < currentTime - PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60 * 1000) {\n+        throw new InvalidParameterException(\"starttime must be within the retention period\");\n+      }\n+\n+      String queryResponse = queryFromBatchMetrics(batchMetrics, metrics, startTime, endTime, samplingPeriod,\n+              DEFAULT_MAX_DATAPOINTS);\n+      sendResponse(exchange, queryResponse, HttpURLConnection.HTTP_OK);\n+    } catch (InvalidParameterException e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.getMessage() + \".\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_BAD_REQUEST);\n+    } catch (Exception e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.toString() + \"\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_INTERNAL_ERROR);\n+    }\n+  }\n+\n+  @VisibleForTesting\n+  public int appendMetrics(Long timestamp, List<String> metrics, StringBuilder builder, int maxDatapoints) throws Exception {\n+    maxDatapoints += 1;\n+    builder.append(\"\\\"\");\n+    builder.append(timestamp);\n+    builder.append(\"\\\":{\");\n+    MetricsDB db = MetricsDB.fetchExisting(timestamp);\n+    for (int metricIndex = 0, numMetrics = metrics.size(); metricIndex < numMetrics; metricIndex++) {\n+      String metric = metrics.get(metricIndex);\n+      Result<Record> results = db.queryMetric(metric, MetricsModel.ALL_METRICS.get(metric).dimensionNames, maxDatapoints);\n+      if (results != null) {\n+        maxDatapoints -= results.size();\n+        if (maxDatapoints == 0) {\n+          throw new InvalidParameterException(String.format(\"requested data exceeds the %d datapoints limit\", DEFAULT_MAX_DATAPOINTS));\n+        }", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4MDIyNDcyOA=="}, "originalCommit": {"oid": "e2f856bf687d4749dc4d3ebec026aa0a6b06c2ef"}, "originalPosition": 249}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTIzMDI1OQ==", "bodyText": "I agree with joydeep and sid. There are standard tested libraries that we should leverage. Can move to a separate PR as a follow up.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485230259", "createdAt": "2020-09-08T22:29:57Z", "author": {"login": "vigyasharma"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/rest/QueryBatchRequestHandler.java", "diffHunk": "@@ -0,0 +1,309 @@\n+/*\n+ * Copyright 2019 Amazon.com, Inc. or its affiliates. All Rights Reserved.\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\").\n+ * You may not use this file except in compliance with the License.\n+ * A copy of the License is located at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * or in the \"license\" file accompanying this file. This file is distributed\n+ * on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either\n+ * express or implied. See the License for the specific language governing\n+ * permissions and limitations under the License.\n+ */\n+\n+package com.amazon.opendistro.elasticsearch.performanceanalyzer.rest;\n+\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatExceptionCode;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.collectors.StatsCollector;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.config.PluginSettings;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metrics.MetricsRestUtil;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.metricsdb.MetricsDB;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.model.MetricsModel;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.net.NetClient;\n+import com.amazon.opendistro.elasticsearch.performanceanalyzer.reader.ReaderMetricsProcessor;\n+import com.google.common.annotations.VisibleForTesting;\n+import com.sun.net.httpserver.HttpExchange;\n+import com.sun.net.httpserver.HttpHandler;\n+import java.io.IOException;\n+import java.io.OutputStream;\n+import java.net.HttpURLConnection;\n+import java.security.InvalidParameterException;\n+import java.util.Arrays;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.NavigableSet;\n+import java.util.Set;\n+import java.util.concurrent.TimeUnit;\n+import org.apache.logging.log4j.LogManager;\n+import org.apache.logging.log4j.Logger;\n+import org.apache.logging.log4j.message.ParameterizedMessage;\n+import org.apache.logging.log4j.util.Supplier;\n+import org.jooq.Record;\n+import org.jooq.Result;\n+\n+/**\n+ * Request handler that supports querying batch metrics from an EC2 instance\n+ *\n+ * <p>Return 1 minute of CPU_Utilization metrics sampled at a 5s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization&starttime=1566413975000&endtime=1566413980000\"\n+ *\n+ * <p>Return 1 minute of CPU_Utilization and Latency metrics sampled at a 10s sampling period:\n+ * \"http://localhost:9600/_opendistro/_performanceanalyzer/batch?metrics=CPU_Utilization,Latency&starttime=1566413975000&endtime=1566413980000&samplingperiod=10\"\n+ *\n+ * <p>Return format:\n+ * {\n+ *   \"1594412650000\": {\n+ *     \"CPU_Utilization\": {\n+ *       \"fields\": [\n+ *         {\n+ *           \"name: \"IndexName\",\n+ *           \"type\": \"VARCHAR\"\n+ *         },\n+ *         <...>\n+ *       ]\n+ *       \"records\": [\n+ *         [\n+ *           \"pmc\",\n+ *           <...>\n+ *         ],\n+ *         <...>\n+ *       ]\n+ *     }\n+ *   }\n+ * }\n+ */\n+public class QueryBatchRequestHandler extends MetricsHandler implements HttpHandler {\n+\n+  private static final Logger LOG = LogManager.getLogger(QueryBatchRequestHandler.class);\n+\n+  private static final int TIME_OUT_VALUE = 2;\n+  private static final TimeUnit TIME_OUT_UNIT = TimeUnit.SECONDS;\n+  private NetClient netClient;\n+  MetricsRestUtil metricsRestUtil;\n+\n+  public static final int DEFAULT_MAX_DATAPOINTS = 100800;  // Must be non-negative\n+  public static final long DEFAULT_SAMPLING_PERIOD = 5000;  // Must be a multiple of 5000\n+\n+  public QueryBatchRequestHandler(NetClient netClient, MetricsRestUtil metricsRestUtil) {\n+    this.netClient = netClient;\n+    this.metricsRestUtil = metricsRestUtil;\n+  }\n+\n+  @Override\n+  public void handle(HttpExchange exchange) throws IOException {\n+    String requestMethod = exchange.getRequestMethod();\n+    if (!requestMethod.equalsIgnoreCase(\"GET\")) {\n+      exchange.sendResponseHeaders(HttpURLConnection.HTTP_NOT_FOUND, -1);\n+      exchange.close();\n+      return;\n+    }\n+\n+    ReaderMetricsProcessor mp = ReaderMetricsProcessor.getInstance();\n+    if (mp == null) {\n+      sendResponse(\n+          exchange,\n+          \"{\\\"error\\\":\\\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\\\"}\",\n+          HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"Metrics Processor is not initialized. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    NavigableSet<Long> batchMetrics = mp.getBatchMetrics();\n+    long currentTime = System.currentTimeMillis();\n+    if (batchMetrics == null) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"The batch metrics api has not been enabled for this node.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"The batch metrics api has not been enabled for this node.\");\n+      return;\n+    }\n+    if (batchMetrics.isEmpty()) {\n+      sendResponse(\n+              exchange,\n+              \"{\\\"error\\\":\\\"There are no metrics databases. The reader has run into an issue or has just started.\\\"}\",\n+              HttpURLConnection.HTTP_UNAVAILABLE);\n+      LOG.warn(\"There are no metrics databases. The reader has run into an issue or has just started.\");\n+      return;\n+    }\n+\n+    exchange.getResponseHeaders().set(\"Content-Type\", \"application/json\");\n+\n+    Map<String, String> params = getParamsMap(exchange.getRequestURI().getQuery());\n+\n+    try {\n+      // Parse and validate parameters\n+      String[] validParamsTmp = {\"\", \"metrics\", \"starttime\", \"endtime\", \"samplingperiod\", \"maxdatapoints\"};\n+      Set<String> validParams = new HashSet<>(Arrays.asList(validParamsTmp));\n+      for (String param : params.keySet()) {\n+        if (!validParams.contains(param)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid parameter\", param));\n+        }\n+      }\n+\n+      List<String> metrics = metricsRestUtil.parseArrayParam(params, \"metrics\", false);\n+      String startTimeParam = params.get(\"starttime\");\n+      String endTimeParam = params.get(\"endtime\");\n+      String samplingPeriodParam = params.get(\"samplingperiod\");\n+\n+      for (String metric : metrics) {\n+        if (!MetricsModel.ALL_METRICS.containsKey(metric)) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid metric\", metric));\n+        }\n+      }\n+\n+      if (startTimeParam == null || startTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"starttime parameter must be set\");\n+      }\n+      long startTime;\n+      try {\n+        startTime = Long.parseUnsignedLong(startTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid starttime\", startTimeParam));\n+      }\n+\n+      if (endTimeParam == null || endTimeParam.isEmpty()) {\n+        throw new InvalidParameterException(\"endtime parameter must be set\");\n+      }\n+      long endTime;\n+      try {\n+        endTime = Long.parseUnsignedLong(endTimeParam);\n+      } catch (NumberFormatException e) {\n+        throw new InvalidParameterException(String.format(\"%s is an invalid endtime\", endTimeParam));\n+      }\n+\n+      long samplingPeriod = DEFAULT_SAMPLING_PERIOD;\n+      if (samplingPeriodParam != null && !samplingPeriodParam.isEmpty()) {\n+        samplingPeriod = Long.parseLong(samplingPeriodParam);\n+        if (samplingPeriod < 5 || samplingPeriod % 5 != 0) {\n+          throw new InvalidParameterException(String.format(\"%s is an invalid sampling period\", samplingPeriodParam));\n+        }\n+        if (samplingPeriod >= PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60) {\n+          throw new InvalidParameterException(\"sampling period must be less than the retention period\");\n+        }\n+        samplingPeriod *= 1000;\n+      }\n+\n+      if (startTime >= endTime) {\n+        throw new InvalidParameterException(\"starttime must be less than the endtime\");\n+      }\n+      startTime -= startTime % samplingPeriod;\n+      endTime -= endTime % samplingPeriod;\n+      if (startTime == endTime) {\n+        throw new InvalidParameterException(\"starttime and endtime cannot be equal when rounded down to the nearest sampling period\");\n+      }\n+      if (endTime > currentTime) {\n+        throw new InvalidParameterException(\"endtime can be no greater than the system time at the node\");\n+      }\n+      if (startTime < currentTime - PluginSettings.instance().getBatchMetricsRetentionPeriodMinutes() * 60 * 1000) {\n+        throw new InvalidParameterException(\"starttime must be within the retention period\");\n+      }\n+\n+      String queryResponse = queryFromBatchMetrics(batchMetrics, metrics, startTime, endTime, samplingPeriod,\n+              DEFAULT_MAX_DATAPOINTS);\n+      sendResponse(exchange, queryResponse, HttpURLConnection.HTTP_OK);\n+    } catch (InvalidParameterException e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.getMessage() + \".\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_BAD_REQUEST);\n+    } catch (Exception e) {\n+      LOG.error(\n+              (Supplier<?>)\n+                      () ->\n+                              new ParameterizedMessage(\n+                                      \"QueryException {} ExceptionCode: {}.\",\n+                                      e.toString(),\n+                                      StatExceptionCode.REQUEST_ERROR.toString()),\n+              e);\n+      StatsCollector.instance().logException(StatExceptionCode.REQUEST_ERROR);\n+      String response = \"{\\\"error\\\":\\\"\" + e.toString() + \"\\\"}\";\n+      sendResponse(exchange, response, HttpURLConnection.HTTP_INTERNAL_ERROR);\n+    }\n+  }\n+\n+  @VisibleForTesting\n+  public int appendMetrics(Long timestamp, List<String> metrics, StringBuilder builder, int maxDatapoints) throws Exception {\n+    maxDatapoints += 1;\n+    builder.append(\"\\\"\");\n+    builder.append(timestamp);\n+    builder.append(\"\\\":{\");\n+    MetricsDB db = MetricsDB.fetchExisting(timestamp);\n+    for (int metricIndex = 0, numMetrics = metrics.size(); metricIndex < numMetrics; metricIndex++) {\n+      String metric = metrics.get(metricIndex);\n+      Result<Record> results = db.queryMetric(metric, MetricsModel.ALL_METRICS.get(metric).dimensionNames, maxDatapoints);\n+      if (results != null) {\n+        maxDatapoints -= results.size();\n+        if (maxDatapoints == 0) {\n+          throw new InvalidParameterException(String.format(\"requested data exceeds the %d datapoints limit\", DEFAULT_MAX_DATAPOINTS));\n+        }\n+        builder.append(\"\\\"\");\n+        builder.append(metric);\n+        builder.append(\"\\\":\");\n+        builder.append(results.formatJSON());\n+        for (metricIndex += 1; metricIndex < numMetrics; metricIndex++) {\n+          metric = metrics.get(metricIndex);\n+          results = db.queryMetric(metric, MetricsModel.ALL_METRICS.get(metric).dimensionNames, maxDatapoints);\n+          if (results != null) {\n+            maxDatapoints -= results.size();\n+            if (maxDatapoints == 0) {\n+              throw new InvalidParameterException(String.format(\"requested data exceeds the %d datapoints limit\", DEFAULT_MAX_DATAPOINTS));\n+            }\n+            builder.append(\",\\\"\");\n+            builder.append(metric);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTUzOTAyNw=="}, "originalCommit": {"oid": "e2f856bf687d4749dc4d3ebec026aa0a6b06c2ef"}, "originalPosition": 263}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTIzMTM4OQ==", "bodyText": "it's just this new version is static and accepts a windowStartTime argument.\n\nwhy do we need a separate static instance of the same method, instead of overloading public void deleteOnDiskFile() ?", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r485231389", "createdAt": "2020-09-08T22:33:05Z", "author": {"login": "vigyasharma"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -259,6 +308,23 @@ public void deleteOnDiskFile() {\n     }\n   }\n \n+  /**\n+   * Deletes the metricsdb file associated with the given timestamp if it exists.\n+   *\n+   * @param windowStartTime the timestamp associated with an existing metricsdb file\n+   */\n+  public static void deleteOnDiskFile(long windowStartTime) {\n+    String dbFilePath = getDBFilePath(windowStartTime);\n+    File dbFile = new File(dbFilePath);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4Mzg1NTI1Mg=="}, "originalCommit": {"oid": "563905e58200952a10e150dc5956112d2a502fe6"}, "originalPosition": 103}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ace75f930857242a31e5780f28c937df54826c28", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/ace75f930857242a31e5780f28c937df54826c28", "committedDate": "2020-09-08T22:47:40Z", "message": "Add comment about concurrent access of batchMetricsDBSet"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bc52cc2b9942cbc39d4208fa2e93d31957ed9095", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/bc52cc2b9942cbc39d4208fa2e93d31957ed9095", "committedDate": "2020-09-08T23:11:47Z", "message": "Cache limit on number of batch metrics files"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8d764a9b897d8a0a9d4bb2f268928f527ede00e9", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/8d764a9b897d8a0a9d4bb2f268928f527ede00e9", "committedDate": "2020-09-09T16:39:12Z", "message": "Address minor nits in QueryBatchRequestHandler"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "61cf265349445e5cab8e921583c85e30cd897042", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/61cf265349445e5cab8e921583c85e30cd897042", "committedDate": "2020-09-09T16:58:49Z", "message": "Separate out snapshot and metricsdb trimming"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a6b344e4cab46708d01ed458f4f5fb7f540fa4b8", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/a6b344e4cab46708d01ed458f4f5fb7f540fa4b8", "committedDate": "2020-09-09T17:21:09Z", "message": "Replace use of VisibleForTesting with shims"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "057291923ecebe6d750f127b3d79e065267039d7", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/057291923ecebe6d750f127b3d79e065267039d7", "committedDate": "2020-09-09T19:48:52Z", "message": "Rename trimMetricsDBFiles to trimOldMetricsDBFiles"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "314306f821cd1be9477cf44e083635b2c4df3e73", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/314306f821cd1be9477cf44e083635b2c4df3e73", "committedDate": "2020-09-10T00:09:27Z", "message": "Purge metricsdb files on startup"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0f935aead0f2bab3dbd912328d3f4a63ccbabae1", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/0f935aead0f2bab3dbd912328d3f4a63ccbabae1", "committedDate": "2020-09-10T00:32:35Z", "message": "Address checkstyle issue"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg1NTEwNTI3", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#pullrequestreview-485510527", "createdAt": "2020-09-10T01:47:14Z", "commit": {"oid": "0f935aead0f2bab3dbd912328d3f4a63ccbabae1"}, "state": "DISMISSED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQwMTo0NzoxNFrOHPf8pg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMFQwMTo0NzoxNFrOHPf8pg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NjAxNDExOA==", "bodyText": "We might skip the overhead of regex compiling by stripping off the parentPath from the prefix -  the remainder is what we are looking for in the directory.", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#discussion_r486014118", "createdAt": "2020-09-10T01:47:14Z", "author": {"login": "yojs"}, "path": "src/main/java/com/amazon/opendistro/elasticsearch/performanceanalyzer/metricsdb/MetricsDB.java", "diffHunk": "@@ -327,6 +331,36 @@ public static void deleteOnDiskFile(long windowStartTime) {\n     }\n   }\n \n+  /**\n+   * Returns the timestamps associated with on-disk files.\n+   *\n+   * @return the timestamps associated with on-disk files\n+   */\n+  public static Set<Long> listOnDiskFiles() {\n+    String prefix = PluginSettings.instance().getSettingValue(DB_FILE_PREFIX_PATH_CONF_NAME, DB_FILE_PREFIX_PATH_DEFAULT);\n+    Path prefixPath = Paths.get(prefix);\n+    Path parentPath = prefixPath.getParent();\n+    Set<Long> found = new HashSet<Long>();\n+    try (Stream<Path> paths = Files.list(parentPath)) {\n+      PathMatcher matcher = FileSystems.getDefault().getPathMatcher(\"regex:\" + prefix + \"\\\\d+\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0f935aead0f2bab3dbd912328d3f4a63ccbabae1"}, "originalPosition": 36}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg1NTEzOTU1", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#pullrequestreview-485513955", "createdAt": "2020-09-10T01:58:32Z", "commit": {"oid": "0f935aead0f2bab3dbd912328d3f4a63ccbabae1"}, "state": "DISMISSED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestCommit", "commit": {"oid": "333d757314e923b6a18931ae320ae0178377a483", "author": {"user": {"login": "ricardolstephen", "name": "Ricardo L. Stephen"}}, "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/commit/333d757314e923b6a18931ae320ae0178377a483", "committedDate": "2020-09-10T02:38:22Z", "message": "Ignore incorrect spotbugs issue"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg1NTQyOTgy", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#pullrequestreview-485542982", "createdAt": "2020-09-10T03:39:10Z", "commit": {"oid": "333d757314e923b6a18931ae320ae0178377a483"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg1NTQ2MTY3", "url": "https://github.com/opendistro-for-elasticsearch/performance-analyzer-rca/pull/315#pullrequestreview-485546167", "createdAt": "2020-09-10T03:51:20Z", "commit": {"oid": "333d757314e923b6a18931ae320ae0178377a483"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 834, "cost": 1, "resetAt": "2021-11-01T16:19:10Z"}}}