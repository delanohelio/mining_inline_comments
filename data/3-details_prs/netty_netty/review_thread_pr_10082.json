{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzgzMzE2NDI2", "number": 10082, "reviewThreads": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQxNDoyMjoxN1rODms1EA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQxMjowNToyMVrODnDDbw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQxOTA2OTYwOnYy", "diffSide": "RIGHT", "path": "codec/src/main/java/io/netty/handler/codec/compression/LzfEncoder.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQxNDoyMjoxN1rOF0RCVA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQxNDoyMjoxN1rOF0RCVA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDM0OTM5Ng==", "bodyText": "we need to also keep the old constructor for backward combat.", "url": "https://github.com/netty/netty/pull/10082#discussion_r390349396", "createdAt": "2020-03-10T14:22:17Z", "author": {"login": "normanmaurer"}, "path": "codec/src/main/java/io/netty/handler/codec/compression/LzfEncoder.java", "diffHunk": "@@ -55,58 +70,73 @@\n      * non-standard platforms it may be necessary to use {@link #LzfEncoder(boolean)} with {@code true} param.\n      */\n     public LzfEncoder() {\n-        this(false, MAX_CHUNK_LEN);\n+        this(false, MAX_CHUNK_LEN, -1);\n     }\n \n     /**\n      * Creates a new LZF encoder with specified encoding instance.\n      *\n-     * @param safeInstance\n-     *        If {@code true} encoder will use {@link ChunkEncoder} that only uses standard JDK access methods,\n-     *        and should work on all Java platforms and JVMs.\n-     *        Otherwise encoder will try to use highly optimized {@link ChunkEncoder} implementation that uses\n-     *        Sun JDK's {@link sun.misc.Unsafe} class (which may be included by other JDK's as well).\n+     * @param safeInstance If {@code true} encoder will use {@link ChunkEncoder} that only uses\n+     *                     standard JDK access methods, and should work on all Java platforms and JVMs.\n+     *                     Otherwise encoder will try to use highly optimized {@link ChunkEncoder}\n+     *                     implementation that uses Sun JDK's {@link sun.misc.Unsafe}\n+     *                     class (which may be included by other JDK's as well).\n      */\n     public LzfEncoder(boolean safeInstance) {\n-        this(safeInstance, MAX_CHUNK_LEN);\n+        this(safeInstance, MAX_CHUNK_LEN, -1);\n+    }\n+\n+    /**\n+     * Creates a new LZF encoder with specified encoding instance and compressThreshold.\n+     *\n+     * @param safeInstance      If {@code true} encoder will use {@link ChunkEncoder} that only uses standard\n+     *                          JDK access methods, and should work on all Java platforms and JVMs.\n+     *                          Otherwise encoder will try to use highly optimized {@link ChunkEncoder}\n+     *                          implementation that uses Sun JDK's {@link sun.misc.Unsafe}\n+     *                          class (which may be included by other JDK's as well).\n+     * @param compressThreshold compress threshold for compression. see {@link #compressThreshold}.\n+     */\n+    public LzfEncoder(boolean safeInstance, int compressThreshold) {\n+        this(safeInstance, MAX_CHUNK_LEN, compressThreshold);\n     }\n \n     /**\n      * Creates a new LZF encoder with specified total length of encoded chunk. You can configure it to encode\n      * your data flow more efficient if you know the average size of messages that you send.\n      *\n-     * @param totalLength\n-     *        Expected total length of content to compress; only matters for outgoing messages that is smaller\n-     *        than maximum chunk size (64k), to optimize encoding hash tables.\n+     * @param totalLength Expected total length of content to compress;\n+     *                    only matters for outgoing messages that is smaller than maximum chunk size (64k),\n+     *                    to optimize encoding hash tables.\n      */\n     public LzfEncoder(int totalLength) {\n-        this(false, totalLength);\n+        this(false, totalLength, -1);\n     }\n \n     /**\n      * Creates a new LZF encoder with specified settings.\n      *\n-     * @param safeInstance\n-     *        If {@code true} encoder will use {@link ChunkEncoder} that only uses standard JDK access methods,\n-     *        and should work on all Java platforms and JVMs.\n-     *        Otherwise encoder will try to use highly optimized {@link ChunkEncoder} implementation that uses\n-     *        Sun JDK's {@link sun.misc.Unsafe} class (which may be included by other JDK's as well).\n-     * @param totalLength\n-     *        Expected total length of content to compress; only matters for outgoing messages that is smaller\n-     *        than maximum chunk size (64k), to optimize encoding hash tables.\n+     * @param safeInstance If {@code true} encoder will use {@link ChunkEncoder} that only uses standard JDK\n+     *                     access methods, and should work on all Java platforms and JVMs.\n+     *                     Otherwise encoder will try to use highly optimized {@link ChunkEncoder}\n+     *                     implementation that uses Sun JDK's {@link sun.misc.Unsafe}\n+     *                     class (which may be included by other JDK's as well).\n+     * @param totalLength  Expected total length of content to compress; only matters for outgoing messages\n+     *                     that is smaller than maximum chunk size (64k), to optimize encoding hash tables.\n      */\n-    public LzfEncoder(boolean safeInstance, int totalLength) {\n+    public LzfEncoder(boolean safeInstance, int totalLength, int compressThreshold) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9b3ff30a4df57d3ceda77a19d33af709ad50e3be"}, "originalPosition": 122}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQxOTA3NzkxOnYy", "diffSide": "RIGHT", "path": "codec/src/main/java/io/netty/handler/codec/compression/LzfEncoder.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQxNDoyMzo1N1rOF0RHiA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQxNDoyMzo1N1rOF0RHiA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDM1MDcyOA==", "bodyText": "I would prefer to not allow this for now... I think there is really no good reason to adjust this on the fly.", "url": "https://github.com/netty/netty/pull/10082#discussion_r390350728", "createdAt": "2020-03-10T14:23:57Z", "author": {"login": "normanmaurer"}, "path": "codec/src/main/java/io/netty/handler/codec/compression/LzfEncoder.java", "diffHunk": "@@ -138,6 +176,48 @@ protected void encode(ChannelHandlerContext ctx, ByteBuf in, ByteBuf out) throws\n         }\n     }\n \n+    private int encodeCompress(byte[] input, int inputPtr, int length, byte[] output, int outputPtr) {\n+        return LZFEncoder.appendEncoded(encoder,\n+                input, inputPtr, length, output, outputPtr) - outputPtr;\n+    }\n+\n+    /**\n+     * Use lzf uncompressed format to encode a piece of input.\n+     */\n+    private static int encodeNonCompress(byte[] input, int inputPtr, int length, byte[] output, int outputPtr) {\n+        int left = length;\n+        int chunkLen = Math.min(LZFChunk.MAX_CHUNK_LEN, left);\n+        outputPtr = LZFChunk.appendNonCompressed(input, inputPtr, length, output, outputPtr);\n+        left -= chunkLen;\n+        if (left < 1) {\n+            return outputPtr;\n+        }\n+        inputPtr += chunkLen;\n+        do {\n+            chunkLen = Math.min(left, LZFChunk.MAX_CHUNK_LEN);\n+            outputPtr = LZFChunk.appendNonCompressed(input, inputPtr, length, output, outputPtr);\n+            inputPtr += chunkLen;\n+            left -= chunkLen;\n+        } while (left > 0);\n+        return outputPtr;\n+    }\n+\n+    public int getCompressThreshold() {\n+        return compressThreshold;\n+    }\n+\n+    /**\n+     * Since we could set this threshold at runtime, so we keep set method.\n+     */\n+    public void setCompressThreshold(int compressThreshold) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9b3ff30a4df57d3ceda77a19d33af709ad50e3be"}, "originalPosition": 198}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQxOTA4MDMyOnYy", "diffSide": "RIGHT", "path": "codec/src/test/java/io/netty/handler/codec/compression/LengthAwareLzfIntegrationTest.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQxNDoyNDoyNFrOF0RI-g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMFQxNDoyNDoyNFrOF0RI-g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDM1MTA5OA==", "bodyText": "remove...", "url": "https://github.com/netty/netty/pull/10082#discussion_r390351098", "createdAt": "2020-03-10T14:24:24Z", "author": {"login": "normanmaurer"}, "path": "codec/src/test/java/io/netty/handler/codec/compression/LengthAwareLzfIntegrationTest.java", "diffHunk": "@@ -0,0 +1,29 @@\n+/*\n+ * Copyright 2020 The Netty Project\n+ *\n+ * The Netty Project licenses this file to you under the Apache License,\n+ * version 2.0 (the \"License\"); you may not use this file except in compliance\n+ * with the License. You may obtain a copy of the License at:\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package io.netty.handler.codec.compression;\n+\n+import io.netty.channel.embedded.EmbeddedChannel;\n+\n+/**\n+ * LengthAwareLzfIntegrationTest", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9b3ff30a4df57d3ceda77a19d33af709ad50e3be"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQyMjAzMjk5OnYy", "diffSide": "RIGHT", "path": "codec/src/main/java/io/netty/handler/codec/compression/LzfEncoder.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQwODo0ODowNlrOF0traA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQwOTowMjowNlrOF0uH5Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDgxODY2NA==", "bodyText": "should we validate this on construction and if so throw ?", "url": "https://github.com/netty/netty/pull/10082#discussion_r390818664", "createdAt": "2020-03-11T08:48:06Z", "author": {"login": "normanmaurer"}, "path": "codec/src/main/java/io/netty/handler/codec/compression/LzfEncoder.java", "diffHunk": "@@ -17,27 +17,42 @@\n \n import com.ning.compress.BufferRecycler;\n import com.ning.compress.lzf.ChunkEncoder;\n+import com.ning.compress.lzf.LZFChunk;\n import com.ning.compress.lzf.LZFEncoder;\n import com.ning.compress.lzf.util.ChunkEncoderFactory;\n import io.netty.buffer.ByteBuf;\n import io.netty.channel.ChannelHandlerContext;\n import io.netty.handler.codec.MessageToByteEncoder;\n+import io.netty.util.internal.logging.InternalLogger;\n+import io.netty.util.internal.logging.InternalLoggerFactory;\n \n-import static com.ning.compress.lzf.LZFChunk.*;\n+import static com.ning.compress.lzf.LZFChunk.MAX_CHUNK_LEN;\n \n /**\n  * Compresses a {@link ByteBuf} using the LZF format.\n- *\n+ * <p>\n  * See original <a href=\"http://oldhome.schmorp.de/marc/liblzf.html\">LZF package</a>\n  * and <a href=\"https://github.com/ning/compress/wiki/LZFFormat\">LZF format</a> for full description.\n  */\n public class LzfEncoder extends MessageToByteEncoder<ByteBuf> {\n+\n+    private static final InternalLogger logger = InternalLoggerFactory.getInstance(LzfEncoder.class);\n+\n     /**\n      * Minimum block size ready for compression. Blocks with length\n      * less than {@link #MIN_BLOCK_TO_COMPRESS} will write as uncompressed.\n      */\n     private static final int MIN_BLOCK_TO_COMPRESS = 16;\n \n+    /**\n+     * Compress threshold for LZF format. When the amount of input data is less than compressThreshold,\n+     * we will construct an uncompressed output according to the LZF format.\n+     * <p>\n+     * When the value is less than {@see ChunkEncoder#MIN_BLOCK_TO_COMPRESS}, since LZF will not compress data\n+     * that is less than {@see ChunkEncoder#MIN_BLOCK_TO_COMPRESS}, compressThreshold will not work.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8dc27b7884b8a7653a0c3700c6e499ff6428f2af"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDgyNTk1Nw==", "bodyText": "Currently I checked compressThreshold <MIN_BLOCK_TO_COMPRESS. If so, compressThreshold = MIN_BLOCK_TO_COMPRESS, and print a log.\nIt seems that the startup phase informs the user that this is an inappropriate value and is a good choice. fixed...", "url": "https://github.com/netty/netty/pull/10082#discussion_r390825957", "createdAt": "2020-03-11T09:02:06Z", "author": {"login": "carryxyh"}, "path": "codec/src/main/java/io/netty/handler/codec/compression/LzfEncoder.java", "diffHunk": "@@ -17,27 +17,42 @@\n \n import com.ning.compress.BufferRecycler;\n import com.ning.compress.lzf.ChunkEncoder;\n+import com.ning.compress.lzf.LZFChunk;\n import com.ning.compress.lzf.LZFEncoder;\n import com.ning.compress.lzf.util.ChunkEncoderFactory;\n import io.netty.buffer.ByteBuf;\n import io.netty.channel.ChannelHandlerContext;\n import io.netty.handler.codec.MessageToByteEncoder;\n+import io.netty.util.internal.logging.InternalLogger;\n+import io.netty.util.internal.logging.InternalLoggerFactory;\n \n-import static com.ning.compress.lzf.LZFChunk.*;\n+import static com.ning.compress.lzf.LZFChunk.MAX_CHUNK_LEN;\n \n /**\n  * Compresses a {@link ByteBuf} using the LZF format.\n- *\n+ * <p>\n  * See original <a href=\"http://oldhome.schmorp.de/marc/liblzf.html\">LZF package</a>\n  * and <a href=\"https://github.com/ning/compress/wiki/LZFFormat\">LZF format</a> for full description.\n  */\n public class LzfEncoder extends MessageToByteEncoder<ByteBuf> {\n+\n+    private static final InternalLogger logger = InternalLoggerFactory.getInstance(LzfEncoder.class);\n+\n     /**\n      * Minimum block size ready for compression. Blocks with length\n      * less than {@link #MIN_BLOCK_TO_COMPRESS} will write as uncompressed.\n      */\n     private static final int MIN_BLOCK_TO_COMPRESS = 16;\n \n+    /**\n+     * Compress threshold for LZF format. When the amount of input data is less than compressThreshold,\n+     * we will construct an uncompressed output according to the LZF format.\n+     * <p>\n+     * When the value is less than {@see ChunkEncoder#MIN_BLOCK_TO_COMPRESS}, since LZF will not compress data\n+     * that is less than {@see ChunkEncoder#MIN_BLOCK_TO_COMPRESS}, compressThreshold will not work.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDgxODY2NA=="}, "originalCommit": {"oid": "8dc27b7884b8a7653a0c3700c6e499ff6428f2af"}, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQyMjAzNDYyOnYy", "diffSide": "RIGHT", "path": "codec/src/main/java/io/netty/handler/codec/compression/LzfEncoder.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQwODo0ODozNVrOF0tsXg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQwODo0ODozNVrOF0tsXg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDgxODkxMA==", "bodyText": "final", "url": "https://github.com/netty/netty/pull/10082#discussion_r390818910", "createdAt": "2020-03-11T08:48:35Z", "author": {"login": "normanmaurer"}, "path": "codec/src/main/java/io/netty/handler/codec/compression/LzfEncoder.java", "diffHunk": "@@ -17,27 +17,42 @@\n \n import com.ning.compress.BufferRecycler;\n import com.ning.compress.lzf.ChunkEncoder;\n+import com.ning.compress.lzf.LZFChunk;\n import com.ning.compress.lzf.LZFEncoder;\n import com.ning.compress.lzf.util.ChunkEncoderFactory;\n import io.netty.buffer.ByteBuf;\n import io.netty.channel.ChannelHandlerContext;\n import io.netty.handler.codec.MessageToByteEncoder;\n+import io.netty.util.internal.logging.InternalLogger;\n+import io.netty.util.internal.logging.InternalLoggerFactory;\n \n-import static com.ning.compress.lzf.LZFChunk.*;\n+import static com.ning.compress.lzf.LZFChunk.MAX_CHUNK_LEN;\n \n /**\n  * Compresses a {@link ByteBuf} using the LZF format.\n- *\n+ * <p>\n  * See original <a href=\"http://oldhome.schmorp.de/marc/liblzf.html\">LZF package</a>\n  * and <a href=\"https://github.com/ning/compress/wiki/LZFFormat\">LZF format</a> for full description.\n  */\n public class LzfEncoder extends MessageToByteEncoder<ByteBuf> {\n+\n+    private static final InternalLogger logger = InternalLoggerFactory.getInstance(LzfEncoder.class);\n+\n     /**\n      * Minimum block size ready for compression. Blocks with length\n      * less than {@link #MIN_BLOCK_TO_COMPRESS} will write as uncompressed.\n      */\n     private static final int MIN_BLOCK_TO_COMPRESS = 16;\n \n+    /**\n+     * Compress threshold for LZF format. When the amount of input data is less than compressThreshold,\n+     * we will construct an uncompressed output according to the LZF format.\n+     * <p>\n+     * When the value is less than {@see ChunkEncoder#MIN_BLOCK_TO_COMPRESS}, since LZF will not compress data\n+     * that is less than {@see ChunkEncoder#MIN_BLOCK_TO_COMPRESS}, compressThreshold will not work.\n+     */\n+    private int compressThreshold;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8dc27b7884b8a7653a0c3700c6e499ff6428f2af"}, "originalPosition": 40}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQyMjAzNjM0OnYy", "diffSide": "RIGHT", "path": "codec/src/main/java/io/netty/handler/codec/compression/LzfEncoder.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQwODo0OTowN1rOF0ttbA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQwODo0OTowN1rOF0ttbA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDgxOTE4MA==", "bodyText": "add javadocs for param compressThreshold as well.", "url": "https://github.com/netty/netty/pull/10082#discussion_r390819180", "createdAt": "2020-03-11T08:49:07Z", "author": {"login": "normanmaurer"}, "path": "codec/src/main/java/io/netty/handler/codec/compression/LzfEncoder.java", "diffHunk": "@@ -55,58 +70,79 @@\n      * non-standard platforms it may be necessary to use {@link #LzfEncoder(boolean)} with {@code true} param.\n      */\n     public LzfEncoder() {\n-        this(false, MAX_CHUNK_LEN);\n+        this(false, MAX_CHUNK_LEN, -1);\n     }\n \n     /**\n      * Creates a new LZF encoder with specified encoding instance.\n      *\n-     * @param safeInstance\n-     *        If {@code true} encoder will use {@link ChunkEncoder} that only uses standard JDK access methods,\n-     *        and should work on all Java platforms and JVMs.\n-     *        Otherwise encoder will try to use highly optimized {@link ChunkEncoder} implementation that uses\n-     *        Sun JDK's {@link sun.misc.Unsafe} class (which may be included by other JDK's as well).\n+     * @param safeInstance If {@code true} encoder will use {@link ChunkEncoder} that only uses\n+     *                     standard JDK access methods, and should work on all Java platforms and JVMs.\n+     *                     Otherwise encoder will try to use highly optimized {@link ChunkEncoder}\n+     *                     implementation that uses Sun JDK's {@link sun.misc.Unsafe}\n+     *                     class (which may be included by other JDK's as well).\n      */\n     public LzfEncoder(boolean safeInstance) {\n-        this(safeInstance, MAX_CHUNK_LEN);\n+        this(safeInstance, MAX_CHUNK_LEN, -1);\n+    }\n+\n+    /**\n+     * Creates a new LZF encoder with specified encoding instance and compressThreshold.\n+     *\n+     * @param safeInstance      If {@code true} encoder will use {@link ChunkEncoder} that only uses standard\n+     *                          JDK access methods, and should work on all Java platforms and JVMs.\n+     *                          Otherwise encoder will try to use highly optimized {@link ChunkEncoder}\n+     *                          implementation that uses Sun JDK's {@link sun.misc.Unsafe}\n+     *                          class (which may be included by other JDK's as well).\n+     * @param totalLength       Expected total length of content to compress; only matters for outgoing messages\n+     *                          that is smaller than maximum chunk size (64k), to optimize encoding hash tables.\n+     */\n+    public LzfEncoder(boolean safeInstance, int totalLength) {\n+        this(safeInstance, totalLength, -1);\n     }\n \n     /**\n      * Creates a new LZF encoder with specified total length of encoded chunk. You can configure it to encode\n      * your data flow more efficient if you know the average size of messages that you send.\n      *\n-     * @param totalLength\n-     *        Expected total length of content to compress; only matters for outgoing messages that is smaller\n-     *        than maximum chunk size (64k), to optimize encoding hash tables.\n+     * @param totalLength Expected total length of content to compress;\n+     *                    only matters for outgoing messages that is smaller than maximum chunk size (64k),\n+     *                    to optimize encoding hash tables.\n      */\n     public LzfEncoder(int totalLength) {\n-        this(false, totalLength);\n+        this(false, totalLength, -1);\n     }\n \n     /**\n      * Creates a new LZF encoder with specified settings.\n      *\n-     * @param safeInstance\n-     *        If {@code true} encoder will use {@link ChunkEncoder} that only uses standard JDK access methods,\n-     *        and should work on all Java platforms and JVMs.\n-     *        Otherwise encoder will try to use highly optimized {@link ChunkEncoder} implementation that uses\n-     *        Sun JDK's {@link sun.misc.Unsafe} class (which may be included by other JDK's as well).\n-     * @param totalLength\n-     *        Expected total length of content to compress; only matters for outgoing messages that is smaller\n-     *        than maximum chunk size (64k), to optimize encoding hash tables.\n+     * @param safeInstance If {@code true} encoder will use {@link ChunkEncoder} that only uses standard JDK\n+     *                     access methods, and should work on all Java platforms and JVMs.\n+     *                     Otherwise encoder will try to use highly optimized {@link ChunkEncoder}\n+     *                     implementation that uses Sun JDK's {@link sun.misc.Unsafe}\n+     *                     class (which may be included by other JDK's as well).\n+     * @param totalLength  Expected total length of content to compress; only matters for outgoing messages\n+     *                     that is smaller than maximum chunk size (64k), to optimize encoding hash tables.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8dc27b7884b8a7653a0c3700c6e499ff6428f2af"}, "originalPosition": 120}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQyMjA4NzMwOnYy", "diffSide": "RIGHT", "path": "codec/src/main/java/io/netty/handler/codec/compression/LzfEncoder.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQwOTowNDo1OFrOF0uNpw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQwOToxNzoxN1rOF0uoNA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDgyNzQzMQ==", "bodyText": "I think we should not use -1 as a special number here and use MIN_BLOCK_TO_COMPRESS  as our default.", "url": "https://github.com/netty/netty/pull/10082#discussion_r390827431", "createdAt": "2020-03-11T09:04:58Z", "author": {"login": "normanmaurer"}, "path": "codec/src/main/java/io/netty/handler/codec/compression/LzfEncoder.java", "diffHunk": "@@ -131,10 +133,10 @@ public LzfEncoder(boolean safeInstance, int totalLength, int compressThreshold)\n                     \" (expected: \" + MIN_BLOCK_TO_COMPRESS + '-' + MAX_CHUNK_LEN + ')');\n         }\n \n-        if (compressThreshold >= 0 && compressThreshold < MIN_BLOCK_TO_COMPRESS) {\n+        if (compressThreshold > 0 && compressThreshold < MIN_BLOCK_TO_COMPRESS) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "173bbde9794eb304239181903052980c2e8846a2"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDgzNDIyOA==", "bodyText": "Fixed.", "url": "https://github.com/netty/netty/pull/10082#discussion_r390834228", "createdAt": "2020-03-11T09:17:17Z", "author": {"login": "carryxyh"}, "path": "codec/src/main/java/io/netty/handler/codec/compression/LzfEncoder.java", "diffHunk": "@@ -131,10 +133,10 @@ public LzfEncoder(boolean safeInstance, int totalLength, int compressThreshold)\n                     \" (expected: \" + MIN_BLOCK_TO_COMPRESS + '-' + MAX_CHUNK_LEN + ')');\n         }\n \n-        if (compressThreshold >= 0 && compressThreshold < MIN_BLOCK_TO_COMPRESS) {\n+        if (compressThreshold > 0 && compressThreshold < MIN_BLOCK_TO_COMPRESS) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDgyNzQzMQ=="}, "originalCommit": {"oid": "173bbde9794eb304239181903052980c2e8846a2"}, "originalPosition": 37}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQyMjE1NzE1OnYy", "diffSide": "RIGHT", "path": "codec/src/main/java/io/netty/handler/codec/compression/LzfEncoder.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQwOToyNDowN1rOF0u3zw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQwOToyNDowN1rOF0u3zw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDgzODIyMw==", "bodyText": "nit: make this final", "url": "https://github.com/netty/netty/pull/10082#discussion_r390838223", "createdAt": "2020-03-11T09:24:07Z", "author": {"login": "normanmaurer"}, "path": "codec/src/main/java/io/netty/handler/codec/compression/LzfEncoder.java", "diffHunk": "@@ -128,8 +166,16 @@ protected void encode(ChannelHandlerContext ctx, ByteBuf in, ByteBuf out) throws\n         out.ensureWritable(maxOutputLength);\n         final byte[] output = out.array();\n         final int outputPtr = out.arrayOffset() + out.writerIndex();\n-        final int outputLength = LZFEncoder.appendEncoded(encoder,\n-                        input, inputPtr, length,  output, outputPtr) - outputPtr;\n+\n+        int outputLength;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5d706c6245b71a84c4aede2c3906d90ef50b331c"}, "originalPosition": 154}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjQyMjcxMDg3OnYy", "diffSide": "RIGHT", "path": "codec/src/main/java/io/netty/handler/codec/compression/LzfEncoder.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQxMjowNToyMVrOF00J9Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMy0xMVQxMjowOTowMVrOF00Qhw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDkyNDc4OQ==", "bodyText": "@carryxyh sorry I missed this before... Please remove this declaration and the related imports as its not used anymore.", "url": "https://github.com/netty/netty/pull/10082#discussion_r390924789", "createdAt": "2020-03-11T12:05:21Z", "author": {"login": "normanmaurer"}, "path": "codec/src/main/java/io/netty/handler/codec/compression/LzfEncoder.java", "diffHunk": "@@ -17,27 +17,42 @@\n \n import com.ning.compress.BufferRecycler;\n import com.ning.compress.lzf.ChunkEncoder;\n+import com.ning.compress.lzf.LZFChunk;\n import com.ning.compress.lzf.LZFEncoder;\n import com.ning.compress.lzf.util.ChunkEncoderFactory;\n import io.netty.buffer.ByteBuf;\n import io.netty.channel.ChannelHandlerContext;\n import io.netty.handler.codec.MessageToByteEncoder;\n+import io.netty.util.internal.logging.InternalLogger;\n+import io.netty.util.internal.logging.InternalLoggerFactory;\n \n-import static com.ning.compress.lzf.LZFChunk.*;\n+import static com.ning.compress.lzf.LZFChunk.MAX_CHUNK_LEN;\n \n /**\n  * Compresses a {@link ByteBuf} using the LZF format.\n- *\n+ * <p>\n  * See original <a href=\"http://oldhome.schmorp.de/marc/liblzf.html\">LZF package</a>\n  * and <a href=\"https://github.com/ning/compress/wiki/LZFFormat\">LZF format</a> for full description.\n  */\n public class LzfEncoder extends MessageToByteEncoder<ByteBuf> {\n+\n+    private static final InternalLogger logger = InternalLoggerFactory.getInstance(LzfEncoder.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "05f61dc01343b56135db5bf28bc8c22f9e5e1d02"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDkyNjQ3MQ==", "bodyText": "Careful. fixed..  :)", "url": "https://github.com/netty/netty/pull/10082#discussion_r390926471", "createdAt": "2020-03-11T12:09:01Z", "author": {"login": "carryxyh"}, "path": "codec/src/main/java/io/netty/handler/codec/compression/LzfEncoder.java", "diffHunk": "@@ -17,27 +17,42 @@\n \n import com.ning.compress.BufferRecycler;\n import com.ning.compress.lzf.ChunkEncoder;\n+import com.ning.compress.lzf.LZFChunk;\n import com.ning.compress.lzf.LZFEncoder;\n import com.ning.compress.lzf.util.ChunkEncoderFactory;\n import io.netty.buffer.ByteBuf;\n import io.netty.channel.ChannelHandlerContext;\n import io.netty.handler.codec.MessageToByteEncoder;\n+import io.netty.util.internal.logging.InternalLogger;\n+import io.netty.util.internal.logging.InternalLoggerFactory;\n \n-import static com.ning.compress.lzf.LZFChunk.*;\n+import static com.ning.compress.lzf.LZFChunk.MAX_CHUNK_LEN;\n \n /**\n  * Compresses a {@link ByteBuf} using the LZF format.\n- *\n+ * <p>\n  * See original <a href=\"http://oldhome.schmorp.de/marc/liblzf.html\">LZF package</a>\n  * and <a href=\"https://github.com/ning/compress/wiki/LZFFormat\">LZF format</a> for full description.\n  */\n public class LzfEncoder extends MessageToByteEncoder<ByteBuf> {\n+\n+    private static final InternalLogger logger = InternalLoggerFactory.getInstance(LzfEncoder.class);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM5MDkyNDc4OQ=="}, "originalCommit": {"oid": "05f61dc01343b56135db5bf28bc8c22f9e5e1d02"}, "originalPosition": 25}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3509, "cost": 1, "resetAt": "2021-11-12T20:28:25Z"}}}