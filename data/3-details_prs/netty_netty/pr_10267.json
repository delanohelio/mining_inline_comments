{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDE1NjczOTU1", "number": 10267, "title": "Reduce memory fragmentation caused by PooledByteBufAllocator", "bodyText": "Review PooledByteBufAllocator in respect of jemalloc 4.x changes and\nupdate allocate algorithm.\nMotivation:\nFor size from 512 bytes to chunkSize, we use a buddy algorithm. The drawback is that it has a large internal fragmentation.\nModifications:\n\nadd SizeClassesMetric and SizeClasses\nremove tiny size, now we have small, normal and huge size\nrewrite the structure of PoolChunk\nrewrite pooled allocate algorithm in PoolChunk\nwhen allocate subpage, using lowest common multiple of pageSize and elemSize instead of pageSize.\nadd more tests in PooledByteBufAllocatorTest and PoolArenaTest\n\nResult:\nReduce internal fragmentation.\nClosed #3910", "createdAt": "2020-05-10T06:01:22Z", "url": "https://github.com/netty/netty/pull/10267", "merged": true, "mergeCommit": {"oid": "7caced28c62f88f5045c3deaf8dfa4d4be1c803c"}, "closed": true, "closedAt": "2020-07-15T19:33:28Z", "author": {"login": "yuanrw"}, "timelineItems": {"totalCount": 33, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcf0i0pAH2gAyNDE1NjczOTU1OmFmNmQ5OTRhZjcwYmUyYTMzMmRmMjVkNzg2NWY2YTQxY2ExNzViNDU=", "endCursor": "Y3Vyc29yOnYyOpPPAAABc0vuPDgFqTQ0NzgxMTM5Mw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "af6d994af70be2a332df25d7865f6a41ca175b45", "author": {"user": {"login": "yuanrw", "name": "Ruwei"}}, "url": "https://github.com/netty/netty/commit/af6d994af70be2a332df25d7865f6a41ca175b45", "committedDate": "2020-05-10T05:50:50Z", "message": "Review PooledByteBufAllocator in respect of jemalloc 4.x changes and\nupdate allocate algorithm.\n\nMotivation:\n\nFor size from 512 bytes to chunkSize, we use a buddy algorithm. The\ndrawback is that it has a large internal fragmentation.\n\nModifications:\n\n1. add SizeClassesMetric and SizeClasses\n2. remove tiny size, now we have small, normal and huge size\n3. rewrite the structure of PoolChunk\n4. rewrite pooled allocate algorithm in PoolChunk\n5. when allocate subpage, using lowest common multiple of pageSize and\n   elemSize instead of pageSize.\n   6. add more tests in PooledByteBufAllocatorTest and PoolArenaTest\n\nResult:\nReduce internal fragmentation.\nClosed #3910\n\nupdate commit and details"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1352b43f65bd04c87ec8fc5440417576dda60e41", "author": {"user": {"login": "yuanrw", "name": "Ruwei"}}, "url": "https://github.com/netty/netty/commit/1352b43f65bd04c87ec8fc5440417576dda60e41", "committedDate": "2020-05-10T05:58:32Z", "message": "fix defaultMaxPages = 2560"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA4NzEwNzE4", "url": "https://github.com/netty/netty/pull/10267#pullrequestreview-408710718", "createdAt": "2020-05-10T06:25:59Z", "commit": {"oid": "1352b43f65bd04c87ec8fc5440417576dda60e41"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMFQwNjoyNTo1OVrOGTBH9Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMFQwNjoyNTo1OVrOGTBH9Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjU5NDU0OQ==", "bodyText": "Given that for the allocator the only version we need is using Long, although less reusable, why not using a long (unboxed) version instead?", "url": "https://github.com/netty/netty/pull/10267#discussion_r422594549", "createdAt": "2020-05-10T06:25:59Z", "author": {"login": "franz1981"}, "path": "common/src/main/java/io/netty/util/RedBlackTree.java", "diffHunk": "@@ -0,0 +1,525 @@\n+/*\n+ * Copyright 2013 The Netty Project\n+ *\n+ * The Netty Project licenses this file to you under the Apache License,\n+ * version 2.0 (the \"License\"); you may not use this file except in compliance\n+ * with the License. You may obtain a copy of the License at:\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package io.netty.util;\n+\n+import java.util.NoSuchElementException;\n+\n+public class RedBlackTree<Key extends Comparable<Key>> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1352b43f65bd04c87ec8fc5440417576dda60e41"}, "originalPosition": 20}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA4NzIyNzA5", "url": "https://github.com/netty/netty/pull/10267#pullrequestreview-408722709", "createdAt": "2020-05-10T08:49:36Z", "commit": {"oid": "1352b43f65bd04c87ec8fc5440417576dda60e41"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMFQwODo0OTozNlrOGTCNlA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMFQwODo0OTozNlrOGTCNlA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjYxMjM3Mg==", "bodyText": "Need to keep these public methods to maintain binary compatibility, implementations could return 0, empty collection etc. and mark them deprecated.", "url": "https://github.com/netty/netty/pull/10267#discussion_r422612372", "createdAt": "2020-05-10T08:49:36Z", "author": {"login": "johnou"}, "path": "buffer/src/main/java/io/netty/buffer/PoolArenaMetric.java", "diffHunk": "@@ -21,18 +21,13 @@\n /**\n  * Expose metrics for an arena.\n  */\n-public interface PoolArenaMetric {\n+public interface PoolArenaMetric extends SizeClassesMetric {\n \n     /**\n      * Returns the number of thread caches backed by this arena.\n      */\n     int numThreadCaches();\n \n-    /**\n-     * Returns the number of tiny sub-pages for the arena.\n-     */\n-    int numTinySubpages();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1352b43f65bd04c87ec8fc5440417576dda60e41"}, "originalPosition": 15}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA4NzIzMDQz", "url": "https://github.com/netty/netty/pull/10267#pullrequestreview-408723043", "createdAt": "2020-05-10T08:53:53Z", "commit": {"oid": "1352b43f65bd04c87ec8fc5440417576dda60e41"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMFQwODo1Mzo1M1rOGTCPjg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMFQwODo1Mzo1M1rOGTCPjg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjYxMjg3OA==", "bodyText": "Need to keep the old constructors and mark them deprecated.", "url": "https://github.com/netty/netty/pull/10267#discussion_r422612878", "createdAt": "2020-05-10T08:53:53Z", "author": {"login": "johnou"}, "path": "buffer/src/main/java/io/netty/buffer/PooledByteBufAllocator.java", "diffHunk": "@@ -208,43 +204,42 @@ public PooledByteBufAllocator(int nHeapArena, int nDirectArena, int pageSize, in\n \n     /**\n      * @deprecated use\n-     * {@link PooledByteBufAllocator#PooledByteBufAllocator(boolean, int, int, int, int, int, int, int, boolean)}\n+     * {@link PooledByteBufAllocator#PooledByteBufAllocator(boolean, int, int, int, int, int, int, boolean)}\n      */\n     @Deprecated\n-    public PooledByteBufAllocator(boolean preferDirect, int nHeapArena, int nDirectArena, int pageSize, int maxOrder) {\n-        this(preferDirect, nHeapArena, nDirectArena, pageSize, maxOrder,\n-                DEFAULT_TINY_CACHE_SIZE, DEFAULT_SMALL_CACHE_SIZE, DEFAULT_NORMAL_CACHE_SIZE);\n+    public PooledByteBufAllocator(boolean preferDirect, int nHeapArena, int nDirectArena, int pageSize, int maxPages) {\n+        this(preferDirect, nHeapArena, nDirectArena, pageSize, maxPages,\n+                DEFAULT_SMALL_CACHE_SIZE, DEFAULT_NORMAL_CACHE_SIZE);\n     }\n \n     /**\n      * @deprecated use\n-     * {@link PooledByteBufAllocator#PooledByteBufAllocator(boolean, int, int, int, int, int, int, int, boolean)}\n+     * {@link PooledByteBufAllocator#PooledByteBufAllocator(boolean, int, int, int, int, int, int, boolean)}\n      */\n     @Deprecated\n-    public PooledByteBufAllocator(boolean preferDirect, int nHeapArena, int nDirectArena, int pageSize, int maxOrder,\n-                                  int tinyCacheSize, int smallCacheSize, int normalCacheSize) {\n-        this(preferDirect, nHeapArena, nDirectArena, pageSize, maxOrder, tinyCacheSize, smallCacheSize,\n+    public PooledByteBufAllocator(boolean preferDirect, int nHeapArena, int nDirectArena, int pageSize, int maxPages,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1352b43f65bd04c87ec8fc5440417576dda60e41"}, "originalPosition": 105}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA5MTgzODc2", "url": "https://github.com/netty/netty/pull/10267#pullrequestreview-409183876", "createdAt": "2020-05-11T13:42:51Z", "commit": {"oid": "1352b43f65bd04c87ec8fc5440417576dda60e41"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 18, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMVQxMzo0Mjo1MlrOGTc1jA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMVQxMzo1ODo1OVrOGTdhrg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzA0ODU4OA==", "bodyText": "I wonder if we can use IntObjectMap here ?", "url": "https://github.com/netty/netty/pull/10267#discussion_r423048588", "createdAt": "2020-05-11T13:42:52Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/main/java/io/netty/buffer/PoolChunk.java", "diffHunk": "@@ -13,117 +13,161 @@\n  * License for the specific language governing permissions and limitations\n  * under the License.\n  */\n-\n package io.netty.buffer;\n \n+import io.netty.util.RedBlackTree;\n+\n import java.nio.ByteBuffer;\n import java.util.ArrayDeque;\n import java.util.Deque;\n+import java.util.HashMap;\n+import java.util.Map;\n \n /**\n  * Description of algorithm for PageRun/PoolSubpage allocation from PoolChunk\n  *\n  * Notation: The following terms are important to understand the code\n  * > page  - a page is the smallest unit of memory chunk that can be allocated\n- * > chunk - a chunk is a collection of pages\n- * > in this code chunkSize = 2^{maxOrder} * pageSize\n+ * > run   - a run is a collection of pages\n+ * > chunk - a chunk is a collection of runs\n+ * > in this code chunkSize = maxPages * pageSize\n  *\n  * To begin we allocate a byte array of size = chunkSize\n  * Whenever a ByteBuf of given size needs to be created we search for the first position\n  * in the byte array that has enough empty space to accommodate the requested size and\n  * return a (long) handle that encodes this offset information, (this memory segment is then\n  * marked as reserved so it is always used by exactly one ByteBuf and no more)\n  *\n- * For simplicity all sizes are normalized according to PoolArena#normalizeCapacity method\n- * This ensures that when we request for memory segments of size >= pageSize the normalizedCapacity\n- * equals the next nearest power of 2\n+ * For simplicity all sizes are normalized according to {@link PoolArena#size2SizeIdx(int)} method\n+ * This ensures that when we request for memory segments of size > pageSize the normalizedCapacity\n+ * equals the next nearest size in {@link SizeClasses}\n+ *\n+ *\n+ *  A chunk has the following layout:\n+ *\n+ *     /-----------------\\\n+ *     | run             |\n+ *     |                 |\n+ *     |                 |\n+ *     |-----------------|\n+ *     | run             |\n+ *     |                 |\n+ *     |-----------------|\n+ *     | unalloctated    |\n+ *     | (freed)         |\n+ *     |                 |\n+ *     |-----------------|\n+ *     | subpage         |\n+ *     |-----------------|\n+ *     | unallocated     |\n+ *     | (freed)         |\n+ *     | ...             |\n+ *     | ...             |\n+ *     | ...             |\n+ *     |                 |\n+ *     |                 |\n+ *     |                 |\n+ *     \\-----------------/\n  *\n- * To search for the first offset in chunk that has at least requested size available we construct a\n- * complete balanced binary tree and store it in an array (just like heaps) - memoryMap\n  *\n- * The tree looks like this (the size of each node being mentioned in the parenthesis)\n+ * handle:\n+ * -------\n+ * a handle is a long number, the bit layout of a run looks like:\n  *\n- * depth=0        1 node (chunkSize)\n- * depth=1        2 nodes (chunkSize/2)\n- * ..\n- * ..\n- * depth=d        2^d nodes (chunkSize/2^d)\n- * ..\n- * depth=maxOrder 2^maxOrder nodes (chunkSize/2^{maxOrder} = pageSize)\n+ * oooooooo ooooooos ssssssss ssssssue bbbbbbbb bbbbbbbb bbbbbbbb bbbbbbbb\n  *\n- * depth=maxOrder is the last level and the leafs consist of pages\n+ * o: runOffset (page offset in the chunk), 15bit\n+ * s: size (number of pages) of this run, 15bit\n+ * u: isUsed?, 1bit\n+ * e: isSubpage?, 1bit\n+ * b: bitmapIdx of subpage, zero if it's not subpage, 32bit\n+ *\n+ * runsAvailMap:\n+ * ------\n+ * a map which manages all runs (used and not in used)\n+ * For each run, the first runOffset and last runOffset are stored in runsAvailMap.\n+ * key: runOffset\n+ * value: handle\n+ *\n+ * runsAvail:\n+ * ----------\n+ * an array of {@link RedBlackTree}\n+ * Each tree manages same size of runs.\n+ * Runs are sorted by offset, so that we always allocate runs with smaller offset.\n  *\n- * With this tree available searching in chunkArray translates like this:\n- * To allocate a memory segment of size chunkSize/2^k we search for the first node (from left) at height k\n- * which is unused\n  *\n  * Algorithm:\n  * ----------\n- * Encode the tree in memoryMap with the notation\n- *   memoryMap[id] = x => in the subtree rooted at id, the first node that is free to be allocated\n- *   is at depth x (counted from depth=0) i.e., at depths [depth_of_id, x), there is no node that is free\n  *\n- *  As we allocate & free nodes, we update values stored in memoryMap so that the property is maintained\n+ *   As we allocate runs, we update values stored in runsAvailMap and runsAvail so that the property is maintained.\n  *\n  * Initialization -\n- *   In the beginning we construct the memoryMap array by storing the depth of a node at each node\n- *     i.e., memoryMap[id] = depth_of_id\n+ *  In the beginning we store the initial run which is the whole chunk.\n+ *  the initial run:\n+ *  runOffset = 0\n+ *  size = chunkSize\n+ *  isUsed = no\n+ *  isSubpage = no\n+ *  bitmapIdx = 0\n  *\n- * Observations:\n- * -------------\n- * 1) memoryMap[id] = depth_of_id  => it is free / unallocated\n- * 2) memoryMap[id] > depth_of_id  => at least one of its child nodes is allocated, so we cannot allocate it, but\n- *                                    some of its children can still be allocated based on their availability\n- * 3) memoryMap[id] = maxOrder + 1 => the node is fully allocated & thus none of its children can be allocated, it\n- *                                    is thus marked as unusable\n- *\n- * Algorithm: [allocateNode(d) => we want to find the first node (from left) at height h that can be allocated]\n- * ----------\n- * 1) start at root (i.e., depth = 0 or id = 1)\n- * 2) if memoryMap[1] > d => cannot be allocated from this chunk\n- * 3) if left node value <= h; we can allocate from left subtree so move to left and repeat until found\n- * 4) else try in right subtree\n  *\n  * Algorithm: [allocateRun(size)]\n  * ----------\n- * 1) Compute d = log_2(chunkSize/size)\n- * 2) Return allocateNode(d)\n+ * 1) find the first avail run using in runsAvails according to size\n+ * 2) if pages of run is larger than request pages then split it, and save the tailing run\n+ *    for later using\n  *\n  * Algorithm: [allocateSubpage(size)]\n  * ----------\n- * 1) use allocateNode(maxOrder) to find an empty (i.e., unused) leaf (i.e., page)\n- * 2) use this handle to construct the PoolSubpage object or if it already exists just call init(normCapacity)\n- *    note that this PoolSubpage object is added to subpagesPool in the PoolArena when we init() it\n+ * 1) find a not full subpage according to size.\n+ *    if it already exists just return, otherwise allocate a new PoolSubpage and call init()\n+ *    note that this subpage object is added to subpagesPool in the PoolArena when we init() it\n+ * 2) call subpage.allocate()\n  *\n- * Note:\n- * -----\n- * In the implementation for improving cache coherence,\n- * we store 2 pieces of information depth_of_id and x as two byte values in memoryMap and depthMap respectively\n+ * Algorithm: [free(handle, length, nioBuffer)]\n+ * ----------\n+ * 1) if it is a subpage, return the slab back into this subpage\n+ * 2) if the subpage is not used or it is a run, then start free this run\n+ * 3) merge continuous avail runs\n+ * 4) save the merged run\n  *\n- * memoryMap[id]= depth_of_id  is defined above\n- * depthMap[id]= x  indicates that the first node which is free to be allocated is at depth x (from root)\n  */\n final class PoolChunk<T> implements PoolChunkMetric {\n \n-    private static final int INTEGER_SIZE_MINUS_ONE = Integer.SIZE - 1;\n+    private static final int OFFSET_BIT_LENGTH = 15;\n+    private static final int SIZE_BIT_LENGTH = 15;\n+    private static final int INUSED_BIT_LENGTH = 1;\n+    private static final int SUBPAGE_BIT_LENGTH = 1;\n+    private static final int BITMAP_IDX_BIT_LENGTH = 32;\n+\n+    static final int ISSUBPAGE_SHIFT = BITMAP_IDX_BIT_LENGTH;\n+    static final int ISUSED_SHIFT = SUBPAGE_BIT_LENGTH + ISSUBPAGE_SHIFT;\n+    static final int SIZE_SHIFT = INUSED_BIT_LENGTH + ISUSED_SHIFT;\n+    static final int RUN_OFFSET_SHIFT = SIZE_BIT_LENGTH + SIZE_SHIFT;\n \n     final PoolArena<T> arena;\n     final T memory;\n     final boolean unpooled;\n     final int offset;\n-    private final byte[] memoryMap;\n-    private final byte[] depthMap;\n+\n+    /**\n+     * store the first page and last page of each avail run\n+     */\n+    private final Map<Integer, Long> runsAvailMap;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1352b43f65bd04c87ec8fc5440417576dda60e41"}, "originalPosition": 198}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzA0ODk4MA==", "bodyText": "static", "url": "https://github.com/netty/netty/pull/10267#discussion_r423048980", "createdAt": "2020-05-11T13:43:30Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/main/java/io/netty/buffer/PoolChunk.java", "diffHunk": "@@ -182,23 +214,58 @@\n         this.arena = arena;\n         this.memory = memory;\n         this.offset = offset;\n-        memoryMap = null;\n-        depthMap = null;\n-        subpages = null;\n-        subpageOverflowMask = 0;\n         pageSize = 0;\n         pageShifts = 0;\n-        maxOrder = 0;\n-        unusable = (byte) (maxOrder + 1);\n+        runsAvailMap = null;\n+        runsAvail = null;\n+        subpages = null;\n         chunkSize = size;\n-        log2ChunkSize = log2(chunkSize);\n-        maxSubpageAllocs = 0;\n         cachedNioBuffers = null;\n     }\n \n     @SuppressWarnings(\"unchecked\")\n-    private PoolSubpage<T>[] newSubpageArray(int size) {\n-        return new PoolSubpage[size];\n+    private RedBlackTree<Long>[] newRunsAvailTreeArray(int size) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1352b43f65bd04c87ec8fc5440417576dda60e41"}, "originalPosition": 296}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzA1MDA0Nw==", "bodyText": "please use one line per declaration as we do normally in netty", "url": "https://github.com/netty/netty/pull/10267#discussion_r423050047", "createdAt": "2020-05-11T13:45:05Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/main/java/io/netty/buffer/PoolChunk.java", "diffHunk": "@@ -222,256 +289,276 @@ private int usage(int freeBytes) {\n         return 100 - freePercentage;\n     }\n \n-    boolean allocate(PooledByteBuf<T> buf, int reqCapacity, int normCapacity, PoolThreadCache threadCache) {\n-        final long handle;\n-        if ((normCapacity & subpageOverflowMask) != 0) { // >= pageSize\n-            handle =  allocateRun(normCapacity);\n+    boolean allocate(PooledByteBuf<T> buf, int reqCapacity, int sizeIdx, PoolThreadCache cache) {\n+        long handle;\n+        if (sizeIdx <= arena.smallMaxSizeIdx) {\n+            // small\n+            handle = allocateSubpage(sizeIdx);\n+            assert isSubpage(handle);\n         } else {\n-            handle = allocateSubpage(normCapacity);\n+            // normal\n+            // runSize must be multiple of pageSize\n+            int runSize = arena.sizeIdx2size(sizeIdx);\n+            handle = allocateRun(runSize);\n         }\n \n         if (handle < 0) {\n             return false;\n         }\n-        ByteBuffer nioBuffer = cachedNioBuffers != null ? cachedNioBuffers.pollLast() : null;\n-        initBuf(buf, nioBuffer, handle, reqCapacity, threadCache);\n+\n+        ByteBuffer nioBuffer = cachedNioBuffers != null? cachedNioBuffers.pollLast() : null;\n+        initBuf(buf, nioBuffer, handle, reqCapacity, cache);\n         return true;\n     }\n \n-    /**\n-     * Update method used by allocate\n-     * This is triggered only when a successor is allocated and all its predecessors\n-     * need to update their state\n-     * The minimal depth at which subtree rooted at id has some free space\n-     *\n-     * @param id id\n-     */\n-    private void updateParentsAlloc(int id) {\n-        while (id > 1) {\n-            int parentId = id >>> 1;\n-            byte val1 = value(id);\n-            byte val2 = value(id ^ 1);\n-            byte val = val1 < val2 ? val1 : val2;\n-            setValue(parentId, val);\n-            id = parentId;\n+    private long allocateRun(int runSize) {\n+        int pages = runSize >> pageShifts;\n+        int pageIdx = arena.pages2pageIdx(pages);\n+\n+        synchronized (runsAvail) {\n+            //find first tree which has at least one big enough run\n+            int treeIdx = runFirstBestFit(pageIdx);\n+            if (treeIdx == -1) {\n+                return -1;\n+            }\n+\n+            //get run with min offset in this tree\n+            RedBlackTree<Long> tree = runsAvail[treeIdx];\n+            long handle = tree.min();\n+\n+            assert !isUsed(handle);\n+\n+            removeAvailRun(tree, handle);\n+\n+            if (handle != -1) {\n+                handle = splitLargeRun(handle, pages);\n+            }\n+\n+            freeBytes -= runSize(pageShifts, handle);\n+            return handle;\n         }\n     }\n \n-    /**\n-     * Update method used by free\n-     * This needs to handle the special case when both children are completely free\n-     * in which case parent be directly allocated on request of size = child-size * 2\n-     *\n-     * @param id id\n-     */\n-    private void updateParentsFree(int id) {\n-        int logChild = depth(id) + 1;\n-        while (id > 1) {\n-            int parentId = id >>> 1;\n-            byte val1 = value(id);\n-            byte val2 = value(id ^ 1);\n-            logChild -= 1; // in first iteration equals log, subsequently reduce 1 from logChild as we traverse up\n-\n-            if (val1 == logChild && val2 == logChild) {\n-                setValue(parentId, (byte) (logChild - 1));\n-            } else {\n-                byte val = val1 < val2 ? val1 : val2;\n-                setValue(parentId, val);\n+    private int calculateRunSize(int sizeIdx) {\n+        int maxElements = 1 << pageShifts - SizeClasses.LOG2_QUANTUM;\n+        int runSize = 0, nElements;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1352b43f65bd04c87ec8fc5440417576dda60e41"}, "originalPosition": 440}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzA1MDY5MQ==", "bodyText": "this could be merged in the while(...)", "url": "https://github.com/netty/netty/pull/10267#discussion_r423050691", "createdAt": "2020-05-11T13:46:00Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/main/java/io/netty/buffer/PoolChunk.java", "diffHunk": "@@ -222,256 +289,276 @@ private int usage(int freeBytes) {\n         return 100 - freePercentage;\n     }\n \n-    boolean allocate(PooledByteBuf<T> buf, int reqCapacity, int normCapacity, PoolThreadCache threadCache) {\n-        final long handle;\n-        if ((normCapacity & subpageOverflowMask) != 0) { // >= pageSize\n-            handle =  allocateRun(normCapacity);\n+    boolean allocate(PooledByteBuf<T> buf, int reqCapacity, int sizeIdx, PoolThreadCache cache) {\n+        long handle;\n+        if (sizeIdx <= arena.smallMaxSizeIdx) {\n+            // small\n+            handle = allocateSubpage(sizeIdx);\n+            assert isSubpage(handle);\n         } else {\n-            handle = allocateSubpage(normCapacity);\n+            // normal\n+            // runSize must be multiple of pageSize\n+            int runSize = arena.sizeIdx2size(sizeIdx);\n+            handle = allocateRun(runSize);\n         }\n \n         if (handle < 0) {\n             return false;\n         }\n-        ByteBuffer nioBuffer = cachedNioBuffers != null ? cachedNioBuffers.pollLast() : null;\n-        initBuf(buf, nioBuffer, handle, reqCapacity, threadCache);\n+\n+        ByteBuffer nioBuffer = cachedNioBuffers != null? cachedNioBuffers.pollLast() : null;\n+        initBuf(buf, nioBuffer, handle, reqCapacity, cache);\n         return true;\n     }\n \n-    /**\n-     * Update method used by allocate\n-     * This is triggered only when a successor is allocated and all its predecessors\n-     * need to update their state\n-     * The minimal depth at which subtree rooted at id has some free space\n-     *\n-     * @param id id\n-     */\n-    private void updateParentsAlloc(int id) {\n-        while (id > 1) {\n-            int parentId = id >>> 1;\n-            byte val1 = value(id);\n-            byte val2 = value(id ^ 1);\n-            byte val = val1 < val2 ? val1 : val2;\n-            setValue(parentId, val);\n-            id = parentId;\n+    private long allocateRun(int runSize) {\n+        int pages = runSize >> pageShifts;\n+        int pageIdx = arena.pages2pageIdx(pages);\n+\n+        synchronized (runsAvail) {\n+            //find first tree which has at least one big enough run\n+            int treeIdx = runFirstBestFit(pageIdx);\n+            if (treeIdx == -1) {\n+                return -1;\n+            }\n+\n+            //get run with min offset in this tree\n+            RedBlackTree<Long> tree = runsAvail[treeIdx];\n+            long handle = tree.min();\n+\n+            assert !isUsed(handle);\n+\n+            removeAvailRun(tree, handle);\n+\n+            if (handle != -1) {\n+                handle = splitLargeRun(handle, pages);\n+            }\n+\n+            freeBytes -= runSize(pageShifts, handle);\n+            return handle;\n         }\n     }\n \n-    /**\n-     * Update method used by free\n-     * This needs to handle the special case when both children are completely free\n-     * in which case parent be directly allocated on request of size = child-size * 2\n-     *\n-     * @param id id\n-     */\n-    private void updateParentsFree(int id) {\n-        int logChild = depth(id) + 1;\n-        while (id > 1) {\n-            int parentId = id >>> 1;\n-            byte val1 = value(id);\n-            byte val2 = value(id ^ 1);\n-            logChild -= 1; // in first iteration equals log, subsequently reduce 1 from logChild as we traverse up\n-\n-            if (val1 == logChild && val2 == logChild) {\n-                setValue(parentId, (byte) (logChild - 1));\n-            } else {\n-                byte val = val1 < val2 ? val1 : val2;\n-                setValue(parentId, val);\n+    private int calculateRunSize(int sizeIdx) {\n+        int maxElements = 1 << pageShifts - SizeClasses.LOG2_QUANTUM;\n+        int runSize = 0, nElements;\n+\n+        final int elemSize = arena.sizeIdx2size(sizeIdx);\n+\n+        //find lowest common multiple of pageSize and elemSize\n+        do {\n+            runSize += pageSize;\n+            nElements = runSize / elemSize;\n+\n+            if (nElements >= maxElements) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1352b43f65bd04c87ec8fc5440417576dda60e41"}, "originalPosition": 449}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzA1Mzc2NQ==", "bodyText": "2020", "url": "https://github.com/netty/netty/pull/10267#discussion_r423053765", "createdAt": "2020-05-11T13:50:28Z", "author": {"login": "normanmaurer"}, "path": "common/src/main/java/io/netty/util/RedBlackTree.java", "diffHunk": "@@ -0,0 +1,525 @@\n+/*\n+ * Copyright 2013 The Netty Project", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1352b43f65bd04c87ec8fc5440417576dda60e41"}, "originalPosition": 2}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzA1NDM3Nw==", "bodyText": "I would prefer to keep this in the buffer package as internal class for now or move this to the internal package. People should not depend on it as otherwise we will need to sign up to not break the API etc", "url": "https://github.com/netty/netty/pull/10267#discussion_r423054377", "createdAt": "2020-05-11T13:51:18Z", "author": {"login": "normanmaurer"}, "path": "common/src/main/java/io/netty/util/RedBlackTree.java", "diffHunk": "@@ -0,0 +1,525 @@\n+/*\n+ * Copyright 2013 The Netty Project\n+ *\n+ * The Netty Project licenses this file to you under the Apache License,\n+ * version 2.0 (the \"License\"); you may not use this file except in compliance\n+ * with the License. You may obtain a copy of the License at:\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package io.netty.util;\n+\n+import java.util.NoSuchElementException;\n+\n+public class RedBlackTree<Key extends Comparable<Key>> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1352b43f65bd04c87ec8fc5440417576dda60e41"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzA1NDg2Mg==", "bodyText": "you could also use an enum just to make it \"cleaner\"", "url": "https://github.com/netty/netty/pull/10267#discussion_r423054862", "createdAt": "2020-05-11T13:51:59Z", "author": {"login": "normanmaurer"}, "path": "common/src/main/java/io/netty/util/RedBlackTree.java", "diffHunk": "@@ -0,0 +1,525 @@\n+/*\n+ * Copyright 2013 The Netty Project\n+ *\n+ * The Netty Project licenses this file to you under the Apache License,\n+ * version 2.0 (the \"License\"); you may not use this file except in compliance\n+ * with the License. You may obtain a copy of the License at:\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package io.netty.util;\n+\n+import java.util.NoSuchElementException;\n+\n+public class RedBlackTree<Key extends Comparable<Key>> {\n+\n+    private static final boolean RED = true;\n+    private static final boolean BLACK = false;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1352b43f65bd04c87ec8fc5440417576dda60e41"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzA1NTIxOQ==", "bodyText": "nit: merge the branches...", "url": "https://github.com/netty/netty/pull/10267#discussion_r423055219", "createdAt": "2020-05-11T13:52:29Z", "author": {"login": "normanmaurer"}, "path": "common/src/main/java/io/netty/util/RedBlackTree.java", "diffHunk": "@@ -0,0 +1,525 @@\n+/*\n+ * Copyright 2013 The Netty Project\n+ *\n+ * The Netty Project licenses this file to you under the Apache License,\n+ * version 2.0 (the \"License\"); you may not use this file except in compliance\n+ * with the License. You may obtain a copy of the License at:\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package io.netty.util;\n+\n+import java.util.NoSuchElementException;\n+\n+public class RedBlackTree<Key extends Comparable<Key>> {\n+\n+    private static final boolean RED = true;\n+    private static final boolean BLACK = false;\n+\n+    private Node root;\n+\n+    private final class Node {\n+        private Key key;\n+        private Node left, right;\n+        private boolean color;\n+        private int size;\n+\n+        private Node(Key key, boolean color, int size) {\n+            this.key = key;\n+            this.color = color;\n+            this.size = size;\n+        }\n+    }\n+\n+    // is node x red; false if x is null ?\n+    private boolean isRed(Node x) {\n+        if (x == null) {\n+            return false;\n+        }\n+        return x.color == RED;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1352b43f65bd04c87ec8fc5440417576dda60e41"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzA1NTI4MA==", "bodyText": "nit: merge the branches...", "url": "https://github.com/netty/netty/pull/10267#discussion_r423055280", "createdAt": "2020-05-11T13:52:33Z", "author": {"login": "normanmaurer"}, "path": "common/src/main/java/io/netty/util/RedBlackTree.java", "diffHunk": "@@ -0,0 +1,525 @@\n+/*\n+ * Copyright 2013 The Netty Project\n+ *\n+ * The Netty Project licenses this file to you under the Apache License,\n+ * version 2.0 (the \"License\"); you may not use this file except in compliance\n+ * with the License. You may obtain a copy of the License at:\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package io.netty.util;\n+\n+import java.util.NoSuchElementException;\n+\n+public class RedBlackTree<Key extends Comparable<Key>> {\n+\n+    private static final boolean RED = true;\n+    private static final boolean BLACK = false;\n+\n+    private Node root;\n+\n+    private final class Node {\n+        private Key key;\n+        private Node left, right;\n+        private boolean color;\n+        private int size;\n+\n+        private Node(Key key, boolean color, int size) {\n+            this.key = key;\n+            this.color = color;\n+            this.size = size;\n+        }\n+    }\n+\n+    // is node x red; false if x is null ?\n+    private boolean isRed(Node x) {\n+        if (x == null) {\n+            return false;\n+        }\n+        return x.color == RED;\n+    }\n+\n+    // number of node in subtree rooted at x; 0 if x is null\n+    private int size(Node x) {\n+        if (x == null) {\n+            return 0;\n+        }\n+        return x.size;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1352b43f65bd04c87ec8fc5440417576dda60e41"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzA1NTQzNg==", "bodyText": "static", "url": "https://github.com/netty/netty/pull/10267#discussion_r423055436", "createdAt": "2020-05-11T13:52:45Z", "author": {"login": "normanmaurer"}, "path": "common/src/main/java/io/netty/util/RedBlackTree.java", "diffHunk": "@@ -0,0 +1,525 @@\n+/*\n+ * Copyright 2013 The Netty Project\n+ *\n+ * The Netty Project licenses this file to you under the Apache License,\n+ * version 2.0 (the \"License\"); you may not use this file except in compliance\n+ * with the License. You may obtain a copy of the License at:\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package io.netty.util;\n+\n+import java.util.NoSuchElementException;\n+\n+public class RedBlackTree<Key extends Comparable<Key>> {\n+\n+    private static final boolean RED = true;\n+    private static final boolean BLACK = false;\n+\n+    private Node root;\n+\n+    private final class Node {\n+        private Key key;\n+        private Node left, right;\n+        private boolean color;\n+        private int size;\n+\n+        private Node(Key key, boolean color, int size) {\n+            this.key = key;\n+            this.color = color;\n+            this.size = size;\n+        }\n+    }\n+\n+    // is node x red; false if x is null ?\n+    private boolean isRed(Node x) {\n+        if (x == null) {\n+            return false;\n+        }\n+        return x.color == RED;\n+    }\n+\n+    // number of node in subtree rooted at x; 0 if x is null\n+    private int size(Node x) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1352b43f65bd04c87ec8fc5440417576dda60e41"}, "originalPosition": 49}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzA1NTUyMQ==", "bodyText": "static", "url": "https://github.com/netty/netty/pull/10267#discussion_r423055521", "createdAt": "2020-05-11T13:52:52Z", "author": {"login": "normanmaurer"}, "path": "common/src/main/java/io/netty/util/RedBlackTree.java", "diffHunk": "@@ -0,0 +1,525 @@\n+/*\n+ * Copyright 2013 The Netty Project\n+ *\n+ * The Netty Project licenses this file to you under the Apache License,\n+ * version 2.0 (the \"License\"); you may not use this file except in compliance\n+ * with the License. You may obtain a copy of the License at:\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package io.netty.util;\n+\n+import java.util.NoSuchElementException;\n+\n+public class RedBlackTree<Key extends Comparable<Key>> {\n+\n+    private static final boolean RED = true;\n+    private static final boolean BLACK = false;\n+\n+    private Node root;\n+\n+    private final class Node {\n+        private Key key;\n+        private Node left, right;\n+        private boolean color;\n+        private int size;\n+\n+        private Node(Key key, boolean color, int size) {\n+            this.key = key;\n+            this.color = color;\n+            this.size = size;\n+        }\n+    }\n+\n+    // is node x red; false if x is null ?\n+    private boolean isRed(Node x) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1352b43f65bd04c87ec8fc5440417576dda60e41"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzA1NjQzMQ==", "bodyText": "nit: remove", "url": "https://github.com/netty/netty/pull/10267#discussion_r423056431", "createdAt": "2020-05-11T13:54:16Z", "author": {"login": "normanmaurer"}, "path": "common/src/main/java/io/netty/util/RedBlackTree.java", "diffHunk": "@@ -0,0 +1,525 @@\n+/*\n+ * Copyright 2013 The Netty Project\n+ *\n+ * The Netty Project licenses this file to you under the Apache License,\n+ * version 2.0 (the \"License\"); you may not use this file except in compliance\n+ * with the License. You may obtain a copy of the License at:\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package io.netty.util;\n+\n+import java.util.NoSuchElementException;\n+\n+public class RedBlackTree<Key extends Comparable<Key>> {\n+\n+    private static final boolean RED = true;\n+    private static final boolean BLACK = false;\n+\n+    private Node root;\n+\n+    private final class Node {\n+        private Key key;\n+        private Node left, right;\n+        private boolean color;\n+        private int size;\n+\n+        private Node(Key key, boolean color, int size) {\n+            this.key = key;\n+            this.color = color;\n+            this.size = size;\n+        }\n+    }\n+\n+    // is node x red; false if x is null ?\n+    private boolean isRed(Node x) {\n+        if (x == null) {\n+            return false;\n+        }\n+        return x.color == RED;\n+    }\n+\n+    // number of node in subtree rooted at x; 0 if x is null\n+    private int size(Node x) {\n+        if (x == null) {\n+            return 0;\n+        }\n+        return x.size;\n+    }\n+\n+    /**\n+     * Returns the number of keys in this tree.\n+     *\n+     * @return the number of keys in this tree\n+     */\n+    public int size() {\n+        return size(root);\n+    }\n+\n+    /**\n+     * Is this tree empty?\n+     *\n+     * @return {@code true} if this tree is empty and {@code false} otherwise\n+     */\n+    public boolean isEmpty() {\n+        return root == null;\n+    }\n+\n+    /**\n+     * Returns the value associated with the given key.\n+     *\n+     * @param key the key\n+     *\n+     * @return the value associated with the given key if the key is in the tree and {@code null} if the key is not in\n+     * the tree\n+     *\n+     * @throws IllegalArgumentException if {@code key} is {@code null}\n+     */\n+    private Key get(Key key) {\n+        if (key == null) {\n+            throw new IllegalArgumentException(\"argument to get() is null\");\n+        }\n+        return get(root, key);\n+    }\n+\n+    private Key get(Node x, Key key) {\n+        while (x != null) {\n+            int cmp = key.compareTo(x.key);\n+            if (cmp < 0) {\n+                x = x.left;\n+            } else if (cmp > 0) {\n+                x = x.right;\n+            } else {\n+                return x.key;\n+            }\n+        }\n+        return null;\n+    }\n+\n+    /**\n+     * Does this tree contain the given key?\n+     *\n+     * @param key the key\n+     *\n+     * @return {@code true} if this tree contains {@code key} and {@code false} otherwise\n+     *\n+     * @throws IllegalArgumentException if {@code key} is {@code null}\n+     */\n+    public boolean contains(Key key) {\n+        return get(key) != null;\n+    }\n+\n+    /**\n+     * Inserts the specified key into the tree, overwriting the old value with the new value if the tree already\n+     * contains the specified key. Deletes the specified key (and its associated value) from this tree if the specified\n+     * value is {@code null}.\n+     *\n+     * @param key the key\n+     *\n+     * @throws IllegalArgumentException if {@code key} is {@code null}\n+     */\n+    public void put(Key key) {\n+        if (key == null) {\n+            throw new IllegalArgumentException(\"first argument to put() is null\");\n+        }\n+\n+        root = put(root, key);\n+        root.color = BLACK;\n+        // assert check();\n+    }\n+\n+    // insert the key in the subtree rooted at h\n+    private Node put(Node h, Key key) {\n+        if (h == null) {\n+            return new Node(key, RED, 1);\n+        }\n+\n+        int cmp = key.compareTo(h.key);\n+        if (cmp < 0) {\n+            h.left = put(h.left, key);\n+        } else if (cmp > 0) {\n+            h.right = put(h.right, key);\n+        } else {\n+            throw new IllegalArgumentException(\"same key is not allowed\");\n+        }\n+\n+        // fix-up any right-leaning links\n+        if (isRed(h.right) && !isRed(h.left)) {\n+            h = rotateLeft(h);\n+        }\n+        return fixup(h);\n+    }\n+\n+    /**\n+     * Removes the smallest key and associated value from the tree.\n+     *\n+     * @throws NoSuchElementException if the tree is empty\n+     */\n+    public void deleteMin() {\n+        if (isEmpty()) {\n+            throw new NoSuchElementException(\"BST underflow\");\n+        }\n+\n+        // if both children of root are black, set root to red\n+        if (!isRed(root.left) && !isRed(root.right)) {\n+            root.color = RED;\n+        }\n+\n+        root = deleteMin(root);\n+        if (!isEmpty()) {\n+            root.color = BLACK;\n+        }\n+        // assert check();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1352b43f65bd04c87ec8fc5440417576dda60e41"}, "originalPosition": 178}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzA1NzUyNA==", "bodyText": "This class should have its own tests.", "url": "https://github.com/netty/netty/pull/10267#discussion_r423057524", "createdAt": "2020-05-11T13:55:39Z", "author": {"login": "normanmaurer"}, "path": "common/src/main/java/io/netty/util/RedBlackTree.java", "diffHunk": "@@ -0,0 +1,525 @@\n+/*\n+ * Copyright 2013 The Netty Project\n+ *\n+ * The Netty Project licenses this file to you under the Apache License,\n+ * version 2.0 (the \"License\"); you may not use this file except in compliance\n+ * with the License. You may obtain a copy of the License at:\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package io.netty.util;\n+\n+import java.util.NoSuchElementException;\n+\n+public class RedBlackTree<Key extends Comparable<Key>> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1352b43f65bd04c87ec8fc5440417576dda60e41"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzA1ODAwMA==", "bodyText": "nit: rename method as now we not only release but also assert the content", "url": "https://github.com/netty/netty/pull/10267#discussion_r423058000", "createdAt": "2020-05-11T13:56:17Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/test/java/io/netty/buffer/PooledByteBufAllocatorTest.java", "diffHunk": "@@ -525,12 +601,14 @@ public void run() {\n         }\n \n         private void releaseBuffers() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1352b43f65bd04c87ec8fc5440417576dda60e41"}, "originalPosition": 228}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzA1OTIyMA==", "bodyText": "2020", "url": "https://github.com/netty/netty/pull/10267#discussion_r423059220", "createdAt": "2020-05-11T13:58:01Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/main/java/io/netty/buffer/SizeClasses.java", "diffHunk": "@@ -0,0 +1,401 @@\n+/*\n+ * Copyright 2012 The Netty Project", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1352b43f65bd04c87ec8fc5440417576dda60e41"}, "originalPosition": 2}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzA1OTMyMw==", "bodyText": "<p>", "url": "https://github.com/netty/netty/pull/10267#discussion_r423059323", "createdAt": "2020-05-11T13:58:10Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/main/java/io/netty/buffer/SizeClasses.java", "diffHunk": "@@ -0,0 +1,401 @@\n+/*\n+ * Copyright 2012 The Netty Project\n+ *\n+ * The Netty Project licenses this file to you under the Apache License,\n+ * version 2.0 (the \"License\"); you may not use this file except in compliance\n+ * with the License. You may obtain a copy of the License at:\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package io.netty.buffer;\n+\n+import static io.netty.buffer.PoolThreadCache.*;\n+\n+/**\n+ * SizeClasses requires {@code pageShifts} to be defined prior to inclusion,\n+ * and it in turn defines:\n+ *", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1352b43f65bd04c87ec8fc5440417576dda60e41"}, "originalPosition": 23}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzA1OTQxMA==", "bodyText": "</p>", "url": "https://github.com/netty/netty/pull/10267#discussion_r423059410", "createdAt": "2020-05-11T13:58:18Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/main/java/io/netty/buffer/SizeClasses.java", "diffHunk": "@@ -0,0 +1,401 @@\n+/*\n+ * Copyright 2012 The Netty Project\n+ *\n+ * The Netty Project licenses this file to you under the Apache License,\n+ * version 2.0 (the \"License\"); you may not use this file except in compliance\n+ * with the License. You may obtain a copy of the License at:\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package io.netty.buffer;\n+\n+import static io.netty.buffer.PoolThreadCache.*;\n+\n+/**\n+ * SizeClasses requires {@code pageShifts} to be defined prior to inclusion,\n+ * and it in turn defines:\n+ *\n+ *   LOG2_SIZE_CLASS_GROUP: Log of size class count for each size doubling.\n+ *   LOG2_MAX_LOOKUP_SIZE: Log of max size class in the lookup table.\n+ *   sizeClasses: Complete table of [index, log2Group, log2Delta, nDelta, isMultiPageSize,\n+ *                 isSubPage, log2DeltaLookup] tuples.\n+ *     index: Size class index.\n+ *     log2Group: Log of group base size (no deltas added).\n+ *     log2Delta: Log of delta to previous size class.\n+ *     nDelta: Delta multiplier.\n+ *     isMultiPageSize: 'yes' if a multiple of the page size, 'no' otherwise.\n+ *     isSubPage: 'yes' if a subpage size class, 'no' otherwise.\n+ *     log2DeltaLookup: Same as log2Delta if a lookup table size class, 'no'\n+ *                      otherwise.\n+ *\n+ *   nSubpages: Number of subpages size classes.\n+ *   nSizes: Number of size classes.\n+ *   nPSizes: Number of size classes that are multiples of pageSize.\n+ *\n+ *   smallMaxSizeIdx: Maximum small size class index.\n+ *\n+ *   lookupMaxclass: Maximum size class included in lookup table.\n+ *   log2NormalMinClass: Log of minimum normal size class.\n+ *\n+ *\n+ *   The first size class and spacing are 1 << LOG2_QUANTUM.\n+ *   Each group has 1 << LOG2_SIZE_CLASS_GROUP of size classes.\n+ *\n+ *   size = 1 << log2Group + nDelta * (1 << log2Delta)\n+ *\n+ *   The first size class has an unusual encoding, because the size has to be\n+ *   split between group and delta*nDelta.\n+ *\n+ *   If pageShift = 13, sizeClasses looks like this:\n+ *\n+ *   (index, log2Group, log2Delta, nDelta, isMultiPageSize, isSubPage, log2DeltaLookup)\n+ *\n+ *   ( 0,     4,        4,         0,       no,             yes,        4)\n+ *   ( 1,     4,        4,         1,       no,             yes,        4)\n+ *   ( 2,     4,        4,         2,       no,             yes,        4)\n+ *   ( 3,     4,        4,         3,       no,             yes,        4)\n+ *\n+ *   ( 4,     6,        4,         1,       no,             yes,        4)\n+ *   ( 5,     6,        4,         2,       no,             yes,        4)\n+ *   ( 6,     6,        4,         3,       no,             yes,        4)\n+ *   ( 7,     6,        4,         4,       no,             yes,        4)\n+ *\n+ *   ( 8,     7,        5,         1,       no,             yes,        5)\n+ *   ( 9,     7,        5,         2,       no,             yes,        5)\n+ *   ( 10,    7,        5,         3,       no,             yes,        5)\n+ *   ( 11,    7,        5,         4,       no,             yes,        5)\n+ *\n+ *   ...\n+ *   ...\n+ *\n+ *   ( 72,    23,       21,        1,       yes,            no,        no)\n+ *   ( 73,    23,       21,        2,       yes,            no,        no)\n+ *   ( 74,    23,       21,        3,       yes,            no,        no)\n+ *   ( 75,    23,       21,        4,       yes,            no,        no)\n+ *\n+ *   ( 76,    24,       22,        1,       yes,            no,        no)\n+ *", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1352b43f65bd04c87ec8fc5440417576dda60e41"}, "originalPosition": 83}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzA1OTg4Ng==", "bodyText": "+1... we cant break api", "url": "https://github.com/netty/netty/pull/10267#discussion_r423059886", "createdAt": "2020-05-11T13:58:59Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/main/java/io/netty/buffer/PooledByteBufAllocator.java", "diffHunk": "@@ -208,43 +204,42 @@ public PooledByteBufAllocator(int nHeapArena, int nDirectArena, int pageSize, in\n \n     /**\n      * @deprecated use\n-     * {@link PooledByteBufAllocator#PooledByteBufAllocator(boolean, int, int, int, int, int, int, int, boolean)}\n+     * {@link PooledByteBufAllocator#PooledByteBufAllocator(boolean, int, int, int, int, int, int, boolean)}\n      */\n     @Deprecated\n-    public PooledByteBufAllocator(boolean preferDirect, int nHeapArena, int nDirectArena, int pageSize, int maxOrder) {\n-        this(preferDirect, nHeapArena, nDirectArena, pageSize, maxOrder,\n-                DEFAULT_TINY_CACHE_SIZE, DEFAULT_SMALL_CACHE_SIZE, DEFAULT_NORMAL_CACHE_SIZE);\n+    public PooledByteBufAllocator(boolean preferDirect, int nHeapArena, int nDirectArena, int pageSize, int maxPages) {\n+        this(preferDirect, nHeapArena, nDirectArena, pageSize, maxPages,\n+                DEFAULT_SMALL_CACHE_SIZE, DEFAULT_NORMAL_CACHE_SIZE);\n     }\n \n     /**\n      * @deprecated use\n-     * {@link PooledByteBufAllocator#PooledByteBufAllocator(boolean, int, int, int, int, int, int, int, boolean)}\n+     * {@link PooledByteBufAllocator#PooledByteBufAllocator(boolean, int, int, int, int, int, int, boolean)}\n      */\n     @Deprecated\n-    public PooledByteBufAllocator(boolean preferDirect, int nHeapArena, int nDirectArena, int pageSize, int maxOrder,\n-                                  int tinyCacheSize, int smallCacheSize, int normalCacheSize) {\n-        this(preferDirect, nHeapArena, nDirectArena, pageSize, maxOrder, tinyCacheSize, smallCacheSize,\n+    public PooledByteBufAllocator(boolean preferDirect, int nHeapArena, int nDirectArena, int pageSize, int maxPages,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjYxMjg3OA=="}, "originalCommit": {"oid": "1352b43f65bd04c87ec8fc5440417576dda60e41"}, "originalPosition": 105}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA5MjU4OTk1", "url": "https://github.com/netty/netty/pull/10267#pullrequestreview-409258995", "createdAt": "2020-05-11T15:03:07Z", "commit": {"oid": "1352b43f65bd04c87ec8fc5440417576dda60e41"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMVQxNTowMzowN1rOGTgV-g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMVQxNTowMzowN1rOGTgV-g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzEwNjA0Mg==", "bodyText": "We could use ObjectUtil.checkPositive(...) to do this check here...", "url": "https://github.com/netty/netty/pull/10267#discussion_r423106042", "createdAt": "2020-05-11T15:03:07Z", "author": {"login": "seedeed"}, "path": "buffer/src/main/java/io/netty/buffer/PooledByteBufAllocator.java", "diffHunk": "@@ -312,19 +307,19 @@ private static int validateAndCalculatePageShifts(int pageSize) {\n         return Integer.SIZE - 1 - Integer.numberOfLeadingZeros(pageSize);\n     }\n \n-    private static int validateAndCalculateChunkSize(int pageSize, int maxOrder) {\n-        if (maxOrder > 14) {\n-            throw new IllegalArgumentException(\"maxOrder: \" + maxOrder + \" (expected: 0-14)\");\n+    private static int validateAndCalculateChunkSize(int pageSize, int maxPages) {\n+        if (maxPages <= 0) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1352b43f65bd04c87ec8fc5440417576dda60e41"}, "originalPosition": 165}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA5MjYxNTAx", "url": "https://github.com/netty/netty/pull/10267#pullrequestreview-409261501", "createdAt": "2020-05-11T15:05:47Z", "commit": {"oid": "1352b43f65bd04c87ec8fc5440417576dda60e41"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMVQxNTowNTo0N1rOGTgdjg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMVQxNTowNTo0N1rOGTgdjg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzEwNzk4Mg==", "bodyText": "2020", "url": "https://github.com/netty/netty/pull/10267#discussion_r423107982", "createdAt": "2020-05-11T15:05:47Z", "author": {"login": "seedeed"}, "path": "buffer/src/main/java/io/netty/buffer/SizeClassesMetric.java", "diffHunk": "@@ -0,0 +1,87 @@\n+/*\n+ * Copyright 2012 The Netty Project", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1352b43f65bd04c87ec8fc5440417576dda60e41"}, "originalPosition": 2}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA5MjczMzM1", "url": "https://github.com/netty/netty/pull/10267#pullrequestreview-409273335", "createdAt": "2020-05-11T15:18:33Z", "commit": {"oid": "1352b43f65bd04c87ec8fc5440417576dda60e41"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMVQxNToxODozM1rOGThBFA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMVQxNToxODozM1rOGThBFA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzExNzA3Ng==", "bodyText": "nit: I think this could be removed...", "url": "https://github.com/netty/netty/pull/10267#discussion_r423117076", "createdAt": "2020-05-11T15:18:33Z", "author": {"login": "seedeed"}, "path": "common/src/main/java/io/netty/util/RedBlackTree.java", "diffHunk": "@@ -0,0 +1,525 @@\n+/*\n+ * Copyright 2013 The Netty Project\n+ *\n+ * The Netty Project licenses this file to you under the Apache License,\n+ * version 2.0 (the \"License\"); you may not use this file except in compliance\n+ * with the License. You may obtain a copy of the License at:\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package io.netty.util;\n+\n+import java.util.NoSuchElementException;\n+\n+public class RedBlackTree<Key extends Comparable<Key>> {\n+\n+    private static final boolean RED = true;\n+    private static final boolean BLACK = false;\n+\n+    private Node root;\n+\n+    private final class Node {\n+        private Key key;\n+        private Node left, right;\n+        private boolean color;\n+        private int size;\n+\n+        private Node(Key key, boolean color, int size) {\n+            this.key = key;\n+            this.color = color;\n+            this.size = size;\n+        }\n+    }\n+\n+    // is node x red; false if x is null ?\n+    private boolean isRed(Node x) {\n+        if (x == null) {\n+            return false;\n+        }\n+        return x.color == RED;\n+    }\n+\n+    // number of node in subtree rooted at x; 0 if x is null\n+    private int size(Node x) {\n+        if (x == null) {\n+            return 0;\n+        }\n+        return x.size;\n+    }\n+\n+    /**\n+     * Returns the number of keys in this tree.\n+     *\n+     * @return the number of keys in this tree\n+     */\n+    public int size() {\n+        return size(root);\n+    }\n+\n+    /**\n+     * Is this tree empty?\n+     *\n+     * @return {@code true} if this tree is empty and {@code false} otherwise\n+     */\n+    public boolean isEmpty() {\n+        return root == null;\n+    }\n+\n+    /**\n+     * Returns the value associated with the given key.\n+     *\n+     * @param key the key\n+     *\n+     * @return the value associated with the given key if the key is in the tree and {@code null} if the key is not in\n+     * the tree\n+     *\n+     * @throws IllegalArgumentException if {@code key} is {@code null}\n+     */\n+    private Key get(Key key) {\n+        if (key == null) {\n+            throw new IllegalArgumentException(\"argument to get() is null\");\n+        }\n+        return get(root, key);\n+    }\n+\n+    private Key get(Node x, Key key) {\n+        while (x != null) {\n+            int cmp = key.compareTo(x.key);\n+            if (cmp < 0) {\n+                x = x.left;\n+            } else if (cmp > 0) {\n+                x = x.right;\n+            } else {\n+                return x.key;\n+            }\n+        }\n+        return null;\n+    }\n+\n+    /**\n+     * Does this tree contain the given key?\n+     *\n+     * @param key the key\n+     *\n+     * @return {@code true} if this tree contains {@code key} and {@code false} otherwise\n+     *\n+     * @throws IllegalArgumentException if {@code key} is {@code null}\n+     */\n+    public boolean contains(Key key) {\n+        return get(key) != null;\n+    }\n+\n+    /**\n+     * Inserts the specified key into the tree, overwriting the old value with the new value if the tree already\n+     * contains the specified key. Deletes the specified key (and its associated value) from this tree if the specified\n+     * value is {@code null}.\n+     *\n+     * @param key the key\n+     *\n+     * @throws IllegalArgumentException if {@code key} is {@code null}\n+     */\n+    public void put(Key key) {\n+        if (key == null) {\n+            throw new IllegalArgumentException(\"first argument to put() is null\");\n+        }\n+\n+        root = put(root, key);\n+        root.color = BLACK;\n+        // assert check();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1352b43f65bd04c87ec8fc5440417576dda60e41"}, "originalPosition": 134}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA5Mjg1NDQy", "url": "https://github.com/netty/netty/pull/10267#pullrequestreview-409285442", "createdAt": "2020-05-11T15:31:25Z", "commit": {"oid": "1352b43f65bd04c87ec8fc5440417576dda60e41"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMVQxNTozMToyNVrOGThlMA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMVQxNTozMToyNVrOGThlMA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzEyNjMyMA==", "bodyText": "I think this inner class could be marked as static...", "url": "https://github.com/netty/netty/pull/10267#discussion_r423126320", "createdAt": "2020-05-11T15:31:25Z", "author": {"login": "seedeed"}, "path": "common/src/main/java/io/netty/util/RedBlackTree.java", "diffHunk": "@@ -0,0 +1,525 @@\n+/*\n+ * Copyright 2013 The Netty Project\n+ *\n+ * The Netty Project licenses this file to you under the Apache License,\n+ * version 2.0 (the \"License\"); you may not use this file except in compliance\n+ * with the License. You may obtain a copy of the License at:\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package io.netty.util;\n+\n+import java.util.NoSuchElementException;\n+\n+public class RedBlackTree<Key extends Comparable<Key>> {\n+\n+    private static final boolean RED = true;\n+    private static final boolean BLACK = false;\n+\n+    private Node root;\n+\n+    private final class Node {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1352b43f65bd04c87ec8fc5440417576dda60e41"}, "originalPosition": 27}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA5MzE2MDA0", "url": "https://github.com/netty/netty/pull/10267#pullrequestreview-409316004", "createdAt": "2020-05-11T16:06:24Z", "commit": {"oid": "1352b43f65bd04c87ec8fc5440417576dda60e41"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMVQxNjowNjoyNFrOGTjDKQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMVQxNjowNjoyNFrOGTjDKQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzE1MDM3Nw==", "bodyText": "Need to keep this method in order to ensure binary compatibility...", "url": "https://github.com/netty/netty/pull/10267#discussion_r423150377", "createdAt": "2020-05-11T16:06:24Z", "author": {"login": "seedeed"}, "path": "buffer/src/main/java/io/netty/buffer/PooledByteBufAllocator.java", "diffHunk": "@@ -573,16 +561,6 @@ public int numThreadLocalCaches() {\n         return total;\n     }\n \n-    /**\n-     * Return the size of the tiny cache.\n-     *\n-     * @deprecated use {@link PooledByteBufAllocatorMetric#tinyCacheSize()}.\n-     */\n-    @Deprecated\n-    public int tinyCacheSize() {\n-        return tinyCacheSize;\n-    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1352b43f65bd04c87ec8fc5440417576dda60e41"}, "originalPosition": 242}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA5MzE5Mjg0", "url": "https://github.com/netty/netty/pull/10267#pullrequestreview-409319284", "createdAt": "2020-05-11T16:10:25Z", "commit": {"oid": "1352b43f65bd04c87ec8fc5440417576dda60e41"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMVQxNjoxMDoyNVrOGTjNcA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0xMVQxNjoxMDoyNVrOGTjNcA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMzE1MzAwOA==", "bodyText": "For compatible reason, we had better keep it for now...", "url": "https://github.com/netty/netty/pull/10267#discussion_r423153008", "createdAt": "2020-05-11T16:10:25Z", "author": {"login": "seedeed"}, "path": "buffer/src/main/java/io/netty/buffer/PooledByteBufAllocatorMetric.java", "diffHunk": "@@ -66,13 +66,6 @@ public int numThreadLocalCaches() {\n         return allocator.numThreadLocalCaches();\n     }\n \n-    /**\n-     * Return the size of the tiny cache.\n-     */\n-    public int tinyCacheSize() {\n-        return allocator.tinyCacheSize();\n-    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1352b43f65bd04c87ec8fc5440417576dda60e41"}, "originalPosition": 9}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "feb76a475f74e072dbd564fb9bd039a4f43b01e8", "author": {"user": {"login": "yuanrw", "name": "Ruwei"}}, "url": "https://github.com/netty/netty/commit/feb76a475f74e072dbd564fb9bd039a4f43b01e8", "committedDate": "2020-05-13T03:41:12Z", "message": "1. Update RedBlackTree and remove it to buffer package.\n2. Remain old apis in PoolArenaMetric PoolSubpageMetric PooledByteBufAllocatorMetric.\n3. Remain old constructors in PooledBytebufAllocator, only add new\n   constructors.\n4. Undo modifications in tests, only add new tests.\n5. Remove maxPages, remain maxOrder in PooledByteBufAllocator"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "692789b88f66d03f4470c9cbe8a3fa9ae3a684d6", "author": {"user": {"login": "yuanrw", "name": "Ruwei"}}, "url": "https://github.com/netty/netty/commit/692789b88f66d03f4470c9cbe8a3fa9ae3a684d6", "committedDate": "2020-05-21T08:40:32Z", "message": "use priority queue instead of RedBlackTree since we don't need to find a\nnode\nfix allocateSubpage bug\nupdate test"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "fc5b0648abb2eaa44a966e534661924300b36f72", "author": {"user": {"login": "yuanrw", "name": "Ruwei"}}, "url": "https://github.com/netty/netty/commit/fc5b0648abb2eaa44a966e534661924300b36f72", "committedDate": "2020-05-20T08:41:51Z", "message": "use priority queue instead of RedBlackTree since we don't need to find a\nnode"}, "afterCommit": {"oid": "692789b88f66d03f4470c9cbe8a3fa9ae3a684d6", "author": {"user": {"login": "yuanrw", "name": "Ruwei"}}, "url": "https://github.com/netty/netty/commit/692789b88f66d03f4470c9cbe8a3fa9ae3a684d6", "committedDate": "2020-05-21T08:40:32Z", "message": "use priority queue instead of RedBlackTree since we don't need to find a\nnode\nfix allocateSubpage bug\nupdate test"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDE2MDk5ODky", "url": "https://github.com/netty/netty/pull/10267#pullrequestreview-416099892", "createdAt": "2020-05-21T12:21:13Z", "commit": {"oid": "692789b88f66d03f4470c9cbe8a3fa9ae3a684d6"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQxMjoyMToxNFrOGYwxPQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQxMjoyNDowNFrOGYw2MA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODYxODA0NQ==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    return isSubpage(handle)? SizeClass.Small : SizeClass.Normal;\n          \n          \n            \n                    return isSubpage(handle) ? SizeClass.Small : SizeClass.Normal;", "url": "https://github.com/netty/netty/pull/10267#discussion_r428618045", "createdAt": "2020-05-21T12:21:14Z", "author": {"login": "johnou"}, "path": "buffer/src/main/java/io/netty/buffer/PoolArena.java", "diffHunk": "@@ -272,24 +222,22 @@ void free(PoolChunk<T> chunk, ByteBuffer nioBuffer, long handle, int normCapacit\n             activeBytesHuge.add(-size);\n             deallocationsHuge.increment();\n         } else {\n-            SizeClass sizeClass = sizeClass(normCapacity);\n+            SizeClass sizeClass = sizeClass(handle);\n             if (cache != null && cache.add(this, chunk, nioBuffer, handle, normCapacity, sizeClass)) {\n                 // cached so not free it.\n                 return;\n             }\n \n-            freeChunk(chunk, handle, sizeClass, nioBuffer, false);\n+            freeChunk(chunk, handle, normCapacity, sizeClass, nioBuffer, false);\n         }\n     }\n \n-    private SizeClass sizeClass(int normCapacity) {\n-        if (!isTinyOrSmall(normCapacity)) {\n-            return SizeClass.Normal;\n-        }\n-        return isTiny(normCapacity) ? SizeClass.Tiny : SizeClass.Small;\n+    private SizeClass sizeClass(long handle) {\n+        return isSubpage(handle)? SizeClass.Small : SizeClass.Normal;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "692789b88f66d03f4470c9cbe8a3fa9ae3a684d6"}, "originalPosition": 278}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODYxODQyNw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    return new ArrayList<PoolSubpageMetric>();\n          \n          \n            \n                    return Collections.emptyList();", "url": "https://github.com/netty/netty/pull/10267#discussion_r428618427", "createdAt": "2020-05-21T12:22:08Z", "author": {"login": "johnou"}, "path": "buffer/src/main/java/io/netty/buffer/PoolArena.java", "diffHunk": "@@ -427,7 +318,7 @@ public int numChunkLists() {\n \n     @Override\n     public List<PoolSubpageMetric> tinySubpages() {\n-        return subPageMetricList(tinySubpagePools);\n+        return new ArrayList<PoolSubpageMetric>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "692789b88f66d03f4470c9cbe8a3fa9ae3a684d6"}, "originalPosition": 382}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODYxOTMxMg==", "bodyText": "can we change the argument order back to the original?", "url": "https://github.com/netty/netty/pull/10267#discussion_r428619312", "createdAt": "2020-05-21T12:24:04Z", "author": {"login": "johnou"}, "path": "buffer/src/main/java/io/netty/buffer/PoolArena.java", "diffHunk": "@@ -724,17 +611,17 @@ int offsetCacheLine(ByteBuffer memory) {\n         }\n \n         @Override\n-        protected PoolChunk<ByteBuffer> newChunk(int pageSize, int maxOrder,\n-                int pageShifts, int chunkSize) {\n+        protected PoolChunk<ByteBuffer> newChunk(int pageSize, int pageShifts,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "692789b88f66d03f4470c9cbe8a3fa9ae3a684d6"}, "originalPosition": 516}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2ab7f9b3f4c803b4c19eb13bc869788771750ce0", "author": {"user": {"login": "yuanrw", "name": "Ruwei"}}, "url": "https://github.com/netty/netty/commit/2ab7f9b3f4c803b4c19eb13bc869788771750ce0", "committedDate": "2020-05-28T04:06:31Z", "message": "update PoolArena for suggest changes"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM4MjMzMTMy", "url": "https://github.com/netty/netty/pull/10267#pullrequestreview-438233132", "createdAt": "2020-06-26T11:53:29Z", "commit": {"oid": "2ab7f9b3f4c803b4c19eb13bc869788771750ce0"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM4MjM1Mzgy", "url": "https://github.com/netty/netty/pull/10267#pullrequestreview-438235382", "createdAt": "2020-06-26T11:57:31Z", "commit": {"oid": "2ab7f9b3f4c803b4c19eb13bc869788771750ce0"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 22, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxMTo1NzozMVrOGpeLkQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxMjoxNDoyMVrOGpen-Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEzOTI4MQ==", "bodyText": "@yuanrw can you also please add @deprecated javadoc", "url": "https://github.com/netty/netty/pull/10267#discussion_r446139281", "createdAt": "2020-06-26T11:57:31Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/main/java/io/netty/buffer/PoolArenaMetric.java", "diffHunk": "@@ -21,18 +21,13 @@\n /**\n  * Expose metrics for an arena.\n  */\n-public interface PoolArenaMetric {\n+public interface PoolArenaMetric extends SizeClassesMetric {\n \n     /**\n      * Returns the number of thread caches backed by this arena.\n      */\n     int numThreadCaches();\n \n-    /**\n-     * Returns the number of tiny sub-pages for the arena.\n-     */\n-    int numTinySubpages();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMjYxMjM3Mg=="}, "originalCommit": {"oid": "1352b43f65bd04c87ec8fc5440417576dda60e41"}, "originalPosition": 15}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEzOTMyNg==", "bodyText": "@yuanrw can you also please add @deprecated javadoc", "url": "https://github.com/netty/netty/pull/10267#discussion_r446139326", "createdAt": "2020-06-26T11:57:37Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/main/java/io/netty/buffer/PoolArenaMetric.java", "diffHunk": "@@ -46,6 +47,7 @@\n     /**\n      * Returns an unmodifiable {@link List} which holds {@link PoolSubpageMetric}s for tiny sub-pages.\n      */\n+    @Deprecated", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2ab7f9b3f4c803b4c19eb13bc869788771750ce0"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEzOTM1OA==", "bodyText": "@yuanrw can you also please add @deprecated javadoc", "url": "https://github.com/netty/netty/pull/10267#discussion_r446139358", "createdAt": "2020-06-26T11:57:41Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/main/java/io/netty/buffer/PoolArenaMetric.java", "diffHunk": "@@ -66,6 +68,7 @@\n     /**\n      * Return the number of tiny allocations done via the arena.\n      */\n+    @Deprecated", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2ab7f9b3f4c803b4c19eb13bc869788771750ce0"}, "originalPosition": 29}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEzOTM5Mg==", "bodyText": "@yuanrw can you also please add @deprecated javadoc", "url": "https://github.com/netty/netty/pull/10267#discussion_r446139392", "createdAt": "2020-06-26T11:57:46Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/main/java/io/netty/buffer/PoolArenaMetric.java", "diffHunk": "@@ -91,6 +94,7 @@\n     /**\n      * Return the number of tiny deallocations done via the arena.\n      */\n+    @Deprecated", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2ab7f9b3f4c803b4c19eb13bc869788771750ce0"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEzOTQyOQ==", "bodyText": "@yuanrw can you also please add @deprecated javadoc", "url": "https://github.com/netty/netty/pull/10267#discussion_r446139429", "createdAt": "2020-06-26T11:57:51Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/main/java/io/netty/buffer/PoolArenaMetric.java", "diffHunk": "@@ -116,6 +120,7 @@\n     /**\n      * Return the number of currently active tiny allocations.\n      */\n+    @Deprecated", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2ab7f9b3f4c803b4c19eb13bc869788771750ce0"}, "originalPosition": 45}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEzOTc0NA==", "bodyText": "nit: missing . at EOL.", "url": "https://github.com/netty/netty/pull/10267#discussion_r446139744", "createdAt": "2020-06-26T11:58:33Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/main/java/io/netty/buffer/PoolChunk.java", "diffHunk": "@@ -13,117 +13,161 @@\n  * License for the specific language governing permissions and limitations\n  * under the License.\n  */\n-\n package io.netty.buffer;\n \n+import io.netty.util.collection.IntObjectHashMap;\n+import io.netty.util.collection.IntObjectMap;\n+\n import java.nio.ByteBuffer;\n import java.util.ArrayDeque;\n import java.util.Deque;\n+import java.util.PriorityQueue;\n \n /**\n  * Description of algorithm for PageRun/PoolSubpage allocation from PoolChunk\n  *\n  * Notation: The following terms are important to understand the code\n  * > page  - a page is the smallest unit of memory chunk that can be allocated\n- * > chunk - a chunk is a collection of pages\n- * > in this code chunkSize = 2^{maxOrder} * pageSize\n+ * > run   - a run is a collection of pages\n+ * > chunk - a chunk is a collection of runs\n+ * > in this code chunkSize = maxPages * pageSize\n  *\n  * To begin we allocate a byte array of size = chunkSize\n  * Whenever a ByteBuf of given size needs to be created we search for the first position\n  * in the byte array that has enough empty space to accommodate the requested size and\n  * return a (long) handle that encodes this offset information, (this memory segment is then\n  * marked as reserved so it is always used by exactly one ByteBuf and no more)\n  *\n- * For simplicity all sizes are normalized according to PoolArena#normalizeCapacity method\n- * This ensures that when we request for memory segments of size >= pageSize the normalizedCapacity\n- * equals the next nearest power of 2\n+ * For simplicity all sizes are normalized according to {@link PoolArena#size2SizeIdx(int)} method", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2ab7f9b3f4c803b4c19eb13bc869788771750ce0"}, "originalPosition": 35}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjEzOTkyMA==", "bodyText": "<3 ascii art :)", "url": "https://github.com/netty/netty/pull/10267#discussion_r446139920", "createdAt": "2020-06-26T11:58:54Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/main/java/io/netty/buffer/PoolChunk.java", "diffHunk": "@@ -13,117 +13,161 @@\n  * License for the specific language governing permissions and limitations\n  * under the License.\n  */\n-\n package io.netty.buffer;\n \n+import io.netty.util.collection.IntObjectHashMap;\n+import io.netty.util.collection.IntObjectMap;\n+\n import java.nio.ByteBuffer;\n import java.util.ArrayDeque;\n import java.util.Deque;\n+import java.util.PriorityQueue;\n \n /**\n  * Description of algorithm for PageRun/PoolSubpage allocation from PoolChunk\n  *\n  * Notation: The following terms are important to understand the code\n  * > page  - a page is the smallest unit of memory chunk that can be allocated\n- * > chunk - a chunk is a collection of pages\n- * > in this code chunkSize = 2^{maxOrder} * pageSize\n+ * > run   - a run is a collection of pages\n+ * > chunk - a chunk is a collection of runs\n+ * > in this code chunkSize = maxPages * pageSize\n  *\n  * To begin we allocate a byte array of size = chunkSize\n  * Whenever a ByteBuf of given size needs to be created we search for the first position\n  * in the byte array that has enough empty space to accommodate the requested size and\n  * return a (long) handle that encodes this offset information, (this memory segment is then\n  * marked as reserved so it is always used by exactly one ByteBuf and no more)\n  *\n- * For simplicity all sizes are normalized according to PoolArena#normalizeCapacity method\n- * This ensures that when we request for memory segments of size >= pageSize the normalizedCapacity\n- * equals the next nearest power of 2\n+ * For simplicity all sizes are normalized according to {@link PoolArena#size2SizeIdx(int)} method\n+ * This ensures that when we request for memory segments of size > pageSize the normalizedCapacity\n+ * equals the next nearest size in {@link SizeClasses}\n+ *\n+ *\n+ *  A chunk has the following layout:\n+ *\n+ *     /-----------------\\\n+ *     | run             |\n+ *     |                 |\n+ *     |                 |\n+ *     |-----------------|\n+ *     | run             |\n+ *     |                 |\n+ *     |-----------------|\n+ *     | unalloctated    |\n+ *     | (freed)         |\n+ *     |                 |\n+ *     |-----------------|\n+ *     | subpage         |\n+ *     |-----------------|\n+ *     | unallocated     |\n+ *     | (freed)         |\n+ *     | ...             |\n+ *     | ...             |\n+ *     | ...             |\n+ *     |                 |\n+ *     |                 |\n+ *     |                 |\n+ *     \\-----------------/", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2ab7f9b3f4c803b4c19eb13bc869788771750ce0"}, "originalPosition": 64}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE0MDI5NA==", "bodyText": "nit: missing . on EOL", "url": "https://github.com/netty/netty/pull/10267#discussion_r446140294", "createdAt": "2020-06-26T11:59:51Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/main/java/io/netty/buffer/PoolChunk.java", "diffHunk": "@@ -13,117 +13,161 @@\n  * License for the specific language governing permissions and limitations\n  * under the License.\n  */\n-\n package io.netty.buffer;\n \n+import io.netty.util.collection.IntObjectHashMap;\n+import io.netty.util.collection.IntObjectMap;\n+\n import java.nio.ByteBuffer;\n import java.util.ArrayDeque;\n import java.util.Deque;\n+import java.util.PriorityQueue;\n \n /**\n  * Description of algorithm for PageRun/PoolSubpage allocation from PoolChunk\n  *\n  * Notation: The following terms are important to understand the code\n  * > page  - a page is the smallest unit of memory chunk that can be allocated\n- * > chunk - a chunk is a collection of pages\n- * > in this code chunkSize = 2^{maxOrder} * pageSize\n+ * > run   - a run is a collection of pages\n+ * > chunk - a chunk is a collection of runs\n+ * > in this code chunkSize = maxPages * pageSize\n  *\n  * To begin we allocate a byte array of size = chunkSize\n  * Whenever a ByteBuf of given size needs to be created we search for the first position\n  * in the byte array that has enough empty space to accommodate the requested size and\n  * return a (long) handle that encodes this offset information, (this memory segment is then\n  * marked as reserved so it is always used by exactly one ByteBuf and no more)\n  *\n- * For simplicity all sizes are normalized according to PoolArena#normalizeCapacity method\n- * This ensures that when we request for memory segments of size >= pageSize the normalizedCapacity\n- * equals the next nearest power of 2\n+ * For simplicity all sizes are normalized according to {@link PoolArena#size2SizeIdx(int)} method\n+ * This ensures that when we request for memory segments of size > pageSize the normalizedCapacity\n+ * equals the next nearest size in {@link SizeClasses}\n+ *\n+ *\n+ *  A chunk has the following layout:\n+ *\n+ *     /-----------------\\\n+ *     | run             |\n+ *     |                 |\n+ *     |                 |\n+ *     |-----------------|\n+ *     | run             |\n+ *     |                 |\n+ *     |-----------------|\n+ *     | unalloctated    |\n+ *     | (freed)         |\n+ *     |                 |\n+ *     |-----------------|\n+ *     | subpage         |\n+ *     |-----------------|\n+ *     | unallocated     |\n+ *     | (freed)         |\n+ *     | ...             |\n+ *     | ...             |\n+ *     | ...             |\n+ *     |                 |\n+ *     |                 |\n+ *     |                 |\n+ *     \\-----------------/\n  *\n- * To search for the first offset in chunk that has at least requested size available we construct a\n- * complete balanced binary tree and store it in an array (just like heaps) - memoryMap\n  *\n- * The tree looks like this (the size of each node being mentioned in the parenthesis)\n+ * handle:\n+ * -------\n+ * a handle is a long number, the bit layout of a run looks like:\n  *\n- * depth=0        1 node (chunkSize)\n- * depth=1        2 nodes (chunkSize/2)\n- * ..\n- * ..\n- * depth=d        2^d nodes (chunkSize/2^d)\n- * ..\n- * depth=maxOrder 2^maxOrder nodes (chunkSize/2^{maxOrder} = pageSize)\n+ * oooooooo ooooooos ssssssss ssssssue bbbbbbbb bbbbbbbb bbbbbbbb bbbbbbbb\n  *\n- * depth=maxOrder is the last level and the leafs consist of pages\n+ * o: runOffset (page offset in the chunk), 15bit\n+ * s: size (number of pages) of this run, 15bit\n+ * u: isUsed?, 1bit\n+ * e: isSubpage?, 1bit\n+ * b: bitmapIdx of subpage, zero if it's not subpage, 32bit\n+ *\n+ * runsAvailMap:\n+ * ------\n+ * a map which manages all runs (used and not in used)\n+ * For each run, the first runOffset and last runOffset are stored in runsAvailMap.\n+ * key: runOffset\n+ * value: handle\n+ *\n+ * runsAvail:\n+ * ----------\n+ * an array of {@link PriorityQueue}", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2ab7f9b3f4c803b4c19eb13bc869788771750ce0"}, "originalPosition": 99}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE0MDMzNQ==", "bodyText": "nit: missing . on EOL", "url": "https://github.com/netty/netty/pull/10267#discussion_r446140335", "createdAt": "2020-06-26T11:59:56Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/main/java/io/netty/buffer/PoolChunk.java", "diffHunk": "@@ -13,117 +13,161 @@\n  * License for the specific language governing permissions and limitations\n  * under the License.\n  */\n-\n package io.netty.buffer;\n \n+import io.netty.util.collection.IntObjectHashMap;\n+import io.netty.util.collection.IntObjectMap;\n+\n import java.nio.ByteBuffer;\n import java.util.ArrayDeque;\n import java.util.Deque;\n+import java.util.PriorityQueue;\n \n /**\n  * Description of algorithm for PageRun/PoolSubpage allocation from PoolChunk\n  *\n  * Notation: The following terms are important to understand the code\n  * > page  - a page is the smallest unit of memory chunk that can be allocated\n- * > chunk - a chunk is a collection of pages\n- * > in this code chunkSize = 2^{maxOrder} * pageSize\n+ * > run   - a run is a collection of pages\n+ * > chunk - a chunk is a collection of runs\n+ * > in this code chunkSize = maxPages * pageSize\n  *\n  * To begin we allocate a byte array of size = chunkSize\n  * Whenever a ByteBuf of given size needs to be created we search for the first position\n  * in the byte array that has enough empty space to accommodate the requested size and\n  * return a (long) handle that encodes this offset information, (this memory segment is then\n  * marked as reserved so it is always used by exactly one ByteBuf and no more)\n  *\n- * For simplicity all sizes are normalized according to PoolArena#normalizeCapacity method\n- * This ensures that when we request for memory segments of size >= pageSize the normalizedCapacity\n- * equals the next nearest power of 2\n+ * For simplicity all sizes are normalized according to {@link PoolArena#size2SizeIdx(int)} method\n+ * This ensures that when we request for memory segments of size > pageSize the normalizedCapacity\n+ * equals the next nearest size in {@link SizeClasses}\n+ *\n+ *\n+ *  A chunk has the following layout:\n+ *\n+ *     /-----------------\\\n+ *     | run             |\n+ *     |                 |\n+ *     |                 |\n+ *     |-----------------|\n+ *     | run             |\n+ *     |                 |\n+ *     |-----------------|\n+ *     | unalloctated    |\n+ *     | (freed)         |\n+ *     |                 |\n+ *     |-----------------|\n+ *     | subpage         |\n+ *     |-----------------|\n+ *     | unallocated     |\n+ *     | (freed)         |\n+ *     | ...             |\n+ *     | ...             |\n+ *     | ...             |\n+ *     |                 |\n+ *     |                 |\n+ *     |                 |\n+ *     \\-----------------/\n  *\n- * To search for the first offset in chunk that has at least requested size available we construct a\n- * complete balanced binary tree and store it in an array (just like heaps) - memoryMap\n  *\n- * The tree looks like this (the size of each node being mentioned in the parenthesis)\n+ * handle:\n+ * -------\n+ * a handle is a long number, the bit layout of a run looks like:\n  *\n- * depth=0        1 node (chunkSize)\n- * depth=1        2 nodes (chunkSize/2)\n- * ..\n- * ..\n- * depth=d        2^d nodes (chunkSize/2^d)\n- * ..\n- * depth=maxOrder 2^maxOrder nodes (chunkSize/2^{maxOrder} = pageSize)\n+ * oooooooo ooooooos ssssssss ssssssue bbbbbbbb bbbbbbbb bbbbbbbb bbbbbbbb\n  *\n- * depth=maxOrder is the last level and the leafs consist of pages\n+ * o: runOffset (page offset in the chunk), 15bit\n+ * s: size (number of pages) of this run, 15bit\n+ * u: isUsed?, 1bit\n+ * e: isSubpage?, 1bit\n+ * b: bitmapIdx of subpage, zero if it's not subpage, 32bit\n+ *\n+ * runsAvailMap:\n+ * ------\n+ * a map which manages all runs (used and not in used)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2ab7f9b3f4c803b4c19eb13bc869788771750ce0"}, "originalPosition": 92}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE0MDU3MQ==", "bodyText": "Nit: The....", "url": "https://github.com/netty/netty/pull/10267#discussion_r446140571", "createdAt": "2020-06-26T12:00:22Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/main/java/io/netty/buffer/PoolChunk.java", "diffHunk": "@@ -13,117 +13,161 @@\n  * License for the specific language governing permissions and limitations\n  * under the License.\n  */\n-\n package io.netty.buffer;\n \n+import io.netty.util.collection.IntObjectHashMap;\n+import io.netty.util.collection.IntObjectMap;\n+\n import java.nio.ByteBuffer;\n import java.util.ArrayDeque;\n import java.util.Deque;\n+import java.util.PriorityQueue;\n \n /**\n  * Description of algorithm for PageRun/PoolSubpage allocation from PoolChunk\n  *\n  * Notation: The following terms are important to understand the code\n  * > page  - a page is the smallest unit of memory chunk that can be allocated\n- * > chunk - a chunk is a collection of pages\n- * > in this code chunkSize = 2^{maxOrder} * pageSize\n+ * > run   - a run is a collection of pages\n+ * > chunk - a chunk is a collection of runs\n+ * > in this code chunkSize = maxPages * pageSize\n  *\n  * To begin we allocate a byte array of size = chunkSize\n  * Whenever a ByteBuf of given size needs to be created we search for the first position\n  * in the byte array that has enough empty space to accommodate the requested size and\n  * return a (long) handle that encodes this offset information, (this memory segment is then\n  * marked as reserved so it is always used by exactly one ByteBuf and no more)\n  *\n- * For simplicity all sizes are normalized according to PoolArena#normalizeCapacity method\n- * This ensures that when we request for memory segments of size >= pageSize the normalizedCapacity\n- * equals the next nearest power of 2\n+ * For simplicity all sizes are normalized according to {@link PoolArena#size2SizeIdx(int)} method\n+ * This ensures that when we request for memory segments of size > pageSize the normalizedCapacity\n+ * equals the next nearest size in {@link SizeClasses}\n+ *\n+ *\n+ *  A chunk has the following layout:\n+ *\n+ *     /-----------------\\\n+ *     | run             |\n+ *     |                 |\n+ *     |                 |\n+ *     |-----------------|\n+ *     | run             |\n+ *     |                 |\n+ *     |-----------------|\n+ *     | unalloctated    |\n+ *     | (freed)         |\n+ *     |                 |\n+ *     |-----------------|\n+ *     | subpage         |\n+ *     |-----------------|\n+ *     | unallocated     |\n+ *     | (freed)         |\n+ *     | ...             |\n+ *     | ...             |\n+ *     | ...             |\n+ *     |                 |\n+ *     |                 |\n+ *     |                 |\n+ *     \\-----------------/\n  *\n- * To search for the first offset in chunk that has at least requested size available we construct a\n- * complete balanced binary tree and store it in an array (just like heaps) - memoryMap\n  *\n- * The tree looks like this (the size of each node being mentioned in the parenthesis)\n+ * handle:\n+ * -------\n+ * a handle is a long number, the bit layout of a run looks like:\n  *\n- * depth=0        1 node (chunkSize)\n- * depth=1        2 nodes (chunkSize/2)\n- * ..\n- * ..\n- * depth=d        2^d nodes (chunkSize/2^d)\n- * ..\n- * depth=maxOrder 2^maxOrder nodes (chunkSize/2^{maxOrder} = pageSize)\n+ * oooooooo ooooooos ssssssss ssssssue bbbbbbbb bbbbbbbb bbbbbbbb bbbbbbbb\n  *\n- * depth=maxOrder is the last level and the leafs consist of pages\n+ * o: runOffset (page offset in the chunk), 15bit\n+ * s: size (number of pages) of this run, 15bit\n+ * u: isUsed?, 1bit\n+ * e: isSubpage?, 1bit\n+ * b: bitmapIdx of subpage, zero if it's not subpage, 32bit\n+ *\n+ * runsAvailMap:\n+ * ------\n+ * a map which manages all runs (used and not in used)\n+ * For each run, the first runOffset and last runOffset are stored in runsAvailMap.\n+ * key: runOffset\n+ * value: handle\n+ *\n+ * runsAvail:\n+ * ----------\n+ * an array of {@link PriorityQueue}\n+ * Each queue manages same size of runs.\n+ * Runs are sorted by offset, so that we always allocate runs with smaller offset.\n  *\n- * With this tree available searching in chunkArray translates like this:\n- * To allocate a memory segment of size chunkSize/2^k we search for the first node (from left) at height k\n- * which is unused\n  *\n  * Algorithm:\n  * ----------\n- * Encode the tree in memoryMap with the notation\n- *   memoryMap[id] = x => in the subtree rooted at id, the first node that is free to be allocated\n- *   is at depth x (counted from depth=0) i.e., at depths [depth_of_id, x), there is no node that is free\n  *\n- *  As we allocate & free nodes, we update values stored in memoryMap so that the property is maintained\n+ *   As we allocate runs, we update values stored in runsAvailMap and runsAvail so that the property is maintained.\n  *\n  * Initialization -\n- *   In the beginning we construct the memoryMap array by storing the depth of a node at each node\n- *     i.e., memoryMap[id] = depth_of_id\n+ *  In the beginning we store the initial run which is the whole chunk.\n+ *  the initial run:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2ab7f9b3f4c803b4c19eb13bc869788771750ce0"}, "originalPosition": 120}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE0MTEwOA==", "bodyText": "nit: I think it should be IS_.....", "url": "https://github.com/netty/netty/pull/10267#discussion_r446141108", "createdAt": "2020-06-26T12:01:32Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/main/java/io/netty/buffer/PoolChunk.java", "diffHunk": "@@ -13,117 +13,161 @@\n  * License for the specific language governing permissions and limitations\n  * under the License.\n  */\n-\n package io.netty.buffer;\n \n+import io.netty.util.collection.IntObjectHashMap;\n+import io.netty.util.collection.IntObjectMap;\n+\n import java.nio.ByteBuffer;\n import java.util.ArrayDeque;\n import java.util.Deque;\n+import java.util.PriorityQueue;\n \n /**\n  * Description of algorithm for PageRun/PoolSubpage allocation from PoolChunk\n  *\n  * Notation: The following terms are important to understand the code\n  * > page  - a page is the smallest unit of memory chunk that can be allocated\n- * > chunk - a chunk is a collection of pages\n- * > in this code chunkSize = 2^{maxOrder} * pageSize\n+ * > run   - a run is a collection of pages\n+ * > chunk - a chunk is a collection of runs\n+ * > in this code chunkSize = maxPages * pageSize\n  *\n  * To begin we allocate a byte array of size = chunkSize\n  * Whenever a ByteBuf of given size needs to be created we search for the first position\n  * in the byte array that has enough empty space to accommodate the requested size and\n  * return a (long) handle that encodes this offset information, (this memory segment is then\n  * marked as reserved so it is always used by exactly one ByteBuf and no more)\n  *\n- * For simplicity all sizes are normalized according to PoolArena#normalizeCapacity method\n- * This ensures that when we request for memory segments of size >= pageSize the normalizedCapacity\n- * equals the next nearest power of 2\n+ * For simplicity all sizes are normalized according to {@link PoolArena#size2SizeIdx(int)} method\n+ * This ensures that when we request for memory segments of size > pageSize the normalizedCapacity\n+ * equals the next nearest size in {@link SizeClasses}\n+ *\n+ *\n+ *  A chunk has the following layout:\n+ *\n+ *     /-----------------\\\n+ *     | run             |\n+ *     |                 |\n+ *     |                 |\n+ *     |-----------------|\n+ *     | run             |\n+ *     |                 |\n+ *     |-----------------|\n+ *     | unalloctated    |\n+ *     | (freed)         |\n+ *     |                 |\n+ *     |-----------------|\n+ *     | subpage         |\n+ *     |-----------------|\n+ *     | unallocated     |\n+ *     | (freed)         |\n+ *     | ...             |\n+ *     | ...             |\n+ *     | ...             |\n+ *     |                 |\n+ *     |                 |\n+ *     |                 |\n+ *     \\-----------------/\n  *\n- * To search for the first offset in chunk that has at least requested size available we construct a\n- * complete balanced binary tree and store it in an array (just like heaps) - memoryMap\n  *\n- * The tree looks like this (the size of each node being mentioned in the parenthesis)\n+ * handle:\n+ * -------\n+ * a handle is a long number, the bit layout of a run looks like:\n  *\n- * depth=0        1 node (chunkSize)\n- * depth=1        2 nodes (chunkSize/2)\n- * ..\n- * ..\n- * depth=d        2^d nodes (chunkSize/2^d)\n- * ..\n- * depth=maxOrder 2^maxOrder nodes (chunkSize/2^{maxOrder} = pageSize)\n+ * oooooooo ooooooos ssssssss ssssssue bbbbbbbb bbbbbbbb bbbbbbbb bbbbbbbb\n  *\n- * depth=maxOrder is the last level and the leafs consist of pages\n+ * o: runOffset (page offset in the chunk), 15bit\n+ * s: size (number of pages) of this run, 15bit\n+ * u: isUsed?, 1bit\n+ * e: isSubpage?, 1bit\n+ * b: bitmapIdx of subpage, zero if it's not subpage, 32bit\n+ *\n+ * runsAvailMap:\n+ * ------\n+ * a map which manages all runs (used and not in used)\n+ * For each run, the first runOffset and last runOffset are stored in runsAvailMap.\n+ * key: runOffset\n+ * value: handle\n+ *\n+ * runsAvail:\n+ * ----------\n+ * an array of {@link PriorityQueue}\n+ * Each queue manages same size of runs.\n+ * Runs are sorted by offset, so that we always allocate runs with smaller offset.\n  *\n- * With this tree available searching in chunkArray translates like this:\n- * To allocate a memory segment of size chunkSize/2^k we search for the first node (from left) at height k\n- * which is unused\n  *\n  * Algorithm:\n  * ----------\n- * Encode the tree in memoryMap with the notation\n- *   memoryMap[id] = x => in the subtree rooted at id, the first node that is free to be allocated\n- *   is at depth x (counted from depth=0) i.e., at depths [depth_of_id, x), there is no node that is free\n  *\n- *  As we allocate & free nodes, we update values stored in memoryMap so that the property is maintained\n+ *   As we allocate runs, we update values stored in runsAvailMap and runsAvail so that the property is maintained.\n  *\n  * Initialization -\n- *   In the beginning we construct the memoryMap array by storing the depth of a node at each node\n- *     i.e., memoryMap[id] = depth_of_id\n+ *  In the beginning we store the initial run which is the whole chunk.\n+ *  the initial run:\n+ *  runOffset = 0\n+ *  size = chunkSize\n+ *  isUsed = no\n+ *  isSubpage = no\n+ *  bitmapIdx = 0\n  *\n- * Observations:\n- * -------------\n- * 1) memoryMap[id] = depth_of_id  => it is free / unallocated\n- * 2) memoryMap[id] > depth_of_id  => at least one of its child nodes is allocated, so we cannot allocate it, but\n- *                                    some of its children can still be allocated based on their availability\n- * 3) memoryMap[id] = maxOrder + 1 => the node is fully allocated & thus none of its children can be allocated, it\n- *                                    is thus marked as unusable\n- *\n- * Algorithm: [allocateNode(d) => we want to find the first node (from left) at height h that can be allocated]\n- * ----------\n- * 1) start at root (i.e., depth = 0 or id = 1)\n- * 2) if memoryMap[1] > d => cannot be allocated from this chunk\n- * 3) if left node value <= h; we can allocate from left subtree so move to left and repeat until found\n- * 4) else try in right subtree\n  *\n  * Algorithm: [allocateRun(size)]\n  * ----------\n- * 1) Compute d = log_2(chunkSize/size)\n- * 2) Return allocateNode(d)\n+ * 1) find the first avail run using in runsAvails according to size\n+ * 2) if pages of run is larger than request pages then split it, and save the tailing run\n+ *    for later using\n  *\n  * Algorithm: [allocateSubpage(size)]\n  * ----------\n- * 1) use allocateNode(maxOrder) to find an empty (i.e., unused) leaf (i.e., page)\n- * 2) use this handle to construct the PoolSubpage object or if it already exists just call init(normCapacity)\n- *    note that this PoolSubpage object is added to subpagesPool in the PoolArena when we init() it\n+ * 1) find a not full subpage according to size.\n+ *    if it already exists just return, otherwise allocate a new PoolSubpage and call init()\n+ *    note that this subpage object is added to subpagesPool in the PoolArena when we init() it\n+ * 2) call subpage.allocate()\n  *\n- * Note:\n- * -----\n- * In the implementation for improving cache coherence,\n- * we store 2 pieces of information depth_of_id and x as two byte values in memoryMap and depthMap respectively\n+ * Algorithm: [free(handle, length, nioBuffer)]\n+ * ----------\n+ * 1) if it is a subpage, return the slab back into this subpage\n+ * 2) if the subpage is not used or it is a run, then start free this run\n+ * 3) merge continuous avail runs\n+ * 4) save the merged run\n  *\n- * memoryMap[id]= depth_of_id  is defined above\n- * depthMap[id]= x  indicates that the first node which is free to be allocated is at depth x (from root)\n  */\n final class PoolChunk<T> implements PoolChunkMetric {\n \n-    private static final int INTEGER_SIZE_MINUS_ONE = Integer.SIZE - 1;\n+    private static final int OFFSET_BIT_LENGTH = 15;\n+    private static final int SIZE_BIT_LENGTH = 15;\n+    private static final int INUSED_BIT_LENGTH = 1;\n+    private static final int SUBPAGE_BIT_LENGTH = 1;\n+    private static final int BITMAP_IDX_BIT_LENGTH = 32;\n+\n+    static final int ISSUBPAGE_SHIFT = BITMAP_IDX_BIT_LENGTH;\n+    static final int ISUSED_SHIFT = SUBPAGE_BIT_LENGTH + ISSUBPAGE_SHIFT;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2ab7f9b3f4c803b4c19eb13bc869788771750ce0"}, "originalPosition": 184}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE0MTg3Ng==", "bodyText": "nit: consider adding lastPage() meted and use it here and above as the calculation is the same", "url": "https://github.com/netty/netty/pull/10267#discussion_r446141876", "createdAt": "2020-06-26T12:03:13Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/main/java/io/netty/buffer/PoolChunk.java", "diffHunk": "@@ -182,23 +214,58 @@\n         this.arena = arena;\n         this.memory = memory;\n         this.offset = offset;\n-        memoryMap = null;\n-        depthMap = null;\n-        subpages = null;\n-        subpageOverflowMask = 0;\n         pageSize = 0;\n         pageShifts = 0;\n-        maxOrder = 0;\n-        unusable = (byte) (maxOrder + 1);\n+        runsAvailMap = null;\n+        runsAvail = null;\n+        subpages = null;\n         chunkSize = size;\n-        log2ChunkSize = log2(chunkSize);\n-        maxSubpageAllocs = 0;\n         cachedNioBuffers = null;\n     }\n \n     @SuppressWarnings(\"unchecked\")\n-    private PoolSubpage<T>[] newSubpageArray(int size) {\n-        return new PoolSubpage[size];\n+    private static PriorityQueue<Long>[] newRunsAvailqueueArray(int size) {\n+        PriorityQueue<Long>[] queueArray = new PriorityQueue[size];\n+        for (int i = 0; i < queueArray.length; i++) {\n+            queueArray[i] = new PriorityQueue<Long>();\n+        }\n+        return queueArray;\n+    }\n+\n+    private void insertAvailRun(int runOffset, int pages, Long handle) {\n+        int pageIdxFloor = arena.pages2pageIdxFloor(pages);\n+        PriorityQueue<Long> queue = runsAvail[pageIdxFloor];\n+        queue.offer(handle);\n+\n+        //insert first page of run\n+        runsAvailMap.put(runOffset, handle);\n+        if (pages > 1) {\n+            //insert last page of run\n+            runsAvailMap.put(runOffset + pages - 1, handle);\n+        }\n+    }\n+\n+    private void removeAvailRun(long handle) {\n+        int pageIdxFloor = arena.pages2pageIdxFloor(runPages(handle));\n+        PriorityQueue<Long> queue = runsAvail[pageIdxFloor];\n+        removeAvailRun(queue, handle);\n+    }\n+\n+    private void removeAvailRun(PriorityQueue<Long> queue, long handle) {\n+        queue.remove(handle);\n+\n+        int runOffset = runOffset(handle);\n+        int pages = runPages(handle);\n+        //remove first page of run\n+        runsAvailMap.remove(runOffset);\n+        if (pages > 1) {\n+            //remove last page of run\n+            runsAvailMap.remove(runOffset + pages - 1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2ab7f9b3f4c803b4c19eb13bc869788771750ce0"}, "originalPosition": 332}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE0MjMyNw==", "bodyText": "can queue.poll() ever return null ? If so this may produce an NPE while unboxing", "url": "https://github.com/netty/netty/pull/10267#discussion_r446142327", "createdAt": "2020-06-26T12:04:18Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/main/java/io/netty/buffer/PoolChunk.java", "diffHunk": "@@ -222,256 +289,278 @@ private int usage(int freeBytes) {\n         return 100 - freePercentage;\n     }\n \n-    boolean allocate(PooledByteBuf<T> buf, int reqCapacity, int normCapacity, PoolThreadCache threadCache) {\n-        final long handle;\n-        if ((normCapacity & subpageOverflowMask) != 0) { // >= pageSize\n-            handle =  allocateRun(normCapacity);\n+    boolean allocate(PooledByteBuf<T> buf, int reqCapacity, int sizeIdx, PoolThreadCache cache) {\n+        long handle;\n+        if (sizeIdx <= arena.smallMaxSizeIdx) {\n+            // small\n+            handle = allocateSubpage(sizeIdx);\n+            if (handle < 0) {\n+                return false;\n+            }\n+            assert isSubpage(handle);\n         } else {\n-            handle = allocateSubpage(normCapacity);\n+            // normal\n+            // runSize must be multiple of pageSize\n+            int runSize = arena.sizeIdx2size(sizeIdx);\n+            handle = allocateRun(runSize);\n+            if (handle < 0) {\n+                return false;\n+            }\n         }\n \n-        if (handle < 0) {\n-            return false;\n-        }\n-        ByteBuffer nioBuffer = cachedNioBuffers != null ? cachedNioBuffers.pollLast() : null;\n-        initBuf(buf, nioBuffer, handle, reqCapacity, threadCache);\n+        ByteBuffer nioBuffer = cachedNioBuffers != null? cachedNioBuffers.pollLast() : null;\n+        initBuf(buf, nioBuffer, handle, reqCapacity, cache);\n         return true;\n     }\n \n-    /**\n-     * Update method used by allocate\n-     * This is triggered only when a successor is allocated and all its predecessors\n-     * need to update their state\n-     * The minimal depth at which subtree rooted at id has some free space\n-     *\n-     * @param id id\n-     */\n-    private void updateParentsAlloc(int id) {\n-        while (id > 1) {\n-            int parentId = id >>> 1;\n-            byte val1 = value(id);\n-            byte val2 = value(id ^ 1);\n-            byte val = val1 < val2 ? val1 : val2;\n-            setValue(parentId, val);\n-            id = parentId;\n-        }\n-    }\n+    private long allocateRun(int runSize) {\n+        int pages = runSize >> pageShifts;\n+        int pageIdx = arena.pages2pageIdx(pages);\n \n-    /**\n-     * Update method used by free\n-     * This needs to handle the special case when both children are completely free\n-     * in which case parent be directly allocated on request of size = child-size * 2\n-     *\n-     * @param id id\n-     */\n-    private void updateParentsFree(int id) {\n-        int logChild = depth(id) + 1;\n-        while (id > 1) {\n-            int parentId = id >>> 1;\n-            byte val1 = value(id);\n-            byte val2 = value(id ^ 1);\n-            logChild -= 1; // in first iteration equals log, subsequently reduce 1 from logChild as we traverse up\n-\n-            if (val1 == logChild && val2 == logChild) {\n-                setValue(parentId, (byte) (logChild - 1));\n-            } else {\n-                byte val = val1 < val2 ? val1 : val2;\n-                setValue(parentId, val);\n+        synchronized (runsAvail) {\n+            //find first queue which has at least one big enough run\n+            int queueIdx = runFirstBestFit(pageIdx);\n+            if (queueIdx == -1) {\n+                return -1;\n+            }\n+\n+            //get run with min offset in this queue\n+            PriorityQueue<Long> queue = runsAvail[queueIdx];\n+            long handle = queue.poll();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2ab7f9b3f4c803b4c19eb13bc869788771750ce0"}, "originalPosition": 430}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE0MjczMA==", "bodyText": "s/make/mark/ ?", "url": "https://github.com/netty/netty/pull/10267#discussion_r446142730", "createdAt": "2020-06-26T12:05:15Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/main/java/io/netty/buffer/PoolChunk.java", "diffHunk": "@@ -222,256 +289,278 @@ private int usage(int freeBytes) {\n         return 100 - freePercentage;\n     }\n \n-    boolean allocate(PooledByteBuf<T> buf, int reqCapacity, int normCapacity, PoolThreadCache threadCache) {\n-        final long handle;\n-        if ((normCapacity & subpageOverflowMask) != 0) { // >= pageSize\n-            handle =  allocateRun(normCapacity);\n+    boolean allocate(PooledByteBuf<T> buf, int reqCapacity, int sizeIdx, PoolThreadCache cache) {\n+        long handle;\n+        if (sizeIdx <= arena.smallMaxSizeIdx) {\n+            // small\n+            handle = allocateSubpage(sizeIdx);\n+            if (handle < 0) {\n+                return false;\n+            }\n+            assert isSubpage(handle);\n         } else {\n-            handle = allocateSubpage(normCapacity);\n+            // normal\n+            // runSize must be multiple of pageSize\n+            int runSize = arena.sizeIdx2size(sizeIdx);\n+            handle = allocateRun(runSize);\n+            if (handle < 0) {\n+                return false;\n+            }\n         }\n \n-        if (handle < 0) {\n-            return false;\n-        }\n-        ByteBuffer nioBuffer = cachedNioBuffers != null ? cachedNioBuffers.pollLast() : null;\n-        initBuf(buf, nioBuffer, handle, reqCapacity, threadCache);\n+        ByteBuffer nioBuffer = cachedNioBuffers != null? cachedNioBuffers.pollLast() : null;\n+        initBuf(buf, nioBuffer, handle, reqCapacity, cache);\n         return true;\n     }\n \n-    /**\n-     * Update method used by allocate\n-     * This is triggered only when a successor is allocated and all its predecessors\n-     * need to update their state\n-     * The minimal depth at which subtree rooted at id has some free space\n-     *\n-     * @param id id\n-     */\n-    private void updateParentsAlloc(int id) {\n-        while (id > 1) {\n-            int parentId = id >>> 1;\n-            byte val1 = value(id);\n-            byte val2 = value(id ^ 1);\n-            byte val = val1 < val2 ? val1 : val2;\n-            setValue(parentId, val);\n-            id = parentId;\n-        }\n-    }\n+    private long allocateRun(int runSize) {\n+        int pages = runSize >> pageShifts;\n+        int pageIdx = arena.pages2pageIdx(pages);\n \n-    /**\n-     * Update method used by free\n-     * This needs to handle the special case when both children are completely free\n-     * in which case parent be directly allocated on request of size = child-size * 2\n-     *\n-     * @param id id\n-     */\n-    private void updateParentsFree(int id) {\n-        int logChild = depth(id) + 1;\n-        while (id > 1) {\n-            int parentId = id >>> 1;\n-            byte val1 = value(id);\n-            byte val2 = value(id ^ 1);\n-            logChild -= 1; // in first iteration equals log, subsequently reduce 1 from logChild as we traverse up\n-\n-            if (val1 == logChild && val2 == logChild) {\n-                setValue(parentId, (byte) (logChild - 1));\n-            } else {\n-                byte val = val1 < val2 ? val1 : val2;\n-                setValue(parentId, val);\n+        synchronized (runsAvail) {\n+            //find first queue which has at least one big enough run\n+            int queueIdx = runFirstBestFit(pageIdx);\n+            if (queueIdx == -1) {\n+                return -1;\n+            }\n+\n+            //get run with min offset in this queue\n+            PriorityQueue<Long> queue = runsAvail[queueIdx];\n+            long handle = queue.poll();\n+\n+            assert !isUsed(handle);\n+\n+            removeAvailRun(queue, handle);\n+\n+            if (handle != -1) {\n+                handle = splitLargeRun(handle, pages);\n             }\n \n-            id = parentId;\n+            freeBytes -= runSize(pageShifts, handle);\n+            return handle;\n         }\n     }\n \n-    /**\n-     * Algorithm to allocate an index in memoryMap when we query for a free node\n-     * at depth d\n-     *\n-     * @param d depth\n-     * @return index in memoryMap\n-     */\n-    private int allocateNode(int d) {\n-        int id = 1;\n-        int initial = - (1 << d); // has last d bits = 0 and rest all = 1\n-        byte val = value(id);\n-        if (val > d) { // unusable\n-            return -1;\n+    private int calculateRunSize(int sizeIdx) {\n+        int maxElements = 1 << pageShifts - SizeClasses.LOG2_QUANTUM;\n+        int runSize = 0;\n+        int nElements;\n+\n+        final int elemSize = arena.sizeIdx2size(sizeIdx);\n+\n+        //find lowest common multiple of pageSize and elemSize\n+        do {\n+            runSize += pageSize;\n+            nElements = runSize / elemSize;\n+        } while (nElements < maxElements && runSize != nElements * elemSize);\n+\n+        while (nElements > maxElements) {\n+            runSize -= pageSize;\n+            nElements = runSize / elemSize;\n         }\n-        while (val < d || (id & initial) == 0) { // id & initial == 1 << d for all ids at depth d, for < d it is 0\n-            id <<= 1;\n-            val = value(id);\n-            if (val > d) {\n-                id ^= 1;\n-                val = value(id);\n+\n+        assert nElements > 0;\n+        assert runSize <= chunkSize;\n+        assert runSize >= elemSize;\n+\n+        return runSize;\n+    }\n+\n+    private int runFirstBestFit(int pageIdx) {\n+        for (int i = pageIdx; i < arena.nPSizes; i++) {\n+            PriorityQueue<Long> queue = runsAvail[i];\n+            if (queue != null && !queue.isEmpty()) {\n+                return i;\n             }\n         }\n-        byte value = value(id);\n-        assert value == d && (id & initial) == 1 << d : String.format(\"val = %d, id & initial = %d, d = %d\",\n-                value, id & initial, d);\n-        setValue(id, unusable); // mark as unusable\n-        updateParentsAlloc(id);\n-        return id;\n+        return -1;\n     }\n \n-    /**\n-     * Allocate a run of pages (>=1)\n-     *\n-     * @param normCapacity normalized capacity\n-     * @return index in memoryMap\n-     */\n-    private long allocateRun(int normCapacity) {\n-        int d = maxOrder - (log2(normCapacity) - pageShifts);\n-        int id = allocateNode(d);\n-        if (id < 0) {\n-            return id;\n+    private long splitLargeRun(long handle, int needPages) {\n+        assert needPages > 0;\n+\n+        int totalPages = runPages(handle);\n+        assert needPages <= totalPages;\n+\n+        int remPages = totalPages - needPages;\n+\n+        if (remPages > 0) {\n+            int runOffset = runOffset(handle);\n+\n+            // keep track of trailing unused pages for later use\n+            int availOffset = runOffset + needPages;\n+            long availRun = toRunHandle(availOffset, remPages, 0);\n+            insertAvailRun(availOffset, remPages, availRun);\n+\n+            // not avail\n+            return toRunHandle(runOffset, needPages, 1);\n         }\n-        freeBytes -= runLength(id);\n-        return id;\n+\n+        //make used", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2ab7f9b3f4c803b4c19eb13bc869788771750ce0"}, "originalPosition": 539}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE0MzQ0OQ==", "bodyText": "in Netty we usually use a \"crying for loop\" :) for (;;) {....}. Consider changing this one here to make it consistent", "url": "https://github.com/netty/netty/pull/10267#discussion_r446143449", "createdAt": "2020-06-26T12:06:57Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/main/java/io/netty/buffer/PoolChunk.java", "diffHunk": "@@ -222,256 +289,278 @@ private int usage(int freeBytes) {\n         return 100 - freePercentage;\n     }\n \n-    boolean allocate(PooledByteBuf<T> buf, int reqCapacity, int normCapacity, PoolThreadCache threadCache) {\n-        final long handle;\n-        if ((normCapacity & subpageOverflowMask) != 0) { // >= pageSize\n-            handle =  allocateRun(normCapacity);\n+    boolean allocate(PooledByteBuf<T> buf, int reqCapacity, int sizeIdx, PoolThreadCache cache) {\n+        long handle;\n+        if (sizeIdx <= arena.smallMaxSizeIdx) {\n+            // small\n+            handle = allocateSubpage(sizeIdx);\n+            if (handle < 0) {\n+                return false;\n+            }\n+            assert isSubpage(handle);\n         } else {\n-            handle = allocateSubpage(normCapacity);\n+            // normal\n+            // runSize must be multiple of pageSize\n+            int runSize = arena.sizeIdx2size(sizeIdx);\n+            handle = allocateRun(runSize);\n+            if (handle < 0) {\n+                return false;\n+            }\n         }\n \n-        if (handle < 0) {\n-            return false;\n-        }\n-        ByteBuffer nioBuffer = cachedNioBuffers != null ? cachedNioBuffers.pollLast() : null;\n-        initBuf(buf, nioBuffer, handle, reqCapacity, threadCache);\n+        ByteBuffer nioBuffer = cachedNioBuffers != null? cachedNioBuffers.pollLast() : null;\n+        initBuf(buf, nioBuffer, handle, reqCapacity, cache);\n         return true;\n     }\n \n-    /**\n-     * Update method used by allocate\n-     * This is triggered only when a successor is allocated and all its predecessors\n-     * need to update their state\n-     * The minimal depth at which subtree rooted at id has some free space\n-     *\n-     * @param id id\n-     */\n-    private void updateParentsAlloc(int id) {\n-        while (id > 1) {\n-            int parentId = id >>> 1;\n-            byte val1 = value(id);\n-            byte val2 = value(id ^ 1);\n-            byte val = val1 < val2 ? val1 : val2;\n-            setValue(parentId, val);\n-            id = parentId;\n-        }\n-    }\n+    private long allocateRun(int runSize) {\n+        int pages = runSize >> pageShifts;\n+        int pageIdx = arena.pages2pageIdx(pages);\n \n-    /**\n-     * Update method used by free\n-     * This needs to handle the special case when both children are completely free\n-     * in which case parent be directly allocated on request of size = child-size * 2\n-     *\n-     * @param id id\n-     */\n-    private void updateParentsFree(int id) {\n-        int logChild = depth(id) + 1;\n-        while (id > 1) {\n-            int parentId = id >>> 1;\n-            byte val1 = value(id);\n-            byte val2 = value(id ^ 1);\n-            logChild -= 1; // in first iteration equals log, subsequently reduce 1 from logChild as we traverse up\n-\n-            if (val1 == logChild && val2 == logChild) {\n-                setValue(parentId, (byte) (logChild - 1));\n-            } else {\n-                byte val = val1 < val2 ? val1 : val2;\n-                setValue(parentId, val);\n+        synchronized (runsAvail) {\n+            //find first queue which has at least one big enough run\n+            int queueIdx = runFirstBestFit(pageIdx);\n+            if (queueIdx == -1) {\n+                return -1;\n+            }\n+\n+            //get run with min offset in this queue\n+            PriorityQueue<Long> queue = runsAvail[queueIdx];\n+            long handle = queue.poll();\n+\n+            assert !isUsed(handle);\n+\n+            removeAvailRun(queue, handle);\n+\n+            if (handle != -1) {\n+                handle = splitLargeRun(handle, pages);\n             }\n \n-            id = parentId;\n+            freeBytes -= runSize(pageShifts, handle);\n+            return handle;\n         }\n     }\n \n-    /**\n-     * Algorithm to allocate an index in memoryMap when we query for a free node\n-     * at depth d\n-     *\n-     * @param d depth\n-     * @return index in memoryMap\n-     */\n-    private int allocateNode(int d) {\n-        int id = 1;\n-        int initial = - (1 << d); // has last d bits = 0 and rest all = 1\n-        byte val = value(id);\n-        if (val > d) { // unusable\n-            return -1;\n+    private int calculateRunSize(int sizeIdx) {\n+        int maxElements = 1 << pageShifts - SizeClasses.LOG2_QUANTUM;\n+        int runSize = 0;\n+        int nElements;\n+\n+        final int elemSize = arena.sizeIdx2size(sizeIdx);\n+\n+        //find lowest common multiple of pageSize and elemSize\n+        do {\n+            runSize += pageSize;\n+            nElements = runSize / elemSize;\n+        } while (nElements < maxElements && runSize != nElements * elemSize);\n+\n+        while (nElements > maxElements) {\n+            runSize -= pageSize;\n+            nElements = runSize / elemSize;\n         }\n-        while (val < d || (id & initial) == 0) { // id & initial == 1 << d for all ids at depth d, for < d it is 0\n-            id <<= 1;\n-            val = value(id);\n-            if (val > d) {\n-                id ^= 1;\n-                val = value(id);\n+\n+        assert nElements > 0;\n+        assert runSize <= chunkSize;\n+        assert runSize >= elemSize;\n+\n+        return runSize;\n+    }\n+\n+    private int runFirstBestFit(int pageIdx) {\n+        for (int i = pageIdx; i < arena.nPSizes; i++) {\n+            PriorityQueue<Long> queue = runsAvail[i];\n+            if (queue != null && !queue.isEmpty()) {\n+                return i;\n             }\n         }\n-        byte value = value(id);\n-        assert value == d && (id & initial) == 1 << d : String.format(\"val = %d, id & initial = %d, d = %d\",\n-                value, id & initial, d);\n-        setValue(id, unusable); // mark as unusable\n-        updateParentsAlloc(id);\n-        return id;\n+        return -1;\n     }\n \n-    /**\n-     * Allocate a run of pages (>=1)\n-     *\n-     * @param normCapacity normalized capacity\n-     * @return index in memoryMap\n-     */\n-    private long allocateRun(int normCapacity) {\n-        int d = maxOrder - (log2(normCapacity) - pageShifts);\n-        int id = allocateNode(d);\n-        if (id < 0) {\n-            return id;\n+    private long splitLargeRun(long handle, int needPages) {\n+        assert needPages > 0;\n+\n+        int totalPages = runPages(handle);\n+        assert needPages <= totalPages;\n+\n+        int remPages = totalPages - needPages;\n+\n+        if (remPages > 0) {\n+            int runOffset = runOffset(handle);\n+\n+            // keep track of trailing unused pages for later use\n+            int availOffset = runOffset + needPages;\n+            long availRun = toRunHandle(availOffset, remPages, 0);\n+            insertAvailRun(availOffset, remPages, availRun);\n+\n+            // not avail\n+            return toRunHandle(runOffset, needPages, 1);\n         }\n-        freeBytes -= runLength(id);\n-        return id;\n+\n+        //make used\n+        handle |= 1L << ISUSED_SHIFT;\n+        return handle;\n     }\n \n     /**\n-     * Create / initialize a new PoolSubpage of normCapacity\n-     * Any PoolSubpage created / initialized here is added to subpage pool in the PoolArena that owns this PoolChunk\n+     * Create / initialize a new PoolSubpage of normCapacity Any PoolSubpage created / initialized here is added to\n+     * subpage pool in the PoolArena that owns this PoolChunk\n+     *\n+     * @param sizeIdx sizeIdx of normalized size\n      *\n-     * @param normCapacity normalized capacity\n      * @return index in memoryMap\n      */\n-    private long allocateSubpage(int normCapacity) {\n+    private long allocateSubpage(int sizeIdx) {\n         // Obtain the head of the PoolSubPage pool that is owned by the PoolArena and synchronize on it.\n         // This is need as we may add it back and so alter the linked-list structure.\n-        PoolSubpage<T> head = arena.findSubpagePoolHead(normCapacity);\n-        int d = maxOrder; // subpages are only be allocated from pages i.e., leaves\n+        PoolSubpage<T> head = arena.findSubpagePoolHead(sizeIdx);\n         synchronized (head) {\n-            int id = allocateNode(d);\n-            if (id < 0) {\n-                return id;\n+            //allocate a new run\n+            int runSize = calculateRunSize(sizeIdx);\n+            //runSize must be multiples of pageSize\n+            long runHandle = allocateRun(runSize);\n+            if (runHandle < 0) {\n+                return -1;\n             }\n \n-            final PoolSubpage<T>[] subpages = this.subpages;\n-            final int pageSize = this.pageSize;\n+            int runOffset = runOffset(runHandle);\n+            int elemSize = arena.sizeIdx2size(sizeIdx);\n \n-            freeBytes -= pageSize;\n+            PoolSubpage<T> subpage = new PoolSubpage<T>(head, this, pageShifts, runOffset,\n+                               runSize(pageShifts, runHandle), elemSize);\n \n-            int subpageIdx = subpageIdx(id);\n-            PoolSubpage<T> subpage = subpages[subpageIdx];\n-            if (subpage == null) {\n-                subpage = new PoolSubpage<T>(head, this, id, runOffset(id), pageSize, normCapacity);\n-                subpages[subpageIdx] = subpage;\n-            } else {\n-                subpage.init(head, normCapacity);\n-            }\n+            subpages[runOffset] = subpage;\n             return subpage.allocate();\n         }\n     }\n \n     /**\n-     * Free a subpage or a run of pages\n-     * When a subpage is freed from PoolSubpage, it might be added back to subpage pool of the owning PoolArena\n-     * If the subpage pool in PoolArena has at least one other PoolSubpage of given elemSize, we can\n-     * completely free the owning Page so it is available for subsequent allocations\n+     * Free a subpage or a run of pages When a subpage is freed from PoolSubpage, it might be added back to subpage pool\n+     * of the owning PoolArena If the subpage pool in PoolArena has at least one other PoolSubpage of given elemSize, we\n+     * can completely free the owning Page so it is available for subsequent allocations\n      *\n      * @param handle handle to free\n      */\n-    void free(long handle, ByteBuffer nioBuffer) {\n-        int memoryMapIdx = memoryMapIdx(handle);\n-        int bitmapIdx = bitmapIdx(handle);\n+    void free(long handle, int normCapacity, ByteBuffer nioBuffer) {\n+        if (isSubpage(handle)) {\n+            int sizeIdx = arena.size2SizeIdx(normCapacity);\n+            PoolSubpage<T> head = arena.findSubpagePoolHead(sizeIdx);\n \n-        if (bitmapIdx != 0) { // free a subpage\n-            PoolSubpage<T> subpage = subpages[subpageIdx(memoryMapIdx)];\n+            PoolSubpage<T> subpage = subpages[runOffset(handle)];\n             assert subpage != null && subpage.doNotDestroy;\n \n             // Obtain the head of the PoolSubPage pool that is owned by the PoolArena and synchronize on it.\n             // This is need as we may add it back and so alter the linked-list structure.\n-            PoolSubpage<T> head = arena.findSubpagePoolHead(subpage.elemSize);\n             synchronized (head) {\n-                if (subpage.free(head, bitmapIdx & 0x3FFFFFFF)) {\n+                if (subpage.free(head, bitmapIdx(handle))) {\n+                    //the subpage is still used, do not free it\n                     return;\n                 }\n             }\n         }\n-        freeBytes += runLength(memoryMapIdx);\n-        setValue(memoryMapIdx, depth(memoryMapIdx));\n-        updateParentsFree(memoryMapIdx);\n \n-        if (nioBuffer != null && cachedNioBuffers != null &&\n-                cachedNioBuffers.size() < PooledByteBufAllocator.DEFAULT_MAX_CACHED_BYTEBUFFERS_PER_CHUNK) {\n-            cachedNioBuffers.offer(nioBuffer);\n+        //start free run\n+        int pages = runPages(handle);\n+\n+        synchronized (runsAvail) {\n+            // collapse continuous runs, successfully collapsed runs\n+            // will be removed from runsAvail and runsAvailMap\n+            long finalRun = collapseRuns(handle);\n+\n+            //set run as not used\n+            finalRun &= ~(1L << ISUSED_SHIFT);\n+            //if it is a subpage, set it to run\n+            finalRun &= ~(1L << ISSUBPAGE_SHIFT);\n+\n+            insertAvailRun(runOffset(finalRun), runPages(finalRun), finalRun);\n+            freeBytes += pages << pageShifts;\n         }\n-    }\n \n-    void initBuf(PooledByteBuf<T> buf, ByteBuffer nioBuffer, long handle, int reqCapacity,\n-                 PoolThreadCache threadCache) {\n-        int memoryMapIdx = memoryMapIdx(handle);\n-        int bitmapIdx = bitmapIdx(handle);\n-        if (bitmapIdx == 0) {\n-            byte val = value(memoryMapIdx);\n-            assert val == unusable : String.valueOf(val);\n-            buf.init(this, nioBuffer, handle, runOffset(memoryMapIdx) + offset,\n-                    reqCapacity, runLength(memoryMapIdx), threadCache);\n-        } else {\n-            initBufWithSubpage(buf, nioBuffer, handle, bitmapIdx, reqCapacity, threadCache);\n+        if (nioBuffer != null && cachedNioBuffers != null &&\n+            cachedNioBuffers.size() < PooledByteBufAllocator.DEFAULT_MAX_CACHED_BYTEBUFFERS_PER_CHUNK) {\n+            cachedNioBuffers.offer(nioBuffer);\n         }\n     }\n \n-    void initBufWithSubpage(PooledByteBuf<T> buf, ByteBuffer nioBuffer, long handle, int reqCapacity,\n-                            PoolThreadCache threadCache) {\n-        initBufWithSubpage(buf, nioBuffer, handle, bitmapIdx(handle), reqCapacity, threadCache);\n+    private long collapseRuns(long handle) {\n+        return collapseNext(collapsePast(handle));\n     }\n \n-    private void initBufWithSubpage(PooledByteBuf<T> buf, ByteBuffer nioBuffer,\n-                                    long handle, int bitmapIdx, int reqCapacity, PoolThreadCache threadCache) {\n-        assert bitmapIdx != 0;\n+    private long collapsePast(long handle) {\n+        while (true) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2ab7f9b3f4c803b4c19eb13bc869788771750ce0"}, "originalPosition": 684}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE0MzYxNw==", "bodyText": "same comment as above... consider using for (;;) {....}", "url": "https://github.com/netty/netty/pull/10267#discussion_r446143617", "createdAt": "2020-06-26T12:07:25Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/main/java/io/netty/buffer/PoolChunk.java", "diffHunk": "@@ -222,256 +289,278 @@ private int usage(int freeBytes) {\n         return 100 - freePercentage;\n     }\n \n-    boolean allocate(PooledByteBuf<T> buf, int reqCapacity, int normCapacity, PoolThreadCache threadCache) {\n-        final long handle;\n-        if ((normCapacity & subpageOverflowMask) != 0) { // >= pageSize\n-            handle =  allocateRun(normCapacity);\n+    boolean allocate(PooledByteBuf<T> buf, int reqCapacity, int sizeIdx, PoolThreadCache cache) {\n+        long handle;\n+        if (sizeIdx <= arena.smallMaxSizeIdx) {\n+            // small\n+            handle = allocateSubpage(sizeIdx);\n+            if (handle < 0) {\n+                return false;\n+            }\n+            assert isSubpage(handle);\n         } else {\n-            handle = allocateSubpage(normCapacity);\n+            // normal\n+            // runSize must be multiple of pageSize\n+            int runSize = arena.sizeIdx2size(sizeIdx);\n+            handle = allocateRun(runSize);\n+            if (handle < 0) {\n+                return false;\n+            }\n         }\n \n-        if (handle < 0) {\n-            return false;\n-        }\n-        ByteBuffer nioBuffer = cachedNioBuffers != null ? cachedNioBuffers.pollLast() : null;\n-        initBuf(buf, nioBuffer, handle, reqCapacity, threadCache);\n+        ByteBuffer nioBuffer = cachedNioBuffers != null? cachedNioBuffers.pollLast() : null;\n+        initBuf(buf, nioBuffer, handle, reqCapacity, cache);\n         return true;\n     }\n \n-    /**\n-     * Update method used by allocate\n-     * This is triggered only when a successor is allocated and all its predecessors\n-     * need to update their state\n-     * The minimal depth at which subtree rooted at id has some free space\n-     *\n-     * @param id id\n-     */\n-    private void updateParentsAlloc(int id) {\n-        while (id > 1) {\n-            int parentId = id >>> 1;\n-            byte val1 = value(id);\n-            byte val2 = value(id ^ 1);\n-            byte val = val1 < val2 ? val1 : val2;\n-            setValue(parentId, val);\n-            id = parentId;\n-        }\n-    }\n+    private long allocateRun(int runSize) {\n+        int pages = runSize >> pageShifts;\n+        int pageIdx = arena.pages2pageIdx(pages);\n \n-    /**\n-     * Update method used by free\n-     * This needs to handle the special case when both children are completely free\n-     * in which case parent be directly allocated on request of size = child-size * 2\n-     *\n-     * @param id id\n-     */\n-    private void updateParentsFree(int id) {\n-        int logChild = depth(id) + 1;\n-        while (id > 1) {\n-            int parentId = id >>> 1;\n-            byte val1 = value(id);\n-            byte val2 = value(id ^ 1);\n-            logChild -= 1; // in first iteration equals log, subsequently reduce 1 from logChild as we traverse up\n-\n-            if (val1 == logChild && val2 == logChild) {\n-                setValue(parentId, (byte) (logChild - 1));\n-            } else {\n-                byte val = val1 < val2 ? val1 : val2;\n-                setValue(parentId, val);\n+        synchronized (runsAvail) {\n+            //find first queue which has at least one big enough run\n+            int queueIdx = runFirstBestFit(pageIdx);\n+            if (queueIdx == -1) {\n+                return -1;\n+            }\n+\n+            //get run with min offset in this queue\n+            PriorityQueue<Long> queue = runsAvail[queueIdx];\n+            long handle = queue.poll();\n+\n+            assert !isUsed(handle);\n+\n+            removeAvailRun(queue, handle);\n+\n+            if (handle != -1) {\n+                handle = splitLargeRun(handle, pages);\n             }\n \n-            id = parentId;\n+            freeBytes -= runSize(pageShifts, handle);\n+            return handle;\n         }\n     }\n \n-    /**\n-     * Algorithm to allocate an index in memoryMap when we query for a free node\n-     * at depth d\n-     *\n-     * @param d depth\n-     * @return index in memoryMap\n-     */\n-    private int allocateNode(int d) {\n-        int id = 1;\n-        int initial = - (1 << d); // has last d bits = 0 and rest all = 1\n-        byte val = value(id);\n-        if (val > d) { // unusable\n-            return -1;\n+    private int calculateRunSize(int sizeIdx) {\n+        int maxElements = 1 << pageShifts - SizeClasses.LOG2_QUANTUM;\n+        int runSize = 0;\n+        int nElements;\n+\n+        final int elemSize = arena.sizeIdx2size(sizeIdx);\n+\n+        //find lowest common multiple of pageSize and elemSize\n+        do {\n+            runSize += pageSize;\n+            nElements = runSize / elemSize;\n+        } while (nElements < maxElements && runSize != nElements * elemSize);\n+\n+        while (nElements > maxElements) {\n+            runSize -= pageSize;\n+            nElements = runSize / elemSize;\n         }\n-        while (val < d || (id & initial) == 0) { // id & initial == 1 << d for all ids at depth d, for < d it is 0\n-            id <<= 1;\n-            val = value(id);\n-            if (val > d) {\n-                id ^= 1;\n-                val = value(id);\n+\n+        assert nElements > 0;\n+        assert runSize <= chunkSize;\n+        assert runSize >= elemSize;\n+\n+        return runSize;\n+    }\n+\n+    private int runFirstBestFit(int pageIdx) {\n+        for (int i = pageIdx; i < arena.nPSizes; i++) {\n+            PriorityQueue<Long> queue = runsAvail[i];\n+            if (queue != null && !queue.isEmpty()) {\n+                return i;\n             }\n         }\n-        byte value = value(id);\n-        assert value == d && (id & initial) == 1 << d : String.format(\"val = %d, id & initial = %d, d = %d\",\n-                value, id & initial, d);\n-        setValue(id, unusable); // mark as unusable\n-        updateParentsAlloc(id);\n-        return id;\n+        return -1;\n     }\n \n-    /**\n-     * Allocate a run of pages (>=1)\n-     *\n-     * @param normCapacity normalized capacity\n-     * @return index in memoryMap\n-     */\n-    private long allocateRun(int normCapacity) {\n-        int d = maxOrder - (log2(normCapacity) - pageShifts);\n-        int id = allocateNode(d);\n-        if (id < 0) {\n-            return id;\n+    private long splitLargeRun(long handle, int needPages) {\n+        assert needPages > 0;\n+\n+        int totalPages = runPages(handle);\n+        assert needPages <= totalPages;\n+\n+        int remPages = totalPages - needPages;\n+\n+        if (remPages > 0) {\n+            int runOffset = runOffset(handle);\n+\n+            // keep track of trailing unused pages for later use\n+            int availOffset = runOffset + needPages;\n+            long availRun = toRunHandle(availOffset, remPages, 0);\n+            insertAvailRun(availOffset, remPages, availRun);\n+\n+            // not avail\n+            return toRunHandle(runOffset, needPages, 1);\n         }\n-        freeBytes -= runLength(id);\n-        return id;\n+\n+        //make used\n+        handle |= 1L << ISUSED_SHIFT;\n+        return handle;\n     }\n \n     /**\n-     * Create / initialize a new PoolSubpage of normCapacity\n-     * Any PoolSubpage created / initialized here is added to subpage pool in the PoolArena that owns this PoolChunk\n+     * Create / initialize a new PoolSubpage of normCapacity Any PoolSubpage created / initialized here is added to\n+     * subpage pool in the PoolArena that owns this PoolChunk\n+     *\n+     * @param sizeIdx sizeIdx of normalized size\n      *\n-     * @param normCapacity normalized capacity\n      * @return index in memoryMap\n      */\n-    private long allocateSubpage(int normCapacity) {\n+    private long allocateSubpage(int sizeIdx) {\n         // Obtain the head of the PoolSubPage pool that is owned by the PoolArena and synchronize on it.\n         // This is need as we may add it back and so alter the linked-list structure.\n-        PoolSubpage<T> head = arena.findSubpagePoolHead(normCapacity);\n-        int d = maxOrder; // subpages are only be allocated from pages i.e., leaves\n+        PoolSubpage<T> head = arena.findSubpagePoolHead(sizeIdx);\n         synchronized (head) {\n-            int id = allocateNode(d);\n-            if (id < 0) {\n-                return id;\n+            //allocate a new run\n+            int runSize = calculateRunSize(sizeIdx);\n+            //runSize must be multiples of pageSize\n+            long runHandle = allocateRun(runSize);\n+            if (runHandle < 0) {\n+                return -1;\n             }\n \n-            final PoolSubpage<T>[] subpages = this.subpages;\n-            final int pageSize = this.pageSize;\n+            int runOffset = runOffset(runHandle);\n+            int elemSize = arena.sizeIdx2size(sizeIdx);\n \n-            freeBytes -= pageSize;\n+            PoolSubpage<T> subpage = new PoolSubpage<T>(head, this, pageShifts, runOffset,\n+                               runSize(pageShifts, runHandle), elemSize);\n \n-            int subpageIdx = subpageIdx(id);\n-            PoolSubpage<T> subpage = subpages[subpageIdx];\n-            if (subpage == null) {\n-                subpage = new PoolSubpage<T>(head, this, id, runOffset(id), pageSize, normCapacity);\n-                subpages[subpageIdx] = subpage;\n-            } else {\n-                subpage.init(head, normCapacity);\n-            }\n+            subpages[runOffset] = subpage;\n             return subpage.allocate();\n         }\n     }\n \n     /**\n-     * Free a subpage or a run of pages\n-     * When a subpage is freed from PoolSubpage, it might be added back to subpage pool of the owning PoolArena\n-     * If the subpage pool in PoolArena has at least one other PoolSubpage of given elemSize, we can\n-     * completely free the owning Page so it is available for subsequent allocations\n+     * Free a subpage or a run of pages When a subpage is freed from PoolSubpage, it might be added back to subpage pool\n+     * of the owning PoolArena If the subpage pool in PoolArena has at least one other PoolSubpage of given elemSize, we\n+     * can completely free the owning Page so it is available for subsequent allocations\n      *\n      * @param handle handle to free\n      */\n-    void free(long handle, ByteBuffer nioBuffer) {\n-        int memoryMapIdx = memoryMapIdx(handle);\n-        int bitmapIdx = bitmapIdx(handle);\n+    void free(long handle, int normCapacity, ByteBuffer nioBuffer) {\n+        if (isSubpage(handle)) {\n+            int sizeIdx = arena.size2SizeIdx(normCapacity);\n+            PoolSubpage<T> head = arena.findSubpagePoolHead(sizeIdx);\n \n-        if (bitmapIdx != 0) { // free a subpage\n-            PoolSubpage<T> subpage = subpages[subpageIdx(memoryMapIdx)];\n+            PoolSubpage<T> subpage = subpages[runOffset(handle)];\n             assert subpage != null && subpage.doNotDestroy;\n \n             // Obtain the head of the PoolSubPage pool that is owned by the PoolArena and synchronize on it.\n             // This is need as we may add it back and so alter the linked-list structure.\n-            PoolSubpage<T> head = arena.findSubpagePoolHead(subpage.elemSize);\n             synchronized (head) {\n-                if (subpage.free(head, bitmapIdx & 0x3FFFFFFF)) {\n+                if (subpage.free(head, bitmapIdx(handle))) {\n+                    //the subpage is still used, do not free it\n                     return;\n                 }\n             }\n         }\n-        freeBytes += runLength(memoryMapIdx);\n-        setValue(memoryMapIdx, depth(memoryMapIdx));\n-        updateParentsFree(memoryMapIdx);\n \n-        if (nioBuffer != null && cachedNioBuffers != null &&\n-                cachedNioBuffers.size() < PooledByteBufAllocator.DEFAULT_MAX_CACHED_BYTEBUFFERS_PER_CHUNK) {\n-            cachedNioBuffers.offer(nioBuffer);\n+        //start free run\n+        int pages = runPages(handle);\n+\n+        synchronized (runsAvail) {\n+            // collapse continuous runs, successfully collapsed runs\n+            // will be removed from runsAvail and runsAvailMap\n+            long finalRun = collapseRuns(handle);\n+\n+            //set run as not used\n+            finalRun &= ~(1L << ISUSED_SHIFT);\n+            //if it is a subpage, set it to run\n+            finalRun &= ~(1L << ISSUBPAGE_SHIFT);\n+\n+            insertAvailRun(runOffset(finalRun), runPages(finalRun), finalRun);\n+            freeBytes += pages << pageShifts;\n         }\n-    }\n \n-    void initBuf(PooledByteBuf<T> buf, ByteBuffer nioBuffer, long handle, int reqCapacity,\n-                 PoolThreadCache threadCache) {\n-        int memoryMapIdx = memoryMapIdx(handle);\n-        int bitmapIdx = bitmapIdx(handle);\n-        if (bitmapIdx == 0) {\n-            byte val = value(memoryMapIdx);\n-            assert val == unusable : String.valueOf(val);\n-            buf.init(this, nioBuffer, handle, runOffset(memoryMapIdx) + offset,\n-                    reqCapacity, runLength(memoryMapIdx), threadCache);\n-        } else {\n-            initBufWithSubpage(buf, nioBuffer, handle, bitmapIdx, reqCapacity, threadCache);\n+        if (nioBuffer != null && cachedNioBuffers != null &&\n+            cachedNioBuffers.size() < PooledByteBufAllocator.DEFAULT_MAX_CACHED_BYTEBUFFERS_PER_CHUNK) {\n+            cachedNioBuffers.offer(nioBuffer);\n         }\n     }\n \n-    void initBufWithSubpage(PooledByteBuf<T> buf, ByteBuffer nioBuffer, long handle, int reqCapacity,\n-                            PoolThreadCache threadCache) {\n-        initBufWithSubpage(buf, nioBuffer, handle, bitmapIdx(handle), reqCapacity, threadCache);\n+    private long collapseRuns(long handle) {\n+        return collapseNext(collapsePast(handle));\n     }\n \n-    private void initBufWithSubpage(PooledByteBuf<T> buf, ByteBuffer nioBuffer,\n-                                    long handle, int bitmapIdx, int reqCapacity, PoolThreadCache threadCache) {\n-        assert bitmapIdx != 0;\n+    private long collapsePast(long handle) {\n+        while (true) {\n+            int runOffset = runOffset(handle);\n+            int runPages = runPages(handle);\n \n-        int memoryMapIdx = memoryMapIdx(handle);\n+            Long pastRun = getAvailRunByOffset(runOffset - 1);\n+            if (pastRun == null) {\n+                return handle;\n+            }\n \n-        PoolSubpage<T> subpage = subpages[subpageIdx(memoryMapIdx)];\n-        assert subpage.doNotDestroy;\n-        assert reqCapacity <= subpage.elemSize;\n+            int pastOffset = runOffset(pastRun);\n+            int pastPages = runPages(pastRun);\n \n-        buf.init(\n-            this, nioBuffer, handle,\n-            runOffset(memoryMapIdx) + (bitmapIdx & 0x3FFFFFFF) * subpage.elemSize + offset,\n-                reqCapacity, subpage.elemSize, threadCache);\n+            //is continuous\n+            if (pastRun != handle && pastOffset + pastPages == runOffset) {\n+                //remove past run\n+                removeAvailRun(pastRun);\n+                handle = toRunHandle(pastOffset, pastPages + runPages, 0);\n+            } else {\n+                return handle;\n+            }\n+        }\n     }\n \n-    private byte value(int id) {\n-        return memoryMap[id];\n-    }\n+    private long collapseNext(long handle) {\n+        while (true) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2ab7f9b3f4c803b4c19eb13bc869788771750ce0"}, "originalPosition": 719}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE0Mzk4OA==", "bodyText": "I think we can't do this as it would be a breaking change.", "url": "https://github.com/netty/netty/pull/10267#discussion_r446143988", "createdAt": "2020-06-26T12:08:24Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/main/java/io/netty/buffer/PoolSubpageMetric.java", "diffHunk": "@@ -36,8 +36,13 @@\n     int elementSize();\n \n     /**\n-     * Return the size (in bytes) of this page.\n+     * Return the page size (in bytes) of this page.\n      */\n     int pageSize();\n+\n+    /**\n+     * Return the size (in bytes) of this subpage.\n+     */\n+    int runSize();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2ab7f9b3f4c803b4c19eb13bc869788771750ce0"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE0NDMzMQ==", "bodyText": "can this be package-private ?", "url": "https://github.com/netty/netty/pull/10267#discussion_r446144331", "createdAt": "2020-06-26T12:09:14Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/main/java/io/netty/buffer/SizeClasses.java", "diffHunk": "@@ -0,0 +1,403 @@\n+/*\n+ * Copyright 2020 The Netty Project\n+ *\n+ * The Netty Project licenses this file to you under the Apache License,\n+ * version 2.0 (the \"License\"); you may not use this file except in compliance\n+ * with the License. You may obtain a copy of the License at:\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package io.netty.buffer;\n+\n+import static io.netty.buffer.PoolThreadCache.*;\n+\n+/**\n+ * SizeClasses requires {@code pageShifts} to be defined prior to inclusion,\n+ * and it in turn defines:\n+ * <p>\n+ *   LOG2_SIZE_CLASS_GROUP: Log of size class count for each size doubling.\n+ *   LOG2_MAX_LOOKUP_SIZE: Log of max size class in the lookup table.\n+ *   sizeClasses: Complete table of [index, log2Group, log2Delta, nDelta, isMultiPageSize,\n+ *                 isSubPage, log2DeltaLookup] tuples.\n+ *     index: Size class index.\n+ *     log2Group: Log of group base size (no deltas added).\n+ *     log2Delta: Log of delta to previous size class.\n+ *     nDelta: Delta multiplier.\n+ *     isMultiPageSize: 'yes' if a multiple of the page size, 'no' otherwise.\n+ *     isSubPage: 'yes' if a subpage size class, 'no' otherwise.\n+ *     log2DeltaLookup: Same as log2Delta if a lookup table size class, 'no'\n+ *                      otherwise.\n+ * <p>\n+ *   nSubpages: Number of subpages size classes.\n+ *   nSizes: Number of size classes.\n+ *   nPSizes: Number of size classes that are multiples of pageSize.\n+ *\n+ *   smallMaxSizeIdx: Maximum small size class index.\n+ *\n+ *   lookupMaxclass: Maximum size class included in lookup table.\n+ *   log2NormalMinClass: Log of minimum normal size class.\n+ * <p>\n+ *   The first size class and spacing are 1 << LOG2_QUANTUM.\n+ *   Each group has 1 << LOG2_SIZE_CLASS_GROUP of size classes.\n+ *\n+ *   size = 1 << log2Group + nDelta * (1 << log2Delta)\n+ *\n+ *   The first size class has an unusual encoding, because the size has to be\n+ *   split between group and delta*nDelta.\n+ *\n+ *   If pageShift = 13, sizeClasses looks like this:\n+ *\n+ *   (index, log2Group, log2Delta, nDelta, isMultiPageSize, isSubPage, log2DeltaLookup)\n+ * <p>\n+ *   ( 0,     4,        4,         0,       no,             yes,        4)\n+ *   ( 1,     4,        4,         1,       no,             yes,        4)\n+ *   ( 2,     4,        4,         2,       no,             yes,        4)\n+ *   ( 3,     4,        4,         3,       no,             yes,        4)\n+ * <p>\n+ *   ( 4,     6,        4,         1,       no,             yes,        4)\n+ *   ( 5,     6,        4,         2,       no,             yes,        4)\n+ *   ( 6,     6,        4,         3,       no,             yes,        4)\n+ *   ( 7,     6,        4,         4,       no,             yes,        4)\n+ * <p>\n+ *   ( 8,     7,        5,         1,       no,             yes,        5)\n+ *   ( 9,     7,        5,         2,       no,             yes,        5)\n+ *   ( 10,    7,        5,         3,       no,             yes,        5)\n+ *   ( 11,    7,        5,         4,       no,             yes,        5)\n+ *   ...\n+ *   ...\n+ *   ( 72,    23,       21,        1,       yes,            no,        no)\n+ *   ( 73,    23,       21,        2,       yes,            no,        no)\n+ *   ( 74,    23,       21,        3,       yes,            no,        no)\n+ *   ( 75,    23,       21,        4,       yes,            no,        no)\n+ * <p>\n+ *   ( 76,    24,       22,        1,       yes,            no,        no)\n+ */\n+public abstract class SizeClasses implements SizeClassesMetric {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2ab7f9b3f4c803b4c19eb13bc869788771750ce0"}, "originalPosition": 81}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE0NDU5NQ==", "bodyText": "please use one declaration per line.", "url": "https://github.com/netty/netty/pull/10267#discussion_r446144595", "createdAt": "2020-06-26T12:09:46Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/main/java/io/netty/buffer/SizeClasses.java", "diffHunk": "@@ -0,0 +1,403 @@\n+/*\n+ * Copyright 2020 The Netty Project\n+ *\n+ * The Netty Project licenses this file to you under the Apache License,\n+ * version 2.0 (the \"License\"); you may not use this file except in compliance\n+ * with the License. You may obtain a copy of the License at:\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package io.netty.buffer;\n+\n+import static io.netty.buffer.PoolThreadCache.*;\n+\n+/**\n+ * SizeClasses requires {@code pageShifts} to be defined prior to inclusion,\n+ * and it in turn defines:\n+ * <p>\n+ *   LOG2_SIZE_CLASS_GROUP: Log of size class count for each size doubling.\n+ *   LOG2_MAX_LOOKUP_SIZE: Log of max size class in the lookup table.\n+ *   sizeClasses: Complete table of [index, log2Group, log2Delta, nDelta, isMultiPageSize,\n+ *                 isSubPage, log2DeltaLookup] tuples.\n+ *     index: Size class index.\n+ *     log2Group: Log of group base size (no deltas added).\n+ *     log2Delta: Log of delta to previous size class.\n+ *     nDelta: Delta multiplier.\n+ *     isMultiPageSize: 'yes' if a multiple of the page size, 'no' otherwise.\n+ *     isSubPage: 'yes' if a subpage size class, 'no' otherwise.\n+ *     log2DeltaLookup: Same as log2Delta if a lookup table size class, 'no'\n+ *                      otherwise.\n+ * <p>\n+ *   nSubpages: Number of subpages size classes.\n+ *   nSizes: Number of size classes.\n+ *   nPSizes: Number of size classes that are multiples of pageSize.\n+ *\n+ *   smallMaxSizeIdx: Maximum small size class index.\n+ *\n+ *   lookupMaxclass: Maximum size class included in lookup table.\n+ *   log2NormalMinClass: Log of minimum normal size class.\n+ * <p>\n+ *   The first size class and spacing are 1 << LOG2_QUANTUM.\n+ *   Each group has 1 << LOG2_SIZE_CLASS_GROUP of size classes.\n+ *\n+ *   size = 1 << log2Group + nDelta * (1 << log2Delta)\n+ *\n+ *   The first size class has an unusual encoding, because the size has to be\n+ *   split between group and delta*nDelta.\n+ *\n+ *   If pageShift = 13, sizeClasses looks like this:\n+ *\n+ *   (index, log2Group, log2Delta, nDelta, isMultiPageSize, isSubPage, log2DeltaLookup)\n+ * <p>\n+ *   ( 0,     4,        4,         0,       no,             yes,        4)\n+ *   ( 1,     4,        4,         1,       no,             yes,        4)\n+ *   ( 2,     4,        4,         2,       no,             yes,        4)\n+ *   ( 3,     4,        4,         3,       no,             yes,        4)\n+ * <p>\n+ *   ( 4,     6,        4,         1,       no,             yes,        4)\n+ *   ( 5,     6,        4,         2,       no,             yes,        4)\n+ *   ( 6,     6,        4,         3,       no,             yes,        4)\n+ *   ( 7,     6,        4,         4,       no,             yes,        4)\n+ * <p>\n+ *   ( 8,     7,        5,         1,       no,             yes,        5)\n+ *   ( 9,     7,        5,         2,       no,             yes,        5)\n+ *   ( 10,    7,        5,         3,       no,             yes,        5)\n+ *   ( 11,    7,        5,         4,       no,             yes,        5)\n+ *   ...\n+ *   ...\n+ *   ( 72,    23,       21,        1,       yes,            no,        no)\n+ *   ( 73,    23,       21,        2,       yes,            no,        no)\n+ *   ( 74,    23,       21,        3,       yes,            no,        no)\n+ *   ( 75,    23,       21,        4,       yes,            no,        no)\n+ * <p>\n+ *   ( 76,    24,       22,        1,       yes,            no,        no)\n+ */\n+public abstract class SizeClasses implements SizeClassesMetric {\n+\n+    static final int LOG2_QUANTUM = 4;\n+\n+    private static final int LOG2_SIZE_CLASS_GROUP = 2;\n+    private static final int LOG2_MAX_LOOKUP_SIZE = 12;\n+\n+    private static final int INDEX_IDX = 0;\n+    private static final int LOG2GROUP_IDX = 1;\n+    private static final int LOG2DELTA_IDX = 2;\n+    private static final int NDELTA_IDX = 3;\n+    private static final int PAGESIZE_IDX = 4;\n+    private static final int SUBPAGE_IDX = 5;\n+    private static final int LOG2_DELTA_LOOKUP_IDX = 6;\n+\n+    private static final byte no = 0, yes = 1;\n+\n+    protected SizeClasses(int pageSize, int pageShifts, int chunkSize, int directMemoryCacheAlignment) {\n+        this.pageSize = pageSize;\n+        this.pageShifts = pageShifts;\n+        this.chunkSize = chunkSize;\n+        this.directMemoryCacheAlignment = directMemoryCacheAlignment;\n+\n+        int group = log2(chunkSize) + 1 - LOG2_QUANTUM;\n+        sizeClasses = new short[group << LOG2_SIZE_CLASS_GROUP][7];\n+\n+        //generate size classes\n+        sizeClasses();\n+        //generate lookup table\n+        idx2SizeTab();\n+        size2idxTab();\n+    }\n+\n+    protected final int pageSize;\n+    protected final int pageShifts;\n+    protected final int chunkSize;\n+    protected final int directMemoryCacheAlignment;\n+\n+    int nSizes, nSubpages, nPSizes;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2ab7f9b3f4c803b4c19eb13bc869788771750ce0"}, "originalPosition": 119}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE0NTUzNA==", "bodyText": "can me merge this into the constructor or mark it as static and call it from the constructor and just pass in sizeIdx2sizeTab and pageIdx2sizeTab  ? This way we could define these two final and so the JVM / JIT may be able to optimise access.", "url": "https://github.com/netty/netty/pull/10267#discussion_r446145534", "createdAt": "2020-06-26T12:12:02Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/main/java/io/netty/buffer/SizeClasses.java", "diffHunk": "@@ -0,0 +1,403 @@\n+/*\n+ * Copyright 2020 The Netty Project\n+ *\n+ * The Netty Project licenses this file to you under the Apache License,\n+ * version 2.0 (the \"License\"); you may not use this file except in compliance\n+ * with the License. You may obtain a copy of the License at:\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package io.netty.buffer;\n+\n+import static io.netty.buffer.PoolThreadCache.*;\n+\n+/**\n+ * SizeClasses requires {@code pageShifts} to be defined prior to inclusion,\n+ * and it in turn defines:\n+ * <p>\n+ *   LOG2_SIZE_CLASS_GROUP: Log of size class count for each size doubling.\n+ *   LOG2_MAX_LOOKUP_SIZE: Log of max size class in the lookup table.\n+ *   sizeClasses: Complete table of [index, log2Group, log2Delta, nDelta, isMultiPageSize,\n+ *                 isSubPage, log2DeltaLookup] tuples.\n+ *     index: Size class index.\n+ *     log2Group: Log of group base size (no deltas added).\n+ *     log2Delta: Log of delta to previous size class.\n+ *     nDelta: Delta multiplier.\n+ *     isMultiPageSize: 'yes' if a multiple of the page size, 'no' otherwise.\n+ *     isSubPage: 'yes' if a subpage size class, 'no' otherwise.\n+ *     log2DeltaLookup: Same as log2Delta if a lookup table size class, 'no'\n+ *                      otherwise.\n+ * <p>\n+ *   nSubpages: Number of subpages size classes.\n+ *   nSizes: Number of size classes.\n+ *   nPSizes: Number of size classes that are multiples of pageSize.\n+ *\n+ *   smallMaxSizeIdx: Maximum small size class index.\n+ *\n+ *   lookupMaxclass: Maximum size class included in lookup table.\n+ *   log2NormalMinClass: Log of minimum normal size class.\n+ * <p>\n+ *   The first size class and spacing are 1 << LOG2_QUANTUM.\n+ *   Each group has 1 << LOG2_SIZE_CLASS_GROUP of size classes.\n+ *\n+ *   size = 1 << log2Group + nDelta * (1 << log2Delta)\n+ *\n+ *   The first size class has an unusual encoding, because the size has to be\n+ *   split between group and delta*nDelta.\n+ *\n+ *   If pageShift = 13, sizeClasses looks like this:\n+ *\n+ *   (index, log2Group, log2Delta, nDelta, isMultiPageSize, isSubPage, log2DeltaLookup)\n+ * <p>\n+ *   ( 0,     4,        4,         0,       no,             yes,        4)\n+ *   ( 1,     4,        4,         1,       no,             yes,        4)\n+ *   ( 2,     4,        4,         2,       no,             yes,        4)\n+ *   ( 3,     4,        4,         3,       no,             yes,        4)\n+ * <p>\n+ *   ( 4,     6,        4,         1,       no,             yes,        4)\n+ *   ( 5,     6,        4,         2,       no,             yes,        4)\n+ *   ( 6,     6,        4,         3,       no,             yes,        4)\n+ *   ( 7,     6,        4,         4,       no,             yes,        4)\n+ * <p>\n+ *   ( 8,     7,        5,         1,       no,             yes,        5)\n+ *   ( 9,     7,        5,         2,       no,             yes,        5)\n+ *   ( 10,    7,        5,         3,       no,             yes,        5)\n+ *   ( 11,    7,        5,         4,       no,             yes,        5)\n+ *   ...\n+ *   ...\n+ *   ( 72,    23,       21,        1,       yes,            no,        no)\n+ *   ( 73,    23,       21,        2,       yes,            no,        no)\n+ *   ( 74,    23,       21,        3,       yes,            no,        no)\n+ *   ( 75,    23,       21,        4,       yes,            no,        no)\n+ * <p>\n+ *   ( 76,    24,       22,        1,       yes,            no,        no)\n+ */\n+public abstract class SizeClasses implements SizeClassesMetric {\n+\n+    static final int LOG2_QUANTUM = 4;\n+\n+    private static final int LOG2_SIZE_CLASS_GROUP = 2;\n+    private static final int LOG2_MAX_LOOKUP_SIZE = 12;\n+\n+    private static final int INDEX_IDX = 0;\n+    private static final int LOG2GROUP_IDX = 1;\n+    private static final int LOG2DELTA_IDX = 2;\n+    private static final int NDELTA_IDX = 3;\n+    private static final int PAGESIZE_IDX = 4;\n+    private static final int SUBPAGE_IDX = 5;\n+    private static final int LOG2_DELTA_LOOKUP_IDX = 6;\n+\n+    private static final byte no = 0, yes = 1;\n+\n+    protected SizeClasses(int pageSize, int pageShifts, int chunkSize, int directMemoryCacheAlignment) {\n+        this.pageSize = pageSize;\n+        this.pageShifts = pageShifts;\n+        this.chunkSize = chunkSize;\n+        this.directMemoryCacheAlignment = directMemoryCacheAlignment;\n+\n+        int group = log2(chunkSize) + 1 - LOG2_QUANTUM;\n+        sizeClasses = new short[group << LOG2_SIZE_CLASS_GROUP][7];\n+\n+        //generate size classes\n+        sizeClasses();\n+        //generate lookup table\n+        idx2SizeTab();\n+        size2idxTab();\n+    }\n+\n+    protected final int pageSize;\n+    protected final int pageShifts;\n+    protected final int chunkSize;\n+    protected final int directMemoryCacheAlignment;\n+\n+    int nSizes, nSubpages, nPSizes;\n+\n+    int smallMaxSizeIdx;\n+\n+    private int lookupMaxSize;\n+\n+    private final short[][] sizeClasses;\n+\n+    private int[] pageIdx2sizeTab;\n+\n+    // lookup table for sizeIdx <= smallMaxSizeIdx\n+    private int[] sizeIdx2sizeTab;\n+\n+    // lookup table used for size <= lookupMaxclass\n+    // spacing is 1 << LOG2_QUANTUM, so the size of array is lookupMaxclass >> LOG2_QUANTUM\n+    private int[] size2idxTab;\n+\n+    private void sizeClasses() {\n+        int normalMaxSize = -1;\n+\n+        int index = 0;\n+        int size = 0;\n+\n+        int log2Group = LOG2_QUANTUM;\n+        int log2Delta = LOG2_QUANTUM;\n+        int ndeltaLimit = 1 << LOG2_SIZE_CLASS_GROUP;\n+\n+        //First small group, nDelta start at 0.\n+        //first size class is 1 << LOG2_QUANTUM\n+        int nDelta = 0;\n+        while (nDelta < ndeltaLimit) {\n+            size = sizeClass(index++, log2Group, log2Delta, nDelta++);\n+        }\n+        log2Group += LOG2_SIZE_CLASS_GROUP;\n+\n+        //All remaining groups, nDelta start at 1.\n+        while (size < chunkSize) {\n+            nDelta = 1;\n+\n+            while (nDelta <= ndeltaLimit && size < chunkSize) {\n+                size = sizeClass(index++, log2Group, log2Delta, nDelta++);\n+                normalMaxSize = size;\n+            }\n+\n+            log2Group++;\n+            log2Delta++;\n+        }\n+\n+        //chunkSize must be normalMaxSize\n+        assert chunkSize == normalMaxSize;\n+\n+        nSizes = index;\n+    }\n+\n+    //calculate size class\n+    private int sizeClass(int index, int log2Group, int log2Delta, int nDelta) {\n+        short isMultiPageSize;\n+        if (log2Delta >= pageShifts) {\n+            isMultiPageSize = yes;\n+        } else {\n+            int pageSize = 1 << pageShifts;\n+            int size = (1 << log2Group) + (1 << log2Delta) * nDelta;\n+\n+            isMultiPageSize = size == size / pageSize * pageSize? yes : no;\n+        }\n+\n+        int log2Ndelta = nDelta == 0? 0 : log2(nDelta);\n+\n+        byte remove = 1 << log2Ndelta < nDelta? yes : no;\n+\n+        int log2Size = log2Delta + log2Ndelta == log2Group? log2Group + 1 : log2Group;\n+        if (log2Size == log2Group) {\n+            remove = yes;\n+        }\n+\n+        short isSubpage = log2Size < pageShifts + LOG2_SIZE_CLASS_GROUP? yes : no;\n+\n+        int log2DeltaLookup = log2Size < LOG2_MAX_LOOKUP_SIZE ||\n+                              log2Size == LOG2_MAX_LOOKUP_SIZE && remove == no\n+                ? log2Delta : no;\n+\n+        short[] sz = {\n+                (short) index, (short) log2Group, (short) log2Delta,\n+                (short) nDelta, isMultiPageSize, isSubpage, (short) log2DeltaLookup\n+        };\n+\n+        sizeClasses[index] = sz;\n+        int size = (1 << log2Group) + (nDelta << log2Delta);\n+\n+        if (sz[PAGESIZE_IDX] == yes) {\n+            nPSizes++;\n+        }\n+        if (sz[SUBPAGE_IDX] == yes) {\n+            nSubpages++;\n+            smallMaxSizeIdx = index;\n+        }\n+        if (sz[LOG2_DELTA_LOOKUP_IDX] != no) {\n+            lookupMaxSize = size;\n+        }\n+        return size;\n+    }\n+\n+    private void idx2SizeTab() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2ab7f9b3f4c803b4c19eb13bc869788771750ce0"}, "originalPosition": 221}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE0NjI5OQ==", "bodyText": "We should inline this method into the constructor to be able to define nSizes final", "url": "https://github.com/netty/netty/pull/10267#discussion_r446146299", "createdAt": "2020-06-26T12:13:46Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/main/java/io/netty/buffer/SizeClasses.java", "diffHunk": "@@ -0,0 +1,403 @@\n+/*\n+ * Copyright 2020 The Netty Project\n+ *\n+ * The Netty Project licenses this file to you under the Apache License,\n+ * version 2.0 (the \"License\"); you may not use this file except in compliance\n+ * with the License. You may obtain a copy of the License at:\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package io.netty.buffer;\n+\n+import static io.netty.buffer.PoolThreadCache.*;\n+\n+/**\n+ * SizeClasses requires {@code pageShifts} to be defined prior to inclusion,\n+ * and it in turn defines:\n+ * <p>\n+ *   LOG2_SIZE_CLASS_GROUP: Log of size class count for each size doubling.\n+ *   LOG2_MAX_LOOKUP_SIZE: Log of max size class in the lookup table.\n+ *   sizeClasses: Complete table of [index, log2Group, log2Delta, nDelta, isMultiPageSize,\n+ *                 isSubPage, log2DeltaLookup] tuples.\n+ *     index: Size class index.\n+ *     log2Group: Log of group base size (no deltas added).\n+ *     log2Delta: Log of delta to previous size class.\n+ *     nDelta: Delta multiplier.\n+ *     isMultiPageSize: 'yes' if a multiple of the page size, 'no' otherwise.\n+ *     isSubPage: 'yes' if a subpage size class, 'no' otherwise.\n+ *     log2DeltaLookup: Same as log2Delta if a lookup table size class, 'no'\n+ *                      otherwise.\n+ * <p>\n+ *   nSubpages: Number of subpages size classes.\n+ *   nSizes: Number of size classes.\n+ *   nPSizes: Number of size classes that are multiples of pageSize.\n+ *\n+ *   smallMaxSizeIdx: Maximum small size class index.\n+ *\n+ *   lookupMaxclass: Maximum size class included in lookup table.\n+ *   log2NormalMinClass: Log of minimum normal size class.\n+ * <p>\n+ *   The first size class and spacing are 1 << LOG2_QUANTUM.\n+ *   Each group has 1 << LOG2_SIZE_CLASS_GROUP of size classes.\n+ *\n+ *   size = 1 << log2Group + nDelta * (1 << log2Delta)\n+ *\n+ *   The first size class has an unusual encoding, because the size has to be\n+ *   split between group and delta*nDelta.\n+ *\n+ *   If pageShift = 13, sizeClasses looks like this:\n+ *\n+ *   (index, log2Group, log2Delta, nDelta, isMultiPageSize, isSubPage, log2DeltaLookup)\n+ * <p>\n+ *   ( 0,     4,        4,         0,       no,             yes,        4)\n+ *   ( 1,     4,        4,         1,       no,             yes,        4)\n+ *   ( 2,     4,        4,         2,       no,             yes,        4)\n+ *   ( 3,     4,        4,         3,       no,             yes,        4)\n+ * <p>\n+ *   ( 4,     6,        4,         1,       no,             yes,        4)\n+ *   ( 5,     6,        4,         2,       no,             yes,        4)\n+ *   ( 6,     6,        4,         3,       no,             yes,        4)\n+ *   ( 7,     6,        4,         4,       no,             yes,        4)\n+ * <p>\n+ *   ( 8,     7,        5,         1,       no,             yes,        5)\n+ *   ( 9,     7,        5,         2,       no,             yes,        5)\n+ *   ( 10,    7,        5,         3,       no,             yes,        5)\n+ *   ( 11,    7,        5,         4,       no,             yes,        5)\n+ *   ...\n+ *   ...\n+ *   ( 72,    23,       21,        1,       yes,            no,        no)\n+ *   ( 73,    23,       21,        2,       yes,            no,        no)\n+ *   ( 74,    23,       21,        3,       yes,            no,        no)\n+ *   ( 75,    23,       21,        4,       yes,            no,        no)\n+ * <p>\n+ *   ( 76,    24,       22,        1,       yes,            no,        no)\n+ */\n+public abstract class SizeClasses implements SizeClassesMetric {\n+\n+    static final int LOG2_QUANTUM = 4;\n+\n+    private static final int LOG2_SIZE_CLASS_GROUP = 2;\n+    private static final int LOG2_MAX_LOOKUP_SIZE = 12;\n+\n+    private static final int INDEX_IDX = 0;\n+    private static final int LOG2GROUP_IDX = 1;\n+    private static final int LOG2DELTA_IDX = 2;\n+    private static final int NDELTA_IDX = 3;\n+    private static final int PAGESIZE_IDX = 4;\n+    private static final int SUBPAGE_IDX = 5;\n+    private static final int LOG2_DELTA_LOOKUP_IDX = 6;\n+\n+    private static final byte no = 0, yes = 1;\n+\n+    protected SizeClasses(int pageSize, int pageShifts, int chunkSize, int directMemoryCacheAlignment) {\n+        this.pageSize = pageSize;\n+        this.pageShifts = pageShifts;\n+        this.chunkSize = chunkSize;\n+        this.directMemoryCacheAlignment = directMemoryCacheAlignment;\n+\n+        int group = log2(chunkSize) + 1 - LOG2_QUANTUM;\n+        sizeClasses = new short[group << LOG2_SIZE_CLASS_GROUP][7];\n+\n+        //generate size classes\n+        sizeClasses();\n+        //generate lookup table\n+        idx2SizeTab();\n+        size2idxTab();\n+    }\n+\n+    protected final int pageSize;\n+    protected final int pageShifts;\n+    protected final int chunkSize;\n+    protected final int directMemoryCacheAlignment;\n+\n+    int nSizes, nSubpages, nPSizes;\n+\n+    int smallMaxSizeIdx;\n+\n+    private int lookupMaxSize;\n+\n+    private final short[][] sizeClasses;\n+\n+    private int[] pageIdx2sizeTab;\n+\n+    // lookup table for sizeIdx <= smallMaxSizeIdx\n+    private int[] sizeIdx2sizeTab;\n+\n+    // lookup table used for size <= lookupMaxclass\n+    // spacing is 1 << LOG2_QUANTUM, so the size of array is lookupMaxclass >> LOG2_QUANTUM\n+    private int[] size2idxTab;\n+\n+    private void sizeClasses() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2ab7f9b3f4c803b4c19eb13bc869788771750ce0"}, "originalPosition": 136}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjE0NjU1Mw==", "bodyText": "we should merge this code into the constructor to be able to define size2idxTab as final", "url": "https://github.com/netty/netty/pull/10267#discussion_r446146553", "createdAt": "2020-06-26T12:14:21Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/main/java/io/netty/buffer/SizeClasses.java", "diffHunk": "@@ -0,0 +1,403 @@\n+/*\n+ * Copyright 2020 The Netty Project\n+ *\n+ * The Netty Project licenses this file to you under the Apache License,\n+ * version 2.0 (the \"License\"); you may not use this file except in compliance\n+ * with the License. You may obtain a copy of the License at:\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package io.netty.buffer;\n+\n+import static io.netty.buffer.PoolThreadCache.*;\n+\n+/**\n+ * SizeClasses requires {@code pageShifts} to be defined prior to inclusion,\n+ * and it in turn defines:\n+ * <p>\n+ *   LOG2_SIZE_CLASS_GROUP: Log of size class count for each size doubling.\n+ *   LOG2_MAX_LOOKUP_SIZE: Log of max size class in the lookup table.\n+ *   sizeClasses: Complete table of [index, log2Group, log2Delta, nDelta, isMultiPageSize,\n+ *                 isSubPage, log2DeltaLookup] tuples.\n+ *     index: Size class index.\n+ *     log2Group: Log of group base size (no deltas added).\n+ *     log2Delta: Log of delta to previous size class.\n+ *     nDelta: Delta multiplier.\n+ *     isMultiPageSize: 'yes' if a multiple of the page size, 'no' otherwise.\n+ *     isSubPage: 'yes' if a subpage size class, 'no' otherwise.\n+ *     log2DeltaLookup: Same as log2Delta if a lookup table size class, 'no'\n+ *                      otherwise.\n+ * <p>\n+ *   nSubpages: Number of subpages size classes.\n+ *   nSizes: Number of size classes.\n+ *   nPSizes: Number of size classes that are multiples of pageSize.\n+ *\n+ *   smallMaxSizeIdx: Maximum small size class index.\n+ *\n+ *   lookupMaxclass: Maximum size class included in lookup table.\n+ *   log2NormalMinClass: Log of minimum normal size class.\n+ * <p>\n+ *   The first size class and spacing are 1 << LOG2_QUANTUM.\n+ *   Each group has 1 << LOG2_SIZE_CLASS_GROUP of size classes.\n+ *\n+ *   size = 1 << log2Group + nDelta * (1 << log2Delta)\n+ *\n+ *   The first size class has an unusual encoding, because the size has to be\n+ *   split between group and delta*nDelta.\n+ *\n+ *   If pageShift = 13, sizeClasses looks like this:\n+ *\n+ *   (index, log2Group, log2Delta, nDelta, isMultiPageSize, isSubPage, log2DeltaLookup)\n+ * <p>\n+ *   ( 0,     4,        4,         0,       no,             yes,        4)\n+ *   ( 1,     4,        4,         1,       no,             yes,        4)\n+ *   ( 2,     4,        4,         2,       no,             yes,        4)\n+ *   ( 3,     4,        4,         3,       no,             yes,        4)\n+ * <p>\n+ *   ( 4,     6,        4,         1,       no,             yes,        4)\n+ *   ( 5,     6,        4,         2,       no,             yes,        4)\n+ *   ( 6,     6,        4,         3,       no,             yes,        4)\n+ *   ( 7,     6,        4,         4,       no,             yes,        4)\n+ * <p>\n+ *   ( 8,     7,        5,         1,       no,             yes,        5)\n+ *   ( 9,     7,        5,         2,       no,             yes,        5)\n+ *   ( 10,    7,        5,         3,       no,             yes,        5)\n+ *   ( 11,    7,        5,         4,       no,             yes,        5)\n+ *   ...\n+ *   ...\n+ *   ( 72,    23,       21,        1,       yes,            no,        no)\n+ *   ( 73,    23,       21,        2,       yes,            no,        no)\n+ *   ( 74,    23,       21,        3,       yes,            no,        no)\n+ *   ( 75,    23,       21,        4,       yes,            no,        no)\n+ * <p>\n+ *   ( 76,    24,       22,        1,       yes,            no,        no)\n+ */\n+public abstract class SizeClasses implements SizeClassesMetric {\n+\n+    static final int LOG2_QUANTUM = 4;\n+\n+    private static final int LOG2_SIZE_CLASS_GROUP = 2;\n+    private static final int LOG2_MAX_LOOKUP_SIZE = 12;\n+\n+    private static final int INDEX_IDX = 0;\n+    private static final int LOG2GROUP_IDX = 1;\n+    private static final int LOG2DELTA_IDX = 2;\n+    private static final int NDELTA_IDX = 3;\n+    private static final int PAGESIZE_IDX = 4;\n+    private static final int SUBPAGE_IDX = 5;\n+    private static final int LOG2_DELTA_LOOKUP_IDX = 6;\n+\n+    private static final byte no = 0, yes = 1;\n+\n+    protected SizeClasses(int pageSize, int pageShifts, int chunkSize, int directMemoryCacheAlignment) {\n+        this.pageSize = pageSize;\n+        this.pageShifts = pageShifts;\n+        this.chunkSize = chunkSize;\n+        this.directMemoryCacheAlignment = directMemoryCacheAlignment;\n+\n+        int group = log2(chunkSize) + 1 - LOG2_QUANTUM;\n+        sizeClasses = new short[group << LOG2_SIZE_CLASS_GROUP][7];\n+\n+        //generate size classes\n+        sizeClasses();\n+        //generate lookup table\n+        idx2SizeTab();\n+        size2idxTab();\n+    }\n+\n+    protected final int pageSize;\n+    protected final int pageShifts;\n+    protected final int chunkSize;\n+    protected final int directMemoryCacheAlignment;\n+\n+    int nSizes, nSubpages, nPSizes;\n+\n+    int smallMaxSizeIdx;\n+\n+    private int lookupMaxSize;\n+\n+    private final short[][] sizeClasses;\n+\n+    private int[] pageIdx2sizeTab;\n+\n+    // lookup table for sizeIdx <= smallMaxSizeIdx\n+    private int[] sizeIdx2sizeTab;\n+\n+    // lookup table used for size <= lookupMaxclass\n+    // spacing is 1 << LOG2_QUANTUM, so the size of array is lookupMaxclass >> LOG2_QUANTUM\n+    private int[] size2idxTab;\n+\n+    private void sizeClasses() {\n+        int normalMaxSize = -1;\n+\n+        int index = 0;\n+        int size = 0;\n+\n+        int log2Group = LOG2_QUANTUM;\n+        int log2Delta = LOG2_QUANTUM;\n+        int ndeltaLimit = 1 << LOG2_SIZE_CLASS_GROUP;\n+\n+        //First small group, nDelta start at 0.\n+        //first size class is 1 << LOG2_QUANTUM\n+        int nDelta = 0;\n+        while (nDelta < ndeltaLimit) {\n+            size = sizeClass(index++, log2Group, log2Delta, nDelta++);\n+        }\n+        log2Group += LOG2_SIZE_CLASS_GROUP;\n+\n+        //All remaining groups, nDelta start at 1.\n+        while (size < chunkSize) {\n+            nDelta = 1;\n+\n+            while (nDelta <= ndeltaLimit && size < chunkSize) {\n+                size = sizeClass(index++, log2Group, log2Delta, nDelta++);\n+                normalMaxSize = size;\n+            }\n+\n+            log2Group++;\n+            log2Delta++;\n+        }\n+\n+        //chunkSize must be normalMaxSize\n+        assert chunkSize == normalMaxSize;\n+\n+        nSizes = index;\n+    }\n+\n+    //calculate size class\n+    private int sizeClass(int index, int log2Group, int log2Delta, int nDelta) {\n+        short isMultiPageSize;\n+        if (log2Delta >= pageShifts) {\n+            isMultiPageSize = yes;\n+        } else {\n+            int pageSize = 1 << pageShifts;\n+            int size = (1 << log2Group) + (1 << log2Delta) * nDelta;\n+\n+            isMultiPageSize = size == size / pageSize * pageSize? yes : no;\n+        }\n+\n+        int log2Ndelta = nDelta == 0? 0 : log2(nDelta);\n+\n+        byte remove = 1 << log2Ndelta < nDelta? yes : no;\n+\n+        int log2Size = log2Delta + log2Ndelta == log2Group? log2Group + 1 : log2Group;\n+        if (log2Size == log2Group) {\n+            remove = yes;\n+        }\n+\n+        short isSubpage = log2Size < pageShifts + LOG2_SIZE_CLASS_GROUP? yes : no;\n+\n+        int log2DeltaLookup = log2Size < LOG2_MAX_LOOKUP_SIZE ||\n+                              log2Size == LOG2_MAX_LOOKUP_SIZE && remove == no\n+                ? log2Delta : no;\n+\n+        short[] sz = {\n+                (short) index, (short) log2Group, (short) log2Delta,\n+                (short) nDelta, isMultiPageSize, isSubpage, (short) log2DeltaLookup\n+        };\n+\n+        sizeClasses[index] = sz;\n+        int size = (1 << log2Group) + (nDelta << log2Delta);\n+\n+        if (sz[PAGESIZE_IDX] == yes) {\n+            nPSizes++;\n+        }\n+        if (sz[SUBPAGE_IDX] == yes) {\n+            nSubpages++;\n+            smallMaxSizeIdx = index;\n+        }\n+        if (sz[LOG2_DELTA_LOOKUP_IDX] != no) {\n+            lookupMaxSize = size;\n+        }\n+        return size;\n+    }\n+\n+    private void idx2SizeTab() {\n+        sizeIdx2sizeTab = new int[nSizes];\n+        pageIdx2sizeTab = new int[nPSizes];\n+\n+        int pageIdx = 0;\n+\n+        for (int i = 0; i < nSizes; i++) {\n+            short[] sizeClass = sizeClasses[i];\n+            int log2Group = sizeClass[LOG2GROUP_IDX];\n+            int log2Delta = sizeClass[LOG2DELTA_IDX];\n+            int nDelta = sizeClass[NDELTA_IDX];\n+\n+            int size = (1 << log2Group) + (nDelta << log2Delta);\n+            sizeIdx2sizeTab[i] = size;\n+\n+            if (sizeClass[PAGESIZE_IDX] == yes) {\n+                pageIdx2sizeTab[pageIdx++] = size;\n+            }\n+        }\n+    }\n+\n+    private void size2idxTab() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2ab7f9b3f4c803b4c19eb13bc869788771750ce0"}, "originalPosition": 242}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "59e8dadf8fa3610a46b028956c7ee582fe0ed107", "author": {"user": {"login": "yuanrw", "name": "Ruwei"}}, "url": "https://github.com/netty/netty/commit/59e8dadf8fa3610a46b028956c7ee582fe0ed107", "committedDate": "2020-06-26T15:12:14Z", "message": "update javadoc,comment and code"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM4NzQ4NDE0", "url": "https://github.com/netty/netty/pull/10267#pullrequestreview-438748414", "createdAt": "2020-06-28T06:31:13Z", "commit": {"oid": "59e8dadf8fa3610a46b028956c7ee582fe0ed107"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yOFQwNjozMToxM1rOGp6x0w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yOFQwNjozMToxM1rOGp6x0w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjYwNzgyNw==", "bodyText": "this should be int as return type.", "url": "https://github.com/netty/netty/pull/10267#discussion_r446607827", "createdAt": "2020-06-28T06:31:13Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/main/java/io/netty/buffer/PoolChunk.java", "diffHunk": "@@ -260,10 +260,14 @@ private void removeAvailRun(PriorityQueue<Long> queue, long handle) {\n         runsAvailMap.remove(runOffset);\n         if (pages > 1) {\n             //remove last page of run\n-            runsAvailMap.remove(runOffset + pages - 1);\n+            runsAvailMap.remove(lastPage(runOffset, pages));\n         }\n     }\n \n+    private static Integer lastPage(int runOffset, int pages) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "59e8dadf8fa3610a46b028956c7ee582fe0ed107"}, "originalPosition": 69}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM4NzQ4NDM2", "url": "https://github.com/netty/netty/pull/10267#pullrequestreview-438748436", "createdAt": "2020-06-28T06:31:34Z", "commit": {"oid": "59e8dadf8fa3610a46b028956c7ee582fe0ed107"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yOFQwNjozMTozNFrOGp6x9Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yOFQwNjozMTozOFrOGp6x-A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjYwNzg2MQ==", "bodyText": "nit: remove space between colons", "url": "https://github.com/netty/netty/pull/10267#discussion_r446607861", "createdAt": "2020-06-28T06:31:34Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/main/java/io/netty/buffer/PoolChunk.java", "diffHunk": "@@ -510,7 +514,7 @@ private long collapsePast(long handle) {\n     }\n \n     private long collapseNext(long handle) {\n-        while (true) {\n+        for (; ;) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "59e8dadf8fa3610a46b028956c7ee582fe0ed107"}, "originalPosition": 113}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjYwNzg2NA==", "bodyText": "nit: remove space between colons", "url": "https://github.com/netty/netty/pull/10267#discussion_r446607864", "createdAt": "2020-06-28T06:31:38Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/main/java/io/netty/buffer/PoolChunk.java", "diffHunk": "@@ -486,7 +490,7 @@ private long collapseRuns(long handle) {\n     }\n \n     private long collapsePast(long handle) {\n-        while (true) {\n+        for (; ;) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "59e8dadf8fa3610a46b028956c7ee582fe0ed107"}, "originalPosition": 104}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "adb57b3f6e04e33f9449786755fbc68fe273ed0b", "author": {"user": {"login": "yuanrw", "name": "Ruwei"}}, "url": "https://github.com/netty/netty/commit/adb57b3f6e04e33f9449786755fbc68fe273ed0b", "committedDate": "2020-06-28T07:19:00Z", "message": "update PoolChunk, fix fail tests in PooledByteBufAllocatorTest"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQzMTIyMjE3", "url": "https://github.com/netty/netty/pull/10267#pullrequestreview-443122217", "createdAt": "2020-07-06T14:22:39Z", "commit": {"oid": "adb57b3f6e04e33f9449786755fbc68fe273ed0b"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wNlQxNDoyMjozOVrOGtZdOg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wNlQxNDozMjo0MlrOGtZ5KQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDI1NjE4Ng==", "bodyText": "I think it would be better if we could move this out of the synchronized(...) block", "url": "https://github.com/netty/netty/pull/10267#discussion_r450256186", "createdAt": "2020-07-06T14:22:39Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/main/java/io/netty/buffer/PoolArena.java", "diffHunk": "@@ -148,114 +129,83 @@ protected PoolArena(PooledByteBufAllocator parent, int pageSize,\n         return buf;\n     }\n \n-    static int tinyIdx(int normCapacity) {\n-        return normCapacity >>> 4;\n-    }\n+    private void allocate(PoolThreadCache cache, PooledByteBuf<T> buf, final int reqCapacity) {\n+        final int sizeIdx = size2SizeIdx(reqCapacity);\n \n-    static int smallIdx(int normCapacity) {\n-        int tableIdx = 0;\n-        int i = normCapacity >>> 10;\n-        while (i != 0) {\n-            i >>>= 1;\n-            tableIdx ++;\n+        if (sizeIdx <= smallMaxSizeIdx) {\n+            tcacheAllocateSmall(cache, buf, reqCapacity, sizeIdx);\n+        } else if (sizeIdx < nSizes) {\n+            tcacheAllocateNormal(cache, buf, reqCapacity, sizeIdx);\n+        } else {\n+            int normCapacity = directMemoryCacheAlignment > 0\n+                    ? normalizeSize(reqCapacity) : reqCapacity;\n+            // Huge allocations are never served via the cache so just call allocateHuge\n+            allocateHuge(buf, normCapacity);\n         }\n-        return tableIdx;\n     }\n \n-    // capacity < pageSize\n-    boolean isTinyOrSmall(int normCapacity) {\n-        return (normCapacity & subpageOverflowMask) == 0;\n-    }\n+    private void tcacheAllocateSmall(PoolThreadCache cache, PooledByteBuf<T> buf, final int reqCapacity,\n+                                     final int sizeIdx) {\n \n-    // normCapacity < 512\n-    static boolean isTiny(int normCapacity) {\n-        return (normCapacity & 0xFFFFFE00) == 0;\n-    }\n+        if (cache.allocateSmall(this, buf, reqCapacity, sizeIdx)) {\n+            // was able to allocate out of the cache so move on\n+            return;\n+        }\n \n-    private void allocate(PoolThreadCache cache, PooledByteBuf<T> buf, final int reqCapacity) {\n-        final int normCapacity = normalizeCapacity(reqCapacity);\n-        if (isTinyOrSmall(normCapacity)) { // capacity < pageSize\n-            int tableIdx;\n-            PoolSubpage<T>[] table;\n-            boolean tiny = isTiny(normCapacity);\n-            if (tiny) { // < 512\n-                if (cache.allocateTiny(this, buf, reqCapacity, normCapacity)) {\n-                    // was able to allocate out of the cache so move on\n-                    return;\n-                }\n-                tableIdx = tinyIdx(normCapacity);\n-                table = tinySubpagePools;\n-            } else {\n-                if (cache.allocateSmall(this, buf, reqCapacity, normCapacity)) {\n-                    // was able to allocate out of the cache so move on\n-                    return;\n-                }\n-                tableIdx = smallIdx(normCapacity);\n-                table = smallSubpagePools;\n+        /**\n+         * Synchronize on the head. This is needed as {@link PoolChunk#allocateSubpage(int)} and\n+         * {@link PoolChunk#free(long)} may modify the doubly linked list as well.\n+         */\n+        final PoolSubpage<T> head = smallSubpagePools[sizeIdx];\n+        synchronized (head) {\n+            final PoolSubpage<T> s = head.next;\n+            if (s != head) {\n+                assert s.doNotDestroy && s.elemSize == sizeIdx2size(sizeIdx);\n+                long handle = s.allocate();\n+                assert handle >= 0;\n+                s.chunk.initBufWithSubpage(buf, null, handle, reqCapacity, cache);\n+                incSmallAllocation();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "adb57b3f6e04e33f9449786755fbc68fe273ed0b"}, "originalPosition": 164}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDI2MDkwNg==", "bodyText": "should we assert that offer always return true ?", "url": "https://github.com/netty/netty/pull/10267#discussion_r450260906", "createdAt": "2020-07-06T14:29:13Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/main/java/io/netty/buffer/PoolChunk.java", "diffHunk": "@@ -182,23 +214,62 @@\n         this.arena = arena;\n         this.memory = memory;\n         this.offset = offset;\n-        memoryMap = null;\n-        depthMap = null;\n-        subpages = null;\n-        subpageOverflowMask = 0;\n         pageSize = 0;\n         pageShifts = 0;\n-        maxOrder = 0;\n-        unusable = (byte) (maxOrder + 1);\n+        runsAvailMap = null;\n+        runsAvail = null;\n+        subpages = null;\n         chunkSize = size;\n-        log2ChunkSize = log2(chunkSize);\n-        maxSubpageAllocs = 0;\n         cachedNioBuffers = null;\n     }\n \n     @SuppressWarnings(\"unchecked\")\n-    private PoolSubpage<T>[] newSubpageArray(int size) {\n-        return new PoolSubpage[size];\n+    private static PriorityQueue<Long>[] newRunsAvailqueueArray(int size) {\n+        PriorityQueue<Long>[] queueArray = new PriorityQueue[size];\n+        for (int i = 0; i < queueArray.length; i++) {\n+            queueArray[i] = new PriorityQueue<Long>();\n+        }\n+        return queueArray;\n+    }\n+\n+    private void insertAvailRun(int runOffset, int pages, Long handle) {\n+        int pageIdxFloor = arena.pages2pageIdxFloor(pages);\n+        PriorityQueue<Long> queue = runsAvail[pageIdxFloor];\n+        queue.offer(handle);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "adb57b3f6e04e33f9449786755fbc68fe273ed0b"}, "originalPosition": 307}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDI2MTI0NA==", "bodyText": "should assert the return value ?", "url": "https://github.com/netty/netty/pull/10267#discussion_r450261244", "createdAt": "2020-07-06T14:29:40Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/main/java/io/netty/buffer/PoolChunk.java", "diffHunk": "@@ -182,23 +214,62 @@\n         this.arena = arena;\n         this.memory = memory;\n         this.offset = offset;\n-        memoryMap = null;\n-        depthMap = null;\n-        subpages = null;\n-        subpageOverflowMask = 0;\n         pageSize = 0;\n         pageShifts = 0;\n-        maxOrder = 0;\n-        unusable = (byte) (maxOrder + 1);\n+        runsAvailMap = null;\n+        runsAvail = null;\n+        subpages = null;\n         chunkSize = size;\n-        log2ChunkSize = log2(chunkSize);\n-        maxSubpageAllocs = 0;\n         cachedNioBuffers = null;\n     }\n \n     @SuppressWarnings(\"unchecked\")\n-    private PoolSubpage<T>[] newSubpageArray(int size) {\n-        return new PoolSubpage[size];\n+    private static PriorityQueue<Long>[] newRunsAvailqueueArray(int size) {\n+        PriorityQueue<Long>[] queueArray = new PriorityQueue[size];\n+        for (int i = 0; i < queueArray.length; i++) {\n+            queueArray[i] = new PriorityQueue<Long>();\n+        }\n+        return queueArray;\n+    }\n+\n+    private void insertAvailRun(int runOffset, int pages, Long handle) {\n+        int pageIdxFloor = arena.pages2pageIdxFloor(pages);\n+        PriorityQueue<Long> queue = runsAvail[pageIdxFloor];\n+        queue.offer(handle);\n+\n+        //insert first page of run\n+        runsAvailMap.put(runOffset, handle);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "adb57b3f6e04e33f9449786755fbc68fe273ed0b"}, "originalPosition": 310}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDI2MjA0OA==", "bodyText": "nit: final", "url": "https://github.com/netty/netty/pull/10267#discussion_r450262048", "createdAt": "2020-07-06T14:30:47Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/main/java/io/netty/buffer/PoolChunk.java", "diffHunk": "@@ -222,256 +293,278 @@ private int usage(int freeBytes) {\n         return 100 - freePercentage;\n     }\n \n-    boolean allocate(PooledByteBuf<T> buf, int reqCapacity, int normCapacity, PoolThreadCache threadCache) {\n-        final long handle;\n-        if ((normCapacity & subpageOverflowMask) != 0) { // >= pageSize\n-            handle =  allocateRun(normCapacity);\n+    boolean allocate(PooledByteBuf<T> buf, int reqCapacity, int sizeIdx, PoolThreadCache cache) {\n+        long handle;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "adb57b3f6e04e33f9449786755fbc68fe273ed0b"}, "originalPosition": 354}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDI2MzA1Ng==", "bodyText": "nit: missing . after normCapacity.", "url": "https://github.com/netty/netty/pull/10267#discussion_r450263056", "createdAt": "2020-07-06T14:32:15Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/main/java/io/netty/buffer/PoolChunk.java", "diffHunk": "@@ -222,256 +293,278 @@ private int usage(int freeBytes) {\n         return 100 - freePercentage;\n     }\n \n-    boolean allocate(PooledByteBuf<T> buf, int reqCapacity, int normCapacity, PoolThreadCache threadCache) {\n-        final long handle;\n-        if ((normCapacity & subpageOverflowMask) != 0) { // >= pageSize\n-            handle =  allocateRun(normCapacity);\n+    boolean allocate(PooledByteBuf<T> buf, int reqCapacity, int sizeIdx, PoolThreadCache cache) {\n+        long handle;\n+        if (sizeIdx <= arena.smallMaxSizeIdx) {\n+            // small\n+            handle = allocateSubpage(sizeIdx);\n+            if (handle < 0) {\n+                return false;\n+            }\n+            assert isSubpage(handle);\n         } else {\n-            handle = allocateSubpage(normCapacity);\n+            // normal\n+            // runSize must be multiple of pageSize\n+            int runSize = arena.sizeIdx2size(sizeIdx);\n+            handle = allocateRun(runSize);\n+            if (handle < 0) {\n+                return false;\n+            }\n         }\n \n-        if (handle < 0) {\n-            return false;\n-        }\n-        ByteBuffer nioBuffer = cachedNioBuffers != null ? cachedNioBuffers.pollLast() : null;\n-        initBuf(buf, nioBuffer, handle, reqCapacity, threadCache);\n+        ByteBuffer nioBuffer = cachedNioBuffers != null? cachedNioBuffers.pollLast() : null;\n+        initBuf(buf, nioBuffer, handle, reqCapacity, cache);\n         return true;\n     }\n \n-    /**\n-     * Update method used by allocate\n-     * This is triggered only when a successor is allocated and all its predecessors\n-     * need to update their state\n-     * The minimal depth at which subtree rooted at id has some free space\n-     *\n-     * @param id id\n-     */\n-    private void updateParentsAlloc(int id) {\n-        while (id > 1) {\n-            int parentId = id >>> 1;\n-            byte val1 = value(id);\n-            byte val2 = value(id ^ 1);\n-            byte val = val1 < val2 ? val1 : val2;\n-            setValue(parentId, val);\n-            id = parentId;\n-        }\n-    }\n+    private long allocateRun(int runSize) {\n+        int pages = runSize >> pageShifts;\n+        int pageIdx = arena.pages2pageIdx(pages);\n \n-    /**\n-     * Update method used by free\n-     * This needs to handle the special case when both children are completely free\n-     * in which case parent be directly allocated on request of size = child-size * 2\n-     *\n-     * @param id id\n-     */\n-    private void updateParentsFree(int id) {\n-        int logChild = depth(id) + 1;\n-        while (id > 1) {\n-            int parentId = id >>> 1;\n-            byte val1 = value(id);\n-            byte val2 = value(id ^ 1);\n-            logChild -= 1; // in first iteration equals log, subsequently reduce 1 from logChild as we traverse up\n-\n-            if (val1 == logChild && val2 == logChild) {\n-                setValue(parentId, (byte) (logChild - 1));\n-            } else {\n-                byte val = val1 < val2 ? val1 : val2;\n-                setValue(parentId, val);\n+        synchronized (runsAvail) {\n+            //find first queue which has at least one big enough run\n+            int queueIdx = runFirstBestFit(pageIdx);\n+            if (queueIdx == -1) {\n+                return -1;\n+            }\n+\n+            //get run with min offset in this queue\n+            PriorityQueue<Long> queue = runsAvail[queueIdx];\n+            long handle = queue.poll();\n+\n+            assert !isUsed(handle);\n+\n+            removeAvailRun(queue, handle);\n+\n+            if (handle != -1) {\n+                handle = splitLargeRun(handle, pages);\n             }\n \n-            id = parentId;\n+            freeBytes -= runSize(pageShifts, handle);\n+            return handle;\n         }\n     }\n \n-    /**\n-     * Algorithm to allocate an index in memoryMap when we query for a free node\n-     * at depth d\n-     *\n-     * @param d depth\n-     * @return index in memoryMap\n-     */\n-    private int allocateNode(int d) {\n-        int id = 1;\n-        int initial = - (1 << d); // has last d bits = 0 and rest all = 1\n-        byte val = value(id);\n-        if (val > d) { // unusable\n-            return -1;\n+    private int calculateRunSize(int sizeIdx) {\n+        int maxElements = 1 << pageShifts - SizeClasses.LOG2_QUANTUM;\n+        int runSize = 0;\n+        int nElements;\n+\n+        final int elemSize = arena.sizeIdx2size(sizeIdx);\n+\n+        //find lowest common multiple of pageSize and elemSize\n+        do {\n+            runSize += pageSize;\n+            nElements = runSize / elemSize;\n+        } while (nElements < maxElements && runSize != nElements * elemSize);\n+\n+        while (nElements > maxElements) {\n+            runSize -= pageSize;\n+            nElements = runSize / elemSize;\n         }\n-        while (val < d || (id & initial) == 0) { // id & initial == 1 << d for all ids at depth d, for < d it is 0\n-            id <<= 1;\n-            val = value(id);\n-            if (val > d) {\n-                id ^= 1;\n-                val = value(id);\n+\n+        assert nElements > 0;\n+        assert runSize <= chunkSize;\n+        assert runSize >= elemSize;\n+\n+        return runSize;\n+    }\n+\n+    private int runFirstBestFit(int pageIdx) {\n+        for (int i = pageIdx; i < arena.nPSizes; i++) {\n+            PriorityQueue<Long> queue = runsAvail[i];\n+            if (queue != null && !queue.isEmpty()) {\n+                return i;\n             }\n         }\n-        byte value = value(id);\n-        assert value == d && (id & initial) == 1 << d : String.format(\"val = %d, id & initial = %d, d = %d\",\n-                value, id & initial, d);\n-        setValue(id, unusable); // mark as unusable\n-        updateParentsAlloc(id);\n-        return id;\n+        return -1;\n     }\n \n-    /**\n-     * Allocate a run of pages (>=1)\n-     *\n-     * @param normCapacity normalized capacity\n-     * @return index in memoryMap\n-     */\n-    private long allocateRun(int normCapacity) {\n-        int d = maxOrder - (log2(normCapacity) - pageShifts);\n-        int id = allocateNode(d);\n-        if (id < 0) {\n-            return id;\n+    private long splitLargeRun(long handle, int needPages) {\n+        assert needPages > 0;\n+\n+        int totalPages = runPages(handle);\n+        assert needPages <= totalPages;\n+\n+        int remPages = totalPages - needPages;\n+\n+        if (remPages > 0) {\n+            int runOffset = runOffset(handle);\n+\n+            // keep track of trailing unused pages for later use\n+            int availOffset = runOffset + needPages;\n+            long availRun = toRunHandle(availOffset, remPages, 0);\n+            insertAvailRun(availOffset, remPages, availRun);\n+\n+            // not avail\n+            return toRunHandle(runOffset, needPages, 1);\n         }\n-        freeBytes -= runLength(id);\n-        return id;\n+\n+        //mark it as used\n+        handle |= 1L << IS_USED_SHIFT;\n+        return handle;\n     }\n \n     /**\n-     * Create / initialize a new PoolSubpage of normCapacity\n-     * Any PoolSubpage created / initialized here is added to subpage pool in the PoolArena that owns this PoolChunk\n+     * Create / initialize a new PoolSubpage of normCapacity Any PoolSubpage created / initialized here is added to", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "adb57b3f6e04e33f9449786755fbc68fe273ed0b"}, "originalPosition": 551}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDI2MzMzNw==", "bodyText": "nit: missing . after PoolArena", "url": "https://github.com/netty/netty/pull/10267#discussion_r450263337", "createdAt": "2020-07-06T14:32:42Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/main/java/io/netty/buffer/PoolChunk.java", "diffHunk": "@@ -222,256 +293,278 @@ private int usage(int freeBytes) {\n         return 100 - freePercentage;\n     }\n \n-    boolean allocate(PooledByteBuf<T> buf, int reqCapacity, int normCapacity, PoolThreadCache threadCache) {\n-        final long handle;\n-        if ((normCapacity & subpageOverflowMask) != 0) { // >= pageSize\n-            handle =  allocateRun(normCapacity);\n+    boolean allocate(PooledByteBuf<T> buf, int reqCapacity, int sizeIdx, PoolThreadCache cache) {\n+        long handle;\n+        if (sizeIdx <= arena.smallMaxSizeIdx) {\n+            // small\n+            handle = allocateSubpage(sizeIdx);\n+            if (handle < 0) {\n+                return false;\n+            }\n+            assert isSubpage(handle);\n         } else {\n-            handle = allocateSubpage(normCapacity);\n+            // normal\n+            // runSize must be multiple of pageSize\n+            int runSize = arena.sizeIdx2size(sizeIdx);\n+            handle = allocateRun(runSize);\n+            if (handle < 0) {\n+                return false;\n+            }\n         }\n \n-        if (handle < 0) {\n-            return false;\n-        }\n-        ByteBuffer nioBuffer = cachedNioBuffers != null ? cachedNioBuffers.pollLast() : null;\n-        initBuf(buf, nioBuffer, handle, reqCapacity, threadCache);\n+        ByteBuffer nioBuffer = cachedNioBuffers != null? cachedNioBuffers.pollLast() : null;\n+        initBuf(buf, nioBuffer, handle, reqCapacity, cache);\n         return true;\n     }\n \n-    /**\n-     * Update method used by allocate\n-     * This is triggered only when a successor is allocated and all its predecessors\n-     * need to update their state\n-     * The minimal depth at which subtree rooted at id has some free space\n-     *\n-     * @param id id\n-     */\n-    private void updateParentsAlloc(int id) {\n-        while (id > 1) {\n-            int parentId = id >>> 1;\n-            byte val1 = value(id);\n-            byte val2 = value(id ^ 1);\n-            byte val = val1 < val2 ? val1 : val2;\n-            setValue(parentId, val);\n-            id = parentId;\n-        }\n-    }\n+    private long allocateRun(int runSize) {\n+        int pages = runSize >> pageShifts;\n+        int pageIdx = arena.pages2pageIdx(pages);\n \n-    /**\n-     * Update method used by free\n-     * This needs to handle the special case when both children are completely free\n-     * in which case parent be directly allocated on request of size = child-size * 2\n-     *\n-     * @param id id\n-     */\n-    private void updateParentsFree(int id) {\n-        int logChild = depth(id) + 1;\n-        while (id > 1) {\n-            int parentId = id >>> 1;\n-            byte val1 = value(id);\n-            byte val2 = value(id ^ 1);\n-            logChild -= 1; // in first iteration equals log, subsequently reduce 1 from logChild as we traverse up\n-\n-            if (val1 == logChild && val2 == logChild) {\n-                setValue(parentId, (byte) (logChild - 1));\n-            } else {\n-                byte val = val1 < val2 ? val1 : val2;\n-                setValue(parentId, val);\n+        synchronized (runsAvail) {\n+            //find first queue which has at least one big enough run\n+            int queueIdx = runFirstBestFit(pageIdx);\n+            if (queueIdx == -1) {\n+                return -1;\n+            }\n+\n+            //get run with min offset in this queue\n+            PriorityQueue<Long> queue = runsAvail[queueIdx];\n+            long handle = queue.poll();\n+\n+            assert !isUsed(handle);\n+\n+            removeAvailRun(queue, handle);\n+\n+            if (handle != -1) {\n+                handle = splitLargeRun(handle, pages);\n             }\n \n-            id = parentId;\n+            freeBytes -= runSize(pageShifts, handle);\n+            return handle;\n         }\n     }\n \n-    /**\n-     * Algorithm to allocate an index in memoryMap when we query for a free node\n-     * at depth d\n-     *\n-     * @param d depth\n-     * @return index in memoryMap\n-     */\n-    private int allocateNode(int d) {\n-        int id = 1;\n-        int initial = - (1 << d); // has last d bits = 0 and rest all = 1\n-        byte val = value(id);\n-        if (val > d) { // unusable\n-            return -1;\n+    private int calculateRunSize(int sizeIdx) {\n+        int maxElements = 1 << pageShifts - SizeClasses.LOG2_QUANTUM;\n+        int runSize = 0;\n+        int nElements;\n+\n+        final int elemSize = arena.sizeIdx2size(sizeIdx);\n+\n+        //find lowest common multiple of pageSize and elemSize\n+        do {\n+            runSize += pageSize;\n+            nElements = runSize / elemSize;\n+        } while (nElements < maxElements && runSize != nElements * elemSize);\n+\n+        while (nElements > maxElements) {\n+            runSize -= pageSize;\n+            nElements = runSize / elemSize;\n         }\n-        while (val < d || (id & initial) == 0) { // id & initial == 1 << d for all ids at depth d, for < d it is 0\n-            id <<= 1;\n-            val = value(id);\n-            if (val > d) {\n-                id ^= 1;\n-                val = value(id);\n+\n+        assert nElements > 0;\n+        assert runSize <= chunkSize;\n+        assert runSize >= elemSize;\n+\n+        return runSize;\n+    }\n+\n+    private int runFirstBestFit(int pageIdx) {\n+        for (int i = pageIdx; i < arena.nPSizes; i++) {\n+            PriorityQueue<Long> queue = runsAvail[i];\n+            if (queue != null && !queue.isEmpty()) {\n+                return i;\n             }\n         }\n-        byte value = value(id);\n-        assert value == d && (id & initial) == 1 << d : String.format(\"val = %d, id & initial = %d, d = %d\",\n-                value, id & initial, d);\n-        setValue(id, unusable); // mark as unusable\n-        updateParentsAlloc(id);\n-        return id;\n+        return -1;\n     }\n \n-    /**\n-     * Allocate a run of pages (>=1)\n-     *\n-     * @param normCapacity normalized capacity\n-     * @return index in memoryMap\n-     */\n-    private long allocateRun(int normCapacity) {\n-        int d = maxOrder - (log2(normCapacity) - pageShifts);\n-        int id = allocateNode(d);\n-        if (id < 0) {\n-            return id;\n+    private long splitLargeRun(long handle, int needPages) {\n+        assert needPages > 0;\n+\n+        int totalPages = runPages(handle);\n+        assert needPages <= totalPages;\n+\n+        int remPages = totalPages - needPages;\n+\n+        if (remPages > 0) {\n+            int runOffset = runOffset(handle);\n+\n+            // keep track of trailing unused pages for later use\n+            int availOffset = runOffset + needPages;\n+            long availRun = toRunHandle(availOffset, remPages, 0);\n+            insertAvailRun(availOffset, remPages, availRun);\n+\n+            // not avail\n+            return toRunHandle(runOffset, needPages, 1);\n         }\n-        freeBytes -= runLength(id);\n-        return id;\n+\n+        //mark it as used\n+        handle |= 1L << IS_USED_SHIFT;\n+        return handle;\n     }\n \n     /**\n-     * Create / initialize a new PoolSubpage of normCapacity\n-     * Any PoolSubpage created / initialized here is added to subpage pool in the PoolArena that owns this PoolChunk\n+     * Create / initialize a new PoolSubpage of normCapacity Any PoolSubpage created / initialized here is added to\n+     * subpage pool in the PoolArena that owns this PoolChunk\n+     *\n+     * @param sizeIdx sizeIdx of normalized size\n      *\n-     * @param normCapacity normalized capacity\n      * @return index in memoryMap\n      */\n-    private long allocateSubpage(int normCapacity) {\n+    private long allocateSubpage(int sizeIdx) {\n         // Obtain the head of the PoolSubPage pool that is owned by the PoolArena and synchronize on it.\n         // This is need as we may add it back and so alter the linked-list structure.\n-        PoolSubpage<T> head = arena.findSubpagePoolHead(normCapacity);\n-        int d = maxOrder; // subpages are only be allocated from pages i.e., leaves\n+        PoolSubpage<T> head = arena.findSubpagePoolHead(sizeIdx);\n         synchronized (head) {\n-            int id = allocateNode(d);\n-            if (id < 0) {\n-                return id;\n+            //allocate a new run\n+            int runSize = calculateRunSize(sizeIdx);\n+            //runSize must be multiples of pageSize\n+            long runHandle = allocateRun(runSize);\n+            if (runHandle < 0) {\n+                return -1;\n             }\n \n-            final PoolSubpage<T>[] subpages = this.subpages;\n-            final int pageSize = this.pageSize;\n+            int runOffset = runOffset(runHandle);\n+            int elemSize = arena.sizeIdx2size(sizeIdx);\n \n-            freeBytes -= pageSize;\n+            PoolSubpage<T> subpage = new PoolSubpage<T>(head, this, pageShifts, runOffset,\n+                               runSize(pageShifts, runHandle), elemSize);\n \n-            int subpageIdx = subpageIdx(id);\n-            PoolSubpage<T> subpage = subpages[subpageIdx];\n-            if (subpage == null) {\n-                subpage = new PoolSubpage<T>(head, this, id, runOffset(id), pageSize, normCapacity);\n-                subpages[subpageIdx] = subpage;\n-            } else {\n-                subpage.init(head, normCapacity);\n-            }\n+            subpages[runOffset] = subpage;\n             return subpage.allocate();\n         }\n     }\n \n     /**\n-     * Free a subpage or a run of pages\n-     * When a subpage is freed from PoolSubpage, it might be added back to subpage pool of the owning PoolArena\n-     * If the subpage pool in PoolArena has at least one other PoolSubpage of given elemSize, we can\n-     * completely free the owning Page so it is available for subsequent allocations\n+     * Free a subpage or a run of pages When a subpage is freed from PoolSubpage, it might be added back to subpage pool\n+     * of the owning PoolArena If the subpage pool in PoolArena has at least one other PoolSubpage of given elemSize, we", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "adb57b3f6e04e33f9449786755fbc68fe273ed0b"}, "originalPosition": 606}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a9a6df33235aeef82e2ac4976dc1164584ed42ce", "author": {"user": {"login": "yuanrw", "name": "Ruwei"}}, "url": "https://github.com/netty/netty/commit/a9a6df33235aeef82e2ac4976dc1164584ed42ce", "committedDate": "2020-07-11T15:24:17Z", "message": "update insertAvailRun() and comments, optimize runFirstBestFit()"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ3MDM3MzQ5", "url": "https://github.com/netty/netty/pull/10267#pullrequestreview-447037349", "createdAt": "2020-07-13T08:32:56Z", "commit": {"oid": "a9a6df33235aeef82e2ac4976dc1164584ed42ce"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ3MDU2NjU1", "url": "https://github.com/netty/netty/pull/10267#pullrequestreview-447056655", "createdAt": "2020-07-13T08:55:32Z", "commit": {"oid": "a9a6df33235aeef82e2ac4976dc1164584ed42ce"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ3MTcxOTYz", "url": "https://github.com/netty/netty/pull/10267#pullrequestreview-447171963", "createdAt": "2020-07-13T11:39:02Z", "commit": {"oid": "a9a6df33235aeef82e2ac4976dc1164584ed42ce"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QxMTozOTowMlrOGwk2CQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QxMTozOTowMlrOGwk2CQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzU4ODQ4OQ==", "bodyText": "nit: can we not use wildcard imports but import what is needed only ?", "url": "https://github.com/netty/netty/pull/10267#discussion_r453588489", "createdAt": "2020-07-13T11:39:02Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/main/java/io/netty/buffer/PoolArena.java", "diffHunk": "@@ -26,31 +26,22 @@\n import java.util.List;\n import java.util.concurrent.atomic.AtomicInteger;\n \n-import static io.netty.util.internal.ObjectUtil.checkPositiveOrZero;\n+import static io.netty.buffer.PoolChunk.*;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a9a6df33235aeef82e2ac4976dc1164584ed42ce"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ3MTcyNjY1", "url": "https://github.com/netty/netty/pull/10267#pullrequestreview-447172665", "createdAt": "2020-07-13T11:40:12Z", "commit": {"oid": "a9a6df33235aeef82e2ac4976dc1164584ed42ce"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QxMTo0MDoxMlrOGwk4OQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QxMTo0MDoxMlrOGwk4OQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzU4OTA0OQ==", "bodyText": "nit: can we not use wildcard imports but just important what is needed ?", "url": "https://github.com/netty/netty/pull/10267#discussion_r453589049", "createdAt": "2020-07-13T11:40:12Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/test/java/io/netty/buffer/PooledByteBufAllocatorTest.java", "diffHunk": "@@ -32,6 +33,7 @@\n import java.util.concurrent.atomic.AtomicReference;\n import java.util.concurrent.locks.LockSupport;\n \n+import static io.netty.buffer.PoolChunk.*;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a9a6df33235aeef82e2ac4976dc1164584ed42ce"}, "originalPosition": 12}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ3MTczMTE1", "url": "https://github.com/netty/netty/pull/10267#pullrequestreview-447173115", "createdAt": "2020-07-13T11:40:52Z", "commit": {"oid": "a9a6df33235aeef82e2ac4976dc1164584ed42ce"}, "state": "CHANGES_REQUESTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QxMTo0MDo1M1rOGwk5pQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xM1QxMjoyMTo1OFrOGwmI6A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzU4OTQxMw==", "bodyText": "can you add a comment why 8388608  was chosen ?", "url": "https://github.com/netty/netty/pull/10267#discussion_r453589413", "createdAt": "2020-07-13T11:40:53Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/test/java/io/netty/buffer/PoolArenaTest.java", "diffHunk": "@@ -20,29 +20,85 @@\n import org.junit.Assert;\n import org.junit.Test;\n \n-import static org.junit.Assume.assumeTrue;\n-\n import java.nio.ByteBuffer;\n \n+import static org.junit.Assert.*;\n+import static org.junit.Assume.*;\n+\n public class PoolArenaTest {\n \n     @Test\n-    public void testNormalizeCapacity() throws Exception {\n-        PoolArena<ByteBuffer> arena = new PoolArena.DirectArena(null, 0, 0, 9, 999999, 0);\n+    public void testNormalizeCapacity() {\n+        PoolArena<ByteBuffer> arena = new PoolArena.DirectArena(null, 4096, 12, 8388608, 0);\n         int[] reqCapacities = {0, 15, 510, 1024, 1023, 1025};\n-        int[] expectedResult = {0, 16, 512, 1024, 1024, 2048};\n+        int[] expectedResult = {16, 16, 512, 1024, 1024, 1280};\n         for (int i = 0; i < reqCapacities.length; i ++) {\n-            Assert.assertEquals(expectedResult[i], arena.normalizeCapacity(reqCapacities[i]));\n+            Assert.assertEquals(expectedResult[i], arena.sizeIdx2size(arena.size2SizeIdx(reqCapacities[i])));\n         }\n     }\n \n     @Test\n-    public void testNormalizeAlignedCapacity() throws Exception {\n-        PoolArena<ByteBuffer> arena = new PoolArena.DirectArena(null, 0, 0, 9, 999999, 64);\n+    public void testNormalizeAlignedCapacity() {\n+        PoolArena<ByteBuffer> arena = new PoolArena.DirectArena(null, 4096, 12, 8388608, 64);\n         int[] reqCapacities = {0, 15, 510, 1024, 1023, 1025};\n-        int[] expectedResult = {0, 64, 512, 1024, 1024, 2048};\n+        int[] expectedResult = {16, 64, 512, 1024, 1024, 1280};\n         for (int i = 0; i < reqCapacities.length; i ++) {\n-            Assert.assertEquals(expectedResult[i], arena.normalizeCapacity(reqCapacities[i]));\n+            Assert.assertEquals(expectedResult[i], arena.sizeIdx2size(arena.size2SizeIdx(reqCapacities[i])));\n+        }\n+    }\n+\n+    @Test\n+    public void testSize2SizeIdx() {\n+        int chunkSize = 16 * 1024 * 1024;\n+\n+        PoolArena<ByteBuffer> arena = new PoolArena.DirectArena(null, 8192, 13, chunkSize, 0);\n+\n+        for (int sz = 0; sz <= chunkSize; sz++) {\n+            int sizeIdx = arena.size2SizeIdx(sz);\n+            Assert.assertTrue(sz <= arena.sizeIdx2size(sizeIdx));\n+            if (sizeIdx > 0) {\n+                Assert.assertTrue(sz > arena.sizeIdx2size(sizeIdx - 1));\n+            }\n+        }\n+    }\n+\n+    @Test\n+    public void testPages2PageIdx() {\n+        int pageSize = 8192;\n+        int pageShifts = 13;\n+        int chunkSize = 16 * 1024 * 1024;\n+\n+        PoolArena<ByteBuffer> arena = new PoolArena.DirectArena(null, pageSize, pageShifts, chunkSize, 0);\n+\n+        int maxPages = chunkSize >> pageShifts;\n+        for (int pages = 1; pages <= maxPages; pages++) {\n+            int pageIdxFloor = arena.pages2pageIdxFloor(pages);\n+            Assert.assertTrue(pages << pageShifts >= arena.pageIdx2size(pageIdxFloor));\n+            if (pageIdxFloor > 0 && pages < maxPages) {\n+                Assert.assertTrue(pages << pageShifts < arena.pageIdx2size(pageIdxFloor + 1));\n+            }\n+\n+            int pageIdxCeiling = arena.pages2pageIdx(pages);\n+            Assert.assertTrue(pages << pageShifts <= arena.pageIdx2size(pageIdxCeiling));\n+            if (pageIdxCeiling > 0) {\n+                Assert.assertTrue(pages << pageShifts > arena.pageIdx2size(pageIdxCeiling - 1));\n+            }\n+        }\n+    }\n+\n+    @Test\n+    public void testSizeIdx2size() {\n+        PoolArena<ByteBuffer> arena = new PoolArena.DirectArena(null, 4096, 12, 8388608, 0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a9a6df33235aeef82e2ac4976dc1164584ed42ce"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzU5MDAyNA==", "bodyText": "can you add a comment why 7 ?", "url": "https://github.com/netty/netty/pull/10267#discussion_r453590024", "createdAt": "2020-07-13T11:42:02Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/main/java/io/netty/buffer/SizeClasses.java", "diffHunk": "@@ -0,0 +1,406 @@\n+/*\n+ * Copyright 2020 The Netty Project\n+ *\n+ * The Netty Project licenses this file to you under the Apache License,\n+ * version 2.0 (the \"License\"); you may not use this file except in compliance\n+ * with the License. You may obtain a copy of the License at:\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT\n+ * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the\n+ * License for the specific language governing permissions and limitations\n+ * under the License.\n+ */\n+package io.netty.buffer;\n+\n+import static io.netty.buffer.PoolThreadCache.*;\n+\n+/**\n+ * SizeClasses requires {@code pageShifts} to be defined prior to inclusion,\n+ * and it in turn defines:\n+ * <p>\n+ *   LOG2_SIZE_CLASS_GROUP: Log of size class count for each size doubling.\n+ *   LOG2_MAX_LOOKUP_SIZE: Log of max size class in the lookup table.\n+ *   sizeClasses: Complete table of [index, log2Group, log2Delta, nDelta, isMultiPageSize,\n+ *                 isSubPage, log2DeltaLookup] tuples.\n+ *     index: Size class index.\n+ *     log2Group: Log of group base size (no deltas added).\n+ *     log2Delta: Log of delta to previous size class.\n+ *     nDelta: Delta multiplier.\n+ *     isMultiPageSize: 'yes' if a multiple of the page size, 'no' otherwise.\n+ *     isSubPage: 'yes' if a subpage size class, 'no' otherwise.\n+ *     log2DeltaLookup: Same as log2Delta if a lookup table size class, 'no'\n+ *                      otherwise.\n+ * <p>\n+ *   nSubpages: Number of subpages size classes.\n+ *   nSizes: Number of size classes.\n+ *   nPSizes: Number of size classes that are multiples of pageSize.\n+ *\n+ *   smallMaxSizeIdx: Maximum small size class index.\n+ *\n+ *   lookupMaxclass: Maximum size class included in lookup table.\n+ *   log2NormalMinClass: Log of minimum normal size class.\n+ * <p>\n+ *   The first size class and spacing are 1 << LOG2_QUANTUM.\n+ *   Each group has 1 << LOG2_SIZE_CLASS_GROUP of size classes.\n+ *\n+ *   size = 1 << log2Group + nDelta * (1 << log2Delta)\n+ *\n+ *   The first size class has an unusual encoding, because the size has to be\n+ *   split between group and delta*nDelta.\n+ *\n+ *   If pageShift = 13, sizeClasses looks like this:\n+ *\n+ *   (index, log2Group, log2Delta, nDelta, isMultiPageSize, isSubPage, log2DeltaLookup)\n+ * <p>\n+ *   ( 0,     4,        4,         0,       no,             yes,        4)\n+ *   ( 1,     4,        4,         1,       no,             yes,        4)\n+ *   ( 2,     4,        4,         2,       no,             yes,        4)\n+ *   ( 3,     4,        4,         3,       no,             yes,        4)\n+ * <p>\n+ *   ( 4,     6,        4,         1,       no,             yes,        4)\n+ *   ( 5,     6,        4,         2,       no,             yes,        4)\n+ *   ( 6,     6,        4,         3,       no,             yes,        4)\n+ *   ( 7,     6,        4,         4,       no,             yes,        4)\n+ * <p>\n+ *   ( 8,     7,        5,         1,       no,             yes,        5)\n+ *   ( 9,     7,        5,         2,       no,             yes,        5)\n+ *   ( 10,    7,        5,         3,       no,             yes,        5)\n+ *   ( 11,    7,        5,         4,       no,             yes,        5)\n+ *   ...\n+ *   ...\n+ *   ( 72,    23,       21,        1,       yes,            no,        no)\n+ *   ( 73,    23,       21,        2,       yes,            no,        no)\n+ *   ( 74,    23,       21,        3,       yes,            no,        no)\n+ *   ( 75,    23,       21,        4,       yes,            no,        no)\n+ * <p>\n+ *   ( 76,    24,       22,        1,       yes,            no,        no)\n+ */\n+abstract class SizeClasses implements SizeClassesMetric {\n+\n+    static final int LOG2_QUANTUM = 4;\n+\n+    private static final int LOG2_SIZE_CLASS_GROUP = 2;\n+    private static final int LOG2_MAX_LOOKUP_SIZE = 12;\n+\n+    private static final int INDEX_IDX = 0;\n+    private static final int LOG2GROUP_IDX = 1;\n+    private static final int LOG2DELTA_IDX = 2;\n+    private static final int NDELTA_IDX = 3;\n+    private static final int PAGESIZE_IDX = 4;\n+    private static final int SUBPAGE_IDX = 5;\n+    private static final int LOG2_DELTA_LOOKUP_IDX = 6;\n+\n+    private static final byte no = 0, yes = 1;\n+\n+    protected SizeClasses(int pageSize, int pageShifts, int chunkSize, int directMemoryCacheAlignment) {\n+        this.pageSize = pageSize;\n+        this.pageShifts = pageShifts;\n+        this.chunkSize = chunkSize;\n+        this.directMemoryCacheAlignment = directMemoryCacheAlignment;\n+\n+        int group = log2(chunkSize) + 1 - LOG2_QUANTUM;\n+\n+        //generate size classes\n+        sizeClasses = new short[group << LOG2_SIZE_CLASS_GROUP][7];", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a9a6df33235aeef82e2ac4976dc1164584ed42ce"}, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzU5MDQ1Ng==", "bodyText": "nit: add @deprecated javadoc", "url": "https://github.com/netty/netty/pull/10267#discussion_r453590456", "createdAt": "2020-07-13T11:42:49Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/main/java/io/netty/buffer/PooledByteBufAllocator.java", "diffHunk": "@@ -406,10 +428,11 @@ public static boolean defaultPreferDirect() {\n     }\n \n     /**\n-     * Default tiny cache size - System Property: io.netty.allocator.tinyCacheSize - default 512\n+     * Default tiny cache size - default 0", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a9a6df33235aeef82e2ac4976dc1164584ed42ce"}, "originalPosition": 130}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzYwOTcwNA==", "bodyText": "@yaroot did you see this ?", "url": "https://github.com/netty/netty/pull/10267#discussion_r453609704", "createdAt": "2020-07-13T12:21:58Z", "author": {"login": "normanmaurer"}, "path": "buffer/src/main/java/io/netty/buffer/PoolArena.java", "diffHunk": "@@ -148,114 +129,83 @@ protected PoolArena(PooledByteBufAllocator parent, int pageSize,\n         return buf;\n     }\n \n-    static int tinyIdx(int normCapacity) {\n-        return normCapacity >>> 4;\n-    }\n+    private void allocate(PoolThreadCache cache, PooledByteBuf<T> buf, final int reqCapacity) {\n+        final int sizeIdx = size2SizeIdx(reqCapacity);\n \n-    static int smallIdx(int normCapacity) {\n-        int tableIdx = 0;\n-        int i = normCapacity >>> 10;\n-        while (i != 0) {\n-            i >>>= 1;\n-            tableIdx ++;\n+        if (sizeIdx <= smallMaxSizeIdx) {\n+            tcacheAllocateSmall(cache, buf, reqCapacity, sizeIdx);\n+        } else if (sizeIdx < nSizes) {\n+            tcacheAllocateNormal(cache, buf, reqCapacity, sizeIdx);\n+        } else {\n+            int normCapacity = directMemoryCacheAlignment > 0\n+                    ? normalizeSize(reqCapacity) : reqCapacity;\n+            // Huge allocations are never served via the cache so just call allocateHuge\n+            allocateHuge(buf, normCapacity);\n         }\n-        return tableIdx;\n     }\n \n-    // capacity < pageSize\n-    boolean isTinyOrSmall(int normCapacity) {\n-        return (normCapacity & subpageOverflowMask) == 0;\n-    }\n+    private void tcacheAllocateSmall(PoolThreadCache cache, PooledByteBuf<T> buf, final int reqCapacity,\n+                                     final int sizeIdx) {\n \n-    // normCapacity < 512\n-    static boolean isTiny(int normCapacity) {\n-        return (normCapacity & 0xFFFFFE00) == 0;\n-    }\n+        if (cache.allocateSmall(this, buf, reqCapacity, sizeIdx)) {\n+            // was able to allocate out of the cache so move on\n+            return;\n+        }\n \n-    private void allocate(PoolThreadCache cache, PooledByteBuf<T> buf, final int reqCapacity) {\n-        final int normCapacity = normalizeCapacity(reqCapacity);\n-        if (isTinyOrSmall(normCapacity)) { // capacity < pageSize\n-            int tableIdx;\n-            PoolSubpage<T>[] table;\n-            boolean tiny = isTiny(normCapacity);\n-            if (tiny) { // < 512\n-                if (cache.allocateTiny(this, buf, reqCapacity, normCapacity)) {\n-                    // was able to allocate out of the cache so move on\n-                    return;\n-                }\n-                tableIdx = tinyIdx(normCapacity);\n-                table = tinySubpagePools;\n-            } else {\n-                if (cache.allocateSmall(this, buf, reqCapacity, normCapacity)) {\n-                    // was able to allocate out of the cache so move on\n-                    return;\n-                }\n-                tableIdx = smallIdx(normCapacity);\n-                table = smallSubpagePools;\n+        /**\n+         * Synchronize on the head. This is needed as {@link PoolChunk#allocateSubpage(int)} and\n+         * {@link PoolChunk#free(long)} may modify the doubly linked list as well.\n+         */\n+        final PoolSubpage<T> head = smallSubpagePools[sizeIdx];\n+        synchronized (head) {\n+            final PoolSubpage<T> s = head.next;\n+            if (s != head) {\n+                assert s.doNotDestroy && s.elemSize == sizeIdx2size(sizeIdx);\n+                long handle = s.allocate();\n+                assert handle >= 0;\n+                s.chunk.initBufWithSubpage(buf, null, handle, reqCapacity, cache);\n+                incSmallAllocation();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MDI1NjE4Ng=="}, "originalCommit": {"oid": "adb57b3f6e04e33f9449786755fbc68fe273ed0b"}, "originalPosition": 164}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "07f1a26c788712ac75c0468a601dd6bafc243e4f", "author": {"user": {"login": "yuanrw", "name": "Ruwei"}}, "url": "https://github.com/netty/netty/commit/07f1a26c788712ac75c0468a601dd6bafc243e4f", "committedDate": "2020-07-14T01:02:05Z", "message": "add comments, optimize imports, update PoolArenaTest"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7d38f9b16acd8fbf359f014aa571f31b23456b77", "author": {"user": {"login": "yuanrw", "name": "Ruwei"}}, "url": "https://github.com/netty/netty/commit/7d38f9b16acd8fbf359f014aa571f31b23456b77", "committedDate": "2020-07-14T03:06:37Z", "message": "fix leak in tests"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ3ODExMzkz", "url": "https://github.com/netty/netty/pull/10267#pullrequestreview-447811393", "createdAt": "2020-07-14T06:06:11Z", "commit": {"oid": "7d38f9b16acd8fbf359f014aa571f31b23456b77"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 299, "cost": 1, "resetAt": "2021-11-01T15:33:45Z"}}}