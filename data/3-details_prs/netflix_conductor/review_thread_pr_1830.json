{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDY4NzYwMDUz", "number": 1830, "reviewThreads": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQxOTowMDoyNlrOEiqAhA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQwMzo0MDo1NFrOEkzYTQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA0Nzc1MzAwOnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/netflix/conductor/core/execution/WorkflowRepairService.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQxOTowMDoyNlrOHQqUHg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xMVQxOTowMDoyNlrOHQqUHg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzIzMjU0Mg==", "bodyText": "This file contains bidirectional Unicode text that may be interpreted or compiled differently than what appears below. To review, open the file in an editor that reveals hidden Unicode characters. Learn more about bidirectional Unicode characters\n\n\n  \n\n\n    \n      \n        Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    if (task.getStatus().equals(Task.Status.SCHEDULED)) {\n          \n          \n            \n                    if (task.getStatus() == Task.Status.SCHEDULED)) {\n          \n      \n    \n    \n  \n\nEnums can be compared using the operator and it also helps avoiding a NullPointerException", "url": "https://github.com/Netflix/conductor/pull/1830#discussion_r487232542", "createdAt": "2020-09-11T19:00:26Z", "author": {"login": "aravindanr"}, "path": "core/src/main/java/com/netflix/conductor/core/execution/WorkflowRepairService.java", "diffHunk": "@@ -0,0 +1,112 @@\n+package com.netflix.conductor.core.execution;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.netflix.conductor.common.metadata.tasks.Task;\n+import com.netflix.conductor.common.run.Workflow;\n+import com.netflix.conductor.core.config.Configuration;\n+import com.netflix.conductor.core.execution.tasks.WorkflowSystemTask;\n+import com.netflix.conductor.dao.ExecutionDAO;\n+import com.netflix.conductor.dao.QueueDAO;\n+import com.netflix.conductor.metrics.Monitors;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.inject.Inject;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.function.Predicate;\n+\n+/**\n+ * A helper service that tries to keep ExecutionDAO and QueueDAO in sync, based on the\n+ * task or workflow state.\n+ *\n+ * This service expects that the underlying Queueing layer implements QueueDAO.containsMessage method. This can be controlled\n+ * with Configuration.isWorkflowRepairServiceEnabled() property.\n+ */\n+public class WorkflowRepairService {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(WorkflowRepairService.class);\n+\n+    private final ExecutionDAO executionDAO;\n+    private final QueueDAO queueDAO;\n+    private final Configuration configuration;\n+\n+    private final Predicate<Task> isSystemTask = task -> WorkflowSystemTask.is(task.getTaskType());\n+\n+    @Inject\n+    public WorkflowRepairService(\n+            ExecutionDAO executionDAO,\n+            QueueDAO queueDAO,\n+            Configuration configuration\n+    ) {\n+        this.executionDAO = executionDAO;\n+        this.queueDAO = queueDAO;\n+        this.configuration = configuration;\n+    }\n+\n+    /**\n+     * Verify and repair if the workflowId exists in deciderQueue, and then if each scheduled task has relevant message\n+     * in the queue.\n+     * @param workflowId\n+     * @param includeTasks\n+     * @return\n+     */\n+    public boolean verifyAndRepairWorkflow(String workflowId, boolean includeTasks) {\n+        Workflow workflow = executionDAO.getWorkflow(workflowId, includeTasks);\n+        AtomicBoolean repaired = new AtomicBoolean(false);\n+        repaired.set(verifyAndRepairDeciderQueue(workflow));\n+        if (includeTasks) {\n+            workflow.getTasks().forEach(task -> {\n+                repaired.set(verifyAndRepairTask(task));\n+            });\n+        }\n+        return repaired.get();\n+    }\n+\n+    /**\n+     * Verify and repair tasks in a workflow\n+     * @param workflowId\n+     */\n+    public void verifyAndRepairWorkflowTasks(String workflowId) {\n+        Workflow workflow = executionDAO.getWorkflow(workflowId, true);\n+        workflow.getTasks().forEach(task -> verifyAndRepairTask(task));\n+    }\n+\n+    /**\n+     * Verify and fix if Workflow decider queue contains this workflowId.\n+     * @param workflow\n+     * @return\n+     */\n+    private boolean verifyAndRepairDeciderQueue(Workflow workflow) {\n+        if (!workflow.getStatus().isTerminal()) {\n+            String queueName = WorkflowExecutor.DECIDER_QUEUE;\n+            if (!queueDAO.containsMessage(queueName, workflow.getWorkflowId())) {\n+                queueDAO.push(queueName, workflow.getWorkflowId(), configuration.getSweepFrequency());\n+                Monitors.recordQueueMessageRepushFromRepairService(queueName);\n+                return true;\n+            }\n+        }\n+        return false;\n+    }\n+\n+    /**\n+     * Verify if ExecutionDAO and QueueDAO agree for the provided task.\n+     * @param task\n+     * @return\n+     */\n+    @VisibleForTesting\n+    protected boolean verifyAndRepairTask(Task task) {\n+        WorkflowSystemTask workflowSystemTask = WorkflowSystemTask.get(task.getTaskType());\n+        if (task.getStatus().equals(Task.Status.SCHEDULED)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "114a91d6d1608693e7011275f987a29c4b08a33f"}, "originalPosition": 99}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1NTM1Mzc4OnYy", "diffSide": "RIGHT", "path": "common/src/main/java/com/netflix/conductor/common/constraints/FaultInjectionInterceptor.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQwMToxMzoxNVrOHRs5cA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQwMToxMzoxNVrOHRs5cA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODMyMzQ0MA==", "bodyText": "Please add license header.", "url": "https://github.com/Netflix/conductor/pull/1830#discussion_r488323440", "createdAt": "2020-09-15T01:13:15Z", "author": {"login": "apanicker-nflx"}, "path": "common/src/main/java/com/netflix/conductor/common/constraints/FaultInjectionInterceptor.java", "diffHunk": "@@ -0,0 +1,14 @@\n+package com.netflix.conductor.common.constraints;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "114a91d6d1608693e7011275f987a29c4b08a33f"}, "originalPosition": 1}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1NTM1OTY2OnYy", "diffSide": "RIGHT", "path": "common/src/main/java/com/netflix/conductor/common/constraints/FaultInjectionInterceptor.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQwMToxNjoyN1rOHRs80g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQwMToxNjoyN1rOHRs80g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODMyNDMwNg==", "bodyText": "This should probably be added to the core module.", "url": "https://github.com/Netflix/conductor/pull/1830#discussion_r488324306", "createdAt": "2020-09-15T01:16:27Z", "author": {"login": "apanicker-nflx"}, "path": "common/src/main/java/com/netflix/conductor/common/constraints/FaultInjectionInterceptor.java", "diffHunk": "@@ -0,0 +1,14 @@\n+package com.netflix.conductor.common.constraints;\n+\n+\n+import java.lang.annotation.ElementType;\n+import java.lang.annotation.Retention;\n+import java.lang.annotation.RetentionPolicy;\n+import java.lang.annotation.Target;\n+\n+/**\n+ * Interceptor intended for failure injection during unit / integration testing.\n+ */\n+@Retention(RetentionPolicy.RUNTIME) @Target(ElementType.METHOD)\n+public @interface FaultInjectionInterceptor {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "114a91d6d1608693e7011275f987a29c4b08a33f"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1NTM2NDQzOnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQwMToxOTowNlrOHRs_lA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQwMToxOTowNlrOHRs_lA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODMyNTAxMg==", "bodyText": "tasks should be removed from queue before status is updated, else tasks to be CANCELED will be polled and processed by the workers.", "url": "https://github.com/Netflix/conductor/pull/1830#discussion_r488325012", "createdAt": "2020-09-15T01:19:06Z", "author": {"login": "apanicker-nflx"}, "path": "core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java", "diffHunk": "@@ -785,6 +782,11 @@ public void terminateWorkflow(Workflow workflow, String reason, String failureWo\n             if (workflow.getWorkflowDefinition().isWorkflowStatusListenerEnabled()) {\n                 workflowStatusListener.onWorkflowTerminated(workflow);\n             }\n+\n+            //remove from the sweep queue", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "114a91d6d1608693e7011275f987a29c4b08a33f"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1NTM2OTMxOnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQwMToyMTozNlrOHRtCcQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQyMzo1NDo1M1rOHSbLiw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODMyNTc0NQ==", "bodyText": "Does this also account for partial failures?", "url": "https://github.com/Netflix/conductor/pull/1830#discussion_r488325745", "createdAt": "2020-09-15T01:21:36Z", "author": {"login": "apanicker-nflx"}, "path": "core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java", "diffHunk": "@@ -1447,6 +1446,19 @@ boolean scheduleTask(Workflow workflow, List<Task> tasks) {\n             // rollbackTasks(workflow.getWorkflowId(), createdTasks);\n             throw new TerminateWorkflowException(errorMsg);\n         }\n+\n+        // On addTaskToQueue failures, ignore the exceptions and let WorkflowRepairService take care of republishing the messages to the queue.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "114a91d6d1608693e7011275f987a29c4b08a33f"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTA4MTczOQ==", "bodyText": "Yes. Partial failures when adding to queue are fine. For eg., if only 2 of 5 messages are added to the queue and the rest failed, the sweeper service would still check if the queue contains each message as long as the task is in scheduled state, and this can be recovered.", "url": "https://github.com/Netflix/conductor/pull/1830#discussion_r489081739", "createdAt": "2020-09-15T23:54:53Z", "author": {"login": "kishorebanala"}, "path": "core/src/main/java/com/netflix/conductor/core/execution/WorkflowExecutor.java", "diffHunk": "@@ -1447,6 +1446,19 @@ boolean scheduleTask(Workflow workflow, List<Task> tasks) {\n             // rollbackTasks(workflow.getWorkflowId(), createdTasks);\n             throw new TerminateWorkflowException(errorMsg);\n         }\n+\n+        // On addTaskToQueue failures, ignore the exceptions and let WorkflowRepairService take care of republishing the messages to the queue.", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODMyNTc0NQ=="}, "originalCommit": {"oid": "114a91d6d1608693e7011275f987a29c4b08a33f"}, "originalPosition": 85}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1NTM2OTY1OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/netflix/conductor/core/execution/WorkflowRepairService.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQwMToyMTo0N1rOHRtCpQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQwMToyMTo0N1rOHRtCpQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODMyNTc5Nw==", "bodyText": "Please add license header", "url": "https://github.com/Netflix/conductor/pull/1830#discussion_r488325797", "createdAt": "2020-09-15T01:21:47Z", "author": {"login": "apanicker-nflx"}, "path": "core/src/main/java/com/netflix/conductor/core/execution/WorkflowRepairService.java", "diffHunk": "@@ -0,0 +1,112 @@\n+package com.netflix.conductor.core.execution;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "114a91d6d1608693e7011275f987a29c4b08a33f"}, "originalPosition": 1}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1NTM3MTE2OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/netflix/conductor/core/execution/WorkflowRepairService.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQwMToyMjozOVrOHRtDgA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQwMToyMjozOVrOHRtDgA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODMyNjAxNg==", "bodyText": "It would be better to link out to the method from the javadoc.", "url": "https://github.com/Netflix/conductor/pull/1830#discussion_r488326016", "createdAt": "2020-09-15T01:22:39Z", "author": {"login": "apanicker-nflx"}, "path": "core/src/main/java/com/netflix/conductor/core/execution/WorkflowRepairService.java", "diffHunk": "@@ -0,0 +1,112 @@\n+package com.netflix.conductor.core.execution;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.netflix.conductor.common.metadata.tasks.Task;\n+import com.netflix.conductor.common.run.Workflow;\n+import com.netflix.conductor.core.config.Configuration;\n+import com.netflix.conductor.core.execution.tasks.WorkflowSystemTask;\n+import com.netflix.conductor.dao.ExecutionDAO;\n+import com.netflix.conductor.dao.QueueDAO;\n+import com.netflix.conductor.metrics.Monitors;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.inject.Inject;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.function.Predicate;\n+\n+/**\n+ * A helper service that tries to keep ExecutionDAO and QueueDAO in sync, based on the\n+ * task or workflow state.\n+ *\n+ * This service expects that the underlying Queueing layer implements QueueDAO.containsMessage method. This can be controlled\n+ * with Configuration.isWorkflowRepairServiceEnabled() property.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "114a91d6d1608693e7011275f987a29c4b08a33f"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1NTM4NTYzOnYy", "diffSide": "RIGHT", "path": "core/src/main/java/com/netflix/conductor/core/execution/WorkflowRepairService.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQwMToyOTozMVrOHRtLmA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQwMToyOTozMVrOHRtLmA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODMyODA4OA==", "bodyText": "For system tasks, the tasks are enqueued in the task type queues and not by the task def name, does this line need to change?", "url": "https://github.com/Netflix/conductor/pull/1830#discussion_r488328088", "createdAt": "2020-09-15T01:29:31Z", "author": {"login": "apanicker-nflx"}, "path": "core/src/main/java/com/netflix/conductor/core/execution/WorkflowRepairService.java", "diffHunk": "@@ -0,0 +1,112 @@\n+package com.netflix.conductor.core.execution;\n+\n+import com.google.common.annotations.VisibleForTesting;\n+import com.netflix.conductor.common.metadata.tasks.Task;\n+import com.netflix.conductor.common.run.Workflow;\n+import com.netflix.conductor.core.config.Configuration;\n+import com.netflix.conductor.core.execution.tasks.WorkflowSystemTask;\n+import com.netflix.conductor.dao.ExecutionDAO;\n+import com.netflix.conductor.dao.QueueDAO;\n+import com.netflix.conductor.metrics.Monitors;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import javax.inject.Inject;\n+import java.util.concurrent.atomic.AtomicBoolean;\n+import java.util.function.Predicate;\n+\n+/**\n+ * A helper service that tries to keep ExecutionDAO and QueueDAO in sync, based on the\n+ * task or workflow state.\n+ *\n+ * This service expects that the underlying Queueing layer implements QueueDAO.containsMessage method. This can be controlled\n+ * with Configuration.isWorkflowRepairServiceEnabled() property.\n+ */\n+public class WorkflowRepairService {\n+\n+    private static final Logger LOGGER = LoggerFactory.getLogger(WorkflowRepairService.class);\n+\n+    private final ExecutionDAO executionDAO;\n+    private final QueueDAO queueDAO;\n+    private final Configuration configuration;\n+\n+    private final Predicate<Task> isSystemTask = task -> WorkflowSystemTask.is(task.getTaskType());\n+\n+    @Inject\n+    public WorkflowRepairService(\n+            ExecutionDAO executionDAO,\n+            QueueDAO queueDAO,\n+            Configuration configuration\n+    ) {\n+        this.executionDAO = executionDAO;\n+        this.queueDAO = queueDAO;\n+        this.configuration = configuration;\n+    }\n+\n+    /**\n+     * Verify and repair if the workflowId exists in deciderQueue, and then if each scheduled task has relevant message\n+     * in the queue.\n+     * @param workflowId\n+     * @param includeTasks\n+     * @return\n+     */\n+    public boolean verifyAndRepairWorkflow(String workflowId, boolean includeTasks) {\n+        Workflow workflow = executionDAO.getWorkflow(workflowId, includeTasks);\n+        AtomicBoolean repaired = new AtomicBoolean(false);\n+        repaired.set(verifyAndRepairDeciderQueue(workflow));\n+        if (includeTasks) {\n+            workflow.getTasks().forEach(task -> {\n+                repaired.set(verifyAndRepairTask(task));\n+            });\n+        }\n+        return repaired.get();\n+    }\n+\n+    /**\n+     * Verify and repair tasks in a workflow\n+     * @param workflowId\n+     */\n+    public void verifyAndRepairWorkflowTasks(String workflowId) {\n+        Workflow workflow = executionDAO.getWorkflow(workflowId, true);\n+        workflow.getTasks().forEach(task -> verifyAndRepairTask(task));\n+    }\n+\n+    /**\n+     * Verify and fix if Workflow decider queue contains this workflowId.\n+     * @param workflow\n+     * @return\n+     */\n+    private boolean verifyAndRepairDeciderQueue(Workflow workflow) {\n+        if (!workflow.getStatus().isTerminal()) {\n+            String queueName = WorkflowExecutor.DECIDER_QUEUE;\n+            if (!queueDAO.containsMessage(queueName, workflow.getWorkflowId())) {\n+                queueDAO.push(queueName, workflow.getWorkflowId(), configuration.getSweepFrequency());\n+                Monitors.recordQueueMessageRepushFromRepairService(queueName);\n+                return true;\n+            }\n+        }\n+        return false;\n+    }\n+\n+    /**\n+     * Verify if ExecutionDAO and QueueDAO agree for the provided task.\n+     * @param task\n+     * @return\n+     */\n+    @VisibleForTesting\n+    protected boolean verifyAndRepairTask(Task task) {\n+        WorkflowSystemTask workflowSystemTask = WorkflowSystemTask.get(task.getTaskType());\n+        if (task.getStatus().equals(Task.Status.SCHEDULED)) {\n+            if (isSystemTask.test(task) && !workflowSystemTask.isAsync()) {\n+                return false;\n+            }\n+            // Ensure QueueDAO contains this taskId\n+            if (!queueDAO.containsMessage(task.getTaskDefName(), task.getTaskId())) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "114a91d6d1608693e7011275f987a29c4b08a33f"}, "originalPosition": 104}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1NTM4ODYwOnYy", "diffSide": "RIGHT", "path": "redis-persistence/src/main/java/com/netflix/conductor/dao/dynomite/RedisExecutionDAO.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQwMTozMTowMlrOHRtNTQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQwMTozMTowMlrOHRtNTQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODMyODUyNQ==", "bodyText": "Since this annotation and the interceptor are used only for testing, can this abstracted out from the execution path. Maybe through some combination of Spy and Mock?", "url": "https://github.com/Netflix/conductor/pull/1830#discussion_r488328525", "createdAt": "2020-09-15T01:31:02Z", "author": {"login": "apanicker-nflx"}, "path": "redis-persistence/src/main/java/com/netflix/conductor/dao/dynomite/RedisExecutionDAO.java", "diffHunk": "@@ -115,6 +116,7 @@ public RedisExecutionDAO(DynoProxy dynoClient, ObjectMapper objectMapper, Config\n \t\treturn tasks;\n \t}\n \n+\t@FaultInjectionInterceptor", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "114a91d6d1608693e7011275f987a29c4b08a33f"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA1NTM4OTA0OnYy", "diffSide": "RIGHT", "path": "test-harness/src/test/groovy/com/netflix/counductor/integration/test/TaskResiliencySpec.groovy", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQwMTozMToxNlrOHRtNjA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNVQwMTozMToxNlrOHRtNjA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4ODMyODU4OA==", "bodyText": "Please add license header.", "url": "https://github.com/Netflix/conductor/pull/1830#discussion_r488328588", "createdAt": "2020-09-15T01:31:16Z", "author": {"login": "apanicker-nflx"}, "path": "test-harness/src/test/groovy/com/netflix/counductor/integration/test/TaskResiliencySpec.groovy", "diffHunk": "@@ -0,0 +1,131 @@\n+package com.netflix.counductor.integration.test", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "114a91d6d1608693e7011275f987a29c4b08a33f"}, "originalPosition": 1}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA3MDI1OTk3OnYy", "diffSide": "RIGHT", "path": "test-harness/src/test/groovy/com/netflix/counductor/integration/test/TaskResiliencySpec.groovy", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQwMzo0MDo1NFrOHT83sQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQwMzo0MDo1NFrOHT83sQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDY4MjI4OQ==", "bodyText": "Nice", "url": "https://github.com/Netflix/conductor/pull/1830#discussion_r490682289", "createdAt": "2020-09-18T03:40:54Z", "author": {"login": "apanicker-nflx"}, "path": "test-harness/src/test/groovy/com/netflix/counductor/integration/test/TaskResiliencySpec.groovy", "diffHunk": "@@ -0,0 +1,125 @@\n+/*\n+ * Copyright 2020 Netflix, Inc.\n+ * <p>\n+ * Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with\n+ * the License. You may obtain a copy of the License at\n+ * <p>\n+ * http://www.apache.org/licenses/LICENSE-2.0\n+ * <p>\n+ * Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on\n+ * an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the\n+ * specific language governing permissions and limitations under the License.\n+ */\n+package com.netflix.counductor.integration.test\n+\n+import com.netflix.conductor.common.metadata.tasks.Task\n+import com.netflix.conductor.common.run.Workflow\n+import com.netflix.conductor.core.execution.WorkflowExecutor\n+import com.netflix.conductor.core.execution.WorkflowRepairService\n+import com.netflix.conductor.dao.QueueDAO\n+import com.netflix.conductor.service.ExecutionService\n+import com.netflix.conductor.test.util.MockQueueDAOModule\n+import com.netflix.conductor.test.util.WorkflowTestUtil\n+import spock.guice.UseModules\n+import spock.lang.Shared\n+import spock.lang.Specification\n+\n+import javax.inject.Inject\n+\n+import static com.netflix.conductor.test.util.WorkflowTestUtil.verifyPolledAndAcknowledgedTask\n+\n+@UseModules(MockQueueDAOModule)\n+class TaskResiliencySpec extends Specification {\n+\n+    @Inject\n+    ExecutionService workflowExecutionService\n+\n+    @Inject\n+    WorkflowExecutor workflowExecutor\n+\n+    @Inject\n+    WorkflowTestUtil workflowTestUtil\n+\n+    @Inject\n+    WorkflowRepairService workflowRepairService\n+\n+    @Inject\n+    QueueDAO queueDAO\n+\n+    @Shared\n+    def SIMPLE_TWO_TASK_WORKFLOW = 'integration_test_wf'\n+\n+    def setup() {\n+        workflowTestUtil.taskDefinitions()\n+        workflowTestUtil.registerWorkflows(\n+                'simple_workflow_1_integration_test.json'\n+        )\n+    }\n+\n+    def cleanup() {\n+        workflowTestUtil.clearWorkflows()\n+    }\n+\n+    def \"Verify that a workflow recovers and completes on schedule task failure from queue push failure\"() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d51db575022710c24e1cfb406f9d3544b7b3dccc"}, "originalPosition": 63}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4114, "cost": 1, "resetAt": "2021-11-12T20:28:25Z"}}}