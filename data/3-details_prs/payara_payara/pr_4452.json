{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0MzY2MzUzNjUy", "number": 4452, "title": "APPSERV-19 Adds monitoring of stuck and hogging threads to monitoring console", "bodyText": "Summary\nChanges on server side:\n\nextends the annotation mechanism added in APPSERV-14 with the keyed flag (details below)\nfixes calculation of duration a thread is working in stuck thread calculations\nchanges stuck thread calculations to be based on millisecond timestamps and duration only (nanosecond precision makes no sense as this would also require running the check below 1ms intervals)\nadds collection of stuck threads metrics and annotations\nadds watch for stuck threads (based on threshold duration)\ncleanup and extension of hogging thread calculation\nlowers hogging thread retry minimum to 0 (no retry)\nadds collection of hogging threads metrics and annotations\nadds watch for hogging threads (based on count of hogging threads)\n\nChanges on client side:\n\nadds a Threads page preset that shows stuck and hogging thread incidents\n\nKeyed Annotations\nUsually annotations are stored in a fixed size queue where newest annotation eventually overrides the oldest. When annotations are keyed this behaviour is altered slightly. For a keyed annotation the first annotation attribute value is considered as a key. All annotations of the same key are automatically removed from the queue when an annotation is added. Only if the size limit is still exceeded the newest still replaces the oldest. This addition allows to effectively update annotation on the same thing identified by the key without necessarily removing annotations on other things.\nThis allows annotations on many things for the same metric series which avoids unnecessarily detailed metrics for each thing.\nIn the context of this PR this means annotations on one thread (usually) do not replace annotations on another thread for the same metric, here stuck thread duration or hogging thread duration.\nTesting\nNew unit tests have been added for the general mechanics of keyed annotations.\nReading the documentation changes payara/Payara-Server-Documentation#699 might help to understand the context of the feature.\nThe feature was tested manual according to below test instructions:\nGeneral Setup:\n\nbuild, install and start the server\nuse set-monitoring-console-configuration --enabled=true to deploy MC\nopen MC at http://localhost:8080/monitoring-console/\nmake sure browser cache for JS/CSS is cleared for MC's domain\n\nTesting Stuck Threads Health Checks\nBy using debug mode:\n0. Start MC in debug mode\n\nOpen admin console at http://localhost:4848/\nnavigate to Configurations => server-config => HealthCheck\nopen tab Stuck Threads, check Enabled, set a Threshold of 1 second and save\nput a breakpoint in a method you know is called (e.g. fish.payara.monitoring.web.MonitoringConsoleResource.getSeriesData(SeriesRequest))\nafter some seconds at the break-point continue execution.\ncheck in MC Threads page that annotation(s) occurs in widget Stuck Thread Incidents\ncheck in MC Alerts and Health Checks page that an related alert exists\n\nAlternatively one could deploy an app with a known REST API method that does take several seconds to complete.\nTesting Hogging Threads Health Checks\nWith a testing app:\n\nOpen admin console at http://localhost:4848/\nnavigate to Configurations => server-config => HealthCheck\nopen tab Hogging Threads, check Enabled, set a Threshold of 50% and a Retry Count of 0-1 and save\ndeploy a test application (see JIRA) with a method that does a busy loop for a given length of time\ninvoke the method for some seconds\ncheck in MC Threads page that widget Hogging Thread Incidents contains entries, check that Method refers to your method with the loop\ncheck in MC Alerts and Heath Checks page that an alert exists\n\nBy restarting (there is a chance):\n\nOpen admin console at http://localhost:4848/\nnavigate to Configurations => server-config => HealthCheck\nopen tab Hogging Threads, check Enabled, set a Threshold of 1% and a Retry Count of 0-1 and save\nrestart the server, and wait until server is up again\ncheck in MC Threads page that widget Hogging Thread Incidents contains entries\ncheck in MC Alerts and Heath Checks page that an alert exists", "createdAt": "2020-01-23T13:09:56Z", "url": "https://github.com/payara/Payara/pull/4452", "merged": true, "mergeCommit": {"oid": "ff7bf071c20e021ef1614e65f765c6ec18bf4468"}, "closed": true, "closedAt": "2020-01-24T14:35:30Z", "author": {"login": "jbee"}, "timelineItems": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABb83fPMgH2gAyMzY2MzUzNjUyOjRkYWY1ZjVkMDI5MjMwMDI0MGEzNmZiOWVmN2EyYmQ5MjlkZGYxY2I=", "endCursor": "Y3Vyc29yOnYyOpPPAAABb9fqvXgFqTM0Nzk4MTE1Mg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "4daf5f5d0292300240a36fb9ef7a2bd929ddf1cb", "author": {"user": {"login": "jbee", "name": "Jan Bernitt"}}, "url": "https://github.com/payara/Payara/commit/4daf5f5d0292300240a36fb9ef7a2bd929ddf1cb", "committedDate": "2020-01-22T15:29:17Z", "message": "Merge branch 'master' into APPSERV-14-slow-sql"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1c24432c7229cf29460e2729fd91fe9d158483a7", "author": {"user": {"login": "jbee", "name": "Jan Bernitt"}}, "url": "https://github.com/payara/Payara/commit/1c24432c7229cf29460e2729fd91fe9d158483a7", "committedDate": "2020-01-22T15:40:19Z", "message": "Merge branch 'master' into APPSERV-19-threads"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "268b0075dfeb1522d4de81ca6c33d5ef931e91e0", "author": {"user": {"login": "jbee", "name": "Jan Bernitt"}}, "url": "https://github.com/payara/Payara/commit/268b0075dfeb1522d4de81ca6c33d5ef931e91e0", "committedDate": "2020-01-23T13:08:33Z", "message": "APPSERV-19 adds initial version of threads page showing stuck and hogging thread incidents"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "430fb236623cc0778c256eb0ad150569efc371ac", "author": {"user": {"login": "jbee", "name": "Jan Bernitt"}}, "url": "https://github.com/payara/Payara/commit/430fb236623cc0778c256eb0ad150569efc371ac", "committedDate": "2020-01-23T15:27:02Z", "message": "APPSERV-19 updates copyright header and retry count min changed to zero"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3c882b33e8efc20138ece79385530a3a97946094", "author": {"user": {"login": "jbee", "name": "Jan Bernitt"}}, "url": "https://github.com/payara/Payara/commit/3c882b33e8efc20138ece79385530a3a97946094", "committedDate": "2020-01-23T15:38:08Z", "message": "APPSERV-19 adds unit tests for SeriesAnnotation keyed property"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ3NDQ2MDIw", "url": "https://github.com/payara/Payara/pull/4452#pullrequestreview-347446020", "createdAt": "2020-01-23T16:41:43Z", "commit": {"oid": "3c882b33e8efc20138ece79385530a3a97946094"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yM1QxNjo0MTo0NFrOFhFFFg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yM1QxNjo0MTo0NFrOFhFFFg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIzMDU1MA==", "bodyText": "NB. using the interval from the options is only an approximation of the actual time passed in the measurement interval. As this now can be different intervals for the check run by the health check service and the monitoring data collection I changed this to use the actual time passed. This is also more accurate.", "url": "https://github.com/payara/Payara/pull/4452#discussion_r370230550", "createdAt": "2020-01-23T16:41:44Z", "author": {"login": "jbee"}, "path": "nucleus/payara-modules/healthcheck-core/src/main/java/fish/payara/nucleus/healthcheck/preliminary/HoggingThreadsHealthCheck.java", "diffHunk": "@@ -91,65 +142,107 @@ public String getDescription() {\n \n     @Override\n     protected HealthCheckResult doCheckInternal() {\n-        hoggingThreads.set(0);\n         HealthCheckResult result = new HealthCheckResult();\n-        ThreadMXBean threadBean = ManagementFactory.getThreadMXBean();\n-\n-        if (!threadBean.isCurrentThreadCpuTimeSupported()) {\n+        if (!supported) {\n             result.add(new HealthCheckResultEntry(HealthCheckResultStatus.CHECK_ERROR, \"JVM implementation or OS does\" +\n                     \" not support getting CPU times\"));\n             return result;\n         }\n+        acceptHoggingThreads(checkRecordsByThreadId, \n+                (percentage, threshold, totalTimeHogging, initialMethod, info) -> {\n+                    result.add(new HealthCheckResultEntry(HealthCheckResultStatus.CRITICAL,\n+                            \"Thread with <id-name>: \" + info.getThreadId() + \"-\" + info.getThreadName() +\n+                            \" is a hogging thread for the last \" +\n+                            prettyPrintDuration(totalTimeHogging) + \"\\n\" + prettyPrintStackTrace(info.getStackTrace())));\n+                });\n+        return result;\n+    }\n \n-        final long[] ids = threadBean.getAllThreadIds();\n-        for (long id : ids) {\n-            if (id == Thread.currentThread().getId())\n-                continue;\n-            final long c = threadBean.getThreadCpuTime(id);\n-            final long u = threadBean.getThreadUserTime(id);\n-            ThreadInfo threadInfo = threadBean.getThreadInfo(id);\n+    @Override\n+    @MonitoringData(ns = \"health\", intervalSeconds = 4)\n+    public void collect(MonitoringDataCollector collector) {\n+        if (options == null || !options.isEnabled() || !supported) {\n+            return;\n+        }\n+        AtomicInteger hoggingThreadCount = new AtomicInteger(0);\n+        AtomicLong hoggingThreadMaxDuration = new AtomicLong(0L);\n+        acceptHoggingThreads(colletionRecordsByThreadId, \n+                (percentage, threshold, totalTimeHogging, initialMethod, info) -> {\n+                    String thread = info.getThreadName();\n+                    if (thread == null || thread.isEmpty()) {\n+                        thread = String.valueOf(info.getThreadId());\n+                    }\n+                    collector.annotate(\"HoggingThreadDuration\", totalTimeHogging, true, //\n+                            \"Thread\", thread, //\n+                            \"Usage%\", String.valueOf(percentage), //\n+                            \"Threshold%\", String.valueOf(threshold), //\n+                            \"Method\", initialMethod, //\n+                            \"Exited\", String.valueOf(!initialMethod.equals(getMethod(info))));\n+                    hoggingThreadCount.incrementAndGet();\n+                    hoggingThreadMaxDuration.updateAndGet(value -> Math.max(value, totalTimeHogging));\n+                });\n+        collector\n+        .collect(\"HoggingThreadCount\", hoggingThreadCount)\n+        .collect(\"HoggingThreadDuration\", hoggingThreadMaxDuration);\n+    }\n \n-            if (c == -1 || u == -1)\n-                continue;\n+    @Override\n+    public void collect(MonitoringWatchCollector collector) {\n+        if (options == null || !options.isEnabled() || !supported) {\n+            return;\n+        }\n+        collector.watch(\"ns:health HoggingThreadCount\", \"Hogging Threads\", \"count\")\n+            .amber(0, -2, false, null, null, false)\n+            .red(1, -2, false, null, null, false);\n+    }\n \n-            ThreadTimes times = threadTimes.get(id);\n-            if (times == null) {\n-                times = new ThreadTimes();\n-                times.setId(id);\n-                times.setName(threadInfo.getThreadName());\n-                times.setStartCpuTime(c);\n-                times.setEndCpuTime(c);\n-                times.setStartUserTime(u);\n-                times.setEndUserTime(u);\n-                threadTimes.put(id, times);\n+    private void acceptHoggingThreads(Map<Long, ThreadCpuTimeRecord> recordsById, HoggingThreadConsumer consumer) {\n+        ThreadMXBean bean = ManagementFactory.getThreadMXBean();\n+        long now = System.currentTimeMillis();\n+        long currentThreadId = Thread.currentThread().getId();\n+        int retryCount = options.getRetryCount();\n+        int threshold = options.getThresholdPercentage().intValue();\n+        for (long threadId : bean.getAllThreadIds()) {\n+            if (threadId == currentThreadId)\n+                continue;\n+            final long cpuTimeInNanos = bean.getThreadCpuTime(threadId);\n+            if (cpuTimeInNanos == -1)\n+                continue;\n+            long cpuTime = TimeUnit.NANOSECONDS.toMillis(cpuTimeInNanos); \n+            // from here all times are in millis\n+            ThreadCpuTimeRecord record = recordsById.get(threadId);\n+            if (record == null) {\n+                record = new ThreadCpuTimeRecord();\n+                recordsById.put(threadId, record);\n             } else {\n-                times.setStartCpuTime(times.getEndCpuTime());\n-                times.setStartUserTime(times.getEndUserTime());\n-                times.setEndCpuTime(c);\n-                times.setEndUserTime(u);\n-\n-                long checkTime = getOptions().getUnit().toMillis(getOptions().getTime());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3c882b33e8efc20138ece79385530a3a97946094"}, "originalPosition": 205}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ3NDQ4NTUz", "url": "https://github.com/payara/Payara/pull/4452#pullrequestreview-347448553", "createdAt": "2020-01-23T16:45:15Z", "commit": {"oid": "3c882b33e8efc20138ece79385530a3a97946094"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yM1QxNjo0NToxNVrOFhFMaw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yM1QxNjo0NToxNVrOFhFMaw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIzMjQyNw==", "bodyText": "NB. As discussed in chat the timeHeld here was a semantic confusion. The map contained the timestamp when the thread started the work. I changed the algorithm accordingly and also changed all the computation to be based on milliseconds as nanosecond level only would make sense if we would run the check often and fast enough (every t with a t < 1ms)", "url": "https://github.com/payara/Payara/pull/4452#discussion_r370232427", "createdAt": "2020-01-23T16:45:15Z", "author": {"login": "jbee"}, "path": "nucleus/payara-modules/healthcheck-stuck/src/main/java/fish/payara/nucleus/healthcheck/stuck/StuckThreadsHealthCheck.java", "diffHunk": "@@ -59,58 +69,118 @@\n \n /**\n  * @since 4.1.2.173\n- * @author jonathan coustick\n+ * @author jonathan coustick (initial)\n+ * @author Jan Bernitt (consumer based and monitoring)\n  */\n @Service(name = \"healthcheck-stuck\")\n @RunLevel(StartupRunLevel.VAL)\n public class StuckThreadsHealthCheck extends\n-        BaseHealthCheck<HealthCheckStuckThreadExecutionOptions, StuckThreadsChecker> {\n+        BaseHealthCheck<HealthCheckStuckThreadExecutionOptions, StuckThreadsChecker>\n+        implements MonitoringDataSource, MonitoringWatchSource {\n+\n+    @FunctionalInterface\n+    private interface StuckThreadConsumer {\n+        void accept(long workStartedTime, long timeWorkingInMillis, long thresholdInMillis, ThreadInfo stuck);\n+    }\n \n     @Inject\n     StuckThreadsStore stuckThreadsStore;\n \n     @Inject\n     StuckThreadsChecker checker;\n \n-    private final Map<ThreadInfo, Long> stuckThreads = new ConcurrentHashMap<>();\n-\n     @PostConstruct\n     void postConstruct() {\n         postConstruct(this, StuckThreadsChecker.class);\n     }\n \n     @Override\n     protected HealthCheckResult doCheckInternal() {\n-        stuckThreads.clear();\n         HealthCheckResult result = new HealthCheckResult();\n-        ThreadMXBean bean = ManagementFactory.getThreadMXBean();\n+        acceptStuckThreads((workStartedTime, timeWorkingInMillis, thresholdInMillis, info) ->\n+            result.add(new HealthCheckResultEntry(HealthCheckResultStatus.WARNING, \"Stuck Thread: \" + info.toString())));\n+        return result;\n+    }\n \n-        Long thresholdNanos = TimeUnit.NANOSECONDS.convert(options.getTimeStuck(), options.getUnitStuck());\n+    @Override\n+    @MonitoringData(ns = \"health\", intervalSeconds = 4)\n+    public void collect(MonitoringDataCollector collector) {\n+        if (options == null || !options.isEnabled()) {\n+            return;\n+        }\n+        AtomicInteger count = new AtomicInteger(0);\n+        AtomicLong maxDuration = new AtomicLong(0L);\n+        acceptStuckThreads((workStartedTime, timeWorkingInMillis, thresholdInMillis, info) -> {\n+            String thread = info.getThreadName();\n+            if (thread == null || thread.isEmpty()) {\n+                thread = String.valueOf(info.getThreadId());\n+            }\n+            collector.annotate(\"StuckThreadDuration\", timeWorkingInMillis, true, //\n+                    \"Thread\", thread, // OBS! must be the first attribute as it is the key.\n+                    \"Started\", String.valueOf(workStartedTime), //\n+                    \"Threshold\", String.valueOf(thresholdInMillis), //\n+                    \"Locked\", Boolean.toString(info.getLockInfo() != null), //\n+                    \"Suspended\", String.valueOf(info.isSuspended()), //\n+                    \"State\", composeStateText(info));\n+            count.incrementAndGet();\n+            maxDuration.updateAndGet(value -> Math.max(value, timeWorkingInMillis));\n+        });\n+        collector.collect(\"StuckThreadDuration\", maxDuration);\n+        collector.collect(\"StuckThreadCount\", count);\n+    }\n \n+    @Override\n+    public void collect(MonitoringWatchCollector collector) {\n+        if (options == null || !options.isEnabled()) {\n+            return;\n+        }\n+        collector.watch(\"ns:health StuckThreadDuration\", \"Stuck Threads\", \"ms\")\n+            .red(getThresholdInMillis(), -30000L, false, null, null, false);\n+    }\n+\n+    public String composeStateText(ThreadInfo info) {\n+        if (info.getLockInfo() == null) {\n+            return \"Running\";\n+        }\n+        Thread.State state = info.getThreadState();\n+        String action = state == State.BLOCKED ? \"Blocked on \" //\n+                : state == State.WAITING || state == State.TIMED_WAITING ? \"Waiting on \" : \"Running \";\n+        return action + info.getLockInfo().toString();\n+    }\n+\n+    private void acceptStuckThreads(StuckThreadConsumer consumer) {\n+        ThreadMXBean bean = ManagementFactory.getThreadMXBean();\n+        long thresholdInMillis = getThresholdInMillis();\n+        long now = System.currentTimeMillis();\n         ConcurrentHashMap<Long, Long> threads = stuckThreadsStore.getThreads();\n-        for (Long thread : threads.keySet()){\n-            Long timeHeld = threads.get(thread);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3c882b33e8efc20138ece79385530a3a97946094"}, "originalPosition": 134}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ3ODk2NDE1", "url": "https://github.com/payara/Payara/pull/4452#pullrequestreview-347896415", "createdAt": "2020-01-24T11:31:16Z", "commit": {"oid": "3c882b33e8efc20138ece79385530a3a97946094"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yNFQxMTozMToxNlrOFhbBaQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wMS0yNFQxMjozMjoxN1rOFhcSSg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDU5MDA1Nw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                            annotations.poll();\n          \n          \n            \n                        annotations.poll();\n          \n      \n    \n    \n  \n\nRandom double indent", "url": "https://github.com/payara/Payara/pull/4452#discussion_r370590057", "createdAt": "2020-01-24T11:31:16Z", "author": {"login": "Pandrex247"}, "path": "appserver/monitoring-console/core/src/main/java/fish/payara/monitoring/store/InMemoryMonitoringDataRepository.java", "diffHunk": "@@ -289,19 +291,22 @@ private void addLocalPoint(CharSequence key, long value) {\n         }\n     }\n \n-    private void addLocalAnnotation(CharSequence series, long value, String[] annotations) {\n+    private void addLocalAnnotation(CharSequence series, long value, boolean keyed, String[] annotations) {\n         Series s = seriesOrNull(series);\n         if (s != null) {\n-            addAnnotation(new SeriesAnnotation(collectedSecond, s, instanceName, value, annotations));\n+            addAnnotation(new SeriesAnnotation(collectedSecond, s, instanceName, value, keyed, annotations));\n         }\n     }\n \n     private void addAnnotation(SeriesAnnotation annotation) {\n         Queue<SeriesAnnotation> annotations = annotationsBySeries.computeIfAbsent(annotation.getSeries(), //\n                 key -> new ConcurrentLinkedQueue<>());\n+        if (annotation.isKeyed()) {\n+            annotations.removeIf(a -> Objects.equals(a.getKeyAttribute(), annotation.getKeyAttribute()));\n+        }\n         annotations.add(annotation);\n-        if (annotations.size() > 20) {\n-            annotations.poll();\n+        if (annotations.size() > MAX_ANNOTATIONS_PER_SERIES) {\n+                annotations.poll();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3c882b33e8efc20138ece79385530a3a97946094"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDU5MDc2NA==", "bodyText": "Just checking - should Usage and Threshold have the %?", "url": "https://github.com/payara/Payara/pull/4452#discussion_r370590764", "createdAt": "2020-01-24T11:33:17Z", "author": {"login": "Pandrex247"}, "path": "appserver/monitoring-console/webapp/src/main/webapp/js/mc-model.js", "diffHunk": "@@ -262,6 +262,24 @@ MonitoringConsole.Model = (function() {\n \t\t\t\t\t\t\tdecorations: { alerts: { noOngoing: true, noAcknowledged: true}},\n \t\t\t\t\t\t\toptions: { noAnnotations: true}},\n \t\t\t\t\t],\n+\t\t\t\t},\n+\t\t\t\tthreads: {\n+\t\t\t\t\tname: 'Threads',\n+\t\t\t\t\tnumberOfColumns: 4,\n+\t\t\t\t\twidgets: [\n+\t\t\t\t\t\t{ series: 'ns:health StuckThreadDuration', type: 'annotation', mode: 'table', unit: 'ms',\n+\t\t\t\t\t\t\tdisplayName: 'Stuck Thread Incidents',\n+\t\t\t\t\t\t\tgrid: {column: 0, item: 1, colspan: 3, rowspan: 1},\n+\t\t\t\t\t\t\tfields: [\"Thread\", \"Started\", \"Value\", \"Threshold\", \"Suspended\", \"Locked\", \"State\"]},\n+\t\t\t\t\t\t{ series: 'ns:health HoggingThreadDuration', type: 'annotation', mode: 'table', unit: 'ms',\n+\t\t\t\t\t\t\tdisplayName: 'Hogging Thread Incidents',\n+\t\t\t\t\t\t\tgrid: {column: 0, item: 2, colspan: 3, rowspan: 1},\n+\t\t\t\t\t\t\tfields: [\"Thread\", \"When\", \"Value\", \"Usage%\", \"Threshold%\", \"Method\", \"Exited\"]},", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3c882b33e8efc20138ece79385530a3a97946094"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDYwNzM1Nw==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    .collect(\"HoggingThreadCount\", hoggingThreadCount)\n          \n          \n            \n                            .collect(\"HoggingThreadCount\", hoggingThreadCount)\n          \n      \n    \n    \n  \n\nIndenting", "url": "https://github.com/payara/Payara/pull/4452#discussion_r370607357", "createdAt": "2020-01-24T12:22:08Z", "author": {"login": "Pandrex247"}, "path": "nucleus/payara-modules/healthcheck-core/src/main/java/fish/payara/nucleus/healthcheck/preliminary/HoggingThreadsHealthCheck.java", "diffHunk": "@@ -91,65 +142,107 @@ public String getDescription() {\n \n     @Override\n     protected HealthCheckResult doCheckInternal() {\n-        hoggingThreads.set(0);\n         HealthCheckResult result = new HealthCheckResult();\n-        ThreadMXBean threadBean = ManagementFactory.getThreadMXBean();\n-\n-        if (!threadBean.isCurrentThreadCpuTimeSupported()) {\n+        if (!supported) {\n             result.add(new HealthCheckResultEntry(HealthCheckResultStatus.CHECK_ERROR, \"JVM implementation or OS does\" +\n                     \" not support getting CPU times\"));\n             return result;\n         }\n+        acceptHoggingThreads(checkRecordsByThreadId, \n+                (percentage, threshold, totalTimeHogging, initialMethod, info) -> {\n+                    result.add(new HealthCheckResultEntry(HealthCheckResultStatus.CRITICAL,\n+                            \"Thread with <id-name>: \" + info.getThreadId() + \"-\" + info.getThreadName() +\n+                            \" is a hogging thread for the last \" +\n+                            prettyPrintDuration(totalTimeHogging) + \"\\n\" + prettyPrintStackTrace(info.getStackTrace())));\n+                });\n+        return result;\n+    }\n \n-        final long[] ids = threadBean.getAllThreadIds();\n-        for (long id : ids) {\n-            if (id == Thread.currentThread().getId())\n-                continue;\n-            final long c = threadBean.getThreadCpuTime(id);\n-            final long u = threadBean.getThreadUserTime(id);\n-            ThreadInfo threadInfo = threadBean.getThreadInfo(id);\n+    @Override\n+    @MonitoringData(ns = \"health\", intervalSeconds = 4)\n+    public void collect(MonitoringDataCollector collector) {\n+        if (options == null || !options.isEnabled() || !supported) {\n+            return;\n+        }\n+        AtomicInteger hoggingThreadCount = new AtomicInteger(0);\n+        AtomicLong hoggingThreadMaxDuration = new AtomicLong(0L);\n+        acceptHoggingThreads(colletionRecordsByThreadId, \n+                (percentage, threshold, totalTimeHogging, initialMethod, info) -> {\n+                    String thread = info.getThreadName();\n+                    if (thread == null || thread.isEmpty()) {\n+                        thread = String.valueOf(info.getThreadId());\n+                    }\n+                    collector.annotate(\"HoggingThreadDuration\", totalTimeHogging, true, //\n+                            \"Thread\", thread, //\n+                            \"Usage%\", String.valueOf(percentage), //\n+                            \"Threshold%\", String.valueOf(threshold), //\n+                            \"Method\", initialMethod, //\n+                            \"Exited\", String.valueOf(!initialMethod.equals(getMethod(info))));\n+                    hoggingThreadCount.incrementAndGet();\n+                    hoggingThreadMaxDuration.updateAndGet(value -> Math.max(value, totalTimeHogging));\n+                });\n+        collector\n+        .collect(\"HoggingThreadCount\", hoggingThreadCount)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3c882b33e8efc20138ece79385530a3a97946094"}, "originalPosition": 155}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDYwNzYyOA==", "bodyText": "Suggested change\n        \n          \n    \n\n        \n      \n    \n    \n      \n          \n            \n                    .collect(\"HoggingThreadDuration\", hoggingThreadMaxDuration);\n          \n          \n            \n                            .collect(\"HoggingThreadDuration\", hoggingThreadMaxDuration);\n          \n      \n    \n    \n  \n\nIndenting 2: The tab vs. space wars", "url": "https://github.com/payara/Payara/pull/4452#discussion_r370607628", "createdAt": "2020-01-24T12:22:56Z", "author": {"login": "Pandrex247"}, "path": "nucleus/payara-modules/healthcheck-core/src/main/java/fish/payara/nucleus/healthcheck/preliminary/HoggingThreadsHealthCheck.java", "diffHunk": "@@ -91,65 +142,107 @@ public String getDescription() {\n \n     @Override\n     protected HealthCheckResult doCheckInternal() {\n-        hoggingThreads.set(0);\n         HealthCheckResult result = new HealthCheckResult();\n-        ThreadMXBean threadBean = ManagementFactory.getThreadMXBean();\n-\n-        if (!threadBean.isCurrentThreadCpuTimeSupported()) {\n+        if (!supported) {\n             result.add(new HealthCheckResultEntry(HealthCheckResultStatus.CHECK_ERROR, \"JVM implementation or OS does\" +\n                     \" not support getting CPU times\"));\n             return result;\n         }\n+        acceptHoggingThreads(checkRecordsByThreadId, \n+                (percentage, threshold, totalTimeHogging, initialMethod, info) -> {\n+                    result.add(new HealthCheckResultEntry(HealthCheckResultStatus.CRITICAL,\n+                            \"Thread with <id-name>: \" + info.getThreadId() + \"-\" + info.getThreadName() +\n+                            \" is a hogging thread for the last \" +\n+                            prettyPrintDuration(totalTimeHogging) + \"\\n\" + prettyPrintStackTrace(info.getStackTrace())));\n+                });\n+        return result;\n+    }\n \n-        final long[] ids = threadBean.getAllThreadIds();\n-        for (long id : ids) {\n-            if (id == Thread.currentThread().getId())\n-                continue;\n-            final long c = threadBean.getThreadCpuTime(id);\n-            final long u = threadBean.getThreadUserTime(id);\n-            ThreadInfo threadInfo = threadBean.getThreadInfo(id);\n+    @Override\n+    @MonitoringData(ns = \"health\", intervalSeconds = 4)\n+    public void collect(MonitoringDataCollector collector) {\n+        if (options == null || !options.isEnabled() || !supported) {\n+            return;\n+        }\n+        AtomicInteger hoggingThreadCount = new AtomicInteger(0);\n+        AtomicLong hoggingThreadMaxDuration = new AtomicLong(0L);\n+        acceptHoggingThreads(colletionRecordsByThreadId, \n+                (percentage, threshold, totalTimeHogging, initialMethod, info) -> {\n+                    String thread = info.getThreadName();\n+                    if (thread == null || thread.isEmpty()) {\n+                        thread = String.valueOf(info.getThreadId());\n+                    }\n+                    collector.annotate(\"HoggingThreadDuration\", totalTimeHogging, true, //\n+                            \"Thread\", thread, //\n+                            \"Usage%\", String.valueOf(percentage), //\n+                            \"Threshold%\", String.valueOf(threshold), //\n+                            \"Method\", initialMethod, //\n+                            \"Exited\", String.valueOf(!initialMethod.equals(getMethod(info))));\n+                    hoggingThreadCount.incrementAndGet();\n+                    hoggingThreadMaxDuration.updateAndGet(value -> Math.max(value, totalTimeHogging));\n+                });\n+        collector\n+        .collect(\"HoggingThreadCount\", hoggingThreadCount)\n+        .collect(\"HoggingThreadDuration\", hoggingThreadMaxDuration);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3c882b33e8efc20138ece79385530a3a97946094"}, "originalPosition": 156}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDYxMDc2Mg==", "bodyText": "I think this possibly needs a bit more cleanup, as you can still configure it with a threshold of 5 nanoseconds.\nParticularly in the monitoring console you get a funny situation where you get a Threshold listed as 0 in comparison to something like 5ms. In this case, you could possibly change it to have it say the threshold is <1ms", "url": "https://github.com/payara/Payara/pull/4452#discussion_r370610762", "createdAt": "2020-01-24T12:32:17Z", "author": {"login": "Pandrex247"}, "path": "nucleus/payara-modules/healthcheck-stuck/src/main/java/fish/payara/nucleus/healthcheck/stuck/StuckThreadsHealthCheck.java", "diffHunk": "@@ -59,58 +69,118 @@\n \n /**\n  * @since 4.1.2.173\n- * @author jonathan coustick\n+ * @author jonathan coustick (initial)\n+ * @author Jan Bernitt (consumer based and monitoring)\n  */\n @Service(name = \"healthcheck-stuck\")\n @RunLevel(StartupRunLevel.VAL)\n public class StuckThreadsHealthCheck extends\n-        BaseHealthCheck<HealthCheckStuckThreadExecutionOptions, StuckThreadsChecker> {\n+        BaseHealthCheck<HealthCheckStuckThreadExecutionOptions, StuckThreadsChecker>\n+        implements MonitoringDataSource, MonitoringWatchSource {\n+\n+    @FunctionalInterface\n+    private interface StuckThreadConsumer {\n+        void accept(long workStartedTime, long timeWorkingInMillis, long thresholdInMillis, ThreadInfo stuck);\n+    }\n \n     @Inject\n     StuckThreadsStore stuckThreadsStore;\n \n     @Inject\n     StuckThreadsChecker checker;\n \n-    private final Map<ThreadInfo, Long> stuckThreads = new ConcurrentHashMap<>();\n-\n     @PostConstruct\n     void postConstruct() {\n         postConstruct(this, StuckThreadsChecker.class);\n     }\n \n     @Override\n     protected HealthCheckResult doCheckInternal() {\n-        stuckThreads.clear();\n         HealthCheckResult result = new HealthCheckResult();\n-        ThreadMXBean bean = ManagementFactory.getThreadMXBean();\n+        acceptStuckThreads((workStartedTime, timeWorkingInMillis, thresholdInMillis, info) ->\n+            result.add(new HealthCheckResultEntry(HealthCheckResultStatus.WARNING, \"Stuck Thread: \" + info.toString())));\n+        return result;\n+    }\n \n-        Long thresholdNanos = TimeUnit.NANOSECONDS.convert(options.getTimeStuck(), options.getUnitStuck());\n+    @Override\n+    @MonitoringData(ns = \"health\", intervalSeconds = 4)\n+    public void collect(MonitoringDataCollector collector) {\n+        if (options == null || !options.isEnabled()) {\n+            return;\n+        }\n+        AtomicInteger count = new AtomicInteger(0);\n+        AtomicLong maxDuration = new AtomicLong(0L);\n+        acceptStuckThreads((workStartedTime, timeWorkingInMillis, thresholdInMillis, info) -> {\n+            String thread = info.getThreadName();\n+            if (thread == null || thread.isEmpty()) {\n+                thread = String.valueOf(info.getThreadId());\n+            }\n+            collector.annotate(\"StuckThreadDuration\", timeWorkingInMillis, true, //\n+                    \"Thread\", thread, // OBS! must be the first attribute as it is the key.\n+                    \"Started\", String.valueOf(workStartedTime), //\n+                    \"Threshold\", String.valueOf(thresholdInMillis), //\n+                    \"Locked\", Boolean.toString(info.getLockInfo() != null), //\n+                    \"Suspended\", String.valueOf(info.isSuspended()), //\n+                    \"State\", composeStateText(info));\n+            count.incrementAndGet();\n+            maxDuration.updateAndGet(value -> Math.max(value, timeWorkingInMillis));\n+        });\n+        collector.collect(\"StuckThreadDuration\", maxDuration);\n+        collector.collect(\"StuckThreadCount\", count);\n+    }\n \n+    @Override\n+    public void collect(MonitoringWatchCollector collector) {\n+        if (options == null || !options.isEnabled()) {\n+            return;\n+        }\n+        collector.watch(\"ns:health StuckThreadDuration\", \"Stuck Threads\", \"ms\")\n+            .red(getThresholdInMillis(), -30000L, false, null, null, false);\n+    }\n+\n+    public String composeStateText(ThreadInfo info) {\n+        if (info.getLockInfo() == null) {\n+            return \"Running\";\n+        }\n+        Thread.State state = info.getThreadState();\n+        String action = state == State.BLOCKED ? \"Blocked on \" //\n+                : state == State.WAITING || state == State.TIMED_WAITING ? \"Waiting on \" : \"Running \";\n+        return action + info.getLockInfo().toString();\n+    }\n+\n+    private void acceptStuckThreads(StuckThreadConsumer consumer) {\n+        ThreadMXBean bean = ManagementFactory.getThreadMXBean();\n+        long thresholdInMillis = getThresholdInMillis();\n+        long now = System.currentTimeMillis();\n         ConcurrentHashMap<Long, Long> threads = stuckThreadsStore.getThreads();\n-        for (Long thread : threads.keySet()){\n-            Long timeHeld = threads.get(thread);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDM3MDIzMjQyNw=="}, "originalCommit": {"oid": "3c882b33e8efc20138ece79385530a3a97946094"}, "originalPosition": 134}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a27d926445481241b78921d4deed860d546e9d89", "author": {"user": {"login": "jbee", "name": "Jan Bernitt"}}, "url": "https://github.com/payara/Payara/commit/a27d926445481241b78921d4deed860d546e9d89", "committedDate": "2020-01-24T13:14:06Z", "message": "Update appserver/monitoring-console/core/src/main/java/fish/payara/monitoring/store/InMemoryMonitoringDataRepository.java\n\nCo-Authored-By: Andrew Pielage <pandrex247@hotmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2ede58b607f9213d05cfbcc1eeef132a76d7b34e", "author": {"user": {"login": "jbee", "name": "Jan Bernitt"}}, "url": "https://github.com/payara/Payara/commit/2ede58b607f9213d05cfbcc1eeef132a76d7b34e", "committedDate": "2020-01-24T13:14:56Z", "message": "Update nucleus/payara-modules/healthcheck-core/src/main/java/fish/payara/nucleus/healthcheck/preliminary/HoggingThreadsHealthCheck.java\n\nCo-Authored-By: Andrew Pielage <pandrex247@hotmail.com>"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "268fd2a3e00c3fd29089de5498c07fb081b44cf8", "author": {"user": {"login": "jbee", "name": "Jan Bernitt"}}, "url": "https://github.com/payara/Payara/commit/268fd2a3e00c3fd29089de5498c07fb081b44cf8", "committedDate": "2020-01-24T13:15:05Z", "message": "Update nucleus/payara-modules/healthcheck-core/src/main/java/fish/payara/nucleus/healthcheck/preliminary/HoggingThreadsHealthCheck.java\n\nCo-Authored-By: Andrew Pielage <pandrex247@hotmail.com>"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3MzQ3OTgxMTUy", "url": "https://github.com/payara/Payara/pull/4452#pullrequestreview-347981152", "createdAt": "2020-01-24T14:18:03Z", "commit": {"oid": "268fd2a3e00c3fd29089de5498c07fb081b44cf8"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 848, "cost": 1, "resetAt": "2021-11-01T16:19:10Z"}}}