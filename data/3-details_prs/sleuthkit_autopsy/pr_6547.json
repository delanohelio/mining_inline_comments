{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTM3Mjk5MjI3", "number": 6547, "title": "7105 domain categories", "bodyText": "", "createdAt": "2020-12-11T19:19:32Z", "url": "https://github.com/sleuthkit/autopsy/pull/6547", "merged": true, "mergeCommit": {"oid": "0a9f9dd8857c5446acccb31ac2aad648a47937f6"}, "closed": true, "closedAt": "2020-12-15T21:46:11Z", "author": {"login": "gdicristofaro"}, "timelineItems": {"totalCount": 20, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdi-OlJAH2gAyNTM3Mjk5MjI3OjhjNzE1NWMzYTFmYzg0ZDg2NTg5YmMyM2NjOTg4NGUzMzcyNjNmMzY=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdmhdlGAFqTU1MjkzMTc2OQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "8c7155c3a1fc84d86589bc23cc9884e337263f36", "author": {"user": {"login": "gdicristofaro", "name": "Greg DiCristofaro"}}, "url": "https://github.com/sleuthkit/autopsy/commit/8c7155c3a1fc84d86589bc23cc9884e337263f36", "committedDate": "2020-12-04T21:00:42Z", "message": "refactoring"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fd5d759d2a828bc39d01af7a3b23356771725c21", "author": {"user": {"login": "gdicristofaro", "name": "Greg DiCristofaro"}}, "url": "https://github.com/sleuthkit/autopsy/commit/fd5d759d2a828bc39d01af7a3b23356771725c21", "committedDate": "2020-12-07T21:35:35Z", "message": "public Core package"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6793bd7dc9518ff1e11ae237dcacf34feaf8ccd4", "author": {"user": {"login": "gdicristofaro", "name": "Greg DiCristofaro"}}, "url": "https://github.com/sleuthkit/autopsy/commit/6793bd7dc9518ff1e11ae237dcacf34feaf8ccd4", "committedDate": "2020-12-08T21:23:32Z", "message": "working through domain to sqlite"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "18ceef0ca59060bea15b47e4e6c3ab99ab05a1e9", "author": {"user": {"login": "gdicristofaro", "name": "Greg DiCristofaro"}}, "url": "https://github.com/sleuthkit/autopsy/commit/18ceef0ca59060bea15b47e4e6c3ab99ab05a1e9", "committedDate": "2020-12-09T16:07:32Z", "message": "updates for closeable"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fb5907aa8cb7632764ff78b4f69b388ae5409bb2", "author": {"user": {"login": "gdicristofaro", "name": "Greg DiCristofaro"}}, "url": "https://github.com/sleuthkit/autopsy/commit/fb5907aa8cb7632764ff78b4f69b388ae5409bb2", "committedDate": "2020-12-09T21:07:50Z", "message": "debugging"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6fe64f3bd063fb066744008c0f80aa773dd83d5c", "author": {"user": {"login": "gdicristofaro", "name": "Greg DiCristofaro"}}, "url": "https://github.com/sleuthkit/autopsy/commit/6fe64f3bd063fb066744008c0f80aa773dd83d5c", "committedDate": "2020-12-10T12:40:48Z", "message": "update for defensive code"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a2ecd38e3a269957de56b1698c720cde9fa14806", "author": {"user": {"login": "gdicristofaro", "name": "Greg DiCristofaro"}}, "url": "https://github.com/sleuthkit/autopsy/commit/a2ecd38e3a269957de56b1698c720cde9fa14806", "committedDate": "2020-12-10T15:19:53Z", "message": "refactoring"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f643c44fa5df2a14726a1bb2d31bebeb1e44feba", "author": {"user": {"login": "gdicristofaro", "name": "Greg DiCristofaro"}}, "url": "https://github.com/sleuthkit/autopsy/commit/f643c44fa5df2a14726a1bb2d31bebeb1e44feba", "committedDate": "2020-12-10T17:07:49Z", "message": "debug"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7e8271ed41554b6231c8cc57ba4f387be550f63b", "author": {"user": {"login": "gdicristofaro", "name": "Greg DiCristofaro"}}, "url": "https://github.com/sleuthkit/autopsy/commit/7e8271ed41554b6231c8cc57ba4f387be550f63b", "committedDate": "2020-12-10T17:08:00Z", "message": "Merge branch 'develop' of github.com:sleuthkit/autopsy into 7105-domainCategories"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c8b79fc8874a9673101398767ca2b545bffa52c0", "author": {"user": {"login": "gdicristofaro", "name": "Greg DiCristofaro"}}, "url": "https://github.com/sleuthkit/autopsy/commit/c8b79fc8874a9673101398767ca2b545bffa52c0", "committedDate": "2020-12-11T12:47:04Z", "message": "Merge branch 'develop' of github.com:sleuthkit/autopsy into 7105-domainCategories"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b0eb8942e128a9e3167ff81f80a69b5d734285af", "author": {"user": {"login": "gdicristofaro", "name": "Greg DiCristofaro"}}, "url": "https://github.com/sleuthkit/autopsy/commit/b0eb8942e128a9e3167ff81f80a69b5d734285af", "committedDate": "2020-12-11T13:11:11Z", "message": "formatting and commenting"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "11cf9b13458109b0e5718400c941c420c9e617a6", "author": {"user": {"login": "gdicristofaro", "name": "Greg DiCristofaro"}}, "url": "https://github.com/sleuthkit/autopsy/commit/11cf9b13458109b0e5718400c941c420c9e617a6", "committedDate": "2020-12-11T16:33:24Z", "message": "ordering fix"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "94466791e8cad96d263dfd32a820708043ccc357", "author": {"user": {"login": "gdicristofaro", "name": "Greg DiCristofaro"}}, "url": "https://github.com/sleuthkit/autopsy/commit/94466791e8cad96d263dfd32a820708043ccc357", "committedDate": "2020-12-11T16:42:40Z", "message": "comment update"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8d2440e3e74655c92da57d83788f92f4d01b30e2", "author": {"user": {"login": "gdicristofaro", "name": "Greg DiCristofaro"}}, "url": "https://github.com/sleuthkit/autopsy/commit/8d2440e3e74655c92da57d83788f92f4d01b30e2", "committedDate": "2020-12-11T18:51:52Z", "message": "public api refinement"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e186d0a9f818d8b4e0910dd0668ba4846a793045", "author": {"user": {"login": "gdicristofaro", "name": "Greg DiCristofaro"}}, "url": "https://github.com/sleuthkit/autopsy/commit/e186d0a9f818d8b4e0910dd0668ba4846a793045", "committedDate": "2020-12-11T19:14:26Z", "message": "bundle update"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ed944d3b599259571dd60fa2b7a60f87450a712b", "author": {"user": {"login": "gdicristofaro", "name": "Greg DiCristofaro"}}, "url": "https://github.com/sleuthkit/autopsy/commit/ed944d3b599259571dd60fa2b7a60f87450a712b", "committedDate": "2020-12-11T19:19:56Z", "message": "Merge branch 'develop' of github.com:sleuthkit/autopsy into 7105-domainCategories"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "72096de18b100dd1318d4d6de50ee983ad61d195", "author": {"user": {"login": "gdicristofaro", "name": "Greg DiCristofaro"}}, "url": "https://github.com/sleuthkit/autopsy/commit/72096de18b100dd1318d4d6de50ee983ad61d195", "committedDate": "2020-12-11T19:51:35Z", "message": "DomainCategory to concrete class and change service provider notation for Default Categorizer"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUxODc5NDAw", "url": "https://github.com/sleuthkit/autopsy/pull/6547#pullrequestreview-551879400", "createdAt": "2020-12-14T20:47:20Z", "commit": {"oid": "72096de18b100dd1318d4d6de50ee983ad61d195"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQyMDo0NzoyMVrOIFn0Qg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xNFQyMTowNDowOVrOIFo5ug==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mjc2NjE0Ng==", "bodyText": "Missing header", "url": "https://github.com/sleuthkit/autopsy/pull/6547#discussion_r542766146", "createdAt": "2020-12-14T20:47:21Z", "author": {"login": "dannysmyda"}, "path": "Core/src/org/sleuthkit/autopsy/url/analytics/DomainCategorizerException.java", "diffHunk": "@@ -0,0 +1,29 @@\n+/*\n+ * To change this license header, choose License Headers in Project Properties.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "72096de18b100dd1318d4d6de50ee983ad61d195"}, "originalPosition": 2}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mjc4MTcwMA==", "bodyText": "Can foundProviders be null? I don't think so, but even if it could, you would get an NPE on line 367.", "url": "https://github.com/sleuthkit/autopsy/pull/6547#discussion_r542781700", "createdAt": "2020-12-14T21:02:02Z", "author": {"login": "dannysmyda"}, "path": "RecentActivity/src/org/sleuthkit/autopsy/recentactivity/DomainCategoryRunner.java", "diffHunk": "@@ -0,0 +1,396 @@\n+/*\n+ * Autopsy Forensic Browser\n+ *\n+ * Copyright 2020 Basis Technology Corp.\n+ * Contact: carrier <at> sleuthkit <dot> org\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.sleuthkit.autopsy.recentactivity;\n+\n+import java.net.MalformedURLException;\n+import java.net.URL;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.logging.Level;\n+import java.util.Set;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n+import org.apache.commons.lang.StringUtils;\n+import org.openide.util.Lookup;\n+import org.openide.util.NbBundle.Messages;\n+import org.sleuthkit.autopsy.coreutils.Logger;\n+import org.sleuthkit.autopsy.coreutils.NetworkUtils;\n+import org.sleuthkit.autopsy.ingest.DataSourceIngestModuleProgress;\n+import org.sleuthkit.autopsy.ingest.IngestJobContext;\n+import org.sleuthkit.autopsy.ingest.IngestModule;\n+import org.sleuthkit.datamodel.AbstractFile;\n+import org.sleuthkit.datamodel.BlackboardArtifact;\n+import org.sleuthkit.datamodel.BlackboardArtifact.ARTIFACT_TYPE;\n+import org.sleuthkit.datamodel.BlackboardAttribute;\n+import org.sleuthkit.datamodel.BlackboardAttribute.ATTRIBUTE_TYPE;\n+import org.sleuthkit.datamodel.Content;\n+import org.sleuthkit.datamodel.TskCoreException;\n+import org.sleuthkit.autopsy.url.analytics.DomainCategorizer;\n+import org.sleuthkit.autopsy.url.analytics.DomainCategorizerException;\n+import org.sleuthkit.autopsy.url.analytics.DomainCategory;\n+\n+/**\n+ * Analyzes a URL to determine if the url host is one of a certain kind of\n+ * category (i.e. webmail, disposable mail). If found, a web category artifact\n+ * is created.\n+ */\n+@Messages({\n+    \"DomainCategoryRunner_moduleName_text=DomainCategoryRunner\",\n+    \"DomainCategoryRunner_Progress_Message_Domain_Types=Finding Domain Types\",\n+    \"DomainCategoryRunner_parentModuleName=Recent Activity\"\n+})\n+class DomainCategoryRunner extends Extract {\n+\n+    // The url regex is based on the regex provided in https://tools.ietf.org/html/rfc3986#appendix-B\n+    // but expanded to be a little more flexible.  This regex also properly parses user info and port in a url.\n+    // this regex has optional colon in front of the scheme (i.e. http// instead of http://) since some urls were coming through without the colon.\n+    private static final String URL_REGEX_SCHEME = \"(((?<scheme>[^:\\\\/?#]+):?)?\\\\/\\\\/)\";\n+\n+    private static final String URL_REGEX_USERINFO = \"((?<userinfo>[^\\\\/?#@]*)@)\";\n+    private static final String URL_REGEX_HOST = \"(?<host>[^\\\\/\\\\.?#:]*\\\\.[^\\\\/?#:]*)\";\n+    private static final String URL_REGEX_PORT = \"(:(?<port>[0-9]{1,5}))\";\n+    private static final String URL_REGEX_AUTHORITY = String.format(\"(%s?%s?%s?\\\\/?)\", URL_REGEX_USERINFO, URL_REGEX_HOST, URL_REGEX_PORT);\n+\n+    private static final String URL_REGEX_PATH = \"(?<path>([^?#]*)(\\\\?([^#]*))?(#(.*))?)\";\n+\n+    private static final String URL_REGEX_STR = String.format(\"^\\\\s*%s?%s?%s?\", URL_REGEX_SCHEME, URL_REGEX_AUTHORITY, URL_REGEX_PATH);\n+    private static final Pattern URL_REGEX = Pattern.compile(URL_REGEX_STR);\n+\n+    private static final Logger logger = Logger.getLogger(DomainCategoryRunner.class.getName());\n+\n+    private Content dataSource;\n+    private IngestJobContext context;\n+    private List<DomainCategorizer> domainProviders = Collections.emptyList();\n+\n+    /**\n+     * Main constructor.\n+     */\n+    DomainCategoryRunner() {\n+        moduleName = null;\n+    }\n+\n+    /**\n+     * Attempts to determine the host from the url string. If none can be\n+     * determined, returns null.\n+     *\n+     * @param urlString The url string.\n+     * @return The host or null if cannot be determined.\n+     */\n+    private String getHost(String urlString) {\n+        String host = null;\n+        try {\n+            // try first using the built-in url class to determine the host.\n+            URL url = new URL(urlString);\n+            if (url != null) {\n+                host = url.getHost();\n+            }\n+        } catch (MalformedURLException ignore) {\n+            // ignore this and go to fallback regex\n+        }\n+\n+        // if the built-in url parsing doesn't work, then use more flexible regex.\n+        if (StringUtils.isBlank(host)) {\n+            Matcher m = URL_REGEX.matcher(urlString);\n+            if (m.find()) {\n+                host = m.group(\"host\");\n+            }\n+        }\n+\n+        return host;\n+    }\n+\n+    /**\n+     * Attempts to find the category for the given host/domain.\n+     *\n+     * @param domain The domain for the item.\n+     * @param host The host for the item.\n+     * @return The domain category result or null if none can be determined.\n+     */\n+    private DomainCategory findCategory(String domain, String host) {\n+        List<DomainCategorizer> safeProviders = domainProviders == null ? Collections.emptyList() : domainProviders;\n+        for (DomainCategorizer provider : safeProviders) {\n+            DomainCategory result;\n+            try {\n+                result = provider.getCategory(domain, host);\n+                if (result != null) {\n+                    return result;\n+                }\n+            } catch (DomainCategorizerException ex) {\n+                logger.log(Level.WARNING, \"There was an error processing results with \" + provider.getClass().getCanonicalName(), ex);\n+            }\n+\n+        }\n+\n+        return null;\n+    }\n+\n+    /**\n+     * Information concerning an artifact's host, domain, and parent file.\n+     */\n+    private static class ArtifactHost {\n+\n+        private final AbstractFile abstractFile;\n+        private final String host;\n+        private final String domain;\n+\n+        /**\n+         * Main constructor.\n+         *\n+         * @param abstractFile The parent file of the artifact.\n+         * @param host The host of the artifact found in the url attribute.\n+         * @param domain The domain of the artifact in the TSK_DOMAIN attribute.\n+         */\n+        ArtifactHost(AbstractFile abstractFile, String host, String domain) {\n+            this.abstractFile = abstractFile;\n+            this.host = host;\n+            this.domain = domain;\n+        }\n+\n+        /**\n+         * @return The parent file of this artifact.\n+         */\n+        AbstractFile getAbstractFile() {\n+            return abstractFile;\n+        }\n+\n+        /**\n+         * @return The host of this artifact if one can be determined.\n+         */\n+        String getHost() {\n+            return host;\n+        }\n+\n+        /**\n+         * @return The domain of the artifact.\n+         */\n+        String getDomain() {\n+            return domain;\n+        }\n+    }\n+\n+    /**\n+     * Determines pertinent information in the artifact like host, domain, and\n+     * parent file.\n+     *\n+     * @param artifact The web artifact to parse.\n+     * @return The pertinent information or null if important information cannot\n+     * be determined.\n+     * @throws TskCoreException\n+     */\n+    private ArtifactHost getDomainAndHost(BlackboardArtifact artifact) throws TskCoreException {\n+        // make sure there is attached file\n+        AbstractFile file = tskCase.getAbstractFileById(artifact.getObjectID());\n+        if (file == null) {\n+            return null;\n+        }\n+\n+        // get the host from the url attribute and the domain from the attribute\n+        BlackboardAttribute urlAttr = artifact.getAttribute(new BlackboardAttribute.Type(BlackboardAttribute.ATTRIBUTE_TYPE.TSK_URL));\n+        String urlString = null;\n+        String host = null;\n+        if (urlAttr != null) {\n+            urlString = urlAttr.getValueString();\n+            if (StringUtils.isNotBlank(urlString)) {\n+                host = getHost(urlString);\n+            }\n+        }\n+\n+        // get the domain from the attribute\n+        BlackboardAttribute domainAttr = artifact.getAttribute(new BlackboardAttribute.Type(BlackboardAttribute.ATTRIBUTE_TYPE.TSK_DOMAIN));\n+        String domainString = null;\n+        if (domainAttr != null) {\n+            domainString = domainAttr.getValueString();\n+        }\n+\n+        boolean hasDomain = StringUtils.isNotBlank(domainString);\n+        boolean hasHost = StringUtils.isNotBlank(host);\n+\n+        // we need at least a host or a domain, if one is missing, compensate with the other.\n+        if (!hasDomain && !hasHost) {\n+            return null;\n+        } else if (!hasDomain) {\n+            domainString = NetworkUtils.extractDomain(host);\n+        } else if (!hasHost) {\n+            host = domainString;\n+        }\n+\n+        return new ArtifactHost(file, host.toLowerCase(), domainString.toLowerCase());\n+    }\n+\n+    /**\n+     * Determines if the given item is already found in the set. If not, the\n+     * item is added to the set.\n+     *\n+     * @param items The set of items.\n+     * @param item The item whose existence will be checked in the set.\n+     * @return True if item is already contained in 'items'. False if the is\n+     * null or if not contained in 'items'.\n+     */\n+    private static boolean isDuplicateOrAdd(Set<String> items, String item) {\n+        if (StringUtils.isBlank(item)) {\n+            return false;\n+        } else if (items.contains(item)) {\n+            return true;\n+        } else {\n+            items.add(item);\n+            return false;\n+        }\n+    }\n+\n+    /**\n+     * Goes through web history artifacts and attempts to determine any hosts of\n+     * a domain type. If any are found, a TSK_WEB_CATEGORIZATION artifact is\n+     * created (at most one per host suffix).\n+     */\n+    private void findDomainTypes() {\n+        int artifactsAnalyzed = 0;\n+        int domainTypeInstancesFound = 0;\n+\n+        // this will track the different hosts seen to avoid a search for the same host more than once\n+        Set<String> hostsSeen = new HashSet<>();\n+\n+        // only one suffix per ingest is captured so this tracks the suffixes seen.\n+        Set<String> hostSuffixesSeen = new HashSet<>();\n+        try {\n+            Collection<BlackboardArtifact> listArtifacts = currentCase.getSleuthkitCase().getBlackboard().getArtifacts(\n+                    Arrays.asList(new BlackboardArtifact.Type(ARTIFACT_TYPE.TSK_WEB_HISTORY)),\n+                    Arrays.asList(dataSource.getId()));\n+\n+            logger.log(Level.INFO, \"Processing {0} blackboard artifacts.\", listArtifacts.size()); //NON-NLS\n+\n+            for (BlackboardArtifact artifact : listArtifacts) {\n+                // make sure we haven't cancelled\n+                if (context.dataSourceIngestIsCancelled()) {\n+                    break;       //User cancelled the process.\n+                }\n+\n+                // get the pertinent details for this artifact.\n+                ArtifactHost curArtHost = getDomainAndHost(artifact);\n+                if (curArtHost == null || isDuplicateOrAdd(hostsSeen, curArtHost.getHost())) {\n+                    continue;\n+                }\n+\n+                // if we reached this point, we are at least analyzing this item\n+                artifactsAnalyzed++;\n+\n+                // attempt to get the domain type for the host using the suffix trie\n+                DomainCategory domainEntryFound = findCategory(curArtHost.getDomain(), curArtHost.getHost());\n+                if (domainEntryFound == null) {\n+                    continue;\n+                }\n+\n+                // make sure both the host suffix and the category are present.\n+                String hostSuffix = domainEntryFound.getHostSuffix();\n+                String domainCategory = domainEntryFound.getCategory();\n+                if (StringUtils.isBlank(hostSuffix) || StringUtils.isBlank(domainCategory)) {\n+                    continue;\n+                }\n+\n+                // if we got this far, we found a domain type, but it may not be unique\n+                domainTypeInstancesFound++;\n+\n+                if (isDuplicateOrAdd(hostSuffixesSeen, hostSuffix)) {\n+                    continue;\n+                }\n+\n+                // if we got this far, we have a unique domain category to post.\n+                addCategoryArtifact(curArtHost, domainCategory);\n+            }\n+        } catch (TskCoreException e) {\n+            logger.log(Level.SEVERE, \"Encountered error retrieving artifacts for messaging domains\", e); //NON-NLS\n+        } finally {\n+            if (context.dataSourceIngestIsCancelled()) {\n+                logger.info(\"Operation terminated by user.\"); //NON-NLS\n+            }\n+            logger.log(Level.INFO, String.format(\"Extracted %s distinct messaging domain(s) from the blackboard.  \"\n+                    + \"Of the %s artifact(s) with valid hosts, %s url(s) contained messaging domain suffix.\",\n+                    hostSuffixesSeen.size(), artifactsAnalyzed, domainTypeInstancesFound));\n+        }\n+    }\n+\n+    /**\n+     * Adds a TSK_WEB_CATEGORIZATION artifact for the given information.\n+     *\n+     * @param artHost Pertinent details for the artifact (i.e. host, domain,\n+     * parent file).\n+     * @param domainCategory The category for this host/domain.\n+     */\n+    private void addCategoryArtifact(ArtifactHost artHost, String domainCategory) {\n+        String moduleName = Bundle.DomainCategoryRunner_parentModuleName();\n+        Collection<BlackboardAttribute> bbattributes = Arrays.asList(\n+                new BlackboardAttribute(ATTRIBUTE_TYPE.TSK_DOMAIN, moduleName, artHost.getDomain()),\n+                new BlackboardAttribute(ATTRIBUTE_TYPE.TSK_HOST, moduleName, artHost.getHost()),\n+                new BlackboardAttribute(ATTRIBUTE_TYPE.TSK_NAME, moduleName, domainCategory)\n+        );\n+        postArtifact(createArtifactWithAttributes(ARTIFACT_TYPE.TSK_WEB_CATEGORIZATION, artHost.getAbstractFile(), bbattributes));\n+    }\n+\n+    @Override\n+    public void process(Content dataSource, IngestJobContext context, DataSourceIngestModuleProgress progressBar) {\n+        this.dataSource = dataSource;\n+        this.context = context;\n+\n+        progressBar.progress(Bundle.DomainCategoryRunner_Progress_Message_Domain_Types());\n+        this.findDomainTypes();\n+    }\n+\n+    @Override\n+    void configExtractor() throws IngestModule.IngestModuleException {\n+        // lookup all providers, filter null providers, and sort providers\n+        List<DomainCategorizer> foundProviders\n+                = Lookup.getDefault().lookupAll(DomainCategorizer.class).stream()\n+                        .filter(provider -> provider != null)\n+                        .sorted((a, b) -> a.getClass().getName().compareToIgnoreCase(b.getClass().getName()))\n+                        .collect(Collectors.toList());\n+\n+        // add the default categorizer last as a last resort\n+        foundProviders.add(new DefaultDomainCategorizer());\n+\n+        for (DomainCategorizer provider : foundProviders) {\n+            try {\n+                provider.initialize();\n+            } catch (DomainCategorizerException ex) {\n+                throw new IngestModule.IngestModuleException(\"There was an error instantiating the provider: \" + provider.getClass().getSimpleName(), ex);\n+            }\n+        }\n+\n+        this.domainProviders = foundProviders == null", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "72096de18b100dd1318d4d6de50ee983ad61d195"}, "originalPosition": 377}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Mjc4MzkzMA==", "bodyText": "Might want to update this comment", "url": "https://github.com/sleuthkit/autopsy/pull/6547#discussion_r542783930", "createdAt": "2020-12-14T21:04:09Z", "author": {"login": "dannysmyda"}, "path": "RecentActivity/src/org/sleuthkit/autopsy/recentactivity/DomainCategoryRunner.java", "diffHunk": "@@ -0,0 +1,396 @@\n+/*\n+ * Autopsy Forensic Browser\n+ *\n+ * Copyright 2020 Basis Technology Corp.\n+ * Contact: carrier <at> sleuthkit <dot> org\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.sleuthkit.autopsy.recentactivity;\n+\n+import java.net.MalformedURLException;\n+import java.net.URL;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.Collections;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.logging.Level;\n+import java.util.Set;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n+import org.apache.commons.lang.StringUtils;\n+import org.openide.util.Lookup;\n+import org.openide.util.NbBundle.Messages;\n+import org.sleuthkit.autopsy.coreutils.Logger;\n+import org.sleuthkit.autopsy.coreutils.NetworkUtils;\n+import org.sleuthkit.autopsy.ingest.DataSourceIngestModuleProgress;\n+import org.sleuthkit.autopsy.ingest.IngestJobContext;\n+import org.sleuthkit.autopsy.ingest.IngestModule;\n+import org.sleuthkit.datamodel.AbstractFile;\n+import org.sleuthkit.datamodel.BlackboardArtifact;\n+import org.sleuthkit.datamodel.BlackboardArtifact.ARTIFACT_TYPE;\n+import org.sleuthkit.datamodel.BlackboardAttribute;\n+import org.sleuthkit.datamodel.BlackboardAttribute.ATTRIBUTE_TYPE;\n+import org.sleuthkit.datamodel.Content;\n+import org.sleuthkit.datamodel.TskCoreException;\n+import org.sleuthkit.autopsy.url.analytics.DomainCategorizer;\n+import org.sleuthkit.autopsy.url.analytics.DomainCategorizerException;\n+import org.sleuthkit.autopsy.url.analytics.DomainCategory;\n+\n+/**\n+ * Analyzes a URL to determine if the url host is one of a certain kind of\n+ * category (i.e. webmail, disposable mail). If found, a web category artifact\n+ * is created.\n+ */\n+@Messages({\n+    \"DomainCategoryRunner_moduleName_text=DomainCategoryRunner\",\n+    \"DomainCategoryRunner_Progress_Message_Domain_Types=Finding Domain Types\",\n+    \"DomainCategoryRunner_parentModuleName=Recent Activity\"\n+})\n+class DomainCategoryRunner extends Extract {\n+\n+    // The url regex is based on the regex provided in https://tools.ietf.org/html/rfc3986#appendix-B\n+    // but expanded to be a little more flexible.  This regex also properly parses user info and port in a url.\n+    // this regex has optional colon in front of the scheme (i.e. http// instead of http://) since some urls were coming through without the colon.\n+    private static final String URL_REGEX_SCHEME = \"(((?<scheme>[^:\\\\/?#]+):?)?\\\\/\\\\/)\";\n+\n+    private static final String URL_REGEX_USERINFO = \"((?<userinfo>[^\\\\/?#@]*)@)\";\n+    private static final String URL_REGEX_HOST = \"(?<host>[^\\\\/\\\\.?#:]*\\\\.[^\\\\/?#:]*)\";\n+    private static final String URL_REGEX_PORT = \"(:(?<port>[0-9]{1,5}))\";\n+    private static final String URL_REGEX_AUTHORITY = String.format(\"(%s?%s?%s?\\\\/?)\", URL_REGEX_USERINFO, URL_REGEX_HOST, URL_REGEX_PORT);\n+\n+    private static final String URL_REGEX_PATH = \"(?<path>([^?#]*)(\\\\?([^#]*))?(#(.*))?)\";\n+\n+    private static final String URL_REGEX_STR = String.format(\"^\\\\s*%s?%s?%s?\", URL_REGEX_SCHEME, URL_REGEX_AUTHORITY, URL_REGEX_PATH);\n+    private static final Pattern URL_REGEX = Pattern.compile(URL_REGEX_STR);\n+\n+    private static final Logger logger = Logger.getLogger(DomainCategoryRunner.class.getName());\n+\n+    private Content dataSource;\n+    private IngestJobContext context;\n+    private List<DomainCategorizer> domainProviders = Collections.emptyList();\n+\n+    /**\n+     * Main constructor.\n+     */\n+    DomainCategoryRunner() {\n+        moduleName = null;\n+    }\n+\n+    /**\n+     * Attempts to determine the host from the url string. If none can be\n+     * determined, returns null.\n+     *\n+     * @param urlString The url string.\n+     * @return The host or null if cannot be determined.\n+     */\n+    private String getHost(String urlString) {\n+        String host = null;\n+        try {\n+            // try first using the built-in url class to determine the host.\n+            URL url = new URL(urlString);\n+            if (url != null) {\n+                host = url.getHost();\n+            }\n+        } catch (MalformedURLException ignore) {\n+            // ignore this and go to fallback regex\n+        }\n+\n+        // if the built-in url parsing doesn't work, then use more flexible regex.\n+        if (StringUtils.isBlank(host)) {\n+            Matcher m = URL_REGEX.matcher(urlString);\n+            if (m.find()) {\n+                host = m.group(\"host\");\n+            }\n+        }\n+\n+        return host;\n+    }\n+\n+    /**\n+     * Attempts to find the category for the given host/domain.\n+     *\n+     * @param domain The domain for the item.\n+     * @param host The host for the item.\n+     * @return The domain category result or null if none can be determined.\n+     */\n+    private DomainCategory findCategory(String domain, String host) {\n+        List<DomainCategorizer> safeProviders = domainProviders == null ? Collections.emptyList() : domainProviders;\n+        for (DomainCategorizer provider : safeProviders) {\n+            DomainCategory result;\n+            try {\n+                result = provider.getCategory(domain, host);\n+                if (result != null) {\n+                    return result;\n+                }\n+            } catch (DomainCategorizerException ex) {\n+                logger.log(Level.WARNING, \"There was an error processing results with \" + provider.getClass().getCanonicalName(), ex);\n+            }\n+\n+        }\n+\n+        return null;\n+    }\n+\n+    /**\n+     * Information concerning an artifact's host, domain, and parent file.\n+     */\n+    private static class ArtifactHost {\n+\n+        private final AbstractFile abstractFile;\n+        private final String host;\n+        private final String domain;\n+\n+        /**\n+         * Main constructor.\n+         *\n+         * @param abstractFile The parent file of the artifact.\n+         * @param host The host of the artifact found in the url attribute.\n+         * @param domain The domain of the artifact in the TSK_DOMAIN attribute.\n+         */\n+        ArtifactHost(AbstractFile abstractFile, String host, String domain) {\n+            this.abstractFile = abstractFile;\n+            this.host = host;\n+            this.domain = domain;\n+        }\n+\n+        /**\n+         * @return The parent file of this artifact.\n+         */\n+        AbstractFile getAbstractFile() {\n+            return abstractFile;\n+        }\n+\n+        /**\n+         * @return The host of this artifact if one can be determined.\n+         */\n+        String getHost() {\n+            return host;\n+        }\n+\n+        /**\n+         * @return The domain of the artifact.\n+         */\n+        String getDomain() {\n+            return domain;\n+        }\n+    }\n+\n+    /**\n+     * Determines pertinent information in the artifact like host, domain, and\n+     * parent file.\n+     *\n+     * @param artifact The web artifact to parse.\n+     * @return The pertinent information or null if important information cannot\n+     * be determined.\n+     * @throws TskCoreException\n+     */\n+    private ArtifactHost getDomainAndHost(BlackboardArtifact artifact) throws TskCoreException {\n+        // make sure there is attached file\n+        AbstractFile file = tskCase.getAbstractFileById(artifact.getObjectID());\n+        if (file == null) {\n+            return null;\n+        }\n+\n+        // get the host from the url attribute and the domain from the attribute\n+        BlackboardAttribute urlAttr = artifact.getAttribute(new BlackboardAttribute.Type(BlackboardAttribute.ATTRIBUTE_TYPE.TSK_URL));\n+        String urlString = null;\n+        String host = null;\n+        if (urlAttr != null) {\n+            urlString = urlAttr.getValueString();\n+            if (StringUtils.isNotBlank(urlString)) {\n+                host = getHost(urlString);\n+            }\n+        }\n+\n+        // get the domain from the attribute\n+        BlackboardAttribute domainAttr = artifact.getAttribute(new BlackboardAttribute.Type(BlackboardAttribute.ATTRIBUTE_TYPE.TSK_DOMAIN));\n+        String domainString = null;\n+        if (domainAttr != null) {\n+            domainString = domainAttr.getValueString();\n+        }\n+\n+        boolean hasDomain = StringUtils.isNotBlank(domainString);\n+        boolean hasHost = StringUtils.isNotBlank(host);\n+\n+        // we need at least a host or a domain, if one is missing, compensate with the other.\n+        if (!hasDomain && !hasHost) {\n+            return null;\n+        } else if (!hasDomain) {\n+            domainString = NetworkUtils.extractDomain(host);\n+        } else if (!hasHost) {\n+            host = domainString;\n+        }\n+\n+        return new ArtifactHost(file, host.toLowerCase(), domainString.toLowerCase());\n+    }\n+\n+    /**\n+     * Determines if the given item is already found in the set. If not, the\n+     * item is added to the set.\n+     *\n+     * @param items The set of items.\n+     * @param item The item whose existence will be checked in the set.\n+     * @return True if item is already contained in 'items'. False if the is\n+     * null or if not contained in 'items'.\n+     */\n+    private static boolean isDuplicateOrAdd(Set<String> items, String item) {\n+        if (StringUtils.isBlank(item)) {\n+            return false;\n+        } else if (items.contains(item)) {\n+            return true;\n+        } else {\n+            items.add(item);\n+            return false;\n+        }\n+    }\n+\n+    /**\n+     * Goes through web history artifacts and attempts to determine any hosts of\n+     * a domain type. If any are found, a TSK_WEB_CATEGORIZATION artifact is\n+     * created (at most one per host suffix).\n+     */\n+    private void findDomainTypes() {\n+        int artifactsAnalyzed = 0;\n+        int domainTypeInstancesFound = 0;\n+\n+        // this will track the different hosts seen to avoid a search for the same host more than once\n+        Set<String> hostsSeen = new HashSet<>();\n+\n+        // only one suffix per ingest is captured so this tracks the suffixes seen.\n+        Set<String> hostSuffixesSeen = new HashSet<>();\n+        try {\n+            Collection<BlackboardArtifact> listArtifacts = currentCase.getSleuthkitCase().getBlackboard().getArtifacts(\n+                    Arrays.asList(new BlackboardArtifact.Type(ARTIFACT_TYPE.TSK_WEB_HISTORY)),\n+                    Arrays.asList(dataSource.getId()));\n+\n+            logger.log(Level.INFO, \"Processing {0} blackboard artifacts.\", listArtifacts.size()); //NON-NLS\n+\n+            for (BlackboardArtifact artifact : listArtifacts) {\n+                // make sure we haven't cancelled\n+                if (context.dataSourceIngestIsCancelled()) {\n+                    break;       //User cancelled the process.\n+                }\n+\n+                // get the pertinent details for this artifact.\n+                ArtifactHost curArtHost = getDomainAndHost(artifact);\n+                if (curArtHost == null || isDuplicateOrAdd(hostsSeen, curArtHost.getHost())) {\n+                    continue;\n+                }\n+\n+                // if we reached this point, we are at least analyzing this item\n+                artifactsAnalyzed++;\n+\n+                // attempt to get the domain type for the host using the suffix trie", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "72096de18b100dd1318d4d6de50ee983ad61d195"}, "originalPosition": 296}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1a43fbf6275ff07c3f4e562e3e4c589d1dd44737", "author": {"user": {"login": "gdicristofaro", "name": "Greg DiCristofaro"}}, "url": "https://github.com/sleuthkit/autopsy/commit/1a43fbf6275ff07c3f4e562e3e4c589d1dd44737", "committedDate": "2020-12-15T14:18:58Z", "message": "bug fixes"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUyOTMxNzY5", "url": "https://github.com/sleuthkit/autopsy/pull/6547#pullrequestreview-552931769", "createdAt": "2020-12-15T21:45:32Z", "commit": {"oid": "1a43fbf6275ff07c3f4e562e3e4c589d1dd44737"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2813, "cost": 1, "resetAt": "2021-11-02T10:47:05Z"}}}