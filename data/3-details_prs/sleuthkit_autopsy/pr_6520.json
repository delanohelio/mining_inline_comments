{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTMyMDA4OTcy", "number": 6520, "title": "7060 webmail domains", "bodyText": "", "createdAt": "2020-12-03T18:56:56Z", "url": "https://github.com/sleuthkit/autopsy/pull/6520", "merged": true, "mergeCommit": {"oid": "cacd9647468a45d8c2f54b78ae3cd388051706f3"}, "closed": true, "closedAt": "2020-12-07T16:17:40Z", "author": {"login": "gdicristofaro"}, "timelineItems": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdh_ezYAH2gAyNTMyMDA4OTcyOmEwZTFiN2E5Yjg2ZTQwODk3YTdiMjk1ZDYyY2E3ZjRlZGZhZjZiNmM=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdj1741AFqTU0NjE2Nzc4Mg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "a0e1b7a9b86e40897a7b295d62ca7f4edfaf6b6c", "author": {"user": {"login": "gdicristofaro", "name": "Greg DiCristofaro"}}, "url": "https://github.com/sleuthkit/autopsy/commit/a0e1b7a9b86e40897a7b295d62ca7f4edfaf6b6c", "committedDate": "2020-12-01T19:54:24Z", "message": "start on message url analyzer"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6a6262878f52d38aba6a82d6212f64ff3f7eafda", "author": {"user": {"login": "gdicristofaro", "name": "Greg DiCristofaro"}}, "url": "https://github.com/sleuthkit/autopsy/commit/6a6262878f52d38aba6a82d6212f64ff3f7eafda", "committedDate": "2020-12-02T13:21:11Z", "message": "continuing to work through message analyzer"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "18bd3517e143b2206a5c84b02dc371ad5901c534", "author": {"user": {"login": "gdicristofaro", "name": "Greg DiCristofaro"}}, "url": "https://github.com/sleuthkit/autopsy/commit/18bd3517e143b2206a5c84b02dc371ad5901c534", "committedDate": "2020-12-02T15:20:27Z", "message": "updating"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "25061a0b7c45b3e6c9a4aa00e799ea2d0c5c8ced", "author": {"user": {"login": "gdicristofaro", "name": "Greg DiCristofaro"}}, "url": "https://github.com/sleuthkit/autopsy/commit/25061a0b7c45b3e6c9a4aa00e799ea2d0c5c8ced", "committedDate": "2020-12-02T16:33:56Z", "message": "working through message url analyzer"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b7baa5e2c84bed9f29fbb50d930253045aaf4b05", "author": {"user": {"login": "gdicristofaro", "name": "Greg DiCristofaro"}}, "url": "https://github.com/sleuthkit/autopsy/commit/b7baa5e2c84bed9f29fbb50d930253045aaf4b05", "committedDate": "2020-12-02T21:43:17Z", "message": "set icons and include message types csv"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "03a23f636bf6fdcfad423705b9321ea9c07e1fc9", "author": {"user": {"login": "gdicristofaro", "name": "Greg DiCristofaro"}}, "url": "https://github.com/sleuthkit/autopsy/commit/03a23f636bf6fdcfad423705b9321ea9c07e1fc9", "committedDate": "2020-12-03T17:37:44Z", "message": "commenting"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3c36f1e39ae190055edde025a7ded301d8b9b879", "author": {"user": {"login": "gdicristofaro", "name": "Greg DiCristofaro"}}, "url": "https://github.com/sleuthkit/autopsy/commit/3c36f1e39ae190055edde025a7ded301d8b9b879", "committedDate": "2020-12-03T18:36:28Z", "message": "formatting and bundle update"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "219c4ba5f65eed91e6064d2f1f4d53f7bf17dad8", "author": {"user": {"login": "gdicristofaro", "name": "Greg DiCristofaro"}}, "url": "https://github.com/sleuthkit/autopsy/commit/219c4ba5f65eed91e6064d2f1f4d53f7bf17dad8", "committedDate": "2020-12-03T18:40:50Z", "message": "formatting"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b11f3bbb00430823e15436490f8fceb223a91d99", "author": {"user": {"login": "gdicristofaro", "name": "Greg DiCristofaro"}}, "url": "https://github.com/sleuthkit/autopsy/commit/b11f3bbb00430823e15436490f8fceb223a91d99", "committedDate": "2020-12-03T18:56:44Z", "message": "merge from develop"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ1MDY4NzQx", "url": "https://github.com/sleuthkit/autopsy/pull/6520#pullrequestreview-545068741", "createdAt": "2020-12-04T15:40:42Z", "commit": {"oid": "b11f3bbb00430823e15436490f8fceb223a91d99"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQxNTo0MDo0MlrOH_WYWA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQxNzowMzoxOVrOH_ZzCw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjE4OTAxNg==", "bodyText": "I think the icon will need to be added to HTMLReports too.", "url": "https://github.com/sleuthkit/autopsy/pull/6520#discussion_r536189016", "createdAt": "2020-12-04T15:40:42Z", "author": {"login": "dannysmyda"}, "path": "Core/src/org/sleuthkit/autopsy/datamodel/utils/IconsUtil.java", "diffHunk": "@@ -121,6 +121,8 @@ public static String getIconFilePath(int typeID) {\n             imageFile = \"web-account-type.png\"; //NON-NLS\n         } else if (typeID == ARTIFACT_TYPE.TSK_WEB_FORM_ADDRESS.getTypeID()) {\n             imageFile = \"web-form-address.png\"; //NON-NLS\n+        } else if (typeID == ARTIFACT_TYPE.TSK_DOMAIN_CATEGORY.getTypeID()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b11f3bbb00430823e15436490f8fceb223a91d99"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjI0NDE3Mg==", "bodyText": "Why not get the TSK_DOMAIN attribute that will be on this artifact? Then, you could skip all the business about getting the host.", "url": "https://github.com/sleuthkit/autopsy/pull/6520#discussion_r536244172", "createdAt": "2020-12-04T17:01:36Z", "author": {"login": "dannysmyda"}, "path": "RecentActivity/src/org/sleuthkit/autopsy/recentactivity/MessageURLAnalyzer.java", "diffHunk": "@@ -0,0 +1,488 @@\n+/*\n+ * Autopsy Forensic Browser\n+ *\n+ * Copyright 2020 Basis Technology Corp.\n+ * Contact: carrier <at> sleuthkit <dot> org\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.sleuthkit.autopsy.recentactivity;\n+\n+import java.io.BufferedReader;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.InputStreamReader;\n+import java.net.MalformedURLException;\n+import java.net.URL;\n+import java.nio.charset.StandardCharsets;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.logging.Level;\n+import java.util.Set;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.commons.lang.StringUtils;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.openide.util.NbBundle.Messages;\n+import org.sleuthkit.autopsy.coreutils.Logger;\n+import org.sleuthkit.autopsy.coreutils.NetworkUtils;\n+import org.sleuthkit.autopsy.ingest.DataSourceIngestModuleProgress;\n+import org.sleuthkit.autopsy.ingest.IngestJobContext;\n+import org.sleuthkit.autopsy.ingest.IngestModule;\n+import org.sleuthkit.datamodel.AbstractFile;\n+import org.sleuthkit.datamodel.BlackboardArtifact;\n+import org.sleuthkit.datamodel.BlackboardArtifact.ARTIFACT_TYPE;\n+import org.sleuthkit.datamodel.BlackboardAttribute;\n+import org.sleuthkit.datamodel.BlackboardAttribute.ATTRIBUTE_TYPE;\n+import org.sleuthkit.datamodel.Content;\n+import org.sleuthkit.datamodel.TskCoreException;\n+\n+/**\n+ * Analyzes a URL to determine if the url host is one that handles messages\n+ * (i.e. webmail, disposable mail). If found, a domain category type artifact is\n+ * created.\n+ *\n+ * CSV entries describing these message types are compiled from sources.\n+ * webmail: https://github.com/mailcheck/mailcheck/wiki/List-of-Popular-Domains\n+ * disposable mail: https://www.npmjs.com/package/disposable-email-domains\n+ */\n+@Messages({\n+    \"MessageURLAnalyzer_moduleName_text=MessageURLAnalyzer\",\n+    \"MessageURLAnalyzer_Progress_Message_Find_Message_URLs=Finding Messaging Domains\",\n+    \"MessageURLAnalyzer_parentModuleName=Recent Activity\"\n+})\n+class MessageURLAnalyzer extends Extract {\n+\n+    /**\n+     * The message service type (i.e. webmail, disposable mail).\n+     */\n+    @Messages({\n+        \"MessageType_disposableMail_displayName=Disposable Email\",\n+        \"MessageType_webmail_displayName=Web Email\"\n+    })\n+    private enum MessageType {\n+        DISPOSABLE_EMAIL(\"disposable\", Bundle.MessageType_disposableMail_displayName()),\n+        WEBMAIL(\"webmail\", Bundle.MessageType_webmail_displayName());\n+\n+        private final String csvId;\n+        private final String attrDisplayName;\n+\n+        /**\n+         * Main constructor.\n+         *\n+         * @param csvId The identifier within the csv for this type.\n+         * @param attrDisplayName The display name in the artifact for this\n+         * domain category.\n+         */\n+        private MessageType(String csvId, String attrDisplayName) {\n+            this.csvId = csvId;\n+            this.attrDisplayName = attrDisplayName;\n+        }\n+\n+        /**\n+         * @return The identifier within the csv for this type.\n+         */\n+        String getCsvId() {\n+            return csvId;\n+        }\n+\n+        /**\n+         * @return The display name in the artifact for this domain category.\n+         */\n+        String getAttrDisplayName() {\n+            return attrDisplayName;\n+        }\n+    }\n+\n+    /**\n+     * A node in the trie indicating a domain suffix token. For instance, the\n+     * csv entry: \"hotmail.com,webmail\" would get parsed to a node, \"com\" having\n+     * a child of \"hotmail\". That child node, as a leaf, would have a webmail\n+     * message type.\n+     */\n+    private static class MessageDomainTrieNode {\n+\n+        private final Map<String, MessageDomainTrieNode> children = new HashMap<>();\n+        private MessageType messageType = null;\n+\n+        /**\n+         * Retrieves the child node of the given key. If that child key does not\n+         * exist, a child node of that key is created and returned.\n+         *\n+         * @param childKey The key for the child (i.e. \"com\").\n+         * @return The retrieved or newly created child node.\n+         */\n+        MessageDomainTrieNode getOrAddChild(String childKey) {\n+            MessageDomainTrieNode child = children.get(childKey);\n+            if (child == null) {\n+                child = new MessageDomainTrieNode();\n+                children.put(childKey, child);\n+            }\n+\n+            return child;\n+        }\n+\n+        /**\n+         * Retrieves the child node of the given key or returns null if child\n+         * does not exist.\n+         *\n+         * @param childKey The key for the child node (i.e. \"com\").\n+         * @return The child node or null if it does not exist.\n+         */\n+        MessageDomainTrieNode getChild(String childKey) {\n+            return children.get(childKey);\n+        }\n+\n+        /**\n+         * @return If this is a leaf node, the type of message for this node.\n+         */\n+        MessageType getMessageType() {\n+            return messageType;\n+        }\n+\n+        /**\n+         * If this is a leaf node, this sets the message type for this node.\n+         *\n+         * @param messageType The message type for this leaf node.\n+         */\n+        void setMessageType(MessageType messageType) {\n+            this.messageType = messageType;\n+        }\n+    }\n+\n+    /**\n+     * Loads the trie of suffixes from the csv resource file.\n+     *\n+     * @return The root trie node.\n+     * @throws IOException\n+     */\n+    private static MessageDomainTrieNode loadTrie() throws IOException {\n+        try (InputStream is = MessageURLAnalyzer.class.getResourceAsStream(MESSAGE_TYPE_CSV);\n+                InputStreamReader isReader = new InputStreamReader(is, StandardCharsets.UTF_8);\n+                BufferedReader reader = new BufferedReader(isReader)) {\n+\n+            MessageDomainTrieNode trie = new MessageDomainTrieNode();\n+            int lineNum = 1;\n+            while (reader.ready()) {\n+                String line = reader.readLine();\n+                if (!StringUtils.isBlank(line)) {\n+                    addItem(trie, line.trim(), lineNum);\n+                    lineNum++;\n+                }\n+            }\n+\n+            return trie;\n+        }\n+    }\n+\n+    /**\n+     * Adds a trie node based on the csv line.\n+     *\n+     * @param trie The root trie node.\n+     * @param line The line to be parsed.\n+     * @param lineNumber The line number of this csv line.\n+     */\n+    private static void addItem(MessageDomainTrieNode trie, String line, int lineNumber) {\n+        // make sure this isn't a blank line.\n+        if (StringUtils.isBlank(line)) {\n+            return;\n+        }\n+\n+        String[] csvItems = line.split(CSV_DELIMITER);\n+        // line should be a key value pair\n+        if (csvItems.length < 2) {\n+            logger.log(Level.WARNING, String.format(\"Unable to properly parse line of \\\"%s\\\" at line %d\", line, lineNumber));\n+            return;\n+        }\n+\n+        // determine the message type from the value, and return if can't be determined.\n+        String messageTypeStr = csvItems[1].trim();\n+\n+        MessageType messageType = (StringUtils.isNotBlank(messageTypeStr))\n+                ? Stream.of(MessageType.values())\n+                        .filter((m) -> m.getCsvId().equalsIgnoreCase(messageTypeStr))\n+                        .findFirst()\n+                        .orElse(null)\n+                : null;\n+\n+        if (messageType == null) {\n+            logger.log(Level.WARNING, String.format(\"Could not determine message type for this line: \\\"%s\\\" at line %d\", line, lineNumber));\n+            return;\n+        }\n+\n+        // gather the domainSuffix and parse into domain trie tokens\n+        String domainSuffix = csvItems[0];\n+        if (StringUtils.isBlank(domainSuffix)) {\n+            logger.log(Level.WARNING, String.format(\"Could not determine domain suffix for this line: \\\"%s\\\" at line %d\", line, lineNumber));\n+            return;\n+        }\n+\n+        String[] domainTokens = domainSuffix.trim().toLowerCase().split(DELIMITER);\n+\n+        // add into the trie\n+        MessageDomainTrieNode node = trie;\n+        for (int i = domainTokens.length - 1; i >= 0; i--) {\n+            String token = domainTokens[i];\n+            if (StringUtils.isBlank(token)) {\n+                continue;\n+            }\n+\n+            node = node.getOrAddChild(domainTokens[i]);\n+        }\n+\n+        node.setMessageType(messageType);\n+\n+    }\n+\n+    // Character for joining domain segments.\n+    private static final String JOINER = \".\";\n+    // delimiter when used with regex for domains\n+    private static final String DELIMITER = \"\\\\\" + JOINER;\n+\n+    // csv delimiter\n+    private static final String CSV_DELIMITER = \",\";\n+\n+    private static final String MESSAGE_TYPE_CSV = \"message_types.csv\"; //NON-NLS\n+\n+    // The url regex is based on the regex provided in https://tools.ietf.org/html/rfc3986#appendix-B\n+    // but expanded to be a little more flexible, and also properly parses user info and port in a url\n+    // this item has optional colon since some urls were coming through without the colon\n+    private static final String URL_REGEX_SCHEME = \"(((?<scheme>[^:\\\\/?#]+):?)?\\\\/\\\\/)\";\n+\n+    private static final String URL_REGEX_USERINFO = \"((?<userinfo>[^\\\\/?#@]*)@)\";\n+    private static final String URL_REGEX_HOST = \"(?<host>[^\\\\/\\\\.?#:]*\\\\.[^\\\\/?#:]*)\";\n+    private static final String URL_REGEX_PORT = \"(:(?<port>[0-9]{1,5}))\";\n+    private static final String URL_REGEX_AUTHORITY = String.format(\"(%s?%s?%s?\\\\/?)\", URL_REGEX_USERINFO, URL_REGEX_HOST, URL_REGEX_PORT);\n+\n+    private static final String URL_REGEX_PATH = \"(?<path>([^?#]*)(\\\\?([^#]*))?(#(.*))?)\";\n+\n+    private static final String URL_REGEX_STR = String.format(\"^\\\\s*%s?%s?%s?\", URL_REGEX_SCHEME, URL_REGEX_AUTHORITY, URL_REGEX_PATH);\n+    private static final Pattern URL_REGEX = Pattern.compile(URL_REGEX_STR);\n+\n+    private static final Logger logger = Logger.getLogger(MessageURLAnalyzer.class.getName());\n+\n+    // the root node for the trie containing suffixes for domain categories.\n+    private MessageDomainTrieNode rootTrie = null;\n+\n+    private Content dataSource;\n+    private IngestJobContext context;\n+\n+    /**\n+     * Main constructor.\n+     */\n+    MessageURLAnalyzer() {\n+        moduleName = null;\n+    }\n+\n+    /**\n+     * Attempts to determine the host from the url string. If none can be\n+     * determined, returns null.\n+     *\n+     * @param urlString The url string.\n+     * @return The host or null if cannot be determined.\n+     */\n+    private String getHost(String urlString) {\n+        String host = null;\n+        try {\n+            // try first using the built-in url class to determine the host.\n+            URL url = new URL(urlString);\n+            if (url != null) {\n+                host = url.getHost();\n+            }\n+        } catch (MalformedURLException ignore) {\n+            // ignore this and go to fallback regex\n+        }\n+\n+        // if the built-in url parsing doesn't work, then use more flexible regex.\n+        if (StringUtils.isBlank(host)) {\n+            Matcher m = URL_REGEX.matcher(urlString);\n+            if (m.find()) {\n+                host = m.group(\"host\");\n+            }\n+        }\n+\n+        return host;\n+    }\n+\n+    /**\n+     * Determines if the host is a message type domain. If so, returns the\n+     * portion of the host suffix that signifies the message domain (i.e.\n+     * \"hotmail.com\" or \"mail.google.com\") and the message type.\n+     *\n+     * @param host The host.\n+     * @return A pair of the host suffix and message type for that suffix if\n+     * found. Otherwise, returns null.\n+     */\n+    private Pair<String, MessageType> findHostSuffix(String host) {\n+        // if no host, return none.\n+        if (StringUtils.isBlank(host)) {\n+            return null;\n+        }\n+\n+        // parse the tokens splitting on delimiter\n+        List<String> tokens = Stream.of(host.toLowerCase().split(DELIMITER))\n+                .filter(StringUtils::isNotBlank)\n+                .collect(Collectors.toList());\n+\n+        MessageDomainTrieNode node = rootTrie;\n+        // the root node is null indicating we won't be able to do a lookup.\n+        if (node == null) {\n+            return null;\n+        }\n+\n+        // iterate through tokens in reverse order\n+        int idx = tokens.size() - 1;\n+        for (; idx >= 0; idx--) {\n+            node = node.getChild(tokens.get(idx));\n+            // if we hit a leaf node or we have no matching child node, continue.\n+            if (node == null || node.getMessageType() != null) {\n+                break;\n+            }\n+        }\n+\n+        MessageType messageType = node != null ? node.getMessageType() : null;\n+\n+        if (messageType == null) {\n+            return null;\n+        } else {\n+            // if there is a message type, we have a result.  Concatenate the \n+            // appropriate domain tokens and return.\n+            int minIndex = Math.max(0, idx);\n+            List<String> subList = tokens.subList(minIndex, tokens.size());\n+            String hostSuffix = String.join(JOINER, subList);\n+            return Pair.of(hostSuffix, messageType);\n+        }\n+    }\n+\n+    /**\n+     * Goes through web history artifacts and attempts to determine any hosts of\n+     * a message type. If any are found, a TSK_DOMAIN_CATEGORY artifact is\n+     * created (at most one per host suffix).\n+     */\n+    private void findMessageDomains() {\n+        if (this.rootTrie == null) {\n+            logger.log(Level.SEVERE, \"Not analyzing message domain.  No root trie loaded.\");\n+            return;\n+        }\n+\n+        int artifactsAnalyzed = 0;\n+        int messageDomainInstancesFound = 0;\n+\n+        // only one suffix per ingest is captured so this tracks the suffixes seen.\n+        Set<String> domainSuffixesSeen = new HashSet<>();\n+\n+        try {\n+            Collection<BlackboardArtifact> listArtifacts = currentCase.getSleuthkitCase().getBlackboard().getArtifacts(\n+                    Arrays.asList(new BlackboardArtifact.Type(ARTIFACT_TYPE.TSK_WEB_HISTORY)),\n+                    Arrays.asList(dataSource.getId()));\n+\n+            logger.log(Level.INFO, \"Processing {0} blackboard artifacts.\", listArtifacts.size()); //NON-NLS\n+\n+            for (BlackboardArtifact artifact : listArtifacts) {\n+                // make sure we haven't cancelled\n+                if (context.dataSourceIngestIsCancelled()) {\n+                    break;       //User cancelled the process.\n+                }\n+\n+                // make sure there is attached file\n+                AbstractFile file = tskCase.getAbstractFileById(artifact.getObjectID());\n+                if (file == null) {\n+                    continue;\n+                }\n+\n+                // get the url string from the artifact\n+                BlackboardAttribute urlAttr = artifact.getAttribute(new BlackboardAttribute.Type(BlackboardAttribute.ATTRIBUTE_TYPE.TSK_URL));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b11f3bbb00430823e15436490f8fceb223a91d99"}, "originalPosition": 410}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjI0NTAwMw==", "bodyText": "Reviewing some code, this extractor will be run after the browser extractors.", "url": "https://github.com/sleuthkit/autopsy/pull/6520#discussion_r536245003", "createdAt": "2020-12-04T17:03:19Z", "author": {"login": "dannysmyda"}, "path": "RecentActivity/src/org/sleuthkit/autopsy/recentactivity/MessageURLAnalyzer.java", "diffHunk": "@@ -0,0 +1,488 @@\n+/*\n+ * Autopsy Forensic Browser\n+ *\n+ * Copyright 2020 Basis Technology Corp.\n+ * Contact: carrier <at> sleuthkit <dot> org\n+ *\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+package org.sleuthkit.autopsy.recentactivity;\n+\n+import java.io.BufferedReader;\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.io.InputStreamReader;\n+import java.net.MalformedURLException;\n+import java.net.URL;\n+import java.nio.charset.StandardCharsets;\n+import java.util.Arrays;\n+import java.util.Collection;\n+import java.util.HashMap;\n+import java.util.HashSet;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.logging.Level;\n+import java.util.Set;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.commons.lang.StringUtils;\n+import org.apache.commons.lang3.tuple.Pair;\n+import org.openide.util.NbBundle.Messages;\n+import org.sleuthkit.autopsy.coreutils.Logger;\n+import org.sleuthkit.autopsy.coreutils.NetworkUtils;\n+import org.sleuthkit.autopsy.ingest.DataSourceIngestModuleProgress;\n+import org.sleuthkit.autopsy.ingest.IngestJobContext;\n+import org.sleuthkit.autopsy.ingest.IngestModule;\n+import org.sleuthkit.datamodel.AbstractFile;\n+import org.sleuthkit.datamodel.BlackboardArtifact;\n+import org.sleuthkit.datamodel.BlackboardArtifact.ARTIFACT_TYPE;\n+import org.sleuthkit.datamodel.BlackboardAttribute;\n+import org.sleuthkit.datamodel.BlackboardAttribute.ATTRIBUTE_TYPE;\n+import org.sleuthkit.datamodel.Content;\n+import org.sleuthkit.datamodel.TskCoreException;\n+\n+/**\n+ * Analyzes a URL to determine if the url host is one that handles messages\n+ * (i.e. webmail, disposable mail). If found, a domain category type artifact is\n+ * created.\n+ *\n+ * CSV entries describing these message types are compiled from sources.\n+ * webmail: https://github.com/mailcheck/mailcheck/wiki/List-of-Popular-Domains\n+ * disposable mail: https://www.npmjs.com/package/disposable-email-domains\n+ */\n+@Messages({\n+    \"MessageURLAnalyzer_moduleName_text=MessageURLAnalyzer\",\n+    \"MessageURLAnalyzer_Progress_Message_Find_Message_URLs=Finding Messaging Domains\",\n+    \"MessageURLAnalyzer_parentModuleName=Recent Activity\"\n+})\n+class MessageURLAnalyzer extends Extract {\n+\n+    /**\n+     * The message service type (i.e. webmail, disposable mail).\n+     */\n+    @Messages({\n+        \"MessageType_disposableMail_displayName=Disposable Email\",\n+        \"MessageType_webmail_displayName=Web Email\"\n+    })\n+    private enum MessageType {\n+        DISPOSABLE_EMAIL(\"disposable\", Bundle.MessageType_disposableMail_displayName()),\n+        WEBMAIL(\"webmail\", Bundle.MessageType_webmail_displayName());\n+\n+        private final String csvId;\n+        private final String attrDisplayName;\n+\n+        /**\n+         * Main constructor.\n+         *\n+         * @param csvId The identifier within the csv for this type.\n+         * @param attrDisplayName The display name in the artifact for this\n+         * domain category.\n+         */\n+        private MessageType(String csvId, String attrDisplayName) {\n+            this.csvId = csvId;\n+            this.attrDisplayName = attrDisplayName;\n+        }\n+\n+        /**\n+         * @return The identifier within the csv for this type.\n+         */\n+        String getCsvId() {\n+            return csvId;\n+        }\n+\n+        /**\n+         * @return The display name in the artifact for this domain category.\n+         */\n+        String getAttrDisplayName() {\n+            return attrDisplayName;\n+        }\n+    }\n+\n+    /**\n+     * A node in the trie indicating a domain suffix token. For instance, the\n+     * csv entry: \"hotmail.com,webmail\" would get parsed to a node, \"com\" having\n+     * a child of \"hotmail\". That child node, as a leaf, would have a webmail\n+     * message type.\n+     */\n+    private static class MessageDomainTrieNode {\n+\n+        private final Map<String, MessageDomainTrieNode> children = new HashMap<>();\n+        private MessageType messageType = null;\n+\n+        /**\n+         * Retrieves the child node of the given key. If that child key does not\n+         * exist, a child node of that key is created and returned.\n+         *\n+         * @param childKey The key for the child (i.e. \"com\").\n+         * @return The retrieved or newly created child node.\n+         */\n+        MessageDomainTrieNode getOrAddChild(String childKey) {\n+            MessageDomainTrieNode child = children.get(childKey);\n+            if (child == null) {\n+                child = new MessageDomainTrieNode();\n+                children.put(childKey, child);\n+            }\n+\n+            return child;\n+        }\n+\n+        /**\n+         * Retrieves the child node of the given key or returns null if child\n+         * does not exist.\n+         *\n+         * @param childKey The key for the child node (i.e. \"com\").\n+         * @return The child node or null if it does not exist.\n+         */\n+        MessageDomainTrieNode getChild(String childKey) {\n+            return children.get(childKey);\n+        }\n+\n+        /**\n+         * @return If this is a leaf node, the type of message for this node.\n+         */\n+        MessageType getMessageType() {\n+            return messageType;\n+        }\n+\n+        /**\n+         * If this is a leaf node, this sets the message type for this node.\n+         *\n+         * @param messageType The message type for this leaf node.\n+         */\n+        void setMessageType(MessageType messageType) {\n+            this.messageType = messageType;\n+        }\n+    }\n+\n+    /**\n+     * Loads the trie of suffixes from the csv resource file.\n+     *\n+     * @return The root trie node.\n+     * @throws IOException\n+     */\n+    private static MessageDomainTrieNode loadTrie() throws IOException {\n+        try (InputStream is = MessageURLAnalyzer.class.getResourceAsStream(MESSAGE_TYPE_CSV);\n+                InputStreamReader isReader = new InputStreamReader(is, StandardCharsets.UTF_8);\n+                BufferedReader reader = new BufferedReader(isReader)) {\n+\n+            MessageDomainTrieNode trie = new MessageDomainTrieNode();\n+            int lineNum = 1;\n+            while (reader.ready()) {\n+                String line = reader.readLine();\n+                if (!StringUtils.isBlank(line)) {\n+                    addItem(trie, line.trim(), lineNum);\n+                    lineNum++;\n+                }\n+            }\n+\n+            return trie;\n+        }\n+    }\n+\n+    /**\n+     * Adds a trie node based on the csv line.\n+     *\n+     * @param trie The root trie node.\n+     * @param line The line to be parsed.\n+     * @param lineNumber The line number of this csv line.\n+     */\n+    private static void addItem(MessageDomainTrieNode trie, String line, int lineNumber) {\n+        // make sure this isn't a blank line.\n+        if (StringUtils.isBlank(line)) {\n+            return;\n+        }\n+\n+        String[] csvItems = line.split(CSV_DELIMITER);\n+        // line should be a key value pair\n+        if (csvItems.length < 2) {\n+            logger.log(Level.WARNING, String.format(\"Unable to properly parse line of \\\"%s\\\" at line %d\", line, lineNumber));\n+            return;\n+        }\n+\n+        // determine the message type from the value, and return if can't be determined.\n+        String messageTypeStr = csvItems[1].trim();\n+\n+        MessageType messageType = (StringUtils.isNotBlank(messageTypeStr))\n+                ? Stream.of(MessageType.values())\n+                        .filter((m) -> m.getCsvId().equalsIgnoreCase(messageTypeStr))\n+                        .findFirst()\n+                        .orElse(null)\n+                : null;\n+\n+        if (messageType == null) {\n+            logger.log(Level.WARNING, String.format(\"Could not determine message type for this line: \\\"%s\\\" at line %d\", line, lineNumber));\n+            return;\n+        }\n+\n+        // gather the domainSuffix and parse into domain trie tokens\n+        String domainSuffix = csvItems[0];\n+        if (StringUtils.isBlank(domainSuffix)) {\n+            logger.log(Level.WARNING, String.format(\"Could not determine domain suffix for this line: \\\"%s\\\" at line %d\", line, lineNumber));\n+            return;\n+        }\n+\n+        String[] domainTokens = domainSuffix.trim().toLowerCase().split(DELIMITER);\n+\n+        // add into the trie\n+        MessageDomainTrieNode node = trie;\n+        for (int i = domainTokens.length - 1; i >= 0; i--) {\n+            String token = domainTokens[i];\n+            if (StringUtils.isBlank(token)) {\n+                continue;\n+            }\n+\n+            node = node.getOrAddChild(domainTokens[i]);\n+        }\n+\n+        node.setMessageType(messageType);\n+\n+    }\n+\n+    // Character for joining domain segments.\n+    private static final String JOINER = \".\";\n+    // delimiter when used with regex for domains\n+    private static final String DELIMITER = \"\\\\\" + JOINER;\n+\n+    // csv delimiter\n+    private static final String CSV_DELIMITER = \",\";\n+\n+    private static final String MESSAGE_TYPE_CSV = \"message_types.csv\"; //NON-NLS\n+\n+    // The url regex is based on the regex provided in https://tools.ietf.org/html/rfc3986#appendix-B\n+    // but expanded to be a little more flexible, and also properly parses user info and port in a url\n+    // this item has optional colon since some urls were coming through without the colon\n+    private static final String URL_REGEX_SCHEME = \"(((?<scheme>[^:\\\\/?#]+):?)?\\\\/\\\\/)\";\n+\n+    private static final String URL_REGEX_USERINFO = \"((?<userinfo>[^\\\\/?#@]*)@)\";\n+    private static final String URL_REGEX_HOST = \"(?<host>[^\\\\/\\\\.?#:]*\\\\.[^\\\\/?#:]*)\";\n+    private static final String URL_REGEX_PORT = \"(:(?<port>[0-9]{1,5}))\";\n+    private static final String URL_REGEX_AUTHORITY = String.format(\"(%s?%s?%s?\\\\/?)\", URL_REGEX_USERINFO, URL_REGEX_HOST, URL_REGEX_PORT);\n+\n+    private static final String URL_REGEX_PATH = \"(?<path>([^?#]*)(\\\\?([^#]*))?(#(.*))?)\";\n+\n+    private static final String URL_REGEX_STR = String.format(\"^\\\\s*%s?%s?%s?\", URL_REGEX_SCHEME, URL_REGEX_AUTHORITY, URL_REGEX_PATH);\n+    private static final Pattern URL_REGEX = Pattern.compile(URL_REGEX_STR);\n+\n+    private static final Logger logger = Logger.getLogger(MessageURLAnalyzer.class.getName());\n+\n+    // the root node for the trie containing suffixes for domain categories.\n+    private MessageDomainTrieNode rootTrie = null;\n+\n+    private Content dataSource;\n+    private IngestJobContext context;\n+\n+    /**\n+     * Main constructor.\n+     */\n+    MessageURLAnalyzer() {\n+        moduleName = null;\n+    }\n+\n+    /**\n+     * Attempts to determine the host from the url string. If none can be\n+     * determined, returns null.\n+     *\n+     * @param urlString The url string.\n+     * @return The host or null if cannot be determined.\n+     */\n+    private String getHost(String urlString) {\n+        String host = null;\n+        try {\n+            // try first using the built-in url class to determine the host.\n+            URL url = new URL(urlString);\n+            if (url != null) {\n+                host = url.getHost();\n+            }\n+        } catch (MalformedURLException ignore) {\n+            // ignore this and go to fallback regex\n+        }\n+\n+        // if the built-in url parsing doesn't work, then use more flexible regex.\n+        if (StringUtils.isBlank(host)) {\n+            Matcher m = URL_REGEX.matcher(urlString);\n+            if (m.find()) {\n+                host = m.group(\"host\");\n+            }\n+        }\n+\n+        return host;\n+    }\n+\n+    /**\n+     * Determines if the host is a message type domain. If so, returns the\n+     * portion of the host suffix that signifies the message domain (i.e.\n+     * \"hotmail.com\" or \"mail.google.com\") and the message type.\n+     *\n+     * @param host The host.\n+     * @return A pair of the host suffix and message type for that suffix if\n+     * found. Otherwise, returns null.\n+     */\n+    private Pair<String, MessageType> findHostSuffix(String host) {\n+        // if no host, return none.\n+        if (StringUtils.isBlank(host)) {\n+            return null;\n+        }\n+\n+        // parse the tokens splitting on delimiter\n+        List<String> tokens = Stream.of(host.toLowerCase().split(DELIMITER))\n+                .filter(StringUtils::isNotBlank)\n+                .collect(Collectors.toList());\n+\n+        MessageDomainTrieNode node = rootTrie;\n+        // the root node is null indicating we won't be able to do a lookup.\n+        if (node == null) {\n+            return null;\n+        }\n+\n+        // iterate through tokens in reverse order\n+        int idx = tokens.size() - 1;\n+        for (; idx >= 0; idx--) {\n+            node = node.getChild(tokens.get(idx));\n+            // if we hit a leaf node or we have no matching child node, continue.\n+            if (node == null || node.getMessageType() != null) {\n+                break;\n+            }\n+        }\n+\n+        MessageType messageType = node != null ? node.getMessageType() : null;\n+\n+        if (messageType == null) {\n+            return null;\n+        } else {\n+            // if there is a message type, we have a result.  Concatenate the \n+            // appropriate domain tokens and return.\n+            int minIndex = Math.max(0, idx);\n+            List<String> subList = tokens.subList(minIndex, tokens.size());\n+            String hostSuffix = String.join(JOINER, subList);\n+            return Pair.of(hostSuffix, messageType);\n+        }\n+    }\n+\n+    /**\n+     * Goes through web history artifacts and attempts to determine any hosts of\n+     * a message type. If any are found, a TSK_DOMAIN_CATEGORY artifact is\n+     * created (at most one per host suffix).\n+     */\n+    private void findMessageDomains() {\n+        if (this.rootTrie == null) {\n+            logger.log(Level.SEVERE, \"Not analyzing message domain.  No root trie loaded.\");\n+            return;\n+        }\n+\n+        int artifactsAnalyzed = 0;\n+        int messageDomainInstancesFound = 0;\n+\n+        // only one suffix per ingest is captured so this tracks the suffixes seen.\n+        Set<String> domainSuffixesSeen = new HashSet<>();\n+\n+        try {\n+            Collection<BlackboardArtifact> listArtifacts = currentCase.getSleuthkitCase().getBlackboard().getArtifacts(\n+                    Arrays.asList(new BlackboardArtifact.Type(ARTIFACT_TYPE.TSK_WEB_HISTORY)),\n+                    Arrays.asList(dataSource.getId()));\n+\n+            logger.log(Level.INFO, \"Processing {0} blackboard artifacts.\", listArtifacts.size()); //NON-NLS\n+\n+            for (BlackboardArtifact artifact : listArtifacts) {\n+                // make sure we haven't cancelled\n+                if (context.dataSourceIngestIsCancelled()) {\n+                    break;       //User cancelled the process.\n+                }\n+\n+                // make sure there is attached file\n+                AbstractFile file = tskCase.getAbstractFileById(artifact.getObjectID());\n+                if (file == null) {\n+                    continue;\n+                }\n+\n+                // get the url string from the artifact\n+                BlackboardAttribute urlAttr = artifact.getAttribute(new BlackboardAttribute.Type(BlackboardAttribute.ATTRIBUTE_TYPE.TSK_URL));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjI0NDE3Mg=="}, "originalCommit": {"oid": "b11f3bbb00430823e15436490f8fceb223a91d99"}, "originalPosition": 410}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "90d8ad0726447ff64d85aa6eab8e24a96793ffa0", "author": {"user": {"login": "gdicristofaro", "name": "Greg DiCristofaro"}}, "url": "https://github.com/sleuthkit/autopsy/commit/90d8ad0726447ff64d85aa6eab8e24a96793ffa0", "committedDate": "2020-12-04T18:26:00Z", "message": "updates to terminology"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "af76bb21b90835d6aff5d76071e6e519f4954a1f", "author": {"user": {"login": "gdicristofaro", "name": "Greg DiCristofaro"}}, "url": "https://github.com/sleuthkit/autopsy/commit/af76bb21b90835d6aff5d76071e6e519f4954a1f", "committedDate": "2020-12-04T18:38:19Z", "message": "bundle fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "616c0d1956ec1bb41996766b42de02a7c23b7a11", "author": {"user": {"login": "gdicristofaro", "name": "Greg DiCristofaro"}}, "url": "https://github.com/sleuthkit/autopsy/commit/616c0d1956ec1bb41996766b42de02a7c23b7a11", "committedDate": "2020-12-04T18:51:39Z", "message": "updates"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ2MTY3Nzgy", "url": "https://github.com/sleuthkit/autopsy/pull/6520#pullrequestreview-546167782", "createdAt": "2020-12-07T13:54:58Z", "commit": {"oid": "616c0d1956ec1bb41996766b42de02a7c23b7a11"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2809, "cost": 1, "resetAt": "2021-11-02T10:47:05Z"}}}