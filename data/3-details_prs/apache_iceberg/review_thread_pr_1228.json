{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDU1MTUzNDcx", "number": 1228, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxNjoyMDoyOFrOERHr1w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxODoxNzo0NlrOERKggw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2Mzg3MTU5OnYy", "diffSide": "RIGHT", "path": "spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java", "isResolved": false, "comments": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxNjoyMDoyOFrOG1qCBw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxNjo0MToxN1rOG1rDtQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkxNjM1OQ==", "bodyText": "Looks like the main problem is that new Path(locationUri.get()) is not the same as new Path(locationUri.get().toString())?", "url": "https://github.com/apache/iceberg/pull/1228#discussion_r458916359", "createdAt": "2020-07-22T16:20:28Z", "author": {"login": "rdblue"}, "path": "spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java", "diffHunk": "@@ -386,7 +386,7 @@ private static SparkPartition toSparkPartition(CatalogTablePartition partition,\n     Preconditions.checkArgument(serde.nonEmpty() || table.provider().nonEmpty(),\n         \"Partition format should be defined\");\n \n-    String uri = String.valueOf(locationUri.get());\n+    URI uri = locationUri.get();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6401f6e342f8bc4eb2571f807a18305206bc032d"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkxODg3MA==", "bodyText": "Yes, Like I wrote on the issue. The constructor of Path(string) assumes the string is decoded. The constructor of Path(Uri) has a URI so it knows it's encoded. That's why we can also fix this by reconverting back to a URI at the last moment (basically re asserting the encoding)", "url": "https://github.com/apache/iceberg/pull/1228#discussion_r458918870", "createdAt": "2020-07-22T16:23:15Z", "author": {"login": "RussellSpitzer"}, "path": "spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java", "diffHunk": "@@ -386,7 +386,7 @@ private static SparkPartition toSparkPartition(CatalogTablePartition partition,\n     Preconditions.checkArgument(serde.nonEmpty() || table.provider().nonEmpty(),\n         \"Partition format should be defined\");\n \n-    String uri = String.valueOf(locationUri.get());\n+    URI uri = locationUri.get();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkxNjM1OQ=="}, "originalCommit": {"oid": "6401f6e342f8bc4eb2571f807a18305206bc032d"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkxOTcxNA==", "bodyText": "scala> import java.net.URI\nimport java.net.URI\n\nscala> import org.apache.hadoop.fs.Path\nimport org.apache.hadoop.fs.Path\n\nscala> val uri = new URI(\"file:///has%20spaces\")\nuri: java.net.URI = file:///has%20spaces\n\nscala> new Path(uri).toString\nres4: String = file:/has spaces\n\nscala> new Path(uri.toString).toString\nres5: String = file:/has%20spaces", "url": "https://github.com/apache/iceberg/pull/1228#discussion_r458919714", "createdAt": "2020-07-22T16:24:04Z", "author": {"login": "RussellSpitzer"}, "path": "spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java", "diffHunk": "@@ -386,7 +386,7 @@ private static SparkPartition toSparkPartition(CatalogTablePartition partition,\n     Preconditions.checkArgument(serde.nonEmpty() || table.provider().nonEmpty(),\n         \"Partition format should be defined\");\n \n-    String uri = String.valueOf(locationUri.get());\n+    URI uri = locationUri.get();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkxNjM1OQ=="}, "originalCommit": {"oid": "6401f6e342f8bc4eb2571f807a18305206bc032d"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkyODU0Mw==", "bodyText": "Here what Spark does:\n  /**\n   * Convert URI to String.\n   * Since URI.toString does not decode the uri, e.g. change '%25' to '%'.\n   * Here we create a hadoop Path with the given URI, and rely on Path.toString\n   * to decode the uri\n   * @param uri the URI of the path\n   * @return the String of the path\n   */\n  def URIToString(uri: URI): String = {\n    new Path(uri).toString\n  }\n\n  /**\n   * Convert String to URI.\n   * Since new URI(string) does not encode string, e.g. change '%' to '%25'.\n   * Here we create a hadoop Path with the given String, and rely on Path.toUri\n   * to encode the string\n   * @param str the String of the path\n   * @return the URI of the path\n   */\n  def stringToURI(str: String): URI = {\n    new Path(str).toUri\n  }", "url": "https://github.com/apache/iceberg/pull/1228#discussion_r458928543", "createdAt": "2020-07-22T16:34:02Z", "author": {"login": "aokolnychyi"}, "path": "spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java", "diffHunk": "@@ -386,7 +386,7 @@ private static SparkPartition toSparkPartition(CatalogTablePartition partition,\n     Preconditions.checkArgument(serde.nonEmpty() || table.provider().nonEmpty(),\n         \"Partition format should be defined\");\n \n-    String uri = String.valueOf(locationUri.get());\n+    URI uri = locationUri.get();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkxNjM1OQ=="}, "originalCommit": {"oid": "6401f6e342f8bc4eb2571f807a18305206bc032d"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkyODYxMw==", "bodyText": "Okay, it sounds like we can keep this fix scoped to just these classes where we need to preserve the original URI instead of modifying it. That's a good rule for us to follow: if we have a URI, then use the URI constructor. If we have a String, use the String constructor.", "url": "https://github.com/apache/iceberg/pull/1228#discussion_r458928613", "createdAt": "2020-07-22T16:34:09Z", "author": {"login": "rdblue"}, "path": "spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java", "diffHunk": "@@ -386,7 +386,7 @@ private static SparkPartition toSparkPartition(CatalogTablePartition partition,\n     Preconditions.checkArgument(serde.nonEmpty() || table.provider().nonEmpty(),\n         \"Partition format should be defined\");\n \n-    String uri = String.valueOf(locationUri.get());\n+    URI uri = locationUri.get();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkxNjM1OQ=="}, "originalCommit": {"oid": "6401f6e342f8bc4eb2571f807a18305206bc032d"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkyOTk1Ng==", "bodyText": "+1 for using the approach that @aokolnychyi pasted.", "url": "https://github.com/apache/iceberg/pull/1228#discussion_r458929956", "createdAt": "2020-07-22T16:36:13Z", "author": {"login": "rdblue"}, "path": "spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java", "diffHunk": "@@ -386,7 +386,7 @@ private static SparkPartition toSparkPartition(CatalogTablePartition partition,\n     Preconditions.checkArgument(serde.nonEmpty() || table.provider().nonEmpty(),\n         \"Partition format should be defined\");\n \n-    String uri = String.valueOf(locationUri.get());\n+    URI uri = locationUri.get();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkxNjM1OQ=="}, "originalCommit": {"oid": "6401f6e342f8bc4eb2571f807a18305206bc032d"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkzMTMzMQ==", "bodyText": "Sounds good to me. I'd rather we didn't have 3 classes involved :) but If Spark does it this way at least we will be broken in similar ways if something doesn't work ;)", "url": "https://github.com/apache/iceberg/pull/1228#discussion_r458931331", "createdAt": "2020-07-22T16:38:30Z", "author": {"login": "RussellSpitzer"}, "path": "spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java", "diffHunk": "@@ -386,7 +386,7 @@ private static SparkPartition toSparkPartition(CatalogTablePartition partition,\n     Preconditions.checkArgument(serde.nonEmpty() || table.provider().nonEmpty(),\n         \"Partition format should be defined\");\n \n-    String uri = String.valueOf(locationUri.get());\n+    URI uri = locationUri.get();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkxNjM1OQ=="}, "originalCommit": {"oid": "6401f6e342f8bc4eb2571f807a18305206bc032d"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkzMzE3Mw==", "bodyText": "Works at least for my little example\nuri: java.net.URI = file:///has%20spaces\n\nscala> new Path(uri).toString\nres0: String = file:/has spaces\n\nscala> new Path(new Path(uri).toString)\nres1: org.apache.hadoop.fs.Path = file:/has spaces", "url": "https://github.com/apache/iceberg/pull/1228#discussion_r458933173", "createdAt": "2020-07-22T16:41:17Z", "author": {"login": "RussellSpitzer"}, "path": "spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java", "diffHunk": "@@ -386,7 +386,7 @@ private static SparkPartition toSparkPartition(CatalogTablePartition partition,\n     Preconditions.checkArgument(serde.nonEmpty() || table.provider().nonEmpty(),\n         \"Partition format should be defined\");\n \n-    String uri = String.valueOf(locationUri.get());\n+    URI uri = locationUri.get();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkxNjM1OQ=="}, "originalCommit": {"oid": "6401f6e342f8bc4eb2571f807a18305206bc032d"}, "originalPosition": 41}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2MzkyMTkwOnYy", "diffSide": "RIGHT", "path": "spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxNjoyOTo1MVrOG1qizQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxNjoyOTo1MVrOG1qizQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkyNDc0OQ==", "bodyText": "The alternate fix is on the line below (an all other times we make a Path from a string), where instead of just passing through the string we pass back through the URI version of the string, or possibly just decode the string before passing it through. I think it's probably safest to use URI the whole time, second safest to change back to URI at the last moment, third safest to attempt to decode and hope Hadoop parses the string like we want it too.", "url": "https://github.com/apache/iceberg/pull/1228#discussion_r458924749", "createdAt": "2020-07-22T16:29:51Z", "author": {"login": "RussellSpitzer"}, "path": "spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java", "diffHunk": "@@ -313,7 +313,7 @@ private SparkTableUtil() {\n     }\n   }\n \n-  private static List<DataFile> listParquetPartition(Map<String, String> partitionPath, String partitionUri,\n+  private static List<DataFile> listParquetPartition(Map<String, String> partitionPath, URI partitionUri,\n                                                      PartitionSpec spec, Configuration conf,\n                                                      MetricsConfig metricsSpec) {\n     try {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6401f6e342f8bc4eb2571f807a18305206bc032d"}, "originalPosition": 26}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2Mzk0ODU4OnYy", "diffSide": "RIGHT", "path": "spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxNjozNDo1NFrOG1qzyA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxNjozNDo1NFrOG1qzyA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkyOTA5Ng==", "bodyText": "I'd like to avoid changing this method since it is public and using a URI will probably change behavior for users passing strings (String -> URI -> Path instead of String -> Path).", "url": "https://github.com/apache/iceberg/pull/1228#discussion_r458929096", "createdAt": "2020-07-22T16:34:54Z", "author": {"login": "rdblue"}, "path": "spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java", "diffHunk": "@@ -271,7 +271,7 @@ private SparkTableUtil() {\n    * @param metricsConfig a metrics conf\n    * @return a List of DataFile\n    */\n-  public static List<DataFile> listPartition(Map<String, String> partition, String uri, String format,\n+  public static List<DataFile> listPartition(Map<String, String> partition, URI uri, String format,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6401f6e342f8bc4eb2571f807a18305206bc032d"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg2NDMzNDExOnYy", "diffSide": "RIGHT", "path": "spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxODoxNzo0NlrOG1umfw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxODozMDowNFrOG1vBuQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODk5MTIzMQ==", "bodyText": "If this is going to be public, I'd rather find a better place than in SparkTableUtil, like org.apache.iceberg.hadoop.Util. I'm also fine with this being a private method here.", "url": "https://github.com/apache/iceberg/pull/1228#discussion_r458991231", "createdAt": "2020-07-22T18:17:46Z", "author": {"login": "rdblue"}, "path": "spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java", "diffHunk": "@@ -105,6 +105,20 @@\n   private SparkTableUtil() {\n   }\n \n+  /**\n+   * From Apache Spark\n+   *\n+   * Convert URI to String.\n+   * Since URI.toString does not decode the uri, e.g. change '%25' to '%'.\n+   * Here we create a hadoop Path with the given URI, and rely on Path.toString\n+   * to decode the uri\n+   * @param uri the URI of the path\n+   * @return the String of the path\n+   */\n+  public static String uriToString(URI uri) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "25528fcd4c5a42e1990cb2a50f10efa3c4f1374d"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODk5ODIwMQ==", "bodyText": "I'll move it to Util, since this will probably come up again in the future and possibly in a non Spark Context (pretty sure all HadoopFS interactions will run into this if we ever implement methods for another system)", "url": "https://github.com/apache/iceberg/pull/1228#discussion_r458998201", "createdAt": "2020-07-22T18:30:04Z", "author": {"login": "RussellSpitzer"}, "path": "spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java", "diffHunk": "@@ -105,6 +105,20 @@\n   private SparkTableUtil() {\n   }\n \n+  /**\n+   * From Apache Spark\n+   *\n+   * Convert URI to String.\n+   * Since URI.toString does not decode the uri, e.g. change '%25' to '%'.\n+   * Here we create a hadoop Path with the given URI, and rely on Path.toString\n+   * to decode the uri\n+   * @param uri the URI of the path\n+   * @return the String of the path\n+   */\n+  public static String uriToString(URI uri) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODk5MTIzMQ=="}, "originalCommit": {"oid": "25528fcd4c5a42e1990cb2a50f10efa3c4f1374d"}, "originalPosition": 14}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3785, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}