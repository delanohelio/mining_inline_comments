{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDYyMjc4NjQx", "number": 1287, "title": "Vectorized Reads of Parquet with Identity Partitions", "bodyText": "Previously vectorization would be disabled whenever an underlying iceberg table\nwas using Parquet files and also used Identity transforms in it's partitioning.\nTo fix this we extend the DummyVectorReader to be a ConstantVectorReader which is\nused when a column's value can be determined from the PartitionSpec. Then when\nconstructing the reader we use a ConstantColumnVector to fill in the missing\ncolumn.", "createdAt": "2020-08-03T16:32:22Z", "url": "https://github.com/apache/iceberg/pull/1287", "merged": true, "mergeCommit": {"oid": "71de51805be7954dd423ec29fd4c7d6b303adc1f"}, "closed": true, "closedAt": "2020-08-05T01:08:04Z", "author": {"login": "RussellSpitzer"}, "timelineItems": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc6VvQpgH2gAyNDYyMjc4NjQxOjcxZmU2Njg4NWNlNzA5OTIzMDQ0MWQ0MzEyZTJjMWU2NzJjNjFkMWM=", "endCursor": "Y3Vyc29yOnYyOpPPAAABc7Zcc3gH2gAyNDYyMjc4NjQxOjhiZDljNWVlNzdhNzEyYmE1ZWI5MTI1ZDMxYzBjMWRlNjIyMGI1NGY=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "71fe66885ce7099230441d4312e2c1e672c61d1c", "author": {"user": {"login": "RussellSpitzer", "name": "Russell Spitzer"}}, "url": "https://github.com/apache/iceberg/commit/71fe66885ce7099230441d4312e2c1e672c61d1c", "committedDate": "2020-07-31T15:13:19Z", "message": "Vectorized Reads of Parquet with Identity Partitions\n\nPreviously vectorization would be disabled whenever an underlying iceberg table\nwas using Parquet files and also used Identity transforms in it's partitioning.\nTo fix this we extend the DummyVectorReader to be a ConstantVectorReader which is\nused when a column's value can be determined from the PartitionSpec. Then when\nconstructing the reader we use a ConstantColumnVector to fill in the missing\ncolumn."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDYwMjIzNDIw", "url": "https://github.com/apache/iceberg/pull/1287#pullrequestreview-460223420", "createdAt": "2020-08-03T17:46:24Z", "commit": {"oid": "71fe66885ce7099230441d4312e2c1e672c61d1c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QxNzo0NjoyNFrOG7C98g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QxNzo0NjoyNFrOG7C98g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDU2Nzc5NA==", "bodyText": "Could we rename this to ConstantVectorHolder instead of \"dummy\"? Now that it returns a constant value, I think it's more accurate to use \"constant\".", "url": "https://github.com/apache/iceberg/pull/1287#discussion_r464567794", "createdAt": "2020-08-03T17:46:24Z", "author": {"login": "rdblue"}, "path": "arrow/src/main/java/org/apache/iceberg/arrow/vectorized/VectorHolder.java", "diffHunk": "@@ -91,17 +91,44 @@ public int numValues() {\n     return vector.getValueCount();\n   }\n \n+  public static VectorHolder constantHolder(int numRows, Object constantValue) {\n+    return new DummyVectorHolder(numRows, constantValue);\n+  }\n+\n   public static VectorHolder dummyHolder(int numRows) {\n-    return new VectorHolder() {\n-      @Override\n-      public int numValues() {\n-        return numRows;\n-      }\n-    };\n+    return new DummyVectorHolder(numRows);\n   }\n \n   public boolean isDummy() {\n     return vector == null;\n   }\n \n+  /**\n+   * A Vector Holder which does not actually produce values, consumers of this class should\n+   * use the constantValue to populate their ColumnVector implementation.\n+   */\n+  public static class DummyVectorHolder extends VectorHolder {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "71fe66885ce7099230441d4312e2c1e672c61d1c"}, "originalPosition": 26}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDYwMjI0NzU5", "url": "https://github.com/apache/iceberg/pull/1287#pullrequestreview-460224759", "createdAt": "2020-08-03T17:48:35Z", "commit": {"oid": "71fe66885ce7099230441d4312e2c1e672c61d1c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QxNzo0ODozNVrOG7DCMw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QxNzo0ODozNVrOG7DCMw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDU2ODg4Mw==", "bodyText": "Nit: Looks like this Javadoc is missing the normal *  at the start of these lines?", "url": "https://github.com/apache/iceberg/pull/1287#discussion_r464568883", "createdAt": "2020-08-03T17:48:35Z", "author": {"login": "rdblue"}, "path": "spark/src/test/java/org/apache/iceberg/spark/source/TestIdentityPartitionData.java", "diffHunk": "@@ -110,24 +113,52 @@ public static void stopSpark() {\n   private Table table = null;\n   private Dataset<Row> logs = null;\n \n-  @Before\n-  public void setupTable() throws Exception {\n+  /*\n+  Use the Hive Based table to make Identity Partition Columns with no duplication of the data in the underlying\n+  parquet files. This makes sure that if the identity mapping fails, the test will also fail.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "71fe66885ce7099230441d4312e2c1e672c61d1c"}, "originalPosition": 22}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDYwMjI1NDc2", "url": "https://github.com/apache/iceberg/pull/1287#pullrequestreview-460225476", "createdAt": "2020-08-03T17:49:41Z", "commit": {"oid": "71fe66885ce7099230441d4312e2c1e672c61d1c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QxNzo0OTo0MVrOG7DEkQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QxNzo0OTo0MVrOG7DEkQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDU2OTQ4OQ==", "bodyText": "Isn't this the default? Why was it necessary to add select?", "url": "https://github.com/apache/iceberg/pull/1287#discussion_r464569489", "createdAt": "2020-08-03T17:49:41Z", "author": {"login": "rdblue"}, "path": "spark/src/test/java/org/apache/iceberg/spark/source/TestIdentityPartitionData.java", "diffHunk": "@@ -110,24 +113,52 @@ public static void stopSpark() {\n   private Table table = null;\n   private Dataset<Row> logs = null;\n \n-  @Before\n-  public void setupTable() throws Exception {\n+  /*\n+  Use the Hive Based table to make Identity Partition Columns with no duplication of the data in the underlying\n+  parquet files. This makes sure that if the identity mapping fails, the test will also fail.\n+   */\n+  private void setupParquet() throws Exception {\n     File location = temp.newFolder(\"logs\");\n+    File hiveLocation = temp.newFolder(\"hive\");\n+    String hiveTable = \"hivetable\";\n     Assert.assertTrue(\"Temp folder should exist\", location.exists());\n \n     Map<String, String> properties = ImmutableMap.of(TableProperties.DEFAULT_FILE_FORMAT, format);\n-    this.table = TABLES.create(LOG_SCHEMA, spec, properties, location.toString());\n     this.logs = spark.createDataFrame(LOGS, LogMessage.class).select(\"id\", \"date\", \"level\", \"message\");\n+    spark.sql(String.format(\"DROP TABLE IF EXISTS %s\", hiveTable));\n+    logs.orderBy(\"date\", \"level\", \"id\").write().partitionBy(\"date\", \"level\").format(\"parquet\")\n+        .option(\"path\", hiveLocation.toString()).saveAsTable(hiveTable);\n+\n+    this.table = TABLES.create(SparkSchemaUtil.schemaForTable(spark, hiveTable),\n+        SparkSchemaUtil.specForTable(spark, hiveTable), properties, location.toString());\n+\n+    SparkTableUtil.importSparkTable(spark, new TableIdentifier(hiveTable), table, location.toString());\n+  }\n \n-    logs.orderBy(\"date\", \"level\", \"id\").write().format(\"iceberg\").mode(\"append\").save(location.toString());\n+  @Before\n+  public void setupTable() throws Exception {\n+    if (format.equals(\"parquet\")) {\n+      setupParquet();\n+    } else {\n+      File location = temp.newFolder(\"logs\");\n+      Assert.assertTrue(\"Temp folder should exist\", location.exists());\n+\n+      Map<String, String> properties = ImmutableMap.of(TableProperties.DEFAULT_FILE_FORMAT, format);\n+      this.table = TABLES.create(LOG_SCHEMA, spec, properties, location.toString());\n+      this.logs = spark.createDataFrame(LOGS, LogMessage.class).select(\"id\", \"date\", \"level\", \"message\");\n+\n+      logs.orderBy(\"date\", \"level\", \"id\").write().format(\"iceberg\").mode(\"append\").save(location.toString());\n+    }\n   }\n \n   @Test\n   public void testFullProjection() {\n     List<Row> expected = logs.orderBy(\"id\").collectAsList();\n     List<Row> actual = spark.read().format(\"iceberg\")\n         .option(\"vectorization-enabled\", String.valueOf(vectorized))\n-        .load(table.location()).orderBy(\"id\").collectAsList();\n+        .load(table.location()).orderBy(\"id\")\n+        .select(\"id\", \"date\", \"level\", \"message\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "71fe66885ce7099230441d4312e2c1e672c61d1c"}, "originalPosition": 67}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDYwMjYyNzE0", "url": "https://github.com/apache/iceberg/pull/1287#pullrequestreview-460262714", "createdAt": "2020-08-03T18:50:10Z", "commit": {"oid": "71fe66885ce7099230441d4312e2c1e672c61d1c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QxODo1MDoxMFrOG7E4-Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0wM1QxODo1MDoxMFrOG7E4-Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ2NDU5OTI4OQ==", "bodyText": "VectorHolder.constantHolder and DummyVectorHolder aren't parameterized. It would make sense to have them accept value of type T as well.", "url": "https://github.com/apache/iceberg/pull/1287#discussion_r464599289", "createdAt": "2020-08-03T18:50:10Z", "author": {"login": "samarthjain"}, "path": "arrow/src/main/java/org/apache/iceberg/arrow/vectorized/VectorizedArrowReader.java", "diffHunk": "@@ -356,5 +356,36 @@ public String toString() {\n     public void setBatchSize(int batchSize) {}\n   }\n \n+  /**\n+   * A Dummy Vector Reader which doesn't actually read files, instead it returns a dummy\n+   * VectorHolder which indicates the constant value which should be used for this column.\n+   * @param <T> The constant value to use\n+   */\n+  public static class ConstantVectorReader<T> extends VectorizedArrowReader {\n+    private final T value;\n+\n+    public ConstantVectorReader(T value) {\n+      this.value = value;\n+    }\n+\n+    @Override\n+    public VectorHolder read(VectorHolder reuse, int numValsToRead) {\n+      return VectorHolder.constantHolder(numValsToRead, value);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "71fe66885ce7099230441d4312e2c1e672c61d1c"}, "originalPosition": 18}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8bd9c5ee77a712ba5eb9125d31c0c1de6220b54f", "author": {"user": {"login": "RussellSpitzer", "name": "Russell Spitzer"}}, "url": "https://github.com/apache/iceberg/commit/8bd9c5ee77a712ba5eb9125d31c0c1de6220b54f", "committedDate": "2020-08-03T22:06:19Z", "message": "Reviewer Comments\n\nRenamed Classes\nParameterized Others"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4384, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}