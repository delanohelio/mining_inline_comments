{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQyNTA1OTE3", "number": 1151, "title": "Add Inspecting tables example by HDFS path in the Iceberg User docs", "bodyText": "Add some sample code for how to inspect tables by HDFS path.", "createdAt": "2020-07-01T07:39:55Z", "url": "https://github.com/apache/iceberg/pull/1151", "merged": true, "mergeCommit": {"oid": "5ae0ed1eba84e5e7ef9cac11c8071bd6d81f2258"}, "closed": true, "closedAt": "2020-07-03T16:25:45Z", "author": {"login": "zhangdove"}, "timelineItems": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcwlMPJAH2gAyNDQyNTA1OTE3OmM1NWQzMTg2MDgwNTkyMDQyZjI0MjE0NDViMjJkYzQ3MjQ0ODE3OWI=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcxV9vggH2gAyNDQyNTA1OTE3Ojg0ZGI2MzM4NjZhZDM3OWE0YThmZjBjZTQyNTFlYmU0NzQ3MWZlOTY=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "c55d3186080592042f2421445b22dc472448179b", "author": {"user": {"login": "zhangdove", "name": "zhangdove"}}, "url": "https://github.com/apache/iceberg/commit/c55d3186080592042f2421445b22dc472448179b", "committedDate": "2020-07-01T07:34:18Z", "message": "Update spark.md\n\nAdd Inspecting tables example by HDFS path"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQxMDMxOTIy", "url": "https://github.com/apache/iceberg/pull/1151#pullrequestreview-441031922", "createdAt": "2020-07-01T16:38:36Z", "commit": {"oid": "c55d3186080592042f2421445b22dc472448179b"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxNjozODozNlrOGrtbjA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0wMVQxNjozODozNlrOGrtbjA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0ODQ4NjI4NA==", "bodyText": "Where does table come from? And why require loading MetadataTableType?\nI think it would be better to use just a string, following the pattern of the other HDFS examples:\nspark.read.format(\"iceberg\").load(\"hdfs://nn:8020/warehouse/db.db/table#history\").show(truncate = false)", "url": "https://github.com/apache/iceberg/pull/1151#discussion_r448486284", "createdAt": "2020-07-01T16:38:36Z", "author": {"login": "rdblue"}, "path": "site/docs/spark.md", "diffHunk": "@@ -136,6 +136,11 @@ To show table history, run:\n ```scala\n spark.read.format(\"iceberg\").load(\"db.table.history\").show(truncate = false)\n ```\n+\n+To show table history by HDFS path, run:\n+```scala\n+spark.read.format(\"iceberg\").load(table.location() + \"#\" + MetadataTableType.HISTORY).show( truncate = false)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c55d3186080592042f2421445b22dc472448179b"}, "originalPosition": 7}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c41a930ac7418c57bbe5d9edd667dd8c919ec260", "author": {"user": {"login": "zhangdove", "name": "zhangdove"}}, "url": "https://github.com/apache/iceberg/commit/c41a930ac7418c57bbe5d9edd667dd8c919ec260", "committedDate": "2020-07-02T01:34:56Z", "message": "load meta path by string"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "84db633866ad379a4a8ff0ce4251ebe47471fe96", "author": {"user": {"login": "rdblue", "name": "Ryan Blue"}}, "url": "https://github.com/apache/iceberg/commit/84db633866ad379a4a8ff0ce4251ebe47471fe96", "committedDate": "2020-07-03T16:23:49Z", "message": "Update spark.md"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4579, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}