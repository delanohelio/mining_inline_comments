{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTI3MTIyMDk3", "number": 1822, "reviewThreads": {"totalCount": 8, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwODo0NjoxOFrOE_Ac5A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwOToyNDozOVrOE_CKLQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0NTAzMTQwOnYy", "diffSide": "RIGHT", "path": "flink/src/main/java/org/apache/iceberg/flink/IcebergTableSource.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwODo0NjoxOFrOH8dqGw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQwNDowMDowM1rOIC0d2Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzE2MjUyMw==", "bodyText": "Why disable the  limit push down for flink table source ?", "url": "https://github.com/apache/iceberg/pull/1822#discussion_r533162523", "createdAt": "2020-12-01T08:46:18Z", "author": {"login": "openinx"}, "path": "flink/src/main/java/org/apache/iceberg/flink/IcebergTableSource.java", "diffHunk": "@@ -36,25 +36,30 @@\n \n /**\n  * Flink Iceberg table source.\n- * TODO: Implement {@link FilterableTableSource} and {@link LimitableTableSource}.\n+ * TODO: Implement {@link FilterableTableSource}\n  */\n-public class IcebergTableSource implements StreamTableSource<RowData>, ProjectableTableSource<RowData> {\n+public class IcebergTableSource\n+    implements StreamTableSource<RowData>, ProjectableTableSource<RowData>, LimitableTableSource<RowData> {\n \n   private final TableLoader loader;\n   private final TableSchema schema;\n   private final Map<String, String> properties;\n   private final int[] projectedFields;\n+  private boolean isLimitPushDown = false;\n+  private long limit = -1L;\n \n   public IcebergTableSource(TableLoader loader, TableSchema schema, Map<String, String> properties) {\n-    this(loader, schema, properties, null);\n+    this(loader, schema, properties, null, false, -1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "06ae6164f5ba5d967c3802d830e5914df32314c8"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTc5MjgxNw==", "bodyText": "I think it may be related to the design of the LimitableTableSource interface in flink 1.11. I looked up some implement classes of LimitableTableSource in flink, such as HiveTableSource. By default, the limit pushdown is disabled", "url": "https://github.com/apache/iceberg/pull/1822#discussion_r535792817", "createdAt": "2020-12-04T02:38:39Z", "author": {"login": "zhangjun0x01"}, "path": "flink/src/main/java/org/apache/iceberg/flink/IcebergTableSource.java", "diffHunk": "@@ -36,25 +36,30 @@\n \n /**\n  * Flink Iceberg table source.\n- * TODO: Implement {@link FilterableTableSource} and {@link LimitableTableSource}.\n+ * TODO: Implement {@link FilterableTableSource}\n  */\n-public class IcebergTableSource implements StreamTableSource<RowData>, ProjectableTableSource<RowData> {\n+public class IcebergTableSource\n+    implements StreamTableSource<RowData>, ProjectableTableSource<RowData>, LimitableTableSource<RowData> {\n \n   private final TableLoader loader;\n   private final TableSchema schema;\n   private final Map<String, String> properties;\n   private final int[] projectedFields;\n+  private boolean isLimitPushDown = false;\n+  private long limit = -1L;\n \n   public IcebergTableSource(TableLoader loader, TableSchema schema, Map<String, String> properties) {\n-    this(loader, schema, properties, null);\n+    this(loader, schema, properties, null, false, -1);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzE2MjUyMw=="}, "originalCommit": {"oid": "06ae6164f5ba5d967c3802d830e5914df32314c8"}, "originalPosition": 20}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTgyNzY3Mw==", "bodyText": "Oh, the table won't have a limit cause by default, so we should set it disabled by default.  It's OK here.", "url": "https://github.com/apache/iceberg/pull/1822#discussion_r539827673", "createdAt": "2020-12-10T04:00:03Z", "author": {"login": "openinx"}, "path": "flink/src/main/java/org/apache/iceberg/flink/IcebergTableSource.java", "diffHunk": "@@ -36,25 +36,30 @@\n \n /**\n  * Flink Iceberg table source.\n- * TODO: Implement {@link FilterableTableSource} and {@link LimitableTableSource}.\n+ * TODO: Implement {@link FilterableTableSource}\n  */\n-public class IcebergTableSource implements StreamTableSource<RowData>, ProjectableTableSource<RowData> {\n+public class IcebergTableSource\n+    implements StreamTableSource<RowData>, ProjectableTableSource<RowData>, LimitableTableSource<RowData> {\n \n   private final TableLoader loader;\n   private final TableSchema schema;\n   private final Map<String, String> properties;\n   private final int[] projectedFields;\n+  private boolean isLimitPushDown = false;\n+  private long limit = -1L;\n \n   public IcebergTableSource(TableLoader loader, TableSchema schema, Map<String, String> properties) {\n-    this(loader, schema, properties, null);\n+    this(loader, schema, properties, null, false, -1);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzE2MjUyMw=="}, "originalCommit": {"oid": "06ae6164f5ba5d967c3802d830e5914df32314c8"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0NTA0MjQyOnYy", "diffSide": "RIGHT", "path": "flink/src/main/java/org/apache/iceberg/flink/IcebergTableSource.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwODo0ODoyMVrOH8dxCA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwODo0ODoyMVrOH8dxCA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzE2NDI5Ng==", "bodyText": "Could we add the final modifier ?  Also no need to initialize it with a default false because the constructor will always assign a given value to it.", "url": "https://github.com/apache/iceberg/pull/1822#discussion_r533164296", "createdAt": "2020-12-01T08:48:21Z", "author": {"login": "openinx"}, "path": "flink/src/main/java/org/apache/iceberg/flink/IcebergTableSource.java", "diffHunk": "@@ -36,25 +36,30 @@\n \n /**\n  * Flink Iceberg table source.\n- * TODO: Implement {@link FilterableTableSource} and {@link LimitableTableSource}.\n+ * TODO: Implement {@link FilterableTableSource}\n  */\n-public class IcebergTableSource implements StreamTableSource<RowData>, ProjectableTableSource<RowData> {\n+public class IcebergTableSource\n+    implements StreamTableSource<RowData>, ProjectableTableSource<RowData>, LimitableTableSource<RowData> {\n \n   private final TableLoader loader;\n   private final TableSchema schema;\n   private final Map<String, String> properties;\n   private final int[] projectedFields;\n+  private boolean isLimitPushDown = false;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "06ae6164f5ba5d967c3802d830e5914df32314c8"}, "originalPosition": 15}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0NTEzOTMyOnYy", "diffSide": "RIGHT", "path": "flink/src/main/java/org/apache/iceberg/flink/IcebergTableSource.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwOTowMTo1MVrOH8exSw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQwMjozMjo1N1rOH--FvA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzE4MDc0Nw==", "bodyText": "if limit is -1L, then means we've disabled the limit push down , right ?  If so, why do we need two fields ?", "url": "https://github.com/apache/iceberg/pull/1822#discussion_r533180747", "createdAt": "2020-12-01T09:01:51Z", "author": {"login": "openinx"}, "path": "flink/src/main/java/org/apache/iceberg/flink/IcebergTableSource.java", "diffHunk": "@@ -36,25 +36,30 @@\n \n /**\n  * Flink Iceberg table source.\n- * TODO: Implement {@link FilterableTableSource} and {@link LimitableTableSource}.\n+ * TODO: Implement {@link FilterableTableSource}\n  */\n-public class IcebergTableSource implements StreamTableSource<RowData>, ProjectableTableSource<RowData> {\n+public class IcebergTableSource\n+    implements StreamTableSource<RowData>, ProjectableTableSource<RowData>, LimitableTableSource<RowData> {\n \n   private final TableLoader loader;\n   private final TableSchema schema;\n   private final Map<String, String> properties;\n   private final int[] projectedFields;\n+  private boolean isLimitPushDown = false;\n+  private long limit = -1L;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "06ae6164f5ba5d967c3802d830e5914df32314c8"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTc5MTAzNg==", "bodyText": "I also think we can judge whether to pushdown by the value of limit, but the  LimitableTableSource interface provides two methods, isLimitPushedDown and applyLimit. From the method comments, I think the author wants to judge whether to pushdown by the isLimitPushedDown method.\nIn versions after flink 1.12, a new interface SupportsLimitPushDown is provided. This interface only provides one method. I think we can judge pushdown by the value of limit", "url": "https://github.com/apache/iceberg/pull/1822#discussion_r535791036", "createdAt": "2020-12-04T02:32:57Z", "author": {"login": "zhangjun0x01"}, "path": "flink/src/main/java/org/apache/iceberg/flink/IcebergTableSource.java", "diffHunk": "@@ -36,25 +36,30 @@\n \n /**\n  * Flink Iceberg table source.\n- * TODO: Implement {@link FilterableTableSource} and {@link LimitableTableSource}.\n+ * TODO: Implement {@link FilterableTableSource}\n  */\n-public class IcebergTableSource implements StreamTableSource<RowData>, ProjectableTableSource<RowData> {\n+public class IcebergTableSource\n+    implements StreamTableSource<RowData>, ProjectableTableSource<RowData>, LimitableTableSource<RowData> {\n \n   private final TableLoader loader;\n   private final TableSchema schema;\n   private final Map<String, String> properties;\n   private final int[] projectedFields;\n+  private boolean isLimitPushDown = false;\n+  private long limit = -1L;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzE4MDc0Nw=="}, "originalCommit": {"oid": "06ae6164f5ba5d967c3802d830e5914df32314c8"}, "originalPosition": 16}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0NTE3MTA4OnYy", "diffSide": "RIGHT", "path": "flink/src/main/java/org/apache/iceberg/flink/IcebergTableSource.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwOTowNjoxM1rOH8fGSw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwOTowNjoxM1rOH8fGSw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzE4NjEyMw==", "bodyText": "Here the isLimitPushDown is always true, how about use the string String.format(\", LimitPushDown: %d\", limit) ?", "url": "https://github.com/apache/iceberg/pull/1822#discussion_r533186123", "createdAt": "2020-12-01T09:06:13Z", "author": {"login": "openinx"}, "path": "flink/src/main/java/org/apache/iceberg/flink/IcebergTableSource.java", "diffHunk": "@@ -102,6 +107,21 @@ public String explainSource() {\n     if (projectedFields != null) {\n       explain += \", ProjectedFields: \" + Arrays.toString(projectedFields);\n     }\n+\n+    if (isLimitPushDown) {\n+      explain += String.format(\", LimitPushDown %s, Limit %d\", isLimitPushDown, limit);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "06ae6164f5ba5d967c3802d830e5914df32314c8"}, "originalPosition": 56}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0NTIxNDI4OnYy", "diffSide": "RIGHT", "path": "flink/src/main/java/org/apache/iceberg/flink/source/ScanContext.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwOToxMjowN1rOH8fiHQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQwMjo0NzoyOVrOH--YaA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzE5MzI0NQ==", "bodyText": "Do we need this ?  we don't parse the limit from properties, right ?", "url": "https://github.com/apache/iceberg/pull/1822#discussion_r533193245", "createdAt": "2020-12-01T09:12:07Z", "author": {"login": "openinx"}, "path": "flink/src/main/java/org/apache/iceberg/flink/source/ScanContext.java", "diffHunk": "@@ -61,6 +61,8 @@\n   private static final ConfigOption<Long> SPLIT_FILE_OPEN_COST =\n       ConfigOptions.key(\"split-file-open-cost\").longType().defaultValue(null);\n \n+  private static final ConfigOption<Long> LIMIT = ConfigOptions.key(\"limit\").longType().defaultValue(-1L);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "06ae6164f5ba5d967c3802d830e5914df32314c8"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTc5NTgxNg==", "bodyText": "I removed it", "url": "https://github.com/apache/iceberg/pull/1822#discussion_r535795816", "createdAt": "2020-12-04T02:47:29Z", "author": {"login": "zhangjun0x01"}, "path": "flink/src/main/java/org/apache/iceberg/flink/source/ScanContext.java", "diffHunk": "@@ -61,6 +61,8 @@\n   private static final ConfigOption<Long> SPLIT_FILE_OPEN_COST =\n       ConfigOptions.key(\"split-file-open-cost\").longType().defaultValue(null);\n \n+  private static final ConfigOption<Long> LIMIT = ConfigOptions.key(\"limit\").longType().defaultValue(-1L);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzE5MzI0NQ=="}, "originalCommit": {"oid": "06ae6164f5ba5d967c3802d830e5914df32314c8"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0NTIzODY5OnYy", "diffSide": "RIGHT", "path": "flink/src/main/java/org/apache/iceberg/flink/source/FlinkInputFormat.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwOToxNToyOVrOH8fyAg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQwMjo0ODowMlrOH--ZKA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzE5NzMxNA==", "bodyText": "How about just using the context.limit()  in reachedEnd, rather than introducing another new transient field limit ?", "url": "https://github.com/apache/iceberg/pull/1822#discussion_r533197314", "createdAt": "2020-12-01T09:15:29Z", "author": {"login": "openinx"}, "path": "flink/src/main/java/org/apache/iceberg/flink/source/FlinkInputFormat.java", "diffHunk": "@@ -48,6 +48,8 @@\n   private final ScanContext context;\n \n   private transient RowDataIterator iterator;\n+  private transient long currentReadCount = 0L;\n+  private transient long limit;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "06ae6164f5ba5d967c3802d830e5914df32314c8"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTc5NjAwOA==", "bodyText": "I deleted the field limit", "url": "https://github.com/apache/iceberg/pull/1822#discussion_r535796008", "createdAt": "2020-12-04T02:48:02Z", "author": {"login": "zhangjun0x01"}, "path": "flink/src/main/java/org/apache/iceberg/flink/source/FlinkInputFormat.java", "diffHunk": "@@ -48,6 +48,8 @@\n   private final ScanContext context;\n \n   private transient RowDataIterator iterator;\n+  private transient long currentReadCount = 0L;\n+  private transient long limit;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzE5NzMxNA=="}, "originalCommit": {"oid": "06ae6164f5ba5d967c3802d830e5914df32314c8"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0NTI4MjgyOnYy", "diffSide": "RIGHT", "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkTableSource.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwOToyMToxMVrOH8gN7A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwOToyMToxMVrOH8gN7A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzIwNDQ2MA==", "bodyText": "nit: with -> WITH", "url": "https://github.com/apache/iceberg/pull/1822#discussion_r533204460", "createdAt": "2020-12-01T09:21:11Z", "author": {"login": "openinx"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkTableSource.java", "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+\n+import java.util.List;\n+import org.apache.iceberg.FileFormat;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import static org.junit.Assert.assertTrue;\n+\n+@RunWith(Parameterized.class)\n+public class TestFlinkTableSource extends FlinkCatalogTestBase {\n+  private static final String TABLE_NAME = \"test_table\";\n+\n+  private final FileFormat format;\n+\n+  @Parameterized.Parameters(name = \"catalogName={0}, baseNamespace={1}, format={2}\")\n+  public static Iterable<Object[]> parameters() {\n+    List<Object[]> parameters = Lists.newArrayList();\n+    for (FileFormat format : new FileFormat[] {FileFormat.ORC, FileFormat.AVRO, FileFormat.PARQUET}) {\n+      for (Object[] catalogParams : FlinkCatalogTestBase.parameters()) {\n+        String catalogName = (String) catalogParams[0];\n+        String[] baseNamespace = (String[]) catalogParams[1];\n+        parameters.add(new Object[] {catalogName, baseNamespace, format});\n+      }\n+    }\n+    return parameters;\n+  }\n+\n+  public TestFlinkTableSource(String catalogName, String[] baseNamespace, FileFormat format) {\n+    super(catalogName, baseNamespace);\n+    this.format = format;\n+  }\n+\n+  @Before\n+  public void before() {\n+    super.before();\n+    sql(\"CREATE DATABASE %s\", flinkDatabase);\n+    sql(\"USE CATALOG %s\", catalogName);\n+    sql(\"USE %s\", DATABASE);\n+    sql(\"CREATE TABLE %s (id INT, data VARCHAR) with ('write.format.default'='%s')\", TABLE_NAME, format.name());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "06ae6164f5ba5d967c3802d830e5914df32314c8"}, "originalPosition": 65}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM0NTMxMTE3OnYy", "diffSide": "RIGHT", "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkTableSource.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwOToyNDozOVrOH8ghCg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQwMjo0NToyMVrOH--VgQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzIwOTM1NA==", "bodyText": "Do we need to add those test cases:\nCase.1 :  SELECT * FROM test LIMIT -1\nCase.2 :  SELECT * FROM test LIMIT 0 \nCase.3:   SELECT * FROM test LIMIT 3 ,  means the limit  exceeds the total rows in table .\nCase.4:   SELECT * FROM test WHERE a = 1 AND LIMIT 2 ,  query data with both limit and filters\netc.", "url": "https://github.com/apache/iceberg/pull/1822#discussion_r533209354", "createdAt": "2020-12-01T09:24:39Z", "author": {"login": "openinx"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkTableSource.java", "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+\n+import java.util.List;\n+import org.apache.iceberg.FileFormat;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import static org.junit.Assert.assertTrue;\n+\n+@RunWith(Parameterized.class)\n+public class TestFlinkTableSource extends FlinkCatalogTestBase {\n+  private static final String TABLE_NAME = \"test_table\";\n+\n+  private final FileFormat format;\n+\n+  @Parameterized.Parameters(name = \"catalogName={0}, baseNamespace={1}, format={2}\")\n+  public static Iterable<Object[]> parameters() {\n+    List<Object[]> parameters = Lists.newArrayList();\n+    for (FileFormat format : new FileFormat[] {FileFormat.ORC, FileFormat.AVRO, FileFormat.PARQUET}) {\n+      for (Object[] catalogParams : FlinkCatalogTestBase.parameters()) {\n+        String catalogName = (String) catalogParams[0];\n+        String[] baseNamespace = (String[]) catalogParams[1];\n+        parameters.add(new Object[] {catalogName, baseNamespace, format});\n+      }\n+    }\n+    return parameters;\n+  }\n+\n+  public TestFlinkTableSource(String catalogName, String[] baseNamespace, FileFormat format) {\n+    super(catalogName, baseNamespace);\n+    this.format = format;\n+  }\n+\n+  @Before\n+  public void before() {\n+    super.before();\n+    sql(\"CREATE DATABASE %s\", flinkDatabase);\n+    sql(\"USE CATALOG %s\", catalogName);\n+    sql(\"USE %s\", DATABASE);\n+    sql(\"CREATE TABLE %s (id INT, data VARCHAR) with ('write.format.default'='%s')\", TABLE_NAME, format.name());\n+  }\n+\n+  @After\n+  public void clean() {\n+    sql(\"DROP TABLE IF EXISTS %s.%s\", flinkDatabase, TABLE_NAME);\n+    sql(\"DROP DATABASE IF EXISTS %s\", flinkDatabase);\n+    super.clean();\n+  }\n+\n+  @Test\n+  public void testLimitPushDown() {\n+    sql(\"INSERT INTO %s  VALUES (1,'a'),(2,'b')\", TABLE_NAME);\n+\n+    String querySql = String.format(\"SELECT * FROM %s LIMIT 1\", TABLE_NAME);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "06ae6164f5ba5d967c3802d830e5914df32314c8"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTc5NTA3Mw==", "bodyText": "I added the test case", "url": "https://github.com/apache/iceberg/pull/1822#discussion_r535795073", "createdAt": "2020-12-04T02:45:21Z", "author": {"login": "zhangjun0x01"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkTableSource.java", "diffHunk": "@@ -0,0 +1,88 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+\n+import java.util.List;\n+import org.apache.iceberg.FileFormat;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+import static org.junit.Assert.assertTrue;\n+\n+@RunWith(Parameterized.class)\n+public class TestFlinkTableSource extends FlinkCatalogTestBase {\n+  private static final String TABLE_NAME = \"test_table\";\n+\n+  private final FileFormat format;\n+\n+  @Parameterized.Parameters(name = \"catalogName={0}, baseNamespace={1}, format={2}\")\n+  public static Iterable<Object[]> parameters() {\n+    List<Object[]> parameters = Lists.newArrayList();\n+    for (FileFormat format : new FileFormat[] {FileFormat.ORC, FileFormat.AVRO, FileFormat.PARQUET}) {\n+      for (Object[] catalogParams : FlinkCatalogTestBase.parameters()) {\n+        String catalogName = (String) catalogParams[0];\n+        String[] baseNamespace = (String[]) catalogParams[1];\n+        parameters.add(new Object[] {catalogName, baseNamespace, format});\n+      }\n+    }\n+    return parameters;\n+  }\n+\n+  public TestFlinkTableSource(String catalogName, String[] baseNamespace, FileFormat format) {\n+    super(catalogName, baseNamespace);\n+    this.format = format;\n+  }\n+\n+  @Before\n+  public void before() {\n+    super.before();\n+    sql(\"CREATE DATABASE %s\", flinkDatabase);\n+    sql(\"USE CATALOG %s\", catalogName);\n+    sql(\"USE %s\", DATABASE);\n+    sql(\"CREATE TABLE %s (id INT, data VARCHAR) with ('write.format.default'='%s')\", TABLE_NAME, format.name());\n+  }\n+\n+  @After\n+  public void clean() {\n+    sql(\"DROP TABLE IF EXISTS %s.%s\", flinkDatabase, TABLE_NAME);\n+    sql(\"DROP DATABASE IF EXISTS %s\", flinkDatabase);\n+    super.clean();\n+  }\n+\n+  @Test\n+  public void testLimitPushDown() {\n+    sql(\"INSERT INTO %s  VALUES (1,'a'),(2,'b')\", TABLE_NAME);\n+\n+    String querySql = String.format(\"SELECT * FROM %s LIMIT 1\", TABLE_NAME);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzIwOTM1NA=="}, "originalCommit": {"oid": "06ae6164f5ba5d967c3802d830e5914df32314c8"}, "originalPosition": 79}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3157, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}