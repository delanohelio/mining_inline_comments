{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDg3OTI1Mjc3", "number": 1465, "reviewThreads": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQxNzoyOToxMFrOEkJ5Fw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QxNzozMjo1NlrOEkpujw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2MzQ2MjYzOnYy", "diffSide": "RIGHT", "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopTableOperations.java", "isResolved": false, "comments": {"totalCount": 9, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQxNzoyOToxMFrOHS7E7A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxODo0MzoyOFrOHUYHxA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTYwNDMzMg==", "bodyText": "Why make this debug instead of warn? I think it is still concerning that the version hint couldn't be found.", "url": "https://github.com/apache/iceberg/pull/1465#discussion_r489604332", "createdAt": "2020-09-16T17:29:10Z", "author": {"login": "rdblue"}, "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopTableOperations.java", "diffHunk": "@@ -289,19 +311,24 @@ int readVersionHint() {\n       return Integer.parseInt(in.readLine().replace(\"\\n\", \"\"));\n \n     } catch (Exception e) {\n-      LOG.warn(\"Error reading version hint file {}\", versionHintFile, e);\n+      LOG.debug(\"Error reading version hint file {}\", versionHintFile, e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "292af8eb888b7df3db4472c37c47a66417845b93"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTYxMzYwOQ==", "bodyText": "I'd go one step further. I think a user should have to opt into this fallback behavior. I think the default should be to throw an exception. Silently \"corrupting\" the table isn't something that should happen.", "url": "https://github.com/apache/iceberg/pull/1465#discussion_r489613609", "createdAt": "2020-09-16T17:45:47Z", "author": {"login": "jacques-n"}, "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopTableOperations.java", "diffHunk": "@@ -289,19 +311,24 @@ int readVersionHint() {\n       return Integer.parseInt(in.readLine().replace(\"\\n\", \"\"));\n \n     } catch (Exception e) {\n-      LOG.warn(\"Error reading version hint file {}\", versionHintFile, e);\n+      LOG.debug(\"Error reading version hint file {}\", versionHintFile, e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTYwNDMzMg=="}, "originalCommit": {"oid": "292af8eb888b7df3db4472c37c47a66417845b93"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTYyMTU3MA==", "bodyText": "The warn message appeared several times for me and I have realized that we call this method even for new tables to check that the data/metadata is not yet there, so this warning message could be misleading.\n@jacques-n: Adding a configuration seems like a good idea because this recovery mechanisms starts to become complicated. Could you help by pointing out some similar configurable solutions from where I can start from?\nThanks,\nPeter", "url": "https://github.com/apache/iceberg/pull/1465#discussion_r489621570", "createdAt": "2020-09-16T17:59:45Z", "author": {"login": "pvary"}, "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopTableOperations.java", "diffHunk": "@@ -289,19 +311,24 @@ int readVersionHint() {\n       return Integer.parseInt(in.readLine().replace(\"\\n\", \"\"));\n \n     } catch (Exception e) {\n-      LOG.warn(\"Error reading version hint file {}\", versionHintFile, e);\n+      LOG.debug(\"Error reading version hint file {}\", versionHintFile, e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTYwNDMzMg=="}, "originalCommit": {"oid": "292af8eb888b7df3db4472c37c47a66417845b93"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTcwNDg1NQ==", "bodyText": "@rdblue we've seen this happening with hadoop implementations that implement create(overwrite=true) by a server-side delete and create operation - so the API isn't consistent - for a split micro-second we get a 404 on the version-hint.text file - we're covering for those with retries - however they do provide read-after-write guarantees on directory listing - so we've looked at solving this in a pretty similar fashion, but instead of a fallback mechanism we went with the approach that a table configuration (or version?) indicates the version resolver implementation, either file based or directory listing based (each version is created as a new, version named file with create(overwrite=false), just like the version files, in the versions directory and the same listing is applied to pick the highest ranking), but I think this approach is actually better cause it's simple however it doesn't control the latency of the list API...\n@jacques-n I don't think that this approach to fallback to directory listing in case of failing to resolve the version hint file can lead to silent \"corruption\" of the table. Can you think of such a scenario? I'm asking cause we were considering doing something similar so I'm interested in any thoughts that may question this approach.\nBut to your point if there so much is a possibility that this approach can lead to table corruption then we should probably not provide this feature at all, let alone say support it by a \"turn-this-feature-at-own-risk\" approach - it will still corrupt the table :)\n@pvary Big difference in the listing directory vs file approach is the constant time in loading data from a file (constant time) vs using hadoop listing directory (probably not constant time).\nI would assume it would take longer to resolve the version and probably it would be advised that older versions are dropped so the list API provides a decent latency.", "url": "https://github.com/apache/iceberg/pull/1465#discussion_r489704855", "createdAt": "2020-09-16T19:29:45Z", "author": {"login": "fbocse"}, "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopTableOperations.java", "diffHunk": "@@ -289,19 +311,24 @@ int readVersionHint() {\n       return Integer.parseInt(in.readLine().replace(\"\\n\", \"\"));\n \n     } catch (Exception e) {\n-      LOG.warn(\"Error reading version hint file {}\", versionHintFile, e);\n+      LOG.debug(\"Error reading version hint file {}\", versionHintFile, e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTYwNDMzMg=="}, "originalCommit": {"oid": "292af8eb888b7df3db4472c37c47a66417845b93"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDEyODQxMA==", "bodyText": "I think this approach is actually better cause it's simple however it doesn't control the latency of the list API...\n\nIf I understand correctly in HadoopTableOperations.refresh() we use the number provided by versionHint() only as a basis for checking newer versions. Would that cover your concerns?\n      Path nextMetadataFile = getMetadataFile(ver + 1);\n      while (nextMetadataFile != null) {\n        ver += 1;\n        metadataFile = nextMetadataFile;\n        nextMetadataFile = getMetadataFile(ver + 1);\n      }\n\n      updateVersionAndMetadata(ver, metadataFile.toString());\n\n\n@pvary Big difference in the listing directory vs file approach is the constant time in loading data from a file (constant time) vs using hadoop listing directory (probably not constant time).\n\nWith the current patch we still do the fast / file based version resolving, and only fall back to the listing based version if there is a problem with the version-hint.txt file.\n\nI would assume it would take longer to resolve the version and probably it would be advised that older versions are dropped so the list API provides a decent latency.\n\nBased on my current understanding the older versions might be needed for timetravel or other features. It should be really the decision of the users to decide when they want to remove them.", "url": "https://github.com/apache/iceberg/pull/1465#discussion_r490128410", "createdAt": "2020-09-17T10:09:54Z", "author": {"login": "pvary"}, "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopTableOperations.java", "diffHunk": "@@ -289,19 +311,24 @@ int readVersionHint() {\n       return Integer.parseInt(in.readLine().replace(\"\\n\", \"\"));\n \n     } catch (Exception e) {\n-      LOG.warn(\"Error reading version hint file {}\", versionHintFile, e);\n+      LOG.debug(\"Error reading version hint file {}\", versionHintFile, e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTYwNDMzMg=="}, "originalCommit": {"oid": "292af8eb888b7df3db4472c37c47a66417845b93"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDQzNzMyMw==", "bodyText": "I think @jacques-n has a good point. The version file should not be corrupt and we should make sure of it by changing how we write the file. Since this is for HDFS, creating the file with an atomic rename to ensure the entire file is written before making it the current version hint makes sense to me. That way we don't get dirty reads.\nDoing that would result in cases like @fbocse brings up: we'd have to delete the version hint file to rename into its place. And there are cases where the hint file is missing, like when trying to load a table to check whether it exists. In that case, I don't think that it makes sense to warn when a hint file is missing, only when it is corrupt. It would still be good to have an info log when the file is missing and there is no metadata (table doesn't exist), and a warning if the file is missing but a metadata file is found.\nLast, I'm for an option to throw an exception when the hint file is corrupt rather than throwing a warning, but the hint file is not intended as a requirement for correctness, so I'd turn this off by default.", "url": "https://github.com/apache/iceberg/pull/1465#discussion_r490437323", "createdAt": "2020-09-17T17:32:00Z", "author": {"login": "rdblue"}, "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopTableOperations.java", "diffHunk": "@@ -289,19 +311,24 @@ int readVersionHint() {\n       return Integer.parseInt(in.readLine().replace(\"\\n\", \"\"));\n \n     } catch (Exception e) {\n-      LOG.warn(\"Error reading version hint file {}\", versionHintFile, e);\n+      LOG.debug(\"Error reading version hint file {}\", versionHintFile, e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTYwNDMzMg=="}, "originalCommit": {"oid": "292af8eb888b7df3db4472c37c47a66417845b93"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDYzMjEyMw==", "bodyText": "Looking at the code, I was wrong about the table corruption. I thought that the version hint file was used in a slightly different manner. I agree with @rdblue that the default probably shouldn't be exception.", "url": "https://github.com/apache/iceberg/pull/1465#discussion_r490632123", "createdAt": "2020-09-18T00:23:32Z", "author": {"login": "jacques-n"}, "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopTableOperations.java", "diffHunk": "@@ -289,19 +311,24 @@ int readVersionHint() {\n       return Integer.parseInt(in.readLine().replace(\"\\n\", \"\"));\n \n     } catch (Exception e) {\n-      LOG.warn(\"Error reading version hint file {}\", versionHintFile, e);\n+      LOG.debug(\"Error reading version hint file {}\", versionHintFile, e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTYwNDMzMg=="}, "originalCommit": {"oid": "292af8eb888b7df3db4472c37c47a66417845b93"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDg1MjcwNA==", "bodyText": "I think @jacques-n has a good point. The version file should not be corrupt and we should make sure of it by changing how we write the file. Since this is for HDFS, creating the file with an atomic rename to ensure the entire file is written before making it the current version hint makes sense to me. That way we don't get dirty reads.\n\nI think that is something for another PR.\n\nIt would still be good to have an info log when the file is missing and there is no metadata (table doesn't exist), and a warning if the file is missing but a metadata file is found.\n\nHere is my proposed solution:\n\nNo metadata directory: DEBUG log - there are some perfectly valid cases where we expect that the directory/table is not there. Higher level log message could be very confusing (Seen very bad examples in Hive code \ud83d\ude22)\nExisting metadata directory, no hint file: WARN log - transient error, or hint file error. Good to be aware of.\nIOException while checking for existence of the metadata directory or listing: WARN log - Some fs level exception. Has to be checked.\n\nYour thoughts?\n\nLast, I'm for an option to throw an exception when the hint file is corrupt rather than throwing a warning, but the hint file is not intended as a requirement for correctness, so I'd turn this off by default.\n\nCould someone please point me a place (code lines) where and how Iceberg configurations are handled, so I can use them correctly?\nThanks,\nPeter", "url": "https://github.com/apache/iceberg/pull/1465#discussion_r490852704", "createdAt": "2020-09-18T10:27:10Z", "author": {"login": "pvary"}, "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopTableOperations.java", "diffHunk": "@@ -289,19 +311,24 @@ int readVersionHint() {\n       return Integer.parseInt(in.readLine().replace(\"\\n\", \"\"));\n \n     } catch (Exception e) {\n-      LOG.warn(\"Error reading version hint file {}\", versionHintFile, e);\n+      LOG.debug(\"Error reading version hint file {}\", versionHintFile, e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTYwNDMzMg=="}, "originalCommit": {"oid": "292af8eb888b7df3db4472c37c47a66417845b93"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MTEyODc3Mg==", "bodyText": "Could someone please point me a place (code lines) where and how Iceberg configurations are handled, so I can use them correctly?\n\nI don't think we need this option since Jacques replied that he agrees it should not be an exception.\nFor configuration, we prefer to use table properties for most configuration, which are defined in the TableProperties class. For other cases, we use the configuration that makes the most sense. Here, I would use the Hadoop configuration because the table implementation is for Hadoop and HDFS.", "url": "https://github.com/apache/iceberg/pull/1465#discussion_r491128772", "createdAt": "2020-09-18T18:43:28Z", "author": {"login": "rdblue"}, "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopTableOperations.java", "diffHunk": "@@ -289,19 +311,24 @@ int readVersionHint() {\n       return Integer.parseInt(in.readLine().replace(\"\\n\", \"\"));\n \n     } catch (Exception e) {\n-      LOG.warn(\"Error reading version hint file {}\", versionHintFile, e);\n+      LOG.debug(\"Error reading version hint file {}\", versionHintFile, e);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTYwNDMzMg=="}, "originalCommit": {"oid": "292af8eb888b7df3db4472c37c47a66417845b93"}, "originalPosition": 79}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2MzQ2ODU3OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopTableOperations.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQxNzozMDo0OVrOHS7Ijw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QxMToxNDo0NlrOHTdGmg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTYwNTI2Mw==", "bodyText": "Nit: we like to have newlines after control flow statements/blocks.", "url": "https://github.com/apache/iceberg/pull/1465#discussion_r489605263", "createdAt": "2020-09-16T17:30:49Z", "author": {"login": "rdblue"}, "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopTableOperations.java", "diffHunk": "@@ -289,19 +311,24 @@ int readVersionHint() {\n       return Integer.parseInt(in.readLine().replace(\"\\n\", \"\"));\n \n     } catch (Exception e) {\n-      LOG.warn(\"Error reading version hint file {}\", versionHintFile, e);\n+      LOG.debug(\"Error reading version hint file {}\", versionHintFile, e);\n       try {\n-        if (getMetadataFile(1) != null) {\n-          // We just assume corrupted metadata and start to read from the first version file\n-          return 1;\n+        // List the metadata directory to find the version files, and try to recover the max available version\n+        FileStatus[] files = fs.listStatus(metadataRoot(), name -> VERSION_PATTERN.matcher(name.getName()).matches());\n+        int maxVersion = 0;\n+\n+        for (FileStatus file : files) {\n+          version = version(file.getPath().getName());\n+          if (version > maxVersion && getMetadataFile(version) != null) {\n+            maxVersion = version;\n+          }\n         }\n+        return maxVersion;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "292af8eb888b7df3db4472c37c47a66417845b93"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDEyODUxOA==", "bodyText": "Done", "url": "https://github.com/apache/iceberg/pull/1465#discussion_r490128518", "createdAt": "2020-09-17T10:10:05Z", "author": {"login": "pvary"}, "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopTableOperations.java", "diffHunk": "@@ -289,19 +311,24 @@ int readVersionHint() {\n       return Integer.parseInt(in.readLine().replace(\"\\n\", \"\"));\n \n     } catch (Exception e) {\n-      LOG.warn(\"Error reading version hint file {}\", versionHintFile, e);\n+      LOG.debug(\"Error reading version hint file {}\", versionHintFile, e);\n       try {\n-        if (getMetadataFile(1) != null) {\n-          // We just assume corrupted metadata and start to read from the first version file\n-          return 1;\n+        // List the metadata directory to find the version files, and try to recover the max available version\n+        FileStatus[] files = fs.listStatus(metadataRoot(), name -> VERSION_PATTERN.matcher(name.getName()).matches());\n+        int maxVersion = 0;\n+\n+        for (FileStatus file : files) {\n+          version = version(file.getPath().getName());\n+          if (version > maxVersion && getMetadataFile(version) != null) {\n+            maxVersion = version;\n+          }\n         }\n+        return maxVersion;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTYwNTI2Mw=="}, "originalCommit": {"oid": "292af8eb888b7df3db4472c37c47a66417845b93"}, "originalPosition": 94}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDE2MTgxOA==", "bodyText": "Done", "url": "https://github.com/apache/iceberg/pull/1465#discussion_r490161818", "createdAt": "2020-09-17T11:14:46Z", "author": {"login": "pvary"}, "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopTableOperations.java", "diffHunk": "@@ -289,19 +311,24 @@ int readVersionHint() {\n       return Integer.parseInt(in.readLine().replace(\"\\n\", \"\"));\n \n     } catch (Exception e) {\n-      LOG.warn(\"Error reading version hint file {}\", versionHintFile, e);\n+      LOG.debug(\"Error reading version hint file {}\", versionHintFile, e);\n       try {\n-        if (getMetadataFile(1) != null) {\n-          // We just assume corrupted metadata and start to read from the first version file\n-          return 1;\n+        // List the metadata directory to find the version files, and try to recover the max available version\n+        FileStatus[] files = fs.listStatus(metadataRoot(), name -> VERSION_PATTERN.matcher(name.getName()).matches());\n+        int maxVersion = 0;\n+\n+        for (FileStatus file : files) {\n+          version = version(file.getPath().getName());\n+          if (version > maxVersion && getMetadataFile(version) != null) {\n+            maxVersion = version;\n+          }\n         }\n+        return maxVersion;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTYwNTI2Mw=="}, "originalCommit": {"oid": "292af8eb888b7df3db4472c37c47a66417845b93"}, "originalPosition": 94}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2MzQ3MjM2OnYy", "diffSide": "RIGHT", "path": "core/src/test/java/org/apache/iceberg/hadoop/TestHadoopCatalog.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQxNzozMTo1NFrOHS7K6g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QxMToxNTozN1rOHTdIfQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTYwNTg2Ng==", "bodyText": "Since this is a new feature, can you put it in its own test method?", "url": "https://github.com/apache/iceberg/pull/1465#discussion_r489605866", "createdAt": "2020-09-16T17:31:54Z", "author": {"login": "rdblue"}, "path": "core/src/test/java/org/apache/iceberg/hadoop/TestHadoopCatalog.java", "diffHunk": "@@ -494,23 +495,42 @@ public void testVersionHintFile() throws Exception {\n       stream.write(\"3\".getBytes(StandardCharsets.UTF_8));\n     }\n \n-    // Check the result of the readVersionHint(), and load the table and check the current snapshotId\n-    Assert.assertEquals(3, tableOperations.readVersionHint());\n+    // Check the result of the versionHint(), and load the table and check the current snapshotId\n+    Assert.assertEquals(3, tableOperations.versionHint());\n     Assert.assertEquals(secondSnapshotId, catalog.loadTable(tableId).currentSnapshot().snapshotId());\n \n     // Write an empty version hint file\n     io.deleteFile(versionHintLocation);\n     io.newOutputFile(versionHintLocation).create().close();\n \n-    // Check the result of the readVersionHint(), and load the table and check the current snapshotId\n-    Assert.assertEquals(1, tableOperations.readVersionHint());\n+    // Check the result of the versionHint(), and load the table and check the current snapshotId\n+    Assert.assertEquals(3, tableOperations.versionHint());\n     Assert.assertEquals(secondSnapshotId, catalog.loadTable(tableId).currentSnapshot().snapshotId());\n \n     // Just delete the file - double check that we have manipulated the correct file\n     io.deleteFile(versionHintLocation);\n \n-    // Check the result of the readVersionHint(), and load the table and check the current snapshotId\n-    Assert.assertEquals(1, tableOperations.readVersionHint());\n+    // Check the result of the versionHint(), and load the table and check the current snapshotId\n+    Assert.assertEquals(3, tableOperations.versionHint());\n     Assert.assertEquals(secondSnapshotId, catalog.loadTable(tableId).currentSnapshot().snapshotId());\n+\n+    // Remove the first version file, and see if we can recover\n+    io.deleteFile(tableOperations.getMetadataFile(1).toString());\n+\n+    // Check the result of the versionHint(), and load the table and check the current snapshotId\n+    Assert.assertEquals(3, tableOperations.versionHint());\n+    Assert.assertEquals(secondSnapshotId, catalog.loadTable(tableId).currentSnapshot().snapshotId());\n+\n+    // Remove all the version files, and see if we can recover. Hint... not :)\n+    io.deleteFile(tableOperations.getMetadataFile(2).toString());\n+    io.deleteFile(tableOperations.getMetadataFile(3).toString());\n+\n+    // Check that we got 0 versionHint, and a NoSuchTableException is thrown when trying to load the table\n+    Assert.assertEquals(0, tableOperations.versionHint());\n+    AssertHelpers.assertThrows(\n+        \"Should not be able to find the table\",\n+        NoSuchTableException.class,\n+        \"Table does not exist: tbl\",\n+        () -> catalog.loadTable(tableId));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "292af8eb888b7df3db4472c37c47a66417845b93"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDEyOTEwNg==", "bodyText": "Done.\nCreate a new method for this.\nMight refactor a little bit later to have a nicer code, but first I would like to be sure that the failing tests are solved", "url": "https://github.com/apache/iceberg/pull/1465#discussion_r490129106", "createdAt": "2020-09-17T10:11:05Z", "author": {"login": "pvary"}, "path": "core/src/test/java/org/apache/iceberg/hadoop/TestHadoopCatalog.java", "diffHunk": "@@ -494,23 +495,42 @@ public void testVersionHintFile() throws Exception {\n       stream.write(\"3\".getBytes(StandardCharsets.UTF_8));\n     }\n \n-    // Check the result of the readVersionHint(), and load the table and check the current snapshotId\n-    Assert.assertEquals(3, tableOperations.readVersionHint());\n+    // Check the result of the versionHint(), and load the table and check the current snapshotId\n+    Assert.assertEquals(3, tableOperations.versionHint());\n     Assert.assertEquals(secondSnapshotId, catalog.loadTable(tableId).currentSnapshot().snapshotId());\n \n     // Write an empty version hint file\n     io.deleteFile(versionHintLocation);\n     io.newOutputFile(versionHintLocation).create().close();\n \n-    // Check the result of the readVersionHint(), and load the table and check the current snapshotId\n-    Assert.assertEquals(1, tableOperations.readVersionHint());\n+    // Check the result of the versionHint(), and load the table and check the current snapshotId\n+    Assert.assertEquals(3, tableOperations.versionHint());\n     Assert.assertEquals(secondSnapshotId, catalog.loadTable(tableId).currentSnapshot().snapshotId());\n \n     // Just delete the file - double check that we have manipulated the correct file\n     io.deleteFile(versionHintLocation);\n \n-    // Check the result of the readVersionHint(), and load the table and check the current snapshotId\n-    Assert.assertEquals(1, tableOperations.readVersionHint());\n+    // Check the result of the versionHint(), and load the table and check the current snapshotId\n+    Assert.assertEquals(3, tableOperations.versionHint());\n     Assert.assertEquals(secondSnapshotId, catalog.loadTable(tableId).currentSnapshot().snapshotId());\n+\n+    // Remove the first version file, and see if we can recover\n+    io.deleteFile(tableOperations.getMetadataFile(1).toString());\n+\n+    // Check the result of the versionHint(), and load the table and check the current snapshotId\n+    Assert.assertEquals(3, tableOperations.versionHint());\n+    Assert.assertEquals(secondSnapshotId, catalog.loadTable(tableId).currentSnapshot().snapshotId());\n+\n+    // Remove all the version files, and see if we can recover. Hint... not :)\n+    io.deleteFile(tableOperations.getMetadataFile(2).toString());\n+    io.deleteFile(tableOperations.getMetadataFile(3).toString());\n+\n+    // Check that we got 0 versionHint, and a NoSuchTableException is thrown when trying to load the table\n+    Assert.assertEquals(0, tableOperations.versionHint());\n+    AssertHelpers.assertThrows(\n+        \"Should not be able to find the table\",\n+        NoSuchTableException.class,\n+        \"Table does not exist: tbl\",\n+        () -> catalog.loadTable(tableId));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTYwNTg2Ng=="}, "originalCommit": {"oid": "292af8eb888b7df3db4472c37c47a66417845b93"}, "originalPosition": 65}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDE2MjMwMQ==", "bodyText": "Done with the refactoring.\nFeel free to request changes in the new version if it could be further improved", "url": "https://github.com/apache/iceberg/pull/1465#discussion_r490162301", "createdAt": "2020-09-17T11:15:37Z", "author": {"login": "pvary"}, "path": "core/src/test/java/org/apache/iceberg/hadoop/TestHadoopCatalog.java", "diffHunk": "@@ -494,23 +495,42 @@ public void testVersionHintFile() throws Exception {\n       stream.write(\"3\".getBytes(StandardCharsets.UTF_8));\n     }\n \n-    // Check the result of the readVersionHint(), and load the table and check the current snapshotId\n-    Assert.assertEquals(3, tableOperations.readVersionHint());\n+    // Check the result of the versionHint(), and load the table and check the current snapshotId\n+    Assert.assertEquals(3, tableOperations.versionHint());\n     Assert.assertEquals(secondSnapshotId, catalog.loadTable(tableId).currentSnapshot().snapshotId());\n \n     // Write an empty version hint file\n     io.deleteFile(versionHintLocation);\n     io.newOutputFile(versionHintLocation).create().close();\n \n-    // Check the result of the readVersionHint(), and load the table and check the current snapshotId\n-    Assert.assertEquals(1, tableOperations.readVersionHint());\n+    // Check the result of the versionHint(), and load the table and check the current snapshotId\n+    Assert.assertEquals(3, tableOperations.versionHint());\n     Assert.assertEquals(secondSnapshotId, catalog.loadTable(tableId).currentSnapshot().snapshotId());\n \n     // Just delete the file - double check that we have manipulated the correct file\n     io.deleteFile(versionHintLocation);\n \n-    // Check the result of the readVersionHint(), and load the table and check the current snapshotId\n-    Assert.assertEquals(1, tableOperations.readVersionHint());\n+    // Check the result of the versionHint(), and load the table and check the current snapshotId\n+    Assert.assertEquals(3, tableOperations.versionHint());\n     Assert.assertEquals(secondSnapshotId, catalog.loadTable(tableId).currentSnapshot().snapshotId());\n+\n+    // Remove the first version file, and see if we can recover\n+    io.deleteFile(tableOperations.getMetadataFile(1).toString());\n+\n+    // Check the result of the versionHint(), and load the table and check the current snapshotId\n+    Assert.assertEquals(3, tableOperations.versionHint());\n+    Assert.assertEquals(secondSnapshotId, catalog.loadTable(tableId).currentSnapshot().snapshotId());\n+\n+    // Remove all the version files, and see if we can recover. Hint... not :)\n+    io.deleteFile(tableOperations.getMetadataFile(2).toString());\n+    io.deleteFile(tableOperations.getMetadataFile(3).toString());\n+\n+    // Check that we got 0 versionHint, and a NoSuchTableException is thrown when trying to load the table\n+    Assert.assertEquals(0, tableOperations.versionHint());\n+    AssertHelpers.assertThrows(\n+        \"Should not be able to find the table\",\n+        NoSuchTableException.class,\n+        \"Table does not exist: tbl\",\n+        () -> catalog.loadTable(tableId));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTYwNTg2Ng=="}, "originalCommit": {"oid": "292af8eb888b7df3db4472c37c47a66417845b93"}, "originalPosition": 65}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2NDA5MjU5OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopTableOperations.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQxOTo0Mjo1NVrOHTBpQw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QxMDoxMzo0MlrOHTbMTw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTcxMTkzOQ==", "bodyText": "This will list all the files in the metadata directory, right? It's just that we're filtering on the client for the files matching the version naming pattern.", "url": "https://github.com/apache/iceberg/pull/1465#discussion_r489711939", "createdAt": "2020-09-16T19:42:55Z", "author": {"login": "fbocse"}, "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopTableOperations.java", "diffHunk": "@@ -289,19 +311,24 @@ int readVersionHint() {\n       return Integer.parseInt(in.readLine().replace(\"\\n\", \"\"));\n \n     } catch (Exception e) {\n-      LOG.warn(\"Error reading version hint file {}\", versionHintFile, e);\n+      LOG.debug(\"Error reading version hint file {}\", versionHintFile, e);\n       try {\n-        if (getMetadataFile(1) != null) {\n-          // We just assume corrupted metadata and start to read from the first version file\n-          return 1;\n+        // List the metadata directory to find the version files, and try to recover the max available version\n+        FileStatus[] files = fs.listStatus(metadataRoot(), name -> VERSION_PATTERN.matcher(name.getName()).matches());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "292af8eb888b7df3db4472c37c47a66417845b93"}, "originalPosition": 85}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDEzMDUxMQ==", "bodyText": "Sadly, yes. I did not find a better solution where the filter is pushed to server side.\nAny ideas how to do it more efficiently?", "url": "https://github.com/apache/iceberg/pull/1465#discussion_r490130511", "createdAt": "2020-09-17T10:13:42Z", "author": {"login": "pvary"}, "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopTableOperations.java", "diffHunk": "@@ -289,19 +311,24 @@ int readVersionHint() {\n       return Integer.parseInt(in.readLine().replace(\"\\n\", \"\"));\n \n     } catch (Exception e) {\n-      LOG.warn(\"Error reading version hint file {}\", versionHintFile, e);\n+      LOG.debug(\"Error reading version hint file {}\", versionHintFile, e);\n       try {\n-        if (getMetadataFile(1) != null) {\n-          // We just assume corrupted metadata and start to read from the first version file\n-          return 1;\n+        // List the metadata directory to find the version files, and try to recover the max available version\n+        FileStatus[] files = fs.listStatus(metadataRoot(), name -> VERSION_PATTERN.matcher(name.getName()).matches());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTcxMTkzOQ=="}, "originalCommit": {"oid": "292af8eb888b7df3db4472c37c47a66417845b93"}, "originalPosition": 85}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2NDU4NDUzOnYy", "diffSide": "RIGHT", "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopTableOperations.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xNlQyMjoyNzoxNVrOHTGUKw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QxMToxNjoxMFrOHTdJZA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTc4ODQ1OQ==", "bodyText": "I didn't catch this at first, but this method should not have a side effect of setting version. It should return version and something else should set it.\nAlso, when we set instance fields, we use the prefix this. so that it is clear that an instance field and not a local variable is set. That's why I missed this in my first round of review.", "url": "https://github.com/apache/iceberg/pull/1465#discussion_r489788459", "createdAt": "2020-09-16T22:27:15Z", "author": {"login": "rdblue"}, "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopTableOperations.java", "diffHunk": "@@ -289,19 +311,24 @@ int readVersionHint() {\n       return Integer.parseInt(in.readLine().replace(\"\\n\", \"\"));\n \n     } catch (Exception e) {\n-      LOG.warn(\"Error reading version hint file {}\", versionHintFile, e);\n+      LOG.debug(\"Error reading version hint file {}\", versionHintFile, e);\n       try {\n-        if (getMetadataFile(1) != null) {\n-          // We just assume corrupted metadata and start to read from the first version file\n-          return 1;\n+        // List the metadata directory to find the version files, and try to recover the max available version\n+        FileStatus[] files = fs.listStatus(metadataRoot(), name -> VERSION_PATTERN.matcher(name.getName()).matches());\n+        int maxVersion = 0;\n+\n+        for (FileStatus file : files) {\n+          version = version(file.getPath().getName());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "292af8eb888b7df3db4472c37c47a66417845b93"}, "originalPosition": 89}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDEzMTU2Mg==", "bodyText": "I was so focused on not finding a way to replicate the failures on my side, that I missed this.\nBig KUDOS for catching this! :)\nI hope fixing this will fix the tests as well (Still not sure why they were passing on my side \ud83d\ude22)", "url": "https://github.com/apache/iceberg/pull/1465#discussion_r490131562", "createdAt": "2020-09-17T10:15:33Z", "author": {"login": "pvary"}, "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopTableOperations.java", "diffHunk": "@@ -289,19 +311,24 @@ int readVersionHint() {\n       return Integer.parseInt(in.readLine().replace(\"\\n\", \"\"));\n \n     } catch (Exception e) {\n-      LOG.warn(\"Error reading version hint file {}\", versionHintFile, e);\n+      LOG.debug(\"Error reading version hint file {}\", versionHintFile, e);\n       try {\n-        if (getMetadataFile(1) != null) {\n-          // We just assume corrupted metadata and start to read from the first version file\n-          return 1;\n+        // List the metadata directory to find the version files, and try to recover the max available version\n+        FileStatus[] files = fs.listStatus(metadataRoot(), name -> VERSION_PATTERN.matcher(name.getName()).matches());\n+        int maxVersion = 0;\n+\n+        for (FileStatus file : files) {\n+          version = version(file.getPath().getName());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTc4ODQ1OQ=="}, "originalCommit": {"oid": "292af8eb888b7df3db4472c37c47a66417845b93"}, "originalPosition": 89}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDE2MjUzMg==", "bodyText": "This fixed the tests. Still not sure why my tests did not repro the case \ud83d\ude22", "url": "https://github.com/apache/iceberg/pull/1465#discussion_r490162532", "createdAt": "2020-09-17T11:16:10Z", "author": {"login": "pvary"}, "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopTableOperations.java", "diffHunk": "@@ -289,19 +311,24 @@ int readVersionHint() {\n       return Integer.parseInt(in.readLine().replace(\"\\n\", \"\"));\n \n     } catch (Exception e) {\n-      LOG.warn(\"Error reading version hint file {}\", versionHintFile, e);\n+      LOG.debug(\"Error reading version hint file {}\", versionHintFile, e);\n       try {\n-        if (getMetadataFile(1) != null) {\n-          // We just assume corrupted metadata and start to read from the first version file\n-          return 1;\n+        // List the metadata directory to find the version files, and try to recover the max available version\n+        FileStatus[] files = fs.listStatus(metadataRoot(), name -> VERSION_PATTERN.matcher(name.getName()).matches());\n+        int maxVersion = 0;\n+\n+        for (FileStatus file : files) {\n+          version = version(file.getPath().getName());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4OTc4ODQ1OQ=="}, "originalCommit": {"oid": "292af8eb888b7df3db4472c37c47a66417845b93"}, "originalPosition": 89}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2ODYyNzQ0OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopTableOperations.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QxNzoyMDowNlrOHTtczg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QxNzozMzoxOFrOHTt9qA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDQyOTY0Ng==", "bodyText": "Nit: This change isn't necessary?", "url": "https://github.com/apache/iceberg/pull/1465#discussion_r490429646", "createdAt": "2020-09-17T17:20:06Z", "author": {"login": "rdblue"}, "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopTableOperations.java", "diffHunk": "@@ -289,19 +311,28 @@ int readVersionHint() {\n       return Integer.parseInt(in.readLine().replace(\"\\n\", \"\"));\n \n     } catch (Exception e) {\n-      LOG.warn(\"Error reading version hint file {}\", versionHintFile, e);\n       try {\n-        if (getMetadataFile(1) != null) {\n-          // We just assume corrupted metadata and start to read from the first version file\n-          return 1;\n+        if (fs.exists(metadataRoot())) {\n+          LOG.warn(\"Error reading version hint file {}\", versionHintFile, e);\n+        }\n+\n+        // List the metadata directory to find the version files, and try to recover the max available version\n+        FileStatus[] files = fs.listStatus(metadataRoot(), name -> VERSION_PATTERN.matcher(name.getName()).matches());\n+        int maxVersion = 0;\n+\n+        for (FileStatus file : files) {\n+          int currentVersion = version(file.getPath().getName());\n+          if (currentVersion > maxVersion && getMetadataFile(currentVersion) != null) {\n+            maxVersion = currentVersion;\n+          }\n         }\n+\n+        return maxVersion;\n       } catch (IOException io) {\n         // We log this error only on debug level since this is just a problem in recovery path\n         LOG.debug(\"Error trying to recover version-hint.txt data for {}\", versionHintFile, e);\n+        return 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "97a84340684e89bbe0b89928583ac616010f2fcd"}, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDQzODA1Ng==", "bodyText": "I think it is more clear that the return value is only used when there is an exception in the recovery path.", "url": "https://github.com/apache/iceberg/pull/1465#discussion_r490438056", "createdAt": "2020-09-17T17:33:18Z", "author": {"login": "pvary"}, "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopTableOperations.java", "diffHunk": "@@ -289,19 +311,28 @@ int readVersionHint() {\n       return Integer.parseInt(in.readLine().replace(\"\\n\", \"\"));\n \n     } catch (Exception e) {\n-      LOG.warn(\"Error reading version hint file {}\", versionHintFile, e);\n       try {\n-        if (getMetadataFile(1) != null) {\n-          // We just assume corrupted metadata and start to read from the first version file\n-          return 1;\n+        if (fs.exists(metadataRoot())) {\n+          LOG.warn(\"Error reading version hint file {}\", versionHintFile, e);\n+        }\n+\n+        // List the metadata directory to find the version files, and try to recover the max available version\n+        FileStatus[] files = fs.listStatus(metadataRoot(), name -> VERSION_PATTERN.matcher(name.getName()).matches());\n+        int maxVersion = 0;\n+\n+        for (FileStatus file : files) {\n+          int currentVersion = version(file.getPath().getName());\n+          if (currentVersion > maxVersion && getMetadataFile(currentVersion) != null) {\n+            maxVersion = currentVersion;\n+          }\n         }\n+\n+        return maxVersion;\n       } catch (IOException io) {\n         // We log this error only on debug level since this is just a problem in recovery path\n         LOG.debug(\"Error trying to recover version-hint.txt data for {}\", versionHintFile, e);\n+        return 0;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDQyOTY0Ng=="}, "originalCommit": {"oid": "97a84340684e89bbe0b89928583ac616010f2fcd"}, "originalPosition": 102}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2ODY3ODU1OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopTableOperations.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QxNzozMjo1NlrOHTt86Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQxMDowMjo1NFrOHUGiHg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDQzNzg2NQ==", "bodyText": "I think a better name for this is findVersion because it will do listing now. It isn't really a hint because it handles the case where the hint is missing.", "url": "https://github.com/apache/iceberg/pull/1465#discussion_r490437865", "createdAt": "2020-09-17T17:32:56Z", "author": {"login": "rdblue"}, "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopTableOperations.java", "diffHunk": "@@ -280,7 +302,7 @@ private void writeVersionHint(int versionToWrite) {\n   }\n \n   @VisibleForTesting\n-  int readVersionHint() {\n+  int versionHint() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "97a84340684e89bbe0b89928583ac616010f2fcd"}, "originalPosition": 70}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDg0MDYwNg==", "bodyText": "Done", "url": "https://github.com/apache/iceberg/pull/1465#discussion_r490840606", "createdAt": "2020-09-18T10:02:54Z", "author": {"login": "pvary"}, "path": "core/src/main/java/org/apache/iceberg/hadoop/HadoopTableOperations.java", "diffHunk": "@@ -280,7 +302,7 @@ private void writeVersionHint(int versionToWrite) {\n   }\n \n   @VisibleForTesting\n-  int readVersionHint() {\n+  int versionHint() {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDQzNzg2NQ=="}, "originalCommit": {"oid": "97a84340684e89bbe0b89928583ac616010f2fcd"}, "originalPosition": 70}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3739, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}