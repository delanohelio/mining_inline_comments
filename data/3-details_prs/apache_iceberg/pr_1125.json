{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDM2NDEyMTk0", "number": 1125, "title": "Implement the parquet value reader & writer for apache flink", "bodyText": "", "createdAt": "2020-06-18T11:33:57Z", "url": "https://github.com/apache/iceberg/pull/1125", "merged": true, "mergeCommit": {"oid": "edb8d7759d74418daa677a8c39420f29e28edb66"}, "closed": true, "closedAt": "2020-06-29T17:56:47Z", "author": {"login": "openinx"}, "timelineItems": {"totalCount": 17, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcscxBNAH2gAyNDM2NDEyMTk0OmFiMGM3ZTRjYTY5MDZjNWMxODc3MDdlYTUwY2Q0MWQ5YzA0NzgyODE=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcvjRUZgFqTQzODczODM5Mw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "ab0c7e4ca6906c5c187707ea50cd41d9c0478281", "author": {"user": {"login": "openinx", "name": "openinx"}}, "url": "https://github.com/apache/iceberg/commit/ab0c7e4ca6906c5c187707ea50cd41d9c0478281", "committedDate": "2020-06-18T11:29:38Z", "message": "Implement the parquet value reader & writer for apache flink"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e33d2cdeb44b4be7e5c8a7c4a6110e32672c938a", "author": {"user": {"login": "openinx", "name": "openinx"}}, "url": "https://github.com/apache/iceberg/commit/e33d2cdeb44b4be7e5c8a7c4a6110e32672c938a", "committedDate": "2020-06-18T11:53:56Z", "message": "Fix the failure unit tests."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM2MjQyMjc3", "url": "https://github.com/apache/iceberg/pull/1125#pullrequestreview-436242277", "createdAt": "2020-06-24T00:14:33Z", "commit": {"oid": "e33d2cdeb44b4be7e5c8a7c4a6110e32672c938a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQwMDoxNDozM1rOGn-vIw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQwMDoxNDozM1rOGn-vIw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU3NTUyMw==", "bodyText": "How high have you tested? I usually test locally with ~1m rows.\nCould you also add tests with the new generation methods that @samarthjain added for Parquet vectorization? Those allow you to generate data that will be dictionary encoded and that will fall back to non-dictionary after a few dictionary pages. \n  \n    \n      iceberg/spark/src/test/java/org/apache/iceberg/spark/data/RandomData.java\n    \n    \n        Lines 99 to 106\n      in\n      705da1b\n    \n    \n    \n    \n\n        \n          \n           public static Iterable<Record> generateFallbackData(Schema schema, int numRecords, long seed, long numDictRecords) { \n        \n\n        \n          \n             return newIterable(() -> new FallbackDataGenerator(schema, seed, numDictRecords), schema, numRecords); \n        \n\n        \n          \n           } \n        \n\n        \n          \n            \n        \n\n        \n          \n           public static Iterable<GenericData.Record> generateDictionaryEncodableData( \n        \n\n        \n          \n               Schema schema, int numRecords, long seed, float nullPercentage) { \n        \n\n        \n          \n             return newIterable(() -> new DictionaryEncodedDataGenerator(schema, seed, nullPercentage), schema, numRecords); \n        \n\n        \n          \n           }", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r444575523", "createdAt": "2020-06-24T00:14:33Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/data/TestFlinkParquetReaderWriter.java", "diffHunk": "@@ -0,0 +1,100 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink.data;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.Iterator;\n+import org.apache.flink.types.Row;\n+import org.apache.iceberg.Files;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.io.CloseableIterable;\n+import org.apache.iceberg.io.FileAppender;\n+import org.apache.iceberg.parquet.Parquet;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+public class TestFlinkParquetReaderWriter {\n+\n+  @Rule\n+  public TemporaryFolder temp = new TemporaryFolder();\n+\n+  private static final Schema COMPLEX_SCHEMA = new Schema(\n+      required(1, \"roots\", Types.LongType.get()),\n+      optional(3, \"lime\", Types.ListType.ofRequired(4, Types.DoubleType.get())),\n+      required(5, \"strict\", Types.StructType.of(\n+          required(9, \"tangerine\", Types.StringType.get()),\n+          optional(6, \"hopeful\", Types.StructType.of(\n+              required(7, \"steel\", Types.FloatType.get()),\n+              required(8, \"lantern\", Types.DateType.get())\n+          )),\n+          optional(10, \"vehement\", Types.LongType.get())\n+      )),\n+      optional(11, \"metamorphosis\", Types.MapType.ofRequired(12, 13,\n+          Types.StringType.get(), Types.TimestampType.withZone())),\n+      required(14, \"winter\", Types.ListType.ofOptional(15, Types.StructType.of(\n+          optional(16, \"beet\", Types.DoubleType.get()),\n+          required(17, \"stamp\", Types.FloatType.get()),\n+          optional(18, \"wheeze\", Types.StringType.get())\n+      ))),\n+      optional(19, \"renovate\", Types.MapType.ofRequired(20, 21,\n+          Types.StringType.get(), Types.StructType.of(\n+              optional(22, \"jumpy\", Types.DoubleType.get()),\n+              required(23, \"koala\", Types.IntegerType.get()),\n+              required(24, \"couch rope\", Types.IntegerType.get())\n+          ))),\n+      optional(2, \"slide\", Types.StringType.get())\n+  );\n+\n+  @Test\n+  public void testCorrectness() throws IOException {\n+    int numRows = 2500;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e33d2cdeb44b4be7e5c8a7c4a6110e32672c938a"}, "originalPosition": 74}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM2MjQyOTU1", "url": "https://github.com/apache/iceberg/pull/1125#pullrequestreview-436242955", "createdAt": "2020-06-24T00:16:51Z", "commit": {"oid": "e33d2cdeb44b4be7e5c8a7c4a6110e32672c938a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQwMDoxNjo1MVrOGn-xZw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQwMDoxNjo1MVrOGn-xZw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU3NjEwMw==", "bodyText": "Should this inherit from the one for Iceberg generics to avoid duplicating the list and map methods? Primitive and struct will need to be implemented, but this could reuse a lot there as well.", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r444576103", "createdAt": "2020-06-24T00:16:51Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/data/RandomData.java", "diffHunk": "@@ -0,0 +1,170 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink.data;\n+\n+import java.nio.ByteBuffer;\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalTime;\n+import java.time.OffsetDateTime;\n+import java.time.ZoneOffset;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Random;\n+import java.util.Set;\n+import java.util.UUID;\n+import java.util.function.Supplier;\n+import org.apache.flink.types.Row;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.apache.iceberg.relocated.com.google.common.collect.Sets;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.TypeUtil;\n+import org.apache.iceberg.types.Types;\n+import org.apache.iceberg.util.RandomUtil;\n+\n+import static java.time.temporal.ChronoUnit.MICROS;\n+\n+public class RandomData {\n+  private RandomData() {\n+  }\n+\n+  public static List<Row> generate(Schema schema, int numRecords, long seed) {\n+    RandomDataGenerator generator = new RandomDataGenerator(seed);\n+    List<Row> rows = Lists.newArrayListWithExpectedSize(numRecords);\n+    for (int i = 0; i < numRecords; i += 1) {\n+      rows.add((Row) TypeUtil.visit(schema, generator));\n+    }\n+\n+    return rows;\n+  }\n+\n+  private static class RandomDataGenerator extends TypeUtil.CustomOrderSchemaVisitor<Object> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e33d2cdeb44b4be7e5c8a7c4a6110e32672c938a"}, "originalPosition": 60}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM2MjQ1MzA4", "url": "https://github.com/apache/iceberg/pull/1125#pullrequestreview-436245308", "createdAt": "2020-06-24T00:24:35Z", "commit": {"oid": "e33d2cdeb44b4be7e5c8a7c4a6110e32672c938a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQwMDoyNDozNVrOGn-5Ig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQwMDoyNDozNVrOGn-5Ig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU3ODA4Mg==", "bodyText": "Instead of adding this interface, what about adding WriteBuilder.createStructWriter to do this? That way, the Flink builder could just inherit from the generic builder and override that one method.\nI think that would be cleaner because adding this interface requires also adding public methods to pass the factory. I'd rather not add those public methods if we can avoid it by adding a protected method and change the builder to a protected class.", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r444578082", "createdAt": "2020-06-24T00:24:35Z", "author": {"login": "rdblue"}, "path": "data/src/main/java/org/apache/iceberg/data/parquet/GenericParquetWriter.java", "diffHunk": "@@ -284,6 +291,11 @@ public void write(int repetitionLevel, byte[] value) {\n     }\n   }\n \n+  public interface StructWriterFactory {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e33d2cdeb44b4be7e5c8a7c4a6110e32672c938a"}, "originalPosition": 37}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM2MjQ2MTUw", "url": "https://github.com/apache/iceberg/pull/1125#pullrequestreview-436246150", "createdAt": "2020-06-24T00:27:22Z", "commit": {"oid": "e33d2cdeb44b4be7e5c8a7c4a6110e32672c938a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQwMDoyNzoyMlrOGn-72A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQwMDoyNzoyMlrOGn-72A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU3ODc3Ng==", "bodyText": "Why change this to use the GenericRecord instance rather than the Record interface?\nI don't see much value in this change. We will just need to change it back if we want to add implementations of Record that are not generic, like we do with our internal classes that extend Avro's IndexedRecord. Ideally, I'd like to change those over to use our generics readers eventually.", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r444578776", "createdAt": "2020-06-24T00:27:22Z", "author": {"login": "rdblue"}, "path": "data/src/main/java/org/apache/iceberg/data/parquet/GenericParquetReaders.java", "diffHunk": "@@ -396,7 +409,12 @@ private FixedReader(ColumnDescriptor desc) {\n     }\n   }\n \n-  static class RecordReader extends StructReader<Record, Record> {\n+  public interface StructReaderFactory<T> {\n+\n+    StructReader<T, T> create(List<Type> types, List<ParquetValueReader<?>> readers, StructType struct);\n+  }\n+\n+  static class RecordReader extends StructReader<GenericRecord, GenericRecord> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e33d2cdeb44b4be7e5c8a7c4a6110e32672c938a"}, "originalPosition": 103}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM2MjQ2OTAy", "url": "https://github.com/apache/iceberg/pull/1125#pullrequestreview-436246902", "createdAt": "2020-06-24T00:29:46Z", "commit": {"oid": "e33d2cdeb44b4be7e5c8a7c4a6110e32672c938a"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQwMDoyOTo0NlrOGn--PQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNFQwMDoyOTo0NlrOGn--PQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NDU3OTM4OQ==", "bodyText": "Similar to the write path, I think it would be nice to refactor this to avoid exposing new public methods and interfaces.", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r444579389", "createdAt": "2020-06-24T00:29:46Z", "author": {"login": "rdblue"}, "path": "data/src/main/java/org/apache/iceberg/data/parquet/GenericParquetReaders.java", "diffHunk": "@@ -396,7 +409,12 @@ private FixedReader(ColumnDescriptor desc) {\n     }\n   }\n \n-  static class RecordReader extends StructReader<Record, Record> {\n+  public interface StructReaderFactory<T> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e33d2cdeb44b4be7e5c8a7c4a6110e32672c938a"}, "originalPosition": 98}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1c37f6def03ed67d4b717f5347909ca4b8763897", "author": {"user": {"login": "openinx", "name": "openinx"}}, "url": "https://github.com/apache/iceberg/commit/1c37f6def03ed67d4b717f5347909ca4b8763897", "committedDate": "2020-06-24T03:46:07Z", "message": "Remove the StructWriterFactory & StructReaderFactory."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f4799a0000639f662c3df823240c2e27d0734b10", "author": {"user": {"login": "openinx", "name": "openinx"}}, "url": "https://github.com/apache/iceberg/commit/f4799a0000639f662c3df823240c2e27d0734b10", "committedDate": "2020-06-24T03:56:44Z", "message": "Revert the generic type in GenericParquetReaders#buildReader"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0350b9b9ce9c717bccbae03256b0ab792bbb710e", "author": {"user": {"login": "openinx", "name": "openinx"}}, "url": "https://github.com/apache/iceberg/commit/0350b9b9ce9c717bccbae03256b0ab792bbb710e", "committedDate": "2020-06-24T09:40:50Z", "message": "Add test suits for DictionaryEncodedData and FallbackData"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "17845b17870ae19d260ba93410206748fc8c6eb7", "author": {"user": {"login": "openinx", "name": "openinx"}}, "url": "https://github.com/apache/iceberg/commit/17845b17870ae19d260ba93410206748fc8c6eb7", "committedDate": "2020-06-25T14:46:37Z", "message": "Revert to user the StructWriterFactory & StructReaderFactory"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "95e197a8544dd32597da0f4bd0b84fa41f6664c6", "author": {"user": {"login": "openinx", "name": "openinx"}}, "url": "https://github.com/apache/iceberg/commit/95e197a8544dd32597da0f4bd0b84fa41f6664c6", "committedDate": "2020-06-25T14:56:40Z", "message": "Use the Record instead of GenericRecord"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM3NTk0NDcz", "url": "https://github.com/apache/iceberg/pull/1125#pullrequestreview-437594473", "createdAt": "2020-06-25T15:12:07Z", "commit": {"oid": "95e197a8544dd32597da0f4bd0b84fa41f6664c6"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNVQxNToxMjowN1rOGo_VKg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNVQxNToxMjowN1rOGo_VKg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NTYzMzgzNA==", "bodyText": "I tried to mark this method to be protected but seems java8 don't allow to do that....", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r445633834", "createdAt": "2020-06-25T15:12:07Z", "author": {"login": "openinx"}, "path": "data/src/main/java/org/apache/iceberg/data/parquet/GenericParquetWriter.java", "diffHunk": "@@ -284,6 +290,11 @@ public void write(int repetitionLevel, byte[] value) {\n     }\n   }\n \n+  public interface StructWriterFactory {\n+\n+    StructWriter<?> create(List<ParquetValueWriter<?>> writers);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "95e197a8544dd32597da0f4bd0b84fa41f6664c6"}, "originalPosition": 41}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM4NDU3Nzk1", "url": "https://github.com/apache/iceberg/pull/1125#pullrequestreview-438457795", "createdAt": "2020-06-26T17:05:07Z", "commit": {"oid": "95e197a8544dd32597da0f4bd0b84fa41f6664c6"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxNzowNTowN1rOGpoTrg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxNzowNTowN1rOGpoTrg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjMwNTE5OA==", "bodyText": "How about RandomRecordGenerator instead of RandomRecordDataGenerator? I think that's more descriptive since it returns random records.", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r446305198", "createdAt": "2020-06-26T17:05:07Z", "author": {"login": "rdblue"}, "path": "data/src/test/java/org/apache/iceberg/data/RandomGenericData.java", "diffHunk": "@@ -55,11 +55,9 @@ private RandomGenericData() {}\n     return records;\n   }\n \n-  private static class RandomDataGenerator extends TypeUtil.CustomOrderSchemaVisitor<Object> {\n-    private final Random random;\n-\n-    private RandomDataGenerator(long seed) {\n-      this.random = new Random(seed);\n+  private static class RandomRecordDataGenerator extends RandomDataGenerator<Record> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "95e197a8544dd32597da0f4bd0b84fa41f6664c6"}, "originalPosition": 18}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM4NDYwMDcy", "url": "https://github.com/apache/iceberg/pull/1125#pullrequestreview-438460072", "createdAt": "2020-06-26T17:08:49Z", "commit": {"oid": "95e197a8544dd32597da0f4bd0b84fa41f6664c6"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxNzowODo1MFrOGpoaZA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yNlQxNzowODo1MFrOGpoaZA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjMwNjkxNg==", "bodyText": "Good to know that this passes, but I don't think we need to run with this high of a record count every time in CI. Could you reduce this to 20_000?", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r446306916", "createdAt": "2020-06-26T17:08:50Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/data/TestFlinkParquetReaderWriter.java", "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink.data;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.Iterator;\n+import org.apache.flink.types.Row;\n+import org.apache.iceberg.Files;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.io.CloseableIterable;\n+import org.apache.iceberg.io.FileAppender;\n+import org.apache.iceberg.parquet.Parquet;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+public class TestFlinkParquetReaderWriter {\n+  private static final int NUM_RECORDS = 1_000_000;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "95e197a8544dd32597da0f4bd0b84fa41f6664c6"}, "originalPosition": 41}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5bffceda9758076f67236011d4ba4e560b92590c", "author": {"user": {"login": "openinx", "name": "openinx"}}, "url": "https://github.com/apache/iceberg/commit/5bffceda9758076f67236011d4ba4e560b92590c", "committedDate": "2020-06-27T02:45:05Z", "message": "Make the flink parquet reader/write inherit the generic parquet reader writer."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDM4NzM4Mzkz", "url": "https://github.com/apache/iceberg/pull/1125#pullrequestreview-438738393", "createdAt": "2020-06-28T02:46:06Z", "commit": {"oid": "5bffceda9758076f67236011d4ba4e560b92590c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yOFQwMjo0NjowNlrOGp50Cg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0yOFQwMjo0NjowNlrOGp50Cg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0NjU5MjAxMA==", "bodyText": "I changed the buildReader to buildRowReader  because the parent buildReader will return with a ParquetValueReader <Record> data type, which clashes with this FlinkParquetReaders 's buildReader returned ParquetValueReader <Row>.", "url": "https://github.com/apache/iceberg/pull/1125#discussion_r446592010", "createdAt": "2020-06-28T02:46:06Z", "author": {"login": "openinx"}, "path": "flink/src/main/java/org/apache/iceberg/flink/data/FlinkParquetReaders.java", "diffHunk": "@@ -0,0 +1,114 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink.data;\n+\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.flink.types.Row;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.data.parquet.GenericParquetReaders;\n+import org.apache.iceberg.parquet.ParquetSchemaUtil;\n+import org.apache.iceberg.parquet.ParquetValueReader;\n+import org.apache.iceberg.parquet.ParquetValueReaders;\n+import org.apache.iceberg.parquet.TypeWithSchemaVisitor;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.types.Types;\n+import org.apache.parquet.schema.MessageType;\n+import org.apache.parquet.schema.Type;\n+\n+public class FlinkParquetReaders extends GenericParquetReaders {\n+  private FlinkParquetReaders() {\n+  }\n+\n+  @SuppressWarnings(\"unchecked\")\n+  public static ParquetValueReader<Row> buildRowReader(Schema expectedSchema,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5bffceda9758076f67236011d4ba4e560b92590c"}, "originalPosition": 41}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4537, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}