{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDExMTk3MTAw", "number": 989, "reviewThreads": {"totalCount": 23, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwNzowMzo0NlrOD36r6w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQwNDowMjoyMVrOD-d2jw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5OTU5Nzg3OnYy", "diffSide": "RIGHT", "path": "orc/src/main/java/org/apache/iceberg/orc/OrcValReader.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwNzowMzo0NlrOGOcUpg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QxNjo1Nzo0MFrOGSHszw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzc5NzI4Ng==", "bodyText": "I want to rename this to OrcValueReader, but an interface with that name already exists. I can rename the other interface OrcRowReader instead. If folks are OK doing this as part of this RB, let me know.", "url": "https://github.com/apache/iceberg/pull/989#discussion_r417797286", "createdAt": "2020-04-30T07:03:46Z", "author": {"login": "rdsr"}, "path": "orc/src/main/java/org/apache/iceberg/orc/OrcValReader.java", "diffHunk": "@@ -0,0 +1,36 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.orc;\n+\n+import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n+\n+\n+public interface OrcValReader<T> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e415147e495c6230dcf7f478cc543652db777852"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY1MzcxMQ==", "bodyText": "That works for me.", "url": "https://github.com/apache/iceberg/pull/989#discussion_r421653711", "createdAt": "2020-05-07T16:57:40Z", "author": {"login": "rdblue"}, "path": "orc/src/main/java/org/apache/iceberg/orc/OrcValReader.java", "diffHunk": "@@ -0,0 +1,36 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.orc;\n+\n+import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n+\n+\n+public interface OrcValReader<T> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzc5NzI4Ng=="}, "originalCommit": {"oid": "e415147e495c6230dcf7f478cc543652db777852"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5OTU5OTExOnYy", "diffSide": "RIGHT", "path": "orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwNzowNDoxNVrOGOcVhQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwNzowNDoxNVrOGOcVhQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzc5NzUwOQ==", "bodyText": "GenericOrcReader can share a lot of the code here.", "url": "https://github.com/apache/iceberg/pull/989#discussion_r417797509", "createdAt": "2020-04-30T07:04:15Z", "author": {"login": "rdsr"}, "path": "orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.orc;\n+\n+import com.google.common.collect.Lists;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.types.Types;\n+import org.apache.orc.storage.ql.exec.vector.BytesColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.DoubleColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.LongColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.StructColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.VectorizedRowBatch;\n+\n+\n+public class OrcValueReaders {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e415147e495c6230dcf7f478cc543652db777852"}, "originalPosition": 35}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU5OTYwMzU3OnYy", "diffSide": "RIGHT", "path": "spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcValueReaders.java", "isResolved": true, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQwNzowNTo0NVrOGOcYMQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMFQyMDo0OTowMlrOGYdR2g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzc5ODE5Mw==", "bodyText": "My guess would be this is what is tanking the perf. Spark[Avro|Parquet]Reader seem to reuse this object. Doing the same for ORC results in test failures", "url": "https://github.com/apache/iceberg/pull/989#discussion_r417798193", "createdAt": "2020-04-30T07:05:45Z", "author": {"login": "rdsr"}, "path": "spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcValueReaders.java", "diffHunk": "@@ -0,0 +1,206 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.data;\n+\n+import com.google.common.collect.Lists;\n+import java.math.BigDecimal;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.orc.OrcValReader;\n+import org.apache.iceberg.orc.OrcValueReaders;\n+import org.apache.iceberg.types.Types;\n+import org.apache.orc.storage.ql.exec.vector.BytesColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.DecimalColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ListColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.MapColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.TimestampColumnVector;\n+import org.apache.orc.storage.serde2.io.HiveDecimalWritable;\n+import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.catalyst.expressions.GenericInternalRow;\n+import org.apache.spark.sql.catalyst.util.ArrayBasedMapData;\n+import org.apache.spark.sql.catalyst.util.ArrayData;\n+import org.apache.spark.sql.catalyst.util.GenericArrayData;\n+import org.apache.spark.sql.catalyst.util.MapData;\n+import org.apache.spark.sql.types.Decimal;\n+import org.apache.spark.unsafe.types.UTF8String;\n+\n+\n+class SparkOrcValueReaders {\n+  private SparkOrcValueReaders() {\n+  }\n+\n+  static OrcValReader<UTF8String> strings() {\n+    return StringReader.INSTANCE;\n+  }\n+\n+  static OrcValReader<?> timestampTzs() {\n+    return TimestampTzReader.INSTANCE;\n+  }\n+\n+  static OrcValReader<?> struct(\n+      List<OrcValReader<?>> readers, Types.StructType struct, Map<Integer, ?> idToConstant) {\n+    return new StructReader(readers, struct, idToConstant);\n+  }\n+\n+  static OrcValReader<?> array(OrcValReader<?> elementReader) {\n+    return new ArrayReader(elementReader);\n+  }\n+\n+  static OrcValReader<?> map(OrcValReader<?> keyReader, OrcValReader<?> valueReader) {\n+    return new MapReader(keyReader, valueReader);\n+  }\n+\n+  private static class ArrayReader implements OrcValReader<ArrayData> {\n+    private final OrcValReader<?> elementReader;\n+    private final List<Object> reusedList = Lists.newArrayList();\n+\n+    private ArrayReader(OrcValReader<?> elementReader) {\n+      this.elementReader = elementReader;\n+    }\n+\n+    @Override\n+    public ArrayData nonNullRead(ColumnVector vector, int row) {\n+      reusedList.clear();\n+      ListColumnVector listVector = (ListColumnVector) vector;\n+      int offset = (int) listVector.offsets[row];\n+      int length = (int) listVector.lengths[row];\n+      for (int c = 0; c < length; ++c) {\n+        reusedList.add(elementReader.read(listVector.child, offset + c));\n+      }\n+      return new GenericArrayData(reusedList.toArray());\n+    }\n+  }\n+\n+  private static class MapReader implements OrcValReader<MapData> {\n+    private final OrcValReader<?> keyReader;\n+    private final OrcValReader<?> valueReader;\n+\n+    private final List<Object> reusedKeyList = Lists.newArrayList();\n+    private final List<Object> reusedValueList = Lists.newArrayList();\n+\n+    private MapReader(OrcValReader<?> keyReader, OrcValReader<?> valueReader) {\n+      this.keyReader = keyReader;\n+      this.valueReader = valueReader;\n+    }\n+\n+    @Override\n+    public MapData nonNullRead(ColumnVector vector, int row) {\n+      reusedKeyList.clear();\n+      reusedValueList.clear();\n+      MapColumnVector mapVector = (MapColumnVector) vector;\n+      int offset = (int) mapVector.offsets[row];\n+      long length = mapVector.lengths[row];\n+      for (int c = 0; c < length; c++) {\n+        reusedKeyList.add(keyReader.read(mapVector.keys, offset + c));\n+        reusedValueList.add(valueReader.read(mapVector.values, offset + c));\n+      }\n+\n+      return new ArrayBasedMapData(\n+          new GenericArrayData(reusedKeyList.toArray()),\n+          new GenericArrayData(reusedValueList.toArray()));\n+    }\n+  }\n+\n+  static class StructReader extends OrcValueReaders.StructReader<InternalRow> {\n+    private final int numFields;\n+    private final InternalRow internalRow;\n+\n+    protected StructReader(List<OrcValReader<?>> readers, Types.StructType struct, Map<Integer, ?> idToConstant) {\n+      super(readers, struct, idToConstant);\n+      this.numFields = readers.size();\n+      internalRow = createOrReuse();\n+    }\n+\n+    @Override\n+    protected InternalRow createOrReuse() {\n+      return new GenericInternalRow(numFields);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e415147e495c6230dcf7f478cc543652db777852"}, "originalPosition": 134}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODU3ODI5MQ==", "bodyText": "I reran the ORC jmh tests and do see any difference.", "url": "https://github.com/apache/iceberg/pull/989#discussion_r418578291", "createdAt": "2020-05-01T14:57:09Z", "author": {"login": "rdsr"}, "path": "spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcValueReaders.java", "diffHunk": "@@ -0,0 +1,206 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.data;\n+\n+import com.google.common.collect.Lists;\n+import java.math.BigDecimal;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.orc.OrcValReader;\n+import org.apache.iceberg.orc.OrcValueReaders;\n+import org.apache.iceberg.types.Types;\n+import org.apache.orc.storage.ql.exec.vector.BytesColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.DecimalColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ListColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.MapColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.TimestampColumnVector;\n+import org.apache.orc.storage.serde2.io.HiveDecimalWritable;\n+import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.catalyst.expressions.GenericInternalRow;\n+import org.apache.spark.sql.catalyst.util.ArrayBasedMapData;\n+import org.apache.spark.sql.catalyst.util.ArrayData;\n+import org.apache.spark.sql.catalyst.util.GenericArrayData;\n+import org.apache.spark.sql.catalyst.util.MapData;\n+import org.apache.spark.sql.types.Decimal;\n+import org.apache.spark.unsafe.types.UTF8String;\n+\n+\n+class SparkOrcValueReaders {\n+  private SparkOrcValueReaders() {\n+  }\n+\n+  static OrcValReader<UTF8String> strings() {\n+    return StringReader.INSTANCE;\n+  }\n+\n+  static OrcValReader<?> timestampTzs() {\n+    return TimestampTzReader.INSTANCE;\n+  }\n+\n+  static OrcValReader<?> struct(\n+      List<OrcValReader<?>> readers, Types.StructType struct, Map<Integer, ?> idToConstant) {\n+    return new StructReader(readers, struct, idToConstant);\n+  }\n+\n+  static OrcValReader<?> array(OrcValReader<?> elementReader) {\n+    return new ArrayReader(elementReader);\n+  }\n+\n+  static OrcValReader<?> map(OrcValReader<?> keyReader, OrcValReader<?> valueReader) {\n+    return new MapReader(keyReader, valueReader);\n+  }\n+\n+  private static class ArrayReader implements OrcValReader<ArrayData> {\n+    private final OrcValReader<?> elementReader;\n+    private final List<Object> reusedList = Lists.newArrayList();\n+\n+    private ArrayReader(OrcValReader<?> elementReader) {\n+      this.elementReader = elementReader;\n+    }\n+\n+    @Override\n+    public ArrayData nonNullRead(ColumnVector vector, int row) {\n+      reusedList.clear();\n+      ListColumnVector listVector = (ListColumnVector) vector;\n+      int offset = (int) listVector.offsets[row];\n+      int length = (int) listVector.lengths[row];\n+      for (int c = 0; c < length; ++c) {\n+        reusedList.add(elementReader.read(listVector.child, offset + c));\n+      }\n+      return new GenericArrayData(reusedList.toArray());\n+    }\n+  }\n+\n+  private static class MapReader implements OrcValReader<MapData> {\n+    private final OrcValReader<?> keyReader;\n+    private final OrcValReader<?> valueReader;\n+\n+    private final List<Object> reusedKeyList = Lists.newArrayList();\n+    private final List<Object> reusedValueList = Lists.newArrayList();\n+\n+    private MapReader(OrcValReader<?> keyReader, OrcValReader<?> valueReader) {\n+      this.keyReader = keyReader;\n+      this.valueReader = valueReader;\n+    }\n+\n+    @Override\n+    public MapData nonNullRead(ColumnVector vector, int row) {\n+      reusedKeyList.clear();\n+      reusedValueList.clear();\n+      MapColumnVector mapVector = (MapColumnVector) vector;\n+      int offset = (int) mapVector.offsets[row];\n+      long length = mapVector.lengths[row];\n+      for (int c = 0; c < length; c++) {\n+        reusedKeyList.add(keyReader.read(mapVector.keys, offset + c));\n+        reusedValueList.add(valueReader.read(mapVector.values, offset + c));\n+      }\n+\n+      return new ArrayBasedMapData(\n+          new GenericArrayData(reusedKeyList.toArray()),\n+          new GenericArrayData(reusedValueList.toArray()));\n+    }\n+  }\n+\n+  static class StructReader extends OrcValueReaders.StructReader<InternalRow> {\n+    private final int numFields;\n+    private final InternalRow internalRow;\n+\n+    protected StructReader(List<OrcValReader<?>> readers, Types.StructType struct, Map<Integer, ?> idToConstant) {\n+      super(readers, struct, idToConstant);\n+      this.numFields = readers.size();\n+      internalRow = createOrReuse();\n+    }\n+\n+    @Override\n+    protected InternalRow createOrReuse() {\n+      return new GenericInternalRow(numFields);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzc5ODE5Mw=="}, "originalCommit": {"oid": "e415147e495c6230dcf7f478cc543652db777852"}, "originalPosition": 134}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTAxNzU3MA==", "bodyText": "Do or do not?", "url": "https://github.com/apache/iceberg/pull/989#discussion_r419017570", "createdAt": "2020-05-02T22:47:56Z", "author": {"login": "rdblue"}, "path": "spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcValueReaders.java", "diffHunk": "@@ -0,0 +1,206 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.data;\n+\n+import com.google.common.collect.Lists;\n+import java.math.BigDecimal;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.orc.OrcValReader;\n+import org.apache.iceberg.orc.OrcValueReaders;\n+import org.apache.iceberg.types.Types;\n+import org.apache.orc.storage.ql.exec.vector.BytesColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.DecimalColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ListColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.MapColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.TimestampColumnVector;\n+import org.apache.orc.storage.serde2.io.HiveDecimalWritable;\n+import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.catalyst.expressions.GenericInternalRow;\n+import org.apache.spark.sql.catalyst.util.ArrayBasedMapData;\n+import org.apache.spark.sql.catalyst.util.ArrayData;\n+import org.apache.spark.sql.catalyst.util.GenericArrayData;\n+import org.apache.spark.sql.catalyst.util.MapData;\n+import org.apache.spark.sql.types.Decimal;\n+import org.apache.spark.unsafe.types.UTF8String;\n+\n+\n+class SparkOrcValueReaders {\n+  private SparkOrcValueReaders() {\n+  }\n+\n+  static OrcValReader<UTF8String> strings() {\n+    return StringReader.INSTANCE;\n+  }\n+\n+  static OrcValReader<?> timestampTzs() {\n+    return TimestampTzReader.INSTANCE;\n+  }\n+\n+  static OrcValReader<?> struct(\n+      List<OrcValReader<?>> readers, Types.StructType struct, Map<Integer, ?> idToConstant) {\n+    return new StructReader(readers, struct, idToConstant);\n+  }\n+\n+  static OrcValReader<?> array(OrcValReader<?> elementReader) {\n+    return new ArrayReader(elementReader);\n+  }\n+\n+  static OrcValReader<?> map(OrcValReader<?> keyReader, OrcValReader<?> valueReader) {\n+    return new MapReader(keyReader, valueReader);\n+  }\n+\n+  private static class ArrayReader implements OrcValReader<ArrayData> {\n+    private final OrcValReader<?> elementReader;\n+    private final List<Object> reusedList = Lists.newArrayList();\n+\n+    private ArrayReader(OrcValReader<?> elementReader) {\n+      this.elementReader = elementReader;\n+    }\n+\n+    @Override\n+    public ArrayData nonNullRead(ColumnVector vector, int row) {\n+      reusedList.clear();\n+      ListColumnVector listVector = (ListColumnVector) vector;\n+      int offset = (int) listVector.offsets[row];\n+      int length = (int) listVector.lengths[row];\n+      for (int c = 0; c < length; ++c) {\n+        reusedList.add(elementReader.read(listVector.child, offset + c));\n+      }\n+      return new GenericArrayData(reusedList.toArray());\n+    }\n+  }\n+\n+  private static class MapReader implements OrcValReader<MapData> {\n+    private final OrcValReader<?> keyReader;\n+    private final OrcValReader<?> valueReader;\n+\n+    private final List<Object> reusedKeyList = Lists.newArrayList();\n+    private final List<Object> reusedValueList = Lists.newArrayList();\n+\n+    private MapReader(OrcValReader<?> keyReader, OrcValReader<?> valueReader) {\n+      this.keyReader = keyReader;\n+      this.valueReader = valueReader;\n+    }\n+\n+    @Override\n+    public MapData nonNullRead(ColumnVector vector, int row) {\n+      reusedKeyList.clear();\n+      reusedValueList.clear();\n+      MapColumnVector mapVector = (MapColumnVector) vector;\n+      int offset = (int) mapVector.offsets[row];\n+      long length = mapVector.lengths[row];\n+      for (int c = 0; c < length; c++) {\n+        reusedKeyList.add(keyReader.read(mapVector.keys, offset + c));\n+        reusedValueList.add(valueReader.read(mapVector.values, offset + c));\n+      }\n+\n+      return new ArrayBasedMapData(\n+          new GenericArrayData(reusedKeyList.toArray()),\n+          new GenericArrayData(reusedValueList.toArray()));\n+    }\n+  }\n+\n+  static class StructReader extends OrcValueReaders.StructReader<InternalRow> {\n+    private final int numFields;\n+    private final InternalRow internalRow;\n+\n+    protected StructReader(List<OrcValReader<?>> readers, Types.StructType struct, Map<Integer, ?> idToConstant) {\n+      super(readers, struct, idToConstant);\n+      this.numFields = readers.size();\n+      internalRow = createOrReuse();\n+    }\n+\n+    @Override\n+    protected InternalRow createOrReuse() {\n+      return new GenericInternalRow(numFields);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzc5ODE5Mw=="}, "originalCommit": {"oid": "e415147e495c6230dcf7f478cc543652db777852"}, "originalPosition": 134}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxOTAyMjU1MA==", "bodyText": "do not see any difference :)", "url": "https://github.com/apache/iceberg/pull/989#discussion_r419022550", "createdAt": "2020-05-02T23:46:40Z", "author": {"login": "rdsr"}, "path": "spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcValueReaders.java", "diffHunk": "@@ -0,0 +1,206 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.data;\n+\n+import com.google.common.collect.Lists;\n+import java.math.BigDecimal;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.orc.OrcValReader;\n+import org.apache.iceberg.orc.OrcValueReaders;\n+import org.apache.iceberg.types.Types;\n+import org.apache.orc.storage.ql.exec.vector.BytesColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.DecimalColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ListColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.MapColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.TimestampColumnVector;\n+import org.apache.orc.storage.serde2.io.HiveDecimalWritable;\n+import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.catalyst.expressions.GenericInternalRow;\n+import org.apache.spark.sql.catalyst.util.ArrayBasedMapData;\n+import org.apache.spark.sql.catalyst.util.ArrayData;\n+import org.apache.spark.sql.catalyst.util.GenericArrayData;\n+import org.apache.spark.sql.catalyst.util.MapData;\n+import org.apache.spark.sql.types.Decimal;\n+import org.apache.spark.unsafe.types.UTF8String;\n+\n+\n+class SparkOrcValueReaders {\n+  private SparkOrcValueReaders() {\n+  }\n+\n+  static OrcValReader<UTF8String> strings() {\n+    return StringReader.INSTANCE;\n+  }\n+\n+  static OrcValReader<?> timestampTzs() {\n+    return TimestampTzReader.INSTANCE;\n+  }\n+\n+  static OrcValReader<?> struct(\n+      List<OrcValReader<?>> readers, Types.StructType struct, Map<Integer, ?> idToConstant) {\n+    return new StructReader(readers, struct, idToConstant);\n+  }\n+\n+  static OrcValReader<?> array(OrcValReader<?> elementReader) {\n+    return new ArrayReader(elementReader);\n+  }\n+\n+  static OrcValReader<?> map(OrcValReader<?> keyReader, OrcValReader<?> valueReader) {\n+    return new MapReader(keyReader, valueReader);\n+  }\n+\n+  private static class ArrayReader implements OrcValReader<ArrayData> {\n+    private final OrcValReader<?> elementReader;\n+    private final List<Object> reusedList = Lists.newArrayList();\n+\n+    private ArrayReader(OrcValReader<?> elementReader) {\n+      this.elementReader = elementReader;\n+    }\n+\n+    @Override\n+    public ArrayData nonNullRead(ColumnVector vector, int row) {\n+      reusedList.clear();\n+      ListColumnVector listVector = (ListColumnVector) vector;\n+      int offset = (int) listVector.offsets[row];\n+      int length = (int) listVector.lengths[row];\n+      for (int c = 0; c < length; ++c) {\n+        reusedList.add(elementReader.read(listVector.child, offset + c));\n+      }\n+      return new GenericArrayData(reusedList.toArray());\n+    }\n+  }\n+\n+  private static class MapReader implements OrcValReader<MapData> {\n+    private final OrcValReader<?> keyReader;\n+    private final OrcValReader<?> valueReader;\n+\n+    private final List<Object> reusedKeyList = Lists.newArrayList();\n+    private final List<Object> reusedValueList = Lists.newArrayList();\n+\n+    private MapReader(OrcValReader<?> keyReader, OrcValReader<?> valueReader) {\n+      this.keyReader = keyReader;\n+      this.valueReader = valueReader;\n+    }\n+\n+    @Override\n+    public MapData nonNullRead(ColumnVector vector, int row) {\n+      reusedKeyList.clear();\n+      reusedValueList.clear();\n+      MapColumnVector mapVector = (MapColumnVector) vector;\n+      int offset = (int) mapVector.offsets[row];\n+      long length = mapVector.lengths[row];\n+      for (int c = 0; c < length; c++) {\n+        reusedKeyList.add(keyReader.read(mapVector.keys, offset + c));\n+        reusedValueList.add(valueReader.read(mapVector.values, offset + c));\n+      }\n+\n+      return new ArrayBasedMapData(\n+          new GenericArrayData(reusedKeyList.toArray()),\n+          new GenericArrayData(reusedValueList.toArray()));\n+    }\n+  }\n+\n+  static class StructReader extends OrcValueReaders.StructReader<InternalRow> {\n+    private final int numFields;\n+    private final InternalRow internalRow;\n+\n+    protected StructReader(List<OrcValReader<?>> readers, Types.StructType struct, Map<Integer, ?> idToConstant) {\n+      super(readers, struct, idToConstant);\n+      this.numFields = readers.size();\n+      internalRow = createOrReuse();\n+    }\n+\n+    @Override\n+    protected InternalRow createOrReuse() {\n+      return new GenericInternalRow(numFields);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzc5ODE5Mw=="}, "originalCommit": {"oid": "e415147e495c6230dcf7f478cc543652db777852"}, "originalPosition": 134}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY3MjgyMQ==", "bodyText": "The Spark/Parquet reader doesn't currently reuse containers.", "url": "https://github.com/apache/iceberg/pull/989#discussion_r421672821", "createdAt": "2020-05-07T17:29:43Z", "author": {"login": "rdblue"}, "path": "spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcValueReaders.java", "diffHunk": "@@ -0,0 +1,206 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.data;\n+\n+import com.google.common.collect.Lists;\n+import java.math.BigDecimal;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.orc.OrcValReader;\n+import org.apache.iceberg.orc.OrcValueReaders;\n+import org.apache.iceberg.types.Types;\n+import org.apache.orc.storage.ql.exec.vector.BytesColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.DecimalColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ListColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.MapColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.TimestampColumnVector;\n+import org.apache.orc.storage.serde2.io.HiveDecimalWritable;\n+import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.catalyst.expressions.GenericInternalRow;\n+import org.apache.spark.sql.catalyst.util.ArrayBasedMapData;\n+import org.apache.spark.sql.catalyst.util.ArrayData;\n+import org.apache.spark.sql.catalyst.util.GenericArrayData;\n+import org.apache.spark.sql.catalyst.util.MapData;\n+import org.apache.spark.sql.types.Decimal;\n+import org.apache.spark.unsafe.types.UTF8String;\n+\n+\n+class SparkOrcValueReaders {\n+  private SparkOrcValueReaders() {\n+  }\n+\n+  static OrcValReader<UTF8String> strings() {\n+    return StringReader.INSTANCE;\n+  }\n+\n+  static OrcValReader<?> timestampTzs() {\n+    return TimestampTzReader.INSTANCE;\n+  }\n+\n+  static OrcValReader<?> struct(\n+      List<OrcValReader<?>> readers, Types.StructType struct, Map<Integer, ?> idToConstant) {\n+    return new StructReader(readers, struct, idToConstant);\n+  }\n+\n+  static OrcValReader<?> array(OrcValReader<?> elementReader) {\n+    return new ArrayReader(elementReader);\n+  }\n+\n+  static OrcValReader<?> map(OrcValReader<?> keyReader, OrcValReader<?> valueReader) {\n+    return new MapReader(keyReader, valueReader);\n+  }\n+\n+  private static class ArrayReader implements OrcValReader<ArrayData> {\n+    private final OrcValReader<?> elementReader;\n+    private final List<Object> reusedList = Lists.newArrayList();\n+\n+    private ArrayReader(OrcValReader<?> elementReader) {\n+      this.elementReader = elementReader;\n+    }\n+\n+    @Override\n+    public ArrayData nonNullRead(ColumnVector vector, int row) {\n+      reusedList.clear();\n+      ListColumnVector listVector = (ListColumnVector) vector;\n+      int offset = (int) listVector.offsets[row];\n+      int length = (int) listVector.lengths[row];\n+      for (int c = 0; c < length; ++c) {\n+        reusedList.add(elementReader.read(listVector.child, offset + c));\n+      }\n+      return new GenericArrayData(reusedList.toArray());\n+    }\n+  }\n+\n+  private static class MapReader implements OrcValReader<MapData> {\n+    private final OrcValReader<?> keyReader;\n+    private final OrcValReader<?> valueReader;\n+\n+    private final List<Object> reusedKeyList = Lists.newArrayList();\n+    private final List<Object> reusedValueList = Lists.newArrayList();\n+\n+    private MapReader(OrcValReader<?> keyReader, OrcValReader<?> valueReader) {\n+      this.keyReader = keyReader;\n+      this.valueReader = valueReader;\n+    }\n+\n+    @Override\n+    public MapData nonNullRead(ColumnVector vector, int row) {\n+      reusedKeyList.clear();\n+      reusedValueList.clear();\n+      MapColumnVector mapVector = (MapColumnVector) vector;\n+      int offset = (int) mapVector.offsets[row];\n+      long length = mapVector.lengths[row];\n+      for (int c = 0; c < length; c++) {\n+        reusedKeyList.add(keyReader.read(mapVector.keys, offset + c));\n+        reusedValueList.add(valueReader.read(mapVector.values, offset + c));\n+      }\n+\n+      return new ArrayBasedMapData(\n+          new GenericArrayData(reusedKeyList.toArray()),\n+          new GenericArrayData(reusedValueList.toArray()));\n+    }\n+  }\n+\n+  static class StructReader extends OrcValueReaders.StructReader<InternalRow> {\n+    private final int numFields;\n+    private final InternalRow internalRow;\n+\n+    protected StructReader(List<OrcValReader<?>> readers, Types.StructType struct, Map<Integer, ?> idToConstant) {\n+      super(readers, struct, idToConstant);\n+      this.numFields = readers.size();\n+      internalRow = createOrReuse();\n+    }\n+\n+    @Override\n+    protected InternalRow createOrReuse() {\n+      return new GenericInternalRow(numFields);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzc5ODE5Mw=="}, "originalCommit": {"oid": "e415147e495c6230dcf7f478cc543652db777852"}, "originalPosition": 134}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODI5ODcxNA==", "bodyText": "@rdblue . Not sure I follow  this..\n\nThe Spark/Parquet reader doesn't currently reuse containers.\n\nI did the JMH testing for ORC before and after my patch", "url": "https://github.com/apache/iceberg/pull/989#discussion_r428298714", "createdAt": "2020-05-20T20:49:02Z", "author": {"login": "rdsr"}, "path": "spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcValueReaders.java", "diffHunk": "@@ -0,0 +1,206 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.data;\n+\n+import com.google.common.collect.Lists;\n+import java.math.BigDecimal;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.orc.OrcValReader;\n+import org.apache.iceberg.orc.OrcValueReaders;\n+import org.apache.iceberg.types.Types;\n+import org.apache.orc.storage.ql.exec.vector.BytesColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.DecimalColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ListColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.MapColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.TimestampColumnVector;\n+import org.apache.orc.storage.serde2.io.HiveDecimalWritable;\n+import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.catalyst.expressions.GenericInternalRow;\n+import org.apache.spark.sql.catalyst.util.ArrayBasedMapData;\n+import org.apache.spark.sql.catalyst.util.ArrayData;\n+import org.apache.spark.sql.catalyst.util.GenericArrayData;\n+import org.apache.spark.sql.catalyst.util.MapData;\n+import org.apache.spark.sql.types.Decimal;\n+import org.apache.spark.unsafe.types.UTF8String;\n+\n+\n+class SparkOrcValueReaders {\n+  private SparkOrcValueReaders() {\n+  }\n+\n+  static OrcValReader<UTF8String> strings() {\n+    return StringReader.INSTANCE;\n+  }\n+\n+  static OrcValReader<?> timestampTzs() {\n+    return TimestampTzReader.INSTANCE;\n+  }\n+\n+  static OrcValReader<?> struct(\n+      List<OrcValReader<?>> readers, Types.StructType struct, Map<Integer, ?> idToConstant) {\n+    return new StructReader(readers, struct, idToConstant);\n+  }\n+\n+  static OrcValReader<?> array(OrcValReader<?> elementReader) {\n+    return new ArrayReader(elementReader);\n+  }\n+\n+  static OrcValReader<?> map(OrcValReader<?> keyReader, OrcValReader<?> valueReader) {\n+    return new MapReader(keyReader, valueReader);\n+  }\n+\n+  private static class ArrayReader implements OrcValReader<ArrayData> {\n+    private final OrcValReader<?> elementReader;\n+    private final List<Object> reusedList = Lists.newArrayList();\n+\n+    private ArrayReader(OrcValReader<?> elementReader) {\n+      this.elementReader = elementReader;\n+    }\n+\n+    @Override\n+    public ArrayData nonNullRead(ColumnVector vector, int row) {\n+      reusedList.clear();\n+      ListColumnVector listVector = (ListColumnVector) vector;\n+      int offset = (int) listVector.offsets[row];\n+      int length = (int) listVector.lengths[row];\n+      for (int c = 0; c < length; ++c) {\n+        reusedList.add(elementReader.read(listVector.child, offset + c));\n+      }\n+      return new GenericArrayData(reusedList.toArray());\n+    }\n+  }\n+\n+  private static class MapReader implements OrcValReader<MapData> {\n+    private final OrcValReader<?> keyReader;\n+    private final OrcValReader<?> valueReader;\n+\n+    private final List<Object> reusedKeyList = Lists.newArrayList();\n+    private final List<Object> reusedValueList = Lists.newArrayList();\n+\n+    private MapReader(OrcValReader<?> keyReader, OrcValReader<?> valueReader) {\n+      this.keyReader = keyReader;\n+      this.valueReader = valueReader;\n+    }\n+\n+    @Override\n+    public MapData nonNullRead(ColumnVector vector, int row) {\n+      reusedKeyList.clear();\n+      reusedValueList.clear();\n+      MapColumnVector mapVector = (MapColumnVector) vector;\n+      int offset = (int) mapVector.offsets[row];\n+      long length = mapVector.lengths[row];\n+      for (int c = 0; c < length; c++) {\n+        reusedKeyList.add(keyReader.read(mapVector.keys, offset + c));\n+        reusedValueList.add(valueReader.read(mapVector.values, offset + c));\n+      }\n+\n+      return new ArrayBasedMapData(\n+          new GenericArrayData(reusedKeyList.toArray()),\n+          new GenericArrayData(reusedValueList.toArray()));\n+    }\n+  }\n+\n+  static class StructReader extends OrcValueReaders.StructReader<InternalRow> {\n+    private final int numFields;\n+    private final InternalRow internalRow;\n+\n+    protected StructReader(List<OrcValReader<?>> readers, Types.StructType struct, Map<Integer, ?> idToConstant) {\n+      super(readers, struct, idToConstant);\n+      this.numFields = readers.size();\n+      internalRow = createOrReuse();\n+    }\n+\n+    @Override\n+    protected InternalRow createOrReuse() {\n+      return new GenericInternalRow(numFields);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxNzc5ODE5Mw=="}, "originalCommit": {"oid": "e415147e495c6230dcf7f478cc543652db777852"}, "originalPosition": 134}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYwMjA3MzU1OnYy", "diffSide": "RIGHT", "path": "orc/src/main/java/org/apache/iceberg/orc/OrcSchemaWithTypeVisitor.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQxODoxMjoyNFrOGO0yew==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0zMFQxODoxMjoyNFrOGO0yew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxODE5ODEzOQ==", "bodyText": "how about using UnsupportedOperationException instead?", "url": "https://github.com/apache/iceberg/pull/989#discussion_r418198139", "createdAt": "2020-04-30T18:12:24Z", "author": {"login": "abti"}, "path": "orc/src/main/java/org/apache/iceberg/orc/OrcSchemaWithTypeVisitor.java", "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.orc;\n+\n+import com.google.common.collect.Lists;\n+import java.util.List;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+import org.apache.orc.TypeDescription;\n+\n+\n+public abstract class OrcSchemaWithTypeVisitor<T> {\n+  public static <T> T visit(\n+      org.apache.iceberg.Schema iSchema, TypeDescription schema, OrcSchemaWithTypeVisitor<T> visitor) {\n+    return visit(iSchema.asStruct(), schema, visitor);\n+  }\n+\n+  public static <T> T visit(Type iType, TypeDescription schema, OrcSchemaWithTypeVisitor<T> visitor) {\n+    switch (schema.getCategory()) {\n+      case STRUCT:\n+        return visitRecord(iType.asStructType(), schema, visitor);\n+\n+      case UNION:\n+        // We don't have an answer for union types.\n+        throw new IllegalArgumentException(\"Can't handle \" + schema);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e415147e495c6230dcf7f478cc543652db777852"}, "originalPosition": 42}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYyMDc5NDk2OnYy", "diffSide": "RIGHT", "path": "orc/src/main/java/org/apache/iceberg/orc/ORCSchemaUtil.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNlQxODoxODowMFrOGRfmbg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMFQyMDo1MDowN1rOGYdUDw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDk5NjcxOA==", "bodyText": "I just noticed the logic here and it's a correctness bug. ORC should not assign column IDs when one is missing. Instead, it should ignore the field.", "url": "https://github.com/apache/iceberg/pull/989#discussion_r420996718", "createdAt": "2020-05-06T18:18:00Z", "author": {"login": "rdblue"}, "path": "orc/src/main/java/org/apache/iceberg/orc/ORCSchemaUtil.java", "diffHunk": "@@ -214,6 +214,7 @@ public static Schema convert(TypeDescription orcSchema) {\n         \"Error in ORC file, children fields and names do not match.\");\n \n     List<Types.NestedField> icebergFields = Lists.newArrayListWithExpectedSize(children.size());\n+    // TODO how we get field ids from ORC schema", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODI5OTI3OQ==", "bodyText": "Should we use another PR to fix this?", "url": "https://github.com/apache/iceberg/pull/989#discussion_r428299279", "createdAt": "2020-05-20T20:50:07Z", "author": {"login": "rdsr"}, "path": "orc/src/main/java/org/apache/iceberg/orc/ORCSchemaUtil.java", "diffHunk": "@@ -214,6 +214,7 @@ public static Schema convert(TypeDescription orcSchema) {\n         \"Error in ORC file, children fields and names do not match.\");\n \n     List<Types.NestedField> icebergFields = Lists.newArrayListWithExpectedSize(children.size());\n+    // TODO how we get field ids from ORC schema", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDk5NjcxOA=="}, "originalCommit": {"oid": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYyMDgwMTIzOnYy", "diffSide": "RIGHT", "path": "orc/src/main/java/org/apache/iceberg/orc/ORCSchemaUtil.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNlQxODoxOTozNVrOGRfqLQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNlQxODoxOTozNVrOGRfqLQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDk5NzY3Nw==", "bodyText": "I don't see this used other than in the conversion logic to assign new IDs. Because that assignment is actually a correctness bug, we don't need this method at all. Also, since it isn't used anywhere else in this PR there is no need to make it package-private instead of private.", "url": "https://github.com/apache/iceberg/pull/989#discussion_r420997677", "createdAt": "2020-05-06T18:19:35Z", "author": {"login": "rdblue"}, "path": "orc/src/main/java/org/apache/iceberg/orc/ORCSchemaUtil.java", "diffHunk": "@@ -496,7 +503,7 @@ private static boolean isRequired(TypeDescription orcType) {\n     }\n   }\n \n-  private static int getMaxIcebergId(TypeDescription originalOrcSchema) {\n+  static int getMaxIcebergId(TypeDescription originalOrcSchema) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0"}, "originalPosition": 50}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYyMzMwMDgyOnYy", "diffSide": "RIGHT", "path": "orc/src/main/java/org/apache/iceberg/orc/ORCSchemaUtil.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QwOTo1Njo1MlrOGR3SVQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQxNjoyMzozNlrOGZc0CA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTM4NDc4OQ==", "bodyText": "For completeness sake, also set ICEBERG_REQUIRED_ATTRIBUTE?", "url": "https://github.com/apache/iceberg/pull/989#discussion_r421384789", "createdAt": "2020-05-07T09:56:52Z", "author": {"login": "shardulm94"}, "path": "orc/src/main/java/org/apache/iceberg/orc/ORCSchemaUtil.java", "diffHunk": "@@ -308,7 +309,7 @@ private static TypeDescription buildOrcProjection(Integer fieldId, Type type, bo\n           orcType = convert(fieldId, type, false);\n         }\n     }\n-\n+    orcType.setAttribute(ICEBERG_ID_ATTRIBUTE, fieldId.toString());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA4MzUyOA==", "bodyText": "Adding this is actually causing failures\norg.apache.iceberg.data.orc.TestGenericReadProjection > testRenamedAddedField FAILED\n    java.lang.IllegalArgumentException: No conversion of type LONG to self needed\n        at org.apache.orc.impl.ConvertTreeReaderFactory.createAnyIntegerConvertTreeReader(ConvertTreeReaderFactory.java:1671)\n        at org.apache.orc.impl.ConvertTreeReaderFactory.createConvertTreeReader(ConvertTreeReaderFactory.java:2124)\n        at org.apache.orc.impl.TreeReaderFactory.createTreeReader(TreeReaderFactory.java:2331)\n        at org.apache.orc.impl.TreeReaderFactory$StructTreeReader.<init>(TreeReaderFactory.java:1961)\n        at org.apache.orc.impl.TreeReaderFactory.createTreeReader(TreeReaderFactory.java:2371)\n        at org.apache.orc.impl.RecordReaderImpl.<init>(RecordReaderImpl.java:227)\n        at org.apache.orc.impl.ReaderImpl.rows(ReaderImpl.java:752)\n        at org.apache.iceberg.orc.OrcIterable.newOrcIterator(OrcIterable.java:80)\n        at org.apache.iceberg.orc.OrcIterable.iterator(OrcIterable.java:65)\n        at com.google.common.collect.Iterables.getOnlyElement(Iterables.java:254)\n        at org.apache.iceberg.data.orc.TestGenericReadProjection.writeAndRead(TestGenericReadProjection.java:53)\n\nAnd I vaguely remember we fixed a similar bug before in ORC", "url": "https://github.com/apache/iceberg/pull/989#discussion_r429083528", "createdAt": "2020-05-22T07:20:41Z", "author": {"login": "rdsr"}, "path": "orc/src/main/java/org/apache/iceberg/orc/ORCSchemaUtil.java", "diffHunk": "@@ -308,7 +309,7 @@ private static TypeDescription buildOrcProjection(Integer fieldId, Type type, bo\n           orcType = convert(fieldId, type, false);\n         }\n     }\n-\n+    orcType.setAttribute(ICEBERG_ID_ATTRIBUTE, fieldId.toString());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTM4NDc4OQ=="}, "originalCommit": {"oid": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTMyNjAzMw==", "bodyText": "It would be great to know what's going on here. Since this is just a projection schema and the reader is built with the Iceberg schema (that has required/optional), I don't think it is really a blocker. But setting a property here shouldn't cause ORC to fail, right?", "url": "https://github.com/apache/iceberg/pull/989#discussion_r429326033", "createdAt": "2020-05-22T15:50:44Z", "author": {"login": "rdblue"}, "path": "orc/src/main/java/org/apache/iceberg/orc/ORCSchemaUtil.java", "diffHunk": "@@ -308,7 +309,7 @@ private static TypeDescription buildOrcProjection(Integer fieldId, Type type, bo\n           orcType = convert(fieldId, type, false);\n         }\n     }\n-\n+    orcType.setAttribute(ICEBERG_ID_ATTRIBUTE, fieldId.toString());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTM4NDc4OQ=="}, "originalCommit": {"oid": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTMzOTY1Ng==", "bodyText": "I'll file the necessary followups.", "url": "https://github.com/apache/iceberg/pull/989#discussion_r429339656", "createdAt": "2020-05-22T16:23:36Z", "author": {"login": "rdsr"}, "path": "orc/src/main/java/org/apache/iceberg/orc/ORCSchemaUtil.java", "diffHunk": "@@ -308,7 +309,7 @@ private static TypeDescription buildOrcProjection(Integer fieldId, Type type, bo\n           orcType = convert(fieldId, type, false);\n         }\n     }\n-\n+    orcType.setAttribute(ICEBERG_ID_ATTRIBUTE, fieldId.toString());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTM4NDc4OQ=="}, "originalCommit": {"oid": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYyNDk1NjI0OnYy", "diffSide": "RIGHT", "path": "orc/src/main/java/org/apache/iceberg/orc/OrcSchemaWithTypeVisitor.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QxNjo1MjoyOVrOGSHgTg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QxNjo1MjoyOVrOGSHgTg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY1MDUxMA==", "bodyText": "In other visitors, we try to name the method after the type in the schema that is being visited. That's why Avro uses array but Iceberg uses list. Since the category for ORC is LIST, should the visitor method be named list?", "url": "https://github.com/apache/iceberg/pull/989#discussion_r421650510", "createdAt": "2020-05-07T16:52:29Z", "author": {"login": "rdblue"}, "path": "orc/src/main/java/org/apache/iceberg/orc/OrcSchemaWithTypeVisitor.java", "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.orc;\n+\n+import com.google.common.collect.Lists;\n+import java.util.List;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+import org.apache.orc.TypeDescription;\n+\n+\n+public abstract class OrcSchemaWithTypeVisitor<T> {\n+  public static <T> T visit(\n+      org.apache.iceberg.Schema iSchema, TypeDescription schema, OrcSchemaWithTypeVisitor<T> visitor) {\n+    return visit(iSchema.asStruct(), schema, visitor);\n+  }\n+\n+  public static <T> T visit(Type iType, TypeDescription schema, OrcSchemaWithTypeVisitor<T> visitor) {\n+    switch (schema.getCategory()) {\n+      case STRUCT:\n+        return visitRecord(iType.asStructType(), schema, visitor);\n+\n+      case UNION:\n+        // We don't have an answer for union types.\n+        throw new IllegalArgumentException(\"Can't handle \" + schema);\n+\n+      case LIST:\n+        Types.ListType list = iType.asListType();\n+        return visitor.array(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0"}, "originalPosition": 46}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYyNDk4MjMwOnYy", "diffSide": "RIGHT", "path": "orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QxNjo1OToyNVrOGSHw_A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMFQyMDo1NjowOFrOGYdgSw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY1NDc4MA==", "bodyText": "Do we need a short reader? Iceberg doesn't support short values in a table schema, so we shouldn't be expecting to ever return a short value.", "url": "https://github.com/apache/iceberg/pull/989#discussion_r421654780", "createdAt": "2020-05-07T16:59:25Z", "author": {"login": "rdblue"}, "path": "orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.orc;\n+\n+import com.google.common.collect.Lists;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.types.Types;\n+import org.apache.orc.storage.ql.exec.vector.BytesColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.DoubleColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.LongColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.StructColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.VectorizedRowBatch;\n+\n+\n+public class OrcValueReaders {\n+  private OrcValueReaders() {\n+  }\n+\n+  public static OrcValReader<?> booleans() {\n+    return BooleanReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> shorts() {\n+    return ShortReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> ints() {\n+    return IntegerReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> longs() {\n+    return LongReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> floats() {\n+    return FloatReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> doubles() {\n+    return DoubleReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> bytes() {\n+    return BytesReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> byteReader() {\n+    return ByteReader.INSTANCE;\n+  }\n+\n+  private static class BooleanReader implements OrcValReader<Boolean> {\n+    static final OrcValReader<?> INSTANCE = new BooleanReader();\n+\n+    private BooleanReader() {\n+    }\n+\n+    @Override\n+    public Boolean nonNullRead(ColumnVector vector, int row) {\n+      return ((LongColumnVector) vector).vector[row] != 0;\n+    }\n+  }\n+\n+  private static class ShortReader implements OrcValReader<Short> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0"}, "originalPosition": 83}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODMwMjQxMQ==", "bodyText": "Ohk. I can change this to ints", "url": "https://github.com/apache/iceberg/pull/989#discussion_r428302411", "createdAt": "2020-05-20T20:56:08Z", "author": {"login": "rdsr"}, "path": "orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.orc;\n+\n+import com.google.common.collect.Lists;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.types.Types;\n+import org.apache.orc.storage.ql.exec.vector.BytesColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.DoubleColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.LongColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.StructColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.VectorizedRowBatch;\n+\n+\n+public class OrcValueReaders {\n+  private OrcValueReaders() {\n+  }\n+\n+  public static OrcValReader<?> booleans() {\n+    return BooleanReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> shorts() {\n+    return ShortReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> ints() {\n+    return IntegerReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> longs() {\n+    return LongReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> floats() {\n+    return FloatReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> doubles() {\n+    return DoubleReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> bytes() {\n+    return BytesReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> byteReader() {\n+    return ByteReader.INSTANCE;\n+  }\n+\n+  private static class BooleanReader implements OrcValReader<Boolean> {\n+    static final OrcValReader<?> INSTANCE = new BooleanReader();\n+\n+    private BooleanReader() {\n+    }\n+\n+    @Override\n+    public Boolean nonNullRead(ColumnVector vector, int row) {\n+      return ((LongColumnVector) vector).vector[row] != 0;\n+    }\n+  }\n+\n+  private static class ShortReader implements OrcValReader<Short> {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY1NDc4MA=="}, "originalCommit": {"oid": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0"}, "originalPosition": 83}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYyNDk4NTcwOnYy", "diffSide": "RIGHT", "path": "orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QxNzowMDoyMFrOGSHzPg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QxNzowMDoyMFrOGSHzPg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY1NTM1OA==", "bodyText": "Similar to short, do we need this reader?", "url": "https://github.com/apache/iceberg/pull/989#discussion_r421655358", "createdAt": "2020-05-07T17:00:20Z", "author": {"login": "rdblue"}, "path": "orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.orc;\n+\n+import com.google.common.collect.Lists;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.types.Types;\n+import org.apache.orc.storage.ql.exec.vector.BytesColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.DoubleColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.LongColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.StructColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.VectorizedRowBatch;\n+\n+\n+public class OrcValueReaders {\n+  private OrcValueReaders() {\n+  }\n+\n+  public static OrcValReader<?> booleans() {\n+    return BooleanReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> shorts() {\n+    return ShortReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> ints() {\n+    return IntegerReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> longs() {\n+    return LongReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> floats() {\n+    return FloatReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> doubles() {\n+    return DoubleReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> bytes() {\n+    return BytesReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> byteReader() {\n+    return ByteReader.INSTANCE;\n+  }\n+\n+  private static class BooleanReader implements OrcValReader<Boolean> {\n+    static final OrcValReader<?> INSTANCE = new BooleanReader();\n+\n+    private BooleanReader() {\n+    }\n+\n+    @Override\n+    public Boolean nonNullRead(ColumnVector vector, int row) {\n+      return ((LongColumnVector) vector).vector[row] != 0;\n+    }\n+  }\n+\n+  private static class ShortReader implements OrcValReader<Short> {\n+    static final OrcValReader<?> INSTANCE = new ShortReader();\n+\n+    private ShortReader() {\n+    }\n+\n+    @Override\n+    public Short nonNullRead(ColumnVector vector, int row) {\n+      return (short) ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class IntegerReader implements OrcValReader<Integer> {\n+    static final OrcValReader<?> INSTANCE = new IntegerReader();\n+\n+    private IntegerReader() {\n+    }\n+\n+    @Override\n+    public Integer nonNullRead(ColumnVector vector, int row) {\n+      return (int) ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class LongReader implements OrcValReader<Long> {\n+    static final OrcValReader<?> INSTANCE = new LongReader();\n+\n+    private LongReader() {\n+    }\n+\n+    @Override\n+    public Long nonNullRead(ColumnVector vector, int row) {\n+      return ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class FloatReader implements OrcValReader<Float> {\n+    private static final FloatReader INSTANCE = new FloatReader();\n+\n+    private FloatReader() {\n+    }\n+\n+    @Override\n+    public Float nonNullRead(ColumnVector vector, int row) {\n+      return (float) ((DoubleColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class DoubleReader implements OrcValReader<Double> {\n+    private static final DoubleReader INSTANCE = new DoubleReader();\n+\n+    private DoubleReader() {\n+    }\n+\n+    @Override\n+    public Double nonNullRead(ColumnVector vector, int row) {\n+      return ((DoubleColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class ByteReader implements OrcValReader<Byte> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0"}, "originalPosition": 143}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYyNDk5NDE4OnYy", "diffSide": "RIGHT", "path": "orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QxNzowMjozNlrOGSH40A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QxNzoxMzo0NVrOGSISEw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY1Njc4NA==", "bodyText": "Where is this used? It doesn't look like using 0-length arrays for positions and constants is correct.", "url": "https://github.com/apache/iceberg/pull/989#discussion_r421656784", "createdAt": "2020-05-07T17:02:36Z", "author": {"login": "rdblue"}, "path": "orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.orc;\n+\n+import com.google.common.collect.Lists;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.types.Types;\n+import org.apache.orc.storage.ql.exec.vector.BytesColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.DoubleColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.LongColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.StructColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.VectorizedRowBatch;\n+\n+\n+public class OrcValueReaders {\n+  private OrcValueReaders() {\n+  }\n+\n+  public static OrcValReader<?> booleans() {\n+    return BooleanReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> shorts() {\n+    return ShortReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> ints() {\n+    return IntegerReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> longs() {\n+    return LongReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> floats() {\n+    return FloatReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> doubles() {\n+    return DoubleReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> bytes() {\n+    return BytesReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> byteReader() {\n+    return ByteReader.INSTANCE;\n+  }\n+\n+  private static class BooleanReader implements OrcValReader<Boolean> {\n+    static final OrcValReader<?> INSTANCE = new BooleanReader();\n+\n+    private BooleanReader() {\n+    }\n+\n+    @Override\n+    public Boolean nonNullRead(ColumnVector vector, int row) {\n+      return ((LongColumnVector) vector).vector[row] != 0;\n+    }\n+  }\n+\n+  private static class ShortReader implements OrcValReader<Short> {\n+    static final OrcValReader<?> INSTANCE = new ShortReader();\n+\n+    private ShortReader() {\n+    }\n+\n+    @Override\n+    public Short nonNullRead(ColumnVector vector, int row) {\n+      return (short) ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class IntegerReader implements OrcValReader<Integer> {\n+    static final OrcValReader<?> INSTANCE = new IntegerReader();\n+\n+    private IntegerReader() {\n+    }\n+\n+    @Override\n+    public Integer nonNullRead(ColumnVector vector, int row) {\n+      return (int) ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class LongReader implements OrcValReader<Long> {\n+    static final OrcValReader<?> INSTANCE = new LongReader();\n+\n+    private LongReader() {\n+    }\n+\n+    @Override\n+    public Long nonNullRead(ColumnVector vector, int row) {\n+      return ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class FloatReader implements OrcValReader<Float> {\n+    private static final FloatReader INSTANCE = new FloatReader();\n+\n+    private FloatReader() {\n+    }\n+\n+    @Override\n+    public Float nonNullRead(ColumnVector vector, int row) {\n+      return (float) ((DoubleColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class DoubleReader implements OrcValReader<Double> {\n+    private static final DoubleReader INSTANCE = new DoubleReader();\n+\n+    private DoubleReader() {\n+    }\n+\n+    @Override\n+    public Double nonNullRead(ColumnVector vector, int row) {\n+      return ((DoubleColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class ByteReader implements OrcValReader<Byte> {\n+    private static final ByteReader INSTANCE = new ByteReader();\n+\n+    private ByteReader() {\n+    }\n+\n+    @Override\n+    public Byte nonNullRead(ColumnVector vector, int row) {\n+      return (byte) ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class BytesReader implements OrcValReader<byte[]> {\n+    private static final BytesReader INSTANCE = new BytesReader();\n+\n+    private BytesReader() {\n+    }\n+\n+    @Override\n+    public byte[] nonNullRead(ColumnVector vector, int row) {\n+      BytesColumnVector bytesVector = (BytesColumnVector) vector;\n+\n+      return Arrays.copyOfRange(\n+          bytesVector.vector[row], bytesVector.start[row], bytesVector.start[row] + bytesVector.length[row]);\n+    }\n+  }\n+\n+  public abstract static class StructReader<T> implements OrcValReader<T> {\n+    private final OrcValReader<?>[] readers;\n+    private final int[] positions;\n+    private final Object[] constants;\n+\n+    protected StructReader(List<OrcValReader<?>> readers) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0"}, "originalPosition": 175}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY2MzI1MQ==", "bodyText": "Nevermind, I see what's happening.", "url": "https://github.com/apache/iceberg/pull/989#discussion_r421663251", "createdAt": "2020-05-07T17:13:45Z", "author": {"login": "rdblue"}, "path": "orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.orc;\n+\n+import com.google.common.collect.Lists;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.types.Types;\n+import org.apache.orc.storage.ql.exec.vector.BytesColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.DoubleColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.LongColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.StructColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.VectorizedRowBatch;\n+\n+\n+public class OrcValueReaders {\n+  private OrcValueReaders() {\n+  }\n+\n+  public static OrcValReader<?> booleans() {\n+    return BooleanReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> shorts() {\n+    return ShortReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> ints() {\n+    return IntegerReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> longs() {\n+    return LongReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> floats() {\n+    return FloatReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> doubles() {\n+    return DoubleReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> bytes() {\n+    return BytesReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> byteReader() {\n+    return ByteReader.INSTANCE;\n+  }\n+\n+  private static class BooleanReader implements OrcValReader<Boolean> {\n+    static final OrcValReader<?> INSTANCE = new BooleanReader();\n+\n+    private BooleanReader() {\n+    }\n+\n+    @Override\n+    public Boolean nonNullRead(ColumnVector vector, int row) {\n+      return ((LongColumnVector) vector).vector[row] != 0;\n+    }\n+  }\n+\n+  private static class ShortReader implements OrcValReader<Short> {\n+    static final OrcValReader<?> INSTANCE = new ShortReader();\n+\n+    private ShortReader() {\n+    }\n+\n+    @Override\n+    public Short nonNullRead(ColumnVector vector, int row) {\n+      return (short) ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class IntegerReader implements OrcValReader<Integer> {\n+    static final OrcValReader<?> INSTANCE = new IntegerReader();\n+\n+    private IntegerReader() {\n+    }\n+\n+    @Override\n+    public Integer nonNullRead(ColumnVector vector, int row) {\n+      return (int) ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class LongReader implements OrcValReader<Long> {\n+    static final OrcValReader<?> INSTANCE = new LongReader();\n+\n+    private LongReader() {\n+    }\n+\n+    @Override\n+    public Long nonNullRead(ColumnVector vector, int row) {\n+      return ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class FloatReader implements OrcValReader<Float> {\n+    private static final FloatReader INSTANCE = new FloatReader();\n+\n+    private FloatReader() {\n+    }\n+\n+    @Override\n+    public Float nonNullRead(ColumnVector vector, int row) {\n+      return (float) ((DoubleColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class DoubleReader implements OrcValReader<Double> {\n+    private static final DoubleReader INSTANCE = new DoubleReader();\n+\n+    private DoubleReader() {\n+    }\n+\n+    @Override\n+    public Double nonNullRead(ColumnVector vector, int row) {\n+      return ((DoubleColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class ByteReader implements OrcValReader<Byte> {\n+    private static final ByteReader INSTANCE = new ByteReader();\n+\n+    private ByteReader() {\n+    }\n+\n+    @Override\n+    public Byte nonNullRead(ColumnVector vector, int row) {\n+      return (byte) ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class BytesReader implements OrcValReader<byte[]> {\n+    private static final BytesReader INSTANCE = new BytesReader();\n+\n+    private BytesReader() {\n+    }\n+\n+    @Override\n+    public byte[] nonNullRead(ColumnVector vector, int row) {\n+      BytesColumnVector bytesVector = (BytesColumnVector) vector;\n+\n+      return Arrays.copyOfRange(\n+          bytesVector.vector[row], bytesVector.start[row], bytesVector.start[row] + bytesVector.length[row]);\n+    }\n+  }\n+\n+  public abstract static class StructReader<T> implements OrcValReader<T> {\n+    private final OrcValReader<?>[] readers;\n+    private final int[] positions;\n+    private final Object[] constants;\n+\n+    protected StructReader(List<OrcValReader<?>> readers) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY1Njc4NA=="}, "originalCommit": {"oid": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0"}, "originalPosition": 175}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYyNTAwMjEyOnYy", "diffSide": "RIGHT", "path": "orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QxNzowNDo1MFrOGSH99w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QxNzowNDo1MFrOGSH99w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY1ODEwMw==", "bodyText": "Why not pass the possibly reused object in here?", "url": "https://github.com/apache/iceberg/pull/989#discussion_r421658103", "createdAt": "2020-05-07T17:04:50Z", "author": {"login": "rdblue"}, "path": "orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.orc;\n+\n+import com.google.common.collect.Lists;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.types.Types;\n+import org.apache.orc.storage.ql.exec.vector.BytesColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.DoubleColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.LongColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.StructColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.VectorizedRowBatch;\n+\n+\n+public class OrcValueReaders {\n+  private OrcValueReaders() {\n+  }\n+\n+  public static OrcValReader<?> booleans() {\n+    return BooleanReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> shorts() {\n+    return ShortReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> ints() {\n+    return IntegerReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> longs() {\n+    return LongReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> floats() {\n+    return FloatReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> doubles() {\n+    return DoubleReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> bytes() {\n+    return BytesReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> byteReader() {\n+    return ByteReader.INSTANCE;\n+  }\n+\n+  private static class BooleanReader implements OrcValReader<Boolean> {\n+    static final OrcValReader<?> INSTANCE = new BooleanReader();\n+\n+    private BooleanReader() {\n+    }\n+\n+    @Override\n+    public Boolean nonNullRead(ColumnVector vector, int row) {\n+      return ((LongColumnVector) vector).vector[row] != 0;\n+    }\n+  }\n+\n+  private static class ShortReader implements OrcValReader<Short> {\n+    static final OrcValReader<?> INSTANCE = new ShortReader();\n+\n+    private ShortReader() {\n+    }\n+\n+    @Override\n+    public Short nonNullRead(ColumnVector vector, int row) {\n+      return (short) ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class IntegerReader implements OrcValReader<Integer> {\n+    static final OrcValReader<?> INSTANCE = new IntegerReader();\n+\n+    private IntegerReader() {\n+    }\n+\n+    @Override\n+    public Integer nonNullRead(ColumnVector vector, int row) {\n+      return (int) ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class LongReader implements OrcValReader<Long> {\n+    static final OrcValReader<?> INSTANCE = new LongReader();\n+\n+    private LongReader() {\n+    }\n+\n+    @Override\n+    public Long nonNullRead(ColumnVector vector, int row) {\n+      return ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class FloatReader implements OrcValReader<Float> {\n+    private static final FloatReader INSTANCE = new FloatReader();\n+\n+    private FloatReader() {\n+    }\n+\n+    @Override\n+    public Float nonNullRead(ColumnVector vector, int row) {\n+      return (float) ((DoubleColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class DoubleReader implements OrcValReader<Double> {\n+    private static final DoubleReader INSTANCE = new DoubleReader();\n+\n+    private DoubleReader() {\n+    }\n+\n+    @Override\n+    public Double nonNullRead(ColumnVector vector, int row) {\n+      return ((DoubleColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class ByteReader implements OrcValReader<Byte> {\n+    private static final ByteReader INSTANCE = new ByteReader();\n+\n+    private ByteReader() {\n+    }\n+\n+    @Override\n+    public Byte nonNullRead(ColumnVector vector, int row) {\n+      return (byte) ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class BytesReader implements OrcValReader<byte[]> {\n+    private static final BytesReader INSTANCE = new BytesReader();\n+\n+    private BytesReader() {\n+    }\n+\n+    @Override\n+    public byte[] nonNullRead(ColumnVector vector, int row) {\n+      BytesColumnVector bytesVector = (BytesColumnVector) vector;\n+\n+      return Arrays.copyOfRange(\n+          bytesVector.vector[row], bytesVector.start[row], bytesVector.start[row] + bytesVector.length[row]);\n+    }\n+  }\n+\n+  public abstract static class StructReader<T> implements OrcValReader<T> {\n+    private final OrcValReader<?>[] readers;\n+    private final int[] positions;\n+    private final Object[] constants;\n+\n+    protected StructReader(List<OrcValReader<?>> readers) {\n+      this.readers = readers.toArray(new OrcValReader[0]);\n+      this.positions = new int[0];\n+      this.constants = new Object[0];\n+    }\n+\n+    protected StructReader(List<OrcValReader<?>> readers, Types.StructType struct, Map<Integer, ?> idToConstant) {\n+      this.readers = readers.toArray(new OrcValReader[0]);\n+      List<Types.NestedField> fields = struct.fields();\n+      List<Integer> positionList = Lists.newArrayListWithCapacity(fields.size());\n+      List<Object> constantList = Lists.newArrayListWithCapacity(fields.size());\n+      for (int pos = 0; pos < fields.size(); pos += 1) {\n+        Types.NestedField field = fields.get(pos);\n+        Object constant = idToConstant.get(field.fieldId());\n+        if (constant != null) {\n+          positionList.add(pos);\n+          constantList.add(idToConstant.get(field.fieldId()));\n+        }\n+      }\n+\n+      this.positions = positionList.stream().mapToInt(Integer::intValue).toArray();\n+      this.constants = constantList.toArray();\n+    }\n+\n+    protected abstract T create();\n+\n+    protected abstract T reuseOrCreate();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0"}, "originalPosition": 201}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYyNTAyNjA3OnYy", "diffSide": "RIGHT", "path": "orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QxNzoxMToyNVrOGSIM6Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQwNzoxODozNlrOGZNITQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY2MTkyOQ==", "bodyText": "Instead of having an interface that uses VectorizedRowBatch, why not just have the top-level reader create a StructColumnVector and pass the batch's columns using that?\nYou can even make a reusable StructColumnVector to avoid needing to create a new one for every batch if you want:\n  class ReusableStructColumnVector extends StructColumnVector {\n    public ReusableStructColumnVector(int len, ColumnVector... fields) {\n      super(len, fields);\n    }\n\n    public ReusableStructColumnVector replaceVectors(ColumnVector[] fields) {\n      this.fields = fields;\n      return this;\n    }\n  }\nThen we'd only need one OrcValueReader interface.", "url": "https://github.com/apache/iceberg/pull/989#discussion_r421661929", "createdAt": "2020-05-07T17:11:25Z", "author": {"login": "rdblue"}, "path": "orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.orc;\n+\n+import com.google.common.collect.Lists;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.types.Types;\n+import org.apache.orc.storage.ql.exec.vector.BytesColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.DoubleColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.LongColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.StructColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.VectorizedRowBatch;\n+\n+\n+public class OrcValueReaders {\n+  private OrcValueReaders() {\n+  }\n+\n+  public static OrcValReader<?> booleans() {\n+    return BooleanReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> shorts() {\n+    return ShortReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> ints() {\n+    return IntegerReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> longs() {\n+    return LongReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> floats() {\n+    return FloatReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> doubles() {\n+    return DoubleReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> bytes() {\n+    return BytesReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> byteReader() {\n+    return ByteReader.INSTANCE;\n+  }\n+\n+  private static class BooleanReader implements OrcValReader<Boolean> {\n+    static final OrcValReader<?> INSTANCE = new BooleanReader();\n+\n+    private BooleanReader() {\n+    }\n+\n+    @Override\n+    public Boolean nonNullRead(ColumnVector vector, int row) {\n+      return ((LongColumnVector) vector).vector[row] != 0;\n+    }\n+  }\n+\n+  private static class ShortReader implements OrcValReader<Short> {\n+    static final OrcValReader<?> INSTANCE = new ShortReader();\n+\n+    private ShortReader() {\n+    }\n+\n+    @Override\n+    public Short nonNullRead(ColumnVector vector, int row) {\n+      return (short) ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class IntegerReader implements OrcValReader<Integer> {\n+    static final OrcValReader<?> INSTANCE = new IntegerReader();\n+\n+    private IntegerReader() {\n+    }\n+\n+    @Override\n+    public Integer nonNullRead(ColumnVector vector, int row) {\n+      return (int) ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class LongReader implements OrcValReader<Long> {\n+    static final OrcValReader<?> INSTANCE = new LongReader();\n+\n+    private LongReader() {\n+    }\n+\n+    @Override\n+    public Long nonNullRead(ColumnVector vector, int row) {\n+      return ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class FloatReader implements OrcValReader<Float> {\n+    private static final FloatReader INSTANCE = new FloatReader();\n+\n+    private FloatReader() {\n+    }\n+\n+    @Override\n+    public Float nonNullRead(ColumnVector vector, int row) {\n+      return (float) ((DoubleColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class DoubleReader implements OrcValReader<Double> {\n+    private static final DoubleReader INSTANCE = new DoubleReader();\n+\n+    private DoubleReader() {\n+    }\n+\n+    @Override\n+    public Double nonNullRead(ColumnVector vector, int row) {\n+      return ((DoubleColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class ByteReader implements OrcValReader<Byte> {\n+    private static final ByteReader INSTANCE = new ByteReader();\n+\n+    private ByteReader() {\n+    }\n+\n+    @Override\n+    public Byte nonNullRead(ColumnVector vector, int row) {\n+      return (byte) ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class BytesReader implements OrcValReader<byte[]> {\n+    private static final BytesReader INSTANCE = new BytesReader();\n+\n+    private BytesReader() {\n+    }\n+\n+    @Override\n+    public byte[] nonNullRead(ColumnVector vector, int row) {\n+      BytesColumnVector bytesVector = (BytesColumnVector) vector;\n+\n+      return Arrays.copyOfRange(\n+          bytesVector.vector[row], bytesVector.start[row], bytesVector.start[row] + bytesVector.length[row]);\n+    }\n+  }\n+\n+  public abstract static class StructReader<T> implements OrcValReader<T> {\n+    private final OrcValReader<?>[] readers;\n+    private final int[] positions;\n+    private final Object[] constants;\n+\n+    protected StructReader(List<OrcValReader<?>> readers) {\n+      this.readers = readers.toArray(new OrcValReader[0]);\n+      this.positions = new int[0];\n+      this.constants = new Object[0];\n+    }\n+\n+    protected StructReader(List<OrcValReader<?>> readers, Types.StructType struct, Map<Integer, ?> idToConstant) {\n+      this.readers = readers.toArray(new OrcValReader[0]);\n+      List<Types.NestedField> fields = struct.fields();\n+      List<Integer> positionList = Lists.newArrayListWithCapacity(fields.size());\n+      List<Object> constantList = Lists.newArrayListWithCapacity(fields.size());\n+      for (int pos = 0; pos < fields.size(); pos += 1) {\n+        Types.NestedField field = fields.get(pos);\n+        Object constant = idToConstant.get(field.fieldId());\n+        if (constant != null) {\n+          positionList.add(pos);\n+          constantList.add(idToConstant.get(field.fieldId()));\n+        }\n+      }\n+\n+      this.positions = positionList.stream().mapToInt(Integer::intValue).toArray();\n+      this.constants = constantList.toArray();\n+    }\n+\n+    protected abstract T create();\n+\n+    protected abstract T reuseOrCreate();\n+\n+    protected abstract void set(T struct, int pos, Object value);\n+\n+    public OrcValReader<?> reader(int pos) {\n+      return readers[pos];\n+    }\n+\n+    @Override\n+    public T nonNullRead(ColumnVector vector, int row) {\n+      StructColumnVector structVector = (StructColumnVector) vector;\n+      return readInternal(create(), structVector.fields, row);\n+    }\n+\n+    public T read(VectorizedRowBatch batch, int row) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0"}, "originalPosition": 215}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTkyMTA2OQ==", "bodyText": "I think I did what you are suggesting before, but ran into issues. Let me try again to get the actual erorr.", "url": "https://github.com/apache/iceberg/pull/989#discussion_r421921069", "createdAt": "2020-05-08T03:48:28Z", "author": {"login": "rdsr"}, "path": "orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.orc;\n+\n+import com.google.common.collect.Lists;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.types.Types;\n+import org.apache.orc.storage.ql.exec.vector.BytesColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.DoubleColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.LongColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.StructColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.VectorizedRowBatch;\n+\n+\n+public class OrcValueReaders {\n+  private OrcValueReaders() {\n+  }\n+\n+  public static OrcValReader<?> booleans() {\n+    return BooleanReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> shorts() {\n+    return ShortReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> ints() {\n+    return IntegerReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> longs() {\n+    return LongReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> floats() {\n+    return FloatReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> doubles() {\n+    return DoubleReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> bytes() {\n+    return BytesReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> byteReader() {\n+    return ByteReader.INSTANCE;\n+  }\n+\n+  private static class BooleanReader implements OrcValReader<Boolean> {\n+    static final OrcValReader<?> INSTANCE = new BooleanReader();\n+\n+    private BooleanReader() {\n+    }\n+\n+    @Override\n+    public Boolean nonNullRead(ColumnVector vector, int row) {\n+      return ((LongColumnVector) vector).vector[row] != 0;\n+    }\n+  }\n+\n+  private static class ShortReader implements OrcValReader<Short> {\n+    static final OrcValReader<?> INSTANCE = new ShortReader();\n+\n+    private ShortReader() {\n+    }\n+\n+    @Override\n+    public Short nonNullRead(ColumnVector vector, int row) {\n+      return (short) ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class IntegerReader implements OrcValReader<Integer> {\n+    static final OrcValReader<?> INSTANCE = new IntegerReader();\n+\n+    private IntegerReader() {\n+    }\n+\n+    @Override\n+    public Integer nonNullRead(ColumnVector vector, int row) {\n+      return (int) ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class LongReader implements OrcValReader<Long> {\n+    static final OrcValReader<?> INSTANCE = new LongReader();\n+\n+    private LongReader() {\n+    }\n+\n+    @Override\n+    public Long nonNullRead(ColumnVector vector, int row) {\n+      return ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class FloatReader implements OrcValReader<Float> {\n+    private static final FloatReader INSTANCE = new FloatReader();\n+\n+    private FloatReader() {\n+    }\n+\n+    @Override\n+    public Float nonNullRead(ColumnVector vector, int row) {\n+      return (float) ((DoubleColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class DoubleReader implements OrcValReader<Double> {\n+    private static final DoubleReader INSTANCE = new DoubleReader();\n+\n+    private DoubleReader() {\n+    }\n+\n+    @Override\n+    public Double nonNullRead(ColumnVector vector, int row) {\n+      return ((DoubleColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class ByteReader implements OrcValReader<Byte> {\n+    private static final ByteReader INSTANCE = new ByteReader();\n+\n+    private ByteReader() {\n+    }\n+\n+    @Override\n+    public Byte nonNullRead(ColumnVector vector, int row) {\n+      return (byte) ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class BytesReader implements OrcValReader<byte[]> {\n+    private static final BytesReader INSTANCE = new BytesReader();\n+\n+    private BytesReader() {\n+    }\n+\n+    @Override\n+    public byte[] nonNullRead(ColumnVector vector, int row) {\n+      BytesColumnVector bytesVector = (BytesColumnVector) vector;\n+\n+      return Arrays.copyOfRange(\n+          bytesVector.vector[row], bytesVector.start[row], bytesVector.start[row] + bytesVector.length[row]);\n+    }\n+  }\n+\n+  public abstract static class StructReader<T> implements OrcValReader<T> {\n+    private final OrcValReader<?>[] readers;\n+    private final int[] positions;\n+    private final Object[] constants;\n+\n+    protected StructReader(List<OrcValReader<?>> readers) {\n+      this.readers = readers.toArray(new OrcValReader[0]);\n+      this.positions = new int[0];\n+      this.constants = new Object[0];\n+    }\n+\n+    protected StructReader(List<OrcValReader<?>> readers, Types.StructType struct, Map<Integer, ?> idToConstant) {\n+      this.readers = readers.toArray(new OrcValReader[0]);\n+      List<Types.NestedField> fields = struct.fields();\n+      List<Integer> positionList = Lists.newArrayListWithCapacity(fields.size());\n+      List<Object> constantList = Lists.newArrayListWithCapacity(fields.size());\n+      for (int pos = 0; pos < fields.size(); pos += 1) {\n+        Types.NestedField field = fields.get(pos);\n+        Object constant = idToConstant.get(field.fieldId());\n+        if (constant != null) {\n+          positionList.add(pos);\n+          constantList.add(idToConstant.get(field.fieldId()));\n+        }\n+      }\n+\n+      this.positions = positionList.stream().mapToInt(Integer::intValue).toArray();\n+      this.constants = constantList.toArray();\n+    }\n+\n+    protected abstract T create();\n+\n+    protected abstract T reuseOrCreate();\n+\n+    protected abstract void set(T struct, int pos, Object value);\n+\n+    public OrcValReader<?> reader(int pos) {\n+      return readers[pos];\n+    }\n+\n+    @Override\n+    public T nonNullRead(ColumnVector vector, int row) {\n+      StructColumnVector structVector = (StructColumnVector) vector;\n+      return readInternal(create(), structVector.fields, row);\n+    }\n+\n+    public T read(VectorizedRowBatch batch, int row) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY2MTkyOQ=="}, "originalCommit": {"oid": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0"}, "originalPosition": 215}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA4MjcwMQ==", "bodyText": "It worked this time.", "url": "https://github.com/apache/iceberg/pull/989#discussion_r429082701", "createdAt": "2020-05-22T07:18:36Z", "author": {"login": "rdsr"}, "path": "orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.orc;\n+\n+import com.google.common.collect.Lists;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.types.Types;\n+import org.apache.orc.storage.ql.exec.vector.BytesColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.DoubleColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.LongColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.StructColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.VectorizedRowBatch;\n+\n+\n+public class OrcValueReaders {\n+  private OrcValueReaders() {\n+  }\n+\n+  public static OrcValReader<?> booleans() {\n+    return BooleanReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> shorts() {\n+    return ShortReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> ints() {\n+    return IntegerReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> longs() {\n+    return LongReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> floats() {\n+    return FloatReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> doubles() {\n+    return DoubleReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> bytes() {\n+    return BytesReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> byteReader() {\n+    return ByteReader.INSTANCE;\n+  }\n+\n+  private static class BooleanReader implements OrcValReader<Boolean> {\n+    static final OrcValReader<?> INSTANCE = new BooleanReader();\n+\n+    private BooleanReader() {\n+    }\n+\n+    @Override\n+    public Boolean nonNullRead(ColumnVector vector, int row) {\n+      return ((LongColumnVector) vector).vector[row] != 0;\n+    }\n+  }\n+\n+  private static class ShortReader implements OrcValReader<Short> {\n+    static final OrcValReader<?> INSTANCE = new ShortReader();\n+\n+    private ShortReader() {\n+    }\n+\n+    @Override\n+    public Short nonNullRead(ColumnVector vector, int row) {\n+      return (short) ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class IntegerReader implements OrcValReader<Integer> {\n+    static final OrcValReader<?> INSTANCE = new IntegerReader();\n+\n+    private IntegerReader() {\n+    }\n+\n+    @Override\n+    public Integer nonNullRead(ColumnVector vector, int row) {\n+      return (int) ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class LongReader implements OrcValReader<Long> {\n+    static final OrcValReader<?> INSTANCE = new LongReader();\n+\n+    private LongReader() {\n+    }\n+\n+    @Override\n+    public Long nonNullRead(ColumnVector vector, int row) {\n+      return ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class FloatReader implements OrcValReader<Float> {\n+    private static final FloatReader INSTANCE = new FloatReader();\n+\n+    private FloatReader() {\n+    }\n+\n+    @Override\n+    public Float nonNullRead(ColumnVector vector, int row) {\n+      return (float) ((DoubleColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class DoubleReader implements OrcValReader<Double> {\n+    private static final DoubleReader INSTANCE = new DoubleReader();\n+\n+    private DoubleReader() {\n+    }\n+\n+    @Override\n+    public Double nonNullRead(ColumnVector vector, int row) {\n+      return ((DoubleColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class ByteReader implements OrcValReader<Byte> {\n+    private static final ByteReader INSTANCE = new ByteReader();\n+\n+    private ByteReader() {\n+    }\n+\n+    @Override\n+    public Byte nonNullRead(ColumnVector vector, int row) {\n+      return (byte) ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class BytesReader implements OrcValReader<byte[]> {\n+    private static final BytesReader INSTANCE = new BytesReader();\n+\n+    private BytesReader() {\n+    }\n+\n+    @Override\n+    public byte[] nonNullRead(ColumnVector vector, int row) {\n+      BytesColumnVector bytesVector = (BytesColumnVector) vector;\n+\n+      return Arrays.copyOfRange(\n+          bytesVector.vector[row], bytesVector.start[row], bytesVector.start[row] + bytesVector.length[row]);\n+    }\n+  }\n+\n+  public abstract static class StructReader<T> implements OrcValReader<T> {\n+    private final OrcValReader<?>[] readers;\n+    private final int[] positions;\n+    private final Object[] constants;\n+\n+    protected StructReader(List<OrcValReader<?>> readers) {\n+      this.readers = readers.toArray(new OrcValReader[0]);\n+      this.positions = new int[0];\n+      this.constants = new Object[0];\n+    }\n+\n+    protected StructReader(List<OrcValReader<?>> readers, Types.StructType struct, Map<Integer, ?> idToConstant) {\n+      this.readers = readers.toArray(new OrcValReader[0]);\n+      List<Types.NestedField> fields = struct.fields();\n+      List<Integer> positionList = Lists.newArrayListWithCapacity(fields.size());\n+      List<Object> constantList = Lists.newArrayListWithCapacity(fields.size());\n+      for (int pos = 0; pos < fields.size(); pos += 1) {\n+        Types.NestedField field = fields.get(pos);\n+        Object constant = idToConstant.get(field.fieldId());\n+        if (constant != null) {\n+          positionList.add(pos);\n+          constantList.add(idToConstant.get(field.fieldId()));\n+        }\n+      }\n+\n+      this.positions = positionList.stream().mapToInt(Integer::intValue).toArray();\n+      this.constants = constantList.toArray();\n+    }\n+\n+    protected abstract T create();\n+\n+    protected abstract T reuseOrCreate();\n+\n+    protected abstract void set(T struct, int pos, Object value);\n+\n+    public OrcValReader<?> reader(int pos) {\n+      return readers[pos];\n+    }\n+\n+    @Override\n+    public T nonNullRead(ColumnVector vector, int row) {\n+      StructColumnVector structVector = (StructColumnVector) vector;\n+      return readInternal(create(), structVector.fields, row);\n+    }\n+\n+    public T read(VectorizedRowBatch batch, int row) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY2MTkyOQ=="}, "originalCommit": {"oid": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0"}, "originalPosition": 215}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYyNTAzMDI1OnYy", "diffSide": "RIGHT", "path": "orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QxNzoxMjo0NFrOGSIPxA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QxNzoxMjo0NFrOGSIPxA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY2MjY2MA==", "bodyText": "These factory methods can declare the type they return, like OrcValueReader<byte[]>.", "url": "https://github.com/apache/iceberg/pull/989#discussion_r421662660", "createdAt": "2020-05-07T17:12:44Z", "author": {"login": "rdblue"}, "path": "orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.orc;\n+\n+import com.google.common.collect.Lists;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.types.Types;\n+import org.apache.orc.storage.ql.exec.vector.BytesColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.DoubleColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.LongColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.StructColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.VectorizedRowBatch;\n+\n+\n+public class OrcValueReaders {\n+  private OrcValueReaders() {\n+  }\n+\n+  public static OrcValReader<?> booleans() {\n+    return BooleanReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> shorts() {\n+    return ShortReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> ints() {\n+    return IntegerReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> longs() {\n+    return LongReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> floats() {\n+    return FloatReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> doubles() {\n+    return DoubleReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> bytes() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0"}, "originalPosition": 63}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYyNTA0NzU0OnYy", "diffSide": "RIGHT", "path": "orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QxNzoxNzozMlrOGSIarw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQxNTo1NDowNFrOGZcF1A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY2NTQ1NQ==", "bodyText": "You might consider a different approach. This currently mirrors what happens in Avro, where the constants are set after reading a record. That is done because Avro can't skip fields easily -- it needs to read through a value even if the value won't be used.\nBut columnar formats can easily skip. That's why in Parquet, we replace the column reader with a constant reader. So the struct reader behaves exactly like normal and reads a value from every child reader. But some of those children might ignore what's in the data file and return a constant. That should be more efficient because you're not materializing columns you don't need to.", "url": "https://github.com/apache/iceberg/pull/989#discussion_r421665455", "createdAt": "2020-05-07T17:17:32Z", "author": {"login": "rdblue"}, "path": "orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.orc;\n+\n+import com.google.common.collect.Lists;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.types.Types;\n+import org.apache.orc.storage.ql.exec.vector.BytesColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.DoubleColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.LongColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.StructColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.VectorizedRowBatch;\n+\n+\n+public class OrcValueReaders {\n+  private OrcValueReaders() {\n+  }\n+\n+  public static OrcValReader<?> booleans() {\n+    return BooleanReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> shorts() {\n+    return ShortReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> ints() {\n+    return IntegerReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> longs() {\n+    return LongReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> floats() {\n+    return FloatReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> doubles() {\n+    return DoubleReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> bytes() {\n+    return BytesReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> byteReader() {\n+    return ByteReader.INSTANCE;\n+  }\n+\n+  private static class BooleanReader implements OrcValReader<Boolean> {\n+    static final OrcValReader<?> INSTANCE = new BooleanReader();\n+\n+    private BooleanReader() {\n+    }\n+\n+    @Override\n+    public Boolean nonNullRead(ColumnVector vector, int row) {\n+      return ((LongColumnVector) vector).vector[row] != 0;\n+    }\n+  }\n+\n+  private static class ShortReader implements OrcValReader<Short> {\n+    static final OrcValReader<?> INSTANCE = new ShortReader();\n+\n+    private ShortReader() {\n+    }\n+\n+    @Override\n+    public Short nonNullRead(ColumnVector vector, int row) {\n+      return (short) ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class IntegerReader implements OrcValReader<Integer> {\n+    static final OrcValReader<?> INSTANCE = new IntegerReader();\n+\n+    private IntegerReader() {\n+    }\n+\n+    @Override\n+    public Integer nonNullRead(ColumnVector vector, int row) {\n+      return (int) ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class LongReader implements OrcValReader<Long> {\n+    static final OrcValReader<?> INSTANCE = new LongReader();\n+\n+    private LongReader() {\n+    }\n+\n+    @Override\n+    public Long nonNullRead(ColumnVector vector, int row) {\n+      return ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class FloatReader implements OrcValReader<Float> {\n+    private static final FloatReader INSTANCE = new FloatReader();\n+\n+    private FloatReader() {\n+    }\n+\n+    @Override\n+    public Float nonNullRead(ColumnVector vector, int row) {\n+      return (float) ((DoubleColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class DoubleReader implements OrcValReader<Double> {\n+    private static final DoubleReader INSTANCE = new DoubleReader();\n+\n+    private DoubleReader() {\n+    }\n+\n+    @Override\n+    public Double nonNullRead(ColumnVector vector, int row) {\n+      return ((DoubleColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class ByteReader implements OrcValReader<Byte> {\n+    private static final ByteReader INSTANCE = new ByteReader();\n+\n+    private ByteReader() {\n+    }\n+\n+    @Override\n+    public Byte nonNullRead(ColumnVector vector, int row) {\n+      return (byte) ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class BytesReader implements OrcValReader<byte[]> {\n+    private static final BytesReader INSTANCE = new BytesReader();\n+\n+    private BytesReader() {\n+    }\n+\n+    @Override\n+    public byte[] nonNullRead(ColumnVector vector, int row) {\n+      BytesColumnVector bytesVector = (BytesColumnVector) vector;\n+\n+      return Arrays.copyOfRange(\n+          bytesVector.vector[row], bytesVector.start[row], bytesVector.start[row] + bytesVector.length[row]);\n+    }\n+  }\n+\n+  public abstract static class StructReader<T> implements OrcValReader<T> {\n+    private final OrcValReader<?>[] readers;\n+    private final int[] positions;\n+    private final Object[] constants;\n+\n+    protected StructReader(List<OrcValReader<?>> readers) {\n+      this.readers = readers.toArray(new OrcValReader[0]);\n+      this.positions = new int[0];\n+      this.constants = new Object[0];\n+    }\n+\n+    protected StructReader(List<OrcValReader<?>> readers, Types.StructType struct, Map<Integer, ?> idToConstant) {\n+      this.readers = readers.toArray(new OrcValReader[0]);\n+      List<Types.NestedField> fields = struct.fields();\n+      List<Integer> positionList = Lists.newArrayListWithCapacity(fields.size());\n+      List<Object> constantList = Lists.newArrayListWithCapacity(fields.size());\n+      for (int pos = 0; pos < fields.size(); pos += 1) {\n+        Types.NestedField field = fields.get(pos);\n+        Object constant = idToConstant.get(field.fieldId());\n+        if (constant != null) {\n+          positionList.add(pos);\n+          constantList.add(idToConstant.get(field.fieldId()));\n+        }\n+      }\n+\n+      this.positions = positionList.stream().mapToInt(Integer::intValue).toArray();\n+      this.constants = constantList.toArray();\n+    }\n+\n+    protected abstract T create();\n+\n+    protected abstract T reuseOrCreate();\n+\n+    protected abstract void set(T struct, int pos, Object value);\n+\n+    public OrcValReader<?> reader(int pos) {\n+      return readers[pos];\n+    }\n+\n+    @Override\n+    public T nonNullRead(ColumnVector vector, int row) {\n+      StructColumnVector structVector = (StructColumnVector) vector;\n+      return readInternal(create(), structVector.fields, row);\n+    }\n+\n+    public T read(VectorizedRowBatch batch, int row) {\n+      return readInternal(reuseOrCreate(), batch.cols, row);\n+    }\n+\n+    private T readInternal(T struct, ColumnVector[] columnVectors, int row) {\n+      for (int c = 0; c < readers.length; ++c) {\n+        set(struct, c, reader(c).read(columnVectors[c], row));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0"}, "originalPosition": 221}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA4MjYwNg==", "bodyText": "Is is ok if I tackle this in followup?", "url": "https://github.com/apache/iceberg/pull/989#discussion_r429082606", "createdAt": "2020-05-22T07:18:19Z", "author": {"login": "rdsr"}, "path": "orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.orc;\n+\n+import com.google.common.collect.Lists;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.types.Types;\n+import org.apache.orc.storage.ql.exec.vector.BytesColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.DoubleColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.LongColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.StructColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.VectorizedRowBatch;\n+\n+\n+public class OrcValueReaders {\n+  private OrcValueReaders() {\n+  }\n+\n+  public static OrcValReader<?> booleans() {\n+    return BooleanReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> shorts() {\n+    return ShortReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> ints() {\n+    return IntegerReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> longs() {\n+    return LongReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> floats() {\n+    return FloatReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> doubles() {\n+    return DoubleReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> bytes() {\n+    return BytesReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> byteReader() {\n+    return ByteReader.INSTANCE;\n+  }\n+\n+  private static class BooleanReader implements OrcValReader<Boolean> {\n+    static final OrcValReader<?> INSTANCE = new BooleanReader();\n+\n+    private BooleanReader() {\n+    }\n+\n+    @Override\n+    public Boolean nonNullRead(ColumnVector vector, int row) {\n+      return ((LongColumnVector) vector).vector[row] != 0;\n+    }\n+  }\n+\n+  private static class ShortReader implements OrcValReader<Short> {\n+    static final OrcValReader<?> INSTANCE = new ShortReader();\n+\n+    private ShortReader() {\n+    }\n+\n+    @Override\n+    public Short nonNullRead(ColumnVector vector, int row) {\n+      return (short) ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class IntegerReader implements OrcValReader<Integer> {\n+    static final OrcValReader<?> INSTANCE = new IntegerReader();\n+\n+    private IntegerReader() {\n+    }\n+\n+    @Override\n+    public Integer nonNullRead(ColumnVector vector, int row) {\n+      return (int) ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class LongReader implements OrcValReader<Long> {\n+    static final OrcValReader<?> INSTANCE = new LongReader();\n+\n+    private LongReader() {\n+    }\n+\n+    @Override\n+    public Long nonNullRead(ColumnVector vector, int row) {\n+      return ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class FloatReader implements OrcValReader<Float> {\n+    private static final FloatReader INSTANCE = new FloatReader();\n+\n+    private FloatReader() {\n+    }\n+\n+    @Override\n+    public Float nonNullRead(ColumnVector vector, int row) {\n+      return (float) ((DoubleColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class DoubleReader implements OrcValReader<Double> {\n+    private static final DoubleReader INSTANCE = new DoubleReader();\n+\n+    private DoubleReader() {\n+    }\n+\n+    @Override\n+    public Double nonNullRead(ColumnVector vector, int row) {\n+      return ((DoubleColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class ByteReader implements OrcValReader<Byte> {\n+    private static final ByteReader INSTANCE = new ByteReader();\n+\n+    private ByteReader() {\n+    }\n+\n+    @Override\n+    public Byte nonNullRead(ColumnVector vector, int row) {\n+      return (byte) ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class BytesReader implements OrcValReader<byte[]> {\n+    private static final BytesReader INSTANCE = new BytesReader();\n+\n+    private BytesReader() {\n+    }\n+\n+    @Override\n+    public byte[] nonNullRead(ColumnVector vector, int row) {\n+      BytesColumnVector bytesVector = (BytesColumnVector) vector;\n+\n+      return Arrays.copyOfRange(\n+          bytesVector.vector[row], bytesVector.start[row], bytesVector.start[row] + bytesVector.length[row]);\n+    }\n+  }\n+\n+  public abstract static class StructReader<T> implements OrcValReader<T> {\n+    private final OrcValReader<?>[] readers;\n+    private final int[] positions;\n+    private final Object[] constants;\n+\n+    protected StructReader(List<OrcValReader<?>> readers) {\n+      this.readers = readers.toArray(new OrcValReader[0]);\n+      this.positions = new int[0];\n+      this.constants = new Object[0];\n+    }\n+\n+    protected StructReader(List<OrcValReader<?>> readers, Types.StructType struct, Map<Integer, ?> idToConstant) {\n+      this.readers = readers.toArray(new OrcValReader[0]);\n+      List<Types.NestedField> fields = struct.fields();\n+      List<Integer> positionList = Lists.newArrayListWithCapacity(fields.size());\n+      List<Object> constantList = Lists.newArrayListWithCapacity(fields.size());\n+      for (int pos = 0; pos < fields.size(); pos += 1) {\n+        Types.NestedField field = fields.get(pos);\n+        Object constant = idToConstant.get(field.fieldId());\n+        if (constant != null) {\n+          positionList.add(pos);\n+          constantList.add(idToConstant.get(field.fieldId()));\n+        }\n+      }\n+\n+      this.positions = positionList.stream().mapToInt(Integer::intValue).toArray();\n+      this.constants = constantList.toArray();\n+    }\n+\n+    protected abstract T create();\n+\n+    protected abstract T reuseOrCreate();\n+\n+    protected abstract void set(T struct, int pos, Object value);\n+\n+    public OrcValReader<?> reader(int pos) {\n+      return readers[pos];\n+    }\n+\n+    @Override\n+    public T nonNullRead(ColumnVector vector, int row) {\n+      StructColumnVector structVector = (StructColumnVector) vector;\n+      return readInternal(create(), structVector.fields, row);\n+    }\n+\n+    public T read(VectorizedRowBatch batch, int row) {\n+      return readInternal(reuseOrCreate(), batch.cols, row);\n+    }\n+\n+    private T readInternal(T struct, ColumnVector[] columnVectors, int row) {\n+      for (int c = 0; c < readers.length; ++c) {\n+        set(struct, c, reader(c).read(columnVectors[c], row));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY2NTQ1NQ=="}, "originalCommit": {"oid": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0"}, "originalPosition": 221}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTMyNzgyOA==", "bodyText": "Yeah, that sounds good.", "url": "https://github.com/apache/iceberg/pull/989#discussion_r429327828", "createdAt": "2020-05-22T15:54:04Z", "author": {"login": "rdblue"}, "path": "orc/src/main/java/org/apache/iceberg/orc/OrcValueReaders.java", "diffHunk": "@@ -0,0 +1,231 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.orc;\n+\n+import com.google.common.collect.Lists;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.types.Types;\n+import org.apache.orc.storage.ql.exec.vector.BytesColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.DoubleColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.LongColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.StructColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.VectorizedRowBatch;\n+\n+\n+public class OrcValueReaders {\n+  private OrcValueReaders() {\n+  }\n+\n+  public static OrcValReader<?> booleans() {\n+    return BooleanReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> shorts() {\n+    return ShortReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> ints() {\n+    return IntegerReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> longs() {\n+    return LongReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> floats() {\n+    return FloatReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> doubles() {\n+    return DoubleReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> bytes() {\n+    return BytesReader.INSTANCE;\n+  }\n+\n+  public static OrcValReader<?> byteReader() {\n+    return ByteReader.INSTANCE;\n+  }\n+\n+  private static class BooleanReader implements OrcValReader<Boolean> {\n+    static final OrcValReader<?> INSTANCE = new BooleanReader();\n+\n+    private BooleanReader() {\n+    }\n+\n+    @Override\n+    public Boolean nonNullRead(ColumnVector vector, int row) {\n+      return ((LongColumnVector) vector).vector[row] != 0;\n+    }\n+  }\n+\n+  private static class ShortReader implements OrcValReader<Short> {\n+    static final OrcValReader<?> INSTANCE = new ShortReader();\n+\n+    private ShortReader() {\n+    }\n+\n+    @Override\n+    public Short nonNullRead(ColumnVector vector, int row) {\n+      return (short) ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class IntegerReader implements OrcValReader<Integer> {\n+    static final OrcValReader<?> INSTANCE = new IntegerReader();\n+\n+    private IntegerReader() {\n+    }\n+\n+    @Override\n+    public Integer nonNullRead(ColumnVector vector, int row) {\n+      return (int) ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class LongReader implements OrcValReader<Long> {\n+    static final OrcValReader<?> INSTANCE = new LongReader();\n+\n+    private LongReader() {\n+    }\n+\n+    @Override\n+    public Long nonNullRead(ColumnVector vector, int row) {\n+      return ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class FloatReader implements OrcValReader<Float> {\n+    private static final FloatReader INSTANCE = new FloatReader();\n+\n+    private FloatReader() {\n+    }\n+\n+    @Override\n+    public Float nonNullRead(ColumnVector vector, int row) {\n+      return (float) ((DoubleColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class DoubleReader implements OrcValReader<Double> {\n+    private static final DoubleReader INSTANCE = new DoubleReader();\n+\n+    private DoubleReader() {\n+    }\n+\n+    @Override\n+    public Double nonNullRead(ColumnVector vector, int row) {\n+      return ((DoubleColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class ByteReader implements OrcValReader<Byte> {\n+    private static final ByteReader INSTANCE = new ByteReader();\n+\n+    private ByteReader() {\n+    }\n+\n+    @Override\n+    public Byte nonNullRead(ColumnVector vector, int row) {\n+      return (byte) ((LongColumnVector) vector).vector[row];\n+    }\n+  }\n+\n+  private static class BytesReader implements OrcValReader<byte[]> {\n+    private static final BytesReader INSTANCE = new BytesReader();\n+\n+    private BytesReader() {\n+    }\n+\n+    @Override\n+    public byte[] nonNullRead(ColumnVector vector, int row) {\n+      BytesColumnVector bytesVector = (BytesColumnVector) vector;\n+\n+      return Arrays.copyOfRange(\n+          bytesVector.vector[row], bytesVector.start[row], bytesVector.start[row] + bytesVector.length[row]);\n+    }\n+  }\n+\n+  public abstract static class StructReader<T> implements OrcValReader<T> {\n+    private final OrcValReader<?>[] readers;\n+    private final int[] positions;\n+    private final Object[] constants;\n+\n+    protected StructReader(List<OrcValReader<?>> readers) {\n+      this.readers = readers.toArray(new OrcValReader[0]);\n+      this.positions = new int[0];\n+      this.constants = new Object[0];\n+    }\n+\n+    protected StructReader(List<OrcValReader<?>> readers, Types.StructType struct, Map<Integer, ?> idToConstant) {\n+      this.readers = readers.toArray(new OrcValReader[0]);\n+      List<Types.NestedField> fields = struct.fields();\n+      List<Integer> positionList = Lists.newArrayListWithCapacity(fields.size());\n+      List<Object> constantList = Lists.newArrayListWithCapacity(fields.size());\n+      for (int pos = 0; pos < fields.size(); pos += 1) {\n+        Types.NestedField field = fields.get(pos);\n+        Object constant = idToConstant.get(field.fieldId());\n+        if (constant != null) {\n+          positionList.add(pos);\n+          constantList.add(idToConstant.get(field.fieldId()));\n+        }\n+      }\n+\n+      this.positions = positionList.stream().mapToInt(Integer::intValue).toArray();\n+      this.constants = constantList.toArray();\n+    }\n+\n+    protected abstract T create();\n+\n+    protected abstract T reuseOrCreate();\n+\n+    protected abstract void set(T struct, int pos, Object value);\n+\n+    public OrcValReader<?> reader(int pos) {\n+      return readers[pos];\n+    }\n+\n+    @Override\n+    public T nonNullRead(ColumnVector vector, int row) {\n+      StructColumnVector structVector = (StructColumnVector) vector;\n+      return readInternal(create(), structVector.fields, row);\n+    }\n+\n+    public T read(VectorizedRowBatch batch, int row) {\n+      return readInternal(reuseOrCreate(), batch.cols, row);\n+    }\n+\n+    private T readInternal(T struct, ColumnVector[] columnVectors, int row) {\n+      for (int c = 0; c < readers.length; ++c) {\n+        set(struct, c, reader(c).read(columnVectors[c], row));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY2NTQ1NQ=="}, "originalCommit": {"oid": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0"}, "originalPosition": 221}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYyNTA1MDQ2OnYy", "diffSide": "RIGHT", "path": "spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcReader.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QxNzoxODoyMVrOGSIcmw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QxNzoxODoyMVrOGSIcmw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY2NTk0Nw==", "bodyText": "Minor: we prefer to use this.reader = when assigning to instance fields so it's clear that it is setting a field.", "url": "https://github.com/apache/iceberg/pull/989#discussion_r421665947", "createdAt": "2020-05-07T17:18:21Z", "author": {"login": "rdblue"}, "path": "spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcReader.java", "diffHunk": "@@ -53,425 +40,83 @@\n  * It minimizes allocations by reusing most of the objects in the implementation.\n  */\n public class SparkOrcReader implements OrcValueReader<InternalRow> {\n-  private static final int INITIAL_SIZE = 128 * 1024;\n-  private final List<TypeDescription> columns;\n-  private final Converter[] converters;\n-  private final UnsafeRowWriter rowWriter;\n+  private final SparkOrcValueReaders.StructReader reader;\n \n-  public SparkOrcReader(TypeDescription readOrcSchema) {\n-    columns = readOrcSchema.getChildren();\n-    converters = buildConverters();\n-    rowWriter = new UnsafeRowWriter(columns.size(), INITIAL_SIZE);\n+  public SparkOrcReader(org.apache.iceberg.Schema expectedSchema, TypeDescription readSchema) {\n+    this(expectedSchema, readSchema, ImmutableMap.of());\n   }\n \n-  private Converter[] buildConverters() {\n-    final Converter[] newConverters = new Converter[columns.size()];\n-    for (int c = 0; c < newConverters.length; ++c) {\n-      newConverters[c] = buildConverter(columns.get(c));\n-    }\n-    return newConverters;\n+  @SuppressWarnings(\"unchecked\")\n+  public SparkOrcReader(\n+      org.apache.iceberg.Schema expectedSchema, TypeDescription readOrcSchema, Map<Integer, ?> idToConstant) {\n+    reader = (SparkOrcValueReaders.StructReader) OrcSchemaWithTypeVisitor.visit(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0"}, "originalPosition": 67}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYyNTA1MzYyOnYy", "diffSide": "RIGHT", "path": "spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcReader.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QxNzoxOToxMlrOGSIeng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQwNzoxNzo1N1rOGZNHYQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY2NjQ2Mg==", "bodyText": "This is where you could wrap the columns from VectorizedRowBatch in a StructColumnVector.", "url": "https://github.com/apache/iceberg/pull/989#discussion_r421666462", "createdAt": "2020-05-07T17:19:12Z", "author": {"login": "rdblue"}, "path": "spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcReader.java", "diffHunk": "@@ -53,425 +40,83 @@\n  * It minimizes allocations by reusing most of the objects in the implementation.\n  */\n public class SparkOrcReader implements OrcValueReader<InternalRow> {\n-  private static final int INITIAL_SIZE = 128 * 1024;\n-  private final List<TypeDescription> columns;\n-  private final Converter[] converters;\n-  private final UnsafeRowWriter rowWriter;\n+  private final SparkOrcValueReaders.StructReader reader;\n \n-  public SparkOrcReader(TypeDescription readOrcSchema) {\n-    columns = readOrcSchema.getChildren();\n-    converters = buildConverters();\n-    rowWriter = new UnsafeRowWriter(columns.size(), INITIAL_SIZE);\n+  public SparkOrcReader(org.apache.iceberg.Schema expectedSchema, TypeDescription readSchema) {\n+    this(expectedSchema, readSchema, ImmutableMap.of());\n   }\n \n-  private Converter[] buildConverters() {\n-    final Converter[] newConverters = new Converter[columns.size()];\n-    for (int c = 0; c < newConverters.length; ++c) {\n-      newConverters[c] = buildConverter(columns.get(c));\n-    }\n-    return newConverters;\n+  @SuppressWarnings(\"unchecked\")\n+  public SparkOrcReader(\n+      org.apache.iceberg.Schema expectedSchema, TypeDescription readOrcSchema, Map<Integer, ?> idToConstant) {\n+    reader = (SparkOrcValueReaders.StructReader) OrcSchemaWithTypeVisitor.visit(\n+        expectedSchema, readOrcSchema, new ReadBuilder(idToConstant));\n   }\n \n   @Override\n   public InternalRow read(VectorizedRowBatch batch, int row) {\n-    rowWriter.reset();\n-    rowWriter.zeroOutNullBytes();\n-    for (int c = 0; c < batch.cols.length; ++c) {\n-      converters[c].convert(rowWriter, c, batch.cols[c], row);\n-    }\n-    return rowWriter.getRow();\n+    return reader.read(batch, row);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA4MjQ2NQ==", "bodyText": "It worked!", "url": "https://github.com/apache/iceberg/pull/989#discussion_r429082465", "createdAt": "2020-05-22T07:17:57Z", "author": {"login": "rdsr"}, "path": "spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcReader.java", "diffHunk": "@@ -53,425 +40,83 @@\n  * It minimizes allocations by reusing most of the objects in the implementation.\n  */\n public class SparkOrcReader implements OrcValueReader<InternalRow> {\n-  private static final int INITIAL_SIZE = 128 * 1024;\n-  private final List<TypeDescription> columns;\n-  private final Converter[] converters;\n-  private final UnsafeRowWriter rowWriter;\n+  private final SparkOrcValueReaders.StructReader reader;\n \n-  public SparkOrcReader(TypeDescription readOrcSchema) {\n-    columns = readOrcSchema.getChildren();\n-    converters = buildConverters();\n-    rowWriter = new UnsafeRowWriter(columns.size(), INITIAL_SIZE);\n+  public SparkOrcReader(org.apache.iceberg.Schema expectedSchema, TypeDescription readSchema) {\n+    this(expectedSchema, readSchema, ImmutableMap.of());\n   }\n \n-  private Converter[] buildConverters() {\n-    final Converter[] newConverters = new Converter[columns.size()];\n-    for (int c = 0; c < newConverters.length; ++c) {\n-      newConverters[c] = buildConverter(columns.get(c));\n-    }\n-    return newConverters;\n+  @SuppressWarnings(\"unchecked\")\n+  public SparkOrcReader(\n+      org.apache.iceberg.Schema expectedSchema, TypeDescription readOrcSchema, Map<Integer, ?> idToConstant) {\n+    reader = (SparkOrcValueReaders.StructReader) OrcSchemaWithTypeVisitor.visit(\n+        expectedSchema, readOrcSchema, new ReadBuilder(idToConstant));\n   }\n \n   @Override\n   public InternalRow read(VectorizedRowBatch batch, int row) {\n-    rowWriter.reset();\n-    rowWriter.zeroOutNullBytes();\n-    for (int c = 0; c < batch.cols.length; ++c) {\n-      converters[c].convert(rowWriter, c, batch.cols[c], row);\n-    }\n-    return rowWriter.getRow();\n+    return reader.read(batch, row);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY2NjQ2Mg=="}, "originalCommit": {"oid": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0"}, "originalPosition": 79}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYyNTA2NzcxOnYy", "diffSide": "RIGHT", "path": "spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcValueReaders.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QxNzoyMzoxNlrOGSIn1g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QxNzoyMzoxNlrOGSIn1g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY2ODgyMg==", "bodyText": "Consider renaming this to something that makes it more obvious that it is returning UTF8String. Avro has a factory method named utf8s to distinguish between strings and its custom Utf8 class.", "url": "https://github.com/apache/iceberg/pull/989#discussion_r421668822", "createdAt": "2020-05-07T17:23:16Z", "author": {"login": "rdblue"}, "path": "spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcValueReaders.java", "diffHunk": "@@ -0,0 +1,213 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.data;\n+\n+import com.google.common.collect.Lists;\n+import java.math.BigDecimal;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.orc.OrcValReader;\n+import org.apache.iceberg.orc.OrcValueReaders;\n+import org.apache.iceberg.types.Types;\n+import org.apache.orc.storage.ql.exec.vector.BytesColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.DecimalColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ListColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.MapColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.TimestampColumnVector;\n+import org.apache.orc.storage.serde2.io.HiveDecimalWritable;\n+import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.catalyst.expressions.GenericInternalRow;\n+import org.apache.spark.sql.catalyst.util.ArrayBasedMapData;\n+import org.apache.spark.sql.catalyst.util.ArrayData;\n+import org.apache.spark.sql.catalyst.util.GenericArrayData;\n+import org.apache.spark.sql.catalyst.util.MapData;\n+import org.apache.spark.sql.types.Decimal;\n+import org.apache.spark.unsafe.types.UTF8String;\n+\n+\n+class SparkOrcValueReaders {\n+  private SparkOrcValueReaders() {\n+  }\n+\n+  static OrcValReader<UTF8String> strings() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0"}, "originalPosition": 50}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYyNTA4NjY0OnYy", "diffSide": "RIGHT", "path": "spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcValueReaders.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QxNzoyODozMFrOGSI0NQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QxNzoyODozMFrOGSI0NQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY3MTk4OQ==", "bodyText": "Container reuse requires passing objects into the read method for correctness.\nThe contract for container reuse is that the caller will consume the record before asking for the next one. For example, Spark might copy the entire row into an UnsafeRow.\nThe problem with keeping a reused list or struct in the reader itself is that the reader might be called more than once to produce a value before the row is consumed. For example, a list of structs locations list<struct<lat:double,long:double>> will call the inner reader for each location struct in the list before returning the record. If the reader reuses the struct, then the same struct will be added to the list multiple times and all of them will have the last values set in the reused struct.", "url": "https://github.com/apache/iceberg/pull/989#discussion_r421671989", "createdAt": "2020-05-07T17:28:30Z", "author": {"login": "rdblue"}, "path": "spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcValueReaders.java", "diffHunk": "@@ -0,0 +1,213 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.data;\n+\n+import com.google.common.collect.Lists;\n+import java.math.BigDecimal;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.orc.OrcValReader;\n+import org.apache.iceberg.orc.OrcValueReaders;\n+import org.apache.iceberg.types.Types;\n+import org.apache.orc.storage.ql.exec.vector.BytesColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.DecimalColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ListColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.MapColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.TimestampColumnVector;\n+import org.apache.orc.storage.serde2.io.HiveDecimalWritable;\n+import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.catalyst.expressions.GenericInternalRow;\n+import org.apache.spark.sql.catalyst.util.ArrayBasedMapData;\n+import org.apache.spark.sql.catalyst.util.ArrayData;\n+import org.apache.spark.sql.catalyst.util.GenericArrayData;\n+import org.apache.spark.sql.catalyst.util.MapData;\n+import org.apache.spark.sql.types.Decimal;\n+import org.apache.spark.unsafe.types.UTF8String;\n+\n+\n+class SparkOrcValueReaders {\n+  private SparkOrcValueReaders() {\n+  }\n+\n+  static OrcValReader<UTF8String> strings() {\n+    return StringReader.INSTANCE;\n+  }\n+\n+  static OrcValReader<?> timestampTzs() {\n+    return TimestampTzReader.INSTANCE;\n+  }\n+\n+  static OrcValReader<?> struct(\n+      List<OrcValReader<?>> readers, Types.StructType struct, Map<Integer, ?> idToConstant) {\n+    return new StructReader(readers, struct, idToConstant);\n+  }\n+\n+  static OrcValReader<?> array(OrcValReader<?> elementReader) {\n+    return new ArrayReader(elementReader);\n+  }\n+\n+  static OrcValReader<?> map(OrcValReader<?> keyReader, OrcValReader<?> valueReader) {\n+    return new MapReader(keyReader, valueReader);\n+  }\n+\n+  private static class ArrayReader implements OrcValReader<ArrayData> {\n+    private final OrcValReader<?> elementReader;\n+    private final List<Object> reusedList = Lists.newArrayList();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0"}, "originalPosition": 73}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYyNTA5NDkzOnYy", "diffSide": "RIGHT", "path": "spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcValueReaders.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QxNzozMDozMlrOGSI5VQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQwNzoxNzo0NlrOGZNHHg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY3MzMwMQ==", "bodyText": "As I noted above, the reader can't keep track of a row like this.", "url": "https://github.com/apache/iceberg/pull/989#discussion_r421673301", "createdAt": "2020-05-07T17:30:32Z", "author": {"login": "rdblue"}, "path": "spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcValueReaders.java", "diffHunk": "@@ -0,0 +1,213 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.data;\n+\n+import com.google.common.collect.Lists;\n+import java.math.BigDecimal;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.orc.OrcValReader;\n+import org.apache.iceberg.orc.OrcValueReaders;\n+import org.apache.iceberg.types.Types;\n+import org.apache.orc.storage.ql.exec.vector.BytesColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.DecimalColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ListColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.MapColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.TimestampColumnVector;\n+import org.apache.orc.storage.serde2.io.HiveDecimalWritable;\n+import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.catalyst.expressions.GenericInternalRow;\n+import org.apache.spark.sql.catalyst.util.ArrayBasedMapData;\n+import org.apache.spark.sql.catalyst.util.ArrayData;\n+import org.apache.spark.sql.catalyst.util.GenericArrayData;\n+import org.apache.spark.sql.catalyst.util.MapData;\n+import org.apache.spark.sql.types.Decimal;\n+import org.apache.spark.unsafe.types.UTF8String;\n+\n+\n+class SparkOrcValueReaders {\n+  private SparkOrcValueReaders() {\n+  }\n+\n+  static OrcValReader<UTF8String> strings() {\n+    return StringReader.INSTANCE;\n+  }\n+\n+  static OrcValReader<?> timestampTzs() {\n+    return TimestampTzReader.INSTANCE;\n+  }\n+\n+  static OrcValReader<?> struct(\n+      List<OrcValReader<?>> readers, Types.StructType struct, Map<Integer, ?> idToConstant) {\n+    return new StructReader(readers, struct, idToConstant);\n+  }\n+\n+  static OrcValReader<?> array(OrcValReader<?> elementReader) {\n+    return new ArrayReader(elementReader);\n+  }\n+\n+  static OrcValReader<?> map(OrcValReader<?> keyReader, OrcValReader<?> valueReader) {\n+    return new MapReader(keyReader, valueReader);\n+  }\n+\n+  private static class ArrayReader implements OrcValReader<ArrayData> {\n+    private final OrcValReader<?> elementReader;\n+    private final List<Object> reusedList = Lists.newArrayList();\n+\n+    private ArrayReader(OrcValReader<?> elementReader) {\n+      this.elementReader = elementReader;\n+    }\n+\n+    @Override\n+    public ArrayData nonNullRead(ColumnVector vector, int row) {\n+      reusedList.clear();\n+      ListColumnVector listVector = (ListColumnVector) vector;\n+      int offset = (int) listVector.offsets[row];\n+      int length = (int) listVector.lengths[row];\n+      for (int c = 0; c < length; ++c) {\n+        reusedList.add(elementReader.read(listVector.child, offset + c));\n+      }\n+      return new GenericArrayData(reusedList.toArray());\n+    }\n+  }\n+\n+  private static class MapReader implements OrcValReader<MapData> {\n+    private final OrcValReader<?> keyReader;\n+    private final OrcValReader<?> valueReader;\n+\n+    private final List<Object> reusedKeyList = Lists.newArrayList();\n+    private final List<Object> reusedValueList = Lists.newArrayList();\n+\n+    private MapReader(OrcValReader<?> keyReader, OrcValReader<?> valueReader) {\n+      this.keyReader = keyReader;\n+      this.valueReader = valueReader;\n+    }\n+\n+    @Override\n+    public MapData nonNullRead(ColumnVector vector, int row) {\n+      reusedKeyList.clear();\n+      reusedValueList.clear();\n+      MapColumnVector mapVector = (MapColumnVector) vector;\n+      int offset = (int) mapVector.offsets[row];\n+      long length = mapVector.lengths[row];\n+      for (int c = 0; c < length; c++) {\n+        reusedKeyList.add(keyReader.read(mapVector.keys, offset + c));\n+        reusedValueList.add(valueReader.read(mapVector.values, offset + c));\n+      }\n+\n+      return new ArrayBasedMapData(\n+          new GenericArrayData(reusedKeyList.toArray()),\n+          new GenericArrayData(reusedValueList.toArray()));\n+    }\n+  }\n+\n+  static class StructReader extends OrcValueReaders.StructReader<InternalRow> {\n+    private final int numFields;\n+    private InternalRow internalRow;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0"}, "originalPosition": 124}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA1MTc3Nw==", "bodyText": "In this case the reuse is only being done for the top level row and not for any internal row. Do u still see this as an issue?", "url": "https://github.com/apache/iceberg/pull/989#discussion_r429051777", "createdAt": "2020-05-22T05:38:17Z", "author": {"login": "rdsr"}, "path": "spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcValueReaders.java", "diffHunk": "@@ -0,0 +1,213 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.data;\n+\n+import com.google.common.collect.Lists;\n+import java.math.BigDecimal;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.orc.OrcValReader;\n+import org.apache.iceberg.orc.OrcValueReaders;\n+import org.apache.iceberg.types.Types;\n+import org.apache.orc.storage.ql.exec.vector.BytesColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.DecimalColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ListColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.MapColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.TimestampColumnVector;\n+import org.apache.orc.storage.serde2.io.HiveDecimalWritable;\n+import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.catalyst.expressions.GenericInternalRow;\n+import org.apache.spark.sql.catalyst.util.ArrayBasedMapData;\n+import org.apache.spark.sql.catalyst.util.ArrayData;\n+import org.apache.spark.sql.catalyst.util.GenericArrayData;\n+import org.apache.spark.sql.catalyst.util.MapData;\n+import org.apache.spark.sql.types.Decimal;\n+import org.apache.spark.unsafe.types.UTF8String;\n+\n+\n+class SparkOrcValueReaders {\n+  private SparkOrcValueReaders() {\n+  }\n+\n+  static OrcValReader<UTF8String> strings() {\n+    return StringReader.INSTANCE;\n+  }\n+\n+  static OrcValReader<?> timestampTzs() {\n+    return TimestampTzReader.INSTANCE;\n+  }\n+\n+  static OrcValReader<?> struct(\n+      List<OrcValReader<?>> readers, Types.StructType struct, Map<Integer, ?> idToConstant) {\n+    return new StructReader(readers, struct, idToConstant);\n+  }\n+\n+  static OrcValReader<?> array(OrcValReader<?> elementReader) {\n+    return new ArrayReader(elementReader);\n+  }\n+\n+  static OrcValReader<?> map(OrcValReader<?> keyReader, OrcValReader<?> valueReader) {\n+    return new MapReader(keyReader, valueReader);\n+  }\n+\n+  private static class ArrayReader implements OrcValReader<ArrayData> {\n+    private final OrcValReader<?> elementReader;\n+    private final List<Object> reusedList = Lists.newArrayList();\n+\n+    private ArrayReader(OrcValReader<?> elementReader) {\n+      this.elementReader = elementReader;\n+    }\n+\n+    @Override\n+    public ArrayData nonNullRead(ColumnVector vector, int row) {\n+      reusedList.clear();\n+      ListColumnVector listVector = (ListColumnVector) vector;\n+      int offset = (int) listVector.offsets[row];\n+      int length = (int) listVector.lengths[row];\n+      for (int c = 0; c < length; ++c) {\n+        reusedList.add(elementReader.read(listVector.child, offset + c));\n+      }\n+      return new GenericArrayData(reusedList.toArray());\n+    }\n+  }\n+\n+  private static class MapReader implements OrcValReader<MapData> {\n+    private final OrcValReader<?> keyReader;\n+    private final OrcValReader<?> valueReader;\n+\n+    private final List<Object> reusedKeyList = Lists.newArrayList();\n+    private final List<Object> reusedValueList = Lists.newArrayList();\n+\n+    private MapReader(OrcValReader<?> keyReader, OrcValReader<?> valueReader) {\n+      this.keyReader = keyReader;\n+      this.valueReader = valueReader;\n+    }\n+\n+    @Override\n+    public MapData nonNullRead(ColumnVector vector, int row) {\n+      reusedKeyList.clear();\n+      reusedValueList.clear();\n+      MapColumnVector mapVector = (MapColumnVector) vector;\n+      int offset = (int) mapVector.offsets[row];\n+      long length = mapVector.lengths[row];\n+      for (int c = 0; c < length; c++) {\n+        reusedKeyList.add(keyReader.read(mapVector.keys, offset + c));\n+        reusedValueList.add(valueReader.read(mapVector.values, offset + c));\n+      }\n+\n+      return new ArrayBasedMapData(\n+          new GenericArrayData(reusedKeyList.toArray()),\n+          new GenericArrayData(reusedValueList.toArray()));\n+    }\n+  }\n+\n+  static class StructReader extends OrcValueReaders.StructReader<InternalRow> {\n+    private final int numFields;\n+    private InternalRow internalRow;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY3MzMwMQ=="}, "originalCommit": {"oid": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0"}, "originalPosition": 124}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA4MjM5OA==", "bodyText": "I ended up removing this for now.", "url": "https://github.com/apache/iceberg/pull/989#discussion_r429082398", "createdAt": "2020-05-22T07:17:46Z", "author": {"login": "rdsr"}, "path": "spark/src/main/java/org/apache/iceberg/spark/data/SparkOrcValueReaders.java", "diffHunk": "@@ -0,0 +1,213 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.data;\n+\n+import com.google.common.collect.Lists;\n+import java.math.BigDecimal;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.orc.OrcValReader;\n+import org.apache.iceberg.orc.OrcValueReaders;\n+import org.apache.iceberg.types.Types;\n+import org.apache.orc.storage.ql.exec.vector.BytesColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.DecimalColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.ListColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.MapColumnVector;\n+import org.apache.orc.storage.ql.exec.vector.TimestampColumnVector;\n+import org.apache.orc.storage.serde2.io.HiveDecimalWritable;\n+import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.catalyst.expressions.GenericInternalRow;\n+import org.apache.spark.sql.catalyst.util.ArrayBasedMapData;\n+import org.apache.spark.sql.catalyst.util.ArrayData;\n+import org.apache.spark.sql.catalyst.util.GenericArrayData;\n+import org.apache.spark.sql.catalyst.util.MapData;\n+import org.apache.spark.sql.types.Decimal;\n+import org.apache.spark.unsafe.types.UTF8String;\n+\n+\n+class SparkOrcValueReaders {\n+  private SparkOrcValueReaders() {\n+  }\n+\n+  static OrcValReader<UTF8String> strings() {\n+    return StringReader.INSTANCE;\n+  }\n+\n+  static OrcValReader<?> timestampTzs() {\n+    return TimestampTzReader.INSTANCE;\n+  }\n+\n+  static OrcValReader<?> struct(\n+      List<OrcValReader<?>> readers, Types.StructType struct, Map<Integer, ?> idToConstant) {\n+    return new StructReader(readers, struct, idToConstant);\n+  }\n+\n+  static OrcValReader<?> array(OrcValReader<?> elementReader) {\n+    return new ArrayReader(elementReader);\n+  }\n+\n+  static OrcValReader<?> map(OrcValReader<?> keyReader, OrcValReader<?> valueReader) {\n+    return new MapReader(keyReader, valueReader);\n+  }\n+\n+  private static class ArrayReader implements OrcValReader<ArrayData> {\n+    private final OrcValReader<?> elementReader;\n+    private final List<Object> reusedList = Lists.newArrayList();\n+\n+    private ArrayReader(OrcValReader<?> elementReader) {\n+      this.elementReader = elementReader;\n+    }\n+\n+    @Override\n+    public ArrayData nonNullRead(ColumnVector vector, int row) {\n+      reusedList.clear();\n+      ListColumnVector listVector = (ListColumnVector) vector;\n+      int offset = (int) listVector.offsets[row];\n+      int length = (int) listVector.lengths[row];\n+      for (int c = 0; c < length; ++c) {\n+        reusedList.add(elementReader.read(listVector.child, offset + c));\n+      }\n+      return new GenericArrayData(reusedList.toArray());\n+    }\n+  }\n+\n+  private static class MapReader implements OrcValReader<MapData> {\n+    private final OrcValReader<?> keyReader;\n+    private final OrcValReader<?> valueReader;\n+\n+    private final List<Object> reusedKeyList = Lists.newArrayList();\n+    private final List<Object> reusedValueList = Lists.newArrayList();\n+\n+    private MapReader(OrcValReader<?> keyReader, OrcValReader<?> valueReader) {\n+      this.keyReader = keyReader;\n+      this.valueReader = valueReader;\n+    }\n+\n+    @Override\n+    public MapData nonNullRead(ColumnVector vector, int row) {\n+      reusedKeyList.clear();\n+      reusedValueList.clear();\n+      MapColumnVector mapVector = (MapColumnVector) vector;\n+      int offset = (int) mapVector.offsets[row];\n+      long length = mapVector.lengths[row];\n+      for (int c = 0; c < length; c++) {\n+        reusedKeyList.add(keyReader.read(mapVector.keys, offset + c));\n+        reusedValueList.add(valueReader.read(mapVector.values, offset + c));\n+      }\n+\n+      return new ArrayBasedMapData(\n+          new GenericArrayData(reusedKeyList.toArray()),\n+          new GenericArrayData(reusedValueList.toArray()));\n+    }\n+  }\n+\n+  static class StructReader extends OrcValueReaders.StructReader<InternalRow> {\n+    private final int numFields;\n+    private InternalRow internalRow;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY3MzMwMQ=="}, "originalCommit": {"oid": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0"}, "originalPosition": 124}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYyNTEwMjk0OnYy", "diffSide": "RIGHT", "path": "spark/src/main/java/org/apache/iceberg/spark/source/RowDataReader.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QxNzozMjo0NVrOGSI-Sw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQxNTo1NjowM1rOGZcJtQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY3NDU3MQ==", "bodyText": "Once this and #1004 are in, we can remove the Spark projection!", "url": "https://github.com/apache/iceberg/pull/989#discussion_r421674571", "createdAt": "2020-05-07T17:32:45Z", "author": {"login": "rdblue"}, "path": "spark/src/main/java/org/apache/iceberg/spark/source/RowDataReader.java", "diffHunk": "@@ -109,23 +104,8 @@\n     Iterator<InternalRow> iter;\n \n     if (hasJoinedPartitionColumns) {\n-      if (SUPPORTS_CONSTANTS.contains(file.format())) {\n-        iterSchema = requiredSchema;\n-        iter = open(task, requiredSchema, PartitionUtil.constantsMap(task, RowDataReader::convertConstant));\n-      } else {\n-        // schema used to read data files\n-        Schema readSchema = TypeUtil.selectNot(requiredSchema, idColumns);\n-        Schema partitionSchema = TypeUtil.select(requiredSchema, idColumns);\n-        PartitionRowConverter convertToRow = new PartitionRowConverter(partitionSchema, spec);\n-        JoinedRow joined = new JoinedRow();\n-\n-        InternalRow partition = convertToRow.apply(file.partition());\n-        joined.withRight(partition);\n-\n-        // create joined rows and project from the joined schema to the final schema\n-        iterSchema = TypeUtil.join(readSchema, partitionSchema);\n-        iter = Iterators.transform(open(task, readSchema, ImmutableMap.of()), joined::withLeft);\n-      }\n+      iterSchema = requiredSchema;\n+      iter = open(task, requiredSchema, PartitionUtil.constantsMap(task, RowDataReader::convertConstant));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0"}, "originalPosition": 62}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTMyODgyMQ==", "bodyText": "#1004 is in. That might be why this has conflicts.", "url": "https://github.com/apache/iceberg/pull/989#discussion_r429328821", "createdAt": "2020-05-22T15:56:03Z", "author": {"login": "rdblue"}, "path": "spark/src/main/java/org/apache/iceberg/spark/source/RowDataReader.java", "diffHunk": "@@ -109,23 +104,8 @@\n     Iterator<InternalRow> iter;\n \n     if (hasJoinedPartitionColumns) {\n-      if (SUPPORTS_CONSTANTS.contains(file.format())) {\n-        iterSchema = requiredSchema;\n-        iter = open(task, requiredSchema, PartitionUtil.constantsMap(task, RowDataReader::convertConstant));\n-      } else {\n-        // schema used to read data files\n-        Schema readSchema = TypeUtil.selectNot(requiredSchema, idColumns);\n-        Schema partitionSchema = TypeUtil.select(requiredSchema, idColumns);\n-        PartitionRowConverter convertToRow = new PartitionRowConverter(partitionSchema, spec);\n-        JoinedRow joined = new JoinedRow();\n-\n-        InternalRow partition = convertToRow.apply(file.partition());\n-        joined.withRight(partition);\n-\n-        // create joined rows and project from the joined schema to the final schema\n-        iterSchema = TypeUtil.join(readSchema, partitionSchema);\n-        iter = Iterators.transform(open(task, readSchema, ImmutableMap.of()), joined::withLeft);\n-      }\n+      iterSchema = requiredSchema;\n+      iter = open(task, requiredSchema, PartitionUtil.constantsMap(task, RowDataReader::convertConstant));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY3NDU3MQ=="}, "originalCommit": {"oid": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0"}, "originalPosition": 62}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjYyNTExNDY3OnYy", "diffSide": "LEFT", "path": "spark/src/test/java/org/apache/iceberg/spark/data/TestSparkOrcReader.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wN1QxNzozNjowNFrOGSJF1A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMlQwNzozNzo1OFrOGZNnAQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY3NjUwMA==", "bodyText": "I think this should test with and without container reuse if that is implemented in this PR. Probably just make this test parameterized.", "url": "https://github.com/apache/iceberg/pull/989#discussion_r421676500", "createdAt": "2020-05-07T17:36:04Z", "author": {"login": "rdblue"}, "path": "spark/src/test/java/org/apache/iceberg/spark/data/TestSparkOrcReader.java", "diffHunk": "@@ -71,7 +71,7 @@ private void writeAndValidateRecords(Schema schema, Iterable<InternalRow> expect\n \n     try (CloseableIterable<InternalRow> reader = ORC.read(Files.localInput(testFile))\n         .project(schema)\n-        .createReaderFunc(SparkOrcReader::new)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyOTA5MDU2MQ==", "bodyText": "For now I've removed the reuse code. We can tackle than in followup", "url": "https://github.com/apache/iceberg/pull/989#discussion_r429090561", "createdAt": "2020-05-22T07:37:58Z", "author": {"login": "rdsr"}, "path": "spark/src/test/java/org/apache/iceberg/spark/data/TestSparkOrcReader.java", "diffHunk": "@@ -71,7 +71,7 @@ private void writeAndValidateRecords(Schema schema, Iterable<InternalRow> expect\n \n     try (CloseableIterable<InternalRow> reader = ORC.read(Files.localInput(testFile))\n         .project(schema)\n-        .createReaderFunc(SparkOrcReader::new)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMTY3NjUwMA=="}, "originalCommit": {"oid": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjY2ODI3NDA3OnYy", "diffSide": "RIGHT", "path": "orc/src/main/java/org/apache/iceberg/orc/OrcSchemaWithTypeVisitor.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQwNDowMjoyMVrOGYld8A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0yMVQwNDowMjoyMVrOGYld8A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyODQzMjg4MA==", "bodyText": "iType can be null if a corresponding field is not found in the Iceberg schema for the current field in the ORC schema. So we should put a null check here and in other places where Type.asXXX() is being done", "url": "https://github.com/apache/iceberg/pull/989#discussion_r428432880", "createdAt": "2020-05-21T04:02:21Z", "author": {"login": "shardulm94"}, "path": "orc/src/main/java/org/apache/iceberg/orc/OrcSchemaWithTypeVisitor.java", "diffHunk": "@@ -0,0 +1,90 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.orc;\n+\n+import com.google.common.collect.Lists;\n+import java.util.List;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+import org.apache.orc.TypeDescription;\n+\n+\n+public abstract class OrcSchemaWithTypeVisitor<T> {\n+  public static <T> T visit(\n+      org.apache.iceberg.Schema iSchema, TypeDescription schema, OrcSchemaWithTypeVisitor<T> visitor) {\n+    return visit(iSchema.asStruct(), schema, visitor);\n+  }\n+\n+  public static <T> T visit(Type iType, TypeDescription schema, OrcSchemaWithTypeVisitor<T> visitor) {\n+    switch (schema.getCategory()) {\n+      case STRUCT:\n+        return visitRecord(iType.asStructType(), schema, visitor);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8b635a062b08a6d9dcf46e019f28e1655dd2dcf0"}, "originalPosition": 38}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3973, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}