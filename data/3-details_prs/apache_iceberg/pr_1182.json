{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQ2MDA0NzI5", "number": 1182, "title": "Flink: Integrate Iceberg catalog to Flink catalog", "bodyText": "Like Spark 3, Flink also has Catalog interface, we can integrate Iceberg catalog to Flink catalog, iceberg as a Flink catalog, users can use Flink DDLs to manipulate iceberg metadata. And query iceberg tables directly.\nThe mapping between Flink database and Iceberg namespace:\n\nSupplying a base namespace for a given catalog, so if you have a catalog that supports a 2-level namespace, you would supply the first level in the catalog configuration and the second level would be exposed as Flink databases.\nThe Iceberg table manages its partitions by itself. The partition of the Iceberg table is independent of the partition of Flink.\n\nThis PR solve #1170\nThis PR depends on:\n\n#1174\n#1176", "createdAt": "2020-07-08T06:12:41Z", "url": "https://github.com/apache/iceberg/pull/1182", "merged": true, "mergeCommit": {"oid": "b8700c3a66aff7f65a38abb5002abddf40620324"}, "closed": true, "closedAt": "2020-07-20T21:52:44Z", "author": {"login": "JingsongLi"}, "timelineItems": {"totalCount": 26, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABczrYLmgFqTQ0NjczMzAwNw==", "endCursor": "Y3Vyc29yOnYyOpPPAAABc242AeAFqTQ1MTk4NDg2Mw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2NzMzMDA3", "url": "https://github.com/apache/iceberg/pull/1182#pullrequestreview-446733007", "createdAt": "2020-07-10T22:28:32Z", "commit": {"oid": "248278f444044d11233d41b81bfcb999f63dadb5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMjoyODozM1rOGwHVew==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMjoyODozM1rOGwHVew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzEwNTAxOQ==", "bodyText": "We would normally use Preconditions.checkArgument in this case.", "url": "https://github.com/apache/iceberg/pull/1182#discussion_r453105019", "createdAt": "2020-07-10T22:28:33Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkCatalog.java", "diffHunk": "@@ -0,0 +1,508 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.catalog.AbstractCatalog;\n+import org.apache.flink.table.catalog.CatalogBaseTable;\n+import org.apache.flink.table.catalog.CatalogDatabase;\n+import org.apache.flink.table.catalog.CatalogDatabaseImpl;\n+import org.apache.flink.table.catalog.CatalogFunction;\n+import org.apache.flink.table.catalog.CatalogPartition;\n+import org.apache.flink.table.catalog.CatalogPartitionSpec;\n+import org.apache.flink.table.catalog.CatalogTableImpl;\n+import org.apache.flink.table.catalog.ObjectPath;\n+import org.apache.flink.table.catalog.exceptions.CatalogException;\n+import org.apache.flink.table.catalog.exceptions.DatabaseAlreadyExistException;\n+import org.apache.flink.table.catalog.exceptions.DatabaseNotEmptyException;\n+import org.apache.flink.table.catalog.exceptions.DatabaseNotExistException;\n+import org.apache.flink.table.catalog.exceptions.FunctionNotExistException;\n+import org.apache.flink.table.catalog.exceptions.TableAlreadyExistException;\n+import org.apache.flink.table.catalog.exceptions.TableNotExistException;\n+import org.apache.flink.table.catalog.stats.CatalogColumnStatistics;\n+import org.apache.flink.table.catalog.stats.CatalogTableStatistics;\n+import org.apache.flink.table.expressions.Expression;\n+import org.apache.flink.util.StringUtils;\n+import org.apache.iceberg.CachingCatalog;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.catalog.Catalog;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.apache.iceberg.relocated.com.google.common.collect.Sets;\n+\n+/**\n+ * A Flink Catalog implementation that wraps an Iceberg {@link Catalog}.\n+ * <p>\n+ * The mapping between Flink database and Iceberg namespace:\n+ * Supplying a base namespace for a given catalog, so if you have a catalog that supports a 2-level namespace, you\n+ * would supply the first level in the catalog configuration and the second level would be exposed as Flink databases.\n+ * <p>\n+ * The Iceberg table manages its partitions by itself. The partition of the Iceberg table is independent of the\n+ * partition of Flink.\n+ */\n+public class FlinkCatalog extends AbstractCatalog {\n+\n+  private final Catalog originalCatalog;\n+  private final Catalog icebergCatalog;\n+  private final String[] baseNamespace;\n+  private final SupportsNamespaces asNamespaceCatalog;\n+\n+  public FlinkCatalog(\n+      String catalogName,\n+      String defaultDatabase,\n+      String[] baseNamespace,\n+      Catalog icebergCatalog,\n+      boolean cacheEnabled) {\n+    super(catalogName, defaultDatabase);\n+    this.originalCatalog = icebergCatalog;\n+    this.icebergCatalog = cacheEnabled ? CachingCatalog.wrap(icebergCatalog) : icebergCatalog;\n+    this.baseNamespace = baseNamespace;\n+    if (icebergCatalog instanceof SupportsNamespaces) {\n+      asNamespaceCatalog = (SupportsNamespaces) icebergCatalog;\n+    } else {\n+      asNamespaceCatalog = null;\n+    }\n+  }\n+\n+  @Override\n+  public void open() throws CatalogException {\n+  }\n+\n+  @Override\n+  public void close() throws CatalogException {\n+    if (originalCatalog instanceof Closeable) {\n+      try {\n+        ((Closeable) originalCatalog).close();\n+      } catch (IOException e) {\n+        throw new CatalogException(e);\n+      }\n+    }\n+  }\n+\n+  private Namespace toNamespace(String database) {\n+    String[] namespace = new String[baseNamespace.length + 1];\n+    System.arraycopy(baseNamespace, 0, namespace, 0, baseNamespace.length);\n+    namespace[baseNamespace.length] = database;\n+    return Namespace.of(namespace);\n+  }\n+\n+  private TableIdentifier toIdentifier(ObjectPath path) {\n+    return TableIdentifier.of(toNamespace(path.getDatabaseName()), path.getObjectName());\n+  }\n+\n+  @Override\n+  public List<String> listDatabases() throws CatalogException {\n+    if (asNamespaceCatalog == null) {\n+      return Collections.singletonList(getDefaultDatabase());\n+    }\n+\n+    return listAllNamespaces(Namespace.empty()).stream()\n+        .map(n -> n.level(n.levels().length - 1))\n+        .collect(Collectors.toList());\n+  }\n+\n+  private List<Namespace> listAllNamespaces(Namespace namespace) {\n+    if (asNamespaceCatalog == null) {\n+      throw new RuntimeException(\"The asNamespaceCatalog should not be null.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "248278f444044d11233d41b81bfcb999f63dadb5"}, "originalPosition": 137}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2NzMzMTc0", "url": "https://github.com/apache/iceberg/pull/1182#pullrequestreview-446733174", "createdAt": "2020-07-10T22:29:08Z", "commit": {"oid": "248278f444044d11233d41b81bfcb999f63dadb5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMjoyOTowOFrOGwHWEg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMjoyOTowOFrOGwHWEg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzEwNTE3MA==", "bodyText": "Nit: we like to add empty lines after control flow blocks (between the last } and this if).", "url": "https://github.com/apache/iceberg/pull/1182#discussion_r453105170", "createdAt": "2020-07-10T22:29:08Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkCatalog.java", "diffHunk": "@@ -0,0 +1,508 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.catalog.AbstractCatalog;\n+import org.apache.flink.table.catalog.CatalogBaseTable;\n+import org.apache.flink.table.catalog.CatalogDatabase;\n+import org.apache.flink.table.catalog.CatalogDatabaseImpl;\n+import org.apache.flink.table.catalog.CatalogFunction;\n+import org.apache.flink.table.catalog.CatalogPartition;\n+import org.apache.flink.table.catalog.CatalogPartitionSpec;\n+import org.apache.flink.table.catalog.CatalogTableImpl;\n+import org.apache.flink.table.catalog.ObjectPath;\n+import org.apache.flink.table.catalog.exceptions.CatalogException;\n+import org.apache.flink.table.catalog.exceptions.DatabaseAlreadyExistException;\n+import org.apache.flink.table.catalog.exceptions.DatabaseNotEmptyException;\n+import org.apache.flink.table.catalog.exceptions.DatabaseNotExistException;\n+import org.apache.flink.table.catalog.exceptions.FunctionNotExistException;\n+import org.apache.flink.table.catalog.exceptions.TableAlreadyExistException;\n+import org.apache.flink.table.catalog.exceptions.TableNotExistException;\n+import org.apache.flink.table.catalog.stats.CatalogColumnStatistics;\n+import org.apache.flink.table.catalog.stats.CatalogTableStatistics;\n+import org.apache.flink.table.expressions.Expression;\n+import org.apache.flink.util.StringUtils;\n+import org.apache.iceberg.CachingCatalog;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.catalog.Catalog;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.apache.iceberg.relocated.com.google.common.collect.Sets;\n+\n+/**\n+ * A Flink Catalog implementation that wraps an Iceberg {@link Catalog}.\n+ * <p>\n+ * The mapping between Flink database and Iceberg namespace:\n+ * Supplying a base namespace for a given catalog, so if you have a catalog that supports a 2-level namespace, you\n+ * would supply the first level in the catalog configuration and the second level would be exposed as Flink databases.\n+ * <p>\n+ * The Iceberg table manages its partitions by itself. The partition of the Iceberg table is independent of the\n+ * partition of Flink.\n+ */\n+public class FlinkCatalog extends AbstractCatalog {\n+\n+  private final Catalog originalCatalog;\n+  private final Catalog icebergCatalog;\n+  private final String[] baseNamespace;\n+  private final SupportsNamespaces asNamespaceCatalog;\n+\n+  public FlinkCatalog(\n+      String catalogName,\n+      String defaultDatabase,\n+      String[] baseNamespace,\n+      Catalog icebergCatalog,\n+      boolean cacheEnabled) {\n+    super(catalogName, defaultDatabase);\n+    this.originalCatalog = icebergCatalog;\n+    this.icebergCatalog = cacheEnabled ? CachingCatalog.wrap(icebergCatalog) : icebergCatalog;\n+    this.baseNamespace = baseNamespace;\n+    if (icebergCatalog instanceof SupportsNamespaces) {\n+      asNamespaceCatalog = (SupportsNamespaces) icebergCatalog;\n+    } else {\n+      asNamespaceCatalog = null;\n+    }\n+  }\n+\n+  @Override\n+  public void open() throws CatalogException {\n+  }\n+\n+  @Override\n+  public void close() throws CatalogException {\n+    if (originalCatalog instanceof Closeable) {\n+      try {\n+        ((Closeable) originalCatalog).close();\n+      } catch (IOException e) {\n+        throw new CatalogException(e);\n+      }\n+    }\n+  }\n+\n+  private Namespace toNamespace(String database) {\n+    String[] namespace = new String[baseNamespace.length + 1];\n+    System.arraycopy(baseNamespace, 0, namespace, 0, baseNamespace.length);\n+    namespace[baseNamespace.length] = database;\n+    return Namespace.of(namespace);\n+  }\n+\n+  private TableIdentifier toIdentifier(ObjectPath path) {\n+    return TableIdentifier.of(toNamespace(path.getDatabaseName()), path.getObjectName());\n+  }\n+\n+  @Override\n+  public List<String> listDatabases() throws CatalogException {\n+    if (asNamespaceCatalog == null) {\n+      return Collections.singletonList(getDefaultDatabase());\n+    }\n+\n+    return listAllNamespaces(Namespace.empty()).stream()\n+        .map(n -> n.level(n.levels().length - 1))\n+        .collect(Collectors.toList());\n+  }\n+\n+  private List<Namespace> listAllNamespaces(Namespace namespace) {\n+    if (asNamespaceCatalog == null) {\n+      throw new RuntimeException(\"The asNamespaceCatalog should not be null.\");\n+    }\n+\n+    String[] levels = namespace.levels();\n+    if (levels.length == baseNamespace.length + 1) {\n+      return Collections.singletonList(namespace);\n+    }\n+    if (levels.length < baseNamespace.length + 1) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "248278f444044d11233d41b81bfcb999f63dadb5"}, "originalPosition": 144}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2NzM0MjI3", "url": "https://github.com/apache/iceberg/pull/1182#pullrequestreview-446734227", "createdAt": "2020-07-10T22:32:49Z", "commit": {"oid": "248278f444044d11233d41b81bfcb999f63dadb5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMjozMjo0OVrOGwHZ_w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMjozMjo0OVrOGwHZ_w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzEwNjE3NQ==", "bodyText": "Why is this recursive? It seems unnecessary.", "url": "https://github.com/apache/iceberg/pull/1182#discussion_r453106175", "createdAt": "2020-07-10T22:32:49Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkCatalog.java", "diffHunk": "@@ -0,0 +1,508 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.catalog.AbstractCatalog;\n+import org.apache.flink.table.catalog.CatalogBaseTable;\n+import org.apache.flink.table.catalog.CatalogDatabase;\n+import org.apache.flink.table.catalog.CatalogDatabaseImpl;\n+import org.apache.flink.table.catalog.CatalogFunction;\n+import org.apache.flink.table.catalog.CatalogPartition;\n+import org.apache.flink.table.catalog.CatalogPartitionSpec;\n+import org.apache.flink.table.catalog.CatalogTableImpl;\n+import org.apache.flink.table.catalog.ObjectPath;\n+import org.apache.flink.table.catalog.exceptions.CatalogException;\n+import org.apache.flink.table.catalog.exceptions.DatabaseAlreadyExistException;\n+import org.apache.flink.table.catalog.exceptions.DatabaseNotEmptyException;\n+import org.apache.flink.table.catalog.exceptions.DatabaseNotExistException;\n+import org.apache.flink.table.catalog.exceptions.FunctionNotExistException;\n+import org.apache.flink.table.catalog.exceptions.TableAlreadyExistException;\n+import org.apache.flink.table.catalog.exceptions.TableNotExistException;\n+import org.apache.flink.table.catalog.stats.CatalogColumnStatistics;\n+import org.apache.flink.table.catalog.stats.CatalogTableStatistics;\n+import org.apache.flink.table.expressions.Expression;\n+import org.apache.flink.util.StringUtils;\n+import org.apache.iceberg.CachingCatalog;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.catalog.Catalog;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.apache.iceberg.relocated.com.google.common.collect.Sets;\n+\n+/**\n+ * A Flink Catalog implementation that wraps an Iceberg {@link Catalog}.\n+ * <p>\n+ * The mapping between Flink database and Iceberg namespace:\n+ * Supplying a base namespace for a given catalog, so if you have a catalog that supports a 2-level namespace, you\n+ * would supply the first level in the catalog configuration and the second level would be exposed as Flink databases.\n+ * <p>\n+ * The Iceberg table manages its partitions by itself. The partition of the Iceberg table is independent of the\n+ * partition of Flink.\n+ */\n+public class FlinkCatalog extends AbstractCatalog {\n+\n+  private final Catalog originalCatalog;\n+  private final Catalog icebergCatalog;\n+  private final String[] baseNamespace;\n+  private final SupportsNamespaces asNamespaceCatalog;\n+\n+  public FlinkCatalog(\n+      String catalogName,\n+      String defaultDatabase,\n+      String[] baseNamespace,\n+      Catalog icebergCatalog,\n+      boolean cacheEnabled) {\n+    super(catalogName, defaultDatabase);\n+    this.originalCatalog = icebergCatalog;\n+    this.icebergCatalog = cacheEnabled ? CachingCatalog.wrap(icebergCatalog) : icebergCatalog;\n+    this.baseNamespace = baseNamespace;\n+    if (icebergCatalog instanceof SupportsNamespaces) {\n+      asNamespaceCatalog = (SupportsNamespaces) icebergCatalog;\n+    } else {\n+      asNamespaceCatalog = null;\n+    }\n+  }\n+\n+  @Override\n+  public void open() throws CatalogException {\n+  }\n+\n+  @Override\n+  public void close() throws CatalogException {\n+    if (originalCatalog instanceof Closeable) {\n+      try {\n+        ((Closeable) originalCatalog).close();\n+      } catch (IOException e) {\n+        throw new CatalogException(e);\n+      }\n+    }\n+  }\n+\n+  private Namespace toNamespace(String database) {\n+    String[] namespace = new String[baseNamespace.length + 1];\n+    System.arraycopy(baseNamespace, 0, namespace, 0, baseNamespace.length);\n+    namespace[baseNamespace.length] = database;\n+    return Namespace.of(namespace);\n+  }\n+\n+  private TableIdentifier toIdentifier(ObjectPath path) {\n+    return TableIdentifier.of(toNamespace(path.getDatabaseName()), path.getObjectName());\n+  }\n+\n+  @Override\n+  public List<String> listDatabases() throws CatalogException {\n+    if (asNamespaceCatalog == null) {\n+      return Collections.singletonList(getDefaultDatabase());\n+    }\n+\n+    return listAllNamespaces(Namespace.empty()).stream()\n+        .map(n -> n.level(n.levels().length - 1))\n+        .collect(Collectors.toList());\n+  }\n+\n+  private List<Namespace> listAllNamespaces(Namespace namespace) {\n+    if (asNamespaceCatalog == null) {\n+      throw new RuntimeException(\"The asNamespaceCatalog should not be null.\");\n+    }\n+\n+    String[] levels = namespace.levels();\n+    if (levels.length == baseNamespace.length + 1) {\n+      return Collections.singletonList(namespace);\n+    }\n+    if (levels.length < baseNamespace.length + 1) {\n+      for (int i = 0; i < levels.length; i++) {\n+        if (!baseNamespace[i].equals(levels[i])) {\n+          return Collections.emptyList();\n+        }\n+      }\n+      List<Namespace> ret = new ArrayList<>();\n+      asNamespaceCatalog.listNamespaces(namespace).forEach(n -> ret.addAll(listAllNamespaces(n)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "248278f444044d11233d41b81bfcb999f63dadb5"}, "originalPosition": 151}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2NzM0NTIz", "url": "https://github.com/apache/iceberg/pull/1182#pullrequestreview-446734523", "createdAt": "2020-07-10T22:33:54Z", "commit": {"oid": "248278f444044d11233d41b81bfcb999f63dadb5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMjozMzo1NFrOGwHa_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMjozMzo1NFrOGwHa_g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzEwNjQzMA==", "bodyText": "Minor: We prefer using the factory methods in Maps instead of specific class names.", "url": "https://github.com/apache/iceberg/pull/1182#discussion_r453106430", "createdAt": "2020-07-10T22:33:54Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkCatalog.java", "diffHunk": "@@ -0,0 +1,508 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.catalog.AbstractCatalog;\n+import org.apache.flink.table.catalog.CatalogBaseTable;\n+import org.apache.flink.table.catalog.CatalogDatabase;\n+import org.apache.flink.table.catalog.CatalogDatabaseImpl;\n+import org.apache.flink.table.catalog.CatalogFunction;\n+import org.apache.flink.table.catalog.CatalogPartition;\n+import org.apache.flink.table.catalog.CatalogPartitionSpec;\n+import org.apache.flink.table.catalog.CatalogTableImpl;\n+import org.apache.flink.table.catalog.ObjectPath;\n+import org.apache.flink.table.catalog.exceptions.CatalogException;\n+import org.apache.flink.table.catalog.exceptions.DatabaseAlreadyExistException;\n+import org.apache.flink.table.catalog.exceptions.DatabaseNotEmptyException;\n+import org.apache.flink.table.catalog.exceptions.DatabaseNotExistException;\n+import org.apache.flink.table.catalog.exceptions.FunctionNotExistException;\n+import org.apache.flink.table.catalog.exceptions.TableAlreadyExistException;\n+import org.apache.flink.table.catalog.exceptions.TableNotExistException;\n+import org.apache.flink.table.catalog.stats.CatalogColumnStatistics;\n+import org.apache.flink.table.catalog.stats.CatalogTableStatistics;\n+import org.apache.flink.table.expressions.Expression;\n+import org.apache.flink.util.StringUtils;\n+import org.apache.iceberg.CachingCatalog;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.catalog.Catalog;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.apache.iceberg.relocated.com.google.common.collect.Sets;\n+\n+/**\n+ * A Flink Catalog implementation that wraps an Iceberg {@link Catalog}.\n+ * <p>\n+ * The mapping between Flink database and Iceberg namespace:\n+ * Supplying a base namespace for a given catalog, so if you have a catalog that supports a 2-level namespace, you\n+ * would supply the first level in the catalog configuration and the second level would be exposed as Flink databases.\n+ * <p>\n+ * The Iceberg table manages its partitions by itself. The partition of the Iceberg table is independent of the\n+ * partition of Flink.\n+ */\n+public class FlinkCatalog extends AbstractCatalog {\n+\n+  private final Catalog originalCatalog;\n+  private final Catalog icebergCatalog;\n+  private final String[] baseNamespace;\n+  private final SupportsNamespaces asNamespaceCatalog;\n+\n+  public FlinkCatalog(\n+      String catalogName,\n+      String defaultDatabase,\n+      String[] baseNamespace,\n+      Catalog icebergCatalog,\n+      boolean cacheEnabled) {\n+    super(catalogName, defaultDatabase);\n+    this.originalCatalog = icebergCatalog;\n+    this.icebergCatalog = cacheEnabled ? CachingCatalog.wrap(icebergCatalog) : icebergCatalog;\n+    this.baseNamespace = baseNamespace;\n+    if (icebergCatalog instanceof SupportsNamespaces) {\n+      asNamespaceCatalog = (SupportsNamespaces) icebergCatalog;\n+    } else {\n+      asNamespaceCatalog = null;\n+    }\n+  }\n+\n+  @Override\n+  public void open() throws CatalogException {\n+  }\n+\n+  @Override\n+  public void close() throws CatalogException {\n+    if (originalCatalog instanceof Closeable) {\n+      try {\n+        ((Closeable) originalCatalog).close();\n+      } catch (IOException e) {\n+        throw new CatalogException(e);\n+      }\n+    }\n+  }\n+\n+  private Namespace toNamespace(String database) {\n+    String[] namespace = new String[baseNamespace.length + 1];\n+    System.arraycopy(baseNamespace, 0, namespace, 0, baseNamespace.length);\n+    namespace[baseNamespace.length] = database;\n+    return Namespace.of(namespace);\n+  }\n+\n+  private TableIdentifier toIdentifier(ObjectPath path) {\n+    return TableIdentifier.of(toNamespace(path.getDatabaseName()), path.getObjectName());\n+  }\n+\n+  @Override\n+  public List<String> listDatabases() throws CatalogException {\n+    if (asNamespaceCatalog == null) {\n+      return Collections.singletonList(getDefaultDatabase());\n+    }\n+\n+    return listAllNamespaces(Namespace.empty()).stream()\n+        .map(n -> n.level(n.levels().length - 1))\n+        .collect(Collectors.toList());\n+  }\n+\n+  private List<Namespace> listAllNamespaces(Namespace namespace) {\n+    if (asNamespaceCatalog == null) {\n+      throw new RuntimeException(\"The asNamespaceCatalog should not be null.\");\n+    }\n+\n+    String[] levels = namespace.levels();\n+    if (levels.length == baseNamespace.length + 1) {\n+      return Collections.singletonList(namespace);\n+    }\n+    if (levels.length < baseNamespace.length + 1) {\n+      for (int i = 0; i < levels.length; i++) {\n+        if (!baseNamespace[i].equals(levels[i])) {\n+          return Collections.emptyList();\n+        }\n+      }\n+      List<Namespace> ret = new ArrayList<>();\n+      asNamespaceCatalog.listNamespaces(namespace).forEach(n -> ret.addAll(listAllNamespaces(n)));\n+      return ret;\n+    }\n+    return Collections.emptyList();\n+  }\n+\n+  @Override\n+  public CatalogDatabase getDatabase(String databaseName) throws DatabaseNotExistException, CatalogException {\n+    if (asNamespaceCatalog == null) {\n+      if (!getDefaultDatabase().equals(databaseName)) {\n+        throw new DatabaseNotExistException(getName(), databaseName);\n+      } else {\n+        return new CatalogDatabaseImpl(new HashMap<>(), \"\");\n+      }\n+    } else {\n+      try {\n+        Map<String, String> metadata =\n+            new HashMap<>(asNamespaceCatalog.loadNamespaceMetadata(toNamespace(databaseName)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "248278f444044d11233d41b81bfcb999f63dadb5"}, "originalPosition": 168}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2NzM2MTI0", "url": "https://github.com/apache/iceberg/pull/1182#pullrequestreview-446736124", "createdAt": "2020-07-10T22:39:50Z", "commit": {"oid": "248278f444044d11233d41b81bfcb999f63dadb5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMjozOTo1MFrOGwHgoQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMjozOTo1MFrOGwHgoQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzEwNzg3Mw==", "bodyText": "This doesn't seem to handle the default database. What is the correct behavior when the catalog doesn't support namespaces, but this is called for the default database?", "url": "https://github.com/apache/iceberg/pull/1182#discussion_r453107873", "createdAt": "2020-07-10T22:39:50Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkCatalog.java", "diffHunk": "@@ -0,0 +1,508 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.catalog.AbstractCatalog;\n+import org.apache.flink.table.catalog.CatalogBaseTable;\n+import org.apache.flink.table.catalog.CatalogDatabase;\n+import org.apache.flink.table.catalog.CatalogDatabaseImpl;\n+import org.apache.flink.table.catalog.CatalogFunction;\n+import org.apache.flink.table.catalog.CatalogPartition;\n+import org.apache.flink.table.catalog.CatalogPartitionSpec;\n+import org.apache.flink.table.catalog.CatalogTableImpl;\n+import org.apache.flink.table.catalog.ObjectPath;\n+import org.apache.flink.table.catalog.exceptions.CatalogException;\n+import org.apache.flink.table.catalog.exceptions.DatabaseAlreadyExistException;\n+import org.apache.flink.table.catalog.exceptions.DatabaseNotEmptyException;\n+import org.apache.flink.table.catalog.exceptions.DatabaseNotExistException;\n+import org.apache.flink.table.catalog.exceptions.FunctionNotExistException;\n+import org.apache.flink.table.catalog.exceptions.TableAlreadyExistException;\n+import org.apache.flink.table.catalog.exceptions.TableNotExistException;\n+import org.apache.flink.table.catalog.stats.CatalogColumnStatistics;\n+import org.apache.flink.table.catalog.stats.CatalogTableStatistics;\n+import org.apache.flink.table.expressions.Expression;\n+import org.apache.flink.util.StringUtils;\n+import org.apache.iceberg.CachingCatalog;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.catalog.Catalog;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.apache.iceberg.relocated.com.google.common.collect.Sets;\n+\n+/**\n+ * A Flink Catalog implementation that wraps an Iceberg {@link Catalog}.\n+ * <p>\n+ * The mapping between Flink database and Iceberg namespace:\n+ * Supplying a base namespace for a given catalog, so if you have a catalog that supports a 2-level namespace, you\n+ * would supply the first level in the catalog configuration and the second level would be exposed as Flink databases.\n+ * <p>\n+ * The Iceberg table manages its partitions by itself. The partition of the Iceberg table is independent of the\n+ * partition of Flink.\n+ */\n+public class FlinkCatalog extends AbstractCatalog {\n+\n+  private final Catalog originalCatalog;\n+  private final Catalog icebergCatalog;\n+  private final String[] baseNamespace;\n+  private final SupportsNamespaces asNamespaceCatalog;\n+\n+  public FlinkCatalog(\n+      String catalogName,\n+      String defaultDatabase,\n+      String[] baseNamespace,\n+      Catalog icebergCatalog,\n+      boolean cacheEnabled) {\n+    super(catalogName, defaultDatabase);\n+    this.originalCatalog = icebergCatalog;\n+    this.icebergCatalog = cacheEnabled ? CachingCatalog.wrap(icebergCatalog) : icebergCatalog;\n+    this.baseNamespace = baseNamespace;\n+    if (icebergCatalog instanceof SupportsNamespaces) {\n+      asNamespaceCatalog = (SupportsNamespaces) icebergCatalog;\n+    } else {\n+      asNamespaceCatalog = null;\n+    }\n+  }\n+\n+  @Override\n+  public void open() throws CatalogException {\n+  }\n+\n+  @Override\n+  public void close() throws CatalogException {\n+    if (originalCatalog instanceof Closeable) {\n+      try {\n+        ((Closeable) originalCatalog).close();\n+      } catch (IOException e) {\n+        throw new CatalogException(e);\n+      }\n+    }\n+  }\n+\n+  private Namespace toNamespace(String database) {\n+    String[] namespace = new String[baseNamespace.length + 1];\n+    System.arraycopy(baseNamespace, 0, namespace, 0, baseNamespace.length);\n+    namespace[baseNamespace.length] = database;\n+    return Namespace.of(namespace);\n+  }\n+\n+  private TableIdentifier toIdentifier(ObjectPath path) {\n+    return TableIdentifier.of(toNamespace(path.getDatabaseName()), path.getObjectName());\n+  }\n+\n+  @Override\n+  public List<String> listDatabases() throws CatalogException {\n+    if (asNamespaceCatalog == null) {\n+      return Collections.singletonList(getDefaultDatabase());\n+    }\n+\n+    return listAllNamespaces(Namespace.empty()).stream()\n+        .map(n -> n.level(n.levels().length - 1))\n+        .collect(Collectors.toList());\n+  }\n+\n+  private List<Namespace> listAllNamespaces(Namespace namespace) {\n+    if (asNamespaceCatalog == null) {\n+      throw new RuntimeException(\"The asNamespaceCatalog should not be null.\");\n+    }\n+\n+    String[] levels = namespace.levels();\n+    if (levels.length == baseNamespace.length + 1) {\n+      return Collections.singletonList(namespace);\n+    }\n+    if (levels.length < baseNamespace.length + 1) {\n+      for (int i = 0; i < levels.length; i++) {\n+        if (!baseNamespace[i].equals(levels[i])) {\n+          return Collections.emptyList();\n+        }\n+      }\n+      List<Namespace> ret = new ArrayList<>();\n+      asNamespaceCatalog.listNamespaces(namespace).forEach(n -> ret.addAll(listAllNamespaces(n)));\n+      return ret;\n+    }\n+    return Collections.emptyList();\n+  }\n+\n+  @Override\n+  public CatalogDatabase getDatabase(String databaseName) throws DatabaseNotExistException, CatalogException {\n+    if (asNamespaceCatalog == null) {\n+      if (!getDefaultDatabase().equals(databaseName)) {\n+        throw new DatabaseNotExistException(getName(), databaseName);\n+      } else {\n+        return new CatalogDatabaseImpl(new HashMap<>(), \"\");\n+      }\n+    } else {\n+      try {\n+        Map<String, String> metadata =\n+            new HashMap<>(asNamespaceCatalog.loadNamespaceMetadata(toNamespace(databaseName)));\n+        String comment = metadata.remove(\"comment\");\n+        return new CatalogDatabaseImpl(metadata, comment);\n+      } catch (NoSuchNamespaceException e) {\n+        throw new DatabaseNotExistException(getName(), databaseName, e);\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public boolean databaseExists(String databaseName) throws CatalogException {\n+    try {\n+      getDatabase(databaseName);\n+      return true;\n+    } catch (DatabaseNotExistException ignore) {\n+      return false;\n+    }\n+  }\n+\n+  @Override\n+  public void createDatabase(String name, CatalogDatabase database, boolean ignoreIfExists)\n+      throws DatabaseAlreadyExistException, CatalogException {\n+    if (asNamespaceCatalog != null) {\n+      try {\n+        asNamespaceCatalog.createNamespace(\n+            toNamespace(name),\n+            mergeComment(database.getProperties(), database.getComment()));\n+      } catch (AlreadyExistsException e) {\n+        if (!ignoreIfExists) {\n+          throw new DatabaseAlreadyExistException(getName(), name, e);\n+        }\n+      }\n+    } else {\n+      throw new UnsupportedOperationException(\"Namespaces are not supported by catalog: \" + getName());\n+    }\n+  }\n+\n+  private Map<String, String> mergeComment(Map<String, String> metadata, String comment) {\n+    Map<String, String> ret = new HashMap<>(metadata);\n+    if (metadata.containsKey(\"comment\")) {\n+      throw new CatalogException(\"Database properties should not contain key: 'comment'.\");\n+    }\n+    if (!StringUtils.isNullOrWhitespaceOnly(comment)) {\n+      ret.put(\"comment\", comment);\n+    }\n+    return ret;\n+  }\n+\n+  @Override\n+  public void dropDatabase(String name, boolean ignoreIfNotExists, boolean cascade)\n+      throws DatabaseNotExistException, DatabaseNotEmptyException, CatalogException {\n+    if (asNamespaceCatalog != null) {\n+      try {\n+        boolean success = asNamespaceCatalog.dropNamespace(toNamespace(name));\n+        if (!success && !ignoreIfNotExists) {\n+          throw new DatabaseNotExistException(getName(), name);\n+        }\n+      } catch (NoSuchNamespaceException e) {\n+        if (!ignoreIfNotExists) {\n+          throw new DatabaseNotExistException(getName(), name, e);\n+        }\n+      } catch (NamespaceNotEmptyException e) {\n+        throw new DatabaseNotEmptyException(getName(), name, e);\n+      }\n+    } else {\n+      if (!ignoreIfNotExists) {\n+        throw new DatabaseNotExistException(getName(), name);\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public void alterDatabase(String name, CatalogDatabase newDatabase, boolean ignoreIfNotExists)\n+      throws DatabaseNotExistException, CatalogException {\n+    if (asNamespaceCatalog != null) {\n+      Namespace namespace = toNamespace(name);\n+      Map<String, String> updates = Maps.newHashMap();\n+      Set<String> removals = Sets.newHashSet();\n+\n+      try {\n+        Map<String, String> oldOptions = asNamespaceCatalog.loadNamespaceMetadata(namespace);\n+        Map<String, String> newOptions = mergeComment(newDatabase.getProperties(), newDatabase.getComment());\n+\n+        for (String key : oldOptions.keySet()) {\n+          if (!newOptions.containsKey(key)) {\n+            removals.add(key);\n+          }\n+        }\n+\n+        for (Map.Entry<String, String> entry : newOptions.entrySet()) {\n+          if (!entry.getValue().equals(oldOptions.get(entry.getKey()))) {\n+            updates.put(entry.getKey(), entry.getValue());\n+          }\n+        }\n+\n+        if (!updates.isEmpty()) {\n+          asNamespaceCatalog.setProperties(namespace, updates);\n+        }\n+\n+        if (!removals.isEmpty()) {\n+          asNamespaceCatalog.removeProperties(namespace, removals);\n+        }\n+\n+      } catch (org.apache.iceberg.exceptions.NoSuchNamespaceException e) {\n+        if (!ignoreIfNotExists) {\n+          throw new DatabaseNotExistException(getName(), name, e);\n+        }\n+      }\n+    } else {\n+      if (!ignoreIfNotExists) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "248278f444044d11233d41b81bfcb999f63dadb5"}, "originalPosition": 277}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2NzM2NjAw", "url": "https://github.com/apache/iceberg/pull/1182#pullrequestreview-446736600", "createdAt": "2020-07-10T22:41:37Z", "commit": {"oid": "248278f444044d11233d41b81bfcb999f63dadb5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMjo0MTozN1rOGwHiYw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMjo0MTozN1rOGwHiYw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzEwODMyMw==", "bodyText": "Passing an empty string is suspicious. Should that be null or omitted to let the impl default?", "url": "https://github.com/apache/iceberg/pull/1182#discussion_r453108323", "createdAt": "2020-07-10T22:41:37Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkCatalog.java", "diffHunk": "@@ -0,0 +1,508 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.catalog.AbstractCatalog;\n+import org.apache.flink.table.catalog.CatalogBaseTable;\n+import org.apache.flink.table.catalog.CatalogDatabase;\n+import org.apache.flink.table.catalog.CatalogDatabaseImpl;\n+import org.apache.flink.table.catalog.CatalogFunction;\n+import org.apache.flink.table.catalog.CatalogPartition;\n+import org.apache.flink.table.catalog.CatalogPartitionSpec;\n+import org.apache.flink.table.catalog.CatalogTableImpl;\n+import org.apache.flink.table.catalog.ObjectPath;\n+import org.apache.flink.table.catalog.exceptions.CatalogException;\n+import org.apache.flink.table.catalog.exceptions.DatabaseAlreadyExistException;\n+import org.apache.flink.table.catalog.exceptions.DatabaseNotEmptyException;\n+import org.apache.flink.table.catalog.exceptions.DatabaseNotExistException;\n+import org.apache.flink.table.catalog.exceptions.FunctionNotExistException;\n+import org.apache.flink.table.catalog.exceptions.TableAlreadyExistException;\n+import org.apache.flink.table.catalog.exceptions.TableNotExistException;\n+import org.apache.flink.table.catalog.stats.CatalogColumnStatistics;\n+import org.apache.flink.table.catalog.stats.CatalogTableStatistics;\n+import org.apache.flink.table.expressions.Expression;\n+import org.apache.flink.util.StringUtils;\n+import org.apache.iceberg.CachingCatalog;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.catalog.Catalog;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.apache.iceberg.relocated.com.google.common.collect.Sets;\n+\n+/**\n+ * A Flink Catalog implementation that wraps an Iceberg {@link Catalog}.\n+ * <p>\n+ * The mapping between Flink database and Iceberg namespace:\n+ * Supplying a base namespace for a given catalog, so if you have a catalog that supports a 2-level namespace, you\n+ * would supply the first level in the catalog configuration and the second level would be exposed as Flink databases.\n+ * <p>\n+ * The Iceberg table manages its partitions by itself. The partition of the Iceberg table is independent of the\n+ * partition of Flink.\n+ */\n+public class FlinkCatalog extends AbstractCatalog {\n+\n+  private final Catalog originalCatalog;\n+  private final Catalog icebergCatalog;\n+  private final String[] baseNamespace;\n+  private final SupportsNamespaces asNamespaceCatalog;\n+\n+  public FlinkCatalog(\n+      String catalogName,\n+      String defaultDatabase,\n+      String[] baseNamespace,\n+      Catalog icebergCatalog,\n+      boolean cacheEnabled) {\n+    super(catalogName, defaultDatabase);\n+    this.originalCatalog = icebergCatalog;\n+    this.icebergCatalog = cacheEnabled ? CachingCatalog.wrap(icebergCatalog) : icebergCatalog;\n+    this.baseNamespace = baseNamespace;\n+    if (icebergCatalog instanceof SupportsNamespaces) {\n+      asNamespaceCatalog = (SupportsNamespaces) icebergCatalog;\n+    } else {\n+      asNamespaceCatalog = null;\n+    }\n+  }\n+\n+  @Override\n+  public void open() throws CatalogException {\n+  }\n+\n+  @Override\n+  public void close() throws CatalogException {\n+    if (originalCatalog instanceof Closeable) {\n+      try {\n+        ((Closeable) originalCatalog).close();\n+      } catch (IOException e) {\n+        throw new CatalogException(e);\n+      }\n+    }\n+  }\n+\n+  private Namespace toNamespace(String database) {\n+    String[] namespace = new String[baseNamespace.length + 1];\n+    System.arraycopy(baseNamespace, 0, namespace, 0, baseNamespace.length);\n+    namespace[baseNamespace.length] = database;\n+    return Namespace.of(namespace);\n+  }\n+\n+  private TableIdentifier toIdentifier(ObjectPath path) {\n+    return TableIdentifier.of(toNamespace(path.getDatabaseName()), path.getObjectName());\n+  }\n+\n+  @Override\n+  public List<String> listDatabases() throws CatalogException {\n+    if (asNamespaceCatalog == null) {\n+      return Collections.singletonList(getDefaultDatabase());\n+    }\n+\n+    return listAllNamespaces(Namespace.empty()).stream()\n+        .map(n -> n.level(n.levels().length - 1))\n+        .collect(Collectors.toList());\n+  }\n+\n+  private List<Namespace> listAllNamespaces(Namespace namespace) {\n+    if (asNamespaceCatalog == null) {\n+      throw new RuntimeException(\"The asNamespaceCatalog should not be null.\");\n+    }\n+\n+    String[] levels = namespace.levels();\n+    if (levels.length == baseNamespace.length + 1) {\n+      return Collections.singletonList(namespace);\n+    }\n+    if (levels.length < baseNamespace.length + 1) {\n+      for (int i = 0; i < levels.length; i++) {\n+        if (!baseNamespace[i].equals(levels[i])) {\n+          return Collections.emptyList();\n+        }\n+      }\n+      List<Namespace> ret = new ArrayList<>();\n+      asNamespaceCatalog.listNamespaces(namespace).forEach(n -> ret.addAll(listAllNamespaces(n)));\n+      return ret;\n+    }\n+    return Collections.emptyList();\n+  }\n+\n+  @Override\n+  public CatalogDatabase getDatabase(String databaseName) throws DatabaseNotExistException, CatalogException {\n+    if (asNamespaceCatalog == null) {\n+      if (!getDefaultDatabase().equals(databaseName)) {\n+        throw new DatabaseNotExistException(getName(), databaseName);\n+      } else {\n+        return new CatalogDatabaseImpl(new HashMap<>(), \"\");\n+      }\n+    } else {\n+      try {\n+        Map<String, String> metadata =\n+            new HashMap<>(asNamespaceCatalog.loadNamespaceMetadata(toNamespace(databaseName)));\n+        String comment = metadata.remove(\"comment\");\n+        return new CatalogDatabaseImpl(metadata, comment);\n+      } catch (NoSuchNamespaceException e) {\n+        throw new DatabaseNotExistException(getName(), databaseName, e);\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public boolean databaseExists(String databaseName) throws CatalogException {\n+    try {\n+      getDatabase(databaseName);\n+      return true;\n+    } catch (DatabaseNotExistException ignore) {\n+      return false;\n+    }\n+  }\n+\n+  @Override\n+  public void createDatabase(String name, CatalogDatabase database, boolean ignoreIfExists)\n+      throws DatabaseAlreadyExistException, CatalogException {\n+    if (asNamespaceCatalog != null) {\n+      try {\n+        asNamespaceCatalog.createNamespace(\n+            toNamespace(name),\n+            mergeComment(database.getProperties(), database.getComment()));\n+      } catch (AlreadyExistsException e) {\n+        if (!ignoreIfExists) {\n+          throw new DatabaseAlreadyExistException(getName(), name, e);\n+        }\n+      }\n+    } else {\n+      throw new UnsupportedOperationException(\"Namespaces are not supported by catalog: \" + getName());\n+    }\n+  }\n+\n+  private Map<String, String> mergeComment(Map<String, String> metadata, String comment) {\n+    Map<String, String> ret = new HashMap<>(metadata);\n+    if (metadata.containsKey(\"comment\")) {\n+      throw new CatalogException(\"Database properties should not contain key: 'comment'.\");\n+    }\n+    if (!StringUtils.isNullOrWhitespaceOnly(comment)) {\n+      ret.put(\"comment\", comment);\n+    }\n+    return ret;\n+  }\n+\n+  @Override\n+  public void dropDatabase(String name, boolean ignoreIfNotExists, boolean cascade)\n+      throws DatabaseNotExistException, DatabaseNotEmptyException, CatalogException {\n+    if (asNamespaceCatalog != null) {\n+      try {\n+        boolean success = asNamespaceCatalog.dropNamespace(toNamespace(name));\n+        if (!success && !ignoreIfNotExists) {\n+          throw new DatabaseNotExistException(getName(), name);\n+        }\n+      } catch (NoSuchNamespaceException e) {\n+        if (!ignoreIfNotExists) {\n+          throw new DatabaseNotExistException(getName(), name, e);\n+        }\n+      } catch (NamespaceNotEmptyException e) {\n+        throw new DatabaseNotEmptyException(getName(), name, e);\n+      }\n+    } else {\n+      if (!ignoreIfNotExists) {\n+        throw new DatabaseNotExistException(getName(), name);\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public void alterDatabase(String name, CatalogDatabase newDatabase, boolean ignoreIfNotExists)\n+      throws DatabaseNotExistException, CatalogException {\n+    if (asNamespaceCatalog != null) {\n+      Namespace namespace = toNamespace(name);\n+      Map<String, String> updates = Maps.newHashMap();\n+      Set<String> removals = Sets.newHashSet();\n+\n+      try {\n+        Map<String, String> oldOptions = asNamespaceCatalog.loadNamespaceMetadata(namespace);\n+        Map<String, String> newOptions = mergeComment(newDatabase.getProperties(), newDatabase.getComment());\n+\n+        for (String key : oldOptions.keySet()) {\n+          if (!newOptions.containsKey(key)) {\n+            removals.add(key);\n+          }\n+        }\n+\n+        for (Map.Entry<String, String> entry : newOptions.entrySet()) {\n+          if (!entry.getValue().equals(oldOptions.get(entry.getKey()))) {\n+            updates.put(entry.getKey(), entry.getValue());\n+          }\n+        }\n+\n+        if (!updates.isEmpty()) {\n+          asNamespaceCatalog.setProperties(namespace, updates);\n+        }\n+\n+        if (!removals.isEmpty()) {\n+          asNamespaceCatalog.removeProperties(namespace, removals);\n+        }\n+\n+      } catch (org.apache.iceberg.exceptions.NoSuchNamespaceException e) {\n+        if (!ignoreIfNotExists) {\n+          throw new DatabaseNotExistException(getName(), name, e);\n+        }\n+      }\n+    } else {\n+      if (!ignoreIfNotExists) {\n+        throw new DatabaseNotExistException(getName(), name);\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public List<String> listTables(String databaseName) throws DatabaseNotExistException, CatalogException {\n+    try {\n+      return icebergCatalog.listTables(toNamespace(databaseName)).stream()\n+          .map(TableIdentifier::name)\n+          .collect(Collectors.toList());\n+    } catch (NoSuchNamespaceException e) {\n+      throw new DatabaseNotExistException(getName(), databaseName, e);\n+    }\n+  }\n+\n+  @Override\n+  public CatalogBaseTable getTable(ObjectPath tablePath) throws TableNotExistException, CatalogException {\n+    try {\n+      Table table = icebergCatalog.loadTable(toIdentifier(tablePath));\n+      TableSchema tableSchema = FlinkSchemaUtil.toSchema(FlinkSchemaUtil.convert(table.schema()));\n+\n+      // NOTE: We can not create a IcebergCatalogTable, because Flink optimizer may use CatalogTableImpl to copy a new\n+      // catalog table.\n+      // Let's re-loading table from Iceberg catalog when creating source/sink operators.\n+      return new CatalogTableImpl(tableSchema, table.properties(), \"\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "248278f444044d11233d41b81bfcb999f63dadb5"}, "originalPosition": 303}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2NzM3MjQz", "url": "https://github.com/apache/iceberg/pull/1182#pullrequestreview-446737243", "createdAt": "2020-07-10T22:43:48Z", "commit": {"oid": "248278f444044d11233d41b81bfcb999f63dadb5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMjo0Mzo0OFrOGwHkkw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMjo0Mzo0OFrOGwHkkw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzEwODg4Mw==", "bodyText": "Can we add partitioning to the Flink DDL parser instead? That seems like a more appropriate place for it.\nOtherwise, I'd recommend just using the PartitionSpecParser.fromJson method.", "url": "https://github.com/apache/iceberg/pull/1182#discussion_r453108883", "createdAt": "2020-07-10T22:43:48Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkCatalog.java", "diffHunk": "@@ -0,0 +1,508 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.catalog.AbstractCatalog;\n+import org.apache.flink.table.catalog.CatalogBaseTable;\n+import org.apache.flink.table.catalog.CatalogDatabase;\n+import org.apache.flink.table.catalog.CatalogDatabaseImpl;\n+import org.apache.flink.table.catalog.CatalogFunction;\n+import org.apache.flink.table.catalog.CatalogPartition;\n+import org.apache.flink.table.catalog.CatalogPartitionSpec;\n+import org.apache.flink.table.catalog.CatalogTableImpl;\n+import org.apache.flink.table.catalog.ObjectPath;\n+import org.apache.flink.table.catalog.exceptions.CatalogException;\n+import org.apache.flink.table.catalog.exceptions.DatabaseAlreadyExistException;\n+import org.apache.flink.table.catalog.exceptions.DatabaseNotEmptyException;\n+import org.apache.flink.table.catalog.exceptions.DatabaseNotExistException;\n+import org.apache.flink.table.catalog.exceptions.FunctionNotExistException;\n+import org.apache.flink.table.catalog.exceptions.TableAlreadyExistException;\n+import org.apache.flink.table.catalog.exceptions.TableNotExistException;\n+import org.apache.flink.table.catalog.stats.CatalogColumnStatistics;\n+import org.apache.flink.table.catalog.stats.CatalogTableStatistics;\n+import org.apache.flink.table.expressions.Expression;\n+import org.apache.flink.util.StringUtils;\n+import org.apache.iceberg.CachingCatalog;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.catalog.Catalog;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.apache.iceberg.relocated.com.google.common.collect.Sets;\n+\n+/**\n+ * A Flink Catalog implementation that wraps an Iceberg {@link Catalog}.\n+ * <p>\n+ * The mapping between Flink database and Iceberg namespace:\n+ * Supplying a base namespace for a given catalog, so if you have a catalog that supports a 2-level namespace, you\n+ * would supply the first level in the catalog configuration and the second level would be exposed as Flink databases.\n+ * <p>\n+ * The Iceberg table manages its partitions by itself. The partition of the Iceberg table is independent of the\n+ * partition of Flink.\n+ */\n+public class FlinkCatalog extends AbstractCatalog {\n+\n+  private final Catalog originalCatalog;\n+  private final Catalog icebergCatalog;\n+  private final String[] baseNamespace;\n+  private final SupportsNamespaces asNamespaceCatalog;\n+\n+  public FlinkCatalog(\n+      String catalogName,\n+      String defaultDatabase,\n+      String[] baseNamespace,\n+      Catalog icebergCatalog,\n+      boolean cacheEnabled) {\n+    super(catalogName, defaultDatabase);\n+    this.originalCatalog = icebergCatalog;\n+    this.icebergCatalog = cacheEnabled ? CachingCatalog.wrap(icebergCatalog) : icebergCatalog;\n+    this.baseNamespace = baseNamespace;\n+    if (icebergCatalog instanceof SupportsNamespaces) {\n+      asNamespaceCatalog = (SupportsNamespaces) icebergCatalog;\n+    } else {\n+      asNamespaceCatalog = null;\n+    }\n+  }\n+\n+  @Override\n+  public void open() throws CatalogException {\n+  }\n+\n+  @Override\n+  public void close() throws CatalogException {\n+    if (originalCatalog instanceof Closeable) {\n+      try {\n+        ((Closeable) originalCatalog).close();\n+      } catch (IOException e) {\n+        throw new CatalogException(e);\n+      }\n+    }\n+  }\n+\n+  private Namespace toNamespace(String database) {\n+    String[] namespace = new String[baseNamespace.length + 1];\n+    System.arraycopy(baseNamespace, 0, namespace, 0, baseNamespace.length);\n+    namespace[baseNamespace.length] = database;\n+    return Namespace.of(namespace);\n+  }\n+\n+  private TableIdentifier toIdentifier(ObjectPath path) {\n+    return TableIdentifier.of(toNamespace(path.getDatabaseName()), path.getObjectName());\n+  }\n+\n+  @Override\n+  public List<String> listDatabases() throws CatalogException {\n+    if (asNamespaceCatalog == null) {\n+      return Collections.singletonList(getDefaultDatabase());\n+    }\n+\n+    return listAllNamespaces(Namespace.empty()).stream()\n+        .map(n -> n.level(n.levels().length - 1))\n+        .collect(Collectors.toList());\n+  }\n+\n+  private List<Namespace> listAllNamespaces(Namespace namespace) {\n+    if (asNamespaceCatalog == null) {\n+      throw new RuntimeException(\"The asNamespaceCatalog should not be null.\");\n+    }\n+\n+    String[] levels = namespace.levels();\n+    if (levels.length == baseNamespace.length + 1) {\n+      return Collections.singletonList(namespace);\n+    }\n+    if (levels.length < baseNamespace.length + 1) {\n+      for (int i = 0; i < levels.length; i++) {\n+        if (!baseNamespace[i].equals(levels[i])) {\n+          return Collections.emptyList();\n+        }\n+      }\n+      List<Namespace> ret = new ArrayList<>();\n+      asNamespaceCatalog.listNamespaces(namespace).forEach(n -> ret.addAll(listAllNamespaces(n)));\n+      return ret;\n+    }\n+    return Collections.emptyList();\n+  }\n+\n+  @Override\n+  public CatalogDatabase getDatabase(String databaseName) throws DatabaseNotExistException, CatalogException {\n+    if (asNamespaceCatalog == null) {\n+      if (!getDefaultDatabase().equals(databaseName)) {\n+        throw new DatabaseNotExistException(getName(), databaseName);\n+      } else {\n+        return new CatalogDatabaseImpl(new HashMap<>(), \"\");\n+      }\n+    } else {\n+      try {\n+        Map<String, String> metadata =\n+            new HashMap<>(asNamespaceCatalog.loadNamespaceMetadata(toNamespace(databaseName)));\n+        String comment = metadata.remove(\"comment\");\n+        return new CatalogDatabaseImpl(metadata, comment);\n+      } catch (NoSuchNamespaceException e) {\n+        throw new DatabaseNotExistException(getName(), databaseName, e);\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public boolean databaseExists(String databaseName) throws CatalogException {\n+    try {\n+      getDatabase(databaseName);\n+      return true;\n+    } catch (DatabaseNotExistException ignore) {\n+      return false;\n+    }\n+  }\n+\n+  @Override\n+  public void createDatabase(String name, CatalogDatabase database, boolean ignoreIfExists)\n+      throws DatabaseAlreadyExistException, CatalogException {\n+    if (asNamespaceCatalog != null) {\n+      try {\n+        asNamespaceCatalog.createNamespace(\n+            toNamespace(name),\n+            mergeComment(database.getProperties(), database.getComment()));\n+      } catch (AlreadyExistsException e) {\n+        if (!ignoreIfExists) {\n+          throw new DatabaseAlreadyExistException(getName(), name, e);\n+        }\n+      }\n+    } else {\n+      throw new UnsupportedOperationException(\"Namespaces are not supported by catalog: \" + getName());\n+    }\n+  }\n+\n+  private Map<String, String> mergeComment(Map<String, String> metadata, String comment) {\n+    Map<String, String> ret = new HashMap<>(metadata);\n+    if (metadata.containsKey(\"comment\")) {\n+      throw new CatalogException(\"Database properties should not contain key: 'comment'.\");\n+    }\n+    if (!StringUtils.isNullOrWhitespaceOnly(comment)) {\n+      ret.put(\"comment\", comment);\n+    }\n+    return ret;\n+  }\n+\n+  @Override\n+  public void dropDatabase(String name, boolean ignoreIfNotExists, boolean cascade)\n+      throws DatabaseNotExistException, DatabaseNotEmptyException, CatalogException {\n+    if (asNamespaceCatalog != null) {\n+      try {\n+        boolean success = asNamespaceCatalog.dropNamespace(toNamespace(name));\n+        if (!success && !ignoreIfNotExists) {\n+          throw new DatabaseNotExistException(getName(), name);\n+        }\n+      } catch (NoSuchNamespaceException e) {\n+        if (!ignoreIfNotExists) {\n+          throw new DatabaseNotExistException(getName(), name, e);\n+        }\n+      } catch (NamespaceNotEmptyException e) {\n+        throw new DatabaseNotEmptyException(getName(), name, e);\n+      }\n+    } else {\n+      if (!ignoreIfNotExists) {\n+        throw new DatabaseNotExistException(getName(), name);\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public void alterDatabase(String name, CatalogDatabase newDatabase, boolean ignoreIfNotExists)\n+      throws DatabaseNotExistException, CatalogException {\n+    if (asNamespaceCatalog != null) {\n+      Namespace namespace = toNamespace(name);\n+      Map<String, String> updates = Maps.newHashMap();\n+      Set<String> removals = Sets.newHashSet();\n+\n+      try {\n+        Map<String, String> oldOptions = asNamespaceCatalog.loadNamespaceMetadata(namespace);\n+        Map<String, String> newOptions = mergeComment(newDatabase.getProperties(), newDatabase.getComment());\n+\n+        for (String key : oldOptions.keySet()) {\n+          if (!newOptions.containsKey(key)) {\n+            removals.add(key);\n+          }\n+        }\n+\n+        for (Map.Entry<String, String> entry : newOptions.entrySet()) {\n+          if (!entry.getValue().equals(oldOptions.get(entry.getKey()))) {\n+            updates.put(entry.getKey(), entry.getValue());\n+          }\n+        }\n+\n+        if (!updates.isEmpty()) {\n+          asNamespaceCatalog.setProperties(namespace, updates);\n+        }\n+\n+        if (!removals.isEmpty()) {\n+          asNamespaceCatalog.removeProperties(namespace, removals);\n+        }\n+\n+      } catch (org.apache.iceberg.exceptions.NoSuchNamespaceException e) {\n+        if (!ignoreIfNotExists) {\n+          throw new DatabaseNotExistException(getName(), name, e);\n+        }\n+      }\n+    } else {\n+      if (!ignoreIfNotExists) {\n+        throw new DatabaseNotExistException(getName(), name);\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public List<String> listTables(String databaseName) throws DatabaseNotExistException, CatalogException {\n+    try {\n+      return icebergCatalog.listTables(toNamespace(databaseName)).stream()\n+          .map(TableIdentifier::name)\n+          .collect(Collectors.toList());\n+    } catch (NoSuchNamespaceException e) {\n+      throw new DatabaseNotExistException(getName(), databaseName, e);\n+    }\n+  }\n+\n+  @Override\n+  public CatalogBaseTable getTable(ObjectPath tablePath) throws TableNotExistException, CatalogException {\n+    try {\n+      Table table = icebergCatalog.loadTable(toIdentifier(tablePath));\n+      TableSchema tableSchema = FlinkSchemaUtil.toSchema(FlinkSchemaUtil.convert(table.schema()));\n+\n+      // NOTE: We can not create a IcebergCatalogTable, because Flink optimizer may use CatalogTableImpl to copy a new\n+      // catalog table.\n+      // Let's re-loading table from Iceberg catalog when creating source/sink operators.\n+      return new CatalogTableImpl(tableSchema, table.properties(), \"\");\n+    } catch (org.apache.iceberg.exceptions.NoSuchTableException e) {\n+      throw new TableNotExistException(getName(), tablePath, e);\n+    }\n+  }\n+\n+  @Override\n+  public boolean tableExists(ObjectPath tablePath) throws CatalogException {\n+    return icebergCatalog.tableExists(toIdentifier(tablePath));\n+  }\n+\n+  @Override\n+  public void dropTable(ObjectPath tablePath, boolean ignoreIfNotExists)\n+      throws TableNotExistException, CatalogException {\n+    try {\n+      icebergCatalog.dropTable(toIdentifier(tablePath));\n+    } catch (org.apache.iceberg.exceptions.NoSuchTableException e) {\n+      throw new TableNotExistException(getName(), tablePath, e);\n+    }\n+  }\n+\n+  @Override\n+  public void renameTable(ObjectPath tablePath, String newTableName, boolean ignoreIfNotExists)\n+      throws TableNotExistException, TableAlreadyExistException, CatalogException {\n+    try {\n+      icebergCatalog.renameTable(\n+          toIdentifier(tablePath),\n+          toIdentifier(new ObjectPath(tablePath.getDatabaseName(), newTableName)));\n+    } catch (org.apache.iceberg.exceptions.NoSuchTableException e) {\n+      throw new TableNotExistException(getName(), tablePath, e);\n+    } catch (AlreadyExistsException e) {\n+      throw new TableAlreadyExistException(getName(), tablePath, e);\n+    }\n+  }\n+\n+  /**\n+   * TODO Implement DDL-string parser for PartitionSpec.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "248278f444044d11233d41b81bfcb999f63dadb5"}, "originalPosition": 339}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2NzM4MTc1", "url": "https://github.com/apache/iceberg/pull/1182#pullrequestreview-446738175", "createdAt": "2020-07-10T22:47:20Z", "commit": {"oid": "248278f444044d11233d41b81bfcb999f63dadb5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMjo0NzoyMFrOGwHn-w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMjo0NzoyMFrOGwHn-w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzEwOTc1NQ==", "bodyText": "We prefer two options for formatting argument lists. Either aligned with the first argument:\npublic void alterPartition(ObjectPath tablePath, CatalogPartitionSpec partitionSpec, CatalogPartition newPartition,\n                           boolean ignoreIfNotExists) throws CatalogException {\n  ...\n}\nOr, indented by 2 indents (4 spaces) and aligned with that position:\npublic void alterPartition(\n    ObjectPath tablePath, CatalogPartitionSpec partitionSpec, CatalogPartition newPartition, boolean ignoreIfNotExists)\n    throws CatalogException {\n  ...\n}\nthrows can be on the next line, indented to the same place.", "url": "https://github.com/apache/iceberg/pull/1182#discussion_r453109755", "createdAt": "2020-07-10T22:47:20Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkCatalog.java", "diffHunk": "@@ -0,0 +1,508 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.io.Closeable;\n+import java.io.IOException;\n+import java.util.ArrayList;\n+import java.util.Collections;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.catalog.AbstractCatalog;\n+import org.apache.flink.table.catalog.CatalogBaseTable;\n+import org.apache.flink.table.catalog.CatalogDatabase;\n+import org.apache.flink.table.catalog.CatalogDatabaseImpl;\n+import org.apache.flink.table.catalog.CatalogFunction;\n+import org.apache.flink.table.catalog.CatalogPartition;\n+import org.apache.flink.table.catalog.CatalogPartitionSpec;\n+import org.apache.flink.table.catalog.CatalogTableImpl;\n+import org.apache.flink.table.catalog.ObjectPath;\n+import org.apache.flink.table.catalog.exceptions.CatalogException;\n+import org.apache.flink.table.catalog.exceptions.DatabaseAlreadyExistException;\n+import org.apache.flink.table.catalog.exceptions.DatabaseNotEmptyException;\n+import org.apache.flink.table.catalog.exceptions.DatabaseNotExistException;\n+import org.apache.flink.table.catalog.exceptions.FunctionNotExistException;\n+import org.apache.flink.table.catalog.exceptions.TableAlreadyExistException;\n+import org.apache.flink.table.catalog.exceptions.TableNotExistException;\n+import org.apache.flink.table.catalog.stats.CatalogColumnStatistics;\n+import org.apache.flink.table.catalog.stats.CatalogTableStatistics;\n+import org.apache.flink.table.expressions.Expression;\n+import org.apache.flink.util.StringUtils;\n+import org.apache.iceberg.CachingCatalog;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.catalog.Catalog;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.apache.iceberg.relocated.com.google.common.collect.Sets;\n+\n+/**\n+ * A Flink Catalog implementation that wraps an Iceberg {@link Catalog}.\n+ * <p>\n+ * The mapping between Flink database and Iceberg namespace:\n+ * Supplying a base namespace for a given catalog, so if you have a catalog that supports a 2-level namespace, you\n+ * would supply the first level in the catalog configuration and the second level would be exposed as Flink databases.\n+ * <p>\n+ * The Iceberg table manages its partitions by itself. The partition of the Iceberg table is independent of the\n+ * partition of Flink.\n+ */\n+public class FlinkCatalog extends AbstractCatalog {\n+\n+  private final Catalog originalCatalog;\n+  private final Catalog icebergCatalog;\n+  private final String[] baseNamespace;\n+  private final SupportsNamespaces asNamespaceCatalog;\n+\n+  public FlinkCatalog(\n+      String catalogName,\n+      String defaultDatabase,\n+      String[] baseNamespace,\n+      Catalog icebergCatalog,\n+      boolean cacheEnabled) {\n+    super(catalogName, defaultDatabase);\n+    this.originalCatalog = icebergCatalog;\n+    this.icebergCatalog = cacheEnabled ? CachingCatalog.wrap(icebergCatalog) : icebergCatalog;\n+    this.baseNamespace = baseNamespace;\n+    if (icebergCatalog instanceof SupportsNamespaces) {\n+      asNamespaceCatalog = (SupportsNamespaces) icebergCatalog;\n+    } else {\n+      asNamespaceCatalog = null;\n+    }\n+  }\n+\n+  @Override\n+  public void open() throws CatalogException {\n+  }\n+\n+  @Override\n+  public void close() throws CatalogException {\n+    if (originalCatalog instanceof Closeable) {\n+      try {\n+        ((Closeable) originalCatalog).close();\n+      } catch (IOException e) {\n+        throw new CatalogException(e);\n+      }\n+    }\n+  }\n+\n+  private Namespace toNamespace(String database) {\n+    String[] namespace = new String[baseNamespace.length + 1];\n+    System.arraycopy(baseNamespace, 0, namespace, 0, baseNamespace.length);\n+    namespace[baseNamespace.length] = database;\n+    return Namespace.of(namespace);\n+  }\n+\n+  private TableIdentifier toIdentifier(ObjectPath path) {\n+    return TableIdentifier.of(toNamespace(path.getDatabaseName()), path.getObjectName());\n+  }\n+\n+  @Override\n+  public List<String> listDatabases() throws CatalogException {\n+    if (asNamespaceCatalog == null) {\n+      return Collections.singletonList(getDefaultDatabase());\n+    }\n+\n+    return listAllNamespaces(Namespace.empty()).stream()\n+        .map(n -> n.level(n.levels().length - 1))\n+        .collect(Collectors.toList());\n+  }\n+\n+  private List<Namespace> listAllNamespaces(Namespace namespace) {\n+    if (asNamespaceCatalog == null) {\n+      throw new RuntimeException(\"The asNamespaceCatalog should not be null.\");\n+    }\n+\n+    String[] levels = namespace.levels();\n+    if (levels.length == baseNamespace.length + 1) {\n+      return Collections.singletonList(namespace);\n+    }\n+    if (levels.length < baseNamespace.length + 1) {\n+      for (int i = 0; i < levels.length; i++) {\n+        if (!baseNamespace[i].equals(levels[i])) {\n+          return Collections.emptyList();\n+        }\n+      }\n+      List<Namespace> ret = new ArrayList<>();\n+      asNamespaceCatalog.listNamespaces(namespace).forEach(n -> ret.addAll(listAllNamespaces(n)));\n+      return ret;\n+    }\n+    return Collections.emptyList();\n+  }\n+\n+  @Override\n+  public CatalogDatabase getDatabase(String databaseName) throws DatabaseNotExistException, CatalogException {\n+    if (asNamespaceCatalog == null) {\n+      if (!getDefaultDatabase().equals(databaseName)) {\n+        throw new DatabaseNotExistException(getName(), databaseName);\n+      } else {\n+        return new CatalogDatabaseImpl(new HashMap<>(), \"\");\n+      }\n+    } else {\n+      try {\n+        Map<String, String> metadata =\n+            new HashMap<>(asNamespaceCatalog.loadNamespaceMetadata(toNamespace(databaseName)));\n+        String comment = metadata.remove(\"comment\");\n+        return new CatalogDatabaseImpl(metadata, comment);\n+      } catch (NoSuchNamespaceException e) {\n+        throw new DatabaseNotExistException(getName(), databaseName, e);\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public boolean databaseExists(String databaseName) throws CatalogException {\n+    try {\n+      getDatabase(databaseName);\n+      return true;\n+    } catch (DatabaseNotExistException ignore) {\n+      return false;\n+    }\n+  }\n+\n+  @Override\n+  public void createDatabase(String name, CatalogDatabase database, boolean ignoreIfExists)\n+      throws DatabaseAlreadyExistException, CatalogException {\n+    if (asNamespaceCatalog != null) {\n+      try {\n+        asNamespaceCatalog.createNamespace(\n+            toNamespace(name),\n+            mergeComment(database.getProperties(), database.getComment()));\n+      } catch (AlreadyExistsException e) {\n+        if (!ignoreIfExists) {\n+          throw new DatabaseAlreadyExistException(getName(), name, e);\n+        }\n+      }\n+    } else {\n+      throw new UnsupportedOperationException(\"Namespaces are not supported by catalog: \" + getName());\n+    }\n+  }\n+\n+  private Map<String, String> mergeComment(Map<String, String> metadata, String comment) {\n+    Map<String, String> ret = new HashMap<>(metadata);\n+    if (metadata.containsKey(\"comment\")) {\n+      throw new CatalogException(\"Database properties should not contain key: 'comment'.\");\n+    }\n+    if (!StringUtils.isNullOrWhitespaceOnly(comment)) {\n+      ret.put(\"comment\", comment);\n+    }\n+    return ret;\n+  }\n+\n+  @Override\n+  public void dropDatabase(String name, boolean ignoreIfNotExists, boolean cascade)\n+      throws DatabaseNotExistException, DatabaseNotEmptyException, CatalogException {\n+    if (asNamespaceCatalog != null) {\n+      try {\n+        boolean success = asNamespaceCatalog.dropNamespace(toNamespace(name));\n+        if (!success && !ignoreIfNotExists) {\n+          throw new DatabaseNotExistException(getName(), name);\n+        }\n+      } catch (NoSuchNamespaceException e) {\n+        if (!ignoreIfNotExists) {\n+          throw new DatabaseNotExistException(getName(), name, e);\n+        }\n+      } catch (NamespaceNotEmptyException e) {\n+        throw new DatabaseNotEmptyException(getName(), name, e);\n+      }\n+    } else {\n+      if (!ignoreIfNotExists) {\n+        throw new DatabaseNotExistException(getName(), name);\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public void alterDatabase(String name, CatalogDatabase newDatabase, boolean ignoreIfNotExists)\n+      throws DatabaseNotExistException, CatalogException {\n+    if (asNamespaceCatalog != null) {\n+      Namespace namespace = toNamespace(name);\n+      Map<String, String> updates = Maps.newHashMap();\n+      Set<String> removals = Sets.newHashSet();\n+\n+      try {\n+        Map<String, String> oldOptions = asNamespaceCatalog.loadNamespaceMetadata(namespace);\n+        Map<String, String> newOptions = mergeComment(newDatabase.getProperties(), newDatabase.getComment());\n+\n+        for (String key : oldOptions.keySet()) {\n+          if (!newOptions.containsKey(key)) {\n+            removals.add(key);\n+          }\n+        }\n+\n+        for (Map.Entry<String, String> entry : newOptions.entrySet()) {\n+          if (!entry.getValue().equals(oldOptions.get(entry.getKey()))) {\n+            updates.put(entry.getKey(), entry.getValue());\n+          }\n+        }\n+\n+        if (!updates.isEmpty()) {\n+          asNamespaceCatalog.setProperties(namespace, updates);\n+        }\n+\n+        if (!removals.isEmpty()) {\n+          asNamespaceCatalog.removeProperties(namespace, removals);\n+        }\n+\n+      } catch (org.apache.iceberg.exceptions.NoSuchNamespaceException e) {\n+        if (!ignoreIfNotExists) {\n+          throw new DatabaseNotExistException(getName(), name, e);\n+        }\n+      }\n+    } else {\n+      if (!ignoreIfNotExists) {\n+        throw new DatabaseNotExistException(getName(), name);\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public List<String> listTables(String databaseName) throws DatabaseNotExistException, CatalogException {\n+    try {\n+      return icebergCatalog.listTables(toNamespace(databaseName)).stream()\n+          .map(TableIdentifier::name)\n+          .collect(Collectors.toList());\n+    } catch (NoSuchNamespaceException e) {\n+      throw new DatabaseNotExistException(getName(), databaseName, e);\n+    }\n+  }\n+\n+  @Override\n+  public CatalogBaseTable getTable(ObjectPath tablePath) throws TableNotExistException, CatalogException {\n+    try {\n+      Table table = icebergCatalog.loadTable(toIdentifier(tablePath));\n+      TableSchema tableSchema = FlinkSchemaUtil.toSchema(FlinkSchemaUtil.convert(table.schema()));\n+\n+      // NOTE: We can not create a IcebergCatalogTable, because Flink optimizer may use CatalogTableImpl to copy a new\n+      // catalog table.\n+      // Let's re-loading table from Iceberg catalog when creating source/sink operators.\n+      return new CatalogTableImpl(tableSchema, table.properties(), \"\");\n+    } catch (org.apache.iceberg.exceptions.NoSuchTableException e) {\n+      throw new TableNotExistException(getName(), tablePath, e);\n+    }\n+  }\n+\n+  @Override\n+  public boolean tableExists(ObjectPath tablePath) throws CatalogException {\n+    return icebergCatalog.tableExists(toIdentifier(tablePath));\n+  }\n+\n+  @Override\n+  public void dropTable(ObjectPath tablePath, boolean ignoreIfNotExists)\n+      throws TableNotExistException, CatalogException {\n+    try {\n+      icebergCatalog.dropTable(toIdentifier(tablePath));\n+    } catch (org.apache.iceberg.exceptions.NoSuchTableException e) {\n+      throw new TableNotExistException(getName(), tablePath, e);\n+    }\n+  }\n+\n+  @Override\n+  public void renameTable(ObjectPath tablePath, String newTableName, boolean ignoreIfNotExists)\n+      throws TableNotExistException, TableAlreadyExistException, CatalogException {\n+    try {\n+      icebergCatalog.renameTable(\n+          toIdentifier(tablePath),\n+          toIdentifier(new ObjectPath(tablePath.getDatabaseName(), newTableName)));\n+    } catch (org.apache.iceberg.exceptions.NoSuchTableException e) {\n+      throw new TableNotExistException(getName(), tablePath, e);\n+    } catch (AlreadyExistsException e) {\n+      throw new TableAlreadyExistException(getName(), tablePath, e);\n+    }\n+  }\n+\n+  /**\n+   * TODO Implement DDL-string parser for PartitionSpec.\n+   */\n+  @Override\n+  public void createTable(ObjectPath tablePath, CatalogBaseTable table, boolean ignoreIfExists)\n+      throws CatalogException {\n+    throw new UnsupportedOperationException(\"Not support createTable now.\");\n+  }\n+\n+  @Override\n+  public void alterTable(ObjectPath tablePath, CatalogBaseTable newTable, boolean ignoreIfNotExists)\n+      throws CatalogException {\n+    throw new UnsupportedOperationException(\"Not support alterTable now.\");\n+  }\n+\n+  // ------------------------------ Unsupported methods ---------------------------------------------\n+\n+  @Override\n+  public List<String> listViews(String databaseName) throws CatalogException {\n+    return Collections.emptyList();\n+  }\n+\n+  @Override\n+  public CatalogPartition getPartition(\n+      ObjectPath tablePath, CatalogPartitionSpec partitionSpec\n+  ) throws CatalogException {\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  @Override\n+  public boolean partitionExists(ObjectPath tablePath, CatalogPartitionSpec partitionSpec) throws CatalogException {\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  @Override\n+  public void createPartition(\n+      ObjectPath tablePath, CatalogPartitionSpec partitionSpec, CatalogPartition partition, boolean ignoreIfExists\n+  ) throws CatalogException {\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  @Override\n+  public void dropPartition(ObjectPath tablePath, CatalogPartitionSpec partitionSpec, boolean ignoreIfNotExists)\n+      throws CatalogException {\n+    throw new UnsupportedOperationException();\n+  }\n+\n+  @Override\n+  public void alterPartition(\n+      ObjectPath tablePath, CatalogPartitionSpec partitionSpec, CatalogPartition newPartition, boolean ignoreIfNotExists\n+  ) throws CatalogException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "248278f444044d11233d41b81bfcb999f63dadb5"}, "originalPosition": 388}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2NzM5MTU2", "url": "https://github.com/apache/iceberg/pull/1182#pullrequestreview-446739156", "createdAt": "2020-07-10T22:51:03Z", "commit": {"oid": "248278f444044d11233d41b81bfcb999f63dadb5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMjo1MTowM1rOGwHrjg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMjo1MTowM1rOGwHrjg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzExMDY3MA==", "bodyText": "This should also be labelled (Hadoop catalog only) because the Hive catalog supports only database.", "url": "https://github.com/apache/iceberg/pull/1182#discussion_r453110670", "createdAt": "2020-07-10T22:51:03Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkCatalogFactory.java", "diffHunk": "@@ -0,0 +1,133 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.flink.configuration.GlobalConfiguration;\n+import org.apache.flink.runtime.util.HadoopUtils;\n+import org.apache.flink.table.catalog.Catalog;\n+import org.apache.flink.table.descriptors.CatalogDescriptorValidator;\n+import org.apache.flink.table.factories.CatalogFactory;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.hadoop.HadoopCatalog;\n+import org.apache.iceberg.hive.HiveCatalog;\n+import org.apache.iceberg.relocated.com.google.common.base.Splitter;\n+\n+/**\n+ * A Flink Catalog factory implementation that creates {@link FlinkCatalog}.\n+ * <p>\n+ * This supports the following catalog configuration options:\n+ * <ul>\n+ *   <li><tt>type</tt> - Flink catalog factory key, should be \"iceberg\"</li>\n+ *   <li><tt>catalog-type</tt> - iceberg catalog type, \"hive\" or \"hadoop\"</li>\n+ *   <li><tt>uri</tt> - the Hive Metastore URI (Hive catalog only)</li>\n+ *   <li><tt>clients</tt> - the Hive Client Pool Size (Hive catalog only)</li>\n+ *   <li><tt>warehouse</tt> - the warehouse path (Hadoop catalog only)</li>\n+ *   <li><tt>default-database</tt> - a database name to use as the default</li>\n+ *   <li><tt>base-namespace</tt> - a base namespace as the prefix for all databases</li>", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "248278f444044d11233d41b81bfcb999f63dadb5"}, "originalPosition": 47}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2NzM5NDk1", "url": "https://github.com/apache/iceberg/pull/1182#pullrequestreview-446739495", "createdAt": "2020-07-10T22:52:13Z", "commit": {"oid": "248278f444044d11233d41b81bfcb999f63dadb5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMjo1MjoxM1rOGwHsxw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMjo1MjoxM1rOGwHsxw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzExMDk4Mw==", "bodyText": "Can you be more specific about this? What is a case where information is lost?", "url": "https://github.com/apache/iceberg/pull/1182#discussion_r453110983", "createdAt": "2020-07-10T22:52:13Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkSchemaUtil.java", "diffHunk": "@@ -21,10 +21,19 @@\n \n import org.apache.flink.table.api.TableSchema;\n import org.apache.flink.table.types.FieldsDataType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.table.types.utils.TypeConversions;\n import org.apache.iceberg.Schema;\n import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.TypeUtil;\n \n+/**\n+ * Converter between Flink types and Iceberg type.\n+ * The conversion is not a 1:1 mapping that not allows back-and-forth conversion. So some information might get lost\n+ * during the back-and-forth conversion.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "248278f444044d11233d41b81bfcb999f63dadb5"}, "originalPosition": 15}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2NzM5OTk3", "url": "https://github.com/apache/iceberg/pull/1182#pullrequestreview-446739997", "createdAt": "2020-07-10T22:54:12Z", "commit": {"oid": "248278f444044d11233d41b81bfcb999f63dadb5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMjo1NDoxMlrOGwHueg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMjo1NDoxMlrOGwHueg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzExMTQxOA==", "bodyText": "Char? Wouldn't this be fixed-length binary?", "url": "https://github.com/apache/iceberg/pull/1182#discussion_r453111418", "createdAt": "2020-07-10T22:54:12Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/TypeToFlinkType.java", "diffHunk": "@@ -0,0 +1,133 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import org.apache.flink.table.types.logical.ArrayType;\n+import org.apache.flink.table.types.logical.BigIntType;\n+import org.apache.flink.table.types.logical.BinaryType;\n+import org.apache.flink.table.types.logical.BooleanType;\n+import org.apache.flink.table.types.logical.CharType;\n+import org.apache.flink.table.types.logical.DateType;\n+import org.apache.flink.table.types.logical.DecimalType;\n+import org.apache.flink.table.types.logical.DoubleType;\n+import org.apache.flink.table.types.logical.FloatType;\n+import org.apache.flink.table.types.logical.IntType;\n+import org.apache.flink.table.types.logical.LocalZonedTimestampType;\n+import org.apache.flink.table.types.logical.LogicalType;\n+import org.apache.flink.table.types.logical.MapType;\n+import org.apache.flink.table.types.logical.RowType;\n+import org.apache.flink.table.types.logical.TimeType;\n+import org.apache.flink.table.types.logical.TimestampType;\n+import org.apache.flink.table.types.logical.VarBinaryType;\n+import org.apache.flink.table.types.logical.VarCharType;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.TypeUtil;\n+import org.apache.iceberg.types.Types;\n+\n+class TypeToFlinkType extends TypeUtil.SchemaVisitor<LogicalType> {\n+  TypeToFlinkType() {\n+  }\n+\n+  @Override\n+  public LogicalType schema(Schema schema, LogicalType structType) {\n+    return structType;\n+  }\n+\n+  @Override\n+  public LogicalType struct(Types.StructType struct, List<LogicalType> fieldResults) {\n+    List<Types.NestedField> fields = struct.fields();\n+\n+    List<RowType.RowField> flinkFields = Lists.newArrayListWithExpectedSize(fieldResults.size());\n+    for (int i = 0; i < fields.size(); i += 1) {\n+      Types.NestedField field = fields.get(i);\n+      LogicalType type = fieldResults.get(i);\n+      RowType.RowField flinkField = new RowType.RowField(\n+          field.name(), type.copy(field.isOptional()), field.doc());\n+      flinkFields.add(flinkField);\n+    }\n+\n+    return new RowType(flinkFields);\n+  }\n+\n+  @Override\n+  public LogicalType field(Types.NestedField field, LogicalType fieldResult) {\n+    return fieldResult;\n+  }\n+\n+  @Override\n+  public LogicalType list(Types.ListType list, LogicalType elementResult) {\n+    return new ArrayType(elementResult.copy(list.isElementOptional()));\n+  }\n+\n+  @Override\n+  public LogicalType map(Types.MapType map, LogicalType keyResult, LogicalType valueResult) {\n+    // keys in map are not allowed to be null.\n+    return new MapType(keyResult.copy(false), valueResult.copy(map.isValueOptional()));\n+  }\n+\n+  @Override\n+  public LogicalType primitive(Type.PrimitiveType primitive) {\n+    switch (primitive.typeId()) {\n+      case BOOLEAN:\n+        return new BooleanType();\n+      case INTEGER:\n+        return new IntType();\n+      case LONG:\n+        return new BigIntType();\n+      case FLOAT:\n+        return new FloatType();\n+      case DOUBLE:\n+        return new DoubleType();\n+      case DATE:\n+        return new DateType();\n+      case TIME:\n+        // MICROS\n+        return new TimeType(6);\n+      case TIMESTAMP:\n+        Types.TimestampType timestamp = (Types.TimestampType) primitive;\n+        if (timestamp.shouldAdjustToUTC()) {\n+          // MICROS\n+          return new LocalZonedTimestampType(6);\n+        } else {\n+          // MICROS\n+          return new TimestampType(6);\n+        }\n+      case STRING:\n+        return new VarCharType(VarCharType.MAX_LENGTH);\n+      case UUID:\n+        // UUID length is 16\n+        return new CharType(16);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "248278f444044d11233d41b81bfcb999f63dadb5"}, "originalPosition": 119}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2NzQwNjc2", "url": "https://github.com/apache/iceberg/pull/1182#pullrequestreview-446740676", "createdAt": "2020-07-10T22:56:51Z", "commit": {"oid": "248278f444044d11233d41b81bfcb999f63dadb5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMjo1Njo1MVrOGwHxDg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMjo1Njo1MVrOGwHxDg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzExMjA3OA==", "bodyText": "Won't this close the catalog after every test method?", "url": "https://github.com/apache/iceberg/pull/1182#discussion_r453112078", "createdAt": "2020-07-10T22:56:51Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/FlinkCatalogTestBase.java", "diffHunk": "@@ -0,0 +1,122 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import org.apache.flink.table.api.EnvironmentSettings;\n+import org.apache.flink.table.api.TableEnvironment;\n+import org.apache.flink.util.ArrayUtils;\n+import org.apache.iceberg.catalog.Catalog;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.hadoop.HadoopCatalog;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.junit.After;\n+import org.junit.AfterClass;\n+import org.junit.Assert;\n+import org.junit.BeforeClass;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+@RunWith(Parameterized.class)\n+public abstract class FlinkCatalogTestBase extends FlinkTestBase {\n+\n+  protected static final String DATABASE = \"db\";\n+  private static File warehouse = null;\n+\n+  @BeforeClass\n+  public static void createWarehouse() throws IOException {\n+    FlinkCatalogTestBase.warehouse = File.createTempFile(\"warehouse\", null);\n+    Assert.assertTrue(warehouse.delete());\n+  }\n+\n+  @AfterClass\n+  public static void dropWarehouse() {\n+    if (warehouse != null && warehouse.exists()) {\n+      warehouse.delete();\n+    }\n+  }\n+\n+  @Parameterized.Parameters\n+  public static Object[][] parameters() {\n+    return new Object[][] {\n+        new Object[] { \"testhive\", new String[0] },\n+        new Object[] { \"testhadoop\", new String[0] },\n+        new Object[] { \"testhadoop\", new String[] { \"l0\", \"l1\" }},\n+    };\n+  }\n+\n+  protected final TableEnvironment tEnv =\n+      TableEnvironment.create(EnvironmentSettings.newInstance().useBlinkPlanner().inBatchMode().build());\n+\n+  protected final String catalogName;\n+  protected final String[] baseNamespace;\n+  protected final Catalog validationCatalog;\n+  protected final SupportsNamespaces validationNamespaceCatalog;\n+  protected final org.apache.flink.table.catalog.Catalog flinkCatalog;\n+\n+  protected final String flinkIdentifier;\n+  protected final Namespace icebergNamespace;\n+  protected final boolean isHadoopCatalog;\n+\n+  public FlinkCatalogTestBase(String catalogName, String[] baseNamespace) {\n+    this.catalogName = catalogName;\n+    this.baseNamespace = baseNamespace;\n+    this.isHadoopCatalog = catalogName.equals(\"testhadoop\");\n+    this.validationCatalog = isHadoopCatalog ?\n+        new HadoopCatalog(hiveConf, \"file:\" + warehouse) :\n+        catalog;\n+    this.validationNamespaceCatalog = (SupportsNamespaces) validationCatalog;\n+\n+    Map<String, String> config = new HashMap<>();\n+    config.put(\"type\", \"iceberg\");\n+    config.put(FlinkCatalogFactory.ICEBERG_CATALOG_TYPE, isHadoopCatalog ? \"hadoop\" : \"hive\");\n+    config.put(FlinkCatalogFactory.HADOOP_WAREHOUSE_LOCATION, \"file:\" + warehouse);\n+    if (baseNamespace.length > 0) {\n+      config.put(FlinkCatalogFactory.BASE_NAMESPACE, Joiner.on(\".\").join(baseNamespace));\n+    }\n+\n+    FlinkCatalogFactory factory = new FlinkCatalogFactory() {\n+      @Override\n+      protected Catalog buildIcebergCatalog(String name, Map<String, String> options) {\n+        // Flink hadoop configuration depends on system env, it is quiet hard to set from testing. So directly pass\n+        // correct hadoop configuration.\n+        return super.buildIcebergCatalog(name, options, hiveConf);\n+      }\n+    };\n+    flinkCatalog = factory.createCatalog(catalogName, config);\n+    tEnv.registerCatalog(catalogName, flinkCatalog);\n+\n+    this.flinkIdentifier = catalogName + \".\" + DATABASE;\n+    this.icebergNamespace = Namespace.of(ArrayUtils.concat(baseNamespace, new String[] { DATABASE }));\n+  }\n+\n+  @After", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "248278f444044d11233d41b81bfcb999f63dadb5"}, "originalPosition": 114}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2NzQxMjg1", "url": "https://github.com/apache/iceberg/pull/1182#pullrequestreview-446741285", "createdAt": "2020-07-10T22:59:15Z", "commit": {"oid": "248278f444044d11233d41b81bfcb999f63dadb5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMjo1OToxNVrOGwHzBw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMjo1OToxNVrOGwHzBw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzExMjU4Mw==", "bodyText": "This sounds like a bug in the Hadoop catalog. Can we fix it instead of ignoring this test case?", "url": "https://github.com/apache/iceberg/pull/1182#discussion_r453112583", "createdAt": "2020-07-10T22:59:15Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkCatalogDatabase.java", "diffHunk": "@@ -0,0 +1,241 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.io.File;\n+import java.util.Map;\n+import org.apache.flink.table.catalog.exceptions.DatabaseNotEmptyException;\n+import org.apache.iceberg.AssertHelpers;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableSet;\n+import org.apache.iceberg.types.Types;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Assume;\n+import org.junit.Test;\n+\n+public class TestFlinkCatalogDatabase extends FlinkCatalogTestBase {\n+\n+  public TestFlinkCatalogDatabase(String catalogName, String[] baseNamepace) {\n+    super(catalogName, baseNamepace);\n+  }\n+\n+  @After\n+  public void clean() {\n+    sql(\"DROP TABLE IF EXISTS %s.tl\", flinkIdentifier);\n+    sql(\"DROP DATABASE IF EXISTS %s\", flinkIdentifier);\n+  }\n+\n+  @Test\n+  public void testCreateNamespace() {\n+    Assert.assertFalse(\n+        \"Database should not already exist\",\n+        validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+\n+    sql(\"CREATE DATABASE %s\", flinkIdentifier);\n+\n+    Assert.assertTrue(\"Database should exist\", validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+  }\n+\n+  @Test\n+  public void testDefaultDatabase() {\n+    sql(\"USE CATALOG %s\", catalogName);\n+\n+    Assert.assertEquals(\"Should use the current catalog\", tEnv.getCurrentCatalog(), catalogName);\n+    Assert.assertEquals(\"Should use the configured default namespace\", tEnv.getCurrentDatabase(), \"default\");\n+  }\n+\n+  @Test\n+  public void testDropEmptyDatabase() {\n+    Assert.assertFalse(\n+        \"Namespace should not already exist\",\n+        validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+\n+    sql(\"CREATE DATABASE %s\", flinkIdentifier);\n+\n+    Assert.assertTrue(\"Namespace should exist\", validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+\n+    sql(\"DROP DATABASE %s\", flinkIdentifier);\n+\n+    Assert.assertFalse(\n+        \"Namespace should have been dropped\",\n+        validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+  }\n+\n+  @Test\n+  public void testDropNonEmptyNamespace() {\n+    Assume.assumeFalse(\"Hadoop catalog throws IOException: Directory is not empty.\", isHadoopCatalog);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "248278f444044d11233d41b81bfcb999f63dadb5"}, "originalPosition": 86}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2NzQxNTcy", "url": "https://github.com/apache/iceberg/pull/1182#pullrequestreview-446741572", "createdAt": "2020-07-10T23:00:27Z", "commit": {"oid": "248278f444044d11233d41b81bfcb999f63dadb5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMzowMDoyN1rOGwH0Gw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMzowMDoyN1rOGwH0Gw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzExMjg1OQ==", "bodyText": "It isn't clear from this name that this is for a database. How about renaming it to flinkDatabase?", "url": "https://github.com/apache/iceberg/pull/1182#discussion_r453112859", "createdAt": "2020-07-10T23:00:27Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/FlinkCatalogTestBase.java", "diffHunk": "@@ -0,0 +1,122 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.io.File;\n+import java.io.IOException;\n+import java.util.HashMap;\n+import java.util.Map;\n+import org.apache.flink.table.api.EnvironmentSettings;\n+import org.apache.flink.table.api.TableEnvironment;\n+import org.apache.flink.util.ArrayUtils;\n+import org.apache.iceberg.catalog.Catalog;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.hadoop.HadoopCatalog;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.junit.After;\n+import org.junit.AfterClass;\n+import org.junit.Assert;\n+import org.junit.BeforeClass;\n+import org.junit.runner.RunWith;\n+import org.junit.runners.Parameterized;\n+\n+@RunWith(Parameterized.class)\n+public abstract class FlinkCatalogTestBase extends FlinkTestBase {\n+\n+  protected static final String DATABASE = \"db\";\n+  private static File warehouse = null;\n+\n+  @BeforeClass\n+  public static void createWarehouse() throws IOException {\n+    FlinkCatalogTestBase.warehouse = File.createTempFile(\"warehouse\", null);\n+    Assert.assertTrue(warehouse.delete());\n+  }\n+\n+  @AfterClass\n+  public static void dropWarehouse() {\n+    if (warehouse != null && warehouse.exists()) {\n+      warehouse.delete();\n+    }\n+  }\n+\n+  @Parameterized.Parameters\n+  public static Object[][] parameters() {\n+    return new Object[][] {\n+        new Object[] { \"testhive\", new String[0] },\n+        new Object[] { \"testhadoop\", new String[0] },\n+        new Object[] { \"testhadoop\", new String[] { \"l0\", \"l1\" }},\n+    };\n+  }\n+\n+  protected final TableEnvironment tEnv =\n+      TableEnvironment.create(EnvironmentSettings.newInstance().useBlinkPlanner().inBatchMode().build());\n+\n+  protected final String catalogName;\n+  protected final String[] baseNamespace;\n+  protected final Catalog validationCatalog;\n+  protected final SupportsNamespaces validationNamespaceCatalog;\n+  protected final org.apache.flink.table.catalog.Catalog flinkCatalog;\n+\n+  protected final String flinkIdentifier;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "248278f444044d11233d41b81bfcb999f63dadb5"}, "originalPosition": 78}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2NzQxODkz", "url": "https://github.com/apache/iceberg/pull/1182#pullrequestreview-446741893", "createdAt": "2020-07-10T23:01:35Z", "commit": {"oid": "248278f444044d11233d41b81bfcb999f63dadb5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMzowMTozNVrOGwH1TA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMzowMTozNVrOGwH1TA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzExMzE2NA==", "bodyText": "Why does this require assertThrowsCause? Is it wrapped in a generic SQL failure exception?", "url": "https://github.com/apache/iceberg/pull/1182#discussion_r453113164", "createdAt": "2020-07-10T23:01:35Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkCatalogDatabase.java", "diffHunk": "@@ -0,0 +1,241 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.io.File;\n+import java.util.Map;\n+import org.apache.flink.table.catalog.exceptions.DatabaseNotEmptyException;\n+import org.apache.iceberg.AssertHelpers;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableSet;\n+import org.apache.iceberg.types.Types;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Assume;\n+import org.junit.Test;\n+\n+public class TestFlinkCatalogDatabase extends FlinkCatalogTestBase {\n+\n+  public TestFlinkCatalogDatabase(String catalogName, String[] baseNamepace) {\n+    super(catalogName, baseNamepace);\n+  }\n+\n+  @After\n+  public void clean() {\n+    sql(\"DROP TABLE IF EXISTS %s.tl\", flinkIdentifier);\n+    sql(\"DROP DATABASE IF EXISTS %s\", flinkIdentifier);\n+  }\n+\n+  @Test\n+  public void testCreateNamespace() {\n+    Assert.assertFalse(\n+        \"Database should not already exist\",\n+        validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+\n+    sql(\"CREATE DATABASE %s\", flinkIdentifier);\n+\n+    Assert.assertTrue(\"Database should exist\", validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+  }\n+\n+  @Test\n+  public void testDefaultDatabase() {\n+    sql(\"USE CATALOG %s\", catalogName);\n+\n+    Assert.assertEquals(\"Should use the current catalog\", tEnv.getCurrentCatalog(), catalogName);\n+    Assert.assertEquals(\"Should use the configured default namespace\", tEnv.getCurrentDatabase(), \"default\");\n+  }\n+\n+  @Test\n+  public void testDropEmptyDatabase() {\n+    Assert.assertFalse(\n+        \"Namespace should not already exist\",\n+        validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+\n+    sql(\"CREATE DATABASE %s\", flinkIdentifier);\n+\n+    Assert.assertTrue(\"Namespace should exist\", validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+\n+    sql(\"DROP DATABASE %s\", flinkIdentifier);\n+\n+    Assert.assertFalse(\n+        \"Namespace should have been dropped\",\n+        validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+  }\n+\n+  @Test\n+  public void testDropNonEmptyNamespace() {\n+    Assume.assumeFalse(\"Hadoop catalog throws IOException: Directory is not empty.\", isHadoopCatalog);\n+\n+    Assert.assertFalse(\n+        \"Namespace should not already exist\",\n+        validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+\n+    sql(\"CREATE DATABASE %s\", flinkIdentifier);\n+\n+    validationCatalog.createTable(\n+        TableIdentifier.of(icebergNamespace, \"tl\"),\n+        new Schema(Types.NestedField.optional(0, \"id\", Types.LongType.get())));\n+\n+    Assert.assertTrue(\"Namespace should exist\", validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+    Assert.assertTrue(\"Table should exist\", validationCatalog.tableExists(TableIdentifier.of(icebergNamespace, \"tl\")));\n+\n+    AssertHelpers.assertThrowsCause(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "248278f444044d11233d41b81bfcb999f63dadb5"}, "originalPosition": 101}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2NzQyMjc3", "url": "https://github.com/apache/iceberg/pull/1182#pullrequestreview-446742277", "createdAt": "2020-07-10T23:02:54Z", "commit": {"oid": "248278f444044d11233d41b81bfcb999f63dadb5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMzowMjo1NFrOGwH2ng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMzowMjo1NFrOGwH2ng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzExMzUwMg==", "bodyText": "Should this call SHOW TABLES?", "url": "https://github.com/apache/iceberg/pull/1182#discussion_r453113502", "createdAt": "2020-07-10T23:02:54Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkCatalogDatabase.java", "diffHunk": "@@ -0,0 +1,241 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.io.File;\n+import java.util.Map;\n+import org.apache.flink.table.catalog.exceptions.DatabaseNotEmptyException;\n+import org.apache.iceberg.AssertHelpers;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableSet;\n+import org.apache.iceberg.types.Types;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Assume;\n+import org.junit.Test;\n+\n+public class TestFlinkCatalogDatabase extends FlinkCatalogTestBase {\n+\n+  public TestFlinkCatalogDatabase(String catalogName, String[] baseNamepace) {\n+    super(catalogName, baseNamepace);\n+  }\n+\n+  @After\n+  public void clean() {\n+    sql(\"DROP TABLE IF EXISTS %s.tl\", flinkIdentifier);\n+    sql(\"DROP DATABASE IF EXISTS %s\", flinkIdentifier);\n+  }\n+\n+  @Test\n+  public void testCreateNamespace() {\n+    Assert.assertFalse(\n+        \"Database should not already exist\",\n+        validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+\n+    sql(\"CREATE DATABASE %s\", flinkIdentifier);\n+\n+    Assert.assertTrue(\"Database should exist\", validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+  }\n+\n+  @Test\n+  public void testDefaultDatabase() {\n+    sql(\"USE CATALOG %s\", catalogName);\n+\n+    Assert.assertEquals(\"Should use the current catalog\", tEnv.getCurrentCatalog(), catalogName);\n+    Assert.assertEquals(\"Should use the configured default namespace\", tEnv.getCurrentDatabase(), \"default\");\n+  }\n+\n+  @Test\n+  public void testDropEmptyDatabase() {\n+    Assert.assertFalse(\n+        \"Namespace should not already exist\",\n+        validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+\n+    sql(\"CREATE DATABASE %s\", flinkIdentifier);\n+\n+    Assert.assertTrue(\"Namespace should exist\", validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+\n+    sql(\"DROP DATABASE %s\", flinkIdentifier);\n+\n+    Assert.assertFalse(\n+        \"Namespace should have been dropped\",\n+        validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+  }\n+\n+  @Test\n+  public void testDropNonEmptyNamespace() {\n+    Assume.assumeFalse(\"Hadoop catalog throws IOException: Directory is not empty.\", isHadoopCatalog);\n+\n+    Assert.assertFalse(\n+        \"Namespace should not already exist\",\n+        validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+\n+    sql(\"CREATE DATABASE %s\", flinkIdentifier);\n+\n+    validationCatalog.createTable(\n+        TableIdentifier.of(icebergNamespace, \"tl\"),\n+        new Schema(Types.NestedField.optional(0, \"id\", Types.LongType.get())));\n+\n+    Assert.assertTrue(\"Namespace should exist\", validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+    Assert.assertTrue(\"Table should exist\", validationCatalog.tableExists(TableIdentifier.of(icebergNamespace, \"tl\")));\n+\n+    AssertHelpers.assertThrowsCause(\n+        \"Should fail if trying to delete a non-empty database\",\n+        DatabaseNotEmptyException.class,\n+        String.format(\"Database %s in catalog %s is not empty.\", DATABASE, catalogName),\n+        () -> sql(\"DROP DATABASE %s\", flinkIdentifier));\n+\n+    sql(\"DROP TABLE %s.tl\", flinkIdentifier);\n+  }\n+\n+  @Test\n+  public void testListTables() {\n+    Assert.assertFalse(\n+        \"Namespace should not already exist\",\n+        validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+\n+    sql(\"CREATE DATABASE %s\", flinkIdentifier);\n+    sql(\"USE CATALOG %s\", catalogName);\n+    sql(\"USE %s\", DATABASE);\n+\n+    Assert.assertTrue(\"Namespace should exist\", validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+\n+    Assert.assertEquals(\"Should not list any tables\", 0, tEnv.listTables().length);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "248278f444044d11233d41b81bfcb999f63dadb5"}, "originalPosition": 122}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2NzQzMzU0", "url": "https://github.com/apache/iceberg/pull/1182#pullrequestreview-446743354", "createdAt": "2020-07-10T23:06:32Z", "commit": {"oid": "248278f444044d11233d41b81bfcb999f63dadb5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMzowNjozMlrOGwH6oQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMzowNjozMlrOGwH6oQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzExNDUyOQ==", "bodyText": "What is TEMPORARY_FOLDER? I don't see it elsewhere in this PR.", "url": "https://github.com/apache/iceberg/pull/1182#discussion_r453114529", "createdAt": "2020-07-10T23:06:32Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkCatalogDatabase.java", "diffHunk": "@@ -0,0 +1,241 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.io.File;\n+import java.util.Map;\n+import org.apache.flink.table.catalog.exceptions.DatabaseNotEmptyException;\n+import org.apache.iceberg.AssertHelpers;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableSet;\n+import org.apache.iceberg.types.Types;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Assume;\n+import org.junit.Test;\n+\n+public class TestFlinkCatalogDatabase extends FlinkCatalogTestBase {\n+\n+  public TestFlinkCatalogDatabase(String catalogName, String[] baseNamepace) {\n+    super(catalogName, baseNamepace);\n+  }\n+\n+  @After\n+  public void clean() {\n+    sql(\"DROP TABLE IF EXISTS %s.tl\", flinkIdentifier);\n+    sql(\"DROP DATABASE IF EXISTS %s\", flinkIdentifier);\n+  }\n+\n+  @Test\n+  public void testCreateNamespace() {\n+    Assert.assertFalse(\n+        \"Database should not already exist\",\n+        validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+\n+    sql(\"CREATE DATABASE %s\", flinkIdentifier);\n+\n+    Assert.assertTrue(\"Database should exist\", validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+  }\n+\n+  @Test\n+  public void testDefaultDatabase() {\n+    sql(\"USE CATALOG %s\", catalogName);\n+\n+    Assert.assertEquals(\"Should use the current catalog\", tEnv.getCurrentCatalog(), catalogName);\n+    Assert.assertEquals(\"Should use the configured default namespace\", tEnv.getCurrentDatabase(), \"default\");\n+  }\n+\n+  @Test\n+  public void testDropEmptyDatabase() {\n+    Assert.assertFalse(\n+        \"Namespace should not already exist\",\n+        validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+\n+    sql(\"CREATE DATABASE %s\", flinkIdentifier);\n+\n+    Assert.assertTrue(\"Namespace should exist\", validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+\n+    sql(\"DROP DATABASE %s\", flinkIdentifier);\n+\n+    Assert.assertFalse(\n+        \"Namespace should have been dropped\",\n+        validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+  }\n+\n+  @Test\n+  public void testDropNonEmptyNamespace() {\n+    Assume.assumeFalse(\"Hadoop catalog throws IOException: Directory is not empty.\", isHadoopCatalog);\n+\n+    Assert.assertFalse(\n+        \"Namespace should not already exist\",\n+        validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+\n+    sql(\"CREATE DATABASE %s\", flinkIdentifier);\n+\n+    validationCatalog.createTable(\n+        TableIdentifier.of(icebergNamespace, \"tl\"),\n+        new Schema(Types.NestedField.optional(0, \"id\", Types.LongType.get())));\n+\n+    Assert.assertTrue(\"Namespace should exist\", validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+    Assert.assertTrue(\"Table should exist\", validationCatalog.tableExists(TableIdentifier.of(icebergNamespace, \"tl\")));\n+\n+    AssertHelpers.assertThrowsCause(\n+        \"Should fail if trying to delete a non-empty database\",\n+        DatabaseNotEmptyException.class,\n+        String.format(\"Database %s in catalog %s is not empty.\", DATABASE, catalogName),\n+        () -> sql(\"DROP DATABASE %s\", flinkIdentifier));\n+\n+    sql(\"DROP TABLE %s.tl\", flinkIdentifier);\n+  }\n+\n+  @Test\n+  public void testListTables() {\n+    Assert.assertFalse(\n+        \"Namespace should not already exist\",\n+        validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+\n+    sql(\"CREATE DATABASE %s\", flinkIdentifier);\n+    sql(\"USE CATALOG %s\", catalogName);\n+    sql(\"USE %s\", DATABASE);\n+\n+    Assert.assertTrue(\"Namespace should exist\", validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+\n+    Assert.assertEquals(\"Should not list any tables\", 0, tEnv.listTables().length);\n+\n+    validationCatalog.createTable(\n+        TableIdentifier.of(icebergNamespace, \"tl\"),\n+        new Schema(Types.NestedField.optional(0, \"id\", Types.LongType.get())));\n+\n+    Assert.assertEquals(\"Only 1 table\", 1, tEnv.listTables().length);\n+    Assert.assertEquals(\"Table name should match\", \"tl\", tEnv.listTables()[0]);\n+  }\n+\n+  @Test\n+  public void testListNamespace() {\n+    Assert.assertFalse(\n+        \"Namespace should not already exist\",\n+        validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+\n+    sql(\"CREATE DATABASE %s\", flinkIdentifier);\n+    sql(\"USE CATALOG %s\", catalogName);\n+\n+    Assert.assertTrue(\"Namespace should exist\", validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+\n+    String[] databases = tEnv.listDatabases();\n+\n+    if (isHadoopCatalog) {\n+      Assert.assertEquals(\"Should have 1 database\", 1, databases.length);\n+      Assert.assertEquals(\"Should have only db database\", \"db\", databases[0]);\n+\n+      if (baseNamespace.length > 0) {\n+        // test namespace not belongs to this catalog\n+        validationNamespaceCatalog.createNamespace(Namespace.of(baseNamespace[0], \"UNKNOWN_NAMESPACE\"));\n+        databases = tEnv.listDatabases();\n+        Assert.assertEquals(\"Should have 1 database\", 1, databases.length);\n+        Assert.assertEquals(\"Should have only db database\", \"db\", databases[0]);\n+      }\n+    } else {\n+      Assert.assertEquals(\"Should have 2 databases\", 2, databases.length);\n+      Assert.assertEquals(\n+          \"Should have default and db databases\",\n+          ImmutableSet.of(\"default\", \"db\"),\n+          ImmutableSet.copyOf(databases));\n+    }\n+  }\n+\n+  @Test\n+  public void testCreateNamespaceWithMetadata() {\n+    Assume.assumeFalse(\"HadoopCatalog does not support namespace metadata\", isHadoopCatalog);\n+\n+    Assert.assertFalse(\n+        \"Namespace should not already exist\",\n+        validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+\n+    sql(\"CREATE DATABASE %s WITH ('prop'='value')\", flinkIdentifier);\n+\n+    Assert.assertTrue(\"Namespace should exist\", validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+\n+    Map<String, String> nsMetadata = validationNamespaceCatalog.loadNamespaceMetadata(icebergNamespace);\n+\n+    Assert.assertEquals(\"Namespace should have expected prop value\", \"value\", nsMetadata.get(\"prop\"));\n+  }\n+\n+  @Test\n+  public void testCreateNamespaceWithComment() {\n+    Assume.assumeFalse(\"HadoopCatalog does not support namespace metadata\", isHadoopCatalog);\n+\n+    Assert.assertFalse(\n+        \"Namespace should not already exist\",\n+        validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+\n+    sql(\"CREATE DATABASE %s COMMENT 'namespace doc'\", flinkIdentifier);\n+\n+    Assert.assertTrue(\"Namespace should exist\", validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+\n+    Map<String, String> nsMetadata = validationNamespaceCatalog.loadNamespaceMetadata(icebergNamespace);\n+\n+    Assert.assertEquals(\"Namespace should have expected comment\", \"namespace doc\", nsMetadata.get(\"comment\"));\n+  }\n+\n+  @Test\n+  public void testCreateNamespaceWithLocation() throws Exception {\n+    Assume.assumeFalse(\"HadoopCatalog does not support namespace locations\", isHadoopCatalog);\n+\n+    Assert.assertFalse(\n+        \"Namespace should not already exist\",\n+        validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+\n+    File location = TEMPORARY_FOLDER.newFile();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "248278f444044d11233d41b81bfcb999f63dadb5"}, "originalPosition": 207}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDQ2NzQzNjY3", "url": "https://github.com/apache/iceberg/pull/1182#pullrequestreview-446743667", "createdAt": "2020-07-10T23:07:33Z", "commit": {"oid": "248278f444044d11233d41b81bfcb999f63dadb5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMzowNzozM1rOGwH7zw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xMFQyMzowNzozM1rOGwH7zw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1MzExNDgzMQ==", "bodyText": "Do we need a test to validate that the CREATE DATABASE statement fails for Hadoop?", "url": "https://github.com/apache/iceberg/pull/1182#discussion_r453114831", "createdAt": "2020-07-10T23:07:33Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkCatalogDatabase.java", "diffHunk": "@@ -0,0 +1,241 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.io.File;\n+import java.util.Map;\n+import org.apache.flink.table.catalog.exceptions.DatabaseNotEmptyException;\n+import org.apache.iceberg.AssertHelpers;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableSet;\n+import org.apache.iceberg.types.Types;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Assume;\n+import org.junit.Test;\n+\n+public class TestFlinkCatalogDatabase extends FlinkCatalogTestBase {\n+\n+  public TestFlinkCatalogDatabase(String catalogName, String[] baseNamepace) {\n+    super(catalogName, baseNamepace);\n+  }\n+\n+  @After\n+  public void clean() {\n+    sql(\"DROP TABLE IF EXISTS %s.tl\", flinkIdentifier);\n+    sql(\"DROP DATABASE IF EXISTS %s\", flinkIdentifier);\n+  }\n+\n+  @Test\n+  public void testCreateNamespace() {\n+    Assert.assertFalse(\n+        \"Database should not already exist\",\n+        validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+\n+    sql(\"CREATE DATABASE %s\", flinkIdentifier);\n+\n+    Assert.assertTrue(\"Database should exist\", validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+  }\n+\n+  @Test\n+  public void testDefaultDatabase() {\n+    sql(\"USE CATALOG %s\", catalogName);\n+\n+    Assert.assertEquals(\"Should use the current catalog\", tEnv.getCurrentCatalog(), catalogName);\n+    Assert.assertEquals(\"Should use the configured default namespace\", tEnv.getCurrentDatabase(), \"default\");\n+  }\n+\n+  @Test\n+  public void testDropEmptyDatabase() {\n+    Assert.assertFalse(\n+        \"Namespace should not already exist\",\n+        validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+\n+    sql(\"CREATE DATABASE %s\", flinkIdentifier);\n+\n+    Assert.assertTrue(\"Namespace should exist\", validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+\n+    sql(\"DROP DATABASE %s\", flinkIdentifier);\n+\n+    Assert.assertFalse(\n+        \"Namespace should have been dropped\",\n+        validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+  }\n+\n+  @Test\n+  public void testDropNonEmptyNamespace() {\n+    Assume.assumeFalse(\"Hadoop catalog throws IOException: Directory is not empty.\", isHadoopCatalog);\n+\n+    Assert.assertFalse(\n+        \"Namespace should not already exist\",\n+        validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+\n+    sql(\"CREATE DATABASE %s\", flinkIdentifier);\n+\n+    validationCatalog.createTable(\n+        TableIdentifier.of(icebergNamespace, \"tl\"),\n+        new Schema(Types.NestedField.optional(0, \"id\", Types.LongType.get())));\n+\n+    Assert.assertTrue(\"Namespace should exist\", validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+    Assert.assertTrue(\"Table should exist\", validationCatalog.tableExists(TableIdentifier.of(icebergNamespace, \"tl\")));\n+\n+    AssertHelpers.assertThrowsCause(\n+        \"Should fail if trying to delete a non-empty database\",\n+        DatabaseNotEmptyException.class,\n+        String.format(\"Database %s in catalog %s is not empty.\", DATABASE, catalogName),\n+        () -> sql(\"DROP DATABASE %s\", flinkIdentifier));\n+\n+    sql(\"DROP TABLE %s.tl\", flinkIdentifier);\n+  }\n+\n+  @Test\n+  public void testListTables() {\n+    Assert.assertFalse(\n+        \"Namespace should not already exist\",\n+        validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+\n+    sql(\"CREATE DATABASE %s\", flinkIdentifier);\n+    sql(\"USE CATALOG %s\", catalogName);\n+    sql(\"USE %s\", DATABASE);\n+\n+    Assert.assertTrue(\"Namespace should exist\", validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+\n+    Assert.assertEquals(\"Should not list any tables\", 0, tEnv.listTables().length);\n+\n+    validationCatalog.createTable(\n+        TableIdentifier.of(icebergNamespace, \"tl\"),\n+        new Schema(Types.NestedField.optional(0, \"id\", Types.LongType.get())));\n+\n+    Assert.assertEquals(\"Only 1 table\", 1, tEnv.listTables().length);\n+    Assert.assertEquals(\"Table name should match\", \"tl\", tEnv.listTables()[0]);\n+  }\n+\n+  @Test\n+  public void testListNamespace() {\n+    Assert.assertFalse(\n+        \"Namespace should not already exist\",\n+        validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+\n+    sql(\"CREATE DATABASE %s\", flinkIdentifier);\n+    sql(\"USE CATALOG %s\", catalogName);\n+\n+    Assert.assertTrue(\"Namespace should exist\", validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+\n+    String[] databases = tEnv.listDatabases();\n+\n+    if (isHadoopCatalog) {\n+      Assert.assertEquals(\"Should have 1 database\", 1, databases.length);\n+      Assert.assertEquals(\"Should have only db database\", \"db\", databases[0]);\n+\n+      if (baseNamespace.length > 0) {\n+        // test namespace not belongs to this catalog\n+        validationNamespaceCatalog.createNamespace(Namespace.of(baseNamespace[0], \"UNKNOWN_NAMESPACE\"));\n+        databases = tEnv.listDatabases();\n+        Assert.assertEquals(\"Should have 1 database\", 1, databases.length);\n+        Assert.assertEquals(\"Should have only db database\", \"db\", databases[0]);\n+      }\n+    } else {\n+      Assert.assertEquals(\"Should have 2 databases\", 2, databases.length);\n+      Assert.assertEquals(\n+          \"Should have default and db databases\",\n+          ImmutableSet.of(\"default\", \"db\"),\n+          ImmutableSet.copyOf(databases));\n+    }\n+  }\n+\n+  @Test\n+  public void testCreateNamespaceWithMetadata() {\n+    Assume.assumeFalse(\"HadoopCatalog does not support namespace metadata\", isHadoopCatalog);\n+\n+    Assert.assertFalse(\n+        \"Namespace should not already exist\",\n+        validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+\n+    sql(\"CREATE DATABASE %s WITH ('prop'='value')\", flinkIdentifier);\n+\n+    Assert.assertTrue(\"Namespace should exist\", validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+\n+    Map<String, String> nsMetadata = validationNamespaceCatalog.loadNamespaceMetadata(icebergNamespace);\n+\n+    Assert.assertEquals(\"Namespace should have expected prop value\", \"value\", nsMetadata.get(\"prop\"));\n+  }\n+\n+  @Test\n+  public void testCreateNamespaceWithComment() {\n+    Assume.assumeFalse(\"HadoopCatalog does not support namespace metadata\", isHadoopCatalog);\n+\n+    Assert.assertFalse(\n+        \"Namespace should not already exist\",\n+        validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+\n+    sql(\"CREATE DATABASE %s COMMENT 'namespace doc'\", flinkIdentifier);\n+\n+    Assert.assertTrue(\"Namespace should exist\", validationNamespaceCatalog.namespaceExists(icebergNamespace));\n+\n+    Map<String, String> nsMetadata = validationNamespaceCatalog.loadNamespaceMetadata(icebergNamespace);\n+\n+    Assert.assertEquals(\"Namespace should have expected comment\", \"namespace doc\", nsMetadata.get(\"comment\"));\n+  }\n+\n+  @Test\n+  public void testCreateNamespaceWithLocation() throws Exception {\n+    Assume.assumeFalse(\"HadoopCatalog does not support namespace locations\", isHadoopCatalog);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "248278f444044d11233d41b81bfcb999f63dadb5"}, "originalPosition": 201}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f63e2ee9e7bc242ed613360f3f6e8dc8a96d7ec1", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/iceberg/commit/f63e2ee9e7bc242ed613360f3f6e8dc8a96d7ec1", "committedDate": "2020-07-14T02:35:02Z", "message": "Try to fix TestHiveMetastore"}, "afterCommit": {"oid": "6a8faaa1568601075b7d2927dd676dd17812c3e2", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/iceberg/commit/6a8faaa1568601075b7d2927dd676dd17812c3e2", "committedDate": "2020-07-14T02:36:36Z", "message": "Try to fix TestHiveMetastore"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "6a8faaa1568601075b7d2927dd676dd17812c3e2", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/iceberg/commit/6a8faaa1568601075b7d2927dd676dd17812c3e2", "committedDate": "2020-07-14T02:36:36Z", "message": "Try to fix TestHiveMetastore"}, "afterCommit": {"oid": "aed759616b235b3397ab65b980e0f2a9b92d34d6", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/iceberg/commit/aed759616b235b3397ab65b980e0f2a9b92d34d6", "committedDate": "2020-07-14T03:24:27Z", "message": "Address comments"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "aed759616b235b3397ab65b980e0f2a9b92d34d6", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/iceberg/commit/aed759616b235b3397ab65b980e0f2a9b92d34d6", "committedDate": "2020-07-14T03:24:27Z", "message": "Address comments"}, "afterCommit": {"oid": "6a4a84afa204ca3f10129ec70f6bda0af40d1097", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/iceberg/commit/6a4a84afa204ca3f10129ec70f6bda0af40d1097", "committedDate": "2020-07-16T02:37:15Z", "message": "Integrate Iceberg catalog to Flink catalog"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "835e0ba93555b252e4dea4b188f548e3103000cf", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/iceberg/commit/835e0ba93555b252e4dea4b188f548e3103000cf", "committedDate": "2020-07-16T02:39:04Z", "message": "Integrate Iceberg catalog to Flink catalog"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "14283d28990de535059d0d683c627cf04ba7beb3", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/iceberg/commit/14283d28990de535059d0d683c627cf04ba7beb3", "committedDate": "2020-07-16T02:57:21Z", "message": "Rebase & Update to 1.11"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "6a4a84afa204ca3f10129ec70f6bda0af40d1097", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/iceberg/commit/6a4a84afa204ca3f10129ec70f6bda0af40d1097", "committedDate": "2020-07-16T02:37:15Z", "message": "Integrate Iceberg catalog to Flink catalog"}, "afterCommit": {"oid": "14283d28990de535059d0d683c627cf04ba7beb3", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/iceberg/commit/14283d28990de535059d0d683c627cf04ba7beb3", "committedDate": "2020-07-16T02:57:21Z", "message": "Rebase & Update to 1.11"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e57e5348000db438437315b6aa800a863eeedf09", "author": {"user": {"login": "JingsongLi", "name": "Jingsong Lee"}}, "url": "https://github.com/apache/iceberg/commit/e57e5348000db438437315b6aa800a863eeedf09", "committedDate": "2020-07-16T06:09:30Z", "message": "Revert gradle-wrapper"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUxOTg0ODYz", "url": "https://github.com/apache/iceberg/pull/1182#pullrequestreview-451984863", "createdAt": "2020-07-20T21:51:39Z", "commit": {"oid": "e57e5348000db438437315b6aa800a863eeedf09"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMFQyMTo1MTo0MFrOG0giwg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMFQyMTo1MTo0MFrOG0giwg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NzcxMjMyMg==", "bodyText": "Nit: the method names weren't updated.", "url": "https://github.com/apache/iceberg/pull/1182#discussion_r457712322", "createdAt": "2020-07-20T21:51:40Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/FlinkTestBase.java", "diffHunk": "@@ -0,0 +1,56 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.concurrent.ConcurrentMap;\n+import org.apache.flink.table.catalog.Catalog;\n+import org.apache.flink.test.util.AbstractTestBase;\n+import org.apache.hadoop.hive.conf.HiveConf;\n+import org.apache.iceberg.hive.HiveCatalog;\n+import org.apache.iceberg.hive.TestHiveMetastore;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.junit.AfterClass;\n+import org.junit.BeforeClass;\n+\n+public abstract class FlinkTestBase extends AbstractTestBase {\n+\n+  private static TestHiveMetastore metastore = null;\n+  protected static HiveConf hiveConf = null;\n+  protected static HiveCatalog catalog = null;\n+  protected static ConcurrentMap<String, Catalog> flinkCatalogs;\n+\n+  @BeforeClass\n+  public static void startMetastoreAndSpark() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e57e5348000db438437315b6aa800a863eeedf09"}, "originalPosition": 40}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4232, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}