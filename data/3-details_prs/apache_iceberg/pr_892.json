{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0Mzk4NzMxNzcz", "number": 892, "title": "Spark: Add ORC to parameterized tests", "bodyText": "This adds ORC to Spark tests that run for each file format.\nThis also updates TestSparkReadProjection and TestFilteredScan to use Iceberg generics instead of Avro generics for the test cases because ORC doesn't support Avro records. It's good to remove the use of Avro in favor of Iceberg generics as well.", "createdAt": "2020-04-04T20:23:14Z", "url": "https://github.com/apache/iceberg/pull/892", "merged": true, "mergeCommit": {"oid": "898c122118ba99847216c80ca7e0d12821133a8a"}, "closed": true, "closedAt": "2020-04-09T16:11:46Z", "author": {"login": "rdblue"}, "timelineItems": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABcUbYr1AH2gAyMzk4NzMxNzczOmMyYmI2OTkxNGRiNTZjMGIzMmRmYjQxMTQ4MDI3ZWEyNzlmMTdmNmU=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcVWvNTAH2gAyMzk4NzMxNzczOmM4OWRkM2ExZjRkMDI4NTVhZDM3MTViNjBhZTAyZjQxYWNmNTVhODc=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "c2bb69914db56c0b32dfb41148027ea279f17f6e", "author": {"user": {"login": "rdblue", "name": "Ryan Blue"}}, "url": "https://github.com/apache/iceberg/commit/c2bb69914db56c0b32dfb41148027ea279f17f6e", "committedDate": "2020-04-04T20:18:58Z", "message": "Spark: Add ORC to parameterized tests."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5b0c174e2b4dad298c8fa662701a86c5acc1d0c2", "author": {"user": {"login": "rdblue", "name": "Ryan Blue"}}, "url": "https://github.com/apache/iceberg/commit/5b0c174e2b4dad298c8fa662701a86c5acc1d0c2", "committedDate": "2020-04-04T20:54:12Z", "message": "Fix GenericsHelpers."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1f0996113923c5d279a5877a03af2db7b7e4e076", "author": {"user": {"login": "rdblue", "name": "Ryan Blue"}}, "url": "https://github.com/apache/iceberg/commit/1f0996113923c5d279a5877a03af2db7b7e4e076", "committedDate": "2020-04-06T19:53:29Z", "message": "Build: Increase JVM heap size."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3Mzg4NTU2MjAy", "url": "https://github.com/apache/iceberg/pull/892#pullrequestreview-388556202", "createdAt": "2020-04-06T19:34:26Z", "commit": {"oid": "5b0c174e2b4dad298c8fa662701a86c5acc1d0c2"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxOTozNDoyNlrOGBm27A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0wNlQxOTo1MTo0NVrOGBna9g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDMzODQxMg==", "bodyText": "nit: might help to know which is the expected and which is the actual record for comparison", "url": "https://github.com/apache/iceberg/pull/892#discussion_r404338412", "createdAt": "2020-04-06T19:34:26Z", "author": {"login": "rdsr"}, "path": "spark/src/test/java/org/apache/iceberg/spark/data/GenericsHelpers.java", "diffHunk": "@@ -0,0 +1,293 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.data;\n+\n+import com.google.common.collect.Lists;\n+import java.math.BigDecimal;\n+import java.nio.ByteBuffer;\n+import java.sql.Timestamp;\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.OffsetDateTime;\n+import java.time.ZoneOffset;\n+import java.time.temporal.ChronoUnit;\n+import java.util.Collection;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import org.apache.iceberg.data.Record;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.catalyst.util.ArrayData;\n+import org.apache.spark.sql.catalyst.util.MapData;\n+import org.apache.spark.sql.types.Decimal;\n+import org.apache.spark.unsafe.types.UTF8String;\n+import org.junit.Assert;\n+import scala.collection.Seq;\n+\n+import static org.apache.iceberg.spark.SparkSchemaUtil.convert;\n+import static scala.collection.JavaConverters.mapAsJavaMapConverter;\n+import static scala.collection.JavaConverters.seqAsJavaListConverter;\n+\n+public class GenericsHelpers {\n+  private GenericsHelpers() {\n+  }\n+\n+  private static final OffsetDateTime EPOCH = Instant.ofEpochMilli(0L).atOffset(ZoneOffset.UTC);\n+  private static final LocalDate EPOCH_DAY = EPOCH.toLocalDate();\n+\n+  public static void assertEqualsSafe(Types.StructType struct, Record rec, Row row) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5b0c174e2b4dad298c8fa662701a86c5acc1d0c2"}, "originalPosition": 59}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNDM0NzYzOA==", "bodyText": "seems like actual can have more elements. Is that ok?", "url": "https://github.com/apache/iceberg/pull/892#discussion_r404347638", "createdAt": "2020-04-06T19:51:45Z", "author": {"login": "rdsr"}, "path": "spark/src/test/java/org/apache/iceberg/spark/data/GenericsHelpers.java", "diffHunk": "@@ -0,0 +1,293 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.data;\n+\n+import com.google.common.collect.Lists;\n+import java.math.BigDecimal;\n+import java.nio.ByteBuffer;\n+import java.sql.Timestamp;\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.OffsetDateTime;\n+import java.time.ZoneOffset;\n+import java.time.temporal.ChronoUnit;\n+import java.util.Collection;\n+import java.util.Date;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import org.apache.iceberg.data.Record;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.catalyst.util.ArrayData;\n+import org.apache.spark.sql.catalyst.util.MapData;\n+import org.apache.spark.sql.types.Decimal;\n+import org.apache.spark.unsafe.types.UTF8String;\n+import org.junit.Assert;\n+import scala.collection.Seq;\n+\n+import static org.apache.iceberg.spark.SparkSchemaUtil.convert;\n+import static scala.collection.JavaConverters.mapAsJavaMapConverter;\n+import static scala.collection.JavaConverters.seqAsJavaListConverter;\n+\n+public class GenericsHelpers {\n+  private GenericsHelpers() {\n+  }\n+\n+  private static final OffsetDateTime EPOCH = Instant.ofEpochMilli(0L).atOffset(ZoneOffset.UTC);\n+  private static final LocalDate EPOCH_DAY = EPOCH.toLocalDate();\n+\n+  public static void assertEqualsSafe(Types.StructType struct, Record rec, Row row) {\n+    List<Types.NestedField> fields = struct.fields();\n+    for (int i = 0; i < fields.size(); i += 1) {\n+      Type fieldType = fields.get(i).type();\n+\n+      Object expectedValue = rec.get(i);\n+      Object actualValue = row.get(i);\n+\n+      assertEqualsSafe(fieldType, expectedValue, actualValue);\n+    }\n+  }\n+\n+  private static void assertEqualsSafe(Types.ListType list, Collection<?> expected, List<?> actual) {\n+    Type elementType = list.elementType();\n+    List<?> expectedElements = Lists.newArrayList(expected);\n+    for (int i = 0; i < expectedElements.size(); i += 1) {\n+      Object expectedValue = expectedElements.get(i);\n+      Object actualValue = actual.get(i);\n+\n+      assertEqualsSafe(elementType, expectedValue, actualValue);\n+    }\n+  }\n+\n+  private static void assertEqualsSafe(Types.MapType map,\n+                                       Map<?, ?> expected, Map<?, ?> actual) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5b0c174e2b4dad298c8fa662701a86c5acc1d0c2"}, "originalPosition": 83}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "442b1a5882c386f4a5bf5f6833215896b10b1424", "author": {"user": {"login": "rdblue", "name": "Ryan Blue"}}, "url": "https://github.com/apache/iceberg/commit/442b1a5882c386f4a5bf5f6833215896b10b1424", "committedDate": "2020-04-06T21:20:11Z", "message": "Fix review comments."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a8e4ac3b103607f3d7581bf0326f6f7fc697f8d0", "author": {"user": {"login": "rdblue", "name": "Ryan Blue"}}, "url": "https://github.com/apache/iceberg/commit/a8e4ac3b103607f3d7581bf0326f6f7fc697f8d0", "committedDate": "2020-04-07T17:27:50Z", "message": "Revert \"Build: Increase JVM heap size.\"\n\nThis reverts commit 1f0996113923c5d279a5877a03af2db7b7e4e076."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c89dd3a1f4d02855ad3715b60ae02f41acf55a87", "author": {"user": {"login": "rdblue", "name": "Ryan Blue"}}, "url": "https://github.com/apache/iceberg/commit/c89dd3a1f4d02855ad3715b60ae02f41acf55a87", "committedDate": "2020-04-07T17:27:58Z", "message": "Avoid keeping records in memory for TestDataFrameWrites."}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4761, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}