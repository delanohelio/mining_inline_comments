{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDA1NDI5NDAw", "number": 937, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xOFQwMjoxODowMVrODzG1-A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQxODoyODozMFrODz3SQw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0OTE2MDg4OnYy", "diffSide": "RIGHT", "path": "spark/src/main/java/org/apache/iceberg/spark/SparkDataFile.java", "isResolved": true, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xOFQwMjoxODowMVrOGHikcw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQwMDowNDoyNFrOGIssHA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDU1OTYwMw==", "bodyText": "As much as I don't like to use the index, referring by column name seems to incur an additional penalty as we will resolve the column name every time (based on what I see in Spark Row).", "url": "https://github.com/apache/iceberg/pull/937#discussion_r410559603", "createdAt": "2020-04-18T02:18:01Z", "author": {"login": "aokolnychyi"}, "path": "spark/src/main/java/org/apache/iceberg/spark/SparkDataFile.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark;\n+\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import org.apache.iceberg.DataFile;\n+import org.apache.iceberg.FileFormat;\n+import org.apache.iceberg.StructLike;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+import org.apache.spark.sql.Row;\n+\n+public class SparkDataFile implements DataFile {\n+\n+  private final Type lowerBoundsType;\n+  private final Type upperBoundsType;\n+  private final Type keyMetadataType;\n+  private final int fieldShift;\n+  private final SparkStructLike wrappedPartition;\n+  private Row wrapped;\n+\n+  public SparkDataFile(Types.StructType type) {\n+    this.lowerBoundsType = type.fieldType(\"lower_bounds\");\n+    this.upperBoundsType = type.fieldType(\"upper_bounds\");\n+    this.keyMetadataType = type.fieldType(\"key_metadata\");\n+    this.wrappedPartition = new SparkStructLike(type.fieldType(\"partition\").asStructType());\n+    // the partition field is absent for unpartitioned tables\n+    this.fieldShift = wrappedPartition.size() != 0 ? 1 : 0;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "31e7d9a98f9c32ecbdc827040767a4a9c4722cb0"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTU5NjU2Mg==", "bodyText": "If we assume that the type passed in here matches the Row, then we should be able to derive the ordinals from that type instead of hard-coding them. I think this would produce an int[] of expected offset to actual offset, like we use in the Avro generics. What do you think?", "url": "https://github.com/apache/iceberg/pull/937#discussion_r411596562", "createdAt": "2020-04-20T18:26:53Z", "author": {"login": "rdblue"}, "path": "spark/src/main/java/org/apache/iceberg/spark/SparkDataFile.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark;\n+\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import org.apache.iceberg.DataFile;\n+import org.apache.iceberg.FileFormat;\n+import org.apache.iceberg.StructLike;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+import org.apache.spark.sql.Row;\n+\n+public class SparkDataFile implements DataFile {\n+\n+  private final Type lowerBoundsType;\n+  private final Type upperBoundsType;\n+  private final Type keyMetadataType;\n+  private final int fieldShift;\n+  private final SparkStructLike wrappedPartition;\n+  private Row wrapped;\n+\n+  public SparkDataFile(Types.StructType type) {\n+    this.lowerBoundsType = type.fieldType(\"lower_bounds\");\n+    this.upperBoundsType = type.fieldType(\"upper_bounds\");\n+    this.keyMetadataType = type.fieldType(\"key_metadata\");\n+    this.wrappedPartition = new SparkStructLike(type.fieldType(\"partition\").asStructType());\n+    // the partition field is absent for unpartitioned tables\n+    this.fieldShift = wrappedPartition.size() != 0 ? 1 : 0;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDU1OTYwMw=="}, "originalCommit": {"oid": "31e7d9a98f9c32ecbdc827040767a4a9c4722cb0"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTU5NjkyNQ==", "bodyText": "Otherwise, I think it would probably be worth the performance penalty to ensure correctness.", "url": "https://github.com/apache/iceberg/pull/937#discussion_r411596925", "createdAt": "2020-04-20T18:27:31Z", "author": {"login": "rdblue"}, "path": "spark/src/main/java/org/apache/iceberg/spark/SparkDataFile.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark;\n+\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import org.apache.iceberg.DataFile;\n+import org.apache.iceberg.FileFormat;\n+import org.apache.iceberg.StructLike;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+import org.apache.spark.sql.Row;\n+\n+public class SparkDataFile implements DataFile {\n+\n+  private final Type lowerBoundsType;\n+  private final Type upperBoundsType;\n+  private final Type keyMetadataType;\n+  private final int fieldShift;\n+  private final SparkStructLike wrappedPartition;\n+  private Row wrapped;\n+\n+  public SparkDataFile(Types.StructType type) {\n+    this.lowerBoundsType = type.fieldType(\"lower_bounds\");\n+    this.upperBoundsType = type.fieldType(\"upper_bounds\");\n+    this.keyMetadataType = type.fieldType(\"key_metadata\");\n+    this.wrappedPartition = new SparkStructLike(type.fieldType(\"partition\").asStructType());\n+    // the partition field is absent for unpartitioned tables\n+    this.fieldShift = wrappedPartition.size() != 0 ? 1 : 0;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDU1OTYwMw=="}, "originalCommit": {"oid": "31e7d9a98f9c32ecbdc827040767a4a9c4722cb0"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTY0NDA1NQ==", "bodyText": "@rdblue, do you mean passing the Spark type alongside the Iceberg type and building a mapping in the constructor?", "url": "https://github.com/apache/iceberg/pull/937#discussion_r411644055", "createdAt": "2020-04-20T19:45:26Z", "author": {"login": "aokolnychyi"}, "path": "spark/src/main/java/org/apache/iceberg/spark/SparkDataFile.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark;\n+\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import org.apache.iceberg.DataFile;\n+import org.apache.iceberg.FileFormat;\n+import org.apache.iceberg.StructLike;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+import org.apache.spark.sql.Row;\n+\n+public class SparkDataFile implements DataFile {\n+\n+  private final Type lowerBoundsType;\n+  private final Type upperBoundsType;\n+  private final Type keyMetadataType;\n+  private final int fieldShift;\n+  private final SparkStructLike wrappedPartition;\n+  private Row wrapped;\n+\n+  public SparkDataFile(Types.StructType type) {\n+    this.lowerBoundsType = type.fieldType(\"lower_bounds\");\n+    this.upperBoundsType = type.fieldType(\"upper_bounds\");\n+    this.keyMetadataType = type.fieldType(\"key_metadata\");\n+    this.wrappedPartition = new SparkStructLike(type.fieldType(\"partition\").asStructType());\n+    // the partition field is absent for unpartitioned tables\n+    this.fieldShift = wrappedPartition.size() != 0 ? 1 : 0;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDU1OTYwMw=="}, "originalCommit": {"oid": "31e7d9a98f9c32ecbdc827040767a4a9c4722cb0"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTY0NzEzOQ==", "bodyText": "Ideally, yes. But if that's not possible we know that the DataFile that will be passed in comes from a metadata table (because we control the implementations that use this) so it would be okay to assume that we know what the Spark schema is.", "url": "https://github.com/apache/iceberg/pull/937#discussion_r411647139", "createdAt": "2020-04-20T19:50:38Z", "author": {"login": "rdblue"}, "path": "spark/src/main/java/org/apache/iceberg/spark/SparkDataFile.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark;\n+\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import org.apache.iceberg.DataFile;\n+import org.apache.iceberg.FileFormat;\n+import org.apache.iceberg.StructLike;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+import org.apache.spark.sql.Row;\n+\n+public class SparkDataFile implements DataFile {\n+\n+  private final Type lowerBoundsType;\n+  private final Type upperBoundsType;\n+  private final Type keyMetadataType;\n+  private final int fieldShift;\n+  private final SparkStructLike wrappedPartition;\n+  private Row wrapped;\n+\n+  public SparkDataFile(Types.StructType type) {\n+    this.lowerBoundsType = type.fieldType(\"lower_bounds\");\n+    this.upperBoundsType = type.fieldType(\"upper_bounds\");\n+    this.keyMetadataType = type.fieldType(\"key_metadata\");\n+    this.wrappedPartition = new SparkStructLike(type.fieldType(\"partition\").asStructType());\n+    // the partition field is absent for unpartitioned tables\n+    this.fieldShift = wrappedPartition.size() != 0 ? 1 : 0;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDU1OTYwMw=="}, "originalCommit": {"oid": "31e7d9a98f9c32ecbdc827040767a4a9c4722cb0"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTc3Mzk4MA==", "bodyText": "Okay, I've updated this to handle arbitrary projections.", "url": "https://github.com/apache/iceberg/pull/937#discussion_r411773980", "createdAt": "2020-04-21T00:04:24Z", "author": {"login": "aokolnychyi"}, "path": "spark/src/main/java/org/apache/iceberg/spark/SparkDataFile.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark;\n+\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import org.apache.iceberg.DataFile;\n+import org.apache.iceberg.FileFormat;\n+import org.apache.iceberg.StructLike;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+import org.apache.spark.sql.Row;\n+\n+public class SparkDataFile implements DataFile {\n+\n+  private final Type lowerBoundsType;\n+  private final Type upperBoundsType;\n+  private final Type keyMetadataType;\n+  private final int fieldShift;\n+  private final SparkStructLike wrappedPartition;\n+  private Row wrapped;\n+\n+  public SparkDataFile(Types.StructType type) {\n+    this.lowerBoundsType = type.fieldType(\"lower_bounds\");\n+    this.upperBoundsType = type.fieldType(\"upper_bounds\");\n+    this.keyMetadataType = type.fieldType(\"key_metadata\");\n+    this.wrappedPartition = new SparkStructLike(type.fieldType(\"partition\").asStructType());\n+    // the partition field is absent for unpartitioned tables\n+    this.fieldShift = wrappedPartition.size() != 0 ? 1 : 0;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDU1OTYwMw=="}, "originalCommit": {"oid": "31e7d9a98f9c32ecbdc827040767a4a9c4722cb0"}, "originalPosition": 48}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU0OTE2ODg2OnYy", "diffSide": "RIGHT", "path": "spark/src/main/java/org/apache/iceberg/spark/SparkDataFile.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xOFQwMjoyMDoxM1rOGHioUw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQwMjoyNzo0OVrOGIAttw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDU2MDU5NQ==", "bodyText": "I am using getAs instead of getLong as getLong and other methods specific to primitives perform a check if the value is null. The downside might be boxing/unboxing.", "url": "https://github.com/apache/iceberg/pull/937#discussion_r410560595", "createdAt": "2020-04-18T02:20:13Z", "author": {"login": "aokolnychyi"}, "path": "spark/src/main/java/org/apache/iceberg/spark/SparkDataFile.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark;\n+\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import org.apache.iceberg.DataFile;\n+import org.apache.iceberg.FileFormat;\n+import org.apache.iceberg.StructLike;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+import org.apache.spark.sql.Row;\n+\n+public class SparkDataFile implements DataFile {\n+\n+  private final Type lowerBoundsType;\n+  private final Type upperBoundsType;\n+  private final Type keyMetadataType;\n+  private final int fieldShift;\n+  private final SparkStructLike wrappedPartition;\n+  private Row wrapped;\n+\n+  public SparkDataFile(Types.StructType type) {\n+    this.lowerBoundsType = type.fieldType(\"lower_bounds\");\n+    this.upperBoundsType = type.fieldType(\"upper_bounds\");\n+    this.keyMetadataType = type.fieldType(\"key_metadata\");\n+    this.wrappedPartition = new SparkStructLike(type.fieldType(\"partition\").asStructType());\n+    // the partition field is absent for unpartitioned tables\n+    this.fieldShift = wrappedPartition.size() != 0 ? 1 : 0;\n+  }\n+\n+  public SparkDataFile wrap(Row row) {\n+    this.wrapped = row;\n+    if (wrappedPartition.size() > 0) {\n+      this.wrappedPartition.wrap(row.getAs(2));\n+    }\n+    return this;\n+  }\n+\n+  @Override\n+  public CharSequence path() {\n+    return wrapped.getAs(0);\n+  }\n+\n+  @Override\n+  public FileFormat format() {\n+    String formatAsString = wrapped.getString(1).toUpperCase(Locale.ROOT);\n+    return FileFormat.valueOf(formatAsString);\n+  }\n+\n+  @Override\n+  public StructLike partition() {\n+    return wrappedPartition;\n+  }\n+\n+  @Override\n+  public long recordCount() {\n+    return wrapped.getAs(fieldShift + 2);\n+  }\n+\n+  @Override\n+  public long fileSizeInBytes() {\n+    return wrapped.getAs(fieldShift + 3);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "31e7d9a98f9c32ecbdc827040767a4a9c4722cb0"}, "originalPosition": 82}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTA1MzQ5NQ==", "bodyText": "Actually, Spark row uses Array[Any] which I assume allocates an array of Objects. So, Spark stores boxed versions and we have to unbox it anyway. If we used getLong, we would also perform a null check.", "url": "https://github.com/apache/iceberg/pull/937#discussion_r411053495", "createdAt": "2020-04-20T02:27:49Z", "author": {"login": "aokolnychyi"}, "path": "spark/src/main/java/org/apache/iceberg/spark/SparkDataFile.java", "diffHunk": "@@ -0,0 +1,134 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark;\n+\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.Locale;\n+import java.util.Map;\n+import org.apache.iceberg.DataFile;\n+import org.apache.iceberg.FileFormat;\n+import org.apache.iceberg.StructLike;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+import org.apache.spark.sql.Row;\n+\n+public class SparkDataFile implements DataFile {\n+\n+  private final Type lowerBoundsType;\n+  private final Type upperBoundsType;\n+  private final Type keyMetadataType;\n+  private final int fieldShift;\n+  private final SparkStructLike wrappedPartition;\n+  private Row wrapped;\n+\n+  public SparkDataFile(Types.StructType type) {\n+    this.lowerBoundsType = type.fieldType(\"lower_bounds\");\n+    this.upperBoundsType = type.fieldType(\"upper_bounds\");\n+    this.keyMetadataType = type.fieldType(\"key_metadata\");\n+    this.wrappedPartition = new SparkStructLike(type.fieldType(\"partition\").asStructType());\n+    // the partition field is absent for unpartitioned tables\n+    this.fieldShift = wrappedPartition.size() != 0 ? 1 : 0;\n+  }\n+\n+  public SparkDataFile wrap(Row row) {\n+    this.wrapped = row;\n+    if (wrappedPartition.size() > 0) {\n+      this.wrappedPartition.wrap(row.getAs(2));\n+    }\n+    return this;\n+  }\n+\n+  @Override\n+  public CharSequence path() {\n+    return wrapped.getAs(0);\n+  }\n+\n+  @Override\n+  public FileFormat format() {\n+    String formatAsString = wrapped.getString(1).toUpperCase(Locale.ROOT);\n+    return FileFormat.valueOf(formatAsString);\n+  }\n+\n+  @Override\n+  public StructLike partition() {\n+    return wrappedPartition;\n+  }\n+\n+  @Override\n+  public long recordCount() {\n+    return wrapped.getAs(fieldShift + 2);\n+  }\n+\n+  @Override\n+  public long fileSizeInBytes() {\n+    return wrapped.getAs(fieldShift + 3);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMDU2MDU5NQ=="}, "originalCommit": {"oid": "31e7d9a98f9c32ecbdc827040767a4a9c4722cb0"}, "originalPosition": 82}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU1NzA3NjYwOnYy", "diffSide": "RIGHT", "path": "build.gradle", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQxODoyMzoyMlrOGIhuOA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQxOTozODoyM1rOGIkgHw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTU5NDI5Ng==", "bodyText": "Why is this necessary? It looks like all of the code here is added to Spark.", "url": "https://github.com/apache/iceberg/pull/937#discussion_r411594296", "createdAt": "2020-04-20T18:23:22Z", "author": {"login": "rdblue"}, "path": "build.gradle", "diffHunk": "@@ -307,6 +307,7 @@ project(':iceberg-spark') {\n     compile project(':iceberg-api')\n     compile project(':iceberg-common')\n     compile project(':iceberg-core')\n+    compile project(':iceberg-data')", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "31e7d9a98f9c32ecbdc827040767a4a9c4722cb0"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTYzOTgzOQ==", "bodyText": "SparkValueConverter uses the following classes:\nimport org.apache.iceberg.data.GenericRecord;\nimport org.apache.iceberg.data.Record;", "url": "https://github.com/apache/iceberg/pull/937#discussion_r411639839", "createdAt": "2020-04-20T19:38:23Z", "author": {"login": "aokolnychyi"}, "path": "build.gradle", "diffHunk": "@@ -307,6 +307,7 @@ project(':iceberg-spark') {\n     compile project(':iceberg-api')\n     compile project(':iceberg-common')\n     compile project(':iceberg-core')\n+    compile project(':iceberg-data')", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTU5NDI5Ng=="}, "originalCommit": {"oid": "31e7d9a98f9c32ecbdc827040767a4a9c4722cb0"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU1NzA5NzYzOnYy", "diffSide": "RIGHT", "path": "spark/src/main/java/org/apache/iceberg/spark/SparkValueConverter.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQxODoyODozMFrOGIh66g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMVQwMDowMjo1MlrOGIsp3Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTU5NzU0Ng==", "bodyText": "It would be nice to have some Javadoc about this, like that values are converted to Iceberg's internal representation.", "url": "https://github.com/apache/iceberg/pull/937#discussion_r411597546", "createdAt": "2020-04-20T18:28:30Z", "author": {"login": "rdblue"}, "path": "spark/src/main/java/org/apache/iceberg/spark/SparkValueConverter.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark;\n+\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Maps;\n+import java.nio.ByteBuffer;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.data.GenericRecord;\n+import org.apache.iceberg.data.Record;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.catalyst.util.DateTimeUtils;\n+\n+public class SparkValueConverter {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "31e7d9a98f9c32ecbdc827040767a4a9c4722cb0"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTY0NDIxOQ==", "bodyText": "Yep, will add.", "url": "https://github.com/apache/iceberg/pull/937#discussion_r411644219", "createdAt": "2020-04-20T19:45:44Z", "author": {"login": "aokolnychyi"}, "path": "spark/src/main/java/org/apache/iceberg/spark/SparkValueConverter.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark;\n+\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Maps;\n+import java.nio.ByteBuffer;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.data.GenericRecord;\n+import org.apache.iceberg.data.Record;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.catalyst.util.DateTimeUtils;\n+\n+public class SparkValueConverter {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTU5NzU0Ng=="}, "originalCommit": {"oid": "31e7d9a98f9c32ecbdc827040767a4a9c4722cb0"}, "originalPosition": 37}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTc3MzQwNQ==", "bodyText": "Done.", "url": "https://github.com/apache/iceberg/pull/937#discussion_r411773405", "createdAt": "2020-04-21T00:02:52Z", "author": {"login": "aokolnychyi"}, "path": "spark/src/main/java/org/apache/iceberg/spark/SparkValueConverter.java", "diffHunk": "@@ -0,0 +1,116 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark;\n+\n+import com.google.common.collect.Lists;\n+import com.google.common.collect.Maps;\n+import java.nio.ByteBuffer;\n+import java.sql.Date;\n+import java.sql.Timestamp;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.data.GenericRecord;\n+import org.apache.iceberg.data.Record;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.catalyst.util.DateTimeUtils;\n+\n+public class SparkValueConverter {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTU5NzU0Ng=="}, "originalCommit": {"oid": "31e7d9a98f9c32ecbdc827040767a4a9c4722cb0"}, "originalPosition": 37}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2936, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}