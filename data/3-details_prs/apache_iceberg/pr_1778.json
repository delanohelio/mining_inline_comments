{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTIyNjQ4Mzkx", "number": 1778, "title": "Parquet - Add a spark session configuration for controlling enabling vectorized reads", "bodyText": "Since enabling vectorized reads internally, we have come across a couple of issues listed below that provide motivation for adding a session level control for enabling/disabling vectorized reads:\n\nFor some pyspark jobs we have noticed that certain libraries like Pandas were not able to handle ColumnarBatch being returned by Iceberg correctly.\nFor example in Spark 2.4.4, the below call failed:\n\nspark_df.toPandas() \n\nwith\njava.lang.ClassCastException: org.apache.spark.sql.vectorized.ColumnarBatch cannot be cast to org.apache.spark.sql.catalyst.InternalRow\n\tat org.apache.spark.sql.execution.datasources.v2.DataSourceV2ScanExecBase$$anonfun$doExecute$1.apply(DataSourceV2ScanExecBase.scala:71)\n\tat scala.collection.Iterator$$anon$11.next(Iterator.scala:410)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:256)\n\tat org.apache.spark.sql.execution.SparkPlan$$anonfun$2.apply(SparkPlan.scala:247)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:841)\n\tat org.apache.spark.rdd.RDD$$anonfun$mapPartitionsInternal$1$$anonfun$apply$25.apply(RDD.scala:841)\n\tat org.apache.spark.rdd.MapPartitionsRDD.compute(MapPartitionsRDD.scala:52)\n\tat org.apache.spark.rdd.RDD.computeOrReadCheckpoint(RDD.scala:329)\n\tat org.apache.spark.rdd.RDD.iterator(RDD.scala:293)\n\tat org.apache.spark.scheduler.ResultTask.runTask(ResultTask.scala:90)\n\tat org.apache.spark.scheduler.Task.run(Task.scala:123)\n\tat org.apache.spark.executor.Executor$TaskRunner$$anonfun$10.apply(Executor.scala:414)\n\tat org.apache.spark.util.Utils$.tryWithSafeFinally(Utils.scala:1361)\n\tat org.apache.spark.executor.Executor$TaskRunner.run(Executor.scala:420)\n\tat java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149)\n\tat java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624)\n\tat java.lang.Thread.run(Thread.java:748)\n\nTill the problem is fixed, having a session level property provides a reasonable workaround to disable vectorized reads in such jobs.\n\nFor some tables with really large columns, storing batches in Arrow buffers exceeds the 2GB limit. While Arrow has introduced various Large*Vector buffer classes, unfortunately, using them regresses performance. For ex - replacing VarCharVector with LargeVarCharVector regressed performance by more than 30% for String columns. Considering this limitation, a couple of possible workarounds are to either reduce the batch size significantly or to disable vectorized reads via table properties altogether. For jobs that are not projecting these large columns, it doesn't make sense to penalize their read times by doing the above two changes. For jobs that are projecting these large columns, they could simply disable vectorization by setting the spark.iceberg.vectorization.enabled property to false.", "createdAt": "2020-11-17T19:17:18Z", "url": "https://github.com/apache/iceberg/pull/1778", "merged": true, "mergeCommit": {"oid": "8685545a7fc1069fb07428a5830e27296d20f119"}, "closed": true, "closedAt": "2020-12-03T22:19:22Z", "author": {"login": "samarthjain"}, "timelineItems": {"totalCount": 15, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABddjW8xgFqTUzMjkzMTg3MA==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdiqv0LAFqTU0NDQ5OTk2Ng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMyOTMxODcw", "url": "https://github.com/apache/iceberg/pull/1778#pullrequestreview-532931870", "createdAt": "2020-11-18T00:52:47Z", "commit": {"oid": "f121d81611f678203d66b6a33e2402ec3021845e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQwMDo1Mjo0N1rOH1Rg5A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQwMDo1Mjo0N1rOH1Rg5A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYyMzUyNA==", "bodyText": "Looks like these 4 lines didn't actually change. Can you revert the whitespace changes here?", "url": "https://github.com/apache/iceberg/pull/1778#discussion_r525623524", "createdAt": "2020-11-18T00:52:47Z", "author": {"login": "rdblue"}, "path": "spark2/src/main/java/org/apache/iceberg/spark/source/Reader.java", "diffHunk": "@@ -156,10 +156,13 @@\n     this.io = io;\n     this.encryptionManager = encryptionManager;\n     this.caseSensitive = caseSensitive;\n-\n-    this.batchReadsEnabled = options.get(\"vectorization-enabled\").map(Boolean::parseBoolean).orElseGet(() ->\n-        PropertyUtil.propertyAsBoolean(table.properties(),\n-            TableProperties.PARQUET_VECTORIZATION_ENABLED, TableProperties.PARQUET_VECTORIZATION_ENABLED_DEFAULT));\n+    boolean batchReadsSparkSessionConf = SparkSession.active().sparkContext().getConf()\n+            .getBoolean(\"read.parquet.vectorization.enabled\", true);\n+    boolean batchReadsEnabledTableProp = options.get(\"vectorization-enabled\").map(Boolean::parseBoolean).orElseGet(() ->\n+            PropertyUtil.propertyAsBoolean(table.properties(),\n+                    TableProperties.PARQUET_VECTORIZATION_ENABLED,\n+                    TableProperties.PARQUET_VECTORIZATION_ENABLED_DEFAULT));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f121d81611f678203d66b6a33e2402ec3021845e"}, "originalPosition": 13}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMyOTMyMTY0", "url": "https://github.com/apache/iceberg/pull/1778#pullrequestreview-532932164", "createdAt": "2020-11-18T00:53:34Z", "commit": {"oid": "f121d81611f678203d66b6a33e2402ec3021845e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQwMDo1MzozNVrOH1Rhww==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQwMDo1MzozNVrOH1Rhww==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYyMzc0Nw==", "bodyText": "Don't Spark settings need to start with spark.? Otherwise they are discarded.\nHow about spark.iceberg.vectorization.enabled?", "url": "https://github.com/apache/iceberg/pull/1778#discussion_r525623747", "createdAt": "2020-11-18T00:53:35Z", "author": {"login": "rdblue"}, "path": "spark2/src/main/java/org/apache/iceberg/spark/source/Reader.java", "diffHunk": "@@ -156,10 +156,13 @@\n     this.io = io;\n     this.encryptionManager = encryptionManager;\n     this.caseSensitive = caseSensitive;\n-\n-    this.batchReadsEnabled = options.get(\"vectorization-enabled\").map(Boolean::parseBoolean).orElseGet(() ->\n-        PropertyUtil.propertyAsBoolean(table.properties(),\n-            TableProperties.PARQUET_VECTORIZATION_ENABLED, TableProperties.PARQUET_VECTORIZATION_ENABLED_DEFAULT));\n+    boolean batchReadsSparkSessionConf = SparkSession.active().sparkContext().getConf()\n+            .getBoolean(\"read.parquet.vectorization.enabled\", true);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f121d81611f678203d66b6a33e2402ec3021845e"}, "originalPosition": 9}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTMyOTM3MTMx", "url": "https://github.com/apache/iceberg/pull/1778#pullrequestreview-532937131", "createdAt": "2020-11-18T01:06:51Z", "commit": {"oid": "f121d81611f678203d66b6a33e2402ec3021845e"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQwMTowNjo1MVrOH1RzSQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQwMTowNjo1MVrOH1RzSQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYyODIzMw==", "bodyText": "Looks like the logic here is too complicated. I think what you're trying to do is disable vectorized reads if the session conf disables them, and otherwise delegate to the table property. In other words, the session conf and the table property must be enabled to use vectorization. If that's the case, then this could be (batchReadsSparkSessionConf && batchReadsEnabledTableProp).\nI'm not sure that logic is a good idea, either. This may have surprising behavior because a user may expect that true enables vectorization for all tables when used as a session property.\nI think a better way to configure is to choose an order of priority and delegate to the next config if the option is not set. Here, I think session should override table. If session is set, return whatever it is. Otherwise, use the table property.", "url": "https://github.com/apache/iceberg/pull/1778#discussion_r525628233", "createdAt": "2020-11-18T01:06:51Z", "author": {"login": "rdblue"}, "path": "spark2/src/main/java/org/apache/iceberg/spark/source/Reader.java", "diffHunk": "@@ -156,10 +156,13 @@\n     this.io = io;\n     this.encryptionManager = encryptionManager;\n     this.caseSensitive = caseSensitive;\n-\n-    this.batchReadsEnabled = options.get(\"vectorization-enabled\").map(Boolean::parseBoolean).orElseGet(() ->\n-        PropertyUtil.propertyAsBoolean(table.properties(),\n-            TableProperties.PARQUET_VECTORIZATION_ENABLED, TableProperties.PARQUET_VECTORIZATION_ENABLED_DEFAULT));\n+    boolean batchReadsSparkSessionConf = SparkSession.active().sparkContext().getConf()\n+            .getBoolean(\"read.parquet.vectorization.enabled\", true);\n+    boolean batchReadsEnabledTableProp = options.get(\"vectorization-enabled\").map(Boolean::parseBoolean).orElseGet(() ->\n+            PropertyUtil.propertyAsBoolean(table.properties(),\n+                    TableProperties.PARQUET_VECTORIZATION_ENABLED,\n+                    TableProperties.PARQUET_VECTORIZATION_ENABLED_DEFAULT));\n+    this.batchReadsEnabled = !batchReadsSparkSessionConf ? false : batchReadsEnabledTableProp;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f121d81611f678203d66b6a33e2402ec3021845e"}, "originalPosition": 14}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "16d8367a0340efab673dd92ebf6880f6b639f310", "author": {"user": {"login": "samarthjain", "name": "Samarth Jain"}}, "url": "https://github.com/apache/iceberg/commit/16d8367a0340efab673dd92ebf6880f6b639f310", "committedDate": "2020-11-18T23:03:15Z", "message": "Prioritize session config if set"}, "afterCommit": {"oid": "f29de7aeca16d3c7ff5aefc1013e0f30a8395ae6", "author": {"user": {"login": "samarthjain", "name": "Samarth Jain"}}, "url": "https://github.com/apache/iceberg/commit/f29de7aeca16d3c7ff5aefc1013e0f30a8395ae6", "committedDate": "2020-11-18T23:45:49Z", "message": "Prioritize session config if set"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f29de7aeca16d3c7ff5aefc1013e0f30a8395ae6", "author": {"user": {"login": "samarthjain", "name": "Samarth Jain"}}, "url": "https://github.com/apache/iceberg/commit/f29de7aeca16d3c7ff5aefc1013e0f30a8395ae6", "committedDate": "2020-11-18T23:45:49Z", "message": "Prioritize session config if set"}, "afterCommit": {"oid": "cb21c1c5c70e06df0a89f476790e69ab200be7ba", "author": {"user": {"login": "samarthjain", "name": "Samarth Jain"}}, "url": "https://github.com/apache/iceberg/commit/cb21c1c5c70e06df0a89f476790e69ab200be7ba", "committedDate": "2020-11-19T00:23:02Z", "message": "Prioritize session config if set"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM0MDA1NjQy", "url": "https://github.com/apache/iceberg/pull/1778#pullrequestreview-534005642", "createdAt": "2020-11-19T01:11:11Z", "commit": {"oid": "cb21c1c5c70e06df0a89f476790e69ab200be7ba"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMToxMToxMlrOH2IooA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMToxMToxMlrOH2IooA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUyNjYyNA==", "bodyText": "Continuation indents are 4 spaces or 2 indents from the previous. Could you update this?", "url": "https://github.com/apache/iceberg/pull/1778#discussion_r526526624", "createdAt": "2020-11-19T01:11:12Z", "author": {"login": "rdblue"}, "path": "spark2/src/main/java/org/apache/iceberg/spark/source/Reader.java", "diffHunk": "@@ -156,10 +157,15 @@\n     this.io = io;\n     this.encryptionManager = encryptionManager;\n     this.caseSensitive = caseSensitive;\n-\n-    this.batchReadsEnabled = options.get(\"vectorization-enabled\").map(Boolean::parseBoolean).orElseGet(() ->\n-        PropertyUtil.propertyAsBoolean(table.properties(),\n-            TableProperties.PARQUET_VECTORIZATION_ENABLED, TableProperties.PARQUET_VECTORIZATION_ENABLED_DEFAULT));\n+    Option<String> option = SparkSession.active().sparkContext().getConf()\n+            .getOption(\"spark.iceberg.vectorization.enabled\");\n+    if (option.isDefined()) {\n+      this.batchReadsEnabled = Boolean.valueOf(option.get());\n+    } else {\n+      this.batchReadsEnabled = options.get(\"vectorization-enabled\").map(Boolean::parseBoolean).orElseGet(() ->\n+              PropertyUtil.propertyAsBoolean(table.properties(), TableProperties.PARQUET_VECTORIZATION_ENABLED,\n+                      TableProperties.PARQUET_VECTORIZATION_ENABLED_DEFAULT));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cb21c1c5c70e06df0a89f476790e69ab200be7ba"}, "originalPosition": 23}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM0MDA2MDgy", "url": "https://github.com/apache/iceberg/pull/1778#pullrequestreview-534006082", "createdAt": "2020-11-19T01:12:14Z", "commit": {"oid": "cb21c1c5c70e06df0a89f476790e69ab200be7ba"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMToxMjoxNFrOH2IqHg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMToxMjoxNFrOH2IqHg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUyNzAwNg==", "bodyText": "You should be able to use SparkSession.active().conf().get(\"key\", null) to get the value or null. No need to use the Spark context's conf.", "url": "https://github.com/apache/iceberg/pull/1778#discussion_r526527006", "createdAt": "2020-11-19T01:12:14Z", "author": {"login": "rdblue"}, "path": "spark2/src/main/java/org/apache/iceberg/spark/source/Reader.java", "diffHunk": "@@ -156,10 +157,15 @@\n     this.io = io;\n     this.encryptionManager = encryptionManager;\n     this.caseSensitive = caseSensitive;\n-\n-    this.batchReadsEnabled = options.get(\"vectorization-enabled\").map(Boolean::parseBoolean).orElseGet(() ->\n-        PropertyUtil.propertyAsBoolean(table.properties(),\n-            TableProperties.PARQUET_VECTORIZATION_ENABLED, TableProperties.PARQUET_VECTORIZATION_ENABLED_DEFAULT));\n+    Option<String> option = SparkSession.active().sparkContext().getConf()\n+            .getOption(\"spark.iceberg.vectorization.enabled\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cb21c1c5c70e06df0a89f476790e69ab200be7ba"}, "originalPosition": 17}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e00b978f4954560c82b397c05e8ec49bbe498374", "author": {"user": {"login": "samarthjain", "name": "Samarth Jain"}}, "url": "https://github.com/apache/iceberg/commit/e00b978f4954560c82b397c05e8ec49bbe498374", "committedDate": "2020-11-19T09:35:13Z", "message": "Code review comments"}, "afterCommit": {"oid": "7c32a5212ace9f0ec2c74ac9d8628cf802ddeb84", "author": {"user": {"login": "samarthjain", "name": "Samarth Jain"}}, "url": "https://github.com/apache/iceberg/commit/7c32a5212ace9f0ec2c74ac9d8628cf802ddeb84", "committedDate": "2020-11-19T09:59:43Z", "message": "Code review comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ea760b96fae6be1c7df95a56712e8ae3e6c6b4a0", "author": {"user": {"login": "samarthjain", "name": "Samarth Jain"}}, "url": "https://github.com/apache/iceberg/commit/ea760b96fae6be1c7df95a56712e8ae3e6c6b4a0", "committedDate": "2020-12-02T22:11:44Z", "message": "Parquet - Add a spark session configuration for controlling enabling vectorized reads"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a2f86a71ece3c2c63363b04182045fed3bc9fe70", "author": {"user": {"login": "samarthjain", "name": "Samarth Jain"}}, "url": "https://github.com/apache/iceberg/commit/a2f86a71ece3c2c63363b04182045fed3bc9fe70", "committedDate": "2020-12-02T22:11:44Z", "message": "Prioritize session config if set"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d29c13a5548fe202f3da5fecaa2f8bb1e31a9e1c", "author": {"user": {"login": "samarthjain", "name": "Samarth Jain"}}, "url": "https://github.com/apache/iceberg/commit/d29c13a5548fe202f3da5fecaa2f8bb1e31a9e1c", "committedDate": "2020-12-02T22:11:44Z", "message": "Code review comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0dddb89342fe73057bb182da9257959ebe1d91c1", "author": {"user": {"login": "samarthjain", "name": "Samarth Jain"}}, "url": "https://github.com/apache/iceberg/commit/0dddb89342fe73057bb182da9257959ebe1d91c1", "committedDate": "2020-12-02T22:13:10Z", "message": "Add config control to Spark3 as well"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ea9d5f8277bceea845b2f4c70a8c7d0552c32502", "author": {"user": {"login": "samarthjain", "name": "Samarth Jain"}}, "url": "https://github.com/apache/iceberg/commit/ea9d5f8277bceea845b2f4c70a8c7d0552c32502", "committedDate": "2020-12-02T22:13:10Z", "message": "Use spark.sql namespace for the config"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "96338f6d285055e536fc627e8567d150e6438a12", "author": {"user": {"login": "samarthjain", "name": "Samarth Jain"}}, "url": "https://github.com/apache/iceberg/commit/96338f6d285055e536fc627e8567d150e6438a12", "committedDate": "2020-12-02T22:10:40Z", "message": "Use spark.sql namespace for the config"}, "afterCommit": {"oid": "ea9d5f8277bceea845b2f4c70a8c7d0552c32502", "author": {"user": {"login": "samarthjain", "name": "Samarth Jain"}}, "url": "https://github.com/apache/iceberg/commit/ea9d5f8277bceea845b2f4c70a8c7d0552c32502", "committedDate": "2020-12-02T22:13:10Z", "message": "Use spark.sql namespace for the config"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ0NDk5OTY2", "url": "https://github.com/apache/iceberg/pull/1778#pullrequestreview-544499966", "createdAt": "2020-12-03T22:18:54Z", "commit": {"oid": "ea9d5f8277bceea845b2f4c70a8c7d0552c32502"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3769, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}