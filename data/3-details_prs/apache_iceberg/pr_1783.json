{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTIzMzk4ODIx", "number": 1783, "title": "Custom catalogs from `IcebergSource`", "bodyText": "I wanted to start a conversation about how to make IcebergSource compatible with custom Iceberg Catalogs in both Spark 2&3.\nThis first attempt is meant to give a straw man for how this could be done. It uses code from LookupCatalog to fetch a Catalog and Identifier from a path. We then try and extract an Iceberg table from it.\nThis works by specifying the catalog(iceberg_catalog) below in the path or by setting a default catalog in spark config.\ndf.write.format(\"iceberg\").mode(\"append\").save(\"iceberg_catalog.testing.foo\")\nSeveral problems:\n\nstill have the fragile path check to delegate to the Hadoop catalog\nnot strictly backwards compatible one has to specify a catalog as part of the path or a default catalog\nnot 100% sure this will work for Spark2\nCopies code from LookupCatalog it would be nice to use that (or similar) directly but that would involve putting scala code in the code path.\nHard to pass parameters to the catalog as we do now\n\nI am soliciting opinions on what might be a better way of doing custom catalogs, has anyone else been thinking about this?\ncc @rdblue @jacques-n @laurentgo", "createdAt": "2020-11-18T18:48:22Z", "url": "https://github.com/apache/iceberg/pull/1783", "merged": true, "mergeCommit": {"oid": "2f136e9da5630e1f4f402f847b1d9e6a40c7401a"}, "closed": true, "closedAt": "2020-12-22T18:09:14Z", "author": {"login": "rymurr"}, "timelineItems": {"totalCount": 55, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdho0j8gBqjQwNTMxMjEyNDE=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdotX7OABqjQxNDA5NDEwNDI=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "85ed0697eedc74e9249604a2b8cd77d951236b04", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/85ed0697eedc74e9249604a2b8cd77d951236b04", "committedDate": "2020-11-30T17:15:01Z", "message": "tests all fixed"}, "afterCommit": {"oid": "2e5ab046dd34c19a07aba7c737ddd5db2b4a6291", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/2e5ab046dd34c19a07aba7c737ddd5db2b4a6291", "committedDate": "2020-11-30T17:30:11Z", "message": "source fixes"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQxNDMyODI4", "url": "https://github.com/apache/iceberg/pull/1783#pullrequestreview-541432828", "createdAt": "2020-12-01T01:57:49Z", "commit": {"oid": "2e5ab046dd34c19a07aba7c737ddd5db2b4a6291"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMTo1Nzo0OVrOH8VG7w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMTo1Nzo0OVrOH8VG7w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAyMjQ0Nw==", "bodyText": "I don't think catalogName is accurate because catalogs have names (this one is spark_catalog). It should be catalogClass to be more clear.", "url": "https://github.com/apache/iceberg/pull/1783#discussion_r533022447", "createdAt": "2020-12-01T01:57:49Z", "author": {"login": "rdblue"}, "path": "spark3/src/test/java/org/apache/iceberg/spark/source/SetupSourceCatalog.java", "diffHunk": "@@ -0,0 +1,41 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iceberg.spark.source;\n+\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.spark.SparkSessionCatalog;\n+import org.apache.spark.sql.SparkSession;\n+\n+public final class SetupSourceCatalog {\n+\n+  private SetupSourceCatalog() {\n+\n+  }\n+\n+  public static void setupSparkCatalog(SparkSession spark) {\n+    setupSparkCatalog(spark, SparkSessionCatalog.class.getName());\n+  }\n+\n+  public static void setupSparkCatalog(SparkSession spark, String catalogName) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2e5ab046dd34c19a07aba7c737ddd5db2b4a6291"}, "originalPosition": 31}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQxNDMzMzIx", "url": "https://github.com/apache/iceberg/pull/1783#pullrequestreview-541433321", "createdAt": "2020-12-01T01:59:15Z", "commit": {"oid": "2e5ab046dd34c19a07aba7c737ddd5db2b4a6291"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMTo1OToxNVrOH8VIeg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMTo1OToxNVrOH8VIeg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAyMjg0Mg==", "bodyText": "Why not add this to the iceberg-spark module? The only thing that isn't compatible is SparkSessionCatalog.class.getName(). The 2.4 code should ignore these settings, and this change would be a lot smaller.", "url": "https://github.com/apache/iceberg/pull/1783#discussion_r533022842", "createdAt": "2020-12-01T01:59:15Z", "author": {"login": "rdblue"}, "path": "spark3/src/test/java/org/apache/iceberg/spark/source/SetupSourceCatalog.java", "diffHunk": "@@ -0,0 +1,41 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iceberg.spark.source;\n+\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.spark.SparkSessionCatalog;\n+import org.apache.spark.sql.SparkSession;\n+\n+public final class SetupSourceCatalog {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2e5ab046dd34c19a07aba7c737ddd5db2b4a6291"}, "originalPosition": 21}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQxNDMzOTQx", "url": "https://github.com/apache/iceberg/pull/1783#pullrequestreview-541433941", "createdAt": "2020-12-01T02:01:00Z", "commit": {"oid": "2e5ab046dd34c19a07aba7c737ddd5db2b4a6291"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMjowMTowMFrOH8VLEw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQwMjowMTowMFrOH8VLEw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzAyMzUwNw==", "bodyText": "@RussellSpitzer, I seem to remember looking at very similar logic recently. Did we commit that anywhere that we can reuse?", "url": "https://github.com/apache/iceberg/pull/1783#discussion_r533023507", "createdAt": "2020-12-01T02:01:00Z", "author": {"login": "rdblue"}, "path": "spark3/src/main/java/org/apache/iceberg/spark/source/IcebergSource.java", "diffHunk": "@@ -56,48 +61,62 @@ public boolean supportsExternalMetadata() {\n   }\n \n   @Override\n-  public SparkTable getTable(StructType schema, Transform[] partitioning, Map<String, String> options) {\n-    // Get Iceberg table from options\n-    Configuration conf = SparkSession.active().sessionState().newHadoopConf();\n-    Table icebergTable = getTableAndResolveHadoopConfiguration(options, conf);\n-\n-    // Build Spark table based on Iceberg table, and return it\n-    // Eagerly refresh the table before reading to ensure views containing this table show up-to-date data\n-    return new SparkTable(icebergTable, schema, true);\n+  public Table getTable(StructType schema, Transform[] partitioning, Map<String, String> options) {\n+    String catalogName = extractCatalog(new CaseInsensitiveStringMap(options));\n+    Identifier ident = extractIdentifier(new CaseInsensitiveStringMap(options));\n+    CatalogManager catalogManager = SparkSession.active().sessionState().catalogManager();\n+    CatalogPlugin catalog = catalogManager.catalog(catalogName);\n+    try {\n+      if (catalog instanceof TableCatalog) {\n+        return ((TableCatalog) catalog).loadTable(ident);\n+      }\n+    } catch (NoSuchTableException e) {\n+      throw new org.apache.iceberg.exceptions.NoSuchTableException(e, \"Cannot find table for %s.\", ident);\n+    }\n+    throw new org.apache.iceberg.exceptions.NoSuchTableException(\"Cannot find table for %s.\", ident);\n   }\n \n-  protected Table findTable(Map<String, String> options, Configuration conf) {\n+  private Pair<String, TableIdentifier> tableIdentifier(CaseInsensitiveStringMap options) {\n+    CatalogManager catalogManager = SparkSession.active().sessionState().catalogManager();\n+    Namespace defaultNamespace = Namespace.of(catalogManager.currentNamespace());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2e5ab046dd34c19a07aba7c737ddd5db2b4a6291"}, "originalPosition": 65}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "2e5ab046dd34c19a07aba7c737ddd5db2b4a6291", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/2e5ab046dd34c19a07aba7c737ddd5db2b4a6291", "committedDate": "2020-11-30T17:30:11Z", "message": "source fixes"}, "afterCommit": {"oid": "ac33ea3fd109d0b808f3c7f90cc38dc704b6923c", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/ac33ea3fd109d0b808f3c7f90cc38dc704b6923c", "committedDate": "2020-12-01T13:00:27Z", "message": "updates based on code review"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQxOTAwMDQ4", "url": "https://github.com/apache/iceberg/pull/1783#pullrequestreview-541900048", "createdAt": "2020-12-01T13:37:45Z", "commit": {"oid": "ac33ea3fd109d0b808f3c7f90cc38dc704b6923c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxMzozNzo0NVrOH8s5Hg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxMzozNzo0NVrOH8s5Hg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzQxMjEyNg==", "bodyText": "A potential complication: SupportsCatalogOptions doesn't allow for specifying the schema. I don't know how much people rely on this feature but it is a breaking change for the IcebergSource", "url": "https://github.com/apache/iceberg/pull/1783#discussion_r533412126", "createdAt": "2020-12-01T13:37:45Z", "author": {"login": "rymurr"}, "path": "spark3/src/test/java/org/apache/iceberg/spark/source/TestSparkSchema3.java", "diffHunk": "@@ -1,23 +0,0 @@\n-/*", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ac33ea3fd109d0b808f3c7f90cc38dc704b6923c"}, "originalPosition": 1}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQyMTYxNTI3", "url": "https://github.com/apache/iceberg/pull/1783#pullrequestreview-542161527", "createdAt": "2020-12-01T18:02:15Z", "commit": {"oid": "ac33ea3fd109d0b808f3c7f90cc38dc704b6923c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxODowMjoxNlrOH85PLA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxODowMjoxNlrOH85PLA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYxNDM4MA==", "bodyText": "Nit: unnecessary whitespace change.", "url": "https://github.com/apache/iceberg/pull/1783#discussion_r533614380", "createdAt": "2020-12-01T18:02:16Z", "author": {"login": "rdblue"}, "path": "spark/src/test/java/org/apache/iceberg/TestScanTaskSerialization.java", "diffHunk": "@@ -60,11 +62,17 @@\n       optional(3, \"c3\", Types.StringType.get())\n   );\n \n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ac33ea3fd109d0b808f3c7f90cc38dc704b6923c"}, "originalPosition": 20}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQyMTYxODA5", "url": "https://github.com/apache/iceberg/pull/1783#pullrequestreview-542161809", "createdAt": "2020-12-01T18:02:38Z", "commit": {"oid": "ac33ea3fd109d0b808f3c7f90cc38dc704b6923c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxODowMjozOFrOH85QDg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxODowMjozOFrOH85QDg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYxNDYwNg==", "bodyText": "Nit: can you remove this newline?", "url": "https://github.com/apache/iceberg/pull/1783#discussion_r533614606", "createdAt": "2020-12-01T18:02:38Z", "author": {"login": "rdblue"}, "path": "spark/src/test/java/org/apache/iceberg/spark/source/SetupSourceCatalog.java", "diffHunk": "@@ -0,0 +1,54 @@\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+/*\n+ * Licensed under the Apache License, Version 2.0 (the \"License\");\n+ * you may not use this file except in compliance with the License.\n+ * You may obtain a copy of the License at\n+ *\n+ *     http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing, software\n+ * distributed under the License is distributed on an \"AS IS\" BASIS,\n+ * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ * See the License for the specific language governing permissions and\n+ * limitations under the License.\n+ */\n+\n+package org.apache.iceberg.spark.source;\n+\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.spark.sql.SparkSession;\n+\n+public final class SetupSourceCatalog {\n+\n+  private SetupSourceCatalog() {\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ac33ea3fd109d0b808f3c7f90cc38dc704b6923c"}, "originalPosition": 37}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQyMTYzNjk1", "url": "https://github.com/apache/iceberg/pull/1783#pullrequestreview-542163695", "createdAt": "2020-12-01T18:05:03Z", "commit": {"oid": "ac33ea3fd109d0b808f3c7f90cc38dc704b6923c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxODowNTowM1rOH85V0Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxODowNTowM1rOH85V0Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYxNjA4MQ==", "bodyText": "I think the correct exception is the Spark exception since this is going to be called from Spark code.", "url": "https://github.com/apache/iceberg/pull/1783#discussion_r533616081", "createdAt": "2020-12-01T18:05:03Z", "author": {"login": "rdblue"}, "path": "spark3/src/main/java/org/apache/iceberg/spark/source/IcebergSource.java", "diffHunk": "@@ -56,48 +61,62 @@ public boolean supportsExternalMetadata() {\n   }\n \n   @Override\n-  public SparkTable getTable(StructType schema, Transform[] partitioning, Map<String, String> options) {\n-    // Get Iceberg table from options\n-    Configuration conf = SparkSession.active().sessionState().newHadoopConf();\n-    Table icebergTable = getTableAndResolveHadoopConfiguration(options, conf);\n-\n-    // Build Spark table based on Iceberg table, and return it\n-    // Eagerly refresh the table before reading to ensure views containing this table show up-to-date data\n-    return new SparkTable(icebergTable, schema, true);\n+  public Table getTable(StructType schema, Transform[] partitioning, Map<String, String> options) {\n+    String catalogName = extractCatalog(new CaseInsensitiveStringMap(options));\n+    Identifier ident = extractIdentifier(new CaseInsensitiveStringMap(options));\n+    CatalogManager catalogManager = SparkSession.active().sessionState().catalogManager();\n+    CatalogPlugin catalog = catalogManager.catalog(catalogName);\n+    try {\n+      if (catalog instanceof TableCatalog) {\n+        return ((TableCatalog) catalog).loadTable(ident);\n+      }\n+    } catch (NoSuchTableException e) {\n+      throw new org.apache.iceberg.exceptions.NoSuchTableException(e, \"Cannot find table for %s.\", ident);\n+    }\n+    throw new org.apache.iceberg.exceptions.NoSuchTableException(\"Cannot find table for %s.\", ident);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ac33ea3fd109d0b808f3c7f90cc38dc704b6923c"}, "originalPosition": 59}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQyMTY2MjY2", "url": "https://github.com/apache/iceberg/pull/1783#pullrequestreview-542166266", "createdAt": "2020-12-01T18:08:28Z", "commit": {"oid": "ac33ea3fd109d0b808f3c7f90cc38dc704b6923c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxODowODoyOFrOH85d4Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxODowODoyOFrOH85d4Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYxODE0NQ==", "bodyText": "Why is this second attempt done?\nWrapping the identifier in ` should escape the entire string as a single identifier, so the parser would return the original path as one component.\nI think this would be equivalent to ident = path.", "url": "https://github.com/apache/iceberg/pull/1783#discussion_r533618145", "createdAt": "2020-12-01T18:08:28Z", "author": {"login": "rdblue"}, "path": "spark3/src/main/java/org/apache/iceberg/spark/source/IcebergSource.java", "diffHunk": "@@ -56,48 +61,62 @@ public boolean supportsExternalMetadata() {\n   }\n \n   @Override\n-  public SparkTable getTable(StructType schema, Transform[] partitioning, Map<String, String> options) {\n-    // Get Iceberg table from options\n-    Configuration conf = SparkSession.active().sessionState().newHadoopConf();\n-    Table icebergTable = getTableAndResolveHadoopConfiguration(options, conf);\n-\n-    // Build Spark table based on Iceberg table, and return it\n-    // Eagerly refresh the table before reading to ensure views containing this table show up-to-date data\n-    return new SparkTable(icebergTable, schema, true);\n+  public Table getTable(StructType schema, Transform[] partitioning, Map<String, String> options) {\n+    String catalogName = extractCatalog(new CaseInsensitiveStringMap(options));\n+    Identifier ident = extractIdentifier(new CaseInsensitiveStringMap(options));\n+    CatalogManager catalogManager = SparkSession.active().sessionState().catalogManager();\n+    CatalogPlugin catalog = catalogManager.catalog(catalogName);\n+    try {\n+      if (catalog instanceof TableCatalog) {\n+        return ((TableCatalog) catalog).loadTable(ident);\n+      }\n+    } catch (NoSuchTableException e) {\n+      throw new org.apache.iceberg.exceptions.NoSuchTableException(e, \"Cannot find table for %s.\", ident);\n+    }\n+    throw new org.apache.iceberg.exceptions.NoSuchTableException(\"Cannot find table for %s.\", ident);\n   }\n \n-  protected Table findTable(Map<String, String> options, Configuration conf) {\n+  private Pair<String, TableIdentifier> tableIdentifier(CaseInsensitiveStringMap options) {\n+    CatalogManager catalogManager = SparkSession.active().sessionState().catalogManager();\n+    Namespace defaultNamespace = Namespace.of(catalogManager.currentNamespace());\n     Preconditions.checkArgument(options.containsKey(\"path\"), \"Cannot open table: path is not set\");\n     String path = options.get(\"path\");\n-\n-    if (path.contains(\"/\")) {\n-      HadoopTables tables = new HadoopTables(conf);\n-      return tables.load(path);\n+    List<String> ident;\n+    try {\n+      ident = scala.collection.JavaConverters.seqAsJavaList(SparkSession.active().sessionState().sqlParser().parseMultipartIdentifier(path));\n+    } catch (ParseException e) {\n+      try {\n+        ident = scala.collection.JavaConverters.seqAsJavaList(SparkSession.active().sessionState().sqlParser().parseMultipartIdentifier(String.format(\"`%s`\", path)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ac33ea3fd109d0b808f3c7f90cc38dc704b6923c"}, "originalPosition": 77}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQyMTY4MTQ4", "url": "https://github.com/apache/iceberg/pull/1783#pullrequestreview-542168148", "createdAt": "2020-12-01T18:10:54Z", "commit": {"oid": "ac33ea3fd109d0b808f3c7f90cc38dc704b6923c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxODoxMDo1NVrOH85jzQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxODoxMDo1NVrOH85jzQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYxOTY2MQ==", "bodyText": "The default implementation always returns spark_catalog, not the current catalog. Since we want to use the current catalog when it isn't defined in the identifier, tableIdentifier(options) should fill it in. That would simplify this logic because it should always be non-null.", "url": "https://github.com/apache/iceberg/pull/1783#discussion_r533619661", "createdAt": "2020-12-01T18:10:55Z", "author": {"login": "rdblue"}, "path": "spark3/src/main/java/org/apache/iceberg/spark/source/IcebergSource.java", "diffHunk": "@@ -56,48 +61,62 @@ public boolean supportsExternalMetadata() {\n   }\n \n   @Override\n-  public SparkTable getTable(StructType schema, Transform[] partitioning, Map<String, String> options) {\n-    // Get Iceberg table from options\n-    Configuration conf = SparkSession.active().sessionState().newHadoopConf();\n-    Table icebergTable = getTableAndResolveHadoopConfiguration(options, conf);\n-\n-    // Build Spark table based on Iceberg table, and return it\n-    // Eagerly refresh the table before reading to ensure views containing this table show up-to-date data\n-    return new SparkTable(icebergTable, schema, true);\n+  public Table getTable(StructType schema, Transform[] partitioning, Map<String, String> options) {\n+    String catalogName = extractCatalog(new CaseInsensitiveStringMap(options));\n+    Identifier ident = extractIdentifier(new CaseInsensitiveStringMap(options));\n+    CatalogManager catalogManager = SparkSession.active().sessionState().catalogManager();\n+    CatalogPlugin catalog = catalogManager.catalog(catalogName);\n+    try {\n+      if (catalog instanceof TableCatalog) {\n+        return ((TableCatalog) catalog).loadTable(ident);\n+      }\n+    } catch (NoSuchTableException e) {\n+      throw new org.apache.iceberg.exceptions.NoSuchTableException(e, \"Cannot find table for %s.\", ident);\n+    }\n+    throw new org.apache.iceberg.exceptions.NoSuchTableException(\"Cannot find table for %s.\", ident);\n   }\n \n-  protected Table findTable(Map<String, String> options, Configuration conf) {\n+  private Pair<String, TableIdentifier> tableIdentifier(CaseInsensitiveStringMap options) {\n+    CatalogManager catalogManager = SparkSession.active().sessionState().catalogManager();\n+    Namespace defaultNamespace = Namespace.of(catalogManager.currentNamespace());\n     Preconditions.checkArgument(options.containsKey(\"path\"), \"Cannot open table: path is not set\");\n     String path = options.get(\"path\");\n-\n-    if (path.contains(\"/\")) {\n-      HadoopTables tables = new HadoopTables(conf);\n-      return tables.load(path);\n+    List<String> ident;\n+    try {\n+      ident = scala.collection.JavaConverters.seqAsJavaList(SparkSession.active().sessionState().sqlParser().parseMultipartIdentifier(path));\n+    } catch (ParseException e) {\n+      try {\n+        ident = scala.collection.JavaConverters.seqAsJavaList(SparkSession.active().sessionState().sqlParser().parseMultipartIdentifier(String.format(\"`%s`\", path)));\n+      } catch (ParseException ignored) {\n+        throw new RuntimeException(e);\n+      }\n+    }\n+    if (ident.size() == 1) {\n+      return Pair.of(null, TableIdentifier.of(defaultNamespace, ident.get(0)));\n+    } else if (ident.size() == 2) {\n+      if (catalogManager.isCatalogRegistered(ident.get(0))) {\n+        return Pair.of(ident.get(0), TableIdentifier.of(defaultNamespace, ident.get(1))); //todo what if path?\n+      } else {\n+        return Pair.of(null, TableIdentifier.of(ident.toArray(new String[0])));\n+      }\n     } else {\n-      HiveCatalog hiveCatalog = HiveCatalogs.loadCatalog(conf);\n-      TableIdentifier tableIdentifier = TableIdentifier.parse(path);\n-      return hiveCatalog.loadTable(tableIdentifier);\n+      if (catalogManager.isCatalogRegistered(ident.get(0))) {\n+        return Pair.of(ident.get(0), TableIdentifier.of(ident.subList(1, ident.size()).toArray(new String[0])));\n+      } else {\n+        return Pair.of(null, TableIdentifier.of(ident.toArray(new String[0])));\n+      }\n     }\n   }\n \n-  private Table getTableAndResolveHadoopConfiguration(Map<String, String> options, Configuration conf) {\n-    // Overwrite configurations from the Spark Context with configurations from the options.\n-    mergeIcebergHadoopConfs(conf, options);\n-\n-    Table table = findTable(options, conf);\n-\n-    // Set confs from table properties\n-    mergeIcebergHadoopConfs(conf, table.properties());\n-\n-    // Re-overwrite values set in options and table properties but were not in the environment.\n-    mergeIcebergHadoopConfs(conf, options);\n-\n-    return table;\n+  @Override\n+  public Identifier extractIdentifier(CaseInsensitiveStringMap options) {\n+    TableIdentifier tableIdentifier = tableIdentifier(options).second();\n+    return Identifier.of(tableIdentifier.namespace().levels(), tableIdentifier.name());\n   }\n \n-  private static void mergeIcebergHadoopConfs(Configuration baseConf, Map<String, String> options) {\n-    options.keySet().stream()\n-        .filter(key -> key.startsWith(\"hadoop.\"))\n-        .forEach(key -> baseConf.set(key.replaceFirst(\"hadoop.\", \"\"), options.get(key)));\n+  @Override\n+  public String extractCatalog(CaseInsensitiveStringMap options) {\n+    String catalogName = tableIdentifier(options).first();\n+    return (catalogName == null) ? SupportsCatalogOptions.super.extractCatalog(options) : catalogName;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ac33ea3fd109d0b808f3c7f90cc38dc704b6923c"}, "originalPosition": 128}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQyMTcwNDQ1", "url": "https://github.com/apache/iceberg/pull/1783#pullrequestreview-542170445", "createdAt": "2020-12-01T18:13:56Z", "commit": {"oid": "ac33ea3fd109d0b808f3c7f90cc38dc704b6923c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxODoxMzo1N1rOH85qkw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxODoxMzo1N1rOH85qkw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYyMTM5NQ==", "bodyText": "This shouldn't fill in the default namespace. If the identifier was two parts, like prod.items, then it is not correct to modify that to be prod.default.items.\nI think that this should use the same logic as the else.", "url": "https://github.com/apache/iceberg/pull/1783#discussion_r533621395", "createdAt": "2020-12-01T18:13:57Z", "author": {"login": "rdblue"}, "path": "spark3/src/main/java/org/apache/iceberg/spark/source/IcebergSource.java", "diffHunk": "@@ -56,48 +61,62 @@ public boolean supportsExternalMetadata() {\n   }\n \n   @Override\n-  public SparkTable getTable(StructType schema, Transform[] partitioning, Map<String, String> options) {\n-    // Get Iceberg table from options\n-    Configuration conf = SparkSession.active().sessionState().newHadoopConf();\n-    Table icebergTable = getTableAndResolveHadoopConfiguration(options, conf);\n-\n-    // Build Spark table based on Iceberg table, and return it\n-    // Eagerly refresh the table before reading to ensure views containing this table show up-to-date data\n-    return new SparkTable(icebergTable, schema, true);\n+  public Table getTable(StructType schema, Transform[] partitioning, Map<String, String> options) {\n+    String catalogName = extractCatalog(new CaseInsensitiveStringMap(options));\n+    Identifier ident = extractIdentifier(new CaseInsensitiveStringMap(options));\n+    CatalogManager catalogManager = SparkSession.active().sessionState().catalogManager();\n+    CatalogPlugin catalog = catalogManager.catalog(catalogName);\n+    try {\n+      if (catalog instanceof TableCatalog) {\n+        return ((TableCatalog) catalog).loadTable(ident);\n+      }\n+    } catch (NoSuchTableException e) {\n+      throw new org.apache.iceberg.exceptions.NoSuchTableException(e, \"Cannot find table for %s.\", ident);\n+    }\n+    throw new org.apache.iceberg.exceptions.NoSuchTableException(\"Cannot find table for %s.\", ident);\n   }\n \n-  protected Table findTable(Map<String, String> options, Configuration conf) {\n+  private Pair<String, TableIdentifier> tableIdentifier(CaseInsensitiveStringMap options) {\n+    CatalogManager catalogManager = SparkSession.active().sessionState().catalogManager();\n+    Namespace defaultNamespace = Namespace.of(catalogManager.currentNamespace());\n     Preconditions.checkArgument(options.containsKey(\"path\"), \"Cannot open table: path is not set\");\n     String path = options.get(\"path\");\n-\n-    if (path.contains(\"/\")) {\n-      HadoopTables tables = new HadoopTables(conf);\n-      return tables.load(path);\n+    List<String> ident;\n+    try {\n+      ident = scala.collection.JavaConverters.seqAsJavaList(SparkSession.active().sessionState().sqlParser().parseMultipartIdentifier(path));\n+    } catch (ParseException e) {\n+      try {\n+        ident = scala.collection.JavaConverters.seqAsJavaList(SparkSession.active().sessionState().sqlParser().parseMultipartIdentifier(String.format(\"`%s`\", path)));\n+      } catch (ParseException ignored) {\n+        throw new RuntimeException(e);\n+      }\n+    }\n+    if (ident.size() == 1) {\n+      return Pair.of(null, TableIdentifier.of(defaultNamespace, ident.get(0)));\n+    } else if (ident.size() == 2) {\n+      if (catalogManager.isCatalogRegistered(ident.get(0))) {\n+        return Pair.of(ident.get(0), TableIdentifier.of(defaultNamespace, ident.get(1))); //todo what if path?", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ac33ea3fd109d0b808f3c7f90cc38dc704b6923c"}, "originalPosition": 86}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQyMTcwNjE5", "url": "https://github.com/apache/iceberg/pull/1783#pullrequestreview-542170619", "createdAt": "2020-12-01T18:14:09Z", "commit": {"oid": "ac33ea3fd109d0b808f3c7f90cc38dc704b6923c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxODoxNDowOVrOH85rEA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxODoxNDowOVrOH85rEA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYyMTUyMA==", "bodyText": "Nit: could you separate the control flow statements with a newline?", "url": "https://github.com/apache/iceberg/pull/1783#discussion_r533621520", "createdAt": "2020-12-01T18:14:09Z", "author": {"login": "rdblue"}, "path": "spark3/src/main/java/org/apache/iceberg/spark/source/IcebergSource.java", "diffHunk": "@@ -56,48 +61,62 @@ public boolean supportsExternalMetadata() {\n   }\n \n   @Override\n-  public SparkTable getTable(StructType schema, Transform[] partitioning, Map<String, String> options) {\n-    // Get Iceberg table from options\n-    Configuration conf = SparkSession.active().sessionState().newHadoopConf();\n-    Table icebergTable = getTableAndResolveHadoopConfiguration(options, conf);\n-\n-    // Build Spark table based on Iceberg table, and return it\n-    // Eagerly refresh the table before reading to ensure views containing this table show up-to-date data\n-    return new SparkTable(icebergTable, schema, true);\n+  public Table getTable(StructType schema, Transform[] partitioning, Map<String, String> options) {\n+    String catalogName = extractCatalog(new CaseInsensitiveStringMap(options));\n+    Identifier ident = extractIdentifier(new CaseInsensitiveStringMap(options));\n+    CatalogManager catalogManager = SparkSession.active().sessionState().catalogManager();\n+    CatalogPlugin catalog = catalogManager.catalog(catalogName);\n+    try {\n+      if (catalog instanceof TableCatalog) {\n+        return ((TableCatalog) catalog).loadTable(ident);\n+      }\n+    } catch (NoSuchTableException e) {\n+      throw new org.apache.iceberg.exceptions.NoSuchTableException(e, \"Cannot find table for %s.\", ident);\n+    }\n+    throw new org.apache.iceberg.exceptions.NoSuchTableException(\"Cannot find table for %s.\", ident);\n   }\n \n-  protected Table findTable(Map<String, String> options, Configuration conf) {\n+  private Pair<String, TableIdentifier> tableIdentifier(CaseInsensitiveStringMap options) {\n+    CatalogManager catalogManager = SparkSession.active().sessionState().catalogManager();\n+    Namespace defaultNamespace = Namespace.of(catalogManager.currentNamespace());\n     Preconditions.checkArgument(options.containsKey(\"path\"), \"Cannot open table: path is not set\");\n     String path = options.get(\"path\");\n-\n-    if (path.contains(\"/\")) {\n-      HadoopTables tables = new HadoopTables(conf);\n-      return tables.load(path);\n+    List<String> ident;\n+    try {\n+      ident = scala.collection.JavaConverters.seqAsJavaList(SparkSession.active().sessionState().sqlParser().parseMultipartIdentifier(path));\n+    } catch (ParseException e) {\n+      try {\n+        ident = scala.collection.JavaConverters.seqAsJavaList(SparkSession.active().sessionState().sqlParser().parseMultipartIdentifier(String.format(\"`%s`\", path)));\n+      } catch (ParseException ignored) {\n+        throw new RuntimeException(e);\n+      }\n+    }\n+    if (ident.size() == 1) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ac33ea3fd109d0b808f3c7f90cc38dc704b6923c"}, "originalPosition": 82}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ0MjU2MjY1", "url": "https://github.com/apache/iceberg/pull/1783#pullrequestreview-544256265", "createdAt": "2020-12-03T18:28:07Z", "commit": {"oid": "033a36adbdb4ab57f50d70e5dfb369541ffd1c67"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxODoyODowN1rOH-rGhg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wM1QxOTowNDo1NlrOH-skSw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTQ3OTk0Mg==", "bodyText": "nit: should not change license", "url": "https://github.com/apache/iceberg/pull/1783#discussion_r535479942", "createdAt": "2020-12-03T18:28:07Z", "author": {"login": "jackye1995"}, "path": "spark3/src/test/java/org/apache/iceberg/spark/source/TestIcebergSource.java", "diffHunk": "@@ -1,27 +1,23 @@\n /*\n- * Licensed to the Apache Software Foundation (ASF) under one", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "033a36adbdb4ab57f50d70e5dfb369541ffd1c67"}, "originalPosition": 2}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNTUwMzk0Nw==", "bodyText": "Because we are now assigning an empty namespace for size==2 case,  I think it can be merged together with the else case. We only get ident.subList(1, ident.size()).toArray(new String[0]) simplified to ident.get(1), but the rest are all duplicates.", "url": "https://github.com/apache/iceberg/pull/1783#discussion_r535503947", "createdAt": "2020-12-03T19:04:56Z", "author": {"login": "jackye1995"}, "path": "spark3/src/main/java/org/apache/iceberg/spark/source/IcebergSource.java", "diffHunk": "@@ -56,48 +62,62 @@ public boolean supportsExternalMetadata() {\n   }\n \n   @Override\n-  public SparkTable getTable(StructType schema, Transform[] partitioning, Map<String, String> options) {\n-    // Get Iceberg table from options\n-    Configuration conf = SparkSession.active().sessionState().newHadoopConf();\n-    Table icebergTable = getTableAndResolveHadoopConfiguration(options, conf);\n-\n-    // Build Spark table based on Iceberg table, and return it\n-    // Eagerly refresh the table before reading to ensure views containing this table show up-to-date data\n-    return new SparkTable(icebergTable, schema, true);\n+  public Table getTable(StructType schema, Transform[] partitioning, Map<String, String> options) {\n+    String catalogName = extractCatalog(new CaseInsensitiveStringMap(options));\n+    Identifier ident = extractIdentifier(new CaseInsensitiveStringMap(options));\n+    CatalogManager catalogManager = SparkSession.active().sessionState().catalogManager();\n+    CatalogPlugin catalog = catalogManager.catalog(catalogName);\n+    try {\n+      if (catalog instanceof TableCatalog) {\n+        return ((TableCatalog) catalog).loadTable(ident);\n+      }\n+    } catch (NoSuchTableException e) {\n+      // throwing an iceberg NoSuchTableException because the Spark one is typed and cant be thrown from this interface\n+      throw new org.apache.iceberg.exceptions.NoSuchTableException(e, \"Cannot find table for %s.\", ident);\n+    }\n+    // throwing an iceberg NoSuchTableException because the Spark one is typed and cant be thrown from this interface\n+    throw new org.apache.iceberg.exceptions.NoSuchTableException(\"Cannot find table for %s.\", ident);\n   }\n \n-  protected Table findTable(Map<String, String> options, Configuration conf) {\n+  private Pair<String, TableIdentifier> tableIdentifier(CaseInsensitiveStringMap options) {\n+    CatalogManager catalogManager = SparkSession.active().sessionState().catalogManager();\n+    String currentCatalogName = catalogManager.currentCatalog().name();\n+    Namespace defaultNamespace = Namespace.of(catalogManager.currentNamespace());\n     Preconditions.checkArgument(options.containsKey(\"path\"), \"Cannot open table: path is not set\");\n     String path = options.get(\"path\");\n+    List<String> ident;\n+    try {\n+      ident = scala.collection.JavaConverters.seqAsJavaList(SparkSession.active().sessionState().sqlParser().parseMultipartIdentifier(path));\n+    } catch (ParseException e) {\n+      ident = new ArrayList<>();\n+      ident.add(path);\n+    }\n \n-    if (path.contains(\"/\")) {\n-      HadoopTables tables = new HadoopTables(conf);\n-      return tables.load(path);\n+    if (ident.size() == 1) {\n+      return Pair.of(currentCatalogName, TableIdentifier.of(defaultNamespace, ident.get(0)));\n+    } else if (ident.size() == 2) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "033a36adbdb4ab57f50d70e5dfb369541ffd1c67"}, "originalPosition": 85}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "be5b16bac688b7276f9c43f7b32c71cec13c54c9", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/be5b16bac688b7276f9c43f7b32c71cec13c54c9", "committedDate": "2020-12-04T14:18:38Z", "message": "clean up and docs"}, "afterCommit": {"oid": "b96e39268dfe840446f260fa8de6eba2b39ac7b3", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/b96e39268dfe840446f260fa8de6eba2b39ac7b3", "committedDate": "2020-12-08T13:14:13Z", "message": "use util function to get catalog and identifier"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b96e39268dfe840446f260fa8de6eba2b39ac7b3", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/b96e39268dfe840446f260fa8de6eba2b39ac7b3", "committedDate": "2020-12-08T13:14:13Z", "message": "use util function to get catalog and identifier"}, "afterCommit": {"oid": "d4bb4b7eb12626bf224ce6aa95aef07bd37f1b93", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/d4bb4b7eb12626bf224ce6aa95aef07bd37f1b93", "committedDate": "2020-12-09T13:40:16Z", "message": "rebase to pick up #1843 and fix build"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ4NDA4MDY2", "url": "https://github.com/apache/iceberg/pull/1783#pullrequestreview-548408066", "createdAt": "2020-12-09T17:10:59Z", "commit": {"oid": "512c268d7c84470e314be4f2b6d3352da62ec6c4"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOVQxNzoxMDo1OVrOICfz9g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOVQxNzoxMDo1OVrOICfz9g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTQ4OTI3MA==", "bodyText": "What does \"using settings from 'catalog'\" mean in practice? Hadoop tables are loaded using a generic HadoopTables, so the catalog doesn't really affect it at all, I think. In that case, this is promising something that it doesn't need to and I'd prefer to avoid making claims about behavior like that.", "url": "https://github.com/apache/iceberg/pull/1783#discussion_r539489270", "createdAt": "2020-12-09T17:10:59Z", "author": {"login": "rdblue"}, "path": "spark3/src/main/java/org/apache/iceberg/spark/source/IcebergSource.java", "diffHunk": "@@ -19,22 +19,49 @@\n \n package org.apache.iceberg.spark.source;\n \n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n import java.util.Map;\n-import org.apache.hadoop.conf.Configuration;\n-import org.apache.iceberg.Table;\n-import org.apache.iceberg.catalog.TableIdentifier;\n-import org.apache.iceberg.hadoop.HadoopTables;\n-import org.apache.iceberg.hive.HiveCatalog;\n-import org.apache.iceberg.hive.HiveCatalogs;\n import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.spark.PathIdentifier;\n+import org.apache.iceberg.spark.Spark3Util;\n+import org.apache.iceberg.spark.SparkCatalog;\n+import org.apache.iceberg.spark.SparkSessionCatalog;\n import org.apache.spark.sql.SparkSession;\n-import org.apache.spark.sql.connector.catalog.TableProvider;\n+import org.apache.spark.sql.catalyst.analysis.NoSuchTableException;\n+import org.apache.spark.sql.catalyst.parser.ParseException;\n+import org.apache.spark.sql.connector.catalog.CatalogManager;\n+import org.apache.spark.sql.connector.catalog.CatalogPlugin;\n+import org.apache.spark.sql.connector.catalog.Identifier;\n+import org.apache.spark.sql.connector.catalog.SupportsCatalogOptions;\n+import org.apache.spark.sql.connector.catalog.Table;\n+import org.apache.spark.sql.connector.catalog.TableCatalog;\n import org.apache.spark.sql.connector.expressions.Transform;\n import org.apache.spark.sql.sources.DataSourceRegister;\n import org.apache.spark.sql.types.StructType;\n import org.apache.spark.sql.util.CaseInsensitiveStringMap;\n \n-public class IcebergSource implements DataSourceRegister, TableProvider {\n+/**\n+ * The IcebergSource loads/writes tables with format \"iceberg\". It can load paths and tables.\n+ *\n+ * How paths/tables are loaded when using spark.read().format(\"iceberg\").path(table)\n+ *\n+ *  table = \"file:/path/to/table\" -> loads a HadoopTable at given path\n+ *  table = \"catalog.`file:/path/to/table`\" -> loads a HadoopTable at given path using settings from 'catalog'", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "512c268d7c84470e314be4f2b6d3352da62ec6c4"}, "originalPosition": 42}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ4NDA5MTcy", "url": "https://github.com/apache/iceberg/pull/1783#pullrequestreview-548409172", "createdAt": "2020-12-09T17:12:11Z", "commit": {"oid": "512c268d7c84470e314be4f2b6d3352da62ec6c4"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOVQxNzoxMjoxMVrOICf3kw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOVQxNzoxMjoxMVrOICf3kw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTQ5MDE5NQ==", "bodyText": "In these examples, I think it is easier to understand if you separate the cases and use catalog and namespace, rather than \"if xxx is a catalog . . . otherwise . . .\".", "url": "https://github.com/apache/iceberg/pull/1783#discussion_r539490195", "createdAt": "2020-12-09T17:12:11Z", "author": {"login": "rdblue"}, "path": "spark3/src/main/java/org/apache/iceberg/spark/source/IcebergSource.java", "diffHunk": "@@ -19,22 +19,49 @@\n \n package org.apache.iceberg.spark.source;\n \n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n import java.util.Map;\n-import org.apache.hadoop.conf.Configuration;\n-import org.apache.iceberg.Table;\n-import org.apache.iceberg.catalog.TableIdentifier;\n-import org.apache.iceberg.hadoop.HadoopTables;\n-import org.apache.iceberg.hive.HiveCatalog;\n-import org.apache.iceberg.hive.HiveCatalogs;\n import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.spark.PathIdentifier;\n+import org.apache.iceberg.spark.Spark3Util;\n+import org.apache.iceberg.spark.SparkCatalog;\n+import org.apache.iceberg.spark.SparkSessionCatalog;\n import org.apache.spark.sql.SparkSession;\n-import org.apache.spark.sql.connector.catalog.TableProvider;\n+import org.apache.spark.sql.catalyst.analysis.NoSuchTableException;\n+import org.apache.spark.sql.catalyst.parser.ParseException;\n+import org.apache.spark.sql.connector.catalog.CatalogManager;\n+import org.apache.spark.sql.connector.catalog.CatalogPlugin;\n+import org.apache.spark.sql.connector.catalog.Identifier;\n+import org.apache.spark.sql.connector.catalog.SupportsCatalogOptions;\n+import org.apache.spark.sql.connector.catalog.Table;\n+import org.apache.spark.sql.connector.catalog.TableCatalog;\n import org.apache.spark.sql.connector.expressions.Transform;\n import org.apache.spark.sql.sources.DataSourceRegister;\n import org.apache.spark.sql.types.StructType;\n import org.apache.spark.sql.util.CaseInsensitiveStringMap;\n \n-public class IcebergSource implements DataSourceRegister, TableProvider {\n+/**\n+ * The IcebergSource loads/writes tables with format \"iceberg\". It can load paths and tables.\n+ *\n+ * How paths/tables are loaded when using spark.read().format(\"iceberg\").path(table)\n+ *\n+ *  table = \"file:/path/to/table\" -> loads a HadoopTable at given path\n+ *  table = \"catalog.`file:/path/to/table`\" -> loads a HadoopTable at given path using settings from 'catalog'\n+ *  table = \"catalog.namespace.`file:/path/to/table`\" -> fails. Namespace doesn't exist for paths\n+ *  table = \"tablename\" -> loads currentCatalog.currentNamespace.tablename\n+ *  table = \"xxx.tablename\" -> if xxx is a catalog load \"tablename\" from the specified catalog. Otherwise\n+ *          load \"xxx.tablename\" from current catalog\n+ *  table = \"xxx.yyy.tablename\" -> if xxx is a catalog load \"yyy.tablename\" from the specified catalog. Otherwise\n+ *          load \"xxx.yyy.tablename\" from current catalog", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "512c268d7c84470e314be4f2b6d3352da62ec6c4"}, "originalPosition": 48}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ4NDExODMy", "url": "https://github.com/apache/iceberg/pull/1783#pullrequestreview-548411832", "createdAt": "2020-12-09T17:15:13Z", "commit": {"oid": "512c268d7c84470e314be4f2b6d3352da62ec6c4"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOVQxNzoxNToxM1rOICgAUQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOVQxNzoxNToxM1rOICgAUQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTQ5MjQzMw==", "bodyText": "When implementing SupportsCatalogOptions, I don't think this will ever be called. Should we remove it and throw UnsupportedOperationException instead?", "url": "https://github.com/apache/iceberg/pull/1783#discussion_r539492433", "createdAt": "2020-12-09T17:15:13Z", "author": {"login": "rdblue"}, "path": "spark3/src/main/java/org/apache/iceberg/spark/source/IcebergSource.java", "diffHunk": "@@ -56,48 +83,85 @@ public boolean supportsExternalMetadata() {\n   }\n \n   @Override\n-  public SparkTable getTable(StructType schema, Transform[] partitioning, Map<String, String> options) {\n-    // Get Iceberg table from options\n-    Configuration conf = SparkSession.active().sessionState().newHadoopConf();\n-    Table icebergTable = getTableAndResolveHadoopConfiguration(options, conf);\n-\n-    // Build Spark table based on Iceberg table, and return it\n-    // Eagerly refresh the table before reading to ensure views containing this table show up-to-date data\n-    return new SparkTable(icebergTable, schema, true);\n+  public Table getTable(StructType schema, Transform[] partitioning, Map<String, String> options) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "512c268d7c84470e314be4f2b6d3352da62ec6c4"}, "originalPosition": 70}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ4NDE1MTc4", "url": "https://github.com/apache/iceberg/pull/1783#pullrequestreview-548415178", "createdAt": "2020-12-09T17:18:48Z", "commit": {"oid": "512c268d7c84470e314be4f2b6d3352da62ec6c4"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOVQxNzoxODo0OVrOICgK-w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOVQxNzoxODo0OVrOICgK-w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTQ5NTE2Mw==", "bodyText": "Is this try/catch to avoid the / check? I think that's a pretty reasonable check. I'm not sure that this is a good idea because the cases you listed above would pass this.\nFor example, this uses a valid identifier, but is clearly a path reference:\nspark.format(\"iceberg\").load(\"catalog.`file:/path/to/table`\");\nAs I mentioned above, I don't think that we should support the mixed path and catalog identifiers, but I still think it is probably a more predictable check to just look for /.", "url": "https://github.com/apache/iceberg/pull/1783#discussion_r539495163", "createdAt": "2020-12-09T17:18:49Z", "author": {"login": "rdblue"}, "path": "spark3/src/main/java/org/apache/iceberg/spark/source/IcebergSource.java", "diffHunk": "@@ -56,48 +83,85 @@ public boolean supportsExternalMetadata() {\n   }\n \n   @Override\n-  public SparkTable getTable(StructType schema, Transform[] partitioning, Map<String, String> options) {\n-    // Get Iceberg table from options\n-    Configuration conf = SparkSession.active().sessionState().newHadoopConf();\n-    Table icebergTable = getTableAndResolveHadoopConfiguration(options, conf);\n-\n-    // Build Spark table based on Iceberg table, and return it\n-    // Eagerly refresh the table before reading to ensure views containing this table show up-to-date data\n-    return new SparkTable(icebergTable, schema, true);\n+  public Table getTable(StructType schema, Transform[] partitioning, Map<String, String> options) {\n+    String catalogName = extractCatalog(new CaseInsensitiveStringMap(options));\n+    Identifier ident = extractIdentifier(new CaseInsensitiveStringMap(options));\n+    CatalogManager catalogManager = SparkSession.active().sessionState().catalogManager();\n+    CatalogPlugin catalog = catalogManager.catalog(catalogName);\n+    try {\n+      if (catalog instanceof TableCatalog) {\n+        return ((TableCatalog) catalog).loadTable(ident);\n+      }\n+    } catch (NoSuchTableException e) {\n+      // throwing an iceberg NoSuchTableException because the Spark one is typed and cant be thrown from this interface\n+      throw new org.apache.iceberg.exceptions.NoSuchTableException(e, \"Cannot find table for %s.\", ident);\n+    }\n+    // throwing an iceberg NoSuchTableException because the Spark one is typed and cant be thrown from this interface\n+    throw new org.apache.iceberg.exceptions.NoSuchTableException(\"Cannot find table for %s.\", ident);\n   }\n \n-  protected Table findTable(Map<String, String> options, Configuration conf) {\n+  private Spark3Util.CatalogAndIdentifier catalogAndIdentifier(CaseInsensitiveStringMap options) {\n     Preconditions.checkArgument(options.containsKey(\"path\"), \"Cannot open table: path is not set\");\n     String path = options.get(\"path\");\n-\n-    if (path.contains(\"/\")) {\n-      HadoopTables tables = new HadoopTables(conf);\n-      return tables.load(path);\n+    SparkSession spark = SparkSession.active();\n+    Spark3Util.CatalogAndIdentifier catalogAndIdentifier;\n+    try {\n+      catalogAndIdentifier = Spark3Util.catalogAndIdentifier(spark, path);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "512c268d7c84470e314be4f2b6d3352da62ec6c4"}, "originalPosition": 98}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ4NDE1ODU1", "url": "https://github.com/apache/iceberg/pull/1783#pullrequestreview-548415855", "createdAt": "2020-12-09T17:19:33Z", "commit": {"oid": "512c268d7c84470e314be4f2b6d3352da62ec6c4"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOVQxNzoxOTozM1rOICgNfw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOVQxNzoxOTozM1rOICgNfw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTQ5NTgwNw==", "bodyText": "Nit: Using ImmutableList makes this more concise: Spark3Util.catalogAndIdentifier(spark, ImmutableList.of(path))", "url": "https://github.com/apache/iceberg/pull/1783#discussion_r539495807", "createdAt": "2020-12-09T17:19:33Z", "author": {"login": "rdblue"}, "path": "spark3/src/main/java/org/apache/iceberg/spark/source/IcebergSource.java", "diffHunk": "@@ -56,48 +83,85 @@ public boolean supportsExternalMetadata() {\n   }\n \n   @Override\n-  public SparkTable getTable(StructType schema, Transform[] partitioning, Map<String, String> options) {\n-    // Get Iceberg table from options\n-    Configuration conf = SparkSession.active().sessionState().newHadoopConf();\n-    Table icebergTable = getTableAndResolveHadoopConfiguration(options, conf);\n-\n-    // Build Spark table based on Iceberg table, and return it\n-    // Eagerly refresh the table before reading to ensure views containing this table show up-to-date data\n-    return new SparkTable(icebergTable, schema, true);\n+  public Table getTable(StructType schema, Transform[] partitioning, Map<String, String> options) {\n+    String catalogName = extractCatalog(new CaseInsensitiveStringMap(options));\n+    Identifier ident = extractIdentifier(new CaseInsensitiveStringMap(options));\n+    CatalogManager catalogManager = SparkSession.active().sessionState().catalogManager();\n+    CatalogPlugin catalog = catalogManager.catalog(catalogName);\n+    try {\n+      if (catalog instanceof TableCatalog) {\n+        return ((TableCatalog) catalog).loadTable(ident);\n+      }\n+    } catch (NoSuchTableException e) {\n+      // throwing an iceberg NoSuchTableException because the Spark one is typed and cant be thrown from this interface\n+      throw new org.apache.iceberg.exceptions.NoSuchTableException(e, \"Cannot find table for %s.\", ident);\n+    }\n+    // throwing an iceberg NoSuchTableException because the Spark one is typed and cant be thrown from this interface\n+    throw new org.apache.iceberg.exceptions.NoSuchTableException(\"Cannot find table for %s.\", ident);\n   }\n \n-  protected Table findTable(Map<String, String> options, Configuration conf) {\n+  private Spark3Util.CatalogAndIdentifier catalogAndIdentifier(CaseInsensitiveStringMap options) {\n     Preconditions.checkArgument(options.containsKey(\"path\"), \"Cannot open table: path is not set\");\n     String path = options.get(\"path\");\n-\n-    if (path.contains(\"/\")) {\n-      HadoopTables tables = new HadoopTables(conf);\n-      return tables.load(path);\n+    SparkSession spark = SparkSession.active();\n+    Spark3Util.CatalogAndIdentifier catalogAndIdentifier;\n+    try {\n+      catalogAndIdentifier = Spark3Util.catalogAndIdentifier(spark, path);\n+    } catch (ParseException e) {\n+      List<String> ident = new ArrayList<>();\n+      ident.add(path);\n+      catalogAndIdentifier = Spark3Util.catalogAndIdentifier(spark, ident);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "512c268d7c84470e314be4f2b6d3352da62ec6c4"}, "originalPosition": 102}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ4NDE5ODQz", "url": "https://github.com/apache/iceberg/pull/1783#pullrequestreview-548419843", "createdAt": "2020-12-09T17:23:57Z", "commit": {"oid": "512c268d7c84470e314be4f2b6d3352da62ec6c4"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOVQxNzoyMzo1N1rOICgZ5g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOVQxNzoyMzo1N1rOICgZ5g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTQ5ODk4Mg==", "bodyText": "I think it would be simpler just to start this method with a check for the path:\nif (path.contains(\"/\")) {\n  Identifier ident = new PathIdentifer(path);\n  // do catalog resolution\n  return catalog, ident;\n}\n\nIt's easier to document and understand if the rules are simple.", "url": "https://github.com/apache/iceberg/pull/1783#discussion_r539498982", "createdAt": "2020-12-09T17:23:57Z", "author": {"login": "rdblue"}, "path": "spark3/src/main/java/org/apache/iceberg/spark/source/IcebergSource.java", "diffHunk": "@@ -56,48 +83,85 @@ public boolean supportsExternalMetadata() {\n   }\n \n   @Override\n-  public SparkTable getTable(StructType schema, Transform[] partitioning, Map<String, String> options) {\n-    // Get Iceberg table from options\n-    Configuration conf = SparkSession.active().sessionState().newHadoopConf();\n-    Table icebergTable = getTableAndResolveHadoopConfiguration(options, conf);\n-\n-    // Build Spark table based on Iceberg table, and return it\n-    // Eagerly refresh the table before reading to ensure views containing this table show up-to-date data\n-    return new SparkTable(icebergTable, schema, true);\n+  public Table getTable(StructType schema, Transform[] partitioning, Map<String, String> options) {\n+    String catalogName = extractCatalog(new CaseInsensitiveStringMap(options));\n+    Identifier ident = extractIdentifier(new CaseInsensitiveStringMap(options));\n+    CatalogManager catalogManager = SparkSession.active().sessionState().catalogManager();\n+    CatalogPlugin catalog = catalogManager.catalog(catalogName);\n+    try {\n+      if (catalog instanceof TableCatalog) {\n+        return ((TableCatalog) catalog).loadTable(ident);\n+      }\n+    } catch (NoSuchTableException e) {\n+      // throwing an iceberg NoSuchTableException because the Spark one is typed and cant be thrown from this interface\n+      throw new org.apache.iceberg.exceptions.NoSuchTableException(e, \"Cannot find table for %s.\", ident);\n+    }\n+    // throwing an iceberg NoSuchTableException because the Spark one is typed and cant be thrown from this interface\n+    throw new org.apache.iceberg.exceptions.NoSuchTableException(\"Cannot find table for %s.\", ident);\n   }\n \n-  protected Table findTable(Map<String, String> options, Configuration conf) {\n+  private Spark3Util.CatalogAndIdentifier catalogAndIdentifier(CaseInsensitiveStringMap options) {\n     Preconditions.checkArgument(options.containsKey(\"path\"), \"Cannot open table: path is not set\");\n     String path = options.get(\"path\");\n-\n-    if (path.contains(\"/\")) {\n-      HadoopTables tables = new HadoopTables(conf);\n-      return tables.load(path);\n+    SparkSession spark = SparkSession.active();\n+    Spark3Util.CatalogAndIdentifier catalogAndIdentifier;\n+    try {\n+      catalogAndIdentifier = Spark3Util.catalogAndIdentifier(spark, path);\n+    } catch (ParseException e) {\n+      List<String> ident = new ArrayList<>();\n+      ident.add(path);\n+      catalogAndIdentifier = Spark3Util.catalogAndIdentifier(spark, ident);\n+    }\n+    CatalogManager catalogManager = spark.sessionState().catalogManager();\n+    String[] currentNamespace = catalogManager.currentNamespace();\n+    // we have to check for paths but want to re-use the exiting utils to extract catalog/identifier\n+    if (checkPathIdentifier(catalogAndIdentifier.identifier(), currentNamespace)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "512c268d7c84470e314be4f2b6d3352da62ec6c4"}, "originalPosition": 107}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ4NzIzMjAz", "url": "https://github.com/apache/iceberg/pull/1783#pullrequestreview-548723203", "createdAt": "2020-12-10T00:20:04Z", "commit": {"oid": "e89c1ba706b123ba1de1a5a19fd6ea92eb90bc37"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQwMDoyMDowNFrOICvlXw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQwMDoyMDowNFrOICvlXw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTc0NzY3OQ==", "bodyText": "I think these lines can be removed from the docs. I don't think we need to document cases that would be parsed as strange table identifiers that were never supported.", "url": "https://github.com/apache/iceberg/pull/1783#discussion_r539747679", "createdAt": "2020-12-10T00:20:04Z", "author": {"login": "rdblue"}, "path": "site/docs/spark.md", "diffHunk": "@@ -325,6 +325,21 @@ spark.read\n \n Time travel is not yet supported by Spark's SQL syntax.\n \n+### Table names and paths\n+\n+Paths and table names can be loaded from the Spark3 dataframe interface. How paths/tables are loaded depends on how\n+the identifier is specified. When using `spark.read().format(\"iceberg\").path(table)` or `spark.table(table)` the `table`\n+variable can take a number of forms as listed below:\n+\n+*  `file:/path/to/table` -> loads a HadoopTable at given path\n+*  ```catalog.`file:/path/to/table` ``` -> fails. Don't set a catalog for paths\n+*  ```catalog.namespace.`file:/path/to/table` ``` -> fails. Namespace doesn't exist for paths", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e89c1ba706b123ba1de1a5a19fd6ea92eb90bc37"}, "originalPosition": 12}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ4NzIzNTA5", "url": "https://github.com/apache/iceberg/pull/1783#pullrequestreview-548723509", "createdAt": "2020-12-10T00:20:50Z", "commit": {"oid": "e89c1ba706b123ba1de1a5a19fd6ea92eb90bc37"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQwMDoyMDo1MFrOICvmsg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQwMDoyMDo1MFrOICvmsg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTc0ODAxOA==", "bodyText": "Same here, no need for the catalog/path lines.", "url": "https://github.com/apache/iceberg/pull/1783#discussion_r539748018", "createdAt": "2020-12-10T00:20:50Z", "author": {"login": "rdblue"}, "path": "spark3/src/main/java/org/apache/iceberg/spark/source/IcebergSource.java", "diffHunk": "@@ -20,21 +20,45 @@\n package org.apache.iceberg.spark.source;\n \n import java.util.Map;\n-import org.apache.hadoop.conf.Configuration;\n-import org.apache.iceberg.Table;\n-import org.apache.iceberg.catalog.TableIdentifier;\n-import org.apache.iceberg.hadoop.HadoopTables;\n-import org.apache.iceberg.hive.HiveCatalog;\n-import org.apache.iceberg.hive.HiveCatalogs;\n import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.base.Splitter;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.spark.PathIdentifier;\n+import org.apache.iceberg.spark.Spark3Util;\n+import org.apache.iceberg.spark.SparkSessionCatalog;\n import org.apache.spark.sql.SparkSession;\n-import org.apache.spark.sql.connector.catalog.TableProvider;\n+import org.apache.spark.sql.catalyst.analysis.NoSuchTableException;\n+import org.apache.spark.sql.connector.catalog.CatalogManager;\n+import org.apache.spark.sql.connector.catalog.CatalogPlugin;\n+import org.apache.spark.sql.connector.catalog.Identifier;\n+import org.apache.spark.sql.connector.catalog.SupportsCatalogOptions;\n+import org.apache.spark.sql.connector.catalog.Table;\n+import org.apache.spark.sql.connector.catalog.TableCatalog;\n import org.apache.spark.sql.connector.expressions.Transform;\n import org.apache.spark.sql.sources.DataSourceRegister;\n import org.apache.spark.sql.types.StructType;\n import org.apache.spark.sql.util.CaseInsensitiveStringMap;\n \n-public class IcebergSource implements DataSourceRegister, TableProvider {\n+/**\n+ * The IcebergSource loads/writes tables with format \"iceberg\". It can load paths and tables.\n+ *\n+ * How paths/tables are loaded when using spark.read().format(\"iceberg\").path(table)\n+ *\n+ *  table = \"file:/path/to/table\" -> loads a HadoopTable at given path\n+ *  table = \"catalog.`file:/path/to/table`\" -> fails. Don't set a catalog for paths\n+ *  table = \"catalog.namespace.`file:/path/to/table`\" -> fails. Namespace doesn't exist for paths", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e89c1ba706b123ba1de1a5a19fd6ea92eb90bc37"}, "originalPosition": 38}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ4NzIzNTk5", "url": "https://github.com/apache/iceberg/pull/1783#pullrequestreview-548723599", "createdAt": "2020-12-10T00:21:01Z", "commit": {"oid": "e89c1ba706b123ba1de1a5a19fd6ea92eb90bc37"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQwMDoyMTowMlrOICvm9g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQwMDoyMTowMlrOICvm9g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTc0ODA4Ng==", "bodyText": "Nit: starts with \"otherwise\" still.", "url": "https://github.com/apache/iceberg/pull/1783#discussion_r539748086", "createdAt": "2020-12-10T00:21:02Z", "author": {"login": "rdblue"}, "path": "spark3/src/main/java/org/apache/iceberg/spark/source/IcebergSource.java", "diffHunk": "@@ -20,21 +20,45 @@\n package org.apache.iceberg.spark.source;\n \n import java.util.Map;\n-import org.apache.hadoop.conf.Configuration;\n-import org.apache.iceberg.Table;\n-import org.apache.iceberg.catalog.TableIdentifier;\n-import org.apache.iceberg.hadoop.HadoopTables;\n-import org.apache.iceberg.hive.HiveCatalog;\n-import org.apache.iceberg.hive.HiveCatalogs;\n import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.base.Splitter;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.spark.PathIdentifier;\n+import org.apache.iceberg.spark.Spark3Util;\n+import org.apache.iceberg.spark.SparkSessionCatalog;\n import org.apache.spark.sql.SparkSession;\n-import org.apache.spark.sql.connector.catalog.TableProvider;\n+import org.apache.spark.sql.catalyst.analysis.NoSuchTableException;\n+import org.apache.spark.sql.connector.catalog.CatalogManager;\n+import org.apache.spark.sql.connector.catalog.CatalogPlugin;\n+import org.apache.spark.sql.connector.catalog.Identifier;\n+import org.apache.spark.sql.connector.catalog.SupportsCatalogOptions;\n+import org.apache.spark.sql.connector.catalog.Table;\n+import org.apache.spark.sql.connector.catalog.TableCatalog;\n import org.apache.spark.sql.connector.expressions.Transform;\n import org.apache.spark.sql.sources.DataSourceRegister;\n import org.apache.spark.sql.types.StructType;\n import org.apache.spark.sql.util.CaseInsensitiveStringMap;\n \n-public class IcebergSource implements DataSourceRegister, TableProvider {\n+/**\n+ * The IcebergSource loads/writes tables with format \"iceberg\". It can load paths and tables.\n+ *\n+ * How paths/tables are loaded when using spark.read().format(\"iceberg\").path(table)\n+ *\n+ *  table = \"file:/path/to/table\" -> loads a HadoopTable at given path\n+ *  table = \"catalog.`file:/path/to/table`\" -> fails. Don't set a catalog for paths\n+ *  table = \"catalog.namespace.`file:/path/to/table`\" -> fails. Namespace doesn't exist for paths\n+ *  table = \"tablename\" -> loads currentCatalog.currentNamespace.tablename\n+ *  table = \"catalog.tablename\" -> load \"tablename\" from the specified catalog.\n+ *  table = \"namespace.tablename\" -> Otherwise load \"namespace.tablename\" from current catalog", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e89c1ba706b123ba1de1a5a19fd6ea92eb90bc37"}, "originalPosition": 41}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ4NzIzNzU3", "url": "https://github.com/apache/iceberg/pull/1783#pullrequestreview-548723757", "createdAt": "2020-12-10T00:21:23Z", "commit": {"oid": "e89c1ba706b123ba1de1a5a19fd6ea92eb90bc37"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQwMDoyMToyM1rOICvndA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQwMDoyMToyM1rOICvndA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTc0ODIxMg==", "bodyText": "Nit: looks like newlines between control flow are missing in a lot of these changes.", "url": "https://github.com/apache/iceberg/pull/1783#discussion_r539748212", "createdAt": "2020-12-10T00:21:23Z", "author": {"login": "rdblue"}, "path": "spark3/src/main/java/org/apache/iceberg/spark/source/IcebergSource.java", "diffHunk": "@@ -56,48 +80,70 @@ public boolean supportsExternalMetadata() {\n   }\n \n   @Override\n-  public SparkTable getTable(StructType schema, Transform[] partitioning, Map<String, String> options) {\n-    // Get Iceberg table from options\n-    Configuration conf = SparkSession.active().sessionState().newHadoopConf();\n-    Table icebergTable = getTableAndResolveHadoopConfiguration(options, conf);\n-\n-    // Build Spark table based on Iceberg table, and return it\n-    // Eagerly refresh the table before reading to ensure views containing this table show up-to-date data\n-    return new SparkTable(icebergTable, schema, true);\n+  public Table getTable(StructType schema, Transform[] partitioning, Map<String, String> options) {\n+    String catalogName = extractCatalog(new CaseInsensitiveStringMap(options));\n+    Identifier ident = extractIdentifier(new CaseInsensitiveStringMap(options));\n+    CatalogManager catalogManager = SparkSession.active().sessionState().catalogManager();\n+    CatalogPlugin catalog = catalogManager.catalog(catalogName);\n+    try {\n+      if (catalog instanceof TableCatalog) {\n+        return ((TableCatalog) catalog).loadTable(ident);\n+      }\n+    } catch (NoSuchTableException e) {\n+      // throwing an iceberg NoSuchTableException because the Spark one is typed and cant be thrown from this interface\n+      throw new org.apache.iceberg.exceptions.NoSuchTableException(e, \"Cannot find table for %s.\", ident);\n+    }\n+    // throwing an iceberg NoSuchTableException because the Spark one is typed and cant be thrown from this interface", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e89c1ba706b123ba1de1a5a19fd6ea92eb90bc37"}, "originalPosition": 79}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ4NzI0NzA4", "url": "https://github.com/apache/iceberg/pull/1783#pullrequestreview-548724708", "createdAt": "2020-12-10T00:23:47Z", "commit": {"oid": "e89c1ba706b123ba1de1a5a19fd6ea92eb90bc37"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQwMDoyMzo0N1rOICvrXQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQwMDoyMzo0N1rOICvrXQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTc0OTIxMw==", "bodyText": "This is doing a lot of extra work by not calling CatalogAndIdentifier directly. There are two maps created, two identical catalog/table resolutions, and then this needs to get the active session and look up the catalog that was already loaded. Is it possible to refactor so that the \"extract\" functions use a common method that can be used here?", "url": "https://github.com/apache/iceberg/pull/1783#discussion_r539749213", "createdAt": "2020-12-10T00:23:47Z", "author": {"login": "rdblue"}, "path": "spark3/src/main/java/org/apache/iceberg/spark/source/IcebergSource.java", "diffHunk": "@@ -56,48 +80,70 @@ public boolean supportsExternalMetadata() {\n   }\n \n   @Override\n-  public SparkTable getTable(StructType schema, Transform[] partitioning, Map<String, String> options) {\n-    // Get Iceberg table from options\n-    Configuration conf = SparkSession.active().sessionState().newHadoopConf();\n-    Table icebergTable = getTableAndResolveHadoopConfiguration(options, conf);\n-\n-    // Build Spark table based on Iceberg table, and return it\n-    // Eagerly refresh the table before reading to ensure views containing this table show up-to-date data\n-    return new SparkTable(icebergTable, schema, true);\n+  public Table getTable(StructType schema, Transform[] partitioning, Map<String, String> options) {\n+    String catalogName = extractCatalog(new CaseInsensitiveStringMap(options));\n+    Identifier ident = extractIdentifier(new CaseInsensitiveStringMap(options));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e89c1ba706b123ba1de1a5a19fd6ea92eb90bc37"}, "originalPosition": 68}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ4NzI1MDY3", "url": "https://github.com/apache/iceberg/pull/1783#pullrequestreview-548725067", "createdAt": "2020-12-10T00:24:39Z", "commit": {"oid": "e89c1ba706b123ba1de1a5a19fd6ea92eb90bc37"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQwMDoyNDozOVrOICvs0A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQwMDoyNDozOVrOICvs0A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzOTc0OTU4NA==", "bodyText": "I think this should parse the identifier using Spark rather than DOT.splitToList. It should be spark.sessionState().sqlParser().parseMultipartIdentifier(path).", "url": "https://github.com/apache/iceberg/pull/1783#discussion_r539749584", "createdAt": "2020-12-10T00:24:39Z", "author": {"login": "rdblue"}, "path": "spark3/src/main/java/org/apache/iceberg/spark/source/IcebergSource.java", "diffHunk": "@@ -56,48 +80,70 @@ public boolean supportsExternalMetadata() {\n   }\n \n   @Override\n-  public SparkTable getTable(StructType schema, Transform[] partitioning, Map<String, String> options) {\n-    // Get Iceberg table from options\n-    Configuration conf = SparkSession.active().sessionState().newHadoopConf();\n-    Table icebergTable = getTableAndResolveHadoopConfiguration(options, conf);\n-\n-    // Build Spark table based on Iceberg table, and return it\n-    // Eagerly refresh the table before reading to ensure views containing this table show up-to-date data\n-    return new SparkTable(icebergTable, schema, true);\n+  public Table getTable(StructType schema, Transform[] partitioning, Map<String, String> options) {\n+    String catalogName = extractCatalog(new CaseInsensitiveStringMap(options));\n+    Identifier ident = extractIdentifier(new CaseInsensitiveStringMap(options));\n+    CatalogManager catalogManager = SparkSession.active().sessionState().catalogManager();\n+    CatalogPlugin catalog = catalogManager.catalog(catalogName);\n+    try {\n+      if (catalog instanceof TableCatalog) {\n+        return ((TableCatalog) catalog).loadTable(ident);\n+      }\n+    } catch (NoSuchTableException e) {\n+      // throwing an iceberg NoSuchTableException because the Spark one is typed and cant be thrown from this interface\n+      throw new org.apache.iceberg.exceptions.NoSuchTableException(e, \"Cannot find table for %s.\", ident);\n+    }\n+    // throwing an iceberg NoSuchTableException because the Spark one is typed and cant be thrown from this interface\n+    throw new org.apache.iceberg.exceptions.NoSuchTableException(\"Cannot find table for %s.\", ident);\n   }\n \n-  protected Table findTable(Map<String, String> options, Configuration conf) {\n+  private Spark3Util.CatalogAndIdentifier catalogAndIdentifier(CaseInsensitiveStringMap options) {\n     Preconditions.checkArgument(options.containsKey(\"path\"), \"Cannot open table: path is not set\");\n+    setupDefaultSparkCatalog();\n     String path = options.get(\"path\");\n+    SparkSession spark = SparkSession.active();\n+    CatalogManager catalogManager = spark.sessionState().catalogManager();\n \n     if (path.contains(\"/\")) {\n-      HadoopTables tables = new HadoopTables(conf);\n-      return tables.load(path);\n+      // contains a path. Return iceberg default catalog and a PathIdentifier\n+      return new Spark3Util.CatalogAndIdentifier(catalogManager.catalog(DEFAULT_CATALOG_NAME),\n+          new PathIdentifier(path));\n+    }\n+    Spark3Util.CatalogAndIdentifier catalogAndIdentifier = Spark3Util.catalogAndIdentifier(spark,\n+        DOT.splitToList(path));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e89c1ba706b123ba1de1a5a19fd6ea92eb90bc37"}, "originalPosition": 99}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e89c1ba706b123ba1de1a5a19fd6ea92eb90bc37", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/e89c1ba706b123ba1de1a5a19fd6ea92eb90bc37", "committedDate": "2020-12-09T18:45:54Z", "message": "address code review and simplify default catalog logic"}, "afterCommit": {"oid": "3ed51bd68b10fe2fcced2b231f28499b69f7cbf5", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/3ed51bd68b10fe2fcced2b231f28499b69f7cbf5", "committedDate": "2020-12-10T12:52:51Z", "message": "clean up based on code review"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ5NzE2OTM4", "url": "https://github.com/apache/iceberg/pull/1783#pullrequestreview-549716938", "createdAt": "2020-12-11T00:27:02Z", "commit": {"oid": "3ed51bd68b10fe2fcced2b231f28499b69f7cbf5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMVQwMDoyNzowMlrOIDjnzg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMVQwMDoyNzowMlrOIDjnzg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDYwMDI3MA==", "bodyText": "Sorry for not catching this before, but I think this should be passed in. This should avoid extra calls to SparkSession.active().", "url": "https://github.com/apache/iceberg/pull/1783#discussion_r540600270", "createdAt": "2020-12-11T00:27:02Z", "author": {"login": "rdblue"}, "path": "spark3/src/main/java/org/apache/iceberg/spark/source/IcebergSource.java", "diffHunk": "@@ -56,48 +77,77 @@ public boolean supportsExternalMetadata() {\n   }\n \n   @Override\n-  public SparkTable getTable(StructType schema, Transform[] partitioning, Map<String, String> options) {\n-    // Get Iceberg table from options\n-    Configuration conf = SparkSession.active().sessionState().newHadoopConf();\n-    Table icebergTable = getTableAndResolveHadoopConfiguration(options, conf);\n-\n-    // Build Spark table based on Iceberg table, and return it\n-    // Eagerly refresh the table before reading to ensure views containing this table show up-to-date data\n-    return new SparkTable(icebergTable, schema, true);\n+  public Table getTable(StructType schema, Transform[] partitioning, Map<String, String> options) {\n+    Spark3Util.CatalogAndIdentifier catalogIdentifier = catalogAndIdentifier(new CaseInsensitiveStringMap(options));\n+    CatalogPlugin catalog = catalogIdentifier.catalog();\n+    Identifier ident = catalogIdentifier.identifier();\n+\n+    try {\n+      if (catalog instanceof TableCatalog) {\n+        return ((TableCatalog) catalog).loadTable(ident);\n+      }\n+    } catch (NoSuchTableException e) {\n+      // throwing an iceberg NoSuchTableException because the Spark one is typed and cant be thrown from this interface\n+      throw new org.apache.iceberg.exceptions.NoSuchTableException(e, \"Cannot find table for %s.\", ident);\n+    }\n+\n+    // throwing an iceberg NoSuchTableException because the Spark one is typed and cant be thrown from this interface\n+    throw new org.apache.iceberg.exceptions.NoSuchTableException(\"Cannot find table for %s.\", ident);\n   }\n \n-  protected Table findTable(Map<String, String> options, Configuration conf) {\n+  private Spark3Util.CatalogAndIdentifier catalogAndIdentifier(CaseInsensitiveStringMap options) {\n     Preconditions.checkArgument(options.containsKey(\"path\"), \"Cannot open table: path is not set\");\n+    setupDefaultSparkCatalog();\n     String path = options.get(\"path\");\n+    SparkSession spark = SparkSession.active();\n+    CatalogManager catalogManager = spark.sessionState().catalogManager();\n \n     if (path.contains(\"/\")) {\n-      HadoopTables tables = new HadoopTables(conf);\n-      return tables.load(path);\n-    } else {\n-      HiveCatalog hiveCatalog = HiveCatalogs.loadCatalog(conf);\n-      TableIdentifier tableIdentifier = TableIdentifier.parse(path);\n-      return hiveCatalog.loadTable(tableIdentifier);\n+      // contains a path. Return iceberg default catalog and a PathIdentifier\n+      return new Spark3Util.CatalogAndIdentifier(catalogManager.catalog(DEFAULT_CATALOG_NAME),\n+          new PathIdentifier(path));\n     }\n-  }\n \n-  private Table getTableAndResolveHadoopConfiguration(Map<String, String> options, Configuration conf) {\n-    // Overwrite configurations from the Spark Context with configurations from the options.\n-    mergeIcebergHadoopConfs(conf, options);\n-\n-    Table table = findTable(options, conf);\n+    final Spark3Util.CatalogAndIdentifier catalogAndIdentifier;\n+    try {\n+      catalogAndIdentifier = Spark3Util.catalogAndIdentifier(spark, path);\n+    } catch (ParseException e) {\n+      throw new IllegalArgumentException(String.format(\"Cannot parse path %s. It is not a valid SQL table\", path), e);\n+    }\n \n-    // Set confs from table properties\n-    mergeIcebergHadoopConfs(conf, table.properties());\n+    if (catalogAndIdentifier.catalog().name().equals(\"spark_catalog\") &&\n+        !(catalogAndIdentifier.catalog() instanceof SparkSessionCatalog)) {\n+      // catalog is a session catalog but does not support Iceberg. Use Iceberg instead.\n+      return new Spark3Util.CatalogAndIdentifier(catalogManager.catalog(DEFAULT_CATALOG_NAME),\n+          catalogAndIdentifier.identifier());\n+    } else {\n+      return catalogAndIdentifier;\n+    }\n+  }\n \n-    // Re-overwrite values set in options and table properties but were not in the environment.\n-    mergeIcebergHadoopConfs(conf, options);\n+  @Override\n+  public Identifier extractIdentifier(CaseInsensitiveStringMap options) {\n+    return catalogAndIdentifier(options).identifier();\n+  }\n \n-    return table;\n+  @Override\n+  public String extractCatalog(CaseInsensitiveStringMap options) {\n+    return catalogAndIdentifier(options).catalog().name();\n   }\n \n-  private static void mergeIcebergHadoopConfs(Configuration baseConf, Map<String, String> options) {\n-    options.keySet().stream()\n-        .filter(key -> key.startsWith(\"hadoop.\"))\n-        .forEach(key -> baseConf.set(key.replaceFirst(\"hadoop.\", \"\"), options.get(key)));\n+  private static void setupDefaultSparkCatalog() {\n+    SparkSession spark = SparkSession.active();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ed51bd68b10fe2fcced2b231f28499b69f7cbf5"}, "originalPosition": 144}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ5NzE4ODE0", "url": "https://github.com/apache/iceberg/pull/1783#pullrequestreview-549718814", "createdAt": "2020-12-11T00:32:20Z", "commit": {"oid": "3ed51bd68b10fe2fcced2b231f28499b69f7cbf5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMVQwMDozMjoyMFrOIDjvWw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMVQwMDozMjoyMFrOIDjvWw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDYwMjIwMw==", "bodyText": "There's no need to catch ParseException any more. A new version of catalogAndIdentifer was added with context to form the error message. This could be:\nSpark3Util.CatalogAndIdentifier catalogAndIdentifier = Spark3Util.catalogAndIdentifier(\"identifier\", spark, path);", "url": "https://github.com/apache/iceberg/pull/1783#discussion_r540602203", "createdAt": "2020-12-11T00:32:20Z", "author": {"login": "rdblue"}, "path": "spark3/src/main/java/org/apache/iceberg/spark/source/IcebergSource.java", "diffHunk": "@@ -56,48 +77,77 @@ public boolean supportsExternalMetadata() {\n   }\n \n   @Override\n-  public SparkTable getTable(StructType schema, Transform[] partitioning, Map<String, String> options) {\n-    // Get Iceberg table from options\n-    Configuration conf = SparkSession.active().sessionState().newHadoopConf();\n-    Table icebergTable = getTableAndResolveHadoopConfiguration(options, conf);\n-\n-    // Build Spark table based on Iceberg table, and return it\n-    // Eagerly refresh the table before reading to ensure views containing this table show up-to-date data\n-    return new SparkTable(icebergTable, schema, true);\n+  public Table getTable(StructType schema, Transform[] partitioning, Map<String, String> options) {\n+    Spark3Util.CatalogAndIdentifier catalogIdentifier = catalogAndIdentifier(new CaseInsensitiveStringMap(options));\n+    CatalogPlugin catalog = catalogIdentifier.catalog();\n+    Identifier ident = catalogIdentifier.identifier();\n+\n+    try {\n+      if (catalog instanceof TableCatalog) {\n+        return ((TableCatalog) catalog).loadTable(ident);\n+      }\n+    } catch (NoSuchTableException e) {\n+      // throwing an iceberg NoSuchTableException because the Spark one is typed and cant be thrown from this interface\n+      throw new org.apache.iceberg.exceptions.NoSuchTableException(e, \"Cannot find table for %s.\", ident);\n+    }\n+\n+    // throwing an iceberg NoSuchTableException because the Spark one is typed and cant be thrown from this interface\n+    throw new org.apache.iceberg.exceptions.NoSuchTableException(\"Cannot find table for %s.\", ident);\n   }\n \n-  protected Table findTable(Map<String, String> options, Configuration conf) {\n+  private Spark3Util.CatalogAndIdentifier catalogAndIdentifier(CaseInsensitiveStringMap options) {\n     Preconditions.checkArgument(options.containsKey(\"path\"), \"Cannot open table: path is not set\");\n+    setupDefaultSparkCatalog();\n     String path = options.get(\"path\");\n+    SparkSession spark = SparkSession.active();\n+    CatalogManager catalogManager = spark.sessionState().catalogManager();\n \n     if (path.contains(\"/\")) {\n-      HadoopTables tables = new HadoopTables(conf);\n-      return tables.load(path);\n-    } else {\n-      HiveCatalog hiveCatalog = HiveCatalogs.loadCatalog(conf);\n-      TableIdentifier tableIdentifier = TableIdentifier.parse(path);\n-      return hiveCatalog.loadTable(tableIdentifier);\n+      // contains a path. Return iceberg default catalog and a PathIdentifier\n+      return new Spark3Util.CatalogAndIdentifier(catalogManager.catalog(DEFAULT_CATALOG_NAME),\n+          new PathIdentifier(path));\n     }\n-  }\n \n-  private Table getTableAndResolveHadoopConfiguration(Map<String, String> options, Configuration conf) {\n-    // Overwrite configurations from the Spark Context with configurations from the options.\n-    mergeIcebergHadoopConfs(conf, options);\n-\n-    Table table = findTable(options, conf);\n+    final Spark3Util.CatalogAndIdentifier catalogAndIdentifier;\n+    try {\n+      catalogAndIdentifier = Spark3Util.catalogAndIdentifier(spark, path);\n+    } catch (ParseException e) {\n+      throw new IllegalArgumentException(String.format(\"Cannot parse path %s. It is not a valid SQL table\", path), e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "3ed51bd68b10fe2fcced2b231f28499b69f7cbf5"}, "originalPosition": 111}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "625422886e3eb4203965414ba0f11d2681a977b9", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/625422886e3eb4203965414ba0f11d2681a977b9", "committedDate": "2020-12-11T10:09:19Z", "message": "minor fixes and simplification"}, "afterCommit": {"oid": "ed421acd7e54a6a88ebc429fc8b3d068c5e1a196", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/ed421acd7e54a6a88ebc429fc8b3d068c5e1a196", "committedDate": "2020-12-11T10:10:46Z", "message": "minor fixes and simplification"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUwMzUzMTMw", "url": "https://github.com/apache/iceberg/pull/1783#pullrequestreview-550353130", "createdAt": "2020-12-11T17:40:31Z", "commit": {"oid": "ed421acd7e54a6a88ebc429fc8b3d068c5e1a196"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMVQxNzo0MDozMVrOIEDF_w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMVQxNzo0MDozMVrOIEDF_w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTExNTkwMw==", "bodyText": "The \"Cannot parse\" part is filled in automatically, so you just need to pass the name of the arg. Probably \"path or identifier\".", "url": "https://github.com/apache/iceberg/pull/1783#discussion_r541115903", "createdAt": "2020-12-11T17:40:31Z", "author": {"login": "rdblue"}, "path": "spark3/src/main/java/org/apache/iceberg/spark/source/IcebergSource.java", "diffHunk": "@@ -56,48 +76,72 @@ public boolean supportsExternalMetadata() {\n   }\n \n   @Override\n-  public SparkTable getTable(StructType schema, Transform[] partitioning, Map<String, String> options) {\n-    // Get Iceberg table from options\n-    Configuration conf = SparkSession.active().sessionState().newHadoopConf();\n-    Table icebergTable = getTableAndResolveHadoopConfiguration(options, conf);\n-\n-    // Build Spark table based on Iceberg table, and return it\n-    // Eagerly refresh the table before reading to ensure views containing this table show up-to-date data\n-    return new SparkTable(icebergTable, schema, true);\n+  public Table getTable(StructType schema, Transform[] partitioning, Map<String, String> options) {\n+    Spark3Util.CatalogAndIdentifier catalogIdentifier = catalogAndIdentifier(new CaseInsensitiveStringMap(options));\n+    CatalogPlugin catalog = catalogIdentifier.catalog();\n+    Identifier ident = catalogIdentifier.identifier();\n+\n+    try {\n+      if (catalog instanceof TableCatalog) {\n+        return ((TableCatalog) catalog).loadTable(ident);\n+      }\n+    } catch (NoSuchTableException e) {\n+      // throwing an iceberg NoSuchTableException because the Spark one is typed and cant be thrown from this interface\n+      throw new org.apache.iceberg.exceptions.NoSuchTableException(e, \"Cannot find table for %s.\", ident);\n+    }\n+\n+    // throwing an iceberg NoSuchTableException because the Spark one is typed and cant be thrown from this interface\n+    throw new org.apache.iceberg.exceptions.NoSuchTableException(\"Cannot find table for %s.\", ident);\n   }\n \n-  protected Table findTable(Map<String, String> options, Configuration conf) {\n+  private Spark3Util.CatalogAndIdentifier catalogAndIdentifier(CaseInsensitiveStringMap options) {\n     Preconditions.checkArgument(options.containsKey(\"path\"), \"Cannot open table: path is not set\");\n+    SparkSession spark = SparkSession.active();\n+    setupDefaultSparkCatalog(spark);\n     String path = options.get(\"path\");\n+    CatalogManager catalogManager = spark.sessionState().catalogManager();\n \n     if (path.contains(\"/\")) {\n-      HadoopTables tables = new HadoopTables(conf);\n-      return tables.load(path);\n-    } else {\n-      HiveCatalog hiveCatalog = HiveCatalogs.loadCatalog(conf);\n-      TableIdentifier tableIdentifier = TableIdentifier.parse(path);\n-      return hiveCatalog.loadTable(tableIdentifier);\n+      // contains a path. Return iceberg default catalog and a PathIdentifier\n+      return new Spark3Util.CatalogAndIdentifier(catalogManager.catalog(DEFAULT_CATALOG_NAME),\n+          new PathIdentifier(path));\n     }\n-  }\n \n-  private Table getTableAndResolveHadoopConfiguration(Map<String, String> options, Configuration conf) {\n-    // Overwrite configurations from the Spark Context with configurations from the options.\n-    mergeIcebergHadoopConfs(conf, options);\n+    final Spark3Util.CatalogAndIdentifier catalogAndIdentifier = Spark3Util.catalogAndIdentifier(\n+        \"Cannot parse path %s. It is not a valid SQL table\", spark, path);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "ed421acd7e54a6a88ebc429fc8b3d068c5e1a196"}, "originalPosition": 105}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "96356e27d0b070f7ebf978e6248bdd37fc66f37b", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/96356e27d0b070f7ebf978e6248bdd37fc66f37b", "committedDate": "2020-12-11T17:43:53Z", "message": "log line fix"}, "afterCommit": {"oid": "d8aada53d5b15833d49fe452021215b7e35ec0e3", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/d8aada53d5b15833d49fe452021215b7e35ec0e3", "committedDate": "2020-12-11T17:45:21Z", "message": "log line fix"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUwMzY3Nzk3", "url": "https://github.com/apache/iceberg/pull/1783#pullrequestreview-550367797", "createdAt": "2020-12-11T17:49:04Z", "commit": {"oid": "ed421acd7e54a6a88ebc429fc8b3d068c5e1a196"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTUwNTc4NjI3", "url": "https://github.com/apache/iceberg/pull/1783#pullrequestreview-550578627", "createdAt": "2020-12-11T21:07:59Z", "commit": {"oid": "d8aada53d5b15833d49fe452021215b7e35ec0e3"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMVQyMTowNzo1OVrOIEN4Vw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMVQyMTowNzo1OVrOIEN4Vw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTI5MjYzMQ==", "bodyText": "Maybe important to note that these are used with this priority as well, ie\nif \"catalog.namespace.table\" is valid it will be read and \"namespace.namespace.table\" will be ignored ?", "url": "https://github.com/apache/iceberg/pull/1783#discussion_r541292631", "createdAt": "2020-12-11T21:07:59Z", "author": {"login": "RussellSpitzer"}, "path": "spark3/src/main/java/org/apache/iceberg/spark/source/IcebergSource.java", "diffHunk": "@@ -20,21 +20,41 @@\n package org.apache.iceberg.spark.source;\n \n import java.util.Map;\n-import org.apache.hadoop.conf.Configuration;\n-import org.apache.iceberg.Table;\n-import org.apache.iceberg.catalog.TableIdentifier;\n-import org.apache.iceberg.hadoop.HadoopTables;\n-import org.apache.iceberg.hive.HiveCatalog;\n-import org.apache.iceberg.hive.HiveCatalogs;\n import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.spark.PathIdentifier;\n+import org.apache.iceberg.spark.Spark3Util;\n+import org.apache.iceberg.spark.SparkSessionCatalog;\n import org.apache.spark.sql.SparkSession;\n-import org.apache.spark.sql.connector.catalog.TableProvider;\n+import org.apache.spark.sql.catalyst.analysis.NoSuchTableException;\n+import org.apache.spark.sql.connector.catalog.CatalogManager;\n+import org.apache.spark.sql.connector.catalog.CatalogPlugin;\n+import org.apache.spark.sql.connector.catalog.Identifier;\n+import org.apache.spark.sql.connector.catalog.SupportsCatalogOptions;\n+import org.apache.spark.sql.connector.catalog.Table;\n+import org.apache.spark.sql.connector.catalog.TableCatalog;\n import org.apache.spark.sql.connector.expressions.Transform;\n import org.apache.spark.sql.sources.DataSourceRegister;\n import org.apache.spark.sql.types.StructType;\n import org.apache.spark.sql.util.CaseInsensitiveStringMap;\n \n-public class IcebergSource implements DataSourceRegister, TableProvider {\n+/**\n+ * The IcebergSource loads/writes tables with format \"iceberg\". It can load paths and tables.\n+ *\n+ * How paths/tables are loaded when using spark.read().format(\"iceberg\").path(table)\n+ *\n+ *  table = \"file:/path/to/table\" -> loads a HadoopTable at given path", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d8aada53d5b15833d49fe452021215b7e35ec0e3"}, "originalPosition": 35}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "409b1ad069f7723fd083d98c1bd6babe2f607395", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/409b1ad069f7723fd083d98c1bd6babe2f607395", "committedDate": "2020-12-22T16:45:38Z", "message": "straw man custom catalog from `IcebergSource`"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d45ee4cc6f0e2c198e192d33e2bf85c87c584de1", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/d45ee4cc6f0e2c198e192d33e2bf85c87c584de1", "committedDate": "2020-12-22T16:45:39Z", "message": "IcebergSource now uses SupportsCatalogOptions\n\nIt compiles and mostly works but SessionCatalog isn't set anywhere.\n\nHave to change a lot of the Spark3 tests to register a catalog now"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "239c2e72f7424fed4c77c66e82ac8ee86aaff3d3", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/239c2e72f7424fed4c77c66e82ac8ee86aaff3d3", "committedDate": "2020-12-22T16:45:40Z", "message": "start fixing tests"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "581638cded5a197447024eecf2970f2418b60eb2", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/581638cded5a197447024eecf2970f2418b60eb2", "committedDate": "2020-12-22T16:45:41Z", "message": "tests all fixed"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ef262111680150957ce4d24f67690045df53ddf4", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/ef262111680150957ce4d24f67690045df53ddf4", "committedDate": "2020-12-22T16:45:41Z", "message": "source fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2a8bac3dfcfa01b0eeed7cb260bfc21653caaf2f", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/2a8bac3dfcfa01b0eeed7cb260bfc21653caaf2f", "committedDate": "2020-12-22T16:45:42Z", "message": "updates based on code review"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c39f108ed03c06f8381c2569ec9e05f20e1643df", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/c39f108ed03c06f8381c2569ec9e05f20e1643df", "committedDate": "2020-12-22T16:45:43Z", "message": "clean up based on code review"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "50808b7e5f3bdd4e16a2a630e68647c4beee9394", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/50808b7e5f3bdd4e16a2a630e68647c4beee9394", "committedDate": "2020-12-22T16:45:44Z", "message": "comment explaining exception type"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8ebe3c9db9c9efdb188a2b8fbb1644e9629564c9", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/8ebe3c9db9c9efdb188a2b8fbb1644e9629564c9", "committedDate": "2020-12-22T16:45:45Z", "message": "clean up and docs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "20e9d218fb43411fa5766a26281bffdad8435ea3", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/20e9d218fb43411fa5766a26281bffdad8435ea3", "committedDate": "2020-12-22T16:45:46Z", "message": "use util function to get catalog and identifier"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "806e92ac97ef7ecbb002647d176b0434609cc8be", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/806e92ac97ef7ecbb002647d176b0434609cc8be", "committedDate": "2020-12-22T16:45:47Z", "message": "rebase to pick up #1843 and fix build"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4821282b25229bf82445a8b01c7bca92ebe1acaf", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/4821282b25229bf82445a8b01c7bca92ebe1acaf", "committedDate": "2020-12-22T16:45:48Z", "message": "start a custom catalog if no iceberg catalogs are available"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "04ce0069aeb9ce0e88f4e9e9fa5fc9560ad6cc12", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/04ce0069aeb9ce0e88f4e9e9fa5fc9560ad6cc12", "committedDate": "2020-12-22T16:45:49Z", "message": "clean up"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ca249bc2770c997df29f322cc544085cf1e221a6", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/ca249bc2770c997df29f322cc544085cf1e221a6", "committedDate": "2020-12-22T16:45:50Z", "message": "address code review and simplify default catalog logic"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4a38352a144ee806cb3118e27fb4a353b3f76ca0", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/4a38352a144ee806cb3118e27fb4a353b3f76ca0", "committedDate": "2020-12-22T16:45:51Z", "message": "clean up based on code review"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c9b6483d078188a7993fbcb0f7d3be9d5dbe20f7", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/c9b6483d078188a7993fbcb0f7d3be9d5dbe20f7", "committedDate": "2020-12-22T16:45:52Z", "message": "minor fixes and simplification"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b8c2320225fec647416249fed3dcc6bef788bc1e", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/b8c2320225fec647416249fed3dcc6bef788bc1e", "committedDate": "2020-12-22T16:45:53Z", "message": "log line fix"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a4c08d1c538e5ecef17fa1e551cc7d5bf2dfd051", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/a4c08d1c538e5ecef17fa1e551cc7d5bf2dfd051", "committedDate": "2020-12-22T16:45:53Z", "message": "log line fix"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "3aa4d2915c8084bf900bc9be79c0ba839ac54ec3", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/3aa4d2915c8084bf900bc9be79c0ba839ac54ec3", "committedDate": "2020-12-14T14:31:03Z", "message": "log line fix"}, "afterCommit": {"oid": "a4c08d1c538e5ecef17fa1e551cc7d5bf2dfd051", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/a4c08d1c538e5ecef17fa1e551cc7d5bf2dfd051", "committedDate": "2020-12-22T16:45:53Z", "message": "log line fix"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3780, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}