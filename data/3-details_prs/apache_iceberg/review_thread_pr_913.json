{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDAyMTE1NDAz", "number": 913, "reviewThreads": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xM1QwMzoxMzo1OVrODxIFeA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQxOToyMjoxN1rODz4mDg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyODM5Mjg4OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/org/apache/iceberg/GenericManifestEntry.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xM1QwMzoxMzo1OVrOGEbePw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwMTo0MjoyNFrOGFmzeA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzI5NzU5OQ==", "bodyText": "nit: missing the sequence number here ?", "url": "https://github.com/apache/iceberg/pull/913#discussion_r407297599", "createdAt": "2020-04-13T03:13:59Z", "author": {"login": "openinx"}, "path": "core/src/main/java/org/apache/iceberg/GenericManifestEntry.java", "diffHunk": "@@ -0,0 +1,179 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg;\n+\n+import com.google.common.base.MoreObjects;\n+import org.apache.avro.generic.IndexedRecord;\n+import org.apache.avro.specific.SpecificData;\n+import org.apache.iceberg.avro.AvroSchemaUtil;\n+import org.apache.iceberg.types.Types;\n+\n+class GenericManifestEntry implements ManifestEntry, IndexedRecord, SpecificData.SchemaConstructable {\n+  private final org.apache.avro.Schema schema;\n+  private final V1Metadata.IndexedDataFile fileWrapper;\n+  private Status status = Status.EXISTING;\n+  private Long snapshotId = null;\n+  private Long sequenceNumber = null;\n+  private DataFile file = null;\n+\n+  GenericManifestEntry(org.apache.avro.Schema schema) {\n+    this.schema = schema;\n+    this.fileWrapper = null; // do not use the file wrapper to read\n+  }\n+\n+  GenericManifestEntry(Types.StructType partitionType) {\n+    this.schema = AvroSchemaUtil.convert(V1Metadata.entrySchema(partitionType), \"manifest_entry\");\n+    this.fileWrapper = new V1Metadata.IndexedDataFile(schema.getField(\"data_file\").schema());\n+  }\n+\n+  private GenericManifestEntry(GenericManifestEntry toCopy, boolean fullCopy) {\n+    this.schema = toCopy.schema;\n+    this.fileWrapper = new V1Metadata.IndexedDataFile(schema.getField(\"data_file\").schema());\n+    this.status = toCopy.status;\n+    this.snapshotId = toCopy.snapshotId;\n+    if (fullCopy) {\n+      this.file = toCopy.file().copy();\n+    } else {\n+      this.file = toCopy.file().copyWithoutStats();\n+    }\n+  }\n+\n+  ManifestEntry wrapExisting(Long newSnapshotId, Long newSequenceNumber, DataFile newFile) {\n+    this.status = Status.EXISTING;\n+    this.snapshotId = newSnapshotId;\n+    this.sequenceNumber = newSequenceNumber;\n+    this.file = newFile;\n+    return this;\n+  }\n+\n+  ManifestEntry wrapAppend(Long newSnapshotId, DataFile newFile) {\n+    this.status = Status.ADDED;\n+    this.snapshotId = newSnapshotId;\n+    this.sequenceNumber = null;\n+    this.file = newFile;\n+    return this;\n+  }\n+\n+  ManifestEntry wrapDelete(Long newSnapshotId, DataFile newFile) {\n+    this.status = Status.DELETED;\n+    this.snapshotId = newSnapshotId;\n+    this.sequenceNumber = null;\n+    this.file = newFile;\n+    return this;\n+  }\n+\n+  /**\n+   * @return the status of the file, whether EXISTING, ADDED, or DELETED\n+   */\n+  public Status status() {\n+    return status;\n+  }\n+\n+  /**\n+   * @return id of the snapshot in which the file was added to the table\n+   */\n+  public Long snapshotId() {\n+    return snapshotId;\n+  }\n+\n+  @Override\n+  public Long sequenceNumber() {\n+    return sequenceNumber;\n+  }\n+\n+  /**\n+   * @return a file\n+   */\n+  public DataFile file() {\n+    return file;\n+  }\n+\n+  public ManifestEntry copy() {\n+    return new GenericManifestEntry(this, true /* full copy */);\n+  }\n+\n+  public ManifestEntry copyWithoutStats() {\n+    return new GenericManifestEntry(this, false /* drop stats */);\n+  }\n+\n+  @Override\n+  public void setSnapshotId(long newSnapshotId) {\n+    this.snapshotId = newSnapshotId;\n+  }\n+\n+  @Override\n+  public void setSequenceNumber(long newSequenceNumber) {\n+    this.sequenceNumber = newSequenceNumber;\n+  }\n+\n+  @Override\n+  public void put(int i, Object v) {\n+    switch (i) {\n+      case 0:\n+        this.status = Status.values()[(Integer) v];\n+        return;\n+      case 1:\n+        this.snapshotId = (Long) v;\n+        return;\n+      case 2:\n+        this.sequenceNumber = (Long) v;\n+        return;\n+      case 3:\n+        this.file = (DataFile) v;\n+        return;\n+      default:\n+        // ignore the object, it must be from a newer version of the format\n+    }\n+  }\n+\n+  @Override\n+  public Object get(int i) {\n+    switch (i) {\n+      case 0:\n+        return status.id();\n+      case 1:\n+        return snapshotId;\n+      case 2:\n+        return sequenceNumber;\n+      case 3:\n+        if (fileWrapper == null || file instanceof GenericDataFile) {\n+          return file;\n+        } else {\n+          return fileWrapper.wrap(file);\n+        }\n+      default:\n+        throw new UnsupportedOperationException(\"Unknown field ordinal: \" + i);\n+    }\n+  }\n+\n+  @Override\n+  public org.apache.avro.Schema getSchema() {\n+    return schema;\n+  }\n+\n+  @Override\n+  public String toString() {\n+    return MoreObjects.toStringHelper(this)\n+        .add(\"status\", status)\n+        .add(\"snapshot_id\", snapshotId)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eaf78717b94097030098c790d7db74f231440408"}, "originalPosition": 175}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODUzMTgzMg==", "bodyText": "Added. Thanks!", "url": "https://github.com/apache/iceberg/pull/913#discussion_r408531832", "createdAt": "2020-04-15T01:42:24Z", "author": {"login": "rdblue"}, "path": "core/src/main/java/org/apache/iceberg/GenericManifestEntry.java", "diffHunk": "@@ -0,0 +1,179 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg;\n+\n+import com.google.common.base.MoreObjects;\n+import org.apache.avro.generic.IndexedRecord;\n+import org.apache.avro.specific.SpecificData;\n+import org.apache.iceberg.avro.AvroSchemaUtil;\n+import org.apache.iceberg.types.Types;\n+\n+class GenericManifestEntry implements ManifestEntry, IndexedRecord, SpecificData.SchemaConstructable {\n+  private final org.apache.avro.Schema schema;\n+  private final V1Metadata.IndexedDataFile fileWrapper;\n+  private Status status = Status.EXISTING;\n+  private Long snapshotId = null;\n+  private Long sequenceNumber = null;\n+  private DataFile file = null;\n+\n+  GenericManifestEntry(org.apache.avro.Schema schema) {\n+    this.schema = schema;\n+    this.fileWrapper = null; // do not use the file wrapper to read\n+  }\n+\n+  GenericManifestEntry(Types.StructType partitionType) {\n+    this.schema = AvroSchemaUtil.convert(V1Metadata.entrySchema(partitionType), \"manifest_entry\");\n+    this.fileWrapper = new V1Metadata.IndexedDataFile(schema.getField(\"data_file\").schema());\n+  }\n+\n+  private GenericManifestEntry(GenericManifestEntry toCopy, boolean fullCopy) {\n+    this.schema = toCopy.schema;\n+    this.fileWrapper = new V1Metadata.IndexedDataFile(schema.getField(\"data_file\").schema());\n+    this.status = toCopy.status;\n+    this.snapshotId = toCopy.snapshotId;\n+    if (fullCopy) {\n+      this.file = toCopy.file().copy();\n+    } else {\n+      this.file = toCopy.file().copyWithoutStats();\n+    }\n+  }\n+\n+  ManifestEntry wrapExisting(Long newSnapshotId, Long newSequenceNumber, DataFile newFile) {\n+    this.status = Status.EXISTING;\n+    this.snapshotId = newSnapshotId;\n+    this.sequenceNumber = newSequenceNumber;\n+    this.file = newFile;\n+    return this;\n+  }\n+\n+  ManifestEntry wrapAppend(Long newSnapshotId, DataFile newFile) {\n+    this.status = Status.ADDED;\n+    this.snapshotId = newSnapshotId;\n+    this.sequenceNumber = null;\n+    this.file = newFile;\n+    return this;\n+  }\n+\n+  ManifestEntry wrapDelete(Long newSnapshotId, DataFile newFile) {\n+    this.status = Status.DELETED;\n+    this.snapshotId = newSnapshotId;\n+    this.sequenceNumber = null;\n+    this.file = newFile;\n+    return this;\n+  }\n+\n+  /**\n+   * @return the status of the file, whether EXISTING, ADDED, or DELETED\n+   */\n+  public Status status() {\n+    return status;\n+  }\n+\n+  /**\n+   * @return id of the snapshot in which the file was added to the table\n+   */\n+  public Long snapshotId() {\n+    return snapshotId;\n+  }\n+\n+  @Override\n+  public Long sequenceNumber() {\n+    return sequenceNumber;\n+  }\n+\n+  /**\n+   * @return a file\n+   */\n+  public DataFile file() {\n+    return file;\n+  }\n+\n+  public ManifestEntry copy() {\n+    return new GenericManifestEntry(this, true /* full copy */);\n+  }\n+\n+  public ManifestEntry copyWithoutStats() {\n+    return new GenericManifestEntry(this, false /* drop stats */);\n+  }\n+\n+  @Override\n+  public void setSnapshotId(long newSnapshotId) {\n+    this.snapshotId = newSnapshotId;\n+  }\n+\n+  @Override\n+  public void setSequenceNumber(long newSequenceNumber) {\n+    this.sequenceNumber = newSequenceNumber;\n+  }\n+\n+  @Override\n+  public void put(int i, Object v) {\n+    switch (i) {\n+      case 0:\n+        this.status = Status.values()[(Integer) v];\n+        return;\n+      case 1:\n+        this.snapshotId = (Long) v;\n+        return;\n+      case 2:\n+        this.sequenceNumber = (Long) v;\n+        return;\n+      case 3:\n+        this.file = (DataFile) v;\n+        return;\n+      default:\n+        // ignore the object, it must be from a newer version of the format\n+    }\n+  }\n+\n+  @Override\n+  public Object get(int i) {\n+    switch (i) {\n+      case 0:\n+        return status.id();\n+      case 1:\n+        return snapshotId;\n+      case 2:\n+        return sequenceNumber;\n+      case 3:\n+        if (fileWrapper == null || file instanceof GenericDataFile) {\n+          return file;\n+        } else {\n+          return fileWrapper.wrap(file);\n+        }\n+      default:\n+        throw new UnsupportedOperationException(\"Unknown field ordinal: \" + i);\n+    }\n+  }\n+\n+  @Override\n+  public org.apache.avro.Schema getSchema() {\n+    return schema;\n+  }\n+\n+  @Override\n+  public String toString() {\n+    return MoreObjects.toStringHelper(this)\n+        .add(\"status\", status)\n+        .add(\"snapshot_id\", snapshotId)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzI5NzU5OQ=="}, "originalCommit": {"oid": "eaf78717b94097030098c790d7db74f231440408"}, "originalPosition": 175}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyODM5NjY0OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/org/apache/iceberg/GenericManifestEntry.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xM1QwMzoxNzoyOVrOGEbgYQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xM1QxNjozOTozOVrOGEsiFA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzI5ODE0NQ==", "bodyText": "The append/delete operations won't attach the sequence number to its entries ?", "url": "https://github.com/apache/iceberg/pull/913#discussion_r407298145", "createdAt": "2020-04-13T03:17:29Z", "author": {"login": "openinx"}, "path": "core/src/main/java/org/apache/iceberg/GenericManifestEntry.java", "diffHunk": "@@ -0,0 +1,179 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg;\n+\n+import com.google.common.base.MoreObjects;\n+import org.apache.avro.generic.IndexedRecord;\n+import org.apache.avro.specific.SpecificData;\n+import org.apache.iceberg.avro.AvroSchemaUtil;\n+import org.apache.iceberg.types.Types;\n+\n+class GenericManifestEntry implements ManifestEntry, IndexedRecord, SpecificData.SchemaConstructable {\n+  private final org.apache.avro.Schema schema;\n+  private final V1Metadata.IndexedDataFile fileWrapper;\n+  private Status status = Status.EXISTING;\n+  private Long snapshotId = null;\n+  private Long sequenceNumber = null;\n+  private DataFile file = null;\n+\n+  GenericManifestEntry(org.apache.avro.Schema schema) {\n+    this.schema = schema;\n+    this.fileWrapper = null; // do not use the file wrapper to read\n+  }\n+\n+  GenericManifestEntry(Types.StructType partitionType) {\n+    this.schema = AvroSchemaUtil.convert(V1Metadata.entrySchema(partitionType), \"manifest_entry\");\n+    this.fileWrapper = new V1Metadata.IndexedDataFile(schema.getField(\"data_file\").schema());\n+  }\n+\n+  private GenericManifestEntry(GenericManifestEntry toCopy, boolean fullCopy) {\n+    this.schema = toCopy.schema;\n+    this.fileWrapper = new V1Metadata.IndexedDataFile(schema.getField(\"data_file\").schema());\n+    this.status = toCopy.status;\n+    this.snapshotId = toCopy.snapshotId;\n+    if (fullCopy) {\n+      this.file = toCopy.file().copy();\n+    } else {\n+      this.file = toCopy.file().copyWithoutStats();\n+    }\n+  }\n+\n+  ManifestEntry wrapExisting(Long newSnapshotId, Long newSequenceNumber, DataFile newFile) {\n+    this.status = Status.EXISTING;\n+    this.snapshotId = newSnapshotId;\n+    this.sequenceNumber = newSequenceNumber;\n+    this.file = newFile;\n+    return this;\n+  }\n+\n+  ManifestEntry wrapAppend(Long newSnapshotId, DataFile newFile) {\n+    this.status = Status.ADDED;\n+    this.snapshotId = newSnapshotId;\n+    this.sequenceNumber = null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eaf78717b94097030098c790d7db74f231440408"}, "originalPosition": 69}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzU3NzEwOA==", "bodyText": "When a file is appended, it must have the sequence number of the snapshot where it is committed. The problem is that the sequence number isn't determined until the snapshot's commit is successful. Two committers may be racing to add a commit with the same sequence number.\nThat's why sequence numbers are assigned initially through inheritance. Every snapshot commit attempt writes a new root manifest list with a new sequence number based on the table metadata's last sequence number. If two writers are trying to commit different snapshots as sequence number 5, one will win and the other will retry with 6. To avoid rewriting the metadata tree below the manifest list, sequence numbers that might change are inherited instead of written into the initial files.", "url": "https://github.com/apache/iceberg/pull/913#discussion_r407577108", "createdAt": "2020-04-13T16:39:39Z", "author": {"login": "rdblue"}, "path": "core/src/main/java/org/apache/iceberg/GenericManifestEntry.java", "diffHunk": "@@ -0,0 +1,179 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg;\n+\n+import com.google.common.base.MoreObjects;\n+import org.apache.avro.generic.IndexedRecord;\n+import org.apache.avro.specific.SpecificData;\n+import org.apache.iceberg.avro.AvroSchemaUtil;\n+import org.apache.iceberg.types.Types;\n+\n+class GenericManifestEntry implements ManifestEntry, IndexedRecord, SpecificData.SchemaConstructable {\n+  private final org.apache.avro.Schema schema;\n+  private final V1Metadata.IndexedDataFile fileWrapper;\n+  private Status status = Status.EXISTING;\n+  private Long snapshotId = null;\n+  private Long sequenceNumber = null;\n+  private DataFile file = null;\n+\n+  GenericManifestEntry(org.apache.avro.Schema schema) {\n+    this.schema = schema;\n+    this.fileWrapper = null; // do not use the file wrapper to read\n+  }\n+\n+  GenericManifestEntry(Types.StructType partitionType) {\n+    this.schema = AvroSchemaUtil.convert(V1Metadata.entrySchema(partitionType), \"manifest_entry\");\n+    this.fileWrapper = new V1Metadata.IndexedDataFile(schema.getField(\"data_file\").schema());\n+  }\n+\n+  private GenericManifestEntry(GenericManifestEntry toCopy, boolean fullCopy) {\n+    this.schema = toCopy.schema;\n+    this.fileWrapper = new V1Metadata.IndexedDataFile(schema.getField(\"data_file\").schema());\n+    this.status = toCopy.status;\n+    this.snapshotId = toCopy.snapshotId;\n+    if (fullCopy) {\n+      this.file = toCopy.file().copy();\n+    } else {\n+      this.file = toCopy.file().copyWithoutStats();\n+    }\n+  }\n+\n+  ManifestEntry wrapExisting(Long newSnapshotId, Long newSequenceNumber, DataFile newFile) {\n+    this.status = Status.EXISTING;\n+    this.snapshotId = newSnapshotId;\n+    this.sequenceNumber = newSequenceNumber;\n+    this.file = newFile;\n+    return this;\n+  }\n+\n+  ManifestEntry wrapAppend(Long newSnapshotId, DataFile newFile) {\n+    this.status = Status.ADDED;\n+    this.snapshotId = newSnapshotId;\n+    this.sequenceNumber = null;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzI5ODE0NQ=="}, "originalCommit": {"oid": "eaf78717b94097030098c790d7db74f231440408"}, "originalPosition": 69}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyODQwMzA1OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/org/apache/iceberg/GenericManifestFile.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xM1QwMzoyMzowMlrOGEbkKw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xM1QxNjo0MTowMFrOGEsk1g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzI5OTExNQ==", "bodyText": "Here we're changing the position of snapshotId/addedFilesCount/ ... etc,   will it break the compatibility ?  I mean the new code couldn't read the old data manifest file ...", "url": "https://github.com/apache/iceberg/pull/913#discussion_r407299115", "createdAt": "2020-04-13T03:23:02Z", "author": {"login": "openinx"}, "path": "core/src/main/java/org/apache/iceberg/GenericManifestFile.java", "diffHunk": "@@ -257,21 +255,25 @@ public Object get(int i) {\n       case 2:\n         return specId;\n       case 3:\n-        return snapshotId;\n+        return sequenceNumber;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eaf78717b94097030098c790d7db74f231440408"}, "originalPosition": 106}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzU3NzgxNA==", "bodyText": "Changing the order won't break compatibility. The requirement here is that the order of fields in these classes must match the order of fields in the schema. That's why this commit freezes the v1 schema and an IndexedWriter for v1. That way, we can write exactly what we would have before for v1, but make changes for v2.", "url": "https://github.com/apache/iceberg/pull/913#discussion_r407577814", "createdAt": "2020-04-13T16:41:00Z", "author": {"login": "rdblue"}, "path": "core/src/main/java/org/apache/iceberg/GenericManifestFile.java", "diffHunk": "@@ -257,21 +255,25 @@ public Object get(int i) {\n       case 2:\n         return specId;\n       case 3:\n-        return snapshotId;\n+        return sequenceNumber;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzI5OTExNQ=="}, "originalCommit": {"oid": "eaf78717b94097030098c790d7db74f231440408"}, "originalPosition": 106}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyODczOTYyOnYy", "diffSide": "RIGHT", "path": "core/src/main/java/org/apache/iceberg/InheritableMetadataFactory.java", "isResolved": false, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xM1QwNzowMDo0NFrOGEekVw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQyMTowMzozOFrOGInmvQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzM0ODMxMQ==", "bodyText": "I'm not sure in which case we will encounter the snapshot == null, mind to explain the case ? Thanks.", "url": "https://github.com/apache/iceberg/pull/913#discussion_r407348311", "createdAt": "2020-04-13T07:00:44Z", "author": {"login": "openinx"}, "path": "core/src/main/java/org/apache/iceberg/InheritableMetadataFactory.java", "diffHunk": "@@ -30,22 +31,40 @@ static InheritableMetadata empty() {\n   }\n \n   static InheritableMetadata fromManifest(ManifestFile manifest) {\n-    return new BaseInheritableMetadata(manifest.snapshotId());\n+    if (manifest.snapshotId() != null) {\n+      return new BaseInheritableMetadata(manifest.snapshotId(), manifest.sequenceNumber());\n+    } else {\n+      return NOOP;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eaf78717b94097030098c790d7db74f231440408"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzU4MzM5Nw==", "bodyText": "Snapshot id is null when a manifest is appended to a table and the snapshot id hasn't been assigned yet.\nIf the manifest is committed to table metadata, then it will be set when writing and will always be present. That's why it is required in the v2 schema for manifest list files.\nSome appended manifests are rewritten before committing. When reading those to rewrite them, this path is used.\nI think I'm going to update how this works, but as a separate commit. The problem is that this allows reading a manifest without filling in the snapshot id. But the rewrite method where the reader that is configured this was is used has the snapshot id. So we should add the snapshot id to the ManifestFile and then read to avoid the special case.", "url": "https://github.com/apache/iceberg/pull/913#discussion_r407583397", "createdAt": "2020-04-13T16:51:05Z", "author": {"login": "rdblue"}, "path": "core/src/main/java/org/apache/iceberg/InheritableMetadataFactory.java", "diffHunk": "@@ -30,22 +31,40 @@ static InheritableMetadata empty() {\n   }\n \n   static InheritableMetadata fromManifest(ManifestFile manifest) {\n-    return new BaseInheritableMetadata(manifest.snapshotId());\n+    if (manifest.snapshotId() != null) {\n+      return new BaseInheritableMetadata(manifest.snapshotId(), manifest.sequenceNumber());\n+    } else {\n+      return NOOP;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzM0ODMxMQ=="}, "originalCommit": {"oid": "eaf78717b94097030098c790d7db74f231440408"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTU2OTUxNw==", "bodyText": "A couple of questions here:\n\nNow added_snapshot_id is optional. Do we plan to make it required once we start assigning the snapshot in ManifestListWriter?\nWe cannot actually remove InheritableMetadata as there might be old manifests where added_snapshot_id is null, correct?", "url": "https://github.com/apache/iceberg/pull/913#discussion_r411569517", "createdAt": "2020-04-20T17:44:12Z", "author": {"login": "aokolnychyi"}, "path": "core/src/main/java/org/apache/iceberg/InheritableMetadataFactory.java", "diffHunk": "@@ -30,22 +31,40 @@ static InheritableMetadata empty() {\n   }\n \n   static InheritableMetadata fromManifest(ManifestFile manifest) {\n-    return new BaseInheritableMetadata(manifest.snapshotId());\n+    if (manifest.snapshotId() != null) {\n+      return new BaseInheritableMetadata(manifest.snapshotId(), manifest.sequenceNumber());\n+    } else {\n+      return NOOP;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzM0ODMxMQ=="}, "originalCommit": {"oid": "eaf78717b94097030098c790d7db74f231440408"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTYzOTI5MQ==", "bodyText": "added_snapshot_id is optional because we used to store manifests as a list in the metadata.json file. V2 changes it to required because we always write a manifest-list with the inherited snapshot id and sequence number.\nMy comment about changing this wasn't about removing InheritableMetadata. It was about the path that rewrites the manifest and uses the no-op InheritableMetadata. I think that we can simplify this by making sure we set the snapshot ID on the ManifestFile before rewriting. That way any rewrite has the snapshot ID and we don't need a special case here.", "url": "https://github.com/apache/iceberg/pull/913#discussion_r411639291", "createdAt": "2020-04-20T19:37:31Z", "author": {"login": "rdblue"}, "path": "core/src/main/java/org/apache/iceberg/InheritableMetadataFactory.java", "diffHunk": "@@ -30,22 +31,40 @@ static InheritableMetadata empty() {\n   }\n \n   static InheritableMetadata fromManifest(ManifestFile manifest) {\n-    return new BaseInheritableMetadata(manifest.snapshotId());\n+    if (manifest.snapshotId() != null) {\n+      return new BaseInheritableMetadata(manifest.snapshotId(), manifest.sequenceNumber());\n+    } else {\n+      return NOOP;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzM0ODMxMQ=="}, "originalCommit": {"oid": "eaf78717b94097030098c790d7db74f231440408"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTY1MDE2Ng==", "bodyText": "I asked about InheritableMetadata as I wondered myself whether we can remove that completely. Seems not.\nYeah, I like the idea of setting the snapshot id in ManifestFile before rewriting.", "url": "https://github.com/apache/iceberg/pull/913#discussion_r411650166", "createdAt": "2020-04-20T19:55:46Z", "author": {"login": "aokolnychyi"}, "path": "core/src/main/java/org/apache/iceberg/InheritableMetadataFactory.java", "diffHunk": "@@ -30,22 +31,40 @@ static InheritableMetadata empty() {\n   }\n \n   static InheritableMetadata fromManifest(ManifestFile manifest) {\n-    return new BaseInheritableMetadata(manifest.snapshotId());\n+    if (manifest.snapshotId() != null) {\n+      return new BaseInheritableMetadata(manifest.snapshotId(), manifest.sequenceNumber());\n+    } else {\n+      return NOOP;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzM0ODMxMQ=="}, "originalCommit": {"oid": "eaf78717b94097030098c790d7db74f231440408"}, "originalPosition": 16}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTY5MDY4NQ==", "bodyText": "I'll look into removing it entirely, although I don't mind it very much. As long as it is baked into the reader and unavoidable, it seems like a clean way to apply the inherited values.", "url": "https://github.com/apache/iceberg/pull/913#discussion_r411690685", "createdAt": "2020-04-20T21:03:38Z", "author": {"login": "rdblue"}, "path": "core/src/main/java/org/apache/iceberg/InheritableMetadataFactory.java", "diffHunk": "@@ -30,22 +31,40 @@ static InheritableMetadata empty() {\n   }\n \n   static InheritableMetadata fromManifest(ManifestFile manifest) {\n-    return new BaseInheritableMetadata(manifest.snapshotId());\n+    if (manifest.snapshotId() != null) {\n+      return new BaseInheritableMetadata(manifest.snapshotId(), manifest.sequenceNumber());\n+    } else {\n+      return NOOP;", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzM0ODMxMQ=="}, "originalCommit": {"oid": "eaf78717b94097030098c790d7db74f231440408"}, "originalPosition": 16}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUyODc3NjE3OnYy", "diffSide": "RIGHT", "path": "api/src/main/java/org/apache/iceberg/ManifestFile.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xM1QwNzoxODo1NFrOGEe5dw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xM1QxNjo1NTozM1rOGEtEKw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzM1MzcxOQ==", "bodyText": "Why need to define this min sequence number ?  for manifest file filtering purpose in read path ?", "url": "https://github.com/apache/iceberg/pull/913#discussion_r407353719", "createdAt": "2020-04-13T07:18:54Z", "author": {"login": "openinx"}, "path": "api/src/main/java/org/apache/iceberg/ManifestFile.java", "diffHunk": "@@ -66,6 +77,16 @@ static Schema schema() {\n    */\n   int partitionSpecId();\n \n+  /**\n+   * @return the sequence number of the commit that added the manifest file\n+   */\n+  long sequenceNumber();\n+\n+  /**\n+   * @return the lowest sequence number of any data file in the manifest\n+   */\n+  long minSequenceNumber();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eaf78717b94097030098c790d7db74f231440408"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzU4NTgzNQ==", "bodyText": "This is additional information for job planning and metadata maintenance.\nThis may change, but the initial idea is that if we have the min sequence number of a manifest, we can use that to filter other manifests for planning. For example, if I have a manifest with delete files that was written at sequence number 14, but only manifests with data files written at sequence number 16 and later, I can ignore the manifest with delete files.\nWe can do something similar when maintaining metadata. If we detect that a delete file is older than all data files then we can remove it.", "url": "https://github.com/apache/iceberg/pull/913#discussion_r407585835", "createdAt": "2020-04-13T16:55:33Z", "author": {"login": "rdblue"}, "path": "api/src/main/java/org/apache/iceberg/ManifestFile.java", "diffHunk": "@@ -66,6 +77,16 @@ static Schema schema() {\n    */\n   int partitionSpecId();\n \n+  /**\n+   * @return the sequence number of the commit that added the manifest file\n+   */\n+  long sequenceNumber();\n+\n+  /**\n+   * @return the lowest sequence number of any data file in the manifest\n+   */\n+  long minSequenceNumber();", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzM1MzcxOQ=="}, "originalCommit": {"oid": "eaf78717b94097030098c790d7db74f231440408"}, "originalPosition": 61}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzMjcyODU2OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/org/apache/iceberg/ManifestLists.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwODozNjoxOFrOGFEBcg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwMTo1MzoyOFrOGFm_XQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzk2MTk3MA==", "bodyText": "I don't see other places call this except a unit test. This may be misused, how about removing it?", "url": "https://github.com/apache/iceberg/pull/913#discussion_r407961970", "createdAt": "2020-04-14T08:36:18Z", "author": {"login": "chenjunjiedada"}, "path": "core/src/main/java/org/apache/iceberg/ManifestLists.java", "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import java.io.IOException;\n+import java.util.List;\n+import org.apache.iceberg.avro.Avro;\n+import org.apache.iceberg.exceptions.RuntimeIOException;\n+import org.apache.iceberg.io.CloseableIterable;\n+import org.apache.iceberg.io.InputFile;\n+import org.apache.iceberg.io.OutputFile;\n+\n+class ManifestLists {\n+  private ManifestLists() {\n+  }\n+\n+  static List<ManifestFile> read(InputFile manifestList) {\n+    try (CloseableIterable<ManifestFile> files = Avro.read(manifestList)\n+        .rename(\"manifest_file\", GenericManifestFile.class.getName())\n+        .rename(\"partitions\", GenericPartitionFieldSummary.class.getName())\n+        .rename(\"r508\", GenericPartitionFieldSummary.class.getName())\n+        .classLoader(GenericManifestFile.class.getClassLoader())\n+        .project(ManifestFile.schema())\n+        .reuseContainers(false)\n+        .build()) {\n+\n+      return Lists.newLinkedList(files);\n+\n+    } catch (IOException e) {\n+      throw new RuntimeIOException(e, \"Cannot read manifest list file: %s\", manifestList.location());\n+    }\n+  }\n+\n+  static ManifestListWriter write(int formatVersion, OutputFile manifestListFile,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eaf78717b94097030098c790d7db74f231440408"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODI3MjIwMQ==", "bodyText": "Yeah, we probably will.", "url": "https://github.com/apache/iceberg/pull/913#discussion_r408272201", "createdAt": "2020-04-14T16:28:33Z", "author": {"login": "rdblue"}, "path": "core/src/main/java/org/apache/iceberg/ManifestLists.java", "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import java.io.IOException;\n+import java.util.List;\n+import org.apache.iceberg.avro.Avro;\n+import org.apache.iceberg.exceptions.RuntimeIOException;\n+import org.apache.iceberg.io.CloseableIterable;\n+import org.apache.iceberg.io.InputFile;\n+import org.apache.iceberg.io.OutputFile;\n+\n+class ManifestLists {\n+  private ManifestLists() {\n+  }\n+\n+  static List<ManifestFile> read(InputFile manifestList) {\n+    try (CloseableIterable<ManifestFile> files = Avro.read(manifestList)\n+        .rename(\"manifest_file\", GenericManifestFile.class.getName())\n+        .rename(\"partitions\", GenericPartitionFieldSummary.class.getName())\n+        .rename(\"r508\", GenericPartitionFieldSummary.class.getName())\n+        .classLoader(GenericManifestFile.class.getClassLoader())\n+        .project(ManifestFile.schema())\n+        .reuseContainers(false)\n+        .build()) {\n+\n+      return Lists.newLinkedList(files);\n+\n+    } catch (IOException e) {\n+      throw new RuntimeIOException(e, \"Cannot read manifest list file: %s\", manifestList.location());\n+    }\n+  }\n+\n+  static ManifestListWriter write(int formatVersion, OutputFile manifestListFile,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzk2MTk3MA=="}, "originalCommit": {"oid": "eaf78717b94097030098c790d7db74f231440408"}, "originalPosition": 53}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODUzNDg3Nw==", "bodyText": "Opened #921 to remove this.", "url": "https://github.com/apache/iceberg/pull/913#discussion_r408534877", "createdAt": "2020-04-15T01:53:28Z", "author": {"login": "rdblue"}, "path": "core/src/main/java/org/apache/iceberg/ManifestLists.java", "diffHunk": "@@ -0,0 +1,73 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import java.io.IOException;\n+import java.util.List;\n+import org.apache.iceberg.avro.Avro;\n+import org.apache.iceberg.exceptions.RuntimeIOException;\n+import org.apache.iceberg.io.CloseableIterable;\n+import org.apache.iceberg.io.InputFile;\n+import org.apache.iceberg.io.OutputFile;\n+\n+class ManifestLists {\n+  private ManifestLists() {\n+  }\n+\n+  static List<ManifestFile> read(InputFile manifestList) {\n+    try (CloseableIterable<ManifestFile> files = Avro.read(manifestList)\n+        .rename(\"manifest_file\", GenericManifestFile.class.getName())\n+        .rename(\"partitions\", GenericPartitionFieldSummary.class.getName())\n+        .rename(\"r508\", GenericPartitionFieldSummary.class.getName())\n+        .classLoader(GenericManifestFile.class.getClassLoader())\n+        .project(ManifestFile.schema())\n+        .reuseContainers(false)\n+        .build()) {\n+\n+      return Lists.newLinkedList(files);\n+\n+    } catch (IOException e) {\n+      throw new RuntimeIOException(e, \"Cannot read manifest list file: %s\", manifestList.location());\n+    }\n+  }\n+\n+  static ManifestListWriter write(int formatVersion, OutputFile manifestListFile,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzk2MTk3MA=="}, "originalCommit": {"oid": "eaf78717b94097030098c790d7db74f231440408"}, "originalPosition": 53}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzMjczMDYxOnYy", "diffSide": "RIGHT", "path": "core/src/main/java/org/apache/iceberg/ManifestFiles.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwODozNjo0N1rOGFECtw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwMTo1MToyMlrOGFm9Jw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzk2MjI5NQ==", "bodyText": "The document is duplicated with the one in ManifestWriter.write. We can remove this function definition and just call from there.", "url": "https://github.com/apache/iceberg/pull/913#discussion_r407962295", "createdAt": "2020-04-14T08:36:47Z", "author": {"login": "chenjunjiedada"}, "path": "core/src/main/java/org/apache/iceberg/ManifestFiles.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg;\n+\n+import com.google.common.base.Preconditions;\n+import java.util.Map;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.io.InputFile;\n+import org.apache.iceberg.io.OutputFile;\n+\n+public class ManifestFiles {\n+  private ManifestFiles() {\n+  }\n+\n+  /**\n+   * Returns a new {@link ManifestReader} for a {@link ManifestFile}.\n+   * <p>\n+   * <em>Note:</em> Callers should use {@link ManifestFiles#read(ManifestFile, FileIO, Map)} to ensure\n+   * the schema used by filters is the latest table schema. This should be used only when reading\n+   * a manifest without filters.\n+   *\n+   * @param manifest a ManifestFile\n+   * @param io a FileIO\n+   * @return a manifest reader\n+   */\n+  public static ManifestReader read(ManifestFile manifest, FileIO io) {\n+    return read(manifest, io, null);\n+  }\n+\n+  /**\n+   * Returns a new {@link ManifestReader} for a {@link ManifestFile}.\n+   *\n+   * @param manifest a {@link ManifestFile}\n+   * @param io a {@link FileIO}\n+   * @param specsById a Map from spec ID to partition spec\n+   * @return a {@link ManifestReader}\n+   */\n+  public static ManifestReader read(ManifestFile manifest, FileIO io, Map<Integer, PartitionSpec> specsById) {\n+    InputFile file = io.newInputFile(manifest.path());\n+    InheritableMetadata inheritableMetadata = InheritableMetadataFactory.fromManifest(manifest);\n+    return new ManifestReader(file, specsById, inheritableMetadata);\n+  }\n+\n+  /**\n+   * Create a new {@link ManifestWriter}.\n+   * <p>\n+   * Manifests created by this writer have all entry snapshot IDs set to null.\n+   * All entries will inherit the snapshot ID that will be assigned to the manifest on commit.\n+   *\n+   * @param spec {@link PartitionSpec} used to produce {@link DataFile} partition tuples\n+   * @param outputFile the destination file location\n+   * @return a manifest writer\n+   */\n+  public static ManifestWriter write(PartitionSpec spec, OutputFile outputFile) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eaf78717b94097030098c790d7db74f231440408"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODI3MTEyMg==", "bodyText": "The one in ManifestWriter was released in version 0.7 so we don't want to remove it from the public API without a period of deprecation. However, we do want to move the factory methods here.", "url": "https://github.com/apache/iceberg/pull/913#discussion_r408271122", "createdAt": "2020-04-14T16:27:02Z", "author": {"login": "rdblue"}, "path": "core/src/main/java/org/apache/iceberg/ManifestFiles.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg;\n+\n+import com.google.common.base.Preconditions;\n+import java.util.Map;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.io.InputFile;\n+import org.apache.iceberg.io.OutputFile;\n+\n+public class ManifestFiles {\n+  private ManifestFiles() {\n+  }\n+\n+  /**\n+   * Returns a new {@link ManifestReader} for a {@link ManifestFile}.\n+   * <p>\n+   * <em>Note:</em> Callers should use {@link ManifestFiles#read(ManifestFile, FileIO, Map)} to ensure\n+   * the schema used by filters is the latest table schema. This should be used only when reading\n+   * a manifest without filters.\n+   *\n+   * @param manifest a ManifestFile\n+   * @param io a FileIO\n+   * @return a manifest reader\n+   */\n+  public static ManifestReader read(ManifestFile manifest, FileIO io) {\n+    return read(manifest, io, null);\n+  }\n+\n+  /**\n+   * Returns a new {@link ManifestReader} for a {@link ManifestFile}.\n+   *\n+   * @param manifest a {@link ManifestFile}\n+   * @param io a {@link FileIO}\n+   * @param specsById a Map from spec ID to partition spec\n+   * @return a {@link ManifestReader}\n+   */\n+  public static ManifestReader read(ManifestFile manifest, FileIO io, Map<Integer, PartitionSpec> specsById) {\n+    InputFile file = io.newInputFile(manifest.path());\n+    InheritableMetadata inheritableMetadata = InheritableMetadataFactory.fromManifest(manifest);\n+    return new ManifestReader(file, specsById, inheritableMetadata);\n+  }\n+\n+  /**\n+   * Create a new {@link ManifestWriter}.\n+   * <p>\n+   * Manifests created by this writer have all entry snapshot IDs set to null.\n+   * All entries will inherit the snapshot ID that will be assigned to the manifest on commit.\n+   *\n+   * @param spec {@link PartitionSpec} used to produce {@link DataFile} partition tuples\n+   * @param outputFile the destination file location\n+   * @return a manifest writer\n+   */\n+  public static ManifestWriter write(PartitionSpec spec, OutputFile outputFile) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzk2MjI5NQ=="}, "originalCommit": {"oid": "eaf78717b94097030098c790d7db74f231440408"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODUzNDMxMQ==", "bodyText": "I see, thanks for the explanation.", "url": "https://github.com/apache/iceberg/pull/913#discussion_r408534311", "createdAt": "2020-04-15T01:51:22Z", "author": {"login": "chenjunjiedada"}, "path": "core/src/main/java/org/apache/iceberg/ManifestFiles.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg;\n+\n+import com.google.common.base.Preconditions;\n+import java.util.Map;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.io.InputFile;\n+import org.apache.iceberg.io.OutputFile;\n+\n+public class ManifestFiles {\n+  private ManifestFiles() {\n+  }\n+\n+  /**\n+   * Returns a new {@link ManifestReader} for a {@link ManifestFile}.\n+   * <p>\n+   * <em>Note:</em> Callers should use {@link ManifestFiles#read(ManifestFile, FileIO, Map)} to ensure\n+   * the schema used by filters is the latest table schema. This should be used only when reading\n+   * a manifest without filters.\n+   *\n+   * @param manifest a ManifestFile\n+   * @param io a FileIO\n+   * @return a manifest reader\n+   */\n+  public static ManifestReader read(ManifestFile manifest, FileIO io) {\n+    return read(manifest, io, null);\n+  }\n+\n+  /**\n+   * Returns a new {@link ManifestReader} for a {@link ManifestFile}.\n+   *\n+   * @param manifest a {@link ManifestFile}\n+   * @param io a {@link FileIO}\n+   * @param specsById a Map from spec ID to partition spec\n+   * @return a {@link ManifestReader}\n+   */\n+  public static ManifestReader read(ManifestFile manifest, FileIO io, Map<Integer, PartitionSpec> specsById) {\n+    InputFile file = io.newInputFile(manifest.path());\n+    InheritableMetadata inheritableMetadata = InheritableMetadataFactory.fromManifest(manifest);\n+    return new ManifestReader(file, specsById, inheritableMetadata);\n+  }\n+\n+  /**\n+   * Create a new {@link ManifestWriter}.\n+   * <p>\n+   * Manifests created by this writer have all entry snapshot IDs set to null.\n+   * All entries will inherit the snapshot ID that will be assigned to the manifest on commit.\n+   *\n+   * @param spec {@link PartitionSpec} used to produce {@link DataFile} partition tuples\n+   * @param outputFile the destination file location\n+   * @return a manifest writer\n+   */\n+  public static ManifestWriter write(PartitionSpec spec, OutputFile outputFile) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzk2MjI5NQ=="}, "originalCommit": {"oid": "eaf78717b94097030098c790d7db74f231440408"}, "originalPosition": 71}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzMjgwNDExOnYy", "diffSide": "RIGHT", "path": "core/src/main/java/org/apache/iceberg/V2Metadata.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwODo1NDo1MFrOGFEvZw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwMTo1MjoxN1rOGFm-Eg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzk3MzczNQ==", "bodyText": "Does this mean that a manifest file with a new snapshot id must have a sequence number?  Maybe add a more detailed reason in the exception message for this.", "url": "https://github.com/apache/iceberg/pull/913#discussion_r407973735", "createdAt": "2020-04-14T08:54:50Z", "author": {"login": "chenjunjiedada"}, "path": "core/src/main/java/org/apache/iceberg/V2Metadata.java", "diffHunk": "@@ -0,0 +1,321 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg;\n+\n+import com.google.common.base.Preconditions;\n+import java.util.List;\n+import org.apache.avro.generic.IndexedRecord;\n+import org.apache.iceberg.avro.AvroSchemaUtil;\n+import org.apache.iceberg.types.Types;\n+\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+class V2Metadata {\n+  private V2Metadata() {\n+  }\n+\n+  // fields for v2 write schema for required metadata\n+  static final Types.NestedField REQUIRED_SNAPSHOT_ID =\n+      required(503, \"added_snapshot_id\", Types.LongType.get());\n+  static final Types.NestedField REQUIRED_ADDED_FILES_COUNT =\n+      required(504, \"added_data_files_count\", Types.IntegerType.get());\n+  static final Types.NestedField REQUIRED_EXISTING_FILES_COUNT =\n+      required(505, \"existing_data_files_count\", Types.IntegerType.get());\n+  static final Types.NestedField REQUIRED_DELETED_FILES_COUNT =\n+      required(506, \"deleted_data_files_count\", Types.IntegerType.get());\n+  static final Types.NestedField REQUIRED_ADDED_ROWS_COUNT =\n+      required(512, \"added_rows_count\", Types.LongType.get());\n+  static final Types.NestedField REQUIRED_EXISTING_ROWS_COUNT =\n+      required(513, \"existing_rows_count\", Types.LongType.get());\n+  static final Types.NestedField REQUIRED_DELETED_ROWS_COUNT =\n+      required(514, \"deleted_rows_count\", Types.LongType.get());\n+  static final Types.NestedField REQUIRED_SEQUENCE_NUMBER =\n+      required(515, \"sequence_number\", Types.LongType.get());\n+  static final Types.NestedField REQUIRED_MIN_SEQUENCE_NUMBER =\n+      required(516, \"min_sequence_number\", Types.LongType.get());\n+\n+  static final Schema MANIFEST_LIST_SCHEMA = new Schema(\n+      ManifestFile.PATH, ManifestFile.LENGTH, ManifestFile.SPEC_ID,\n+      REQUIRED_SEQUENCE_NUMBER, REQUIRED_MIN_SEQUENCE_NUMBER, REQUIRED_SNAPSHOT_ID,\n+      REQUIRED_ADDED_FILES_COUNT, REQUIRED_EXISTING_FILES_COUNT, REQUIRED_DELETED_FILES_COUNT,\n+      REQUIRED_ADDED_ROWS_COUNT, REQUIRED_EXISTING_ROWS_COUNT, REQUIRED_DELETED_ROWS_COUNT,\n+      ManifestFile.PARTITION_SUMMARIES);\n+\n+\n+  /**\n+   * A wrapper class to write any ManifestFile implementation to Avro using the v2 write schema.\n+   *\n+   * This is used to maintain compatibility with v2 by writing manifest list files with the old schema, instead of\n+   * writing a sequence number into metadata files in v2 tables.\n+   */\n+  static class IndexedManifestFile implements ManifestFile, IndexedRecord {\n+    private static final org.apache.avro.Schema AVRO_SCHEMA =\n+        AvroSchemaUtil.convert(MANIFEST_LIST_SCHEMA, \"manifest_file\");\n+\n+    private final long snapshotId;\n+    private final long sequenceNumber;\n+    private ManifestFile wrapped = null;\n+\n+    IndexedManifestFile(long snapshotId, long sequenceNumber) {\n+      this.snapshotId = snapshotId;\n+      this.sequenceNumber = sequenceNumber;\n+    }\n+\n+    public ManifestFile wrap(ManifestFile file) {\n+      this.wrapped = file;\n+      return this;\n+    }\n+\n+    @Override\n+    public org.apache.avro.Schema getSchema() {\n+      return AVRO_SCHEMA;\n+    }\n+\n+    @Override\n+    public void put(int i, Object v) {\n+      throw new UnsupportedOperationException(\"Cannot read using IndexedManifestFile\");\n+    }\n+\n+    @Override\n+    public Object get(int pos) {\n+      switch (pos) {\n+        case 0:\n+          return wrapped.path();\n+        case 1:\n+          return wrapped.length();\n+        case 2:\n+          return wrapped.partitionSpecId();\n+        case 3:\n+          if (wrapped.sequenceNumber() == ManifestWriter.UNASSIGNED_SEQ) {\n+            Preconditions.checkState(snapshotId == wrapped.snapshotId(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eaf78717b94097030098c790d7db74f231440408"}, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODI3MzQzOQ==", "bodyText": "This validates that only new manifests created by the current snapshot will have the sequence number added on write.", "url": "https://github.com/apache/iceberg/pull/913#discussion_r408273439", "createdAt": "2020-04-14T16:30:13Z", "author": {"login": "rdblue"}, "path": "core/src/main/java/org/apache/iceberg/V2Metadata.java", "diffHunk": "@@ -0,0 +1,321 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg;\n+\n+import com.google.common.base.Preconditions;\n+import java.util.List;\n+import org.apache.avro.generic.IndexedRecord;\n+import org.apache.iceberg.avro.AvroSchemaUtil;\n+import org.apache.iceberg.types.Types;\n+\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+class V2Metadata {\n+  private V2Metadata() {\n+  }\n+\n+  // fields for v2 write schema for required metadata\n+  static final Types.NestedField REQUIRED_SNAPSHOT_ID =\n+      required(503, \"added_snapshot_id\", Types.LongType.get());\n+  static final Types.NestedField REQUIRED_ADDED_FILES_COUNT =\n+      required(504, \"added_data_files_count\", Types.IntegerType.get());\n+  static final Types.NestedField REQUIRED_EXISTING_FILES_COUNT =\n+      required(505, \"existing_data_files_count\", Types.IntegerType.get());\n+  static final Types.NestedField REQUIRED_DELETED_FILES_COUNT =\n+      required(506, \"deleted_data_files_count\", Types.IntegerType.get());\n+  static final Types.NestedField REQUIRED_ADDED_ROWS_COUNT =\n+      required(512, \"added_rows_count\", Types.LongType.get());\n+  static final Types.NestedField REQUIRED_EXISTING_ROWS_COUNT =\n+      required(513, \"existing_rows_count\", Types.LongType.get());\n+  static final Types.NestedField REQUIRED_DELETED_ROWS_COUNT =\n+      required(514, \"deleted_rows_count\", Types.LongType.get());\n+  static final Types.NestedField REQUIRED_SEQUENCE_NUMBER =\n+      required(515, \"sequence_number\", Types.LongType.get());\n+  static final Types.NestedField REQUIRED_MIN_SEQUENCE_NUMBER =\n+      required(516, \"min_sequence_number\", Types.LongType.get());\n+\n+  static final Schema MANIFEST_LIST_SCHEMA = new Schema(\n+      ManifestFile.PATH, ManifestFile.LENGTH, ManifestFile.SPEC_ID,\n+      REQUIRED_SEQUENCE_NUMBER, REQUIRED_MIN_SEQUENCE_NUMBER, REQUIRED_SNAPSHOT_ID,\n+      REQUIRED_ADDED_FILES_COUNT, REQUIRED_EXISTING_FILES_COUNT, REQUIRED_DELETED_FILES_COUNT,\n+      REQUIRED_ADDED_ROWS_COUNT, REQUIRED_EXISTING_ROWS_COUNT, REQUIRED_DELETED_ROWS_COUNT,\n+      ManifestFile.PARTITION_SUMMARIES);\n+\n+\n+  /**\n+   * A wrapper class to write any ManifestFile implementation to Avro using the v2 write schema.\n+   *\n+   * This is used to maintain compatibility with v2 by writing manifest list files with the old schema, instead of\n+   * writing a sequence number into metadata files in v2 tables.\n+   */\n+  static class IndexedManifestFile implements ManifestFile, IndexedRecord {\n+    private static final org.apache.avro.Schema AVRO_SCHEMA =\n+        AvroSchemaUtil.convert(MANIFEST_LIST_SCHEMA, \"manifest_file\");\n+\n+    private final long snapshotId;\n+    private final long sequenceNumber;\n+    private ManifestFile wrapped = null;\n+\n+    IndexedManifestFile(long snapshotId, long sequenceNumber) {\n+      this.snapshotId = snapshotId;\n+      this.sequenceNumber = sequenceNumber;\n+    }\n+\n+    public ManifestFile wrap(ManifestFile file) {\n+      this.wrapped = file;\n+      return this;\n+    }\n+\n+    @Override\n+    public org.apache.avro.Schema getSchema() {\n+      return AVRO_SCHEMA;\n+    }\n+\n+    @Override\n+    public void put(int i, Object v) {\n+      throw new UnsupportedOperationException(\"Cannot read using IndexedManifestFile\");\n+    }\n+\n+    @Override\n+    public Object get(int pos) {\n+      switch (pos) {\n+        case 0:\n+          return wrapped.path();\n+        case 1:\n+          return wrapped.length();\n+        case 2:\n+          return wrapped.partitionSpecId();\n+        case 3:\n+          if (wrapped.sequenceNumber() == ManifestWriter.UNASSIGNED_SEQ) {\n+            Preconditions.checkState(snapshotId == wrapped.snapshotId(),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzk3MzczNQ=="}, "originalCommit": {"oid": "eaf78717b94097030098c790d7db74f231440408"}, "originalPosition": 107}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODUzNDU0Ng==", "bodyText": "I added a better comment here.", "url": "https://github.com/apache/iceberg/pull/913#discussion_r408534546", "createdAt": "2020-04-15T01:52:17Z", "author": {"login": "rdblue"}, "path": "core/src/main/java/org/apache/iceberg/V2Metadata.java", "diffHunk": "@@ -0,0 +1,321 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg;\n+\n+import com.google.common.base.Preconditions;\n+import java.util.List;\n+import org.apache.avro.generic.IndexedRecord;\n+import org.apache.iceberg.avro.AvroSchemaUtil;\n+import org.apache.iceberg.types.Types;\n+\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+class V2Metadata {\n+  private V2Metadata() {\n+  }\n+\n+  // fields for v2 write schema for required metadata\n+  static final Types.NestedField REQUIRED_SNAPSHOT_ID =\n+      required(503, \"added_snapshot_id\", Types.LongType.get());\n+  static final Types.NestedField REQUIRED_ADDED_FILES_COUNT =\n+      required(504, \"added_data_files_count\", Types.IntegerType.get());\n+  static final Types.NestedField REQUIRED_EXISTING_FILES_COUNT =\n+      required(505, \"existing_data_files_count\", Types.IntegerType.get());\n+  static final Types.NestedField REQUIRED_DELETED_FILES_COUNT =\n+      required(506, \"deleted_data_files_count\", Types.IntegerType.get());\n+  static final Types.NestedField REQUIRED_ADDED_ROWS_COUNT =\n+      required(512, \"added_rows_count\", Types.LongType.get());\n+  static final Types.NestedField REQUIRED_EXISTING_ROWS_COUNT =\n+      required(513, \"existing_rows_count\", Types.LongType.get());\n+  static final Types.NestedField REQUIRED_DELETED_ROWS_COUNT =\n+      required(514, \"deleted_rows_count\", Types.LongType.get());\n+  static final Types.NestedField REQUIRED_SEQUENCE_NUMBER =\n+      required(515, \"sequence_number\", Types.LongType.get());\n+  static final Types.NestedField REQUIRED_MIN_SEQUENCE_NUMBER =\n+      required(516, \"min_sequence_number\", Types.LongType.get());\n+\n+  static final Schema MANIFEST_LIST_SCHEMA = new Schema(\n+      ManifestFile.PATH, ManifestFile.LENGTH, ManifestFile.SPEC_ID,\n+      REQUIRED_SEQUENCE_NUMBER, REQUIRED_MIN_SEQUENCE_NUMBER, REQUIRED_SNAPSHOT_ID,\n+      REQUIRED_ADDED_FILES_COUNT, REQUIRED_EXISTING_FILES_COUNT, REQUIRED_DELETED_FILES_COUNT,\n+      REQUIRED_ADDED_ROWS_COUNT, REQUIRED_EXISTING_ROWS_COUNT, REQUIRED_DELETED_ROWS_COUNT,\n+      ManifestFile.PARTITION_SUMMARIES);\n+\n+\n+  /**\n+   * A wrapper class to write any ManifestFile implementation to Avro using the v2 write schema.\n+   *\n+   * This is used to maintain compatibility with v2 by writing manifest list files with the old schema, instead of\n+   * writing a sequence number into metadata files in v2 tables.\n+   */\n+  static class IndexedManifestFile implements ManifestFile, IndexedRecord {\n+    private static final org.apache.avro.Schema AVRO_SCHEMA =\n+        AvroSchemaUtil.convert(MANIFEST_LIST_SCHEMA, \"manifest_file\");\n+\n+    private final long snapshotId;\n+    private final long sequenceNumber;\n+    private ManifestFile wrapped = null;\n+\n+    IndexedManifestFile(long snapshotId, long sequenceNumber) {\n+      this.snapshotId = snapshotId;\n+      this.sequenceNumber = sequenceNumber;\n+    }\n+\n+    public ManifestFile wrap(ManifestFile file) {\n+      this.wrapped = file;\n+      return this;\n+    }\n+\n+    @Override\n+    public org.apache.avro.Schema getSchema() {\n+      return AVRO_SCHEMA;\n+    }\n+\n+    @Override\n+    public void put(int i, Object v) {\n+      throw new UnsupportedOperationException(\"Cannot read using IndexedManifestFile\");\n+    }\n+\n+    @Override\n+    public Object get(int pos) {\n+      switch (pos) {\n+        case 0:\n+          return wrapped.path();\n+        case 1:\n+          return wrapped.length();\n+        case 2:\n+          return wrapped.partitionSpecId();\n+        case 3:\n+          if (wrapped.sequenceNumber() == ManifestWriter.UNASSIGNED_SEQ) {\n+            Preconditions.checkState(snapshotId == wrapped.snapshotId(),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzk3MzczNQ=="}, "originalCommit": {"oid": "eaf78717b94097030098c790d7db74f231440408"}, "originalPosition": 107}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjUzMjg5Njc3OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/org/apache/iceberg/V2Metadata.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNFQwOToxNzowOFrOGFFn4w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0xNVQwMTo1MjoyOFrOGFm-Qg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzk4ODE5NQ==", "bodyText": "I think this also needs some detail or document about why it happens.", "url": "https://github.com/apache/iceberg/pull/913#discussion_r407988195", "createdAt": "2020-04-14T09:17:08Z", "author": {"login": "chenjunjiedada"}, "path": "core/src/main/java/org/apache/iceberg/V2Metadata.java", "diffHunk": "@@ -0,0 +1,321 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg;\n+\n+import com.google.common.base.Preconditions;\n+import java.util.List;\n+import org.apache.avro.generic.IndexedRecord;\n+import org.apache.iceberg.avro.AvroSchemaUtil;\n+import org.apache.iceberg.types.Types;\n+\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+class V2Metadata {\n+  private V2Metadata() {\n+  }\n+\n+  // fields for v2 write schema for required metadata\n+  static final Types.NestedField REQUIRED_SNAPSHOT_ID =\n+      required(503, \"added_snapshot_id\", Types.LongType.get());\n+  static final Types.NestedField REQUIRED_ADDED_FILES_COUNT =\n+      required(504, \"added_data_files_count\", Types.IntegerType.get());\n+  static final Types.NestedField REQUIRED_EXISTING_FILES_COUNT =\n+      required(505, \"existing_data_files_count\", Types.IntegerType.get());\n+  static final Types.NestedField REQUIRED_DELETED_FILES_COUNT =\n+      required(506, \"deleted_data_files_count\", Types.IntegerType.get());\n+  static final Types.NestedField REQUIRED_ADDED_ROWS_COUNT =\n+      required(512, \"added_rows_count\", Types.LongType.get());\n+  static final Types.NestedField REQUIRED_EXISTING_ROWS_COUNT =\n+      required(513, \"existing_rows_count\", Types.LongType.get());\n+  static final Types.NestedField REQUIRED_DELETED_ROWS_COUNT =\n+      required(514, \"deleted_rows_count\", Types.LongType.get());\n+  static final Types.NestedField REQUIRED_SEQUENCE_NUMBER =\n+      required(515, \"sequence_number\", Types.LongType.get());\n+  static final Types.NestedField REQUIRED_MIN_SEQUENCE_NUMBER =\n+      required(516, \"min_sequence_number\", Types.LongType.get());\n+\n+  static final Schema MANIFEST_LIST_SCHEMA = new Schema(\n+      ManifestFile.PATH, ManifestFile.LENGTH, ManifestFile.SPEC_ID,\n+      REQUIRED_SEQUENCE_NUMBER, REQUIRED_MIN_SEQUENCE_NUMBER, REQUIRED_SNAPSHOT_ID,\n+      REQUIRED_ADDED_FILES_COUNT, REQUIRED_EXISTING_FILES_COUNT, REQUIRED_DELETED_FILES_COUNT,\n+      REQUIRED_ADDED_ROWS_COUNT, REQUIRED_EXISTING_ROWS_COUNT, REQUIRED_DELETED_ROWS_COUNT,\n+      ManifestFile.PARTITION_SUMMARIES);\n+\n+\n+  /**\n+   * A wrapper class to write any ManifestFile implementation to Avro using the v2 write schema.\n+   *\n+   * This is used to maintain compatibility with v2 by writing manifest list files with the old schema, instead of\n+   * writing a sequence number into metadata files in v2 tables.\n+   */\n+  static class IndexedManifestFile implements ManifestFile, IndexedRecord {\n+    private static final org.apache.avro.Schema AVRO_SCHEMA =\n+        AvroSchemaUtil.convert(MANIFEST_LIST_SCHEMA, \"manifest_file\");\n+\n+    private final long snapshotId;\n+    private final long sequenceNumber;\n+    private ManifestFile wrapped = null;\n+\n+    IndexedManifestFile(long snapshotId, long sequenceNumber) {\n+      this.snapshotId = snapshotId;\n+      this.sequenceNumber = sequenceNumber;\n+    }\n+\n+    public ManifestFile wrap(ManifestFile file) {\n+      this.wrapped = file;\n+      return this;\n+    }\n+\n+    @Override\n+    public org.apache.avro.Schema getSchema() {\n+      return AVRO_SCHEMA;\n+    }\n+\n+    @Override\n+    public void put(int i, Object v) {\n+      throw new UnsupportedOperationException(\"Cannot read using IndexedManifestFile\");\n+    }\n+\n+    @Override\n+    public Object get(int pos) {\n+      switch (pos) {\n+        case 0:\n+          return wrapped.path();\n+        case 1:\n+          return wrapped.length();\n+        case 2:\n+          return wrapped.partitionSpecId();\n+        case 3:\n+          if (wrapped.sequenceNumber() == ManifestWriter.UNASSIGNED_SEQ) {\n+            Preconditions.checkState(snapshotId == wrapped.snapshotId(),\n+                \"Found unassigned sequence number for a manifest from snapshot: %s\", wrapped.snapshotId());\n+            return sequenceNumber;\n+          } else {\n+            return wrapped.sequenceNumber();\n+          }\n+        case 4:\n+          return wrapped.minSequenceNumber();\n+        case 5:\n+          return wrapped.snapshotId();\n+        case 6:\n+          return wrapped.addedFilesCount();\n+        case 7:\n+          return wrapped.existingFilesCount();\n+        case 8:\n+          return wrapped.deletedFilesCount();\n+        case 9:\n+          return wrapped.addedRowsCount();\n+        case 10:\n+          return wrapped.existingRowsCount();\n+        case 11:\n+          return wrapped.deletedRowsCount();\n+        case 12:\n+          return wrapped.partitions();\n+        default:\n+          throw new UnsupportedOperationException(\"Unknown field ordinal: \" + pos);\n+      }\n+    }\n+\n+    @Override\n+    public String path() {\n+      return wrapped.path();\n+    }\n+\n+    @Override\n+    public long length() {\n+      return wrapped.length();\n+    }\n+\n+    @Override\n+    public int partitionSpecId() {\n+      return wrapped.partitionSpecId();\n+    }\n+\n+    @Override\n+    public long sequenceNumber() {\n+      return wrapped.sequenceNumber();\n+    }\n+\n+    @Override\n+    public long minSequenceNumber() {\n+      return wrapped.minSequenceNumber();\n+    }\n+\n+    @Override\n+    public Long snapshotId() {\n+      return wrapped.snapshotId();\n+    }\n+\n+    @Override\n+    public boolean hasAddedFiles() {\n+      return wrapped.hasAddedFiles();\n+    }\n+\n+    @Override\n+    public Integer addedFilesCount() {\n+      return wrapped.addedFilesCount();\n+    }\n+\n+    @Override\n+    public Long addedRowsCount() {\n+      return wrapped.addedRowsCount();\n+    }\n+\n+    @Override\n+    public boolean hasExistingFiles() {\n+      return wrapped.hasExistingFiles();\n+    }\n+\n+    @Override\n+    public Integer existingFilesCount() {\n+      return wrapped.existingFilesCount();\n+    }\n+\n+    @Override\n+    public Long existingRowsCount() {\n+      return wrapped.existingRowsCount();\n+    }\n+\n+    @Override\n+    public boolean hasDeletedFiles() {\n+      return wrapped.hasDeletedFiles();\n+    }\n+\n+    @Override\n+    public Integer deletedFilesCount() {\n+      return wrapped.deletedFilesCount();\n+    }\n+\n+    @Override\n+    public Long deletedRowsCount() {\n+      return wrapped.deletedRowsCount();\n+    }\n+\n+    @Override\n+    public List<PartitionFieldSummary> partitions() {\n+      return wrapped.partitions();\n+    }\n+\n+    @Override\n+    public ManifestFile copy() {\n+      return wrapped.copy();\n+    }\n+  }\n+\n+  static Schema entrySchema(Types.StructType partitionType) {\n+    return wrapFileSchema(DataFile.getType(partitionType));\n+  }\n+\n+  static Schema wrapFileSchema(Types.StructType fileSchema) {\n+    // this is used to build projection schemas\n+    return new Schema(\n+        ManifestEntry.STATUS, ManifestEntry.SNAPSHOT_ID,\n+        required(ManifestEntry.DATA_FILE_ID, \"data_file\", fileSchema));\n+  }\n+\n+  static class IndexedManifestEntry implements ManifestEntry, IndexedRecord {\n+    private final org.apache.avro.Schema avroSchema;\n+    private final long snapshotId;\n+    private final V1Metadata.IndexedDataFile fileWrapper;\n+    private ManifestEntry wrapped = null;\n+\n+    IndexedManifestEntry(long snapshotId, Types.StructType partitionType) {\n+      this.avroSchema = AvroSchemaUtil.convert(entrySchema(partitionType), \"manifest_entry\");\n+      this.snapshotId = snapshotId;\n+      // TODO: when v2 data files differ from v1, this should use a v2 wrapper\n+      this.fileWrapper = new V1Metadata.IndexedDataFile(avroSchema.getField(\"data_file\").schema());\n+    }\n+\n+    public IndexedManifestEntry wrap(ManifestEntry entry) {\n+      this.wrapped = entry;\n+      return this;\n+    }\n+\n+    @Override\n+    public org.apache.avro.Schema getSchema() {\n+      return avroSchema;\n+    }\n+\n+    @Override\n+    public void put(int i, Object v) {\n+      throw new UnsupportedOperationException(\"Cannot read using IndexedManifestEntry\");\n+    }\n+\n+    @Override\n+    public Object get(int i) {\n+      switch (i) {\n+        case 0:\n+          return wrapped.status().id();\n+        case 1:\n+          return wrapped.snapshotId();\n+        case 2:\n+          if (wrapped.sequenceNumber() == null) {\n+            Preconditions.checkState(wrapped.snapshotId() == null || snapshotId == wrapped.snapshotId(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eaf78717b94097030098c790d7db74f231440408"}, "originalPosition": 270}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwODUzNDU5NA==", "bodyText": "I added a comment to explain here as well.", "url": "https://github.com/apache/iceberg/pull/913#discussion_r408534594", "createdAt": "2020-04-15T01:52:28Z", "author": {"login": "rdblue"}, "path": "core/src/main/java/org/apache/iceberg/V2Metadata.java", "diffHunk": "@@ -0,0 +1,321 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg;\n+\n+import com.google.common.base.Preconditions;\n+import java.util.List;\n+import org.apache.avro.generic.IndexedRecord;\n+import org.apache.iceberg.avro.AvroSchemaUtil;\n+import org.apache.iceberg.types.Types;\n+\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+class V2Metadata {\n+  private V2Metadata() {\n+  }\n+\n+  // fields for v2 write schema for required metadata\n+  static final Types.NestedField REQUIRED_SNAPSHOT_ID =\n+      required(503, \"added_snapshot_id\", Types.LongType.get());\n+  static final Types.NestedField REQUIRED_ADDED_FILES_COUNT =\n+      required(504, \"added_data_files_count\", Types.IntegerType.get());\n+  static final Types.NestedField REQUIRED_EXISTING_FILES_COUNT =\n+      required(505, \"existing_data_files_count\", Types.IntegerType.get());\n+  static final Types.NestedField REQUIRED_DELETED_FILES_COUNT =\n+      required(506, \"deleted_data_files_count\", Types.IntegerType.get());\n+  static final Types.NestedField REQUIRED_ADDED_ROWS_COUNT =\n+      required(512, \"added_rows_count\", Types.LongType.get());\n+  static final Types.NestedField REQUIRED_EXISTING_ROWS_COUNT =\n+      required(513, \"existing_rows_count\", Types.LongType.get());\n+  static final Types.NestedField REQUIRED_DELETED_ROWS_COUNT =\n+      required(514, \"deleted_rows_count\", Types.LongType.get());\n+  static final Types.NestedField REQUIRED_SEQUENCE_NUMBER =\n+      required(515, \"sequence_number\", Types.LongType.get());\n+  static final Types.NestedField REQUIRED_MIN_SEQUENCE_NUMBER =\n+      required(516, \"min_sequence_number\", Types.LongType.get());\n+\n+  static final Schema MANIFEST_LIST_SCHEMA = new Schema(\n+      ManifestFile.PATH, ManifestFile.LENGTH, ManifestFile.SPEC_ID,\n+      REQUIRED_SEQUENCE_NUMBER, REQUIRED_MIN_SEQUENCE_NUMBER, REQUIRED_SNAPSHOT_ID,\n+      REQUIRED_ADDED_FILES_COUNT, REQUIRED_EXISTING_FILES_COUNT, REQUIRED_DELETED_FILES_COUNT,\n+      REQUIRED_ADDED_ROWS_COUNT, REQUIRED_EXISTING_ROWS_COUNT, REQUIRED_DELETED_ROWS_COUNT,\n+      ManifestFile.PARTITION_SUMMARIES);\n+\n+\n+  /**\n+   * A wrapper class to write any ManifestFile implementation to Avro using the v2 write schema.\n+   *\n+   * This is used to maintain compatibility with v2 by writing manifest list files with the old schema, instead of\n+   * writing a sequence number into metadata files in v2 tables.\n+   */\n+  static class IndexedManifestFile implements ManifestFile, IndexedRecord {\n+    private static final org.apache.avro.Schema AVRO_SCHEMA =\n+        AvroSchemaUtil.convert(MANIFEST_LIST_SCHEMA, \"manifest_file\");\n+\n+    private final long snapshotId;\n+    private final long sequenceNumber;\n+    private ManifestFile wrapped = null;\n+\n+    IndexedManifestFile(long snapshotId, long sequenceNumber) {\n+      this.snapshotId = snapshotId;\n+      this.sequenceNumber = sequenceNumber;\n+    }\n+\n+    public ManifestFile wrap(ManifestFile file) {\n+      this.wrapped = file;\n+      return this;\n+    }\n+\n+    @Override\n+    public org.apache.avro.Schema getSchema() {\n+      return AVRO_SCHEMA;\n+    }\n+\n+    @Override\n+    public void put(int i, Object v) {\n+      throw new UnsupportedOperationException(\"Cannot read using IndexedManifestFile\");\n+    }\n+\n+    @Override\n+    public Object get(int pos) {\n+      switch (pos) {\n+        case 0:\n+          return wrapped.path();\n+        case 1:\n+          return wrapped.length();\n+        case 2:\n+          return wrapped.partitionSpecId();\n+        case 3:\n+          if (wrapped.sequenceNumber() == ManifestWriter.UNASSIGNED_SEQ) {\n+            Preconditions.checkState(snapshotId == wrapped.snapshotId(),\n+                \"Found unassigned sequence number for a manifest from snapshot: %s\", wrapped.snapshotId());\n+            return sequenceNumber;\n+          } else {\n+            return wrapped.sequenceNumber();\n+          }\n+        case 4:\n+          return wrapped.minSequenceNumber();\n+        case 5:\n+          return wrapped.snapshotId();\n+        case 6:\n+          return wrapped.addedFilesCount();\n+        case 7:\n+          return wrapped.existingFilesCount();\n+        case 8:\n+          return wrapped.deletedFilesCount();\n+        case 9:\n+          return wrapped.addedRowsCount();\n+        case 10:\n+          return wrapped.existingRowsCount();\n+        case 11:\n+          return wrapped.deletedRowsCount();\n+        case 12:\n+          return wrapped.partitions();\n+        default:\n+          throw new UnsupportedOperationException(\"Unknown field ordinal: \" + pos);\n+      }\n+    }\n+\n+    @Override\n+    public String path() {\n+      return wrapped.path();\n+    }\n+\n+    @Override\n+    public long length() {\n+      return wrapped.length();\n+    }\n+\n+    @Override\n+    public int partitionSpecId() {\n+      return wrapped.partitionSpecId();\n+    }\n+\n+    @Override\n+    public long sequenceNumber() {\n+      return wrapped.sequenceNumber();\n+    }\n+\n+    @Override\n+    public long minSequenceNumber() {\n+      return wrapped.minSequenceNumber();\n+    }\n+\n+    @Override\n+    public Long snapshotId() {\n+      return wrapped.snapshotId();\n+    }\n+\n+    @Override\n+    public boolean hasAddedFiles() {\n+      return wrapped.hasAddedFiles();\n+    }\n+\n+    @Override\n+    public Integer addedFilesCount() {\n+      return wrapped.addedFilesCount();\n+    }\n+\n+    @Override\n+    public Long addedRowsCount() {\n+      return wrapped.addedRowsCount();\n+    }\n+\n+    @Override\n+    public boolean hasExistingFiles() {\n+      return wrapped.hasExistingFiles();\n+    }\n+\n+    @Override\n+    public Integer existingFilesCount() {\n+      return wrapped.existingFilesCount();\n+    }\n+\n+    @Override\n+    public Long existingRowsCount() {\n+      return wrapped.existingRowsCount();\n+    }\n+\n+    @Override\n+    public boolean hasDeletedFiles() {\n+      return wrapped.hasDeletedFiles();\n+    }\n+\n+    @Override\n+    public Integer deletedFilesCount() {\n+      return wrapped.deletedFilesCount();\n+    }\n+\n+    @Override\n+    public Long deletedRowsCount() {\n+      return wrapped.deletedRowsCount();\n+    }\n+\n+    @Override\n+    public List<PartitionFieldSummary> partitions() {\n+      return wrapped.partitions();\n+    }\n+\n+    @Override\n+    public ManifestFile copy() {\n+      return wrapped.copy();\n+    }\n+  }\n+\n+  static Schema entrySchema(Types.StructType partitionType) {\n+    return wrapFileSchema(DataFile.getType(partitionType));\n+  }\n+\n+  static Schema wrapFileSchema(Types.StructType fileSchema) {\n+    // this is used to build projection schemas\n+    return new Schema(\n+        ManifestEntry.STATUS, ManifestEntry.SNAPSHOT_ID,\n+        required(ManifestEntry.DATA_FILE_ID, \"data_file\", fileSchema));\n+  }\n+\n+  static class IndexedManifestEntry implements ManifestEntry, IndexedRecord {\n+    private final org.apache.avro.Schema avroSchema;\n+    private final long snapshotId;\n+    private final V1Metadata.IndexedDataFile fileWrapper;\n+    private ManifestEntry wrapped = null;\n+\n+    IndexedManifestEntry(long snapshotId, Types.StructType partitionType) {\n+      this.avroSchema = AvroSchemaUtil.convert(entrySchema(partitionType), \"manifest_entry\");\n+      this.snapshotId = snapshotId;\n+      // TODO: when v2 data files differ from v1, this should use a v2 wrapper\n+      this.fileWrapper = new V1Metadata.IndexedDataFile(avroSchema.getField(\"data_file\").schema());\n+    }\n+\n+    public IndexedManifestEntry wrap(ManifestEntry entry) {\n+      this.wrapped = entry;\n+      return this;\n+    }\n+\n+    @Override\n+    public org.apache.avro.Schema getSchema() {\n+      return avroSchema;\n+    }\n+\n+    @Override\n+    public void put(int i, Object v) {\n+      throw new UnsupportedOperationException(\"Cannot read using IndexedManifestEntry\");\n+    }\n+\n+    @Override\n+    public Object get(int i) {\n+      switch (i) {\n+        case 0:\n+          return wrapped.status().id();\n+        case 1:\n+          return wrapped.snapshotId();\n+        case 2:\n+          if (wrapped.sequenceNumber() == null) {\n+            Preconditions.checkState(wrapped.snapshotId() == null || snapshotId == wrapped.snapshotId(),", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQwNzk4ODE5NQ=="}, "originalCommit": {"oid": "eaf78717b94097030098c790d7db74f231440408"}, "originalPosition": 270}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjU1NzMxMjE0OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/org/apache/iceberg/ManifestWriter.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQxOToyMjoxN1rOGIj6_Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNC0yMFQxOTo0MTowMVrOGIkmTQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTYzMDMzMw==", "bodyText": "nit: I think we need to update the Javadoc.", "url": "https://github.com/apache/iceberg/pull/913#discussion_r411630333", "createdAt": "2020-04-20T19:22:17Z", "author": {"login": "aokolnychyi"}, "path": "core/src/main/java/org/apache/iceberg/ManifestWriter.java", "diffHunk": "@@ -116,12 +126,12 @@ void add(ManifestEntry entry) {\n    * @param existingFile a data file\n    * @param fileSnapshotId snapshot ID when the data file was added to the table\n    */\n-  public void existing(DataFile existingFile, long fileSnapshotId) {\n-    addEntry(reused.wrapExisting(fileSnapshotId, existingFile));\n+  public void existing(DataFile existingFile, long fileSnapshotId, long sequenceNumber) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "af1d77f7cd3ccbca164e66472983d1b6f1be9ef3"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTYzMzYyOA==", "bodyText": "Also, I am using this method in the rewrite manifests action. The entries metadata table will have sequenceNumber but its value will be 0, correct?", "url": "https://github.com/apache/iceberg/pull/913#discussion_r411633628", "createdAt": "2020-04-20T19:27:55Z", "author": {"login": "aokolnychyi"}, "path": "core/src/main/java/org/apache/iceberg/ManifestWriter.java", "diffHunk": "@@ -116,12 +126,12 @@ void add(ManifestEntry entry) {\n    * @param existingFile a data file\n    * @param fileSnapshotId snapshot ID when the data file was added to the table\n    */\n-  public void existing(DataFile existingFile, long fileSnapshotId) {\n-    addEntry(reused.wrapExisting(fileSnapshotId, existingFile));\n+  public void existing(DataFile existingFile, long fileSnapshotId, long sequenceNumber) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTYzMDMzMw=="}, "originalCommit": {"oid": "af1d77f7cd3ccbca164e66472983d1b6f1be9ef3"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTY0MTQyMQ==", "bodyText": "The new action should use the sequence number from the metadata table. That will be 0 for metadata written without sequence numbers, or the correct sequence number for v2 tables.", "url": "https://github.com/apache/iceberg/pull/913#discussion_r411641421", "createdAt": "2020-04-20T19:41:01Z", "author": {"login": "rdblue"}, "path": "core/src/main/java/org/apache/iceberg/ManifestWriter.java", "diffHunk": "@@ -116,12 +126,12 @@ void add(ManifestEntry entry) {\n    * @param existingFile a data file\n    * @param fileSnapshotId snapshot ID when the data file was added to the table\n    */\n-  public void existing(DataFile existingFile, long fileSnapshotId) {\n-    addEntry(reused.wrapExisting(fileSnapshotId, existingFile));\n+  public void existing(DataFile existingFile, long fileSnapshotId, long sequenceNumber) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQxMTYzMDMzMw=="}, "originalCommit": {"oid": "af1d77f7cd3ccbca164e66472983d1b6f1be9ef3"}, "originalPosition": 60}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 2908, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}