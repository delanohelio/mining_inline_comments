{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDU1MTUzNDcx", "number": 1228, "title": "Fix Handling of SparkPartitions with Whitepsace in Location", "bodyText": "More info at #1224\nPreviously the listPartition method would use a string representation\nof the Partition's URI when creating the Hadoop Path. This constructor would\nhandle the string as the literal input for the path and ignore any encoded\ncharacters. This casues an issue if the directory or filename has whitespace\nor some other special character being reported as it's encoded version\nresulting in FNF exceptions. By switching to passing a URI as\nthe SparkPartition's location uri, the escaped characters are correctly handled\nby the Hadoop Path class..", "createdAt": "2020-07-22T14:25:35Z", "url": "https://github.com/apache/iceberg/pull/1228", "merged": true, "mergeCommit": {"oid": "dfefa5d2f69dd951a0301b3aba282ffa974364bf"}, "closed": true, "closedAt": "2020-07-22T20:11:53Z", "author": {"login": "RussellSpitzer"}, "timelineItems": {"totalCount": 7, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc3NS87gH2gAyNDU1MTUzNDcxOjY0MDFmNmUzNDJmOGJjNGViMjU3MWY4MDdhMTgzMDUyMDZiYzAzMmQ=", "endCursor": "Y3Vyc29yOnYyOpPPAAABc3fTepgH2gAyNDU1MTUzNDcxOmIzODlhN2E3ZTU3NTg0NDdjMjAxMjRkMmMyNGQwZjhiNTY1Zjg4MWU=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "6401f6e342f8bc4eb2571f807a18305206bc032d", "author": {"user": {"login": "RussellSpitzer", "name": "Russell Spitzer"}}, "url": "https://github.com/apache/iceberg/commit/6401f6e342f8bc4eb2571f807a18305206bc032d", "committedDate": "2020-07-21T21:41:23Z", "message": "Fix Handling of SparkPartitions with Whitepsace in Location\n\nPreviously the listPartition method would use a string representation\nof the Partition's URI when creating the Hadoop Path. This constructor would\nhandle the string as the literal input for the path and ignore any encoded\ncharacters. This casues an issue if the directory or filename has whitespace\nor some other special character being reported as it's encoded version\n resulting in FNF exceptions. By switching to passing a URI as\nthe SparkPartition's location uri, the escaped characters are correctly handled\nby the Hadoop Path class.."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUzNDgwMTQ5", "url": "https://github.com/apache/iceberg/pull/1228#pullrequestreview-453480149", "createdAt": "2020-07-22T16:20:28Z", "commit": {"oid": "6401f6e342f8bc4eb2571f807a18305206bc032d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxNjoyMDoyOFrOG1qCBw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxNjoyMDoyOFrOG1qCBw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkxNjM1OQ==", "bodyText": "Looks like the main problem is that new Path(locationUri.get()) is not the same as new Path(locationUri.get().toString())?", "url": "https://github.com/apache/iceberg/pull/1228#discussion_r458916359", "createdAt": "2020-07-22T16:20:28Z", "author": {"login": "rdblue"}, "path": "spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java", "diffHunk": "@@ -386,7 +386,7 @@ private static SparkPartition toSparkPartition(CatalogTablePartition partition,\n     Preconditions.checkArgument(serde.nonEmpty() || table.provider().nonEmpty(),\n         \"Partition format should be defined\");\n \n-    String uri = String.valueOf(locationUri.get());\n+    URI uri = locationUri.get();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6401f6e342f8bc4eb2571f807a18305206bc032d"}, "originalPosition": 41}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUzNDg4NjEy", "url": "https://github.com/apache/iceberg/pull/1228#pullrequestreview-453488612", "createdAt": "2020-07-22T16:29:51Z", "commit": {"oid": "6401f6e342f8bc4eb2571f807a18305206bc032d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxNjoyOTo1MVrOG1qizQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxNjoyOTo1MVrOG1qizQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkyNDc0OQ==", "bodyText": "The alternate fix is on the line below (an all other times we make a Path from a string), where instead of just passing through the string we pass back through the URI version of the string, or possibly just decode the string before passing it through. I think it's probably safest to use URI the whole time, second safest to change back to URI at the last moment, third safest to attempt to decode and hope Hadoop parses the string like we want it too.", "url": "https://github.com/apache/iceberg/pull/1228#discussion_r458924749", "createdAt": "2020-07-22T16:29:51Z", "author": {"login": "RussellSpitzer"}, "path": "spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java", "diffHunk": "@@ -313,7 +313,7 @@ private SparkTableUtil() {\n     }\n   }\n \n-  private static List<DataFile> listParquetPartition(Map<String, String> partitionPath, String partitionUri,\n+  private static List<DataFile> listParquetPartition(Map<String, String> partitionPath, URI partitionUri,\n                                                      PartitionSpec spec, Configuration conf,\n                                                      MetricsConfig metricsSpec) {\n     try {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6401f6e342f8bc4eb2571f807a18305206bc032d"}, "originalPosition": 26}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUzNDkyNjcz", "url": "https://github.com/apache/iceberg/pull/1228#pullrequestreview-453492673", "createdAt": "2020-07-22T16:34:54Z", "commit": {"oid": "6401f6e342f8bc4eb2571f807a18305206bc032d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxNjozNDo1NFrOG1qzyA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxNjozNDo1NFrOG1qzyA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODkyOTA5Ng==", "bodyText": "I'd like to avoid changing this method since it is public and using a URI will probably change behavior for users passing strings (String -> URI -> Path instead of String -> Path).", "url": "https://github.com/apache/iceberg/pull/1228#discussion_r458929096", "createdAt": "2020-07-22T16:34:54Z", "author": {"login": "rdblue"}, "path": "spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java", "diffHunk": "@@ -271,7 +271,7 @@ private SparkTableUtil() {\n    * @param metricsConfig a metrics conf\n    * @return a List of DataFile\n    */\n-  public static List<DataFile> listPartition(Map<String, String> partition, String uri, String format,\n+  public static List<DataFile> listPartition(Map<String, String> partition, URI uri, String format,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6401f6e342f8bc4eb2571f807a18305206bc032d"}, "originalPosition": 5}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "25528fcd4c5a42e1990cb2a50f10efa3c4f1374d", "author": {"user": {"login": "RussellSpitzer", "name": "Russell Spitzer"}}, "url": "https://github.com/apache/iceberg/commit/25528fcd4c5a42e1990cb2a50f10efa3c4f1374d", "committedDate": "2020-07-22T17:57:20Z", "message": "Address Reviewer Comments\n\nIn order to avoid changing the API and SparkSQL compatible types we will fix the whitespace issue by\ninstead replacing the encoded string representation with a decoded string representation. We use a\nmethod identical to Apache Spark, taking the Hadoop Path representation of the URI and getting the\nstring representation from that."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDUzNTY5ODE2", "url": "https://github.com/apache/iceberg/pull/1228#pullrequestreview-453569816", "createdAt": "2020-07-22T18:17:46Z", "commit": {"oid": "25528fcd4c5a42e1990cb2a50f10efa3c4f1374d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxODoxNzo0NlrOG1umfw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0yMlQxODoxNzo0NlrOG1umfw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1ODk5MTIzMQ==", "bodyText": "If this is going to be public, I'd rather find a better place than in SparkTableUtil, like org.apache.iceberg.hadoop.Util. I'm also fine with this being a private method here.", "url": "https://github.com/apache/iceberg/pull/1228#discussion_r458991231", "createdAt": "2020-07-22T18:17:46Z", "author": {"login": "rdblue"}, "path": "spark/src/main/java/org/apache/iceberg/spark/SparkTableUtil.java", "diffHunk": "@@ -105,6 +105,20 @@\n   private SparkTableUtil() {\n   }\n \n+  /**\n+   * From Apache Spark\n+   *\n+   * Convert URI to String.\n+   * Since URI.toString does not decode the uri, e.g. change '%25' to '%'.\n+   * Here we create a hadoop Path with the given URI, and rely on Path.toString\n+   * to decode the uri\n+   * @param uri the URI of the path\n+   * @return the String of the path\n+   */\n+  public static String uriToString(URI uri) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "25528fcd4c5a42e1990cb2a50f10efa3c4f1374d"}, "originalPosition": 14}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b389a7a7e5758447c20124d2c24d0f8b565f881e", "author": {"user": {"login": "RussellSpitzer", "name": "Russell Spitzer"}}, "url": "https://github.com/apache/iceberg/commit/b389a7a7e5758447c20124d2c24d0f8b565f881e", "committedDate": "2020-07-22T18:40:15Z", "message": "Move uriToString to Hadoop Util Class\n\nFor any future integrations which need to change URI's to strings."}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4302, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}