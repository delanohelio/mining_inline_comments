{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTE1MDkwMDQ4", "number": 1715, "reviewThreads": {"totalCount": 12, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNFQwMzowMDoxMVrOE1DgWg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQxNzo0MzoxMVrOE6sKRQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI0MDY3NDE4OnYy", "diffSide": "RIGHT", "path": "spark/src/main/java/org/apache/iceberg/actions/BaseAction.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNFQwMzowMDoxMVrOHtHirg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNFQwMzowMDoxMVrOHtHirg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzA3MTUzNA==", "bodyText": "Maybe this method can not handle some corner cases.\nFor example, in the spark2 action, the file_path is very special (file://level1.level2.level3.level4/database/table).", "url": "https://github.com/apache/iceberg/pull/1715#discussion_r517071534", "createdAt": "2020-11-04T03:00:11Z", "author": {"login": "liukun4515"}, "path": "spark/src/main/java/org/apache/iceberg/actions/BaseAction.java", "diffHunk": "@@ -144,6 +123,32 @@ protected String metadataTableName(String tableName, MetadataTableType type) {\n     return manifestDF.union(otherMetadataFileDF).union(manifestListDF);\n   }\n \n+  protected Dataset<Row> loadMetadataTable(SparkSession spark, String tableName, MetadataTableType type) {\n+    String metadataTableName = metadataTableName(tableName, type);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9ab39c789cf014a8b27749e8736e914c4d882b15"}, "originalPosition": 52}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI0MDcxNzg2OnYy", "diffSide": "RIGHT", "path": "spark/src/main/java/org/apache/iceberg/actions/BaseAction.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNFQwMzoyNjo0OVrOHtH7zQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNFQwMzoyNjo0OVrOHtH7zQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzA3Nzk2NQ==", "bodyText": "can we add some examples for explaining the case?", "url": "https://github.com/apache/iceberg/pull/1715#discussion_r517077965", "createdAt": "2020-11-04T03:26:49Z", "author": {"login": "liukun4515"}, "path": "spark/src/main/java/org/apache/iceberg/actions/BaseAction.java", "diffHunk": "@@ -144,6 +123,32 @@ protected String metadataTableName(String tableName, MetadataTableType type) {\n     return manifestDF.union(otherMetadataFileDF).union(manifestListDF);\n   }\n \n+  protected Dataset<Row> loadMetadataTable(SparkSession spark, String tableName, MetadataTableType type) {\n+    String metadataTableName = metadataTableName(tableName, type);\n+    if (metadataTableName.split(\"\\\\.\").length > 3) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9ab39c789cf014a8b27749e8736e914c4d882b15"}, "originalPosition": 53}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI0MDc4NTY5OnYy", "diffSide": "RIGHT", "path": "spark3/src/test/java/org/apache/iceberg/actions/TestRemoveOrphanFilesAction3.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNFQwNDoxMjo1NFrOHtIiTw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNFQwNDoxMjo1NFrOHtIiTw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzA4NzgyMw==", "bodyText": "I only added this, (and the test inside orphan files) because we'll have additional coverage for the use cases once the SQL api is introduced and vectorizing the entire suite of actions was getting a bit onerous.", "url": "https://github.com/apache/iceberg/pull/1715#discussion_r517087823", "createdAt": "2020-11-04T04:12:54Z", "author": {"login": "RussellSpitzer"}, "path": "spark3/src/test/java/org/apache/iceberg/actions/TestRemoveOrphanFilesAction3.java", "diffHunk": "@@ -19,5 +19,46 @@\n \n package org.apache.iceberg.actions;\n \n+import java.io.File;\n+import java.io.IOException;\n+import java.util.List;\n+import java.util.Map;\n+import org.apache.iceberg.relocated.com.google.common.collect.Maps;\n+import org.apache.iceberg.spark.SparkCatalog;\n+import org.apache.iceberg.spark.SparkSchemaUtil;\n+import org.apache.iceberg.spark.source.SparkTable;\n+import org.apache.spark.sql.catalyst.analysis.NoSuchTableException;\n+import org.apache.spark.sql.catalyst.analysis.TableAlreadyExistsException;\n+import org.apache.spark.sql.connector.catalog.Identifier;\n+import org.apache.spark.sql.connector.expressions.Transform;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n public class TestRemoveOrphanFilesAction3 extends TestRemoveOrphanFilesAction {\n+  @Test", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d7acebf5da8c73d72caedebf6dfb94d36cb4534"}, "originalPosition": 20}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI0MDc4Nzg2OnYy", "diffSide": "RIGHT", "path": "spark/src/main/java/org/apache/iceberg/actions/BaseSparkAction.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNFQwNDoxNDoyMlrOHtIjhQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wNFQwNDoxNDoyMlrOHtIjhQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNzA4ODEzMw==", "bodyText": "I didn't want to make these static, but because two of the actions no longer extend BaseSparkActions they cannot access these methods anymore. I think in the future we should try our best to keep from having Actions implementing  \"BaseAction\" if we can help it so that the implementations of frame work specific code can use their shared methods.", "url": "https://github.com/apache/iceberg/pull/1715#discussion_r517088133", "createdAt": "2020-11-04T04:14:22Z", "author": {"login": "RussellSpitzer"}, "path": "spark/src/main/java/org/apache/iceberg/actions/BaseSparkAction.java", "diffHunk": "@@ -86,6 +125,33 @@\n     return manifestDF.union(otherMetadataFileDF).union(manifestListDF);\n   }\n \n+  protected static Dataset<Row> loadMetadataTable(SparkSession spark, String tableName, String tableLocation,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2d7acebf5da8c73d72caedebf6dfb94d36cb4534"}, "originalPosition": 87}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI5NTQ2MDMyOnYy", "diffSide": "RIGHT", "path": "spark/src/main/java/org/apache/iceberg/actions/BaseSparkAction.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QyMzozMzoxM1rOH1PzYA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QyMzozMzoxM1rOH1PzYA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU5NTQ4OA==", "bodyText": "nit: It may not necessarily be a metadata location. It can be a valid Hadoop table location too.", "url": "https://github.com/apache/iceberg/pull/1715#discussion_r525595488", "createdAt": "2020-11-17T23:33:13Z", "author": {"login": "aokolnychyi"}, "path": "spark/src/main/java/org/apache/iceberg/actions/BaseSparkAction.java", "diffHunk": "@@ -86,6 +126,32 @@\n     return manifestDF.union(otherMetadataFileDF).union(manifestListDF);\n   }\n \n+  protected static Dataset<Row> loadMetadataTable(SparkSession spark, String tableName, String tableLocation,\n+                                                  MetadataTableType type) {\n+    DataFrameReader noCatalogReader = spark.read().format(\"iceberg\");\n+    if (tableName.contains(\"/\")) {\n+      // Metadata location passed, load without a catalog", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7594cc7d9bde91ccb2795b300960a927c648f83f"}, "originalPosition": 94}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI5NTQ2NzY1OnYy", "diffSide": "RIGHT", "path": "spark/src/main/java/org/apache/iceberg/actions/BaseSparkAction.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QyMzozNjoxMVrOH1P3mQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QyMzo1NjowMlrOH1QTog==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU5NjU2OQ==", "bodyText": "nit: do we think this else helps clarity? We have a return statement anyway. Without this else, we could reduce the indentation of the block below.", "url": "https://github.com/apache/iceberg/pull/1715#discussion_r525596569", "createdAt": "2020-11-17T23:36:11Z", "author": {"login": "aokolnychyi"}, "path": "spark/src/main/java/org/apache/iceberg/actions/BaseSparkAction.java", "diffHunk": "@@ -86,6 +126,32 @@\n     return manifestDF.union(otherMetadataFileDF).union(manifestListDF);\n   }\n \n+  protected static Dataset<Row> loadMetadataTable(SparkSession spark, String tableName, String tableLocation,\n+                                                  MetadataTableType type) {\n+    DataFrameReader noCatalogReader = spark.read().format(\"iceberg\");\n+    if (tableName.contains(\"/\")) {\n+      // Metadata location passed, load without a catalog\n+      return noCatalogReader.load(tableName + \"#\" + type);\n+    } else {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7594cc7d9bde91ccb2795b300960a927c648f83f"}, "originalPosition": 96}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYwMzc0Ng==", "bodyText": "It helps for my brain,  but I can drop the if else if you like. I tend to prefer nesting over implied control flow breaks but I think I'm not in the majority here. I'll change it since its what we did on the other pr as well", "url": "https://github.com/apache/iceberg/pull/1715#discussion_r525603746", "createdAt": "2020-11-17T23:56:02Z", "author": {"login": "RussellSpitzer"}, "path": "spark/src/main/java/org/apache/iceberg/actions/BaseSparkAction.java", "diffHunk": "@@ -86,6 +126,32 @@\n     return manifestDF.union(otherMetadataFileDF).union(manifestListDF);\n   }\n \n+  protected static Dataset<Row> loadMetadataTable(SparkSession spark, String tableName, String tableLocation,\n+                                                  MetadataTableType type) {\n+    DataFrameReader noCatalogReader = spark.read().format(\"iceberg\");\n+    if (tableName.contains(\"/\")) {\n+      // Metadata location passed, load without a catalog\n+      return noCatalogReader.load(tableName + \"#\" + type);\n+    } else {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU5NjU2OQ=="}, "originalCommit": {"oid": "7594cc7d9bde91ccb2795b300960a927c648f83f"}, "originalPosition": 96}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI5NTQ4MjIyOnYy", "diffSide": "RIGHT", "path": "spark/src/main/java/org/apache/iceberg/actions/BaseSparkAction.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QyMzo0MjoyM1rOH1QAUw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QyMzo0MzoxNFrOH1QBcQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU5ODgwMw==", "bodyText": "If we do a static import for ALL_MANIFESTS, will it fit on one line?", "url": "https://github.com/apache/iceberg/pull/1715#discussion_r525598803", "createdAt": "2020-11-17T23:42:23Z", "author": {"login": "aokolnychyi"}, "path": "spark/src/main/java/org/apache/iceberg/actions/BaseSparkAction.java", "diffHunk": "@@ -47,9 +87,9 @@\n   protected Dataset<Row> buildValidDataFileDF(SparkSession spark, String tableName) {\n     JavaSparkContext context = new JavaSparkContext(spark.sparkContext());\n     Broadcast<FileIO> ioBroadcast = context.broadcast(SparkUtil.serializableFileIO(table()));\n-    String allManifestsMetadataTable = metadataTableName(tableName, MetadataTableType.ALL_MANIFESTS);\n \n-    Dataset<ManifestFileBean> allManifests = spark.read().format(\"iceberg\").load(allManifestsMetadataTable)\n+    Dataset<ManifestFileBean> allManifests = loadMetadataTable(spark, tableName, table().location(),\n+        MetadataTableType.ALL_MANIFESTS)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7594cc7d9bde91ccb2795b300960a927c648f83f"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU5OTA4OQ==", "bodyText": "If not, we can make a var String tableLocation = table().location() if we need to reduce the length further.", "url": "https://github.com/apache/iceberg/pull/1715#discussion_r525599089", "createdAt": "2020-11-17T23:43:14Z", "author": {"login": "aokolnychyi"}, "path": "spark/src/main/java/org/apache/iceberg/actions/BaseSparkAction.java", "diffHunk": "@@ -47,9 +87,9 @@\n   protected Dataset<Row> buildValidDataFileDF(SparkSession spark, String tableName) {\n     JavaSparkContext context = new JavaSparkContext(spark.sparkContext());\n     Broadcast<FileIO> ioBroadcast = context.broadcast(SparkUtil.serializableFileIO(table()));\n-    String allManifestsMetadataTable = metadataTableName(tableName, MetadataTableType.ALL_MANIFESTS);\n \n-    Dataset<ManifestFileBean> allManifests = spark.read().format(\"iceberg\").load(allManifestsMetadataTable)\n+    Dataset<ManifestFileBean> allManifests = loadMetadataTable(spark, tableName, table().location(),\n+        MetadataTableType.ALL_MANIFESTS)", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU5ODgwMw=="}, "originalCommit": {"oid": "7594cc7d9bde91ccb2795b300960a927c648f83f"}, "originalPosition": 71}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI5NTQ4NTk0OnYy", "diffSide": "RIGHT", "path": "spark/src/main/java/org/apache/iceberg/actions/RewriteManifestsAction.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QyMzo0NDowNFrOH1QCpQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xN1QyMzo0NDowNFrOH1QCpQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTU5OTM5Nw==", "bodyText": "Same here. Any way to fit on one line?", "url": "https://github.com/apache/iceberg/pull/1715#discussion_r525599397", "createdAt": "2020-11-17T23:44:04Z", "author": {"login": "aokolnychyi"}, "path": "spark/src/main/java/org/apache/iceberg/actions/RewriteManifestsAction.java", "diffHunk": "@@ -202,9 +202,8 @@ public RewriteManifestsActionResult execute() {\n         .createDataset(Lists.transform(manifests, ManifestFile::path), Encoders.STRING())\n         .toDF(\"manifest\");\n \n-    String entriesMetadataTable = metadataTableName(MetadataTableType.ENTRIES);\n-    Dataset<Row> manifestEntryDF = spark.read().format(\"iceberg\")\n-        .load(entriesMetadataTable)\n+    Dataset<Row> manifestEntryDF = BaseSparkAction.loadMetadataTable(spark, table.name(), table().location(),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7594cc7d9bde91ccb2795b300960a927c648f83f"}, "originalPosition": 7}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI5NTYzMjE0OnYy", "diffSide": "RIGHT", "path": "spark/src/main/java/org/apache/iceberg/actions/BaseSparkAction.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQwMDo0NjowNVrOH1RX2w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQxNjowNjoyOVrOH11SPg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYyMTIxMQ==", "bodyText": "Can this be a more specific exception? Seems dangerous to catch 'em all.", "url": "https://github.com/apache/iceberg/pull/1715#discussion_r525621211", "createdAt": "2020-11-18T00:46:05Z", "author": {"login": "rdblue"}, "path": "spark/src/main/java/org/apache/iceberg/actions/BaseSparkAction.java", "diffHunk": "@@ -86,6 +126,32 @@\n     return manifestDF.union(otherMetadataFileDF).union(manifestListDF);\n   }\n \n+  protected static Dataset<Row> loadMetadataTable(SparkSession spark, String tableName, String tableLocation,\n+                                                  MetadataTableType type) {\n+    DataFrameReader noCatalogReader = spark.read().format(\"iceberg\");\n+    if (tableName.contains(\"/\")) {\n+      // Metadata location passed, load without a catalog\n+      return noCatalogReader.load(tableName + \"#\" + type);\n+    } else {\n+      // Try catalog based name based resolution\n+      try {\n+        return spark.table(tableName + \".\" + type);\n+      } catch (Exception e) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7594cc7d9bde91ccb2795b300960a927c648f83f"}, "originalPosition": 100}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYzNTI1Mg==", "bodyText": ":pokemon: - Let me check what gets thrown and I\"ll try to narrow it down to reasonable classes of exception", "url": "https://github.com/apache/iceberg/pull/1715#discussion_r525635252", "createdAt": "2020-11-18T01:28:07Z", "author": {"login": "RussellSpitzer"}, "path": "spark/src/main/java/org/apache/iceberg/actions/BaseSparkAction.java", "diffHunk": "@@ -86,6 +126,32 @@\n     return manifestDF.union(otherMetadataFileDF).union(manifestListDF);\n   }\n \n+  protected static Dataset<Row> loadMetadataTable(SparkSession spark, String tableName, String tableLocation,\n+                                                  MetadataTableType type) {\n+    DataFrameReader noCatalogReader = spark.read().format(\"iceberg\");\n+    if (tableName.contains(\"/\")) {\n+      // Metadata location passed, load without a catalog\n+      return noCatalogReader.load(tableName + \"#\" + type);\n+    } else {\n+      // Try catalog based name based resolution\n+      try {\n+        return spark.table(tableName + \".\" + type);\n+      } catch (Exception e) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYyMTIxMQ=="}, "originalCommit": {"oid": "7594cc7d9bde91ccb2795b300960a927c648f83f"}, "originalPosition": 100}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjIwOTU5OA==", "bodyText": "Unfortunately these are unchecked from Scala so we do need to catch all runtime exceptions, but I can do a check after the exception is caught if it is a ParseException (2.4) or AnalysisException(3.0) and rethrow if it isn't.", "url": "https://github.com/apache/iceberg/pull/1715#discussion_r526209598", "createdAt": "2020-11-18T16:06:29Z", "author": {"login": "RussellSpitzer"}, "path": "spark/src/main/java/org/apache/iceberg/actions/BaseSparkAction.java", "diffHunk": "@@ -86,6 +126,32 @@\n     return manifestDF.union(otherMetadataFileDF).union(manifestListDF);\n   }\n \n+  protected static Dataset<Row> loadMetadataTable(SparkSession spark, String tableName, String tableLocation,\n+                                                  MetadataTableType type) {\n+    DataFrameReader noCatalogReader = spark.read().format(\"iceberg\");\n+    if (tableName.contains(\"/\")) {\n+      // Metadata location passed, load without a catalog\n+      return noCatalogReader.load(tableName + \"#\" + type);\n+    } else {\n+      // Try catalog based name based resolution\n+      try {\n+        return spark.table(tableName + \".\" + type);\n+      } catch (Exception e) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYyMTIxMQ=="}, "originalCommit": {"oid": "7594cc7d9bde91ccb2795b300960a927c648f83f"}, "originalPosition": 100}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI5NTY0MzQ2OnYy", "diffSide": "RIGHT", "path": "spark/src/main/java/org/apache/iceberg/actions/BaseSparkAction.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQwMDo1MTowM1rOH1Rejg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQwMToyNTowM1rOH1SKrQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYyMjkyNg==", "bodyText": "This logic is just for Spark 2.x right? If so then maybe we can add a comment explaining it and noting when we can remove it.", "url": "https://github.com/apache/iceberg/pull/1715#discussion_r525622926", "createdAt": "2020-11-18T00:51:03Z", "author": {"login": "rdblue"}, "path": "spark/src/main/java/org/apache/iceberg/actions/BaseSparkAction.java", "diffHunk": "@@ -86,6 +126,32 @@\n     return manifestDF.union(otherMetadataFileDF).union(manifestListDF);\n   }\n \n+  protected static Dataset<Row> loadMetadataTable(SparkSession spark, String tableName, String tableLocation,\n+                                                  MetadataTableType type) {\n+    DataFrameReader noCatalogReader = spark.read().format(\"iceberg\");\n+    if (tableName.contains(\"/\")) {\n+      // Metadata location passed, load without a catalog\n+      return noCatalogReader.load(tableName + \"#\" + type);\n+    } else {\n+      // Try catalog based name based resolution\n+      try {\n+        return spark.table(tableName + \".\" + type);\n+      } catch (Exception e) {\n+        // Catalog based resolution failed, our catalog may be a non-DatasourceV2 Catalog\n+        if (tableName.startsWith(\"hadoop.\")) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7594cc7d9bde91ccb2795b300960a927c648f83f"}, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYzMjEyMw==", "bodyText": "Anton I were talking about this, the issue is that it isn't just for SparkV2 as it's quite possible for a user to be using manual catalogs in a Spark3 application (or ported Spark2 application.) If we remove this we break anyone who is accessing tables by this method.\nI think that's actually something that's fine to break eventually but I think it would be pretty big breaking change.\nExample\nActions.forTable(tableCreatedFromHadoopOrHiveCatalog)", "url": "https://github.com/apache/iceberg/pull/1715#discussion_r525632123", "createdAt": "2020-11-18T01:18:43Z", "author": {"login": "RussellSpitzer"}, "path": "spark/src/main/java/org/apache/iceberg/actions/BaseSparkAction.java", "diffHunk": "@@ -86,6 +126,32 @@\n     return manifestDF.union(otherMetadataFileDF).union(manifestListDF);\n   }\n \n+  protected static Dataset<Row> loadMetadataTable(SparkSession spark, String tableName, String tableLocation,\n+                                                  MetadataTableType type) {\n+    DataFrameReader noCatalogReader = spark.read().format(\"iceberg\");\n+    if (tableName.contains(\"/\")) {\n+      // Metadata location passed, load without a catalog\n+      return noCatalogReader.load(tableName + \"#\" + type);\n+    } else {\n+      // Try catalog based name based resolution\n+      try {\n+        return spark.table(tableName + \".\" + type);\n+      } catch (Exception e) {\n+        // Catalog based resolution failed, our catalog may be a non-DatasourceV2 Catalog\n+        if (tableName.startsWith(\"hadoop.\")) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYyMjkyNg=="}, "originalCommit": {"oid": "7594cc7d9bde91ccb2795b300960a927c648f83f"}, "originalPosition": 102}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYzNDIyMQ==", "bodyText": "Sounds reasonable to me.", "url": "https://github.com/apache/iceberg/pull/1715#discussion_r525634221", "createdAt": "2020-11-18T01:25:03Z", "author": {"login": "rdblue"}, "path": "spark/src/main/java/org/apache/iceberg/actions/BaseSparkAction.java", "diffHunk": "@@ -86,6 +126,32 @@\n     return manifestDF.union(otherMetadataFileDF).union(manifestListDF);\n   }\n \n+  protected static Dataset<Row> loadMetadataTable(SparkSession spark, String tableName, String tableLocation,\n+                                                  MetadataTableType type) {\n+    DataFrameReader noCatalogReader = spark.read().format(\"iceberg\");\n+    if (tableName.contains(\"/\")) {\n+      // Metadata location passed, load without a catalog\n+      return noCatalogReader.load(tableName + \"#\" + type);\n+    } else {\n+      // Try catalog based name based resolution\n+      try {\n+        return spark.table(tableName + \".\" + type);\n+      } catch (Exception e) {\n+        // Catalog based resolution failed, our catalog may be a non-DatasourceV2 Catalog\n+        if (tableName.startsWith(\"hadoop.\")) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYyMjkyNg=="}, "originalCommit": {"oid": "7594cc7d9bde91ccb2795b300960a927c648f83f"}, "originalPosition": 102}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI5OTc1OTkwOnYy", "diffSide": "RIGHT", "path": "spark/src/main/java/org/apache/iceberg/actions/BaseSparkAction.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQxNzo0MjowOFrOH16cLA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQxNzo0MjowOFrOH16cLA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjI5NDA2MA==", "bodyText": "I think it should be fine to add it to our exceptions in checkstyle.xml. I thought it was already there.", "url": "https://github.com/apache/iceberg/pull/1715#discussion_r526294060", "createdAt": "2020-11-18T17:42:08Z", "author": {"login": "aokolnychyi"}, "path": "spark/src/main/java/org/apache/iceberg/actions/BaseSparkAction.java", "diffHunk": "@@ -24,21 +24,67 @@\n import org.apache.iceberg.BaseTable;\n import org.apache.iceberg.ManifestFiles;\n import org.apache.iceberg.MetadataTableType;\n+import org.apache.iceberg.Snapshot;\n import org.apache.iceberg.StaticTableOperations;\n import org.apache.iceberg.Table;\n+import org.apache.iceberg.TableMetadata;\n import org.apache.iceberg.TableOperations;\n import org.apache.iceberg.io.ClosingIterator;\n import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n import org.apache.iceberg.spark.SparkUtil;\n import org.apache.spark.api.java.JavaSparkContext;\n import org.apache.spark.api.java.function.FlatMapFunction;\n import org.apache.spark.broadcast.Broadcast;\n+import org.apache.spark.sql.AnalysisException;\n+import org.apache.spark.sql.DataFrameReader;\n import org.apache.spark.sql.Dataset;\n import org.apache.spark.sql.Encoders;\n import org.apache.spark.sql.Row;\n import org.apache.spark.sql.SparkSession;\n+import org.apache.spark.sql.catalyst.parser.ParseException;\n+\n+// CHECKSTYLE:OFF\n+import static org.apache.iceberg.MetadataTableType.ALL_MANIFESTS;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1e989b78a3f284415de9cacf8b95bb7e8da248e7"}, "originalPosition": 25}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI5OTc2Mzg5OnYy", "diffSide": "RIGHT", "path": "spark/src/main/java/org/apache/iceberg/actions/RewriteManifestsAction.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQxNzo0MzoxMVrOH16e2Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQxNzo0MzoxMVrOH16e2Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjI5NDc0NQ==", "bodyText": "same here", "url": "https://github.com/apache/iceberg/pull/1715#discussion_r526294745", "createdAt": "2020-11-18T17:43:11Z", "author": {"login": "aokolnychyi"}, "path": "spark/src/main/java/org/apache/iceberg/actions/RewriteManifestsAction.java", "diffHunk": "@@ -67,6 +66,10 @@\n import org.slf4j.Logger;\n import org.slf4j.LoggerFactory;\n \n+// CHECKSTYLE:OFF\n+import static org.apache.iceberg.MetadataTableType.ENTRIES;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1e989b78a3f284415de9cacf8b95bb7e8da248e7"}, "originalPosition": 13}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3380, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}