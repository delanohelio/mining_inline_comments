{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTIxMTQ4MDgy", "number": 1774, "reviewThreads": {"totalCount": 15, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwOToxMjoxMFrOE9IVsQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQwMjowODo0NVrOE9c2kA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyNTM1MjE3OnYy", "diffSide": "RIGHT", "path": "site/docs/configuration.md", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwOToxMjoxMFrOH5pqwg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwOTozMzoyOFrOH5qkQw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDIxMzU3MA==", "bodyText": "Table write.partitioned.fanout.enabled\n\nWe won't have table option for the write.partitioned.fanout.enabled, right ?   Could just write false by default here.", "url": "https://github.com/apache/iceberg/pull/1774#discussion_r530213570", "createdAt": "2020-11-25T09:12:10Z", "author": {"login": "openinx"}, "path": "site/docs/configuration.md", "diffHunk": "@@ -155,4 +156,5 @@ df.write\n | target-file-size-bytes | As per table property      | Overrides this table's write.target-file-size-bytes          |\n | check-nullability      | true                       | Sets the nullable check on fields                            |\n | snapshot-property._custom-key_    | null            | Adds an entry with custom-key and corresponding value in the snapshot summary  |\n+| partitioned.fanout.enabled       | Table write.partitioned.fanout.enabled        | Overrides this table's write.partitioned.fanout.enabled  |", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1e3e886a451e8fbcf0b2e65daa9ab4f902e905fb"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDIyODI5MQ==", "bodyText": "Table write.partitioned.fanout.enabled\n\nWe won't have table option for the write.partitioned.fanout.enabled, right ? Could just write false by default here.\n\nright, We won't have table option write.partitioned.fanout.enabled, false is ok.", "url": "https://github.com/apache/iceberg/pull/1774#discussion_r530228291", "createdAt": "2020-11-25T09:33:28Z", "author": {"login": "XuQianJin-Stars"}, "path": "site/docs/configuration.md", "diffHunk": "@@ -155,4 +156,5 @@ df.write\n | target-file-size-bytes | As per table property      | Overrides this table's write.target-file-size-bytes          |\n | check-nullability      | true                       | Sets the nullable check on fields                            |\n | snapshot-property._custom-key_    | null            | Adds an entry with custom-key and corresponding value in the snapshot summary  |\n+| partitioned.fanout.enabled       | Table write.partitioned.fanout.enabled        | Overrides this table's write.partitioned.fanout.enabled  |", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDIxMzU3MA=="}, "originalCommit": {"oid": "1e3e886a451e8fbcf0b2e65daa9ab4f902e905fb"}, "originalPosition": 12}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyNTM1NjE5OnYy", "diffSide": "RIGHT", "path": "spark/src/main/java/org/apache/iceberg/spark/source/RowDataRewriter.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwOToxMzowOFrOH5ptOA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwOToxMzowOFrOH5ptOA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDIxNDIwMA==", "bodyText": "nit:  don't need to break into a new line here", "url": "https://github.com/apache/iceberg/pull/1774#discussion_r530214200", "createdAt": "2020-11-25T09:13:08Z", "author": {"login": "openinx"}, "path": "spark/src/main/java/org/apache/iceberg/spark/source/RowDataRewriter.java", "diffHunk": "@@ -106,8 +107,17 @@ public RowDataRewriter(Table table, PartitionSpec spec, boolean caseSensitive,\n     if (spec.fields().isEmpty()) {\n       writer = new UnpartitionedWriter<>(spec, format, appenderFactory, fileFactory, io.value(), Long.MAX_VALUE);\n     } else {\n-      writer = new SparkPartitionedWriter(spec, format, appenderFactory, fileFactory, io.value(), Long.MAX_VALUE,\n-          schema, structType);\n+      if (PropertyUtil.propertyAsBoolean(properties,\n+          TableProperties.WRITE_PARTITIONED_FANOUT_ENABLED,\n+          TableProperties.WRITE_PARTITIONED_FANOUT_ENABLED_DEFAULT)) {\n+        writer = new SparkPartitionedFanoutWriter(spec, format, appenderFactory, fileFactory, io.value(),\n+            Long.MAX_VALUE,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1e3e886a451e8fbcf0b2e65daa9ab4f902e905fb"}, "originalPosition": 18}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyNTM1Njc5OnYy", "diffSide": "RIGHT", "path": "spark/src/main/java/org/apache/iceberg/spark/source/RowDataRewriter.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwOToxMzoxN1rOH5ptng==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwOToxMzoxN1rOH5ptng==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDIxNDMwMg==", "bodyText": "ditto.", "url": "https://github.com/apache/iceberg/pull/1774#discussion_r530214302", "createdAt": "2020-11-25T09:13:17Z", "author": {"login": "openinx"}, "path": "spark/src/main/java/org/apache/iceberg/spark/source/RowDataRewriter.java", "diffHunk": "@@ -106,8 +107,17 @@ public RowDataRewriter(Table table, PartitionSpec spec, boolean caseSensitive,\n     if (spec.fields().isEmpty()) {\n       writer = new UnpartitionedWriter<>(spec, format, appenderFactory, fileFactory, io.value(), Long.MAX_VALUE);\n     } else {\n-      writer = new SparkPartitionedWriter(spec, format, appenderFactory, fileFactory, io.value(), Long.MAX_VALUE,\n-          schema, structType);\n+      if (PropertyUtil.propertyAsBoolean(properties,\n+          TableProperties.WRITE_PARTITIONED_FANOUT_ENABLED,\n+          TableProperties.WRITE_PARTITIONED_FANOUT_ENABLED_DEFAULT)) {\n+        writer = new SparkPartitionedFanoutWriter(spec, format, appenderFactory, fileFactory, io.value(),\n+            Long.MAX_VALUE,\n+            schema, structType);\n+      } else {\n+        writer = new SparkPartitionedWriter(spec, format, appenderFactory, fileFactory, io.value(),\n+            Long.MAX_VALUE,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1e3e886a451e8fbcf0b2e65daa9ab4f902e905fb"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyNTM2OTE3OnYy", "diffSide": "RIGHT", "path": "spark2/src/main/java/org/apache/iceberg/spark/source/Writer.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwOToxNjowOFrOH5p1FQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxMToxODowNVrOH5uwQg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDIxNjIxMw==", "bodyText": "Q:  will we set this for a given table ?  In my option,  it's per job ?", "url": "https://github.com/apache/iceberg/pull/1774#discussion_r530216213", "createdAt": "2020-11-25T09:16:08Z", "author": {"login": "openinx"}, "path": "spark2/src/main/java/org/apache/iceberg/spark/source/Writer.java", "diffHunk": "@@ -113,6 +116,10 @@\n     long tableTargetFileSize = PropertyUtil.propertyAsLong(\n         table.properties(), WRITE_TARGET_FILE_SIZE_BYTES, WRITE_TARGET_FILE_SIZE_BYTES_DEFAULT);\n     this.targetFileSize = options.getLong(\"target-file-size-bytes\", tableTargetFileSize);\n+\n+    boolean tablePartitionedFanoutEnabled = PropertyUtil.propertyAsBoolean(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1e3e886a451e8fbcf0b2e65daa9ab4f902e905fb"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDI5Njg5OA==", "bodyText": "we need set this option for a given table, Because some tables require fanout.", "url": "https://github.com/apache/iceberg/pull/1774#discussion_r530296898", "createdAt": "2020-11-25T11:18:05Z", "author": {"login": "XuQianJin-Stars"}, "path": "spark2/src/main/java/org/apache/iceberg/spark/source/Writer.java", "diffHunk": "@@ -113,6 +116,10 @@\n     long tableTargetFileSize = PropertyUtil.propertyAsLong(\n         table.properties(), WRITE_TARGET_FILE_SIZE_BYTES, WRITE_TARGET_FILE_SIZE_BYTES_DEFAULT);\n     this.targetFileSize = options.getLong(\"target-file-size-bytes\", tableTargetFileSize);\n+\n+    boolean tablePartitionedFanoutEnabled = PropertyUtil.propertyAsBoolean(", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDIxNjIxMw=="}, "originalCommit": {"oid": "1e3e886a451e8fbcf0b2e65daa9ab4f902e905fb"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyNTM3NTIzOnYy", "diffSide": "RIGHT", "path": "spark3/src/main/java/org/apache/iceberg/spark/source/SparkWrite.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwOToxNzoyNlrOH5p4ow==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwOToxNzoyNlrOH5p4ow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDIxNzEyMw==", "bodyText": "ditto.", "url": "https://github.com/apache/iceberg/pull/1774#discussion_r530217123", "createdAt": "2020-11-25T09:17:26Z", "author": {"login": "openinx"}, "path": "spark3/src/main/java/org/apache/iceberg/spark/source/SparkWrite.java", "diffHunk": "@@ -113,6 +116,11 @@\n     long tableTargetFileSize = PropertyUtil.propertyAsLong(\n         table.properties(), WRITE_TARGET_FILE_SIZE_BYTES, WRITE_TARGET_FILE_SIZE_BYTES_DEFAULT);\n     this.targetFileSize = writeInfo.options().getLong(\"target-file-size-bytes\", tableTargetFileSize);\n+\n+    boolean tablePartitionedFanoutEnabled = PropertyUtil.propertyAsBoolean(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1e3e886a451e8fbcf0b2e65daa9ab4f902e905fb"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyNTM5MzU0OnYy", "diffSide": "RIGHT", "path": "spark/src/test/java/org/apache/iceberg/spark/source/TestSparkDataWrite.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwOToyMToxOVrOH5qDjQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwOToyMToxOVrOH5qDjQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDIxOTkxNw==", "bodyText": "For partitioned fanout case, we don't have to sort based on data column ?  Otherwise, what's the difference compared to PartitionedWriter ?", "url": "https://github.com/apache/iceberg/pull/1774#discussion_r530219917", "createdAt": "2020-11-25T09:21:19Z", "author": {"login": "openinx"}, "path": "spark/src/test/java/org/apache/iceberg/spark/source/TestSparkDataWrite.java", "diffHunk": "@@ -374,6 +375,58 @@ public void testPartitionedCreateWithTargetFileSizeViaOption() throws IOExceptio\n     }\n   }\n \n+  @Test\n+  public void testPartitionedFanoutCreateWithTargetFileSizeViaOption() throws IOException {\n+    File parent = temp.newFolder(format.toString());\n+    File location = new File(parent, \"test\");\n+\n+    HadoopTables tables = new HadoopTables(CONF);\n+    PartitionSpec spec = PartitionSpec.builderFor(SCHEMA).identity(\"data\").build();\n+    Table table = tables.create(SCHEMA, spec, location.toString());\n+    table.updateProperties()\n+        .set(WRITE_PARTITIONED_FANOUT_ENABLED, \"true\")\n+        .commit();\n+\n+    List<SimpleRecord> expected = Lists.newArrayListWithCapacity(8000);\n+    for (int i = 0; i < 2000; i++) {\n+      expected.add(new SimpleRecord(i, \"a\"));\n+      expected.add(new SimpleRecord(i, \"b\"));\n+      expected.add(new SimpleRecord(i, \"c\"));\n+      expected.add(new SimpleRecord(i, \"d\"));\n+    }\n+\n+    Dataset<Row> df = spark.createDataFrame(expected, SimpleRecord.class);\n+\n+    df.select(\"id\", \"data\").sort(\"data\").write()", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1e3e886a451e8fbcf0b2e65daa9ab4f902e905fb"}, "originalPosition": 34}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyNTM5NzExOnYy", "diffSide": "RIGHT", "path": "spark/src/test/java/org/apache/iceberg/spark/source/TestSparkDataWrite.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwOToyMjoxMVrOH5qFxA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQwOTozMDozM1rOH5qcWg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDIyMDQ4NA==", "bodyText": "In general,  I think we could abstract a common method between this method and testPartitionedCreateWithTargetFileSizeViaOption,  they are almost the same.", "url": "https://github.com/apache/iceberg/pull/1774#discussion_r530220484", "createdAt": "2020-11-25T09:22:11Z", "author": {"login": "openinx"}, "path": "spark/src/test/java/org/apache/iceberg/spark/source/TestSparkDataWrite.java", "diffHunk": "@@ -374,6 +375,58 @@ public void testPartitionedCreateWithTargetFileSizeViaOption() throws IOExceptio\n     }\n   }\n \n+  @Test\n+  public void testPartitionedFanoutCreateWithTargetFileSizeViaOption() throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1e3e886a451e8fbcf0b2e65daa9ab4f902e905fb"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDIyNjI2Ng==", "bodyText": "Well, let me change it.", "url": "https://github.com/apache/iceberg/pull/1774#discussion_r530226266", "createdAt": "2020-11-25T09:30:33Z", "author": {"login": "XuQianJin-Stars"}, "path": "spark/src/test/java/org/apache/iceberg/spark/source/TestSparkDataWrite.java", "diffHunk": "@@ -374,6 +375,58 @@ public void testPartitionedCreateWithTargetFileSizeViaOption() throws IOExceptio\n     }\n   }\n \n+  @Test\n+  public void testPartitionedFanoutCreateWithTargetFileSizeViaOption() throws IOException {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDIyMDQ4NA=="}, "originalCommit": {"oid": "1e3e886a451e8fbcf0b2e65daa9ab4f902e905fb"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyNjIyNTIwOnYy", "diffSide": "RIGHT", "path": "spark/src/main/java/org/apache/iceberg/spark/source/SparkPartitionedFanoutWriter.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxMjo0ODozNVrOH5x7UQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNVQxMjo1MDoyMFrOH5x_aA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDM0ODg4MQ==", "bodyText": "nit:   seems we could format the code to align with the previous line ?", "url": "https://github.com/apache/iceberg/pull/1774#discussion_r530348881", "createdAt": "2020-11-25T12:48:35Z", "author": {"login": "openinx"}, "path": "spark/src/main/java/org/apache/iceberg/spark/source/SparkPartitionedFanoutWriter.java", "diffHunk": "@@ -0,0 +1,51 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.source;\n+\n+import org.apache.iceberg.FileFormat;\n+import org.apache.iceberg.PartitionKey;\n+import org.apache.iceberg.PartitionSpec;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.io.FileAppenderFactory;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.io.OutputFileFactory;\n+import org.apache.iceberg.io.PartitionedFanoutWriter;\n+import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.types.StructType;\n+\n+public class SparkPartitionedFanoutWriter extends PartitionedFanoutWriter<InternalRow> {\n+  private final PartitionKey partitionKey;\n+  private final InternalRowWrapper internalRowWrapper;\n+\n+  public SparkPartitionedFanoutWriter(PartitionSpec spec, FileFormat format,\n+                                FileAppenderFactory<InternalRow> appenderFactory,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6f102777203c537089e430216710be7b08d7418f"}, "originalPosition": 38}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDM0OTkyOA==", "bodyText": "well", "url": "https://github.com/apache/iceberg/pull/1774#discussion_r530349928", "createdAt": "2020-11-25T12:50:20Z", "author": {"login": "XuQianJin-Stars"}, "path": "spark/src/main/java/org/apache/iceberg/spark/source/SparkPartitionedFanoutWriter.java", "diffHunk": "@@ -0,0 +1,51 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.source;\n+\n+import org.apache.iceberg.FileFormat;\n+import org.apache.iceberg.PartitionKey;\n+import org.apache.iceberg.PartitionSpec;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.io.FileAppenderFactory;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.io.OutputFileFactory;\n+import org.apache.iceberg.io.PartitionedFanoutWriter;\n+import org.apache.spark.sql.catalyst.InternalRow;\n+import org.apache.spark.sql.types.StructType;\n+\n+public class SparkPartitionedFanoutWriter extends PartitionedFanoutWriter<InternalRow> {\n+  private final PartitionKey partitionKey;\n+  private final InternalRowWrapper internalRowWrapper;\n+\n+  public SparkPartitionedFanoutWriter(PartitionSpec spec, FileFormat format,\n+                                FileAppenderFactory<InternalRow> appenderFactory,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDM0ODg4MQ=="}, "originalCommit": {"oid": "6f102777203c537089e430216710be7b08d7418f"}, "originalPosition": 38}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyODY4NTA4OnYy", "diffSide": "RIGHT", "path": "site/docs/configuration.md", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQwMTo1MzoxOVrOH6JIwQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQwMTo1NTo0NFrOH6JLzg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDcyOTE1Mw==", "bodyText": "Should we rename this property to write.partitioned.fanout.enabled  ?", "url": "https://github.com/apache/iceberg/pull/1774#discussion_r530729153", "createdAt": "2020-11-26T01:53:19Z", "author": {"login": "openinx"}, "path": "site/docs/configuration.md", "diffHunk": "@@ -68,6 +68,7 @@ Iceberg tables support table properties to configure table behavior, like the de\n | write.summary.partition-limit      | 0                  | Includes partition-level summary stats in snapshot summaries if the changed partition count is less than this limit |\n | write.metadata.delete-after-commit.enabled | false      | Controls whether to delete the oldest version metadata files after commit |\n | write.metadata.previous-versions-max       | 100        | The max number of previous version metadata files to keep before deleting after commit |\n+| write.partitioned.fanout.writer       | false        | Enables Partitioned-Fanout-Writer writes |", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "600d2307bd0705dd290d068eebec268f5846039f"}, "originalPosition": 4}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDcyOTkzNA==", "bodyText": "Should we rename this property to write.partitioned.fanout.enabled ?\n\nwell , let me change it.", "url": "https://github.com/apache/iceberg/pull/1774#discussion_r530729934", "createdAt": "2020-11-26T01:55:44Z", "author": {"login": "XuQianJin-Stars"}, "path": "site/docs/configuration.md", "diffHunk": "@@ -68,6 +68,7 @@ Iceberg tables support table properties to configure table behavior, like the de\n | write.summary.partition-limit      | 0                  | Includes partition-level summary stats in snapshot summaries if the changed partition count is less than this limit |\n | write.metadata.delete-after-commit.enabled | false      | Controls whether to delete the oldest version metadata files after commit |\n | write.metadata.previous-versions-max       | 100        | The max number of previous version metadata files to keep before deleting after commit |\n+| write.partitioned.fanout.writer       | false        | Enables Partitioned-Fanout-Writer writes |", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDcyOTE1Mw=="}, "originalCommit": {"oid": "600d2307bd0705dd290d068eebec268f5846039f"}, "originalPosition": 4}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyODY5Njk2OnYy", "diffSide": "RIGHT", "path": "spark/src/main/java/org/apache/iceberg/spark/source/RowDataRewriter.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQwMTo1OToyNFrOH6JPoQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQwMjowMDozNFrOH6JQ3g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDczMDkxMw==", "bodyText": "nit:  I think it's more clear to just use :\nif(spec.fields().isEmpty()){\n   return UnpartitionedWriter\n} else if(xxx){\n    return SparkPartitionedFanoutWriter ; \n} else {\n    return SparkPartitionedWriter\n}", "url": "https://github.com/apache/iceberg/pull/1774#discussion_r530730913", "createdAt": "2020-11-26T01:59:24Z", "author": {"login": "openinx"}, "path": "spark/src/main/java/org/apache/iceberg/spark/source/RowDataRewriter.java", "diffHunk": "@@ -106,8 +107,15 @@ public RowDataRewriter(Table table, PartitionSpec spec, boolean caseSensitive,\n     if (spec.fields().isEmpty()) {\n       writer = new UnpartitionedWriter<>(spec, format, appenderFactory, fileFactory, io.value(), Long.MAX_VALUE);\n     } else {\n-      writer = new SparkPartitionedWriter(spec, format, appenderFactory, fileFactory, io.value(), Long.MAX_VALUE,\n-          schema, structType);\n+      if (PropertyUtil.propertyAsBoolean(properties,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "600d2307bd0705dd290d068eebec268f5846039f"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDczMTIzMA==", "bodyText": "well", "url": "https://github.com/apache/iceberg/pull/1774#discussion_r530731230", "createdAt": "2020-11-26T02:00:34Z", "author": {"login": "XuQianJin-Stars"}, "path": "spark/src/main/java/org/apache/iceberg/spark/source/RowDataRewriter.java", "diffHunk": "@@ -106,8 +107,15 @@ public RowDataRewriter(Table table, PartitionSpec spec, boolean caseSensitive,\n     if (spec.fields().isEmpty()) {\n       writer = new UnpartitionedWriter<>(spec, format, appenderFactory, fileFactory, io.value(), Long.MAX_VALUE);\n     } else {\n-      writer = new SparkPartitionedWriter(spec, format, appenderFactory, fileFactory, io.value(), Long.MAX_VALUE,\n-          schema, structType);\n+      if (PropertyUtil.propertyAsBoolean(properties,", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDczMDkxMw=="}, "originalCommit": {"oid": "600d2307bd0705dd290d068eebec268f5846039f"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyODcwNDE2OnYy", "diffSide": "RIGHT", "path": "spark/src/test/java/org/apache/iceberg/spark/source/TestSparkDataWrite.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQwMjowMzo0M1rOH6JTxw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQwMjowMzo0M1rOH6JTxw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDczMTk3NQ==", "bodyText": "Do we need an unit test to cover the spark's partitioned.fanout.enabled option ?   I saw there's an unit test which use the table's write.partitioned.fanout.enabled property to define the fanout behavior.", "url": "https://github.com/apache/iceberg/pull/1774#discussion_r530731975", "createdAt": "2020-11-26T02:03:43Z", "author": {"login": "openinx"}, "path": "spark/src/test/java/org/apache/iceberg/spark/source/TestSparkDataWrite.java", "diffHunk": "@@ -327,51 +328,12 @@ public void testUnpartitionedCreateWithTargetFileSizeViaTableProperties() throws\n \n   @Test\n   public void testPartitionedCreateWithTargetFileSizeViaOption() throws IOException {\n-    File parent = temp.newFolder(format.toString());\n-    File location = new File(parent, \"test\");\n-\n-    HadoopTables tables = new HadoopTables(CONF);\n-    PartitionSpec spec = PartitionSpec.builderFor(SCHEMA).identity(\"data\").build();\n-    Table table = tables.create(SCHEMA, spec, location.toString());\n-\n-    List<SimpleRecord> expected = Lists.newArrayListWithCapacity(8000);\n-    for (int i = 0; i < 2000; i++) {\n-      expected.add(new SimpleRecord(i, \"a\"));\n-      expected.add(new SimpleRecord(i, \"b\"));\n-      expected.add(new SimpleRecord(i, \"c\"));\n-      expected.add(new SimpleRecord(i, \"d\"));\n-    }\n-\n-    Dataset<Row> df = spark.createDataFrame(expected, SimpleRecord.class);\n-\n-    df.select(\"id\", \"data\").sort(\"data\").write()\n-        .format(\"iceberg\")\n-        .option(\"write-format\", format.toString())\n-        .mode(\"append\")\n-        .option(\"target-file-size-bytes\", 4) // ~4 bytes; low enough to trigger\n-        .save(location.toString());\n-\n-    table.refresh();\n-\n-    Dataset<Row> result = spark.read()\n-        .format(\"iceberg\")\n-        .load(location.toString());\n-\n-    List<SimpleRecord> actual = result.orderBy(\"id\").as(Encoders.bean(SimpleRecord.class)).collectAsList();\n-    Assert.assertEquals(\"Number of rows should match\", expected.size(), actual.size());\n-    Assert.assertEquals(\"Result rows should match\", expected, actual);\n+    partitionedCreateWithTargetFileSizeViaOption(false);\n+  }\n \n-    List<DataFile> files = Lists.newArrayList();\n-    for (ManifestFile manifest : table.currentSnapshot().allManifests()) {\n-      for (DataFile file : ManifestFiles.read(manifest, table.io())) {\n-        files.add(file);\n-      }\n-    }\n-    // TODO: ORC file now not support target file size\n-    if (!format.equals(FileFormat.ORC)) {\n-      Assert.assertEquals(\"Should have 8 DataFiles\", 8, files.size());\n-      Assert.assertTrue(\"All DataFiles contain 1000 rows\", files.stream().allMatch(d -> d.recordCount() == 1000));\n-    }\n+  @Test\n+  public void testPartitionedFanoutCreateWithTargetFileSizeViaOption() throws IOException {\n+    partitionedCreateWithTargetFileSizeViaOption(true);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "600d2307bd0705dd290d068eebec268f5846039f"}, "originalPosition": 61}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyODcwOTYwOnYy", "diffSide": "RIGHT", "path": "spark2/src/main/java/org/apache/iceberg/spark/source/Writer.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQwMjowNjozMFrOH6JWzw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQwMjowNjozMFrOH6JWzw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDczMjc1MQ==", "bodyText": "nit:  could simplify it as:\nif(spec.fields().isEmpty()){\n\n} else if(partitionedFanoutEnabled){\n\n} else {\n\n}", "url": "https://github.com/apache/iceberg/pull/1774#discussion_r530732751", "createdAt": "2020-11-26T02:06:30Z", "author": {"login": "openinx"}, "path": "spark2/src/main/java/org/apache/iceberg/spark/source/Writer.java", "diffHunk": "@@ -271,8 +280,13 @@ public String toString() {\n       if (spec.fields().isEmpty()) {\n         return new Unpartitioned24Writer(spec, format, appenderFactory, fileFactory, io.value(), targetFileSize);\n       } else {\n-        return new Partitioned24Writer(spec, format, appenderFactory, fileFactory, io.value(),\n-            targetFileSize, writeSchema, dsSchema);\n+        if (partitionedFanoutEnabled) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "600d2307bd0705dd290d068eebec268f5846039f"}, "originalPosition": 65}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyODcxMjAxOnYy", "diffSide": "RIGHT", "path": "spark2/src/main/java/org/apache/iceberg/spark/source/Writer.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQwMjowODowNVrOH6JYRw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQwMjowODowNVrOH6JYRw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDczMzEyNw==", "bodyText": "nit: format those lines as:\n    PartitionedFanout24Writer(PartitionSpec spec, FileFormat format,\n                              SparkAppenderFactory appenderFactory,\n                              OutputFileFactory fileFactory, FileIO fileIo, long targetFileSize,\n                              Schema schema, StructType sparkSchema) {\n      super(spec, format, appenderFactory, fileFactory, fileIo, targetFileSize, schema, sparkSchema);\n    }", "url": "https://github.com/apache/iceberg/pull/1774#discussion_r530733127", "createdAt": "2020-11-26T02:08:05Z", "author": {"login": "openinx"}, "path": "spark2/src/main/java/org/apache/iceberg/spark/source/Writer.java", "diffHunk": "@@ -307,4 +321,23 @@ public WriterCommitMessage commit() throws IOException {\n       return new TaskCommit(complete());\n     }\n   }\n+\n+  private static class PartitionedFanout24Writer extends SparkPartitionedFanoutWriter\n+      implements DataWriter<InternalRow> {\n+\n+    PartitionedFanout24Writer(PartitionSpec spec, FileFormat format,\n+        SparkAppenderFactory appenderFactory,\n+        OutputFileFactory fileFactory, FileIO fileIo, long targetFileSize,\n+        Schema schema, StructType sparkSchema) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "600d2307bd0705dd290d068eebec268f5846039f"}, "originalPosition": 86}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyODcxMjY4OnYy", "diffSide": "RIGHT", "path": "spark3/src/main/java/org/apache/iceberg/spark/source/SparkWrite.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQwMjowODozOFrOH6JYtQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQwMjowODozOFrOH6JYtQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDczMzIzNw==", "bodyText": "ditto", "url": "https://github.com/apache/iceberg/pull/1774#discussion_r530733237", "createdAt": "2020-11-26T02:08:38Z", "author": {"login": "openinx"}, "path": "spark3/src/main/java/org/apache/iceberg/spark/source/SparkWrite.java", "diffHunk": "@@ -420,8 +430,15 @@ protected WriterFactory(PartitionSpec spec, FileFormat format, LocationProvider\n       if (spec.fields().isEmpty()) {\n         return new Unpartitioned3Writer(spec, format, appenderFactory, fileFactory, io.value(), targetFileSize);\n       } else {\n-        return new Partitioned3Writer(\n-            spec, format, appenderFactory, fileFactory, io.value(), targetFileSize, writeSchema, dsSchema);\n+        if (partitionedFanoutEnabled) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "600d2307bd0705dd290d068eebec268f5846039f"}, "originalPosition": 66}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMyODcxMzEyOnYy", "diffSide": "RIGHT", "path": "spark3/src/main/java/org/apache/iceberg/spark/source/SparkWrite.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQwMjowODo0NVrOH6JY7w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yNlQwMjowODo0NVrOH6JY7w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMDczMzI5NQ==", "bodyText": "nit: format", "url": "https://github.com/apache/iceberg/pull/1774#discussion_r530733295", "createdAt": "2020-11-26T02:08:45Z", "author": {"login": "openinx"}, "path": "spark3/src/main/java/org/apache/iceberg/spark/source/SparkWrite.java", "diffHunk": "@@ -455,4 +472,20 @@ public WriterCommitMessage commit() throws IOException {\n       return new TaskCommit(complete());\n     }\n   }\n+\n+  private static class PartitionedFanout3Writer extends SparkPartitionedFanoutWriter\n+      implements DataWriter<InternalRow> {\n+    PartitionedFanout3Writer(PartitionSpec spec, FileFormat format, SparkAppenderFactory appenderFactory,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "600d2307bd0705dd290d068eebec268f5846039f"}, "originalPosition": 85}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3458, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}