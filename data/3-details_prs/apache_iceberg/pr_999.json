{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDEzMTIwNTQx", "number": 999, "title": "Spark: Pass correct types to get data from InternalRow", "bodyText": "This fixes a problem with Spark 3.0 CTAS queries that use tinyint or smallint types. When Iceberg converts a Dataset schema, it promotes both smaller integers to int. Normally, Spark will insert casts in the analyzer so that the values are ints, but during a CTAS query, the table is created and the values may be passed as short or byte in the rows passed to Iceberg.\nThe problem happens when Iceberg accesses values from InternalRow. Before this commit, Iceberg would use the table's type to fetch a value, causing unsafe rows to return a corrupted byte or short value because 4 bytes had been read instead of 1 or 2.\nThe fix is to keep track of the Dataset schema and use it when accessing fields. This required building visitors for Avro and Parquet that traverse a Spark schema with a file schema.", "createdAt": "2020-05-04T18:46:14Z", "url": "https://github.com/apache/iceberg/pull/999", "merged": true, "mergeCommit": {"oid": "699e68a919c708ccbb43179928e3e7fb4fec58f6"}, "closed": true, "closedAt": "2020-05-07T15:55:01Z", "author": {"login": "rdblue"}, "timelineItems": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABceD9rvAH2gAyNDEzMTIwNTQxOmY2YzYxMDljMzFlMzlmODdjZDcyOGEyZTc3MDIzNjU4ZTkzZTgzYTU=", "endCursor": "Y3Vyc29yOnYyOpPPAAABcesY21gFqTQwNjg0NzEzMA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "f6c6109c31e39f87cd728a2e77023658e93e83a5", "author": {"user": {"login": "rdblue", "name": "Ryan Blue"}}, "url": "https://github.com/apache/iceberg/commit/f6c6109c31e39f87cd728a2e77023658e93e83a5", "committedDate": "2020-05-04T18:40:54Z", "message": "Spark: Pass correct types to get data from InternalRow."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "65cfb2952480d0b89351375ac5088068bf2f97cf", "author": {"user": {"login": "rdblue", "name": "Ryan Blue"}}, "url": "https://github.com/apache/iceberg/commit/65cfb2952480d0b89351375ac5088068bf2f97cf", "committedDate": "2020-05-04T20:28:23Z", "message": "Add missing methods from the refactor in #950."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "65c341ea077171f6cd015dd031ef5b1de7d90bab", "author": {"user": {"login": "rdblue", "name": "Ryan Blue"}}, "url": "https://github.com/apache/iceberg/commit/65c341ea077171f6cd015dd031ef5b1de7d90bab", "committedDate": "2020-05-04T21:31:49Z", "message": "Fix errorprone problems."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e6849265ce3d6031d913b3abc8f4090f956957fb", "author": {"user": {"login": "rdblue", "name": "Ryan Blue"}}, "url": "https://github.com/apache/iceberg/commit/e6849265ce3d6031d913b3abc8f4090f956957fb", "committedDate": "2020-05-05T15:59:55Z", "message": "Fix checkstyle problems."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fbef50728d347ec3b695c42b3d6b54b7ab5b2ca0", "author": {"user": {"login": "rdblue", "name": "Ryan Blue"}}, "url": "https://github.com/apache/iceberg/commit/fbef50728d347ec3b695c42b3d6b54b7ab5b2ca0", "committedDate": "2020-05-05T16:12:08Z", "message": "Fix benchmarks."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d5d9afe092ce9d6bc496885785a8bdecc68b7261", "author": {"user": {"login": "rdblue", "name": "Ryan Blue"}}, "url": "https://github.com/apache/iceberg/commit/d5d9afe092ce9d6bc496885785a8bdecc68b7261", "committedDate": "2020-05-05T16:32:07Z", "message": "Fix checkstyle."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA2NjkwMTIy", "url": "https://github.com/apache/iceberg/pull/999#pullrequestreview-406690122", "createdAt": "2020-05-06T14:48:49Z", "commit": {"oid": "d5d9afe092ce9d6bc496885785a8bdecc68b7261"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNlQxNDo0ODo0OVrOGRWyFw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNS0wNlQxNTozMTowOFrOGRYyow==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDg1MjI0Nw==", "bodyText": "I presume this will only be nullable unions", "url": "https://github.com/apache/iceberg/pull/999#discussion_r420852247", "createdAt": "2020-05-06T14:48:49Z", "author": {"login": "rdsr"}, "path": "spark/src/main/java/org/apache/iceberg/spark/data/AvroWithSparkSchemaVisitor.java", "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.data;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import java.util.Deque;\n+import java.util.List;\n+import org.apache.avro.Schema;\n+import org.apache.iceberg.avro.AvroSchemaUtil;\n+import org.apache.iceberg.avro.LogicalMap;\n+import org.apache.spark.sql.types.ArrayType;\n+import org.apache.spark.sql.types.DataType;\n+import org.apache.spark.sql.types.DataTypes;\n+import org.apache.spark.sql.types.MapType;\n+import org.apache.spark.sql.types.StringType;\n+import org.apache.spark.sql.types.StructField;\n+import org.apache.spark.sql.types.StructType;\n+\n+public abstract class AvroWithSparkSchemaVisitor<T> {\n+  public static <T> T visit(StructType struct, Schema schema, AvroWithSparkSchemaVisitor<T> visitor) {\n+    return visitRecord(struct, schema, visitor);\n+  }\n+\n+  public static <T> T visit(DataType type, Schema schema, AvroWithSparkSchemaVisitor<T> visitor) {\n+    switch (schema.getType()) {\n+      case RECORD:\n+        Preconditions.checkArgument(type instanceof StructType, \"Invalid struct: %s is not a struct\", type);\n+        return visitRecord((StructType) type, schema, visitor);\n+\n+      case UNION:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d5d9afe092ce9d6bc496885785a8bdecc68b7261"}, "originalPosition": 48}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDg1NTQ4Ng==", "bodyText": "Since we are traversing this with Spark schema, which does not support unions. Should we make sure that we are only processing nullable unions?", "url": "https://github.com/apache/iceberg/pull/999#discussion_r420855486", "createdAt": "2020-05-06T14:52:59Z", "author": {"login": "rdsr"}, "path": "spark/src/main/java/org/apache/iceberg/spark/data/AvroWithSparkSchemaVisitor.java", "diffHunk": "@@ -0,0 +1,150 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.data;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import java.util.Deque;\n+import java.util.List;\n+import org.apache.avro.Schema;\n+import org.apache.iceberg.avro.AvroSchemaUtil;\n+import org.apache.iceberg.avro.LogicalMap;\n+import org.apache.spark.sql.types.ArrayType;\n+import org.apache.spark.sql.types.DataType;\n+import org.apache.spark.sql.types.DataTypes;\n+import org.apache.spark.sql.types.MapType;\n+import org.apache.spark.sql.types.StringType;\n+import org.apache.spark.sql.types.StructField;\n+import org.apache.spark.sql.types.StructType;\n+\n+public abstract class AvroWithSparkSchemaVisitor<T> {\n+  public static <T> T visit(StructType struct, Schema schema, AvroWithSparkSchemaVisitor<T> visitor) {\n+    return visitRecord(struct, schema, visitor);\n+  }\n+\n+  public static <T> T visit(DataType type, Schema schema, AvroWithSparkSchemaVisitor<T> visitor) {\n+    switch (schema.getType()) {\n+      case RECORD:\n+        Preconditions.checkArgument(type instanceof StructType, \"Invalid struct: %s is not a struct\", type);\n+        return visitRecord((StructType) type, schema, visitor);\n+\n+      case UNION:\n+        return visitUnion(type, schema, visitor);\n+\n+      case ARRAY:\n+        return visitArray(type, schema, visitor);\n+\n+      case MAP:\n+        Preconditions.checkArgument(type instanceof MapType, \"Invalid map: %s is not a map\", type);\n+        MapType map = (MapType) type;\n+        Preconditions.checkArgument(map.keyType() instanceof StringType,\n+            \"Invalid map: %s is not a string\", map.keyType());\n+        return visitor.map(map, schema, visit(map.valueType(), schema.getValueType(), visitor));\n+\n+      default:\n+        return visitor.primitive(type, schema);\n+    }\n+  }\n+\n+  private static <T> T visitRecord(StructType struct, Schema record, AvroWithSparkSchemaVisitor<T> visitor) {\n+    // check to make sure this hasn't been visited before\n+    String name = record.getFullName();\n+    Preconditions.checkState(!visitor.recordLevels.contains(name),\n+        \"Cannot process recursive Avro record %s\", name);\n+    StructField[] sFields = struct.fields();\n+    List<Schema.Field> fields = record.getFields();\n+    Preconditions.checkArgument(sFields.length == fields.size(),\n+        \"Structs do not match: %s != %s\", struct, record);\n+\n+    visitor.recordLevels.push(name);\n+\n+    List<String> names = Lists.newArrayListWithExpectedSize(fields.size());\n+    List<T> results = Lists.newArrayListWithExpectedSize(fields.size());\n+    for (int i = 0; i < sFields.length; i += 1) {\n+      StructField sField = sFields[i];\n+      Schema.Field field = fields.get(i);\n+      Preconditions.checkArgument(AvroSchemaUtil.makeCompatibleName(sField.name()).equals(field.name()),\n+          \"Structs do not match: field %s != %s\", sField.name(), field.name());\n+      results.add(visit(sField.dataType(), field.schema(), visitor));\n+    }\n+\n+    visitor.recordLevels.pop();\n+\n+    return visitor.record(struct, record, names, results);\n+  }\n+\n+  private static <T> T visitUnion(DataType type, Schema union, AvroWithSparkSchemaVisitor<T> visitor) {\n+    List<Schema> types = union.getTypes();\n+    List<T> options = Lists.newArrayListWithExpectedSize(types.size());\n+    for (Schema branch : types) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d5d9afe092ce9d6bc496885785a8bdecc68b7261"}, "originalPosition": 96}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDg4MTYzMQ==", "bodyText": "nit:  this can be on same line", "url": "https://github.com/apache/iceberg/pull/999#discussion_r420881631", "createdAt": "2020-05-06T15:26:28Z", "author": {"login": "rdsr"}, "path": "spark/src/main/java/org/apache/iceberg/spark/data/ParquetWithSparkSchemaVisitor.java", "diffHunk": "@@ -0,0 +1,209 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.data;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import java.util.Deque;\n+import java.util.List;\n+import org.apache.iceberg.avro.AvroSchemaUtil;\n+import org.apache.parquet.schema.GroupType;\n+import org.apache.parquet.schema.MessageType;\n+import org.apache.parquet.schema.OriginalType;\n+import org.apache.parquet.schema.PrimitiveType;\n+import org.apache.parquet.schema.Type;\n+import org.apache.parquet.schema.Type.Repetition;\n+import org.apache.spark.sql.types.ArrayType;\n+import org.apache.spark.sql.types.DataType;\n+import org.apache.spark.sql.types.MapType;\n+import org.apache.spark.sql.types.Metadata;\n+import org.apache.spark.sql.types.StructField;\n+import org.apache.spark.sql.types.StructType;\n+\n+/**\n+ * Visitor for traversing a Parquet type with a companion Spark type.\n+ *\n+ * @param <T> the Java class returned by the visitor\n+ */\n+public class ParquetWithSparkSchemaVisitor<T> {\n+  private final Deque<String> fieldNames = Lists.newLinkedList();\n+\n+  public static <T> T visit(DataType sType, Type type, ParquetWithSparkSchemaVisitor<T> visitor) {\n+    Preconditions.checkArgument(sType != null, \"Invalid DataType: null\");\n+    if (type instanceof MessageType) {\n+      Preconditions.checkArgument(sType instanceof StructType, \"Invalid struct: %s is not a struct\", sType);\n+      StructType struct = (StructType) sType;\n+      return visitor.message(struct, (MessageType) type, visitFields(struct, type.asGroupType(), visitor));\n+\n+    } else if (type.isPrimitive()) {\n+      return visitor.primitive(sType, type.asPrimitiveType());\n+\n+    } else {\n+      // if not a primitive, the typeId must be a group\n+      GroupType group = type.asGroupType();\n+      OriginalType annotation = group.getOriginalType();\n+      if (annotation != null) {\n+        switch (annotation) {\n+          case LIST:\n+            Preconditions.checkArgument(!group.isRepetition(Repetition.REPEATED),\n+                \"Invalid list: top-level group is repeated: %s\", group);\n+            Preconditions.checkArgument(group.getFieldCount() == 1,\n+                \"Invalid list: does not contain single repeated field: %s\", group);\n+\n+            GroupType repeatedElement = group.getFields().get(0).asGroupType();\n+            Preconditions.checkArgument(repeatedElement.isRepetition(Repetition.REPEATED),\n+                \"Invalid list: inner group is not repeated\");\n+            Preconditions.checkArgument(repeatedElement.getFieldCount() <= 1,\n+                \"Invalid list: repeated group is not a single field: %s\", group);\n+\n+            Preconditions.checkArgument(sType instanceof ArrayType, \"Invalid list: %s is not an array\", sType);\n+            ArrayType array = (ArrayType) sType;\n+            StructField element = new StructField(\n+                \"element\", array.elementType(), array.containsNull(), Metadata.empty());\n+\n+            visitor.fieldNames.push(repeatedElement.getName());\n+            try {\n+              T elementResult = null;\n+              if (repeatedElement.getFieldCount() > 0) {\n+                elementResult = visitField(element, repeatedElement.getType(0), visitor);\n+              }\n+\n+              return visitor.list(array, group, elementResult);\n+\n+            } finally {\n+              visitor.fieldNames.pop();\n+            }\n+\n+          case MAP:\n+            Preconditions.checkArgument(!group.isRepetition(Repetition.REPEATED),\n+                \"Invalid map: top-level group is repeated: %s\", group);\n+            Preconditions.checkArgument(group.getFieldCount() == 1,\n+                \"Invalid map: does not contain single repeated field: %s\", group);\n+\n+            GroupType repeatedKeyValue = group.getType(0).asGroupType();\n+            Preconditions.checkArgument(repeatedKeyValue.isRepetition(Repetition.REPEATED),\n+                \"Invalid map: inner group is not repeated\");\n+            Preconditions.checkArgument(repeatedKeyValue.getFieldCount() <= 2,\n+                \"Invalid map: repeated group does not have 2 fields\");\n+\n+            Preconditions.checkArgument(sType instanceof MapType, \"Invalid map: %s is not a map\", sType);\n+            MapType map = (MapType) sType;\n+            StructField keyField = new StructField(\"key\", map.keyType(), false, Metadata.empty());\n+            StructField valueField = new StructField(\n+                \"value\", map.valueType(), map.valueContainsNull(), Metadata.empty());\n+\n+            visitor.fieldNames.push(repeatedKeyValue.getName());\n+            try {\n+              T keyResult = null;\n+              T valueResult = null;\n+              switch (repeatedKeyValue.getFieldCount()) {\n+                case 2:\n+                  // if there are 2 fields, both key and value are projected\n+                  keyResult = visitField(keyField, repeatedKeyValue.getType(0), visitor);\n+                  valueResult = visitField(valueField, repeatedKeyValue.getType(1), visitor);\n+                  break;\n+                case 1:\n+                  // if there is just one, use the name to determine what it is\n+                  Type keyOrValue = repeatedKeyValue.getType(0);\n+                  if (keyOrValue.getName().equalsIgnoreCase(\"key\")) {\n+                    keyResult = visitField(keyField, keyOrValue, visitor);\n+                    // value result remains null\n+                  } else {\n+                    valueResult = visitField(valueField, keyOrValue, visitor);\n+                    // key result remains null\n+                  }\n+                  break;\n+                default:\n+                  // both results will remain null\n+              }\n+\n+              return visitor.map(map, group, keyResult, valueResult);\n+\n+            } finally {\n+              visitor.fieldNames.pop();\n+            }\n+\n+          default:\n+        }\n+      }\n+\n+      Preconditions.checkArgument(sType instanceof StructType, \"Invalid struct: %s is not a struct\", sType);\n+      StructType struct = (StructType) sType;\n+      return visitor.struct(struct, group, visitFields(struct, group, visitor));\n+    }\n+  }\n+\n+  private static <T> T visitField(StructField sField, Type field, ParquetWithSparkSchemaVisitor<T> visitor) {\n+    visitor.fieldNames.push(field.getName());\n+    try {\n+      return visit(sField.dataType(), field, visitor);\n+    } finally {\n+      visitor.fieldNames.pop();\n+    }\n+  }\n+\n+  private static <T> List<T> visitFields(StructType struct, GroupType group,\n+                                         ParquetWithSparkSchemaVisitor<T> visitor) {\n+    StructField[] sFields = struct.fields();\n+    Preconditions.checkArgument(sFields.length == group.getFieldCount(),\n+        \"Structs do not match: %s and %s\", struct, group);\n+    List<T> results = Lists.newArrayListWithExpectedSize(group.getFieldCount());\n+    for (int i = 0; i < sFields.length; i += 1) {\n+      Type field = group.getFields().get(i);\n+      StructField sField = sFields[i];\n+      Preconditions.checkArgument(field.getName().equals(AvroSchemaUtil.makeCompatibleName(sField.name())),\n+          \"Structs do not match: field %s != %s\", field.getName(), sField.name());\n+      results.add(visitField(sField, field, visitor));\n+    }\n+\n+    return results;\n+  }\n+\n+  public T message(StructType sStruct, MessageType message, List<T> fields) {\n+    return null;\n+  }\n+\n+  public T struct(StructType sStruct, GroupType struct, List<T> fields) {\n+    return null;\n+  }\n+\n+  public T list(ArrayType sArray, GroupType array, T element) {\n+    return null;\n+  }\n+\n+  public T map(MapType sMap, GroupType map, T key, T value) {\n+    return null;\n+  }\n+\n+  public T primitive(DataType sPrimitive,\n+                     PrimitiveType primitive) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d5d9afe092ce9d6bc496885785a8bdecc68b7261"}, "originalPosition": 196}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQyMDg4NTE1NQ==", "bodyText": "should we expose this functionality through the beforeField and afterField apis?", "url": "https://github.com/apache/iceberg/pull/999#discussion_r420885155", "createdAt": "2020-05-06T15:31:08Z", "author": {"login": "rdsr"}, "path": "spark/src/main/java/org/apache/iceberg/spark/data/ParquetWithSparkSchemaVisitor.java", "diffHunk": "@@ -0,0 +1,209 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.data;\n+\n+import com.google.common.base.Preconditions;\n+import com.google.common.collect.Lists;\n+import java.util.Deque;\n+import java.util.List;\n+import org.apache.iceberg.avro.AvroSchemaUtil;\n+import org.apache.parquet.schema.GroupType;\n+import org.apache.parquet.schema.MessageType;\n+import org.apache.parquet.schema.OriginalType;\n+import org.apache.parquet.schema.PrimitiveType;\n+import org.apache.parquet.schema.Type;\n+import org.apache.parquet.schema.Type.Repetition;\n+import org.apache.spark.sql.types.ArrayType;\n+import org.apache.spark.sql.types.DataType;\n+import org.apache.spark.sql.types.MapType;\n+import org.apache.spark.sql.types.Metadata;\n+import org.apache.spark.sql.types.StructField;\n+import org.apache.spark.sql.types.StructType;\n+\n+/**\n+ * Visitor for traversing a Parquet type with a companion Spark type.\n+ *\n+ * @param <T> the Java class returned by the visitor\n+ */\n+public class ParquetWithSparkSchemaVisitor<T> {\n+  private final Deque<String> fieldNames = Lists.newLinkedList();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "d5d9afe092ce9d6bc496885785a8bdecc68b7261"}, "originalPosition": 46}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "05d6680b79ce9a8b3f0c3894f8afcc70ad788403", "author": {"user": {"login": "rdblue", "name": "Ryan Blue"}}, "url": "https://github.com/apache/iceberg/commit/05d6680b79ce9a8b3f0c3894f8afcc70ad788403", "committedDate": "2020-05-06T17:16:22Z", "message": "Fix issues from review."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9f7ba7ab239fe9d244233b78025c700ffa985c29", "author": {"user": {"login": "rdblue", "name": "Ryan Blue"}}, "url": "https://github.com/apache/iceberg/commit/9f7ba7ab239fe9d244233b78025c700ffa985c29", "committedDate": "2020-05-06T17:31:46Z", "message": "Fix checkstyle."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDA2ODQ3MTMw", "url": "https://github.com/apache/iceberg/pull/999#pullrequestreview-406847130", "createdAt": "2020-05-06T17:46:47Z", "commit": {"oid": "9f7ba7ab239fe9d244233b78025c700ffa985c29"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4653, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}