{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDkxNjcxMzEy", "number": 1490, "title": "Hive read docs", "bodyText": "This change adds documentation for Hive read support.", "createdAt": "2020-09-23T10:20:50Z", "url": "https://github.com/apache/iceberg/pull/1490", "merged": true, "mergeCommit": {"oid": "afdf265526e2f84502dc767fbf18c91b67152bd8"}, "closed": true, "closedAt": "2020-10-01T17:51:07Z", "author": {"login": "massdosage"}, "timelineItems": {"totalCount": 11, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdLEaOYAH2gAyNDkxNjcxMzEyOjYwZDI4MWI2OGYxNWM0NTBiODkyNjNjYjY0ZWI4MjY1M2ExYmExMmY=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdOVI8YgFqTUwMDU4NDAzMw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "60d281b68f15c450b89263cb64eb82653a1ba12f", "author": {"user": {"login": "massdosage", "name": "Adrian Woodhead"}}, "url": "https://github.com/apache/iceberg/commit/60d281b68f15c450b89263cb64eb82653a1ba12f", "committedDate": "2020-09-21T14:38:40Z", "message": "first cut at Hive docs"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4b8084e4eb6403cd372e1f9ef7edf4f2477e3624", "author": {"user": {"login": "massdosage", "name": "Adrian Woodhead"}}, "url": "https://github.com/apache/iceberg/commit/4b8084e4eb6403cd372e1f9ef7edf4f2477e3624", "committedDate": "2020-09-23T10:15:38Z", "message": "various improvements"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9a418b47ce88221b0b7956f5fbae01c706c067d9", "author": {"user": {"login": "massdosage", "name": "Adrian Woodhead"}}, "url": "https://github.com/apache/iceberg/commit/9a418b47ce88221b0b7956f5fbae01c706c067d9", "committedDate": "2020-09-23T10:20:10Z", "message": "lower the case"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk0NTE3Mjc3", "url": "https://github.com/apache/iceberg/pull/1490#pullrequestreview-494517277", "createdAt": "2020-09-23T10:28:18Z", "commit": {"oid": "9a418b47ce88221b0b7956f5fbae01c706c067d9"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QxMDoyODoxOFrOHWkKtQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QxMDoyODoxOFrOHWkKtQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzQyMzI4NQ==", "bodyText": "In reality this is Catalog specific. Works with HadoopTables / HadoopCatalog.\nI am not entirely sure, but I think this step could be omitted with HiveCatalog. @marton-bod?", "url": "https://github.com/apache/iceberg/pull/1490#discussion_r493423285", "createdAt": "2020-09-23T10:28:18Z", "author": {"login": "pvary"}, "path": "site/docs/hive.md", "diffHunk": "@@ -0,0 +1,62 @@\n+<!--\n+ - Licensed to the Apache Software Foundation (ASF) under one or more\n+ - contributor license agreements.  See the NOTICE file distributed with\n+ - this work for additional information regarding copyright ownership.\n+ - The ASF licenses this file to You under the Apache License, Version 2.0\n+ - (the \"License\"); you may not use this file except in compliance with\n+ - the License.  You may obtain a copy of the License at\n+ -\n+ -   http://www.apache.org/licenses/LICENSE-2.0\n+ -\n+ - Unless required by applicable law or agreed to in writing, software\n+ - distributed under the License is distributed on an \"AS IS\" BASIS,\n+ - WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ - See the License for the specific language governing permissions and\n+ - limitations under the License.\n+ -->\n+\n+# Hive\n+\n+## Hive read support\n+Iceberg supports the reading of Iceberg tables from [Hive](https://hive.apache.org) by using a [StorageHandler](https://cwiki.apache.org/confluence/display/Hive/StorageHandlers). \n+\n+### Table creation\n+This section explains the various steps needed in order to overlay a Hive table \"on top of\" an existing Iceberg table.\n+\n+#### Create an Iceberg table\n+The first step is to create an Iceberg table using the Spark/Java/Python API. For the purposes of this documentation we will assume that the table is called `table_a` and that the base location of the table is `s3://some_bucket/some_path/table_a`.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a418b47ce88221b0b7956f5fbae01c706c067d9"}, "originalPosition": 27}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk0NTM5NTE2", "url": "https://github.com/apache/iceberg/pull/1490#pullrequestreview-494539516", "createdAt": "2020-09-23T10:59:54Z", "commit": {"oid": "9a418b47ce88221b0b7956f5fbae01c706c067d9"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QxMDo1OTo1NVrOHWl6Fw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QxMDo1OTo1NVrOHWl6Fw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzQ1MTc5OQ==", "bodyText": "Nit: Consider There is a plan to add this in the future. Soon to me implies that it's being actively worked on and it sounds more correct imo to leave it as \"in the future\" over \"soon\".\nAgain though, just a nit.", "url": "https://github.com/apache/iceberg/pull/1490#discussion_r493451799", "createdAt": "2020-09-23T10:59:55Z", "author": {"login": "kbendick"}, "path": "site/docs/hive.md", "diffHunk": "@@ -0,0 +1,62 @@\n+<!--\n+ - Licensed to the Apache Software Foundation (ASF) under one or more\n+ - contributor license agreements.  See the NOTICE file distributed with\n+ - this work for additional information regarding copyright ownership.\n+ - The ASF licenses this file to You under the Apache License, Version 2.0\n+ - (the \"License\"); you may not use this file except in compliance with\n+ - the License.  You may obtain a copy of the License at\n+ -\n+ -   http://www.apache.org/licenses/LICENSE-2.0\n+ -\n+ - Unless required by applicable law or agreed to in writing, software\n+ - distributed under the License is distributed on an \"AS IS\" BASIS,\n+ - WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ - See the License for the specific language governing permissions and\n+ - limitations under the License.\n+ -->\n+\n+# Hive\n+\n+## Hive read support\n+Iceberg supports the reading of Iceberg tables from [Hive](https://hive.apache.org) by using a [StorageHandler](https://cwiki.apache.org/confluence/display/Hive/StorageHandlers). \n+\n+### Table creation\n+This section explains the various steps needed in order to overlay a Hive table \"on top of\" an existing Iceberg table.\n+\n+#### Create an Iceberg table\n+The first step is to create an Iceberg table using the Spark/Java/Python API. For the purposes of this documentation we will assume that the table is called `table_a` and that the base location of the table is `s3://some_bucket/some_path/table_a`.\n+\n+#### Add the Iceberg Hive Runtime jar file to the Hive classpath\n+The `HiveIcebergStorageHandler` and supporting classes need to be made available on Hive's classpath. For example, if using Hive 2.x and the Hive shell, this can be achieved by issuing a statement like so:\n+```sql\n+add jar /path/to/iceberg-hive-runtime.jar;\n+```\n+There are many others ways to achieve this including adding the jar file to Hive's auxillary classpath (so it is available by default) - please refer to Hive's documentation for more information.\n+\n+#### Create a Hive table\n+Now overlay a Hive table on top of this Iceberg table by issuing Hive DDL like so:\n+```sql\n+CREATE EXTERNAL TABLE table_a \n+STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' \n+LOCATION 's3://some_bucket/some_path/table_a';\n+```\n+\n+#### Query the Iceberg table via Hive\n+You should now be able to issue Hive SQL `SELECT` queries using the above table and see the results returned from the underlying Iceberg table. Both the Map Reduce and Tez query execution engines are supported.\n+```sql\n+SELECT * from table_a;\n+```\n+\n+### Features\n+\n+#### Predicate pushdown\n+Pushdown of the Hive SQL `WHERE` clause has been implemented so that these filters are used at the Iceberg TableScan level as well as by the Parquet and ORC Readers.\n+\n+#### Column selection\n+The projection of columns from the HiveSQL `SELECT` clause down to the Iceberg readers to reduce the number of columns read is currently being worked on.\n+\n+### Time travel and system tables\n+Support for accesing Iceberg's time travel feature and other system tables isn't currently supported but there is a plan to add this soon.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9a418b47ce88221b0b7956f5fbae01c706c067d9"}, "originalPosition": 59}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "431c58a72843d51bd6636c9ef30c3fc21040117d", "author": {"user": {"login": "massdosage", "name": "Adrian Woodhead"}}, "url": "https://github.com/apache/iceberg/commit/431c58a72843d51bd6636c9ef30c3fc21040117d", "committedDate": "2020-09-23T11:03:06Z", "message": "in the future"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk0ODUyNzcw", "url": "https://github.com/apache/iceberg/pull/1490#pullrequestreview-494852770", "createdAt": "2020-09-23T16:43:36Z", "commit": {"oid": "431c58a72843d51bd6636c9ef30c3fc21040117d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QxNjo0MzozN1rOHW3ZtA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yM1QxNjo0MzozN1rOHW3ZtA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MzczODQyMA==", "bodyText": "Should we update the Hive metastore integration to automatically set up the correct StorageHandler so HMS tables are automatically readable? That seems reasonable for 0.10.0.", "url": "https://github.com/apache/iceberg/pull/1490#discussion_r493738420", "createdAt": "2020-09-23T16:43:37Z", "author": {"login": "rdblue"}, "path": "site/docs/hive.md", "diffHunk": "@@ -0,0 +1,62 @@\n+<!--\n+ - Licensed to the Apache Software Foundation (ASF) under one or more\n+ - contributor license agreements.  See the NOTICE file distributed with\n+ - this work for additional information regarding copyright ownership.\n+ - The ASF licenses this file to You under the Apache License, Version 2.0\n+ - (the \"License\"); you may not use this file except in compliance with\n+ - the License.  You may obtain a copy of the License at\n+ -\n+ -   http://www.apache.org/licenses/LICENSE-2.0\n+ -\n+ - Unless required by applicable law or agreed to in writing, software\n+ - distributed under the License is distributed on an \"AS IS\" BASIS,\n+ - WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ - See the License for the specific language governing permissions and\n+ - limitations under the License.\n+ -->\n+\n+# Hive\n+\n+## Hive read support\n+Iceberg supports the reading of Iceberg tables from [Hive](https://hive.apache.org) by using a [StorageHandler](https://cwiki.apache.org/confluence/display/Hive/StorageHandlers). \n+\n+### Table creation\n+This section explains the various steps needed in order to overlay a Hive table \"on top of\" an existing Iceberg table.\n+\n+#### Create an Iceberg table", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "431c58a72843d51bd6636c9ef30c3fc21040117d"}, "originalPosition": 26}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk1OTg3Njcw", "url": "https://github.com/apache/iceberg/pull/1490#pullrequestreview-495987670", "createdAt": "2020-09-24T22:15:33Z", "commit": {"oid": "431c58a72843d51bd6636c9ef30c3fc21040117d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQyMjoxNTozM1rOHXud7Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQyMjoxNTozM1rOHXud7Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDY0MDYyMQ==", "bodyText": "Does this need to be available to the metastore or just the client?", "url": "https://github.com/apache/iceberg/pull/1490#discussion_r494640621", "createdAt": "2020-09-24T22:15:33Z", "author": {"login": "rdblue"}, "path": "site/docs/hive.md", "diffHunk": "@@ -0,0 +1,62 @@\n+<!--\n+ - Licensed to the Apache Software Foundation (ASF) under one or more\n+ - contributor license agreements.  See the NOTICE file distributed with\n+ - this work for additional information regarding copyright ownership.\n+ - The ASF licenses this file to You under the Apache License, Version 2.0\n+ - (the \"License\"); you may not use this file except in compliance with\n+ - the License.  You may obtain a copy of the License at\n+ -\n+ -   http://www.apache.org/licenses/LICENSE-2.0\n+ -\n+ - Unless required by applicable law or agreed to in writing, software\n+ - distributed under the License is distributed on an \"AS IS\" BASIS,\n+ - WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ - See the License for the specific language governing permissions and\n+ - limitations under the License.\n+ -->\n+\n+# Hive\n+\n+## Hive read support\n+Iceberg supports the reading of Iceberg tables from [Hive](https://hive.apache.org) by using a [StorageHandler](https://cwiki.apache.org/confluence/display/Hive/StorageHandlers). \n+\n+### Table creation\n+This section explains the various steps needed in order to overlay a Hive table \"on top of\" an existing Iceberg table.\n+\n+#### Create an Iceberg table\n+The first step is to create an Iceberg table using the Spark/Java/Python API. For the purposes of this documentation we will assume that the table is called `table_a` and that the base location of the table is `s3://some_bucket/some_path/table_a`.\n+\n+#### Add the Iceberg Hive Runtime jar file to the Hive classpath\n+The `HiveIcebergStorageHandler` and supporting classes need to be made available on Hive's classpath. For example, if using Hive 2.x and the Hive shell, this can be achieved by issuing a statement like so:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "431c58a72843d51bd6636c9ef30c3fc21040117d"}, "originalPosition": 30}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk1OTg4MzEy", "url": "https://github.com/apache/iceberg/pull/1490#pullrequestreview-495988312", "createdAt": "2020-09-24T22:17:06Z", "commit": {"oid": "431c58a72843d51bd6636c9ef30c3fc21040117d"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQyMjoxNzowNlrOHXugGg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQyMjoxNzowNlrOHXugGg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDY0MTE3OA==", "bodyText": "Spark and Flink docs use tables at the top of docs to signal what is supported or not and to give status updates. Would it make sense to use one here as well? Then we don't have to find the sections that need to be removed.", "url": "https://github.com/apache/iceberg/pull/1490#discussion_r494641178", "createdAt": "2020-09-24T22:17:06Z", "author": {"login": "rdblue"}, "path": "site/docs/hive.md", "diffHunk": "@@ -0,0 +1,62 @@\n+<!--\n+ - Licensed to the Apache Software Foundation (ASF) under one or more\n+ - contributor license agreements.  See the NOTICE file distributed with\n+ - this work for additional information regarding copyright ownership.\n+ - The ASF licenses this file to You under the Apache License, Version 2.0\n+ - (the \"License\"); you may not use this file except in compliance with\n+ - the License.  You may obtain a copy of the License at\n+ -\n+ -   http://www.apache.org/licenses/LICENSE-2.0\n+ -\n+ - Unless required by applicable law or agreed to in writing, software\n+ - distributed under the License is distributed on an \"AS IS\" BASIS,\n+ - WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n+ - See the License for the specific language governing permissions and\n+ - limitations under the License.\n+ -->\n+\n+# Hive\n+\n+## Hive read support\n+Iceberg supports the reading of Iceberg tables from [Hive](https://hive.apache.org) by using a [StorageHandler](https://cwiki.apache.org/confluence/display/Hive/StorageHandlers). \n+\n+### Table creation\n+This section explains the various steps needed in order to overlay a Hive table \"on top of\" an existing Iceberg table.\n+\n+#### Create an Iceberg table\n+The first step is to create an Iceberg table using the Spark/Java/Python API. For the purposes of this documentation we will assume that the table is called `table_a` and that the base location of the table is `s3://some_bucket/some_path/table_a`.\n+\n+#### Add the Iceberg Hive Runtime jar file to the Hive classpath\n+The `HiveIcebergStorageHandler` and supporting classes need to be made available on Hive's classpath. For example, if using Hive 2.x and the Hive shell, this can be achieved by issuing a statement like so:\n+```sql\n+add jar /path/to/iceberg-hive-runtime.jar;\n+```\n+There are many others ways to achieve this including adding the jar file to Hive's auxillary classpath (so it is available by default) - please refer to Hive's documentation for more information.\n+\n+#### Create a Hive table\n+Now overlay a Hive table on top of this Iceberg table by issuing Hive DDL like so:\n+```sql\n+CREATE EXTERNAL TABLE table_a \n+STORED BY 'org.apache.iceberg.mr.hive.HiveIcebergStorageHandler' \n+LOCATION 's3://some_bucket/some_path/table_a';\n+```\n+\n+#### Query the Iceberg table via Hive\n+You should now be able to issue Hive SQL `SELECT` queries using the above table and see the results returned from the underlying Iceberg table. Both the Map Reduce and Tez query execution engines are supported.\n+```sql\n+SELECT * from table_a;\n+```\n+\n+### Features\n+\n+#### Predicate pushdown\n+Pushdown of the Hive SQL `WHERE` clause has been implemented so that these filters are used at the Iceberg TableScan level as well as by the Parquet and ORC Readers.\n+\n+#### Column selection\n+The projection of columns from the HiveSQL `SELECT` clause down to the Iceberg readers to reduce the number of columns read is currently being worked on.\n+\n+### Time travel and system tables\n+Support for accesing Iceberg's time travel feature and other system tables isn't currently supported but there is a plan to add this in the future.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "431c58a72843d51bd6636c9ef30c3fc21040117d"}, "originalPosition": 59}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "80e7c05d9bcd93f5f058c5655c0b7c3131271dd0", "author": {"user": {"login": "massdosage", "name": "Adrian Woodhead"}}, "url": "https://github.com/apache/iceberg/commit/80e7c05d9bcd93f5f058c5655c0b7c3131271dd0", "committedDate": "2020-09-30T19:38:12Z", "message": "remove unsupported, clarify hadoop tables"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTAwNTg0MDMz", "url": "https://github.com/apache/iceberg/pull/1490#pullrequestreview-500584033", "createdAt": "2020-10-01T17:49:57Z", "commit": {"oid": "80e7c05d9bcd93f5f058c5655c0b7c3131271dd0"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3817, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}