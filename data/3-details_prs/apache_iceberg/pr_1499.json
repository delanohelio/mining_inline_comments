{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDkxOTU1NTAw", "number": 1499, "title": "Update the Iceberg spec for row-level deletes", "bodyText": "This updates the Iceberg spec with requirements for row-level deletes, as implemented in Java.", "createdAt": "2020-09-23T18:19:04Z", "url": "https://github.com/apache/iceberg/pull/1499", "merged": true, "mergeCommit": {"oid": "8ae9104a7c3de6b4a74711f5dfc47f25856b398e"}, "closed": true, "closedAt": "2020-10-28T22:40:23Z", "author": {"login": "rdblue"}, "timelineItems": {"totalCount": 15, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdLwtbgAH2gAyNDkxOTU1NTAwOjVlNTI1ODExOTkzOTE4Yzc1MjI4MWJjNzZhMjc0NDYwNWFiYmQzMjU=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdXFa0rgFqTUxOTEzNTU0OQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "5e525811993918c752281bc76a2744605abbd325", "author": {"user": {"login": "rdblue", "name": "Ryan Blue"}}, "url": "https://github.com/apache/iceberg/commit/5e525811993918c752281bc76a2744605abbd325", "committedDate": "2020-09-23T18:15:28Z", "message": "Update spec for row-level deletes."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk1MjU3Njc0", "url": "https://github.com/apache/iceberg/pull/1499#pullrequestreview-495257674", "createdAt": "2020-09-24T06:35:32Z", "commit": {"oid": "5e525811993918c752281bc76a2744605abbd325"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQwNjozNTozMlrOHXLpTQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNFQwNjozNTozMlrOHXLpTQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDA3MDA5Mw==", "bodyText": "both stored -> both store ?", "url": "https://github.com/apache/iceberg/pull/1499#discussion_r494070093", "createdAt": "2020-09-24T06:35:32Z", "author": {"login": "rdsr"}, "path": "site/docs/spec.md", "diffHunk": "@@ -208,136 +256,202 @@ Notes:\n \n ### Manifests\n \n-A manifest is an immutable Avro file that lists a set of data files, along with each file\u2019s partition data tuple, metrics, and tracking information. One or more manifest files are used to store a snapshot, which tracks all of the files in a table at some point in time.\n+A manifest is an immutable Avro file that lists data files or delete files, along with each file\u2019s partition data tuple, metrics, and tracking information. One or more manifest files are used to store a [snapshot](#snapshots), which tracks all of the files in a table at some point in time. Manifests are tracked by a [manifest list](#manifest-lists) for each table snapshot.\n+\n+A manifest is a valid Iceberg data file: files must use valid Iceberg formats, schemas, and column projection.\n+\n+A manifest may store either data files or delete files, but not both because manifests that contain delete files are scanned first during job planning. Whether a manifest is a data manifest or a delete manifest is stored in manifest metadata.\n \n-A manifest is a valid Iceberg data file. Files must use Iceberg schemas and column projection.\n+A manifest stores files for a single partition spec. When a table\u2019s partition spec changes, old files remain in the older manifest and newer files are written to a new manifest. This is required because a manifest file\u2019s schema is based on its partition spec (see below). The partition spec of each manifest is also used to transform predicates on the table's data rows into predicates on partition values that are used during job planning to select files from a manifest.\n \n-A manifest stores files for a single partition spec. When a table\u2019s partition spec changes, old files remain in the older manifest and newer files are written to a new manifest. This is required because a manifest file\u2019s schema is based on its partition spec (see below). This restriction also simplifies selecting files from a manifest because the same boolean expression can be used to select or filter all rows.\n+A manifest file must store the partition spec and other metadata as properties in the Avro file's key-value metadata:\n \n-The partition spec for a manifest and the current table schema must be stored in the key-value properties of the manifest file. The partition spec is stored as a JSON string under the key `partition-spec`. The table schema is stored as a JSON string under the key `schema`.\n+| v1         | v2         | Key                 | Value                                                                        |\n+|------------|------------|---------------------|------------------------------------------------------------------------------|\n+| _required_ | _required_ | `schema`            | JSON representation of the table schema at the time the manifest was written |\n+| _required_ | _required_ | `partition-spec`    | JSON fields representation of the partition spec used to write the manifest  |\n+| _optional_ | _required_ | `partition-spec-id` | Id of the partition spec used to write the manifest as a string              |\n+| _optional_ | _required_ | `format-version`    | Table format version number of the manifest as a string                      |\n+|            | _required_ | `content`           | Type of content files tracked by the manifest: \"data\" or \"deletes\"           |\n \n The schema of a manifest file is a struct called `manifest_entry` with the following fields:\n \n-| Field id, name       | Type                                                      | Description                                                     |\n-|----------------------|-----------------------------------------------------------|-----------------------------------------------------------------|\n-| **`0  status`**      | `int` with meaning: `0: EXISTING` `1: ADDED` `2: DELETED` | Used to track additions and deletions                           |\n-| **`1  snapshot_id`** | `long`                                                    | Snapshot id where the file was added, or deleted if status is 2 |\n-| **`2  data_file`**   | `data_file` `struct` (see below)                          | File path, partition tuple, metrics, ...                        |\n+| v1         | v2         | Field id, name           | Type                                                      | Description                                                                           |\n+| ---------- | ---------- |--------------------------|-----------------------------------------------------------|---------------------------------------------------------------------------------------|\n+| _required_ | _required_ | **`0  status`**          | `int` with meaning: `0: EXISTING` `1: ADDED` `2: DELETED` | Used to track additions and deletions                                                 |\n+| _required_ | _optional_ | **`1  snapshot_id`**     | `long`                                                    | Snapshot id where the file was added, or deleted if status is 2. Inherited when null. |\n+|            | _optional_ | **`3  sequence_number`** | `long`                                                    | Sequence number when the file was added. Inherited when null.                         |\n+| _required_ | _required_ | **`2  data_file`**       | `data_file` `struct` (see below)                          | File path, partition tuple, metrics, ...                                              |\n \n `data_file` is a struct with the following fields:\n \n-| Field id, name                    | Type                                  | Description                                                                                                                                                                                          |\n-|-----------------------------------|---------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n-| **`100  file_path`**              | `string`                              | Full URI for the file with FS scheme                                                                                                                                                                 |\n-| **`101  file_format`**            | `string`                              | String file format name, avro, orc or parquet                                                                                                                                                        |\n-| **`102  partition`**              | `struct<...>`                         | Partition data tuple, schema based on the partition spec                                                                                                                                             |\n-| **`103  record_count`**           | `long`                                | Number of records in this file                                                                                                                                                                       |\n-| **`104  file_size_in_bytes`**     | `long`                                | Total file size in bytes                                                                                                                                                                             |\n-| ~~**`105 block_size_in_bytes`**~~ | `long`                                | **Deprecated. Always write a default value and do not read.**                                                                                                                                        |\n-| ~~**`106  file_ordinal`**~~       | `optional int`                        | **Deprecated. Do not use.**                                                                                                                                                                          |\n-| ~~**`107  sort_columns`**~~       | `optional list`                       | **Deprecated. Do not use.**                                                                                                                                                                          |\n-| **`108  column_sizes`**           | `optional map`                        | Map from column id to the total size on disk of all regions that store the column. Does not include bytes necessary to read other columns, like footers. Leave null for row-oriented formats (Avro). |\n-| **`109  value_counts`**           | `optional map`                        | Map from column id to number of values in the column (including null values)                                                                                                                         |\n-| **`110  null_value_counts`**      | `optional map`                        | Map from column id to number of null values in the column                                                                                                                                            |\n-| ~~**`111 distinct_counts`**~~     | `optional map`                        | **Deprecated. Do not use.**                                                                                                                                                                          |\n-| **`125  lower_bounds`**           | `optional map<126: int, 127: binary>` | Map from column id to lower bound in the column serialized as binary [1]. Each value must be less than or equal to all values in the column for the file.                                            |\n-| **`128  upper_bounds`**           | `optional map<129: int, 130: binary>` | Map from column id to upper bound in the column serialized as binary [1]. Each value must be greater than or equal to all values in the column for the file.                                         |\n-| **`131  key_metadata`**           | `optional binary`                     | Implementation-specific key metadata for encryption                                                                                                                                                  |\n-| **`132  split_offsets`**          | `optional list`                       | Split offsets for the data file. For example, all row group offsets in a Parquet file. Must be sorted ascending.                                                                                     |\n+| v1         | v2         | Field id, name                    | Type                         | Description |\n+| ---------- | ---------- |-----------------------------------|------------------------------|-------------|\n+|            | _required_ | **`134  content`**                | `int` with meaning: `0: DATA`, `1: POSITION DELETES`, `2: EQUALITY DELETES` | Type of content stored by the data file: data, equality deletes, or position deletes (all v1 files are data files) |\n+| _required_ | _required_ | **`100  file_path`**              | `string`                     | Full URI for the file with FS scheme |\n+| _required_ | _required_ | **`101  file_format`**            | `string`                     | String file format name, avro, orc or parquet |\n+| _required_ | _required_ | **`102  partition`**              | `struct<...>`                | Partition data tuple, schema based on the partition spec |\n+| _required_ | _required_ | **`103  record_count`**           | `long`                       | Number of records in this file |\n+| _required_ | _required_ | **`104  file_size_in_bytes`**     | `long`                       | Total file size in bytes |\n+| _required_ |            | ~~**`105 block_size_in_bytes`**~~ | `long`                       | **Deprecated. Always write a default in v1. Do not write in v2.** |\n+| _optional_ |            | ~~**`106  file_ordinal`**~~       | `int`                        | **Deprecated. Do not write.** |\n+| _optional_ |            | ~~**`107  sort_columns`**~~       | `list<112: int>`             | **Deprecated. Do not write.** |\n+| _optional_ | _optional_ | **`108  column_sizes`**           | `map<117: int, 118: long>`   | Map from column id to the total size on disk of all regions that store the column. Does not include bytes necessary to read other columns, like footers. Leave null for row-oriented formats (Avro) |\n+| _optional_ | _optional_ | **`109  value_counts`**           | `map<119: int, 120: long>`   | Map from column id to number of values in the column (including null values) |\n+| _optional_ | _optional_ | **`110  null_value_counts`**      | `map<121: int, 122: long>`   | Map from column id to number of null values in the column |\n+| _optional_ |            | ~~**`111 distinct_counts`**~~     | `map<123: int, 124: long>`   | **Deprecated. Do not write.** |\n+| _optional_ | _optional_ | **`125  lower_bounds`**           | `map<126: int, 127: binary>` | Map from column id to lower bound in the column serialized as binary [1]. Each value must be less than or equal to all values in the column for the file |\n+| _optional_ | _optional_ | **`128  upper_bounds`**           | `map<129: int, 130: binary>` | Map from column id to upper bound in the column serialized as binary [1]. Each value must be greater than or equal to all values in the column for the file |\n+| _optional_ | _optional_ | **`131  key_metadata`**           | `binary`                     | Implementation-specific key metadata for encryption |\n+| _optional_ | _optional_ | **`132  split_offsets`**          | `list<133: long>`            | Split offsets for the data file. For example, all row group offsets in a Parquet file. Must be sorted ascending |\n+|            | _optional_ | **`135  equality_ids`**           | `list<136: int>`             | Field ids used to determine row equality in equality delete files. Required when `content=2` and should be null otherwise. Fields with ids listed in this column must be present in the delete file |\n \n Notes:\n \n 1. Single-value serialization for lower and upper bounds is detailed in Appendix D.\n \n-The `partition` struct stores the tuple of partition values for each file. Its type is derived from the partition fields of the partition spec for the manifest file.\n+The `partition` struct stores the tuple of partition values for each file. Its type is derived from the partition fields of the partition spec used to write the manifest file. In v2, the partition struct's field ids must match the ids from the partition spec.\n \n-Each manifest file must store its partition spec and the current table schema in the Avro file\u2019s key-value metadata. The partition spec is used to transform predicates on the table\u2019s data rows into predicates on the manifest\u2019s partition values during job planning.\n+The column metrics maps are used when filtering to select both data and delete files. For delete files, the metrics must store bounds and counts for all deleted rows, or must be omitted. Storing metrics for deleted rows ensures that the values can be used during job planning to find delete files that must be merged during a scan.\n \n \n #### Manifest Entry Fields\n \n The manifest entry fields are used to keep track of the snapshot in which files were added or logically deleted. The `data_file` struct is nested inside of the manifest entry so that it can be easily passed to job planning without the manifest entry fields.\n \n-When a data file is added to the dataset, it\u2019s manifest entry should store the snapshot ID in which the file was added and set status to 1 (added).\n+When a file is added to the dataset, it\u2019s manifest entry should store the snapshot ID in which the file was added and set status to 1 (added).\n \n-When a data file is replaced or deleted from the dataset, it\u2019s manifest entry fields store the snapshot ID in which the file was deleted and status 2 (deleted). The file may be deleted from the file system when the snapshot in which it was deleted is garbage collected, assuming that older snapshots have also been garbage collected [1].\n+When a file is replaced or deleted from the dataset, it\u2019s manifest entry fields store the snapshot ID in which the file was deleted and status 2 (deleted). The file may be deleted from the file system when the snapshot in which it was deleted is garbage collected, assuming that older snapshots have also been garbage collected [1].\n+\n+Iceberg v2 adds a sequence number to the entry and makes the snapshot id optional. Both fields, `sequence_number` and `snapshot_id`, are inherited from manifest metadata when `null`. That is, if the field is `null` for an entry, then the entry must inherit its value from the manifest file's metadata, stored in the manifest list [2].\n \n Notes:\n \n 1. Technically, data files can be deleted when the last snapshot that contains the file as \u201clive\u201d data is garbage collected. But this is harder to detect and requires finding the diff of multiple snapshots. It is easier to track what files are deleted in a snapshot and delete them when that snapshot expires.\n+2. Manifest list files are required in v2, so that the `sequence_number` and `snapshot_id` to inherit are always available.\n+\n+#### Sequence Number Inheritance\n+\n+Manifests track the sequence number when a data or delete file was added to the table.\n+\n+When adding new file, its sequence number is set to `null` because the snapshot's sequence number is not assigned until the snapshot is successfully committed. When reading, sequence numbers are inherited by replacing `null` with the manifest's sequence number from the manifest list.\n+\n+When writing an existing file to a new manifest, the sequence number must be non-null and set to the sequence number that was inherited.\n+\n+Inheriting sequence numbers through the metadata tree allows writing a new manifest without a known sequence number, so that a manifest can be written once and reused in commit retries. To change a sequence number for a retry, only the manifest list must be rewritten.\n+\n+When reading v1 manifests with no sequence number column, sequence numbers for all files must default to 0.\n+\n \n ### Snapshots\n \n A snapshot consists of the following fields:\n \n-*   **`snapshot-id`** -- A unique long ID.\n-*   **`parent-snapshot-id`** -- (Optional) The snapshot ID of the snapshot\u2019s parent. This field is not present for snapshots that have no parent snapshot, such as snapshots created before this field was added or the first snapshot of a table.\n-*   **`sequence-number`** -- A monotonically increasing long that tracks the order of snapshots in a table. (**v2 only**)\n-*   **`timestamp-ms`** -- A timestamp when the snapshot was created. This is used when garbage collecting snapshots.\n-*   **`manifests`** -- A list of manifest file locations. The data files in a snapshot are the union of all data files listed in these manifests. (Deprecated in favor of `manifest-list`)\n-*   **`manifest-list`** -- (Optional) The location of a manifest list file for this snapshot, which contains a list of manifest files with additional metadata. If present, the manifests field must be omitted.\n-*   **`summary`** -- (Optional) A summary that encodes the `operation` that produced the snapshot and other relevant information specific to that operation. This allows some operations like snapshot expiration to skip processing some snapshots. Possible values of `operation` are:\n-    *   `append` -- Data files were added and no files were removed.\n-    *   `replace` -- Data files were rewritten with the same data; i.e., compaction, changing the data file format, or relocating data files.\n-    *   `overwrite` -- Data files were deleted and added in a logical overwrite operation.\n-    *   `delete` -- Data files were removed and their contents logically deleted.\n+| v1         | v2         | Field                    | Description |\n+| ---------- | ---------- | ------------------------ | ----------- |\n+| _required_ | _required_ | **`snapshot-id`**        | A unique long ID |\n+| _optional_ | _optional_ | **`parent-snapshot-id`** | The snapshot ID of the snapshot's parent. Omitted for any snapshot with no parent |\n+|            | _required_ | **`sequence-number`**    | A monotonically increasing long that tracks the order of changes to a table |\n+| _required_ | _required_ | **`timestamp-ms`**       | A timestamp when the snapshot was created, used for garbage collection and table inspection |\n+| _optional_ | _required_ | **`manifest-list`**      | The location of a manifest list for this snapshot that tracks manifest files with additional meadata |\n+| _optional_ |            | **`manifests`**          | A list of manifest file locations. Must be omitted if `manifest-list` is present |\n+| _optional_ | _required_ | **`summary`**            | A string map that summarizes the snapshot changes, including `operation` (see below) |\n \n-Snapshots can be split across more than one manifest. This enables:\n+The snapshot summary's `operation` field is used by some operations, like snapshot expiration, to skip processing certain snapshots. Possible `operation` values are:\n+\n+*   `append` -- Only data files were added and no files were removed.\n+*   `replace` -- Data and delete files were added and removed without changing table data; i.e., compaction, changing the data file format, or relocating data files.\n+*   `overwrite` -- Data and delete files were added and removed in a logical overwrite operation.\n+*   `delete` -- Data files were removed and their contents logically deleted and/or delete files were added to delete rows.\n+\n+Data and delete files for a snapshot can be stored in more than one manifest. This enables:\n \n *   Appends can add a new manifest to minimize the amount of data written, instead of adding new records by rewriting and appending to an existing manifest. (This is called a \u201cfast append\u201d.)\n *   Tables can use multiple partition specs. A table\u2019s partition configuration can evolve if, for example, its data volume changes. Each manifest uses a single partition spec, and queries do not need to change because partition filters are derived from data predicates.\n *   Large tables can be split across multiple manifests so that implementations can parallelize job planning or reduce the cost of rewriting a manifest.\n \n+Manifests for a snapshot are tracked by a manifest list.\n+\n Valid snapshots are stored as a list in table metadata. For serialization, see Appendix C.\n \n \n+#### Manifest Lists\n+\n+Snapshots are embedded in table metadata, but the list of manifests for a snapshot are stored in a separate manifest list file.\n+\n+A new manifest list is written for each attempt to commit a snapshot because the list of manifests always changes to produce a new snapshot. When a manifest list is written, the (optimistic) sequence number of the snapshot is written for all new manifest files tracked by the list.\n+\n+A manifest list includes summary metadata that can be used to avoid scanning all of the manifests in a snapshot when planning a table scan. This includes the number of added, existing, and deleted files, and a summary of values for each field of the partition spec used to write the manifest.\n+\n+A manifest list is a valid Iceberg data file: files must use valid Iceberg formats, schemas, and column projection.\n+\n+Manifest list files store `manifest_file`, a struct with the following fields:\n+\n+| v1         | v2         | Field id, name                 | Type                                        | Description |\n+| ---------- | ---------- |--------------------------------|---------------------------------------------|-------------|\n+| _required_ | _required_ | **`500 manifest_path`**        | `string`                                    | Location of the manifest file |\n+| _required_ | _required_ | **`501 manifest_length`**      | `long`                                      | Length of the manifest file |\n+| _required_ | _required_ | **`502 partition_spec_id`**    | `int`                                       | ID of a partition spec for the table; must be listed in table metadata `partition-specs` |\n+|            | _required_ | **`517 content`**              | `int` with meaning: `0: data`, `1: deletes` | The type of files tracked by the manifest, either data or delete files; 0 for all v1 manifests |\n+|            | _required_ | **`515 sequence_number`**      | `long`                                      | The sequence number when the manifest was added to the table; use 0 when reading v1 manifest lists |\n+|            | _required_ | **`516 min_sequence_number`**  | `long`                                      | The minimum sequence number of all data or delete files in the manifest; use 0 when reading v1 manifest lists |\n+| _required_ | _required_ | **`503 added_snapshot_id`**    | `long`                                      | ID of the snapshot where the  manifest file was added |\n+| _optional_ | _required_ | **`504 added_files_count`**    | `int`                                       | Number of entries in the manifest that have status `ADDED` (1), when `null` this is assumed to be non-zero |\n+| _optional_ | _required_ | **`505 existing_files_count`** | `int`                                       | Number of entries in the manifest that have status `EXISTING` (0), when `null` this is assumed to be non-zero |\n+| _optional_ | _required_ | **`506 deleted_files_count`**  | `int`                                       | Number of entries in the manifest that have status `DELETED` (2), when `null` this is assumed to be non-zero |\n+| _optional_ | _required_ | **`512 added_rows_count`**     | `long`                                      | Number of rows in all of files in the manifest that have status `ADDED`, when `null` this is assumed to be non-zero |\n+| _optional_ | _required_ | **`513 existing_rows_count`**  | `long`                                      | Number of rows in all of files in the manifest that have status `EXISTING`, when `null` this is assumed to be non-zero |\n+| _optional_ | _required_ | **`514 deleted_rows_count`**   | `long`                                      | Number of rows in all of files in the manifest that have status `DELETED`, when `null` this is assumed to be non-zero |\n+| _optional_ | _optional_ | **`507 partitions`**           | `list<508: field_summary>` (see below)      | A list of field summaries for each partition field in the spec. Each field in the list corresponds to a field in the manifest file\u2019s partition spec. |\n+\n+`field_summary` is a struct with the following fields:\n+\n+| v1         | v2         | Field id, name          | Type          | Description |\n+| ---------- | ---------- |-------------------------|---------------|-------------|\n+| _required_ | _required_ | **`509 contains_null`** | `boolean`     | Whether the manifest contains at least one partition with a null value for the field |\n+| _optional_ | _optional_ | **`510 lower_bound`**   | `bytes`   [1] | Lower bound for the non-null values in the partition field, or null if all values are null |\n+| _optional_ | _optional_ | **`511 upper_bound`**   | `bytes`   [1] | Upper bound for the non-null values in the partition field, or null if all values are null |\n+\n+Notes:\n+\n+1. Lower and upper bounds are serialized to bytes using the single-object serialization in Appendix D. The type of used to encode the value is the type of the partition field data.\n+\n+\n #### Scan Planning\n \n-Scans are planned by reading the manifest files for the current snapshot listed in the table metadata. Deleted entries in a manifest are not included in the scan.\n+Scans are planned by reading the manifest files for the current snapshot. Deleted entries in data and delete manifests are not used in a scan.\n+\n+Manifests that contain no matching files, determined using either file counts or partition summaries, may be skipped.\n \n-For each manifest, scan predicates, which filter data rows, are converted to partition predicates, which filter data files. These partition predicates are used to select the data files in the manifest. This conversion uses the partition spec used to write the manifest file.\n+For each manifest, scan predicates, which filter data rows, are converted to partition predicates, which filter data and delete files. These partition predicates are used to select the data and delete files in the manifest. This conversion uses the partition spec used to write the manifest file.\n \n-Scan predicates are converted to partition predicates using an inclusive projection: if a scan predicate matches a row, then the partition predicate must match that row\u2019s partition. This is an _inclusive projection_ [1] because rows that do not match the scan predicate may be included in the scan by the partition predicate.\n+Scan predicates are converted to partition predicates using an _inclusive projection_: if a scan predicate matches a row, then the partition predicate must match that row\u2019s partition. This is called _inclusive_ [1] because rows that do not match the scan predicate may be included in the scan by the partition predicate.\n \n For example, an `events` table with a timestamp column named `ts` that is partitioned by `ts_day=day(ts)` is queried by users with ranges over the timestamp column: `ts > X`. The inclusive projection is `ts_day >= day(X)`, which is used to select files that may have matching rows. Note that, in most cases, timestamps just before `X` will be included in the scan because the file contains rows that match the predicate and rows that do not match the predicate.\n \n-Notes:\n+Scan predicates are also used to filter data and delete files using column bounds and counts that are stored by field id in manifests. The same filter logic can be used for both data and delete files because both stored metrics of the rows either inserted or deleted. If metrics show that a delete file has no rows that match a scan predicate, it may be ignored just as a data file would be ignored [2].", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5e525811993918c752281bc76a2744605abbd325"}, "originalPosition": 348}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk2MTEyNjEy", "url": "https://github.com/apache/iceberg/pull/1499#pullrequestreview-496112612", "createdAt": "2020-09-25T05:05:38Z", "commit": {"oid": "5e525811993918c752281bc76a2744605abbd325"}, "state": "COMMENTED", "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQwNTowNTozOFrOHX1GtA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQwNjoxODo1M1rOHX2Ylw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDc0OTM2NA==", "bodyText": "What is the reason behind the recommendation for delete files and table data to have the same file format?", "url": "https://github.com/apache/iceberg/pull/1499#discussion_r494749364", "createdAt": "2020-09-25T05:05:38Z", "author": {"login": "shardulm94"}, "path": "site/docs/spec.md", "diffHunk": "@@ -416,25 +530,91 @@ Notes:\n \n ### Delete Formats\n \n-This section details how to encode row-level deletes in Iceberg metadata. Row-level deletes are not supported in the current format version 1. This part of the spec is not yet complete and will be completed as format version 2.\n+This section details how to encode row-level deletes in Iceberg delete files. Row-level deletes are not supported in v1.\n+\n+Row-level delete files are valid Iceberg data files: files must use valid Iceberg formats, schemas, and column projection. It is recommended that delete files are written using the table's default file format.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5e525811993918c752281bc76a2744605abbd325"}, "originalPosition": 428}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDc1MDM1Mg==", "bodyText": "Typo: Full URI of", "url": "https://github.com/apache/iceberg/pull/1499#discussion_r494750352", "createdAt": "2020-09-25T05:09:50Z", "author": {"login": "shardulm94"}, "path": "site/docs/spec.md", "diffHunk": "@@ -416,25 +530,91 @@ Notes:\n \n ### Delete Formats\n \n-This section details how to encode row-level deletes in Iceberg metadata. Row-level deletes are not supported in the current format version 1. This part of the spec is not yet complete and will be completed as format version 2.\n+This section details how to encode row-level deletes in Iceberg delete files. Row-level deletes are not supported in v1.\n+\n+Row-level delete files are valid Iceberg data files: files must use valid Iceberg formats, schemas, and column projection. It is recommended that delete files are written using the table's default file format.\n+\n+Row-level delete files are tracked by manifests, like data files. A separate set of manifests is used for delete files, but the manifest schemas are identical.\n \n-#### Position-based Delete Files\n+Both position and equality deletes allow encoding deleted row values with a delete. This can be used to reconstruct a stream of changes to a table.\n \n-Position-based delete files identify rows in one or more data files that have been deleted.\n+\n+#### Position Delete Files\n+\n+Position-based delete files identify deleted rows by file and position in one or more data files, and may optionally contain the deleted row.\n+\n+A data row is deleted if there is an entry in a position delete file for the row's file and position in the data file, starting at 0.\n \n Position-based delete files store `file_position_delete`, a struct with the following fields:\n \n-| Field id, name          | Type                            | Description                                                                                                              |\n-|-------------------------|---------------------------------|--------------------------------------------------------------------------------------------------------------------------|\n-| **`1  file_path`**     | `required string`               | The full URI of a data file with FS scheme. This must match the `file_path` of the target data file in a manifest entry.   |\n-| **`2  position`**      | `required long`                 | The ordinal position of a deleted row in the target data file identified by `file_path`, starting at `0`.                    |\n+| Field id, name              | Type                   | Description |\n+|-----------------------------|------------------------|-------------|\n+| **`2147483546  file_path`** | `string`               | Full URI or a data file with FS scheme. This must match the `file_path` of the target data file in a manifest entry |", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5e525811993918c752281bc76a2744605abbd325"}, "originalPosition": 451}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NDc3MDMyNw==", "bodyText": "Should this be linked to #scan-planning?", "url": "https://github.com/apache/iceberg/pull/1499#discussion_r494770327", "createdAt": "2020-09-25T06:18:53Z", "author": {"login": "shardulm94"}, "path": "site/docs/spec.md", "diffHunk": "@@ -416,25 +530,91 @@ Notes:\n \n ### Delete Formats\n \n-This section details how to encode row-level deletes in Iceberg metadata. Row-level deletes are not supported in the current format version 1. This part of the spec is not yet complete and will be completed as format version 2.\n+This section details how to encode row-level deletes in Iceberg delete files. Row-level deletes are not supported in v1.\n+\n+Row-level delete files are valid Iceberg data files: files must use valid Iceberg formats, schemas, and column projection. It is recommended that delete files are written using the table's default file format.\n+\n+Row-level delete files are tracked by manifests, like data files. A separate set of manifests is used for delete files, but the manifest schemas are identical.\n \n-#### Position-based Delete Files\n+Both position and equality deletes allow encoding deleted row values with a delete. This can be used to reconstruct a stream of changes to a table.\n \n-Position-based delete files identify rows in one or more data files that have been deleted.\n+\n+#### Position Delete Files\n+\n+Position-based delete files identify deleted rows by file and position in one or more data files, and may optionally contain the deleted row.\n+\n+A data row is deleted if there is an entry in a position delete file for the row's file and position in the data file, starting at 0.\n \n Position-based delete files store `file_position_delete`, a struct with the following fields:\n \n-| Field id, name          | Type                            | Description                                                                                                              |\n-|-------------------------|---------------------------------|--------------------------------------------------------------------------------------------------------------------------|\n-| **`1  file_path`**     | `required string`               | The full URI of a data file with FS scheme. This must match the `file_path` of the target data file in a manifest entry.   |\n-| **`2  position`**      | `required long`                 | The ordinal position of a deleted row in the target data file identified by `file_path`, starting at `0`.                    |\n+| Field id, name              | Type                   | Description |\n+|-----------------------------|------------------------|-------------|\n+| **`2147483546  file_path`** | `string`               | Full URI or a data file with FS scheme. This must match the `file_path` of the target data file in a manifest entry |\n+| **`2147483545  pos`**       | `long`                 | Ordinal position of a deleted row in the target data file identified by `file_path`, starting at `0` |\n+| **`2147483544  row`**       | `required struct<...>` | Deleted row values. Omit the column when not storing deleted rows. |\n+\n+When the deleted row is present, its schema may be any subset of the table schema. When the column is present, the deleted row values for every delete must be stored.\n \n The rows in the delete file must be sorted by `file_path` then `position` to optimize filtering rows while scanning. \n \n *  Sorting by `file_path` allows filter pushdown by file in columnar storage formats.\n *  Sorting by `position` allows filtering rows while scanning, to avoid keeping deletes in memory.\n \n-Though the delete files can be written using any supported data file format in Iceberg, it is recommended to write delete files with same file format as the table's file format.\n+#### Equality Delete Files\n+\n+Equality delete files identify deleted rows in a collection of data files by one or more column values, and may optionally contain additional columns of the deleted row.\n+\n+Equality delete files store any subset of a table's columns and use the table's field ids. The _delete columns_ are the columns of the delete file used to match data rows. Delete columns are identified by id in the delete file [metadata column `equality_ids`](#manifests).\n+\n+A data row is deleted if its values are equal to all delete columns for any row in an equality delete file that applies to the row's data file (see [`Job Planning`](#job-planning)).", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5e525811993918c752281bc76a2744605abbd325"}, "originalPosition": 469}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk2OTE3MzA3", "url": "https://github.com/apache/iceberg/pull/1499#pullrequestreview-496917307", "createdAt": "2020-09-25T23:57:16Z", "commit": {"oid": "5e525811993918c752281bc76a2744605abbd325"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQyMzo1NzoxNlrOHYYdfg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yNVQyMzo1NzoxNlrOHYYdfg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTMyODYzOA==", "bodyText": "What is the use case for allowing \"deleting rows that were added in the same commit\"?", "url": "https://github.com/apache/iceberg/pull/1499#discussion_r495328638", "createdAt": "2020-09-25T23:57:16Z", "author": {"login": "shardulm94"}, "path": "site/docs/spec.md", "diffHunk": "@@ -208,136 +256,202 @@ Notes:\n \n ### Manifests\n \n-A manifest is an immutable Avro file that lists a set of data files, along with each file\u2019s partition data tuple, metrics, and tracking information. One or more manifest files are used to store a snapshot, which tracks all of the files in a table at some point in time.\n+A manifest is an immutable Avro file that lists data files or delete files, along with each file\u2019s partition data tuple, metrics, and tracking information. One or more manifest files are used to store a [snapshot](#snapshots), which tracks all of the files in a table at some point in time. Manifests are tracked by a [manifest list](#manifest-lists) for each table snapshot.\n+\n+A manifest is a valid Iceberg data file: files must use valid Iceberg formats, schemas, and column projection.\n+\n+A manifest may store either data files or delete files, but not both because manifests that contain delete files are scanned first during job planning. Whether a manifest is a data manifest or a delete manifest is stored in manifest metadata.\n \n-A manifest is a valid Iceberg data file. Files must use Iceberg schemas and column projection.\n+A manifest stores files for a single partition spec. When a table\u2019s partition spec changes, old files remain in the older manifest and newer files are written to a new manifest. This is required because a manifest file\u2019s schema is based on its partition spec (see below). The partition spec of each manifest is also used to transform predicates on the table's data rows into predicates on partition values that are used during job planning to select files from a manifest.\n \n-A manifest stores files for a single partition spec. When a table\u2019s partition spec changes, old files remain in the older manifest and newer files are written to a new manifest. This is required because a manifest file\u2019s schema is based on its partition spec (see below). This restriction also simplifies selecting files from a manifest because the same boolean expression can be used to select or filter all rows.\n+A manifest file must store the partition spec and other metadata as properties in the Avro file's key-value metadata:\n \n-The partition spec for a manifest and the current table schema must be stored in the key-value properties of the manifest file. The partition spec is stored as a JSON string under the key `partition-spec`. The table schema is stored as a JSON string under the key `schema`.\n+| v1         | v2         | Key                 | Value                                                                        |\n+|------------|------------|---------------------|------------------------------------------------------------------------------|\n+| _required_ | _required_ | `schema`            | JSON representation of the table schema at the time the manifest was written |\n+| _required_ | _required_ | `partition-spec`    | JSON fields representation of the partition spec used to write the manifest  |\n+| _optional_ | _required_ | `partition-spec-id` | Id of the partition spec used to write the manifest as a string              |\n+| _optional_ | _required_ | `format-version`    | Table format version number of the manifest as a string                      |\n+|            | _required_ | `content`           | Type of content files tracked by the manifest: \"data\" or \"deletes\"           |\n \n The schema of a manifest file is a struct called `manifest_entry` with the following fields:\n \n-| Field id, name       | Type                                                      | Description                                                     |\n-|----------------------|-----------------------------------------------------------|-----------------------------------------------------------------|\n-| **`0  status`**      | `int` with meaning: `0: EXISTING` `1: ADDED` `2: DELETED` | Used to track additions and deletions                           |\n-| **`1  snapshot_id`** | `long`                                                    | Snapshot id where the file was added, or deleted if status is 2 |\n-| **`2  data_file`**   | `data_file` `struct` (see below)                          | File path, partition tuple, metrics, ...                        |\n+| v1         | v2         | Field id, name           | Type                                                      | Description                                                                           |\n+| ---------- | ---------- |--------------------------|-----------------------------------------------------------|---------------------------------------------------------------------------------------|\n+| _required_ | _required_ | **`0  status`**          | `int` with meaning: `0: EXISTING` `1: ADDED` `2: DELETED` | Used to track additions and deletions                                                 |\n+| _required_ | _optional_ | **`1  snapshot_id`**     | `long`                                                    | Snapshot id where the file was added, or deleted if status is 2. Inherited when null. |\n+|            | _optional_ | **`3  sequence_number`** | `long`                                                    | Sequence number when the file was added. Inherited when null.                         |\n+| _required_ | _required_ | **`2  data_file`**       | `data_file` `struct` (see below)                          | File path, partition tuple, metrics, ...                                              |\n \n `data_file` is a struct with the following fields:\n \n-| Field id, name                    | Type                                  | Description                                                                                                                                                                                          |\n-|-----------------------------------|---------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n-| **`100  file_path`**              | `string`                              | Full URI for the file with FS scheme                                                                                                                                                                 |\n-| **`101  file_format`**            | `string`                              | String file format name, avro, orc or parquet                                                                                                                                                        |\n-| **`102  partition`**              | `struct<...>`                         | Partition data tuple, schema based on the partition spec                                                                                                                                             |\n-| **`103  record_count`**           | `long`                                | Number of records in this file                                                                                                                                                                       |\n-| **`104  file_size_in_bytes`**     | `long`                                | Total file size in bytes                                                                                                                                                                             |\n-| ~~**`105 block_size_in_bytes`**~~ | `long`                                | **Deprecated. Always write a default value and do not read.**                                                                                                                                        |\n-| ~~**`106  file_ordinal`**~~       | `optional int`                        | **Deprecated. Do not use.**                                                                                                                                                                          |\n-| ~~**`107  sort_columns`**~~       | `optional list`                       | **Deprecated. Do not use.**                                                                                                                                                                          |\n-| **`108  column_sizes`**           | `optional map`                        | Map from column id to the total size on disk of all regions that store the column. Does not include bytes necessary to read other columns, like footers. Leave null for row-oriented formats (Avro). |\n-| **`109  value_counts`**           | `optional map`                        | Map from column id to number of values in the column (including null values)                                                                                                                         |\n-| **`110  null_value_counts`**      | `optional map`                        | Map from column id to number of null values in the column                                                                                                                                            |\n-| ~~**`111 distinct_counts`**~~     | `optional map`                        | **Deprecated. Do not use.**                                                                                                                                                                          |\n-| **`125  lower_bounds`**           | `optional map<126: int, 127: binary>` | Map from column id to lower bound in the column serialized as binary [1]. Each value must be less than or equal to all values in the column for the file.                                            |\n-| **`128  upper_bounds`**           | `optional map<129: int, 130: binary>` | Map from column id to upper bound in the column serialized as binary [1]. Each value must be greater than or equal to all values in the column for the file.                                         |\n-| **`131  key_metadata`**           | `optional binary`                     | Implementation-specific key metadata for encryption                                                                                                                                                  |\n-| **`132  split_offsets`**          | `optional list`                       | Split offsets for the data file. For example, all row group offsets in a Parquet file. Must be sorted ascending.                                                                                     |\n+| v1         | v2         | Field id, name                    | Type                         | Description |\n+| ---------- | ---------- |-----------------------------------|------------------------------|-------------|\n+|            | _required_ | **`134  content`**                | `int` with meaning: `0: DATA`, `1: POSITION DELETES`, `2: EQUALITY DELETES` | Type of content stored by the data file: data, equality deletes, or position deletes (all v1 files are data files) |\n+| _required_ | _required_ | **`100  file_path`**              | `string`                     | Full URI for the file with FS scheme |\n+| _required_ | _required_ | **`101  file_format`**            | `string`                     | String file format name, avro, orc or parquet |\n+| _required_ | _required_ | **`102  partition`**              | `struct<...>`                | Partition data tuple, schema based on the partition spec |\n+| _required_ | _required_ | **`103  record_count`**           | `long`                       | Number of records in this file |\n+| _required_ | _required_ | **`104  file_size_in_bytes`**     | `long`                       | Total file size in bytes |\n+| _required_ |            | ~~**`105 block_size_in_bytes`**~~ | `long`                       | **Deprecated. Always write a default in v1. Do not write in v2.** |\n+| _optional_ |            | ~~**`106  file_ordinal`**~~       | `int`                        | **Deprecated. Do not write.** |\n+| _optional_ |            | ~~**`107  sort_columns`**~~       | `list<112: int>`             | **Deprecated. Do not write.** |\n+| _optional_ | _optional_ | **`108  column_sizes`**           | `map<117: int, 118: long>`   | Map from column id to the total size on disk of all regions that store the column. Does not include bytes necessary to read other columns, like footers. Leave null for row-oriented formats (Avro) |\n+| _optional_ | _optional_ | **`109  value_counts`**           | `map<119: int, 120: long>`   | Map from column id to number of values in the column (including null values) |\n+| _optional_ | _optional_ | **`110  null_value_counts`**      | `map<121: int, 122: long>`   | Map from column id to number of null values in the column |\n+| _optional_ |            | ~~**`111 distinct_counts`**~~     | `map<123: int, 124: long>`   | **Deprecated. Do not write.** |\n+| _optional_ | _optional_ | **`125  lower_bounds`**           | `map<126: int, 127: binary>` | Map from column id to lower bound in the column serialized as binary [1]. Each value must be less than or equal to all values in the column for the file |\n+| _optional_ | _optional_ | **`128  upper_bounds`**           | `map<129: int, 130: binary>` | Map from column id to upper bound in the column serialized as binary [1]. Each value must be greater than or equal to all values in the column for the file |\n+| _optional_ | _optional_ | **`131  key_metadata`**           | `binary`                     | Implementation-specific key metadata for encryption |\n+| _optional_ | _optional_ | **`132  split_offsets`**          | `list<133: long>`            | Split offsets for the data file. For example, all row group offsets in a Parquet file. Must be sorted ascending |\n+|            | _optional_ | **`135  equality_ids`**           | `list<136: int>`             | Field ids used to determine row equality in equality delete files. Required when `content=2` and should be null otherwise. Fields with ids listed in this column must be present in the delete file |\n \n Notes:\n \n 1. Single-value serialization for lower and upper bounds is detailed in Appendix D.\n \n-The `partition` struct stores the tuple of partition values for each file. Its type is derived from the partition fields of the partition spec for the manifest file.\n+The `partition` struct stores the tuple of partition values for each file. Its type is derived from the partition fields of the partition spec used to write the manifest file. In v2, the partition struct's field ids must match the ids from the partition spec.\n \n-Each manifest file must store its partition spec and the current table schema in the Avro file\u2019s key-value metadata. The partition spec is used to transform predicates on the table\u2019s data rows into predicates on the manifest\u2019s partition values during job planning.\n+The column metrics maps are used when filtering to select both data and delete files. For delete files, the metrics must store bounds and counts for all deleted rows, or must be omitted. Storing metrics for deleted rows ensures that the values can be used during job planning to find delete files that must be merged during a scan.\n \n \n #### Manifest Entry Fields\n \n The manifest entry fields are used to keep track of the snapshot in which files were added or logically deleted. The `data_file` struct is nested inside of the manifest entry so that it can be easily passed to job planning without the manifest entry fields.\n \n-When a data file is added to the dataset, it\u2019s manifest entry should store the snapshot ID in which the file was added and set status to 1 (added).\n+When a file is added to the dataset, it\u2019s manifest entry should store the snapshot ID in which the file was added and set status to 1 (added).\n \n-When a data file is replaced or deleted from the dataset, it\u2019s manifest entry fields store the snapshot ID in which the file was deleted and status 2 (deleted). The file may be deleted from the file system when the snapshot in which it was deleted is garbage collected, assuming that older snapshots have also been garbage collected [1].\n+When a file is replaced or deleted from the dataset, it\u2019s manifest entry fields store the snapshot ID in which the file was deleted and status 2 (deleted). The file may be deleted from the file system when the snapshot in which it was deleted is garbage collected, assuming that older snapshots have also been garbage collected [1].\n+\n+Iceberg v2 adds a sequence number to the entry and makes the snapshot id optional. Both fields, `sequence_number` and `snapshot_id`, are inherited from manifest metadata when `null`. That is, if the field is `null` for an entry, then the entry must inherit its value from the manifest file's metadata, stored in the manifest list [2].\n \n Notes:\n \n 1. Technically, data files can be deleted when the last snapshot that contains the file as \u201clive\u201d data is garbage collected. But this is harder to detect and requires finding the diff of multiple snapshots. It is easier to track what files are deleted in a snapshot and delete them when that snapshot expires.\n+2. Manifest list files are required in v2, so that the `sequence_number` and `snapshot_id` to inherit are always available.\n+\n+#### Sequence Number Inheritance\n+\n+Manifests track the sequence number when a data or delete file was added to the table.\n+\n+When adding new file, its sequence number is set to `null` because the snapshot's sequence number is not assigned until the snapshot is successfully committed. When reading, sequence numbers are inherited by replacing `null` with the manifest's sequence number from the manifest list.\n+\n+When writing an existing file to a new manifest, the sequence number must be non-null and set to the sequence number that was inherited.\n+\n+Inheriting sequence numbers through the metadata tree allows writing a new manifest without a known sequence number, so that a manifest can be written once and reused in commit retries. To change a sequence number for a retry, only the manifest list must be rewritten.\n+\n+When reading v1 manifests with no sequence number column, sequence numbers for all files must default to 0.\n+\n \n ### Snapshots\n \n A snapshot consists of the following fields:\n \n-*   **`snapshot-id`** -- A unique long ID.\n-*   **`parent-snapshot-id`** -- (Optional) The snapshot ID of the snapshot\u2019s parent. This field is not present for snapshots that have no parent snapshot, such as snapshots created before this field was added or the first snapshot of a table.\n-*   **`sequence-number`** -- A monotonically increasing long that tracks the order of snapshots in a table. (**v2 only**)\n-*   **`timestamp-ms`** -- A timestamp when the snapshot was created. This is used when garbage collecting snapshots.\n-*   **`manifests`** -- A list of manifest file locations. The data files in a snapshot are the union of all data files listed in these manifests. (Deprecated in favor of `manifest-list`)\n-*   **`manifest-list`** -- (Optional) The location of a manifest list file for this snapshot, which contains a list of manifest files with additional metadata. If present, the manifests field must be omitted.\n-*   **`summary`** -- (Optional) A summary that encodes the `operation` that produced the snapshot and other relevant information specific to that operation. This allows some operations like snapshot expiration to skip processing some snapshots. Possible values of `operation` are:\n-    *   `append` -- Data files were added and no files were removed.\n-    *   `replace` -- Data files were rewritten with the same data; i.e., compaction, changing the data file format, or relocating data files.\n-    *   `overwrite` -- Data files were deleted and added in a logical overwrite operation.\n-    *   `delete` -- Data files were removed and their contents logically deleted.\n+| v1         | v2         | Field                    | Description |\n+| ---------- | ---------- | ------------------------ | ----------- |\n+| _required_ | _required_ | **`snapshot-id`**        | A unique long ID |\n+| _optional_ | _optional_ | **`parent-snapshot-id`** | The snapshot ID of the snapshot's parent. Omitted for any snapshot with no parent |\n+|            | _required_ | **`sequence-number`**    | A monotonically increasing long that tracks the order of changes to a table |\n+| _required_ | _required_ | **`timestamp-ms`**       | A timestamp when the snapshot was created, used for garbage collection and table inspection |\n+| _optional_ | _required_ | **`manifest-list`**      | The location of a manifest list for this snapshot that tracks manifest files with additional meadata |\n+| _optional_ |            | **`manifests`**          | A list of manifest file locations. Must be omitted if `manifest-list` is present |\n+| _optional_ | _required_ | **`summary`**            | A string map that summarizes the snapshot changes, including `operation` (see below) |\n \n-Snapshots can be split across more than one manifest. This enables:\n+The snapshot summary's `operation` field is used by some operations, like snapshot expiration, to skip processing certain snapshots. Possible `operation` values are:\n+\n+*   `append` -- Only data files were added and no files were removed.\n+*   `replace` -- Data and delete files were added and removed without changing table data; i.e., compaction, changing the data file format, or relocating data files.\n+*   `overwrite` -- Data and delete files were added and removed in a logical overwrite operation.\n+*   `delete` -- Data files were removed and their contents logically deleted and/or delete files were added to delete rows.\n+\n+Data and delete files for a snapshot can be stored in more than one manifest. This enables:\n \n *   Appends can add a new manifest to minimize the amount of data written, instead of adding new records by rewriting and appending to an existing manifest. (This is called a \u201cfast append\u201d.)\n *   Tables can use multiple partition specs. A table\u2019s partition configuration can evolve if, for example, its data volume changes. Each manifest uses a single partition spec, and queries do not need to change because partition filters are derived from data predicates.\n *   Large tables can be split across multiple manifests so that implementations can parallelize job planning or reduce the cost of rewriting a manifest.\n \n+Manifests for a snapshot are tracked by a manifest list.\n+\n Valid snapshots are stored as a list in table metadata. For serialization, see Appendix C.\n \n \n+#### Manifest Lists\n+\n+Snapshots are embedded in table metadata, but the list of manifests for a snapshot are stored in a separate manifest list file.\n+\n+A new manifest list is written for each attempt to commit a snapshot because the list of manifests always changes to produce a new snapshot. When a manifest list is written, the (optimistic) sequence number of the snapshot is written for all new manifest files tracked by the list.\n+\n+A manifest list includes summary metadata that can be used to avoid scanning all of the manifests in a snapshot when planning a table scan. This includes the number of added, existing, and deleted files, and a summary of values for each field of the partition spec used to write the manifest.\n+\n+A manifest list is a valid Iceberg data file: files must use valid Iceberg formats, schemas, and column projection.\n+\n+Manifest list files store `manifest_file`, a struct with the following fields:\n+\n+| v1         | v2         | Field id, name                 | Type                                        | Description |\n+| ---------- | ---------- |--------------------------------|---------------------------------------------|-------------|\n+| _required_ | _required_ | **`500 manifest_path`**        | `string`                                    | Location of the manifest file |\n+| _required_ | _required_ | **`501 manifest_length`**      | `long`                                      | Length of the manifest file |\n+| _required_ | _required_ | **`502 partition_spec_id`**    | `int`                                       | ID of a partition spec for the table; must be listed in table metadata `partition-specs` |\n+|            | _required_ | **`517 content`**              | `int` with meaning: `0: data`, `1: deletes` | The type of files tracked by the manifest, either data or delete files; 0 for all v1 manifests |\n+|            | _required_ | **`515 sequence_number`**      | `long`                                      | The sequence number when the manifest was added to the table; use 0 when reading v1 manifest lists |\n+|            | _required_ | **`516 min_sequence_number`**  | `long`                                      | The minimum sequence number of all data or delete files in the manifest; use 0 when reading v1 manifest lists |\n+| _required_ | _required_ | **`503 added_snapshot_id`**    | `long`                                      | ID of the snapshot where the  manifest file was added |\n+| _optional_ | _required_ | **`504 added_files_count`**    | `int`                                       | Number of entries in the manifest that have status `ADDED` (1), when `null` this is assumed to be non-zero |\n+| _optional_ | _required_ | **`505 existing_files_count`** | `int`                                       | Number of entries in the manifest that have status `EXISTING` (0), when `null` this is assumed to be non-zero |\n+| _optional_ | _required_ | **`506 deleted_files_count`**  | `int`                                       | Number of entries in the manifest that have status `DELETED` (2), when `null` this is assumed to be non-zero |\n+| _optional_ | _required_ | **`512 added_rows_count`**     | `long`                                      | Number of rows in all of files in the manifest that have status `ADDED`, when `null` this is assumed to be non-zero |\n+| _optional_ | _required_ | **`513 existing_rows_count`**  | `long`                                      | Number of rows in all of files in the manifest that have status `EXISTING`, when `null` this is assumed to be non-zero |\n+| _optional_ | _required_ | **`514 deleted_rows_count`**   | `long`                                      | Number of rows in all of files in the manifest that have status `DELETED`, when `null` this is assumed to be non-zero |\n+| _optional_ | _optional_ | **`507 partitions`**           | `list<508: field_summary>` (see below)      | A list of field summaries for each partition field in the spec. Each field in the list corresponds to a field in the manifest file\u2019s partition spec. |\n+\n+`field_summary` is a struct with the following fields:\n+\n+| v1         | v2         | Field id, name          | Type          | Description |\n+| ---------- | ---------- |-------------------------|---------------|-------------|\n+| _required_ | _required_ | **`509 contains_null`** | `boolean`     | Whether the manifest contains at least one partition with a null value for the field |\n+| _optional_ | _optional_ | **`510 lower_bound`**   | `bytes`   [1] | Lower bound for the non-null values in the partition field, or null if all values are null |\n+| _optional_ | _optional_ | **`511 upper_bound`**   | `bytes`   [1] | Upper bound for the non-null values in the partition field, or null if all values are null |\n+\n+Notes:\n+\n+1. Lower and upper bounds are serialized to bytes using the single-object serialization in Appendix D. The type of used to encode the value is the type of the partition field data.\n+\n+\n #### Scan Planning\n \n-Scans are planned by reading the manifest files for the current snapshot listed in the table metadata. Deleted entries in a manifest are not included in the scan.\n+Scans are planned by reading the manifest files for the current snapshot. Deleted entries in data and delete manifests are not used in a scan.\n+\n+Manifests that contain no matching files, determined using either file counts or partition summaries, may be skipped.\n \n-For each manifest, scan predicates, which filter data rows, are converted to partition predicates, which filter data files. These partition predicates are used to select the data files in the manifest. This conversion uses the partition spec used to write the manifest file.\n+For each manifest, scan predicates, which filter data rows, are converted to partition predicates, which filter data and delete files. These partition predicates are used to select the data and delete files in the manifest. This conversion uses the partition spec used to write the manifest file.\n \n-Scan predicates are converted to partition predicates using an inclusive projection: if a scan predicate matches a row, then the partition predicate must match that row\u2019s partition. This is an _inclusive projection_ [1] because rows that do not match the scan predicate may be included in the scan by the partition predicate.\n+Scan predicates are converted to partition predicates using an _inclusive projection_: if a scan predicate matches a row, then the partition predicate must match that row\u2019s partition. This is called _inclusive_ [1] because rows that do not match the scan predicate may be included in the scan by the partition predicate.\n \n For example, an `events` table with a timestamp column named `ts` that is partitioned by `ts_day=day(ts)` is queried by users with ranges over the timestamp column: `ts > X`. The inclusive projection is `ts_day >= day(X)`, which is used to select files that may have matching rows. Note that, in most cases, timestamps just before `X` will be included in the scan because the file contains rows that match the predicate and rows that do not match the predicate.\n \n-Notes:\n+Scan predicates are also used to filter data and delete files using column bounds and counts that are stored by field id in manifests. The same filter logic can be used for both data and delete files because both stored metrics of the rows either inserted or deleted. If metrics show that a delete file has no rows that match a scan predicate, it may be ignored just as a data file would be ignored [2].\n \n-1. An alternative, *strict projection*, creates a partition predicate that will match a file if all of the rows in the file must match the scan predicate. These projections are used to calculate the residual predicates for each file in a scan.\n+Data files that match the query filter must be read by the scan.\n \n-#### Manifest Lists\n+Delete files that match the query filter must be applied to data files at read time, limited by the scope of the delete file using the following rules.\n \n-Snapshots are embedded in table metadata, but the list of manifests for a snapshot can be stored in a separate manifest list file.\n+* A _position_ delete file must be applied to a data file when all of the following are true:\n+    - The data file's sequence number is _less than or equal to_ the delete file's sequence number\n+    - The data file's partition (both spec and partition values) is equal to the delete file's partition\n+* An _equality_ delete file must be applied to a data file when all of the following are true:\n+    - The data file's sequence number is _strictly less than_ the delete's sequence number\n+    - The data file's partition (both spec and partition values) is equal to the delete file's partition _or_ the delete file's partition spec is unpartitioned\n \n-A manifest list encodes extra fields that can be used to avoid scanning all of the manifests in a snapshot when planning a table scan. \n+In general, deletes are applied only to data files that are older and in the same partition, except for two special cases:\n \n-Manifest list files store `manifest_file`, a struct with the following fields:\n+* Equality delete files stored with an unpartitioned spec are applied as global deletes. Otherwise, delete files do not apply to files in other partitions.\n+* Position delete files must be applied to data files from the same commit, when the data and delete file sequence numbers are equal. This allows deleting rows that were added in the same commit.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5e525811993918c752281bc76a2744605abbd325"}, "originalPosition": 369}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk3MTA3NTk0", "url": "https://github.com/apache/iceberg/pull/1499#pullrequestreview-497107594", "createdAt": "2020-09-27T20:13:09Z", "commit": {"oid": "5e525811993918c752281bc76a2744605abbd325"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yN1QyMDoxMzoxMFrOHYpr9g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yN1QyMDoxMzoxMFrOHYpr9g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTYxMDg3MA==", "bodyText": "equality?", "url": "https://github.com/apache/iceberg/pull/1499#discussion_r495610870", "createdAt": "2020-09-27T20:13:10Z", "author": {"login": "aokolnychyi"}, "path": "site/docs/spec.md", "diffHunk": "@@ -138,19 +164,41 @@ Valid type promotions are:\n * `float` to `double`\n * `decimal(P, S)` to `decimal(P', S)` if `P' > P` -- widen the precision of decimal types.\n \n-Any struct, including a top-level schema, can evolve through deleting fields, adding new fields, renaming existing fields, or promoting a primitive using the valid type promotions. Adding a new field assigns a new ID for that field and for any nested fields. Renaming an existing field must change the name, but not the field ID. Deleting a field removes it from the current schema. Field deletion cannot be rolled back unless the field was nullable or if the current snapshot has not changed.\n+Any struct, including a top-level schema, can evolve through deleting fields, adding new fields, renaming existing fields, reordering existing fields, or promoting a primitive using the valid type promotions. Adding a new field assigns a new ID for that field and for any nested fields. Renaming an existing field must change the name, but not the field ID. Deleting a field removes it from the current schema. Field deletion cannot be rolled back unless the field was nullable or if the current snapshot has not changed.\n \n Grouping a subset of a struct\u2019s fields into a nested struct is **not** allowed, nor is moving fields from a nested struct into its immediate parent struct (`struct<a, b, c> \u2194 struct<a, struct<b, c>>`). Evolving primitive types to structs is **not** allowed, nor is evolving a single-field struct to a primitive (`map<string, int> \u2194 map<string, struct<int>>`).\n \n \n+#### Column Projection\n+\n+Columns in Iceberg data files are selected by field id. Column names and order may change between after a data file is written, and projection must be done using field ids. If a field id is missing from a data file, its value for each row should be `null`.\n+\n+For example, a file may be written with schema `1: a int, 2: b string, 3: c double` and read using projection schema `3: measurement, 2: name, 4: a`. This must select file columns `c` (renamed to `measurement`), `b` (now called `name`), and a column of `null` values called `a`; in that order.\n+\n+\n+#### Reserved Field IDs\n+\n+Iceberg tables must not use field ids greater than 2147483447 (`Integer.MAX_VALUE - 200`). This id range is reserved for metadata columns that can be used in user data schemas, like the `_file` column that holds the file path in which a row was stored.\n+\n+The set of metadata columns is:\n+\n+| Field id, name              | Type          | Description |\n+|-----------------------------|---------------|-------------|\n+| **`2147483646  _file`**     | `string`      | Path of the file in which a row is stored |\n+| **`2147483645  _pos`**      | `long`        | Ordinal position of a row in the source data file |\n+| **`2147483546  file_path`** | `string`      | Path of a file, used in position-based delete files |\n+| **`2147483545  pos`**       | `long`        | Ordinal position of a row, used in position-based delete files |\n+| **`2147483544  row`**       | `struct<...>` | Deleted row values, used in position-based delete files |", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5e525811993918c752281bc76a2744605abbd325"}, "originalPosition": 109}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk3MTA3Njk0", "url": "https://github.com/apache/iceberg/pull/1499#pullrequestreview-497107694", "createdAt": "2020-09-27T20:14:51Z", "commit": {"oid": "5e525811993918c752281bc76a2744605abbd325"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yN1QyMDoxNDo1MVrOHYpsjA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yN1QyMDoxNDo1MVrOHYpsjA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NTYxMTAyMA==", "bodyText": "We don't store partition values in positional deletes just yet, do we?", "url": "https://github.com/apache/iceberg/pull/1499#discussion_r495611020", "createdAt": "2020-09-27T20:14:51Z", "author": {"login": "aokolnychyi"}, "path": "site/docs/spec.md", "diffHunk": "@@ -52,14 +52,37 @@ Data files in snapshots are tracked by one or more manifest files that contain a\n \n The manifests that make up a snapshot are stored in a manifest list file. Each manifest list stores metadata about manifests, including partition stats and data file counts. These stats are used to avoid reading manifests that are not required for an operation.\n \n-#### MVCC and Optimistic Concurrency\n+#### Optimistic Concurrency\n \n-An atomic swap of one table metadata file for another provides serializable isolation. Readers use the snapshot that was current when they load the table metadata and are not affected by changes until they refresh and pick up a new metadata location.\n+An atomic swap of one table metadata file for another provides the basis for serializable isolation. Readers use the snapshot that was current when they load the table metadata and are not affected by changes until they refresh and pick up a new metadata location.\n \n Writers create table metadata files optimistically, assuming that the current version will not be changed before the writer's commit. Once a writer has created an update, it commits by swapping the table\u2019s metadata file pointer from the base version to the new version.\n \n If the snapshot on which an update is based is no longer current, the writer must retry the update based on the new current version. Some operations support retry by re-applying metadata changes and committing, under well-defined conditions. For example, a change that rewrites files can be applied to a new table snapshot if all of the rewritten files are still in the table.\n \n+The conditions required by a write to successfully commit determines the isolation level. Writers can select what to validate and can make different isolation guarantees.\n+\n+#### Sequence Numbers\n+\n+The relative age of data and delete files relies on a sequence number that is assigned to every successful commit. When a snapshot is created for a commit, it is optimistically assigned the next sequence number, and it is written into the snapshot's metadata. If the commit fails and must be retried, the sequence number is reassigned and written into new snapshot metadata.\n+\n+All manifests, data files, and delete files created for a snapshot inherit the snapshot's sequence number. Manifest file metadata in the manifest list stores a manifest's sequence number. New data and metadata file entries are written with `null` in place of a sequence number, which is replaced with the manifest's sequence number at read time. When a data or delete file is written to a new manifest (as \"existing\"), the inherited sequence number is written to ensure it does not change after it is first inherited.\n+\n+Inheriting the sequence number from manifest metadata allows writing a new manifest once and reusing it in commit retries. To change a sequence number for a retry, only the manifest list must be rewritten -- which would be rewritten anyway with the latest set of manifests.\n+\n+\n+#### Row-level Deletes\n+\n+Row-level deletes are stored in delete files.\n+\n+There are two ways to encode a row-level delete:\n+\n+* [_Position deletes_](#position-delete-files) mark a row deleted by data file path and the row position in the data file\n+* [_Equality deletes_](#equality-delete-files) mark a row deleted by one or more column values, like `id = 5`\n+\n+Like data files, delete files are tracked by partition. In general, a delete file must be applied to older data files with the same partition; see [Scan Planning](#scan-planning) for details. Column metrics can be used to determine whether a delete file's rows overlap the contents of a data file or a scan range.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5e525811993918c752281bc76a2744605abbd325"}, "originalPosition": 43}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk4NjM0NDkz", "url": "https://github.com/apache/iceberg/pull/1499#pullrequestreview-498634493", "createdAt": "2020-09-29T15:47:37Z", "commit": {"oid": "5e525811993918c752281bc76a2744605abbd325"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxNTo0NzozN1rOHZ0Z_g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQxNTo0NzozN1rOHZ0Z_g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NjgzNTA3MA==", "bodyText": "may optionally contain additional columns of the deleted row\n\nWhat is the use case for this?", "url": "https://github.com/apache/iceberg/pull/1499#discussion_r496835070", "createdAt": "2020-09-29T15:47:37Z", "author": {"login": "electrum"}, "path": "site/docs/spec.md", "diffHunk": "@@ -416,25 +530,91 @@ Notes:\n \n ### Delete Formats\n \n-This section details how to encode row-level deletes in Iceberg metadata. Row-level deletes are not supported in the current format version 1. This part of the spec is not yet complete and will be completed as format version 2.\n+This section details how to encode row-level deletes in Iceberg delete files. Row-level deletes are not supported in v1.\n+\n+Row-level delete files are valid Iceberg data files: files must use valid Iceberg formats, schemas, and column projection. It is recommended that delete files are written using the table's default file format.\n+\n+Row-level delete files are tracked by manifests, like data files. A separate set of manifests is used for delete files, but the manifest schemas are identical.\n \n-#### Position-based Delete Files\n+Both position and equality deletes allow encoding deleted row values with a delete. This can be used to reconstruct a stream of changes to a table.\n \n-Position-based delete files identify rows in one or more data files that have been deleted.\n+\n+#### Position Delete Files\n+\n+Position-based delete files identify deleted rows by file and position in one or more data files, and may optionally contain the deleted row.\n+\n+A data row is deleted if there is an entry in a position delete file for the row's file and position in the data file, starting at 0.\n \n Position-based delete files store `file_position_delete`, a struct with the following fields:\n \n-| Field id, name          | Type                            | Description                                                                                                              |\n-|-------------------------|---------------------------------|--------------------------------------------------------------------------------------------------------------------------|\n-| **`1  file_path`**     | `required string`               | The full URI of a data file with FS scheme. This must match the `file_path` of the target data file in a manifest entry.   |\n-| **`2  position`**      | `required long`                 | The ordinal position of a deleted row in the target data file identified by `file_path`, starting at `0`.                    |\n+| Field id, name              | Type                   | Description |\n+|-----------------------------|------------------------|-------------|\n+| **`2147483546  file_path`** | `string`               | Full URI or a data file with FS scheme. This must match the `file_path` of the target data file in a manifest entry |\n+| **`2147483545  pos`**       | `long`                 | Ordinal position of a deleted row in the target data file identified by `file_path`, starting at `0` |\n+| **`2147483544  row`**       | `required struct<...>` | Deleted row values. Omit the column when not storing deleted rows. |\n+\n+When the deleted row is present, its schema may be any subset of the table schema. When the column is present, the deleted row values for every delete must be stored.\n \n The rows in the delete file must be sorted by `file_path` then `position` to optimize filtering rows while scanning. \n \n *  Sorting by `file_path` allows filter pushdown by file in columnar storage formats.\n *  Sorting by `position` allows filtering rows while scanning, to avoid keeping deletes in memory.\n \n-Though the delete files can be written using any supported data file format in Iceberg, it is recommended to write delete files with same file format as the table's file format.\n+#### Equality Delete Files\n+\n+Equality delete files identify deleted rows in a collection of data files by one or more column values, and may optionally contain additional columns of the deleted row.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5e525811993918c752281bc76a2744605abbd325"}, "originalPosition": 465}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk4ODg3MTY2", "url": "https://github.com/apache/iceberg/pull/1499#pullrequestreview-498887166", "createdAt": "2020-09-29T20:57:46Z", "commit": {"oid": "5e525811993918c752281bc76a2744605abbd325"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQyMDo1Nzo0NlrOHaBoUg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0yOVQyMDo1Nzo0NlrOHaBoUg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzA1MTczMA==", "bodyText": "I think this is a bit confusing, it's a required struct that could be omitted?\n\nOmit the column when not storing deleted rows.\n\nAlso a above it mentions:\n\nand may optionally contain the deleted row.\n\nIs this column required or am I missing something?", "url": "https://github.com/apache/iceberg/pull/1499#discussion_r497051730", "createdAt": "2020-09-29T20:57:46Z", "author": {"login": "edgarRd"}, "path": "site/docs/spec.md", "diffHunk": "@@ -416,25 +530,91 @@ Notes:\n \n ### Delete Formats\n \n-This section details how to encode row-level deletes in Iceberg metadata. Row-level deletes are not supported in the current format version 1. This part of the spec is not yet complete and will be completed as format version 2.\n+This section details how to encode row-level deletes in Iceberg delete files. Row-level deletes are not supported in v1.\n+\n+Row-level delete files are valid Iceberg data files: files must use valid Iceberg formats, schemas, and column projection. It is recommended that delete files are written using the table's default file format.\n+\n+Row-level delete files are tracked by manifests, like data files. A separate set of manifests is used for delete files, but the manifest schemas are identical.\n \n-#### Position-based Delete Files\n+Both position and equality deletes allow encoding deleted row values with a delete. This can be used to reconstruct a stream of changes to a table.\n \n-Position-based delete files identify rows in one or more data files that have been deleted.\n+\n+#### Position Delete Files\n+\n+Position-based delete files identify deleted rows by file and position in one or more data files, and may optionally contain the deleted row.\n+\n+A data row is deleted if there is an entry in a position delete file for the row's file and position in the data file, starting at 0.\n \n Position-based delete files store `file_position_delete`, a struct with the following fields:\n \n-| Field id, name          | Type                            | Description                                                                                                              |\n-|-------------------------|---------------------------------|--------------------------------------------------------------------------------------------------------------------------|\n-| **`1  file_path`**     | `required string`               | The full URI of a data file with FS scheme. This must match the `file_path` of the target data file in a manifest entry.   |\n-| **`2  position`**      | `required long`                 | The ordinal position of a deleted row in the target data file identified by `file_path`, starting at `0`.                    |\n+| Field id, name              | Type                   | Description |\n+|-----------------------------|------------------------|-------------|\n+| **`2147483546  file_path`** | `string`               | Full URI or a data file with FS scheme. This must match the `file_path` of the target data file in a manifest entry |\n+| **`2147483545  pos`**       | `long`                 | Ordinal position of a deleted row in the target data file identified by `file_path`, starting at `0` |\n+| **`2147483544  row`**       | `required struct<...>` | Deleted row values. Omit the column when not storing deleted rows. |", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5e525811993918c752281bc76a2744605abbd325"}, "originalPosition": 453}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk5MDExNzkw", "url": "https://github.com/apache/iceberg/pull/1499#pullrequestreview-499011790", "createdAt": "2020-09-30T00:28:17Z", "commit": {"oid": "5e525811993918c752281bc76a2744605abbd325"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0zMFQwMDoyODoxN1rOHaJW_w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0zMFQwMDoyODoxN1rOHaJW_w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzE3ODM2Nw==", "bodyText": "Good catch.", "url": "https://github.com/apache/iceberg/pull/1499#discussion_r497178367", "createdAt": "2020-09-30T00:28:17Z", "author": {"login": "aokolnychyi"}, "path": "site/docs/spec.md", "diffHunk": "@@ -32,7 +32,7 @@ The goal of version 2 is to provide a way to encode row-level deletes. This upda\n \n ## Goals\n \n-* **Snapshot isolation** -- Reads will be isolated from concurrent writes and always use a committed snapshot of a table\u2019s data. Writes will support removing and adding files in a single operation and are never partially visible. Readers will not acquire locks.\n+* **Serializable isolation** -- Reads will be isolated from concurrent writes and always use a committed snapshot of a table\u2019s data. Writes will support removing and adding files in a single operation and are never partially visible. Readers will not acquire locks.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5e525811993918c752281bc76a2744605abbd325"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk5MDEzMDk4", "url": "https://github.com/apache/iceberg/pull/1499#pullrequestreview-499013098", "createdAt": "2020-09-30T00:32:47Z", "commit": {"oid": "5e525811993918c752281bc76a2744605abbd325"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0zMFQwMDozMjo0OFrOHaJbmg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0zMFQwMDozMjo0OFrOHaJbmg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzE3OTU0Ng==", "bodyText": "Not related to this PR: there is no requirement for it to be Avro, right?", "url": "https://github.com/apache/iceberg/pull/1499#discussion_r497179546", "createdAt": "2020-09-30T00:32:48Z", "author": {"login": "aokolnychyi"}, "path": "site/docs/spec.md", "diffHunk": "@@ -208,136 +256,202 @@ Notes:\n \n ### Manifests\n \n-A manifest is an immutable Avro file that lists a set of data files, along with each file\u2019s partition data tuple, metrics, and tracking information. One or more manifest files are used to store a snapshot, which tracks all of the files in a table at some point in time.\n+A manifest is an immutable Avro file that lists data files or delete files, along with each file\u2019s partition data tuple, metrics, and tracking information. One or more manifest files are used to store a [snapshot](#snapshots), which tracks all of the files in a table at some point in time. Manifests are tracked by a [manifest list](#manifest-lists) for each table snapshot.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5e525811993918c752281bc76a2744605abbd325"}, "originalPosition": 129}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk5MDE5NzQ3", "url": "https://github.com/apache/iceberg/pull/1499#pullrequestreview-499019747", "createdAt": "2020-09-30T00:55:43Z", "commit": {"oid": "5e525811993918c752281bc76a2744605abbd325"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0zMFQwMDo1NTo0NFrOHaJzAw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0zMFQwMDo1NTo0NFrOHaJzAw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzE4NTUzOQ==", "bodyText": "its schema may be any subset of the table schema\n\nHow will we later map values into columns if it is a subset and does not use the current schema?", "url": "https://github.com/apache/iceberg/pull/1499#discussion_r497185539", "createdAt": "2020-09-30T00:55:44Z", "author": {"login": "aokolnychyi"}, "path": "site/docs/spec.md", "diffHunk": "@@ -416,25 +530,91 @@ Notes:\n \n ### Delete Formats\n \n-This section details how to encode row-level deletes in Iceberg metadata. Row-level deletes are not supported in the current format version 1. This part of the spec is not yet complete and will be completed as format version 2.\n+This section details how to encode row-level deletes in Iceberg delete files. Row-level deletes are not supported in v1.\n+\n+Row-level delete files are valid Iceberg data files: files must use valid Iceberg formats, schemas, and column projection. It is recommended that delete files are written using the table's default file format.\n+\n+Row-level delete files are tracked by manifests, like data files. A separate set of manifests is used for delete files, but the manifest schemas are identical.\n \n-#### Position-based Delete Files\n+Both position and equality deletes allow encoding deleted row values with a delete. This can be used to reconstruct a stream of changes to a table.\n \n-Position-based delete files identify rows in one or more data files that have been deleted.\n+\n+#### Position Delete Files\n+\n+Position-based delete files identify deleted rows by file and position in one or more data files, and may optionally contain the deleted row.\n+\n+A data row is deleted if there is an entry in a position delete file for the row's file and position in the data file, starting at 0.\n \n Position-based delete files store `file_position_delete`, a struct with the following fields:\n \n-| Field id, name          | Type                            | Description                                                                                                              |\n-|-------------------------|---------------------------------|--------------------------------------------------------------------------------------------------------------------------|\n-| **`1  file_path`**     | `required string`               | The full URI of a data file with FS scheme. This must match the `file_path` of the target data file in a manifest entry.   |\n-| **`2  position`**      | `required long`                 | The ordinal position of a deleted row in the target data file identified by `file_path`, starting at `0`.                    |\n+| Field id, name              | Type                   | Description |\n+|-----------------------------|------------------------|-------------|\n+| **`2147483546  file_path`** | `string`               | Full URI or a data file with FS scheme. This must match the `file_path` of the target data file in a manifest entry |\n+| **`2147483545  pos`**       | `long`                 | Ordinal position of a deleted row in the target data file identified by `file_path`, starting at `0` |\n+| **`2147483544  row`**       | `required struct<...>` | Deleted row values. Omit the column when not storing deleted rows. |\n+\n+When the deleted row is present, its schema may be any subset of the table schema. When the column is present, the deleted row values for every delete must be stored.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5e525811993918c752281bc76a2744605abbd325"}, "originalPosition": 455}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDk5MDIxMjEy", "url": "https://github.com/apache/iceberg/pull/1499#pullrequestreview-499021212", "createdAt": "2020-09-30T01:01:07Z", "commit": {"oid": "5e525811993918c752281bc76a2744605abbd325"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0zMFQwMTowMTowN1rOHaJ4Dg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0zMFQwMTowMTowN1rOHaJ4Dg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5NzE4NjgzMA==", "bodyText": "How do we plan to handle nulls as valid values and nulls as no value at all?", "url": "https://github.com/apache/iceberg/pull/1499#discussion_r497186830", "createdAt": "2020-09-30T01:01:07Z", "author": {"login": "aokolnychyi"}, "path": "site/docs/spec.md", "diffHunk": "@@ -416,25 +530,91 @@ Notes:\n \n ### Delete Formats\n \n-This section details how to encode row-level deletes in Iceberg metadata. Row-level deletes are not supported in the current format version 1. This part of the spec is not yet complete and will be completed as format version 2.\n+This section details how to encode row-level deletes in Iceberg delete files. Row-level deletes are not supported in v1.\n+\n+Row-level delete files are valid Iceberg data files: files must use valid Iceberg formats, schemas, and column projection. It is recommended that delete files are written using the table's default file format.\n+\n+Row-level delete files are tracked by manifests, like data files. A separate set of manifests is used for delete files, but the manifest schemas are identical.\n \n-#### Position-based Delete Files\n+Both position and equality deletes allow encoding deleted row values with a delete. This can be used to reconstruct a stream of changes to a table.\n \n-Position-based delete files identify rows in one or more data files that have been deleted.\n+\n+#### Position Delete Files\n+\n+Position-based delete files identify deleted rows by file and position in one or more data files, and may optionally contain the deleted row.\n+\n+A data row is deleted if there is an entry in a position delete file for the row's file and position in the data file, starting at 0.\n \n Position-based delete files store `file_position_delete`, a struct with the following fields:\n \n-| Field id, name          | Type                            | Description                                                                                                              |\n-|-------------------------|---------------------------------|--------------------------------------------------------------------------------------------------------------------------|\n-| **`1  file_path`**     | `required string`               | The full URI of a data file with FS scheme. This must match the `file_path` of the target data file in a manifest entry.   |\n-| **`2  position`**      | `required long`                 | The ordinal position of a deleted row in the target data file identified by `file_path`, starting at `0`.                    |\n+| Field id, name              | Type                   | Description |\n+|-----------------------------|------------------------|-------------|\n+| **`2147483546  file_path`** | `string`               | Full URI or a data file with FS scheme. This must match the `file_path` of the target data file in a manifest entry |\n+| **`2147483545  pos`**       | `long`                 | Ordinal position of a deleted row in the target data file identified by `file_path`, starting at `0` |\n+| **`2147483544  row`**       | `required struct<...>` | Deleted row values. Omit the column when not storing deleted rows. |\n+\n+When the deleted row is present, its schema may be any subset of the table schema. When the column is present, the deleted row values for every delete must be stored.\n \n The rows in the delete file must be sorted by `file_path` then `position` to optimize filtering rows while scanning. \n \n *  Sorting by `file_path` allows filter pushdown by file in columnar storage formats.\n *  Sorting by `position` allows filtering rows while scanning, to avoid keeping deletes in memory.\n \n-Though the delete files can be written using any supported data file format in Iceberg, it is recommended to write delete files with same file format as the table's file format.\n+#### Equality Delete Files\n+\n+Equality delete files identify deleted rows in a collection of data files by one or more column values, and may optionally contain additional columns of the deleted row.\n+\n+Equality delete files store any subset of a table's columns and use the table's field ids. The _delete columns_ are the columns of the delete file used to match data rows. Delete columns are identified by id in the delete file [metadata column `equality_ids`](#manifests).\n+\n+A data row is deleted if its values are equal to all delete columns for any row in an equality delete file that applies to the row's data file (see [`Job Planning`](#job-planning)).", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5e525811993918c752281bc76a2744605abbd325"}, "originalPosition": 469}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA3ODg4MDQx", "url": "https://github.com/apache/iceberg/pull/1499#pullrequestreview-507888041", "createdAt": "2020-10-13T23:03:44Z", "commit": {"oid": "5e525811993918c752281bc76a2744605abbd325"}, "state": "COMMENTED", "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QyMzowMzo0NVrOHg8elg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xM1QyMzowNDo0MFrOHg8fyA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDMwNzM1MA==", "bodyText": "To me this looks more like the ID of a partition spec for the manifest, instead of the table?", "url": "https://github.com/apache/iceberg/pull/1499#discussion_r504307350", "createdAt": "2020-10-13T23:03:45Z", "author": {"login": "yyanyy"}, "path": "site/docs/spec.md", "diffHunk": "@@ -208,136 +256,202 @@ Notes:\n \n ### Manifests\n \n-A manifest is an immutable Avro file that lists a set of data files, along with each file\u2019s partition data tuple, metrics, and tracking information. One or more manifest files are used to store a snapshot, which tracks all of the files in a table at some point in time.\n+A manifest is an immutable Avro file that lists data files or delete files, along with each file\u2019s partition data tuple, metrics, and tracking information. One or more manifest files are used to store a [snapshot](#snapshots), which tracks all of the files in a table at some point in time. Manifests are tracked by a [manifest list](#manifest-lists) for each table snapshot.\n+\n+A manifest is a valid Iceberg data file: files must use valid Iceberg formats, schemas, and column projection.\n+\n+A manifest may store either data files or delete files, but not both because manifests that contain delete files are scanned first during job planning. Whether a manifest is a data manifest or a delete manifest is stored in manifest metadata.\n \n-A manifest is a valid Iceberg data file. Files must use Iceberg schemas and column projection.\n+A manifest stores files for a single partition spec. When a table\u2019s partition spec changes, old files remain in the older manifest and newer files are written to a new manifest. This is required because a manifest file\u2019s schema is based on its partition spec (see below). The partition spec of each manifest is also used to transform predicates on the table's data rows into predicates on partition values that are used during job planning to select files from a manifest.\n \n-A manifest stores files for a single partition spec. When a table\u2019s partition spec changes, old files remain in the older manifest and newer files are written to a new manifest. This is required because a manifest file\u2019s schema is based on its partition spec (see below). This restriction also simplifies selecting files from a manifest because the same boolean expression can be used to select or filter all rows.\n+A manifest file must store the partition spec and other metadata as properties in the Avro file's key-value metadata:\n \n-The partition spec for a manifest and the current table schema must be stored in the key-value properties of the manifest file. The partition spec is stored as a JSON string under the key `partition-spec`. The table schema is stored as a JSON string under the key `schema`.\n+| v1         | v2         | Key                 | Value                                                                        |\n+|------------|------------|---------------------|------------------------------------------------------------------------------|\n+| _required_ | _required_ | `schema`            | JSON representation of the table schema at the time the manifest was written |\n+| _required_ | _required_ | `partition-spec`    | JSON fields representation of the partition spec used to write the manifest  |\n+| _optional_ | _required_ | `partition-spec-id` | Id of the partition spec used to write the manifest as a string              |\n+| _optional_ | _required_ | `format-version`    | Table format version number of the manifest as a string                      |\n+|            | _required_ | `content`           | Type of content files tracked by the manifest: \"data\" or \"deletes\"           |\n \n The schema of a manifest file is a struct called `manifest_entry` with the following fields:\n \n-| Field id, name       | Type                                                      | Description                                                     |\n-|----------------------|-----------------------------------------------------------|-----------------------------------------------------------------|\n-| **`0  status`**      | `int` with meaning: `0: EXISTING` `1: ADDED` `2: DELETED` | Used to track additions and deletions                           |\n-| **`1  snapshot_id`** | `long`                                                    | Snapshot id where the file was added, or deleted if status is 2 |\n-| **`2  data_file`**   | `data_file` `struct` (see below)                          | File path, partition tuple, metrics, ...                        |\n+| v1         | v2         | Field id, name           | Type                                                      | Description                                                                           |\n+| ---------- | ---------- |--------------------------|-----------------------------------------------------------|---------------------------------------------------------------------------------------|\n+| _required_ | _required_ | **`0  status`**          | `int` with meaning: `0: EXISTING` `1: ADDED` `2: DELETED` | Used to track additions and deletions                                                 |\n+| _required_ | _optional_ | **`1  snapshot_id`**     | `long`                                                    | Snapshot id where the file was added, or deleted if status is 2. Inherited when null. |\n+|            | _optional_ | **`3  sequence_number`** | `long`                                                    | Sequence number when the file was added. Inherited when null.                         |\n+| _required_ | _required_ | **`2  data_file`**       | `data_file` `struct` (see below)                          | File path, partition tuple, metrics, ...                                              |\n \n `data_file` is a struct with the following fields:\n \n-| Field id, name                    | Type                                  | Description                                                                                                                                                                                          |\n-|-----------------------------------|---------------------------------------|------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n-| **`100  file_path`**              | `string`                              | Full URI for the file with FS scheme                                                                                                                                                                 |\n-| **`101  file_format`**            | `string`                              | String file format name, avro, orc or parquet                                                                                                                                                        |\n-| **`102  partition`**              | `struct<...>`                         | Partition data tuple, schema based on the partition spec                                                                                                                                             |\n-| **`103  record_count`**           | `long`                                | Number of records in this file                                                                                                                                                                       |\n-| **`104  file_size_in_bytes`**     | `long`                                | Total file size in bytes                                                                                                                                                                             |\n-| ~~**`105 block_size_in_bytes`**~~ | `long`                                | **Deprecated. Always write a default value and do not read.**                                                                                                                                        |\n-| ~~**`106  file_ordinal`**~~       | `optional int`                        | **Deprecated. Do not use.**                                                                                                                                                                          |\n-| ~~**`107  sort_columns`**~~       | `optional list`                       | **Deprecated. Do not use.**                                                                                                                                                                          |\n-| **`108  column_sizes`**           | `optional map`                        | Map from column id to the total size on disk of all regions that store the column. Does not include bytes necessary to read other columns, like footers. Leave null for row-oriented formats (Avro). |\n-| **`109  value_counts`**           | `optional map`                        | Map from column id to number of values in the column (including null values)                                                                                                                         |\n-| **`110  null_value_counts`**      | `optional map`                        | Map from column id to number of null values in the column                                                                                                                                            |\n-| ~~**`111 distinct_counts`**~~     | `optional map`                        | **Deprecated. Do not use.**                                                                                                                                                                          |\n-| **`125  lower_bounds`**           | `optional map<126: int, 127: binary>` | Map from column id to lower bound in the column serialized as binary [1]. Each value must be less than or equal to all values in the column for the file.                                            |\n-| **`128  upper_bounds`**           | `optional map<129: int, 130: binary>` | Map from column id to upper bound in the column serialized as binary [1]. Each value must be greater than or equal to all values in the column for the file.                                         |\n-| **`131  key_metadata`**           | `optional binary`                     | Implementation-specific key metadata for encryption                                                                                                                                                  |\n-| **`132  split_offsets`**          | `optional list`                       | Split offsets for the data file. For example, all row group offsets in a Parquet file. Must be sorted ascending.                                                                                     |\n+| v1         | v2         | Field id, name                    | Type                         | Description |\n+| ---------- | ---------- |-----------------------------------|------------------------------|-------------|\n+|            | _required_ | **`134  content`**                | `int` with meaning: `0: DATA`, `1: POSITION DELETES`, `2: EQUALITY DELETES` | Type of content stored by the data file: data, equality deletes, or position deletes (all v1 files are data files) |\n+| _required_ | _required_ | **`100  file_path`**              | `string`                     | Full URI for the file with FS scheme |\n+| _required_ | _required_ | **`101  file_format`**            | `string`                     | String file format name, avro, orc or parquet |\n+| _required_ | _required_ | **`102  partition`**              | `struct<...>`                | Partition data tuple, schema based on the partition spec |\n+| _required_ | _required_ | **`103  record_count`**           | `long`                       | Number of records in this file |\n+| _required_ | _required_ | **`104  file_size_in_bytes`**     | `long`                       | Total file size in bytes |\n+| _required_ |            | ~~**`105 block_size_in_bytes`**~~ | `long`                       | **Deprecated. Always write a default in v1. Do not write in v2.** |\n+| _optional_ |            | ~~**`106  file_ordinal`**~~       | `int`                        | **Deprecated. Do not write.** |\n+| _optional_ |            | ~~**`107  sort_columns`**~~       | `list<112: int>`             | **Deprecated. Do not write.** |\n+| _optional_ | _optional_ | **`108  column_sizes`**           | `map<117: int, 118: long>`   | Map from column id to the total size on disk of all regions that store the column. Does not include bytes necessary to read other columns, like footers. Leave null for row-oriented formats (Avro) |\n+| _optional_ | _optional_ | **`109  value_counts`**           | `map<119: int, 120: long>`   | Map from column id to number of values in the column (including null values) |\n+| _optional_ | _optional_ | **`110  null_value_counts`**      | `map<121: int, 122: long>`   | Map from column id to number of null values in the column |\n+| _optional_ |            | ~~**`111 distinct_counts`**~~     | `map<123: int, 124: long>`   | **Deprecated. Do not write.** |\n+| _optional_ | _optional_ | **`125  lower_bounds`**           | `map<126: int, 127: binary>` | Map from column id to lower bound in the column serialized as binary [1]. Each value must be less than or equal to all values in the column for the file |\n+| _optional_ | _optional_ | **`128  upper_bounds`**           | `map<129: int, 130: binary>` | Map from column id to upper bound in the column serialized as binary [1]. Each value must be greater than or equal to all values in the column for the file |\n+| _optional_ | _optional_ | **`131  key_metadata`**           | `binary`                     | Implementation-specific key metadata for encryption |\n+| _optional_ | _optional_ | **`132  split_offsets`**          | `list<133: long>`            | Split offsets for the data file. For example, all row group offsets in a Parquet file. Must be sorted ascending |\n+|            | _optional_ | **`135  equality_ids`**           | `list<136: int>`             | Field ids used to determine row equality in equality delete files. Required when `content=2` and should be null otherwise. Fields with ids listed in this column must be present in the delete file |\n \n Notes:\n \n 1. Single-value serialization for lower and upper bounds is detailed in Appendix D.\n \n-The `partition` struct stores the tuple of partition values for each file. Its type is derived from the partition fields of the partition spec for the manifest file.\n+The `partition` struct stores the tuple of partition values for each file. Its type is derived from the partition fields of the partition spec used to write the manifest file. In v2, the partition struct's field ids must match the ids from the partition spec.\n \n-Each manifest file must store its partition spec and the current table schema in the Avro file\u2019s key-value metadata. The partition spec is used to transform predicates on the table\u2019s data rows into predicates on the manifest\u2019s partition values during job planning.\n+The column metrics maps are used when filtering to select both data and delete files. For delete files, the metrics must store bounds and counts for all deleted rows, or must be omitted. Storing metrics for deleted rows ensures that the values can be used during job planning to find delete files that must be merged during a scan.\n \n \n #### Manifest Entry Fields\n \n The manifest entry fields are used to keep track of the snapshot in which files were added or logically deleted. The `data_file` struct is nested inside of the manifest entry so that it can be easily passed to job planning without the manifest entry fields.\n \n-When a data file is added to the dataset, it\u2019s manifest entry should store the snapshot ID in which the file was added and set status to 1 (added).\n+When a file is added to the dataset, it\u2019s manifest entry should store the snapshot ID in which the file was added and set status to 1 (added).\n \n-When a data file is replaced or deleted from the dataset, it\u2019s manifest entry fields store the snapshot ID in which the file was deleted and status 2 (deleted). The file may be deleted from the file system when the snapshot in which it was deleted is garbage collected, assuming that older snapshots have also been garbage collected [1].\n+When a file is replaced or deleted from the dataset, it\u2019s manifest entry fields store the snapshot ID in which the file was deleted and status 2 (deleted). The file may be deleted from the file system when the snapshot in which it was deleted is garbage collected, assuming that older snapshots have also been garbage collected [1].\n+\n+Iceberg v2 adds a sequence number to the entry and makes the snapshot id optional. Both fields, `sequence_number` and `snapshot_id`, are inherited from manifest metadata when `null`. That is, if the field is `null` for an entry, then the entry must inherit its value from the manifest file's metadata, stored in the manifest list [2].\n \n Notes:\n \n 1. Technically, data files can be deleted when the last snapshot that contains the file as \u201clive\u201d data is garbage collected. But this is harder to detect and requires finding the diff of multiple snapshots. It is easier to track what files are deleted in a snapshot and delete them when that snapshot expires.\n+2. Manifest list files are required in v2, so that the `sequence_number` and `snapshot_id` to inherit are always available.\n+\n+#### Sequence Number Inheritance\n+\n+Manifests track the sequence number when a data or delete file was added to the table.\n+\n+When adding new file, its sequence number is set to `null` because the snapshot's sequence number is not assigned until the snapshot is successfully committed. When reading, sequence numbers are inherited by replacing `null` with the manifest's sequence number from the manifest list.\n+\n+When writing an existing file to a new manifest, the sequence number must be non-null and set to the sequence number that was inherited.\n+\n+Inheriting sequence numbers through the metadata tree allows writing a new manifest without a known sequence number, so that a manifest can be written once and reused in commit retries. To change a sequence number for a retry, only the manifest list must be rewritten.\n+\n+When reading v1 manifests with no sequence number column, sequence numbers for all files must default to 0.\n+\n \n ### Snapshots\n \n A snapshot consists of the following fields:\n \n-*   **`snapshot-id`** -- A unique long ID.\n-*   **`parent-snapshot-id`** -- (Optional) The snapshot ID of the snapshot\u2019s parent. This field is not present for snapshots that have no parent snapshot, such as snapshots created before this field was added or the first snapshot of a table.\n-*   **`sequence-number`** -- A monotonically increasing long that tracks the order of snapshots in a table. (**v2 only**)\n-*   **`timestamp-ms`** -- A timestamp when the snapshot was created. This is used when garbage collecting snapshots.\n-*   **`manifests`** -- A list of manifest file locations. The data files in a snapshot are the union of all data files listed in these manifests. (Deprecated in favor of `manifest-list`)\n-*   **`manifest-list`** -- (Optional) The location of a manifest list file for this snapshot, which contains a list of manifest files with additional metadata. If present, the manifests field must be omitted.\n-*   **`summary`** -- (Optional) A summary that encodes the `operation` that produced the snapshot and other relevant information specific to that operation. This allows some operations like snapshot expiration to skip processing some snapshots. Possible values of `operation` are:\n-    *   `append` -- Data files were added and no files were removed.\n-    *   `replace` -- Data files were rewritten with the same data; i.e., compaction, changing the data file format, or relocating data files.\n-    *   `overwrite` -- Data files were deleted and added in a logical overwrite operation.\n-    *   `delete` -- Data files were removed and their contents logically deleted.\n+| v1         | v2         | Field                    | Description |\n+| ---------- | ---------- | ------------------------ | ----------- |\n+| _required_ | _required_ | **`snapshot-id`**        | A unique long ID |\n+| _optional_ | _optional_ | **`parent-snapshot-id`** | The snapshot ID of the snapshot's parent. Omitted for any snapshot with no parent |\n+|            | _required_ | **`sequence-number`**    | A monotonically increasing long that tracks the order of changes to a table |\n+| _required_ | _required_ | **`timestamp-ms`**       | A timestamp when the snapshot was created, used for garbage collection and table inspection |\n+| _optional_ | _required_ | **`manifest-list`**      | The location of a manifest list for this snapshot that tracks manifest files with additional meadata |\n+| _optional_ |            | **`manifests`**          | A list of manifest file locations. Must be omitted if `manifest-list` is present |\n+| _optional_ | _required_ | **`summary`**            | A string map that summarizes the snapshot changes, including `operation` (see below) |\n \n-Snapshots can be split across more than one manifest. This enables:\n+The snapshot summary's `operation` field is used by some operations, like snapshot expiration, to skip processing certain snapshots. Possible `operation` values are:\n+\n+*   `append` -- Only data files were added and no files were removed.\n+*   `replace` -- Data and delete files were added and removed without changing table data; i.e., compaction, changing the data file format, or relocating data files.\n+*   `overwrite` -- Data and delete files were added and removed in a logical overwrite operation.\n+*   `delete` -- Data files were removed and their contents logically deleted and/or delete files were added to delete rows.\n+\n+Data and delete files for a snapshot can be stored in more than one manifest. This enables:\n \n *   Appends can add a new manifest to minimize the amount of data written, instead of adding new records by rewriting and appending to an existing manifest. (This is called a \u201cfast append\u201d.)\n *   Tables can use multiple partition specs. A table\u2019s partition configuration can evolve if, for example, its data volume changes. Each manifest uses a single partition spec, and queries do not need to change because partition filters are derived from data predicates.\n *   Large tables can be split across multiple manifests so that implementations can parallelize job planning or reduce the cost of rewriting a manifest.\n \n+Manifests for a snapshot are tracked by a manifest list.\n+\n Valid snapshots are stored as a list in table metadata. For serialization, see Appendix C.\n \n \n+#### Manifest Lists\n+\n+Snapshots are embedded in table metadata, but the list of manifests for a snapshot are stored in a separate manifest list file.\n+\n+A new manifest list is written for each attempt to commit a snapshot because the list of manifests always changes to produce a new snapshot. When a manifest list is written, the (optimistic) sequence number of the snapshot is written for all new manifest files tracked by the list.\n+\n+A manifest list includes summary metadata that can be used to avoid scanning all of the manifests in a snapshot when planning a table scan. This includes the number of added, existing, and deleted files, and a summary of values for each field of the partition spec used to write the manifest.\n+\n+A manifest list is a valid Iceberg data file: files must use valid Iceberg formats, schemas, and column projection.\n+\n+Manifest list files store `manifest_file`, a struct with the following fields:\n+\n+| v1         | v2         | Field id, name                 | Type                                        | Description |\n+| ---------- | ---------- |--------------------------------|---------------------------------------------|-------------|\n+| _required_ | _required_ | **`500 manifest_path`**        | `string`                                    | Location of the manifest file |\n+| _required_ | _required_ | **`501 manifest_length`**      | `long`                                      | Length of the manifest file |\n+| _required_ | _required_ | **`502 partition_spec_id`**    | `int`                                       | ID of a partition spec for the table; must be listed in table metadata `partition-specs` |", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5e525811993918c752281bc76a2744605abbd325"}, "originalPosition": 306}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDMwNzQyNA==", "bodyText": "Just for my understanding, the example given is just one way of representing it, alternatively it could be\nequality_ids=[1, 2]\n\n 1: id | 2: category\n-------|-------------\n 4     | NULL\n\nis that correct?\nAlso it sounds to me that for reconstructing a CDC pipeline efficiently, either the delete file or the table may need an additional flag to signal that a delete file (or all delete files) contain all columns of rows, but I guess that's outside of the scope.", "url": "https://github.com/apache/iceberg/pull/1499#discussion_r504307424", "createdAt": "2020-10-13T23:03:59Z", "author": {"login": "yyanyy"}, "path": "site/docs/spec.md", "diffHunk": "@@ -416,25 +530,91 @@ Notes:\n \n ### Delete Formats\n \n-This section details how to encode row-level deletes in Iceberg metadata. Row-level deletes are not supported in the current format version 1. This part of the spec is not yet complete and will be completed as format version 2.\n+This section details how to encode row-level deletes in Iceberg delete files. Row-level deletes are not supported in v1.\n+\n+Row-level delete files are valid Iceberg data files: files must use valid Iceberg formats, schemas, and column projection. It is recommended that delete files are written using the table's default file format.\n+\n+Row-level delete files are tracked by manifests, like data files. A separate set of manifests is used for delete files, but the manifest schemas are identical.\n \n-#### Position-based Delete Files\n+Both position and equality deletes allow encoding deleted row values with a delete. This can be used to reconstruct a stream of changes to a table.\n \n-Position-based delete files identify rows in one or more data files that have been deleted.\n+\n+#### Position Delete Files\n+\n+Position-based delete files identify deleted rows by file and position in one or more data files, and may optionally contain the deleted row.\n+\n+A data row is deleted if there is an entry in a position delete file for the row's file and position in the data file, starting at 0.\n \n Position-based delete files store `file_position_delete`, a struct with the following fields:\n \n-| Field id, name          | Type                            | Description                                                                                                              |\n-|-------------------------|---------------------------------|--------------------------------------------------------------------------------------------------------------------------|\n-| **`1  file_path`**     | `required string`               | The full URI of a data file with FS scheme. This must match the `file_path` of the target data file in a manifest entry.   |\n-| **`2  position`**      | `required long`                 | The ordinal position of a deleted row in the target data file identified by `file_path`, starting at `0`.                    |\n+| Field id, name              | Type                   | Description |\n+|-----------------------------|------------------------|-------------|\n+| **`2147483546  file_path`** | `string`               | Full URI or a data file with FS scheme. This must match the `file_path` of the target data file in a manifest entry |\n+| **`2147483545  pos`**       | `long`                 | Ordinal position of a deleted row in the target data file identified by `file_path`, starting at `0` |\n+| **`2147483544  row`**       | `required struct<...>` | Deleted row values. Omit the column when not storing deleted rows. |\n+\n+When the deleted row is present, its schema may be any subset of the table schema. When the column is present, the deleted row values for every delete must be stored.\n \n The rows in the delete file must be sorted by `file_path` then `position` to optimize filtering rows while scanning. \n \n *  Sorting by `file_path` allows filter pushdown by file in columnar storage formats.\n *  Sorting by `position` allows filtering rows while scanning, to avoid keeping deletes in memory.\n \n-Though the delete files can be written using any supported data file format in Iceberg, it is recommended to write delete files with same file format as the table's file format.\n+#### Equality Delete Files\n+\n+Equality delete files identify deleted rows in a collection of data files by one or more column values, and may optionally contain additional columns of the deleted row.\n+\n+Equality delete files store any subset of a table's columns and use the table's field ids. The _delete columns_ are the columns of the delete file used to match data rows. Delete columns are identified by id in the delete file [metadata column `equality_ids`](#manifests).\n+\n+A data row is deleted if its values are equal to all delete columns for any row in an equality delete file that applies to the row's data file (see [`Job Planning`](#job-planning)).\n+\n+Each row of the delete file produces one equality predicate that matches any row where the delete columns are equal. Multiple columns can be thought of as an `AND` of equality predicates. A `null` value in a delete column matches a row if the row's value is `null`, equivalent to `col IS NULL`.\n+\n+For example, a table with the following data:\n+\n+```text\n+ 1: id | 2: category | 3: name\n+-------|-------------|---------\n+ 1     | marsupial   | Koala\n+ 2     | toy         | Teddy\n+ 3     | NULL        | Grizzly\n+ 4     | NULL        | Polar\n+```\n+\n+The delete `id = 3` could be written as either of the following equality delete files:\n+\n+```text\n+equality_ids=[1]\n+\n+ 1: id\n+-------\n+ 3\n+```\n+\n+```text\n+equality_ids=[1]\n+\n+ 1: id | 2: category | 3: name\n+-------|-------------|---------\n+ 3     | NULL        | Grizzly\n+```\n+\n+The delete `id = 4 AND category IS NULL` could be written as the following equality delete file:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5e525811993918c752281bc76a2744605abbd325"}, "originalPosition": 502}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDMwNzQ2NQ==", "bodyText": "Curious, what's the use case of encoding deleted row values within an equality delete file? I thought one reason of using equality delete file is to not have to read the data file, otherwise we may directly create a position delete file. Or this will only happen when the delete query happen to include all row values of the row it wants to delete? If this is the case, how common is this use case?", "url": "https://github.com/apache/iceberg/pull/1499#discussion_r504307465", "createdAt": "2020-10-13T23:04:02Z", "author": {"login": "yyanyy"}, "path": "site/docs/spec.md", "diffHunk": "@@ -416,25 +530,91 @@ Notes:\n \n ### Delete Formats\n \n-This section details how to encode row-level deletes in Iceberg metadata. Row-level deletes are not supported in the current format version 1. This part of the spec is not yet complete and will be completed as format version 2.\n+This section details how to encode row-level deletes in Iceberg delete files. Row-level deletes are not supported in v1.\n+\n+Row-level delete files are valid Iceberg data files: files must use valid Iceberg formats, schemas, and column projection. It is recommended that delete files are written using the table's default file format.\n+\n+Row-level delete files are tracked by manifests, like data files. A separate set of manifests is used for delete files, but the manifest schemas are identical.\n \n-#### Position-based Delete Files\n+Both position and equality deletes allow encoding deleted row values with a delete. This can be used to reconstruct a stream of changes to a table.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5e525811993918c752281bc76a2744605abbd325"}, "originalPosition": 433}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwNDMwNzY1Ng==", "bodyText": "\"Column names and order may change between after\" ?", "url": "https://github.com/apache/iceberg/pull/1499#discussion_r504307656", "createdAt": "2020-10-13T23:04:40Z", "author": {"login": "yyanyy"}, "path": "site/docs/spec.md", "diffHunk": "@@ -138,19 +164,41 @@ Valid type promotions are:\n * `float` to `double`\n * `decimal(P, S)` to `decimal(P', S)` if `P' > P` -- widen the precision of decimal types.\n \n-Any struct, including a top-level schema, can evolve through deleting fields, adding new fields, renaming existing fields, or promoting a primitive using the valid type promotions. Adding a new field assigns a new ID for that field and for any nested fields. Renaming an existing field must change the name, but not the field ID. Deleting a field removes it from the current schema. Field deletion cannot be rolled back unless the field was nullable or if the current snapshot has not changed.\n+Any struct, including a top-level schema, can evolve through deleting fields, adding new fields, renaming existing fields, reordering existing fields, or promoting a primitive using the valid type promotions. Adding a new field assigns a new ID for that field and for any nested fields. Renaming an existing field must change the name, but not the field ID. Deleting a field removes it from the current schema. Field deletion cannot be rolled back unless the field was nullable or if the current snapshot has not changed.\n \n Grouping a subset of a struct\u2019s fields into a nested struct is **not** allowed, nor is moving fields from a nested struct into its immediate parent struct (`struct<a, b, c> \u2194 struct<a, struct<b, c>>`). Evolving primitive types to structs is **not** allowed, nor is evolving a single-field struct to a primitive (`map<string, int> \u2194 map<string, struct<int>>`).\n \n \n+#### Column Projection\n+\n+Columns in Iceberg data files are selected by field id. Column names and order may change between after a data file is written, and projection must be done using field ids. If a field id is missing from a data file, its value for each row should be `null`.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "5e525811993918c752281bc76a2744605abbd325"}, "originalPosition": 92}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "85f0b16f9b750c721e8753ed69361b0c08c383a5", "author": {"user": {"login": "rdblue", "name": "Ryan Blue"}}, "url": "https://github.com/apache/iceberg/commit/85f0b16f9b750c721e8753ed69361b0c08c383a5", "committedDate": "2020-10-28T22:22:36Z", "message": "Update for review comments."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE5MTM1NTQ5", "url": "https://github.com/apache/iceberg/pull/1499#pullrequestreview-519135549", "createdAt": "2020-10-28T22:36:19Z", "commit": {"oid": "85f0b16f9b750c721e8753ed69361b0c08c383a5"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3835, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}