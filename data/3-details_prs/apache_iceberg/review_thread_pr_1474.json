{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDg4OTc3Njk5", "number": 1474, "reviewThreads": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QyMzozMDoyN1rOEkwq3A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQwMDoxMTo1M1rOEkxJGQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2OTgxNTk2OnYy", "diffSide": "LEFT", "path": "parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QyMzozMDoyN1rOHT44ug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QyMzo0NDozOFrOHT5JLQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDYxNzAxOA==", "bodyText": "@sudssf This needs to initialize a new reader as we want to get row positions relative to the start of the file and not start of the split. I think the only change that is necessary in this PR is to close the reader.", "url": "https://github.com/apache/iceberg/pull/1474#discussion_r490617018", "createdAt": "2020-09-17T23:30:27Z", "author": {"login": "shardulm94"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java", "diffHunk": "@@ -165,12 +165,12 @@ ParquetFileReader reader() {\n     return shouldSkip;\n   }\n \n-  private Map<Long, Long> generateOffsetToStartPos() {\n-    ParquetFileReader fileReader = newReader(this.file, ParquetReadOptions.builder().build());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a427eef4fcb8de7a6060be6ee2d49283200041a1"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDYxNzU1Mg==", "bodyText": "ok I will revert to previous commit thanks for reply", "url": "https://github.com/apache/iceberg/pull/1474#discussion_r490617552", "createdAt": "2020-09-17T23:32:15Z", "author": {"login": "sudssf"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java", "diffHunk": "@@ -165,12 +165,12 @@ ParquetFileReader reader() {\n     return shouldSkip;\n   }\n \n-  private Map<Long, Long> generateOffsetToStartPos() {\n-    ParquetFileReader fileReader = newReader(this.file, ParquetReadOptions.builder().build());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDYxNzAxOA=="}, "originalCommit": {"oid": "a427eef4fcb8de7a6060be6ee2d49283200041a1"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDYyMTIyOQ==", "bodyText": "Can you remove the extra newline here?", "url": "https://github.com/apache/iceberg/pull/1474#discussion_r490621229", "createdAt": "2020-09-17T23:44:38Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java", "diffHunk": "@@ -165,12 +165,12 @@ ParquetFileReader reader() {\n     return shouldSkip;\n   }\n \n-  private Map<Long, Long> generateOffsetToStartPos() {\n-    ParquetFileReader fileReader = newReader(this.file, ParquetReadOptions.builder().build());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDYxNzAxOA=="}, "originalCommit": {"oid": "a427eef4fcb8de7a6060be6ee2d49283200041a1"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2OTgxOTc0OnYy", "diffSide": "LEFT", "path": "parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java", "isResolved": true, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QyMzozMjoxNlrOHT461w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QyMzozMzoxMlrOHT471g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDYxNzU1OQ==", "bodyText": "The reason for a new reader is to create one that doesn't have a filter pushed down through ParquetReadOptions.\nWhen building a reader, a file range can be added to ParquetReadOptions, which will filter Parquet row groups as they are read. Iceberg uses this to handle file split ranges, and Parquet avoids reading the row group metadata in case there are a lot of row groups in the file.\nThere are a couple options to fix this. We could stop pushing the file range to Parquet so that it reads all the row groups and use your implementation here. That would also require applying the range in ReadConf and setting shouldSkip appropriately.\nA second option is to properly close the file that is opened here, like this:\n  private Map<Long, Long> generateOffsetToStartPos() {\n    try (ParquetFileReader fileReader = newReader(file, ParquetReadOptions.builder().build())) {\n      Map<Long, Long> offsetToStartPos = Maps.newHashMap();\n\n      long curRowCount = 0;\n      for (int i = 0; i < fileReader.getRowGroups().size(); i += 1) {\n        BlockMetaData meta = fileReader.getRowGroups().get(i);\n        offsetToStartPos.put(meta.getStartingPos(), curRowCount);\n        curRowCount += meta.getRowCount();\n      }\n\n      return offsetToStartPos;\n\n    } catch (IOException e) {\n      throw new UncheckedIOException(\"Failed to close reader for file: \" + file, e);\n    }\n  }\nI think it's a good idea to go with the first option, but we might want to fix this with the second option in the mean time.", "url": "https://github.com/apache/iceberg/pull/1474#discussion_r490617559", "createdAt": "2020-09-17T23:32:16Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java", "diffHunk": "@@ -165,12 +165,12 @@ ParquetFileReader reader() {\n     return shouldSkip;\n   }\n \n-  private Map<Long, Long> generateOffsetToStartPos() {\n-    ParquetFileReader fileReader = newReader(this.file, ParquetReadOptions.builder().build());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "a427eef4fcb8de7a6060be6ee2d49283200041a1"}, "originalPosition": 14}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDYxNzgxNA==", "bodyText": "thanks let me revert to option1", "url": "https://github.com/apache/iceberg/pull/1474#discussion_r490617814", "createdAt": "2020-09-17T23:33:12Z", "author": {"login": "sudssf"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java", "diffHunk": "@@ -165,12 +165,12 @@ ParquetFileReader reader() {\n     return shouldSkip;\n   }\n \n-  private Map<Long, Long> generateOffsetToStartPos() {\n-    ParquetFileReader fileReader = newReader(this.file, ParquetReadOptions.builder().build());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDYxNzU1OQ=="}, "originalCommit": {"oid": "a427eef4fcb8de7a6060be6ee2d49283200041a1"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2OTg0MTM4OnYy", "diffSide": "RIGHT", "path": "parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QyMzo0MzoyNFrOHT5Hyw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QyMzo0OTozOFrOHT5Owg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDYyMDg3NQ==", "bodyText": "Nit: missing space between try and (. This will probably fail validation.", "url": "https://github.com/apache/iceberg/pull/1474#discussion_r490620875", "createdAt": "2020-09-17T23:43:24Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java", "diffHunk": "@@ -166,15 +167,19 @@ ParquetFileReader reader() {\n   }\n \n   private Map<Long, Long> generateOffsetToStartPos() {\n-    ParquetFileReader fileReader = newReader(this.file, ParquetReadOptions.builder().build());\n+\n     Map<Long, Long> offsetToStartPos = new HashMap<>();\n-    long curRowCount = 0;\n-    for (int i = 0; i < fileReader.getRowGroups().size(); i += 1) {\n-      BlockMetaData meta = fileReader.getRowGroups().get(i);\n-      offsetToStartPos.put(meta.getStartingPos(), curRowCount);\n-      curRowCount += meta.getRowCount();\n-    }\n \n+    try(ParquetFileReader fileReader = newReader(this.file, ParquetReadOptions.builder().build())) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6b08ce32455b5cb830bcc396f93ab6b32fd0ced9"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDYyMTA2NQ==", "bodyText": "While you're changing this, can you remove this. from the variable reference? We use this. to distinguish setting instance fields, not getting instance fields.", "url": "https://github.com/apache/iceberg/pull/1474#discussion_r490621065", "createdAt": "2020-09-17T23:44:04Z", "author": {"login": "rdblue"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java", "diffHunk": "@@ -166,15 +167,19 @@ ParquetFileReader reader() {\n   }\n \n   private Map<Long, Long> generateOffsetToStartPos() {\n-    ParquetFileReader fileReader = newReader(this.file, ParquetReadOptions.builder().build());\n+\n     Map<Long, Long> offsetToStartPos = new HashMap<>();\n-    long curRowCount = 0;\n-    for (int i = 0; i < fileReader.getRowGroups().size(); i += 1) {\n-      BlockMetaData meta = fileReader.getRowGroups().get(i);\n-      offsetToStartPos.put(meta.getStartingPos(), curRowCount);\n-      curRowCount += meta.getRowCount();\n-    }\n \n+    try(ParquetFileReader fileReader = newReader(this.file, ParquetReadOptions.builder().build())) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDYyMDg3NQ=="}, "originalCommit": {"oid": "6b08ce32455b5cb830bcc396f93ab6b32fd0ced9"}, "originalPosition": 22}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDYyMjY1OA==", "bodyText": "yup I will revert to code you posted above :)", "url": "https://github.com/apache/iceberg/pull/1474#discussion_r490622658", "createdAt": "2020-09-17T23:49:38Z", "author": {"login": "sudssf"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java", "diffHunk": "@@ -166,15 +167,19 @@ ParquetFileReader reader() {\n   }\n \n   private Map<Long, Long> generateOffsetToStartPos() {\n-    ParquetFileReader fileReader = newReader(this.file, ParquetReadOptions.builder().build());\n+\n     Map<Long, Long> offsetToStartPos = new HashMap<>();\n-    long curRowCount = 0;\n-    for (int i = 0; i < fileReader.getRowGroups().size(); i += 1) {\n-      BlockMetaData meta = fileReader.getRowGroups().get(i);\n-      offsetToStartPos.put(meta.getStartingPos(), curRowCount);\n-      curRowCount += meta.getRowCount();\n-    }\n \n+    try(ParquetFileReader fileReader = newReader(this.file, ParquetReadOptions.builder().build())) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDYyMDg3NQ=="}, "originalCommit": {"oid": "6b08ce32455b5cb830bcc396f93ab6b32fd0ced9"}, "originalPosition": 22}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2OTg2MTk4OnYy", "diffSide": "RIGHT", "path": "parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QyMzo1NDoxNVrOHT5Tqg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xN1QyMzo1NDoxNVrOHT5Tqg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDYyMzkxNA==", "bodyText": "Maps.newHashMap() was not auto resolved by imports so going to use default constructor", "url": "https://github.com/apache/iceberg/pull/1474#discussion_r490623914", "createdAt": "2020-09-17T23:54:15Z", "author": {"login": "sudssf"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java", "diffHunk": "@@ -166,17 +167,22 @@ ParquetFileReader reader() {\n   }\n \n   private Map<Long, Long> generateOffsetToStartPos() {\n-    ParquetFileReader fileReader = newReader(this.file, ParquetReadOptions.builder().build());\n-    Map<Long, Long> offsetToStartPos = new HashMap<>();\n-    long curRowCount = 0;\n-    for (int i = 0; i < fileReader.getRowGroups().size(); i += 1) {\n-      BlockMetaData meta = fileReader.getRowGroups().get(i);\n-      offsetToStartPos.put(meta.getStartingPos(), curRowCount);\n-      curRowCount += meta.getRowCount();\n-    }\n+      try (ParquetFileReader fileReader = newReader(file, ParquetReadOptions.builder().build())) {\n+        Map<Long, Long> offsetToStartPos = new HashMap<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b257dba9dcc18596e10ae5aefd6e53eea950ebf"}, "originalPosition": 21}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzA2OTg5MzM3OnYy", "diffSide": "RIGHT", "path": "parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java", "isResolved": true, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQwMDoxMTo1NFrOHT5mLw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xOFQwMDoxMTo1NFrOHT5mLw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ5MDYyODY1NQ==", "bodyText": "The message may be \"failed to create reader\"?", "url": "https://github.com/apache/iceberg/pull/1474#discussion_r490628655", "createdAt": "2020-09-18T00:11:54Z", "author": {"login": "chenjunjiedada"}, "path": "parquet/src/main/java/org/apache/iceberg/parquet/ReadConf.java", "diffHunk": "@@ -166,17 +167,22 @@ ParquetFileReader reader() {\n   }\n \n   private Map<Long, Long> generateOffsetToStartPos() {\n-    ParquetFileReader fileReader = newReader(this.file, ParquetReadOptions.builder().build());\n-    Map<Long, Long> offsetToStartPos = new HashMap<>();\n-    long curRowCount = 0;\n-    for (int i = 0; i < fileReader.getRowGroups().size(); i += 1) {\n-      BlockMetaData meta = fileReader.getRowGroups().get(i);\n-      offsetToStartPos.put(meta.getStartingPos(), curRowCount);\n-      curRowCount += meta.getRowCount();\n-    }\n+      try (ParquetFileReader fileReader = newReader(file, ParquetReadOptions.builder().build())) {\n+        Map<Long, Long> offsetToStartPos = new HashMap<>();\n \n-    return offsetToStartPos;\n-  }\n+        long curRowCount = 0;\n+        for (int i = 0; i < fileReader.getRowGroups().size(); i += 1) {\n+          BlockMetaData meta = fileReader.getRowGroups().get(i);\n+          offsetToStartPos.put(meta.getStartingPos(), curRowCount);\n+          curRowCount += meta.getRowCount();\n+        }\n+\n+        return offsetToStartPos;\n+\n+      } catch (IOException e) {\n+        throw new UncheckedIOException(\"Failed to close reader for file: \" + file, e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2b257dba9dcc18596e10ae5aefd6e53eea950ebf"}, "originalPosition": 35}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3743, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}