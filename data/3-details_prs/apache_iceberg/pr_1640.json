{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTA3OTM2MTgw", "number": 1640, "title": "Allow loading custom Catalog implementation in Spark and Flink", "bodyText": "As we are having multiple new Catalog implementations added to Iceberg, we need a way to load those Catalogs in Spark and Flink easily. Currently there is a simple switch branch that chooses between hive and hadoop catalogs. This approach requires the iceberg-spark and iceberg-flink module to take a dependency on the catalog implementation modules. This would potentially bring in many unnecessary dependencies as more and more cloud providers try to add support for Iceberg.\nThis PR proposes the following way to load custom Catalog implementations:\n\nthe type of a catalog can be hive or hadoop to keep existing behaviors\nif catalog-impl is set, type is ignored and we will load catalog based on the class value\nA catalog must have a no-arg constructor be initialized by calling initialize()\nA catalog must implement Hadoop Configurable to read Hadoop configuration\n\nFor example, a GlueCatalog will be used in Spark like the following:\nspark.sql.catalog.glue = org.apache.iceberg.spark.SparkCatalog\nspark.sql.catalog.glue.catalog-impl = org.apache.iceberg.aws.glue.GlueCatalog", "createdAt": "2020-10-22T00:23:38Z", "url": "https://github.com/apache/iceberg/pull/1640", "merged": true, "mergeCommit": {"oid": "b623b074c6242ac3b48fce8712dedd7f97e6ee5b"}, "closed": true, "closedAt": "2020-11-04T22:24:22Z", "author": {"login": "jackye1995"}, "timelineItems": {"totalCount": 27, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdVIdrTAFqTUxNTExMzk1Mg==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdZAs7egFqTUyMjkxMzMxNg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE1MTEzOTUy", "url": "https://github.com/apache/iceberg/pull/1640#pullrequestreview-515113952", "createdAt": "2020-10-22T20:58:53Z", "commit": {"oid": "17f1c5c17b7789778599b2d9f499fc47837a7806"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQyMDo1ODo1M1rOHmzl3Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yMlQyMTowMToxNVrOHmzq6w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDQ1MzIxMw==", "bodyText": "NIT: Avoid hard code it", "url": "https://github.com/apache/iceberg/pull/1640#discussion_r510453213", "createdAt": "2020-10-22T20:58:53Z", "author": {"login": "giovannifumarola"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkCatalogFactory.java", "diffHunk": "@@ -79,6 +80,10 @@ protected CatalogLoader createCatalogLoader(String name, Map<String, String> pro\n         String warehouseLocation = properties.get(HADOOP_WAREHOUSE_LOCATION);\n         return CatalogLoader.hadoop(name, hadoopConf, warehouseLocation);\n \n+      case \"custom\":", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "17f1c5c17b7789778599b2d9f499fc47837a7806"}, "originalPosition": 12}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMDQ1NDUwNw==", "bodyText": "Maybe this method can be static and be called from other places.", "url": "https://github.com/apache/iceberg/pull/1640#discussion_r510454507", "createdAt": "2020-10-22T21:01:15Z", "author": {"login": "giovannifumarola"}, "path": "flink/src/main/java/org/apache/iceberg/flink/CatalogLoader.java", "diffHunk": "@@ -94,4 +100,47 @@ public String toString() {\n           .toString();\n     }\n   }\n+\n+  class CustomCatalogLoader implements CatalogLoader {\n+\n+    private final SerializableConfiguration hadoopConf;\n+    private final String name;\n+    private final String impl;\n+\n+    private CustomCatalogLoader(String name, Configuration conf, String impl) {\n+      this.hadoopConf = new SerializableConfiguration(conf);\n+      this.name = name;\n+      this.impl = Preconditions.checkNotNull(impl,\n+          \"Cannot initialize custom Catalog because impl property is not set\");\n+    }\n+\n+    @Override\n+    public Catalog loadCatalog() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "17f1c5c17b7789778599b2d9f499fc47837a7806"}, "originalPosition": 43}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "cd57ea032a236b4590cb9863a2a0b4fd52f98aa3", "author": {"user": {"login": "jackye1995", "name": "Jack Ye"}}, "url": "https://github.com/apache/iceberg/commit/cd57ea032a236b4590cb9863a2a0b4fd52f98aa3", "committedDate": "2020-10-27T23:14:01Z", "message": "add map to constructor, add custom catalog for spark2"}, "afterCommit": {"oid": "6942c9da6dc9e0065ed6494b6689220708370b2f", "author": {"user": {"login": "jackye1995", "name": "Jack Ye"}}, "url": "https://github.com/apache/iceberg/commit/6942c9da6dc9e0065ed6494b6689220708370b2f", "committedDate": "2020-10-27T23:13:04Z", "message": "initial impl using custom type"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "6942c9da6dc9e0065ed6494b6689220708370b2f", "author": {"user": {"login": "jackye1995", "name": "Jack Ye"}}, "url": "https://github.com/apache/iceberg/commit/6942c9da6dc9e0065ed6494b6689220708370b2f", "committedDate": "2020-10-27T23:13:04Z", "message": "initial impl using custom type"}, "afterCommit": {"oid": "40c914d0ea7a659a48dbc445240ac8a30ab8bf97", "author": {"user": {"login": "marton-bod", "name": "Marton Bod"}}, "url": "https://github.com/apache/iceberg/commit/40c914d0ea7a659a48dbc445240ac8a30ab8bf97", "committedDate": "2020-10-27T23:13:04Z", "message": "Hive: Add TestHiveShell for parameterized StorageHandler tests (#1631)\n\nCo-authored-by: Marton Bod <mbod@cloudera.com>"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "40c914d0ea7a659a48dbc445240ac8a30ab8bf97", "author": {"user": {"login": "marton-bod", "name": "Marton Bod"}}, "url": "https://github.com/apache/iceberg/commit/40c914d0ea7a659a48dbc445240ac8a30ab8bf97", "committedDate": "2020-10-27T23:13:04Z", "message": "Hive: Add TestHiveShell for parameterized StorageHandler tests (#1631)\n\nCo-authored-by: Marton Bod <mbod@cloudera.com>"}, "afterCommit": {"oid": "f1776f64ba1d298a063bb3da6dc41e52b803b038", "author": {"user": {"login": "Fokko", "name": "Fokko Driesprong"}}, "url": "https://github.com/apache/iceberg/commit/f1776f64ba1d298a063bb3da6dc41e52b803b038", "committedDate": "2020-10-27T23:13:04Z", "message": "Spark: Bump Spark 3 version to 3.0.1 (#1656)"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f1776f64ba1d298a063bb3da6dc41e52b803b038", "author": {"user": {"login": "Fokko", "name": "Fokko Driesprong"}}, "url": "https://github.com/apache/iceberg/commit/f1776f64ba1d298a063bb3da6dc41e52b803b038", "committedDate": "2020-10-27T23:13:04Z", "message": "Spark: Bump Spark 3 version to 3.0.1 (#1656)"}, "afterCommit": {"oid": "f4708aa2f414d4c9027b797ebdb87232563bc3cb", "author": {"user": {"login": "RussellSpitzer", "name": "Russell Spitzer"}}, "url": "https://github.com/apache/iceberg/commit/f4708aa2f414d4c9027b797ebdb87232563bc3cb", "committedDate": "2020-10-27T23:13:04Z", "message": "Docs: Fix docs typo in ParquetVectorizedReader (#1658)"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f4708aa2f414d4c9027b797ebdb87232563bc3cb", "author": {"user": {"login": "RussellSpitzer", "name": "Russell Spitzer"}}, "url": "https://github.com/apache/iceberg/commit/f4708aa2f414d4c9027b797ebdb87232563bc3cb", "committedDate": "2020-10-27T23:13:04Z", "message": "Docs: Fix docs typo in ParquetVectorizedReader (#1658)"}, "afterCommit": {"oid": "fe56b3b346f5ccea6d22f530f31cb0677f7d16a1", "author": {"user": {"login": "marton-bod", "name": "Marton Bod"}}, "url": "https://github.com/apache/iceberg/commit/fe56b3b346f5ccea6d22f530f31cb0677f7d16a1", "committedDate": "2020-10-27T23:13:04Z", "message": "Hive: Update test code for Hive4 (#1645)\n\nCo-authored-by: Marton Bod <mbod@cloudera.com>"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "fe56b3b346f5ccea6d22f530f31cb0677f7d16a1", "author": {"user": {"login": "marton-bod", "name": "Marton Bod"}}, "url": "https://github.com/apache/iceberg/commit/fe56b3b346f5ccea6d22f530f31cb0677f7d16a1", "committedDate": "2020-10-27T23:13:04Z", "message": "Hive: Update test code for Hive4 (#1645)\n\nCo-authored-by: Marton Bod <mbod@cloudera.com>"}, "afterCommit": {"oid": "e72109d246c2aa2b1f1409e189c597742b342f86", "author": {"user": {"login": "samarthjain", "name": "Samarth Jain"}}, "url": "https://github.com/apache/iceberg/commit/e72109d246c2aa2b1f1409e189c597742b342f86", "committedDate": "2020-10-27T23:13:04Z", "message": "Parquet: Add test for Arrow buffer reallocation (#1480)"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e72109d246c2aa2b1f1409e189c597742b342f86", "author": {"user": {"login": "samarthjain", "name": "Samarth Jain"}}, "url": "https://github.com/apache/iceberg/commit/e72109d246c2aa2b1f1409e189c597742b342f86", "committedDate": "2020-10-27T23:13:04Z", "message": "Parquet: Add test for Arrow buffer reallocation (#1480)"}, "afterCommit": {"oid": "0ff356b03cfbf9a0a1ef535d5f9754641f7c9edf", "author": {"user": {"login": "openinx", "name": "openinx"}}, "url": "https://github.com/apache/iceberg/commit/0ff356b03cfbf9a0a1ef535d5f9754641f7c9edf", "committedDate": "2020-10-27T23:13:04Z", "message": "Flink: Load hive-site.xml for HiveCatalog (#1586)"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0ff356b03cfbf9a0a1ef535d5f9754641f7c9edf", "author": {"user": {"login": "openinx", "name": "openinx"}}, "url": "https://github.com/apache/iceberg/commit/0ff356b03cfbf9a0a1ef535d5f9754641f7c9edf", "committedDate": "2020-10-27T23:13:04Z", "message": "Flink: Load hive-site.xml for HiveCatalog (#1586)"}, "afterCommit": {"oid": "9d0083be4c8d2d03d95af7c1dde59931673133ff", "author": {"user": {"login": "skambha", "name": "Sunitha Kambhampati"}}, "url": "https://github.com/apache/iceberg/commit/9d0083be4c8d2d03d95af7c1dde59931673133ff", "committedDate": "2020-10-27T23:11:59Z", "message": "Docs: Document property behavior for Spark REPLACE TABLE (#1644)"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9d0083be4c8d2d03d95af7c1dde59931673133ff", "author": {"user": {"login": "skambha", "name": "Sunitha Kambhampati"}}, "url": "https://github.com/apache/iceberg/commit/9d0083be4c8d2d03d95af7c1dde59931673133ff", "committedDate": "2020-10-27T23:11:59Z", "message": "Docs: Document property behavior for Spark REPLACE TABLE (#1644)"}, "afterCommit": {"oid": "4f8efcbc39387e2b13b961bd3a777cefbf846427", "author": {"user": {"login": "Fokko", "name": "Fokko Driesprong"}}, "url": "https://github.com/apache/iceberg/commit/4f8efcbc39387e2b13b961bd3a777cefbf846427", "committedDate": "2020-10-27T23:11:59Z", "message": "Spark: Bump Spark 2 module to 2.4.7 (#1646)"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "4f8efcbc39387e2b13b961bd3a777cefbf846427", "author": {"user": {"login": "Fokko", "name": "Fokko Driesprong"}}, "url": "https://github.com/apache/iceberg/commit/4f8efcbc39387e2b13b961bd3a777cefbf846427", "committedDate": "2020-10-27T23:11:59Z", "message": "Spark: Bump Spark 2 module to 2.4.7 (#1646)"}, "afterCommit": {"oid": "9535ebe2244a94277901095a70e9e827a810f4b0", "author": {"user": {"login": "Fokko", "name": "Fokko Driesprong"}}, "url": "https://github.com/apache/iceberg/commit/9535ebe2244a94277901095a70e9e827a810f4b0", "committedDate": "2020-10-27T23:11:59Z", "message": "Lint: Fix small issues (#1650)"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9535ebe2244a94277901095a70e9e827a810f4b0", "author": {"user": {"login": "Fokko", "name": "Fokko Driesprong"}}, "url": "https://github.com/apache/iceberg/commit/9535ebe2244a94277901095a70e9e827a810f4b0", "committedDate": "2020-10-27T23:11:59Z", "message": "Lint: Fix small issues (#1650)"}, "afterCommit": {"oid": "47bb57a0f2787dd1b2aaf8857717321ca4b39efd", "author": {"user": {"login": "RussellSpitzer", "name": "Russell Spitzer"}}, "url": "https://github.com/apache/iceberg/commit/47bb57a0f2787dd1b2aaf8857717321ca4b39efd", "committedDate": "2020-10-27T23:11:59Z", "message": "Spark: Split Actions for Spark 2 and 3 using reflection (#1616)"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "47bb57a0f2787dd1b2aaf8857717321ca4b39efd", "author": {"user": {"login": "RussellSpitzer", "name": "Russell Spitzer"}}, "url": "https://github.com/apache/iceberg/commit/47bb57a0f2787dd1b2aaf8857717321ca4b39efd", "committedDate": "2020-10-27T23:11:59Z", "message": "Spark: Split Actions for Spark 2 and 3 using reflection (#1616)"}, "afterCommit": {"oid": "d3201f241dfec6c9a8091b39ce6f16cd3bf9bb96", "author": {"user": {"login": "RussellSpitzer", "name": "Russell Spitzer"}}, "url": "https://github.com/apache/iceberg/commit/d3201f241dfec6c9a8091b39ce6f16cd3bf9bb96", "committedDate": "2020-10-27T23:11:59Z", "message": "Parquet: Fix row group filtering with old CDH stats (#1638)"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d3201f241dfec6c9a8091b39ce6f16cd3bf9bb96", "author": {"user": {"login": "RussellSpitzer", "name": "Russell Spitzer"}}, "url": "https://github.com/apache/iceberg/commit/d3201f241dfec6c9a8091b39ce6f16cd3bf9bb96", "committedDate": "2020-10-27T23:11:59Z", "message": "Parquet: Fix row group filtering with old CDH stats (#1638)"}, "afterCommit": {"oid": "17f1c5c17b7789778599b2d9f499fc47837a7806", "author": {"user": {"login": "jackye1995", "name": "Jack Ye"}}, "url": "https://github.com/apache/iceberg/commit/17f1c5c17b7789778599b2d9f499fc47837a7806", "committedDate": "2020-10-22T00:10:55Z", "message": "initial impl using custom type"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "17f1c5c17b7789778599b2d9f499fc47837a7806", "author": {"user": {"login": "jackye1995", "name": "Jack Ye"}}, "url": "https://github.com/apache/iceberg/commit/17f1c5c17b7789778599b2d9f499fc47837a7806", "committedDate": "2020-10-22T00:10:55Z", "message": "initial impl using custom type"}, "afterCommit": {"oid": "d3ec64385b2ca6687167fa09a7e768e6da7c61df", "author": {"user": {"login": "openinx", "name": "openinx"}}, "url": "https://github.com/apache/iceberg/commit/d3ec64385b2ca6687167fa09a7e768e6da7c61df", "committedDate": "2020-10-21T01:09:35Z", "message": "Flink: Support configurable parallelism for write tasks (#1619)"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE4MjUzMTk0", "url": "https://github.com/apache/iceberg/pull/1640#pullrequestreview-518253194", "createdAt": "2020-10-28T00:57:22Z", "commit": {"oid": "1b3997450a142d951915aae70474cef63d6ba4f9"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQwMDo1NzoyMlrOHpWNyw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yOFQwMDo1NzoyMlrOHpWNyw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMzExNzY0Mw==", "bodyText": "We definitely need an option to create a catalog without passing Configuration but still passing config properties. I originally thought that it would make sense to use another constructor, but then I thought about how name is passed... and I think the number of possible constructors may get out of hand.\nInstead of adding a lot of constructors, I think we should do this:\n\nUse a no-arg constructor for all catalogs\nAdd an initialize method to catalogs that is called to pass the catalog name and a string map of config (this matches what Spark does)\nIf the catalog implements Hadoop's Configurable interface, also call setConf to set the Hadoop config.\n\nThat way, we avoid having Configuration in any of our APIs and minimize the number of constructors that we need to support. What do you think, @jackye1995?", "url": "https://github.com/apache/iceberg/pull/1640#discussion_r513117643", "createdAt": "2020-10-28T00:57:22Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/CatalogLoader.java", "diffHunk": "@@ -105,4 +113,54 @@ public String toString() {\n           .toString();\n     }\n   }\n+\n+  class CustomCatalogLoader implements CatalogLoader {\n+\n+    private final SerializableConfiguration hadoopConf;\n+    private final Map<String, String> properties;\n+    private final String name;\n+    private final String impl;\n+\n+    private CustomCatalogLoader(\n+        String name,\n+        Map<String, String> properties,\n+        Configuration conf,\n+        String impl) {\n+      this.hadoopConf = new SerializableConfiguration(conf);\n+      this.properties = new HashMap<>(properties); // use hashmap for serialization\n+      this.name = name;\n+      this.impl = Preconditions.checkNotNull(impl,\n+          \"Cannot initialize custom Catalog because impl property is not set\");\n+    }\n+\n+    @Override\n+    public Catalog loadCatalog() {\n+      DynConstructors.Ctor<Catalog> ctor;\n+      try {\n+        ctor = DynConstructors.builder(Catalog.class)\n+            .impl(impl, Map.class, Configuration.class) // take in flink properties and hadoop configs\n+            .impl(impl) // fall back to no-arg constructor", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1b3997450a142d951915aae70474cef63d6ba4f9"}, "originalPosition": 58}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIyMTM1NjQ3", "url": "https://github.com/apache/iceberg/pull/1640#pullrequestreview-522135647", "createdAt": "2020-11-03T01:04:38Z", "commit": {"oid": "c427e9875a27c4e52dcafa8e53ea0561234786db"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QwMTowNDozOFrOHsdJkQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QwMTowNDozOFrOHsdJkQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM3Njk3Nw==", "bodyText": "Nit: I would expect impl to come first to keep the configuration (name, options) together.", "url": "https://github.com/apache/iceberg/pull/1640#discussion_r516376977", "createdAt": "2020-11-03T01:04:38Z", "author": {"login": "rdblue"}, "path": "core/src/main/java/org/apache/iceberg/CatalogUtil.java", "diffHunk": "@@ -117,4 +122,45 @@ private static void deleteFiles(FileIO io, Set<ManifestFile> allManifests) {\n           }\n         });\n   }\n+\n+  /**\n+   * Load a custom catalog implementation.\n+   * The catalog must have a no-arg constructor.\n+   * If the catalog implements {@link org.apache.hadoop.conf.Configurable},\n+   * {@code Configurable.setConf(org.apache.hadoop.conf.Configuration conf)} is called to set Hadoop configuration.\n+   * {@code Catalog.initialize(String name, Map<String, String> options)} is called to complete the initialization.\n+   * @param catalogName catalog name\n+   * @param impl catalog implementation full class name\n+   * @param engineOptions configuration options from a compute engine like Spark or Flink to initialize the catalog\n+   * @param hadoopConf hadoop configuration if needed\n+   * @return initialized catalog object\n+   * @throws IllegalArgumentException if no-arg constructor not found or error during initialization\n+   */\n+  public static Catalog loadCustomCatalog(\n+      String catalogName,\n+      String impl,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c427e9875a27c4e52dcafa8e53ea0561234786db"}, "originalPosition": 35}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIyMTM1NzUx", "url": "https://github.com/apache/iceberg/pull/1640#pullrequestreview-522135751", "createdAt": "2020-11-03T01:04:56Z", "commit": {"oid": "c427e9875a27c4e52dcafa8e53ea0561234786db"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QwMTowNDo1N1rOHsdKOg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QwMTowNDo1N1rOHsdKOg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM3NzE0Ng==", "bodyText": "This may all fit on one line now.", "url": "https://github.com/apache/iceberg/pull/1640#discussion_r516377146", "createdAt": "2020-11-03T01:04:57Z", "author": {"login": "rdblue"}, "path": "core/src/main/java/org/apache/iceberg/CatalogUtil.java", "diffHunk": "@@ -117,4 +122,45 @@ private static void deleteFiles(FileIO io, Set<ManifestFile> allManifests) {\n           }\n         });\n   }\n+\n+  /**\n+   * Load a custom catalog implementation.\n+   * The catalog must have a no-arg constructor.\n+   * If the catalog implements {@link org.apache.hadoop.conf.Configurable},\n+   * {@code Configurable.setConf(org.apache.hadoop.conf.Configuration conf)} is called to set Hadoop configuration.\n+   * {@code Catalog.initialize(String name, Map<String, String> options)} is called to complete the initialization.\n+   * @param catalogName catalog name\n+   * @param impl catalog implementation full class name\n+   * @param engineOptions configuration options from a compute engine like Spark or Flink to initialize the catalog\n+   * @param hadoopConf hadoop configuration if needed\n+   * @return initialized catalog object\n+   * @throws IllegalArgumentException if no-arg constructor not found or error during initialization\n+   */\n+  public static Catalog loadCustomCatalog(\n+      String catalogName,\n+      String impl,\n+      Map<String, String> engineOptions,\n+      Configuration hadoopConf) {\n+    Preconditions.checkNotNull(impl, \"Cannot initialize custom Catalog because impl property is not set\");\n+    DynConstructors.Ctor<Catalog> ctor;\n+    try {\n+      ctor = DynConstructors.builder(Catalog.class)\n+          .impl(impl)\n+          .buildChecked();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c427e9875a27c4e52dcafa8e53ea0561234786db"}, "originalPosition": 43}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIyMTM1OTgw", "url": "https://github.com/apache/iceberg/pull/1640#pullrequestreview-522135980", "createdAt": "2020-11-03T01:05:44Z", "commit": {"oid": "c427e9875a27c4e52dcafa8e53ea0561234786db"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QwMTowNTo0NFrOHsdLkw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QwMTowNTo0NFrOHsdLkw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM3NzQ5MQ==", "bodyText": "Can we move configuration out of the try/catch block? It doesn't need to be there.", "url": "https://github.com/apache/iceberg/pull/1640#discussion_r516377491", "createdAt": "2020-11-03T01:05:44Z", "author": {"login": "rdblue"}, "path": "core/src/main/java/org/apache/iceberg/CatalogUtil.java", "diffHunk": "@@ -117,4 +122,45 @@ private static void deleteFiles(FileIO io, Set<ManifestFile> allManifests) {\n           }\n         });\n   }\n+\n+  /**\n+   * Load a custom catalog implementation.\n+   * The catalog must have a no-arg constructor.\n+   * If the catalog implements {@link org.apache.hadoop.conf.Configurable},\n+   * {@code Configurable.setConf(org.apache.hadoop.conf.Configuration conf)} is called to set Hadoop configuration.\n+   * {@code Catalog.initialize(String name, Map<String, String> options)} is called to complete the initialization.\n+   * @param catalogName catalog name\n+   * @param impl catalog implementation full class name\n+   * @param engineOptions configuration options from a compute engine like Spark or Flink to initialize the catalog\n+   * @param hadoopConf hadoop configuration if needed\n+   * @return initialized catalog object\n+   * @throws IllegalArgumentException if no-arg constructor not found or error during initialization\n+   */\n+  public static Catalog loadCustomCatalog(\n+      String catalogName,\n+      String impl,\n+      Map<String, String> engineOptions,\n+      Configuration hadoopConf) {\n+    Preconditions.checkNotNull(impl, \"Cannot initialize custom Catalog because impl property is not set\");\n+    DynConstructors.Ctor<Catalog> ctor;\n+    try {\n+      ctor = DynConstructors.builder(Catalog.class)\n+          .impl(impl)\n+          .buildChecked();\n+    } catch (NoSuchMethodException e) {\n+      throw new IllegalArgumentException(String.format(\n+          \"Cannot initialize Catalog, please make sure %s has a no-arg constructor\", impl), e);\n+    }\n+    try {\n+      Catalog catalog = ctor.newInstance();\n+      if (catalog instanceof Configurable) {\n+        ((Configurable) catalog).setConf(hadoopConf);\n+      }\n+      catalog.initialize(catalogName, engineOptions);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c427e9875a27c4e52dcafa8e53ea0561234786db"}, "originalPosition": 53}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIyMTQ3MDk0", "url": "https://github.com/apache/iceberg/pull/1640#pullrequestreview-522147094", "createdAt": "2020-11-03T01:48:35Z", "commit": {"oid": "c427e9875a27c4e52dcafa8e53ea0561234786db"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QwMTo0ODozNVrOHsd0vQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QwMTo0ODozNVrOHsd0vQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM4ODAyOQ==", "bodyText": "The name engineOptions seems too specific because it assumes that the caller is an engine. But it could be a user of the API that isn't an engine. I think config or properties would be a better name.", "url": "https://github.com/apache/iceberg/pull/1640#discussion_r516388029", "createdAt": "2020-11-03T01:48:35Z", "author": {"login": "rdblue"}, "path": "core/src/main/java/org/apache/iceberg/CatalogUtil.java", "diffHunk": "@@ -117,4 +122,45 @@ private static void deleteFiles(FileIO io, Set<ManifestFile> allManifests) {\n           }\n         });\n   }\n+\n+  /**\n+   * Load a custom catalog implementation.\n+   * The catalog must have a no-arg constructor.\n+   * If the catalog implements {@link org.apache.hadoop.conf.Configurable},\n+   * {@code Configurable.setConf(org.apache.hadoop.conf.Configuration conf)} is called to set Hadoop configuration.\n+   * {@code Catalog.initialize(String name, Map<String, String> options)} is called to complete the initialization.\n+   * @param catalogName catalog name\n+   * @param impl catalog implementation full class name\n+   * @param engineOptions configuration options from a compute engine like Spark or Flink to initialize the catalog\n+   * @param hadoopConf hadoop configuration if needed\n+   * @return initialized catalog object\n+   * @throws IllegalArgumentException if no-arg constructor not found or error during initialization\n+   */\n+  public static Catalog loadCustomCatalog(\n+      String catalogName,\n+      String impl,\n+      Map<String, String> engineOptions,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c427e9875a27c4e52dcafa8e53ea0561234786db"}, "originalPosition": 36}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIyMTQ3NTc2", "url": "https://github.com/apache/iceberg/pull/1640#pullrequestreview-522147576", "createdAt": "2020-11-03T01:50:25Z", "commit": {"oid": "c427e9875a27c4e52dcafa8e53ea0561234786db"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QwMTo1MDoyNVrOHsd2-A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QwMTo1MDoyNVrOHsd2-A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM4ODYwMA==", "bodyText": "Minor: I tend to opt for removing words that aren't needed, so I would remove \"custom\" from here. I think that's pretty much implied by loading an implementation class.", "url": "https://github.com/apache/iceberg/pull/1640#discussion_r516388600", "createdAt": "2020-11-03T01:50:25Z", "author": {"login": "rdblue"}, "path": "core/src/main/java/org/apache/iceberg/CatalogUtil.java", "diffHunk": "@@ -117,4 +122,45 @@ private static void deleteFiles(FileIO io, Set<ManifestFile> allManifests) {\n           }\n         });\n   }\n+\n+  /**\n+   * Load a custom catalog implementation.\n+   * The catalog must have a no-arg constructor.\n+   * If the catalog implements {@link org.apache.hadoop.conf.Configurable},\n+   * {@code Configurable.setConf(org.apache.hadoop.conf.Configuration conf)} is called to set Hadoop configuration.\n+   * {@code Catalog.initialize(String name, Map<String, String> options)} is called to complete the initialization.\n+   * @param catalogName catalog name\n+   * @param impl catalog implementation full class name\n+   * @param engineOptions configuration options from a compute engine like Spark or Flink to initialize the catalog\n+   * @param hadoopConf hadoop configuration if needed\n+   * @return initialized catalog object\n+   * @throws IllegalArgumentException if no-arg constructor not found or error during initialization\n+   */\n+  public static Catalog loadCustomCatalog(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c427e9875a27c4e52dcafa8e53ea0561234786db"}, "originalPosition": 33}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIyMTQ3ODk1", "url": "https://github.com/apache/iceberg/pull/1640#pullrequestreview-522147895", "createdAt": "2020-11-03T01:51:49Z", "commit": {"oid": "c427e9875a27c4e52dcafa8e53ea0561234786db"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QwMTo1MTo1MFrOHsd4SQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QwMTo1MTo1MFrOHsd4SQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM4ODkzNw==", "bodyText": "Instead of using type=custom and impl=com.example.Catalog, why not just combine them into type=com.example.Catalog. We can try to load the type as an implementation class if it isn't a well-known name like \"hive\".", "url": "https://github.com/apache/iceberg/pull/1640#discussion_r516388937", "createdAt": "2020-11-03T01:51:50Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkCatalogFactory.java", "diffHunk": "@@ -58,13 +59,19 @@\n \n   // Can not just use \"type\", it conflicts with CATALOG_TYPE.\n   public static final String ICEBERG_CATALOG_TYPE = \"catalog-type\";\n+  public static final String ICEBERG_CATALOG_TYPE_HADOOP = \"hadoop\";\n+  public static final String ICEBERG_CATALOG_TYPE_HIVE = \"hive\";\n+  public static final String ICEBERG_CATALOG_TYPE_CUSTOM = \"custom\";", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c427e9875a27c4e52dcafa8e53ea0561234786db"}, "originalPosition": 14}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIyMTQ4Mjc2", "url": "https://github.com/apache/iceberg/pull/1640#pullrequestreview-522148276", "createdAt": "2020-11-03T01:53:27Z", "commit": {"oid": "c427e9875a27c4e52dcafa8e53ea0561234786db"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QwMTo1MzoyN1rOHsd5tA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wM1QwMTo1MzoyN1rOHsd5tA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxNjM4OTMwMA==", "bodyText": "I think we shouldn't change the behavior of IcebergSource in this PR. We want to change how this source works and route queries through a catalog, but I'm not sure that using impl is the right way to do it. Let's stick with HiveCatalogs for now and revisit this in a follow up.", "url": "https://github.com/apache/iceberg/pull/1640#discussion_r516389300", "createdAt": "2020-11-03T01:53:27Z", "author": {"login": "rdblue"}, "path": "spark2/src/main/java/org/apache/iceberg/spark/source/IcebergSource.java", "diffHunk": "@@ -137,9 +138,11 @@ protected Table findTable(DataSourceOptions options, Configuration conf) {\n       HadoopTables tables = new HadoopTables(conf);\n       return tables.load(path.get());\n     } else {\n-      HiveCatalog hiveCatalog = HiveCatalogs.loadCatalog(conf);\n+      Catalog catalog = options.get(\"impl\")\n+          .map(impl -> CatalogUtil.loadCustomCatalog(\"custom\", impl, options.asMap(), conf))\n+          .orElseGet(() -> HiveCatalogs.loadCatalog(conf));\n       TableIdentifier tableIdentifier = TableIdentifier.parse(path.get());\n-      return hiveCatalog.loadTable(tableIdentifier);\n+      return catalog.loadTable(tableIdentifier);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c427e9875a27c4e52dcafa8e53ea0561234786db"}, "originalPosition": 25}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "2ddfeb72823e07b3cf117f4666f4329ec9ebb37f", "author": {"user": {"login": "jackye1995", "name": "Jack Ye"}}, "url": "https://github.com/apache/iceberg/commit/2ddfeb72823e07b3cf117f4666f4329ec9ebb37f", "committedDate": "2020-11-03T05:28:16Z", "message": "fix spacing"}, "afterCommit": {"oid": "c7ce41ab642d0320142f50da78c2b0c95b622a27", "author": {"user": {"login": "jackye1995", "name": "Jack Ye"}}, "url": "https://github.com/apache/iceberg/commit/c7ce41ab642d0320142f50da78c2b0c95b622a27", "committedDate": "2020-11-03T18:46:36Z", "message": "Allow loading custom Catalog implementation in Spark and Flink"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "485dea0552b40faa329c2c956c2c462412dc8a8e", "author": {"user": {"login": "jackye1995", "name": "Jack Ye"}}, "url": "https://github.com/apache/iceberg/commit/485dea0552b40faa329c2c956c2c462412dc8a8e", "committedDate": "2020-11-03T21:37:08Z", "message": "Allow loading custom Catalog implementation in Spark and Flink"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c7ce41ab642d0320142f50da78c2b0c95b622a27", "author": {"user": {"login": "jackye1995", "name": "Jack Ye"}}, "url": "https://github.com/apache/iceberg/commit/c7ce41ab642d0320142f50da78c2b0c95b622a27", "committedDate": "2020-11-03T18:46:36Z", "message": "Allow loading custom Catalog implementation in Spark and Flink"}, "afterCommit": {"oid": "485dea0552b40faa329c2c956c2c462412dc8a8e", "author": {"user": {"login": "jackye1995", "name": "Jack Ye"}}, "url": "https://github.com/apache/iceberg/commit/485dea0552b40faa329c2c956c2c462412dc8a8e", "committedDate": "2020-11-03T21:37:08Z", "message": "Allow loading custom Catalog implementation in Spark and Flink"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTIyOTEzMzE2", "url": "https://github.com/apache/iceberg/pull/1640#pullrequestreview-522913316", "createdAt": "2020-11-03T22:14:25Z", "commit": {"oid": "485dea0552b40faa329c2c956c2c462412dc8a8e"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4006, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}