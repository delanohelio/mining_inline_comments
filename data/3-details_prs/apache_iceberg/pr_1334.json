{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDY3MzY2MjA1", "number": 1334, "title": "Fix Error Prone ByteBuffer warnings", "bodyText": "There are some warnings that violate our Error Prone linter that we use. This PR closes out #1292\nI have removed the ByteBuffer ones by tracking them down and ensuring that they could be suppressed according to the warnings given on the Error Prone documentation.\nAccording to the documentation on the warning found here https://errorprone.info/bugpattern/ByteBufferBackingArray, if the ByteBuffer was instantiated with a local / on-heap backing array, such as with ByteBuffer.wrap or Bytebuffer.allocate then you're good to call .array() and assume that this is an on-heap byte array.\nMost of the suppressions come from calling some sort of inner static class with a call to BUFFER.get() that creates via one of the two above methods.\nThere was one case that I do not believe solved this solution. It's in the PR, and perhaps somebody with more Orc knowledge than I have can be of assistance, but the ByteBufferWriter doesn't really tell you much about the ByteBufer that's being written into the Orc file and the user needs to grab the underlying backing array (or generate it fif the data is off heao). Thinking about vectorized orc readers in spark as an example with off heap memory enabled, this would likely not be the case that these ByteBuffers were allocated with backing arrays (spark.unsafe might also need to be true, but my point is that I can see a probable situation where the precondition that this ByteBuffer is on heap is not met. So I decided to check if it hasArray, which is an inexpensive methiod, and then copied the ByteBuffer into a bytep[] if this were not the case.\nTo verify that this removed all ByteBuffer warnings, I ran ./gradlew clean && ./gradlew build &> build.txt && cat build.txt | grep -n ByteBuffer which returned no results.", "createdAt": "2020-08-13T12:54:02Z", "url": "https://github.com/apache/iceberg/pull/1334", "merged": true, "mergeCommit": {"oid": "a435a0da585b3ce8cc8871443b9eca5ece2928ad"}, "closed": true, "closedAt": "2020-08-30T00:00:00Z", "author": {"login": "kbendick"}, "timelineItems": {"totalCount": 60, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABc7gmlLgH2gAyNDY3MzY2MjA1OjgxZTkzYzRjNmIyMGQ3N2MxZDgzYjNjNWEzYWIxMzMxN2MyZGMxOWM=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdDyS-LgFqTQ3ODE2MDcxMQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "81e93c4c6b20d77c1d83b3c5a3ab13317c2dc19c", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/81e93c4c6b20d77c1d83b3c5a3ab13317c2dc19c", "committedDate": "2020-08-04T06:26:43Z", "message": "Add in basic autolabeler github action"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bc92e2a0f6ffee3ed670a1bab1a183456e0011aa", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/bc92e2a0f6ffee3ed670a1bab1a183456e0011aa", "committedDate": "2020-08-04T06:35:51Z", "message": "Add in missing quotes from yaml - we should definitely consider the yaml linter"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d0d7895b189dd474368ad35c9ef15d020d96d86f", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/d0d7895b189dd474368ad35c9ef15d020d96d86f", "committedDate": "2020-08-04T06:38:19Z", "message": "Give credit to spark project for the top level doc comment"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f157fb06b9bee7c0f6b90555092a5b80e7f1ea2f", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/f157fb06b9bee7c0f6b90555092a5b80e7f1ea2f", "committedDate": "2020-08-04T06:41:11Z", "message": "Sentence syntax for the comment crediting spark project"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b2368bbf4a44cfb8de90a975f8a724225289a1d9", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/b2368bbf4a44cfb8de90a975f8a724225289a1d9", "committedDate": "2020-08-04T21:30:40Z", "message": "address some pr feedback"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ce99c1981b6efd3482f06af1e8ce180632ce31c3", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/ce99c1981b6efd3482f06af1e8ce180632ce31c3", "committedDate": "2020-08-05T07:11:36Z", "message": "add the asf license file header"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "3c373bd0686c5a0bf23e5a6d1bcb538543c74f2c", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/3c373bd0686c5a0bf23e5a6d1bcb538543c74f2c", "committedDate": "2020-08-05T07:28:18Z", "message": "address some more PR feedback on keeping mkdocs.yaml in docs and out of infrastructure"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e9619651ab68b5fb25254f968ea9b97c8aa30937", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/e9619651ab68b5fb25254f968ea9b97c8aa30937", "committedDate": "2020-08-05T07:31:50Z", "message": "Only match on top level directories, not subdirectories"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "35a171f26885a4d72dfb84d62d042c825acd0577", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/35a171f26885a4d72dfb84d62d042c825acd0577", "committedDate": "2020-08-05T07:38:36Z", "message": "label any file with gradle in the name as BUILD and include the gradle version dependencies properties file"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "51c6d9c5f35cb85565fcba602368aa0762ec9688", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/51c6d9c5f35cb85565fcba602368aa0762ec9688", "committedDate": "2020-08-05T07:40:46Z", "message": "theres no need for the top level gradle folder rule as it will be matched by the all files or directories containing gradle rule"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b5c1ea2893ad51fe01ea20441484720061b0f97a", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/b5c1ea2893ad51fe01ea20441484720061b0f97a", "committedDate": "2020-08-05T07:42:17Z", "message": "small whitespac change to merge this in my personal fork for testing"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "56b544fe63e2ddf57a8375cabca2748a76af7bff", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/56b544fe63e2ddf57a8375cabca2748a76af7bff", "committedDate": "2020-08-05T07:44:12Z", "message": "Add in an autolabeler github action\n\n* Add in an autolabeler github action. This will be used to then test that the autolabeler action works as expected before merging in the apache/iceberg repo."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "799c4e8f3bdedaa6767567232679557d9466585a", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/799c4e8f3bdedaa6767567232679557d9466585a", "committedDate": "2020-08-05T08:26:28Z", "message": "add leading slash"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b8bd352105f1cbc4c366b344984ea3210074ec7f", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/b8bd352105f1cbc4c366b344984ea3210074ec7f", "committedDate": "2020-08-05T08:32:38Z", "message": "make sure we match infinite depth from root folder"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "68b7302a416c8ca3e31dec63aa6c9b43afe983d2", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/68b7302a416c8ca3e31dec63aa6c9b43afe983d2", "committedDate": "2020-08-05T08:39:51Z", "message": "allow for matching files and not just directories"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d5ddfd9ed13ccfec5f46eb6efaadb2389bab8501", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/d5ddfd9ed13ccfec5f46eb6efaadb2389bab8501", "committedDate": "2020-08-05T08:40:47Z", "message": "add leading slash to labeler config now that the bot is installed\n\nadd leading slash to labeler config now that the bot is installed"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "11de827df9fc3a90b08669ad61aa3f282e73df4f", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/11de827df9fc3a90b08669ad61aa3f282e73df4f", "committedDate": "2020-08-05T08:56:10Z", "message": "Make autlolabeler.yml top level comments valid yaml comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c1e99acc691c611d71f446c75a2409a79f19dcc1", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/c1e99acc691c611d71f446c75a2409a79f19dcc1", "committedDate": "2020-08-05T09:20:04Z", "message": "Make the license comment a valid YAML comment and then use a leading slash to match files and directories below top level folders"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6702e7489d81640534099a20eff3f30ee27c8cc0", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/6702e7489d81640534099a20eff3f30ee27c8cc0", "committedDate": "2020-08-05T09:20:55Z", "message": "Update autolabeler.yml"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5d628fff2e0399511351bc535a3ad7b811d1e709", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/5d628fff2e0399511351bc535a3ad7b811d1e709", "committedDate": "2020-08-05T09:30:39Z", "message": "Leave an empty line between the license header and file contents"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1644adb2256268eef0fe9bb24b6f09ca56a1f5d5", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/1644adb2256268eef0fe9bb24b6f09ca56a1f5d5", "committedDate": "2020-08-05T22:42:52Z", "message": "Remove bash label"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "827599ea679938315931fe2c799a3cd2ab4f66fa", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/827599ea679938315931fe2c799a3cd2ab4f66fa", "committedDate": "2020-08-05T22:43:05Z", "message": "Merge branch 'autolabeler-github-action' of github.com:kbendick/iceberg into autolabeler-github-action"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1c77e39815b7b7d58bc670abb260562f39695084", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/1c77e39815b7b7d58bc670abb260562f39695084", "committedDate": "2020-08-05T22:46:54Z", "message": "move dev directory from build to infra"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "7a82421b119251abc8c222d4fbddbb5a57cfc689", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/7a82421b119251abc8c222d4fbddbb5a57cfc689", "committedDate": "2020-08-05T22:52:15Z", "message": "use leading slash syntax for top level . folders"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a97dab051a680138f58aa2ea805cb840a3adee1e", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/a97dab051a680138f58aa2ea805cb840a3adee1e", "committedDate": "2020-08-05T22:57:15Z", "message": "Merge branch 'master' into autolabeler-v2-test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c75b14f41e9c4f13e98ddfb6c288b6745aa7a666", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/c75b14f41e9c4f13e98ddfb6c288b6745aa7a666", "committedDate": "2020-08-05T22:58:22Z", "message": "Autolabeler v2 test\n\n- Uses leading slash syntax for top level folders that start with a ."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "845e4ffbda59fe877edde69d37a7f0a5c28dfa08", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/845e4ffbda59fe877edde69d37a7f0a5c28dfa08", "committedDate": "2020-08-13T10:15:37Z", "message": "merge upstream master"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cd4fd45df432e65227db3df22c05329ab40688dc", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/cd4fd45df432e65227db3df22c05329ab40688dc", "committedDate": "2020-08-13T12:43:52Z", "message": "Suprress and remove the one potentially unspressable reference - will check if anybody with more knowledge of Orc knows but I think it would be needed for one person wo have all knowledge of systes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "37b7b618a2ab4dd3042529656f9f2aa618bc1332", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/37b7b618a2ab4dd3042529656f9f2aa618bc1332", "committedDate": "2020-08-13T12:57:29Z", "message": "Make whitespace the sane on untouched PR portions"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY2ODU0MTEz", "url": "https://github.com/apache/iceberg/pull/1334#pullrequestreview-466854113", "createdAt": "2020-08-13T15:07:18Z", "commit": {"oid": "37b7b618a2ab4dd3042529656f9f2aa618bc1332"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xM1QxNTowNzoxOVrOHAP6iA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xM1QxNTowNzoxOVrOHAP6iA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDAyMjc5Mg==", "bodyText": "I believe the write can only come from org.apache.orc.storage.ql.exec.vector.BytesColumnVector, which would be heap array backed. Unless there is another implementation I don't know about.\nSee\nhttps://orc.apache.org/api/hive-storage-api/index.html?org/apache/hadoop/hive/ql/exec/vector/BytesColumnVector.html\nand\nhttps://github.com/apache/hive/blob/master/storage-api/src/java/org/apache/hadoop/hive/ql/exec/vector/BytesColumnVector.java", "url": "https://github.com/apache/iceberg/pull/1334#discussion_r470022792", "createdAt": "2020-08-13T15:07:19Z", "author": {"login": "RussellSpitzer"}, "path": "data/src/main/java/org/apache/iceberg/data/orc/GenericOrcWriters.java", "diffHunk": "@@ -231,7 +231,24 @@ public void nonNullWrite(int rowId, String data, ColumnVector output) {\n \n     @Override\n     public void nonNullWrite(int rowId, ByteBuffer data, ColumnVector output) {\n-      ((BytesColumnVector) output).setRef(rowId, data.array(), 0, data.array().length);\n+      // We technically can't be sure if the ByteBuffer coming in is on or off\n+      // heap so we cannot safely call `.array()` on it without first checking\n+      // via the method ByteBuffer.hasArray().\n+      // See: https://errorprone.info/bugpattern/ByteBufferBackingArray\n+      //\n+      // When there is a backing heap based byte array, we avoided the overhead of\n+      // copying, which is especially important for small byte buffers.\n+      //\n+      // TODO - This copy slows it down, perhap unnecessarily. Is there any other way to tell, or no?", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "37b7b618a2ab4dd3042529656f9f2aa618bc1332"}, "originalPosition": 13}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY3NzQ4MTQ5", "url": "https://github.com/apache/iceberg/pull/1334#pullrequestreview-467748149", "createdAt": "2020-08-14T17:28:50Z", "commit": {"oid": "37b7b618a2ab4dd3042529656f9f2aa618bc1332"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQxNzoyODo1MFrOHA81Sw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQxNzoyODo1MFrOHA81Sw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDc1ODczMQ==", "bodyText": "This is not a correct use of ByteBuffer because it doesn't use arrayOffset or remaining. I think the current version must work because Spark returns new arrays that we wrap in ByteBuffer, but if the goal here is to make this accept any ByteBuffer then we should account for cases where the buffer is not simply the entire backing array.", "url": "https://github.com/apache/iceberg/pull/1334#discussion_r470758731", "createdAt": "2020-08-14T17:28:50Z", "author": {"login": "rdblue"}, "path": "data/src/main/java/org/apache/iceberg/data/orc/GenericOrcWriters.java", "diffHunk": "@@ -231,7 +231,24 @@ public void nonNullWrite(int rowId, String data, ColumnVector output) {\n \n     @Override\n     public void nonNullWrite(int rowId, ByteBuffer data, ColumnVector output) {\n-      ((BytesColumnVector) output).setRef(rowId, data.array(), 0, data.array().length);\n+      // We technically can't be sure if the ByteBuffer coming in is on or off\n+      // heap so we cannot safely call `.array()` on it without first checking\n+      // via the method ByteBuffer.hasArray().\n+      // See: https://errorprone.info/bugpattern/ByteBufferBackingArray\n+      //\n+      // When there is a backing heap based byte array, we avoided the overhead of\n+      // copying, which is especially important for small byte buffers.\n+      //\n+      // TODO - This copy slows it down, perhap unnecessarily. Is there any other way to tell, or no?\n+      //        My guess is no, if I consider things like VectorizedOrcReaders on Spark.\n+      if (data.hasArray()) {\n+        ((BytesColumnVector) output).setRef(rowId, data.array(), 0, data.array().length);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "37b7b618a2ab4dd3042529656f9f2aa618bc1332"}, "originalPosition": 16}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY3NzUzMTQ1", "url": "https://github.com/apache/iceberg/pull/1334#pullrequestreview-467753145", "createdAt": "2020-08-14T17:36:55Z", "commit": {"oid": "37b7b618a2ab4dd3042529656f9f2aa618bc1332"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQxNzozNjo1NlrOHA9Etg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNFQxNzozNjo1NlrOHA9Etg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MDc2MjY3OA==", "bodyText": "I don't think this is correct. This calls buffer.get(new byte[...]), which returns the ByteBuffer that get was called on. It is no different than returning new DataByteArray(buffer.array()). Calling get shows that the intent was to read the bytes into a new array and pass that to create a DataByteArray.\nThe correct implementation is this:\nByteBuffer buffer = (ByteBuffer) value;\nbyte[] bytes = new byte[buffer.remaining()];\nbuffer.get(bytes);\nreturn new DataByteArray(bytes);", "url": "https://github.com/apache/iceberg/pull/1334#discussion_r470762678", "createdAt": "2020-08-14T17:36:56Z", "author": {"login": "rdblue"}, "path": "pig/src/main/java/org/apache/iceberg/pig/IcebergPigInputFormat.java", "diffHunk": "@@ -243,6 +243,7 @@ private boolean advance() throws IOException {\n       return true;\n     }\n \n+    @SuppressWarnings(\"ByteBufferBackingArray\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "37b7b618a2ab4dd3042529656f9f2aa618bc1332"}, "originalPosition": 4}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "00921bfc114fd3e117ce3e1ae82f8d996e036330", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/00921bfc114fd3e117ce3e1ae82f8d996e036330", "committedDate": "2020-08-16T04:54:26Z", "message": "Use slice to take a shallow copy of the remaining data in the backing array of data"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8fe4ecdb2a522c419791c57567c6ae0cbf6ecf23", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/8fe4ecdb2a522c419791c57567c6ae0cbf6ecf23", "committedDate": "2020-08-16T04:59:39Z", "message": "Fix issue in IcebergPigInputFormat"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ed800998af3e0c06e96b107afe605d87fea2ae42", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/ed800998af3e0c06e96b107afe605d87fea2ae42", "committedDate": "2020-08-16T05:02:38Z", "message": "Use the simpler relative consuming get as we've already called .remaining on the byte buffer"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "00f9e46044b270aca0d29179e2405a9c312455e6", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/00f9e46044b270aca0d29179e2405a9c312455e6", "committedDate": "2020-08-16T05:04:45Z", "message": "Small fixes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "11828085e8ab5d5d63e394053495ff46128a3571", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/11828085e8ab5d5d63e394053495ff46128a3571", "committedDate": "2020-08-16T05:23:52Z", "message": "Merge remote-tracking branch 'upstream/master' into fix-errorprone-bytebuffer-warnings"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY4MDMzNjM1", "url": "https://github.com/apache/iceberg/pull/1334#pullrequestreview-468033635", "createdAt": "2020-08-16T05:01:04Z", "commit": {"oid": "8fe4ecdb2a522c419791c57567c6ae0cbf6ecf23"}, "state": "COMMENTED", "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNlQwNTowMTowNFrOHBPkzA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xNlQwNTo0MjowMFrOHBPwaw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTA2NTgwNA==", "bodyText": "I updated this one as you requested @rdblue, however I wasn't sure if I should return the input value to its original position (vs consuming the remainder of the byte buffer and moving the position to the end).", "url": "https://github.com/apache/iceberg/pull/1334#discussion_r471065804", "createdAt": "2020-08-16T05:01:04Z", "author": {"login": "kbendick"}, "path": "pig/src/main/java/org/apache/iceberg/pig/IcebergPigInputFormat.java", "diffHunk": "@@ -246,7 +246,11 @@ private boolean advance() throws IOException {\n     private Object convertPartitionValue(Type type, Object value) {\n       if (type.typeId() == Types.BinaryType.get().typeId()) {\n         ByteBuffer buffer = (ByteBuffer) value;\n-        return new DataByteArray(buffer.get(new byte[buffer.remaining()]).array());\n+        byte[] bytes = new byte[buffer.remaining()];\n+        buffer.get(bytes);\n+        // Return the input buffer back to its original position.\n+        buffer.position(buffer.position() - bytes.length);\n+        return new DataByteArray(bytes);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "8fe4ecdb2a522c419791c57567c6ae0cbf6ecf23"}, "originalPosition": 9}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTA2ODc3OQ==", "bodyText": "I updated this line to not assume that the entire backing array of data is what we're reading in. Via the use of slice, a shallow copy takes place (which mimics the previous shallow copy). Does this resolve your previous concern?\nI can clean up the comments etc once I know if this resolves any on going issues or not @rdblue . Thanks so much for your thorough review!", "url": "https://github.com/apache/iceberg/pull/1334#discussion_r471068779", "createdAt": "2020-08-16T05:42:00Z", "author": {"login": "kbendick"}, "path": "data/src/main/java/org/apache/iceberg/data/orc/GenericOrcWriters.java", "diffHunk": "@@ -231,7 +231,23 @@ public void nonNullWrite(int rowId, String data, ColumnVector output) {\n \n     @Override\n     public void nonNullWrite(int rowId, ByteBuffer data, ColumnVector output) {\n-      ((BytesColumnVector) output).setRef(rowId, data.array(), 0, data.array().length);\n+      // When there is a backing heap based byte array, we avoid the overhead of\n+      // copying it.\n+      if (data.hasArray()) {\n+        // Don't assume the we're reading in the entire backing array.\n+        // Using slice as any mutations to the data at rowId of output\n+        // would also be visible in `data`.\n+        ByteBuffer slice = data.slice();\n+        ((BytesColumnVector) output).setRef(rowId, slice.array(), 0, slice.array().length);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "00f9e46044b270aca0d29179e2405a9c312455e6"}, "originalPosition": 12}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1684ac45736a7ea92cd1bd06a0b64d7a503a605b", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/1684ac45736a7ea92cd1bd06a0b64d7a503a605b", "committedDate": "2020-08-17T00:21:17Z", "message": "wip but copy over a function from ParquetValueWriters"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY4NjgyMjU3", "url": "https://github.com/apache/iceberg/pull/1334#pullrequestreview-468682257", "createdAt": "2020-08-17T17:35:22Z", "commit": {"oid": "00f9e46044b270aca0d29179e2405a9c312455e6"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxNzozNToyMlrOHBzUWA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xN1QxNzozNToyMlrOHBzUWA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTY1MTQxNg==", "bodyText": "Could you avoid this by using slice too? Maybe factoring the slice out of the if...else?", "url": "https://github.com/apache/iceberg/pull/1334#discussion_r471651416", "createdAt": "2020-08-17T17:35:22Z", "author": {"login": "edgarRd"}, "path": "data/src/main/java/org/apache/iceberg/data/orc/GenericOrcWriters.java", "diffHunk": "@@ -231,7 +231,23 @@ public void nonNullWrite(int rowId, String data, ColumnVector output) {\n \n     @Override\n     public void nonNullWrite(int rowId, ByteBuffer data, ColumnVector output) {\n-      ((BytesColumnVector) output).setRef(rowId, data.array(), 0, data.array().length);\n+      // When there is a backing heap based byte array, we avoid the overhead of\n+      // copying it.\n+      if (data.hasArray()) {\n+        // Don't assume the we're reading in the entire backing array.\n+        // Using slice as any mutations to the data at rowId of output\n+        // would also be visible in `data`.\n+        ByteBuffer slice = data.slice();\n+        ((BytesColumnVector) output).setRef(rowId, slice.array(), 0, slice.array().length);\n+      } else {\n+        // Consume the remaining contents of the input data\n+        byte[] bytes = new byte[data.remaining()];\n+        data.get(bytes);\n+        // Restores the buffer position\n+        // TODO - Is this necessary?\n+        data.position(data.position() - bytes.length);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "00f9e46044b270aca0d29179e2405a9c312455e6"}, "originalPosition": 19}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "9c6c190f1cc07bbc4f498a1d5967f284deaac34f", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/9c6c190f1cc07bbc4f498a1d5967f284deaac34f", "committedDate": "2020-08-18T03:38:25Z", "message": "Using logic from ParquetValueWriters, remove ByteBuffer warnings from GenericOrcWriters nonNullWrite method"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDY4OTY5Nzc2", "url": "https://github.com/apache/iceberg/pull/1334#pullrequestreview-468969776", "createdAt": "2020-08-18T03:40:58Z", "commit": {"oid": "9c6c190f1cc07bbc4f498a1d5967f284deaac34f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQwMzo0MDo1OFrOHCCNTQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOFQwMzo0MDo1OFrOHCCNTQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MTg5NTM3Mw==", "bodyText": "I took the logic for copying from following org.apache.iceberg.io.ParquetValueWriters into org.apache.parquet.io.api.Binary, specifically the need to update both the limit and the position in order to return the original ByteBuffer, data, back to its original position as ByteBuffer offers no API to do that.\nSince I was no longer going to use any optimizations if the buffer is on heap or not (such as the usage of .slice() or .duplicate() or .array() I chose to skip entirely the check for data.hasArray().\nI somewhat copied emulated the logic to copy and reset the original byte buffer data's position (which could be invalidated by moving the position passed the limit), as demonstrated in org.apache.parquet.io.api.Binary", "url": "https://github.com/apache/iceberg/pull/1334#discussion_r471895373", "createdAt": "2020-08-18T03:40:58Z", "author": {"login": "kbendick"}, "path": "data/src/main/java/org/apache/iceberg/data/orc/GenericOrcWriters.java", "diffHunk": "@@ -231,7 +231,33 @@ public void nonNullWrite(int rowId, String data, ColumnVector output) {\n \n     @Override\n     public void nonNullWrite(int rowId, ByteBuffer data, ColumnVector output) {\n-      ((BytesColumnVector) output).setRef(rowId, data.array(), 0, data.array().length);\n+      // Don't assume the we're reading in the entire backing array.\n+      //\n+      // We use the same logic for on heap vs off heap buffers as we don't assume\n+      // that the position of the byte buffer received for the write is at the beginning\n+      // position, such an assumption is needed to make use of methods like `.slice()`\n+      // or any methods that would be useful here if we checked if there is an on-heap\n+      // backing array and that the buffer is at the beginning position. (aka we don't check\n+      // that one can use if `data.hasArray()` is true as we couldn't make any optimizations\n+      // in that case).\n+      int position = data.position();\n+      int limit = data.limit();\n+      int curIndex = data.arrayOffset() + data.position();\n+      int endIndex = curIndex + data.remaining();\n+\n+      // Prep for copy into bytes\n+      byte[] bytes = new byte[data.remaining()];\n+      data.limit(curIndex + limit);\n+      data.position(curIndex);\n+\n+      // Perform copy into bytes of remainder of byte buffer.\n+      data.get(bytes, curIndex, endIndex - curIndex);\n+\n+      // Reset the byte buffer.\n+      data.limit(limit);\n+      data.position(position);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9c6c190f1cc07bbc4f498a1d5967f284deaac34f"}, "originalPosition": 29}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d1f9506f39948022b9aca54c6197167877c73136", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/d1f9506f39948022b9aca54c6197167877c73136", "committedDate": "2020-08-18T03:52:31Z", "message": "simplify the logic of copying the byte buffer"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d57d81ad92c1997190ab4ca656033e5c3deecb40", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/d57d81ad92c1997190ab4ca656033e5c3deecb40", "committedDate": "2020-08-19T06:28:07Z", "message": "Use duplicate to avoid having to reposition the original byte buffer"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c91503c02d799c007d6c2fe5046da3bc7a8ad0e4", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/c91503c02d799c007d6c2fe5046da3bc7a8ad0e4", "committedDate": "2020-08-19T07:03:46Z", "message": "roll back a few commits and then factor out to use duplicate with arrayOffset for on heap buffers with orc"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f39802c8913abd778b4802c0b6a611592448a942", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/f39802c8913abd778b4802c0b6a611592448a942", "committedDate": "2020-08-19T07:05:42Z", "message": "use dupe throughout once it's created"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "60d3ef03e6905257ede7a7d7caf6d07bce5a3134", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/60d3ef03e6905257ede7a7d7caf6d07bce5a3134", "committedDate": "2020-08-19T07:20:00Z", "message": "duplicate directly after cast so nobody is tempted to use value"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDcwNTgzNTA4", "url": "https://github.com/apache/iceberg/pull/1334#pullrequestreview-470583508", "createdAt": "2020-08-19T15:38:26Z", "commit": {"oid": "60d3ef03e6905257ede7a7d7caf6d07bce5a3134"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQxNTozODoyNlrOHDNNGw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQxNTozODoyNlrOHDNNGw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzEyNDEyMw==", "bodyText": "The offset should be dupe.arrayOffset() + dupe.position().", "url": "https://github.com/apache/iceberg/pull/1334#discussion_r473124123", "createdAt": "2020-08-19T15:38:26Z", "author": {"login": "rdblue"}, "path": "data/src/main/java/org/apache/iceberg/data/orc/GenericOrcWriters.java", "diffHunk": "@@ -231,7 +231,14 @@ public void nonNullWrite(int rowId, String data, ColumnVector output) {\n \n     @Override\n     public void nonNullWrite(int rowId, ByteBuffer data, ColumnVector output) {\n-      ((BytesColumnVector) output).setRef(rowId, data.array(), 0, data.array().length);\n+      ByteBuffer dupe = data.duplicate();\n+      if (dupe.hasArray()) {\n+        ((BytesColumnVector) output).setRef(rowId, dupe.array(), dupe.arrayOffset(), dupe.remaining());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "60d3ef03e6905257ede7a7d7caf6d07bce5a3134"}, "originalPosition": 7}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDcwNTg0MTIy", "url": "https://github.com/apache/iceberg/pull/1334#pullrequestreview-470584122", "createdAt": "2020-08-19T15:39:07Z", "commit": {"oid": "60d3ef03e6905257ede7a7d7caf6d07bce5a3134"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQxNTozOTowN1rOHDNPBg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQxNTozOTowN1rOHDNPBg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzEyNDYxNA==", "bodyText": "There is no need to duplicate the ByteBuffer when accessing the backing on-heap byte array, so this should only be done in the case where we read from the ByteBuffer using get.", "url": "https://github.com/apache/iceberg/pull/1334#discussion_r473124614", "createdAt": "2020-08-19T15:39:07Z", "author": {"login": "rdblue"}, "path": "data/src/main/java/org/apache/iceberg/data/orc/GenericOrcWriters.java", "diffHunk": "@@ -231,7 +231,14 @@ public void nonNullWrite(int rowId, String data, ColumnVector output) {\n \n     @Override\n     public void nonNullWrite(int rowId, ByteBuffer data, ColumnVector output) {\n-      ((BytesColumnVector) output).setRef(rowId, data.array(), 0, data.array().length);\n+      ByteBuffer dupe = data.duplicate();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "60d3ef03e6905257ede7a7d7caf6d07bce5a3134"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDcwNTg3MDcy", "url": "https://github.com/apache/iceberg/pull/1334#pullrequestreview-470587072", "createdAt": "2020-08-19T15:42:16Z", "commit": {"oid": "60d3ef03e6905257ede7a7d7caf6d07bce5a3134"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQxNTo0MjoxN1rOHDNXkQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0xOVQxNTo0MjoxN1rOHDNXkQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3MzEyNjgwMQ==", "bodyText": "I don't think that we need to check hasArray here. I think the reason why this didn't previously check hasArray is that the array passed to DataByteArray must start at offset 0 and be valid through the array length, so a copy was needed in almost every case.\nIt may be simpler to change this to use ByteBuffers.toByteArray and pass the result to create DataByteArray.", "url": "https://github.com/apache/iceberg/pull/1334#discussion_r473126801", "createdAt": "2020-08-19T15:42:17Z", "author": {"login": "rdblue"}, "path": "pig/src/main/java/org/apache/iceberg/pig/IcebergPigInputFormat.java", "diffHunk": "@@ -245,8 +245,14 @@ private boolean advance() throws IOException {\n \n     private Object convertPartitionValue(Type type, Object value) {\n       if (type.typeId() == Types.BinaryType.get().typeId()) {\n-        ByteBuffer buffer = (ByteBuffer) value;\n-        return new DataByteArray(buffer.get(new byte[buffer.remaining()]).array());\n+        ByteBuffer dupe = ((ByteBuffer) value).duplicate();\n+        if (dupe.hasArray()) {\n+          return new DataByteArray(dupe.array());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "60d3ef03e6905257ede7a7d7caf6d07bce5a3134"}, "originalPosition": 8}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "27f3d855cf33202b737e55dc8b044432dd247697", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/27f3d855cf33202b737e55dc8b044432dd247697", "committedDate": "2020-08-29T07:43:23Z", "message": "use utility function in IcebergPigInputFormat for ByteBuffer.toByteArray"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2882f9cd957639c10e24e34a85fe72a4f11e4f0f", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/2882f9cd957639c10e24e34a85fe72a4f11e4f0f", "committedDate": "2020-08-29T07:46:29Z", "message": "Remove unnecessary duplicate call on ByteBuffer as it's handled in the utility"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fbd6021bdf0a5f71b7756786d993dd2a7d2c29e4", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/fbd6021bdf0a5f71b7756786d993dd2a7d2c29e4", "committedDate": "2020-08-29T07:57:36Z", "message": "Cleanup GenericOrcWriters and use utility copy function for off-heap"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDc4MTA5NDk0", "url": "https://github.com/apache/iceberg/pull/1334#pullrequestreview-478109494", "createdAt": "2020-08-29T07:59:21Z", "commit": {"oid": "fbd6021bdf0a5f71b7756786d993dd2a7d2c29e4"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOVQwNzo1OToyMVrOHJZ4NA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOVQwNzo1OToyMVrOHJZ4NA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTYyMzIyMA==", "bodyText": "@rdblue please let me know if this is an appropriate use of ByteBuffers.toByteArray (since we know this is off-heap, I figure this brings it on heap in the way I was somewhat before).\nAnd is the null check necessary? I saw that toByteArray returned null if null was passed in, and I didn't see any @NonNull kind of tags so I wasn't sure.", "url": "https://github.com/apache/iceberg/pull/1334#discussion_r479623220", "createdAt": "2020-08-29T07:59:21Z", "author": {"login": "kbendick"}, "path": "data/src/main/java/org/apache/iceberg/data/orc/GenericOrcWriters.java", "diffHunk": "@@ -231,7 +234,13 @@ public void nonNullWrite(int rowId, String data, ColumnVector output) {\n \n     @Override\n     public void nonNullWrite(int rowId, ByteBuffer data, ColumnVector output) {\n-      ((BytesColumnVector) output).setRef(rowId, data.array(), 0, data.array().length);\n+      if (data != null && data.hasArray()) {\n+        ((BytesColumnVector) output).setRef(rowId, data.array(), data.arrayOffset() + data.position(), data.remaining());\n+      } else {\n+        byte[] rawData = ByteBuffers.toByteArray(data);\n+        int length = rawData == null ? 0 : rawData.length;\n+        ((BytesColumnVector) output).setRef(rowId, rawData, 0, length);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fbd6021bdf0a5f71b7756786d993dd2a7d2c29e4"}, "originalPosition": 27}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDc4MTQ0NjIw", "url": "https://github.com/apache/iceberg/pull/1334#pullrequestreview-478144620", "createdAt": "2020-08-29T17:53:24Z", "commit": {"oid": "fbd6021bdf0a5f71b7756786d993dd2a7d2c29e4"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOVQxNzo1MzoyNVrOHJc9Rw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOVQxNzo1MzoyNVrOHJc9Rw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTY3MzY3MQ==", "bodyText": "Looks good.", "url": "https://github.com/apache/iceberg/pull/1334#discussion_r479673671", "createdAt": "2020-08-29T17:53:25Z", "author": {"login": "rdblue"}, "path": "pig/src/main/java/org/apache/iceberg/pig/IcebergPigInputFormat.java", "diffHunk": "@@ -245,8 +246,7 @@ private boolean advance() throws IOException {\n \n     private Object convertPartitionValue(Type type, Object value) {\n       if (type.typeId() == Types.BinaryType.get().typeId()) {\n-        ByteBuffer buffer = (ByteBuffer) value;\n-        return new DataByteArray(buffer.get(new byte[buffer.remaining()]).array());\n+        return new DataByteArray(ByteBuffers.toByteArray(((ByteBuffer) value));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fbd6021bdf0a5f71b7756786d993dd2a7d2c29e4"}, "originalPosition": 14}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDc4MTQ0NjMx", "url": "https://github.com/apache/iceberg/pull/1334#pullrequestreview-478144631", "createdAt": "2020-08-29T17:53:35Z", "commit": {"oid": "fbd6021bdf0a5f71b7756786d993dd2a7d2c29e4"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOVQxNzo1MzozNlrOHJc9UA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOVQxNzo1MzozNlrOHJc9UA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTY3MzY4MA==", "bodyText": "Looks good.", "url": "https://github.com/apache/iceberg/pull/1334#discussion_r479673680", "createdAt": "2020-08-29T17:53:36Z", "author": {"login": "rdblue"}, "path": "data/src/main/java/org/apache/iceberg/data/orc/GenericOrcWriters.java", "diffHunk": "@@ -231,7 +234,13 @@ public void nonNullWrite(int rowId, String data, ColumnVector output) {\n \n     @Override\n     public void nonNullWrite(int rowId, ByteBuffer data, ColumnVector output) {\n-      ((BytesColumnVector) output).setRef(rowId, data.array(), 0, data.array().length);\n+      if (data != null && data.hasArray()) {\n+        ((BytesColumnVector) output).setRef(rowId, data.array(), data.arrayOffset() + data.position(), data.remaining());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fbd6021bdf0a5f71b7756786d993dd2a7d2c29e4"}, "originalPosition": 23}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8521649d671a94ba71febe17f18a46898171ebbf", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/8521649d671a94ba71febe17f18a46898171ebbf", "committedDate": "2020-08-29T22:57:15Z", "message": "Remove unneceessary null checks in nonNullWrite"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c8515ba47bbc997979b7f680f072dde2a1a1797b", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/c8515ba47bbc997979b7f680f072dde2a1a1797b", "committedDate": "2020-08-29T23:03:18Z", "message": "Adds in missing closing parens"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "737b8afa1fd84d1156c8aedd7f9ae1e41430ff1f", "author": {"user": {"login": "kbendick", "name": "Kyle Bendickson"}}, "url": "https://github.com/apache/iceberg/commit/737b8afa1fd84d1156c8aedd7f9ae1e41430ff1f", "committedDate": "2020-08-29T23:22:46Z", "message": "Cleans up linter failing errors in GenericOrcWriters"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDc4MTYwNzEx", "url": "https://github.com/apache/iceberg/pull/1334#pullrequestreview-478160711", "createdAt": "2020-08-29T23:34:59Z", "commit": {"oid": "737b8afa1fd84d1156c8aedd7f9ae1e41430ff1f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOVQyMzozNDo1OVrOHJemtQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOC0yOVQyMzozNDo1OVrOHJemtQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ3OTcwMDY2MQ==", "bodyText": "There was a line length breaking linter error here. Not sure what the expected way to break up the argument list is, so I chose something that seemed to make sense and that passed the linter.", "url": "https://github.com/apache/iceberg/pull/1334#discussion_r479700661", "createdAt": "2020-08-29T23:34:59Z", "author": {"login": "kbendick"}, "path": "data/src/main/java/org/apache/iceberg/data/orc/GenericOrcWriters.java", "diffHunk": "@@ -231,7 +232,13 @@ public void nonNullWrite(int rowId, String data, ColumnVector output) {\n \n     @Override\n     public void nonNullWrite(int rowId, ByteBuffer data, ColumnVector output) {\n-      ((BytesColumnVector) output).setRef(rowId, data.array(), 0, data.array().length);\n+      if (data.hasArray()) {\n+        ((BytesColumnVector) output).setRef(rowId, data.array(),\n+                data.arrayOffset() + data.position(), data.remaining());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "737b8afa1fd84d1156c8aedd7f9ae1e41430ff1f"}, "originalPosition": 15}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4033, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}