{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTMwNDA2MTIy", "number": 1854, "title": "Hive: Implement Deserializer for Hive writes", "bodyText": "Implements the Deserializer for Hive writes, and creates the corresponding test suite", "createdAt": "2020-12-01T15:59:59Z", "url": "https://github.com/apache/iceberg/pull/1854", "merged": true, "mergeCommit": {"oid": "ddba7fc076ce28d2c483846d765046a82b4d8aa5"}, "closed": true, "closedAt": "2020-12-08T23:48:53Z", "author": {"login": "pvary"}, "timelineItems": {"totalCount": 21, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdh8HJngH2gAyNTMwNDA2MTIyOjJhODVlNzIzYzIwNDNjNTdjOTNhNmUwODRjNzY5MzVmZTlkYzc0MGQ=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdkTBrIAFqTU0NzcyODcwMA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "2a85e723c2043c57c93a6e084c76935fe9dc740d", "author": {"user": {"login": "pvary", "name": null}}, "url": "https://github.com/apache/iceberg/commit/2a85e723c2043c57c93a6e084c76935fe9dc740d", "committedDate": "2020-12-01T15:58:51Z", "message": "Hive: Implement Deserializer for Hive writes"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQyOTQyNjk2", "url": "https://github.com/apache/iceberg/pull/1854#pullrequestreview-542942696", "createdAt": "2020-12-02T15:19:06Z", "commit": {"oid": "2a85e723c2043c57c93a6e084c76935fe9dc740d"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxNToxOTowNlrOH9f_Ig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMlQxNjoyMjoxNlrOH9jHBg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDI0OTI1MA==", "bodyText": "did you mean FieldDeserializer here?", "url": "https://github.com/apache/iceberg/pull/1854#discussion_r534249250", "createdAt": "2020-12-02T15:19:06Z", "author": {"login": "marton-bod"}, "path": "mr/src/main/java/org/apache/iceberg/mr/hive/Deserializer.java", "diffHunk": "@@ -0,0 +1,127 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.util.List;\n+import java.util.UUID;\n+import org.apache.hadoop.hive.serde2.SerDeException;\n+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.StructField;\n+import org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.BooleanObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.DoubleObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.FloatObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.IntObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.LongObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.StringObjectInspector;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.data.GenericRecord;\n+import org.apache.iceberg.data.Record;\n+import org.apache.iceberg.mr.hive.serde.objectinspector.IcebergWriteObjectInspector;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+\n+class Deserializer {\n+  private FiledDeserializer mainDeserializer;\n+\n+  Deserializer(Schema schema, ObjectInspector fieldInspector) throws SerDeException {\n+    this.mainDeserializer = deserializer(schema.asStruct(), fieldInspector);\n+  }\n+\n+  Record deserialize(Object data) {\n+    return (Record) mainDeserializer.value(data);\n+  }\n+\n+  private interface FiledDeserializer {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2a85e723c2043c57c93a6e084c76935fe9dc740d"}, "originalPosition": 52}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDI4OTc0MA==", "bodyText": "Can't we return an OffsetDateTime object?", "url": "https://github.com/apache/iceberg/pull/1854#discussion_r534289740", "createdAt": "2020-12-02T16:08:37Z", "author": {"login": "marton-bod"}, "path": "mr/src/main/java/org/apache/iceberg/mr/hive/serde/objectinspector/IcebergTimestampObjectInspector.java", "diffHunk": "@@ -22,26 +22,38 @@\n import java.sql.Timestamp;\n import java.time.LocalDateTime;\n import java.time.OffsetDateTime;\n+import java.time.ZoneId;\n import org.apache.hadoop.hive.serde2.io.TimestampWritable;\n import org.apache.hadoop.hive.serde2.objectinspector.primitive.AbstractPrimitiveJavaObjectInspector;\n import org.apache.hadoop.hive.serde2.objectinspector.primitive.TimestampObjectInspector;\n import org.apache.hadoop.hive.serde2.typeinfo.TypeInfoFactory;\n \n public abstract class IcebergTimestampObjectInspector extends AbstractPrimitiveJavaObjectInspector\n-                                                      implements TimestampObjectInspector {\n+    implements TimestampObjectInspector, IcebergWriteObjectInspector {\n \n   private static final IcebergTimestampObjectInspector INSTANCE_WITH_ZONE = new IcebergTimestampObjectInspector() {\n     @Override\n     LocalDateTime toLocalDateTime(Object o) {\n       return ((OffsetDateTime) o).toLocalDateTime();\n     }\n+\n+    @Override\n+    public Object getIcebergObject(Object o) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2a85e723c2043c57c93a6e084c76935fe9dc740d"}, "originalPosition": 21}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDI5MjY1NA==", "bodyText": "nit: unless we have other deserializers, I would just name this field deserializer or fieldDeserializer", "url": "https://github.com/apache/iceberg/pull/1854#discussion_r534292654", "createdAt": "2020-12-02T16:12:15Z", "author": {"login": "marton-bod"}, "path": "mr/src/main/java/org/apache/iceberg/mr/hive/Deserializer.java", "diffHunk": "@@ -0,0 +1,127 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.util.List;\n+import java.util.UUID;\n+import org.apache.hadoop.hive.serde2.SerDeException;\n+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.StructField;\n+import org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.BooleanObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.DoubleObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.FloatObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.IntObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.LongObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.StringObjectInspector;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.data.GenericRecord;\n+import org.apache.iceberg.data.Record;\n+import org.apache.iceberg.mr.hive.serde.objectinspector.IcebergWriteObjectInspector;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+\n+class Deserializer {\n+  private FiledDeserializer mainDeserializer;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2a85e723c2043c57c93a6e084c76935fe9dc740d"}, "originalPosition": 42}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDI5Mzc3NQ==", "bodyText": "Is there a way to handle the Parquet case? Just wondering what happens if someone tries to write UUID data with parquet", "url": "https://github.com/apache/iceberg/pull/1854#discussion_r534293775", "createdAt": "2020-12-02T16:13:45Z", "author": {"login": "marton-bod"}, "path": "mr/src/main/java/org/apache/iceberg/mr/hive/Deserializer.java", "diffHunk": "@@ -0,0 +1,127 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.util.List;\n+import java.util.UUID;\n+import org.apache.hadoop.hive.serde2.SerDeException;\n+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.StructField;\n+import org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.BooleanObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.DoubleObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.FloatObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.IntObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.LongObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.StringObjectInspector;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.data.GenericRecord;\n+import org.apache.iceberg.data.Record;\n+import org.apache.iceberg.mr.hive.serde.objectinspector.IcebergWriteObjectInspector;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+\n+class Deserializer {\n+  private FiledDeserializer mainDeserializer;\n+\n+  Deserializer(Schema schema, ObjectInspector fieldInspector) throws SerDeException {\n+    this.mainDeserializer = deserializer(schema.asStruct(), fieldInspector);\n+  }\n+\n+  Record deserialize(Object data) {\n+    return (Record) mainDeserializer.value(data);\n+  }\n+\n+  private interface FiledDeserializer {\n+    Object value(Object object);\n+  }\n+\n+  private static FiledDeserializer deserializer(Type type, ObjectInspector fieldInspector) throws SerDeException {\n+    switch (type.typeId()) {\n+      case BOOLEAN:\n+        return o -> ((BooleanObjectInspector) fieldInspector).get(o);\n+      case INTEGER:\n+        return o -> ((IntObjectInspector) fieldInspector).get(o);\n+      case LONG:\n+        return o -> ((LongObjectInspector) fieldInspector).get(o);\n+      case FLOAT:\n+        return o -> ((FloatObjectInspector) fieldInspector).get(o);\n+      case DOUBLE:\n+        return o -> ((DoubleObjectInspector) fieldInspector).get(o);\n+      case STRING:\n+        return o -> ((StringObjectInspector) fieldInspector).getPrimitiveJavaObject(o);\n+      case UUID:\n+        // TODO: This will not work with Parquet. Parquet UUID expect byte[], others are expecting UUID", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2a85e723c2043c57c93a6e084c76935fe9dc740d"}, "originalPosition": 71}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDI5NjY2Nw==", "bodyText": "if the fieldValue is null, shouldn't we still set the null in the result record?", "url": "https://github.com/apache/iceberg/pull/1854#discussion_r534296667", "createdAt": "2020-12-02T16:17:28Z", "author": {"login": "marton-bod"}, "path": "mr/src/main/java/org/apache/iceberg/mr/hive/Deserializer.java", "diffHunk": "@@ -0,0 +1,127 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.util.List;\n+import java.util.UUID;\n+import org.apache.hadoop.hive.serde2.SerDeException;\n+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.StructField;\n+import org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.BooleanObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.DoubleObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.FloatObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.IntObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.LongObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.StringObjectInspector;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.data.GenericRecord;\n+import org.apache.iceberg.data.Record;\n+import org.apache.iceberg.mr.hive.serde.objectinspector.IcebergWriteObjectInspector;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+\n+class Deserializer {\n+  private FiledDeserializer mainDeserializer;\n+\n+  Deserializer(Schema schema, ObjectInspector fieldInspector) throws SerDeException {\n+    this.mainDeserializer = deserializer(schema.asStruct(), fieldInspector);\n+  }\n+\n+  Record deserialize(Object data) {\n+    return (Record) mainDeserializer.value(data);\n+  }\n+\n+  private interface FiledDeserializer {\n+    Object value(Object object);\n+  }\n+\n+  private static FiledDeserializer deserializer(Type type, ObjectInspector fieldInspector) throws SerDeException {\n+    switch (type.typeId()) {\n+      case BOOLEAN:\n+        return o -> ((BooleanObjectInspector) fieldInspector).get(o);\n+      case INTEGER:\n+        return o -> ((IntObjectInspector) fieldInspector).get(o);\n+      case LONG:\n+        return o -> ((LongObjectInspector) fieldInspector).get(o);\n+      case FLOAT:\n+        return o -> ((FloatObjectInspector) fieldInspector).get(o);\n+      case DOUBLE:\n+        return o -> ((DoubleObjectInspector) fieldInspector).get(o);\n+      case STRING:\n+        return o -> ((StringObjectInspector) fieldInspector).getPrimitiveJavaObject(o);\n+      case UUID:\n+        // TODO: This will not work with Parquet. Parquet UUID expect byte[], others are expecting UUID\n+        return o -> UUID.fromString(((StringObjectInspector) fieldInspector).getPrimitiveJavaObject(o));\n+      case DATE:\n+      case TIMESTAMP:\n+      case FIXED:\n+      case BINARY:\n+      case DECIMAL:\n+        // Iceberg specific conversions\n+        return o -> ((IcebergWriteObjectInspector) fieldInspector).getIcebergObject(o);\n+      case STRUCT:\n+        return new StructDeserializer((Types.StructType) type, (StructObjectInspector) fieldInspector);\n+      case LIST:\n+      case MAP:\n+      case TIME:\n+      default:\n+        throw new SerDeException(\"Unsupported column type: \" + type);\n+    }\n+  }\n+\n+  private static class StructDeserializer implements FiledDeserializer {\n+    private final FiledDeserializer[] filedDeserializers;\n+    private final StructObjectInspector fieldInspector;\n+    private final Types.StructType type;\n+\n+    private StructDeserializer(Types.StructType type, StructObjectInspector fieldInspector) throws SerDeException {\n+      List<? extends StructField> structFields = fieldInspector.getAllStructFieldRefs();\n+      List<Types.NestedField> nestedFields = type.fields();\n+      this.filedDeserializers = new FiledDeserializer[structFields.size()];\n+      this.fieldInspector = fieldInspector;\n+      this.type = type;\n+\n+      for (int i = 0; i < filedDeserializers.length; i++) {\n+        filedDeserializers[i] =\n+            deserializer(nestedFields.get(i).type(), structFields.get(i).getFieldObjectInspector());\n+      }\n+    }\n+\n+    @Override\n+    public Record value(Object object) {\n+      if (object == null) {\n+        return null;\n+      }\n+\n+      List<Object> data = fieldInspector.getStructFieldsDataAsList(object);\n+      Record result = GenericRecord.create(type);\n+\n+      for (int i = 0; i < filedDeserializers.length; i++) {\n+        Object fieldValue = data.get(i);\n+        if (fieldValue != null) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2a85e723c2043c57c93a6e084c76935fe9dc740d"}, "originalPosition": 119}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNDMwMDQyMg==", "bodyText": "Can we add a test case where a SerdeException should be thrown?", "url": "https://github.com/apache/iceberg/pull/1854#discussion_r534300422", "createdAt": "2020-12-02T16:22:16Z", "author": {"login": "marton-bod"}, "path": "mr/src/test/java/org/apache/iceberg/mr/hive/TestDeserializer.java", "diffHunk": "@@ -0,0 +1,99 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.util.Arrays;\n+import org.apache.hadoop.hive.serde2.SerDeException;\n+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory;\n+import org.apache.hadoop.hive.serde2.objectinspector.StandardStructObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;\n+import org.apache.hadoop.io.LongWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.data.GenericRecord;\n+import org.apache.iceberg.data.Record;\n+import org.apache.iceberg.hive.MetastoreUtil;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Assume;\n+import org.junit.Test;\n+\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+\n+public class TestDeserializer {\n+  private static final Schema CUSTOMER_SCHEMA = new Schema(\n+      optional(1, \"customer_id\", Types.LongType.get()),\n+      optional(2, \"first_name\", Types.StringType.get())\n+  );\n+\n+  private static final StandardStructObjectInspector CUSTOMER_OBJECT_INSPECTOR =\n+      ObjectInspectorFactory.getStandardStructObjectInspector(\n+          Arrays.asList(\"customer_id\", \"first_name\"),\n+          Arrays.asList(\n+              PrimitiveObjectInspectorFactory.writableLongObjectInspector,\n+              PrimitiveObjectInspectorFactory.writableStringObjectInspector\n+          ));\n+\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2a85e723c2043c57c93a6e084c76935fe9dc740d"}, "originalPosition": 54}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ac3f608c6de396ae0cf4b84a4a4570c00d9f2b60", "author": {"user": {"login": "pvary", "name": null}}, "url": "https://github.com/apache/iceberg/commit/ac3f608c6de396ae0cf4b84a4a4570c00d9f2b60", "committedDate": "2020-12-02T16:52:41Z", "message": "Addressed Marton's comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "2eea35667e1e157525808a8248302b670a6b2884", "author": {"user": {"login": "pvary", "name": null}}, "url": "https://github.com/apache/iceberg/commit/2eea35667e1e157525808a8248302b670a6b2884", "committedDate": "2020-12-02T19:23:16Z", "message": "Checkstyle"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ1Mzg5NTM3", "url": "https://github.com/apache/iceberg/pull/1854#pullrequestreview-545389537", "createdAt": "2020-12-05T01:41:20Z", "commit": {"oid": "2eea35667e1e157525808a8248302b670a6b2884"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwMTo0MToyMFrOH_n7ug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwMTo0MToyMFrOH_n7ug==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ3NjYwMg==", "bodyText": "List and Map aren't supported?", "url": "https://github.com/apache/iceberg/pull/1854#discussion_r536476602", "createdAt": "2020-12-05T01:41:20Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/hive/Deserializer.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.util.List;\n+import java.util.UUID;\n+import org.apache.hadoop.hive.serde2.SerDeException;\n+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.StructField;\n+import org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.BooleanObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.DoubleObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.FloatObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.IntObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.LongObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.StringObjectInspector;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.data.GenericRecord;\n+import org.apache.iceberg.data.Record;\n+import org.apache.iceberg.mr.hive.serde.objectinspector.IcebergWriteObjectInspector;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+\n+class Deserializer {\n+  private FieldDeserializer fieldDeserializer;\n+\n+  Deserializer(Schema schema, ObjectInspector fieldInspector) throws SerDeException {\n+    this.fieldDeserializer = deserializer(schema.asStruct(), fieldInspector);\n+  }\n+\n+  Record deserialize(Object data) {\n+    return (Record) fieldDeserializer.value(data);\n+  }\n+\n+  private interface FieldDeserializer {\n+    Object value(Object object);\n+  }\n+\n+  private static FieldDeserializer deserializer(Type type, ObjectInspector fieldInspector) throws SerDeException {\n+    switch (type.typeId()) {\n+      case BOOLEAN:\n+        return o -> ((BooleanObjectInspector) fieldInspector).get(o);\n+      case INTEGER:\n+        return o -> ((IntObjectInspector) fieldInspector).get(o);\n+      case LONG:\n+        return o -> ((LongObjectInspector) fieldInspector).get(o);\n+      case FLOAT:\n+        return o -> ((FloatObjectInspector) fieldInspector).get(o);\n+      case DOUBLE:\n+        return o -> ((DoubleObjectInspector) fieldInspector).get(o);\n+      case STRING:\n+        return o -> ((StringObjectInspector) fieldInspector).getPrimitiveJavaObject(o);\n+      case UUID:\n+        // TODO: This will not work with Parquet. Parquet UUID expect byte[], others are expecting UUID\n+        return o -> UUID.fromString(((StringObjectInspector) fieldInspector).getPrimitiveJavaObject(o));\n+      case DATE:\n+      case TIMESTAMP:\n+      case FIXED:\n+      case BINARY:\n+      case DECIMAL:\n+        // Iceberg specific conversions\n+        return o -> ((IcebergWriteObjectInspector) fieldInspector).getIcebergObject(o);\n+      case STRUCT:\n+        return new StructDeserializer((Types.StructType) type, (StructObjectInspector) fieldInspector);\n+      case LIST:\n+      case MAP:\n+      case TIME:\n+      default:\n+        throw new SerDeException(\"Unsupported column type: \" + type);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2eea35667e1e157525808a8248302b670a6b2884"}, "originalPosition": 86}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ1MzkwMDY1", "url": "https://github.com/apache/iceberg/pull/1854#pullrequestreview-545390065", "createdAt": "2020-12-05T01:45:48Z", "commit": {"oid": "2eea35667e1e157525808a8248302b670a6b2884"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwMTo0NTo0OFrOH_n_Mw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwMTo0NTo0OFrOH_n_Mw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ3NzQ5MQ==", "bodyText": "Most of the other modules use the visitor pattern to traverse a type. That keeps the logic for traversing a schema in just one place so you don't need to mix it in with your domain-specific code.\nIt looks like this method is called from with the StructDeserializer constructor, so there is a recursive traversal of the schema that goes back and forth between object constructors and this method. That's a bit hard to follow, so I think it would be simpler if you took the visitor approach.\nA GenericAvroReader is similar to what you're building here, so take a look at that as an example: https://github.com/apache/iceberg/blob/master/core/src/main/java/org/apache/iceberg/avro/GenericAvroReader.java", "url": "https://github.com/apache/iceberg/pull/1854#discussion_r536477491", "createdAt": "2020-12-05T01:45:48Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/hive/Deserializer.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.util.List;\n+import java.util.UUID;\n+import org.apache.hadoop.hive.serde2.SerDeException;\n+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.StructField;\n+import org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.BooleanObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.DoubleObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.FloatObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.IntObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.LongObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.StringObjectInspector;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.data.GenericRecord;\n+import org.apache.iceberg.data.Record;\n+import org.apache.iceberg.mr.hive.serde.objectinspector.IcebergWriteObjectInspector;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+\n+class Deserializer {\n+  private FieldDeserializer fieldDeserializer;\n+\n+  Deserializer(Schema schema, ObjectInspector fieldInspector) throws SerDeException {\n+    this.fieldDeserializer = deserializer(schema.asStruct(), fieldInspector);\n+  }\n+\n+  Record deserialize(Object data) {\n+    return (Record) fieldDeserializer.value(data);\n+  }\n+\n+  private interface FieldDeserializer {\n+    Object value(Object object);\n+  }\n+\n+  private static FieldDeserializer deserializer(Type type, ObjectInspector fieldInspector) throws SerDeException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2eea35667e1e157525808a8248302b670a6b2884"}, "originalPosition": 56}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ1MzkwMjMw", "url": "https://github.com/apache/iceberg/pull/1854#pullrequestreview-545390230", "createdAt": "2020-12-05T01:47:07Z", "commit": {"oid": "2eea35667e1e157525808a8248302b670a6b2884"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwMTo0NzowOFrOH_oAZA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwMTo0NzowOFrOH_oAZA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ3Nzc5Ng==", "bodyText": "As I noted above, I think this would be cleaner if you used a visitor and passed the field deserializers into this constructor instead of calling deserializer here.", "url": "https://github.com/apache/iceberg/pull/1854#discussion_r536477796", "createdAt": "2020-12-05T01:47:08Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/hive/Deserializer.java", "diffHunk": "@@ -0,0 +1,129 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.util.List;\n+import java.util.UUID;\n+import org.apache.hadoop.hive.serde2.SerDeException;\n+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.StructField;\n+import org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.BooleanObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.DoubleObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.FloatObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.IntObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.LongObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.StringObjectInspector;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.data.GenericRecord;\n+import org.apache.iceberg.data.Record;\n+import org.apache.iceberg.mr.hive.serde.objectinspector.IcebergWriteObjectInspector;\n+import org.apache.iceberg.types.Type;\n+import org.apache.iceberg.types.Types;\n+\n+class Deserializer {\n+  private FieldDeserializer fieldDeserializer;\n+\n+  Deserializer(Schema schema, ObjectInspector fieldInspector) throws SerDeException {\n+    this.fieldDeserializer = deserializer(schema.asStruct(), fieldInspector);\n+  }\n+\n+  Record deserialize(Object data) {\n+    return (Record) fieldDeserializer.value(data);\n+  }\n+\n+  private interface FieldDeserializer {\n+    Object value(Object object);\n+  }\n+\n+  private static FieldDeserializer deserializer(Type type, ObjectInspector fieldInspector) throws SerDeException {\n+    switch (type.typeId()) {\n+      case BOOLEAN:\n+        return o -> ((BooleanObjectInspector) fieldInspector).get(o);\n+      case INTEGER:\n+        return o -> ((IntObjectInspector) fieldInspector).get(o);\n+      case LONG:\n+        return o -> ((LongObjectInspector) fieldInspector).get(o);\n+      case FLOAT:\n+        return o -> ((FloatObjectInspector) fieldInspector).get(o);\n+      case DOUBLE:\n+        return o -> ((DoubleObjectInspector) fieldInspector).get(o);\n+      case STRING:\n+        return o -> ((StringObjectInspector) fieldInspector).getPrimitiveJavaObject(o);\n+      case UUID:\n+        // TODO: This will not work with Parquet. Parquet UUID expect byte[], others are expecting UUID\n+        return o -> UUID.fromString(((StringObjectInspector) fieldInspector).getPrimitiveJavaObject(o));\n+      case DATE:\n+      case TIMESTAMP:\n+      case FIXED:\n+      case BINARY:\n+      case DECIMAL:\n+        // Iceberg specific conversions\n+        return o -> ((IcebergWriteObjectInspector) fieldInspector).getIcebergObject(o);\n+      case STRUCT:\n+        return new StructDeserializer((Types.StructType) type, (StructObjectInspector) fieldInspector);\n+      case LIST:\n+      case MAP:\n+      case TIME:\n+      default:\n+        throw new SerDeException(\"Unsupported column type: \" + type);\n+    }\n+  }\n+\n+  private static class StructDeserializer implements FieldDeserializer {\n+    private final FieldDeserializer[] fieldDeserializers;\n+    private final StructObjectInspector fieldInspector;\n+    private final Types.StructType type;\n+\n+    private StructDeserializer(Types.StructType type, StructObjectInspector fieldInspector) throws SerDeException {\n+      List<? extends StructField> structFields = fieldInspector.getAllStructFieldRefs();\n+      List<Types.NestedField> nestedFields = type.fields();\n+      this.fieldDeserializers = new FieldDeserializer[structFields.size()];\n+      this.fieldInspector = fieldInspector;\n+      this.type = type;\n+\n+      for (int i = 0; i < fieldDeserializers.length; i++) {\n+        fieldDeserializers[i] =\n+            deserializer(nestedFields.get(i).type(), structFields.get(i).getFieldObjectInspector());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2eea35667e1e157525808a8248302b670a6b2884"}, "originalPosition": 104}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ1MzkwNzgx", "url": "https://github.com/apache/iceberg/pull/1854#pullrequestreview-545390781", "createdAt": "2020-12-05T01:51:58Z", "commit": {"oid": "2eea35667e1e157525808a8248302b670a6b2884"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwMTo1MTo1OFrOH_oD6w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwMTo1MTo1OFrOH_oD6w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ3ODY5OQ==", "bodyText": "We avoid get in APIs because it doesn't add much value and could be misleading in some cases. I think it is misleading here because this actually converts the object to the value to the Iceberg generic representation rather than just returning it. We also shouldn't need \"Iceberg\" in the name because it's in IcebergWriteObjectInspector.\nHow about naming this convert?\nAlso, where we have similar interfaces elsewhere, we tend to like to use parameterized types. ValueWriters is a good example.", "url": "https://github.com/apache/iceberg/pull/1854#discussion_r536478699", "createdAt": "2020-12-05T01:51:58Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/hive/serde/objectinspector/IcebergWriteObjectInspector.java", "diffHunk": "@@ -0,0 +1,24 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive.serde.objectinspector;\n+\n+public interface IcebergWriteObjectInspector {\n+  Object getIcebergObject(Object value);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2eea35667e1e157525808a8248302b670a6b2884"}, "originalPosition": 23}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ1MzkwODU5", "url": "https://github.com/apache/iceberg/pull/1854#pullrequestreview-545390859", "createdAt": "2020-12-05T01:52:41Z", "commit": {"oid": "2eea35667e1e157525808a8248302b670a6b2884"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwMTo1Mjo0MlrOH_oEhQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwMTo1Mjo0MlrOH_oEhQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ3ODg1Mw==", "bodyText": "Can you file a bug for this?", "url": "https://github.com/apache/iceberg/pull/1854#discussion_r536478853", "createdAt": "2020-12-05T01:52:42Z", "author": {"login": "rdblue"}, "path": "mr/src/test/java/org/apache/iceberg/mr/hive/HiveIcebergTestUtils.java", "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.nio.ByteBuffer;\n+import java.sql.Timestamp;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.OffsetDateTime;\n+import java.time.ZoneOffset;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.UUID;\n+import org.apache.hadoop.hive.common.type.HiveDecimal;\n+import org.apache.hadoop.hive.serde2.io.DateWritable;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.hadoop.hive.serde2.io.TimestampWritable;\n+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory;\n+import org.apache.hadoop.hive.serde2.objectinspector.StandardStructObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;\n+import org.apache.hadoop.io.BooleanWritable;\n+import org.apache.hadoop.io.BytesWritable;\n+import org.apache.hadoop.io.DoubleWritable;\n+import org.apache.hadoop.io.FloatWritable;\n+import org.apache.hadoop.io.IntWritable;\n+import org.apache.hadoop.io.LongWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.data.GenericRecord;\n+import org.apache.iceberg.data.Record;\n+import org.apache.iceberg.mr.hive.serde.objectinspector.IcebergBinaryObjectInspector;\n+import org.apache.iceberg.mr.hive.serde.objectinspector.IcebergDecimalObjectInspector;\n+import org.apache.iceberg.mr.hive.serde.objectinspector.IcebergObjectInspector;\n+import org.apache.iceberg.types.Types;\n+import org.apache.iceberg.util.UUIDUtil;\n+import org.junit.Assert;\n+\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+\n+public class HiveIcebergTestUtils {\n+  // TODO: Can this be a constant all around the Iceberg tests?\n+  public static final Schema FULL_SCHEMA = new Schema(\n+      optional(1, \"boolean_type\", Types.BooleanType.get()),\n+      optional(2, \"integer_type\", Types.IntegerType.get()),\n+      optional(3, \"long_type\", Types.LongType.get()),\n+      optional(4, \"float_type\", Types.FloatType.get()),\n+      optional(5, \"double_type\", Types.DoubleType.get()),\n+      optional(6, \"date_type\", Types.DateType.get()),\n+      // TimeType is not supported\n+      // required(7, \"time_type\", Types.TimeType.get()),\n+      optional(7, \"tsTz\", Types.TimestampType.withZone()),\n+      optional(8, \"ts\", Types.TimestampType.withoutZone()),\n+      optional(9, \"string_type\", Types.StringType.get()),\n+      optional(10, \"uuid_type\", Types.UUIDType.get()),\n+      optional(11, \"fixed_type\", Types.FixedType.ofLength(3)),\n+      optional(12, \"binary_type\", Types.BinaryType.get()),\n+      optional(13, \"decimal_type\", Types.DecimalType.of(38, 10)));\n+\n+  public static final StandardStructObjectInspector FULL_SCHEMA_OBJECT_INSPECTOR =\n+      ObjectInspectorFactory.getStandardStructObjectInspector(\n+          // Capitalized `boolean_type` field to check for field case insensitivity.\n+          Arrays.asList(\"Boolean_Type\", \"integer_type\", \"long_type\", \"float_type\", \"double_type\",\n+              \"date_type\", \"tsTz\", \"ts\", \"string_type\", \"uuid_type\", \"fixed_type\", \"binary_type\", \"decimal_type\"),\n+          Arrays.asList(\n+              PrimitiveObjectInspectorFactory.writableBooleanObjectInspector,\n+              PrimitiveObjectInspectorFactory.writableIntObjectInspector,\n+              PrimitiveObjectInspectorFactory.writableLongObjectInspector,\n+              PrimitiveObjectInspectorFactory.writableFloatObjectInspector,\n+              PrimitiveObjectInspectorFactory.writableDoubleObjectInspector,\n+              IcebergObjectInspector.DATE_INSPECTOR,\n+              IcebergObjectInspector.TIMESTAMP_INSPECTOR_WITH_TZ,\n+              IcebergObjectInspector.TIMESTAMP_INSPECTOR,\n+              PrimitiveObjectInspectorFactory.writableStringObjectInspector,\n+              PrimitiveObjectInspectorFactory.writableStringObjectInspector,\n+              IcebergBinaryObjectInspector.byteArray(),\n+              IcebergBinaryObjectInspector.byteBuffer(),\n+              IcebergDecimalObjectInspector.get(38, 10)\n+          ));\n+\n+  private HiveIcebergTestUtils() {\n+    // Empty constructor for the utility class\n+  }\n+\n+  public static Record getTestRecord(boolean uuidAsByte) {\n+    Record record = GenericRecord.create(HiveIcebergTestUtils.FULL_SCHEMA);\n+    record.set(0, true);\n+    record.set(1, 1);\n+    record.set(2, 2L);\n+    record.set(3, 3.1f);\n+    record.set(4, 4.2d);\n+    record.set(5, LocalDate.of(2020, 1, 21));\n+    // TimeType is not supported\n+    // record.set(6, LocalTime.of(11, 33));\n+    // Nano is not supported ?\n+    record.set(6, OffsetDateTime.of(2017, 11, 22, 11, 30, 7, 0, ZoneOffset.ofHours(2)));\n+    record.set(7, LocalDateTime.of(2019, 2, 22, 9, 44, 54));\n+    record.set(8, \"kilenc\");\n+    if (uuidAsByte) {\n+      // TODO: Parquet UUID expect byte[], others are expecting UUID", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2eea35667e1e157525808a8248302b670a6b2884"}, "originalPosition": 117}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ1MzkxMDIx", "url": "https://github.com/apache/iceberg/pull/1854#pullrequestreview-545391021", "createdAt": "2020-12-05T01:53:56Z", "commit": {"oid": "2eea35667e1e157525808a8248302b670a6b2884"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwMTo1Mzo1NlrOH_oFaA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwMTo1Mzo1NlrOH_oFaA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ3OTA4MA==", "bodyText": "You should be able to use utils in ByteBuffers for this.", "url": "https://github.com/apache/iceberg/pull/1854#discussion_r536479080", "createdAt": "2020-12-05T01:53:56Z", "author": {"login": "rdblue"}, "path": "mr/src/test/java/org/apache/iceberg/mr/hive/HiveIcebergTestUtils.java", "diffHunk": "@@ -0,0 +1,180 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.math.BigDecimal;\n+import java.nio.ByteBuffer;\n+import java.sql.Timestamp;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.OffsetDateTime;\n+import java.time.ZoneOffset;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.UUID;\n+import org.apache.hadoop.hive.common.type.HiveDecimal;\n+import org.apache.hadoop.hive.serde2.io.DateWritable;\n+import org.apache.hadoop.hive.serde2.io.HiveDecimalWritable;\n+import org.apache.hadoop.hive.serde2.io.TimestampWritable;\n+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory;\n+import org.apache.hadoop.hive.serde2.objectinspector.StandardStructObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;\n+import org.apache.hadoop.io.BooleanWritable;\n+import org.apache.hadoop.io.BytesWritable;\n+import org.apache.hadoop.io.DoubleWritable;\n+import org.apache.hadoop.io.FloatWritable;\n+import org.apache.hadoop.io.IntWritable;\n+import org.apache.hadoop.io.LongWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.data.GenericRecord;\n+import org.apache.iceberg.data.Record;\n+import org.apache.iceberg.mr.hive.serde.objectinspector.IcebergBinaryObjectInspector;\n+import org.apache.iceberg.mr.hive.serde.objectinspector.IcebergDecimalObjectInspector;\n+import org.apache.iceberg.mr.hive.serde.objectinspector.IcebergObjectInspector;\n+import org.apache.iceberg.types.Types;\n+import org.apache.iceberg.util.UUIDUtil;\n+import org.junit.Assert;\n+\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+\n+public class HiveIcebergTestUtils {\n+  // TODO: Can this be a constant all around the Iceberg tests?\n+  public static final Schema FULL_SCHEMA = new Schema(\n+      optional(1, \"boolean_type\", Types.BooleanType.get()),\n+      optional(2, \"integer_type\", Types.IntegerType.get()),\n+      optional(3, \"long_type\", Types.LongType.get()),\n+      optional(4, \"float_type\", Types.FloatType.get()),\n+      optional(5, \"double_type\", Types.DoubleType.get()),\n+      optional(6, \"date_type\", Types.DateType.get()),\n+      // TimeType is not supported\n+      // required(7, \"time_type\", Types.TimeType.get()),\n+      optional(7, \"tsTz\", Types.TimestampType.withZone()),\n+      optional(8, \"ts\", Types.TimestampType.withoutZone()),\n+      optional(9, \"string_type\", Types.StringType.get()),\n+      optional(10, \"uuid_type\", Types.UUIDType.get()),\n+      optional(11, \"fixed_type\", Types.FixedType.ofLength(3)),\n+      optional(12, \"binary_type\", Types.BinaryType.get()),\n+      optional(13, \"decimal_type\", Types.DecimalType.of(38, 10)));\n+\n+  public static final StandardStructObjectInspector FULL_SCHEMA_OBJECT_INSPECTOR =\n+      ObjectInspectorFactory.getStandardStructObjectInspector(\n+          // Capitalized `boolean_type` field to check for field case insensitivity.\n+          Arrays.asList(\"Boolean_Type\", \"integer_type\", \"long_type\", \"float_type\", \"double_type\",\n+              \"date_type\", \"tsTz\", \"ts\", \"string_type\", \"uuid_type\", \"fixed_type\", \"binary_type\", \"decimal_type\"),\n+          Arrays.asList(\n+              PrimitiveObjectInspectorFactory.writableBooleanObjectInspector,\n+              PrimitiveObjectInspectorFactory.writableIntObjectInspector,\n+              PrimitiveObjectInspectorFactory.writableLongObjectInspector,\n+              PrimitiveObjectInspectorFactory.writableFloatObjectInspector,\n+              PrimitiveObjectInspectorFactory.writableDoubleObjectInspector,\n+              IcebergObjectInspector.DATE_INSPECTOR,\n+              IcebergObjectInspector.TIMESTAMP_INSPECTOR_WITH_TZ,\n+              IcebergObjectInspector.TIMESTAMP_INSPECTOR,\n+              PrimitiveObjectInspectorFactory.writableStringObjectInspector,\n+              PrimitiveObjectInspectorFactory.writableStringObjectInspector,\n+              IcebergBinaryObjectInspector.byteArray(),\n+              IcebergBinaryObjectInspector.byteBuffer(),\n+              IcebergDecimalObjectInspector.get(38, 10)\n+          ));\n+\n+  private HiveIcebergTestUtils() {\n+    // Empty constructor for the utility class\n+  }\n+\n+  public static Record getTestRecord(boolean uuidAsByte) {\n+    Record record = GenericRecord.create(HiveIcebergTestUtils.FULL_SCHEMA);\n+    record.set(0, true);\n+    record.set(1, 1);\n+    record.set(2, 2L);\n+    record.set(3, 3.1f);\n+    record.set(4, 4.2d);\n+    record.set(5, LocalDate.of(2020, 1, 21));\n+    // TimeType is not supported\n+    // record.set(6, LocalTime.of(11, 33));\n+    // Nano is not supported ?\n+    record.set(6, OffsetDateTime.of(2017, 11, 22, 11, 30, 7, 0, ZoneOffset.ofHours(2)));\n+    record.set(7, LocalDateTime.of(2019, 2, 22, 9, 44, 54));\n+    record.set(8, \"kilenc\");\n+    if (uuidAsByte) {\n+      // TODO: Parquet UUID expect byte[], others are expecting UUID\n+      record.set(9, UUIDUtil.convert(UUID.fromString(\"1-2-3-4-5\")));\n+    } else {\n+      record.set(9, UUID.fromString(\"1-2-3-4-5\"));\n+    }\n+    record.set(10, new byte[]{0, 1, 2});\n+    record.set(11, ByteBuffer.wrap(new byte[]{0, 1, 2, 3}));\n+    record.set(12, new BigDecimal(\"0.0000000013\"));\n+\n+    return record;\n+  }\n+\n+  public static Record getNullTestRecord() {\n+    Record record = GenericRecord.create(HiveIcebergTestUtils.FULL_SCHEMA);\n+\n+    for (int i = 0; i < HiveIcebergTestUtils.FULL_SCHEMA.columns().size(); i++) {\n+      record.set(i, null);\n+    }\n+\n+    return record;\n+  }\n+\n+  public static List<Object> valuesForTestRecord(Record record) {\n+    ByteBuffer byteBuffer = record.get(11, ByteBuffer.class);\n+    byte[] bytes = new byte[byteBuffer.remaining()];", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2eea35667e1e157525808a8248302b670a6b2884"}, "originalPosition": 141}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ1MzkxMDU4", "url": "https://github.com/apache/iceberg/pull/1854#pullrequestreview-545391058", "createdAt": "2020-12-05T01:54:15Z", "commit": {"oid": "2eea35667e1e157525808a8248302b670a6b2884"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwMTo1NDoxNlrOH_oFnw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwMTo1NDoxNlrOH_oFnw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ3OTEzNQ==", "bodyText": "Nit: double whitespace.", "url": "https://github.com/apache/iceberg/pull/1854#discussion_r536479135", "createdAt": "2020-12-05T01:54:16Z", "author": {"login": "rdblue"}, "path": "mr/src/test/java/org/apache/iceberg/mr/hive/TestDeserializer.java", "diffHunk": "@@ -0,0 +1,113 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.util.Arrays;\n+import org.apache.hadoop.hive.serde2.SerDeException;\n+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory;\n+import org.apache.hadoop.hive.serde2.objectinspector.StandardStructObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;\n+import org.apache.hadoop.io.LongWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.data.GenericRecord;\n+import org.apache.iceberg.data.Record;\n+import org.apache.iceberg.hive.MetastoreUtil;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Assume;\n+import org.junit.Test;\n+\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+\n+public class TestDeserializer {\n+  private static final Schema CUSTOMER_SCHEMA = new Schema(\n+      optional(1, \"customer_id\", Types.LongType.get()),\n+      optional(2, \"first_name\", Types.StringType.get())\n+  );\n+\n+  private static final StandardStructObjectInspector CUSTOMER_OBJECT_INSPECTOR =\n+      ObjectInspectorFactory.getStandardStructObjectInspector(\n+          Arrays.asList(\"customer_id\", \"first_name\"),\n+          Arrays.asList(\n+              PrimitiveObjectInspectorFactory.writableLongObjectInspector,\n+              PrimitiveObjectInspectorFactory.writableStringObjectInspector\n+          ));\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2eea35667e1e157525808a8248302b670a6b2884"}, "originalPosition": 53}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ1MzkxMTM5", "url": "https://github.com/apache/iceberg/pull/1854#pullrequestreview-545391139", "createdAt": "2020-12-05T01:55:00Z", "commit": {"oid": "2eea35667e1e157525808a8248302b670a6b2884"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwMTo1NTowMVrOH_oGSQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwMTo1NTowMVrOH_oGSQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ3OTMwNQ==", "bodyText": "I think that Assume can be passed string context. This would be a good thing to pass in.", "url": "https://github.com/apache/iceberg/pull/1854#discussion_r536479305", "createdAt": "2020-12-05T01:55:01Z", "author": {"login": "rdblue"}, "path": "mr/src/test/java/org/apache/iceberg/mr/hive/TestDeserializer.java", "diffHunk": "@@ -0,0 +1,113 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.util.Arrays;\n+import org.apache.hadoop.hive.serde2.SerDeException;\n+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory;\n+import org.apache.hadoop.hive.serde2.objectinspector.StandardStructObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;\n+import org.apache.hadoop.io.LongWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.data.GenericRecord;\n+import org.apache.iceberg.data.Record;\n+import org.apache.iceberg.hive.MetastoreUtil;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Assume;\n+import org.junit.Test;\n+\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+\n+public class TestDeserializer {\n+  private static final Schema CUSTOMER_SCHEMA = new Schema(\n+      optional(1, \"customer_id\", Types.LongType.get()),\n+      optional(2, \"first_name\", Types.StringType.get())\n+  );\n+\n+  private static final StandardStructObjectInspector CUSTOMER_OBJECT_INSPECTOR =\n+      ObjectInspectorFactory.getStandardStructObjectInspector(\n+          Arrays.asList(\"customer_id\", \"first_name\"),\n+          Arrays.asList(\n+              PrimitiveObjectInspectorFactory.writableLongObjectInspector,\n+              PrimitiveObjectInspectorFactory.writableStringObjectInspector\n+          ));\n+\n+\n+  @Test\n+  public void testSimpleDeserialize() throws SerDeException {\n+    Deserializer deserializer = new Deserializer(CUSTOMER_SCHEMA, CUSTOMER_OBJECT_INSPECTOR);\n+\n+    Record expected = GenericRecord.create(CUSTOMER_SCHEMA);\n+    expected.set(0, 1L);\n+    expected.set(1, \"Bob\");\n+\n+    Record actual = deserializer.deserialize(new Object[] { new LongWritable(1L), new Text(\"Bob\") });\n+\n+    Assert.assertEquals(expected, actual);\n+  }\n+\n+  @Test\n+  public void testDeserializeEverySupportedType() throws SerDeException {\n+    // No test yet for Hive3 (Date/Timestamp creation)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2eea35667e1e157525808a8248302b670a6b2884"}, "originalPosition": 70}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ1MzkxMzAz", "url": "https://github.com/apache/iceberg/pull/1854#pullrequestreview-545391303", "createdAt": "2020-12-05T01:56:20Z", "commit": {"oid": "2eea35667e1e157525808a8248302b670a6b2884"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwMTo1NjoyMFrOH_oHJQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwMTo1NjoyMFrOH_oHJQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ3OTUyNQ==", "bodyText": "We typically prefer to use AssertHelpers.assertThrows rather than expected. When we're testing other places, we can continue making assertions after the exception is thrown that way. Here it probably doesn't matter much, but it is a good habit to be in.", "url": "https://github.com/apache/iceberg/pull/1854#discussion_r536479525", "createdAt": "2020-12-05T01:56:20Z", "author": {"login": "rdblue"}, "path": "mr/src/test/java/org/apache/iceberg/mr/hive/TestDeserializer.java", "diffHunk": "@@ -0,0 +1,113 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.util.Arrays;\n+import org.apache.hadoop.hive.serde2.SerDeException;\n+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory;\n+import org.apache.hadoop.hive.serde2.objectinspector.StandardStructObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;\n+import org.apache.hadoop.io.LongWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.data.GenericRecord;\n+import org.apache.iceberg.data.Record;\n+import org.apache.iceberg.hive.MetastoreUtil;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Assume;\n+import org.junit.Test;\n+\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+\n+public class TestDeserializer {\n+  private static final Schema CUSTOMER_SCHEMA = new Schema(\n+      optional(1, \"customer_id\", Types.LongType.get()),\n+      optional(2, \"first_name\", Types.StringType.get())\n+  );\n+\n+  private static final StandardStructObjectInspector CUSTOMER_OBJECT_INSPECTOR =\n+      ObjectInspectorFactory.getStandardStructObjectInspector(\n+          Arrays.asList(\"customer_id\", \"first_name\"),\n+          Arrays.asList(\n+              PrimitiveObjectInspectorFactory.writableLongObjectInspector,\n+              PrimitiveObjectInspectorFactory.writableStringObjectInspector\n+          ));\n+\n+\n+  @Test\n+  public void testSimpleDeserialize() throws SerDeException {\n+    Deserializer deserializer = new Deserializer(CUSTOMER_SCHEMA, CUSTOMER_OBJECT_INSPECTOR);\n+\n+    Record expected = GenericRecord.create(CUSTOMER_SCHEMA);\n+    expected.set(0, 1L);\n+    expected.set(1, \"Bob\");\n+\n+    Record actual = deserializer.deserialize(new Object[] { new LongWritable(1L), new Text(\"Bob\") });\n+\n+    Assert.assertEquals(expected, actual);\n+  }\n+\n+  @Test\n+  public void testDeserializeEverySupportedType() throws SerDeException {\n+    // No test yet for Hive3 (Date/Timestamp creation)\n+    Assume.assumeFalse(MetastoreUtil.hive3PresentOnClasspath());\n+\n+    Deserializer deserializer = new Deserializer(HiveIcebergTestUtils.FULL_SCHEMA,\n+        HiveIcebergTestUtils.FULL_SCHEMA_OBJECT_INSPECTOR);\n+\n+    Record expected = HiveIcebergTestUtils.getTestRecord(false);\n+    Record actual = deserializer.deserialize(HiveIcebergTestUtils.valuesForTestRecord(expected));\n+\n+    HiveIcebergTestUtils.assertEquals(expected, actual);\n+  }\n+\n+  @Test\n+  public void testNullDeserialize() throws SerDeException {\n+    Deserializer deserializer = new Deserializer(HiveIcebergTestUtils.FULL_SCHEMA,\n+        HiveIcebergTestUtils.FULL_SCHEMA_OBJECT_INSPECTOR);\n+\n+    Record expected = HiveIcebergTestUtils.getNullTestRecord();\n+\n+    Object[] nulls = new Object[HiveIcebergTestUtils.FULL_SCHEMA.columns().size()];\n+    Arrays.fill(nulls, null);\n+\n+    Record actual = deserializer.deserialize(nulls);\n+\n+    Assert.assertEquals(expected, actual);\n+\n+    // Check null record as well\n+    Assert.assertNull(deserializer.deserialize(null));\n+  }\n+\n+  @Test(expected = SerDeException.class)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2eea35667e1e157525808a8248302b670a6b2884"}, "originalPosition": 100}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ1MzkxMzM1", "url": "https://github.com/apache/iceberg/pull/1854#pullrequestreview-545391335", "createdAt": "2020-12-05T01:56:35Z", "commit": {"oid": "2eea35667e1e157525808a8248302b670a6b2884"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwMTo1NjozNVrOH_oHhQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwMTo1NjozNVrOH_oHhQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ3OTYyMQ==", "bodyText": "Why did you choose to use SerDeException? Is that expected by Hive?", "url": "https://github.com/apache/iceberg/pull/1854#discussion_r536479621", "createdAt": "2020-12-05T01:56:35Z", "author": {"login": "rdblue"}, "path": "mr/src/test/java/org/apache/iceberg/mr/hive/TestDeserializer.java", "diffHunk": "@@ -0,0 +1,113 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.util.Arrays;\n+import org.apache.hadoop.hive.serde2.SerDeException;\n+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspectorFactory;\n+import org.apache.hadoop.hive.serde2.objectinspector.StandardStructObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.PrimitiveObjectInspectorFactory;\n+import org.apache.hadoop.io.LongWritable;\n+import org.apache.hadoop.io.Text;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.data.GenericRecord;\n+import org.apache.iceberg.data.Record;\n+import org.apache.iceberg.hive.MetastoreUtil;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Assume;\n+import org.junit.Test;\n+\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+\n+public class TestDeserializer {\n+  private static final Schema CUSTOMER_SCHEMA = new Schema(\n+      optional(1, \"customer_id\", Types.LongType.get()),\n+      optional(2, \"first_name\", Types.StringType.get())\n+  );\n+\n+  private static final StandardStructObjectInspector CUSTOMER_OBJECT_INSPECTOR =\n+      ObjectInspectorFactory.getStandardStructObjectInspector(\n+          Arrays.asList(\"customer_id\", \"first_name\"),\n+          Arrays.asList(\n+              PrimitiveObjectInspectorFactory.writableLongObjectInspector,\n+              PrimitiveObjectInspectorFactory.writableStringObjectInspector\n+          ));\n+\n+\n+  @Test\n+  public void testSimpleDeserialize() throws SerDeException {\n+    Deserializer deserializer = new Deserializer(CUSTOMER_SCHEMA, CUSTOMER_OBJECT_INSPECTOR);\n+\n+    Record expected = GenericRecord.create(CUSTOMER_SCHEMA);\n+    expected.set(0, 1L);\n+    expected.set(1, \"Bob\");\n+\n+    Record actual = deserializer.deserialize(new Object[] { new LongWritable(1L), new Text(\"Bob\") });\n+\n+    Assert.assertEquals(expected, actual);\n+  }\n+\n+  @Test\n+  public void testDeserializeEverySupportedType() throws SerDeException {\n+    // No test yet for Hive3 (Date/Timestamp creation)\n+    Assume.assumeFalse(MetastoreUtil.hive3PresentOnClasspath());\n+\n+    Deserializer deserializer = new Deserializer(HiveIcebergTestUtils.FULL_SCHEMA,\n+        HiveIcebergTestUtils.FULL_SCHEMA_OBJECT_INSPECTOR);\n+\n+    Record expected = HiveIcebergTestUtils.getTestRecord(false);\n+    Record actual = deserializer.deserialize(HiveIcebergTestUtils.valuesForTestRecord(expected));\n+\n+    HiveIcebergTestUtils.assertEquals(expected, actual);\n+  }\n+\n+  @Test\n+  public void testNullDeserialize() throws SerDeException {\n+    Deserializer deserializer = new Deserializer(HiveIcebergTestUtils.FULL_SCHEMA,\n+        HiveIcebergTestUtils.FULL_SCHEMA_OBJECT_INSPECTOR);\n+\n+    Record expected = HiveIcebergTestUtils.getNullTestRecord();\n+\n+    Object[] nulls = new Object[HiveIcebergTestUtils.FULL_SCHEMA.columns().size()];\n+    Arrays.fill(nulls, null);\n+\n+    Record actual = deserializer.deserialize(nulls);\n+\n+    Assert.assertEquals(expected, actual);\n+\n+    // Check null record as well\n+    Assert.assertNull(deserializer.deserialize(null));\n+  }\n+\n+  @Test(expected = SerDeException.class)\n+  public void testSerDeException() throws SerDeException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "2eea35667e1e157525808a8248302b670a6b2884"}, "originalPosition": 101}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "294abb0921525db40b07826a0fd98b46b7177383", "author": {"user": {"login": "pvary", "name": null}}, "url": "https://github.com/apache/iceberg/commit/294abb0921525db40b07826a0fd98b46b7177383", "committedDate": "2020-12-06T19:43:02Z", "message": "Using the Visitor for going through the Schema"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "37fd4fd86badf1d234bc03859b7b480332f49375", "author": {"user": {"login": "pvary", "name": null}}, "url": "https://github.com/apache/iceberg/commit/37fd4fd86badf1d234bc03859b7b480332f49375", "committedDate": "2020-12-06T21:05:55Z", "message": "Renamed IcebergWriteObjectInspector to WriteObjectInspector"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b8d5a64ea1d1a3fca6b635118dea32ab2ee9e9da", "author": {"user": {"login": "pvary", "name": null}}, "url": "https://github.com/apache/iceberg/commit/b8d5a64ea1d1a3fca6b635118dea32ab2ee9e9da", "committedDate": "2020-12-08T19:02:51Z", "message": "Handling Hive Schema problem and some javadoc"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ3NjQ2NTc5", "url": "https://github.com/apache/iceberg/pull/1854#pullrequestreview-547646579", "createdAt": "2020-12-08T21:28:05Z", "commit": {"oid": "b8d5a64ea1d1a3fca6b635118dea32ab2ee9e9da"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOFQyMToyODowNVrOIB2-fA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOFQyMToyODowNVrOIB2-fA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODgyMDIyMA==", "bodyText": "Nit: prefer Lists.newArrayList().", "url": "https://github.com/apache/iceberg/pull/1854#discussion_r538820220", "createdAt": "2020-12-08T21:28:05Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/hive/Deserializer.java", "diffHunk": "@@ -0,0 +1,271 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import org.apache.hadoop.hive.serde2.objectinspector.ListObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.MapObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.StructField;\n+import org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.StringObjectInspector;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.data.GenericRecord;\n+import org.apache.iceberg.data.Record;\n+import org.apache.iceberg.mr.hive.serde.objectinspector.WriteObjectInspector;\n+import org.apache.iceberg.schema.SchemaWithPartnerVisitor;\n+import org.apache.iceberg.types.Type.PrimitiveType;\n+import org.apache.iceberg.types.Types.ListType;\n+import org.apache.iceberg.types.Types.MapType;\n+import org.apache.iceberg.types.Types.NestedField;\n+import org.apache.iceberg.types.Types.StructType;\n+\n+\n+class Deserializer {\n+  private FieldDeserializer fieldDeserializer;\n+\n+  /**\n+   * Builder to create a Deserializer instance.\n+   * Requires an Iceberg Schema and the Hive ObjectInspector for converting the data.\n+   */\n+  static class Builder {\n+    private Schema schema;\n+    private ObjectInspector inspector;\n+\n+    Builder schema(Schema mainSchema) {\n+      this.schema = mainSchema;\n+      return this;\n+    }\n+\n+    Builder inspector(ObjectInspector mainInspector) {\n+      this.inspector = mainInspector;\n+      return this;\n+    }\n+\n+    Deserializer build() {\n+      return new Deserializer(schema, inspector);\n+    }\n+  }\n+\n+  /**\n+   * Deserializes the Hive result object to an Iceberg record using the provided ObjectInspectors.\n+   * @param data The Hive data to deserialize\n+   * @return The resulting Iceberg Record\n+   */\n+  Record deserialize(Object data) {\n+    return (Record) fieldDeserializer.value(data);\n+  }\n+\n+  private Deserializer(Schema schema, ObjectInspector fieldInspector) {\n+    this.fieldDeserializer = DeserializerVisitor.visit(schema, fieldInspector);\n+  }\n+\n+  private static class DeserializerVisitor extends SchemaWithPartnerVisitor<ObjectInspector, FieldDeserializer> {\n+\n+    public static FieldDeserializer visit(Schema schema, ObjectInspector objectInspector) {\n+      return visit(schema, new FixNameMappingObjectInspector(schema, objectInspector), new DeserializerVisitor(),\n+          new PartnerObjectInspectorByNameAccessors());\n+    }\n+\n+    @Override\n+    public FieldDeserializer schema(Schema schema, ObjectInspector inspector, FieldDeserializer deserializer) {\n+      return deserializer;\n+    }\n+\n+    @Override\n+    public FieldDeserializer field(NestedField field, ObjectInspector inspector, FieldDeserializer deserializer) {\n+      return deserializer;\n+    }\n+\n+    @Override\n+    public FieldDeserializer primitive(PrimitiveType type, ObjectInspector inspector) {\n+      switch (type.typeId()) {\n+        case BOOLEAN:\n+        case INTEGER:\n+        case LONG:\n+        case FLOAT:\n+        case DOUBLE:\n+        case STRING:\n+          // Generic conversions where Iceberg and Hive are using the same java object\n+          return o -> ((PrimitiveObjectInspector) inspector).getPrimitiveJavaObject(o);\n+        case UUID:\n+          // TODO: This will not work with Parquet. Parquet UUID expect byte[], others are expecting UUID\n+          return o -> UUID.fromString(((StringObjectInspector) inspector).getPrimitiveJavaObject(o));\n+        case DATE:\n+        case TIMESTAMP:\n+        case FIXED:\n+        case BINARY:\n+        case DECIMAL:\n+          // Iceberg specific conversions\n+          return o -> ((WriteObjectInspector) inspector).convert(o);\n+        case TIME:\n+        default:\n+          throw new IllegalArgumentException(\"Unsupported column type: \" + type);\n+      }\n+    }\n+\n+    @Override\n+    public FieldDeserializer struct(StructType type, ObjectInspector inspector, List<FieldDeserializer> deserializers) {\n+      return o -> {\n+        if (o == null) {\n+          return null;\n+        }\n+\n+        List<Object> data = ((StructObjectInspector) inspector).getStructFieldsDataAsList(o);\n+        Record result = GenericRecord.create(type);\n+\n+        for (int i = 0; i < deserializers.size(); i++) {\n+          Object fieldValue = data.get(i);\n+          if (fieldValue != null) {\n+            result.set(i, deserializers.get(i).value(fieldValue));\n+          } else {\n+            result.set(i, null);\n+          }\n+        }\n+\n+        return result;\n+      };\n+    }\n+\n+    @Override\n+    public FieldDeserializer list(ListType listTypeInfo, ObjectInspector inspector, FieldDeserializer deserializer) {\n+      return o -> {\n+        if (o == null) {\n+          return null;\n+        }\n+\n+        List<Object> result = new ArrayList<>();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8d5a64ea1d1a3fca6b635118dea32ab2ee9e9da"}, "originalPosition": 159}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ3NjQ3MzEw", "url": "https://github.com/apache/iceberg/pull/1854#pullrequestreview-547647310", "createdAt": "2020-12-08T21:29:06Z", "commit": {"oid": "b8d5a64ea1d1a3fca6b635118dea32ab2ee9e9da"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOFQyMToyOTowN1rOIB3AwQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOFQyMToyOTowN1rOIB3AwQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODgyMDgwMQ==", "bodyText": "Minor: This could probably be a singleton.", "url": "https://github.com/apache/iceberg/pull/1854#discussion_r538820801", "createdAt": "2020-12-08T21:29:07Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/hive/Deserializer.java", "diffHunk": "@@ -0,0 +1,271 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import org.apache.hadoop.hive.serde2.objectinspector.ListObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.MapObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.StructField;\n+import org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.StringObjectInspector;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.data.GenericRecord;\n+import org.apache.iceberg.data.Record;\n+import org.apache.iceberg.mr.hive.serde.objectinspector.WriteObjectInspector;\n+import org.apache.iceberg.schema.SchemaWithPartnerVisitor;\n+import org.apache.iceberg.types.Type.PrimitiveType;\n+import org.apache.iceberg.types.Types.ListType;\n+import org.apache.iceberg.types.Types.MapType;\n+import org.apache.iceberg.types.Types.NestedField;\n+import org.apache.iceberg.types.Types.StructType;\n+\n+\n+class Deserializer {\n+  private FieldDeserializer fieldDeserializer;\n+\n+  /**\n+   * Builder to create a Deserializer instance.\n+   * Requires an Iceberg Schema and the Hive ObjectInspector for converting the data.\n+   */\n+  static class Builder {\n+    private Schema schema;\n+    private ObjectInspector inspector;\n+\n+    Builder schema(Schema mainSchema) {\n+      this.schema = mainSchema;\n+      return this;\n+    }\n+\n+    Builder inspector(ObjectInspector mainInspector) {\n+      this.inspector = mainInspector;\n+      return this;\n+    }\n+\n+    Deserializer build() {\n+      return new Deserializer(schema, inspector);\n+    }\n+  }\n+\n+  /**\n+   * Deserializes the Hive result object to an Iceberg record using the provided ObjectInspectors.\n+   * @param data The Hive data to deserialize\n+   * @return The resulting Iceberg Record\n+   */\n+  Record deserialize(Object data) {\n+    return (Record) fieldDeserializer.value(data);\n+  }\n+\n+  private Deserializer(Schema schema, ObjectInspector fieldInspector) {\n+    this.fieldDeserializer = DeserializerVisitor.visit(schema, fieldInspector);\n+  }\n+\n+  private static class DeserializerVisitor extends SchemaWithPartnerVisitor<ObjectInspector, FieldDeserializer> {\n+\n+    public static FieldDeserializer visit(Schema schema, ObjectInspector objectInspector) {\n+      return visit(schema, new FixNameMappingObjectInspector(schema, objectInspector), new DeserializerVisitor(),\n+          new PartnerObjectInspectorByNameAccessors());\n+    }\n+\n+    @Override\n+    public FieldDeserializer schema(Schema schema, ObjectInspector inspector, FieldDeserializer deserializer) {\n+      return deserializer;\n+    }\n+\n+    @Override\n+    public FieldDeserializer field(NestedField field, ObjectInspector inspector, FieldDeserializer deserializer) {\n+      return deserializer;\n+    }\n+\n+    @Override\n+    public FieldDeserializer primitive(PrimitiveType type, ObjectInspector inspector) {\n+      switch (type.typeId()) {\n+        case BOOLEAN:\n+        case INTEGER:\n+        case LONG:\n+        case FLOAT:\n+        case DOUBLE:\n+        case STRING:\n+          // Generic conversions where Iceberg and Hive are using the same java object\n+          return o -> ((PrimitiveObjectInspector) inspector).getPrimitiveJavaObject(o);\n+        case UUID:\n+          // TODO: This will not work with Parquet. Parquet UUID expect byte[], others are expecting UUID\n+          return o -> UUID.fromString(((StringObjectInspector) inspector).getPrimitiveJavaObject(o));\n+        case DATE:\n+        case TIMESTAMP:\n+        case FIXED:\n+        case BINARY:\n+        case DECIMAL:\n+          // Iceberg specific conversions\n+          return o -> ((WriteObjectInspector) inspector).convert(o);\n+        case TIME:\n+        default:\n+          throw new IllegalArgumentException(\"Unsupported column type: \" + type);\n+      }\n+    }\n+\n+    @Override\n+    public FieldDeserializer struct(StructType type, ObjectInspector inspector, List<FieldDeserializer> deserializers) {\n+      return o -> {\n+        if (o == null) {\n+          return null;\n+        }\n+\n+        List<Object> data = ((StructObjectInspector) inspector).getStructFieldsDataAsList(o);\n+        Record result = GenericRecord.create(type);\n+\n+        for (int i = 0; i < deserializers.size(); i++) {\n+          Object fieldValue = data.get(i);\n+          if (fieldValue != null) {\n+            result.set(i, deserializers.get(i).value(fieldValue));\n+          } else {\n+            result.set(i, null);\n+          }\n+        }\n+\n+        return result;\n+      };\n+    }\n+\n+    @Override\n+    public FieldDeserializer list(ListType listTypeInfo, ObjectInspector inspector, FieldDeserializer deserializer) {\n+      return o -> {\n+        if (o == null) {\n+          return null;\n+        }\n+\n+        List<Object> result = new ArrayList<>();\n+        ListObjectInspector listInspector = (ListObjectInspector) inspector;\n+\n+        for (Object val : listInspector.getList(o)) {\n+          result.add(deserializer.value(val));\n+        }\n+\n+        return result;\n+      };\n+    }\n+\n+    @Override\n+    public FieldDeserializer map(MapType mapType, ObjectInspector inspector, FieldDeserializer keyDeserializer,\n+                                 FieldDeserializer valueDeserializer) {\n+      return o -> {\n+        if (o == null) {\n+          return null;\n+        }\n+\n+        Map<Object, Object> result = new HashMap<>();\n+        MapObjectInspector mapObjectInspector = (MapObjectInspector) inspector;\n+\n+        for (Map.Entry<?, ?> entry : mapObjectInspector.getMap(o).entrySet()) {\n+          result.put(keyDeserializer.value(entry.getKey()), valueDeserializer.value(entry.getValue()));\n+        }\n+        return result;\n+      };\n+    }\n+  }\n+\n+  private static class PartnerObjectInspectorByNameAccessors\n+      implements SchemaWithPartnerVisitor.PartnerAccessors<ObjectInspector> {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8d5a64ea1d1a3fca6b635118dea32ab2ee9e9da"}, "originalPosition": 190}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ3NzI4NTEx", "url": "https://github.com/apache/iceberg/pull/1854#pullrequestreview-547728511", "createdAt": "2020-12-08T23:48:06Z", "commit": {"oid": "b8d5a64ea1d1a3fca6b635118dea32ab2ee9e9da"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOFQyMzo0ODowNlrOIB7mUg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOFQyMzo0ODowNlrOIB7mUg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODg5NTk1NA==", "bodyText": "Don't all of the structs need to be wrapped by this?", "url": "https://github.com/apache/iceberg/pull/1854#discussion_r538895954", "createdAt": "2020-12-08T23:48:06Z", "author": {"login": "rdblue"}, "path": "mr/src/main/java/org/apache/iceberg/mr/hive/Deserializer.java", "diffHunk": "@@ -0,0 +1,271 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.mr.hive;\n+\n+import java.util.ArrayList;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.UUID;\n+import org.apache.hadoop.hive.serde2.objectinspector.ListObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.MapObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.ObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.PrimitiveObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.StructField;\n+import org.apache.hadoop.hive.serde2.objectinspector.StructObjectInspector;\n+import org.apache.hadoop.hive.serde2.objectinspector.primitive.StringObjectInspector;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.data.GenericRecord;\n+import org.apache.iceberg.data.Record;\n+import org.apache.iceberg.mr.hive.serde.objectinspector.WriteObjectInspector;\n+import org.apache.iceberg.schema.SchemaWithPartnerVisitor;\n+import org.apache.iceberg.types.Type.PrimitiveType;\n+import org.apache.iceberg.types.Types.ListType;\n+import org.apache.iceberg.types.Types.MapType;\n+import org.apache.iceberg.types.Types.NestedField;\n+import org.apache.iceberg.types.Types.StructType;\n+\n+\n+class Deserializer {\n+  private FieldDeserializer fieldDeserializer;\n+\n+  /**\n+   * Builder to create a Deserializer instance.\n+   * Requires an Iceberg Schema and the Hive ObjectInspector for converting the data.\n+   */\n+  static class Builder {\n+    private Schema schema;\n+    private ObjectInspector inspector;\n+\n+    Builder schema(Schema mainSchema) {\n+      this.schema = mainSchema;\n+      return this;\n+    }\n+\n+    Builder inspector(ObjectInspector mainInspector) {\n+      this.inspector = mainInspector;\n+      return this;\n+    }\n+\n+    Deserializer build() {\n+      return new Deserializer(schema, inspector);\n+    }\n+  }\n+\n+  /**\n+   * Deserializes the Hive result object to an Iceberg record using the provided ObjectInspectors.\n+   * @param data The Hive data to deserialize\n+   * @return The resulting Iceberg Record\n+   */\n+  Record deserialize(Object data) {\n+    return (Record) fieldDeserializer.value(data);\n+  }\n+\n+  private Deserializer(Schema schema, ObjectInspector fieldInspector) {\n+    this.fieldDeserializer = DeserializerVisitor.visit(schema, fieldInspector);\n+  }\n+\n+  private static class DeserializerVisitor extends SchemaWithPartnerVisitor<ObjectInspector, FieldDeserializer> {\n+\n+    public static FieldDeserializer visit(Schema schema, ObjectInspector objectInspector) {\n+      return visit(schema, new FixNameMappingObjectInspector(schema, objectInspector), new DeserializerVisitor(),\n+          new PartnerObjectInspectorByNameAccessors());\n+    }\n+\n+    @Override\n+    public FieldDeserializer schema(Schema schema, ObjectInspector inspector, FieldDeserializer deserializer) {\n+      return deserializer;\n+    }\n+\n+    @Override\n+    public FieldDeserializer field(NestedField field, ObjectInspector inspector, FieldDeserializer deserializer) {\n+      return deserializer;\n+    }\n+\n+    @Override\n+    public FieldDeserializer primitive(PrimitiveType type, ObjectInspector inspector) {\n+      switch (type.typeId()) {\n+        case BOOLEAN:\n+        case INTEGER:\n+        case LONG:\n+        case FLOAT:\n+        case DOUBLE:\n+        case STRING:\n+          // Generic conversions where Iceberg and Hive are using the same java object\n+          return o -> ((PrimitiveObjectInspector) inspector).getPrimitiveJavaObject(o);\n+        case UUID:\n+          // TODO: This will not work with Parquet. Parquet UUID expect byte[], others are expecting UUID\n+          return o -> UUID.fromString(((StringObjectInspector) inspector).getPrimitiveJavaObject(o));\n+        case DATE:\n+        case TIMESTAMP:\n+        case FIXED:\n+        case BINARY:\n+        case DECIMAL:\n+          // Iceberg specific conversions\n+          return o -> ((WriteObjectInspector) inspector).convert(o);\n+        case TIME:\n+        default:\n+          throw new IllegalArgumentException(\"Unsupported column type: \" + type);\n+      }\n+    }\n+\n+    @Override\n+    public FieldDeserializer struct(StructType type, ObjectInspector inspector, List<FieldDeserializer> deserializers) {\n+      return o -> {\n+        if (o == null) {\n+          return null;\n+        }\n+\n+        List<Object> data = ((StructObjectInspector) inspector).getStructFieldsDataAsList(o);\n+        Record result = GenericRecord.create(type);\n+\n+        for (int i = 0; i < deserializers.size(); i++) {\n+          Object fieldValue = data.get(i);\n+          if (fieldValue != null) {\n+            result.set(i, deserializers.get(i).value(fieldValue));\n+          } else {\n+            result.set(i, null);\n+          }\n+        }\n+\n+        return result;\n+      };\n+    }\n+\n+    @Override\n+    public FieldDeserializer list(ListType listTypeInfo, ObjectInspector inspector, FieldDeserializer deserializer) {\n+      return o -> {\n+        if (o == null) {\n+          return null;\n+        }\n+\n+        List<Object> result = new ArrayList<>();\n+        ListObjectInspector listInspector = (ListObjectInspector) inspector;\n+\n+        for (Object val : listInspector.getList(o)) {\n+          result.add(deserializer.value(val));\n+        }\n+\n+        return result;\n+      };\n+    }\n+\n+    @Override\n+    public FieldDeserializer map(MapType mapType, ObjectInspector inspector, FieldDeserializer keyDeserializer,\n+                                 FieldDeserializer valueDeserializer) {\n+      return o -> {\n+        if (o == null) {\n+          return null;\n+        }\n+\n+        Map<Object, Object> result = new HashMap<>();\n+        MapObjectInspector mapObjectInspector = (MapObjectInspector) inspector;\n+\n+        for (Map.Entry<?, ?> entry : mapObjectInspector.getMap(o).entrySet()) {\n+          result.put(keyDeserializer.value(entry.getKey()), valueDeserializer.value(entry.getValue()));\n+        }\n+        return result;\n+      };\n+    }\n+  }\n+\n+  private static class PartnerObjectInspectorByNameAccessors\n+      implements SchemaWithPartnerVisitor.PartnerAccessors<ObjectInspector> {\n+\n+    @Override\n+    public ObjectInspector fieldPartner(ObjectInspector inspector, int fieldId, String name) {\n+      StructObjectInspector fieldInspector  = (StructObjectInspector) inspector;\n+      return fieldInspector.getStructFieldRef(name).getFieldObjectInspector();\n+    }\n+\n+    @Override\n+    public ObjectInspector mapKeyPartner(ObjectInspector inspector) {\n+      MapObjectInspector fieldInspector  = (MapObjectInspector) inspector;\n+      return fieldInspector.getMapKeyObjectInspector();\n+    }\n+\n+    @Override\n+    public ObjectInspector mapValuePartner(ObjectInspector inspector) {\n+      MapObjectInspector fieldInspector  = (MapObjectInspector) inspector;\n+      return fieldInspector.getMapValueObjectInspector();\n+    }\n+\n+    @Override\n+    public ObjectInspector listElementPartner(ObjectInspector inspector) {\n+      ListObjectInspector fieldInspector  = (ListObjectInspector) inspector;\n+      return fieldInspector.getListElementObjectInspector();\n+    }\n+  }\n+\n+  private interface FieldDeserializer {\n+    Object value(Object object);\n+  }\n+\n+  /**\n+   * Hive query results schema column names do not match the target Iceberg column names.\n+   * Instead we have to rely on the column order. To keep the other parts of the code generic we fix this with a\n+   * wrapper around the ObjectInspector. This wrapper uses the Iceberg schema column names instead of the Hive column\n+   * names for {@link #getStructFieldRef(String) getStructFieldRef}\n+   */\n+  private static class FixNameMappingObjectInspector extends StructObjectInspector {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b8d5a64ea1d1a3fca6b635118dea32ab2ee9e9da"}, "originalPosition": 227}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ3NzI4NzAw", "url": "https://github.com/apache/iceberg/pull/1854#pullrequestreview-547728700", "createdAt": "2020-12-08T23:48:32Z", "commit": {"oid": "b8d5a64ea1d1a3fca6b635118dea32ab2ee9e9da"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3472, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}