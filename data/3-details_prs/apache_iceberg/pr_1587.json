{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTAxNjQ5OTYy", "number": 1587, "title": "Nessie support for core ", "bodyText": "As per the mailing list annoucenment we would like to contribute integration between Iceberg and Nessie to the Iceberg project.\nThis PR does the following:\n\nadds a NessieCatalog for core iceberg acid operations\nadds nessie support to the catalog and source interfaces for spark 2 and spark 3\nmakes nessie branches and tags addressable for iceberg operations\n\nPlease have a look at Iceberg Spark for a more complete description of Nessie's capabilities with iceberg and Nessie Features for a broader introduction to Nessie.\nNote this is currently in draft until a gradle plugin required for testing Nessie has been published.", "createdAt": "2020-10-12T15:25:48Z", "url": "https://github.com/apache/iceberg/pull/1587", "merged": true, "mergeCommit": {"oid": "87143d53c05de308332860be12a450a8c7afb95f"}, "closed": true, "closedAt": "2020-11-23T18:36:04Z", "author": {"login": "rymurr"}, "timelineItems": {"totalCount": 103, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdfZUKMAFqTUzNjczMzIzNg==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdfZbEkgFqTUzNjczODU4Nw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM2NzMzMjM2", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-536733236", "createdAt": "2020-11-23T18:18:31Z", "commit": {"oid": "fc7cc8f6d4d2e83e75fb4e30f4bc285591a47ab7"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QxODoxODozMlrOH4Z2rQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QxODoxODozMlrOH4Z2rQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODkwNTkwMQ==", "bodyText": "Nit: static final constants should use upper case names, like LOGGER. I'm not sure why style checks didn't catch this.\n(Not a blocker)", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r528905901", "createdAt": "2020-11-23T18:18:32Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,336 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.BaseNessieClientServerException;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.Tasks;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+  private static final Logger logger = LoggerFactory.getLogger(NessieCatalog.class);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fc7cc8f6d4d2e83e75fb4e30f4bc285591a47ab7"}, "originalPosition": 72}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM2NzM0NDU3", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-536734457", "createdAt": "2020-11-23T18:20:14Z", "commit": {"oid": "fc7cc8f6d4d2e83e75fb4e30f4bc285591a47ab7"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QxODoyMDoxNFrOH4Z6bg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QxODoyMDoxNFrOH4Z6bg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODkwNjg2Mg==", "bodyText": "Nit: threw is no longer needed so this could be simply return true. That simplifies the logic at the end of the method to just return false.\nUp to you whether to change this or not. I know some people strongly prefer only one exit point from a method.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r528906862", "createdAt": "2020-11-23T18:20:14Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,336 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.BaseNessieClientServerException;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.Tasks;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+  private static final Logger logger = LoggerFactory.getLogger(NessieCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+  private FileIO fileIO;\n+\n+  public NessieCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String inputName, Map<String, String> options) {\n+    String fileIOImpl = options.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ? new HadoopFileIO(config) : CatalogUtil.loadFileIO(fileIOImpl, options, config);\n+    this.name = inputName == null ? \"nessie\" : inputName;\n+    // remove nessie prefix\n+    final Function<String, String> removePrefix = x -> x.replace(\"nessie.\", \"\");\n+\n+    this.client = NessieClient.withConfig(x -> options.get(removePrefix.apply(x)));\n+\n+    this.warehouseLocation = options.get(CatalogProperties.WAREHOUSE_LOCATION);\n+    if (warehouseLocation == null) {\n+      throw new IllegalStateException(\"Parameter warehouse not set, nessie can't store data.\");\n+    }\n+    final String requestedRef = options.get(removePrefix.apply(NessieClient.CONF_NESSIE_REF));\n+    this.reference = loadReference(requestedRef);\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    TableReference pti = TableReference.parse(tableIdentifier);\n+    UpdateableReference newReference = this.reference;\n+    if (pti.reference() != null) {\n+      newReference = loadReference(pti.reference());\n+    }\n+    return new NessieTableOperations(NessieUtil.toKey(pti.tableIdentifier()), newReference, client, fileIO);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+\n+    // We try to drop the table. Simple retry after ref update.\n+    boolean threw = true;\n+    try {\n+      Tasks.foreach(identifier)\n+           .retry(5)\n+           .stopRetryOn(NessieNotFoundException.class)\n+           .throwFailureWhenFinished()\n+           .run(this::dropTableInner, BaseNessieClientServerException.class);\n+      threw = false;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fc7cc8f6d4d2e83e75fb4e30f4bc285591a47ab7"}, "originalPosition": 152}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM2NzM4NTg3", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-536738587", "createdAt": "2020-11-23T18:26:05Z", "commit": {"oid": "fc7cc8f6d4d2e83e75fb4e30f4bc285591a47ab7"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QxODoyNjowNVrOH4aHfQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yM1QxODoyNjowNVrOH4aHfQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyODkxMDIwNQ==", "bodyText": "Did you intend to change this to \"ref\"? Your reply seemed to imply that: #1587 (comment)", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r528910205", "createdAt": "2020-11-23T18:26:05Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,336 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.BaseNessieClientServerException;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Function;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.Tasks;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+  private static final Logger logger = LoggerFactory.getLogger(NessieCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+  private FileIO fileIO;\n+\n+  public NessieCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String inputName, Map<String, String> options) {\n+    String fileIOImpl = options.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ? new HadoopFileIO(config) : CatalogUtil.loadFileIO(fileIOImpl, options, config);\n+    this.name = inputName == null ? \"nessie\" : inputName;\n+    // remove nessie prefix\n+    final Function<String, String> removePrefix = x -> x.replace(\"nessie.\", \"\");\n+\n+    this.client = NessieClient.withConfig(x -> options.get(removePrefix.apply(x)));\n+\n+    this.warehouseLocation = options.get(CatalogProperties.WAREHOUSE_LOCATION);\n+    if (warehouseLocation == null) {\n+      throw new IllegalStateException(\"Parameter warehouse not set, nessie can't store data.\");\n+    }\n+    final String requestedRef = options.get(removePrefix.apply(NessieClient.CONF_NESSIE_REF));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "fc7cc8f6d4d2e83e75fb4e30f4bc285591a47ab7"}, "originalPosition": 98}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA2NzQ2MzQw", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-506746340", "createdAt": "2020-10-12T16:03:59Z", "commit": {"oid": "df32d8e297bd5db0b085972c64e58992284e1ebf"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xMlQxNjowMzo1OVrOHgEsrQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xMlQxNjowMzo1OVrOHgEsrQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzM5MzQ1Mw==", "bodyText": "not sure if this is the best way to get hold of a directory to write tables into. Anyone have any suggestions?", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r503393453", "createdAt": "2020-10-12T16:03:59Z", "author": {"login": "rymurr"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.client.NessieClient.AuthType;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableMultiContents;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.MultiContents;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable {\n+\n+  public static final String CONF_NESSIE_URL = \"nessie.url\";\n+  public static final String CONF_NESSIE_USERNAME = \"nessie.username\";\n+  public static final String CONF_NESSIE_PASSWORD = \"nessie.password\";\n+  public static final String CONF_NESSIE_AUTH_TYPE = \"nessie.auth_type\";\n+  public static final String NESSIE_AUTH_TYPE_DEFAULT = \"BASIC\";\n+  public static final String CONF_NESSIE_REF = \"nessie.ref\";\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  private static final String ICEBERG_HADOOP_WAREHOUSE_BASE = \"iceberg/warehouse\";\n+  private final NessieClient client;\n+  private final String warehouseLocation;\n+  private final Configuration config;\n+  private final UpdateableReference reference;\n+  private final String name;\n+\n+  /**\n+   * create a catalog from a hadoop configuration.\n+   */\n+  public NessieCatalog(Configuration config) {\n+    this(\"nessie\", config);\n+  }\n+\n+  /**\n+   * create a catalog from a hadoop configuration.\n+   */\n+  public NessieCatalog(Configuration config, String ref) {\n+    this(\"nessie\", config, ref);\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config) {\n+    this(name, config, null);\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref) {\n+    this(name, config, ref, null);\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url) {\n+    this.config = config;\n+    this.name = name;\n+    String path = url == null ? config.get(CONF_NESSIE_URL) : url;\n+    String username = config.get(CONF_NESSIE_USERNAME);\n+    String password = config.get(CONF_NESSIE_PASSWORD);\n+    String authTypeStr = config.get(CONF_NESSIE_AUTH_TYPE, NESSIE_AUTH_TYPE_DEFAULT);\n+    AuthType authType = AuthType.valueOf(authTypeStr);\n+    this.client = new NessieClient(authType, path, username, password);\n+\n+    warehouseLocation = getWarehouseLocation();\n+\n+    final String requestedRef = ref != null ? ref : config.get(CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private String getWarehouseLocation() {\n+    String nessieWarehouseDir = config.get(\"nessie.warehouse.dir\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "df32d8e297bd5db0b085972c64e58992284e1ebf"}, "originalPosition": 121}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA2NzQ4MjM3", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-506748237", "createdAt": "2020-10-12T16:06:37Z", "commit": {"oid": "df32d8e297bd5db0b085972c64e58992284e1ebf"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xMlQxNjowNjozOFrOHgEyeQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xMlQxNjowNjozOFrOHgEyeQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzM5NDkzNw==", "bodyText": "The nessie specific tests all modify spark settings and reset the settings at the end. This is to interfere as little as possible w/ the 'normal' iceberg path.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r503394937", "createdAt": "2020-10-12T16:06:38Z", "author": {"login": "rymurr"}, "path": "spark/src/test/java/org/apache/iceberg/spark/source/TestIcebergSourceNessieTables.java", "diffHunk": "@@ -0,0 +1,120 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.source;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import java.io.IOException;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.hadoop.fs.FileSystem;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.PartitionSpec;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.nessie.NessieCatalog;\n+import org.apache.iceberg.spark.SparkTestBase;\n+import org.junit.After;\n+import org.junit.Before;\n+\n+public abstract class TestIcebergSourceNessieTables extends TestIcebergSourceTablesBase {\n+\n+  private static TableIdentifier currentIdentifier;\n+\n+  private NessieClient client;\n+  private String branch;\n+\n+  private Configuration getConfig() throws IOException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "df32d8e297bd5db0b085972c64e58992284e1ebf"}, "originalPosition": 44}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA2NzQ5MTAx", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-506749101", "createdAt": "2020-10-12T16:07:50Z", "commit": {"oid": "df32d8e297bd5db0b085972c64e58992284e1ebf"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xMlQxNjowNzo1MFrOHgE1DA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xMlQxNjowNzo1MFrOHgE1DA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzM5NTU5Ng==", "bodyText": "We identify Nessie as the core catalog/source when there are specific parameters available on the classpath or hadoop config. The idea here is to be fully backwards compatible w/ Hive and Hadoop catalogs.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r503395596", "createdAt": "2020-10-12T16:07:50Z", "author": {"login": "rymurr"}, "path": "spark2/src/main/java/org/apache/iceberg/spark/source/IcebergSource.java", "diffHunk": "@@ -133,16 +135,29 @@ protected Table findTable(DataSourceOptions options, Configuration conf) {\n     Optional<String> path = options.get(\"path\");\n     Preconditions.checkArgument(path.isPresent(), \"Cannot open table: path is not set\");\n \n-    if (path.get().contains(\"/\")) {\n-      HadoopTables tables = new HadoopTables(conf);\n-      return tables.load(path.get());\n+    if (nessie(options.asMap(), conf)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "df32d8e297bd5db0b085972c64e58992284e1ebf"}, "originalPosition": 16}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA2NzQ5NTQz", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-506749543", "createdAt": "2020-10-12T16:08:30Z", "commit": {"oid": "df32d8e297bd5db0b085972c64e58992284e1ebf"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xMlQxNjowODozMVrOHgE2Ug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xMlQxNjowODozMVrOHgE2Ug==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzM5NTkyMg==", "bodyText": "All Nessie tests are run in their own branch to not interfere with parallel test execution", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r503395922", "createdAt": "2020-10-12T16:08:31Z", "author": {"login": "rymurr"}, "path": "spark3/src/test/java/org/apache/iceberg/spark/SparkCatalogTestBase.java", "diffHunk": "@@ -83,12 +90,40 @@ public static void dropWarehouse() {\n   protected final SupportsNamespaces validationNamespaceCatalog;\n   protected final TableIdentifier tableIdent = TableIdentifier.of(Namespace.of(\"default\"), \"table\");\n   protected final String tableName;\n+  protected NessieClient client;\n+  protected String branch;\n \n   public SparkCatalogTestBase(String catalogName, String implementation, Map<String, String> config) {\n     this.catalogName = catalogName;\n-    this.validationCatalog = catalogName.equals(\"testhadoop\") ?\n-        new HadoopCatalog(spark.sessionState().newHadoopConf(), \"file:\" + warehouse) :\n-        catalog;\n+    switch (catalogName) {\n+      case \"testhadoop\":\n+        this.validationCatalog = new HadoopCatalog(spark.sessionState().newHadoopConf(), \"file:\" + warehouse);\n+        break;\n+      case \"testnessie\":\n+        String path = \"http://localhost:19121/api/v1\";\n+        branch = config.get(\"nessie_ref\");\n+        setHadoopConfig(path, branch);\n+\n+        this.client = new NessieClient(NessieClient.AuthType.NONE, path, null, null);\n+        try {\n+          try {\n+            this.client.getTreeApi().createEmptyBranch(branch);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "df32d8e297bd5db0b085972c64e58992284e1ebf"}, "originalPosition": 56}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA2NzUxMDM1", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-506751035", "createdAt": "2020-10-12T16:10:37Z", "commit": {"oid": "df32d8e297bd5db0b085972c64e58992284e1ebf"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xMlQxNjoxMDozOFrOHgE6zA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xMlQxNjoxMDozOFrOHgE6zA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzM5NzA2OA==", "bodyText": "The concept of a namespace is implicit in Nessie and are therefore not managed through the normal SupportsNamespaces interface. We skip tests of this interface when the catalog is a NessieCatalog.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r503397068", "createdAt": "2020-10-12T16:10:38Z", "author": {"login": "rymurr"}, "path": "spark3/src/test/java/org/apache/iceberg/spark/sql/TestNamespaceSQL.java", "diffHunk": "@@ -56,6 +56,8 @@ public void cleanNamespaces() {\n \n   @Test\n   public void testCreateNamespace() {\n+    // Nessie namespaces are explicit and do not need to be explicitly managed\n+    Assume.assumeFalse(catalogName.endsWith(\"testnessie\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "df32d8e297bd5db0b085972c64e58992284e1ebf"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTA2NzUxOTUx", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-506751951", "createdAt": "2020-10-12T16:11:58Z", "commit": {"oid": "df32d8e297bd5db0b085972c64e58992284e1ebf"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xMlQxNjoxMTo1OFrOHgE9tg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0xMlQxNjoxMTo1OFrOHgE9tg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUwMzM5NzgxNA==", "bodyText": "We do not extend SupportsNamespaces as a Nessie object store supports the concept of namespaces implicitly. A Nessie namespace can be arbitrarily deep but is not explicitly created or stored. Similar to empty folders in git.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r503397814", "createdAt": "2020-10-12T16:11:58Z", "author": {"login": "rymurr"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,340 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.client.NessieClient.AuthType;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableMultiContents;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.MultiContents;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "df32d8e297bd5db0b085972c64e58992284e1ebf"}, "originalPosition": 56}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE2MDMxMzU3", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-516031357", "createdAt": "2020-10-23T21:54:47Z", "commit": {"oid": "834c3549f5709828c633444de3bae63ac9ecbbd5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yM1QyMTo1NDo0OFrOHnfemA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yM1QyMTo1NDo0OFrOHnfemA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE3MjI0OA==", "bodyText": "What's happening in the Nessie plugin?", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r511172248", "createdAt": "2020-10-23T21:54:48Z", "author": {"login": "rdblue"}, "path": "build.gradle", "diffHunk": "@@ -891,6 +924,49 @@ project(':iceberg-pig') {\n   }\n }\n \n+project(':iceberg-nessie') {\n+  apply plugin: 'org.projectnessie'", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "834c3549f5709828c633444de3bae63ac9ecbbd5"}, "originalPosition": 98}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE2MDMyMDMw", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-516032030", "createdAt": "2020-10-23T21:56:29Z", "commit": {"oid": "834c3549f5709828c633444de3bae63ac9ecbbd5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yM1QyMTo1NjoyOVrOHnfg0Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yM1QyMTo1NjoyOVrOHnfg0Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE3MjgxNw==", "bodyText": "From the comments in the Iceberg sync, it sounds like this is running a stand-alone Nessie server? Is that something we could handle like the current Hive MetaStore tests, where each test suite creates a new metastore and tears it down after the suite runs?", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r511172817", "createdAt": "2020-10-23T21:56:29Z", "author": {"login": "rdblue"}, "path": "build.gradle", "diffHunk": "@@ -693,6 +709,8 @@ if (jdkVersion == '8') {\n       // Vectorized reads need more memory\n       maxHeapSize '2500m'\n     }\n+    // start and stop quarkus for nessie tests\n+    tasks.test.dependsOn(\"quarkus-start\").finalizedBy(\"quarkus-stop\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "834c3549f5709828c633444de3bae63ac9ecbbd5"}, "originalPosition": 51}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE2MDM2MTg3", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-516036187", "createdAt": "2020-10-23T22:07:51Z", "commit": {"oid": "834c3549f5709828c633444de3bae63ac9ecbbd5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yM1QyMjowNzo1MVrOHnfuPw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yM1QyMjowNzo1MVrOHnfuPw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE3NjI1NQ==", "bodyText": "Looks like this will return all tables underneath the given namespace, even if they are nested in other namespaces?\nI haven't tested this in spark, does it work as expected?", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r511176255", "createdAt": "2020-10-23T22:07:51Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,333 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableMultiContents;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.MultiContents;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  private static final String ICEBERG_HADOOP_WAREHOUSE_BASE = \"iceberg/warehouse\";\n+  private final NessieClient client;\n+  private final String warehouseLocation;\n+  private final Configuration config;\n+  private final UpdateableReference reference;\n+  private final String name;\n+\n+  /**\n+   * create a catalog from a hadoop configuration.\n+   */\n+  public NessieCatalog(Configuration config) {\n+    this(\"nessie\", config);\n+  }\n+\n+  /**\n+   * create a catalog from a hadoop configuration.\n+   */\n+  public NessieCatalog(Configuration config, String ref) {\n+    this(\"nessie\", config, ref);\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config) {\n+    this(name, config, null);\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref) {\n+    this(name, config, ref, null);\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url) {\n+    this.config = config;\n+    this.name = name;\n+\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    warehouseLocation = getWarehouseLocation();\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private String getWarehouseLocation() {\n+    String nessieWarehouseDir = config.get(\"nessie.warehouse.dir\");\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    String hiveWarehouseDir = config.get(\"hive.metastore.warehouse.dir\");\n+    if (hiveWarehouseDir != null) {\n+      return hiveWarehouseDir;\n+    }\n+    String defaultFS = config.get(\"fs.defaultFS\");\n+    if (defaultFS != null) {\n+      return defaultFS + \"/\" + ICEBERG_HADOOP_WAREHOUSE_BASE;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. \" +\n+        \"Please set one of the following:\\n\" +\n+        \"nessie.warehouse.dir\\n\" +\n+        \"hive.metastore.warehouse.dir\\n\" +\n+        \"fs.defaultFS.\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);\n+      }\n+\n+      throw new IllegalArgumentException(String.format(\"Nessie does not have an existing default branch.\" +\n+        \"Either configure an alternative ref via %s or create the default branch on the server.\",\n+          NessieClient.CONF_NESSIE_REF), ex);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  private static ContentsKey toKey(TableIdentifier tableIdentifier) {\n+    List<String> identifiers = new ArrayList<>();\n+    if (tableIdentifier.hasNamespace()) {\n+      identifiers.addAll(Arrays.asList(tableIdentifier.namespace().levels()));\n+    }\n+    identifiers.add(tableIdentifier.name());\n+\n+    ContentsKey key = new ContentsKey(identifiers);\n+    return key;\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {\n+        return (IcebergTable) table;\n+      }\n+    } catch (NessieNotFoundException e) {\n+      // ignore\n+    }\n+    return null;\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(tableIdentifier, new HashMap<>());\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = get(pti.getReference());\n+    }\n+    return new NessieTableOperations(config,\n+                                     toKey(pti.getTableIdentifier()),\n+                                     newReference,\n+                                     client);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    try {\n+      return client.getTreeApi()\n+          .getEntries(reference.getHash())\n+          .getEntries()\n+          .stream()\n+          .filter(namespacePredicate(namespace))\n+          .map(NessieCatalog::toIdentifier)\n+          .collect(Collectors.toList());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "834c3549f5709828c633444de3bae63ac9ecbbd5"}, "originalPosition": 214}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE2MDM2MzU2", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-516036356", "createdAt": "2020-10-23T22:08:23Z", "commit": {"oid": "834c3549f5709828c633444de3bae63ac9ecbbd5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yM1QyMjowODoyNFrOHnfuyw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yM1QyMjowODoyNFrOHnfuyw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE3NjM5NQ==", "bodyText": "Probably shouldn't use RuntimeException here. How about NoSuchNamespaceException?", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r511176395", "createdAt": "2020-10-23T22:08:24Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,333 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableMultiContents;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.MultiContents;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  private static final String ICEBERG_HADOOP_WAREHOUSE_BASE = \"iceberg/warehouse\";\n+  private final NessieClient client;\n+  private final String warehouseLocation;\n+  private final Configuration config;\n+  private final UpdateableReference reference;\n+  private final String name;\n+\n+  /**\n+   * create a catalog from a hadoop configuration.\n+   */\n+  public NessieCatalog(Configuration config) {\n+    this(\"nessie\", config);\n+  }\n+\n+  /**\n+   * create a catalog from a hadoop configuration.\n+   */\n+  public NessieCatalog(Configuration config, String ref) {\n+    this(\"nessie\", config, ref);\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config) {\n+    this(name, config, null);\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref) {\n+    this(name, config, ref, null);\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url) {\n+    this.config = config;\n+    this.name = name;\n+\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    warehouseLocation = getWarehouseLocation();\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private String getWarehouseLocation() {\n+    String nessieWarehouseDir = config.get(\"nessie.warehouse.dir\");\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    String hiveWarehouseDir = config.get(\"hive.metastore.warehouse.dir\");\n+    if (hiveWarehouseDir != null) {\n+      return hiveWarehouseDir;\n+    }\n+    String defaultFS = config.get(\"fs.defaultFS\");\n+    if (defaultFS != null) {\n+      return defaultFS + \"/\" + ICEBERG_HADOOP_WAREHOUSE_BASE;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. \" +\n+        \"Please set one of the following:\\n\" +\n+        \"nessie.warehouse.dir\\n\" +\n+        \"hive.metastore.warehouse.dir\\n\" +\n+        \"fs.defaultFS.\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);\n+      }\n+\n+      throw new IllegalArgumentException(String.format(\"Nessie does not have an existing default branch.\" +\n+        \"Either configure an alternative ref via %s or create the default branch on the server.\",\n+          NessieClient.CONF_NESSIE_REF), ex);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  private static ContentsKey toKey(TableIdentifier tableIdentifier) {\n+    List<String> identifiers = new ArrayList<>();\n+    if (tableIdentifier.hasNamespace()) {\n+      identifiers.addAll(Arrays.asList(tableIdentifier.namespace().levels()));\n+    }\n+    identifiers.add(tableIdentifier.name());\n+\n+    ContentsKey key = new ContentsKey(identifiers);\n+    return key;\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {\n+        return (IcebergTable) table;\n+      }\n+    } catch (NessieNotFoundException e) {\n+      // ignore\n+    }\n+    return null;\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(tableIdentifier, new HashMap<>());\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = get(pti.getReference());\n+    }\n+    return new NessieTableOperations(config,\n+                                     toKey(pti.getTableIdentifier()),\n+                                     newReference,\n+                                     client);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    try {\n+      return client.getTreeApi()\n+          .getEntries(reference.getHash())\n+          .getEntries()\n+          .stream()\n+          .filter(namespacePredicate(namespace))\n+          .map(NessieCatalog::toIdentifier)\n+          .collect(Collectors.toList());\n+    } catch (NessieNotFoundException ex) {\n+      throw new RuntimeException(\"Unable to list tables due to missing ref.\", ex);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "834c3549f5709828c633444de3bae63ac9ecbbd5"}, "originalPosition": 216}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE2MDM3OTI5", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-516037929", "createdAt": "2020-10-23T22:13:03Z", "commit": {"oid": "834c3549f5709828c633444de3bae63ac9ecbbd5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yM1QyMjoxMzowM1rOHnfzzA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yM1QyMjoxMzowM1rOHnfzzA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE3NzY3Ng==", "bodyText": "Style: Most Iceberg error messages use the form Cannot <some action>: <reason> (<workaround>). Consistency here tends to make at least Iceberg errors more readable and easy to consume.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r511177676", "createdAt": "2020-10-23T22:13:03Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java", "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableIcebergTable;\n+import java.lang.reflect.Method;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+\n+/**\n+ * Nessie implementation of Iceberg TableOperations.\n+ */\n+public class NessieTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static Method sparkConfMethod;\n+  private static Method appIdMethod;\n+  private static Method sparkEnvMethod;\n+\n+  private final Configuration conf;\n+  private final NessieClient client;\n+  private final ContentsKey key;\n+  private UpdateableReference reference;\n+  private IcebergTable table;\n+  private HadoopFileIO fileIO;\n+\n+  /**\n+   * Create a nessie table operations given a table identifier.\n+   */\n+  public NessieTableOperations(\n+      Configuration conf,\n+      ContentsKey key,\n+      UpdateableReference reference,\n+      NessieClient client) {\n+    this.conf = conf;\n+    this.key = key;\n+    this.reference = reference;\n+    this.client = client;\n+  }\n+\n+  @Override\n+  protected void doRefresh() {\n+    // break reference with parent (to avoid cross-over refresh)\n+    // TODO, confirm this is correct behavior.\n+    // reference = reference.copy();\n+\n+    reference.refresh();\n+    String metadataLocation = null;\n+    try {\n+      Contents contents = client.getContentsApi().getContents(key, reference.getHash());\n+      this.table = contents.unwrap(IcebergTable.class)\n+          .orElseThrow(() -> new IllegalStateException(\"Nessie points to a non-Iceberg object for that path.\"));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "834c3549f5709828c633444de3bae63ac9ecbbd5"}, "originalPosition": 78}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE2MDM5MjEy", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-516039212", "createdAt": "2020-10-23T22:16:53Z", "commit": {"oid": "834c3549f5709828c633444de3bae63ac9ecbbd5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yM1QyMjoxNjo1M1rOHnf33Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yM1QyMjoxNjo1M1rOHnf33Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE3ODcxNw==", "bodyText": "I think this should throw NoSuchTableException if the existing metadata is not null because the table was deleted under the reference. You'll probably want to follow the same behavior as the Hive catalog.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r511178717", "createdAt": "2020-10-23T22:16:53Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java", "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableIcebergTable;\n+import java.lang.reflect.Method;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+\n+/**\n+ * Nessie implementation of Iceberg TableOperations.\n+ */\n+public class NessieTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static Method sparkConfMethod;\n+  private static Method appIdMethod;\n+  private static Method sparkEnvMethod;\n+\n+  private final Configuration conf;\n+  private final NessieClient client;\n+  private final ContentsKey key;\n+  private UpdateableReference reference;\n+  private IcebergTable table;\n+  private HadoopFileIO fileIO;\n+\n+  /**\n+   * Create a nessie table operations given a table identifier.\n+   */\n+  public NessieTableOperations(\n+      Configuration conf,\n+      ContentsKey key,\n+      UpdateableReference reference,\n+      NessieClient client) {\n+    this.conf = conf;\n+    this.key = key;\n+    this.reference = reference;\n+    this.client = client;\n+  }\n+\n+  @Override\n+  protected void doRefresh() {\n+    // break reference with parent (to avoid cross-over refresh)\n+    // TODO, confirm this is correct behavior.\n+    // reference = reference.copy();\n+\n+    reference.refresh();\n+    String metadataLocation = null;\n+    try {\n+      Contents contents = client.getContentsApi().getContents(key, reference.getHash());\n+      this.table = contents.unwrap(IcebergTable.class)\n+          .orElseThrow(() -> new IllegalStateException(\"Nessie points to a non-Iceberg object for that path.\"));\n+      metadataLocation = table.getMetadataLocation();\n+    } catch (NessieNotFoundException ex) {\n+      this.table = null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "834c3549f5709828c633444de3bae63ac9ecbbd5"}, "originalPosition": 81}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE2MDM5NDc5", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-516039479", "createdAt": "2020-10-23T22:17:35Z", "commit": {"oid": "834c3549f5709828c633444de3bae63ac9ecbbd5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yM1QyMjoxNzozNlrOHnf4qA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yM1QyMjoxNzozNlrOHnf4qA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE3ODkyMA==", "bodyText": "Doesn't look like the format here is quite correct. Missing a space?", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r511178920", "createdAt": "2020-10-23T22:17:36Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java", "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableIcebergTable;\n+import java.lang.reflect.Method;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+\n+/**\n+ * Nessie implementation of Iceberg TableOperations.\n+ */\n+public class NessieTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static Method sparkConfMethod;\n+  private static Method appIdMethod;\n+  private static Method sparkEnvMethod;\n+\n+  private final Configuration conf;\n+  private final NessieClient client;\n+  private final ContentsKey key;\n+  private UpdateableReference reference;\n+  private IcebergTable table;\n+  private HadoopFileIO fileIO;\n+\n+  /**\n+   * Create a nessie table operations given a table identifier.\n+   */\n+  public NessieTableOperations(\n+      Configuration conf,\n+      ContentsKey key,\n+      UpdateableReference reference,\n+      NessieClient client) {\n+    this.conf = conf;\n+    this.key = key;\n+    this.reference = reference;\n+    this.client = client;\n+  }\n+\n+  @Override\n+  protected void doRefresh() {\n+    // break reference with parent (to avoid cross-over refresh)\n+    // TODO, confirm this is correct behavior.\n+    // reference = reference.copy();\n+\n+    reference.refresh();\n+    String metadataLocation = null;\n+    try {\n+      Contents contents = client.getContentsApi().getContents(key, reference.getHash());\n+      this.table = contents.unwrap(IcebergTable.class)\n+          .orElseThrow(() -> new IllegalStateException(\"Nessie points to a non-Iceberg object for that path.\"));\n+      metadataLocation = table.getMetadataLocation();\n+    } catch (NessieNotFoundException ex) {\n+      this.table = null;\n+    }\n+    refreshFromMetadataLocation(metadataLocation, 2);\n+  }\n+\n+  @Override\n+  protected void doCommit(TableMetadata base, TableMetadata metadata) {\n+    reference.checkMutable();\n+\n+    String newMetadataLocation = writeNewMetadata(metadata, currentVersion() + 1);\n+\n+    try {\n+      IcebergTable newTable = ImmutableIcebergTable.builder().metadataLocation(newMetadataLocation).build();\n+      client.getContentsApi().setContents(key,\n+                                          reference.getAsBranch().getName(),\n+                                          reference.getHash(),\n+                                          String.format(\"iceberg commit%s\", applicationId()),", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "834c3549f5709828c633444de3bae63ac9ecbbd5"}, "originalPosition": 97}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE2MDM5Njkx", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-516039691", "createdAt": "2020-10-23T22:18:12Z", "commit": {"oid": "834c3549f5709828c633444de3bae63ac9ecbbd5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yM1QyMjoxODoxMlrOHnf5OQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yM1QyMjoxODoxMlrOHnf5OQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE3OTA2NQ==", "bodyText": "Is this right for NotFoundException? Iceberg will retry failed commits.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r511179065", "createdAt": "2020-10-23T22:18:12Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java", "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableIcebergTable;\n+import java.lang.reflect.Method;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+\n+/**\n+ * Nessie implementation of Iceberg TableOperations.\n+ */\n+public class NessieTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static Method sparkConfMethod;\n+  private static Method appIdMethod;\n+  private static Method sparkEnvMethod;\n+\n+  private final Configuration conf;\n+  private final NessieClient client;\n+  private final ContentsKey key;\n+  private UpdateableReference reference;\n+  private IcebergTable table;\n+  private HadoopFileIO fileIO;\n+\n+  /**\n+   * Create a nessie table operations given a table identifier.\n+   */\n+  public NessieTableOperations(\n+      Configuration conf,\n+      ContentsKey key,\n+      UpdateableReference reference,\n+      NessieClient client) {\n+    this.conf = conf;\n+    this.key = key;\n+    this.reference = reference;\n+    this.client = client;\n+  }\n+\n+  @Override\n+  protected void doRefresh() {\n+    // break reference with parent (to avoid cross-over refresh)\n+    // TODO, confirm this is correct behavior.\n+    // reference = reference.copy();\n+\n+    reference.refresh();\n+    String metadataLocation = null;\n+    try {\n+      Contents contents = client.getContentsApi().getContents(key, reference.getHash());\n+      this.table = contents.unwrap(IcebergTable.class)\n+          .orElseThrow(() -> new IllegalStateException(\"Nessie points to a non-Iceberg object for that path.\"));\n+      metadataLocation = table.getMetadataLocation();\n+    } catch (NessieNotFoundException ex) {\n+      this.table = null;\n+    }\n+    refreshFromMetadataLocation(metadataLocation, 2);\n+  }\n+\n+  @Override\n+  protected void doCommit(TableMetadata base, TableMetadata metadata) {\n+    reference.checkMutable();\n+\n+    String newMetadataLocation = writeNewMetadata(metadata, currentVersion() + 1);\n+\n+    try {\n+      IcebergTable newTable = ImmutableIcebergTable.builder().metadataLocation(newMetadataLocation).build();\n+      client.getContentsApi().setContents(key,\n+                                          reference.getAsBranch().getName(),\n+                                          reference.getHash(),\n+                                          String.format(\"iceberg commit%s\", applicationId()),\n+                                          newTable);\n+    } catch (NessieNotFoundException | NessieConflictException ex) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "834c3549f5709828c633444de3bae63ac9ecbbd5"}, "originalPosition": 99}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE2MDM5OTEw", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-516039910", "createdAt": "2020-10-23T22:18:52Z", "commit": {"oid": "834c3549f5709828c633444de3bae63ac9ecbbd5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yM1QyMjoxODo1MlrOHnf54w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yM1QyMjoxODo1MlrOHnf54w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE3OTIzNQ==", "bodyText": "You can use the DynFields helpers to do this a bit more easily.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r511179235", "createdAt": "2020-10-23T22:18:52Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java", "diffHunk": "@@ -0,0 +1,142 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableIcebergTable;\n+import java.lang.reflect.Method;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+\n+/**\n+ * Nessie implementation of Iceberg TableOperations.\n+ */\n+public class NessieTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static Method sparkConfMethod;\n+  private static Method appIdMethod;\n+  private static Method sparkEnvMethod;\n+\n+  private final Configuration conf;\n+  private final NessieClient client;\n+  private final ContentsKey key;\n+  private UpdateableReference reference;\n+  private IcebergTable table;\n+  private HadoopFileIO fileIO;\n+\n+  /**\n+   * Create a nessie table operations given a table identifier.\n+   */\n+  public NessieTableOperations(\n+      Configuration conf,\n+      ContentsKey key,\n+      UpdateableReference reference,\n+      NessieClient client) {\n+    this.conf = conf;\n+    this.key = key;\n+    this.reference = reference;\n+    this.client = client;\n+  }\n+\n+  @Override\n+  protected void doRefresh() {\n+    // break reference with parent (to avoid cross-over refresh)\n+    // TODO, confirm this is correct behavior.\n+    // reference = reference.copy();\n+\n+    reference.refresh();\n+    String metadataLocation = null;\n+    try {\n+      Contents contents = client.getContentsApi().getContents(key, reference.getHash());\n+      this.table = contents.unwrap(IcebergTable.class)\n+          .orElseThrow(() -> new IllegalStateException(\"Nessie points to a non-Iceberg object for that path.\"));\n+      metadataLocation = table.getMetadataLocation();\n+    } catch (NessieNotFoundException ex) {\n+      this.table = null;\n+    }\n+    refreshFromMetadataLocation(metadataLocation, 2);\n+  }\n+\n+  @Override\n+  protected void doCommit(TableMetadata base, TableMetadata metadata) {\n+    reference.checkMutable();\n+\n+    String newMetadataLocation = writeNewMetadata(metadata, currentVersion() + 1);\n+\n+    try {\n+      IcebergTable newTable = ImmutableIcebergTable.builder().metadataLocation(newMetadataLocation).build();\n+      client.getContentsApi().setContents(key,\n+                                          reference.getAsBranch().getName(),\n+                                          reference.getHash(),\n+                                          String.format(\"iceberg commit%s\", applicationId()),\n+                                          newTable);\n+    } catch (NessieNotFoundException | NessieConflictException ex) {\n+      io().deleteFile(newMetadataLocation);\n+      throw new CommitFailedException(ex, \"failed\");\n+    } catch (Throwable e) {\n+      io().deleteFile(newMetadataLocation);\n+      throw new RuntimeException(\"Unexpected commit exception\", e);\n+    }\n+  }\n+\n+  @Override\n+  public FileIO io() {\n+    if (fileIO == null) {\n+      fileIO = new HadoopFileIO(conf);\n+    }\n+\n+    return fileIO;\n+  }\n+\n+  /**\n+   * try and get a Spark application id if one exists.\n+   *\n+   * <p>\n+   *   We haven't figured out a general way to pass commit messages through to the Nessie committer yet.\n+   *   This is hacky but gets the job done until we can have a more complete commit/audit log.\n+   * </p>\n+   */\n+  private static String applicationId() {\n+    try {\n+      if (sparkConfMethod == null) {\n+        Class sparkEnvClazz = Class.forName(\"org.apache.spark.SparkEnv\");\n+        sparkEnvMethod = sparkEnvClazz.getMethod(\"get\");\n+        Class sparkConfClazz = Class.forName(\"org.apache.spark.SparkConf\");\n+        sparkConfMethod = sparkEnvClazz.getMethod(\"conf\");\n+        appIdMethod = sparkConfClazz.getMethod(\"getAppId\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "834c3549f5709828c633444de3bae63ac9ecbbd5"}, "originalPosition": 132}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE2MDQxMDg5", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-516041089", "createdAt": "2020-10-23T22:22:45Z", "commit": {"oid": "834c3549f5709828c633444de3bae63ac9ecbbd5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yM1QyMjoyMjo0NVrOHnf90w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yM1QyMjoyMjo0NVrOHnf90w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE4MDI0Mw==", "bodyText": "We prefer using AssertHelpers.assertThrows so that state after the exception was thrown can be validated. For example, testing catalog.createTable(invalid) would not only check ValidationException but also verify that the table was not created.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r511180243", "createdAt": "2020-10-23T22:22:45Z", "author": {"login": "rdblue"}, "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestParsedTableIdentifier.java", "diffHunk": "@@ -0,0 +1,143 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import java.util.HashMap;\n+import java.util.Map;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestParsedTableIdentifier {\n+\n+\n+  @Test\n+  public void noMarkings() {\n+    String path = \"foo\";\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(path, new HashMap<>());\n+    Assert.assertEquals(path, pti.getTableIdentifier().name());\n+    Assert.assertNull(pti.getReference());\n+    Assert.assertNull(pti.getTimestamp());\n+  }\n+\n+  @Test\n+  public void branchOnly() {\n+    String path = \"foo@bar\";\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(path, new HashMap<>());\n+    Assert.assertEquals(\"foo\", pti.getTableIdentifier().name());\n+    Assert.assertEquals(\"bar\", pti.getReference());\n+    Assert.assertNull(pti.getTimestamp());\n+  }\n+\n+  @Test(expected = IllegalArgumentException.class)\n+  public void timestampOnly() {\n+    String path = \"foo#baz\";\n+    ParsedTableIdentifier.getParsedTableIdentifier(path, new HashMap<>());\n+  }\n+\n+  @Test(expected = IllegalArgumentException.class)\n+  public void branchAndTimestamp() {\n+    String path = \"foo@bar#baz\";\n+    ParsedTableIdentifier.getParsedTableIdentifier(path, new HashMap<>());\n+  }\n+\n+  @Test(expected = IllegalArgumentException.class)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "834c3549f5709828c633444de3bae63ac9ecbbd5"}, "originalPosition": 61}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE2MDQyNjYx", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-516042661", "createdAt": "2020-10-23T22:27:29Z", "commit": {"oid": "834c3549f5709828c633444de3bae63ac9ecbbd5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yM1QyMjoyNzoyOVrOHngDKg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yM1QyMjoyNzoyOVrOHngDKg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE4MTYxMA==", "bodyText": "Please have a look at #1640, I'd like to standardize how we do this. I do like using type = nessie, so we may want to have a lookup that points to the NessieCatalog implementation.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r511181610", "createdAt": "2020-10-23T22:27:29Z", "author": {"login": "rdblue"}, "path": "spark3/src/main/java/org/apache/iceberg/spark/SparkCatalog.java", "diffHunk": "@@ -103,6 +106,10 @@ protected Catalog buildIcebergCatalog(String name, CaseInsensitiveStringMap opti\n         String warehouseLocation = options.get(\"warehouse\");\n         return new HadoopCatalog(name, conf, warehouseLocation);\n \n+      case \"nessie\":\n+        String defaultBranch = options.getOrDefault(\"nessie_ref\", \"main\");\n+        String nessieUrl = options.get(\"nessie_url\");\n+        return new NessieCatalog(name, conf, defaultBranch, nessieUrl);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "834c3549f5709828c633444de3bae63ac9ecbbd5"}, "originalPosition": 33}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTE2MDQzMDE0", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-516043014", "createdAt": "2020-10-23T22:28:37Z", "commit": {"oid": "834c3549f5709828c633444de3bae63ac9ecbbd5"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yM1QyMjoyODozN1rOHngEVQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMC0yM1QyMjoyODozN1rOHngEVQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxMTE4MTkwOQ==", "bodyText": "Why was this needed?", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r511181909", "createdAt": "2020-10-23T22:28:37Z", "author": {"login": "rdblue"}, "path": "spark3/src/test/java/org/apache/iceberg/spark/sql/TestCreateTableAsSelect.java", "diffHunk": "@@ -50,6 +50,7 @@ public TestCreateTableAsSelect(String catalogName, String implementation, Map<St\n   @After\n   public void removeTables() {\n     sql(\"DROP TABLE IF EXISTS %s\", tableName);\n+    sql(\"DROP TABLE IF EXISTS %s\", sourceName);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "834c3549f5709828c633444de3bae63ac9ecbbd5"}, "originalPosition": 4}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "834c3549f5709828c633444de3bae63ac9ecbbd5", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/834c3549f5709828c633444de3bae63ac9ecbbd5", "committedDate": "2020-10-12T16:30:37Z", "message": "tidy up"}, "afterCommit": {"oid": "da33d558c0f1a283f8315dbea9fba82824dfa600", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/da33d558c0f1a283f8315dbea9fba82824dfa600", "committedDate": "2020-10-26T18:09:38Z", "message": "some more updates for code review"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "da33d558c0f1a283f8315dbea9fba82824dfa600", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/da33d558c0f1a283f8315dbea9fba82824dfa600", "committedDate": "2020-10-26T18:09:38Z", "message": "some more updates for code review"}, "afterCommit": {"oid": "4ac611f4b827b2216be431c2c28a1e80349b9b60", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/4ac611f4b827b2216be431c2c28a1e80349b9b60", "committedDate": "2020-10-30T23:44:33Z", "message": "fix tests and bump plugin version"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "4ac611f4b827b2216be431c2c28a1e80349b9b60", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/4ac611f4b827b2216be431c2c28a1e80349b9b60", "committedDate": "2020-10-30T23:44:33Z", "message": "fix tests and bump plugin version"}, "afterCommit": {"oid": "31ddd6b77be8814008663d1aafdf01e373e1b372", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/31ddd6b77be8814008663d1aafdf01e373e1b372", "committedDate": "2020-11-05T14:21:20Z", "message": "update to support #1640"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI1NTgyMjI3", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-525582227", "createdAt": "2020-11-07T02:05:00Z", "commit": {"oid": "31ddd6b77be8814008663d1aafdf01e373e1b372"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QwMjowNTowMFrOHvCOJA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0wN1QwMjowNTowMFrOHvCOJA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUxOTA4MTUwOA==", "bodyText": "For Spark writes, we pass the application ID in through snapshot.summary(): \n  \n    \n      iceberg/spark3/src/main/java/org/apache/iceberg/spark/source/SparkBatchWrite.java\n    \n    \n         Line 153\n      in\n      9af545e\n    \n    \n    \n    \n\n        \n          \n           operation.set(\"spark.app.id\", applicationId);", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r519081508", "createdAt": "2020-11-07T02:05:00Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableIcebergTable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.common.DynFields;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+\n+/**\n+ * Nessie implementation of Iceberg TableOperations.\n+ */\n+public class NessieTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static DynFields.StaticField<Object> sparkEnvMethod;\n+  private static DynFields.UnboundField<Object> sparkConfMethod;\n+  private static DynFields.UnboundField<Object> appIdMethod;\n+  private final Configuration conf;\n+  private final NessieClient client;\n+  private final ContentsKey key;\n+  private UpdateableReference reference;\n+  private IcebergTable table;\n+  private HadoopFileIO fileIO;\n+\n+  /**\n+   * Create a nessie table operations given a table identifier.\n+   */\n+  public NessieTableOperations(\n+      Configuration conf,\n+      ContentsKey key,\n+      UpdateableReference reference,\n+      NessieClient client) {\n+    this.conf = conf;\n+    this.key = key;\n+    this.reference = reference;\n+    this.client = client;\n+  }\n+\n+  @Override\n+  protected void doRefresh() {\n+    // break reference with parent (to avoid cross-over refresh)\n+    // TODO, confirm this is correct behavior.\n+    // reference = reference.copy();\n+\n+    reference.refresh();\n+    String metadataLocation = null;\n+    try {\n+      Contents contents = client.getContentsApi().getContents(key, reference.getHash());\n+      this.table = contents.unwrap(IcebergTable.class)\n+          .orElseThrow(() ->\n+              new IllegalStateException(\"Cannot refresh iceberg table: \" +\n+                  String.format(\"Nessie points to a non-Iceberg object for path: %s.\", key)));\n+      metadataLocation = table.getMetadataLocation();\n+    } catch (NessieNotFoundException ex) {\n+      if (currentMetadataLocation() != null) {\n+        throw new NoSuchTableException(ex, \"No such table %s\", key);\n+      }\n+    }\n+    refreshFromMetadataLocation(metadataLocation, 2);\n+  }\n+\n+  @Override\n+  protected void doCommit(TableMetadata base, TableMetadata metadata) {\n+    reference.checkMutable();\n+\n+    String newMetadataLocation = writeNewMetadata(metadata, currentVersion() + 1);\n+\n+    try {\n+      IcebergTable newTable = ImmutableIcebergTable.builder().metadataLocation(newMetadataLocation).build();\n+      client.getContentsApi().setContents(key,\n+                                          reference.getAsBranch().getName(),\n+                                          reference.getHash(),\n+                                          String.format(\"iceberg commit%s\", applicationId()),\n+                                          newTable);\n+    } catch (NessieConflictException ex) {\n+      io().deleteFile(newMetadataLocation);\n+      String fixMsg = reference.isBranch() ?\n+          String.format(\"Update the reference %s and try again\", reference.getName()) :\n+          String.format(\"Can't commit to the tag %s\", reference.getName());\n+      throw new CommitFailedException(ex, \"Commit failed: Reference hash is out of date. %s\", fixMsg);\n+    } catch (NessieNotFoundException ex) {\n+      io().deleteFile(newMetadataLocation);\n+      throw new RuntimeException(String.format(\"Commit failed: Reference %s does not exist\", reference.getName()), ex);\n+    } catch (Throwable e) {\n+      io().deleteFile(newMetadataLocation);\n+      throw new RuntimeException(\"Unexpected commit exception\", e);\n+    }\n+  }\n+\n+  @Override\n+  public FileIO io() {\n+    if (fileIO == null) {\n+      fileIO = new HadoopFileIO(conf);\n+    }\n+\n+    return fileIO;\n+  }\n+\n+  /**\n+   * try and get a Spark application id if one exists.\n+   *\n+   * <p>\n+   *   We haven't figured out a general way to pass commit messages through to the Nessie committer yet.\n+   *   This is hacky but gets the job done until we can have a more complete commit/audit log.\n+   * </p>\n+   */\n+  private static String applicationId() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "31ddd6b77be8814008663d1aafdf01e373e1b372"}, "originalPosition": 135}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "31ddd6b77be8814008663d1aafdf01e373e1b372", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/31ddd6b77be8814008663d1aafdf01e373e1b372", "committedDate": "2020-11-05T14:21:20Z", "message": "update to support #1640"}, "afterCommit": {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/6eba2838dd053690f7f0e66ed0f3095147465a58", "committedDate": "2020-11-09T12:44:51Z", "message": "simpler way to get spark app id"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3NTI5MzUw", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-527529350", "createdAt": "2020-11-10T19:16:12Z", "commit": {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxOToxNjoxMlrOHwr6xw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxOToxNjoxMlrOHwr6xw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxMzI1NQ==", "bodyText": "#1640 is in. It uses a no-arg constructor and adds an initialize(String name, Map<String, String> config) method to initialize and configure the catalog. I think you should be able to update this now.\nI'm hoping that this removes the need to make Spark and Flink depend on the new Nessie and Glue modules. We should make sure we have a test suite we can include here that uses Flink and Spark.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520813255", "createdAt": "2020-11-10T19:16:12Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58"}, "originalPosition": 82}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3NTMwNzc2", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-527530776", "createdAt": "2020-11-10T19:18:09Z", "commit": {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxOToxODowOVrOHwr_KQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxOToxODowOVrOHwr_KQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxNDM3Nw==", "bodyText": "I don't think that any configuration should come from the Hadoop Configuration unless it is used for a Hadoop component, like HadoopFileIO. Can you initialize this from the catalog config passed to initialize?", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520814377", "createdAt": "2020-11-10T19:18:09Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private static String getWarehouseLocation(Configuration config) {\n+    String nessieWarehouseDir = config.get(NESSIE_WAREHOUSE_DIR);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58"}, "originalPosition": 111}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3NTMxOTg0", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-527531984", "createdAt": "2020-11-10T19:19:45Z", "commit": {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxOToxOTo0NVrOHwsDAw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxOToxOTo0NVrOHwsDAw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxNTM2Mw==", "bodyText": "This error message could easily be incorrect because it doesn't use CONF_NESSIE_REF directly. It assumes the caller did.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520815363", "createdAt": "2020-11-10T19:19:45Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private static String getWarehouseLocation(Configuration config) {\n+    String nessieWarehouseDir = config.get(NESSIE_WAREHOUSE_DIR);\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. Please set nessie.warehouse.dir\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58"}, "originalPosition": 126}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3NTMyODEy", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-527532812", "createdAt": "2020-11-10T19:20:56Z", "commit": {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxOToyMDo1N1rOHwsFsg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxOToyMDo1N1rOHwsFsg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxNjA1MA==", "bodyText": "Here as well, I don't think this should pull config from Configuration.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520816050", "createdAt": "2020-11-10T19:20:57Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58"}, "originalPosition": 101}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3NTMzMjQw", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-527533240", "createdAt": "2020-11-10T19:21:32Z", "commit": {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxOToyMTozMlrOHwsG6g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxOToyMTozMlrOHwsG6g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxNjM2Mg==", "bodyText": "Looks like reference must never be null, correct?", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520816362", "createdAt": "2020-11-10T19:21:32Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58"}, "originalPosition": 107}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3NTM0MjA3", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-527534207", "createdAt": "2020-11-10T19:22:54Z", "commit": {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxOToyMjo1NFrOHwsJ9w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxOToyMjo1NFrOHwsJ9w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxNzE0Mw==", "bodyText": "I think it would be helpful for get to have a better name for uses like this. What about findReference or loadReference?", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520817143", "createdAt": "2020-11-10T19:22:54Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private static String getWarehouseLocation(Configuration config) {\n+    String nessieWarehouseDir = config.get(NESSIE_WAREHOUSE_DIR);\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. Please set nessie.warehouse.dir\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);\n+      }\n+\n+      throw new IllegalArgumentException(String.format(\"Nessie does not have an existing default branch.\" +\n+        \"Either configure an alternative ref via %s or create the default branch on the server.\",\n+          NessieClient.CONF_NESSIE_REF), ex);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  private static ContentsKey toKey(TableIdentifier tableIdentifier) {\n+    List<String> identifiers = new ArrayList<>();\n+    if (tableIdentifier.hasNamespace()) {\n+      identifiers.addAll(Arrays.asList(tableIdentifier.namespace().levels()));\n+    }\n+    identifiers.add(tableIdentifier.name());\n+\n+    ContentsKey key = new ContentsKey(identifiers);\n+    return key;\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {\n+        return (IcebergTable) table;\n+      }\n+    } catch (NessieNotFoundException e) {\n+      // ignore\n+    }\n+    return null;\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(tableIdentifier, new HashMap<>());\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = get(pti.getReference());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58"}, "originalPosition": 174}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3NTM1MTQ4", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-527535148", "createdAt": "2020-11-10T19:24:13Z", "commit": {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxOToyNDoxM1rOHwsMxQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxOToyNDoxM1rOHwsMxQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxNzg2MQ==", "bodyText": "How about passing ImmutableMap.of() instead of new HashMap<>()? That avoids unnecessary object creation. Better yet, what about a version of this that doesn't need to pass a map if there isn't one?", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520817861", "createdAt": "2020-11-10T19:24:13Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private static String getWarehouseLocation(Configuration config) {\n+    String nessieWarehouseDir = config.get(NESSIE_WAREHOUSE_DIR);\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. Please set nessie.warehouse.dir\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);\n+      }\n+\n+      throw new IllegalArgumentException(String.format(\"Nessie does not have an existing default branch.\" +\n+        \"Either configure an alternative ref via %s or create the default branch on the server.\",\n+          NessieClient.CONF_NESSIE_REF), ex);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  private static ContentsKey toKey(TableIdentifier tableIdentifier) {\n+    List<String> identifiers = new ArrayList<>();\n+    if (tableIdentifier.hasNamespace()) {\n+      identifiers.addAll(Arrays.asList(tableIdentifier.namespace().levels()));\n+    }\n+    identifiers.add(tableIdentifier.name());\n+\n+    ContentsKey key = new ContentsKey(identifiers);\n+    return key;\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {\n+        return (IcebergTable) table;\n+      }\n+    } catch (NessieNotFoundException e) {\n+      // ignore\n+    }\n+    return null;\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(tableIdentifier, new HashMap<>());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58"}, "originalPosition": 171}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3NTM3MzA4", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-527537308", "createdAt": "2020-11-10T19:27:11Z", "commit": {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxOToyNzoxMVrOHwsTZw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxOToyNzoxMVrOHwsTZw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxOTU1OQ==", "bodyText": "Is this assuming that the NessieNotFoundException is referring to the ref because the table was loaded just above? Or is that always used for a ref?", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520819559", "createdAt": "2020-11-10T19:27:11Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private static String getWarehouseLocation(Configuration config) {\n+    String nessieWarehouseDir = config.get(NESSIE_WAREHOUSE_DIR);\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. Please set nessie.warehouse.dir\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);\n+      }\n+\n+      throw new IllegalArgumentException(String.format(\"Nessie does not have an existing default branch.\" +\n+        \"Either configure an alternative ref via %s or create the default branch on the server.\",\n+          NessieClient.CONF_NESSIE_REF), ex);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  private static ContentsKey toKey(TableIdentifier tableIdentifier) {\n+    List<String> identifiers = new ArrayList<>();\n+    if (tableIdentifier.hasNamespace()) {\n+      identifiers.addAll(Arrays.asList(tableIdentifier.namespace().levels()));\n+    }\n+    identifiers.add(tableIdentifier.name());\n+\n+    ContentsKey key = new ContentsKey(identifiers);\n+    return key;\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {\n+        return (IcebergTable) table;\n+      }\n+    } catch (NessieNotFoundException e) {\n+      // ignore\n+    }\n+    return null;\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(tableIdentifier, new HashMap<>());\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = get(pti.getReference());\n+    }\n+    return new NessieTableOperations(config,\n+                                     toKey(pti.getTableIdentifier()),\n+                                     newReference,\n+                                     client);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  private Stream<TableIdentifier> tableStream(Namespace namespace) {\n+    try {\n+      return client.getTreeApi()\n+          .getEntries(reference.getHash())\n+          .getEntries()\n+          .stream()\n+          .filter(namespacePredicate(namespace))\n+          .map(NessieCatalog::toIdentifier);\n+    } catch (NessieNotFoundException ex) {\n+      throw new NoSuchNamespaceException(ex, \"Unable to list tables due to missing ref. %s\", reference.getName());\n+    }\n+  }\n+\n+  private static Predicate<EntriesResponse.Entry> namespacePredicate(Namespace ns) {\n+    // TODO: filter to just iceberg tables.\n+    if (ns == null) {\n+      return e -> true;\n+    }\n+\n+    final List<String> namespace = Arrays.asList(ns.levels());\n+    Predicate<EntriesResponse.Entry> predicate = e -> {\n+      List<String> names = e.getName().getElements();\n+\n+      if (names.size() <= namespace.size()) {\n+        return false;\n+      }\n+\n+      return namespace.equals(names.subList(0, namespace.size()));\n+    };\n+    return predicate;\n+  }\n+\n+  private static TableIdentifier toIdentifier(EntriesResponse.Entry entry) {\n+    List<String> elements = entry.getName().getElements();\n+    return TableIdentifier.of(elements.toArray(new String[elements.size()]));\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata;\n+    if (purge && ops.current() != null) {\n+      lastMetadata = ops.current();\n+    } else {\n+      lastMetadata = null;\n+    }\n+\n+    try {\n+      client.getContentsApi().deleteContents(toKey(identifier), reference.getAsBranch().getName(), reference.getHash(),\n+          \"no message\");\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to drop table as ref is no longer valid.\", e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58"}, "originalPosition": 252}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3NTM3Nzg2", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-527537786", "createdAt": "2020-11-10T19:27:49Z", "commit": {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxOToyNzo0OVrOHwsU5g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxOToyNzo0OVrOHwsU5g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgxOTk0Mg==", "bodyText": "Can't this refresh and complete the operation?", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520819942", "createdAt": "2020-11-10T19:27:49Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private static String getWarehouseLocation(Configuration config) {\n+    String nessieWarehouseDir = config.get(NESSIE_WAREHOUSE_DIR);\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. Please set nessie.warehouse.dir\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);\n+      }\n+\n+      throw new IllegalArgumentException(String.format(\"Nessie does not have an existing default branch.\" +\n+        \"Either configure an alternative ref via %s or create the default branch on the server.\",\n+          NessieClient.CONF_NESSIE_REF), ex);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  private static ContentsKey toKey(TableIdentifier tableIdentifier) {\n+    List<String> identifiers = new ArrayList<>();\n+    if (tableIdentifier.hasNamespace()) {\n+      identifiers.addAll(Arrays.asList(tableIdentifier.namespace().levels()));\n+    }\n+    identifiers.add(tableIdentifier.name());\n+\n+    ContentsKey key = new ContentsKey(identifiers);\n+    return key;\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {\n+        return (IcebergTable) table;\n+      }\n+    } catch (NessieNotFoundException e) {\n+      // ignore\n+    }\n+    return null;\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(tableIdentifier, new HashMap<>());\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = get(pti.getReference());\n+    }\n+    return new NessieTableOperations(config,\n+                                     toKey(pti.getTableIdentifier()),\n+                                     newReference,\n+                                     client);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  private Stream<TableIdentifier> tableStream(Namespace namespace) {\n+    try {\n+      return client.getTreeApi()\n+          .getEntries(reference.getHash())\n+          .getEntries()\n+          .stream()\n+          .filter(namespacePredicate(namespace))\n+          .map(NessieCatalog::toIdentifier);\n+    } catch (NessieNotFoundException ex) {\n+      throw new NoSuchNamespaceException(ex, \"Unable to list tables due to missing ref. %s\", reference.getName());\n+    }\n+  }\n+\n+  private static Predicate<EntriesResponse.Entry> namespacePredicate(Namespace ns) {\n+    // TODO: filter to just iceberg tables.\n+    if (ns == null) {\n+      return e -> true;\n+    }\n+\n+    final List<String> namespace = Arrays.asList(ns.levels());\n+    Predicate<EntriesResponse.Entry> predicate = e -> {\n+      List<String> names = e.getName().getElements();\n+\n+      if (names.size() <= namespace.size()) {\n+        return false;\n+      }\n+\n+      return namespace.equals(names.subList(0, namespace.size()));\n+    };\n+    return predicate;\n+  }\n+\n+  private static TableIdentifier toIdentifier(EntriesResponse.Entry entry) {\n+    List<String> elements = entry.getName().getElements();\n+    return TableIdentifier.of(elements.toArray(new String[elements.size()]));\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata;\n+    if (purge && ops.current() != null) {\n+      lastMetadata = ops.current();\n+    } else {\n+      lastMetadata = null;\n+    }\n+\n+    try {\n+      client.getContentsApi().deleteContents(toKey(identifier), reference.getAsBranch().getName(), reference.getHash(),\n+          \"no message\");\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to drop table as ref is no longer valid.\", e);\n+    } catch (NessieConflictException e) {\n+      throw new RuntimeException(\"Failed to drop table as table state needs to be refreshed.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58"}, "originalPosition": 254}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3NTM4MjU2", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-527538256", "createdAt": "2020-11-10T19:28:28Z", "commit": {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxOToyODoyOFrOHwsWZw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxOToyODoyOFrOHwsWZw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyMDMyNw==", "bodyText": "In this case, just remove the purge. We do that in our catalog as well because we never delete data as a result of a user action. We garbage collect it later.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520820327", "createdAt": "2020-11-10T19:28:28Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private static String getWarehouseLocation(Configuration config) {\n+    String nessieWarehouseDir = config.get(NESSIE_WAREHOUSE_DIR);\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. Please set nessie.warehouse.dir\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);\n+      }\n+\n+      throw new IllegalArgumentException(String.format(\"Nessie does not have an existing default branch.\" +\n+        \"Either configure an alternative ref via %s or create the default branch on the server.\",\n+          NessieClient.CONF_NESSIE_REF), ex);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  private static ContentsKey toKey(TableIdentifier tableIdentifier) {\n+    List<String> identifiers = new ArrayList<>();\n+    if (tableIdentifier.hasNamespace()) {\n+      identifiers.addAll(Arrays.asList(tableIdentifier.namespace().levels()));\n+    }\n+    identifiers.add(tableIdentifier.name());\n+\n+    ContentsKey key = new ContentsKey(identifiers);\n+    return key;\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {\n+        return (IcebergTable) table;\n+      }\n+    } catch (NessieNotFoundException e) {\n+      // ignore\n+    }\n+    return null;\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(tableIdentifier, new HashMap<>());\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = get(pti.getReference());\n+    }\n+    return new NessieTableOperations(config,\n+                                     toKey(pti.getTableIdentifier()),\n+                                     newReference,\n+                                     client);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  private Stream<TableIdentifier> tableStream(Namespace namespace) {\n+    try {\n+      return client.getTreeApi()\n+          .getEntries(reference.getHash())\n+          .getEntries()\n+          .stream()\n+          .filter(namespacePredicate(namespace))\n+          .map(NessieCatalog::toIdentifier);\n+    } catch (NessieNotFoundException ex) {\n+      throw new NoSuchNamespaceException(ex, \"Unable to list tables due to missing ref. %s\", reference.getName());\n+    }\n+  }\n+\n+  private static Predicate<EntriesResponse.Entry> namespacePredicate(Namespace ns) {\n+    // TODO: filter to just iceberg tables.\n+    if (ns == null) {\n+      return e -> true;\n+    }\n+\n+    final List<String> namespace = Arrays.asList(ns.levels());\n+    Predicate<EntriesResponse.Entry> predicate = e -> {\n+      List<String> names = e.getName().getElements();\n+\n+      if (names.size() <= namespace.size()) {\n+        return false;\n+      }\n+\n+      return namespace.equals(names.subList(0, namespace.size()));\n+    };\n+    return predicate;\n+  }\n+\n+  private static TableIdentifier toIdentifier(EntriesResponse.Entry entry) {\n+    List<String> elements = entry.getName().getElements();\n+    return TableIdentifier.of(elements.toArray(new String[elements.size()]));\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata;\n+    if (purge && ops.current() != null) {\n+      lastMetadata = ops.current();\n+    } else {\n+      lastMetadata = null;\n+    }\n+\n+    try {\n+      client.getContentsApi().deleteContents(toKey(identifier), reference.getAsBranch().getName(), reference.getHash(),\n+          \"no message\");\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to drop table as ref is no longer valid.\", e);\n+    } catch (NessieConflictException e) {\n+      throw new RuntimeException(\"Failed to drop table as table state needs to be refreshed.\");\n+    }\n+\n+    // TODO: purge should be blocked since nessie will clean through other means.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58"}, "originalPosition": 257}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3NTM4NDI5", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-527538429", "createdAt": "2020-11-10T19:28:42Z", "commit": {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxOToyODo0MlrOHwsW5w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxOToyODo0MlrOHwsW5w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyMDQ1NQ==", "bodyText": "What is this referring to?", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520820455", "createdAt": "2020-11-10T19:28:42Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private static String getWarehouseLocation(Configuration config) {\n+    String nessieWarehouseDir = config.get(NESSIE_WAREHOUSE_DIR);\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. Please set nessie.warehouse.dir\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);\n+      }\n+\n+      throw new IllegalArgumentException(String.format(\"Nessie does not have an existing default branch.\" +\n+        \"Either configure an alternative ref via %s or create the default branch on the server.\",\n+          NessieClient.CONF_NESSIE_REF), ex);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  private static ContentsKey toKey(TableIdentifier tableIdentifier) {\n+    List<String> identifiers = new ArrayList<>();\n+    if (tableIdentifier.hasNamespace()) {\n+      identifiers.addAll(Arrays.asList(tableIdentifier.namespace().levels()));\n+    }\n+    identifiers.add(tableIdentifier.name());\n+\n+    ContentsKey key = new ContentsKey(identifiers);\n+    return key;\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {\n+        return (IcebergTable) table;\n+      }\n+    } catch (NessieNotFoundException e) {\n+      // ignore\n+    }\n+    return null;\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(tableIdentifier, new HashMap<>());\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = get(pti.getReference());\n+    }\n+    return new NessieTableOperations(config,\n+                                     toKey(pti.getTableIdentifier()),\n+                                     newReference,\n+                                     client);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  private Stream<TableIdentifier> tableStream(Namespace namespace) {\n+    try {\n+      return client.getTreeApi()\n+          .getEntries(reference.getHash())\n+          .getEntries()\n+          .stream()\n+          .filter(namespacePredicate(namespace))\n+          .map(NessieCatalog::toIdentifier);\n+    } catch (NessieNotFoundException ex) {\n+      throw new NoSuchNamespaceException(ex, \"Unable to list tables due to missing ref. %s\", reference.getName());\n+    }\n+  }\n+\n+  private static Predicate<EntriesResponse.Entry> namespacePredicate(Namespace ns) {\n+    // TODO: filter to just iceberg tables.\n+    if (ns == null) {\n+      return e -> true;\n+    }\n+\n+    final List<String> namespace = Arrays.asList(ns.levels());\n+    Predicate<EntriesResponse.Entry> predicate = e -> {\n+      List<String> names = e.getName().getElements();\n+\n+      if (names.size() <= namespace.size()) {\n+        return false;\n+      }\n+\n+      return namespace.equals(names.subList(0, namespace.size()));\n+    };\n+    return predicate;\n+  }\n+\n+  private static TableIdentifier toIdentifier(EntriesResponse.Entry entry) {\n+    List<String> elements = entry.getName().getElements();\n+    return TableIdentifier.of(elements.toArray(new String[elements.size()]));\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata;\n+    if (purge && ops.current() != null) {\n+      lastMetadata = ops.current();\n+    } else {\n+      lastMetadata = null;\n+    }\n+\n+    try {\n+      client.getContentsApi().deleteContents(toKey(identifier), reference.getAsBranch().getName(), reference.getHash(),\n+          \"no message\");\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to drop table as ref is no longer valid.\", e);\n+    } catch (NessieConflictException e) {\n+      throw new RuntimeException(\"Failed to drop table as table state needs to be refreshed.\");\n+    }\n+\n+    // TODO: purge should be blocked since nessie will clean through other means.\n+    if (purge && lastMetadata != null) {\n+      BaseMetastoreCatalog.dropTableData(ops.io(), lastMetadata);\n+    }\n+    // TODO: fix this so we don't depend on it in tests.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58"}, "originalPosition": 261}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3NTQwODM3", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-527540837", "createdAt": "2020-11-10T19:31:57Z", "commit": {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxOTozMTo1N1rOHwseUg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxOTozMTo1N1rOHwseUg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyMjM1NA==", "bodyText": "Util methods seem to be mixed in. I think it may help readability if these were at the bottom, or were static methods in a NessieUtil class.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520822354", "createdAt": "2020-11-10T19:31:57Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private static String getWarehouseLocation(Configuration config) {\n+    String nessieWarehouseDir = config.get(NESSIE_WAREHOUSE_DIR);\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. Please set nessie.warehouse.dir\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);\n+      }\n+\n+      throw new IllegalArgumentException(String.format(\"Nessie does not have an existing default branch.\" +\n+        \"Either configure an alternative ref via %s or create the default branch on the server.\",\n+          NessieClient.CONF_NESSIE_REF), ex);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  private static ContentsKey toKey(TableIdentifier tableIdentifier) {\n+    List<String> identifiers = new ArrayList<>();\n+    if (tableIdentifier.hasNamespace()) {\n+      identifiers.addAll(Arrays.asList(tableIdentifier.namespace().levels()));\n+    }\n+    identifiers.add(tableIdentifier.name());\n+\n+    ContentsKey key = new ContentsKey(identifiers);\n+    return key;\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {\n+        return (IcebergTable) table;\n+      }\n+    } catch (NessieNotFoundException e) {\n+      // ignore\n+    }\n+    return null;\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(tableIdentifier, new HashMap<>());\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = get(pti.getReference());\n+    }\n+    return new NessieTableOperations(config,\n+                                     toKey(pti.getTableIdentifier()),\n+                                     newReference,\n+                                     client);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  private Stream<TableIdentifier> tableStream(Namespace namespace) {\n+    try {\n+      return client.getTreeApi()\n+          .getEntries(reference.getHash())\n+          .getEntries()\n+          .stream()\n+          .filter(namespacePredicate(namespace))\n+          .map(NessieCatalog::toIdentifier);\n+    } catch (NessieNotFoundException ex) {\n+      throw new NoSuchNamespaceException(ex, \"Unable to list tables due to missing ref. %s\", reference.getName());\n+    }\n+  }\n+\n+  private static Predicate<EntriesResponse.Entry> namespacePredicate(Namespace ns) {\n+    // TODO: filter to just iceberg tables.\n+    if (ns == null) {\n+      return e -> true;\n+    }\n+\n+    final List<String> namespace = Arrays.asList(ns.levels());\n+    Predicate<EntriesResponse.Entry> predicate = e -> {\n+      List<String> names = e.getName().getElements();\n+\n+      if (names.size() <= namespace.size()) {\n+        return false;\n+      }\n+\n+      return namespace.equals(names.subList(0, namespace.size()));\n+    };\n+    return predicate;\n+  }\n+\n+  private static TableIdentifier toIdentifier(EntriesResponse.Entry entry) {\n+    List<String> elements = entry.getName().getElements();\n+    return TableIdentifier.of(elements.toArray(new String[elements.size()]));\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata;\n+    if (purge && ops.current() != null) {\n+      lastMetadata = ops.current();\n+    } else {\n+      lastMetadata = null;\n+    }\n+\n+    try {\n+      client.getContentsApi().deleteContents(toKey(identifier), reference.getAsBranch().getName(), reference.getHash(),\n+          \"no message\");\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to drop table as ref is no longer valid.\", e);\n+    } catch (NessieConflictException e) {\n+      throw new RuntimeException(\"Failed to drop table as table state needs to be refreshed.\");\n+    }\n+\n+    // TODO: purge should be blocked since nessie will clean through other means.\n+    if (purge && lastMetadata != null) {\n+      BaseMetastoreCatalog.dropTableData(ops.io(), lastMetadata);\n+    }\n+    // TODO: fix this so we don't depend on it in tests.\n+    refresh();\n+    return true;\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier toOriginal) {\n+    reference.checkMutable();\n+\n+    TableIdentifier to = removeCatalogName(toOriginal);\n+\n+    IcebergTable existingFromTable = table(from);\n+    if (existingFromTable == null) {\n+      throw new NoSuchTableException(\"table %s doesn't exists\", from.name());\n+    }\n+    IcebergTable existingToTable = table(to);\n+    if (existingToTable != null) {\n+      throw new AlreadyExistsException(\"table %s already exists\", to.name());\n+    }\n+\n+    Operations contents = ImmutableOperations.builder()\n+        .addOperations(ImmutablePut.builder().key(toKey(to)).contents(existingFromTable).build(),\n+            ImmutableDelete.builder().key(toKey(from)).build())\n+        .build();\n+\n+    try {\n+      client.getTreeApi().commitMultipleOperations(reference.getAsBranch().getName(), reference.getHash(),\n+          \"iceberg rename table\", contents);\n+      // TODO: fix this so we don't depend on it in tests.\n+      refresh();\n+    } catch (Exception e) {\n+      throw new CommitFailedException(e, \"failed\");\n+    }\n+  }\n+\n+  private TableIdentifier removeCatalogName(TableIdentifier to) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58"}, "originalPosition": 296}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3NTQxNDEw", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-527541410", "createdAt": "2020-11-10T19:32:49Z", "commit": {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxOTozMjo0OVrOHwsf9g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxOTozMjo0OVrOHwsf9g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyMjc3NA==", "bodyText": "Is there a more specific name for this? It isn't clear what catalog.getHash() should be.\nAlso, style nit: we avoid using get where a more specific verb would add value.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520822774", "createdAt": "2020-11-10T19:32:49Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private static String getWarehouseLocation(Configuration config) {\n+    String nessieWarehouseDir = config.get(NESSIE_WAREHOUSE_DIR);\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. Please set nessie.warehouse.dir\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);\n+      }\n+\n+      throw new IllegalArgumentException(String.format(\"Nessie does not have an existing default branch.\" +\n+        \"Either configure an alternative ref via %s or create the default branch on the server.\",\n+          NessieClient.CONF_NESSIE_REF), ex);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  private static ContentsKey toKey(TableIdentifier tableIdentifier) {\n+    List<String> identifiers = new ArrayList<>();\n+    if (tableIdentifier.hasNamespace()) {\n+      identifiers.addAll(Arrays.asList(tableIdentifier.namespace().levels()));\n+    }\n+    identifiers.add(tableIdentifier.name());\n+\n+    ContentsKey key = new ContentsKey(identifiers);\n+    return key;\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {\n+        return (IcebergTable) table;\n+      }\n+    } catch (NessieNotFoundException e) {\n+      // ignore\n+    }\n+    return null;\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(tableIdentifier, new HashMap<>());\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = get(pti.getReference());\n+    }\n+    return new NessieTableOperations(config,\n+                                     toKey(pti.getTableIdentifier()),\n+                                     newReference,\n+                                     client);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  private Stream<TableIdentifier> tableStream(Namespace namespace) {\n+    try {\n+      return client.getTreeApi()\n+          .getEntries(reference.getHash())\n+          .getEntries()\n+          .stream()\n+          .filter(namespacePredicate(namespace))\n+          .map(NessieCatalog::toIdentifier);\n+    } catch (NessieNotFoundException ex) {\n+      throw new NoSuchNamespaceException(ex, \"Unable to list tables due to missing ref. %s\", reference.getName());\n+    }\n+  }\n+\n+  private static Predicate<EntriesResponse.Entry> namespacePredicate(Namespace ns) {\n+    // TODO: filter to just iceberg tables.\n+    if (ns == null) {\n+      return e -> true;\n+    }\n+\n+    final List<String> namespace = Arrays.asList(ns.levels());\n+    Predicate<EntriesResponse.Entry> predicate = e -> {\n+      List<String> names = e.getName().getElements();\n+\n+      if (names.size() <= namespace.size()) {\n+        return false;\n+      }\n+\n+      return namespace.equals(names.subList(0, namespace.size()));\n+    };\n+    return predicate;\n+  }\n+\n+  private static TableIdentifier toIdentifier(EntriesResponse.Entry entry) {\n+    List<String> elements = entry.getName().getElements();\n+    return TableIdentifier.of(elements.toArray(new String[elements.size()]));\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata;\n+    if (purge && ops.current() != null) {\n+      lastMetadata = ops.current();\n+    } else {\n+      lastMetadata = null;\n+    }\n+\n+    try {\n+      client.getContentsApi().deleteContents(toKey(identifier), reference.getAsBranch().getName(), reference.getHash(),\n+          \"no message\");\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to drop table as ref is no longer valid.\", e);\n+    } catch (NessieConflictException e) {\n+      throw new RuntimeException(\"Failed to drop table as table state needs to be refreshed.\");\n+    }\n+\n+    // TODO: purge should be blocked since nessie will clean through other means.\n+    if (purge && lastMetadata != null) {\n+      BaseMetastoreCatalog.dropTableData(ops.io(), lastMetadata);\n+    }\n+    // TODO: fix this so we don't depend on it in tests.\n+    refresh();\n+    return true;\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier toOriginal) {\n+    reference.checkMutable();\n+\n+    TableIdentifier to = removeCatalogName(toOriginal);\n+\n+    IcebergTable existingFromTable = table(from);\n+    if (existingFromTable == null) {\n+      throw new NoSuchTableException(\"table %s doesn't exists\", from.name());\n+    }\n+    IcebergTable existingToTable = table(to);\n+    if (existingToTable != null) {\n+      throw new AlreadyExistsException(\"table %s already exists\", to.name());\n+    }\n+\n+    Operations contents = ImmutableOperations.builder()\n+        .addOperations(ImmutablePut.builder().key(toKey(to)).contents(existingFromTable).build(),\n+            ImmutableDelete.builder().key(toKey(from)).build())\n+        .build();\n+\n+    try {\n+      client.getTreeApi().commitMultipleOperations(reference.getAsBranch().getName(), reference.getHash(),\n+          \"iceberg rename table\", contents);\n+      // TODO: fix this so we don't depend on it in tests.\n+      refresh();\n+    } catch (Exception e) {\n+      throw new CommitFailedException(e, \"failed\");\n+    }\n+  }\n+\n+  private TableIdentifier removeCatalogName(TableIdentifier to) {\n+\n+    String[] levels = to.namespace().levels();\n+    // check if the identifier includes the catalog name and remove it\n+    if (levels.length >= 2 && name().equalsIgnoreCase(to.namespace().level(0))) {\n+      Namespace trimmedNamespace = Namespace.of(Arrays.copyOfRange(levels, 1, levels.length));\n+      return TableIdentifier.of(trimmedNamespace, to.name());\n+    }\n+\n+    // return the original unmodified\n+    return to;\n+  }\n+\n+  public TreeApi getTreeApi() {\n+    return client.getTreeApi();\n+  }\n+\n+  public void refresh() {\n+    reference.refresh();\n+  }\n+\n+  public String getHash() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58"}, "originalPosition": 317}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3NTQyMTI5", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-527542129", "createdAt": "2020-11-10T19:33:47Z", "commit": {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxOTozMzo0N1rOHwsiag==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxOTozMzo0N1rOHwsiag==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyMzQwMg==", "bodyText": "Should we create a trait just for listing namespaces that are implicit?", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520823402", "createdAt": "2020-11-10T19:33:47Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private static String getWarehouseLocation(Configuration config) {\n+    String nessieWarehouseDir = config.get(NESSIE_WAREHOUSE_DIR);\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. Please set nessie.warehouse.dir\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);\n+      }\n+\n+      throw new IllegalArgumentException(String.format(\"Nessie does not have an existing default branch.\" +\n+        \"Either configure an alternative ref via %s or create the default branch on the server.\",\n+          NessieClient.CONF_NESSIE_REF), ex);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  private static ContentsKey toKey(TableIdentifier tableIdentifier) {\n+    List<String> identifiers = new ArrayList<>();\n+    if (tableIdentifier.hasNamespace()) {\n+      identifiers.addAll(Arrays.asList(tableIdentifier.namespace().levels()));\n+    }\n+    identifiers.add(tableIdentifier.name());\n+\n+    ContentsKey key = new ContentsKey(identifiers);\n+    return key;\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {\n+        return (IcebergTable) table;\n+      }\n+    } catch (NessieNotFoundException e) {\n+      // ignore\n+    }\n+    return null;\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(tableIdentifier, new HashMap<>());\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = get(pti.getReference());\n+    }\n+    return new NessieTableOperations(config,\n+                                     toKey(pti.getTableIdentifier()),\n+                                     newReference,\n+                                     client);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  private Stream<TableIdentifier> tableStream(Namespace namespace) {\n+    try {\n+      return client.getTreeApi()\n+          .getEntries(reference.getHash())\n+          .getEntries()\n+          .stream()\n+          .filter(namespacePredicate(namespace))\n+          .map(NessieCatalog::toIdentifier);\n+    } catch (NessieNotFoundException ex) {\n+      throw new NoSuchNamespaceException(ex, \"Unable to list tables due to missing ref. %s\", reference.getName());\n+    }\n+  }\n+\n+  private static Predicate<EntriesResponse.Entry> namespacePredicate(Namespace ns) {\n+    // TODO: filter to just iceberg tables.\n+    if (ns == null) {\n+      return e -> true;\n+    }\n+\n+    final List<String> namespace = Arrays.asList(ns.levels());\n+    Predicate<EntriesResponse.Entry> predicate = e -> {\n+      List<String> names = e.getName().getElements();\n+\n+      if (names.size() <= namespace.size()) {\n+        return false;\n+      }\n+\n+      return namespace.equals(names.subList(0, namespace.size()));\n+    };\n+    return predicate;\n+  }\n+\n+  private static TableIdentifier toIdentifier(EntriesResponse.Entry entry) {\n+    List<String> elements = entry.getName().getElements();\n+    return TableIdentifier.of(elements.toArray(new String[elements.size()]));\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata;\n+    if (purge && ops.current() != null) {\n+      lastMetadata = ops.current();\n+    } else {\n+      lastMetadata = null;\n+    }\n+\n+    try {\n+      client.getContentsApi().deleteContents(toKey(identifier), reference.getAsBranch().getName(), reference.getHash(),\n+          \"no message\");\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to drop table as ref is no longer valid.\", e);\n+    } catch (NessieConflictException e) {\n+      throw new RuntimeException(\"Failed to drop table as table state needs to be refreshed.\");\n+    }\n+\n+    // TODO: purge should be blocked since nessie will clean through other means.\n+    if (purge && lastMetadata != null) {\n+      BaseMetastoreCatalog.dropTableData(ops.io(), lastMetadata);\n+    }\n+    // TODO: fix this so we don't depend on it in tests.\n+    refresh();\n+    return true;\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier toOriginal) {\n+    reference.checkMutable();\n+\n+    TableIdentifier to = removeCatalogName(toOriginal);\n+\n+    IcebergTable existingFromTable = table(from);\n+    if (existingFromTable == null) {\n+      throw new NoSuchTableException(\"table %s doesn't exists\", from.name());\n+    }\n+    IcebergTable existingToTable = table(to);\n+    if (existingToTable != null) {\n+      throw new AlreadyExistsException(\"table %s already exists\", to.name());\n+    }\n+\n+    Operations contents = ImmutableOperations.builder()\n+        .addOperations(ImmutablePut.builder().key(toKey(to)).contents(existingFromTable).build(),\n+            ImmutableDelete.builder().key(toKey(from)).build())\n+        .build();\n+\n+    try {\n+      client.getTreeApi().commitMultipleOperations(reference.getAsBranch().getName(), reference.getHash(),\n+          \"iceberg rename table\", contents);\n+      // TODO: fix this so we don't depend on it in tests.\n+      refresh();\n+    } catch (Exception e) {\n+      throw new CommitFailedException(e, \"failed\");\n+    }\n+  }\n+\n+  private TableIdentifier removeCatalogName(TableIdentifier to) {\n+\n+    String[] levels = to.namespace().levels();\n+    // check if the identifier includes the catalog name and remove it\n+    if (levels.length >= 2 && name().equalsIgnoreCase(to.namespace().level(0))) {\n+      Namespace trimmedNamespace = Namespace.of(Arrays.copyOfRange(levels, 1, levels.length));\n+      return TableIdentifier.of(trimmedNamespace, to.name());\n+    }\n+\n+    // return the original unmodified\n+    return to;\n+  }\n+\n+  public TreeApi getTreeApi() {\n+    return client.getTreeApi();\n+  }\n+\n+  public void refresh() {\n+    reference.refresh();\n+  }\n+\n+  public String getHash() {\n+    return reference.getHash();\n+  }\n+\n+  public static Builder builder(Configuration conf) {\n+    return new Builder(conf);\n+  }\n+\n+  /**\n+   * creating namespaces in nessie is implicit, therefore this is a no-op. Metadata is ignored.\n+   *\n+   * @param namespace a multi-part namespace\n+   * @param metadata a string Map of properties for the given namespace\n+   */\n+  @Override\n+  public void createNamespace(Namespace namespace, Map<String, String> metadata) {\n+  }\n+\n+  @Override\n+  public List<Namespace> listNamespaces(Namespace namespace) throws NoSuchNamespaceException {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58"}, "originalPosition": 336}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3NTQyNTg0", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-527542584", "createdAt": "2020-11-10T19:34:24Z", "commit": {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxOTozNDoyNFrOHwsjuA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxOTozNDoyNFrOHwsjuA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyMzczNg==", "bodyText": "Ignore my comments above, since it looks like you've already added this. Can you merge this with init and the constructors?", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520823736", "createdAt": "2020-11-10T19:34:24Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private static String getWarehouseLocation(Configuration config) {\n+    String nessieWarehouseDir = config.get(NESSIE_WAREHOUSE_DIR);\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. Please set nessie.warehouse.dir\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);\n+      }\n+\n+      throw new IllegalArgumentException(String.format(\"Nessie does not have an existing default branch.\" +\n+        \"Either configure an alternative ref via %s or create the default branch on the server.\",\n+          NessieClient.CONF_NESSIE_REF), ex);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  private static ContentsKey toKey(TableIdentifier tableIdentifier) {\n+    List<String> identifiers = new ArrayList<>();\n+    if (tableIdentifier.hasNamespace()) {\n+      identifiers.addAll(Arrays.asList(tableIdentifier.namespace().levels()));\n+    }\n+    identifiers.add(tableIdentifier.name());\n+\n+    ContentsKey key = new ContentsKey(identifiers);\n+    return key;\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {\n+        return (IcebergTable) table;\n+      }\n+    } catch (NessieNotFoundException e) {\n+      // ignore\n+    }\n+    return null;\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(tableIdentifier, new HashMap<>());\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = get(pti.getReference());\n+    }\n+    return new NessieTableOperations(config,\n+                                     toKey(pti.getTableIdentifier()),\n+                                     newReference,\n+                                     client);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  private Stream<TableIdentifier> tableStream(Namespace namespace) {\n+    try {\n+      return client.getTreeApi()\n+          .getEntries(reference.getHash())\n+          .getEntries()\n+          .stream()\n+          .filter(namespacePredicate(namespace))\n+          .map(NessieCatalog::toIdentifier);\n+    } catch (NessieNotFoundException ex) {\n+      throw new NoSuchNamespaceException(ex, \"Unable to list tables due to missing ref. %s\", reference.getName());\n+    }\n+  }\n+\n+  private static Predicate<EntriesResponse.Entry> namespacePredicate(Namespace ns) {\n+    // TODO: filter to just iceberg tables.\n+    if (ns == null) {\n+      return e -> true;\n+    }\n+\n+    final List<String> namespace = Arrays.asList(ns.levels());\n+    Predicate<EntriesResponse.Entry> predicate = e -> {\n+      List<String> names = e.getName().getElements();\n+\n+      if (names.size() <= namespace.size()) {\n+        return false;\n+      }\n+\n+      return namespace.equals(names.subList(0, namespace.size()));\n+    };\n+    return predicate;\n+  }\n+\n+  private static TableIdentifier toIdentifier(EntriesResponse.Entry entry) {\n+    List<String> elements = entry.getName().getElements();\n+    return TableIdentifier.of(elements.toArray(new String[elements.size()]));\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata;\n+    if (purge && ops.current() != null) {\n+      lastMetadata = ops.current();\n+    } else {\n+      lastMetadata = null;\n+    }\n+\n+    try {\n+      client.getContentsApi().deleteContents(toKey(identifier), reference.getAsBranch().getName(), reference.getHash(),\n+          \"no message\");\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to drop table as ref is no longer valid.\", e);\n+    } catch (NessieConflictException e) {\n+      throw new RuntimeException(\"Failed to drop table as table state needs to be refreshed.\");\n+    }\n+\n+    // TODO: purge should be blocked since nessie will clean through other means.\n+    if (purge && lastMetadata != null) {\n+      BaseMetastoreCatalog.dropTableData(ops.io(), lastMetadata);\n+    }\n+    // TODO: fix this so we don't depend on it in tests.\n+    refresh();\n+    return true;\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier toOriginal) {\n+    reference.checkMutable();\n+\n+    TableIdentifier to = removeCatalogName(toOriginal);\n+\n+    IcebergTable existingFromTable = table(from);\n+    if (existingFromTable == null) {\n+      throw new NoSuchTableException(\"table %s doesn't exists\", from.name());\n+    }\n+    IcebergTable existingToTable = table(to);\n+    if (existingToTable != null) {\n+      throw new AlreadyExistsException(\"table %s already exists\", to.name());\n+    }\n+\n+    Operations contents = ImmutableOperations.builder()\n+        .addOperations(ImmutablePut.builder().key(toKey(to)).contents(existingFromTable).build(),\n+            ImmutableDelete.builder().key(toKey(from)).build())\n+        .build();\n+\n+    try {\n+      client.getTreeApi().commitMultipleOperations(reference.getAsBranch().getName(), reference.getHash(),\n+          \"iceberg rename table\", contents);\n+      // TODO: fix this so we don't depend on it in tests.\n+      refresh();\n+    } catch (Exception e) {\n+      throw new CommitFailedException(e, \"failed\");\n+    }\n+  }\n+\n+  private TableIdentifier removeCatalogName(TableIdentifier to) {\n+\n+    String[] levels = to.namespace().levels();\n+    // check if the identifier includes the catalog name and remove it\n+    if (levels.length >= 2 && name().equalsIgnoreCase(to.namespace().level(0))) {\n+      Namespace trimmedNamespace = Namespace.of(Arrays.copyOfRange(levels, 1, levels.length));\n+      return TableIdentifier.of(trimmedNamespace, to.name());\n+    }\n+\n+    // return the original unmodified\n+    return to;\n+  }\n+\n+  public TreeApi getTreeApi() {\n+    return client.getTreeApi();\n+  }\n+\n+  public void refresh() {\n+    reference.refresh();\n+  }\n+\n+  public String getHash() {\n+    return reference.getHash();\n+  }\n+\n+  public static Builder builder(Configuration conf) {\n+    return new Builder(conf);\n+  }\n+\n+  /**\n+   * creating namespaces in nessie is implicit, therefore this is a no-op. Metadata is ignored.\n+   *\n+   * @param namespace a multi-part namespace\n+   * @param metadata a string Map of properties for the given namespace\n+   */\n+  @Override\n+  public void createNamespace(Namespace namespace, Map<String, String> metadata) {\n+  }\n+\n+  @Override\n+  public List<Namespace> listNamespaces(Namespace namespace) throws NoSuchNamespaceException {\n+    return tableStream(namespace)\n+        .map(TableIdentifier::namespace)\n+        .filter(n -> !n.isEmpty())\n+        .distinct()\n+        .collect(Collectors.toList());\n+  }\n+\n+  /**\n+   * namespace metadata is not supported in Nessie and we return an empty map.\n+   *\n+   * @param namespace a namespace. {@link Namespace}\n+   * @return an empty map\n+   */\n+  @Override\n+  public Map<String, String> loadNamespaceMetadata(Namespace namespace) throws NoSuchNamespaceException {\n+    return ImmutableMap.of();\n+  }\n+\n+  /**\n+   * Namespaces in Nessie are implicit and deleting them results in a no-op.\n+   *\n+   * @param namespace a namespace. {@link Namespace}\n+   * @return always false.\n+   */\n+  @Override\n+  public boolean dropNamespace(Namespace namespace) throws NamespaceNotEmptyException {\n+    return false;\n+  }\n+\n+  @Override\n+  public boolean setProperties(Namespace namespace, Map<String, String> properties) throws NoSuchNamespaceException {\n+    throw new UnsupportedOperationException(\n+        \"Cannot set namespace properties \" + namespace + \" : setProperties is not supported\");\n+  }\n+\n+  @Override\n+  public boolean removeProperties(Namespace namespace, Set<String> properties) throws NoSuchNamespaceException {\n+    throw new UnsupportedOperationException(\n+        \"Cannot remove properties \" + namespace + \" : removeProperties is not supported\");\n+  }\n+\n+  @Override\n+  public void setConf(Configuration conf) {\n+    this.config = conf;\n+  }\n+\n+  @Override\n+  public Configuration getConf() {\n+    return config;\n+  }\n+\n+  @Override\n+  public void initialize(String inputName, Map<String, String> options) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58"}, "originalPosition": 389}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3NTQyOTgy", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-527542982", "createdAt": "2020-11-10T19:34:55Z", "commit": {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxOTozNDo1NlrOHwslFA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxOTozNDo1NlrOHwslFA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyNDA4NA==", "bodyText": "Nessie URL? In other places, we configure the connection using uri.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520824084", "createdAt": "2020-11-10T19:34:56Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private static String getWarehouseLocation(Configuration config) {\n+    String nessieWarehouseDir = config.get(NESSIE_WAREHOUSE_DIR);\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. Please set nessie.warehouse.dir\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);\n+      }\n+\n+      throw new IllegalArgumentException(String.format(\"Nessie does not have an existing default branch.\" +\n+        \"Either configure an alternative ref via %s or create the default branch on the server.\",\n+          NessieClient.CONF_NESSIE_REF), ex);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  private static ContentsKey toKey(TableIdentifier tableIdentifier) {\n+    List<String> identifiers = new ArrayList<>();\n+    if (tableIdentifier.hasNamespace()) {\n+      identifiers.addAll(Arrays.asList(tableIdentifier.namespace().levels()));\n+    }\n+    identifiers.add(tableIdentifier.name());\n+\n+    ContentsKey key = new ContentsKey(identifiers);\n+    return key;\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {\n+        return (IcebergTable) table;\n+      }\n+    } catch (NessieNotFoundException e) {\n+      // ignore\n+    }\n+    return null;\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(tableIdentifier, new HashMap<>());\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = get(pti.getReference());\n+    }\n+    return new NessieTableOperations(config,\n+                                     toKey(pti.getTableIdentifier()),\n+                                     newReference,\n+                                     client);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  private Stream<TableIdentifier> tableStream(Namespace namespace) {\n+    try {\n+      return client.getTreeApi()\n+          .getEntries(reference.getHash())\n+          .getEntries()\n+          .stream()\n+          .filter(namespacePredicate(namespace))\n+          .map(NessieCatalog::toIdentifier);\n+    } catch (NessieNotFoundException ex) {\n+      throw new NoSuchNamespaceException(ex, \"Unable to list tables due to missing ref. %s\", reference.getName());\n+    }\n+  }\n+\n+  private static Predicate<EntriesResponse.Entry> namespacePredicate(Namespace ns) {\n+    // TODO: filter to just iceberg tables.\n+    if (ns == null) {\n+      return e -> true;\n+    }\n+\n+    final List<String> namespace = Arrays.asList(ns.levels());\n+    Predicate<EntriesResponse.Entry> predicate = e -> {\n+      List<String> names = e.getName().getElements();\n+\n+      if (names.size() <= namespace.size()) {\n+        return false;\n+      }\n+\n+      return namespace.equals(names.subList(0, namespace.size()));\n+    };\n+    return predicate;\n+  }\n+\n+  private static TableIdentifier toIdentifier(EntriesResponse.Entry entry) {\n+    List<String> elements = entry.getName().getElements();\n+    return TableIdentifier.of(elements.toArray(new String[elements.size()]));\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata;\n+    if (purge && ops.current() != null) {\n+      lastMetadata = ops.current();\n+    } else {\n+      lastMetadata = null;\n+    }\n+\n+    try {\n+      client.getContentsApi().deleteContents(toKey(identifier), reference.getAsBranch().getName(), reference.getHash(),\n+          \"no message\");\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to drop table as ref is no longer valid.\", e);\n+    } catch (NessieConflictException e) {\n+      throw new RuntimeException(\"Failed to drop table as table state needs to be refreshed.\");\n+    }\n+\n+    // TODO: purge should be blocked since nessie will clean through other means.\n+    if (purge && lastMetadata != null) {\n+      BaseMetastoreCatalog.dropTableData(ops.io(), lastMetadata);\n+    }\n+    // TODO: fix this so we don't depend on it in tests.\n+    refresh();\n+    return true;\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier toOriginal) {\n+    reference.checkMutable();\n+\n+    TableIdentifier to = removeCatalogName(toOriginal);\n+\n+    IcebergTable existingFromTable = table(from);\n+    if (existingFromTable == null) {\n+      throw new NoSuchTableException(\"table %s doesn't exists\", from.name());\n+    }\n+    IcebergTable existingToTable = table(to);\n+    if (existingToTable != null) {\n+      throw new AlreadyExistsException(\"table %s already exists\", to.name());\n+    }\n+\n+    Operations contents = ImmutableOperations.builder()\n+        .addOperations(ImmutablePut.builder().key(toKey(to)).contents(existingFromTable).build(),\n+            ImmutableDelete.builder().key(toKey(from)).build())\n+        .build();\n+\n+    try {\n+      client.getTreeApi().commitMultipleOperations(reference.getAsBranch().getName(), reference.getHash(),\n+          \"iceberg rename table\", contents);\n+      // TODO: fix this so we don't depend on it in tests.\n+      refresh();\n+    } catch (Exception e) {\n+      throw new CommitFailedException(e, \"failed\");\n+    }\n+  }\n+\n+  private TableIdentifier removeCatalogName(TableIdentifier to) {\n+\n+    String[] levels = to.namespace().levels();\n+    // check if the identifier includes the catalog name and remove it\n+    if (levels.length >= 2 && name().equalsIgnoreCase(to.namespace().level(0))) {\n+      Namespace trimmedNamespace = Namespace.of(Arrays.copyOfRange(levels, 1, levels.length));\n+      return TableIdentifier.of(trimmedNamespace, to.name());\n+    }\n+\n+    // return the original unmodified\n+    return to;\n+  }\n+\n+  public TreeApi getTreeApi() {\n+    return client.getTreeApi();\n+  }\n+\n+  public void refresh() {\n+    reference.refresh();\n+  }\n+\n+  public String getHash() {\n+    return reference.getHash();\n+  }\n+\n+  public static Builder builder(Configuration conf) {\n+    return new Builder(conf);\n+  }\n+\n+  /**\n+   * creating namespaces in nessie is implicit, therefore this is a no-op. Metadata is ignored.\n+   *\n+   * @param namespace a multi-part namespace\n+   * @param metadata a string Map of properties for the given namespace\n+   */\n+  @Override\n+  public void createNamespace(Namespace namespace, Map<String, String> metadata) {\n+  }\n+\n+  @Override\n+  public List<Namespace> listNamespaces(Namespace namespace) throws NoSuchNamespaceException {\n+    return tableStream(namespace)\n+        .map(TableIdentifier::namespace)\n+        .filter(n -> !n.isEmpty())\n+        .distinct()\n+        .collect(Collectors.toList());\n+  }\n+\n+  /**\n+   * namespace metadata is not supported in Nessie and we return an empty map.\n+   *\n+   * @param namespace a namespace. {@link Namespace}\n+   * @return an empty map\n+   */\n+  @Override\n+  public Map<String, String> loadNamespaceMetadata(Namespace namespace) throws NoSuchNamespaceException {\n+    return ImmutableMap.of();\n+  }\n+\n+  /**\n+   * Namespaces in Nessie are implicit and deleting them results in a no-op.\n+   *\n+   * @param namespace a namespace. {@link Namespace}\n+   * @return always false.\n+   */\n+  @Override\n+  public boolean dropNamespace(Namespace namespace) throws NamespaceNotEmptyException {\n+    return false;\n+  }\n+\n+  @Override\n+  public boolean setProperties(Namespace namespace, Map<String, String> properties) throws NoSuchNamespaceException {\n+    throw new UnsupportedOperationException(\n+        \"Cannot set namespace properties \" + namespace + \" : setProperties is not supported\");\n+  }\n+\n+  @Override\n+  public boolean removeProperties(Namespace namespace, Set<String> properties) throws NoSuchNamespaceException {\n+    throw new UnsupportedOperationException(\n+        \"Cannot remove properties \" + namespace + \" : removeProperties is not supported\");\n+  }\n+\n+  @Override\n+  public void setConf(Configuration conf) {\n+    this.config = conf;\n+  }\n+\n+  @Override\n+  public Configuration getConf() {\n+    return config;\n+  }\n+\n+  @Override\n+  public void initialize(String inputName, Map<String, String> options) {\n+    this.name = inputName;\n+    init(options.getOrDefault(NessieClient.CONF_NESSIE_REF, config.get(NessieClient.CONF_NESSIE_REF)),\n+         options.getOrDefault(NessieClient.CONF_NESSIE_URL, config.get(NessieClient.CONF_NESSIE_URL)),\n+         options.getOrDefault(NESSIE_WAREHOUSE_DIR, config.get(NESSIE_WAREHOUSE_DIR)));\n+  }\n+\n+  public static class Builder {\n+    private final Configuration conf;\n+    private String url;\n+    private String ref;\n+    private String warehouseLocation;\n+    private String name;\n+\n+    public Builder(Configuration conf) {\n+      this.conf = conf;\n+    }\n+\n+    public Builder setUrl(String url) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58"}, "originalPosition": 407}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3NTQzNDY1", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-527543465", "createdAt": "2020-11-10T19:35:36Z", "commit": {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxOTozNTozNlrOHwsnEw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxOTozNTozNlrOHwsnEw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyNDU5NQ==", "bodyText": "This is the default ref, right? Tables can override it. I think that would be a better name if you can use this catalog to load other refs.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520824595", "createdAt": "2020-11-10T19:35:36Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,431 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.EntriesResponse;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.HashMap;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.function.Predicate;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+\n+  /**\n+   * Try to avoid passing parameters via hadoop config. Dynamic catalog expects Map instead\n+   *\n+   * todo replace with #1640 style constructor\n+   */\n+  public NessieCatalog() {\n+  }\n+\n+  /**\n+   * Create a catalog with a known name from a hadoop configuration.\n+   */\n+  public NessieCatalog(String name, Configuration config, String ref, String url, String warehouseLocation) {\n+    this.config = config;\n+    this.name = name == null ? \"nessie\" : name;\n+    init(ref, url, warehouseLocation);\n+  }\n+\n+  private void init(String ref, String url, String inputWarehouseLocation) {\n+    this.client = NessieClient.withConfig(s -> {\n+      if (s.equals(NessieClient.CONF_NESSIE_URL)) {\n+        return url == null ? config.get(s) : url;\n+      }\n+      return config.get(s);\n+    });\n+\n+    this.warehouseLocation = inputWarehouseLocation == null ? getWarehouseLocation(config) : inputWarehouseLocation;\n+\n+    final String requestedRef = ref != null ? ref : config.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = get(requestedRef);\n+  }\n+\n+  private static String getWarehouseLocation(Configuration config) {\n+    String nessieWarehouseDir = config.get(NESSIE_WAREHOUSE_DIR);\n+    if (nessieWarehouseDir != null) {\n+      return nessieWarehouseDir;\n+    }\n+    throw new IllegalStateException(\"Don't know where to put the nessie iceberg data. Please set nessie.warehouse.dir\");\n+  }\n+\n+  private UpdateableReference get(String requestedRef) {\n+    try {\n+      Reference ref = requestedRef == null ? client.getTreeApi().getDefaultBranch()\n+          : client.getTreeApi().getReferenceByName(requestedRef);\n+      return new UpdateableReference(ref, client.getTreeApi());\n+    } catch (NessieNotFoundException ex) {\n+      if (requestedRef != null) {\n+        throw new IllegalArgumentException(String.format(\"Nessie ref '%s' provided via %s does not exist. \" +\n+          \"This ref must exist before creating a NessieCatalog.\", requestedRef, NessieClient.CONF_NESSIE_REF), ex);\n+      }\n+\n+      throw new IllegalArgumentException(String.format(\"Nessie does not have an existing default branch.\" +\n+        \"Either configure an alternative ref via %s or create the default branch on the server.\",\n+          NessieClient.CONF_NESSIE_REF), ex);\n+    }\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  private static ContentsKey toKey(TableIdentifier tableIdentifier) {\n+    List<String> identifiers = new ArrayList<>();\n+    if (tableIdentifier.hasNamespace()) {\n+      identifiers.addAll(Arrays.asList(tableIdentifier.namespace().levels()));\n+    }\n+    identifiers.add(tableIdentifier.name());\n+\n+    ContentsKey key = new ContentsKey(identifiers);\n+    return key;\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {\n+        return (IcebergTable) table;\n+      }\n+    } catch (NessieNotFoundException e) {\n+      // ignore\n+    }\n+    return null;\n+  }\n+\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    ParsedTableIdentifier pti = ParsedTableIdentifier.getParsedTableIdentifier(tableIdentifier, new HashMap<>());\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = get(pti.getReference());\n+    }\n+    return new NessieTableOperations(config,\n+                                     toKey(pti.getTableIdentifier()),\n+                                     newReference,\n+                                     client);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  private Stream<TableIdentifier> tableStream(Namespace namespace) {\n+    try {\n+      return client.getTreeApi()\n+          .getEntries(reference.getHash())\n+          .getEntries()\n+          .stream()\n+          .filter(namespacePredicate(namespace))\n+          .map(NessieCatalog::toIdentifier);\n+    } catch (NessieNotFoundException ex) {\n+      throw new NoSuchNamespaceException(ex, \"Unable to list tables due to missing ref. %s\", reference.getName());\n+    }\n+  }\n+\n+  private static Predicate<EntriesResponse.Entry> namespacePredicate(Namespace ns) {\n+    // TODO: filter to just iceberg tables.\n+    if (ns == null) {\n+      return e -> true;\n+    }\n+\n+    final List<String> namespace = Arrays.asList(ns.levels());\n+    Predicate<EntriesResponse.Entry> predicate = e -> {\n+      List<String> names = e.getName().getElements();\n+\n+      if (names.size() <= namespace.size()) {\n+        return false;\n+      }\n+\n+      return namespace.equals(names.subList(0, namespace.size()));\n+    };\n+    return predicate;\n+  }\n+\n+  private static TableIdentifier toIdentifier(EntriesResponse.Entry entry) {\n+    List<String> elements = entry.getName().getElements();\n+    return TableIdentifier.of(elements.toArray(new String[elements.size()]));\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+    TableOperations ops = newTableOps(identifier);\n+    TableMetadata lastMetadata;\n+    if (purge && ops.current() != null) {\n+      lastMetadata = ops.current();\n+    } else {\n+      lastMetadata = null;\n+    }\n+\n+    try {\n+      client.getContentsApi().deleteContents(toKey(identifier), reference.getAsBranch().getName(), reference.getHash(),\n+          \"no message\");\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to drop table as ref is no longer valid.\", e);\n+    } catch (NessieConflictException e) {\n+      throw new RuntimeException(\"Failed to drop table as table state needs to be refreshed.\");\n+    }\n+\n+    // TODO: purge should be blocked since nessie will clean through other means.\n+    if (purge && lastMetadata != null) {\n+      BaseMetastoreCatalog.dropTableData(ops.io(), lastMetadata);\n+    }\n+    // TODO: fix this so we don't depend on it in tests.\n+    refresh();\n+    return true;\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier toOriginal) {\n+    reference.checkMutable();\n+\n+    TableIdentifier to = removeCatalogName(toOriginal);\n+\n+    IcebergTable existingFromTable = table(from);\n+    if (existingFromTable == null) {\n+      throw new NoSuchTableException(\"table %s doesn't exists\", from.name());\n+    }\n+    IcebergTable existingToTable = table(to);\n+    if (existingToTable != null) {\n+      throw new AlreadyExistsException(\"table %s already exists\", to.name());\n+    }\n+\n+    Operations contents = ImmutableOperations.builder()\n+        .addOperations(ImmutablePut.builder().key(toKey(to)).contents(existingFromTable).build(),\n+            ImmutableDelete.builder().key(toKey(from)).build())\n+        .build();\n+\n+    try {\n+      client.getTreeApi().commitMultipleOperations(reference.getAsBranch().getName(), reference.getHash(),\n+          \"iceberg rename table\", contents);\n+      // TODO: fix this so we don't depend on it in tests.\n+      refresh();\n+    } catch (Exception e) {\n+      throw new CommitFailedException(e, \"failed\");\n+    }\n+  }\n+\n+  private TableIdentifier removeCatalogName(TableIdentifier to) {\n+\n+    String[] levels = to.namespace().levels();\n+    // check if the identifier includes the catalog name and remove it\n+    if (levels.length >= 2 && name().equalsIgnoreCase(to.namespace().level(0))) {\n+      Namespace trimmedNamespace = Namespace.of(Arrays.copyOfRange(levels, 1, levels.length));\n+      return TableIdentifier.of(trimmedNamespace, to.name());\n+    }\n+\n+    // return the original unmodified\n+    return to;\n+  }\n+\n+  public TreeApi getTreeApi() {\n+    return client.getTreeApi();\n+  }\n+\n+  public void refresh() {\n+    reference.refresh();\n+  }\n+\n+  public String getHash() {\n+    return reference.getHash();\n+  }\n+\n+  public static Builder builder(Configuration conf) {\n+    return new Builder(conf);\n+  }\n+\n+  /**\n+   * creating namespaces in nessie is implicit, therefore this is a no-op. Metadata is ignored.\n+   *\n+   * @param namespace a multi-part namespace\n+   * @param metadata a string Map of properties for the given namespace\n+   */\n+  @Override\n+  public void createNamespace(Namespace namespace, Map<String, String> metadata) {\n+  }\n+\n+  @Override\n+  public List<Namespace> listNamespaces(Namespace namespace) throws NoSuchNamespaceException {\n+    return tableStream(namespace)\n+        .map(TableIdentifier::namespace)\n+        .filter(n -> !n.isEmpty())\n+        .distinct()\n+        .collect(Collectors.toList());\n+  }\n+\n+  /**\n+   * namespace metadata is not supported in Nessie and we return an empty map.\n+   *\n+   * @param namespace a namespace. {@link Namespace}\n+   * @return an empty map\n+   */\n+  @Override\n+  public Map<String, String> loadNamespaceMetadata(Namespace namespace) throws NoSuchNamespaceException {\n+    return ImmutableMap.of();\n+  }\n+\n+  /**\n+   * Namespaces in Nessie are implicit and deleting them results in a no-op.\n+   *\n+   * @param namespace a namespace. {@link Namespace}\n+   * @return always false.\n+   */\n+  @Override\n+  public boolean dropNamespace(Namespace namespace) throws NamespaceNotEmptyException {\n+    return false;\n+  }\n+\n+  @Override\n+  public boolean setProperties(Namespace namespace, Map<String, String> properties) throws NoSuchNamespaceException {\n+    throw new UnsupportedOperationException(\n+        \"Cannot set namespace properties \" + namespace + \" : setProperties is not supported\");\n+  }\n+\n+  @Override\n+  public boolean removeProperties(Namespace namespace, Set<String> properties) throws NoSuchNamespaceException {\n+    throw new UnsupportedOperationException(\n+        \"Cannot remove properties \" + namespace + \" : removeProperties is not supported\");\n+  }\n+\n+  @Override\n+  public void setConf(Configuration conf) {\n+    this.config = conf;\n+  }\n+\n+  @Override\n+  public Configuration getConf() {\n+    return config;\n+  }\n+\n+  @Override\n+  public void initialize(String inputName, Map<String, String> options) {\n+    this.name = inputName;\n+    init(options.getOrDefault(NessieClient.CONF_NESSIE_REF, config.get(NessieClient.CONF_NESSIE_REF)),\n+         options.getOrDefault(NessieClient.CONF_NESSIE_URL, config.get(NessieClient.CONF_NESSIE_URL)),\n+         options.getOrDefault(NESSIE_WAREHOUSE_DIR, config.get(NESSIE_WAREHOUSE_DIR)));\n+  }\n+\n+  public static class Builder {\n+    private final Configuration conf;\n+    private String url;\n+    private String ref;\n+    private String warehouseLocation;\n+    private String name;\n+\n+    public Builder(Configuration conf) {\n+      this.conf = conf;\n+    }\n+\n+    public Builder setUrl(String url) {\n+      this.url = url;\n+      return this;\n+    }\n+\n+    public Builder setRef(String ref) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58"}, "originalPosition": 412}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3NTQ0NzU1", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-527544755", "createdAt": "2020-11-10T19:37:21Z", "commit": {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxOTozNzoyMVrOHwsq3A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxOTozNzoyMVrOHwsq3A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyNTU2NA==", "bodyText": "If an update doesn't create a snapshot, then this method will return the app ID that committed the last snapshot. That may not be correct. Should we create a class in core to hold this information instead? Then we could set it somewhere in Spark and Flink so you'd always have identifiers without needing to resort to reflection?", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520825564", "createdAt": "2020-11-10T19:37:21Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableIcebergTable;\n+import java.util.Map;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.Snapshot;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.common.DynFields;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+\n+/**\n+ * Nessie implementation of Iceberg TableOperations.\n+ */\n+public class NessieTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static DynFields.StaticField<Object> sparkEnvMethod;\n+  private static DynFields.UnboundField<Object> sparkConfMethod;\n+  private static DynFields.UnboundField<Object> appIdMethod;\n+  private final Configuration conf;\n+  private final NessieClient client;\n+  private final ContentsKey key;\n+  private UpdateableReference reference;\n+  private IcebergTable table;\n+  private HadoopFileIO fileIO;\n+\n+  /**\n+   * Create a nessie table operations given a table identifier.\n+   */\n+  public NessieTableOperations(\n+      Configuration conf,\n+      ContentsKey key,\n+      UpdateableReference reference,\n+      NessieClient client) {\n+    this.conf = conf;\n+    this.key = key;\n+    this.reference = reference;\n+    this.client = client;\n+  }\n+\n+  @Override\n+  protected void doRefresh() {\n+    // break reference with parent (to avoid cross-over refresh)\n+    // TODO, confirm this is correct behavior.\n+    // reference = reference.copy();\n+\n+    reference.refresh();\n+    String metadataLocation = null;\n+    try {\n+      Contents contents = client.getContentsApi().getContents(key, reference.getHash());\n+      this.table = contents.unwrap(IcebergTable.class)\n+          .orElseThrow(() ->\n+              new IllegalStateException(\"Cannot refresh iceberg table: \" +\n+                  String.format(\"Nessie points to a non-Iceberg object for path: %s.\", key)));\n+      metadataLocation = table.getMetadataLocation();\n+    } catch (NessieNotFoundException ex) {\n+      if (currentMetadataLocation() != null) {\n+        throw new NoSuchTableException(ex, \"No such table %s\", key);\n+      }\n+    }\n+    refreshFromMetadataLocation(metadataLocation, 2);\n+  }\n+\n+  @Override\n+  protected void doCommit(TableMetadata base, TableMetadata metadata) {\n+    reference.checkMutable();\n+\n+    String newMetadataLocation = writeNewMetadata(metadata, currentVersion() + 1);\n+\n+    try {\n+      IcebergTable newTable = ImmutableIcebergTable.builder().metadataLocation(newMetadataLocation).build();\n+      client.getContentsApi().setContents(key,\n+                                          reference.getAsBranch().getName(),\n+                                          reference.getHash(),\n+                                          String.format(\"iceberg commit%s\", applicationId()),\n+                                          newTable);\n+    } catch (NessieConflictException ex) {\n+      io().deleteFile(newMetadataLocation);\n+      String fixMsg = reference.isBranch() ?\n+          String.format(\"Update the reference %s and try again\", reference.getName()) :\n+          String.format(\"Can't commit to the tag %s\", reference.getName());\n+      throw new CommitFailedException(ex, \"Commit failed: Reference hash is out of date. %s\", fixMsg);\n+    } catch (NessieNotFoundException ex) {\n+      io().deleteFile(newMetadataLocation);\n+      throw new RuntimeException(String.format(\"Commit failed: Reference %s does not exist\", reference.getName()), ex);\n+    } catch (Throwable e) {\n+      io().deleteFile(newMetadataLocation);\n+      throw new RuntimeException(\"Unexpected commit exception\", e);\n+    }\n+  }\n+\n+  @Override\n+  public FileIO io() {\n+    if (fileIO == null) {\n+      fileIO = new HadoopFileIO(conf);\n+    }\n+\n+    return fileIO;\n+  }\n+\n+  /**\n+   * try and get a Spark application id if one exists.\n+   *\n+   * <p>\n+   *   We haven't figured out a general way to pass commit messages through to the Nessie committer yet.\n+   *   This is hacky but gets the job done until we can have a more complete commit/audit log.\n+   * </p>\n+   */\n+  private String applicationId() {\n+    String appId = null;\n+    TableMetadata current = current();\n+    if (current != null) {\n+      Snapshot snapshot = current.currentSnapshot();\n+      if (snapshot != null) {\n+        Map<String, String> summary = snapshot.summary();\n+        appId = summary.get(\"spark.app.id\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58"}, "originalPosition": 144}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3NTQ1OTU4", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-527545958", "createdAt": "2020-11-10T19:38:59Z", "commit": {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxOTozOTowM1rOHwsueQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxOTozOTowM1rOHwsueQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyNjQ4OQ==", "bodyText": "What about doing this delete in a finally block if threw is false? That's usually a better way than catching Throwable and wrapping it in a RuntimeException.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520826489", "createdAt": "2020-11-10T19:39:03Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableIcebergTable;\n+import java.util.Map;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.Snapshot;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.common.DynFields;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+\n+/**\n+ * Nessie implementation of Iceberg TableOperations.\n+ */\n+public class NessieTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static DynFields.StaticField<Object> sparkEnvMethod;\n+  private static DynFields.UnboundField<Object> sparkConfMethod;\n+  private static DynFields.UnboundField<Object> appIdMethod;\n+  private final Configuration conf;\n+  private final NessieClient client;\n+  private final ContentsKey key;\n+  private UpdateableReference reference;\n+  private IcebergTable table;\n+  private HadoopFileIO fileIO;\n+\n+  /**\n+   * Create a nessie table operations given a table identifier.\n+   */\n+  public NessieTableOperations(\n+      Configuration conf,\n+      ContentsKey key,\n+      UpdateableReference reference,\n+      NessieClient client) {\n+    this.conf = conf;\n+    this.key = key;\n+    this.reference = reference;\n+    this.client = client;\n+  }\n+\n+  @Override\n+  protected void doRefresh() {\n+    // break reference with parent (to avoid cross-over refresh)\n+    // TODO, confirm this is correct behavior.\n+    // reference = reference.copy();\n+\n+    reference.refresh();\n+    String metadataLocation = null;\n+    try {\n+      Contents contents = client.getContentsApi().getContents(key, reference.getHash());\n+      this.table = contents.unwrap(IcebergTable.class)\n+          .orElseThrow(() ->\n+              new IllegalStateException(\"Cannot refresh iceberg table: \" +\n+                  String.format(\"Nessie points to a non-Iceberg object for path: %s.\", key)));\n+      metadataLocation = table.getMetadataLocation();\n+    } catch (NessieNotFoundException ex) {\n+      if (currentMetadataLocation() != null) {\n+        throw new NoSuchTableException(ex, \"No such table %s\", key);\n+      }\n+    }\n+    refreshFromMetadataLocation(metadataLocation, 2);\n+  }\n+\n+  @Override\n+  protected void doCommit(TableMetadata base, TableMetadata metadata) {\n+    reference.checkMutable();\n+\n+    String newMetadataLocation = writeNewMetadata(metadata, currentVersion() + 1);\n+\n+    try {\n+      IcebergTable newTable = ImmutableIcebergTable.builder().metadataLocation(newMetadataLocation).build();\n+      client.getContentsApi().setContents(key,\n+                                          reference.getAsBranch().getName(),\n+                                          reference.getHash(),\n+                                          String.format(\"iceberg commit%s\", applicationId()),\n+                                          newTable);\n+    } catch (NessieConflictException ex) {\n+      io().deleteFile(newMetadataLocation);\n+      String fixMsg = reference.isBranch() ?\n+          String.format(\"Update the reference %s and try again\", reference.getName()) :\n+          String.format(\"Can't commit to the tag %s\", reference.getName());\n+      throw new CommitFailedException(ex, \"Commit failed: Reference hash is out of date. %s\", fixMsg);\n+    } catch (NessieNotFoundException ex) {\n+      io().deleteFile(newMetadataLocation);\n+      throw new RuntimeException(String.format(\"Commit failed: Reference %s does not exist\", reference.getName()), ex);\n+    } catch (Throwable e) {\n+      io().deleteFile(newMetadataLocation);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58"}, "originalPosition": 115}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3NTQ3OTMx", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-527547931", "createdAt": "2020-11-10T19:41:46Z", "commit": {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxOTo0MTo0N1rOHws0lQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQxOTo0MTo0N1rOHws0lQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDgyODA1Mw==", "bodyText": "This doesn't seem correct to me. I try to maintain single-table state by catalog, so that all uses of a table stay in sync. I think it would make sense to do the same with refs. If you update a branch by refreshing or committing any table, it should also refresh everything that is related to stay in sync. Otherwise, you're left with the problem of not knowing whether two tables with the same ref are in sync.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520828053", "createdAt": "2020-11-10T19:41:47Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java", "diffHunk": "@@ -0,0 +1,151 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableIcebergTable;\n+import java.util.Map;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.Snapshot;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.common.DynFields;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+\n+/**\n+ * Nessie implementation of Iceberg TableOperations.\n+ */\n+public class NessieTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static DynFields.StaticField<Object> sparkEnvMethod;\n+  private static DynFields.UnboundField<Object> sparkConfMethod;\n+  private static DynFields.UnboundField<Object> appIdMethod;\n+  private final Configuration conf;\n+  private final NessieClient client;\n+  private final ContentsKey key;\n+  private UpdateableReference reference;\n+  private IcebergTable table;\n+  private HadoopFileIO fileIO;\n+\n+  /**\n+   * Create a nessie table operations given a table identifier.\n+   */\n+  public NessieTableOperations(\n+      Configuration conf,\n+      ContentsKey key,\n+      UpdateableReference reference,\n+      NessieClient client) {\n+    this.conf = conf;\n+    this.key = key;\n+    this.reference = reference;\n+    this.client = client;\n+  }\n+\n+  @Override\n+  protected void doRefresh() {\n+    // break reference with parent (to avoid cross-over refresh)\n+    // TODO, confirm this is correct behavior.\n+    // reference = reference.copy();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58"}, "originalPosition": 73}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "6eba2838dd053690f7f0e66ed0f3095147465a58", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/6eba2838dd053690f7f0e66ed0f3095147465a58", "committedDate": "2020-11-09T12:44:51Z", "message": "simpler way to get spark app id"}, "afterCommit": {"oid": "e3748801b817a76dc1c71f76904271222c7a5f99", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/e3748801b817a76dc1c71f76904271222c7a5f99", "committedDate": "2020-11-10T20:54:02Z", "message": "address code review"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3NjM5NzQy", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-527639742", "createdAt": "2020-11-10T21:56:24Z", "commit": {"oid": "e3748801b817a76dc1c71f76904271222c7a5f99"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQyMTo1NjoyNFrOHwxKOg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQyMTo1NjoyNFrOHwxKOg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg5OTEzMA==", "bodyText": "We try to use simpler error messages and avoid referring to specific people, like \"we\" or \"you\". A good rule of thumb is \"Cannot [some action]: [problem[ [(suggestion to fix)]\" or \"Invalid [something]: [problem]\". How about \"Invalid table name: # is not allowed (reference by timestamp is not supported)\"?", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520899130", "createdAt": "2020-11-10T21:56:24Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/ParsedTableIdentifier.java", "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import java.time.Instant;\n+import java.util.Map;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+public class ParsedTableIdentifier {\n+\n+  private final TableIdentifier tableIdentifier;\n+  private final Instant timestamp;\n+  private final String reference;\n+\n+  /**\n+   * container class to hold all options in a Nessie table name.\n+   */\n+  public ParsedTableIdentifier(TableIdentifier tableIdentifier, Instant timestamp, String reference) {\n+    this.tableIdentifier = tableIdentifier;\n+    this.timestamp = timestamp;\n+    this.reference = reference;\n+  }\n+\n+  public TableIdentifier getTableIdentifier() {\n+    return tableIdentifier;\n+  }\n+\n+  public Instant getTimestamp() {\n+    return timestamp;\n+  }\n+\n+  public String getReference() {\n+    return reference;\n+  }\n+\n+  /**\n+   * Convert dataset read/write options to a table and ref/hash.\n+   */\n+  public static ParsedTableIdentifier getParsedTableIdentifier(TableIdentifier path) {\n+    return getParsedTableIdentifier(path, ImmutableMap.of());\n+  }\n+  /**\n+   * Convert dataset read/write options to a table and ref/hash.\n+   */\n+  public static ParsedTableIdentifier getParsedTableIdentifier(String path, Map<String, String> properties) {\n+    // I am assuming tables can't have @ or # symbols\n+    if (path.split(\"@\").length > 2) {\n+      throw new IllegalArgumentException(String.format(\"Can only reference one branch in %s\", path));\n+    }\n+    if (path.split(\"#\").length > 2) {\n+      throw new IllegalArgumentException(String.format(\"Can only reference one timestamp in %s\", path));\n+    }\n+\n+    if (path.contains(\"@\") && path.contains(\"#\")) {\n+      throw new IllegalArgumentException(\"Currently we don't support referencing by timestamp, # is not allowed in \" +\n+          \"the table name\");\n+    }\n+\n+    if (path.contains(\"@\")) {\n+      String[] tableRef = path.split(\"@\");\n+      TableIdentifier identifier = TableIdentifier.parse(tableRef[0]);\n+      return new ParsedTableIdentifier(identifier, null, tableRef[1]);\n+    }\n+\n+    if (path.contains(\"#\")) {\n+      throw new IllegalArgumentException(\"Currently we don't support referencing by timestamp, # is not allowed in \" +", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e3748801b817a76dc1c71f76904271222c7a5f99"}, "originalPosition": 85}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3NjM5ODYy", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-527639862", "createdAt": "2020-11-10T21:56:34Z", "commit": {"oid": "e3748801b817a76dc1c71f76904271222c7a5f99"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQyMTo1NjozNVrOHwxKkQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQyMTo1NjozNVrOHwxKkQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDg5OTIxNw==", "bodyText": "Can we use a simpler verb, like parse or parseTableIdentifier? It's wordy to use \"get\" and then a past tense verb.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520899217", "createdAt": "2020-11-10T21:56:35Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/ParsedTableIdentifier.java", "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import java.time.Instant;\n+import java.util.Map;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+public class ParsedTableIdentifier {\n+\n+  private final TableIdentifier tableIdentifier;\n+  private final Instant timestamp;\n+  private final String reference;\n+\n+  /**\n+   * container class to hold all options in a Nessie table name.\n+   */\n+  public ParsedTableIdentifier(TableIdentifier tableIdentifier, Instant timestamp, String reference) {\n+    this.tableIdentifier = tableIdentifier;\n+    this.timestamp = timestamp;\n+    this.reference = reference;\n+  }\n+\n+  public TableIdentifier getTableIdentifier() {\n+    return tableIdentifier;\n+  }\n+\n+  public Instant getTimestamp() {\n+    return timestamp;\n+  }\n+\n+  public String getReference() {\n+    return reference;\n+  }\n+\n+  /**\n+   * Convert dataset read/write options to a table and ref/hash.\n+   */\n+  public static ParsedTableIdentifier getParsedTableIdentifier(TableIdentifier path) {\n+    return getParsedTableIdentifier(path, ImmutableMap.of());\n+  }\n+  /**\n+   * Convert dataset read/write options to a table and ref/hash.\n+   */\n+  public static ParsedTableIdentifier getParsedTableIdentifier(String path, Map<String, String> properties) {\n+    // I am assuming tables can't have @ or # symbols\n+    if (path.split(\"@\").length > 2) {\n+      throw new IllegalArgumentException(String.format(\"Can only reference one branch in %s\", path));\n+    }\n+    if (path.split(\"#\").length > 2) {\n+      throw new IllegalArgumentException(String.format(\"Can only reference one timestamp in %s\", path));\n+    }\n+\n+    if (path.contains(\"@\") && path.contains(\"#\")) {\n+      throw new IllegalArgumentException(\"Currently we don't support referencing by timestamp, # is not allowed in \" +\n+          \"the table name\");\n+    }\n+\n+    if (path.contains(\"@\")) {\n+      String[] tableRef = path.split(\"@\");\n+      TableIdentifier identifier = TableIdentifier.parse(tableRef[0]);\n+      return new ParsedTableIdentifier(identifier, null, tableRef[1]);\n+    }\n+\n+    if (path.contains(\"#\")) {\n+      throw new IllegalArgumentException(\"Currently we don't support referencing by timestamp, # is not allowed in \" +\n+          \"the table name\");\n+    }\n+\n+    TableIdentifier identifier = TableIdentifier.parse(path);\n+    String reference = properties.get(NessieClient.CONF_NESSIE_REF);\n+    return new ParsedTableIdentifier(identifier, null, reference);\n+  }\n+\n+  /**\n+   * Convert dataset read/write options to a table and ref/hash.\n+   */\n+  public static ParsedTableIdentifier getParsedTableIdentifier(TableIdentifier path, Map<String, String> properties) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e3748801b817a76dc1c71f76904271222c7a5f99"}, "originalPosition": 97}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3NjQxNTE3", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-527641517", "createdAt": "2020-11-10T21:59:10Z", "commit": {"oid": "e3748801b817a76dc1c71f76904271222c7a5f99"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQyMTo1OToxMFrOHwxPhw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQyMTo1OToxMFrOHwxPhw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwMDQ4Nw==", "bodyText": "I'm wondering if there is a more specific name for this class. Maybe something like TableReference because it has both an identifier and a ref? Or maybe NessieIdentifier? ParsedTableIdentifier doesn't really tell me what is different about this as opposed to TableIdentifier.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520900487", "createdAt": "2020-11-10T21:59:10Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/ParsedTableIdentifier.java", "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import java.time.Instant;\n+import java.util.Map;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+public class ParsedTableIdentifier {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e3748801b817a76dc1c71f76904271222c7a5f99"}, "originalPosition": 28}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3NjQ0NDk3", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-527644497", "createdAt": "2020-11-10T22:03:39Z", "commit": {"oid": "e3748801b817a76dc1c71f76904271222c7a5f99"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQyMjowMzozOVrOHwxYNA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQyMjowMzozOVrOHwxYNA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwMjcwOA==", "bodyText": "Table no longer exists? Or the ref no longer exists?\nAlso, NotFoundException is for files that don't exist. Tables should use NoSuchTableException", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520902708", "createdAt": "2020-11-10T22:03:39Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/UpdateableReference.java", "diffHunk": "@@ -0,0 +1,80 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Branch;\n+import com.dremio.nessie.model.Hash;\n+import com.dremio.nessie.model.Reference;\n+import org.apache.iceberg.exceptions.NotFoundException;\n+\n+class UpdateableReference {\n+\n+  private Reference reference;\n+  private final TreeApi client;\n+\n+  UpdateableReference(Reference reference, TreeApi client) {\n+    this.reference = reference;\n+    this.client = client;\n+  }\n+\n+  public boolean refresh() {\n+    if (reference instanceof Hash) {\n+      return false;\n+    }\n+    Reference oldReference = reference;\n+    try {\n+      reference = client.getReferenceByName(reference.getName());\n+    } catch (NessieNotFoundException e) {\n+      throw new NotFoundException(e, \"Failure refreshing data, table no longer exists.\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e3748801b817a76dc1c71f76904271222c7a5f99"}, "originalPosition": 47}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3NjQ1Nzg0", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-527645784", "createdAt": "2020-11-10T22:05:48Z", "commit": {"oid": "e3748801b817a76dc1c71f76904271222c7a5f99"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQyMjowNTo0OFrOHwxcRg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQyMjowNTo0OFrOHwxcRg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwMzc1MA==", "bodyText": "Most tests use @Rule TemporaryFolder temp so that JUnit handles temp lifecycle. I'd recommend doing that here, too.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520903750", "createdAt": "2020-11-10T22:05:48Z", "author": {"login": "rdblue"}, "path": "nessie/src/test/java/org/apache/iceberg/nessie/BaseTestIceberg.java", "diffHunk": "@@ -0,0 +1,171 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.ContentsApi;\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Branch;\n+import com.dremio.nessie.model.Reference;\n+import java.io.File;\n+import java.nio.file.attribute.PosixFilePermissions;\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseTable;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.types.Types;\n+import org.apache.iceberg.types.Types.LongType;\n+import org.apache.iceberg.types.Types.StructType;\n+import org.junit.After;\n+import org.junit.AfterClass;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+public abstract class BaseTestIceberg {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(BaseTestIceberg.class);\n+\n+  protected static File tempDir;\n+  protected NessieCatalog catalog;\n+  protected NessieClient client;\n+  protected TreeApi tree;\n+  protected ContentsApi contents;\n+  protected Configuration hadoopConfig;\n+  protected final String branch;\n+\n+  @BeforeClass\n+  public static void create() throws Exception {\n+    tempDir = java.nio.file.Files.createTempDirectory(\n+        \"test\",\n+        PosixFilePermissions.asFileAttribute(PosixFilePermissions.fromString(\"rwxrwxrwx\")))", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e3748801b817a76dc1c71f76904271222c7a5f99"}, "originalPosition": 68}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3NjQ3MDA2", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-527647006", "createdAt": "2020-11-10T22:07:45Z", "commit": {"oid": "e3748801b817a76dc1c71f76904271222c7a5f99"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQyMjowNzo0NVrOHwxf1g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQyMjowNzo0NVrOHwxf1g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwNDY2Mg==", "bodyText": "This looks like it should have a more specific name because it returns the metadata location for a table.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520904662", "createdAt": "2020-11-10T22:07:45Z", "author": {"login": "rdblue"}, "path": "nessie/src/test/java/org/apache/iceberg/nessie/BaseTestIceberg.java", "diffHunk": "@@ -0,0 +1,171 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.ContentsApi;\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Branch;\n+import com.dremio.nessie.model.Reference;\n+import java.io.File;\n+import java.nio.file.attribute.PosixFilePermissions;\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseTable;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.types.Types;\n+import org.apache.iceberg.types.Types.LongType;\n+import org.apache.iceberg.types.Types.StructType;\n+import org.junit.After;\n+import org.junit.AfterClass;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+public abstract class BaseTestIceberg {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(BaseTestIceberg.class);\n+\n+  protected static File tempDir;\n+  protected NessieCatalog catalog;\n+  protected NessieClient client;\n+  protected TreeApi tree;\n+  protected ContentsApi contents;\n+  protected Configuration hadoopConfig;\n+  protected final String branch;\n+\n+  @BeforeClass\n+  public static void create() throws Exception {\n+    tempDir = java.nio.file.Files.createTempDirectory(\n+        \"test\",\n+        PosixFilePermissions.asFileAttribute(PosixFilePermissions.fromString(\"rwxrwxrwx\")))\n+        .toFile();\n+  }\n+\n+  public BaseTestIceberg(String branch) {\n+    this.branch = branch;\n+  }\n+\n+  private void resetData() throws NessieConflictException, NessieNotFoundException {\n+    for (Reference r : tree.getAllReferences()) {\n+      if (r instanceof Branch) {\n+        tree.deleteBranch(r.getName(), r.getHash());\n+      } else {\n+        tree.deleteTag(r.getName(), r.getHash());\n+      }\n+    }\n+    tree.createReference(Branch.of(\"main\", null));\n+  }\n+\n+  @Before\n+  public void beforeEach() throws NessieConflictException, NessieNotFoundException {\n+    String port = System.getProperty(\"quarkus.http.test-port\", \"19120\");\n+    String path = String.format(\"http://localhost:%s/api/v1\", port);\n+    this.client = NessieClient.none(path);\n+    tree = client.getTreeApi();\n+    contents = client.getContentsApi();\n+\n+    resetData();\n+\n+    try {\n+      tree.createReference(Branch.of(branch, null));\n+    } catch (Exception e) {\n+      // ignore, already created. Cant run this in BeforeAll as quarkus hasn't disabled auth\n+    }\n+\n+    hadoopConfig = new Configuration();\n+    hadoopConfig.set(NessieClient.CONF_NESSIE_URL, path);\n+    hadoopConfig.set(NessieClient.CONF_NESSIE_REF, branch);\n+    hadoopConfig.set(NessieClient.CONF_NESSIE_AUTH_TYPE, \"NONE\");\n+    hadoopConfig.set(\"nessie.warehouse.dir\", tempDir.toURI().toString());\n+    catalog = initCatalog(branch);\n+  }\n+\n+  NessieCatalog initCatalog(String ref) {\n+    NessieCatalog newCatalog = new NessieCatalog();\n+    newCatalog.setConf(hadoopConfig);\n+    newCatalog.initialize(null, ImmutableMap.of(NessieClient.CONF_NESSIE_REF, ref));\n+    return newCatalog;\n+  }\n+\n+  protected Table createTable(TableIdentifier tableIdentifier, int count) {\n+    try {\n+      return catalog.createTable(tableIdentifier, schema(count));\n+    } catch (Throwable t) {\n+      LOGGER.error(\"unable to do create \" + tableIdentifier.toString(), t);\n+      throw t;\n+    }\n+  }\n+\n+  protected void createTable(TableIdentifier tableIdentifier) {\n+    Schema schema = new Schema(StructType.of(required(1, \"id\", LongType.get()))\n+                                         .fields());\n+    catalog.createTable(tableIdentifier, schema).location();\n+  }\n+\n+  protected static Schema schema(int count) {\n+    List<Types.NestedField> fields = new ArrayList<>();\n+    for (int i = 0; i < count; i++) {\n+      fields.add(required(i, \"id\" + i, Types.LongType.get()));\n+    }\n+    return new Schema(Types.StructType.of(fields).fields());\n+  }\n+\n+  void createBranch(String name, String hash) throws NessieNotFoundException, NessieConflictException {\n+    if (hash == null) {\n+      tree.createReference(Branch.of(name, null));\n+    } else {\n+      tree.createReference(Branch.of(name, hash));\n+    }\n+  }\n+\n+  @After\n+  public void afterEach() throws Exception {\n+    catalog.close();\n+    client.close();\n+    catalog = null;\n+    client = null;\n+    hadoopConfig = null;\n+  }\n+\n+  @AfterClass\n+  public static void destroy() throws Exception {\n+    tempDir.delete();\n+  }\n+\n+  static String getContent(NessieCatalog catalog, TableIdentifier tableIdentifier) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e3748801b817a76dc1c71f76904271222c7a5f99"}, "originalPosition": 163}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3NjQ3NTE4", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-527647518", "createdAt": "2020-11-10T22:08:31Z", "commit": {"oid": "e3748801b817a76dc1c71f76904271222c7a5f99"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQyMjowODozMVrOHwxhZw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQyMjowODozMVrOHwxhZw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwNTA2Mw==", "bodyText": "Looks like this could just always pass hash.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520905063", "createdAt": "2020-11-10T22:08:31Z", "author": {"login": "rdblue"}, "path": "nessie/src/test/java/org/apache/iceberg/nessie/BaseTestIceberg.java", "diffHunk": "@@ -0,0 +1,171 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.ContentsApi;\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Branch;\n+import com.dremio.nessie.model.Reference;\n+import java.io.File;\n+import java.nio.file.attribute.PosixFilePermissions;\n+import java.util.ArrayList;\n+import java.util.List;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseTable;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.types.Types;\n+import org.apache.iceberg.types.Types.LongType;\n+import org.apache.iceberg.types.Types.StructType;\n+import org.junit.After;\n+import org.junit.AfterClass;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+public abstract class BaseTestIceberg {\n+\n+  private static final Logger LOGGER = LoggerFactory.getLogger(BaseTestIceberg.class);\n+\n+  protected static File tempDir;\n+  protected NessieCatalog catalog;\n+  protected NessieClient client;\n+  protected TreeApi tree;\n+  protected ContentsApi contents;\n+  protected Configuration hadoopConfig;\n+  protected final String branch;\n+\n+  @BeforeClass\n+  public static void create() throws Exception {\n+    tempDir = java.nio.file.Files.createTempDirectory(\n+        \"test\",\n+        PosixFilePermissions.asFileAttribute(PosixFilePermissions.fromString(\"rwxrwxrwx\")))\n+        .toFile();\n+  }\n+\n+  public BaseTestIceberg(String branch) {\n+    this.branch = branch;\n+  }\n+\n+  private void resetData() throws NessieConflictException, NessieNotFoundException {\n+    for (Reference r : tree.getAllReferences()) {\n+      if (r instanceof Branch) {\n+        tree.deleteBranch(r.getName(), r.getHash());\n+      } else {\n+        tree.deleteTag(r.getName(), r.getHash());\n+      }\n+    }\n+    tree.createReference(Branch.of(\"main\", null));\n+  }\n+\n+  @Before\n+  public void beforeEach() throws NessieConflictException, NessieNotFoundException {\n+    String port = System.getProperty(\"quarkus.http.test-port\", \"19120\");\n+    String path = String.format(\"http://localhost:%s/api/v1\", port);\n+    this.client = NessieClient.none(path);\n+    tree = client.getTreeApi();\n+    contents = client.getContentsApi();\n+\n+    resetData();\n+\n+    try {\n+      tree.createReference(Branch.of(branch, null));\n+    } catch (Exception e) {\n+      // ignore, already created. Cant run this in BeforeAll as quarkus hasn't disabled auth\n+    }\n+\n+    hadoopConfig = new Configuration();\n+    hadoopConfig.set(NessieClient.CONF_NESSIE_URL, path);\n+    hadoopConfig.set(NessieClient.CONF_NESSIE_REF, branch);\n+    hadoopConfig.set(NessieClient.CONF_NESSIE_AUTH_TYPE, \"NONE\");\n+    hadoopConfig.set(\"nessie.warehouse.dir\", tempDir.toURI().toString());\n+    catalog = initCatalog(branch);\n+  }\n+\n+  NessieCatalog initCatalog(String ref) {\n+    NessieCatalog newCatalog = new NessieCatalog();\n+    newCatalog.setConf(hadoopConfig);\n+    newCatalog.initialize(null, ImmutableMap.of(NessieClient.CONF_NESSIE_REF, ref));\n+    return newCatalog;\n+  }\n+\n+  protected Table createTable(TableIdentifier tableIdentifier, int count) {\n+    try {\n+      return catalog.createTable(tableIdentifier, schema(count));\n+    } catch (Throwable t) {\n+      LOGGER.error(\"unable to do create \" + tableIdentifier.toString(), t);\n+      throw t;\n+    }\n+  }\n+\n+  protected void createTable(TableIdentifier tableIdentifier) {\n+    Schema schema = new Schema(StructType.of(required(1, \"id\", LongType.get()))\n+                                         .fields());\n+    catalog.createTable(tableIdentifier, schema).location();\n+  }\n+\n+  protected static Schema schema(int count) {\n+    List<Types.NestedField> fields = new ArrayList<>();\n+    for (int i = 0; i < count; i++) {\n+      fields.add(required(i, \"id\" + i, Types.LongType.get()));\n+    }\n+    return new Schema(Types.StructType.of(fields).fields());\n+  }\n+\n+  void createBranch(String name, String hash) throws NessieNotFoundException, NessieConflictException {\n+    if (hash == null) {\n+      tree.createReference(Branch.of(name, null));\n+    } else {\n+      tree.createReference(Branch.of(name, hash));\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e3748801b817a76dc1c71f76904271222c7a5f99"}, "originalPosition": 146}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3NjQ5MTc1", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-527649175", "createdAt": "2020-11-10T22:11:02Z", "commit": {"oid": "e3748801b817a76dc1c71f76904271222c7a5f99"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQyMjoxMTowMlrOHwxmcA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQyMjoxMTowMlrOHwxmcA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwNjM1Mg==", "bodyText": "I prefer to separate tests into distinct cases. It looks like this combines testRename with testListTables. Combining test cases into a single method causes failures to prevent other tests from running, which makes the whole suite harder to work with.\nIt is also a lot easier to spot missing test cases and add new ones when tests are separate. I'd recommend taking a look at most of these test suites.\nThat said, I think that you'll be the primary reviewers here so in the end it is mostly up to you what conventions you want to maintain.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520906352", "createdAt": "2020-11-10T22:11:02Z", "author": {"login": "rdblue"}, "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestCatalog.java", "diffHunk": "@@ -0,0 +1,53 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import java.util.List;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestCatalog extends BaseTestIceberg {\n+\n+  private static final String BRANCH = \"test-catalog-branch\";\n+\n+  public TestCatalog() {\n+    super(BRANCH);\n+  }\n+\n+  @Test\n+  public void test() {\n+    createTable(TableIdentifier.of(\"foo\", \"bar\"));\n+    List<TableIdentifier> tables = catalog.listTables(Namespace.of(\"foo\"));\n+    Assert.assertEquals(1, tables.size());\n+    Assert.assertEquals(\"bar\", tables.get(0).name());\n+    Assert.assertEquals(\"foo\", tables.get(0).namespace().toString());\n+    catalog.renameTable(TableIdentifier.of(\"foo\", \"bar\"), TableIdentifier.of(\"foo\", \"baz\"));\n+    tables = catalog.listTables(null);\n+    Assert.assertEquals(1, tables.size());\n+    Assert.assertEquals(\"baz\", tables.get(0).name());\n+    Assert.assertEquals(\"foo\", tables.get(0).namespace().toString());\n+    catalog.dropTable(TableIdentifier.of(\"foo\", \"baz\"));\n+    tables = catalog.listTables(Namespace.empty());\n+    Assert.assertTrue(tables.isEmpty());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e3748801b817a76dc1c71f76904271222c7a5f99"}, "originalPosition": 50}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3NjUxMDA4", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-527651008", "createdAt": "2020-11-10T22:14:01Z", "commit": {"oid": "e3748801b817a76dc1c71f76904271222c7a5f99"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQyMjoxNDowMVrOHwxsXg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQyMjoxNDowMVrOHwxsXg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwNzg3MA==", "bodyText": "What is this suppressing?", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520907870", "createdAt": "2020-11-10T22:14:01Z", "author": {"login": "rdblue"}, "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestNessieTable.java", "diffHunk": "@@ -0,0 +1,349 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Branch;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import org.apache.avro.generic.GenericData;\n+import org.apache.avro.generic.GenericRecordBuilder;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.DataFile;\n+import org.apache.iceberg.DataFiles;\n+import org.apache.iceberg.Files;\n+import org.apache.iceberg.HasTableOperations;\n+import org.apache.iceberg.ManifestFile;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.TableMetadataParser;\n+import org.apache.iceberg.avro.Avro;\n+import org.apache.iceberg.avro.AvroSchemaUtil;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.io.FileAppender;\n+import org.apache.iceberg.types.Types;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import static org.apache.iceberg.TableMetadataParser.getFileExtension;\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+\n+public class TestNessieTable extends BaseTestIceberg {\n+\n+  private static final String BRANCH = \"iceberg-table-test\";\n+\n+  private static final String DB_NAME = \"db\";\n+  private static final String TABLE_NAME = \"tbl\";\n+  private static final TableIdentifier TABLE_IDENTIFIER = TableIdentifier.of(DB_NAME, TABLE_NAME);\n+  private static final ContentsKey KEY = ContentsKey.of(DB_NAME, TABLE_NAME);\n+  private static final Schema schema = new Schema(Types.StructType.of(\n+      required(1, \"id\", Types.LongType.get())).fields());\n+  private static final Schema altered = new Schema(Types.StructType.of(\n+      required(1, \"id\", Types.LongType.get()),\n+      optional(2, \"data\", Types.LongType.get())).fields());\n+\n+  private Path tableLocation;\n+\n+  public TestNessieTable() {\n+    super(BRANCH);\n+  }\n+\n+  @Before\n+  public void beforeEach() throws NessieConflictException, NessieNotFoundException {\n+    super.beforeEach();\n+    this.tableLocation = new Path(catalog.createTable(TABLE_IDENTIFIER, schema).location());\n+  }\n+\n+  @After\n+  public void afterEach() throws Exception {\n+    // drop the table data\n+    if (tableLocation != null) {\n+      tableLocation.getFileSystem(hadoopConfig).delete(tableLocation, true);\n+      catalog.refresh();\n+      catalog.dropTable(TABLE_IDENTIFIER, false);\n+    }\n+\n+    super.afterEach();\n+  }\n+\n+  private com.dremio.nessie.model.IcebergTable getTable(ContentsKey key) throws NessieNotFoundException {\n+    return client.getContentsApi()\n+        .getContents(key, BRANCH)\n+        .unwrap(IcebergTable.class).get();\n+  }\n+\n+  @Test\n+  public void testCreate() throws NessieNotFoundException {\n+    // Table should be created in iceberg\n+    // Table should be renamed in iceberg\n+    String tableName = TABLE_IDENTIFIER.name();\n+    Table icebergTable = catalog.loadTable(TABLE_IDENTIFIER);\n+    // add a column\n+    icebergTable.updateSchema().addColumn(\"mother\", Types.LongType.get()).commit();\n+    IcebergTable table = getTable(KEY);\n+    // check parameters are in expected state\n+    Assert.assertEquals(getTableLocation(tableName),\n+                            (tempDir.toURI().toString() + DB_NAME + \"/\" +\n+                             tableName).replace(\"//\",\n+                                                \"/\"));\n+\n+    // Only 1 snapshotFile Should exist and no manifests should exist\n+    Assert.assertEquals(2, metadataVersionFiles(tableName).size());\n+    Assert.assertEquals(0, manifestFiles(tableName).size());\n+  }\n+\n+\n+  @SuppressWarnings(\"VariableDeclarationUsageDistance\")\n+  @Test\n+  public void testRename() {\n+    String renamedTableName = \"rename_table_name\";\n+    TableIdentifier renameTableIdentifier = TableIdentifier.of(TABLE_IDENTIFIER.namespace(),\n+                                                               renamedTableName);\n+\n+    Table original = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    catalog.renameTable(TABLE_IDENTIFIER, renameTableIdentifier);\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+    Assert.assertTrue(catalog.tableExists(renameTableIdentifier));\n+\n+    Table renamed = catalog.loadTable(renameTableIdentifier);\n+\n+    Assert.assertEquals(original.schema().asStruct(), renamed.schema().asStruct());\n+    Assert.assertEquals(original.spec(), renamed.spec());\n+    Assert.assertEquals(original.location(), renamed.location());\n+    Assert.assertEquals(original.currentSnapshot(), renamed.currentSnapshot());\n+\n+    Assert.assertTrue(catalog.dropTable(renameTableIdentifier));\n+  }\n+\n+  @Test\n+  public void testDrop() {\n+    Assert.assertTrue(catalog.tableExists(TABLE_IDENTIFIER));\n+    Assert.assertTrue(catalog.dropTable(TABLE_IDENTIFIER));\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+  }\n+\n+  @Test\n+  public void testDropWithoutPurgeLeavesTableData() throws IOException {\n+    Table table = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    GenericRecordBuilder recordBuilder =\n+        new GenericRecordBuilder(AvroSchemaUtil.convert(schema, \"test\"));\n+    List<GenericData.Record> records = new ArrayList<>();\n+    records.add(recordBuilder.set(\"id\", 1L).build());\n+    records.add(recordBuilder.set(\"id\", 2L).build());\n+    records.add(recordBuilder.set(\"id\", 3L).build());\n+\n+    String fileLocation = table.location().replace(\"file:\", \"\") + \"/data/file.avro\";\n+    try (FileAppender<GenericData.Record> writer = Avro.write(Files.localOutput(fileLocation))\n+                                                       .schema(schema)\n+                                                       .named(\"test\")\n+                                                       .build()) {\n+      for (GenericData.Record rec : records) {\n+        writer.add(rec);\n+      }\n+    }\n+\n+    DataFile file = DataFiles.builder(table.spec())\n+                             .withRecordCount(3)\n+                             .withPath(fileLocation)\n+                             .withFileSizeInBytes(Files.localInput(fileLocation).getLength())\n+                             .build();\n+\n+    table.newAppend().appendFile(file).commit();\n+\n+    String manifestListLocation =\n+        table.currentSnapshot().manifestListLocation().replace(\"file:\", \"\");\n+\n+    Assert.assertTrue(catalog.dropTable(TABLE_IDENTIFIER, false));\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+\n+    Assert.assertTrue(new File(fileLocation).exists());\n+    Assert.assertTrue(new File(manifestListLocation).exists());\n+  }\n+\n+\n+  @SuppressWarnings(\"VariableDeclarationUsageDistance\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e3748801b817a76dc1c71f76904271222c7a5f99"}, "originalPosition": 197}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3NjUxNzk4", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-527651798", "createdAt": "2020-11-10T22:15:19Z", "commit": {"oid": "e3748801b817a76dc1c71f76904271222c7a5f99"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQyMjoxNToxOVrOHwxu5g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQyMjoxNToxOVrOHwxu5g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwODUxOA==", "bodyText": "Can you use AssertHelpers.assertThrows instead? That way, you can add assertions after the exception to check other things, like that the table has not been modified.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520908518", "createdAt": "2020-11-10T22:15:19Z", "author": {"login": "rdblue"}, "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestNessieTable.java", "diffHunk": "@@ -0,0 +1,349 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Branch;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import org.apache.avro.generic.GenericData;\n+import org.apache.avro.generic.GenericRecordBuilder;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.DataFile;\n+import org.apache.iceberg.DataFiles;\n+import org.apache.iceberg.Files;\n+import org.apache.iceberg.HasTableOperations;\n+import org.apache.iceberg.ManifestFile;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.TableMetadataParser;\n+import org.apache.iceberg.avro.Avro;\n+import org.apache.iceberg.avro.AvroSchemaUtil;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.io.FileAppender;\n+import org.apache.iceberg.types.Types;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import static org.apache.iceberg.TableMetadataParser.getFileExtension;\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+\n+public class TestNessieTable extends BaseTestIceberg {\n+\n+  private static final String BRANCH = \"iceberg-table-test\";\n+\n+  private static final String DB_NAME = \"db\";\n+  private static final String TABLE_NAME = \"tbl\";\n+  private static final TableIdentifier TABLE_IDENTIFIER = TableIdentifier.of(DB_NAME, TABLE_NAME);\n+  private static final ContentsKey KEY = ContentsKey.of(DB_NAME, TABLE_NAME);\n+  private static final Schema schema = new Schema(Types.StructType.of(\n+      required(1, \"id\", Types.LongType.get())).fields());\n+  private static final Schema altered = new Schema(Types.StructType.of(\n+      required(1, \"id\", Types.LongType.get()),\n+      optional(2, \"data\", Types.LongType.get())).fields());\n+\n+  private Path tableLocation;\n+\n+  public TestNessieTable() {\n+    super(BRANCH);\n+  }\n+\n+  @Before\n+  public void beforeEach() throws NessieConflictException, NessieNotFoundException {\n+    super.beforeEach();\n+    this.tableLocation = new Path(catalog.createTable(TABLE_IDENTIFIER, schema).location());\n+  }\n+\n+  @After\n+  public void afterEach() throws Exception {\n+    // drop the table data\n+    if (tableLocation != null) {\n+      tableLocation.getFileSystem(hadoopConfig).delete(tableLocation, true);\n+      catalog.refresh();\n+      catalog.dropTable(TABLE_IDENTIFIER, false);\n+    }\n+\n+    super.afterEach();\n+  }\n+\n+  private com.dremio.nessie.model.IcebergTable getTable(ContentsKey key) throws NessieNotFoundException {\n+    return client.getContentsApi()\n+        .getContents(key, BRANCH)\n+        .unwrap(IcebergTable.class).get();\n+  }\n+\n+  @Test\n+  public void testCreate() throws NessieNotFoundException {\n+    // Table should be created in iceberg\n+    // Table should be renamed in iceberg\n+    String tableName = TABLE_IDENTIFIER.name();\n+    Table icebergTable = catalog.loadTable(TABLE_IDENTIFIER);\n+    // add a column\n+    icebergTable.updateSchema().addColumn(\"mother\", Types.LongType.get()).commit();\n+    IcebergTable table = getTable(KEY);\n+    // check parameters are in expected state\n+    Assert.assertEquals(getTableLocation(tableName),\n+                            (tempDir.toURI().toString() + DB_NAME + \"/\" +\n+                             tableName).replace(\"//\",\n+                                                \"/\"));\n+\n+    // Only 1 snapshotFile Should exist and no manifests should exist\n+    Assert.assertEquals(2, metadataVersionFiles(tableName).size());\n+    Assert.assertEquals(0, manifestFiles(tableName).size());\n+  }\n+\n+\n+  @SuppressWarnings(\"VariableDeclarationUsageDistance\")\n+  @Test\n+  public void testRename() {\n+    String renamedTableName = \"rename_table_name\";\n+    TableIdentifier renameTableIdentifier = TableIdentifier.of(TABLE_IDENTIFIER.namespace(),\n+                                                               renamedTableName);\n+\n+    Table original = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    catalog.renameTable(TABLE_IDENTIFIER, renameTableIdentifier);\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+    Assert.assertTrue(catalog.tableExists(renameTableIdentifier));\n+\n+    Table renamed = catalog.loadTable(renameTableIdentifier);\n+\n+    Assert.assertEquals(original.schema().asStruct(), renamed.schema().asStruct());\n+    Assert.assertEquals(original.spec(), renamed.spec());\n+    Assert.assertEquals(original.location(), renamed.location());\n+    Assert.assertEquals(original.currentSnapshot(), renamed.currentSnapshot());\n+\n+    Assert.assertTrue(catalog.dropTable(renameTableIdentifier));\n+  }\n+\n+  @Test\n+  public void testDrop() {\n+    Assert.assertTrue(catalog.tableExists(TABLE_IDENTIFIER));\n+    Assert.assertTrue(catalog.dropTable(TABLE_IDENTIFIER));\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+  }\n+\n+  @Test\n+  public void testDropWithoutPurgeLeavesTableData() throws IOException {\n+    Table table = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    GenericRecordBuilder recordBuilder =\n+        new GenericRecordBuilder(AvroSchemaUtil.convert(schema, \"test\"));\n+    List<GenericData.Record> records = new ArrayList<>();\n+    records.add(recordBuilder.set(\"id\", 1L).build());\n+    records.add(recordBuilder.set(\"id\", 2L).build());\n+    records.add(recordBuilder.set(\"id\", 3L).build());\n+\n+    String fileLocation = table.location().replace(\"file:\", \"\") + \"/data/file.avro\";\n+    try (FileAppender<GenericData.Record> writer = Avro.write(Files.localOutput(fileLocation))\n+                                                       .schema(schema)\n+                                                       .named(\"test\")\n+                                                       .build()) {\n+      for (GenericData.Record rec : records) {\n+        writer.add(rec);\n+      }\n+    }\n+\n+    DataFile file = DataFiles.builder(table.spec())\n+                             .withRecordCount(3)\n+                             .withPath(fileLocation)\n+                             .withFileSizeInBytes(Files.localInput(fileLocation).getLength())\n+                             .build();\n+\n+    table.newAppend().appendFile(file).commit();\n+\n+    String manifestListLocation =\n+        table.currentSnapshot().manifestListLocation().replace(\"file:\", \"\");\n+\n+    Assert.assertTrue(catalog.dropTable(TABLE_IDENTIFIER, false));\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+\n+    Assert.assertTrue(new File(fileLocation).exists());\n+    Assert.assertTrue(new File(manifestListLocation).exists());\n+  }\n+\n+\n+  @SuppressWarnings(\"VariableDeclarationUsageDistance\")\n+  @Test\n+  public void testDropTable() throws IOException {\n+    Table table = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    GenericRecordBuilder recordBuilder =\n+        new GenericRecordBuilder(AvroSchemaUtil.convert(schema, \"test\"));\n+    List<GenericData.Record> records = new ArrayList<>();\n+    records.add(recordBuilder.set(\"id\", 1L).build());\n+    records.add(recordBuilder.set(\"id\", 2L).build());\n+    records.add(recordBuilder.set(\"id\", 3L).build());\n+\n+    String location1 = table.location().replace(\"file:\", \"\") + \"/data/file1.avro\";\n+    try (FileAppender<GenericData.Record> writer = Avro.write(Files.localOutput(location1))\n+                                                       .schema(schema)\n+                                                       .named(\"test\")\n+                                                       .build()) {\n+      for (GenericData.Record rec : records) {\n+        writer.add(rec);\n+      }\n+    }\n+\n+    String location2 = table.location().replace(\"file:\", \"\") + \"/data/file2.avro\";\n+    try (FileAppender<GenericData.Record> writer = Avro.write(Files.localOutput(location2))\n+                                                       .schema(schema)\n+                                                       .named(\"test\")\n+                                                       .build()) {\n+      for (GenericData.Record rec : records) {\n+        writer.add(rec);\n+      }\n+    }\n+\n+    DataFile file1 = DataFiles.builder(table.spec())\n+                              .withRecordCount(3)\n+                              .withPath(location1)\n+                              .withFileSizeInBytes(Files.localInput(location2).getLength())\n+                              .build();\n+\n+    DataFile file2 = DataFiles.builder(table.spec())\n+                              .withRecordCount(3)\n+                              .withPath(location2)\n+                              .withFileSizeInBytes(Files.localInput(location1).getLength())\n+                              .build();\n+\n+    // add both data files\n+    table.newAppend().appendFile(file1).appendFile(file2).commit();\n+\n+    // delete file2\n+    table.newDelete().deleteFile(file2.path()).commit();\n+\n+    String manifestListLocation =\n+        table.currentSnapshot().manifestListLocation().replace(\"file:\", \"\");\n+\n+    List<ManifestFile> manifests = table.currentSnapshot().allManifests();\n+\n+    Assert.assertTrue(catalog.dropTable(TABLE_IDENTIFIER));\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+\n+    Assert.assertTrue(new File(location1).exists());\n+    Assert.assertTrue(new File(location2).exists());\n+    Assert.assertTrue(new File(manifestListLocation).exists());\n+    for (ManifestFile manifest : manifests) {\n+      Assert.assertTrue(new File(manifest.path().replace(\"file:\", \"\")).exists());\n+    }\n+    Assert.assertTrue(new File(\n+        ((HasTableOperations) table).operations()\n+                                  .current()\n+                                  .metadataFileLocation()\n+                                  .replace(\"file:\", \"\"))\n+                             .exists());\n+  }\n+\n+  @Test\n+  public void testExistingTableUpdate() {\n+    Table icebergTable = catalog.loadTable(TABLE_IDENTIFIER);\n+    // add a column\n+    icebergTable.updateSchema().addColumn(\"data\", Types.LongType.get()).commit();\n+\n+    icebergTable = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    // Only 2 snapshotFile Should exist and no manifests should exist\n+    Assert.assertEquals(2, metadataVersionFiles(TABLE_NAME).size());\n+    Assert.assertEquals(0, manifestFiles(TABLE_NAME).size());\n+    Assert.assertEquals(altered.asStruct(), icebergTable.schema().asStruct());\n+\n+  }\n+\n+  @Test(expected = CommitFailedException.class)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e3748801b817a76dc1c71f76904271222c7a5f99"}, "originalPosition": 284}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3NjUyNTc2", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-527652576", "createdAt": "2020-11-10T22:16:35Z", "commit": {"oid": "e3748801b817a76dc1c71f76904271222c7a5f99"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQyMjoxNjozNVrOHwxxOA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQyMjoxNjozNVrOHwxxOA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwOTExMg==", "bodyText": "We've moved the other implementations to create a FileIO at the catalog level and pass it into TableOperations. You may want to do the same. Also, you'll probably want to update to use the same logic so that the implementation can be overridden dynamically.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520909112", "createdAt": "2020-11-10T22:16:35Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java", "diffHunk": "@@ -0,0 +1,148 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableIcebergTable;\n+import java.util.Map;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.Snapshot;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.common.DynFields;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+\n+/**\n+ * Nessie implementation of Iceberg TableOperations.\n+ */\n+public class NessieTableOperations extends BaseMetastoreTableOperations {\n+\n+  private static DynFields.StaticField<Object> sparkEnvMethod;\n+  private static DynFields.UnboundField<Object> sparkConfMethod;\n+  private static DynFields.UnboundField<Object> appIdMethod;\n+  private final Configuration conf;\n+  private final NessieClient client;\n+  private final ContentsKey key;\n+  private UpdateableReference reference;\n+  private IcebergTable table;\n+  private HadoopFileIO fileIO;\n+\n+  /**\n+   * Create a nessie table operations given a table identifier.\n+   */\n+  public NessieTableOperations(\n+      Configuration conf,\n+      ContentsKey key,\n+      UpdateableReference reference,\n+      NessieClient client) {\n+    this.conf = conf;\n+    this.key = key;\n+    this.reference = reference;\n+    this.client = client;\n+  }\n+\n+  @Override\n+  protected void doRefresh() {\n+    reference.refresh();\n+    String metadataLocation = null;\n+    try {\n+      Contents contents = client.getContentsApi().getContents(key, reference.getHash());\n+      this.table = contents.unwrap(IcebergTable.class)\n+          .orElseThrow(() ->\n+              new IllegalStateException(\"Cannot refresh iceberg table: \" +\n+                  String.format(\"Nessie points to a non-Iceberg object for path: %s.\", key)));\n+      metadataLocation = table.getMetadataLocation();\n+    } catch (NessieNotFoundException ex) {\n+      if (currentMetadataLocation() != null) {\n+        throw new NoSuchTableException(ex, \"No such table %s\", key);\n+      }\n+    }\n+    refreshFromMetadataLocation(metadataLocation, 2);\n+  }\n+\n+  @Override\n+  protected void doCommit(TableMetadata base, TableMetadata metadata) {\n+    reference.checkMutable();\n+\n+    String newMetadataLocation = writeNewMetadata(metadata, currentVersion() + 1);\n+\n+    boolean threw = true;\n+    try {\n+      IcebergTable newTable = ImmutableIcebergTable.builder().metadataLocation(newMetadataLocation).build();\n+      client.getContentsApi().setContents(key,\n+                                          reference.getAsBranch().getName(),\n+                                          reference.getHash(),\n+                                          String.format(\"iceberg commit%s\", applicationId()),\n+                                          newTable);\n+      threw = false;\n+    } catch (NessieConflictException ex) {\n+      String fixMsg = reference.isBranch() ?\n+          String.format(\"Update the reference %s and try again\", reference.getName()) :\n+          String.format(\"Can't commit to the tag %s\", reference.getName());\n+      throw new CommitFailedException(ex, \"Commit failed: Reference hash is out of date. %s\", fixMsg);\n+    } catch (NessieNotFoundException ex) {\n+      throw new RuntimeException(String.format(\"Commit failed: Reference %s does not exist\", reference.getName()), ex);\n+    } finally {\n+      if (threw) {\n+        io().deleteFile(newMetadataLocation);\n+      }\n+    }\n+  }\n+\n+  @Override\n+  public FileIO io() {\n+    if (fileIO == null) {\n+      fileIO = new HadoopFileIO(conf);\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e3748801b817a76dc1c71f76904271222c7a5f99"}, "originalPosition": 121}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3NjUzNTAy", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-527653502", "createdAt": "2020-11-10T22:18:10Z", "commit": {"oid": "e3748801b817a76dc1c71f76904271222c7a5f99"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQyMjoxODoxMFrOHwx0Fg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQyMjoxODoxMFrOHwx0Fg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkwOTg0Ng==", "bodyText": "Does this need properties? The only thing that is used is an optional ref. That could be passed by itself rather than as a map.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520909846", "createdAt": "2020-11-10T22:18:10Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/ParsedTableIdentifier.java", "diffHunk": "@@ -0,0 +1,103 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import java.time.Instant;\n+import java.util.Map;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+public class ParsedTableIdentifier {\n+\n+  private final TableIdentifier tableIdentifier;\n+  private final Instant timestamp;\n+  private final String reference;\n+\n+  /**\n+   * container class to hold all options in a Nessie table name.\n+   */\n+  public ParsedTableIdentifier(TableIdentifier tableIdentifier, Instant timestamp, String reference) {\n+    this.tableIdentifier = tableIdentifier;\n+    this.timestamp = timestamp;\n+    this.reference = reference;\n+  }\n+\n+  public TableIdentifier getTableIdentifier() {\n+    return tableIdentifier;\n+  }\n+\n+  public Instant getTimestamp() {\n+    return timestamp;\n+  }\n+\n+  public String getReference() {\n+    return reference;\n+  }\n+\n+  /**\n+   * Convert dataset read/write options to a table and ref/hash.\n+   */\n+  public static ParsedTableIdentifier getParsedTableIdentifier(TableIdentifier path) {\n+    return getParsedTableIdentifier(path, ImmutableMap.of());\n+  }\n+  /**\n+   * Convert dataset read/write options to a table and ref/hash.\n+   */\n+  public static ParsedTableIdentifier getParsedTableIdentifier(String path, Map<String, String> properties) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e3748801b817a76dc1c71f76904271222c7a5f99"}, "originalPosition": 64}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTI3NjUzOTkz", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-527653993", "createdAt": "2020-11-10T22:18:59Z", "commit": {"oid": "e3748801b817a76dc1c71f76904271222c7a5f99"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQyMjoxOTowMFrOHwx1fw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xMFQyMjoxOTowMFrOHwx1fw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyMDkxMDIwNw==", "bodyText": "We typically use a continuation indent of 2 indents / 4 spaces, rather than aligning with the previous method call.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r520910207", "createdAt": "2020-11-10T22:19:00Z", "author": {"login": "rdblue"}, "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestNessieTable.java", "diffHunk": "@@ -0,0 +1,349 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Branch;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import org.apache.avro.generic.GenericData;\n+import org.apache.avro.generic.GenericRecordBuilder;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.DataFile;\n+import org.apache.iceberg.DataFiles;\n+import org.apache.iceberg.Files;\n+import org.apache.iceberg.HasTableOperations;\n+import org.apache.iceberg.ManifestFile;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.TableMetadataParser;\n+import org.apache.iceberg.avro.Avro;\n+import org.apache.iceberg.avro.AvroSchemaUtil;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.io.FileAppender;\n+import org.apache.iceberg.types.Types;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import static org.apache.iceberg.TableMetadataParser.getFileExtension;\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+\n+public class TestNessieTable extends BaseTestIceberg {\n+\n+  private static final String BRANCH = \"iceberg-table-test\";\n+\n+  private static final String DB_NAME = \"db\";\n+  private static final String TABLE_NAME = \"tbl\";\n+  private static final TableIdentifier TABLE_IDENTIFIER = TableIdentifier.of(DB_NAME, TABLE_NAME);\n+  private static final ContentsKey KEY = ContentsKey.of(DB_NAME, TABLE_NAME);\n+  private static final Schema schema = new Schema(Types.StructType.of(\n+      required(1, \"id\", Types.LongType.get())).fields());\n+  private static final Schema altered = new Schema(Types.StructType.of(\n+      required(1, \"id\", Types.LongType.get()),\n+      optional(2, \"data\", Types.LongType.get())).fields());\n+\n+  private Path tableLocation;\n+\n+  public TestNessieTable() {\n+    super(BRANCH);\n+  }\n+\n+  @Before\n+  public void beforeEach() throws NessieConflictException, NessieNotFoundException {\n+    super.beforeEach();\n+    this.tableLocation = new Path(catalog.createTable(TABLE_IDENTIFIER, schema).location());\n+  }\n+\n+  @After\n+  public void afterEach() throws Exception {\n+    // drop the table data\n+    if (tableLocation != null) {\n+      tableLocation.getFileSystem(hadoopConfig).delete(tableLocation, true);\n+      catalog.refresh();\n+      catalog.dropTable(TABLE_IDENTIFIER, false);\n+    }\n+\n+    super.afterEach();\n+  }\n+\n+  private com.dremio.nessie.model.IcebergTable getTable(ContentsKey key) throws NessieNotFoundException {\n+    return client.getContentsApi()\n+        .getContents(key, BRANCH)\n+        .unwrap(IcebergTable.class).get();\n+  }\n+\n+  @Test\n+  public void testCreate() throws NessieNotFoundException {\n+    // Table should be created in iceberg\n+    // Table should be renamed in iceberg\n+    String tableName = TABLE_IDENTIFIER.name();\n+    Table icebergTable = catalog.loadTable(TABLE_IDENTIFIER);\n+    // add a column\n+    icebergTable.updateSchema().addColumn(\"mother\", Types.LongType.get()).commit();\n+    IcebergTable table = getTable(KEY);\n+    // check parameters are in expected state\n+    Assert.assertEquals(getTableLocation(tableName),\n+                            (tempDir.toURI().toString() + DB_NAME + \"/\" +\n+                             tableName).replace(\"//\",\n+                                                \"/\"));\n+\n+    // Only 1 snapshotFile Should exist and no manifests should exist\n+    Assert.assertEquals(2, metadataVersionFiles(tableName).size());\n+    Assert.assertEquals(0, manifestFiles(tableName).size());\n+  }\n+\n+\n+  @SuppressWarnings(\"VariableDeclarationUsageDistance\")\n+  @Test\n+  public void testRename() {\n+    String renamedTableName = \"rename_table_name\";\n+    TableIdentifier renameTableIdentifier = TableIdentifier.of(TABLE_IDENTIFIER.namespace(),\n+                                                               renamedTableName);\n+\n+    Table original = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    catalog.renameTable(TABLE_IDENTIFIER, renameTableIdentifier);\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+    Assert.assertTrue(catalog.tableExists(renameTableIdentifier));\n+\n+    Table renamed = catalog.loadTable(renameTableIdentifier);\n+\n+    Assert.assertEquals(original.schema().asStruct(), renamed.schema().asStruct());\n+    Assert.assertEquals(original.spec(), renamed.spec());\n+    Assert.assertEquals(original.location(), renamed.location());\n+    Assert.assertEquals(original.currentSnapshot(), renamed.currentSnapshot());\n+\n+    Assert.assertTrue(catalog.dropTable(renameTableIdentifier));\n+  }\n+\n+  @Test\n+  public void testDrop() {\n+    Assert.assertTrue(catalog.tableExists(TABLE_IDENTIFIER));\n+    Assert.assertTrue(catalog.dropTable(TABLE_IDENTIFIER));\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+  }\n+\n+  @Test\n+  public void testDropWithoutPurgeLeavesTableData() throws IOException {\n+    Table table = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    GenericRecordBuilder recordBuilder =\n+        new GenericRecordBuilder(AvroSchemaUtil.convert(schema, \"test\"));\n+    List<GenericData.Record> records = new ArrayList<>();\n+    records.add(recordBuilder.set(\"id\", 1L).build());\n+    records.add(recordBuilder.set(\"id\", 2L).build());\n+    records.add(recordBuilder.set(\"id\", 3L).build());\n+\n+    String fileLocation = table.location().replace(\"file:\", \"\") + \"/data/file.avro\";\n+    try (FileAppender<GenericData.Record> writer = Avro.write(Files.localOutput(fileLocation))\n+                                                       .schema(schema)\n+                                                       .named(\"test\")\n+                                                       .build()) {\n+      for (GenericData.Record rec : records) {\n+        writer.add(rec);\n+      }\n+    }\n+\n+    DataFile file = DataFiles.builder(table.spec())\n+                             .withRecordCount(3)\n+                             .withPath(fileLocation)\n+                             .withFileSizeInBytes(Files.localInput(fileLocation).getLength())\n+                             .build();\n+\n+    table.newAppend().appendFile(file).commit();\n+\n+    String manifestListLocation =\n+        table.currentSnapshot().manifestListLocation().replace(\"file:\", \"\");\n+\n+    Assert.assertTrue(catalog.dropTable(TABLE_IDENTIFIER, false));\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+\n+    Assert.assertTrue(new File(fileLocation).exists());\n+    Assert.assertTrue(new File(manifestListLocation).exists());\n+  }\n+\n+\n+  @SuppressWarnings(\"VariableDeclarationUsageDistance\")\n+  @Test\n+  public void testDropTable() throws IOException {\n+    Table table = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    GenericRecordBuilder recordBuilder =\n+        new GenericRecordBuilder(AvroSchemaUtil.convert(schema, \"test\"));\n+    List<GenericData.Record> records = new ArrayList<>();\n+    records.add(recordBuilder.set(\"id\", 1L).build());\n+    records.add(recordBuilder.set(\"id\", 2L).build());\n+    records.add(recordBuilder.set(\"id\", 3L).build());\n+\n+    String location1 = table.location().replace(\"file:\", \"\") + \"/data/file1.avro\";\n+    try (FileAppender<GenericData.Record> writer = Avro.write(Files.localOutput(location1))\n+                                                       .schema(schema)\n+                                                       .named(\"test\")\n+                                                       .build()) {\n+      for (GenericData.Record rec : records) {\n+        writer.add(rec);\n+      }\n+    }\n+\n+    String location2 = table.location().replace(\"file:\", \"\") + \"/data/file2.avro\";\n+    try (FileAppender<GenericData.Record> writer = Avro.write(Files.localOutput(location2))\n+                                                       .schema(schema)\n+                                                       .named(\"test\")\n+                                                       .build()) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e3748801b817a76dc1c71f76904271222c7a5f99"}, "originalPosition": 223}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "55f8dc3c9a164f64c931c0028f14a6fa515fa82d", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/55f8dc3c9a164f64c931c0028f14a6fa515fa82d", "committedDate": "2020-11-11T16:28:01Z", "message": "another round of code review"}, "afterCommit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/b46dbf7a2599e7bd8cea384cd968366ce4767382", "committedDate": "2020-11-18T13:52:21Z", "message": "respond to code review comments"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM0MDA4Nzg5", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-534008789", "createdAt": "2020-11-19T01:19:41Z", "commit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMToxOTo0MVrOH2IzPw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMToxOTo0MVrOH2IzPw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUyOTM0Mw==", "bodyText": "Minor: It seems strange to me to default this in the catalog rather than in the tests. I would probably use a precondition to validate it isn't null instead.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526529343", "createdAt": "2020-11-19T01:19:41Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,322 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+  private static final Logger logger = LoggerFactory.getLogger(NessieCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+  private FileIO fileIO;\n+\n+  public NessieCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String inputName, Map<String, String> options) {\n+    String fileIOImpl = options.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ? new HadoopFileIO(config) : CatalogUtil.loadFileIO(fileIOImpl, options, config);\n+    this.name = inputName == null ? \"nessie\" : inputName;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "originalPosition": 86}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM0MDA5Njk0", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-534009694", "createdAt": "2020-11-19T01:22:11Z", "commit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMToyMjoxMlrOH2I2Ug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMToyMjoxMlrOH2I2Ug==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzMDEzMA==", "bodyText": "Other catalogs use \"warehouse\" instead of a catalog-specific property. It would be slightly better for consistency to do the same, although it is fine this way. If the NessieClient is expecting config like this, it may well be more consistent for Nessie users to always use the full namespaced names.\nJust be aware that this will require properties like spark.sql.catalog.some_name.nessie.warehouse.dir=...", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526530130", "createdAt": "2020-11-19T01:22:12Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,322 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+  private static final Logger logger = LoggerFactory.getLogger(NessieCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+  private FileIO fileIO;\n+\n+  public NessieCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String inputName, Map<String, String> options) {\n+    String fileIOImpl = options.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ? new HadoopFileIO(config) : CatalogUtil.loadFileIO(fileIOImpl, options, config);\n+    this.name = inputName == null ? \"nessie\" : inputName;\n+    this.client = NessieClient.withConfig(options::get);\n+\n+    this.warehouseLocation = options.get(NESSIE_WAREHOUSE_DIR);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "originalPosition": 89}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM0MDEwOTEx", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-534010911", "createdAt": "2020-11-19T01:25:36Z", "commit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMToyNTozNlrOH2I6kw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMToyNTozNlrOH2I6kw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzMTIxOQ==", "bodyText": "Similar, it may be easier to configure using just \"ref\".", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526531219", "createdAt": "2020-11-19T01:25:36Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,322 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+  private static final Logger logger = LoggerFactory.getLogger(NessieCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+  private FileIO fileIO;\n+\n+  public NessieCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String inputName, Map<String, String> options) {\n+    String fileIOImpl = options.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ? new HadoopFileIO(config) : CatalogUtil.loadFileIO(fileIOImpl, options, config);\n+    this.name = inputName == null ? \"nessie\" : inputName;\n+    this.client = NessieClient.withConfig(options::get);\n+\n+    this.warehouseLocation = options.get(NESSIE_WAREHOUSE_DIR);\n+    if (warehouseLocation == null) {\n+      throw new IllegalStateException(\"Parameter nessie.warehouse.dir not set, nessie can't store data.\");\n+    }\n+    final String requestedRef = options.get(NessieClient.CONF_NESSIE_REF);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "originalPosition": 93}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM0MDEzNjAz", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-534013603", "createdAt": "2020-11-19T01:32:51Z", "commit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMTozMjo1MVrOH2JDug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMTozMjo1MVrOH2JDug==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzMzU2Mg==", "bodyText": "You can replace this with Tasks:\nTasks.foreach(identifier)\n    .retry(5)\n    .stopRetryOn(NessieNotFoundException.class)\n    .throwFailureWhenFinished()\n    .run(this::dropTableInner)\nTasks is pretty flexible and allows you to configure exponential backoff, whether to retry on all exceptions but a known list (stopRetryOn), whether to retry on specific exceptions (onlyRetryOn), and set up callbacks (onFailure).\nIt helps us avoid logic like this everywhere.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526533562", "createdAt": "2020-11-19T01:32:51Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,322 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+  private static final Logger logger = LoggerFactory.getLogger(NessieCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+  private FileIO fileIO;\n+\n+  public NessieCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String inputName, Map<String, String> options) {\n+    String fileIOImpl = options.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ? new HadoopFileIO(config) : CatalogUtil.loadFileIO(fileIOImpl, options, config);\n+    this.name = inputName == null ? \"nessie\" : inputName;\n+    this.client = NessieClient.withConfig(options::get);\n+\n+    this.warehouseLocation = options.get(NESSIE_WAREHOUSE_DIR);\n+    if (warehouseLocation == null) {\n+      throw new IllegalStateException(\"Parameter nessie.warehouse.dir not set, nessie can't store data.\");\n+    }\n+    final String requestedRef = options.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = loadReference(requestedRef);\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    TableReference pti = TableReference.parse(tableIdentifier);\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = loadReference(pti.getReference());\n+    }\n+    return new NessieTableOperations(NessieUtil.toKey(pti.getTableIdentifier()), newReference, client, fileIO);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+\n+    // We try to drop the table. Simple retry after ref update.\n+    int count = 0;\n+    while (count < 5) {\n+      count++;\n+      try {\n+        dropTableInner(identifier);\n+        break;\n+      } catch (NessieConflictException e) {\n+        // pass for retry\n+      } catch (NessieNotFoundException e) {\n+        logger.error(\"Cannot drop table: ref is no longer valid.\", e);\n+        return false;\n+      }\n+    }\n+    if (count >= 5) {\n+      logger.error(\"Cannot drop table: failed after retry (update hash and retry)\");\n+      return false;\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "originalPosition": 156}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM0MDE0NTc4", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-534014578", "createdAt": "2020-11-19T01:35:27Z", "commit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMTozNToyOFrOH2JG5A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMTozNToyOFrOH2JG5A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzNDM3Mg==", "bodyText": "I'd prefer an error message with more context, like Failed to rename X to Y. There's no guarantee that the error message from Nessie has that information. It probably has information about the state of the ref, rather than what was being attempted.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526534372", "createdAt": "2020-11-19T01:35:28Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,322 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+  private static final Logger logger = LoggerFactory.getLogger(NessieCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+  private FileIO fileIO;\n+\n+  public NessieCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String inputName, Map<String, String> options) {\n+    String fileIOImpl = options.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ? new HadoopFileIO(config) : CatalogUtil.loadFileIO(fileIOImpl, options, config);\n+    this.name = inputName == null ? \"nessie\" : inputName;\n+    this.client = NessieClient.withConfig(options::get);\n+\n+    this.warehouseLocation = options.get(NESSIE_WAREHOUSE_DIR);\n+    if (warehouseLocation == null) {\n+      throw new IllegalStateException(\"Parameter nessie.warehouse.dir not set, nessie can't store data.\");\n+    }\n+    final String requestedRef = options.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = loadReference(requestedRef);\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    TableReference pti = TableReference.parse(tableIdentifier);\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = loadReference(pti.getReference());\n+    }\n+    return new NessieTableOperations(NessieUtil.toKey(pti.getTableIdentifier()), newReference, client, fileIO);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+\n+    // We try to drop the table. Simple retry after ref update.\n+    int count = 0;\n+    while (count < 5) {\n+      count++;\n+      try {\n+        dropTableInner(identifier);\n+        break;\n+      } catch (NessieConflictException e) {\n+        // pass for retry\n+      } catch (NessieNotFoundException e) {\n+        logger.error(\"Cannot drop table: ref is no longer valid.\", e);\n+        return false;\n+      }\n+    }\n+    if (count >= 5) {\n+      logger.error(\"Cannot drop table: failed after retry (update hash and retry)\");\n+      return false;\n+    }\n+    return true;\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier toOriginal) {\n+    reference.checkMutable();\n+\n+    TableIdentifier to = NessieUtil.removeCatalogName(toOriginal, name());\n+\n+    IcebergTable existingFromTable = table(from);\n+    if (existingFromTable == null) {\n+      throw new NoSuchTableException(\"table %s doesn't exists\", from.name());\n+    }\n+    IcebergTable existingToTable = table(to);\n+    if (existingToTable != null) {\n+      throw new AlreadyExistsException(\"table %s already exists\", to.name());\n+    }\n+\n+    Operations contents = ImmutableOperations.builder()\n+        .addOperations(ImmutablePut.builder().key(NessieUtil.toKey(to)).contents(existingFromTable).build(),\n+            ImmutableDelete.builder().key(NessieUtil.toKey(from)).build())\n+        .build();\n+\n+    try {\n+      client.getTreeApi().commitMultipleOperations(reference.getAsBranch().getName(), reference.getHash(),\n+          \"iceberg rename table\", contents);\n+      // TODO: fix this so we don't depend on it in tests.\n+      refresh();\n+    } catch (NessieConflictException e) {\n+      throw new CommitFailedException(e, \"failed\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "originalPosition": 186}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM0MDE1MDcz", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-534015073", "createdAt": "2020-11-19T01:36:56Z", "commit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMTozNjo1NlrOH2JIig==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMTozNjo1NlrOH2JIig==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzNDc5NA==", "bodyText": "This can't happen if the to table has already been dropped? Seems like this assumes that the NessieNotFoundException refers to the ref.\nMaybe we're guaranteed that the ref hasn't changed because this isn't a NessieConflictException? If so, a comment would help.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526534794", "createdAt": "2020-11-19T01:36:56Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,322 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+  private static final Logger logger = LoggerFactory.getLogger(NessieCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+  private FileIO fileIO;\n+\n+  public NessieCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String inputName, Map<String, String> options) {\n+    String fileIOImpl = options.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ? new HadoopFileIO(config) : CatalogUtil.loadFileIO(fileIOImpl, options, config);\n+    this.name = inputName == null ? \"nessie\" : inputName;\n+    this.client = NessieClient.withConfig(options::get);\n+\n+    this.warehouseLocation = options.get(NESSIE_WAREHOUSE_DIR);\n+    if (warehouseLocation == null) {\n+      throw new IllegalStateException(\"Parameter nessie.warehouse.dir not set, nessie can't store data.\");\n+    }\n+    final String requestedRef = options.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = loadReference(requestedRef);\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    TableReference pti = TableReference.parse(tableIdentifier);\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = loadReference(pti.getReference());\n+    }\n+    return new NessieTableOperations(NessieUtil.toKey(pti.getTableIdentifier()), newReference, client, fileIO);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+\n+    // We try to drop the table. Simple retry after ref update.\n+    int count = 0;\n+    while (count < 5) {\n+      count++;\n+      try {\n+        dropTableInner(identifier);\n+        break;\n+      } catch (NessieConflictException e) {\n+        // pass for retry\n+      } catch (NessieNotFoundException e) {\n+        logger.error(\"Cannot drop table: ref is no longer valid.\", e);\n+        return false;\n+      }\n+    }\n+    if (count >= 5) {\n+      logger.error(\"Cannot drop table: failed after retry (update hash and retry)\");\n+      return false;\n+    }\n+    return true;\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier toOriginal) {\n+    reference.checkMutable();\n+\n+    TableIdentifier to = NessieUtil.removeCatalogName(toOriginal, name());\n+\n+    IcebergTable existingFromTable = table(from);\n+    if (existingFromTable == null) {\n+      throw new NoSuchTableException(\"table %s doesn't exists\", from.name());\n+    }\n+    IcebergTable existingToTable = table(to);\n+    if (existingToTable != null) {\n+      throw new AlreadyExistsException(\"table %s already exists\", to.name());\n+    }\n+\n+    Operations contents = ImmutableOperations.builder()\n+        .addOperations(ImmutablePut.builder().key(NessieUtil.toKey(to)).contents(existingFromTable).build(),\n+            ImmutableDelete.builder().key(NessieUtil.toKey(from)).build())\n+        .build();\n+\n+    try {\n+      client.getTreeApi().commitMultipleOperations(reference.getAsBranch().getName(), reference.getHash(),\n+          \"iceberg rename table\", contents);\n+      // TODO: fix this so we don't depend on it in tests.\n+      refresh();\n+    } catch (NessieConflictException e) {\n+      throw new CommitFailedException(e, \"failed\");\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to drop table as ref is no longer valid.\", e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "originalPosition": 188}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM0MDE1MzY4", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-534015368", "createdAt": "2020-11-19T01:37:43Z", "commit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMTozNzo0M1rOH2JJww==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMTozNzo0M1rOH2JJww==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzNTEwNw==", "bodyText": "Why is this public?\nNot a blocker, just normal code lint.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526535107", "createdAt": "2020-11-19T01:37:43Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,322 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+  private static final Logger logger = LoggerFactory.getLogger(NessieCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+  private FileIO fileIO;\n+\n+  public NessieCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String inputName, Map<String, String> options) {\n+    String fileIOImpl = options.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ? new HadoopFileIO(config) : CatalogUtil.loadFileIO(fileIOImpl, options, config);\n+    this.name = inputName == null ? \"nessie\" : inputName;\n+    this.client = NessieClient.withConfig(options::get);\n+\n+    this.warehouseLocation = options.get(NESSIE_WAREHOUSE_DIR);\n+    if (warehouseLocation == null) {\n+      throw new IllegalStateException(\"Parameter nessie.warehouse.dir not set, nessie can't store data.\");\n+    }\n+    final String requestedRef = options.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = loadReference(requestedRef);\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    TableReference pti = TableReference.parse(tableIdentifier);\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = loadReference(pti.getReference());\n+    }\n+    return new NessieTableOperations(NessieUtil.toKey(pti.getTableIdentifier()), newReference, client, fileIO);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+\n+    // We try to drop the table. Simple retry after ref update.\n+    int count = 0;\n+    while (count < 5) {\n+      count++;\n+      try {\n+        dropTableInner(identifier);\n+        break;\n+      } catch (NessieConflictException e) {\n+        // pass for retry\n+      } catch (NessieNotFoundException e) {\n+        logger.error(\"Cannot drop table: ref is no longer valid.\", e);\n+        return false;\n+      }\n+    }\n+    if (count >= 5) {\n+      logger.error(\"Cannot drop table: failed after retry (update hash and retry)\");\n+      return false;\n+    }\n+    return true;\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier toOriginal) {\n+    reference.checkMutable();\n+\n+    TableIdentifier to = NessieUtil.removeCatalogName(toOriginal, name());\n+\n+    IcebergTable existingFromTable = table(from);\n+    if (existingFromTable == null) {\n+      throw new NoSuchTableException(\"table %s doesn't exists\", from.name());\n+    }\n+    IcebergTable existingToTable = table(to);\n+    if (existingToTable != null) {\n+      throw new AlreadyExistsException(\"table %s already exists\", to.name());\n+    }\n+\n+    Operations contents = ImmutableOperations.builder()\n+        .addOperations(ImmutablePut.builder().key(NessieUtil.toKey(to)).contents(existingFromTable).build(),\n+            ImmutableDelete.builder().key(NessieUtil.toKey(from)).build())\n+        .build();\n+\n+    try {\n+      client.getTreeApi().commitMultipleOperations(reference.getAsBranch().getName(), reference.getHash(),\n+          \"iceberg rename table\", contents);\n+      // TODO: fix this so we don't depend on it in tests.\n+      refresh();\n+    } catch (NessieConflictException e) {\n+      throw new CommitFailedException(e, \"failed\");\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to drop table as ref is no longer valid.\", e);\n+    }\n+  }\n+\n+  /**\n+   * creating namespaces in nessie is implicit, therefore this is a no-op. Metadata is ignored.\n+   *\n+   * @param namespace a multi-part namespace\n+   * @param metadata a string Map of properties for the given namespace\n+   */\n+  @Override\n+  public void createNamespace(Namespace namespace, Map<String, String> metadata) {\n+  }\n+\n+  @Override\n+  public List<Namespace> listNamespaces(Namespace namespace) throws NoSuchNamespaceException {\n+    return tableStream(namespace)\n+        .map(TableIdentifier::namespace)\n+        .filter(n -> !n.isEmpty())\n+        .distinct()\n+        .collect(Collectors.toList());\n+  }\n+\n+  /**\n+   * namespace metadata is not supported in Nessie and we return an empty map.\n+   *\n+   * @param namespace a namespace. {@link Namespace}\n+   * @return an empty map\n+   */\n+  @Override\n+  public Map<String, String> loadNamespaceMetadata(Namespace namespace) throws NoSuchNamespaceException {\n+    return ImmutableMap.of();\n+  }\n+\n+  /**\n+   * Namespaces in Nessie are implicit and deleting them results in a no-op.\n+   *\n+   * @param namespace a namespace. {@link Namespace}\n+   * @return always false.\n+   */\n+  @Override\n+  public boolean dropNamespace(Namespace namespace) throws NamespaceNotEmptyException {\n+    return false;\n+  }\n+\n+  @Override\n+  public boolean setProperties(Namespace namespace, Map<String, String> properties) throws NoSuchNamespaceException {\n+    throw new UnsupportedOperationException(\n+        \"Cannot set namespace properties \" + namespace + \" : setProperties is not supported\");\n+  }\n+\n+  @Override\n+  public boolean removeProperties(Namespace namespace, Set<String> properties) throws NoSuchNamespaceException {\n+    throw new UnsupportedOperationException(\n+        \"Cannot remove properties \" + namespace + \" : removeProperties is not supported\");\n+  }\n+\n+  @Override\n+  public void setConf(Configuration conf) {\n+    this.config = conf;\n+  }\n+\n+  @Override\n+  public Configuration getConf() {\n+    return config;\n+  }\n+\n+  public TreeApi getTreeApi() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "originalPosition": 255}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM0MDE2Njc4", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-534016678", "createdAt": "2020-11-19T01:41:18Z", "commit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMTo0MToxOFrOH2JOTg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMTo0MToxOFrOH2JOTg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzNjI3MA==", "bodyText": "We may want to let the original exception propagate instead of throwing a RuntimeException so that people working with the table can take action if the ref is gone. I'm not really sure what the right thing is here.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526536270", "createdAt": "2020-11-19T01:41:18Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java", "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableIcebergTable;\n+import java.util.Map;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.Snapshot;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.io.FileIO;\n+\n+/**\n+ * Nessie implementation of Iceberg TableOperations.\n+ */\n+public class NessieTableOperations extends BaseMetastoreTableOperations {\n+\n+  private final NessieClient client;\n+  private final ContentsKey key;\n+  private UpdateableReference reference;\n+  private IcebergTable table;\n+  private FileIO fileIO;\n+\n+  /**\n+   * Create a nessie table operations given a table identifier.\n+   */\n+  public NessieTableOperations(\n+      ContentsKey key,\n+      UpdateableReference reference,\n+      NessieClient client,\n+      FileIO fileIO) {\n+    this.key = key;\n+    this.reference = reference;\n+    this.client = client;\n+    this.fileIO = fileIO;\n+  }\n+\n+  @Override\n+  protected void doRefresh() {\n+    try {\n+      reference.refresh();\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to refresh as ref is no longer valid.\", e);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "originalPosition": 67}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM0MDE3MTEx", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-534017111", "createdAt": "2020-11-19T01:42:35Z", "commit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMTo0MjozNVrOH2JP8g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMTo0MjozNVrOH2JP8g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzNjY5MA==", "bodyText": "NessieTableOperations calls unwrap instead of using instanceof.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526536690", "createdAt": "2020-11-19T01:42:35Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieCatalog.java", "diffHunk": "@@ -0,0 +1,322 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.api.TreeApi;\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableDelete;\n+import com.dremio.nessie.model.ImmutableOperations;\n+import com.dremio.nessie.model.ImmutablePut;\n+import com.dremio.nessie.model.Operations;\n+import com.dremio.nessie.model.Reference;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Set;\n+import java.util.stream.Collectors;\n+import java.util.stream.Stream;\n+import org.apache.hadoop.conf.Configurable;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.BaseMetastoreCatalog;\n+import org.apache.iceberg.CatalogProperties;\n+import org.apache.iceberg.CatalogUtil;\n+import org.apache.iceberg.TableOperations;\n+import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.catalog.SupportsNamespaces;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.AlreadyExistsException;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NamespaceNotEmptyException;\n+import org.apache.iceberg.exceptions.NoSuchNamespaceException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.hadoop.HadoopFileIO;\n+import org.apache.iceberg.io.FileIO;\n+import org.apache.iceberg.relocated.com.google.common.base.Joiner;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.slf4j.Logger;\n+import org.slf4j.LoggerFactory;\n+\n+/**\n+ * Nessie implementation of Iceberg Catalog.\n+ *\n+ * <p>\n+ *   A note on namespaces: Nessie namespaces are implicit and do not need to be explicitly created or deleted.\n+ *   The create and delete namespace methods are no-ops for the NessieCatalog. One can still list namespaces that have\n+ *   objects stored in them to assist with namespace-centric catalog exploration.\n+ * </p>\n+ */\n+public class NessieCatalog extends BaseMetastoreCatalog implements AutoCloseable, SupportsNamespaces, Configurable {\n+  private static final Logger logger = LoggerFactory.getLogger(NessieCatalog.class);\n+  private static final Joiner SLASH = Joiner.on(\"/\");\n+  public static final String NESSIE_WAREHOUSE_DIR = \"nessie.warehouse.dir\";\n+  private NessieClient client;\n+  private String warehouseLocation;\n+  private Configuration config;\n+  private UpdateableReference reference;\n+  private String name;\n+  private FileIO fileIO;\n+\n+  public NessieCatalog() {\n+  }\n+\n+  @Override\n+  public void initialize(String inputName, Map<String, String> options) {\n+    String fileIOImpl = options.get(CatalogProperties.FILE_IO_IMPL);\n+    this.fileIO = fileIOImpl == null ? new HadoopFileIO(config) : CatalogUtil.loadFileIO(fileIOImpl, options, config);\n+    this.name = inputName == null ? \"nessie\" : inputName;\n+    this.client = NessieClient.withConfig(options::get);\n+\n+    this.warehouseLocation = options.get(NESSIE_WAREHOUSE_DIR);\n+    if (warehouseLocation == null) {\n+      throw new IllegalStateException(\"Parameter nessie.warehouse.dir not set, nessie can't store data.\");\n+    }\n+    final String requestedRef = options.get(NessieClient.CONF_NESSIE_REF);\n+    this.reference = loadReference(requestedRef);\n+  }\n+\n+  @Override\n+  public void close() {\n+    client.close();\n+  }\n+\n+  @Override\n+  public String name() {\n+    return name;\n+  }\n+\n+  @Override\n+  protected TableOperations newTableOps(TableIdentifier tableIdentifier) {\n+    TableReference pti = TableReference.parse(tableIdentifier);\n+    UpdateableReference newReference = this.reference;\n+    if (pti.getReference() != null) {\n+      newReference = loadReference(pti.getReference());\n+    }\n+    return new NessieTableOperations(NessieUtil.toKey(pti.getTableIdentifier()), newReference, client, fileIO);\n+  }\n+\n+  @Override\n+  protected String defaultWarehouseLocation(TableIdentifier table) {\n+    if (table.hasNamespace()) {\n+      return SLASH.join(warehouseLocation, table.namespace().toString(), table.name());\n+    }\n+    return SLASH.join(warehouseLocation, table.name());\n+  }\n+\n+  @Override\n+  public List<TableIdentifier> listTables(Namespace namespace) {\n+    return tableStream(namespace).collect(Collectors.toList());\n+  }\n+\n+  @Override\n+  public boolean dropTable(TableIdentifier identifier, boolean purge) {\n+    reference.checkMutable();\n+\n+    IcebergTable existingTable = table(identifier);\n+    if (existingTable == null) {\n+      return false;\n+    }\n+\n+    // We try to drop the table. Simple retry after ref update.\n+    int count = 0;\n+    while (count < 5) {\n+      count++;\n+      try {\n+        dropTableInner(identifier);\n+        break;\n+      } catch (NessieConflictException e) {\n+        // pass for retry\n+      } catch (NessieNotFoundException e) {\n+        logger.error(\"Cannot drop table: ref is no longer valid.\", e);\n+        return false;\n+      }\n+    }\n+    if (count >= 5) {\n+      logger.error(\"Cannot drop table: failed after retry (update hash and retry)\");\n+      return false;\n+    }\n+    return true;\n+  }\n+\n+  @Override\n+  public void renameTable(TableIdentifier from, TableIdentifier toOriginal) {\n+    reference.checkMutable();\n+\n+    TableIdentifier to = NessieUtil.removeCatalogName(toOriginal, name());\n+\n+    IcebergTable existingFromTable = table(from);\n+    if (existingFromTable == null) {\n+      throw new NoSuchTableException(\"table %s doesn't exists\", from.name());\n+    }\n+    IcebergTable existingToTable = table(to);\n+    if (existingToTable != null) {\n+      throw new AlreadyExistsException(\"table %s already exists\", to.name());\n+    }\n+\n+    Operations contents = ImmutableOperations.builder()\n+        .addOperations(ImmutablePut.builder().key(NessieUtil.toKey(to)).contents(existingFromTable).build(),\n+            ImmutableDelete.builder().key(NessieUtil.toKey(from)).build())\n+        .build();\n+\n+    try {\n+      client.getTreeApi().commitMultipleOperations(reference.getAsBranch().getName(), reference.getHash(),\n+          \"iceberg rename table\", contents);\n+      // TODO: fix this so we don't depend on it in tests.\n+      refresh();\n+    } catch (NessieConflictException e) {\n+      throw new CommitFailedException(e, \"failed\");\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to drop table as ref is no longer valid.\", e);\n+    }\n+  }\n+\n+  /**\n+   * creating namespaces in nessie is implicit, therefore this is a no-op. Metadata is ignored.\n+   *\n+   * @param namespace a multi-part namespace\n+   * @param metadata a string Map of properties for the given namespace\n+   */\n+  @Override\n+  public void createNamespace(Namespace namespace, Map<String, String> metadata) {\n+  }\n+\n+  @Override\n+  public List<Namespace> listNamespaces(Namespace namespace) throws NoSuchNamespaceException {\n+    return tableStream(namespace)\n+        .map(TableIdentifier::namespace)\n+        .filter(n -> !n.isEmpty())\n+        .distinct()\n+        .collect(Collectors.toList());\n+  }\n+\n+  /**\n+   * namespace metadata is not supported in Nessie and we return an empty map.\n+   *\n+   * @param namespace a namespace. {@link Namespace}\n+   * @return an empty map\n+   */\n+  @Override\n+  public Map<String, String> loadNamespaceMetadata(Namespace namespace) throws NoSuchNamespaceException {\n+    return ImmutableMap.of();\n+  }\n+\n+  /**\n+   * Namespaces in Nessie are implicit and deleting them results in a no-op.\n+   *\n+   * @param namespace a namespace. {@link Namespace}\n+   * @return always false.\n+   */\n+  @Override\n+  public boolean dropNamespace(Namespace namespace) throws NamespaceNotEmptyException {\n+    return false;\n+  }\n+\n+  @Override\n+  public boolean setProperties(Namespace namespace, Map<String, String> properties) throws NoSuchNamespaceException {\n+    throw new UnsupportedOperationException(\n+        \"Cannot set namespace properties \" + namespace + \" : setProperties is not supported\");\n+  }\n+\n+  @Override\n+  public boolean removeProperties(Namespace namespace, Set<String> properties) throws NoSuchNamespaceException {\n+    throw new UnsupportedOperationException(\n+        \"Cannot remove properties \" + namespace + \" : removeProperties is not supported\");\n+  }\n+\n+  @Override\n+  public void setConf(Configuration conf) {\n+    this.config = conf;\n+  }\n+\n+  @Override\n+  public Configuration getConf() {\n+    return config;\n+  }\n+\n+  public TreeApi getTreeApi() {\n+    return client.getTreeApi();\n+  }\n+\n+  public void refresh() throws NessieNotFoundException {\n+    reference.refresh();\n+  }\n+\n+  public String currentHash() {\n+    return reference.getHash();\n+  }\n+\n+  private IcebergTable table(TableIdentifier tableIdentifier) {\n+    try {\n+      Contents table = client.getContentsApi().getContents(NessieUtil.toKey(tableIdentifier), reference.getHash());\n+      if (table instanceof IcebergTable) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "originalPosition": 270}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM0MDE5Mjkz", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-534019293", "createdAt": "2020-11-19T01:48:53Z", "commit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMTo0ODo1M1rOH2JXyQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMTo0ODo1M1rOH2JXyQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzODY5Nw==", "bodyText": "CommitFailedException is used to trigger a table refresh and a retry. Throwing it for NessieConflictException seems correct to me, but reading the error messages makes me less sure.\nIf the ref is a tag, then we don't want to retry because it can't be updated, right? In that case, this should throw some other exception because the table is read-only.\nIf the ref is a branch, then the ref should be refreshed using the normal retry logic so everything looks good. doRefresh will update the ref and then update the table content.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526538697", "createdAt": "2020-11-19T01:48:53Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java", "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableIcebergTable;\n+import java.util.Map;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.Snapshot;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.io.FileIO;\n+\n+/**\n+ * Nessie implementation of Iceberg TableOperations.\n+ */\n+public class NessieTableOperations extends BaseMetastoreTableOperations {\n+\n+  private final NessieClient client;\n+  private final ContentsKey key;\n+  private UpdateableReference reference;\n+  private IcebergTable table;\n+  private FileIO fileIO;\n+\n+  /**\n+   * Create a nessie table operations given a table identifier.\n+   */\n+  public NessieTableOperations(\n+      ContentsKey key,\n+      UpdateableReference reference,\n+      NessieClient client,\n+      FileIO fileIO) {\n+    this.key = key;\n+    this.reference = reference;\n+    this.client = client;\n+    this.fileIO = fileIO;\n+  }\n+\n+  @Override\n+  protected void doRefresh() {\n+    try {\n+      reference.refresh();\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to refresh as ref is no longer valid.\", e);\n+    }\n+    String metadataLocation = null;\n+    try {\n+      Contents contents = client.getContentsApi().getContents(key, reference.getHash());\n+      this.table = contents.unwrap(IcebergTable.class)\n+          .orElseThrow(() ->\n+              new IllegalStateException(\"Cannot refresh iceberg table: \" +\n+                  String.format(\"Nessie points to a non-Iceberg object for path: %s.\", key)));\n+      metadataLocation = table.getMetadataLocation();\n+    } catch (NessieNotFoundException ex) {\n+      if (currentMetadataLocation() != null) {\n+        throw new NoSuchTableException(ex, \"No such table %s\", key);\n+      }\n+    }\n+    refreshFromMetadataLocation(metadataLocation, 2);\n+  }\n+\n+  @Override\n+  protected void doCommit(TableMetadata base, TableMetadata metadata) {\n+    reference.checkMutable();\n+\n+    String newMetadataLocation = writeNewMetadata(metadata, currentVersion() + 1);\n+\n+    boolean threw = true;\n+    try {\n+      IcebergTable newTable = ImmutableIcebergTable.builder().metadataLocation(newMetadataLocation).build();\n+      client.getContentsApi().setContents(key,\n+                                          reference.getAsBranch().getName(),\n+                                          reference.getHash(),\n+                                          String.format(\"iceberg commit%s\", applicationId()),\n+                                          newTable);\n+      threw = false;\n+    } catch (NessieConflictException ex) {\n+      String fixMsg = reference.isBranch() ?\n+          String.format(\"Update the reference %s and try again\", reference.getName()) :\n+          String.format(\"Can't commit to the tag %s\", reference.getName());\n+      throw new CommitFailedException(ex, \"Commit failed: Reference hash is out of date. %s\", fixMsg);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "originalPosition": 104}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM0MDE5NjIz", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-534019623", "createdAt": "2020-11-19T01:49:47Z", "commit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMTo0OTo0N1rOH2JY-A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMTo0OTo0N1rOH2JY-A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzOTAwMA==", "bodyText": "Like above, do we know this is the ref because the current ref already loaded the table?", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526539000", "createdAt": "2020-11-19T01:49:47Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/NessieTableOperations.java", "diffHunk": "@@ -0,0 +1,141 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Contents;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import com.dremio.nessie.model.ImmutableIcebergTable;\n+import java.util.Map;\n+import org.apache.iceberg.BaseMetastoreTableOperations;\n+import org.apache.iceberg.Snapshot;\n+import org.apache.iceberg.TableMetadata;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.exceptions.NoSuchTableException;\n+import org.apache.iceberg.io.FileIO;\n+\n+/**\n+ * Nessie implementation of Iceberg TableOperations.\n+ */\n+public class NessieTableOperations extends BaseMetastoreTableOperations {\n+\n+  private final NessieClient client;\n+  private final ContentsKey key;\n+  private UpdateableReference reference;\n+  private IcebergTable table;\n+  private FileIO fileIO;\n+\n+  /**\n+   * Create a nessie table operations given a table identifier.\n+   */\n+  public NessieTableOperations(\n+      ContentsKey key,\n+      UpdateableReference reference,\n+      NessieClient client,\n+      FileIO fileIO) {\n+    this.key = key;\n+    this.reference = reference;\n+    this.client = client;\n+    this.fileIO = fileIO;\n+  }\n+\n+  @Override\n+  protected void doRefresh() {\n+    try {\n+      reference.refresh();\n+    } catch (NessieNotFoundException e) {\n+      throw new RuntimeException(\"Failed to refresh as ref is no longer valid.\", e);\n+    }\n+    String metadataLocation = null;\n+    try {\n+      Contents contents = client.getContentsApi().getContents(key, reference.getHash());\n+      this.table = contents.unwrap(IcebergTable.class)\n+          .orElseThrow(() ->\n+              new IllegalStateException(\"Cannot refresh iceberg table: \" +\n+                  String.format(\"Nessie points to a non-Iceberg object for path: %s.\", key)));\n+      metadataLocation = table.getMetadataLocation();\n+    } catch (NessieNotFoundException ex) {\n+      if (currentMetadataLocation() != null) {\n+        throw new NoSuchTableException(ex, \"No such table %s\", key);\n+      }\n+    }\n+    refreshFromMetadataLocation(metadataLocation, 2);\n+  }\n+\n+  @Override\n+  protected void doCommit(TableMetadata base, TableMetadata metadata) {\n+    reference.checkMutable();\n+\n+    String newMetadataLocation = writeNewMetadata(metadata, currentVersion() + 1);\n+\n+    boolean threw = true;\n+    try {\n+      IcebergTable newTable = ImmutableIcebergTable.builder().metadataLocation(newMetadataLocation).build();\n+      client.getContentsApi().setContents(key,\n+                                          reference.getAsBranch().getName(),\n+                                          reference.getHash(),\n+                                          String.format(\"iceberg commit%s\", applicationId()),\n+                                          newTable);\n+      threw = false;\n+    } catch (NessieConflictException ex) {\n+      String fixMsg = reference.isBranch() ?\n+          String.format(\"Update the reference %s and try again\", reference.getName()) :\n+          String.format(\"Can't commit to the tag %s\", reference.getName());\n+      throw new CommitFailedException(ex, \"Commit failed: Reference hash is out of date. %s\", fixMsg);\n+    } catch (NessieNotFoundException ex) {\n+      throw new RuntimeException(String.format(\"Commit failed: Reference %s does not exist\", reference.getName()), ex);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "originalPosition": 106}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM0MDIwMzk1", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-534020395", "createdAt": "2020-11-19T01:51:51Z", "commit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMTo1MTo1MVrOH2JbuQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMTo1MTo1MVrOH2JbuQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUzOTcwNQ==", "bodyText": "Nit: We usually omit get from getter method names because it doesn't add value and looks weird in other languages (like Scala and Kotlin).", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526539705", "createdAt": "2020-11-19T01:51:51Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/TableReference.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import java.time.Instant;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+\n+public class TableReference {\n+\n+  private final TableIdentifier tableIdentifier;\n+  private final Instant timestamp;\n+  private final String reference;\n+\n+  /**\n+   * Container class to specify a TableIdentifier on a specific Reference or at an Instant in time.\n+   */\n+  public TableReference(TableIdentifier tableIdentifier, Instant timestamp, String reference) {\n+    this.tableIdentifier = tableIdentifier;\n+    this.timestamp = timestamp;\n+    this.reference = reference;\n+  }\n+\n+  public TableIdentifier getTableIdentifier() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "originalPosition": 40}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM0MDIxMTM0", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-534021134", "createdAt": "2020-11-19T01:53:51Z", "commit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMTo1Mzo1MVrOH2JeLg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMTo1Mzo1MVrOH2JeLg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0MDMzNA==", "bodyText": "Looks like this check is the only one needed for #. It doesn't matter if the identifier also contains @ and it also doesn't matter if there is more than one #.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526540334", "createdAt": "2020-11-19T01:53:51Z", "author": {"login": "rdblue"}, "path": "nessie/src/main/java/org/apache/iceberg/nessie/TableReference.java", "diffHunk": "@@ -0,0 +1,94 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import java.time.Instant;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+\n+public class TableReference {\n+\n+  private final TableIdentifier tableIdentifier;\n+  private final Instant timestamp;\n+  private final String reference;\n+\n+  /**\n+   * Container class to specify a TableIdentifier on a specific Reference or at an Instant in time.\n+   */\n+  public TableReference(TableIdentifier tableIdentifier, Instant timestamp, String reference) {\n+    this.tableIdentifier = tableIdentifier;\n+    this.timestamp = timestamp;\n+    this.reference = reference;\n+  }\n+\n+  public TableIdentifier getTableIdentifier() {\n+    return tableIdentifier;\n+  }\n+\n+  public Instant getTimestamp() {\n+    return timestamp;\n+  }\n+\n+  public String getReference() {\n+    return reference;\n+  }\n+\n+  /**\n+   * Convert dataset read/write options to a table and ref/hash.\n+   */\n+  public static TableReference parse(TableIdentifier path) {\n+    TableReference pti = parse(path.name());\n+    return new TableReference(TableIdentifier.of(path.namespace(), pti.getTableIdentifier().name()),\n+        pti.getTimestamp(),\n+        pti.getReference());\n+  }\n+\n+  /**\n+   * Convert dataset read/write options to a table and ref/hash.\n+   */\n+  public static TableReference parse(String path) {\n+    // I am assuming tables can't have @ or # symbols\n+    if (path.split(\"@\").length > 2) {\n+      throw new IllegalArgumentException(String.format(\"Can only reference one branch in %s\", path));\n+    }\n+    if (path.split(\"#\").length > 2) {\n+      throw new IllegalArgumentException(String.format(\"Can only reference one timestamp in %s\", path));\n+    }\n+\n+    if (path.contains(\"@\") && path.contains(\"#\")) {\n+      throw new IllegalArgumentException(\"Invalid table name:\" +\n+          \" # is not allowed (reference by timestamp is not supported)\");\n+    }\n+\n+    if (path.contains(\"@\")) {\n+      String[] tableRef = path.split(\"@\");\n+      TableIdentifier identifier = TableIdentifier.parse(tableRef[0]);\n+      return new TableReference(identifier, null, tableRef[1]);\n+    }\n+\n+    if (path.contains(\"#\")) {\n+      throw new IllegalArgumentException(\"Invalid table name:\" +\n+          \" # is not allowed (reference by timestamp is not supported)\");\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "originalPosition": 88}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM0MDIyMzYy", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-534022362", "createdAt": "2020-11-19T01:57:14Z", "commit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMTo1NzoxNVrOH2Jiug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMTo1NzoxNVrOH2Jiug==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0MTQ5OA==", "bodyText": "Isn't it automatically refreshed because it is shared with the NessieTableOperations?", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526541498", "createdAt": "2020-11-19T01:57:15Z", "author": {"login": "rdblue"}, "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestBranchHash.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestBranchHash extends BaseTestIceberg {\n+\n+  private static final String BRANCH = \"test-branch-hash\";\n+\n+  public TestBranchHash() {\n+    super(BRANCH);\n+  }\n+\n+  @Test\n+  public void testBasicBranch() throws NessieNotFoundException, NessieConflictException {\n+    TableIdentifier foobar = TableIdentifier.of(\"foo\", \"bar\");\n+\n+    Table bar = createTable(foobar, 1); // table 1\n+    catalog.refresh();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "originalPosition": 44}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM0MDIzMjYx", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-534023261", "createdAt": "2020-11-19T01:59:42Z", "commit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMTo1OTo0MlrOH2Jl0g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMTo1OTo0MlrOH2Jl0g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0MjI5MA==", "bodyText": "Using the table name \"foo.bar\" is fine, but using foobar as a variable name makes the test harder to read because it isn't obvious what metadataLocation(catalog, foobar) does exactly. If foobar is a Namespace, then it would be the default location for a table, for example. It would be easier to read if this were something more descriptive, like tableIdent.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526542290", "createdAt": "2020-11-19T01:59:42Z", "author": {"login": "rdblue"}, "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestBranchHash.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestBranchHash extends BaseTestIceberg {\n+\n+  private static final String BRANCH = \"test-branch-hash\";\n+\n+  public TestBranchHash() {\n+    super(BRANCH);\n+  }\n+\n+  @Test\n+  public void testBasicBranch() throws NessieNotFoundException, NessieConflictException {\n+    TableIdentifier foobar = TableIdentifier.of(\"foo\", \"bar\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "originalPosition": 41}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM0MDIzNDc3", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-534023477", "createdAt": "2020-11-19T02:00:18Z", "commit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMjowMDoxOFrOH2JmoA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMjowMDoxOFrOH2JmoA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0MjQ5Ng==", "bodyText": "Similar, it would be good to name this table for clarity later on in this long test method.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526542496", "createdAt": "2020-11-19T02:00:18Z", "author": {"login": "rdblue"}, "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestBranchHash.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestBranchHash extends BaseTestIceberg {\n+\n+  private static final String BRANCH = \"test-branch-hash\";\n+\n+  public TestBranchHash() {\n+    super(BRANCH);\n+  }\n+\n+  @Test\n+  public void testBasicBranch() throws NessieNotFoundException, NessieConflictException {\n+    TableIdentifier foobar = TableIdentifier.of(\"foo\", \"bar\");\n+\n+    Table bar = createTable(foobar, 1); // table 1", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "originalPosition": 43}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM0MDI0MDI3", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-534024027", "createdAt": "2020-11-19T02:01:46Z", "commit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMjowMTo0NlrOH2JomQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMjowMTo0NlrOH2JomQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0MzAwMQ==", "bodyText": "This is another test I think could be broken into distinct cases with a @Before to set up the default branch and table.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526543001", "createdAt": "2020-11-19T02:01:46Z", "author": {"login": "rdblue"}, "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestBranchHash.java", "diffHunk": "@@ -0,0 +1,78 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestBranchHash extends BaseTestIceberg {\n+\n+  private static final String BRANCH = \"test-branch-hash\";\n+\n+  public TestBranchHash() {\n+    super(BRANCH);\n+  }\n+\n+  @Test\n+  public void testBasicBranch() throws NessieNotFoundException, NessieConflictException {\n+    TableIdentifier foobar = TableIdentifier.of(\"foo\", \"bar\");\n+\n+    Table bar = createTable(foobar, 1); // table 1\n+    catalog.refresh();\n+    createBranch(\"test\", catalog.currentHash());\n+\n+    hadoopConfig.set(NessieClient.CONF_NESSIE_REF, \"test\");\n+\n+    NessieCatalog newCatalog = initCatalog(\"test\");\n+    String initialMetadataLocation = metadataLocation(newCatalog, foobar);\n+    Assert.assertEquals(initialMetadataLocation, metadataLocation(catalog, foobar));\n+\n+    bar.updateSchema().addColumn(\"id1\", Types.LongType.get()).commit();\n+\n+    // metadata location changed no longer matches\n+    Assert.assertNotEquals(metadataLocation(catalog, foobar), metadataLocation(newCatalog, foobar));\n+\n+    // points to the previous metadata location\n+    Assert.assertEquals(initialMetadataLocation, metadataLocation(newCatalog, foobar));\n+\n+\n+    String mainHash = tree.getReferenceByName(BRANCH).getHash();\n+    // catalog created with ref and no hash points to same catalog as above\n+    NessieCatalog refCatalog = initCatalog(\"test\");\n+    Assert.assertEquals(metadataLocation(newCatalog, foobar), metadataLocation(refCatalog, foobar));\n+    // catalog created with ref and hash points to\n+    NessieCatalog refHashCatalog = initCatalog(mainHash);\n+    Assert.assertEquals(metadataLocation(catalog, foobar), metadataLocation(refHashCatalog, foobar));\n+\n+    // asking for table@branch gives expected regardless of catalog\n+    Assert.assertEquals(metadataLocation(newCatalog, foobar),\n+        metadataLocation(catalog, TableIdentifier.of(\"foo\", \"bar@test\")));\n+    // asking for table@branch#hash gives expected regardless of catalog\n+    Assert.assertEquals(metadataLocation(catalog, foobar),\n+        metadataLocation(catalog, TableIdentifier.of(\"foo\", \"bar@\" + mainHash)));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "originalPosition": 75}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM0MDI0NTkx", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-534024591", "createdAt": "2020-11-19T02:03:22Z", "commit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMjowMzoyM1rOH2JqrA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMjowMzoyM1rOH2JqrA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0MzUzMg==", "bodyText": "Context helpers would make this test more readable and would be helpful if it ever fails.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526543532", "createdAt": "2020-11-19T02:03:23Z", "author": {"login": "rdblue"}, "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestCatalogBranch.java", "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Branch;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestCatalogBranch extends BaseTestIceberg {\n+\n+  public TestCatalogBranch() {\n+    super(\"main\");\n+  }\n+\n+  @SuppressWarnings(\"VariableDeclarationUsageDistance\")\n+  @Test\n+  public void testBasicBranch() throws NessieNotFoundException, NessieConflictException {\n+    TableIdentifier foobar = TableIdentifier.of(\"foo\", \"bar\");\n+    TableIdentifier foobaz = TableIdentifier.of(\"foo\", \"baz\");\n+    Table bar = createTable(foobar, 1); // table 1\n+    createTable(foobaz, 1); // table 2\n+    catalog.refresh();\n+    createBranch(\"test\", catalog.currentHash());\n+\n+    hadoopConfig.set(NessieClient.CONF_NESSIE_REF, \"test\");\n+\n+    NessieCatalog newCatalog = initCatalog(\"test\");\n+    String initialMetadataLocation = metadataLocation(newCatalog, foobar);\n+    Assert.assertEquals(initialMetadataLocation, metadataLocation(catalog, foobar));\n+    Assert.assertEquals(metadataLocation(newCatalog, foobaz), metadataLocation(catalog, foobaz));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "originalPosition": 53}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM0MDI0ODU0", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-534024854", "createdAt": "2020-11-19T02:04:05Z", "commit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMjowNDowNVrOH2Jrfw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMjowNDowNVrOH2Jrfw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0Mzc0Mw==", "bodyText": "What does this suppress?", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526543743", "createdAt": "2020-11-19T02:04:05Z", "author": {"login": "rdblue"}, "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestCatalogBranch.java", "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Branch;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestCatalogBranch extends BaseTestIceberg {\n+\n+  public TestCatalogBranch() {\n+    super(\"main\");\n+  }\n+\n+  @SuppressWarnings(\"VariableDeclarationUsageDistance\")", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "originalPosition": 38}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM0MDI1MTMx", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-534025131", "createdAt": "2020-11-19T02:04:50Z", "commit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMjowNDo1MFrOH2Jsjw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMjowNDo1MFrOH2Jsjw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0NDAxNQ==", "bodyText": "What is the main difference between this suite and the branch suite above? Seems very similar to me, so I think I've missed the point. Smaller test cases that are well named would help.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526544015", "createdAt": "2020-11-19T02:04:50Z", "author": {"login": "rdblue"}, "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestCatalogBranch.java", "diffHunk": "@@ -0,0 +1,84 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Branch;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestCatalogBranch extends BaseTestIceberg {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "originalPosition": 32}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM0MDI1NDEw", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-534025410", "createdAt": "2020-11-19T02:05:35Z", "commit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMjowNTozNVrOH2Jtmg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMjowNTozNVrOH2Jtmg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0NDI4Mg==", "bodyText": "Nit: println usage.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526544282", "createdAt": "2020-11-19T02:05:35Z", "author": {"login": "rdblue"}, "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestDefaultCatalogBranch.java", "diffHunk": "@@ -0,0 +1,82 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Branch;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+/**\n+ * test tag operations with a default tag set by server.\n+ */\n+public class TestDefaultCatalogBranch extends BaseTestIceberg {\n+\n+  public TestDefaultCatalogBranch() {\n+    super(\"main\");\n+  }\n+\n+  @SuppressWarnings(\"VariableDeclarationUsageDistance\")\n+  @Test\n+  public void testBasicBranch() throws NessieNotFoundException, NessieConflictException {\n+    TableIdentifier foobar = TableIdentifier.of(\"foo\", \"bar\");\n+    TableIdentifier foobaz = TableIdentifier.of(\"foo\", \"baz\");\n+    createTable(foobar, 1); // table 1\n+    createTable(foobaz, 1); // table 2\n+\n+    catalog.refresh();\n+    tree.createReference(Branch.of(\"FORWARD\", catalog.currentHash()));\n+    hadoopConfig.set(NessieClient.CONF_NESSIE_REF, \"FORWARD\");\n+    NessieCatalog forwardCatalog = initCatalog(\"FORWARD\");\n+    forwardCatalog.loadTable(foobaz).updateSchema().addColumn(\"id1\", Types.LongType.get()).commit();\n+    forwardCatalog.loadTable(foobar).updateSchema().addColumn(\"id1\", Types.LongType.get()).commit();\n+    Assert.assertNotEquals(metadataLocation(forwardCatalog, foobar),\n+                               metadataLocation(catalog, foobar));\n+    Assert.assertNotEquals(metadataLocation(forwardCatalog, foobaz),\n+                               metadataLocation(catalog, foobaz));\n+\n+    System.out.println(metadataLocation(forwardCatalog, foobar));\n+    System.out.println(metadataLocation(catalog, foobar));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "originalPosition": 60}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM0MDI1NjUw", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-534025650", "createdAt": "2020-11-19T02:06:21Z", "commit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMjowNjoyMlrOH2JuXQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMjowNjoyMlrOH2JuXQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0NDQ3Nw==", "bodyText": "This is another test that doesn't seem very different from the others. Can these be combined into a single suite with good test case names that calls out what is unique about each test?", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526544477", "createdAt": "2020-11-19T02:06:22Z", "author": {"login": "rdblue"}, "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestDefaultCatalogBranch.java", "diffHunk": "@@ -0,0 +1,82 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+import com.dremio.nessie.client.NessieClient;\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Branch;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.types.Types;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+/**\n+ * test tag operations with a default tag set by server.\n+ */\n+public class TestDefaultCatalogBranch extends BaseTestIceberg {\n+\n+  public TestDefaultCatalogBranch() {\n+    super(\"main\");\n+  }\n+\n+  @SuppressWarnings(\"VariableDeclarationUsageDistance\")\n+  @Test\n+  public void testBasicBranch() throws NessieNotFoundException, NessieConflictException {\n+    TableIdentifier foobar = TableIdentifier.of(\"foo\", \"bar\");\n+    TableIdentifier foobaz = TableIdentifier.of(\"foo\", \"baz\");\n+    createTable(foobar, 1); // table 1\n+    createTable(foobaz, 1); // table 2\n+\n+    catalog.refresh();\n+    tree.createReference(Branch.of(\"FORWARD\", catalog.currentHash()));\n+    hadoopConfig.set(NessieClient.CONF_NESSIE_REF, \"FORWARD\");\n+    NessieCatalog forwardCatalog = initCatalog(\"FORWARD\");\n+    forwardCatalog.loadTable(foobaz).updateSchema().addColumn(\"id1\", Types.LongType.get()).commit();\n+    forwardCatalog.loadTable(foobar).updateSchema().addColumn(\"id1\", Types.LongType.get()).commit();\n+    Assert.assertNotEquals(metadataLocation(forwardCatalog, foobar),\n+                               metadataLocation(catalog, foobar));\n+    Assert.assertNotEquals(metadataLocation(forwardCatalog, foobaz),\n+                               metadataLocation(catalog, foobaz));\n+\n+    System.out.println(metadataLocation(forwardCatalog, foobar));\n+    System.out.println(metadataLocation(catalog, foobar));\n+\n+    forwardCatalog.refresh();\n+    tree.assignBranch(\"main\",\n+        tree.getReferenceByName(\"main\").getHash(),\n+        Branch.of(\"main\", forwardCatalog.currentHash()));\n+\n+    catalog.refresh();\n+\n+    System.out.println(metadataLocation(forwardCatalog, foobar));\n+    System.out.println(metadataLocation(catalog, foobar));\n+\n+    Assert.assertEquals(metadataLocation(forwardCatalog, foobar),\n+                            metadataLocation(catalog, foobar));\n+    Assert.assertEquals(metadataLocation(forwardCatalog, foobaz),\n+                            metadataLocation(catalog, foobaz));\n+\n+    catalog.dropTable(foobar);\n+    catalog.dropTable(foobaz);\n+    tree.deleteBranch(\"FORWARD\", tree.getReferenceByName(\"FORWARD\").getHash());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "originalPosition": 79}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM0MDI2NTQ2", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-534026546", "createdAt": "2020-11-19T02:08:46Z", "commit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMjowODo0NlrOH2Jxfw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMjowODo0NlrOH2Jxfw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0NTI3OQ==", "bodyText": "Could this be refactored to be smaller and use a couple of util functions? Something like addFile(table, filename) could help.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526545279", "createdAt": "2020-11-19T02:08:46Z", "author": {"login": "rdblue"}, "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestNessieTable.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Branch;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import org.apache.avro.generic.GenericData;\n+import org.apache.avro.generic.GenericRecordBuilder;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.AssertHelpers;\n+import org.apache.iceberg.DataFile;\n+import org.apache.iceberg.DataFiles;\n+import org.apache.iceberg.Files;\n+import org.apache.iceberg.HasTableOperations;\n+import org.apache.iceberg.ManifestFile;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.TableMetadataParser;\n+import org.apache.iceberg.avro.Avro;\n+import org.apache.iceberg.avro.AvroSchemaUtil;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.io.FileAppender;\n+import org.apache.iceberg.types.Types;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import static org.apache.iceberg.TableMetadataParser.getFileExtension;\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+\n+public class TestNessieTable extends BaseTestIceberg {\n+\n+  private static final String BRANCH = \"iceberg-table-test\";\n+\n+  private static final String DB_NAME = \"db\";\n+  private static final String TABLE_NAME = \"tbl\";\n+  private static final TableIdentifier TABLE_IDENTIFIER = TableIdentifier.of(DB_NAME, TABLE_NAME);\n+  private static final ContentsKey KEY = ContentsKey.of(DB_NAME, TABLE_NAME);\n+  private static final Schema schema = new Schema(Types.StructType.of(\n+      required(1, \"id\", Types.LongType.get())).fields());\n+  private static final Schema altered = new Schema(Types.StructType.of(\n+      required(1, \"id\", Types.LongType.get()),\n+      optional(2, \"data\", Types.LongType.get())).fields());\n+\n+  private Path tableLocation;\n+\n+  public TestNessieTable() {\n+    super(BRANCH);\n+  }\n+\n+  @Before\n+  public void beforeEach() throws IOException {\n+    super.beforeEach();\n+    this.tableLocation = new Path(catalog.createTable(TABLE_IDENTIFIER, schema).location());\n+  }\n+\n+  @After\n+  public void afterEach() throws Exception {\n+    // drop the table data\n+    if (tableLocation != null) {\n+      tableLocation.getFileSystem(hadoopConfig).delete(tableLocation, true);\n+      catalog.refresh();\n+      catalog.dropTable(TABLE_IDENTIFIER, false);\n+    }\n+\n+    super.afterEach();\n+  }\n+\n+  private com.dremio.nessie.model.IcebergTable getTable(ContentsKey key) throws NessieNotFoundException {\n+    return client.getContentsApi()\n+        .getContents(key, BRANCH)\n+        .unwrap(IcebergTable.class).get();\n+  }\n+\n+  @Test\n+  public void testCreate() throws NessieNotFoundException, IOException {\n+    // Table should be created in iceberg\n+    // Table should be renamed in iceberg\n+    String tableName = TABLE_IDENTIFIER.name();\n+    Table icebergTable = catalog.loadTable(TABLE_IDENTIFIER);\n+    // add a column\n+    icebergTable.updateSchema().addColumn(\"mother\", Types.LongType.get()).commit();\n+    IcebergTable table = getTable(KEY);\n+    // check parameters are in expected state\n+    Assert.assertEquals(getTableLocation(tableName),\n+        (temp.getRoot().toURI().toString() + DB_NAME + \"/\" +\n+            tableName).replace(\"//\",\n+            \"/\"));\n+\n+    // Only 1 snapshotFile Should exist and no manifests should exist\n+    Assert.assertEquals(2, metadataVersionFiles(tableName).size());\n+    Assert.assertEquals(0, manifestFiles(tableName).size());\n+  }\n+\n+  @Test\n+  public void testRename() {\n+    String renamedTableName = \"rename_table_name\";\n+    TableIdentifier renameTableIdentifier = TableIdentifier.of(TABLE_IDENTIFIER.namespace(),\n+        renamedTableName);\n+\n+    Table original = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    catalog.renameTable(TABLE_IDENTIFIER, renameTableIdentifier);\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+    Assert.assertTrue(catalog.tableExists(renameTableIdentifier));\n+\n+    Table renamed = catalog.loadTable(renameTableIdentifier);\n+\n+    Assert.assertEquals(original.schema().asStruct(), renamed.schema().asStruct());\n+    Assert.assertEquals(original.spec(), renamed.spec());\n+    Assert.assertEquals(original.location(), renamed.location());\n+    Assert.assertEquals(original.currentSnapshot(), renamed.currentSnapshot());\n+\n+    Assert.assertTrue(catalog.dropTable(renameTableIdentifier));\n+  }\n+\n+  @Test\n+  public void testDrop() {\n+    Assert.assertTrue(catalog.tableExists(TABLE_IDENTIFIER));\n+    Assert.assertTrue(catalog.dropTable(TABLE_IDENTIFIER));\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+  }\n+\n+  @Test\n+  public void testDropWithoutPurgeLeavesTableData() throws IOException {\n+    Table table = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    GenericRecordBuilder recordBuilder =\n+        new GenericRecordBuilder(AvroSchemaUtil.convert(schema, \"test\"));\n+    List<GenericData.Record> records = new ArrayList<>();\n+    records.add(recordBuilder.set(\"id\", 1L).build());\n+    records.add(recordBuilder.set(\"id\", 2L).build());\n+    records.add(recordBuilder.set(\"id\", 3L).build());\n+\n+    String fileLocation = table.location().replace(\"file:\", \"\") + \"/data/file.avro\";\n+    try (FileAppender<GenericData.Record> writer = Avro.write(Files.localOutput(fileLocation))\n+        .schema(schema)\n+        .named(\"test\")\n+        .build()) {\n+      for (GenericData.Record rec : records) {\n+        writer.add(rec);\n+      }\n+    }\n+\n+    DataFile file = DataFiles.builder(table.spec())\n+        .withRecordCount(3)\n+        .withPath(fileLocation)\n+        .withFileSizeInBytes(Files.localInput(fileLocation).getLength())\n+        .build();\n+\n+    table.newAppend().appendFile(file).commit();\n+\n+    String manifestListLocation =\n+        table.currentSnapshot().manifestListLocation().replace(\"file:\", \"\");\n+\n+    Assert.assertTrue(catalog.dropTable(TABLE_IDENTIFIER, false));\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+\n+    Assert.assertTrue(new File(fileLocation).exists());\n+    Assert.assertTrue(new File(manifestListLocation).exists());\n+  }\n+\n+  @Test\n+  public void testDropTable() throws IOException {\n+    Table table = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    GenericRecordBuilder recordBuilder =\n+        new GenericRecordBuilder(AvroSchemaUtil.convert(schema, \"test\"));\n+    List<GenericData.Record> records = new ArrayList<>();\n+    records.add(recordBuilder.set(\"id\", 1L).build());\n+    records.add(recordBuilder.set(\"id\", 2L).build());\n+    records.add(recordBuilder.set(\"id\", 3L).build());\n+\n+    String location1 = table.location().replace(\"file:\", \"\") + \"/data/file1.avro\";\n+    try (FileAppender<GenericData.Record> writer = Avro.write(Files.localOutput(location1))\n+        .schema(schema)\n+        .named(\"test\")\n+        .build()) {\n+      for (GenericData.Record rec : records) {\n+        writer.add(rec);\n+      }\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "originalPosition": 214}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTM0MDI3NDkz", "url": "https://github.com/apache/iceberg/pull/1587#pullrequestreview-534027493", "createdAt": "2020-11-19T02:11:21Z", "commit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMjoxMToyMlrOH2J0yw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMjoxMToyMlrOH2J0yw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjU0NjEyMw==", "bodyText": "Do you have a test for concurrent writes to the same table from multiple catalogs? That would be good with two cases: two tables that share the same ref (loaded by the same catalog) and two tables that were loaded by different catalogs and have separate refs.", "url": "https://github.com/apache/iceberg/pull/1587#discussion_r526546123", "createdAt": "2020-11-19T02:11:22Z", "author": {"login": "rdblue"}, "path": "nessie/src/test/java/org/apache/iceberg/nessie/TestNessieTable.java", "diffHunk": "@@ -0,0 +1,348 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.nessie;\n+\n+\n+import com.dremio.nessie.error.NessieConflictException;\n+import com.dremio.nessie.error.NessieNotFoundException;\n+import com.dremio.nessie.model.Branch;\n+import com.dremio.nessie.model.ContentsKey;\n+import com.dremio.nessie.model.IcebergTable;\n+import java.io.File;\n+import java.io.IOException;\n+import java.nio.file.Paths;\n+import java.util.ArrayList;\n+import java.util.Arrays;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import org.apache.avro.generic.GenericData;\n+import org.apache.avro.generic.GenericRecordBuilder;\n+import org.apache.hadoop.fs.Path;\n+import org.apache.iceberg.AssertHelpers;\n+import org.apache.iceberg.DataFile;\n+import org.apache.iceberg.DataFiles;\n+import org.apache.iceberg.Files;\n+import org.apache.iceberg.HasTableOperations;\n+import org.apache.iceberg.ManifestFile;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.TableMetadataParser;\n+import org.apache.iceberg.avro.Avro;\n+import org.apache.iceberg.avro.AvroSchemaUtil;\n+import org.apache.iceberg.catalog.TableIdentifier;\n+import org.apache.iceberg.exceptions.CommitFailedException;\n+import org.apache.iceberg.io.FileAppender;\n+import org.apache.iceberg.types.Types;\n+import org.junit.After;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.Test;\n+\n+import static org.apache.iceberg.TableMetadataParser.getFileExtension;\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+import static org.apache.iceberg.types.Types.NestedField.required;\n+\n+\n+public class TestNessieTable extends BaseTestIceberg {\n+\n+  private static final String BRANCH = \"iceberg-table-test\";\n+\n+  private static final String DB_NAME = \"db\";\n+  private static final String TABLE_NAME = \"tbl\";\n+  private static final TableIdentifier TABLE_IDENTIFIER = TableIdentifier.of(DB_NAME, TABLE_NAME);\n+  private static final ContentsKey KEY = ContentsKey.of(DB_NAME, TABLE_NAME);\n+  private static final Schema schema = new Schema(Types.StructType.of(\n+      required(1, \"id\", Types.LongType.get())).fields());\n+  private static final Schema altered = new Schema(Types.StructType.of(\n+      required(1, \"id\", Types.LongType.get()),\n+      optional(2, \"data\", Types.LongType.get())).fields());\n+\n+  private Path tableLocation;\n+\n+  public TestNessieTable() {\n+    super(BRANCH);\n+  }\n+\n+  @Before\n+  public void beforeEach() throws IOException {\n+    super.beforeEach();\n+    this.tableLocation = new Path(catalog.createTable(TABLE_IDENTIFIER, schema).location());\n+  }\n+\n+  @After\n+  public void afterEach() throws Exception {\n+    // drop the table data\n+    if (tableLocation != null) {\n+      tableLocation.getFileSystem(hadoopConfig).delete(tableLocation, true);\n+      catalog.refresh();\n+      catalog.dropTable(TABLE_IDENTIFIER, false);\n+    }\n+\n+    super.afterEach();\n+  }\n+\n+  private com.dremio.nessie.model.IcebergTable getTable(ContentsKey key) throws NessieNotFoundException {\n+    return client.getContentsApi()\n+        .getContents(key, BRANCH)\n+        .unwrap(IcebergTable.class).get();\n+  }\n+\n+  @Test\n+  public void testCreate() throws NessieNotFoundException, IOException {\n+    // Table should be created in iceberg\n+    // Table should be renamed in iceberg\n+    String tableName = TABLE_IDENTIFIER.name();\n+    Table icebergTable = catalog.loadTable(TABLE_IDENTIFIER);\n+    // add a column\n+    icebergTable.updateSchema().addColumn(\"mother\", Types.LongType.get()).commit();\n+    IcebergTable table = getTable(KEY);\n+    // check parameters are in expected state\n+    Assert.assertEquals(getTableLocation(tableName),\n+        (temp.getRoot().toURI().toString() + DB_NAME + \"/\" +\n+            tableName).replace(\"//\",\n+            \"/\"));\n+\n+    // Only 1 snapshotFile Should exist and no manifests should exist\n+    Assert.assertEquals(2, metadataVersionFiles(tableName).size());\n+    Assert.assertEquals(0, manifestFiles(tableName).size());\n+  }\n+\n+  @Test\n+  public void testRename() {\n+    String renamedTableName = \"rename_table_name\";\n+    TableIdentifier renameTableIdentifier = TableIdentifier.of(TABLE_IDENTIFIER.namespace(),\n+        renamedTableName);\n+\n+    Table original = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    catalog.renameTable(TABLE_IDENTIFIER, renameTableIdentifier);\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+    Assert.assertTrue(catalog.tableExists(renameTableIdentifier));\n+\n+    Table renamed = catalog.loadTable(renameTableIdentifier);\n+\n+    Assert.assertEquals(original.schema().asStruct(), renamed.schema().asStruct());\n+    Assert.assertEquals(original.spec(), renamed.spec());\n+    Assert.assertEquals(original.location(), renamed.location());\n+    Assert.assertEquals(original.currentSnapshot(), renamed.currentSnapshot());\n+\n+    Assert.assertTrue(catalog.dropTable(renameTableIdentifier));\n+  }\n+\n+  @Test\n+  public void testDrop() {\n+    Assert.assertTrue(catalog.tableExists(TABLE_IDENTIFIER));\n+    Assert.assertTrue(catalog.dropTable(TABLE_IDENTIFIER));\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+  }\n+\n+  @Test\n+  public void testDropWithoutPurgeLeavesTableData() throws IOException {\n+    Table table = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    GenericRecordBuilder recordBuilder =\n+        new GenericRecordBuilder(AvroSchemaUtil.convert(schema, \"test\"));\n+    List<GenericData.Record> records = new ArrayList<>();\n+    records.add(recordBuilder.set(\"id\", 1L).build());\n+    records.add(recordBuilder.set(\"id\", 2L).build());\n+    records.add(recordBuilder.set(\"id\", 3L).build());\n+\n+    String fileLocation = table.location().replace(\"file:\", \"\") + \"/data/file.avro\";\n+    try (FileAppender<GenericData.Record> writer = Avro.write(Files.localOutput(fileLocation))\n+        .schema(schema)\n+        .named(\"test\")\n+        .build()) {\n+      for (GenericData.Record rec : records) {\n+        writer.add(rec);\n+      }\n+    }\n+\n+    DataFile file = DataFiles.builder(table.spec())\n+        .withRecordCount(3)\n+        .withPath(fileLocation)\n+        .withFileSizeInBytes(Files.localInput(fileLocation).getLength())\n+        .build();\n+\n+    table.newAppend().appendFile(file).commit();\n+\n+    String manifestListLocation =\n+        table.currentSnapshot().manifestListLocation().replace(\"file:\", \"\");\n+\n+    Assert.assertTrue(catalog.dropTable(TABLE_IDENTIFIER, false));\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+\n+    Assert.assertTrue(new File(fileLocation).exists());\n+    Assert.assertTrue(new File(manifestListLocation).exists());\n+  }\n+\n+  @Test\n+  public void testDropTable() throws IOException {\n+    Table table = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    GenericRecordBuilder recordBuilder =\n+        new GenericRecordBuilder(AvroSchemaUtil.convert(schema, \"test\"));\n+    List<GenericData.Record> records = new ArrayList<>();\n+    records.add(recordBuilder.set(\"id\", 1L).build());\n+    records.add(recordBuilder.set(\"id\", 2L).build());\n+    records.add(recordBuilder.set(\"id\", 3L).build());\n+\n+    String location1 = table.location().replace(\"file:\", \"\") + \"/data/file1.avro\";\n+    try (FileAppender<GenericData.Record> writer = Avro.write(Files.localOutput(location1))\n+        .schema(schema)\n+        .named(\"test\")\n+        .build()) {\n+      for (GenericData.Record rec : records) {\n+        writer.add(rec);\n+      }\n+    }\n+\n+    String location2 = table.location().replace(\"file:\", \"\") + \"/data/file2.avro\";\n+    try (FileAppender<GenericData.Record> writer = Avro.write(Files.localOutput(location2))\n+        .schema(schema)\n+        .named(\"test\")\n+        .build()) {\n+      for (GenericData.Record rec : records) {\n+        writer.add(rec);\n+      }\n+    }\n+\n+    DataFile file1 = DataFiles.builder(table.spec())\n+        .withRecordCount(3)\n+        .withPath(location1)\n+        .withFileSizeInBytes(Files.localInput(location2).getLength())\n+        .build();\n+\n+    DataFile file2 = DataFiles.builder(table.spec())\n+        .withRecordCount(3)\n+        .withPath(location2)\n+        .withFileSizeInBytes(Files.localInput(location1).getLength())\n+        .build();\n+\n+    // add both data files\n+    table.newAppend().appendFile(file1).appendFile(file2).commit();\n+\n+    // delete file2\n+    table.newDelete().deleteFile(file2.path()).commit();\n+\n+    String manifestListLocation =\n+        table.currentSnapshot().manifestListLocation().replace(\"file:\", \"\");\n+\n+    List<ManifestFile> manifests = table.currentSnapshot().allManifests();\n+\n+    Assert.assertTrue(catalog.dropTable(TABLE_IDENTIFIER));\n+    Assert.assertFalse(catalog.tableExists(TABLE_IDENTIFIER));\n+\n+    Assert.assertTrue(new File(location1).exists());\n+    Assert.assertTrue(new File(location2).exists());\n+    Assert.assertTrue(new File(manifestListLocation).exists());\n+    for (ManifestFile manifest : manifests) {\n+      Assert.assertTrue(new File(manifest.path().replace(\"file:\", \"\")).exists());\n+    }\n+    Assert.assertTrue(new File(\n+        ((HasTableOperations) table).operations()\n+            .current()\n+            .metadataFileLocation()\n+            .replace(\"file:\", \"\"))\n+        .exists());\n+  }\n+\n+  @Test\n+  public void testExistingTableUpdate() {\n+    Table icebergTable = catalog.loadTable(TABLE_IDENTIFIER);\n+    // add a column\n+    icebergTable.updateSchema().addColumn(\"data\", Types.LongType.get()).commit();\n+\n+    icebergTable = catalog.loadTable(TABLE_IDENTIFIER);\n+\n+    // Only 2 snapshotFile Should exist and no manifests should exist\n+    Assert.assertEquals(2, metadataVersionFiles(TABLE_NAME).size());\n+    Assert.assertEquals(0, manifestFiles(TABLE_NAME).size());\n+    Assert.assertEquals(altered.asStruct(), icebergTable.schema().asStruct());\n+\n+  }\n+\n+  @Test\n+  public void testFailure() throws NessieNotFoundException, NessieConflictException {\n+    Table icebergTable = catalog.loadTable(TABLE_IDENTIFIER);\n+    Branch branch = (Branch) client.getTreeApi().getReferenceByName(BRANCH);\n+\n+    IcebergTable table = client.getContentsApi().getContents(KEY, BRANCH).unwrap(IcebergTable.class).get();\n+\n+    client.getContentsApi().setContents(KEY, branch.getName(), branch.getHash(), \"\",\n+        IcebergTable.of(\"dummytable.metadata.json\"));\n+\n+    AssertHelpers.assertThrows(\"Update schema fails with conflict exception, ref not up to date\",\n+        CommitFailedException.class,\n+        () -> icebergTable.updateSchema().addColumn(\"data\", Types.LongType.get()).commit());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382"}, "originalPosition": 293}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "52b34b7f8090a7af05261cf280a8bfe0e5ad9248", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/52b34b7f8090a7af05261cf280a8bfe0e5ad9248", "committedDate": "2020-11-20T12:57:08Z", "message": "initial commit of nessie:\n\n* nessie catalog/table ops\n* modifications to catalog/source for spark\n* add nessie to tests\n\nleft to do:\n* support namespaces\n* start/stop nessie as part of gradle build"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "dd7278d84c2d2c01c15192420f8b50410374308c", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/dd7278d84c2d2c01c15192420f8b50410374308c", "committedDate": "2020-11-20T12:57:09Z", "message": "working nessie\n\n* remove namespace for nessie, handled implicitly\n* add gradle plugin"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a76061e136b5fd00bab4a6ffab2f77e527d73d6c", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/a76061e136b5fd00bab4a6ffab2f77e527d73d6c", "committedDate": "2020-11-20T12:57:10Z", "message": "fix versions"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a0e98a7f1db3877913a91e2e8771df78e9c2fe6d", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/a0e98a7f1db3877913a91e2e8771df78e9c2fe6d", "committedDate": "2020-11-20T12:57:11Z", "message": "tidy up"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "0052ab3b5df33df6cc4a3011f5f56f2579e2957e", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/0052ab3b5df33df6cc4a3011f5f56f2579e2957e", "committedDate": "2020-11-20T12:57:12Z", "message": "fix up quarkus plugin"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "491e7c2018385169a388e582c6625936ffd82de6", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/491e7c2018385169a388e582c6625936ffd82de6", "committedDate": "2020-11-20T12:57:13Z", "message": "code review comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c1ca68c94c9eaaf0fb46ba39e6089df579e33302", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/c1ca68c94c9eaaf0fb46ba39e6089df579e33302", "committedDate": "2020-11-20T12:57:14Z", "message": "revert spark changes"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "a52e751fae2f126d0d86a5e2be29111ac219b45f", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/a52e751fae2f126d0d86a5e2be29111ac219b45f", "committedDate": "2020-11-20T12:57:15Z", "message": "some more updates for code review"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "823e5bca690dde951ead0f7a6cd96f385d28f41e", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/823e5bca690dde951ead0f7a6cd96f385d28f41e", "committedDate": "2020-11-20T12:57:16Z", "message": "basic support for Namespaces"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4ef071f3e8e7a6e949ccb6650f2556304db5bc01", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/4ef071f3e8e7a6e949ccb6650f2556304db5bc01", "committedDate": "2020-11-20T12:57:16Z", "message": "fix tests and bump plugin version"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "6fa22bb3967de6918f39ac45e688dfe94ffe7306", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/6fa22bb3967de6918f39ac45e688dfe94ffe7306", "committedDate": "2020-11-20T12:57:17Z", "message": "update to support #1640"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "b23f6dac9179fd46cb6ec821a879b7e7b467e95a", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/b23f6dac9179fd46cb6ec821a879b7e7b467e95a", "committedDate": "2020-11-20T12:57:18Z", "message": "simpler way to get spark app id"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "8a9009b06ba78c3ff62c22f13ec8908156dd5151", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/8a9009b06ba78c3ff62c22f13ec8908156dd5151", "committedDate": "2020-11-20T12:57:19Z", "message": "address code review"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bf52afa2053150ff079ba6918518b78b95e8d86e", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/bf52afa2053150ff079ba6918518b78b95e8d86e", "committedDate": "2020-11-20T12:57:20Z", "message": "another round of code review"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5a15cde230c0b0c7e101fff9ea85f77b6122a4df", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/5a15cde230c0b0c7e101fff9ea85f77b6122a4df", "committedDate": "2020-11-20T12:57:21Z", "message": "respond to code review comments"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f9bc7ba8488260f738eac4e6d163a6bf98a9b22c", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/f9bc7ba8488260f738eac4e6d163a6bf98a9b22c", "committedDate": "2020-11-20T19:17:59Z", "message": "next round of code review"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "b46dbf7a2599e7bd8cea384cd968366ce4767382", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/b46dbf7a2599e7bd8cea384cd968366ce4767382", "committedDate": "2020-11-18T13:52:21Z", "message": "respond to code review comments"}, "afterCommit": {"oid": "f9bc7ba8488260f738eac4e6d163a6bf98a9b22c", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/f9bc7ba8488260f738eac4e6d163a6bf98a9b22c", "committedDate": "2020-11-20T19:17:59Z", "message": "next round of code review"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fc7cc8f6d4d2e83e75fb4e30f4bc285591a47ab7", "author": {"user": {"login": "rymurr", "name": "Ryan Murray"}}, "url": "https://github.com/apache/iceberg/commit/fc7cc8f6d4d2e83e75fb4e30f4bc285591a47ab7", "committedDate": "2020-11-23T17:48:13Z", "message": "clarify branch/table visibility tests"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3941, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}