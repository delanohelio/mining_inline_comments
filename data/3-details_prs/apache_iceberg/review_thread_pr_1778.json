{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTIyNjQ4Mzkx", "number": 1778, "reviewThreads": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQwMDo1Mjo0N1rOE6TCTA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMToxMjoxNFrOE61Puw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI5NTY0NzQ4OnYy", "diffSide": "RIGHT", "path": "spark2/src/main/java/org/apache/iceberg/spark/source/Reader.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQwMDo1Mjo0N1rOH1Rg5A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQwMTowNDowM1rOH1RvlQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYyMzUyNA==", "bodyText": "Looks like these 4 lines didn't actually change. Can you revert the whitespace changes here?", "url": "https://github.com/apache/iceberg/pull/1778#discussion_r525623524", "createdAt": "2020-11-18T00:52:47Z", "author": {"login": "rdblue"}, "path": "spark2/src/main/java/org/apache/iceberg/spark/source/Reader.java", "diffHunk": "@@ -156,10 +156,13 @@\n     this.io = io;\n     this.encryptionManager = encryptionManager;\n     this.caseSensitive = caseSensitive;\n-\n-    this.batchReadsEnabled = options.get(\"vectorization-enabled\").map(Boolean::parseBoolean).orElseGet(() ->\n-        PropertyUtil.propertyAsBoolean(table.properties(),\n-            TableProperties.PARQUET_VECTORIZATION_ENABLED, TableProperties.PARQUET_VECTORIZATION_ENABLED_DEFAULT));\n+    boolean batchReadsSparkSessionConf = SparkSession.active().sparkContext().getConf()\n+            .getBoolean(\"read.parquet.vectorization.enabled\", true);\n+    boolean batchReadsEnabledTableProp = options.get(\"vectorization-enabled\").map(Boolean::parseBoolean).orElseGet(() ->\n+            PropertyUtil.propertyAsBoolean(table.properties(),\n+                    TableProperties.PARQUET_VECTORIZATION_ENABLED,\n+                    TableProperties.PARQUET_VECTORIZATION_ENABLED_DEFAULT));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f121d81611f678203d66b6a33e2402ec3021845e"}, "originalPosition": 13}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYyNzI4NQ==", "bodyText": "The variable name was changed which caused the previous line to exceed the 120 character limit.", "url": "https://github.com/apache/iceberg/pull/1778#discussion_r525627285", "createdAt": "2020-11-18T01:04:03Z", "author": {"login": "samarthjain"}, "path": "spark2/src/main/java/org/apache/iceberg/spark/source/Reader.java", "diffHunk": "@@ -156,10 +156,13 @@\n     this.io = io;\n     this.encryptionManager = encryptionManager;\n     this.caseSensitive = caseSensitive;\n-\n-    this.batchReadsEnabled = options.get(\"vectorization-enabled\").map(Boolean::parseBoolean).orElseGet(() ->\n-        PropertyUtil.propertyAsBoolean(table.properties(),\n-            TableProperties.PARQUET_VECTORIZATION_ENABLED, TableProperties.PARQUET_VECTORIZATION_ENABLED_DEFAULT));\n+    boolean batchReadsSparkSessionConf = SparkSession.active().sparkContext().getConf()\n+            .getBoolean(\"read.parquet.vectorization.enabled\", true);\n+    boolean batchReadsEnabledTableProp = options.get(\"vectorization-enabled\").map(Boolean::parseBoolean).orElseGet(() ->\n+            PropertyUtil.propertyAsBoolean(table.properties(),\n+                    TableProperties.PARQUET_VECTORIZATION_ENABLED,\n+                    TableProperties.PARQUET_VECTORIZATION_ENABLED_DEFAULT));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYyMzUyNA=="}, "originalCommit": {"oid": "f121d81611f678203d66b6a33e2402ec3021845e"}, "originalPosition": 13}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI5NTY0ODcxOnYy", "diffSide": "RIGHT", "path": "spark2/src/main/java/org/apache/iceberg/spark/source/Reader.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQwMDo1MzozNVrOH1Rhww==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQwMDo1MzozNVrOH1Rhww==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYyMzc0Nw==", "bodyText": "Don't Spark settings need to start with spark.? Otherwise they are discarded.\nHow about spark.iceberg.vectorization.enabled?", "url": "https://github.com/apache/iceberg/pull/1778#discussion_r525623747", "createdAt": "2020-11-18T00:53:35Z", "author": {"login": "rdblue"}, "path": "spark2/src/main/java/org/apache/iceberg/spark/source/Reader.java", "diffHunk": "@@ -156,10 +156,13 @@\n     this.io = io;\n     this.encryptionManager = encryptionManager;\n     this.caseSensitive = caseSensitive;\n-\n-    this.batchReadsEnabled = options.get(\"vectorization-enabled\").map(Boolean::parseBoolean).orElseGet(() ->\n-        PropertyUtil.propertyAsBoolean(table.properties(),\n-            TableProperties.PARQUET_VECTORIZATION_ENABLED, TableProperties.PARQUET_VECTORIZATION_ENABLED_DEFAULT));\n+    boolean batchReadsSparkSessionConf = SparkSession.active().sparkContext().getConf()\n+            .getBoolean(\"read.parquet.vectorization.enabled\", true);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f121d81611f678203d66b6a33e2402ec3021845e"}, "originalPosition": 9}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzI5NTY3ODI4OnYy", "diffSide": "RIGHT", "path": "spark2/src/main/java/org/apache/iceberg/spark/source/Reader.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQwMTowNjo1MVrOH1RzSQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOFQwMTowNjo1MVrOH1RzSQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNTYyODIzMw==", "bodyText": "Looks like the logic here is too complicated. I think what you're trying to do is disable vectorized reads if the session conf disables them, and otherwise delegate to the table property. In other words, the session conf and the table property must be enabled to use vectorization. If that's the case, then this could be (batchReadsSparkSessionConf && batchReadsEnabledTableProp).\nI'm not sure that logic is a good idea, either. This may have surprising behavior because a user may expect that true enables vectorization for all tables when used as a session property.\nI think a better way to configure is to choose an order of priority and delegate to the next config if the option is not set. Here, I think session should override table. If session is set, return whatever it is. Otherwise, use the table property.", "url": "https://github.com/apache/iceberg/pull/1778#discussion_r525628233", "createdAt": "2020-11-18T01:06:51Z", "author": {"login": "rdblue"}, "path": "spark2/src/main/java/org/apache/iceberg/spark/source/Reader.java", "diffHunk": "@@ -156,10 +156,13 @@\n     this.io = io;\n     this.encryptionManager = encryptionManager;\n     this.caseSensitive = caseSensitive;\n-\n-    this.batchReadsEnabled = options.get(\"vectorization-enabled\").map(Boolean::parseBoolean).orElseGet(() ->\n-        PropertyUtil.propertyAsBoolean(table.properties(),\n-            TableProperties.PARQUET_VECTORIZATION_ENABLED, TableProperties.PARQUET_VECTORIZATION_ENABLED_DEFAULT));\n+    boolean batchReadsSparkSessionConf = SparkSession.active().sparkContext().getConf()\n+            .getBoolean(\"read.parquet.vectorization.enabled\", true);\n+    boolean batchReadsEnabledTableProp = options.get(\"vectorization-enabled\").map(Boolean::parseBoolean).orElseGet(() ->\n+            PropertyUtil.propertyAsBoolean(table.properties(),\n+                    TableProperties.PARQUET_VECTORIZATION_ENABLED,\n+                    TableProperties.PARQUET_VECTORIZATION_ENABLED_DEFAULT));\n+    this.batchReadsEnabled = !batchReadsSparkSessionConf ? false : batchReadsEnabledTableProp;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f121d81611f678203d66b6a33e2402ec3021845e"}, "originalPosition": 14}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwMTI0OTg0OnYy", "diffSide": "RIGHT", "path": "spark2/src/main/java/org/apache/iceberg/spark/source/Reader.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMToxMToxMlrOH2IooA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMToxMToxMlrOH2IooA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUyNjYyNA==", "bodyText": "Continuation indents are 4 spaces or 2 indents from the previous. Could you update this?", "url": "https://github.com/apache/iceberg/pull/1778#discussion_r526526624", "createdAt": "2020-11-19T01:11:12Z", "author": {"login": "rdblue"}, "path": "spark2/src/main/java/org/apache/iceberg/spark/source/Reader.java", "diffHunk": "@@ -156,10 +157,15 @@\n     this.io = io;\n     this.encryptionManager = encryptionManager;\n     this.caseSensitive = caseSensitive;\n-\n-    this.batchReadsEnabled = options.get(\"vectorization-enabled\").map(Boolean::parseBoolean).orElseGet(() ->\n-        PropertyUtil.propertyAsBoolean(table.properties(),\n-            TableProperties.PARQUET_VECTORIZATION_ENABLED, TableProperties.PARQUET_VECTORIZATION_ENABLED_DEFAULT));\n+    Option<String> option = SparkSession.active().sparkContext().getConf()\n+            .getOption(\"spark.iceberg.vectorization.enabled\");\n+    if (option.isDefined()) {\n+      this.batchReadsEnabled = Boolean.valueOf(option.get());\n+    } else {\n+      this.batchReadsEnabled = options.get(\"vectorization-enabled\").map(Boolean::parseBoolean).orElseGet(() ->\n+              PropertyUtil.propertyAsBoolean(table.properties(), TableProperties.PARQUET_VECTORIZATION_ENABLED,\n+                      TableProperties.PARQUET_VECTORIZATION_ENABLED_DEFAULT));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cb21c1c5c70e06df0a89f476790e69ab200be7ba"}, "originalPosition": 23}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMwMTI1MjQzOnYy", "diffSide": "RIGHT", "path": "spark2/src/main/java/org/apache/iceberg/spark/source/Reader.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMToxMjoxNFrOH2IqHg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0xOVQwMToxMjoxNFrOH2IqHg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUyNjUyNzAwNg==", "bodyText": "You should be able to use SparkSession.active().conf().get(\"key\", null) to get the value or null. No need to use the Spark context's conf.", "url": "https://github.com/apache/iceberg/pull/1778#discussion_r526527006", "createdAt": "2020-11-19T01:12:14Z", "author": {"login": "rdblue"}, "path": "spark2/src/main/java/org/apache/iceberg/spark/source/Reader.java", "diffHunk": "@@ -156,10 +157,15 @@\n     this.io = io;\n     this.encryptionManager = encryptionManager;\n     this.caseSensitive = caseSensitive;\n-\n-    this.batchReadsEnabled = options.get(\"vectorization-enabled\").map(Boolean::parseBoolean).orElseGet(() ->\n-        PropertyUtil.propertyAsBoolean(table.properties(),\n-            TableProperties.PARQUET_VECTORIZATION_ENABLED, TableProperties.PARQUET_VECTORIZATION_ENABLED_DEFAULT));\n+    Option<String> option = SparkSession.active().sparkContext().getConf()\n+            .getOption(\"spark.iceberg.vectorization.enabled\");", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "cb21c1c5c70e06df0a89f476790e69ab200be7ba"}, "originalPosition": 17}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3463, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}