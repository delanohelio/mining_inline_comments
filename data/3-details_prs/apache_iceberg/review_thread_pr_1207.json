{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDQ5MjQwOTIz", "number": 1207, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQyMDozMzo0NlrOEO2RQQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQyMjoyOTo1OVrOEO5Jsw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0MDA0NjczOnYy", "diffSide": "RIGHT", "path": "orc/src/main/java/org/apache/iceberg/orc/OrcRowReader.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQyMDozMzo0NlrOGyO1kQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQyMjoyODozMVrOGyTfzg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTMyNTA3Mw==", "bodyText": "This seems to introduce a lot of code churn, when most implementations don't use batchOffsetInFile. What about a less intrusive way of passing this by using a context method that is called once for each batch?\nParquet has something similar, where each row group causes new context to be passed to the readers: https://github.com/apache/iceberg/blob/master/parquet/src/main/java/org/apache/iceberg/parquet/ParquetValueReader.java#L32\nThis could expose a method like setBatchContext(long batchOffsetInFile) with a no-op default. Then only a few implementations would need to change.", "url": "https://github.com/apache/iceberg/pull/1207#discussion_r455325073", "createdAt": "2020-07-15T20:33:46Z", "author": {"login": "rdblue"}, "path": "orc/src/main/java/org/apache/iceberg/orc/OrcRowReader.java", "diffHunk": "@@ -29,6 +29,6 @@\n   /**\n    * Reads a row.\n    */\n-  T read(VectorizedRowBatch batch, int row);\n+  T read(VectorizedRowBatch batch, long batchOffsetInFile, int rowOffsetInBatch);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1bc55be9857af48730a6c740a9cbd27093b4b06d"}, "originalPosition": 5}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQwMTQyMg==", "bodyText": "Thanks for the suggestion! This reduces the code changes significantly.", "url": "https://github.com/apache/iceberg/pull/1207#discussion_r455401422", "createdAt": "2020-07-15T22:28:31Z", "author": {"login": "shardulm94"}, "path": "orc/src/main/java/org/apache/iceberg/orc/OrcRowReader.java", "diffHunk": "@@ -29,6 +29,6 @@\n   /**\n    * Reads a row.\n    */\n-  T read(VectorizedRowBatch batch, int row);\n+  T read(VectorizedRowBatch batch, long batchOffsetInFile, int rowOffsetInBatch);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTMyNTA3Mw=="}, "originalCommit": {"oid": "1bc55be9857af48730a6c740a9cbd27093b4b06d"}, "originalPosition": 5}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjg0MDUxODkxOnYy", "diffSide": "RIGHT", "path": "spark/src/main/java/org/apache/iceberg/spark/data/vectorized/VectorizedSparkOrcReaders.java", "isResolved": false, "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQyMjoyOTo1OVrOGyTiEg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNy0xNVQyMjoyOTo1OVrOGyTiEg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ1NTQwMjAwMg==", "bodyText": "I am checking the current field with the ROW_POSITION field defined in MetadataColumns, we can probably check just the field ID though.", "url": "https://github.com/apache/iceberg/pull/1207#discussion_r455402002", "createdAt": "2020-07-15T22:29:59Z", "author": {"login": "shardulm94"}, "path": "spark/src/main/java/org/apache/iceberg/spark/data/vectorized/VectorizedSparkOrcReaders.java", "diffHunk": "@@ -378,16 +395,20 @@ private StructConverter(Types.StructType structType, List<Converter> fieldConver\n     }\n \n     @Override\n-    public ColumnVector convert(org.apache.orc.storage.ql.exec.vector.ColumnVector vector, int batchSize) {\n+    public ColumnVector convert(org.apache.orc.storage.ql.exec.vector.ColumnVector vector, int batchSize,\n+                                long batchOffsetInFile) {\n       StructColumnVector structVector = (StructColumnVector) vector;\n       List<Types.NestedField> fields = structType.fields();\n       List<ColumnVector> fieldVectors = Lists.newArrayListWithExpectedSize(fields.size());\n       for (int pos = 0, vectorIndex = 0; pos < fields.size(); pos += 1) {\n         Types.NestedField field = fields.get(pos);\n         if (idToConstant.containsKey(field.fieldId())) {\n           fieldVectors.add(new ConstantColumnVector(field.type(), batchSize, idToConstant.get(field.fieldId())));\n+        } else if (field.equals(MetadataColumns.ROW_POSITION)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1c5de07152fc60658b6de1a0b926ce10acdf121d"}, "originalPosition": 125}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3769, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}