{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTM1Njg1NzE4", "number": 1900, "reviewThreads": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQyMzowNDo0MFrOFDujaQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQyMzowNDo0MFrOFDujaQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM5NDUyNzc3OnYy", "diffSide": "RIGHT", "path": "aws/src/integration/java/org/apache/iceberg/aws/s3/S3MultipartUploadTest.java", "isResolved": false, "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMFQyMzowNDo0MFrOIDhgFg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xMVQxNzowODozMFrOIEB5uA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDU2NTUyNg==", "bodyText": "Maybe I'm missing something, but I don't think these are actually testing the multipart upload.  If we're writing with the OutputStream::write interface, that would only be writing a single byte, so 100 bytes in this case.  That wouldn't be enough to trigger the multipart behavior.\nI think that's the case for most of the tests I see here.  You might want to look at the S3Outputstream test because you can actually validate the operations performed like this: https://github.com/apache/iceberg/blob/master/aws/src/test/java/org/apache/iceberg/aws/s3/S3OutputStreamTest.java#L109", "url": "https://github.com/apache/iceberg/pull/1900#discussion_r540565526", "createdAt": "2020-12-10T23:04:40Z", "author": {"login": "danielcweeks"}, "path": "aws/src/integration/java/org/apache/iceberg/aws/s3/S3MultipartUploadTest.java", "diffHunk": "@@ -0,0 +1,192 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.aws.s3;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.Random;\n+import java.util.UUID;\n+import java.util.stream.IntStream;\n+import org.apache.iceberg.aws.AwsClientUtil;\n+import org.apache.iceberg.aws.AwsIntegTestUtil;\n+import org.apache.iceberg.aws.AwsProperties;\n+import org.apache.iceberg.io.InputFile;\n+import org.apache.iceberg.io.PositionOutputStream;\n+import org.apache.iceberg.io.SeekableInputStream;\n+import org.junit.AfterClass;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import software.amazon.awssdk.services.s3.S3Client;\n+\n+/**\n+ * Long-running tests to ensure multipart upload logic is resilient\n+ */\n+public class S3MultipartUploadTest {\n+\n+  private final Random random = new Random(1);\n+  private static S3Client s3;\n+  private static String bucketName;\n+  private static String prefix;\n+  private String objectUri;\n+\n+  @BeforeClass\n+  public static void beforeClass() {\n+    s3 = AwsClientUtil.defaultS3Client();\n+    bucketName = AwsIntegTestUtil.testBucketName();\n+    prefix = UUID.randomUUID().toString();\n+  }\n+\n+  @AfterClass\n+  public static void afterClass() {\n+    AwsIntegTestUtil.cleanS3Bucket(s3, bucketName, prefix);\n+  }\n+\n+  @Before\n+  public void before() {\n+    String objectKey = String.format(\"%s/%s\", prefix, UUID.randomUUID().toString());\n+    objectUri = String.format(\"s3://%s/%s\", bucketName, objectKey);\n+  }\n+\n+  @Test\n+  public void testManyParts_writeWithInt() throws IOException {\n+    AwsProperties properties = new AwsProperties();\n+    properties.setS3FileIoMultiPartSize(AwsProperties.S3FILEIO_MULTIPART_SIZE_MIN);\n+    S3FileIO io = new S3FileIO(() -> s3, properties);\n+    PositionOutputStream outputStream = io.newOutputFile(objectUri).create();\n+    for (int i = 0; i < 100; i++) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "02cfb2c174c1a11f84944d44df5954421f9308be"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDU4MjM5OQ==", "bodyText": "that would only be writing a single byte, so 100 bytes in this case\n\nThere is an internal loop for (int j = 0; j < AwsProperties.S3FILEIO_MULTIPART_SIZE_MIN; j++).\n\nYou might want to look at the S3Outputstream test because you can actually validate the operations performed like this\n\nthe tests here are trying to verify against actual result in s3 instead of verifying the number of calls, because I know those are verified in the tests you referenced. But I think I am being very not DRY here, let me refactor the tests a little bit", "url": "https://github.com/apache/iceberg/pull/1900#discussion_r540582399", "createdAt": "2020-12-10T23:41:59Z", "author": {"login": "jackye1995"}, "path": "aws/src/integration/java/org/apache/iceberg/aws/s3/S3MultipartUploadTest.java", "diffHunk": "@@ -0,0 +1,192 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.aws.s3;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.Random;\n+import java.util.UUID;\n+import java.util.stream.IntStream;\n+import org.apache.iceberg.aws.AwsClientUtil;\n+import org.apache.iceberg.aws.AwsIntegTestUtil;\n+import org.apache.iceberg.aws.AwsProperties;\n+import org.apache.iceberg.io.InputFile;\n+import org.apache.iceberg.io.PositionOutputStream;\n+import org.apache.iceberg.io.SeekableInputStream;\n+import org.junit.AfterClass;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import software.amazon.awssdk.services.s3.S3Client;\n+\n+/**\n+ * Long-running tests to ensure multipart upload logic is resilient\n+ */\n+public class S3MultipartUploadTest {\n+\n+  private final Random random = new Random(1);\n+  private static S3Client s3;\n+  private static String bucketName;\n+  private static String prefix;\n+  private String objectUri;\n+\n+  @BeforeClass\n+  public static void beforeClass() {\n+    s3 = AwsClientUtil.defaultS3Client();\n+    bucketName = AwsIntegTestUtil.testBucketName();\n+    prefix = UUID.randomUUID().toString();\n+  }\n+\n+  @AfterClass\n+  public static void afterClass() {\n+    AwsIntegTestUtil.cleanS3Bucket(s3, bucketName, prefix);\n+  }\n+\n+  @Before\n+  public void before() {\n+    String objectKey = String.format(\"%s/%s\", prefix, UUID.randomUUID().toString());\n+    objectUri = String.format(\"s3://%s/%s\", bucketName, objectKey);\n+  }\n+\n+  @Test\n+  public void testManyParts_writeWithInt() throws IOException {\n+    AwsProperties properties = new AwsProperties();\n+    properties.setS3FileIoMultiPartSize(AwsProperties.S3FILEIO_MULTIPART_SIZE_MIN);\n+    S3FileIO io = new S3FileIO(() -> s3, properties);\n+    PositionOutputStream outputStream = io.newOutputFile(objectUri).create();\n+    for (int i = 0; i < 100; i++) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDU2NTUyNg=="}, "originalCommit": {"oid": "02cfb2c174c1a11f84944d44df5954421f9308be"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDU4ODYwNA==", "bodyText": "No, I just mixed up this test and the next one and missed the inner loop here.  However, you might be able to combine some of the upload and content validation into a single test, but it looks like you already have some thoughts on it, so I'll wait.\nI guess there's two minor questions I have:\n\nIs it reasonable to be creating large files in S3 as part of the integration test (I'm not clear on if we run these as part of our actual build or it's left up to users to run in their own accounts).\nAre there cases where we think the s3mock wouldn't catch something that these tests would?", "url": "https://github.com/apache/iceberg/pull/1900#discussion_r540588604", "createdAt": "2020-12-10T23:57:08Z", "author": {"login": "danielcweeks"}, "path": "aws/src/integration/java/org/apache/iceberg/aws/s3/S3MultipartUploadTest.java", "diffHunk": "@@ -0,0 +1,192 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.aws.s3;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.Random;\n+import java.util.UUID;\n+import java.util.stream.IntStream;\n+import org.apache.iceberg.aws.AwsClientUtil;\n+import org.apache.iceberg.aws.AwsIntegTestUtil;\n+import org.apache.iceberg.aws.AwsProperties;\n+import org.apache.iceberg.io.InputFile;\n+import org.apache.iceberg.io.PositionOutputStream;\n+import org.apache.iceberg.io.SeekableInputStream;\n+import org.junit.AfterClass;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import software.amazon.awssdk.services.s3.S3Client;\n+\n+/**\n+ * Long-running tests to ensure multipart upload logic is resilient\n+ */\n+public class S3MultipartUploadTest {\n+\n+  private final Random random = new Random(1);\n+  private static S3Client s3;\n+  private static String bucketName;\n+  private static String prefix;\n+  private String objectUri;\n+\n+  @BeforeClass\n+  public static void beforeClass() {\n+    s3 = AwsClientUtil.defaultS3Client();\n+    bucketName = AwsIntegTestUtil.testBucketName();\n+    prefix = UUID.randomUUID().toString();\n+  }\n+\n+  @AfterClass\n+  public static void afterClass() {\n+    AwsIntegTestUtil.cleanS3Bucket(s3, bucketName, prefix);\n+  }\n+\n+  @Before\n+  public void before() {\n+    String objectKey = String.format(\"%s/%s\", prefix, UUID.randomUUID().toString());\n+    objectUri = String.format(\"s3://%s/%s\", bucketName, objectKey);\n+  }\n+\n+  @Test\n+  public void testManyParts_writeWithInt() throws IOException {\n+    AwsProperties properties = new AwsProperties();\n+    properties.setS3FileIoMultiPartSize(AwsProperties.S3FILEIO_MULTIPART_SIZE_MIN);\n+    S3FileIO io = new S3FileIO(() -> s3, properties);\n+    PositionOutputStream outputStream = io.newOutputFile(objectUri).create();\n+    for (int i = 0; i < 100; i++) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDU2NTUyNg=="}, "originalCommit": {"oid": "02cfb2c174c1a11f84944d44df5954421f9308be"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDU5OTcyMw==", "bodyText": "Is it reasonable to be creating large files in S3 as part of the integration test (I'm not clear on if we run these as part of our actual build or it's left up to users to run in their own accounts).\n\n\nI don't expect this to be run for every actual build, and the tests take quite a while to complete, so it's mostly for users to run in their own account. With that being said, I am in progress of potentially getting an account to run these tests for all PRs committing to the aws module with cost covered.\n\n\nAre there cases where we think the s3mock wouldn't catch something that these tests would?\n\n\nIt is hard to say how different is the actual S3 compared to S3mock, so this serves as a line of defense to catch potentially different behaviors and potential errors during non-local network calls.", "url": "https://github.com/apache/iceberg/pull/1900#discussion_r540599723", "createdAt": "2020-12-11T00:25:30Z", "author": {"login": "jackye1995"}, "path": "aws/src/integration/java/org/apache/iceberg/aws/s3/S3MultipartUploadTest.java", "diffHunk": "@@ -0,0 +1,192 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.aws.s3;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.Random;\n+import java.util.UUID;\n+import java.util.stream.IntStream;\n+import org.apache.iceberg.aws.AwsClientUtil;\n+import org.apache.iceberg.aws.AwsIntegTestUtil;\n+import org.apache.iceberg.aws.AwsProperties;\n+import org.apache.iceberg.io.InputFile;\n+import org.apache.iceberg.io.PositionOutputStream;\n+import org.apache.iceberg.io.SeekableInputStream;\n+import org.junit.AfterClass;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import software.amazon.awssdk.services.s3.S3Client;\n+\n+/**\n+ * Long-running tests to ensure multipart upload logic is resilient\n+ */\n+public class S3MultipartUploadTest {\n+\n+  private final Random random = new Random(1);\n+  private static S3Client s3;\n+  private static String bucketName;\n+  private static String prefix;\n+  private String objectUri;\n+\n+  @BeforeClass\n+  public static void beforeClass() {\n+    s3 = AwsClientUtil.defaultS3Client();\n+    bucketName = AwsIntegTestUtil.testBucketName();\n+    prefix = UUID.randomUUID().toString();\n+  }\n+\n+  @AfterClass\n+  public static void afterClass() {\n+    AwsIntegTestUtil.cleanS3Bucket(s3, bucketName, prefix);\n+  }\n+\n+  @Before\n+  public void before() {\n+    String objectKey = String.format(\"%s/%s\", prefix, UUID.randomUUID().toString());\n+    objectUri = String.format(\"s3://%s/%s\", bucketName, objectKey);\n+  }\n+\n+  @Test\n+  public void testManyParts_writeWithInt() throws IOException {\n+    AwsProperties properties = new AwsProperties();\n+    properties.setS3FileIoMultiPartSize(AwsProperties.S3FILEIO_MULTIPART_SIZE_MIN);\n+    S3FileIO io = new S3FileIO(() -> s3, properties);\n+    PositionOutputStream outputStream = io.newOutputFile(objectUri).create();\n+    for (int i = 0; i < 100; i++) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDU2NTUyNg=="}, "originalCommit": {"oid": "02cfb2c174c1a11f84944d44df5954421f9308be"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDcwNDE2OQ==", "bodyText": "@danielcweeks refactored tests, please let me know if it looks good to you.", "url": "https://github.com/apache/iceberg/pull/1900#discussion_r540704169", "createdAt": "2020-12-11T05:40:57Z", "author": {"login": "jackye1995"}, "path": "aws/src/integration/java/org/apache/iceberg/aws/s3/S3MultipartUploadTest.java", "diffHunk": "@@ -0,0 +1,192 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.aws.s3;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.Random;\n+import java.util.UUID;\n+import java.util.stream.IntStream;\n+import org.apache.iceberg.aws.AwsClientUtil;\n+import org.apache.iceberg.aws.AwsIntegTestUtil;\n+import org.apache.iceberg.aws.AwsProperties;\n+import org.apache.iceberg.io.InputFile;\n+import org.apache.iceberg.io.PositionOutputStream;\n+import org.apache.iceberg.io.SeekableInputStream;\n+import org.junit.AfterClass;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import software.amazon.awssdk.services.s3.S3Client;\n+\n+/**\n+ * Long-running tests to ensure multipart upload logic is resilient\n+ */\n+public class S3MultipartUploadTest {\n+\n+  private final Random random = new Random(1);\n+  private static S3Client s3;\n+  private static String bucketName;\n+  private static String prefix;\n+  private String objectUri;\n+\n+  @BeforeClass\n+  public static void beforeClass() {\n+    s3 = AwsClientUtil.defaultS3Client();\n+    bucketName = AwsIntegTestUtil.testBucketName();\n+    prefix = UUID.randomUUID().toString();\n+  }\n+\n+  @AfterClass\n+  public static void afterClass() {\n+    AwsIntegTestUtil.cleanS3Bucket(s3, bucketName, prefix);\n+  }\n+\n+  @Before\n+  public void before() {\n+    String objectKey = String.format(\"%s/%s\", prefix, UUID.randomUUID().toString());\n+    objectUri = String.format(\"s3://%s/%s\", bucketName, objectKey);\n+  }\n+\n+  @Test\n+  public void testManyParts_writeWithInt() throws IOException {\n+    AwsProperties properties = new AwsProperties();\n+    properties.setS3FileIoMultiPartSize(AwsProperties.S3FILEIO_MULTIPART_SIZE_MIN);\n+    S3FileIO io = new S3FileIO(() -> s3, properties);\n+    PositionOutputStream outputStream = io.newOutputFile(objectUri).create();\n+    for (int i = 0; i < 100; i++) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDU2NTUyNg=="}, "originalCommit": {"oid": "02cfb2c174c1a11f84944d44df5954421f9308be"}, "originalPosition": 75}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MTA5NjM3Ng==", "bodyText": "Yeah, looks good.  It seems for #2 there are a number of things we won't be able to test against s3mock (like sts) so it makes sense to add these integration tests once we have an account.\nThanks!", "url": "https://github.com/apache/iceberg/pull/1900#discussion_r541096376", "createdAt": "2020-12-11T17:08:30Z", "author": {"login": "danielcweeks"}, "path": "aws/src/integration/java/org/apache/iceberg/aws/s3/S3MultipartUploadTest.java", "diffHunk": "@@ -0,0 +1,192 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.aws.s3;\n+\n+import java.io.IOException;\n+import java.io.InputStream;\n+import java.util.Random;\n+import java.util.UUID;\n+import java.util.stream.IntStream;\n+import org.apache.iceberg.aws.AwsClientUtil;\n+import org.apache.iceberg.aws.AwsIntegTestUtil;\n+import org.apache.iceberg.aws.AwsProperties;\n+import org.apache.iceberg.io.InputFile;\n+import org.apache.iceberg.io.PositionOutputStream;\n+import org.apache.iceberg.io.SeekableInputStream;\n+import org.junit.AfterClass;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.Test;\n+import software.amazon.awssdk.services.s3.S3Client;\n+\n+/**\n+ * Long-running tests to ensure multipart upload logic is resilient\n+ */\n+public class S3MultipartUploadTest {\n+\n+  private final Random random = new Random(1);\n+  private static S3Client s3;\n+  private static String bucketName;\n+  private static String prefix;\n+  private String objectUri;\n+\n+  @BeforeClass\n+  public static void beforeClass() {\n+    s3 = AwsClientUtil.defaultS3Client();\n+    bucketName = AwsIntegTestUtil.testBucketName();\n+    prefix = UUID.randomUUID().toString();\n+  }\n+\n+  @AfterClass\n+  public static void afterClass() {\n+    AwsIntegTestUtil.cleanS3Bucket(s3, bucketName, prefix);\n+  }\n+\n+  @Before\n+  public void before() {\n+    String objectKey = String.format(\"%s/%s\", prefix, UUID.randomUUID().toString());\n+    objectUri = String.format(\"s3://%s/%s\", bucketName, objectKey);\n+  }\n+\n+  @Test\n+  public void testManyParts_writeWithInt() throws IOException {\n+    AwsProperties properties = new AwsProperties();\n+    properties.setS3FileIoMultiPartSize(AwsProperties.S3FILEIO_MULTIPART_SIZE_MIN);\n+    S3FileIO io = new S3FileIO(() -> s3, properties);\n+    PositionOutputStream outputStream = io.newOutputFile(objectUri).create();\n+    for (int i = 0; i < 100; i++) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0MDU2NTUyNg=="}, "originalCommit": {"oid": "02cfb2c174c1a11f84944d44df5954421f9308be"}, "originalPosition": 75}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3311, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}