{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDMxMzI1MDgw", "number": 1105, "reviewThreads": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNTo1NTo0M1rOEEXANA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNVQxNToyNTozNlrOEFldBA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczMDA2NjQ0OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/org/apache/iceberg/FileMetadata.java", "isResolved": false, "comments": {"totalCount": 4, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNTo1NTo0M1rOGh7nCw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNVQyMzo0MDoyOVrOGkGR8A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODIzMjg0Mw==", "bodyText": "This is named FileMetadata because DeleteFiles is the public API for deleting data files.", "url": "https://github.com/apache/iceberg/pull/1105#discussion_r438232843", "createdAt": "2020-06-10T15:55:43Z", "author": {"login": "rdblue"}, "path": "core/src/main/java/org/apache/iceberg/FileMetadata.java", "diffHunk": "@@ -0,0 +1,217 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg;\n+\n+import java.nio.ByteBuffer;\n+import java.util.Locale;\n+import java.util.Map;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.iceberg.encryption.EncryptedOutputFile;\n+import org.apache.iceberg.encryption.EncryptionKeyMetadata;\n+import org.apache.iceberg.hadoop.HadoopInputFile;\n+import org.apache.iceberg.io.InputFile;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.util.ByteBuffers;\n+\n+class FileMetadata {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eb25080181da91d195d0e9fd401044ce75382c8f"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDIzNzA0NA==", "bodyText": "Ideally, we would name it DeleteFiles to be consistent with DataFiles but that's not possible. Do we want to move DataFiles into FileMetadata and deprecate it (not now, in the future)?", "url": "https://github.com/apache/iceberg/pull/1105#discussion_r440237044", "createdAt": "2020-06-15T14:56:18Z", "author": {"login": "aokolnychyi"}, "path": "core/src/main/java/org/apache/iceberg/FileMetadata.java", "diffHunk": "@@ -0,0 +1,217 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg;\n+\n+import java.nio.ByteBuffer;\n+import java.util.Locale;\n+import java.util.Map;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.iceberg.encryption.EncryptedOutputFile;\n+import org.apache.iceberg.encryption.EncryptionKeyMetadata;\n+import org.apache.iceberg.hadoop.HadoopInputFile;\n+import org.apache.iceberg.io.InputFile;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.util.ByteBuffers;\n+\n+class FileMetadata {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODIzMjg0Mw=="}, "originalCommit": {"oid": "eb25080181da91d195d0e9fd401044ce75382c8f"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDIzODY3Mw==", "bodyText": "Then we won't have to use methods from DataFiles here.", "url": "https://github.com/apache/iceberg/pull/1105#discussion_r440238673", "createdAt": "2020-06-15T14:58:28Z", "author": {"login": "aokolnychyi"}, "path": "core/src/main/java/org/apache/iceberg/FileMetadata.java", "diffHunk": "@@ -0,0 +1,217 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg;\n+\n+import java.nio.ByteBuffer;\n+import java.util.Locale;\n+import java.util.Map;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.iceberg.encryption.EncryptedOutputFile;\n+import org.apache.iceberg.encryption.EncryptionKeyMetadata;\n+import org.apache.iceberg.hadoop.HadoopInputFile;\n+import org.apache.iceberg.io.InputFile;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.util.ByteBuffers;\n+\n+class FileMetadata {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODIzMjg0Mw=="}, "originalCommit": {"oid": "eb25080181da91d195d0e9fd401044ce75382c8f"}, "originalPosition": 33}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDUwNDgxNg==", "bodyText": "I don't want to move anything in DataFiles in this commit because it's large enough already. I'm also thinking that this API may evolve further, so it's probably better to hold off on any compatibility breaking changes for now, until we know more about what this is going to look like.", "url": "https://github.com/apache/iceberg/pull/1105#discussion_r440504816", "createdAt": "2020-06-15T23:40:29Z", "author": {"login": "rdblue"}, "path": "core/src/main/java/org/apache/iceberg/FileMetadata.java", "diffHunk": "@@ -0,0 +1,217 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg;\n+\n+import java.nio.ByteBuffer;\n+import java.util.Locale;\n+import java.util.Map;\n+import org.apache.hadoop.fs.FileStatus;\n+import org.apache.iceberg.encryption.EncryptedOutputFile;\n+import org.apache.iceberg.encryption.EncryptionKeyMetadata;\n+import org.apache.iceberg.hadoop.HadoopInputFile;\n+import org.apache.iceberg.io.InputFile;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.util.ByteBuffers;\n+\n+class FileMetadata {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODIzMjg0Mw=="}, "originalCommit": {"oid": "eb25080181da91d195d0e9fd401044ce75382c8f"}, "originalPosition": 33}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjczMDA5NzQ5OnYy", "diffSide": "RIGHT", "path": "core/src/test/java/org/apache/iceberg/TestRowDelta.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xMFQxNjowMzowNFrOGh77MA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNVQyMzo0MDo1NVrOGkGSjQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODIzODAwMA==", "bodyText": "Should we detect whether delete and data files are added and change this to append or delete if there are only delete or only data files?", "url": "https://github.com/apache/iceberg/pull/1105#discussion_r438238000", "createdAt": "2020-06-10T16:03:04Z", "author": {"login": "rdblue"}, "path": "core/src/test/java/org/apache/iceberg/TestRowDelta.java", "diffHunk": "@@ -0,0 +1,306 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg;\n+\n+import org.apache.iceberg.ManifestEntry.Status;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestRowDelta extends V2TableTestBase {\n+  @Test\n+  public void testAddDeleteFile() {\n+    table.newRowDelta()\n+        .addRows(FILE_A)\n+        .addDeletes(FILE_A_DELETES)\n+        .addDeletes(FILE_B_DELETES)\n+        .commit();\n+\n+    Snapshot snap = table.currentSnapshot();\n+    Assert.assertEquals(\"Commit should produce sequence number 1\", 1, snap.sequenceNumber());\n+    Assert.assertEquals(\"Last sequence number should be 1\", 1, table.ops().current().lastSequenceNumber());\n+    Assert.assertEquals(\"Delta commit should use operation 'overwrite'\", DataOperations.OVERWRITE, snap.operation());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "eb25080181da91d195d0e9fd401044ce75382c8f"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDI2MzE3Mg==", "bodyText": "Seems like a good idea to me.", "url": "https://github.com/apache/iceberg/pull/1105#discussion_r440263172", "createdAt": "2020-06-15T15:32:56Z", "author": {"login": "aokolnychyi"}, "path": "core/src/test/java/org/apache/iceberg/TestRowDelta.java", "diffHunk": "@@ -0,0 +1,306 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg;\n+\n+import org.apache.iceberg.ManifestEntry.Status;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestRowDelta extends V2TableTestBase {\n+  @Test\n+  public void testAddDeleteFile() {\n+    table.newRowDelta()\n+        .addRows(FILE_A)\n+        .addDeletes(FILE_A_DELETES)\n+        .addDeletes(FILE_B_DELETES)\n+        .commit();\n+\n+    Snapshot snap = table.currentSnapshot();\n+    Assert.assertEquals(\"Commit should produce sequence number 1\", 1, snap.sequenceNumber());\n+    Assert.assertEquals(\"Last sequence number should be 1\", 1, table.ops().current().lastSequenceNumber());\n+    Assert.assertEquals(\"Delta commit should use operation 'overwrite'\", DataOperations.OVERWRITE, snap.operation());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODIzODAwMA=="}, "originalCommit": {"oid": "eb25080181da91d195d0e9fd401044ce75382c8f"}, "originalPosition": 39}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDUwNDk3Mw==", "bodyText": "Will do, possibly in a follow-up.", "url": "https://github.com/apache/iceberg/pull/1105#discussion_r440504973", "createdAt": "2020-06-15T23:40:55Z", "author": {"login": "rdblue"}, "path": "core/src/test/java/org/apache/iceberg/TestRowDelta.java", "diffHunk": "@@ -0,0 +1,306 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg;\n+\n+import org.apache.iceberg.ManifestEntry.Status;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestRowDelta extends V2TableTestBase {\n+  @Test\n+  public void testAddDeleteFile() {\n+    table.newRowDelta()\n+        .addRows(FILE_A)\n+        .addDeletes(FILE_A_DELETES)\n+        .addDeletes(FILE_B_DELETES)\n+        .commit();\n+\n+    Snapshot snap = table.currentSnapshot();\n+    Assert.assertEquals(\"Commit should produce sequence number 1\", 1, snap.sequenceNumber());\n+    Assert.assertEquals(\"Last sequence number should be 1\", 1, table.ops().current().lastSequenceNumber());\n+    Assert.assertEquals(\"Delta commit should use operation 'overwrite'\", DataOperations.OVERWRITE, snap.operation());", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQzODIzODAwMA=="}, "originalCommit": {"oid": "eb25080181da91d195d0e9fd401044ce75382c8f"}, "originalPosition": 39}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc0MjkwMDg2OnYy", "diffSide": "RIGHT", "path": "core/src/main/java/org/apache/iceberg/MergingSnapshotProducer.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNVQxNToyMToyNVrOGj3CRg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNVQyMzo0MzoxNFrOGkGVPQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDI1NTA0Ng==", "bodyText": "Does it mean I can use the DeleteFiles API to remove delete files now? Currently, that API accepts only data files and locations. Now, we can give a path and this will remove a delete file too. Removing a delete file means adding data back? If that's what we want, will we also allow passing DeleteFile for performance?", "url": "https://github.com/apache/iceberg/pull/1105#discussion_r440255046", "createdAt": "2020-06-15T15:21:25Z", "author": {"login": "aokolnychyi"}, "path": "core/src/main/java/org/apache/iceberg/MergingSnapshotProducer.java", "diffHunk": "@@ -166,41 +125,66 @@ protected void failMissingDeletePaths() {\n   protected void deleteByRowFilter(Expression expr) {\n     this.deleteExpression = expr;\n     filterManager.deleteByRowFilter(expr);\n+    // if a delete file matches the row filter, then it can be deleted because the rows will also be deleted\n+    deleteFilterManager.deleteByRowFilter(expr);\n   }\n \n   /**\n    * Add a partition tuple to drop from the table during the delete phase.\n    */\n   protected void dropPartition(StructLike partition) {\n+    // dropping the data in a partition also drops all deletes in the partition\n     filterManager.dropPartition(partition);\n+    deleteFilterManager.dropPartition(partition);\n   }\n \n   /**\n-   * Add a specific path to be deleted in the new snapshot.\n+   * Add a specific data file to be deleted in the new snapshot.\n    */\n   protected void delete(DataFile file) {\n     filterManager.delete(file);\n   }\n \n+  /**\n+   * Add a specific delete file to be deleted in the new snapshot.\n+   */\n+  protected void delete(DeleteFile file) {\n+    deleteFilterManager.delete(file);\n+  }\n+\n   /**\n    * Add a specific path to be deleted in the new snapshot.\n    */\n   protected void delete(CharSequence path) {\n+    // because this is a location, it may be a data file or a delete file and must be added to both filter managers\n     filterManager.delete(path);\n+    deleteFilterManager.delete(path);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "effe279998c34e62f54dbbb5d1fb8e8df1bda373"}, "originalPosition": 148}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDUwNTY2MQ==", "bodyText": "Good point. I think we should remove this and make it so the older path-based delete only deletes data files. I haven't exposed delete(DeleteFile) through any of the public APIs on purpose for the reason you cite: it would un-delete data.\nI think it is probably better to automatically delete in most circumstances, like removing all deletes where the data files must also be deleted or removing delete files if there are no data files that could match by sequence number.", "url": "https://github.com/apache/iceberg/pull/1105#discussion_r440505661", "createdAt": "2020-06-15T23:43:14Z", "author": {"login": "rdblue"}, "path": "core/src/main/java/org/apache/iceberg/MergingSnapshotProducer.java", "diffHunk": "@@ -166,41 +125,66 @@ protected void failMissingDeletePaths() {\n   protected void deleteByRowFilter(Expression expr) {\n     this.deleteExpression = expr;\n     filterManager.deleteByRowFilter(expr);\n+    // if a delete file matches the row filter, then it can be deleted because the rows will also be deleted\n+    deleteFilterManager.deleteByRowFilter(expr);\n   }\n \n   /**\n    * Add a partition tuple to drop from the table during the delete phase.\n    */\n   protected void dropPartition(StructLike partition) {\n+    // dropping the data in a partition also drops all deletes in the partition\n     filterManager.dropPartition(partition);\n+    deleteFilterManager.dropPartition(partition);\n   }\n \n   /**\n-   * Add a specific path to be deleted in the new snapshot.\n+   * Add a specific data file to be deleted in the new snapshot.\n    */\n   protected void delete(DataFile file) {\n     filterManager.delete(file);\n   }\n \n+  /**\n+   * Add a specific delete file to be deleted in the new snapshot.\n+   */\n+  protected void delete(DeleteFile file) {\n+    deleteFilterManager.delete(file);\n+  }\n+\n   /**\n    * Add a specific path to be deleted in the new snapshot.\n    */\n   protected void delete(CharSequence path) {\n+    // because this is a location, it may be a data file or a delete file and must be added to both filter managers\n     filterManager.delete(path);\n+    deleteFilterManager.delete(path);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDI1NTA0Ng=="}, "originalCommit": {"oid": "effe279998c34e62f54dbbb5d1fb8e8df1bda373"}, "originalPosition": 148}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMjc0MjkxOTcyOnYy", "diffSide": "RIGHT", "path": "core/src/main/java/org/apache/iceberg/MergingSnapshotProducer.java", "isResolved": false, "comments": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNVQxNToyNTozNlrOGj3N5A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wNi0xNVQxNTozMDoxMlrOGj3a2Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDI1ODAyMA==", "bodyText": "Will it be useful to track the number of delete files separately? I find it extremely useful to look at snapshot summaries on large tables as it gives an overview of the current state. Knowing the number of delete files separately from the number of data files seems reasonable and can guide users to perform compactions.", "url": "https://github.com/apache/iceberg/pull/1105#discussion_r440258020", "createdAt": "2020-06-15T15:25:36Z", "author": {"login": "aokolnychyi"}, "path": "core/src/main/java/org/apache/iceberg/MergingSnapshotProducer.java", "diffHunk": "@@ -166,41 +125,66 @@ protected void failMissingDeletePaths() {\n   protected void deleteByRowFilter(Expression expr) {\n     this.deleteExpression = expr;\n     filterManager.deleteByRowFilter(expr);\n+    // if a delete file matches the row filter, then it can be deleted because the rows will also be deleted\n+    deleteFilterManager.deleteByRowFilter(expr);\n   }\n \n   /**\n    * Add a partition tuple to drop from the table during the delete phase.\n    */\n   protected void dropPartition(StructLike partition) {\n+    // dropping the data in a partition also drops all deletes in the partition\n     filterManager.dropPartition(partition);\n+    deleteFilterManager.dropPartition(partition);\n   }\n \n   /**\n-   * Add a specific path to be deleted in the new snapshot.\n+   * Add a specific data file to be deleted in the new snapshot.\n    */\n   protected void delete(DataFile file) {\n     filterManager.delete(file);\n   }\n \n+  /**\n+   * Add a specific delete file to be deleted in the new snapshot.\n+   */\n+  protected void delete(DeleteFile file) {\n+    deleteFilterManager.delete(file);\n+  }\n+\n   /**\n    * Add a specific path to be deleted in the new snapshot.\n    */\n   protected void delete(CharSequence path) {\n+    // because this is a location, it may be a data file or a delete file and must be added to both filter managers\n     filterManager.delete(path);\n+    deleteFilterManager.delete(path);\n   }\n \n   /**\n-   * Add a file to the new snapshot.\n+   * Add a data file to the new snapshot.\n    */\n   protected void add(DataFile file) {\n+    addedFilesSummary.addedFile(spec, file);\n     hasNewFiles = true;\n     newFiles.add(file);\n   }\n \n+  /**\n+   * Add a delete file to the new snapshot.\n+   */\n+  protected void add(DeleteFile file) {\n+    addedFilesSummary.addedFile(spec, file);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "effe279998c34e62f54dbbb5d1fb8e8df1bda373"}, "originalPosition": 165}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDI2MTMzNw==", "bodyText": "Oh, it is actually already taken care of below. Great!", "url": "https://github.com/apache/iceberg/pull/1105#discussion_r440261337", "createdAt": "2020-06-15T15:30:12Z", "author": {"login": "aokolnychyi"}, "path": "core/src/main/java/org/apache/iceberg/MergingSnapshotProducer.java", "diffHunk": "@@ -166,41 +125,66 @@ protected void failMissingDeletePaths() {\n   protected void deleteByRowFilter(Expression expr) {\n     this.deleteExpression = expr;\n     filterManager.deleteByRowFilter(expr);\n+    // if a delete file matches the row filter, then it can be deleted because the rows will also be deleted\n+    deleteFilterManager.deleteByRowFilter(expr);\n   }\n \n   /**\n    * Add a partition tuple to drop from the table during the delete phase.\n    */\n   protected void dropPartition(StructLike partition) {\n+    // dropping the data in a partition also drops all deletes in the partition\n     filterManager.dropPartition(partition);\n+    deleteFilterManager.dropPartition(partition);\n   }\n \n   /**\n-   * Add a specific path to be deleted in the new snapshot.\n+   * Add a specific data file to be deleted in the new snapshot.\n    */\n   protected void delete(DataFile file) {\n     filterManager.delete(file);\n   }\n \n+  /**\n+   * Add a specific delete file to be deleted in the new snapshot.\n+   */\n+  protected void delete(DeleteFile file) {\n+    deleteFilterManager.delete(file);\n+  }\n+\n   /**\n    * Add a specific path to be deleted in the new snapshot.\n    */\n   protected void delete(CharSequence path) {\n+    // because this is a location, it may be a data file or a delete file and must be added to both filter managers\n     filterManager.delete(path);\n+    deleteFilterManager.delete(path);\n   }\n \n   /**\n-   * Add a file to the new snapshot.\n+   * Add a data file to the new snapshot.\n    */\n   protected void add(DataFile file) {\n+    addedFilesSummary.addedFile(spec, file);\n     hasNewFiles = true;\n     newFiles.add(file);\n   }\n \n+  /**\n+   * Add a delete file to the new snapshot.\n+   */\n+  protected void add(DeleteFile file) {\n+    addedFilesSummary.addedFile(spec, file);", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ0MDI1ODAyMA=="}, "originalCommit": {"oid": "effe279998c34e62f54dbbb5d1fb8e8df1bda373"}, "originalPosition": 165}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3891, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}