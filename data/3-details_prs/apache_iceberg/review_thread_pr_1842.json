{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTI4NTczNzE1", "number": 1842, "reviewThreads": {"totalCount": 2, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yOFQxODoxMjoyMlrOE-TQMQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwMTozODowMlrOFBC8IA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzMzNzYyNjA5OnYy", "diffSide": "RIGHT", "path": "hive-metastore/src/main/java/org/apache/iceberg/hive/HiveTypeConverter.java", "isResolved": true, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMS0yOFQxODoxMjoyM1rOH7cMpA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wMVQxNzo0MTozOFrOH84adg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjA5MDAyMA==", "bodyText": "Don't we need to copy the comments/doc from FieldSchema as well?", "url": "https://github.com/apache/iceberg/pull/1842#discussion_r532090020", "createdAt": "2020-11-28T18:12:23Z", "author": {"login": "rdsr"}, "path": "hive-metastore/src/main/java/org/apache/iceberg/hive/HiveTypeConverter.java", "diffHunk": "@@ -30,7 +37,52 @@ private HiveTypeConverter() {\n \n   }\n \n-  public static String convert(Type type) {\n+  /**\n+   * Converts the Iceberg schema to a Hive schema.\n+   * @param schema The original Iceberg schema to convert\n+   * @return The Hive column list generated from the Iceberg schema\n+   */\n+  public static List<FieldSchema> hiveSchema(Schema schema) {\n+    return schema.columns().stream()\n+        .map(col -> new FieldSchema(col.name(), HiveTypeConverter.convert(col.type()), \"\"))\n+        .collect(Collectors.toList());\n+  }\n+\n+  /**\n+   * Converts the list of Hive FieldSchemas to an Iceberg schema.\n+   * <p>\n+   * The list should contain the columns and the partition columns as well.\n+   * @param fieldSchemas The list of the columns\n+   * @return An equivalent Iceberg Schema\n+   */\n+  public static Schema icebergSchema(List<FieldSchema> fieldSchemas) {\n+    List<String> names = new ArrayList<>(fieldSchemas.size());\n+    List<TypeInfo> typeInfos = new ArrayList<>(fieldSchemas.size());\n+\n+    for (FieldSchema col : fieldSchemas) {\n+      names.add(col.getName());\n+      typeInfos.add(TypeInfoUtils.getTypeInfoFromTypeString(col.getType()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "77b1d08ee80300457ceb3a911b2644e538cab156"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjYzMzI5MA==", "bodyText": "Thanks @rdsr for the review!\nIn my previous PRs I have been asked to stick to minimal changes so it is easier to review, so I did not even started to think about adding any change here \ud83d\ude04 (I have been in the reviewing end of the changes and I definitely understand the pain of reviewing the big changes)\nThat said, your suggestion definitely worth checking. I have some concerns that Hive might disregard the comments set in the schema. I have seen columns with \"from deserializer\" and I am a little bit concerned about how Hive will handle this.\nWould you think this should be another PR, or should we handle this here?\nThanks,\nPeter", "url": "https://github.com/apache/iceberg/pull/1842#discussion_r532633290", "createdAt": "2020-11-30T14:23:59Z", "author": {"login": "pvary"}, "path": "hive-metastore/src/main/java/org/apache/iceberg/hive/HiveTypeConverter.java", "diffHunk": "@@ -30,7 +37,52 @@ private HiveTypeConverter() {\n \n   }\n \n-  public static String convert(Type type) {\n+  /**\n+   * Converts the Iceberg schema to a Hive schema.\n+   * @param schema The original Iceberg schema to convert\n+   * @return The Hive column list generated from the Iceberg schema\n+   */\n+  public static List<FieldSchema> hiveSchema(Schema schema) {\n+    return schema.columns().stream()\n+        .map(col -> new FieldSchema(col.name(), HiveTypeConverter.convert(col.type()), \"\"))\n+        .collect(Collectors.toList());\n+  }\n+\n+  /**\n+   * Converts the list of Hive FieldSchemas to an Iceberg schema.\n+   * <p>\n+   * The list should contain the columns and the partition columns as well.\n+   * @param fieldSchemas The list of the columns\n+   * @return An equivalent Iceberg Schema\n+   */\n+  public static Schema icebergSchema(List<FieldSchema> fieldSchemas) {\n+    List<String> names = new ArrayList<>(fieldSchemas.size());\n+    List<TypeInfo> typeInfos = new ArrayList<>(fieldSchemas.size());\n+\n+    for (FieldSchema col : fieldSchemas) {\n+      names.add(col.getName());\n+      typeInfos.add(TypeInfoUtils.getTypeInfoFromTypeString(col.getType()));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjA5MDAyMA=="}, "originalCommit": {"oid": "77b1d08ee80300457ceb3a911b2644e538cab156"}, "originalPosition": 44}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMzYwMDg4Ng==", "bodyText": "Handling it separately is fine!", "url": "https://github.com/apache/iceberg/pull/1842#discussion_r533600886", "createdAt": "2020-12-01T17:41:38Z", "author": {"login": "rdsr"}, "path": "hive-metastore/src/main/java/org/apache/iceberg/hive/HiveTypeConverter.java", "diffHunk": "@@ -30,7 +37,52 @@ private HiveTypeConverter() {\n \n   }\n \n-  public static String convert(Type type) {\n+  /**\n+   * Converts the Iceberg schema to a Hive schema.\n+   * @param schema The original Iceberg schema to convert\n+   * @return The Hive column list generated from the Iceberg schema\n+   */\n+  public static List<FieldSchema> hiveSchema(Schema schema) {\n+    return schema.columns().stream()\n+        .map(col -> new FieldSchema(col.name(), HiveTypeConverter.convert(col.type()), \"\"))\n+        .collect(Collectors.toList());\n+  }\n+\n+  /**\n+   * Converts the list of Hive FieldSchemas to an Iceberg schema.\n+   * <p>\n+   * The list should contain the columns and the partition columns as well.\n+   * @param fieldSchemas The list of the columns\n+   * @return An equivalent Iceberg Schema\n+   */\n+  public static Schema icebergSchema(List<FieldSchema> fieldSchemas) {\n+    List<String> names = new ArrayList<>(fieldSchemas.size());\n+    List<TypeInfo> typeInfos = new ArrayList<>(fieldSchemas.size());\n+\n+    for (FieldSchema col : fieldSchemas) {\n+      names.add(col.getName());\n+      typeInfos.add(TypeInfoUtils.getTypeInfoFromTypeString(col.getType()));", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzMjA5MDAyMA=="}, "originalCommit": {"oid": "77b1d08ee80300457ceb3a911b2644e538cab156"}, "originalPosition": 44}]}}, {"id": "MDIzOlB1bGxSZXF1ZXN0UmV2aWV3VGhyZWFkMzM2NjQxMDU2OnYy", "diffSide": "RIGHT", "path": "hive-metastore/src/main/java/org/apache/iceberg/hive/HiveTypeConverter.java", "isResolved": false, "comments": {"totalCount": 3, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNVQwMTozODowM1rOH_n5Sw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wN1QyMTo1NToyOFrOIA8fGQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ3NTk3OQ==", "bodyText": "Most of the other modules use a different naming convention:\n\nAvroSchemaUtil.convert for Schema to Iceberg type and Iceberg type to Schema\nParquetSchemaUtil.convert\nSparkSchemaUtil.convert\nFlinkSchemaUtil.convert\n\nI think it would be nice to use the same convention here: use HiveSchemaUtil instead of HiveTypeConverter and then use overloads of convert. This would also make the API a bit less confusing because HiveTypeConverter and HiveSchemaConverter are very similar names and share a lot of the same tasks with different method args. Could these be combined into one?\nSome schema classes have a different type for the top-level schema (Iceberg and Parquet) and we usually convert between the two. Here, I think you could convert between Iceberg Schema and List<FieldSchema>, and between Iceberg Type and TypeInfo.", "url": "https://github.com/apache/iceberg/pull/1842#discussion_r536475979", "createdAt": "2020-12-05T01:38:03Z", "author": {"login": "rdblue"}, "path": "hive-metastore/src/main/java/org/apache/iceberg/hive/HiveTypeConverter.java", "diffHunk": "@@ -30,7 +37,52 @@ private HiveTypeConverter() {\n \n   }\n \n-  public static String convert(Type type) {\n+  /**\n+   * Converts the Iceberg schema to a Hive schema.\n+   * @param schema The original Iceberg schema to convert\n+   * @return The Hive column list generated from the Iceberg schema\n+   */\n+  public static List<FieldSchema> hiveSchema(Schema schema) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "77b1d08ee80300457ceb3a911b2644e538cab156"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzA0MTY0MA==", "bodyText": "Thanks @rdblue for the review!\nRenamed the class to HiveSchemaUtil and the methods to convert. Also added convert methods for Type conversion.\nKept the HiveSchemaConverter class for now for 2 reasons:\n\nWe have to extend the actual converter for Hive3 (Timestamp with local timezone is a separate type in Hive 3)\nYou suggested to implement a Hive type visitor on another review - we might want to use that for conversions when it is ready\n\nUntil we have a final solution I added a javadoc where specifically stated that this package private class should not be used anywhere for conversion and pointed to the correct class to use.\nWhat do you think? Would this be good enough for start?\nThanks,\nPeter", "url": "https://github.com/apache/iceberg/pull/1842#discussion_r537041640", "createdAt": "2020-12-06T13:42:22Z", "author": {"login": "pvary"}, "path": "hive-metastore/src/main/java/org/apache/iceberg/hive/HiveTypeConverter.java", "diffHunk": "@@ -30,7 +37,52 @@ private HiveTypeConverter() {\n \n   }\n \n-  public static String convert(Type type) {\n+  /**\n+   * Converts the Iceberg schema to a Hive schema.\n+   * @param schema The original Iceberg schema to convert\n+   * @return The Hive column list generated from the Iceberg schema\n+   */\n+  public static List<FieldSchema> hiveSchema(Schema schema) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ3NTk3OQ=="}, "originalCommit": {"oid": "77b1d08ee80300457ceb3a911b2644e538cab156"}, "originalPosition": 25}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNzg2MTkxMw==", "bodyText": "Yes, sounds like you're heading in the direction I suggested. I'm flexible on how we get there and would defer to your judgement on it.", "url": "https://github.com/apache/iceberg/pull/1842#discussion_r537861913", "createdAt": "2020-12-07T21:55:28Z", "author": {"login": "rdblue"}, "path": "hive-metastore/src/main/java/org/apache/iceberg/hive/HiveTypeConverter.java", "diffHunk": "@@ -30,7 +37,52 @@ private HiveTypeConverter() {\n \n   }\n \n-  public static String convert(Type type) {\n+  /**\n+   * Converts the Iceberg schema to a Hive schema.\n+   * @param schema The original Iceberg schema to convert\n+   * @return The Hive column list generated from the Iceberg schema\n+   */\n+  public static List<FieldSchema> hiveSchema(Schema schema) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjQ3NTk3OQ=="}, "originalCommit": {"oid": "77b1d08ee80300457ceb3a911b2644e538cab156"}, "originalPosition": 25}]}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3185, "cost": 1, "resetAt": "2021-11-12T09:44:50Z"}}}