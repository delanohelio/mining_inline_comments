{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NDgxMjU0MDM2", "number": 1430, "title": "API: Fix Metrics serialization", "bodyText": "Metrics implements Serializable, but contains ByteBuffers which are not serializable.\nThis PR makes sure that the Metrics object remain serializable", "createdAt": "2020-09-07T10:12:50Z", "url": "https://github.com/apache/iceberg/pull/1430", "merged": true, "mergeCommit": {"oid": "dece71c1797da08b7a0c33797a485d75e4d9cbb5"}, "closed": true, "closedAt": "2020-09-15T00:48:29Z", "author": {"login": "pvary"}, "timelineItems": {"totalCount": 10, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdGgLjrAH2gAyNDgxMjU0MDM2OjQxYThlOTU5YWZkMDk4OWZlMjgyZGI1ZGM4OThjNGE0NmI2ZDA0MGM=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdIv0eWgH2gAyNDgxMjU0MDM2OmU0MTY3NWI4NDFlZmJkYWYxZmRlZGRkMzRiNmI5NWQwMjYyYzI5ZTQ=", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestCommit", "commit": {"oid": "41a8e959afd0989fe282db5dc898c4a46b6d040c", "author": {"user": {"login": "pvary", "name": null}}, "url": "https://github.com/apache/iceberg/commit/41a8e959afd0989fe282db5dc898c4a46b6d040c", "committedDate": "2020-09-07T10:10:22Z", "message": "Core: Fix Metrics serialization"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg0MjY4NTI0", "url": "https://github.com/apache/iceberg/pull/1430#pullrequestreview-484268524", "createdAt": "2020-09-08T15:41:02Z", "commit": {"oid": "41a8e959afd0989fe282db5dc898c4a46b6d040c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxNTo0MTowMlrOHOjL7g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOFQxNTo0MTowMlrOHOjL7g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTAxODYwNg==", "bodyText": "I think this is one of those possibly dangerous things if the underlying implementation of the byte buffer isn't backed by an array. I believe the safe way to handle this is\nbyte[] b = new byte[bb.remaining()];\nbb.get(b);\n\nhttp://errorprone.info/bugpattern/ByteBufferBackingArray", "url": "https://github.com/apache/iceberg/pull/1430#discussion_r485018606", "createdAt": "2020-09-08T15:41:02Z", "author": {"login": "RussellSpitzer"}, "path": "api/src/main/java/org/apache/iceberg/Metrics.java", "diffHunk": "@@ -120,4 +124,83 @@ public Long recordCount() {\n   public Map<Integer, ByteBuffer> upperBounds() {\n     return upperBounds;\n   }\n+\n+  /**\n+   * Implemented the method to enable serialization of ByteBuffers.\n+   * @param out The stream where to write\n+   * @throws IOException On serialization error\n+   */\n+  private void writeObject(ObjectOutputStream out) throws IOException {\n+    out.writeObject(rowCount);\n+    out.writeObject(columnSizes);\n+    out.writeObject(valueCounts);\n+    out.writeObject(nullValueCounts);\n+\n+    writeByteBufferMap(out, lowerBounds);\n+    writeByteBufferMap(out, upperBounds);\n+  }\n+\n+  private static void writeByteBufferMap(ObjectOutputStream out, Map<Integer, ByteBuffer> byteBufferMap)\n+      throws IOException {\n+    if (byteBufferMap == null) {\n+      out.writeInt(-1);\n+\n+    } else {\n+      // Write the size\n+      out.writeInt(byteBufferMap.size());\n+\n+      for (Map.Entry<Integer, ByteBuffer> entry : byteBufferMap.entrySet()) {\n+        // Write the key\n+        out.writeObject(entry.getKey());\n+\n+        // Write the value\n+        if (entry.getValue() != null) {\n+          out.writeObject(entry.getValue().array());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "41a8e959afd0989fe282db5dc898c4a46b6d040c"}, "originalPosition": 49}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "61a49ea813c47622cb7c666c8428c2acea3f39da", "author": {"user": {"login": "pvary", "name": null}}, "url": "https://github.com/apache/iceberg/commit/61a49ea813c47622cb7c666c8428c2acea3f39da", "committedDate": "2020-09-09T11:30:26Z", "message": "Fix ByteBuffer serialization issue."}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg1MTc1NDYy", "url": "https://github.com/apache/iceberg/pull/1430#pullrequestreview-485175462", "createdAt": "2020-09-09T16:04:56Z", "commit": {"oid": "61a49ea813c47622cb7c666c8428c2acea3f39da"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQxNjowNDo1N1rOHPOlew==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0wOVQxNjowNDo1N1rOHPOlew==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NTcyOTY1OQ==", "bodyText": "Seems like we can probably just get away with a simple new java.util.HashMap(), no need for guava as a dependency for this class.", "url": "https://github.com/apache/iceberg/pull/1430#discussion_r485729659", "createdAt": "2020-09-09T16:04:57Z", "author": {"login": "fbocse"}, "path": "api/src/main/java/org/apache/iceberg/Metrics.java", "diffHunk": "@@ -120,4 +124,90 @@ public Long recordCount() {\n   public Map<Integer, ByteBuffer> upperBounds() {\n     return upperBounds;\n   }\n+\n+  /**\n+   * Implemented the method to enable serialization of ByteBuffers.\n+   * @param out The stream where to write\n+   * @throws IOException On serialization error\n+   */\n+  private void writeObject(ObjectOutputStream out) throws IOException {\n+    out.writeObject(rowCount);\n+    out.writeObject(columnSizes);\n+    out.writeObject(valueCounts);\n+    out.writeObject(nullValueCounts);\n+\n+    writeByteBufferMap(out, lowerBounds);\n+    writeByteBufferMap(out, upperBounds);\n+  }\n+\n+  private static void writeByteBufferMap(ObjectOutputStream out, Map<Integer, ByteBuffer> byteBufferMap)\n+      throws IOException {\n+    if (byteBufferMap == null) {\n+      out.writeInt(-1);\n+\n+    } else {\n+      // Write the size\n+      out.writeInt(byteBufferMap.size());\n+\n+      for (Map.Entry<Integer, ByteBuffer> entry : byteBufferMap.entrySet()) {\n+        // Write the key\n+        out.writeObject(entry.getKey());\n+\n+        // Write the value\n+        if (entry.getValue() != null) {\n+          // Copy the actual values from the buffer\n+          ByteBuffer bb = entry.getValue();\n+          byte[] bytes = new byte[bb.remaining()];\n+          bb.get(bytes);\n+          bb.position(bb.position() - bytes.length); // Restores the buffer position\n+\n+          // Write out the data\n+          out.writeObject(bytes);\n+        } else {\n+          out.writeObject(null);\n+        }\n+      }\n+    }\n+  }\n+\n+  /**\n+   * Implemented the method to enable deserialization of ByteBuffers.\n+   * @param in The stream to read from\n+   * @throws IOException On serialization error\n+   * @throws ClassNotFoundException If the class is not found\n+   */\n+  private void readObject(ObjectInputStream in) throws IOException, ClassNotFoundException {\n+    rowCount = (Long) in.readObject();\n+    columnSizes = (Map<Integer, Long>) in.readObject();\n+    valueCounts = (Map<Integer, Long>) in.readObject();\n+    nullValueCounts = (Map<Integer, Long>) in.readObject();\n+\n+    lowerBounds = readByteBufferMap(in);\n+    upperBounds = readByteBufferMap(in);\n+  }\n+\n+  private static Map<Integer, ByteBuffer> readByteBufferMap(ObjectInputStream in)\n+      throws IOException, ClassNotFoundException {\n+    int size = in.readInt();\n+\n+    if (size == -1) {\n+      return null;\n+\n+    } else {\n+      Map<Integer, ByteBuffer> result = Maps.newHashMap();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "61a49ea813c47622cb7c666c8428c2acea3f39da"}, "originalPosition": 88}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "1737739a6424af07aecef6c38ce1669a0482ab42", "author": {"user": {"login": "pvary", "name": null}}, "url": "https://github.com/apache/iceberg/commit/1737739a6424af07aecef6c38ce1669a0482ab42", "committedDate": "2020-09-09T18:06:00Z", "message": "Removed guava dependency"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg3MzQ1NDA4", "url": "https://github.com/apache/iceberg/pull/1430#pullrequestreview-487345408", "createdAt": "2020-09-13T22:32:56Z", "commit": {"oid": "1737739a6424af07aecef6c38ce1669a0482ab42"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xM1QyMjozMjo1NlrOHQ_3Vw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xM1QyMjozMjo1NlrOHQ_3Vw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzU4NTYyMw==", "bodyText": "We have a ByteBuffers util located in the core module at org.apache.iceberg.util.ByteBuffers that handles the appropriate copying and restoration of ByteBuffers.\nPlease consider using that for consistency and for easier refactoring of ByteBuffer issues in the future. Here's a link to that class: https://github.com/apache/iceberg/blob/master/core/src/main/java/org/apache/iceberg/util/ByteBuffers.java", "url": "https://github.com/apache/iceberg/pull/1430#discussion_r487585623", "createdAt": "2020-09-13T22:32:56Z", "author": {"login": "kbendick"}, "path": "api/src/main/java/org/apache/iceberg/Metrics.java", "diffHunk": "@@ -120,4 +124,90 @@ public Long recordCount() {\n   public Map<Integer, ByteBuffer> upperBounds() {\n     return upperBounds;\n   }\n+\n+  /**\n+   * Implemented the method to enable serialization of ByteBuffers.\n+   * @param out The stream where to write\n+   * @throws IOException On serialization error\n+   */\n+  private void writeObject(ObjectOutputStream out) throws IOException {\n+    out.writeObject(rowCount);\n+    out.writeObject(columnSizes);\n+    out.writeObject(valueCounts);\n+    out.writeObject(nullValueCounts);\n+\n+    writeByteBufferMap(out, lowerBounds);\n+    writeByteBufferMap(out, upperBounds);\n+  }\n+\n+  private static void writeByteBufferMap(ObjectOutputStream out, Map<Integer, ByteBuffer> byteBufferMap)\n+      throws IOException {\n+    if (byteBufferMap == null) {\n+      out.writeInt(-1);\n+\n+    } else {\n+      // Write the size\n+      out.writeInt(byteBufferMap.size());\n+\n+      for (Map.Entry<Integer, ByteBuffer> entry : byteBufferMap.entrySet()) {\n+        // Write the key\n+        out.writeObject(entry.getKey());\n+\n+        // Write the value\n+        if (entry.getValue() != null) {\n+          // Copy the actual values from the buffer\n+          ByteBuffer bb = entry.getValue();\n+          byte[] bytes = new byte[bb.remaining()];\n+          bb.get(bytes);\n+          bb.position(bb.position() - bytes.length); // Restores the buffer position", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1737739a6424af07aecef6c38ce1669a0482ab42"}, "originalPosition": 52}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg3MzQ2NTM3", "url": "https://github.com/apache/iceberg/pull/1430#pullrequestreview-487346537", "createdAt": "2020-09-13T22:51:07Z", "commit": {"oid": "1737739a6424af07aecef6c38ce1669a0482ab42"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xM1QyMjo1MTowOFrOHQ_92g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xM1QyMjo1MTowOFrOHQ_92g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzU4NzI5MA==", "bodyText": "Is this serialization format, e.g. rowCount, columnSizes, valueCounts, nullValueCounts and then the lowerBounds followed by upperBounds currently used anywhere else?\nIf so, perhaps there's a utility class that can be used?\nIf not, I personally think that this serialization format should be  documented somewhere. We might need to include the format version in it as well, like we do for other places (where the new v2 format specification will be what is used to support row level deletes).\nAdditionally, would it make sense to move this serialization logic into a utility class if there's nothing that currently meets this need?\nFor example, type conversions to get the lower bounds value from the ByteBuffer are currently done in org.apache.iceberg.types.Conversion#fromByteBuffer as mentioned elsehwere in this file. Here's a link to the code, perhaps something there might make this task easier / more standardized: https://github.com/apache/iceberg/blob/master/api/src/main/java/org/apache/iceberg/types/Conversions.java\nAnd if there's not a utility class, would it make sense to add one (like how the actual conversion of upperBounds and lowerBounds from their ByteBuffers is deletegated to the Conversions class?", "url": "https://github.com/apache/iceberg/pull/1430#discussion_r487587290", "createdAt": "2020-09-13T22:51:08Z", "author": {"login": "kbendick"}, "path": "api/src/main/java/org/apache/iceberg/Metrics.java", "diffHunk": "@@ -120,4 +124,90 @@ public Long recordCount() {\n   public Map<Integer, ByteBuffer> upperBounds() {\n     return upperBounds;\n   }\n+\n+  /**\n+   * Implemented the method to enable serialization of ByteBuffers.\n+   * @param out The stream where to write\n+   * @throws IOException On serialization error\n+   */\n+  private void writeObject(ObjectOutputStream out) throws IOException {\n+    out.writeObject(rowCount);\n+    out.writeObject(columnSizes);\n+    out.writeObject(valueCounts);\n+    out.writeObject(nullValueCounts);\n+\n+    writeByteBufferMap(out, lowerBounds);\n+    writeByteBufferMap(out, upperBounds);\n+  }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1737739a6424af07aecef6c38ce1669a0482ab42"}, "originalPosition": 31}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NDg3MzUyNjc0", "url": "https://github.com/apache/iceberg/pull/1430#pullrequestreview-487352674", "createdAt": "2020-09-13T23:58:15Z", "commit": {"oid": "1737739a6424af07aecef6c38ce1669a0482ab42"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xM1QyMzo1ODoxNVrOHRAbUw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0wOS0xM1QyMzo1ODoxNVrOHRAbUw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDQ4NzU5NDgzNQ==", "bodyText": "Don't we need to flush the object output stream?", "url": "https://github.com/apache/iceberg/pull/1430#discussion_r487594835", "createdAt": "2020-09-13T23:58:15Z", "author": {"login": "rdblue"}, "path": "api/src/test/java/org/apache/iceberg/TestMetricsSerialization.java", "diffHunk": "@@ -0,0 +1,123 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg;\n+\n+import java.io.ByteArrayInputStream;\n+import java.io.ByteArrayOutputStream;\n+import java.io.IOException;\n+import java.io.ObjectInputStream;\n+import java.io.ObjectOutputStream;\n+import java.nio.ByteBuffer;\n+import java.util.HashMap;\n+import java.util.Map;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestMetricsSerialization {\n+\n+  @Test\n+  public void testSerialization() throws IOException, ClassNotFoundException {\n+    Metrics original = generateMetrics();\n+\n+    byte[] serialized = serialize(original);\n+    Metrics result = deserialize(serialized);\n+\n+    assertEquals(original, result);\n+  }\n+\n+  @Test\n+  public void testSerializationWithNulls() throws IOException, ClassNotFoundException {\n+    Metrics original = generateMetricsWithNulls();\n+\n+    byte[] serialized = serialize(original);\n+    Metrics result = deserialize(serialized);\n+\n+    assertEquals(original, result);\n+  }\n+\n+  private static byte[] serialize(Metrics metrics) throws IOException {\n+    try (ByteArrayOutputStream byteArrayOutputStream = new ByteArrayOutputStream()) {\n+      ObjectOutputStream objectOutputStream = new ObjectOutputStream(byteArrayOutputStream);\n+      objectOutputStream.writeObject(metrics);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1737739a6424af07aecef6c38ce1669a0482ab42"}, "originalPosition": 58}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "bc2ae6951a44f9798517c601350c936f057c6a07", "author": {"user": {"login": "pvary", "name": null}}, "url": "https://github.com/apache/iceberg/commit/bc2ae6951a44f9798517c601350c936f057c6a07", "committedDate": "2020-09-14T09:24:07Z", "message": "Used ByteBuffers.toByteArray to get the byte[] from the buffers."}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e41675b841efbdaf1fdeddd34b6b95d0262c29e4", "author": {"user": {"login": "pvary", "name": null}}, "url": "https://github.com/apache/iceberg/commit/e41675b841efbdaf1fdeddd34b6b95d0262c29e4", "committedDate": "2020-09-14T09:31:29Z", "message": "Flushing the stream in the tests to prevent possible flakiness"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 4183, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}