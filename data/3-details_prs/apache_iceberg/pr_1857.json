{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTMwNjYxMzg5", "number": 1857, "title": "rewrite equals filters", "bodyText": "This PR is based on #1747. Currently it couldn't compile but I have confirmed locally that the project could build and all tests passed after rebasing it on top of #1747. This is because there are a few files required from #1747 to let the tests work. I will rebase the change and mark as ready for review once 1747 is merged.", "createdAt": "2020-12-02T00:36:28Z", "url": "https://github.com/apache/iceberg/pull/1857", "merged": true, "mergeCommit": {"oid": "04e73deb7d68e3c4011101384f725abb1aae6236"}, "closed": true, "closedAt": "2020-12-10T23:57:17Z", "author": {"login": "yyanyy"}, "timelineItems": {"totalCount": 14, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdiZEVIgFqTU0MzM3NzA0OA==", "endCursor": "Y3Vyc29yOnYyOpPPAAABdk8UwWgFqTU0OTcwNDYyOQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQzMzc3MDQ4", "url": "https://github.com/apache/iceberg/pull/1857#pullrequestreview-543377048", "createdAt": "2020-12-03T01:43:01Z", "commit": {"oid": "445ee6db3bec3086a4bccf99de18b8bc79f246b7"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ1MjkxNDAz", "url": "https://github.com/apache/iceberg/pull/1857#pullrequestreview-545291403", "createdAt": "2020-12-04T20:57:51Z", "commit": {"oid": "445ee6db3bec3086a4bccf99de18b8bc79f246b7"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQyMDo1Nzo1MVrOH_hweQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQyMDo1Nzo1MVrOH_hweQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjM3NTQxNw==", "bodyText": "why is this not directly inside Expressions.equal, so we can avoid duplication between spark 2 and 3?", "url": "https://github.com/apache/iceberg/pull/1857#discussion_r536375417", "createdAt": "2020-12-04T20:57:51Z", "author": {"login": "jackye1995"}, "path": "spark2/src/main/java/org/apache/iceberg/spark/SparkFilters.java", "diffHunk": "@@ -113,13 +115,13 @@ public static Expression convert(Filter filter) {\n             // comparison with null in normal equality is always null. this is probably a mistake.\n             Preconditions.checkNotNull(eq.value(),\n                 \"Expression is always false (eq is not null-safe): %s\", filter);\n-            return equal(eq.attribute(), convertLiteral(eq.value()));\n+            return handleEqual(eq.attribute(), eq.value());\n           } else {\n             EqualNullSafe eq = (EqualNullSafe) filter;\n             if (eq.value() == null) {\n               return isNull(eq.attribute());\n             } else {\n-              return equal(eq.attribute(), convertLiteral(eq.value()));\n+              return handleEqual(eq.attribute(), eq.value());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "445ee6db3bec3086a4bccf99de18b8bc79f246b7"}, "originalPosition": 28}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ1MjkzNzgw", "url": "https://github.com/apache/iceberg/pull/1857#pullrequestreview-545293780", "createdAt": "2020-12-04T21:01:55Z", "commit": {"oid": "445ee6db3bec3086a4bccf99de18b8bc79f246b7"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQyMTowMTo1NVrOH_h4ZQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNFQyMTowMTo1NVrOH_h4ZQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjM3NzQ0NQ==", "bodyText": "I think we should also try to test it for spark2, maybe update some tests in TestReadProjection?", "url": "https://github.com/apache/iceberg/pull/1857#discussion_r536377445", "createdAt": "2020-12-04T21:01:55Z", "author": {"login": "jackye1995"}, "path": "spark3/src/test/java/org/apache/iceberg/spark/sql/TestSelect.java", "diffHunk": "@@ -49,8 +49,8 @@ public TestSelect(String catalogName, String implementation, Map<String, String>\n ", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "445ee6db3bec3086a4bccf99de18b8bc79f246b7"}, "originalPosition": 1}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ1NjYxODYx", "url": "https://github.com/apache/iceberg/pull/1857#pullrequestreview-545661861", "createdAt": "2020-12-06T01:18:07Z", "commit": {"oid": "445ee6db3bec3086a4bccf99de18b8bc79f246b7"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNlQwMToxODowN1rOIADeCg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wNlQwMToxODowN1rOIADeCg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzNjkyNzc1NA==", "bodyText": "This should be moved into the else block because literal should not allow creating a NaN literal.", "url": "https://github.com/apache/iceberg/pull/1857#discussion_r536927754", "createdAt": "2020-12-06T01:18:07Z", "author": {"login": "rdblue"}, "path": "spark2/src/main/java/org/apache/iceberg/spark/SparkFilters.java", "diffHunk": "@@ -177,4 +179,13 @@ private static Object convertLiteral(Object value) {\n     }\n     return value;\n   }\n+\n+  private static Expression handleEqual(String attribute, Object value) {\n+    Object literal = convertLiteral(value);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "445ee6db3bec3086a4bccf99de18b8bc79f246b7"}, "originalPosition": 38}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "445ee6db3bec3086a4bccf99de18b8bc79f246b7", "author": {"user": {"login": "yyanyy", "name": null}}, "url": "https://github.com/apache/iceberg/commit/445ee6db3bec3086a4bccf99de18b8bc79f246b7", "committedDate": "2020-12-02T00:30:38Z", "message": "rewrite equals filters"}, "afterCommit": {"oid": "730ce5b791ea775b04870189940e18014211fb59", "author": {"user": {"login": "yyanyy", "name": null}}, "url": "https://github.com/apache/iceberg/commit/730ce5b791ea775b04870189940e18014211fb59", "committedDate": "2020-12-08T02:29:14Z", "message": "add spark2 test"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ3NzMxODcy", "url": "https://github.com/apache/iceberg/pull/1857#pullrequestreview-547731872", "createdAt": "2020-12-08T23:56:31Z", "commit": {"oid": "730ce5b791ea775b04870189940e18014211fb59"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOFQyMzo1NjozMVrOIB7z0g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOFQyMzo1NjozMVrOIB7z0g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODg5OTQxMA==", "bodyText": "Shouldn't this be is_nan(float) instead of = NaN?", "url": "https://github.com/apache/iceberg/pull/1857#discussion_r538899410", "createdAt": "2020-12-08T23:56:31Z", "author": {"login": "rdblue"}, "path": "spark3/src/test/java/org/apache/iceberg/spark/sql/TestSelect.java", "diffHunk": "@@ -63,11 +63,25 @@ public void removeTables() {\n \n   @Test\n   public void testSelect() {\n-    List<Object[]> expected = ImmutableList.of(row(1L, \"a\"), row(2L, \"b\"), row(3L, \"c\"));\n+    List<Object[]> expected = ImmutableList.of(\n+        row(1L, \"a\", 1.0F), row(2L, \"b\", 2.0F), row(3L, \"c\", Float.NaN));\n \n     assertEquals(\"Should return all expected rows\", expected, sql(\"SELECT * FROM %s\", tableName));\n   }\n \n+  @Test\n+  public void testSelectRewrite() {\n+    List<Object[]> expected = ImmutableList.of(row(3L, \"c\", Float.NaN));\n+\n+    assertEquals(\"Should return all expected rows\", expected,\n+        sql(\"SELECT * FROM %s where float = float('NaN')\", tableName));\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should push down expected filter\",\n+        \"(float IS NOT NULL AND float = NaN)\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "730ce5b791ea775b04870189940e18014211fb59"}, "originalPosition": 31}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ3NzMyNzM4", "url": "https://github.com/apache/iceberg/pull/1857#pullrequestreview-547732738", "createdAt": "2020-12-08T23:58:39Z", "commit": {"oid": "730ce5b791ea775b04870189940e18014211fb59"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOFQyMzo1ODozOVrOIB73Hw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOFQyMzo1ODozOVrOIB73Hw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODkwMDI1NQ==", "bodyText": "Shouldn't this validate more than just the number of scans?", "url": "https://github.com/apache/iceberg/pull/1857#discussion_r538900255", "createdAt": "2020-12-08T23:58:39Z", "author": {"login": "rdblue"}, "path": "spark2/src/test/java/org/apache/iceberg/spark/source/TestSelect.java", "diffHunk": "@@ -0,0 +1,230 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.source;\n+\n+import java.io.File;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.events.Listeners;\n+import org.apache.iceberg.events.ScanEvent;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.hadoop.HadoopTables;\n+import org.apache.iceberg.relocated.com.google.common.base.Objects;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.types.Types;\n+import org.apache.spark.sql.Dataset;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.SparkSession;\n+import org.junit.AfterClass;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+\n+public class TestSelect {\n+  private static final HadoopTables TABLES = new HadoopTables(new Configuration());\n+  private static final Schema SCHEMA = new Schema(\n+      optional(1, \"id\", Types.IntegerType.get()),\n+      optional(2, \"data\", Types.StringType.get()),\n+      optional(3, \"doubleVal\", Types.DoubleType.get())\n+  );\n+\n+  private static SparkSession spark;\n+\n+  private static int scanEventCount = 0;\n+  private static ScanEvent lastScanEvent = null;\n+\n+  private Table table;\n+\n+  static {\n+    Listeners.register(event -> {\n+      scanEventCount += 1;\n+      lastScanEvent = event;\n+    }, ScanEvent.class);\n+  }\n+\n+  @BeforeClass\n+  public static void startSpark() {\n+    spark = SparkSession.builder()\n+        .master(\"local[2]\")\n+        .getOrCreate();\n+  }\n+\n+  @AfterClass\n+  public static void stopSpark() {\n+    SparkSession currentSpark = spark;\n+    spark = null;\n+    currentSpark.stop();\n+  }\n+\n+  @Rule\n+  public TemporaryFolder temp = new TemporaryFolder();\n+\n+  private String tableLocation = null;\n+\n+  @Before\n+  public void init() throws Exception {\n+    File tableDir = temp.newFolder();\n+    this.tableLocation = tableDir.toURI().toString();\n+\n+    table = TABLES.create(SCHEMA, tableLocation);\n+\n+    List<Record> rows = Lists.newArrayList(\n+        new Record(1, \"a\", 1.0),\n+        new Record(2, \"b\", 2.0),\n+        new Record(3, \"c\", Double.NaN)\n+    );\n+\n+    Dataset<Row> df = spark.createDataFrame(rows, Record.class);\n+\n+    df.select(\"id\", \"data\", \"doubleVal\").write()\n+        .format(\"iceberg\")\n+        .mode(\"append\")\n+        .save(tableLocation);\n+\n+    table.refresh();\n+\n+    Dataset<Row> results = spark.read()\n+        .format(\"iceberg\")\n+        .load(tableLocation);\n+    results.createOrReplaceTempView(\"table\");\n+\n+    scanEventCount = 0;\n+    lastScanEvent = null;\n+  }\n+\n+  @Test\n+  public void testSelect() {\n+    List<Record> expected = ImmutableList.of(\n+        new Record(1, \"a\", 1.0), new Record(2, \"b\", 2.0), new Record(3, \"c\", Double.NaN));\n+\n+    Assert.assertEquals(\"Should return all expected rows\", expected, sql(\"select * from table\"));\n+  }\n+\n+  @Test\n+  public void testSelectRewrite() {\n+    List<Record> expected = ImmutableList.of(new Record(3, \"c\", Double.NaN));\n+\n+    Assert.assertEquals(\"Should return all expected rows\", expected,\n+        sql(\"SELECT * FROM table where doubleVal = double('NaN')\"));\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "730ce5b791ea775b04870189940e18014211fb59"}, "originalPosition": 135}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ3NzM0Mzg2", "url": "https://github.com/apache/iceberg/pull/1857#pullrequestreview-547734386", "createdAt": "2020-12-09T00:02:41Z", "commit": {"oid": "730ce5b791ea775b04870189940e18014211fb59"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOVQwMDowMjo0MVrOIB79Vg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0wOVQwMDowMjo0MVrOIB79Vg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDUzODkwMTg0Ng==", "bodyText": "This seems brittle because it uses types to place the results.\nOther tests use StructProjection and StructLikeSet for similar validations. The incoming row is wrapped to be a StructLike and added to a StructLikeSet based on the expected schema. Then another StructLikeSet is created with the expected rows, which are projected using StructProjection and the expected schema. That is a cleaner way to do this, I think.", "url": "https://github.com/apache/iceberg/pull/1857#discussion_r538901846", "createdAt": "2020-12-09T00:02:41Z", "author": {"login": "rdblue"}, "path": "spark2/src/test/java/org/apache/iceberg/spark/source/TestSelect.java", "diffHunk": "@@ -0,0 +1,230 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.spark.source;\n+\n+import java.io.File;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import org.apache.hadoop.conf.Configuration;\n+import org.apache.iceberg.Schema;\n+import org.apache.iceberg.Table;\n+import org.apache.iceberg.events.Listeners;\n+import org.apache.iceberg.events.ScanEvent;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.hadoop.HadoopTables;\n+import org.apache.iceberg.relocated.com.google.common.base.Objects;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n+import org.apache.iceberg.types.Types;\n+import org.apache.spark.sql.Dataset;\n+import org.apache.spark.sql.Row;\n+import org.apache.spark.sql.SparkSession;\n+import org.junit.AfterClass;\n+import org.junit.Assert;\n+import org.junit.Before;\n+import org.junit.BeforeClass;\n+import org.junit.Rule;\n+import org.junit.Test;\n+import org.junit.rules.TemporaryFolder;\n+\n+import static org.apache.iceberg.types.Types.NestedField.optional;\n+\n+public class TestSelect {\n+  private static final HadoopTables TABLES = new HadoopTables(new Configuration());\n+  private static final Schema SCHEMA = new Schema(\n+      optional(1, \"id\", Types.IntegerType.get()),\n+      optional(2, \"data\", Types.StringType.get()),\n+      optional(3, \"doubleVal\", Types.DoubleType.get())\n+  );\n+\n+  private static SparkSession spark;\n+\n+  private static int scanEventCount = 0;\n+  private static ScanEvent lastScanEvent = null;\n+\n+  private Table table;\n+\n+  static {\n+    Listeners.register(event -> {\n+      scanEventCount += 1;\n+      lastScanEvent = event;\n+    }, ScanEvent.class);\n+  }\n+\n+  @BeforeClass\n+  public static void startSpark() {\n+    spark = SparkSession.builder()\n+        .master(\"local[2]\")\n+        .getOrCreate();\n+  }\n+\n+  @AfterClass\n+  public static void stopSpark() {\n+    SparkSession currentSpark = spark;\n+    spark = null;\n+    currentSpark.stop();\n+  }\n+\n+  @Rule\n+  public TemporaryFolder temp = new TemporaryFolder();\n+\n+  private String tableLocation = null;\n+\n+  @Before\n+  public void init() throws Exception {\n+    File tableDir = temp.newFolder();\n+    this.tableLocation = tableDir.toURI().toString();\n+\n+    table = TABLES.create(SCHEMA, tableLocation);\n+\n+    List<Record> rows = Lists.newArrayList(\n+        new Record(1, \"a\", 1.0),\n+        new Record(2, \"b\", 2.0),\n+        new Record(3, \"c\", Double.NaN)\n+    );\n+\n+    Dataset<Row> df = spark.createDataFrame(rows, Record.class);\n+\n+    df.select(\"id\", \"data\", \"doubleVal\").write()\n+        .format(\"iceberg\")\n+        .mode(\"append\")\n+        .save(tableLocation);\n+\n+    table.refresh();\n+\n+    Dataset<Row> results = spark.read()\n+        .format(\"iceberg\")\n+        .load(tableLocation);\n+    results.createOrReplaceTempView(\"table\");\n+\n+    scanEventCount = 0;\n+    lastScanEvent = null;\n+  }\n+\n+  @Test\n+  public void testSelect() {\n+    List<Record> expected = ImmutableList.of(\n+        new Record(1, \"a\", 1.0), new Record(2, \"b\", 2.0), new Record(3, \"c\", Double.NaN));\n+\n+    Assert.assertEquals(\"Should return all expected rows\", expected, sql(\"select * from table\"));\n+  }\n+\n+  @Test\n+  public void testSelectRewrite() {\n+    List<Record> expected = ImmutableList.of(new Record(3, \"c\", Double.NaN));\n+\n+    Assert.assertEquals(\"Should return all expected rows\", expected,\n+        sql(\"SELECT * FROM table where doubleVal = double('NaN')\"));\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+  }\n+\n+  @Test\n+  public void testProjection() {\n+    List<Record> expected = ImmutableList.of(\n+        new Record(1, null, null), new Record(2, null, null), new Record(3, null, null));\n+\n+    Assert.assertEquals(\"Should return all expected rows\", expected, sql(\"SELECT id FROM table\"));\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should not push down a filter\", Expressions.alwaysTrue(), lastScanEvent.filter());\n+    Assert.assertEquals(\"Should project only the id column\",\n+        table.schema().select(\"id\").asStruct(),\n+        lastScanEvent.projection().asStruct());\n+  }\n+\n+  @Test\n+  public void testExpressionPushdown() {\n+    List<Record> expected = ImmutableList.of(new Record(null, \"b\", null));\n+\n+    Assert.assertEquals(\"Should return all expected rows\", expected, sql(\"SELECT data FROM table WHERE id = 2\"));\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should project only id and data columns\",\n+        table.schema().select(\"id\", \"data\").asStruct(),\n+        lastScanEvent.projection().asStruct());\n+  }\n+\n+  private List<Record> sql(String str) {\n+    List<Row> rows = spark.sql(str).collectAsList();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "730ce5b791ea775b04870189940e18014211fb59"}, "originalPosition": 165}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "cc8dc2b38895b251e8e5394535f986d3ec92025f", "author": {"user": {"login": "yyanyy", "name": null}}, "url": "https://github.com/apache/iceberg/commit/cc8dc2b38895b251e8e5394535f986d3ec92025f", "committedDate": "2020-12-09T22:17:27Z", "message": "rewrite equals filters"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "e8942159baa2d3dc747d25314b7b970fd07afc18", "author": {"user": {"login": "yyanyy", "name": null}}, "url": "https://github.com/apache/iceberg/commit/e8942159baa2d3dc747d25314b7b970fd07afc18", "committedDate": "2020-12-09T22:17:27Z", "message": "add spark2 test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "ecb3839c039f21427ee5b8b191e84af0b1d2d848", "author": {"user": {"login": "yyanyy", "name": null}}, "url": "https://github.com/apache/iceberg/commit/ecb3839c039f21427ee5b8b191e84af0b1d2d848", "committedDate": "2020-12-09T22:18:39Z", "message": "update spark2 test"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "730ce5b791ea775b04870189940e18014211fb59", "author": {"user": {"login": "yyanyy", "name": null}}, "url": "https://github.com/apache/iceberg/commit/730ce5b791ea775b04870189940e18014211fb59", "committedDate": "2020-12-08T02:29:14Z", "message": "add spark2 test"}, "afterCommit": {"oid": "ecb3839c039f21427ee5b8b191e84af0b1d2d848", "author": {"user": {"login": "yyanyy", "name": null}}, "url": "https://github.com/apache/iceberg/commit/ecb3839c039f21427ee5b8b191e84af0b1d2d848", "committedDate": "2020-12-09T22:18:39Z", "message": "update spark2 test"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "031582f21a4d91d91a497181ad96f92967d8cbcf", "author": {"user": {"login": "yyanyy", "name": null}}, "url": "https://github.com/apache/iceberg/commit/031582f21a4d91d91a497181ad96f92967d8cbcf", "committedDate": "2020-12-10T02:27:01Z", "message": "change is_nan() representation in describe()"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTQ5NzA0NjI5", "url": "https://github.com/apache/iceberg/pull/1857#pullrequestreview-549704629", "createdAt": "2020-12-10T23:55:29Z", "commit": {"oid": "031582f21a4d91d91a497181ad96f92967d8cbcf"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3475, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}