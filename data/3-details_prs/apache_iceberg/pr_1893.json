{"data": {"repository": {"pullRequest": {"id": "MDExOlB1bGxSZXF1ZXN0NTM0ODUyNjk4", "number": 1893, "title": "Flink: Support filter pushdown in IcebergTableSource", "bodyText": "add filter push down for IcebergTableSource", "createdAt": "2020-12-09T02:33:58Z", "url": "https://github.com/apache/iceberg/pull/1893", "merged": true, "mergeCommit": {"oid": "70d309e6e1f8e2538bae274febf39a92fcbe3bb2"}, "closed": true, "closedAt": "2021-01-18T20:49:48Z", "author": {"login": "zhangjun0x01"}, "timelineItems": {"totalCount": 121, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpPPAAABdwr-f7gBqjQyMTM5NzEyMzI=", "endCursor": "Y3Vyc29yOnYyOpPPAAABdxdCULAFqTU3MDc3MDcxNA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "edad5ee6f8c8e458de5c3a497876b6bf37d800e5", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/edad5ee6f8c8e458de5c3a497876b6bf37d800e5", "committedDate": "2021-01-16T11:12:34Z", "message": "fix some issues, and add some test case"}, "afterCommit": {"oid": "7daffa6ccf6b7889faa7ef8c14193d9de206786c", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/7daffa6ccf6b7889faa7ef8c14193d9de206786c", "committedDate": "2021-01-16T11:39:23Z", "message": "fix some issues, and add some test case"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "7daffa6ccf6b7889faa7ef8c14193d9de206786c", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/7daffa6ccf6b7889faa7ef8c14193d9de206786c", "committedDate": "2021-01-16T11:39:23Z", "message": "fix some issues, and add some test case"}, "afterCommit": {"oid": "d33aa4981701d5ee5cea2995de2dfe2775e9ffff", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/d33aa4981701d5ee5cea2995de2dfe2775e9ffff", "committedDate": "2021-01-16T14:15:19Z", "message": "fix some issues, and add some test case"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d33aa4981701d5ee5cea2995de2dfe2775e9ffff", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/d33aa4981701d5ee5cea2995de2dfe2775e9ffff", "committedDate": "2021-01-16T14:15:19Z", "message": "fix some issues, and add some test case"}, "afterCommit": {"oid": "217d05955b5719813d72c00aea8cf6e11eda38a9", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/217d05955b5719813d72c00aea8cf6e11eda38a9", "committedDate": "2021-01-16T14:33:05Z", "message": "fix some issues, and add some test case"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY5OTU3Mzcx", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-569957371", "createdAt": "2021-01-16T18:13:27Z", "commit": {"oid": "217d05955b5719813d72c00aea8cf6e11eda38a9"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNlQxODoxMzoyN1rOIVGE-A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNlQxODoxMzoyN1rOIVGE-A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODk5MDU4NA==", "bodyText": "These casts are unnecessary.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r558990584", "createdAt": "2021-01-16T18:13:27Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkFilters.java", "diffHunk": "@@ -0,0 +1,389 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.math.BigDecimal;\n+import java.nio.ByteBuffer;\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.stream.Collectors;\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.Expressions;\n+import org.apache.flink.table.api.TableColumn;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.expressions.ApiExpressionUtils;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.Expression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.UnresolvedCallExpression;\n+import org.apache.flink.table.expressions.UnresolvedReferenceExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.expressions.utils.ApiExpressionDefaultVisitor;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.iceberg.expressions.And;\n+import org.apache.iceberg.expressions.BoundLiteralPredicate;\n+import org.apache.iceberg.expressions.Not;\n+import org.apache.iceberg.expressions.Or;\n+import org.apache.iceberg.expressions.UnboundPredicate;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n+import org.apache.iceberg.util.DateTimeUtil;\n+import org.apache.iceberg.util.Pair;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestFlinkFilters {\n+\n+  private static final TableSchema TABLE_SCHEMA = TableSchema.builder()\n+      .field(\"field1\", DataTypes.INT())\n+      .field(\"field2\", DataTypes.BIGINT())\n+      .field(\"field3\", DataTypes.FLOAT())\n+      .field(\"field4\", DataTypes.DOUBLE())\n+      .field(\"field5\", DataTypes.STRING())\n+      .field(\"field6\", DataTypes.BOOLEAN())\n+      .field(\"field7\", DataTypes.BINARY(2))\n+      .field(\"field8\", DataTypes.DECIMAL(10, 2))\n+      .field(\"field9\", DataTypes.DATE())\n+      .field(\"field10\", DataTypes.TIME())\n+      .field(\"field11\", DataTypes.TIMESTAMP())\n+      .field(\"field12\", DataTypes.TIMESTAMP_WITH_LOCAL_TIME_ZONE())\n+      .build();\n+\n+  // A map list of fields and values used to verify the conversion of flink expression to iceberg expression\n+  private static final List<Pair<String, Object>> FIELD_VALUE_LIST = ImmutableList.of(\n+      Pair.of(\"field1\", 1),\n+      Pair.of(\"field2\", 2L),\n+      Pair.of(\"field3\", 3F),\n+      Pair.of(\"field4\", 4D),\n+      Pair.of(\"field5\", \"iceberg\"),\n+      Pair.of(\"field6\", true),\n+      Pair.of(\"field7\", new byte[] {'a', 'b'}),\n+      Pair.of(\"field8\", BigDecimal.valueOf(10.12)),\n+      Pair.of(\"field9\", DateTimeUtil.daysFromDate(LocalDate.now())),\n+      Pair.of(\"field10\", DateTimeUtil.microsFromTime(LocalTime.now())),\n+      Pair.of(\"field11\", DateTimeUtil.microsFromTimestamp(LocalDateTime.now())),\n+      Pair.of(\"field12\", DateTimeUtil.microsFromInstant(Instant.now()))\n+  );\n+\n+  @Test\n+  public void testFlinkDataTypeEqual() {\n+    matchLiteral(\"field1\", 1, 1);\n+    matchLiteral(\"field2\", 10L, 10L);\n+    matchLiteral(\"field3\", 1.2F, 1.2F);\n+    matchLiteral(\"field4\", 3.4D, 3.4D);\n+    matchLiteral(\"field5\", \"abcd\", \"abcd\");\n+    matchLiteral(\"field6\", true, true);\n+    matchLiteral(\"field7\", new byte[] {'a', 'b'}, ByteBuffer.wrap(new byte[] {'a', 'b'}));\n+    matchLiteral(\"field8\", BigDecimal.valueOf(10.12), BigDecimal.valueOf(10.12));\n+\n+    LocalDate date = LocalDate.parse(\"2020-12-23\");\n+    matchLiteral(\"field9\", date, DateTimeUtil.daysFromDate(date));\n+\n+    LocalTime time = LocalTime.parse(\"12:13:14\");\n+    matchLiteral(\"field10\", time, DateTimeUtil.microsFromTime(time));\n+\n+    LocalDateTime dateTime = LocalDateTime.parse(\"2020-12-23T12:13:14\");\n+    matchLiteral(\"field11\", dateTime, DateTimeUtil.microsFromTimestamp(dateTime));\n+\n+    Instant instant = Instant.parse(\"2020-12-23T12:13:14.00Z\");\n+    matchLiteral(\"field12\", instant, DateTimeUtil.microsFromInstant(instant));\n+  }\n+\n+  @Test\n+  public void testEquals() {\n+    for (Pair<String, Object> pair : FIELD_VALUE_LIST) {\n+      UnboundPredicate<?> expected = org.apache.iceberg.expressions.Expressions.equal(pair.first(), pair.second());\n+\n+      Optional<org.apache.iceberg.expressions.Expression> actual =\n+          FlinkFilters.convert(resolve(Expressions.$(pair.first()).isEqual(Expressions.lit(pair.second()))));\n+      Assert.assertTrue(\"Conversion should succeed\", actual.isPresent());\n+      assertPredicatesMatch(expected, actual.get());\n+\n+      Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+          FlinkFilters.convert(resolve(Expressions.lit(pair.second()).isEqual(Expressions.$(pair.first()))));\n+      Assert.assertTrue(\"Conversion should succeed\", actual1.isPresent());\n+      assertPredicatesMatch(expected, actual1.get());\n+    }\n+  }\n+\n+  @Test\n+  public void testEqualsNaN() {\n+    UnboundPredicate<Float> expected = org.apache.iceberg.expressions.Expressions.isNaN(\"field3\");\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field3\").isEqual(Expressions.lit(Float.NaN))));\n+    Assert.assertTrue(\"Conversion should succeed\", actual.isPresent());\n+    assertPredicatesMatch(expected, actual.get());\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(Float.NaN).isEqual(Expressions.$(\"field3\"))));\n+    Assert.assertTrue(\"Conversion should succeed\", actual1.isPresent());\n+    assertPredicatesMatch(expected, actual1.get());\n+  }\n+\n+  @Test\n+  public void testNotEquals() {\n+    for (Pair<String, Object> pair : FIELD_VALUE_LIST) {\n+      UnboundPredicate<?> expected = org.apache.iceberg.expressions.Expressions.notEqual(pair.first(), pair.second());\n+\n+      Optional<org.apache.iceberg.expressions.Expression> actual =\n+          FlinkFilters.convert(resolve(Expressions.$(pair.first()).isNotEqual(Expressions.lit(pair.second()))));\n+      Assert.assertTrue(\"Conversion should succeed\", actual.isPresent());\n+      assertPredicatesMatch(expected, actual.get());\n+\n+      Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+          FlinkFilters.convert(resolve(Expressions.lit(pair.second()).isNotEqual(Expressions.$(pair.first()))));\n+      Assert.assertTrue(\"Conversion should succeed\", actual1.isPresent());\n+      assertPredicatesMatch(expected, actual1.get());\n+    }\n+  }\n+\n+  @Test\n+  public void testNotEqualsNaN() {\n+    UnboundPredicate<Float> expected = org.apache.iceberg.expressions.Expressions.notNaN(\"field3\");\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field3\").isNotEqual(Expressions.lit(Float.NaN))));\n+    Assert.assertTrue(\"Conversion should succeed\", actual.isPresent());\n+    assertPredicatesMatch(expected, actual.get());\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(Float.NaN).isNotEqual(Expressions.$(\"field3\"))));\n+    Assert.assertTrue(\"Conversion should succeed\", actual1.isPresent());\n+    assertPredicatesMatch(expected, actual1.get());\n+  }\n+\n+  @Test\n+  public void testGreaterThan() {\n+    UnboundPredicate<Integer> expected = org.apache.iceberg.expressions.Expressions.greaterThan(\"field1\", 1);\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field1\").isGreater(Expressions.lit(1))));\n+    Assert.assertTrue(\"Conversion should succeed\", actual.isPresent());\n+    assertPredicatesMatch(expected, actual.get());\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(1).isLess(Expressions.$(\"field1\"))));\n+    Assert.assertTrue(\"Conversion should succeed\", actual1.isPresent());\n+    assertPredicatesMatch(expected, actual1.get());\n+  }\n+\n+  @Test\n+  public void testGreaterThanEquals() {\n+    UnboundPredicate<Integer> expected = org.apache.iceberg.expressions.Expressions.greaterThanOrEqual(\"field1\", 1);\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field1\").isGreaterOrEqual(Expressions.lit(1))));\n+    Assert.assertTrue(\"Conversion should succeed\", actual.isPresent());\n+    assertPredicatesMatch(expected, actual.get());\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(1).isLessOrEqual(Expressions.$(\"field1\"))));\n+    Assert.assertTrue(\"Conversion should succeed\", actual1.isPresent());\n+    assertPredicatesMatch(expected, actual1.get());\n+  }\n+\n+  @Test\n+  public void testLessThan() {\n+    UnboundPredicate<Integer> expected = org.apache.iceberg.expressions.Expressions.lessThan(\"field1\", 1);\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field1\").isLess(Expressions.lit(1))));\n+    Assert.assertTrue(\"Conversion should succeed\", actual.isPresent());\n+    assertPredicatesMatch(expected, actual.get());\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(1).isGreater(Expressions.$(\"field1\"))));\n+    Assert.assertTrue(\"Conversion should succeed\", actual1.isPresent());\n+    assertPredicatesMatch(expected, actual1.get());\n+  }\n+\n+  @Test\n+  public void testLessThanEquals() {\n+    UnboundPredicate<Integer> expected = org.apache.iceberg.expressions.Expressions.lessThanOrEqual(\"field1\", 1);\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field1\").isLessOrEqual(Expressions.lit(1))));\n+    Assert.assertTrue(\"Conversion should succeed\", actual.isPresent());\n+    assertPredicatesMatch(expected, actual.get());\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(1).isGreaterOrEqual(Expressions.$(\"field1\"))));\n+    Assert.assertTrue(\"Conversion should succeed\", actual1.isPresent());\n+    assertPredicatesMatch(expected, actual1.get());\n+  }\n+\n+  @Test\n+  public void testIsNull() {\n+    Expression expr = resolve(Expressions.$(\"field1\").isNull());\n+    Optional<org.apache.iceberg.expressions.Expression> actual = FlinkFilters.convert(expr);\n+    Assert.assertTrue(\"Conversion should succeed\", actual.isPresent());\n+    UnboundPredicate<Object> expected = org.apache.iceberg.expressions.Expressions.isNull(\"field1\");\n+    assertPredicatesMatch(expected, actual.get());\n+  }\n+\n+  @Test\n+  public void testIsNotNull() {\n+    Expression expr = resolve(Expressions.$(\"field1\").isNotNull());\n+    Optional<org.apache.iceberg.expressions.Expression> actual = FlinkFilters.convert(expr);\n+    Assert.assertTrue(\"Conversion should succeed\", actual.isPresent());\n+    UnboundPredicate<Object> expected = org.apache.iceberg.expressions.Expressions.notNull(\"field1\");\n+    assertPredicatesMatch(expected, actual.get());\n+  }\n+\n+  @Test\n+  public void testAnd() {\n+    Expression expr = resolve(\n+        Expressions.$(\"field1\").isEqual(Expressions.lit(1)).and(Expressions.$(\"field2\").isEqual(Expressions.lit(2L))));\n+    Optional<org.apache.iceberg.expressions.Expression> actual = FlinkFilters.convert(expr);\n+    Assert.assertTrue(\"Conversion should succeed\", actual.isPresent());\n+    And and = (And) actual.get();\n+    And expected = (And) org.apache.iceberg.expressions.Expressions.and(\n+        org.apache.iceberg.expressions.Expressions.equal(\"field1\", 1),\n+        org.apache.iceberg.expressions.Expressions.equal(\"field2\", 2L));\n+\n+    assertPredicatesMatch(expected.left(), and.left());\n+    assertPredicatesMatch(expected.right(), and.right());\n+  }\n+\n+  @Test\n+  public void testOr() {\n+    Expression expr = resolve(\n+        Expressions.$(\"field1\").isEqual(Expressions.lit(1)).or(Expressions.$(\"field2\").isEqual(Expressions.lit(2L))));\n+    Optional<org.apache.iceberg.expressions.Expression> actual = FlinkFilters.convert(expr);\n+    Assert.assertTrue(\"Conversion should succeed\", actual.isPresent());\n+    Or or = (Or) actual.get();\n+    Or expected = (Or) org.apache.iceberg.expressions.Expressions.or(\n+        org.apache.iceberg.expressions.Expressions.equal(\"field1\", 1),\n+        org.apache.iceberg.expressions.Expressions.equal(\"field2\", 2L));\n+\n+    assertPredicatesMatch(expected.left(), or.left());\n+    assertPredicatesMatch(expected.right(), or.right());\n+  }\n+\n+  @Test\n+  public void testNot() {\n+    Expression expr = resolve(ApiExpressionUtils.unresolvedCall(\n+        BuiltInFunctionDefinitions.NOT, Expressions.$(\"field1\").isEqual(Expressions.lit(1))));\n+    Optional<org.apache.iceberg.expressions.Expression> actual = FlinkFilters.convert(expr);\n+    Assert.assertTrue(\"Conversion should succeed\", actual.isPresent());\n+    Not not = (Not) actual.get();\n+    Not expected = (Not) org.apache.iceberg.expressions.Expressions.not(\n+        org.apache.iceberg.expressions.Expressions.equal(\"field1\", 1));\n+\n+    Assert.assertEquals(\"Predicate operation should match\", expected.op(), not.op());\n+    assertPredicatesMatch((UnboundPredicate<?>) expected.child(), (UnboundPredicate<?>) not.child());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "217d05955b5719813d72c00aea8cf6e11eda38a9"}, "originalPosition": 296}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY5OTU3NDky", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-569957492", "createdAt": "2021-01-16T18:15:39Z", "commit": {"oid": "217d05955b5719813d72c00aea8cf6e11eda38a9"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNlQxODoxNTozOVrOIVGHvQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNlQxODoxNTozOVrOIVGHvQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODk5MTI5Mw==", "bodyText": "Style: this line should wrap arguments, not the method call. Can you change these cases to this style?\n    Assert.assertArrayEquals(\"Should produce the expected record\",\n        new Object[] {1, \"iceberg\", 10.0}, resultLike.get(0));", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r558991293", "createdAt": "2021-01-16T18:15:39Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkTableSource.java", "diffHunk": "@@ -75,32 +92,584 @@ public void clean() {\n \n   @Test\n   public void testLimitPushDown() {\n-    sql(\"INSERT INTO %s  VALUES (1,'a'),(2,'b')\", TABLE_NAME);\n-\n     String querySql = String.format(\"SELECT * FROM %s LIMIT 1\", TABLE_NAME);\n     String explain = getTableEnv().explainSql(querySql);\n     String expectedExplain = \"LimitPushDown : 1\";\n-    Assert.assertTrue(\"explain should contains LimitPushDown\", explain.contains(expectedExplain));\n+    Assert.assertTrue(\"Explain should contain LimitPushDown\", explain.contains(expectedExplain));\n     List<Object[]> result = sql(querySql);\n-    Assert.assertEquals(\"should have 1 record\", 1, result.size());\n-    Assert.assertArrayEquals(\"Should produce the expected records\", result.get(0), new Object[] {1, \"a\"});\n+    Assert.assertEquals(\"Should have 1 record\", 1, result.size());\n+    Assert.assertArrayEquals(\"Should produce the expected records\", new Object[] {1, \"iceberg\", 10.0}, result.get(0));\n \n     AssertHelpers.assertThrows(\"Invalid limit number: -1 \", SqlParserException.class,\n         () -> sql(\"SELECT * FROM %s LIMIT -1\", TABLE_NAME));\n \n-    Assert.assertEquals(\"should have 0 record\", 0, sql(\"SELECT * FROM %s LIMIT 0\", TABLE_NAME).size());\n+    Assert.assertEquals(\"Should have 0 record\", 0, sql(\"SELECT * FROM %s LIMIT 0\", TABLE_NAME).size());\n \n-    String sqlLimitExceed = String.format(\"SELECT * FROM %s LIMIT 3\", TABLE_NAME);\n+    String sqlLimitExceed = String.format(\"SELECT * FROM %s LIMIT 4\", TABLE_NAME);\n     List<Object[]> resultExceed = sql(sqlLimitExceed);\n-    Assert.assertEquals(\"should have 2 record\", 2, resultExceed.size());\n+    Assert.assertEquals(\"Should have 3 record\", 3, resultExceed.size());\n     List<Object[]> expectedList = Lists.newArrayList();\n-    expectedList.add(new Object[] {1, \"a\"});\n-    expectedList.add(new Object[] {2, \"b\"});\n-    Assert.assertArrayEquals(\"Should produce the expected records\", resultExceed.toArray(), expectedList.toArray());\n+    expectedList.add(new Object[] {1, \"iceberg\", 10.0});\n+    expectedList.add(new Object[] {2, \"b\", 20.0});\n+    expectedList.add(new Object[] {3, null, 30.0});\n+    Assert.assertArrayEquals(\"Should produce the expected records\", expectedList.toArray(), resultExceed.toArray());\n \n     String sqlMixed = String.format(\"SELECT * FROM %s WHERE id = 1 LIMIT 2\", TABLE_NAME);\n     List<Object[]> mixedResult = sql(sqlMixed);\n-    Assert.assertEquals(\"should have 1 record\", 1, mixedResult.size());\n-    Assert.assertArrayEquals(\"Should produce the expected records\", mixedResult.get(0), new Object[] {1, \"a\"});\n+    Assert.assertEquals(\"Should have 1 record\", 1, mixedResult.size());\n+    Assert.assertArrayEquals(\"Should produce the expected records\",\n+        new Object[] {1, \"iceberg\", 10.0}, mixedResult.get(0));\n+  }\n+\n+  @Test\n+  public void testNoFilterPushDown() {\n+    String sql = String.format(\"SELECT * FROM %s \", TABLE_NAME);\n+    String explain = getTableEnv().explainSql(sql);\n+    Assert.assertFalse(\"Explain should not contain FilterPushDown\", explain.contains(expectedFilterPushDownExplain));\n+    Assert.assertNull(\"Should not push down a filter\", lastScanEvent);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownEqual() {\n+    String sqlLiteralRight = String.format(\"SELECT * FROM %s WHERE id = 1 \", TABLE_NAME);\n+    String explain = getTableEnv().explainSql(sqlLiteralRight);\n+    String expectedFilter = \"ref(name=\\\"id\\\") == 1\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explain.contains(expectedFilter));\n+\n+    List<Object[]> result = sql(sqlLiteralRight);\n+    Assert.assertEquals(\"Should have 1 record\", 1, result.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", new Object[] {1, \"iceberg\", 10.0}, result.get(0));\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownEqualNull() {\n+    String sqlEqualNull = String.format(\"SELECT * FROM %s WHERE data = NULL \", TABLE_NAME);\n+    String explainEqualNull = getTableEnv().explainSql(sqlEqualNull);\n+    Assert.assertFalse(\"Explain should not contain FilterPushDown\",\n+        explainEqualNull.contains(expectedFilterPushDownExplain));\n+\n+    List<Object[]> result = sql(sqlEqualNull);\n+    Assert.assertEquals(\"Should have 0 record\", 0, result.size());\n+    Assert.assertNull(\"Should not push down a filter\", lastScanEvent);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownEqualLiteralOnLeft() {\n+    String sqlLiteralLeft = String.format(\"SELECT * FROM %s WHERE 1 = id \", TABLE_NAME);\n+    String explainLeft = getTableEnv().explainSql(sqlLiteralLeft);\n+    String expectedFilter = \"ref(name=\\\"id\\\") == 1\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainLeft.contains(expectedFilter));\n+\n+    List<Object[]> resultLeft = sql(sqlLiteralLeft);\n+    Assert.assertEquals(\"Should have 1 record\", 1, resultLeft.size());\n+    Assert\n+        .assertArrayEquals(\"Should produce the expected record\", new Object[] {1, \"iceberg\", 10.0}, resultLeft.get(0));\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownNoEqual() {\n+    String sqlNE = String.format(\"SELECT * FROM %s WHERE id <> 1 \", TABLE_NAME);\n+    String explainNE = getTableEnv().explainSql(sqlNE);\n+    String expectedFilter = \"ref(name=\\\"id\\\") != 1\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainNE.contains(expectedFilter));\n+\n+    List<Object[]> resultNE = sql(sqlNE);\n+    Assert.assertEquals(\"Should have 2 records\", 2, resultNE.size());\n+\n+    List<Object[]> expectedNE = Lists.newArrayList();\n+    expectedNE.add(new Object[] {2, \"b\", 20.0});\n+    expectedNE.add(new Object[] {3, null, 30.0});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", expectedNE.toArray(), resultNE.toArray());\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownNoEqualNull() {\n+    String sqlNotEqualNull = String.format(\"SELECT * FROM %s WHERE data <> NULL \", TABLE_NAME);\n+    String explainNotEqualNull = getTableEnv().explainSql(sqlNotEqualNull);\n+    Assert.assertFalse(\"Explain should not contain FilterPushDown\", explainNotEqualNull.contains(\n+        expectedFilterPushDownExplain));\n+\n+    List<Object[]> resultNE = sql(sqlNotEqualNull);\n+    Assert.assertEquals(\"Should have 0 records\", 0, resultNE.size());\n+    Assert.assertNull(\"Should not push down a filter\", lastScanEvent);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownAnd() {\n+    String sqlAnd = String.format(\"SELECT * FROM %s WHERE id = 1 AND data = 'iceberg' \", TABLE_NAME);\n+    String explainAnd = getTableEnv().explainSql(sqlAnd);\n+    String expectedFilter = \"ref(name=\\\"id\\\") == 1,ref(name=\\\"data\\\") == \\\"iceberg\\\"\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainAnd.contains(expectedFilter));\n+\n+    List<Object[]> resultAnd = sql(sqlAnd);\n+    Assert.assertEquals(\"Should have 1 record\", 1, resultAnd.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", new Object[] {1, \"iceberg\", 10.0}, resultAnd.get(0));\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    String expected = \"(ref(name=\\\"id\\\") == 1 and ref(name=\\\"data\\\") == \\\"iceberg\\\")\";\n+    Assert.assertEquals(\"Should contain the push down filter\", expected, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownOr() {\n+    String sqlOr = String.format(\"SELECT * FROM %s WHERE id = 1 OR data = 'b' \", TABLE_NAME);\n+    String explainOr = getTableEnv().explainSql(sqlOr);\n+    String expectedFilter = \"(ref(name=\\\"id\\\") == 1 or ref(name=\\\"data\\\") == \\\"b\\\")\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainOr.contains(expectedFilter));\n+\n+    List<Object[]> resultOr = sql(sqlOr);\n+    Assert.assertEquals(\"Should have 2 record\", 2, resultOr.size());\n+\n+    List<Object[]> expectedOR = Lists.newArrayList();\n+    expectedOR.add(new Object[] {1, \"iceberg\", 10.0});\n+    expectedOR.add(new Object[] {2, \"b\", 20.0});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", expectedOR.toArray(), resultOr.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownGreaterThan() {\n+    String sqlGT = String.format(\"SELECT * FROM %s WHERE id > 1 \", TABLE_NAME);\n+    String explainGT = getTableEnv().explainSql(sqlGT);\n+    String expectedFilter = \"ref(name=\\\"id\\\") > 1\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainGT.contains(expectedFilter));\n+\n+    List<Object[]> resultGT = sql(sqlGT);\n+    Assert.assertEquals(\"Should have 2 record\", 2, resultGT.size());\n+\n+    List<Object[]> expectedGT = Lists.newArrayList();\n+    expectedGT.add(new Object[] {2, \"b\", 20.0});\n+    expectedGT.add(new Object[] {3, null, 30.0});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", expectedGT.toArray(), resultGT.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownGreaterThanNull() {\n+    String sqlGT = String.format(\"SELECT * FROM %s WHERE data > null \", TABLE_NAME);\n+    String explainGT = getTableEnv().explainSql(sqlGT);\n+    Assert.assertFalse(\"Explain should not contain FilterPushDown\", explainGT.contains(expectedFilterPushDownExplain));\n+\n+    List<Object[]> resultGT = sql(sqlGT);\n+    Assert.assertEquals(\"Should have 0 record\", 0, resultGT.size());\n+    Assert.assertNull(\"Should not push down a filter\", lastScanEvent);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownGreaterThanLiteralOnLeft() {\n+    String sqlGT = String.format(\"SELECT * FROM %s WHERE 3 > id \", TABLE_NAME);\n+    String explainGT = getTableEnv().explainSql(sqlGT);\n+    String expectedFilter = \"ref(name=\\\"id\\\") < 3\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainGT.contains(expectedFilter));\n+\n+    List<Object[]> resultGT = sql(sqlGT);\n+    Assert.assertEquals(\"Should have 2 records\", 2, resultGT.size());\n+\n+    List<Object[]> expectedGT = Lists.newArrayList();\n+    expectedGT.add(new Object[] {1, \"iceberg\", 10.0});\n+    expectedGT.add(new Object[] {2, \"b\", 20.0});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", expectedGT.toArray(), resultGT.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownGreaterThanEqual() {\n+    String sqlGTE = String.format(\"SELECT * FROM %s WHERE id >= 2 \", TABLE_NAME);\n+    String explainGTE = getTableEnv().explainSql(sqlGTE);\n+    String expectedFilter = \"ref(name=\\\"id\\\") >= 2\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainGTE.contains(expectedFilter));\n+\n+    List<Object[]> resultGTE = sql(sqlGTE);\n+    Assert.assertEquals(\"Should have 2 records\", 2, resultGTE.size());\n+\n+    List<Object[]> expectedGTE = Lists.newArrayList();\n+    expectedGTE.add(new Object[] {2, \"b\", 20.0});\n+    expectedGTE.add(new Object[] {3, null, 30.0});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", expectedGTE.toArray(), resultGTE.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownGreaterThanEqualNull() {\n+    String sqlGTE = String.format(\"SELECT * FROM %s WHERE data >= null \", TABLE_NAME);\n+    String explainGTE = getTableEnv().explainSql(sqlGTE);\n+    Assert.assertFalse(\"Explain should not contain FilterPushDown\", explainGTE.contains(expectedFilterPushDownExplain));\n+\n+    List<Object[]> resultGT = sql(sqlGTE);\n+    Assert.assertEquals(\"Should have 0 record\", 0, resultGT.size());\n+    Assert.assertNull(\"Should not push down a filter\", lastScanEvent);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownGreaterThanEqualLiteralOnLeft() {\n+    String sqlGTE = String.format(\"SELECT * FROM %s WHERE 2 >= id \", TABLE_NAME);\n+    String explainGTE = getTableEnv().explainSql(sqlGTE);\n+    String expectedFilter = \"ref(name=\\\"id\\\") <= 2\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainGTE.contains(expectedFilter));\n+\n+    List<Object[]> resultGTE = sql(sqlGTE);\n+    Assert.assertEquals(\"Should have 2 records\", 2, resultGTE.size());\n+\n+    List<Object[]> expectedGTE = Lists.newArrayList();\n+    expectedGTE.add(new Object[] {1, \"iceberg\", 10.0});\n+    expectedGTE.add(new Object[] {2, \"b\", 20.0});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", expectedGTE.toArray(), resultGTE.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownLessThan() {\n+    String sqlLT = String.format(\"SELECT * FROM %s WHERE id < 2 \", TABLE_NAME);\n+    String explainLT = getTableEnv().explainSql(sqlLT);\n+    String expectedFilter = \"ref(name=\\\"id\\\") < 2\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainLT.contains(expectedFilter));\n+\n+    List<Object[]> resultLT = sql(sqlLT);\n+    Assert.assertEquals(\"Should have 1 record\", 1, resultLT.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", new Object[] {1, \"iceberg\", 10.0}, resultLT.get(0));\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownLessThanNull() {\n+    String sqlLT = String.format(\"SELECT * FROM %s WHERE data < null \", TABLE_NAME);\n+    String explainLT = getTableEnv().explainSql(sqlLT);\n+    Assert.assertFalse(\"Explain should not contain FilterPushDown\", explainLT.contains(expectedFilterPushDownExplain));\n+\n+    List<Object[]> resultGT = sql(sqlLT);\n+    Assert.assertEquals(\"Should have 0 record\", 0, resultGT.size());\n+    Assert.assertNull(\"Should not push down a filter\", lastScanEvent);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownLessThanLiteralOnLeft() {\n+    String sqlLT = String.format(\"SELECT * FROM %s WHERE 2 < id \", TABLE_NAME);\n+    String explainLT = getTableEnv().explainSql(sqlLT);\n+    String expectedFilter = \"ref(name=\\\"id\\\") > 2\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainLT.contains(expectedFilter));\n+\n+    List<Object[]> resultLT = sql(sqlLT);\n+    Assert.assertEquals(\"Should have 1 record\", 1, resultLT.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", new Object[] {3, null, 30.0}, resultLT.get(0));\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownLessThanEqual() {\n+    String sqlLTE = String.format(\"SELECT * FROM %s WHERE id <= 1 \", TABLE_NAME);\n+    String explainLTE = getTableEnv().explainSql(sqlLTE);\n+    String expectedFilter = \"ref(name=\\\"id\\\") <= 1\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainLTE.contains(expectedFilter));\n+\n+    List<Object[]> resultLTE = sql(sqlLTE);\n+    Assert.assertEquals(\"Should have 1 record\", 1, resultLTE.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", new Object[] {1, \"iceberg\", 10.0}, resultLTE.get(0));\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownLessThanEqualNull() {\n+    String sqlLTE = String.format(\"SELECT * FROM %s WHERE data <= null \", TABLE_NAME);\n+    String explainLTE = getTableEnv().explainSql(sqlLTE);\n+    Assert.assertFalse(\"Explain should not contain FilterPushDown\", explainLTE.contains(expectedFilterPushDownExplain));\n+\n+    List<Object[]> resultGT = sql(sqlLTE);\n+    Assert.assertEquals(\"Should have 0 record\", 0, resultGT.size());\n+    Assert.assertNull(\"Should not push down a filter\", lastScanEvent);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownLessThanEqualLiteralOnLeft() {\n+    String sqlLTE = String.format(\"SELECT * FROM %s WHERE 3 <= id  \", TABLE_NAME);\n+    String explainLTE = getTableEnv().explainSql(sqlLTE);\n+    String expectedFilter = \"ref(name=\\\"id\\\") >= 3\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainLTE.contains(expectedFilter));\n+\n+    List<Object[]> resultLTE = sql(sqlLTE);\n+    Assert.assertEquals(\"Should have 1 record\", 1, resultLTE.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", new Object[] {3, null, 30.0}, resultLTE.get(0));\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownIn() {\n+    String sqlIN = String.format(\"SELECT * FROM %s WHERE id IN (1,2) \", TABLE_NAME);\n+    String explainIN = getTableEnv().explainSql(sqlIN);\n+    String expectedFilter = \"(ref(name=\\\"id\\\") == 1 or ref(name=\\\"id\\\") == 2)\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainIN.contains(expectedFilter));\n+    List<Object[]> resultIN = sql(sqlIN);\n+    Assert.assertEquals(\"Should have 2 records\", 2, resultIN.size());\n+\n+    List<Object[]> expectedIN = Lists.newArrayList();\n+    expectedIN.add(new Object[] {1, \"iceberg\", 10.0});\n+    expectedIN.add(new Object[] {2, \"b\", 20.0});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", expectedIN.toArray(), resultIN.toArray());\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownInNull() {\n+    String sqlInNull = String.format(\"SELECT * FROM %s WHERE data IN ('iceberg',NULL) \", TABLE_NAME);\n+    String explainInNull = getTableEnv().explainSql(sqlInNull);\n+    Assert.assertFalse(\"Explain should not contain FilterPushDown\",\n+        explainInNull.contains(expectedFilterPushDownExplain));\n+\n+    List<Object[]> result = sql(sqlInNull);\n+    Assert.assertEquals(\"Should have 1 record\", 1, result.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", new Object[] {1, \"iceberg\", 10.0}, result.get(0));\n+    Assert.assertEquals(\"Should not push down a filter\", Expressions.alwaysTrue(), lastScanEvent.filter());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownNotIn() {\n+    String sqlNotIn = String.format(\"SELECT * FROM %s WHERE id NOT IN (3,2) \", TABLE_NAME);\n+    String explainNotIn = getTableEnv().explainSql(sqlNotIn);\n+    String expectedFilter = \"ref(name=\\\"id\\\") != 3,ref(name=\\\"id\\\") != 2\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainNotIn.contains(expectedFilter));\n+\n+    List<Object[]> resultNotIn = sql(sqlNotIn);\n+    Assert.assertEquals(\"Should have 1 record\", 1, resultNotIn.size());\n+    Assert\n+        .assertArrayEquals(\"Should produce the expected record\", new Object[] {1, \"iceberg\", 10.0}, resultNotIn.get(0));\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    String expectedScan = \"(ref(name=\\\"id\\\") != 3 and ref(name=\\\"id\\\") != 2)\";\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedScan, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownNotInNull() {\n+    String sqlNotInNull = String.format(\"SELECT * FROM %s WHERE id NOT IN (1,2,NULL) \", TABLE_NAME);\n+    String explainNotInNull = getTableEnv().explainSql(sqlNotInNull);\n+    Assert.assertFalse(\"Explain should not contain FilterPushDown\",\n+        explainNotInNull.contains(expectedFilterPushDownExplain));\n+    List<Object[]> resultGT = sql(sqlNotInNull);\n+    Assert.assertEquals(\"Should have 0 record\", 0, resultGT.size());\n+    Assert.assertEquals(\"Should not push down a filter\", Expressions.alwaysTrue(), lastScanEvent.filter());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownIsNotNull() {\n+    String sqlNotNull = String.format(\"SELECT * FROM %s WHERE data IS NOT NULL\", TABLE_NAME);\n+    String explainNotNull = getTableEnv().explainSql(sqlNotNull);\n+    String expectedFilter = \"not_null(ref(name=\\\"data\\\"))\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainNotNull.contains(expectedFilter));\n+\n+    List<Object[]> resultNotNull = sql(sqlNotNull);\n+    Assert.assertEquals(\"Should have 2 record\", 2, resultNotNull.size());\n+\n+    List<Object[]> expected = Lists.newArrayList();\n+    expected.add(new Object[] {1, \"iceberg\", 10.0});\n+    expected.add(new Object[] {2, \"b\", 20.0});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", expected.toArray(), resultNotNull.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownIsNull() {\n+    String sqlNull = String.format(\"SELECT * FROM %s WHERE data IS  NULL\", TABLE_NAME);\n+    String explainNull = getTableEnv().explainSql(sqlNull);\n+    String expectedFilter = \"is_null(ref(name=\\\"data\\\"))\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainNull.contains(expectedFilter));\n+\n+    List<Object[]> resultNull = sql(sqlNull);\n+    Assert.assertEquals(\"Should have 1 record\", 1, resultNull.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", new Object[] {3, null, 30.0}, resultNull.get(0));\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownNot() {\n+    String sqlNot = String.format(\"SELECT * FROM %s WHERE NOT (id = 1 OR id = 2 ) \", TABLE_NAME);\n+    String explainNot = getTableEnv().explainSql(sqlNot);\n+    String expectedFilter = \"ref(name=\\\"id\\\") != 1,ref(name=\\\"id\\\") != 2\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainNot.contains(expectedFilter));\n+\n+    List<Object[]> resultNot = sql(sqlNot);\n+    Assert.assertEquals(\"Should have 1 record\", 1, resultNot.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", new Object[] {3, null, 30.0}, resultNot.get(0));\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    expectedFilter = \"(ref(name=\\\"id\\\") != 1 and ref(name=\\\"id\\\") != 2)\";\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownBetween() {\n+    String sqlBetween = String.format(\"SELECT * FROM %s WHERE id BETWEEN 1 AND 2 \", TABLE_NAME);\n+    String explainBetween = getTableEnv().explainSql(sqlBetween);\n+    String expectedFilter = \"ref(name=\\\"id\\\") >= 1,ref(name=\\\"id\\\") <= 2\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainBetween.contains(expectedFilter));\n+\n+    List<Object[]> resultBetween = sql(sqlBetween);\n+    Assert.assertEquals(\"Should have 2 record\", 2, resultBetween.size());\n+\n+    List<Object[]> expectedBetween = Lists.newArrayList();\n+    expectedBetween.add(new Object[] {1, \"iceberg\", 10.0});\n+    expectedBetween.add(new Object[] {2, \"b\", 20.0});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", expectedBetween.toArray(), resultBetween.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    String expected = \"(ref(name=\\\"id\\\") >= 1 and ref(name=\\\"id\\\") <= 2)\";\n+    Assert.assertEquals(\"Should contain the push down filter\", expected, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownNotBetween() {\n+    String sqlNotBetween = String.format(\"SELECT * FROM %s WHERE id  NOT BETWEEN 2 AND 3 \", TABLE_NAME);\n+    String explainNotBetween = getTableEnv().explainSql(sqlNotBetween);\n+    String expectedFilter = \"(ref(name=\\\"id\\\") < 2 or ref(name=\\\"id\\\") > 3)\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainNotBetween.contains(expectedFilter));\n+\n+    List<Object[]> resultNotBetween = sql(sqlNotBetween);\n+    Assert.assertEquals(\"Should have 1 record\", 1, resultNotBetween.size());\n+    Assert.assertArrayEquals(\"the not between Should produce the expected record\", resultNotBetween.get(0),\n+        new Object[] {1, \"iceberg\", 10.0});\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownLike() {\n+    String sqlLike = \"SELECT * FROM \" + TABLE_NAME + \" WHERE data LIKE 'ice%' \";\n+    String explainLike = getTableEnv().explainSql(sqlLike);\n+    String expectedFilter = \"ref(name=\\\"data\\\") startsWith \\\"\\\"ice\\\"\\\"\";\n+    Assert.assertTrue(\"the like sql Explain should contain the push down filter\", explainLike.contains(expectedFilter));\n+\n+    sqlLike = \"SELECT * FROM \" + TABLE_NAME + \" WHERE data LIKE 'ice%%' \";\n+    List<Object[]> resultLike = sql(sqlLike);\n+    Assert.assertEquals(\"Should have 1 record\", 1, resultLike.size());\n+    Assert.assertArrayEquals(\"The like result should produce the expected record\",\n+        new Object[] {1, \"iceberg\", 10.0}, resultLike.get(0));\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterNotPushDownLike() {\n+    String sqlNoPushDown = \"SELECT * FROM \" + TABLE_NAME + \" WHERE data LIKE '%i' \";\n+    String explainNoPushDown = getTableEnv().explainSql(sqlNoPushDown);\n+    Assert.assertFalse(\"Explain should not contain FilterPushDown\",\n+        explainNoPushDown.contains(expectedFilterPushDownExplain));\n+    sqlNoPushDown = \"SELECT * FROM \" + TABLE_NAME + \" WHERE data LIKE '%%i' \";\n+    List<Object[]> resultLike = sql(sqlNoPushDown);\n+    Assert.assertEquals(\"Should have 1 record\", 0, resultLike.size());\n+    Assert.assertEquals(\"Should not push down a filter\", Expressions.alwaysTrue(), lastScanEvent.filter());\n+\n+    sqlNoPushDown = \"SELECT * FROM \" + TABLE_NAME + \" WHERE data LIKE '%i%' \";\n+    explainNoPushDown = getTableEnv().explainSql(sqlNoPushDown);\n+    Assert.assertFalse(\"Explain should not contain FilterPushDown\",\n+        explainNoPushDown.contains(expectedFilterPushDownExplain));\n+    sqlNoPushDown = \"SELECT * FROM \" + TABLE_NAME + \" WHERE data LIKE '%%i%%' \";\n+    resultLike = sql(sqlNoPushDown);\n+    Assert.assertEquals(\"Should have 1 record\", 1, resultLike.size());\n+    Assert\n+        .assertArrayEquals(\"Should produce the expected record\", new Object[] {1, \"iceberg\", 10.0}, resultLike.get(0));\n+    Assert.assertEquals(\"Should not push down a filter\", Expressions.alwaysTrue(), lastScanEvent.filter());\n+\n+    sqlNoPushDown = \"SELECT * FROM  \" + TABLE_NAME + \"  WHERE data LIKE '%ice%g' \";\n+    explainNoPushDown = getTableEnv().explainSql(sqlNoPushDown);\n+    Assert.assertFalse(\"Explain should not contain FilterPushDown\",\n+        explainNoPushDown.contains(expectedFilterPushDownExplain));\n+    sqlNoPushDown = \"SELECT * FROM  \" + TABLE_NAME + \"  WHERE data LIKE '%%ice%%g' \";\n+    resultLike = sql(sqlNoPushDown);\n+    Assert.assertEquals(\"Should have 1 record\", 1, resultLike.size());\n+    Assert\n+        .assertArrayEquals(\"Should produce the expected record\", new Object[] {1, \"iceberg\", 10.0}, resultLike.get(0));\n+    Assert.assertEquals(\"Should not push down a filter\", Expressions.alwaysTrue(), lastScanEvent.filter());\n+\n+    sqlNoPushDown = \"SELECT * FROM  \" + TABLE_NAME + \"  WHERE data LIKE '%' \";\n+    explainNoPushDown = getTableEnv().explainSql(sqlNoPushDown);\n+    Assert.assertFalse(\"Explain should not contain FilterPushDown\",\n+        explainNoPushDown.contains(expectedFilterPushDownExplain));\n+    sqlNoPushDown = \"SELECT * FROM  \" + TABLE_NAME + \"  WHERE data LIKE '%%' \";\n+    resultLike = sql(sqlNoPushDown);\n+    Assert.assertEquals(\"Should have 2 records\", 2, resultLike.size());\n+    List<Object[]> expectedRecords = Lists.newArrayList();\n+    expectedRecords.add(new Object[] {1, \"iceberg\", 10.0});\n+    expectedRecords.add(new Object[] {2, \"b\", 20.0});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", expectedRecords.toArray(), resultLike.toArray());\n+    Assert.assertEquals(\"Should not push down a filter\", Expressions.alwaysTrue(), lastScanEvent.filter());\n+\n+    sqlNoPushDown = \"SELECT * FROM  \" + TABLE_NAME + \"  WHERE data LIKE 'iceber_' \";\n+    explainNoPushDown = getTableEnv().explainSql(sqlNoPushDown);\n+    Assert.assertFalse(\"Explain should not contain FilterPushDown\",\n+        explainNoPushDown.contains(expectedFilterPushDownExplain));\n+    resultLike = sql(sqlNoPushDown);\n+    Assert.assertEquals(\"Should have 1 record\", 1, resultLike.size());\n+    Assert\n+        .assertArrayEquals(\"Should produce the expected record\", new Object[] {1, \"iceberg\", 10.0}, resultLike.get(0));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "217d05955b5719813d72c00aea8cf6e11eda38a9"}, "originalPosition": 610}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY5OTU4NDE5", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-569958419", "createdAt": "2021-01-16T18:30:01Z", "commit": {"oid": "217d05955b5719813d72c00aea8cf6e11eda38a9"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNlQxODozMDowMVrOIVGZyQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNlQxODozMDowMVrOIVGZyQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1ODk5NTkxMw==", "bodyText": "I think this is missing a case for i%g. It has a case for %ice%g, but I think it should test both.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r558995913", "createdAt": "2021-01-16T18:30:01Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkTableSource.java", "diffHunk": "@@ -75,32 +92,584 @@ public void clean() {\n \n   @Test\n   public void testLimitPushDown() {\n-    sql(\"INSERT INTO %s  VALUES (1,'a'),(2,'b')\", TABLE_NAME);\n-\n     String querySql = String.format(\"SELECT * FROM %s LIMIT 1\", TABLE_NAME);\n     String explain = getTableEnv().explainSql(querySql);\n     String expectedExplain = \"LimitPushDown : 1\";\n-    Assert.assertTrue(\"explain should contains LimitPushDown\", explain.contains(expectedExplain));\n+    Assert.assertTrue(\"Explain should contain LimitPushDown\", explain.contains(expectedExplain));\n     List<Object[]> result = sql(querySql);\n-    Assert.assertEquals(\"should have 1 record\", 1, result.size());\n-    Assert.assertArrayEquals(\"Should produce the expected records\", result.get(0), new Object[] {1, \"a\"});\n+    Assert.assertEquals(\"Should have 1 record\", 1, result.size());\n+    Assert.assertArrayEquals(\"Should produce the expected records\", new Object[] {1, \"iceberg\", 10.0}, result.get(0));\n \n     AssertHelpers.assertThrows(\"Invalid limit number: -1 \", SqlParserException.class,\n         () -> sql(\"SELECT * FROM %s LIMIT -1\", TABLE_NAME));\n \n-    Assert.assertEquals(\"should have 0 record\", 0, sql(\"SELECT * FROM %s LIMIT 0\", TABLE_NAME).size());\n+    Assert.assertEquals(\"Should have 0 record\", 0, sql(\"SELECT * FROM %s LIMIT 0\", TABLE_NAME).size());\n \n-    String sqlLimitExceed = String.format(\"SELECT * FROM %s LIMIT 3\", TABLE_NAME);\n+    String sqlLimitExceed = String.format(\"SELECT * FROM %s LIMIT 4\", TABLE_NAME);\n     List<Object[]> resultExceed = sql(sqlLimitExceed);\n-    Assert.assertEquals(\"should have 2 record\", 2, resultExceed.size());\n+    Assert.assertEquals(\"Should have 3 record\", 3, resultExceed.size());\n     List<Object[]> expectedList = Lists.newArrayList();\n-    expectedList.add(new Object[] {1, \"a\"});\n-    expectedList.add(new Object[] {2, \"b\"});\n-    Assert.assertArrayEquals(\"Should produce the expected records\", resultExceed.toArray(), expectedList.toArray());\n+    expectedList.add(new Object[] {1, \"iceberg\", 10.0});\n+    expectedList.add(new Object[] {2, \"b\", 20.0});\n+    expectedList.add(new Object[] {3, null, 30.0});\n+    Assert.assertArrayEquals(\"Should produce the expected records\", expectedList.toArray(), resultExceed.toArray());\n \n     String sqlMixed = String.format(\"SELECT * FROM %s WHERE id = 1 LIMIT 2\", TABLE_NAME);\n     List<Object[]> mixedResult = sql(sqlMixed);\n-    Assert.assertEquals(\"should have 1 record\", 1, mixedResult.size());\n-    Assert.assertArrayEquals(\"Should produce the expected records\", mixedResult.get(0), new Object[] {1, \"a\"});\n+    Assert.assertEquals(\"Should have 1 record\", 1, mixedResult.size());\n+    Assert.assertArrayEquals(\"Should produce the expected records\",\n+        new Object[] {1, \"iceberg\", 10.0}, mixedResult.get(0));\n+  }\n+\n+  @Test\n+  public void testNoFilterPushDown() {\n+    String sql = String.format(\"SELECT * FROM %s \", TABLE_NAME);\n+    String explain = getTableEnv().explainSql(sql);\n+    Assert.assertFalse(\"Explain should not contain FilterPushDown\", explain.contains(expectedFilterPushDownExplain));\n+    Assert.assertNull(\"Should not push down a filter\", lastScanEvent);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownEqual() {\n+    String sqlLiteralRight = String.format(\"SELECT * FROM %s WHERE id = 1 \", TABLE_NAME);\n+    String explain = getTableEnv().explainSql(sqlLiteralRight);\n+    String expectedFilter = \"ref(name=\\\"id\\\") == 1\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explain.contains(expectedFilter));\n+\n+    List<Object[]> result = sql(sqlLiteralRight);\n+    Assert.assertEquals(\"Should have 1 record\", 1, result.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", new Object[] {1, \"iceberg\", 10.0}, result.get(0));\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownEqualNull() {\n+    String sqlEqualNull = String.format(\"SELECT * FROM %s WHERE data = NULL \", TABLE_NAME);\n+    String explainEqualNull = getTableEnv().explainSql(sqlEqualNull);\n+    Assert.assertFalse(\"Explain should not contain FilterPushDown\",\n+        explainEqualNull.contains(expectedFilterPushDownExplain));\n+\n+    List<Object[]> result = sql(sqlEqualNull);\n+    Assert.assertEquals(\"Should have 0 record\", 0, result.size());\n+    Assert.assertNull(\"Should not push down a filter\", lastScanEvent);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownEqualLiteralOnLeft() {\n+    String sqlLiteralLeft = String.format(\"SELECT * FROM %s WHERE 1 = id \", TABLE_NAME);\n+    String explainLeft = getTableEnv().explainSql(sqlLiteralLeft);\n+    String expectedFilter = \"ref(name=\\\"id\\\") == 1\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainLeft.contains(expectedFilter));\n+\n+    List<Object[]> resultLeft = sql(sqlLiteralLeft);\n+    Assert.assertEquals(\"Should have 1 record\", 1, resultLeft.size());\n+    Assert\n+        .assertArrayEquals(\"Should produce the expected record\", new Object[] {1, \"iceberg\", 10.0}, resultLeft.get(0));\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownNoEqual() {\n+    String sqlNE = String.format(\"SELECT * FROM %s WHERE id <> 1 \", TABLE_NAME);\n+    String explainNE = getTableEnv().explainSql(sqlNE);\n+    String expectedFilter = \"ref(name=\\\"id\\\") != 1\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainNE.contains(expectedFilter));\n+\n+    List<Object[]> resultNE = sql(sqlNE);\n+    Assert.assertEquals(\"Should have 2 records\", 2, resultNE.size());\n+\n+    List<Object[]> expectedNE = Lists.newArrayList();\n+    expectedNE.add(new Object[] {2, \"b\", 20.0});\n+    expectedNE.add(new Object[] {3, null, 30.0});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", expectedNE.toArray(), resultNE.toArray());\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownNoEqualNull() {\n+    String sqlNotEqualNull = String.format(\"SELECT * FROM %s WHERE data <> NULL \", TABLE_NAME);\n+    String explainNotEqualNull = getTableEnv().explainSql(sqlNotEqualNull);\n+    Assert.assertFalse(\"Explain should not contain FilterPushDown\", explainNotEqualNull.contains(\n+        expectedFilterPushDownExplain));\n+\n+    List<Object[]> resultNE = sql(sqlNotEqualNull);\n+    Assert.assertEquals(\"Should have 0 records\", 0, resultNE.size());\n+    Assert.assertNull(\"Should not push down a filter\", lastScanEvent);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownAnd() {\n+    String sqlAnd = String.format(\"SELECT * FROM %s WHERE id = 1 AND data = 'iceberg' \", TABLE_NAME);\n+    String explainAnd = getTableEnv().explainSql(sqlAnd);\n+    String expectedFilter = \"ref(name=\\\"id\\\") == 1,ref(name=\\\"data\\\") == \\\"iceberg\\\"\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainAnd.contains(expectedFilter));\n+\n+    List<Object[]> resultAnd = sql(sqlAnd);\n+    Assert.assertEquals(\"Should have 1 record\", 1, resultAnd.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", new Object[] {1, \"iceberg\", 10.0}, resultAnd.get(0));\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    String expected = \"(ref(name=\\\"id\\\") == 1 and ref(name=\\\"data\\\") == \\\"iceberg\\\")\";\n+    Assert.assertEquals(\"Should contain the push down filter\", expected, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownOr() {\n+    String sqlOr = String.format(\"SELECT * FROM %s WHERE id = 1 OR data = 'b' \", TABLE_NAME);\n+    String explainOr = getTableEnv().explainSql(sqlOr);\n+    String expectedFilter = \"(ref(name=\\\"id\\\") == 1 or ref(name=\\\"data\\\") == \\\"b\\\")\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainOr.contains(expectedFilter));\n+\n+    List<Object[]> resultOr = sql(sqlOr);\n+    Assert.assertEquals(\"Should have 2 record\", 2, resultOr.size());\n+\n+    List<Object[]> expectedOR = Lists.newArrayList();\n+    expectedOR.add(new Object[] {1, \"iceberg\", 10.0});\n+    expectedOR.add(new Object[] {2, \"b\", 20.0});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", expectedOR.toArray(), resultOr.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownGreaterThan() {\n+    String sqlGT = String.format(\"SELECT * FROM %s WHERE id > 1 \", TABLE_NAME);\n+    String explainGT = getTableEnv().explainSql(sqlGT);\n+    String expectedFilter = \"ref(name=\\\"id\\\") > 1\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainGT.contains(expectedFilter));\n+\n+    List<Object[]> resultGT = sql(sqlGT);\n+    Assert.assertEquals(\"Should have 2 record\", 2, resultGT.size());\n+\n+    List<Object[]> expectedGT = Lists.newArrayList();\n+    expectedGT.add(new Object[] {2, \"b\", 20.0});\n+    expectedGT.add(new Object[] {3, null, 30.0});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", expectedGT.toArray(), resultGT.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownGreaterThanNull() {\n+    String sqlGT = String.format(\"SELECT * FROM %s WHERE data > null \", TABLE_NAME);\n+    String explainGT = getTableEnv().explainSql(sqlGT);\n+    Assert.assertFalse(\"Explain should not contain FilterPushDown\", explainGT.contains(expectedFilterPushDownExplain));\n+\n+    List<Object[]> resultGT = sql(sqlGT);\n+    Assert.assertEquals(\"Should have 0 record\", 0, resultGT.size());\n+    Assert.assertNull(\"Should not push down a filter\", lastScanEvent);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownGreaterThanLiteralOnLeft() {\n+    String sqlGT = String.format(\"SELECT * FROM %s WHERE 3 > id \", TABLE_NAME);\n+    String explainGT = getTableEnv().explainSql(sqlGT);\n+    String expectedFilter = \"ref(name=\\\"id\\\") < 3\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainGT.contains(expectedFilter));\n+\n+    List<Object[]> resultGT = sql(sqlGT);\n+    Assert.assertEquals(\"Should have 2 records\", 2, resultGT.size());\n+\n+    List<Object[]> expectedGT = Lists.newArrayList();\n+    expectedGT.add(new Object[] {1, \"iceberg\", 10.0});\n+    expectedGT.add(new Object[] {2, \"b\", 20.0});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", expectedGT.toArray(), resultGT.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownGreaterThanEqual() {\n+    String sqlGTE = String.format(\"SELECT * FROM %s WHERE id >= 2 \", TABLE_NAME);\n+    String explainGTE = getTableEnv().explainSql(sqlGTE);\n+    String expectedFilter = \"ref(name=\\\"id\\\") >= 2\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainGTE.contains(expectedFilter));\n+\n+    List<Object[]> resultGTE = sql(sqlGTE);\n+    Assert.assertEquals(\"Should have 2 records\", 2, resultGTE.size());\n+\n+    List<Object[]> expectedGTE = Lists.newArrayList();\n+    expectedGTE.add(new Object[] {2, \"b\", 20.0});\n+    expectedGTE.add(new Object[] {3, null, 30.0});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", expectedGTE.toArray(), resultGTE.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownGreaterThanEqualNull() {\n+    String sqlGTE = String.format(\"SELECT * FROM %s WHERE data >= null \", TABLE_NAME);\n+    String explainGTE = getTableEnv().explainSql(sqlGTE);\n+    Assert.assertFalse(\"Explain should not contain FilterPushDown\", explainGTE.contains(expectedFilterPushDownExplain));\n+\n+    List<Object[]> resultGT = sql(sqlGTE);\n+    Assert.assertEquals(\"Should have 0 record\", 0, resultGT.size());\n+    Assert.assertNull(\"Should not push down a filter\", lastScanEvent);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownGreaterThanEqualLiteralOnLeft() {\n+    String sqlGTE = String.format(\"SELECT * FROM %s WHERE 2 >= id \", TABLE_NAME);\n+    String explainGTE = getTableEnv().explainSql(sqlGTE);\n+    String expectedFilter = \"ref(name=\\\"id\\\") <= 2\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainGTE.contains(expectedFilter));\n+\n+    List<Object[]> resultGTE = sql(sqlGTE);\n+    Assert.assertEquals(\"Should have 2 records\", 2, resultGTE.size());\n+\n+    List<Object[]> expectedGTE = Lists.newArrayList();\n+    expectedGTE.add(new Object[] {1, \"iceberg\", 10.0});\n+    expectedGTE.add(new Object[] {2, \"b\", 20.0});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", expectedGTE.toArray(), resultGTE.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownLessThan() {\n+    String sqlLT = String.format(\"SELECT * FROM %s WHERE id < 2 \", TABLE_NAME);\n+    String explainLT = getTableEnv().explainSql(sqlLT);\n+    String expectedFilter = \"ref(name=\\\"id\\\") < 2\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainLT.contains(expectedFilter));\n+\n+    List<Object[]> resultLT = sql(sqlLT);\n+    Assert.assertEquals(\"Should have 1 record\", 1, resultLT.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", new Object[] {1, \"iceberg\", 10.0}, resultLT.get(0));\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownLessThanNull() {\n+    String sqlLT = String.format(\"SELECT * FROM %s WHERE data < null \", TABLE_NAME);\n+    String explainLT = getTableEnv().explainSql(sqlLT);\n+    Assert.assertFalse(\"Explain should not contain FilterPushDown\", explainLT.contains(expectedFilterPushDownExplain));\n+\n+    List<Object[]> resultGT = sql(sqlLT);\n+    Assert.assertEquals(\"Should have 0 record\", 0, resultGT.size());\n+    Assert.assertNull(\"Should not push down a filter\", lastScanEvent);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownLessThanLiteralOnLeft() {\n+    String sqlLT = String.format(\"SELECT * FROM %s WHERE 2 < id \", TABLE_NAME);\n+    String explainLT = getTableEnv().explainSql(sqlLT);\n+    String expectedFilter = \"ref(name=\\\"id\\\") > 2\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainLT.contains(expectedFilter));\n+\n+    List<Object[]> resultLT = sql(sqlLT);\n+    Assert.assertEquals(\"Should have 1 record\", 1, resultLT.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", new Object[] {3, null, 30.0}, resultLT.get(0));\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownLessThanEqual() {\n+    String sqlLTE = String.format(\"SELECT * FROM %s WHERE id <= 1 \", TABLE_NAME);\n+    String explainLTE = getTableEnv().explainSql(sqlLTE);\n+    String expectedFilter = \"ref(name=\\\"id\\\") <= 1\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainLTE.contains(expectedFilter));\n+\n+    List<Object[]> resultLTE = sql(sqlLTE);\n+    Assert.assertEquals(\"Should have 1 record\", 1, resultLTE.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", new Object[] {1, \"iceberg\", 10.0}, resultLTE.get(0));\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownLessThanEqualNull() {\n+    String sqlLTE = String.format(\"SELECT * FROM %s WHERE data <= null \", TABLE_NAME);\n+    String explainLTE = getTableEnv().explainSql(sqlLTE);\n+    Assert.assertFalse(\"Explain should not contain FilterPushDown\", explainLTE.contains(expectedFilterPushDownExplain));\n+\n+    List<Object[]> resultGT = sql(sqlLTE);\n+    Assert.assertEquals(\"Should have 0 record\", 0, resultGT.size());\n+    Assert.assertNull(\"Should not push down a filter\", lastScanEvent);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownLessThanEqualLiteralOnLeft() {\n+    String sqlLTE = String.format(\"SELECT * FROM %s WHERE 3 <= id  \", TABLE_NAME);\n+    String explainLTE = getTableEnv().explainSql(sqlLTE);\n+    String expectedFilter = \"ref(name=\\\"id\\\") >= 3\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainLTE.contains(expectedFilter));\n+\n+    List<Object[]> resultLTE = sql(sqlLTE);\n+    Assert.assertEquals(\"Should have 1 record\", 1, resultLTE.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", new Object[] {3, null, 30.0}, resultLTE.get(0));\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownIn() {\n+    String sqlIN = String.format(\"SELECT * FROM %s WHERE id IN (1,2) \", TABLE_NAME);\n+    String explainIN = getTableEnv().explainSql(sqlIN);\n+    String expectedFilter = \"(ref(name=\\\"id\\\") == 1 or ref(name=\\\"id\\\") == 2)\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainIN.contains(expectedFilter));\n+    List<Object[]> resultIN = sql(sqlIN);\n+    Assert.assertEquals(\"Should have 2 records\", 2, resultIN.size());\n+\n+    List<Object[]> expectedIN = Lists.newArrayList();\n+    expectedIN.add(new Object[] {1, \"iceberg\", 10.0});\n+    expectedIN.add(new Object[] {2, \"b\", 20.0});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", expectedIN.toArray(), resultIN.toArray());\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownInNull() {\n+    String sqlInNull = String.format(\"SELECT * FROM %s WHERE data IN ('iceberg',NULL) \", TABLE_NAME);\n+    String explainInNull = getTableEnv().explainSql(sqlInNull);\n+    Assert.assertFalse(\"Explain should not contain FilterPushDown\",\n+        explainInNull.contains(expectedFilterPushDownExplain));\n+\n+    List<Object[]> result = sql(sqlInNull);\n+    Assert.assertEquals(\"Should have 1 record\", 1, result.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", new Object[] {1, \"iceberg\", 10.0}, result.get(0));\n+    Assert.assertEquals(\"Should not push down a filter\", Expressions.alwaysTrue(), lastScanEvent.filter());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownNotIn() {\n+    String sqlNotIn = String.format(\"SELECT * FROM %s WHERE id NOT IN (3,2) \", TABLE_NAME);\n+    String explainNotIn = getTableEnv().explainSql(sqlNotIn);\n+    String expectedFilter = \"ref(name=\\\"id\\\") != 3,ref(name=\\\"id\\\") != 2\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainNotIn.contains(expectedFilter));\n+\n+    List<Object[]> resultNotIn = sql(sqlNotIn);\n+    Assert.assertEquals(\"Should have 1 record\", 1, resultNotIn.size());\n+    Assert\n+        .assertArrayEquals(\"Should produce the expected record\", new Object[] {1, \"iceberg\", 10.0}, resultNotIn.get(0));\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    String expectedScan = \"(ref(name=\\\"id\\\") != 3 and ref(name=\\\"id\\\") != 2)\";\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedScan, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownNotInNull() {\n+    String sqlNotInNull = String.format(\"SELECT * FROM %s WHERE id NOT IN (1,2,NULL) \", TABLE_NAME);\n+    String explainNotInNull = getTableEnv().explainSql(sqlNotInNull);\n+    Assert.assertFalse(\"Explain should not contain FilterPushDown\",\n+        explainNotInNull.contains(expectedFilterPushDownExplain));\n+    List<Object[]> resultGT = sql(sqlNotInNull);\n+    Assert.assertEquals(\"Should have 0 record\", 0, resultGT.size());\n+    Assert.assertEquals(\"Should not push down a filter\", Expressions.alwaysTrue(), lastScanEvent.filter());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownIsNotNull() {\n+    String sqlNotNull = String.format(\"SELECT * FROM %s WHERE data IS NOT NULL\", TABLE_NAME);\n+    String explainNotNull = getTableEnv().explainSql(sqlNotNull);\n+    String expectedFilter = \"not_null(ref(name=\\\"data\\\"))\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainNotNull.contains(expectedFilter));\n+\n+    List<Object[]> resultNotNull = sql(sqlNotNull);\n+    Assert.assertEquals(\"Should have 2 record\", 2, resultNotNull.size());\n+\n+    List<Object[]> expected = Lists.newArrayList();\n+    expected.add(new Object[] {1, \"iceberg\", 10.0});\n+    expected.add(new Object[] {2, \"b\", 20.0});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", expected.toArray(), resultNotNull.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownIsNull() {\n+    String sqlNull = String.format(\"SELECT * FROM %s WHERE data IS  NULL\", TABLE_NAME);\n+    String explainNull = getTableEnv().explainSql(sqlNull);\n+    String expectedFilter = \"is_null(ref(name=\\\"data\\\"))\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainNull.contains(expectedFilter));\n+\n+    List<Object[]> resultNull = sql(sqlNull);\n+    Assert.assertEquals(\"Should have 1 record\", 1, resultNull.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", new Object[] {3, null, 30.0}, resultNull.get(0));\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownNot() {\n+    String sqlNot = String.format(\"SELECT * FROM %s WHERE NOT (id = 1 OR id = 2 ) \", TABLE_NAME);\n+    String explainNot = getTableEnv().explainSql(sqlNot);\n+    String expectedFilter = \"ref(name=\\\"id\\\") != 1,ref(name=\\\"id\\\") != 2\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainNot.contains(expectedFilter));\n+\n+    List<Object[]> resultNot = sql(sqlNot);\n+    Assert.assertEquals(\"Should have 1 record\", 1, resultNot.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", new Object[] {3, null, 30.0}, resultNot.get(0));\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    expectedFilter = \"(ref(name=\\\"id\\\") != 1 and ref(name=\\\"id\\\") != 2)\";\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownBetween() {\n+    String sqlBetween = String.format(\"SELECT * FROM %s WHERE id BETWEEN 1 AND 2 \", TABLE_NAME);\n+    String explainBetween = getTableEnv().explainSql(sqlBetween);\n+    String expectedFilter = \"ref(name=\\\"id\\\") >= 1,ref(name=\\\"id\\\") <= 2\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainBetween.contains(expectedFilter));\n+\n+    List<Object[]> resultBetween = sql(sqlBetween);\n+    Assert.assertEquals(\"Should have 2 record\", 2, resultBetween.size());\n+\n+    List<Object[]> expectedBetween = Lists.newArrayList();\n+    expectedBetween.add(new Object[] {1, \"iceberg\", 10.0});\n+    expectedBetween.add(new Object[] {2, \"b\", 20.0});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", expectedBetween.toArray(), resultBetween.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    String expected = \"(ref(name=\\\"id\\\") >= 1 and ref(name=\\\"id\\\") <= 2)\";\n+    Assert.assertEquals(\"Should contain the push down filter\", expected, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownNotBetween() {\n+    String sqlNotBetween = String.format(\"SELECT * FROM %s WHERE id  NOT BETWEEN 2 AND 3 \", TABLE_NAME);\n+    String explainNotBetween = getTableEnv().explainSql(sqlNotBetween);\n+    String expectedFilter = \"(ref(name=\\\"id\\\") < 2 or ref(name=\\\"id\\\") > 3)\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainNotBetween.contains(expectedFilter));\n+\n+    List<Object[]> resultNotBetween = sql(sqlNotBetween);\n+    Assert.assertEquals(\"Should have 1 record\", 1, resultNotBetween.size());\n+    Assert.assertArrayEquals(\"the not between Should produce the expected record\", resultNotBetween.get(0),\n+        new Object[] {1, \"iceberg\", 10.0});\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownLike() {\n+    String sqlLike = \"SELECT * FROM \" + TABLE_NAME + \" WHERE data LIKE 'ice%' \";\n+    String explainLike = getTableEnv().explainSql(sqlLike);\n+    String expectedFilter = \"ref(name=\\\"data\\\") startsWith \\\"\\\"ice\\\"\\\"\";\n+    Assert.assertTrue(\"the like sql Explain should contain the push down filter\", explainLike.contains(expectedFilter));\n+\n+    sqlLike = \"SELECT * FROM \" + TABLE_NAME + \" WHERE data LIKE 'ice%%' \";\n+    List<Object[]> resultLike = sql(sqlLike);\n+    Assert.assertEquals(\"Should have 1 record\", 1, resultLike.size());\n+    Assert.assertArrayEquals(\"The like result should produce the expected record\",\n+        new Object[] {1, \"iceberg\", 10.0}, resultLike.get(0));\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterNotPushDownLike() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "217d05955b5719813d72c00aea8cf6e11eda38a9"}, "originalPosition": 558}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY5OTU5NTk3", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-569959597", "createdAt": "2021-01-16T18:47:52Z", "commit": {"oid": "217d05955b5719813d72c00aea8cf6e11eda38a9"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNlQxODo0Nzo1MlrOIVGxiw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNlQxODo0Nzo1MlrOIVGxiw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1OTAwMTk5NQ==", "bodyText": "I don't see the function DOUBLE documented in Flink's built-in functions. I think what you want is to use CAST instead: CAST('NaN' AS DOUBLE).", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r559001995", "createdAt": "2021-01-16T18:47:52Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkTableSource.java", "diffHunk": "@@ -75,32 +92,584 @@ public void clean() {\n \n   @Test\n   public void testLimitPushDown() {\n-    sql(\"INSERT INTO %s  VALUES (1,'a'),(2,'b')\", TABLE_NAME);\n-\n     String querySql = String.format(\"SELECT * FROM %s LIMIT 1\", TABLE_NAME);\n     String explain = getTableEnv().explainSql(querySql);\n     String expectedExplain = \"LimitPushDown : 1\";\n-    Assert.assertTrue(\"explain should contains LimitPushDown\", explain.contains(expectedExplain));\n+    Assert.assertTrue(\"Explain should contain LimitPushDown\", explain.contains(expectedExplain));\n     List<Object[]> result = sql(querySql);\n-    Assert.assertEquals(\"should have 1 record\", 1, result.size());\n-    Assert.assertArrayEquals(\"Should produce the expected records\", result.get(0), new Object[] {1, \"a\"});\n+    Assert.assertEquals(\"Should have 1 record\", 1, result.size());\n+    Assert.assertArrayEquals(\"Should produce the expected records\", new Object[] {1, \"iceberg\", 10.0}, result.get(0));\n \n     AssertHelpers.assertThrows(\"Invalid limit number: -1 \", SqlParserException.class,\n         () -> sql(\"SELECT * FROM %s LIMIT -1\", TABLE_NAME));\n \n-    Assert.assertEquals(\"should have 0 record\", 0, sql(\"SELECT * FROM %s LIMIT 0\", TABLE_NAME).size());\n+    Assert.assertEquals(\"Should have 0 record\", 0, sql(\"SELECT * FROM %s LIMIT 0\", TABLE_NAME).size());\n \n-    String sqlLimitExceed = String.format(\"SELECT * FROM %s LIMIT 3\", TABLE_NAME);\n+    String sqlLimitExceed = String.format(\"SELECT * FROM %s LIMIT 4\", TABLE_NAME);\n     List<Object[]> resultExceed = sql(sqlLimitExceed);\n-    Assert.assertEquals(\"should have 2 record\", 2, resultExceed.size());\n+    Assert.assertEquals(\"Should have 3 record\", 3, resultExceed.size());\n     List<Object[]> expectedList = Lists.newArrayList();\n-    expectedList.add(new Object[] {1, \"a\"});\n-    expectedList.add(new Object[] {2, \"b\"});\n-    Assert.assertArrayEquals(\"Should produce the expected records\", resultExceed.toArray(), expectedList.toArray());\n+    expectedList.add(new Object[] {1, \"iceberg\", 10.0});\n+    expectedList.add(new Object[] {2, \"b\", 20.0});\n+    expectedList.add(new Object[] {3, null, 30.0});\n+    Assert.assertArrayEquals(\"Should produce the expected records\", expectedList.toArray(), resultExceed.toArray());\n \n     String sqlMixed = String.format(\"SELECT * FROM %s WHERE id = 1 LIMIT 2\", TABLE_NAME);\n     List<Object[]> mixedResult = sql(sqlMixed);\n-    Assert.assertEquals(\"should have 1 record\", 1, mixedResult.size());\n-    Assert.assertArrayEquals(\"Should produce the expected records\", mixedResult.get(0), new Object[] {1, \"a\"});\n+    Assert.assertEquals(\"Should have 1 record\", 1, mixedResult.size());\n+    Assert.assertArrayEquals(\"Should produce the expected records\",\n+        new Object[] {1, \"iceberg\", 10.0}, mixedResult.get(0));\n+  }\n+\n+  @Test\n+  public void testNoFilterPushDown() {\n+    String sql = String.format(\"SELECT * FROM %s \", TABLE_NAME);\n+    String explain = getTableEnv().explainSql(sql);\n+    Assert.assertFalse(\"Explain should not contain FilterPushDown\", explain.contains(expectedFilterPushDownExplain));\n+    Assert.assertNull(\"Should not push down a filter\", lastScanEvent);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownEqual() {\n+    String sqlLiteralRight = String.format(\"SELECT * FROM %s WHERE id = 1 \", TABLE_NAME);\n+    String explain = getTableEnv().explainSql(sqlLiteralRight);\n+    String expectedFilter = \"ref(name=\\\"id\\\") == 1\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explain.contains(expectedFilter));\n+\n+    List<Object[]> result = sql(sqlLiteralRight);\n+    Assert.assertEquals(\"Should have 1 record\", 1, result.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", new Object[] {1, \"iceberg\", 10.0}, result.get(0));\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownEqualNull() {\n+    String sqlEqualNull = String.format(\"SELECT * FROM %s WHERE data = NULL \", TABLE_NAME);\n+    String explainEqualNull = getTableEnv().explainSql(sqlEqualNull);\n+    Assert.assertFalse(\"Explain should not contain FilterPushDown\",\n+        explainEqualNull.contains(expectedFilterPushDownExplain));\n+\n+    List<Object[]> result = sql(sqlEqualNull);\n+    Assert.assertEquals(\"Should have 0 record\", 0, result.size());\n+    Assert.assertNull(\"Should not push down a filter\", lastScanEvent);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownEqualLiteralOnLeft() {\n+    String sqlLiteralLeft = String.format(\"SELECT * FROM %s WHERE 1 = id \", TABLE_NAME);\n+    String explainLeft = getTableEnv().explainSql(sqlLiteralLeft);\n+    String expectedFilter = \"ref(name=\\\"id\\\") == 1\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainLeft.contains(expectedFilter));\n+\n+    List<Object[]> resultLeft = sql(sqlLiteralLeft);\n+    Assert.assertEquals(\"Should have 1 record\", 1, resultLeft.size());\n+    Assert\n+        .assertArrayEquals(\"Should produce the expected record\", new Object[] {1, \"iceberg\", 10.0}, resultLeft.get(0));\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownNoEqual() {\n+    String sqlNE = String.format(\"SELECT * FROM %s WHERE id <> 1 \", TABLE_NAME);\n+    String explainNE = getTableEnv().explainSql(sqlNE);\n+    String expectedFilter = \"ref(name=\\\"id\\\") != 1\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainNE.contains(expectedFilter));\n+\n+    List<Object[]> resultNE = sql(sqlNE);\n+    Assert.assertEquals(\"Should have 2 records\", 2, resultNE.size());\n+\n+    List<Object[]> expectedNE = Lists.newArrayList();\n+    expectedNE.add(new Object[] {2, \"b\", 20.0});\n+    expectedNE.add(new Object[] {3, null, 30.0});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", expectedNE.toArray(), resultNE.toArray());\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownNoEqualNull() {\n+    String sqlNotEqualNull = String.format(\"SELECT * FROM %s WHERE data <> NULL \", TABLE_NAME);\n+    String explainNotEqualNull = getTableEnv().explainSql(sqlNotEqualNull);\n+    Assert.assertFalse(\"Explain should not contain FilterPushDown\", explainNotEqualNull.contains(\n+        expectedFilterPushDownExplain));\n+\n+    List<Object[]> resultNE = sql(sqlNotEqualNull);\n+    Assert.assertEquals(\"Should have 0 records\", 0, resultNE.size());\n+    Assert.assertNull(\"Should not push down a filter\", lastScanEvent);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownAnd() {\n+    String sqlAnd = String.format(\"SELECT * FROM %s WHERE id = 1 AND data = 'iceberg' \", TABLE_NAME);\n+    String explainAnd = getTableEnv().explainSql(sqlAnd);\n+    String expectedFilter = \"ref(name=\\\"id\\\") == 1,ref(name=\\\"data\\\") == \\\"iceberg\\\"\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainAnd.contains(expectedFilter));\n+\n+    List<Object[]> resultAnd = sql(sqlAnd);\n+    Assert.assertEquals(\"Should have 1 record\", 1, resultAnd.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", new Object[] {1, \"iceberg\", 10.0}, resultAnd.get(0));\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    String expected = \"(ref(name=\\\"id\\\") == 1 and ref(name=\\\"data\\\") == \\\"iceberg\\\")\";\n+    Assert.assertEquals(\"Should contain the push down filter\", expected, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownOr() {\n+    String sqlOr = String.format(\"SELECT * FROM %s WHERE id = 1 OR data = 'b' \", TABLE_NAME);\n+    String explainOr = getTableEnv().explainSql(sqlOr);\n+    String expectedFilter = \"(ref(name=\\\"id\\\") == 1 or ref(name=\\\"data\\\") == \\\"b\\\")\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainOr.contains(expectedFilter));\n+\n+    List<Object[]> resultOr = sql(sqlOr);\n+    Assert.assertEquals(\"Should have 2 record\", 2, resultOr.size());\n+\n+    List<Object[]> expectedOR = Lists.newArrayList();\n+    expectedOR.add(new Object[] {1, \"iceberg\", 10.0});\n+    expectedOR.add(new Object[] {2, \"b\", 20.0});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", expectedOR.toArray(), resultOr.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownGreaterThan() {\n+    String sqlGT = String.format(\"SELECT * FROM %s WHERE id > 1 \", TABLE_NAME);\n+    String explainGT = getTableEnv().explainSql(sqlGT);\n+    String expectedFilter = \"ref(name=\\\"id\\\") > 1\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainGT.contains(expectedFilter));\n+\n+    List<Object[]> resultGT = sql(sqlGT);\n+    Assert.assertEquals(\"Should have 2 record\", 2, resultGT.size());\n+\n+    List<Object[]> expectedGT = Lists.newArrayList();\n+    expectedGT.add(new Object[] {2, \"b\", 20.0});\n+    expectedGT.add(new Object[] {3, null, 30.0});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", expectedGT.toArray(), resultGT.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownGreaterThanNull() {\n+    String sqlGT = String.format(\"SELECT * FROM %s WHERE data > null \", TABLE_NAME);\n+    String explainGT = getTableEnv().explainSql(sqlGT);\n+    Assert.assertFalse(\"Explain should not contain FilterPushDown\", explainGT.contains(expectedFilterPushDownExplain));\n+\n+    List<Object[]> resultGT = sql(sqlGT);\n+    Assert.assertEquals(\"Should have 0 record\", 0, resultGT.size());\n+    Assert.assertNull(\"Should not push down a filter\", lastScanEvent);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownGreaterThanLiteralOnLeft() {\n+    String sqlGT = String.format(\"SELECT * FROM %s WHERE 3 > id \", TABLE_NAME);\n+    String explainGT = getTableEnv().explainSql(sqlGT);\n+    String expectedFilter = \"ref(name=\\\"id\\\") < 3\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainGT.contains(expectedFilter));\n+\n+    List<Object[]> resultGT = sql(sqlGT);\n+    Assert.assertEquals(\"Should have 2 records\", 2, resultGT.size());\n+\n+    List<Object[]> expectedGT = Lists.newArrayList();\n+    expectedGT.add(new Object[] {1, \"iceberg\", 10.0});\n+    expectedGT.add(new Object[] {2, \"b\", 20.0});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", expectedGT.toArray(), resultGT.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownGreaterThanEqual() {\n+    String sqlGTE = String.format(\"SELECT * FROM %s WHERE id >= 2 \", TABLE_NAME);\n+    String explainGTE = getTableEnv().explainSql(sqlGTE);\n+    String expectedFilter = \"ref(name=\\\"id\\\") >= 2\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainGTE.contains(expectedFilter));\n+\n+    List<Object[]> resultGTE = sql(sqlGTE);\n+    Assert.assertEquals(\"Should have 2 records\", 2, resultGTE.size());\n+\n+    List<Object[]> expectedGTE = Lists.newArrayList();\n+    expectedGTE.add(new Object[] {2, \"b\", 20.0});\n+    expectedGTE.add(new Object[] {3, null, 30.0});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", expectedGTE.toArray(), resultGTE.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownGreaterThanEqualNull() {\n+    String sqlGTE = String.format(\"SELECT * FROM %s WHERE data >= null \", TABLE_NAME);\n+    String explainGTE = getTableEnv().explainSql(sqlGTE);\n+    Assert.assertFalse(\"Explain should not contain FilterPushDown\", explainGTE.contains(expectedFilterPushDownExplain));\n+\n+    List<Object[]> resultGT = sql(sqlGTE);\n+    Assert.assertEquals(\"Should have 0 record\", 0, resultGT.size());\n+    Assert.assertNull(\"Should not push down a filter\", lastScanEvent);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownGreaterThanEqualLiteralOnLeft() {\n+    String sqlGTE = String.format(\"SELECT * FROM %s WHERE 2 >= id \", TABLE_NAME);\n+    String explainGTE = getTableEnv().explainSql(sqlGTE);\n+    String expectedFilter = \"ref(name=\\\"id\\\") <= 2\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainGTE.contains(expectedFilter));\n+\n+    List<Object[]> resultGTE = sql(sqlGTE);\n+    Assert.assertEquals(\"Should have 2 records\", 2, resultGTE.size());\n+\n+    List<Object[]> expectedGTE = Lists.newArrayList();\n+    expectedGTE.add(new Object[] {1, \"iceberg\", 10.0});\n+    expectedGTE.add(new Object[] {2, \"b\", 20.0});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", expectedGTE.toArray(), resultGTE.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownLessThan() {\n+    String sqlLT = String.format(\"SELECT * FROM %s WHERE id < 2 \", TABLE_NAME);\n+    String explainLT = getTableEnv().explainSql(sqlLT);\n+    String expectedFilter = \"ref(name=\\\"id\\\") < 2\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainLT.contains(expectedFilter));\n+\n+    List<Object[]> resultLT = sql(sqlLT);\n+    Assert.assertEquals(\"Should have 1 record\", 1, resultLT.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", new Object[] {1, \"iceberg\", 10.0}, resultLT.get(0));\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownLessThanNull() {\n+    String sqlLT = String.format(\"SELECT * FROM %s WHERE data < null \", TABLE_NAME);\n+    String explainLT = getTableEnv().explainSql(sqlLT);\n+    Assert.assertFalse(\"Explain should not contain FilterPushDown\", explainLT.contains(expectedFilterPushDownExplain));\n+\n+    List<Object[]> resultGT = sql(sqlLT);\n+    Assert.assertEquals(\"Should have 0 record\", 0, resultGT.size());\n+    Assert.assertNull(\"Should not push down a filter\", lastScanEvent);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownLessThanLiteralOnLeft() {\n+    String sqlLT = String.format(\"SELECT * FROM %s WHERE 2 < id \", TABLE_NAME);\n+    String explainLT = getTableEnv().explainSql(sqlLT);\n+    String expectedFilter = \"ref(name=\\\"id\\\") > 2\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainLT.contains(expectedFilter));\n+\n+    List<Object[]> resultLT = sql(sqlLT);\n+    Assert.assertEquals(\"Should have 1 record\", 1, resultLT.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", new Object[] {3, null, 30.0}, resultLT.get(0));\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownLessThanEqual() {\n+    String sqlLTE = String.format(\"SELECT * FROM %s WHERE id <= 1 \", TABLE_NAME);\n+    String explainLTE = getTableEnv().explainSql(sqlLTE);\n+    String expectedFilter = \"ref(name=\\\"id\\\") <= 1\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainLTE.contains(expectedFilter));\n+\n+    List<Object[]> resultLTE = sql(sqlLTE);\n+    Assert.assertEquals(\"Should have 1 record\", 1, resultLTE.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", new Object[] {1, \"iceberg\", 10.0}, resultLTE.get(0));\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownLessThanEqualNull() {\n+    String sqlLTE = String.format(\"SELECT * FROM %s WHERE data <= null \", TABLE_NAME);\n+    String explainLTE = getTableEnv().explainSql(sqlLTE);\n+    Assert.assertFalse(\"Explain should not contain FilterPushDown\", explainLTE.contains(expectedFilterPushDownExplain));\n+\n+    List<Object[]> resultGT = sql(sqlLTE);\n+    Assert.assertEquals(\"Should have 0 record\", 0, resultGT.size());\n+    Assert.assertNull(\"Should not push down a filter\", lastScanEvent);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownLessThanEqualLiteralOnLeft() {\n+    String sqlLTE = String.format(\"SELECT * FROM %s WHERE 3 <= id  \", TABLE_NAME);\n+    String explainLTE = getTableEnv().explainSql(sqlLTE);\n+    String expectedFilter = \"ref(name=\\\"id\\\") >= 3\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainLTE.contains(expectedFilter));\n+\n+    List<Object[]> resultLTE = sql(sqlLTE);\n+    Assert.assertEquals(\"Should have 1 record\", 1, resultLTE.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", new Object[] {3, null, 30.0}, resultLTE.get(0));\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownIn() {\n+    String sqlIN = String.format(\"SELECT * FROM %s WHERE id IN (1,2) \", TABLE_NAME);\n+    String explainIN = getTableEnv().explainSql(sqlIN);\n+    String expectedFilter = \"(ref(name=\\\"id\\\") == 1 or ref(name=\\\"id\\\") == 2)\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainIN.contains(expectedFilter));\n+    List<Object[]> resultIN = sql(sqlIN);\n+    Assert.assertEquals(\"Should have 2 records\", 2, resultIN.size());\n+\n+    List<Object[]> expectedIN = Lists.newArrayList();\n+    expectedIN.add(new Object[] {1, \"iceberg\", 10.0});\n+    expectedIN.add(new Object[] {2, \"b\", 20.0});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", expectedIN.toArray(), resultIN.toArray());\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownInNull() {\n+    String sqlInNull = String.format(\"SELECT * FROM %s WHERE data IN ('iceberg',NULL) \", TABLE_NAME);\n+    String explainInNull = getTableEnv().explainSql(sqlInNull);\n+    Assert.assertFalse(\"Explain should not contain FilterPushDown\",\n+        explainInNull.contains(expectedFilterPushDownExplain));\n+\n+    List<Object[]> result = sql(sqlInNull);\n+    Assert.assertEquals(\"Should have 1 record\", 1, result.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", new Object[] {1, \"iceberg\", 10.0}, result.get(0));\n+    Assert.assertEquals(\"Should not push down a filter\", Expressions.alwaysTrue(), lastScanEvent.filter());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownNotIn() {\n+    String sqlNotIn = String.format(\"SELECT * FROM %s WHERE id NOT IN (3,2) \", TABLE_NAME);\n+    String explainNotIn = getTableEnv().explainSql(sqlNotIn);\n+    String expectedFilter = \"ref(name=\\\"id\\\") != 3,ref(name=\\\"id\\\") != 2\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainNotIn.contains(expectedFilter));\n+\n+    List<Object[]> resultNotIn = sql(sqlNotIn);\n+    Assert.assertEquals(\"Should have 1 record\", 1, resultNotIn.size());\n+    Assert\n+        .assertArrayEquals(\"Should produce the expected record\", new Object[] {1, \"iceberg\", 10.0}, resultNotIn.get(0));\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    String expectedScan = \"(ref(name=\\\"id\\\") != 3 and ref(name=\\\"id\\\") != 2)\";\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedScan, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownNotInNull() {\n+    String sqlNotInNull = String.format(\"SELECT * FROM %s WHERE id NOT IN (1,2,NULL) \", TABLE_NAME);\n+    String explainNotInNull = getTableEnv().explainSql(sqlNotInNull);\n+    Assert.assertFalse(\"Explain should not contain FilterPushDown\",\n+        explainNotInNull.contains(expectedFilterPushDownExplain));\n+    List<Object[]> resultGT = sql(sqlNotInNull);\n+    Assert.assertEquals(\"Should have 0 record\", 0, resultGT.size());\n+    Assert.assertEquals(\"Should not push down a filter\", Expressions.alwaysTrue(), lastScanEvent.filter());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownIsNotNull() {\n+    String sqlNotNull = String.format(\"SELECT * FROM %s WHERE data IS NOT NULL\", TABLE_NAME);\n+    String explainNotNull = getTableEnv().explainSql(sqlNotNull);\n+    String expectedFilter = \"not_null(ref(name=\\\"data\\\"))\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainNotNull.contains(expectedFilter));\n+\n+    List<Object[]> resultNotNull = sql(sqlNotNull);\n+    Assert.assertEquals(\"Should have 2 record\", 2, resultNotNull.size());\n+\n+    List<Object[]> expected = Lists.newArrayList();\n+    expected.add(new Object[] {1, \"iceberg\", 10.0});\n+    expected.add(new Object[] {2, \"b\", 20.0});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", expected.toArray(), resultNotNull.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownIsNull() {\n+    String sqlNull = String.format(\"SELECT * FROM %s WHERE data IS  NULL\", TABLE_NAME);\n+    String explainNull = getTableEnv().explainSql(sqlNull);\n+    String expectedFilter = \"is_null(ref(name=\\\"data\\\"))\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainNull.contains(expectedFilter));\n+\n+    List<Object[]> resultNull = sql(sqlNull);\n+    Assert.assertEquals(\"Should have 1 record\", 1, resultNull.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", new Object[] {3, null, 30.0}, resultNull.get(0));\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownNot() {\n+    String sqlNot = String.format(\"SELECT * FROM %s WHERE NOT (id = 1 OR id = 2 ) \", TABLE_NAME);\n+    String explainNot = getTableEnv().explainSql(sqlNot);\n+    String expectedFilter = \"ref(name=\\\"id\\\") != 1,ref(name=\\\"id\\\") != 2\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainNot.contains(expectedFilter));\n+\n+    List<Object[]> resultNot = sql(sqlNot);\n+    Assert.assertEquals(\"Should have 1 record\", 1, resultNot.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", new Object[] {3, null, 30.0}, resultNot.get(0));\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    expectedFilter = \"(ref(name=\\\"id\\\") != 1 and ref(name=\\\"id\\\") != 2)\";\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownBetween() {\n+    String sqlBetween = String.format(\"SELECT * FROM %s WHERE id BETWEEN 1 AND 2 \", TABLE_NAME);\n+    String explainBetween = getTableEnv().explainSql(sqlBetween);\n+    String expectedFilter = \"ref(name=\\\"id\\\") >= 1,ref(name=\\\"id\\\") <= 2\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainBetween.contains(expectedFilter));\n+\n+    List<Object[]> resultBetween = sql(sqlBetween);\n+    Assert.assertEquals(\"Should have 2 record\", 2, resultBetween.size());\n+\n+    List<Object[]> expectedBetween = Lists.newArrayList();\n+    expectedBetween.add(new Object[] {1, \"iceberg\", 10.0});\n+    expectedBetween.add(new Object[] {2, \"b\", 20.0});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", expectedBetween.toArray(), resultBetween.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    String expected = \"(ref(name=\\\"id\\\") >= 1 and ref(name=\\\"id\\\") <= 2)\";\n+    Assert.assertEquals(\"Should contain the push down filter\", expected, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownNotBetween() {\n+    String sqlNotBetween = String.format(\"SELECT * FROM %s WHERE id  NOT BETWEEN 2 AND 3 \", TABLE_NAME);\n+    String explainNotBetween = getTableEnv().explainSql(sqlNotBetween);\n+    String expectedFilter = \"(ref(name=\\\"id\\\") < 2 or ref(name=\\\"id\\\") > 3)\";\n+    Assert.assertTrue(\"Explain should contain the push down filter\", explainNotBetween.contains(expectedFilter));\n+\n+    List<Object[]> resultNotBetween = sql(sqlNotBetween);\n+    Assert.assertEquals(\"Should have 1 record\", 1, resultNotBetween.size());\n+    Assert.assertArrayEquals(\"the not between Should produce the expected record\", resultNotBetween.get(0),\n+        new Object[] {1, \"iceberg\", 10.0});\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownLike() {\n+    String sqlLike = \"SELECT * FROM \" + TABLE_NAME + \" WHERE data LIKE 'ice%' \";\n+    String explainLike = getTableEnv().explainSql(sqlLike);\n+    String expectedFilter = \"ref(name=\\\"data\\\") startsWith \\\"\\\"ice\\\"\\\"\";\n+    Assert.assertTrue(\"the like sql Explain should contain the push down filter\", explainLike.contains(expectedFilter));\n+\n+    sqlLike = \"SELECT * FROM \" + TABLE_NAME + \" WHERE data LIKE 'ice%%' \";\n+    List<Object[]> resultLike = sql(sqlLike);\n+    Assert.assertEquals(\"Should have 1 record\", 1, resultLike.size());\n+    Assert.assertArrayEquals(\"The like result should produce the expected record\",\n+        new Object[] {1, \"iceberg\", 10.0}, resultLike.get(0));\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should contain the push down filter\", expectedFilter, lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterNotPushDownLike() {\n+    String sqlNoPushDown = \"SELECT * FROM \" + TABLE_NAME + \" WHERE data LIKE '%i' \";\n+    String explainNoPushDown = getTableEnv().explainSql(sqlNoPushDown);\n+    Assert.assertFalse(\"Explain should not contain FilterPushDown\",\n+        explainNoPushDown.contains(expectedFilterPushDownExplain));\n+    sqlNoPushDown = \"SELECT * FROM \" + TABLE_NAME + \" WHERE data LIKE '%%i' \";\n+    List<Object[]> resultLike = sql(sqlNoPushDown);\n+    Assert.assertEquals(\"Should have 1 record\", 0, resultLike.size());\n+    Assert.assertEquals(\"Should not push down a filter\", Expressions.alwaysTrue(), lastScanEvent.filter());\n+\n+    sqlNoPushDown = \"SELECT * FROM \" + TABLE_NAME + \" WHERE data LIKE '%i%' \";\n+    explainNoPushDown = getTableEnv().explainSql(sqlNoPushDown);\n+    Assert.assertFalse(\"Explain should not contain FilterPushDown\",\n+        explainNoPushDown.contains(expectedFilterPushDownExplain));\n+    sqlNoPushDown = \"SELECT * FROM \" + TABLE_NAME + \" WHERE data LIKE '%%i%%' \";\n+    resultLike = sql(sqlNoPushDown);\n+    Assert.assertEquals(\"Should have 1 record\", 1, resultLike.size());\n+    Assert\n+        .assertArrayEquals(\"Should produce the expected record\", new Object[] {1, \"iceberg\", 10.0}, resultLike.get(0));\n+    Assert.assertEquals(\"Should not push down a filter\", Expressions.alwaysTrue(), lastScanEvent.filter());\n+\n+    sqlNoPushDown = \"SELECT * FROM  \" + TABLE_NAME + \"  WHERE data LIKE '%ice%g' \";\n+    explainNoPushDown = getTableEnv().explainSql(sqlNoPushDown);\n+    Assert.assertFalse(\"Explain should not contain FilterPushDown\",\n+        explainNoPushDown.contains(expectedFilterPushDownExplain));\n+    sqlNoPushDown = \"SELECT * FROM  \" + TABLE_NAME + \"  WHERE data LIKE '%%ice%%g' \";\n+    resultLike = sql(sqlNoPushDown);\n+    Assert.assertEquals(\"Should have 1 record\", 1, resultLike.size());\n+    Assert\n+        .assertArrayEquals(\"Should produce the expected record\", new Object[] {1, \"iceberg\", 10.0}, resultLike.get(0));\n+    Assert.assertEquals(\"Should not push down a filter\", Expressions.alwaysTrue(), lastScanEvent.filter());\n+\n+    sqlNoPushDown = \"SELECT * FROM  \" + TABLE_NAME + \"  WHERE data LIKE '%' \";\n+    explainNoPushDown = getTableEnv().explainSql(sqlNoPushDown);\n+    Assert.assertFalse(\"Explain should not contain FilterPushDown\",\n+        explainNoPushDown.contains(expectedFilterPushDownExplain));\n+    sqlNoPushDown = \"SELECT * FROM  \" + TABLE_NAME + \"  WHERE data LIKE '%%' \";\n+    resultLike = sql(sqlNoPushDown);\n+    Assert.assertEquals(\"Should have 2 records\", 2, resultLike.size());\n+    List<Object[]> expectedRecords = Lists.newArrayList();\n+    expectedRecords.add(new Object[] {1, \"iceberg\", 10.0});\n+    expectedRecords.add(new Object[] {2, \"b\", 20.0});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", expectedRecords.toArray(), resultLike.toArray());\n+    Assert.assertEquals(\"Should not push down a filter\", Expressions.alwaysTrue(), lastScanEvent.filter());\n+\n+    sqlNoPushDown = \"SELECT * FROM  \" + TABLE_NAME + \"  WHERE data LIKE 'iceber_' \";\n+    explainNoPushDown = getTableEnv().explainSql(sqlNoPushDown);\n+    Assert.assertFalse(\"Explain should not contain FilterPushDown\",\n+        explainNoPushDown.contains(expectedFilterPushDownExplain));\n+    resultLike = sql(sqlNoPushDown);\n+    Assert.assertEquals(\"Should have 1 record\", 1, resultLike.size());\n+    Assert\n+        .assertArrayEquals(\"Should produce the expected record\", new Object[] {1, \"iceberg\", 10.0}, resultLike.get(0));\n+    Assert.assertEquals(\"Should not push down a filter\", Expressions.alwaysTrue(), lastScanEvent.filter());\n+  }\n+\n+  @Test\n+  public void testFilterPushDown2Literal() {\n+    String sql2Literal = String.format(\"SELECT * FROM %s WHERE 1 > 0 \", TABLE_NAME);\n+    String explain2Literal = getTableEnv().explainSql(sql2Literal);\n+    Assert.assertFalse(\"Explain should not contain FilterPushDown\",\n+        explain2Literal.contains(expectedFilterPushDownExplain));\n+    Assert.assertNull(\"Should not push down a filter\", lastScanEvent);\n+  }\n+\n+  /**\n+   * NaN is not supported by flink now, so we add the test case to assert the parse error, when we upgrade the flink\n+   * that supports NaN, we will delele the method, and add some test case to test NaN.\n+   */\n+  @Test\n+  public void testSqlParseError() {\n+    String sqlParseErrorEqual = String.format(\"SELECT * FROM %s WHERE d = DOUBLE('NaN') \", TABLE_NAME);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "217d05955b5719813d72c00aea8cf6e11eda38a9"}, "originalPosition": 629}]}}, {"__typename": "PullRequestCommit", "commit": {"oid": "4981f606c3870f425a76c2cb5a78caced7dadd9e", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/4981f606c3870f425a76c2cb5a78caced7dadd9e", "committedDate": "2021-01-17T02:45:56Z", "message": "add filter push down"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f2e493ab197e457faf46160f60022d69ac935eab", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/f2e493ab197e457faf46160f60022d69ac935eab", "committedDate": "2021-01-17T02:45:56Z", "message": "fix some issue"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "fbb0f3b09985b7acda4f68aef51bb4f5a776a2c8", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/fbb0f3b09985b7acda4f68aef51bb4f5a776a2c8", "committedDate": "2021-01-17T02:45:56Z", "message": "update  Expression to Optional"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "5a573f28aab03c949533d1fc8a9086d6d797730c", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/5a573f28aab03c949533d1fc8a9086d6d797730c", "committedDate": "2021-01-17T02:45:57Z", "message": "fix some bugs and add test case"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f94ebaaa3269bab96fe805e78642b8e68740ec2d", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/f94ebaaa3269bab96fe805e78642b8e68740ec2d", "committedDate": "2021-01-17T02:45:57Z", "message": "fix some issues"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "c8bd0d921b1b7dcfa3ce7ecb32c7b0b82733cf24", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/c8bd0d921b1b7dcfa3ce7ecb32c7b0b82733cf24", "committedDate": "2021-01-17T02:45:57Z", "message": "do not format sql when args length is 0"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "28980d1195880bb34ecdef14d1acf4218902463d", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/28980d1195880bb34ecdef14d1acf4218902463d", "committedDate": "2021-01-17T02:45:57Z", "message": "fix some issues"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "d8c39aaf0ef68a57f4ca9ec0845ce15dbfed67e2", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/d8c39aaf0ef68a57f4ca9ec0845ce15dbfed67e2", "committedDate": "2021-01-17T02:45:57Z", "message": "fix  issues"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "38f9593d1c82d6ff2abea97339d5add534db348b", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/38f9593d1c82d6ff2abea97339d5add534db348b", "committedDate": "2021-01-17T02:45:57Z", "message": "fix some issues"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "f6e70282f8c1a9853bf66c7f3d545d84dfd21d58", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/f6e70282f8c1a9853bf66c7f3d545d84dfd21d58", "committedDate": "2021-01-17T02:45:57Z", "message": "fix some issues, and add some test case"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "217d05955b5719813d72c00aea8cf6e11eda38a9", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/217d05955b5719813d72c00aea8cf6e11eda38a9", "committedDate": "2021-01-16T14:33:05Z", "message": "fix some issues, and add some test case"}, "afterCommit": {"oid": "c93eaa7347475e26e33897584e47e2974abefd30", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/c93eaa7347475e26e33897584e47e2974abefd30", "committedDate": "2021-01-17T02:45:57Z", "message": "refactor TestFlinkTableSource and fix some issues"}}, {"__typename": "PullRequestCommit", "commit": {"oid": "138fa467c543f70d76a37874d6182e3331c14701", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/138fa467c543f70d76a37874d6182e3331c14701", "committedDate": "2021-01-17T04:24:10Z", "message": "refactor TestFlinkTableSource and fix some issues"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "c93eaa7347475e26e33897584e47e2974abefd30", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/c93eaa7347475e26e33897584e47e2974abefd30", "committedDate": "2021-01-17T02:45:57Z", "message": "refactor TestFlinkTableSource and fix some issues"}, "afterCommit": {"oid": "138fa467c543f70d76a37874d6182e3331c14701", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/138fa467c543f70d76a37874d6182e3331c14701", "committedDate": "2021-01-17T04:24:10Z", "message": "refactor TestFlinkTableSource and fix some issues"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTcwNzcwNzE0", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-570770714", "createdAt": "2021-01-18T20:49:18Z", "commit": {"oid": "138fa467c543f70d76a37874d6182e3331c14701"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "2fe26eea13bb5ccb35b0a31615e8b4458d754862", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/2fe26eea13bb5ccb35b0a31615e8b4458d754862", "committedDate": "2020-12-09T02:29:52Z", "message": "add filter push down"}, "afterCommit": {"oid": "e05b6e98528ed626dd9b44144e4dd12d58d86260", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/e05b6e98528ed626dd9b44144e4dd12d58d86260", "committedDate": "2020-12-10T05:33:14Z", "message": "add filter push down"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU0MjQ1ODI4", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-554245828", "createdAt": "2020-12-17T03:01:06Z", "commit": {"oid": "e05b6e98528ed626dd9b44144e4dd12d58d86260"}, "state": "COMMENTED", "comments": {"totalCount": 6, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QwMzowMTowN1rOIHie2Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QwMzoxMzoyN1rOIHiunQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDc3NTg5Nw==", "bodyText": "I'm not familiar with flink, I wonder if it should be a valid use case here and in other places that we return null; should we throw instead?", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r544775897", "createdAt": "2020-12-17T03:01:07Z", "author": {"login": "yyanyy"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,169 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinition;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+public class FlinkFilters {\n+  private FlinkFilters() {\n+  }\n+\n+  private static final Map<BuiltInFunctionDefinition, Operation> FILTERS = ImmutableMap\n+      .<BuiltInFunctionDefinition, Operation>builder()\n+      .put(BuiltInFunctionDefinitions.EQUALS, Operation.EQ)\n+      .put(BuiltInFunctionDefinitions.NOT_EQUALS, Operation.NOT_EQ)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN, Operation.GT)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, Operation.GT_EQ)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN, Operation.LT)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, Operation.LT_EQ)\n+      .put(BuiltInFunctionDefinitions.IN, Operation.IN)\n+      .put(BuiltInFunctionDefinitions.IS_NULL, Operation.IS_NULL)\n+      .put(BuiltInFunctionDefinitions.IS_NOT_NULL, Operation.NOT_NULL)\n+      .put(BuiltInFunctionDefinitions.AND, Operation.AND)\n+      .put(BuiltInFunctionDefinitions.OR, Operation.OR)\n+      .put(BuiltInFunctionDefinitions.NOT, Operation.NOT)\n+      .build();\n+\n+\n+  public static Expression convert(org.apache.flink.table.expressions.Expression flinkExpression) {\n+    if (!(flinkExpression instanceof CallExpression)) {\n+      return null;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e05b6e98528ed626dd9b44144e4dd12d58d86260"}, "originalPosition": 60}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDc3Njk3NA==", "bodyText": "Nit: I think these are input values, not expressions", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r544776974", "createdAt": "2020-12-17T03:04:31Z", "author": {"login": "yyanyy"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,169 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinition;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+public class FlinkFilters {\n+  private FlinkFilters() {\n+  }\n+\n+  private static final Map<BuiltInFunctionDefinition, Operation> FILTERS = ImmutableMap\n+      .<BuiltInFunctionDefinition, Operation>builder()\n+      .put(BuiltInFunctionDefinitions.EQUALS, Operation.EQ)\n+      .put(BuiltInFunctionDefinitions.NOT_EQUALS, Operation.NOT_EQ)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN, Operation.GT)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, Operation.GT_EQ)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN, Operation.LT)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, Operation.LT_EQ)\n+      .put(BuiltInFunctionDefinitions.IN, Operation.IN)\n+      .put(BuiltInFunctionDefinitions.IS_NULL, Operation.IS_NULL)\n+      .put(BuiltInFunctionDefinitions.IS_NOT_NULL, Operation.NOT_NULL)\n+      .put(BuiltInFunctionDefinitions.AND, Operation.AND)\n+      .put(BuiltInFunctionDefinitions.OR, Operation.OR)\n+      .put(BuiltInFunctionDefinitions.NOT, Operation.NOT)\n+      .build();\n+\n+\n+  public static Expression convert(org.apache.flink.table.expressions.Expression flinkExpression) {\n+    if (!(flinkExpression instanceof CallExpression)) {\n+      return null;\n+    }\n+\n+    CallExpression call = (CallExpression) flinkExpression;\n+    Operation op = FILTERS.get(call.getFunctionDefinition());\n+    if (op != null) {\n+      switch (op) {\n+        case IS_NULL:\n+          FieldReferenceExpression isNullFilter = (FieldReferenceExpression) call.getResolvedChildren().get(0);\n+          return Expressions.isNull(isNullFilter.getName());\n+\n+        case NOT_NULL:\n+          FieldReferenceExpression notNullExpression = (FieldReferenceExpression) call.getResolvedChildren().get(0);\n+          return Expressions.notNull(notNullExpression.getName());\n+\n+        case LT:\n+          return convertComparisonExpression(Expressions::lessThan, call);\n+\n+        case LT_EQ:\n+          return convertComparisonExpression(Expressions::lessThanOrEqual, call);\n+\n+        case GT:\n+          return convertComparisonExpression(Expressions::greaterThan, call);\n+\n+        case GT_EQ:\n+          return convertComparisonExpression(Expressions::greaterThanOrEqual, call);\n+\n+        case EQ:\n+          return convertComparisonExpression(Expressions::equal, call);\n+\n+        case NOT_EQ:\n+          return convertComparisonExpression(Expressions::notEqual, call);\n+\n+        case IN:\n+          List<ResolvedExpression> args = call.getResolvedChildren();\n+          FieldReferenceExpression field = (FieldReferenceExpression) args.get(0);\n+          List<ResolvedExpression> values = args.subList(1, args.size());\n+\n+          List<Object> expressions = values.stream().filter(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e05b6e98528ed626dd9b44144e4dd12d58d86260"}, "originalPosition": 98}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDc3NzM3Mw==", "bodyText": "Nit: no need to have ? true : false", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r544777373", "createdAt": "2020-12-17T03:05:41Z", "author": {"login": "yyanyy"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,169 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinition;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+public class FlinkFilters {\n+  private FlinkFilters() {\n+  }\n+\n+  private static final Map<BuiltInFunctionDefinition, Operation> FILTERS = ImmutableMap\n+      .<BuiltInFunctionDefinition, Operation>builder()\n+      .put(BuiltInFunctionDefinitions.EQUALS, Operation.EQ)\n+      .put(BuiltInFunctionDefinitions.NOT_EQUALS, Operation.NOT_EQ)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN, Operation.GT)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, Operation.GT_EQ)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN, Operation.LT)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, Operation.LT_EQ)\n+      .put(BuiltInFunctionDefinitions.IN, Operation.IN)\n+      .put(BuiltInFunctionDefinitions.IS_NULL, Operation.IS_NULL)\n+      .put(BuiltInFunctionDefinitions.IS_NOT_NULL, Operation.NOT_NULL)\n+      .put(BuiltInFunctionDefinitions.AND, Operation.AND)\n+      .put(BuiltInFunctionDefinitions.OR, Operation.OR)\n+      .put(BuiltInFunctionDefinitions.NOT, Operation.NOT)\n+      .build();\n+\n+\n+  public static Expression convert(org.apache.flink.table.expressions.Expression flinkExpression) {\n+    if (!(flinkExpression instanceof CallExpression)) {\n+      return null;\n+    }\n+\n+    CallExpression call = (CallExpression) flinkExpression;\n+    Operation op = FILTERS.get(call.getFunctionDefinition());\n+    if (op != null) {\n+      switch (op) {\n+        case IS_NULL:\n+          FieldReferenceExpression isNullFilter = (FieldReferenceExpression) call.getResolvedChildren().get(0);\n+          return Expressions.isNull(isNullFilter.getName());\n+\n+        case NOT_NULL:\n+          FieldReferenceExpression notNullExpression = (FieldReferenceExpression) call.getResolvedChildren().get(0);\n+          return Expressions.notNull(notNullExpression.getName());\n+\n+        case LT:\n+          return convertComparisonExpression(Expressions::lessThan, call);\n+\n+        case LT_EQ:\n+          return convertComparisonExpression(Expressions::lessThanOrEqual, call);\n+\n+        case GT:\n+          return convertComparisonExpression(Expressions::greaterThan, call);\n+\n+        case GT_EQ:\n+          return convertComparisonExpression(Expressions::greaterThanOrEqual, call);\n+\n+        case EQ:\n+          return convertComparisonExpression(Expressions::equal, call);\n+\n+        case NOT_EQ:\n+          return convertComparisonExpression(Expressions::notEqual, call);\n+\n+        case IN:\n+          List<ResolvedExpression> args = call.getResolvedChildren();\n+          FieldReferenceExpression field = (FieldReferenceExpression) args.get(0);\n+          List<ResolvedExpression> values = args.subList(1, args.size());\n+\n+          List<Object> expressions = values.stream().filter(\n+              expression -> {\n+                if (expression instanceof ValueLiteralExpression) {\n+                  return !((ValueLiteralExpression) flinkExpression).isNull();\n+                }\n+\n+                return false;\n+              }\n+          ).map(expression -> {\n+            ValueLiteralExpression valueLiteralExpression = (ValueLiteralExpression) expression;\n+            return valueLiteralExpression.getValueAs(valueLiteralExpression.getOutputDataType().getConversionClass())\n+                .get();\n+          }).collect(Collectors.toList());\n+          return Expressions.in(field.getName(), expressions);\n+\n+        case NOT:\n+          Expression child = convert(call.getResolvedChildren().get(0));\n+          if (child != null) {\n+            return Expressions.not(child);\n+          }\n+\n+          return null;\n+\n+        case AND: {\n+          return convertLogicExpression(Expressions::and, call);\n+        }\n+\n+        case OR: {\n+          return convertLogicExpression(Expressions::or, call);\n+        }\n+      }\n+    }\n+\n+    return null;\n+  }\n+\n+  private static Expression convertLogicExpression(BiFunction<Expression, Expression, Expression> function,\n+                                                   CallExpression call) {\n+    List<ResolvedExpression> args = call.getResolvedChildren();\n+    Expression left = convert(args.get(0));\n+    Expression right = convert(args.get(1));\n+    if (left != null && right != null) {\n+      return function.apply(left, right);\n+    }\n+\n+    return null;\n+\n+  }\n+\n+  private static Expression convertComparisonExpression(BiFunction<String, Object, Expression> function,\n+                                                        CallExpression call) {\n+    List<ResolvedExpression> args = call.getResolvedChildren();\n+    FieldReferenceExpression fieldReferenceExpression;\n+    ValueLiteralExpression valueLiteralExpression;\n+    if (literalOnRight(args)) {\n+      fieldReferenceExpression = (FieldReferenceExpression) args.get(0);\n+      valueLiteralExpression = (ValueLiteralExpression) args.get(1);\n+    } else {\n+      fieldReferenceExpression = (FieldReferenceExpression) args.get(1);\n+      valueLiteralExpression = (ValueLiteralExpression) args.get(0);\n+    }\n+\n+    String name = fieldReferenceExpression.getName();\n+    Class clazz = valueLiteralExpression.getOutputDataType().getConversionClass();\n+    return function.apply(name, valueLiteralExpression.getValueAs(clazz).get());\n+  }\n+\n+  private static boolean literalOnRight(List<ResolvedExpression> args) {\n+    return args.get(0) instanceof FieldReferenceExpression && args.get(1) instanceof ValueLiteralExpression ? true :", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e05b6e98528ed626dd9b44144e4dd12d58d86260"}, "originalPosition": 166}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDc3OTI5Nw==", "bodyText": "Seems that this is mapping flink operations to iceberg operations in the following switch statement? If that's the case we probably don't really need it, and could directly switch based on the input flinkExpression. getFunctionDefinition()?\nAlso, there's a recent change that requires rewriting NaN in equals/notEquals to isNaN/notNaN as Iceberg's equals no longer accepts NaN as literal, so we will have to rewrite here as well. Here is a similar change done in spark filters.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r544779297", "createdAt": "2020-12-17T03:11:37Z", "author": {"login": "yyanyy"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,169 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinition;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+\n+public class FlinkFilters {\n+  private FlinkFilters() {\n+  }\n+\n+  private static final Map<BuiltInFunctionDefinition, Operation> FILTERS = ImmutableMap", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e05b6e98528ed626dd9b44144e4dd12d58d86260"}, "originalPosition": 41}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDc3OTgwNA==", "bodyText": "I think returning null in the filters class will cause NPE here as well", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r544779804", "createdAt": "2020-12-17T03:13:00Z", "author": {"login": "yyanyy"}, "path": "flink/src/main/java/org/apache/iceberg/flink/IcebergTableSource.java", "diffHunk": "@@ -112,6 +119,11 @@ public String explainSource() {\n       explain += String.format(\", LimitPushDown : %d\", limit);\n     }\n \n+    if (filters != null) {\n+      explain += String.format(\", FilterPushDown,the filters :%s\",\n+          filters.stream().map(filter -> filter.toString()).collect(Collectors.joining(\",\")));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e05b6e98528ed626dd9b44144e4dd12d58d86260"}, "originalPosition": 79}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NDc3OTkzMw==", "bodyText": "Nit: @Override?", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r544779933", "createdAt": "2020-12-17T03:13:27Z", "author": {"login": "yyanyy"}, "path": "flink/src/main/java/org/apache/iceberg/flink/IcebergTableSource.java", "diffHunk": "@@ -122,6 +134,21 @@ public boolean isLimitPushedDown() {\n \n   @Override\n   public TableSource<RowData> applyLimit(long newLimit) {\n-    return new IcebergTableSource(loader, schema, properties, projectedFields, true, newLimit);\n+    return new IcebergTableSource(loader, schema, properties, projectedFields, true, newLimit, filters);\n+  }\n+\n+  public TableSource<RowData> applyPredicate(List<Expression> predicates) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "e05b6e98528ed626dd9b44144e4dd12d58d86260"}, "originalPosition": 93}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "e05b6e98528ed626dd9b44144e4dd12d58d86260", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/e05b6e98528ed626dd9b44144e4dd12d58d86260", "committedDate": "2020-12-10T05:33:14Z", "message": "add filter push down"}, "afterCommit": {"oid": "7f7cbf527f6fa9558c7f0f1cec7f7df97f6aae36", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/7f7cbf527f6fa9558c7f0f1cec7f7df97f6aae36", "committedDate": "2020-12-17T06:50:22Z", "message": "fix some issue"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU0OTQ0MzQ2", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-554944346", "createdAt": "2020-12-17T20:01:37Z", "commit": {"oid": "7f7cbf527f6fa9558c7f0f1cec7f7df97f6aae36"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMDowMTozN1rOIIGmRg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xN1QyMDowMTozN1rOIIGmRg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NTM2NzYyMg==", "bodyText": "I think we may want to rewrite NOT_EQUALS to notNaN as well as notEquals in Iceberg also doesn't accept NaN as literal; I think SparkFilters doesn't do that because there's no NotEqualTo filter in Spark.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r545367622", "createdAt": "2020-12-17T20:01:37Z", "author": {"login": "yyanyy"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,185 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinition;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.NaNUtil;\n+\n+public class FlinkFilters {\n+  private FlinkFilters() {\n+  }\n+\n+  private static final Map<BuiltInFunctionDefinition, Operation> FILTERS = ImmutableMap\n+      .<BuiltInFunctionDefinition, Operation>builder()\n+      .put(BuiltInFunctionDefinitions.EQUALS, Operation.EQ)\n+      .put(BuiltInFunctionDefinitions.NOT_EQUALS, Operation.NOT_EQ)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN, Operation.GT)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, Operation.GT_EQ)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN, Operation.LT)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, Operation.LT_EQ)\n+      .put(BuiltInFunctionDefinitions.IN, Operation.IN)\n+      .put(BuiltInFunctionDefinitions.IS_NULL, Operation.IS_NULL)\n+      .put(BuiltInFunctionDefinitions.IS_NOT_NULL, Operation.NOT_NULL)\n+      .put(BuiltInFunctionDefinitions.AND, Operation.AND)\n+      .put(BuiltInFunctionDefinitions.OR, Operation.OR)\n+      .put(BuiltInFunctionDefinitions.NOT, Operation.NOT)\n+      .build();\n+\n+\n+  public static Expression convert(org.apache.flink.table.expressions.Expression flinkExpression) {\n+    if (!(flinkExpression instanceof CallExpression)) {\n+      return null;\n+    }\n+\n+    CallExpression call = (CallExpression) flinkExpression;\n+    Operation op = FILTERS.get(call.getFunctionDefinition());\n+    if (op != null) {\n+      switch (op) {\n+        case IS_NULL:\n+          FieldReferenceExpression isNullFilter = (FieldReferenceExpression) call.getResolvedChildren().get(0);\n+          return Expressions.isNull(isNullFilter.getName());\n+\n+        case NOT_NULL:\n+          FieldReferenceExpression notNullExpression = (FieldReferenceExpression) call.getResolvedChildren().get(0);\n+          return Expressions.notNull(notNullExpression.getName());\n+\n+        case LT:\n+          return convertComparisonExpression(Expressions::lessThan, call);\n+\n+        case LT_EQ:\n+          return convertComparisonExpression(Expressions::lessThanOrEqual, call);\n+\n+        case GT:\n+          return convertComparisonExpression(Expressions::greaterThan, call);\n+\n+        case GT_EQ:\n+          return convertComparisonExpression(Expressions::greaterThanOrEqual, call);\n+\n+        case EQ:\n+          return convertComparisonExpression(Expressions::equal, call);\n+\n+        case NOT_EQ:\n+          return convertComparisonExpression(Expressions::notEqual, call);\n+\n+        case IN:\n+          List<ResolvedExpression> args = call.getResolvedChildren();\n+          FieldReferenceExpression field = (FieldReferenceExpression) args.get(0);\n+          List<ResolvedExpression> values = args.subList(1, args.size());\n+\n+          List<Object> inputValues = values.stream().filter(\n+              expression -> {\n+                if (expression instanceof ValueLiteralExpression) {\n+                  return !((ValueLiteralExpression) flinkExpression).isNull();\n+                }\n+\n+                return false;\n+              }\n+          ).map(expression -> {\n+            ValueLiteralExpression valueLiteralExpression = (ValueLiteralExpression) expression;\n+            return valueLiteralExpression.getValueAs(valueLiteralExpression.getOutputDataType().getConversionClass())\n+                .get();\n+          }).collect(Collectors.toList());\n+          return Expressions.in(field.getName(), inputValues);\n+\n+        case NOT:\n+          Expression child = convert(call.getResolvedChildren().get(0));\n+          if (child != null) {\n+            return Expressions.not(child);\n+          }\n+\n+          return null;\n+\n+        case AND: {\n+          return convertLogicExpression(Expressions::and, call);\n+        }\n+\n+        case OR: {\n+          return convertLogicExpression(Expressions::or, call);\n+        }\n+      }\n+    }\n+\n+    return null;\n+  }\n+\n+  private static Expression convertLogicExpression(BiFunction<Expression, Expression, Expression> function,\n+                                                   CallExpression call) {\n+    List<ResolvedExpression> args = call.getResolvedChildren();\n+    Expression left = convert(args.get(0));\n+    Expression right = convert(args.get(1));\n+    if (left != null && right != null) {\n+      return function.apply(left, right);\n+    }\n+\n+    return null;\n+  }\n+\n+  private static Expression convertComparisonExpression(BiFunction<String, Object, Expression> function,\n+                                                        CallExpression call) {\n+    List<ResolvedExpression> args = call.getResolvedChildren();\n+    FieldReferenceExpression fieldReferenceExpression;\n+    ValueLiteralExpression valueLiteralExpression;\n+    if (literalOnRight(args)) {\n+      fieldReferenceExpression = (FieldReferenceExpression) args.get(0);\n+      valueLiteralExpression = (ValueLiteralExpression) args.get(1);\n+    } else {\n+      fieldReferenceExpression = (FieldReferenceExpression) args.get(1);\n+      valueLiteralExpression = (ValueLiteralExpression) args.get(0);\n+    }\n+\n+    String name = fieldReferenceExpression.getName();\n+    Class clazz = valueLiteralExpression.getOutputDataType().getConversionClass();\n+    Object value = valueLiteralExpression.getValueAs(clazz).get();\n+\n+    BuiltInFunctionDefinition functionDefinition = (BuiltInFunctionDefinition) call.getFunctionDefinition();\n+    if (functionDefinition.equals(BuiltInFunctionDefinitions.EQUALS)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "7f7cbf527f6fa9558c7f0f1cec7f7df97f6aae36"}, "originalPosition": 166}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "7f7cbf527f6fa9558c7f0f1cec7f7df97f6aae36", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/7f7cbf527f6fa9558c7f0f1cec7f7df97f6aae36", "committedDate": "2020-12-17T06:50:22Z", "message": "fix some issue"}, "afterCommit": {"oid": "658b61d752ff517debf9e5ea5ebb110a5aaf8d94", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/658b61d752ff517debf9e5ea5ebb110a5aaf8d94", "committedDate": "2020-12-18T03:53:08Z", "message": "update  Expression to Optional"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "658b61d752ff517debf9e5ea5ebb110a5aaf8d94", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/658b61d752ff517debf9e5ea5ebb110a5aaf8d94", "committedDate": "2020-12-18T03:53:08Z", "message": "update  Expression to Optional"}, "afterCommit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/629c5afea86e90ac2c72fd8220d12a2543581b25", "committedDate": "2020-12-18T04:06:16Z", "message": "update  Expression to Optional"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1NzM1NDE0", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-555735414", "createdAt": "2020-12-18T18:55:03Z", "commit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxODo1NTowNFrOIIu2yQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxODo1NTowNFrOIIu2yQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjAyNzIwOQ==", "bodyText": "My IDE warns that this is a suspicious call because it gets a FunctionDefinition from a map keyed by BuiltInFunctionDefinition. To fix it, I think the map should be Map<FunctionDefinition, Operation>.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r546027209", "createdAt": "2020-12-18T18:55:04Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinition;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.NaNUtil;\n+\n+public class FlinkFilters {\n+  private FlinkFilters() {\n+  }\n+\n+  private static final Map<BuiltInFunctionDefinition, Operation> FILTERS = ImmutableMap\n+      .<BuiltInFunctionDefinition, Operation>builder()\n+      .put(BuiltInFunctionDefinitions.EQUALS, Operation.EQ)\n+      .put(BuiltInFunctionDefinitions.NOT_EQUALS, Operation.NOT_EQ)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN, Operation.GT)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, Operation.GT_EQ)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN, Operation.LT)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, Operation.LT_EQ)\n+      .put(BuiltInFunctionDefinitions.IN, Operation.IN)\n+      .put(BuiltInFunctionDefinitions.IS_NULL, Operation.IS_NULL)\n+      .put(BuiltInFunctionDefinitions.IS_NOT_NULL, Operation.NOT_NULL)\n+      .put(BuiltInFunctionDefinitions.AND, Operation.AND)\n+      .put(BuiltInFunctionDefinitions.OR, Operation.OR)\n+      .put(BuiltInFunctionDefinitions.NOT, Operation.NOT)\n+      .build();\n+\n+\n+  public static Optional<Expression> convert(org.apache.flink.table.expressions.Expression flinkExpression) {\n+    if (!(flinkExpression instanceof CallExpression)) {\n+      return Optional.empty();\n+    }\n+\n+    CallExpression call = (CallExpression) flinkExpression;\n+    Operation op = FILTERS.get(call.getFunctionDefinition());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "originalPosition": 67}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1NzM1NDky", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-555735492", "createdAt": "2020-12-18T18:55:11Z", "commit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxODo1NToxMVrOIIu3CQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxODo1NToxMVrOIIu3CQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjAyNzI3Mw==", "bodyText": "Nit: extra newline.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r546027273", "createdAt": "2020-12-18T18:55:11Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinition;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.NaNUtil;\n+\n+public class FlinkFilters {\n+  private FlinkFilters() {\n+  }\n+\n+  private static final Map<BuiltInFunctionDefinition, Operation> FILTERS = ImmutableMap\n+      .<BuiltInFunctionDefinition, Operation>builder()\n+      .put(BuiltInFunctionDefinitions.EQUALS, Operation.EQ)\n+      .put(BuiltInFunctionDefinitions.NOT_EQUALS, Operation.NOT_EQ)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN, Operation.GT)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, Operation.GT_EQ)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN, Operation.LT)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, Operation.LT_EQ)\n+      .put(BuiltInFunctionDefinitions.IN, Operation.IN)\n+      .put(BuiltInFunctionDefinitions.IS_NULL, Operation.IS_NULL)\n+      .put(BuiltInFunctionDefinitions.IS_NOT_NULL, Operation.NOT_NULL)\n+      .put(BuiltInFunctionDefinitions.AND, Operation.AND)\n+      .put(BuiltInFunctionDefinitions.OR, Operation.OR)\n+      .put(BuiltInFunctionDefinitions.NOT, Operation.NOT)\n+      .build();\n+", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "originalPosition": 59}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1NzM3OTAz", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-555737903", "createdAt": "2020-12-18T18:58:11Z", "commit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxODo1ODoxMVrOIIu8_Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxODo1ODoxMVrOIIu8_Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjAyODc5Nw==", "bodyText": "How does FieldReferenceExpression.getName() reference nested fields?", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r546028797", "createdAt": "2020-12-18T18:58:11Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinition;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.NaNUtil;\n+\n+public class FlinkFilters {\n+  private FlinkFilters() {\n+  }\n+\n+  private static final Map<BuiltInFunctionDefinition, Operation> FILTERS = ImmutableMap\n+      .<BuiltInFunctionDefinition, Operation>builder()\n+      .put(BuiltInFunctionDefinitions.EQUALS, Operation.EQ)\n+      .put(BuiltInFunctionDefinitions.NOT_EQUALS, Operation.NOT_EQ)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN, Operation.GT)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, Operation.GT_EQ)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN, Operation.LT)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, Operation.LT_EQ)\n+      .put(BuiltInFunctionDefinitions.IN, Operation.IN)\n+      .put(BuiltInFunctionDefinitions.IS_NULL, Operation.IS_NULL)\n+      .put(BuiltInFunctionDefinitions.IS_NOT_NULL, Operation.NOT_NULL)\n+      .put(BuiltInFunctionDefinitions.AND, Operation.AND)\n+      .put(BuiltInFunctionDefinitions.OR, Operation.OR)\n+      .put(BuiltInFunctionDefinitions.NOT, Operation.NOT)\n+      .build();\n+\n+\n+  public static Optional<Expression> convert(org.apache.flink.table.expressions.Expression flinkExpression) {\n+    if (!(flinkExpression instanceof CallExpression)) {\n+      return Optional.empty();\n+    }\n+\n+    CallExpression call = (CallExpression) flinkExpression;\n+    Operation op = FILTERS.get(call.getFunctionDefinition());\n+    if (op != null) {\n+      switch (op) {\n+        case IS_NULL:\n+          FieldReferenceExpression isNullFilter = (FieldReferenceExpression) call.getResolvedChildren().get(0);\n+          return Optional.of(Expressions.isNull(isNullFilter.getName()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "originalPosition": 72}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1NzM5MDUx", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-555739051", "createdAt": "2020-12-18T18:59:34Z", "commit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxODo1OTozNFrOIIvBcA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxODo1OTozNFrOIIvBcA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjAyOTkzNg==", "bodyText": "Class is parameterized, so this should be Class<?>", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r546029936", "createdAt": "2020-12-18T18:59:34Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinition;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.NaNUtil;\n+\n+public class FlinkFilters {\n+  private FlinkFilters() {\n+  }\n+\n+  private static final Map<BuiltInFunctionDefinition, Operation> FILTERS = ImmutableMap\n+      .<BuiltInFunctionDefinition, Operation>builder()\n+      .put(BuiltInFunctionDefinitions.EQUALS, Operation.EQ)\n+      .put(BuiltInFunctionDefinitions.NOT_EQUALS, Operation.NOT_EQ)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN, Operation.GT)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, Operation.GT_EQ)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN, Operation.LT)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, Operation.LT_EQ)\n+      .put(BuiltInFunctionDefinitions.IN, Operation.IN)\n+      .put(BuiltInFunctionDefinitions.IS_NULL, Operation.IS_NULL)\n+      .put(BuiltInFunctionDefinitions.IS_NOT_NULL, Operation.NOT_NULL)\n+      .put(BuiltInFunctionDefinitions.AND, Operation.AND)\n+      .put(BuiltInFunctionDefinitions.OR, Operation.OR)\n+      .put(BuiltInFunctionDefinitions.NOT, Operation.NOT)\n+      .build();\n+\n+\n+  public static Optional<Expression> convert(org.apache.flink.table.expressions.Expression flinkExpression) {\n+    if (!(flinkExpression instanceof CallExpression)) {\n+      return Optional.empty();\n+    }\n+\n+    CallExpression call = (CallExpression) flinkExpression;\n+    Operation op = FILTERS.get(call.getFunctionDefinition());\n+    if (op != null) {\n+      switch (op) {\n+        case IS_NULL:\n+          FieldReferenceExpression isNullFilter = (FieldReferenceExpression) call.getResolvedChildren().get(0);\n+          return Optional.of(Expressions.isNull(isNullFilter.getName()));\n+\n+        case NOT_NULL:\n+          FieldReferenceExpression notNullExpression = (FieldReferenceExpression) call.getResolvedChildren().get(0);\n+          return Optional.of(Expressions.notNull(notNullExpression.getName()));\n+\n+        case LT:\n+          return convertComparisonExpression(Expressions::lessThan, call);\n+\n+        case LT_EQ:\n+          return convertComparisonExpression(Expressions::lessThanOrEqual, call);\n+\n+        case GT:\n+          return convertComparisonExpression(Expressions::greaterThan, call);\n+\n+        case GT_EQ:\n+          return convertComparisonExpression(Expressions::greaterThanOrEqual, call);\n+\n+        case EQ:\n+          return convertComparisonExpression(Expressions::equal, call);\n+\n+        case NOT_EQ:\n+          return convertComparisonExpression(Expressions::notEqual, call);\n+\n+        case IN:\n+          List<ResolvedExpression> args = call.getResolvedChildren();\n+          FieldReferenceExpression field = (FieldReferenceExpression) args.get(0);\n+          List<ResolvedExpression> values = args.subList(1, args.size());\n+\n+          List<Object> inputValues = values.stream().filter(\n+              expression -> {\n+                if (expression instanceof ValueLiteralExpression) {\n+                  return !((ValueLiteralExpression) flinkExpression).isNull();\n+                }\n+\n+                return false;\n+              }\n+          ).map(expression -> {\n+            ValueLiteralExpression valueLiteralExpression = (ValueLiteralExpression) expression;\n+            return valueLiteralExpression.getValueAs(valueLiteralExpression.getOutputDataType().getConversionClass())\n+                .get();\n+          }).collect(Collectors.toList());\n+          return Optional.of(Expressions.in(field.getName(), inputValues));\n+\n+        case NOT:\n+          Optional<Expression> child = convert(call.getResolvedChildren().get(0));\n+          if (child.isPresent()) {\n+            return Optional.of(Expressions.not(child.get()));\n+          }\n+\n+          return Optional.empty();\n+\n+        case AND: {\n+          return convertLogicExpression(Expressions::and, call);\n+        }\n+\n+        case OR: {\n+          return convertLogicExpression(Expressions::or, call);\n+        }\n+      }\n+    }\n+\n+    return Optional.empty();\n+  }\n+\n+  private static Optional<Expression> convertLogicExpression(BiFunction<Expression, Expression, Expression> function,\n+                                                             CallExpression call) {\n+    List<ResolvedExpression> args = call.getResolvedChildren();\n+    Optional<Expression> left = convert(args.get(0));\n+    Optional<Expression> right = convert(args.get(1));\n+    if (left.isPresent() && right.isPresent()) {\n+      return Optional.of(function.apply(left.get(), right.get()));\n+    }\n+\n+    return Optional.empty();\n+  }\n+\n+  private static Optional<Expression> convertComparisonExpression(BiFunction<String, Object, Expression> function,\n+                                                                  CallExpression call) {\n+    List<ResolvedExpression> args = call.getResolvedChildren();\n+    FieldReferenceExpression fieldReferenceExpression;\n+    ValueLiteralExpression valueLiteralExpression;\n+    if (literalOnRight(args)) {\n+      fieldReferenceExpression = (FieldReferenceExpression) args.get(0);\n+      valueLiteralExpression = (ValueLiteralExpression) args.get(1);\n+    } else {\n+      fieldReferenceExpression = (FieldReferenceExpression) args.get(1);\n+      valueLiteralExpression = (ValueLiteralExpression) args.get(0);\n+    }\n+\n+    String name = fieldReferenceExpression.getName();\n+    Class clazz = valueLiteralExpression.getOutputDataType().getConversionClass();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "originalPosition": 163}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1NzQwNDgy", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-555740482", "createdAt": "2020-12-18T19:01:46Z", "commit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxOTowMTo0N1rOIIvHiQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxOTowMTo0N1rOIIvHiQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjAzMTQ5Nw==", "bodyText": "ValueLiteralExpression allows the value to be null, in which case get here will throw an exception. How is this avoided? Does the parser reject col = null expressions?\n@openinx may be able to help here, too.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r546031497", "createdAt": "2020-12-18T19:01:47Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinition;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.NaNUtil;\n+\n+public class FlinkFilters {\n+  private FlinkFilters() {\n+  }\n+\n+  private static final Map<BuiltInFunctionDefinition, Operation> FILTERS = ImmutableMap\n+      .<BuiltInFunctionDefinition, Operation>builder()\n+      .put(BuiltInFunctionDefinitions.EQUALS, Operation.EQ)\n+      .put(BuiltInFunctionDefinitions.NOT_EQUALS, Operation.NOT_EQ)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN, Operation.GT)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, Operation.GT_EQ)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN, Operation.LT)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, Operation.LT_EQ)\n+      .put(BuiltInFunctionDefinitions.IN, Operation.IN)\n+      .put(BuiltInFunctionDefinitions.IS_NULL, Operation.IS_NULL)\n+      .put(BuiltInFunctionDefinitions.IS_NOT_NULL, Operation.NOT_NULL)\n+      .put(BuiltInFunctionDefinitions.AND, Operation.AND)\n+      .put(BuiltInFunctionDefinitions.OR, Operation.OR)\n+      .put(BuiltInFunctionDefinitions.NOT, Operation.NOT)\n+      .build();\n+\n+\n+  public static Optional<Expression> convert(org.apache.flink.table.expressions.Expression flinkExpression) {\n+    if (!(flinkExpression instanceof CallExpression)) {\n+      return Optional.empty();\n+    }\n+\n+    CallExpression call = (CallExpression) flinkExpression;\n+    Operation op = FILTERS.get(call.getFunctionDefinition());\n+    if (op != null) {\n+      switch (op) {\n+        case IS_NULL:\n+          FieldReferenceExpression isNullFilter = (FieldReferenceExpression) call.getResolvedChildren().get(0);\n+          return Optional.of(Expressions.isNull(isNullFilter.getName()));\n+\n+        case NOT_NULL:\n+          FieldReferenceExpression notNullExpression = (FieldReferenceExpression) call.getResolvedChildren().get(0);\n+          return Optional.of(Expressions.notNull(notNullExpression.getName()));\n+\n+        case LT:\n+          return convertComparisonExpression(Expressions::lessThan, call);\n+\n+        case LT_EQ:\n+          return convertComparisonExpression(Expressions::lessThanOrEqual, call);\n+\n+        case GT:\n+          return convertComparisonExpression(Expressions::greaterThan, call);\n+\n+        case GT_EQ:\n+          return convertComparisonExpression(Expressions::greaterThanOrEqual, call);\n+\n+        case EQ:\n+          return convertComparisonExpression(Expressions::equal, call);\n+\n+        case NOT_EQ:\n+          return convertComparisonExpression(Expressions::notEqual, call);\n+\n+        case IN:\n+          List<ResolvedExpression> args = call.getResolvedChildren();\n+          FieldReferenceExpression field = (FieldReferenceExpression) args.get(0);\n+          List<ResolvedExpression> values = args.subList(1, args.size());\n+\n+          List<Object> inputValues = values.stream().filter(\n+              expression -> {\n+                if (expression instanceof ValueLiteralExpression) {\n+                  return !((ValueLiteralExpression) flinkExpression).isNull();\n+                }\n+\n+                return false;\n+              }\n+          ).map(expression -> {\n+            ValueLiteralExpression valueLiteralExpression = (ValueLiteralExpression) expression;\n+            return valueLiteralExpression.getValueAs(valueLiteralExpression.getOutputDataType().getConversionClass())\n+                .get();\n+          }).collect(Collectors.toList());\n+          return Optional.of(Expressions.in(field.getName(), inputValues));\n+\n+        case NOT:\n+          Optional<Expression> child = convert(call.getResolvedChildren().get(0));\n+          if (child.isPresent()) {\n+            return Optional.of(Expressions.not(child.get()));\n+          }\n+\n+          return Optional.empty();\n+\n+        case AND: {\n+          return convertLogicExpression(Expressions::and, call);\n+        }\n+\n+        case OR: {\n+          return convertLogicExpression(Expressions::or, call);\n+        }\n+      }\n+    }\n+\n+    return Optional.empty();\n+  }\n+\n+  private static Optional<Expression> convertLogicExpression(BiFunction<Expression, Expression, Expression> function,\n+                                                             CallExpression call) {\n+    List<ResolvedExpression> args = call.getResolvedChildren();\n+    Optional<Expression> left = convert(args.get(0));\n+    Optional<Expression> right = convert(args.get(1));\n+    if (left.isPresent() && right.isPresent()) {\n+      return Optional.of(function.apply(left.get(), right.get()));\n+    }\n+\n+    return Optional.empty();\n+  }\n+\n+  private static Optional<Expression> convertComparisonExpression(BiFunction<String, Object, Expression> function,\n+                                                                  CallExpression call) {\n+    List<ResolvedExpression> args = call.getResolvedChildren();\n+    FieldReferenceExpression fieldReferenceExpression;\n+    ValueLiteralExpression valueLiteralExpression;\n+    if (literalOnRight(args)) {\n+      fieldReferenceExpression = (FieldReferenceExpression) args.get(0);\n+      valueLiteralExpression = (ValueLiteralExpression) args.get(1);\n+    } else {\n+      fieldReferenceExpression = (FieldReferenceExpression) args.get(1);\n+      valueLiteralExpression = (ValueLiteralExpression) args.get(0);\n+    }\n+\n+    String name = fieldReferenceExpression.getName();\n+    Class clazz = valueLiteralExpression.getOutputDataType().getConversionClass();\n+    Object value = valueLiteralExpression.getValueAs(clazz).get();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "originalPosition": 164}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1NzQyMjI1", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-555742225", "createdAt": "2020-12-18T19:04:35Z", "commit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxOTowNDozNVrOIIvMuw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxOTowNDozNVrOIIvMuw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjAzMjgyNw==", "bodyText": "I think it would be cleaner to have a method to extract the column name and literal value as a pair, rather than passing the function to create an expression in here. Handling the expression type in the caller, but then also handling it here doesn't provide very good separation of concerns.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r546032827", "createdAt": "2020-12-18T19:04:35Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinition;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.NaNUtil;\n+\n+public class FlinkFilters {\n+  private FlinkFilters() {\n+  }\n+\n+  private static final Map<BuiltInFunctionDefinition, Operation> FILTERS = ImmutableMap\n+      .<BuiltInFunctionDefinition, Operation>builder()\n+      .put(BuiltInFunctionDefinitions.EQUALS, Operation.EQ)\n+      .put(BuiltInFunctionDefinitions.NOT_EQUALS, Operation.NOT_EQ)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN, Operation.GT)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, Operation.GT_EQ)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN, Operation.LT)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, Operation.LT_EQ)\n+      .put(BuiltInFunctionDefinitions.IN, Operation.IN)\n+      .put(BuiltInFunctionDefinitions.IS_NULL, Operation.IS_NULL)\n+      .put(BuiltInFunctionDefinitions.IS_NOT_NULL, Operation.NOT_NULL)\n+      .put(BuiltInFunctionDefinitions.AND, Operation.AND)\n+      .put(BuiltInFunctionDefinitions.OR, Operation.OR)\n+      .put(BuiltInFunctionDefinitions.NOT, Operation.NOT)\n+      .build();\n+\n+\n+  public static Optional<Expression> convert(org.apache.flink.table.expressions.Expression flinkExpression) {\n+    if (!(flinkExpression instanceof CallExpression)) {\n+      return Optional.empty();\n+    }\n+\n+    CallExpression call = (CallExpression) flinkExpression;\n+    Operation op = FILTERS.get(call.getFunctionDefinition());\n+    if (op != null) {\n+      switch (op) {\n+        case IS_NULL:\n+          FieldReferenceExpression isNullFilter = (FieldReferenceExpression) call.getResolvedChildren().get(0);\n+          return Optional.of(Expressions.isNull(isNullFilter.getName()));\n+\n+        case NOT_NULL:\n+          FieldReferenceExpression notNullExpression = (FieldReferenceExpression) call.getResolvedChildren().get(0);\n+          return Optional.of(Expressions.notNull(notNullExpression.getName()));\n+\n+        case LT:\n+          return convertComparisonExpression(Expressions::lessThan, call);\n+\n+        case LT_EQ:\n+          return convertComparisonExpression(Expressions::lessThanOrEqual, call);\n+\n+        case GT:\n+          return convertComparisonExpression(Expressions::greaterThan, call);\n+\n+        case GT_EQ:\n+          return convertComparisonExpression(Expressions::greaterThanOrEqual, call);\n+\n+        case EQ:\n+          return convertComparisonExpression(Expressions::equal, call);\n+\n+        case NOT_EQ:\n+          return convertComparisonExpression(Expressions::notEqual, call);\n+\n+        case IN:\n+          List<ResolvedExpression> args = call.getResolvedChildren();\n+          FieldReferenceExpression field = (FieldReferenceExpression) args.get(0);\n+          List<ResolvedExpression> values = args.subList(1, args.size());\n+\n+          List<Object> inputValues = values.stream().filter(\n+              expression -> {\n+                if (expression instanceof ValueLiteralExpression) {\n+                  return !((ValueLiteralExpression) flinkExpression).isNull();\n+                }\n+\n+                return false;\n+              }\n+          ).map(expression -> {\n+            ValueLiteralExpression valueLiteralExpression = (ValueLiteralExpression) expression;\n+            return valueLiteralExpression.getValueAs(valueLiteralExpression.getOutputDataType().getConversionClass())\n+                .get();\n+          }).collect(Collectors.toList());\n+          return Optional.of(Expressions.in(field.getName(), inputValues));\n+\n+        case NOT:\n+          Optional<Expression> child = convert(call.getResolvedChildren().get(0));\n+          if (child.isPresent()) {\n+            return Optional.of(Expressions.not(child.get()));\n+          }\n+\n+          return Optional.empty();\n+\n+        case AND: {\n+          return convertLogicExpression(Expressions::and, call);\n+        }\n+\n+        case OR: {\n+          return convertLogicExpression(Expressions::or, call);\n+        }\n+      }\n+    }\n+\n+    return Optional.empty();\n+  }\n+\n+  private static Optional<Expression> convertLogicExpression(BiFunction<Expression, Expression, Expression> function,\n+                                                             CallExpression call) {\n+    List<ResolvedExpression> args = call.getResolvedChildren();\n+    Optional<Expression> left = convert(args.get(0));\n+    Optional<Expression> right = convert(args.get(1));\n+    if (left.isPresent() && right.isPresent()) {\n+      return Optional.of(function.apply(left.get(), right.get()));\n+    }\n+\n+    return Optional.empty();\n+  }\n+\n+  private static Optional<Expression> convertComparisonExpression(BiFunction<String, Object, Expression> function,\n+                                                                  CallExpression call) {\n+    List<ResolvedExpression> args = call.getResolvedChildren();\n+    FieldReferenceExpression fieldReferenceExpression;\n+    ValueLiteralExpression valueLiteralExpression;\n+    if (literalOnRight(args)) {\n+      fieldReferenceExpression = (FieldReferenceExpression) args.get(0);\n+      valueLiteralExpression = (ValueLiteralExpression) args.get(1);\n+    } else {\n+      fieldReferenceExpression = (FieldReferenceExpression) args.get(1);\n+      valueLiteralExpression = (ValueLiteralExpression) args.get(0);\n+    }\n+\n+    String name = fieldReferenceExpression.getName();\n+    Class clazz = valueLiteralExpression.getOutputDataType().getConversionClass();\n+    Object value = valueLiteralExpression.getValueAs(clazz).get();\n+\n+    BuiltInFunctionDefinition functionDefinition = (BuiltInFunctionDefinition) call.getFunctionDefinition();\n+    if (functionDefinition.equals(BuiltInFunctionDefinitions.EQUALS) &&\n+        functionDefinition.equals(BuiltInFunctionDefinitions.NOT_EQUALS)) {\n+      Preconditions.checkNotNull(value, \"Expression is always false : %s\", call);\n+      if (NaNUtil.isNaN(value)) {\n+        return Optional.of(Expressions.isNaN(name));\n+      } else {\n+        return Optional.of(function.apply(name, value));\n+      }\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "originalPosition": 175}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1NzQ1MDA3", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-555745007", "createdAt": "2020-12-18T19:08:53Z", "commit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxOTowODo1M1rOIIvUmA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxOTowODo1M1rOIIvUmA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjAzNDg0MA==", "bodyText": "This should not discard anything that is not a ValueLiteralExpression. Instead, if there is a non-literal this should either throw IllegalArgumentException or return Optional.empty to signal that the expression cannot be converted.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r546034840", "createdAt": "2020-12-18T19:08:53Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinition;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.NaNUtil;\n+\n+public class FlinkFilters {\n+  private FlinkFilters() {\n+  }\n+\n+  private static final Map<BuiltInFunctionDefinition, Operation> FILTERS = ImmutableMap\n+      .<BuiltInFunctionDefinition, Operation>builder()\n+      .put(BuiltInFunctionDefinitions.EQUALS, Operation.EQ)\n+      .put(BuiltInFunctionDefinitions.NOT_EQUALS, Operation.NOT_EQ)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN, Operation.GT)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, Operation.GT_EQ)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN, Operation.LT)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, Operation.LT_EQ)\n+      .put(BuiltInFunctionDefinitions.IN, Operation.IN)\n+      .put(BuiltInFunctionDefinitions.IS_NULL, Operation.IS_NULL)\n+      .put(BuiltInFunctionDefinitions.IS_NOT_NULL, Operation.NOT_NULL)\n+      .put(BuiltInFunctionDefinitions.AND, Operation.AND)\n+      .put(BuiltInFunctionDefinitions.OR, Operation.OR)\n+      .put(BuiltInFunctionDefinitions.NOT, Operation.NOT)\n+      .build();\n+\n+\n+  public static Optional<Expression> convert(org.apache.flink.table.expressions.Expression flinkExpression) {\n+    if (!(flinkExpression instanceof CallExpression)) {\n+      return Optional.empty();\n+    }\n+\n+    CallExpression call = (CallExpression) flinkExpression;\n+    Operation op = FILTERS.get(call.getFunctionDefinition());\n+    if (op != null) {\n+      switch (op) {\n+        case IS_NULL:\n+          FieldReferenceExpression isNullFilter = (FieldReferenceExpression) call.getResolvedChildren().get(0);\n+          return Optional.of(Expressions.isNull(isNullFilter.getName()));\n+\n+        case NOT_NULL:\n+          FieldReferenceExpression notNullExpression = (FieldReferenceExpression) call.getResolvedChildren().get(0);\n+          return Optional.of(Expressions.notNull(notNullExpression.getName()));\n+\n+        case LT:\n+          return convertComparisonExpression(Expressions::lessThan, call);\n+\n+        case LT_EQ:\n+          return convertComparisonExpression(Expressions::lessThanOrEqual, call);\n+\n+        case GT:\n+          return convertComparisonExpression(Expressions::greaterThan, call);\n+\n+        case GT_EQ:\n+          return convertComparisonExpression(Expressions::greaterThanOrEqual, call);\n+\n+        case EQ:\n+          return convertComparisonExpression(Expressions::equal, call);\n+\n+        case NOT_EQ:\n+          return convertComparisonExpression(Expressions::notEqual, call);\n+\n+        case IN:\n+          List<ResolvedExpression> args = call.getResolvedChildren();\n+          FieldReferenceExpression field = (FieldReferenceExpression) args.get(0);\n+          List<ResolvedExpression> values = args.subList(1, args.size());\n+\n+          List<Object> inputValues = values.stream().filter(\n+              expression -> {\n+                if (expression instanceof ValueLiteralExpression) {\n+                  return !((ValueLiteralExpression) flinkExpression).isNull();\n+                }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "originalPosition": 105}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1NzQ4ODI4", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-555748828", "createdAt": "2020-12-18T19:11:41Z", "commit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxOToxMTo0MVrOIIvb9g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxOToxMTo0MVrOIIvb9g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjAzNjcyNg==", "bodyText": "I think this should be converted to List<ValueLiteralExpression> to simplify value conversion.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r546036726", "createdAt": "2020-12-18T19:11:41Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinition;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.NaNUtil;\n+\n+public class FlinkFilters {\n+  private FlinkFilters() {\n+  }\n+\n+  private static final Map<BuiltInFunctionDefinition, Operation> FILTERS = ImmutableMap\n+      .<BuiltInFunctionDefinition, Operation>builder()\n+      .put(BuiltInFunctionDefinitions.EQUALS, Operation.EQ)\n+      .put(BuiltInFunctionDefinitions.NOT_EQUALS, Operation.NOT_EQ)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN, Operation.GT)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, Operation.GT_EQ)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN, Operation.LT)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, Operation.LT_EQ)\n+      .put(BuiltInFunctionDefinitions.IN, Operation.IN)\n+      .put(BuiltInFunctionDefinitions.IS_NULL, Operation.IS_NULL)\n+      .put(BuiltInFunctionDefinitions.IS_NOT_NULL, Operation.NOT_NULL)\n+      .put(BuiltInFunctionDefinitions.AND, Operation.AND)\n+      .put(BuiltInFunctionDefinitions.OR, Operation.OR)\n+      .put(BuiltInFunctionDefinitions.NOT, Operation.NOT)\n+      .build();\n+\n+\n+  public static Optional<Expression> convert(org.apache.flink.table.expressions.Expression flinkExpression) {\n+    if (!(flinkExpression instanceof CallExpression)) {\n+      return Optional.empty();\n+    }\n+\n+    CallExpression call = (CallExpression) flinkExpression;\n+    Operation op = FILTERS.get(call.getFunctionDefinition());\n+    if (op != null) {\n+      switch (op) {\n+        case IS_NULL:\n+          FieldReferenceExpression isNullFilter = (FieldReferenceExpression) call.getResolvedChildren().get(0);\n+          return Optional.of(Expressions.isNull(isNullFilter.getName()));\n+\n+        case NOT_NULL:\n+          FieldReferenceExpression notNullExpression = (FieldReferenceExpression) call.getResolvedChildren().get(0);\n+          return Optional.of(Expressions.notNull(notNullExpression.getName()));\n+\n+        case LT:\n+          return convertComparisonExpression(Expressions::lessThan, call);\n+\n+        case LT_EQ:\n+          return convertComparisonExpression(Expressions::lessThanOrEqual, call);\n+\n+        case GT:\n+          return convertComparisonExpression(Expressions::greaterThan, call);\n+\n+        case GT_EQ:\n+          return convertComparisonExpression(Expressions::greaterThanOrEqual, call);\n+\n+        case EQ:\n+          return convertComparisonExpression(Expressions::equal, call);\n+\n+        case NOT_EQ:\n+          return convertComparisonExpression(Expressions::notEqual, call);\n+\n+        case IN:\n+          List<ResolvedExpression> args = call.getResolvedChildren();\n+          FieldReferenceExpression field = (FieldReferenceExpression) args.get(0);\n+          List<ResolvedExpression> values = args.subList(1, args.size());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "originalPosition": 99}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1NzUxMTE5", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-555751119", "createdAt": "2020-12-18T19:14:40Z", "commit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxOToxNDo0MVrOIIvpqw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxOToxNDo0MVrOIIvpqw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjA0MDIzNQ==", "bodyText": "Null values can't be ignored. This should either return Optional.empty or throw IllegalArgumentException if there is a null value.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r546040235", "createdAt": "2020-12-18T19:14:41Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinition;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.NaNUtil;\n+\n+public class FlinkFilters {\n+  private FlinkFilters() {\n+  }\n+\n+  private static final Map<BuiltInFunctionDefinition, Operation> FILTERS = ImmutableMap\n+      .<BuiltInFunctionDefinition, Operation>builder()\n+      .put(BuiltInFunctionDefinitions.EQUALS, Operation.EQ)\n+      .put(BuiltInFunctionDefinitions.NOT_EQUALS, Operation.NOT_EQ)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN, Operation.GT)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, Operation.GT_EQ)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN, Operation.LT)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, Operation.LT_EQ)\n+      .put(BuiltInFunctionDefinitions.IN, Operation.IN)\n+      .put(BuiltInFunctionDefinitions.IS_NULL, Operation.IS_NULL)\n+      .put(BuiltInFunctionDefinitions.IS_NOT_NULL, Operation.NOT_NULL)\n+      .put(BuiltInFunctionDefinitions.AND, Operation.AND)\n+      .put(BuiltInFunctionDefinitions.OR, Operation.OR)\n+      .put(BuiltInFunctionDefinitions.NOT, Operation.NOT)\n+      .build();\n+\n+\n+  public static Optional<Expression> convert(org.apache.flink.table.expressions.Expression flinkExpression) {\n+    if (!(flinkExpression instanceof CallExpression)) {\n+      return Optional.empty();\n+    }\n+\n+    CallExpression call = (CallExpression) flinkExpression;\n+    Operation op = FILTERS.get(call.getFunctionDefinition());\n+    if (op != null) {\n+      switch (op) {\n+        case IS_NULL:\n+          FieldReferenceExpression isNullFilter = (FieldReferenceExpression) call.getResolvedChildren().get(0);\n+          return Optional.of(Expressions.isNull(isNullFilter.getName()));\n+\n+        case NOT_NULL:\n+          FieldReferenceExpression notNullExpression = (FieldReferenceExpression) call.getResolvedChildren().get(0);\n+          return Optional.of(Expressions.notNull(notNullExpression.getName()));\n+\n+        case LT:\n+          return convertComparisonExpression(Expressions::lessThan, call);\n+\n+        case LT_EQ:\n+          return convertComparisonExpression(Expressions::lessThanOrEqual, call);\n+\n+        case GT:\n+          return convertComparisonExpression(Expressions::greaterThan, call);\n+\n+        case GT_EQ:\n+          return convertComparisonExpression(Expressions::greaterThanOrEqual, call);\n+\n+        case EQ:\n+          return convertComparisonExpression(Expressions::equal, call);\n+\n+        case NOT_EQ:\n+          return convertComparisonExpression(Expressions::notEqual, call);\n+\n+        case IN:\n+          List<ResolvedExpression> args = call.getResolvedChildren();\n+          FieldReferenceExpression field = (FieldReferenceExpression) args.get(0);\n+          List<ResolvedExpression> values = args.subList(1, args.size());\n+\n+          List<Object> inputValues = values.stream().filter(\n+              expression -> {\n+                if (expression instanceof ValueLiteralExpression) {\n+                  return !((ValueLiteralExpression) flinkExpression).isNull();\n+                }\n+\n+                return false;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "originalPosition": 107}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1NzU0MDI5", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-555754029", "createdAt": "2020-12-18T19:19:46Z", "commit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxOToxOTo0N1rOIIv0MQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxOToxOTo0N1rOIIv0MQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjA0MjkyOQ==", "bodyText": "There are several calls to getResolvedChildren().get(0). I think that should be converted to a method that validates there is only one child and also validates the type:\n  private <T extends ResolvedExpression> Optional<T> getOnlyChild(CallExpression call, Class<T> expectedChildClass) {\n    List<ResolvedExpression> children = call.getResolvedChildren();\n    if (children.size() != 1) {\n      return Optional.empty();\n    }\n\n    ResolvedExpression child = children.get(0);\n    if (!expectedChildClass.isInstance(child)) {\n      return Optional.empty();\n    }\n\n    return Optional.of(expectedChildClass.cast(child));\n  }", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r546042929", "createdAt": "2020-12-18T19:19:47Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinition;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.NaNUtil;\n+\n+public class FlinkFilters {\n+  private FlinkFilters() {\n+  }\n+\n+  private static final Map<BuiltInFunctionDefinition, Operation> FILTERS = ImmutableMap\n+      .<BuiltInFunctionDefinition, Operation>builder()\n+      .put(BuiltInFunctionDefinitions.EQUALS, Operation.EQ)\n+      .put(BuiltInFunctionDefinitions.NOT_EQUALS, Operation.NOT_EQ)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN, Operation.GT)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, Operation.GT_EQ)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN, Operation.LT)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, Operation.LT_EQ)\n+      .put(BuiltInFunctionDefinitions.IN, Operation.IN)\n+      .put(BuiltInFunctionDefinitions.IS_NULL, Operation.IS_NULL)\n+      .put(BuiltInFunctionDefinitions.IS_NOT_NULL, Operation.NOT_NULL)\n+      .put(BuiltInFunctionDefinitions.AND, Operation.AND)\n+      .put(BuiltInFunctionDefinitions.OR, Operation.OR)\n+      .put(BuiltInFunctionDefinitions.NOT, Operation.NOT)\n+      .build();\n+\n+\n+  public static Optional<Expression> convert(org.apache.flink.table.expressions.Expression flinkExpression) {\n+    if (!(flinkExpression instanceof CallExpression)) {\n+      return Optional.empty();\n+    }\n+\n+    CallExpression call = (CallExpression) flinkExpression;\n+    Operation op = FILTERS.get(call.getFunctionDefinition());\n+    if (op != null) {\n+      switch (op) {\n+        case IS_NULL:\n+          FieldReferenceExpression isNullFilter = (FieldReferenceExpression) call.getResolvedChildren().get(0);\n+          return Optional.of(Expressions.isNull(isNullFilter.getName()));\n+\n+        case NOT_NULL:\n+          FieldReferenceExpression notNullExpression = (FieldReferenceExpression) call.getResolvedChildren().get(0);\n+          return Optional.of(Expressions.notNull(notNullExpression.getName()));\n+\n+        case LT:\n+          return convertComparisonExpression(Expressions::lessThan, call);\n+\n+        case LT_EQ:\n+          return convertComparisonExpression(Expressions::lessThanOrEqual, call);\n+\n+        case GT:\n+          return convertComparisonExpression(Expressions::greaterThan, call);\n+\n+        case GT_EQ:\n+          return convertComparisonExpression(Expressions::greaterThanOrEqual, call);\n+\n+        case EQ:\n+          return convertComparisonExpression(Expressions::equal, call);\n+\n+        case NOT_EQ:\n+          return convertComparisonExpression(Expressions::notEqual, call);\n+\n+        case IN:\n+          List<ResolvedExpression> args = call.getResolvedChildren();\n+          FieldReferenceExpression field = (FieldReferenceExpression) args.get(0);\n+          List<ResolvedExpression> values = args.subList(1, args.size());\n+\n+          List<Object> inputValues = values.stream().filter(\n+              expression -> {\n+                if (expression instanceof ValueLiteralExpression) {\n+                  return !((ValueLiteralExpression) flinkExpression).isNull();\n+                }\n+\n+                return false;\n+              }\n+          ).map(expression -> {\n+            ValueLiteralExpression valueLiteralExpression = (ValueLiteralExpression) expression;\n+            return valueLiteralExpression.getValueAs(valueLiteralExpression.getOutputDataType().getConversionClass())\n+                .get();\n+          }).collect(Collectors.toList());\n+          return Optional.of(Expressions.in(field.getName(), inputValues));\n+\n+        case NOT:\n+          Optional<Expression> child = convert(call.getResolvedChildren().get(0));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "originalPosition": 117}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1NzU0Nzk3", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-555754797", "createdAt": "2020-12-18T19:21:01Z", "commit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxOToyMTowMlrOIIv2kA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxOToyMTowMlrOIIv2kA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjA0MzUzNg==", "bodyText": "This can be child.map(Expressions::not).", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r546043536", "createdAt": "2020-12-18T19:21:02Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinition;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.NaNUtil;\n+\n+public class FlinkFilters {\n+  private FlinkFilters() {\n+  }\n+\n+  private static final Map<BuiltInFunctionDefinition, Operation> FILTERS = ImmutableMap\n+      .<BuiltInFunctionDefinition, Operation>builder()\n+      .put(BuiltInFunctionDefinitions.EQUALS, Operation.EQ)\n+      .put(BuiltInFunctionDefinitions.NOT_EQUALS, Operation.NOT_EQ)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN, Operation.GT)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, Operation.GT_EQ)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN, Operation.LT)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, Operation.LT_EQ)\n+      .put(BuiltInFunctionDefinitions.IN, Operation.IN)\n+      .put(BuiltInFunctionDefinitions.IS_NULL, Operation.IS_NULL)\n+      .put(BuiltInFunctionDefinitions.IS_NOT_NULL, Operation.NOT_NULL)\n+      .put(BuiltInFunctionDefinitions.AND, Operation.AND)\n+      .put(BuiltInFunctionDefinitions.OR, Operation.OR)\n+      .put(BuiltInFunctionDefinitions.NOT, Operation.NOT)\n+      .build();\n+\n+\n+  public static Optional<Expression> convert(org.apache.flink.table.expressions.Expression flinkExpression) {\n+    if (!(flinkExpression instanceof CallExpression)) {\n+      return Optional.empty();\n+    }\n+\n+    CallExpression call = (CallExpression) flinkExpression;\n+    Operation op = FILTERS.get(call.getFunctionDefinition());\n+    if (op != null) {\n+      switch (op) {\n+        case IS_NULL:\n+          FieldReferenceExpression isNullFilter = (FieldReferenceExpression) call.getResolvedChildren().get(0);\n+          return Optional.of(Expressions.isNull(isNullFilter.getName()));\n+\n+        case NOT_NULL:\n+          FieldReferenceExpression notNullExpression = (FieldReferenceExpression) call.getResolvedChildren().get(0);\n+          return Optional.of(Expressions.notNull(notNullExpression.getName()));\n+\n+        case LT:\n+          return convertComparisonExpression(Expressions::lessThan, call);\n+\n+        case LT_EQ:\n+          return convertComparisonExpression(Expressions::lessThanOrEqual, call);\n+\n+        case GT:\n+          return convertComparisonExpression(Expressions::greaterThan, call);\n+\n+        case GT_EQ:\n+          return convertComparisonExpression(Expressions::greaterThanOrEqual, call);\n+\n+        case EQ:\n+          return convertComparisonExpression(Expressions::equal, call);\n+\n+        case NOT_EQ:\n+          return convertComparisonExpression(Expressions::notEqual, call);\n+\n+        case IN:\n+          List<ResolvedExpression> args = call.getResolvedChildren();\n+          FieldReferenceExpression field = (FieldReferenceExpression) args.get(0);\n+          List<ResolvedExpression> values = args.subList(1, args.size());\n+\n+          List<Object> inputValues = values.stream().filter(\n+              expression -> {\n+                if (expression instanceof ValueLiteralExpression) {\n+                  return !((ValueLiteralExpression) flinkExpression).isNull();\n+                }\n+\n+                return false;\n+              }\n+          ).map(expression -> {\n+            ValueLiteralExpression valueLiteralExpression = (ValueLiteralExpression) expression;\n+            return valueLiteralExpression.getValueAs(valueLiteralExpression.getOutputDataType().getConversionClass())\n+                .get();\n+          }).collect(Collectors.toList());\n+          return Optional.of(Expressions.in(field.getName(), inputValues));\n+\n+        case NOT:\n+          Optional<Expression> child = convert(call.getResolvedChildren().get(0));\n+          if (child.isPresent()) {\n+            return Optional.of(Expressions.not(child.get()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "originalPosition": 119}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1NzU3NzU0", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-555757754", "createdAt": "2020-12-18T19:24:40Z", "commit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxOToyNDo0MVrOIIwA-g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxOToyNDo0MVrOIIwA-g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjA0NjIwMg==", "bodyText": "The literal value needs to be converted to Iceberg's internal representation before being passed to create an expression. Flink will return LocalDate, LocalTime, LocalDateTime, etc. just in the getValueAs method. And it isn't clear whether the value stored in the literal is the correct representation for other types as well.\n@openinx, could you help recommend how to do the conversion here?", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r546046202", "createdAt": "2020-12-18T19:24:41Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinition;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.NaNUtil;\n+\n+public class FlinkFilters {\n+  private FlinkFilters() {\n+  }\n+\n+  private static final Map<BuiltInFunctionDefinition, Operation> FILTERS = ImmutableMap\n+      .<BuiltInFunctionDefinition, Operation>builder()\n+      .put(BuiltInFunctionDefinitions.EQUALS, Operation.EQ)\n+      .put(BuiltInFunctionDefinitions.NOT_EQUALS, Operation.NOT_EQ)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN, Operation.GT)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, Operation.GT_EQ)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN, Operation.LT)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, Operation.LT_EQ)\n+      .put(BuiltInFunctionDefinitions.IN, Operation.IN)\n+      .put(BuiltInFunctionDefinitions.IS_NULL, Operation.IS_NULL)\n+      .put(BuiltInFunctionDefinitions.IS_NOT_NULL, Operation.NOT_NULL)\n+      .put(BuiltInFunctionDefinitions.AND, Operation.AND)\n+      .put(BuiltInFunctionDefinitions.OR, Operation.OR)\n+      .put(BuiltInFunctionDefinitions.NOT, Operation.NOT)\n+      .build();\n+\n+\n+  public static Optional<Expression> convert(org.apache.flink.table.expressions.Expression flinkExpression) {\n+    if (!(flinkExpression instanceof CallExpression)) {\n+      return Optional.empty();\n+    }\n+\n+    CallExpression call = (CallExpression) flinkExpression;\n+    Operation op = FILTERS.get(call.getFunctionDefinition());\n+    if (op != null) {\n+      switch (op) {\n+        case IS_NULL:\n+          FieldReferenceExpression isNullFilter = (FieldReferenceExpression) call.getResolvedChildren().get(0);\n+          return Optional.of(Expressions.isNull(isNullFilter.getName()));\n+\n+        case NOT_NULL:\n+          FieldReferenceExpression notNullExpression = (FieldReferenceExpression) call.getResolvedChildren().get(0);\n+          return Optional.of(Expressions.notNull(notNullExpression.getName()));\n+\n+        case LT:\n+          return convertComparisonExpression(Expressions::lessThan, call);\n+\n+        case LT_EQ:\n+          return convertComparisonExpression(Expressions::lessThanOrEqual, call);\n+\n+        case GT:\n+          return convertComparisonExpression(Expressions::greaterThan, call);\n+\n+        case GT_EQ:\n+          return convertComparisonExpression(Expressions::greaterThanOrEqual, call);\n+\n+        case EQ:\n+          return convertComparisonExpression(Expressions::equal, call);\n+\n+        case NOT_EQ:\n+          return convertComparisonExpression(Expressions::notEqual, call);\n+\n+        case IN:\n+          List<ResolvedExpression> args = call.getResolvedChildren();\n+          FieldReferenceExpression field = (FieldReferenceExpression) args.get(0);\n+          List<ResolvedExpression> values = args.subList(1, args.size());\n+\n+          List<Object> inputValues = values.stream().filter(\n+              expression -> {\n+                if (expression instanceof ValueLiteralExpression) {\n+                  return !((ValueLiteralExpression) flinkExpression).isNull();\n+                }\n+\n+                return false;\n+              }\n+          ).map(expression -> {\n+            ValueLiteralExpression valueLiteralExpression = (ValueLiteralExpression) expression;\n+            return valueLiteralExpression.getValueAs(valueLiteralExpression.getOutputDataType().getConversionClass())\n+                .get();\n+          }).collect(Collectors.toList());\n+          return Optional.of(Expressions.in(field.getName(), inputValues));\n+\n+        case NOT:\n+          Optional<Expression> child = convert(call.getResolvedChildren().get(0));\n+          if (child.isPresent()) {\n+            return Optional.of(Expressions.not(child.get()));\n+          }\n+\n+          return Optional.empty();\n+\n+        case AND: {\n+          return convertLogicExpression(Expressions::and, call);\n+        }\n+\n+        case OR: {\n+          return convertLogicExpression(Expressions::or, call);\n+        }\n+      }\n+    }\n+\n+    return Optional.empty();\n+  }\n+\n+  private static Optional<Expression> convertLogicExpression(BiFunction<Expression, Expression, Expression> function,\n+                                                             CallExpression call) {\n+    List<ResolvedExpression> args = call.getResolvedChildren();\n+    Optional<Expression> left = convert(args.get(0));\n+    Optional<Expression> right = convert(args.get(1));\n+    if (left.isPresent() && right.isPresent()) {\n+      return Optional.of(function.apply(left.get(), right.get()));\n+    }\n+\n+    return Optional.empty();\n+  }\n+\n+  private static Optional<Expression> convertComparisonExpression(BiFunction<String, Object, Expression> function,\n+                                                                  CallExpression call) {\n+    List<ResolvedExpression> args = call.getResolvedChildren();\n+    FieldReferenceExpression fieldReferenceExpression;\n+    ValueLiteralExpression valueLiteralExpression;\n+    if (literalOnRight(args)) {\n+      fieldReferenceExpression = (FieldReferenceExpression) args.get(0);\n+      valueLiteralExpression = (ValueLiteralExpression) args.get(1);\n+    } else {\n+      fieldReferenceExpression = (FieldReferenceExpression) args.get(1);\n+      valueLiteralExpression = (ValueLiteralExpression) args.get(0);\n+    }\n+\n+    String name = fieldReferenceExpression.getName();\n+    Class clazz = valueLiteralExpression.getOutputDataType().getConversionClass();\n+    Object value = valueLiteralExpression.getValueAs(clazz).get();\n+\n+    BuiltInFunctionDefinition functionDefinition = (BuiltInFunctionDefinition) call.getFunctionDefinition();\n+    if (functionDefinition.equals(BuiltInFunctionDefinitions.EQUALS) &&\n+        functionDefinition.equals(BuiltInFunctionDefinitions.NOT_EQUALS)) {\n+      Preconditions.checkNotNull(value, \"Expression is always false : %s\", call);\n+      if (NaNUtil.isNaN(value)) {\n+        return Optional.of(Expressions.isNaN(name));\n+      } else {\n+        return Optional.of(function.apply(name, value));\n+      }\n+    }\n+\n+    return Optional.of(function.apply(name, value));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "originalPosition": 177}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1NzU4NzU3", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-555758757", "createdAt": "2020-12-18T19:26:16Z", "commit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxOToyNjoxNlrOIIwEEw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxOToyNjoxNlrOIIwEEw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjA0Njk5NQ==", "bodyText": "Tests should be broken into individual methods that are each a test case. To share code, use @Before and @After and different test suites.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r546046995", "createdAt": "2020-12-18T19:26:16Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkTableSource.java", "diffHunk": "@@ -102,4 +105,154 @@ public void testLimitPushDown() {\n     Assert.assertEquals(\"should have 1 record\", 1, mixedResult.size());\n     Assert.assertArrayEquals(\"Should produce the expected records\", mixedResult.get(0), new Object[] {1, \"a\"});\n   }\n+\n+  @Test\n+  public void testFilterPushDown() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "originalPosition": 16}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU1NzYwODk5", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-555760899", "createdAt": "2020-12-18T19:29:45Z", "commit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxOToyOTo0NVrOIIwK6w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0xOFQxOToyOTo0NVrOIIwK6w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0NjA0ODc0Nw==", "bodyText": "This class needs an extensive test suite that checks the conversion from expected Flink expressions, not just a test for the source.\nThe conversion needs to cover at least these cases:\n\nEquals with null\nNot equals with null\nIn with null\nNot in with null\nEquals with NaN\nNot equals with NaN\nIn with NaN\nNot in with NaN\nAll inequalities with null\nAll inequalities with NaN\nAll expressions with a non-null and non-Nan value (preferably one string and one numeric)\nEach data type that is supposed by Iceberg/Flink", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r546048747", "createdAt": "2020-12-18T19:29:45Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinition;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.NaNUtil;\n+\n+public class FlinkFilters {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "originalPosition": 40}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU3ODcyMzY3", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-557872367", "createdAt": "2020-12-23T13:37:33Z", "commit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxMzozNzozNFrOIKk-iA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxMzozNzozNFrOIKk-iA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Nzk2MjUwNA==", "bodyText": "Q:  is it possible that we have two literals in both left and right side ? For example,  someone may write the SQL: SELECT * FROM test where 1 > 0,  then we could not think that the left MUST be a field and the right MUST be a value in this else block.\nWe have done the similar work in our own branch before,  you could see the PR: https://github.com/generic-datalake/iceberg-poc/pull/2/files#diff-86160616589acf1dd526b10b73418a46fe60f9e5e5ab6946a4ea3c8f019542f5R123", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r547962504", "createdAt": "2020-12-23T13:37:34Z", "author": {"login": "openinx"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinition;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.NaNUtil;\n+\n+public class FlinkFilters {\n+  private FlinkFilters() {\n+  }\n+\n+  private static final Map<BuiltInFunctionDefinition, Operation> FILTERS = ImmutableMap\n+      .<BuiltInFunctionDefinition, Operation>builder()\n+      .put(BuiltInFunctionDefinitions.EQUALS, Operation.EQ)\n+      .put(BuiltInFunctionDefinitions.NOT_EQUALS, Operation.NOT_EQ)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN, Operation.GT)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, Operation.GT_EQ)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN, Operation.LT)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, Operation.LT_EQ)\n+      .put(BuiltInFunctionDefinitions.IN, Operation.IN)\n+      .put(BuiltInFunctionDefinitions.IS_NULL, Operation.IS_NULL)\n+      .put(BuiltInFunctionDefinitions.IS_NOT_NULL, Operation.NOT_NULL)\n+      .put(BuiltInFunctionDefinitions.AND, Operation.AND)\n+      .put(BuiltInFunctionDefinitions.OR, Operation.OR)\n+      .put(BuiltInFunctionDefinitions.NOT, Operation.NOT)\n+      .build();\n+\n+\n+  public static Optional<Expression> convert(org.apache.flink.table.expressions.Expression flinkExpression) {\n+    if (!(flinkExpression instanceof CallExpression)) {\n+      return Optional.empty();\n+    }\n+\n+    CallExpression call = (CallExpression) flinkExpression;\n+    Operation op = FILTERS.get(call.getFunctionDefinition());\n+    if (op != null) {\n+      switch (op) {\n+        case IS_NULL:\n+          FieldReferenceExpression isNullFilter = (FieldReferenceExpression) call.getResolvedChildren().get(0);\n+          return Optional.of(Expressions.isNull(isNullFilter.getName()));\n+\n+        case NOT_NULL:\n+          FieldReferenceExpression notNullExpression = (FieldReferenceExpression) call.getResolvedChildren().get(0);\n+          return Optional.of(Expressions.notNull(notNullExpression.getName()));\n+\n+        case LT:\n+          return convertComparisonExpression(Expressions::lessThan, call);\n+\n+        case LT_EQ:\n+          return convertComparisonExpression(Expressions::lessThanOrEqual, call);\n+\n+        case GT:\n+          return convertComparisonExpression(Expressions::greaterThan, call);\n+\n+        case GT_EQ:\n+          return convertComparisonExpression(Expressions::greaterThanOrEqual, call);\n+\n+        case EQ:\n+          return convertComparisonExpression(Expressions::equal, call);\n+\n+        case NOT_EQ:\n+          return convertComparisonExpression(Expressions::notEqual, call);\n+\n+        case IN:\n+          List<ResolvedExpression> args = call.getResolvedChildren();\n+          FieldReferenceExpression field = (FieldReferenceExpression) args.get(0);\n+          List<ResolvedExpression> values = args.subList(1, args.size());\n+\n+          List<Object> inputValues = values.stream().filter(\n+              expression -> {\n+                if (expression instanceof ValueLiteralExpression) {\n+                  return !((ValueLiteralExpression) flinkExpression).isNull();\n+                }\n+\n+                return false;\n+              }\n+          ).map(expression -> {\n+            ValueLiteralExpression valueLiteralExpression = (ValueLiteralExpression) expression;\n+            return valueLiteralExpression.getValueAs(valueLiteralExpression.getOutputDataType().getConversionClass())\n+                .get();\n+          }).collect(Collectors.toList());\n+          return Optional.of(Expressions.in(field.getName(), inputValues));\n+\n+        case NOT:\n+          Optional<Expression> child = convert(call.getResolvedChildren().get(0));\n+          if (child.isPresent()) {\n+            return Optional.of(Expressions.not(child.get()));\n+          }\n+\n+          return Optional.empty();\n+\n+        case AND: {\n+          return convertLogicExpression(Expressions::and, call);\n+        }\n+\n+        case OR: {\n+          return convertLogicExpression(Expressions::or, call);\n+        }\n+      }\n+    }\n+\n+    return Optional.empty();\n+  }\n+\n+  private static Optional<Expression> convertLogicExpression(BiFunction<Expression, Expression, Expression> function,\n+                                                             CallExpression call) {\n+    List<ResolvedExpression> args = call.getResolvedChildren();\n+    Optional<Expression> left = convert(args.get(0));\n+    Optional<Expression> right = convert(args.get(1));\n+    if (left.isPresent() && right.isPresent()) {\n+      return Optional.of(function.apply(left.get(), right.get()));\n+    }\n+\n+    return Optional.empty();\n+  }\n+\n+  private static Optional<Expression> convertComparisonExpression(BiFunction<String, Object, Expression> function,\n+                                                                  CallExpression call) {\n+    List<ResolvedExpression> args = call.getResolvedChildren();\n+    FieldReferenceExpression fieldReferenceExpression;\n+    ValueLiteralExpression valueLiteralExpression;\n+    if (literalOnRight(args)) {\n+      fieldReferenceExpression = (FieldReferenceExpression) args.get(0);\n+      valueLiteralExpression = (ValueLiteralExpression) args.get(1);\n+    } else {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "originalPosition": 157}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU3ODc0NTk1", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-557874595", "createdAt": "2020-12-23T13:41:53Z", "commit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxMzo0MTo1NFrOIKlFKw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxMzo0MTo1NFrOIKlFKw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Nzk2NDIwMw==", "bodyText": "Is this sentence correct  ?    should transform the && to || ?", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r547964203", "createdAt": "2020-12-23T13:41:54Z", "author": {"login": "openinx"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinition;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.NaNUtil;\n+\n+public class FlinkFilters {\n+  private FlinkFilters() {\n+  }\n+\n+  private static final Map<BuiltInFunctionDefinition, Operation> FILTERS = ImmutableMap\n+      .<BuiltInFunctionDefinition, Operation>builder()\n+      .put(BuiltInFunctionDefinitions.EQUALS, Operation.EQ)\n+      .put(BuiltInFunctionDefinitions.NOT_EQUALS, Operation.NOT_EQ)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN, Operation.GT)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, Operation.GT_EQ)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN, Operation.LT)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, Operation.LT_EQ)\n+      .put(BuiltInFunctionDefinitions.IN, Operation.IN)\n+      .put(BuiltInFunctionDefinitions.IS_NULL, Operation.IS_NULL)\n+      .put(BuiltInFunctionDefinitions.IS_NOT_NULL, Operation.NOT_NULL)\n+      .put(BuiltInFunctionDefinitions.AND, Operation.AND)\n+      .put(BuiltInFunctionDefinitions.OR, Operation.OR)\n+      .put(BuiltInFunctionDefinitions.NOT, Operation.NOT)\n+      .build();\n+\n+\n+  public static Optional<Expression> convert(org.apache.flink.table.expressions.Expression flinkExpression) {\n+    if (!(flinkExpression instanceof CallExpression)) {\n+      return Optional.empty();\n+    }\n+\n+    CallExpression call = (CallExpression) flinkExpression;\n+    Operation op = FILTERS.get(call.getFunctionDefinition());\n+    if (op != null) {\n+      switch (op) {\n+        case IS_NULL:\n+          FieldReferenceExpression isNullFilter = (FieldReferenceExpression) call.getResolvedChildren().get(0);\n+          return Optional.of(Expressions.isNull(isNullFilter.getName()));\n+\n+        case NOT_NULL:\n+          FieldReferenceExpression notNullExpression = (FieldReferenceExpression) call.getResolvedChildren().get(0);\n+          return Optional.of(Expressions.notNull(notNullExpression.getName()));\n+\n+        case LT:\n+          return convertComparisonExpression(Expressions::lessThan, call);\n+\n+        case LT_EQ:\n+          return convertComparisonExpression(Expressions::lessThanOrEqual, call);\n+\n+        case GT:\n+          return convertComparisonExpression(Expressions::greaterThan, call);\n+\n+        case GT_EQ:\n+          return convertComparisonExpression(Expressions::greaterThanOrEqual, call);\n+\n+        case EQ:\n+          return convertComparisonExpression(Expressions::equal, call);\n+\n+        case NOT_EQ:\n+          return convertComparisonExpression(Expressions::notEqual, call);\n+\n+        case IN:\n+          List<ResolvedExpression> args = call.getResolvedChildren();\n+          FieldReferenceExpression field = (FieldReferenceExpression) args.get(0);\n+          List<ResolvedExpression> values = args.subList(1, args.size());\n+\n+          List<Object> inputValues = values.stream().filter(\n+              expression -> {\n+                if (expression instanceof ValueLiteralExpression) {\n+                  return !((ValueLiteralExpression) flinkExpression).isNull();\n+                }\n+\n+                return false;\n+              }\n+          ).map(expression -> {\n+            ValueLiteralExpression valueLiteralExpression = (ValueLiteralExpression) expression;\n+            return valueLiteralExpression.getValueAs(valueLiteralExpression.getOutputDataType().getConversionClass())\n+                .get();\n+          }).collect(Collectors.toList());\n+          return Optional.of(Expressions.in(field.getName(), inputValues));\n+\n+        case NOT:\n+          Optional<Expression> child = convert(call.getResolvedChildren().get(0));\n+          if (child.isPresent()) {\n+            return Optional.of(Expressions.not(child.get()));\n+          }\n+\n+          return Optional.empty();\n+\n+        case AND: {\n+          return convertLogicExpression(Expressions::and, call);\n+        }\n+\n+        case OR: {\n+          return convertLogicExpression(Expressions::or, call);\n+        }\n+      }\n+    }\n+\n+    return Optional.empty();\n+  }\n+\n+  private static Optional<Expression> convertLogicExpression(BiFunction<Expression, Expression, Expression> function,\n+                                                             CallExpression call) {\n+    List<ResolvedExpression> args = call.getResolvedChildren();\n+    Optional<Expression> left = convert(args.get(0));\n+    Optional<Expression> right = convert(args.get(1));\n+    if (left.isPresent() && right.isPresent()) {\n+      return Optional.of(function.apply(left.get(), right.get()));\n+    }\n+\n+    return Optional.empty();\n+  }\n+\n+  private static Optional<Expression> convertComparisonExpression(BiFunction<String, Object, Expression> function,\n+                                                                  CallExpression call) {\n+    List<ResolvedExpression> args = call.getResolvedChildren();\n+    FieldReferenceExpression fieldReferenceExpression;\n+    ValueLiteralExpression valueLiteralExpression;\n+    if (literalOnRight(args)) {\n+      fieldReferenceExpression = (FieldReferenceExpression) args.get(0);\n+      valueLiteralExpression = (ValueLiteralExpression) args.get(1);\n+    } else {\n+      fieldReferenceExpression = (FieldReferenceExpression) args.get(1);\n+      valueLiteralExpression = (ValueLiteralExpression) args.get(0);\n+    }\n+\n+    String name = fieldReferenceExpression.getName();\n+    Class clazz = valueLiteralExpression.getOutputDataType().getConversionClass();\n+    Object value = valueLiteralExpression.getValueAs(clazz).get();\n+\n+    BuiltInFunctionDefinition functionDefinition = (BuiltInFunctionDefinition) call.getFunctionDefinition();\n+    if (functionDefinition.equals(BuiltInFunctionDefinitions.EQUALS) &&", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "originalPosition": 167}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU3ODkwNjI2", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-557890626", "createdAt": "2020-12-23T14:10:34Z", "commit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxNDoxMDozNVrOIKl18w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxNDoxMDozNVrOIKl18w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Nzk3NjY5MQ==", "bodyText": "Q:  the call.getResolvedChildren().get(0) MUST be a FieldReferenceExpression ?   I would recommend to use the similar  toReference method to check whether it's indeed a FieldReferenceExpression,  that's more safe.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r547976691", "createdAt": "2020-12-23T14:10:35Z", "author": {"login": "openinx"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinition;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.NaNUtil;\n+\n+public class FlinkFilters {\n+  private FlinkFilters() {\n+  }\n+\n+  private static final Map<BuiltInFunctionDefinition, Operation> FILTERS = ImmutableMap\n+      .<BuiltInFunctionDefinition, Operation>builder()\n+      .put(BuiltInFunctionDefinitions.EQUALS, Operation.EQ)\n+      .put(BuiltInFunctionDefinitions.NOT_EQUALS, Operation.NOT_EQ)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN, Operation.GT)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, Operation.GT_EQ)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN, Operation.LT)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, Operation.LT_EQ)\n+      .put(BuiltInFunctionDefinitions.IN, Operation.IN)\n+      .put(BuiltInFunctionDefinitions.IS_NULL, Operation.IS_NULL)\n+      .put(BuiltInFunctionDefinitions.IS_NOT_NULL, Operation.NOT_NULL)\n+      .put(BuiltInFunctionDefinitions.AND, Operation.AND)\n+      .put(BuiltInFunctionDefinitions.OR, Operation.OR)\n+      .put(BuiltInFunctionDefinitions.NOT, Operation.NOT)\n+      .build();\n+\n+\n+  public static Optional<Expression> convert(org.apache.flink.table.expressions.Expression flinkExpression) {\n+    if (!(flinkExpression instanceof CallExpression)) {\n+      return Optional.empty();\n+    }\n+\n+    CallExpression call = (CallExpression) flinkExpression;\n+    Operation op = FILTERS.get(call.getFunctionDefinition());\n+    if (op != null) {\n+      switch (op) {\n+        case IS_NULL:\n+          FieldReferenceExpression isNullFilter = (FieldReferenceExpression) call.getResolvedChildren().get(0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "originalPosition": 71}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU3ODk0MTAx", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-557894101", "createdAt": "2020-12-23T14:16:31Z", "commit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxNDoxNjozMVrOIKmAYQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxNDoxNjozMVrOIKmAYQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Nzk3OTM2MQ==", "bodyText": "Pls check its class type before casting to FieldReferenceExpression directly.  It's more safe to cast if we're sure that it's indeed the expected class.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r547979361", "createdAt": "2020-12-23T14:16:31Z", "author": {"login": "openinx"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinition;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.NaNUtil;\n+\n+public class FlinkFilters {\n+  private FlinkFilters() {\n+  }\n+\n+  private static final Map<BuiltInFunctionDefinition, Operation> FILTERS = ImmutableMap\n+      .<BuiltInFunctionDefinition, Operation>builder()\n+      .put(BuiltInFunctionDefinitions.EQUALS, Operation.EQ)\n+      .put(BuiltInFunctionDefinitions.NOT_EQUALS, Operation.NOT_EQ)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN, Operation.GT)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, Operation.GT_EQ)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN, Operation.LT)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, Operation.LT_EQ)\n+      .put(BuiltInFunctionDefinitions.IN, Operation.IN)\n+      .put(BuiltInFunctionDefinitions.IS_NULL, Operation.IS_NULL)\n+      .put(BuiltInFunctionDefinitions.IS_NOT_NULL, Operation.NOT_NULL)\n+      .put(BuiltInFunctionDefinitions.AND, Operation.AND)\n+      .put(BuiltInFunctionDefinitions.OR, Operation.OR)\n+      .put(BuiltInFunctionDefinitions.NOT, Operation.NOT)\n+      .build();\n+\n+\n+  public static Optional<Expression> convert(org.apache.flink.table.expressions.Expression flinkExpression) {\n+    if (!(flinkExpression instanceof CallExpression)) {\n+      return Optional.empty();\n+    }\n+\n+    CallExpression call = (CallExpression) flinkExpression;\n+    Operation op = FILTERS.get(call.getFunctionDefinition());\n+    if (op != null) {\n+      switch (op) {\n+        case IS_NULL:\n+          FieldReferenceExpression isNullFilter = (FieldReferenceExpression) call.getResolvedChildren().get(0);\n+          return Optional.of(Expressions.isNull(isNullFilter.getName()));\n+\n+        case NOT_NULL:\n+          FieldReferenceExpression notNullExpression = (FieldReferenceExpression) call.getResolvedChildren().get(0);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "originalPosition": 75}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU3ODk4MjA3", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-557898207", "createdAt": "2020-12-23T14:23:40Z", "commit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxNDoyMzo0MVrOIKmM7g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxNDoyMzo0MVrOIKmM7g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Nzk4MjU3NA==", "bodyText": "nit:  the { and } could be removed .", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r547982574", "createdAt": "2020-12-23T14:23:41Z", "author": {"login": "openinx"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinition;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.NaNUtil;\n+\n+public class FlinkFilters {\n+  private FlinkFilters() {\n+  }\n+\n+  private static final Map<BuiltInFunctionDefinition, Operation> FILTERS = ImmutableMap\n+      .<BuiltInFunctionDefinition, Operation>builder()\n+      .put(BuiltInFunctionDefinitions.EQUALS, Operation.EQ)\n+      .put(BuiltInFunctionDefinitions.NOT_EQUALS, Operation.NOT_EQ)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN, Operation.GT)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, Operation.GT_EQ)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN, Operation.LT)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, Operation.LT_EQ)\n+      .put(BuiltInFunctionDefinitions.IN, Operation.IN)\n+      .put(BuiltInFunctionDefinitions.IS_NULL, Operation.IS_NULL)\n+      .put(BuiltInFunctionDefinitions.IS_NOT_NULL, Operation.NOT_NULL)\n+      .put(BuiltInFunctionDefinitions.AND, Operation.AND)\n+      .put(BuiltInFunctionDefinitions.OR, Operation.OR)\n+      .put(BuiltInFunctionDefinitions.NOT, Operation.NOT)\n+      .build();\n+\n+\n+  public static Optional<Expression> convert(org.apache.flink.table.expressions.Expression flinkExpression) {\n+    if (!(flinkExpression instanceof CallExpression)) {\n+      return Optional.empty();\n+    }\n+\n+    CallExpression call = (CallExpression) flinkExpression;\n+    Operation op = FILTERS.get(call.getFunctionDefinition());\n+    if (op != null) {\n+      switch (op) {\n+        case IS_NULL:\n+          FieldReferenceExpression isNullFilter = (FieldReferenceExpression) call.getResolvedChildren().get(0);\n+          return Optional.of(Expressions.isNull(isNullFilter.getName()));\n+\n+        case NOT_NULL:\n+          FieldReferenceExpression notNullExpression = (FieldReferenceExpression) call.getResolvedChildren().get(0);\n+          return Optional.of(Expressions.notNull(notNullExpression.getName()));\n+\n+        case LT:\n+          return convertComparisonExpression(Expressions::lessThan, call);\n+\n+        case LT_EQ:\n+          return convertComparisonExpression(Expressions::lessThanOrEqual, call);\n+\n+        case GT:\n+          return convertComparisonExpression(Expressions::greaterThan, call);\n+\n+        case GT_EQ:\n+          return convertComparisonExpression(Expressions::greaterThanOrEqual, call);\n+\n+        case EQ:\n+          return convertComparisonExpression(Expressions::equal, call);\n+\n+        case NOT_EQ:\n+          return convertComparisonExpression(Expressions::notEqual, call);\n+\n+        case IN:\n+          List<ResolvedExpression> args = call.getResolvedChildren();\n+          FieldReferenceExpression field = (FieldReferenceExpression) args.get(0);\n+          List<ResolvedExpression> values = args.subList(1, args.size());\n+\n+          List<Object> inputValues = values.stream().filter(\n+              expression -> {\n+                if (expression instanceof ValueLiteralExpression) {\n+                  return !((ValueLiteralExpression) flinkExpression).isNull();\n+                }\n+\n+                return false;\n+              }\n+          ).map(expression -> {\n+            ValueLiteralExpression valueLiteralExpression = (ValueLiteralExpression) expression;\n+            return valueLiteralExpression.getValueAs(valueLiteralExpression.getOutputDataType().getConversionClass())\n+                .get();\n+          }).collect(Collectors.toList());\n+          return Optional.of(Expressions.in(field.getName(), inputValues));\n+\n+        case NOT:\n+          Optional<Expression> child = convert(call.getResolvedChildren().get(0));\n+          if (child.isPresent()) {\n+            return Optional.of(Expressions.not(child.get()));\n+          }\n+\n+          return Optional.empty();\n+\n+        case AND: {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "originalPosition": 124}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU3ODk4Mjc3", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-557898277", "createdAt": "2020-12-23T14:23:47Z", "commit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxNDoyMzo0N1rOIKmNJw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxNDoyMzo0N1rOIKmNJw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Nzk4MjYzMQ==", "bodyText": "ditto", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r547982631", "createdAt": "2020-12-23T14:23:47Z", "author": {"login": "openinx"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinition;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.NaNUtil;\n+\n+public class FlinkFilters {\n+  private FlinkFilters() {\n+  }\n+\n+  private static final Map<BuiltInFunctionDefinition, Operation> FILTERS = ImmutableMap\n+      .<BuiltInFunctionDefinition, Operation>builder()\n+      .put(BuiltInFunctionDefinitions.EQUALS, Operation.EQ)\n+      .put(BuiltInFunctionDefinitions.NOT_EQUALS, Operation.NOT_EQ)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN, Operation.GT)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, Operation.GT_EQ)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN, Operation.LT)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, Operation.LT_EQ)\n+      .put(BuiltInFunctionDefinitions.IN, Operation.IN)\n+      .put(BuiltInFunctionDefinitions.IS_NULL, Operation.IS_NULL)\n+      .put(BuiltInFunctionDefinitions.IS_NOT_NULL, Operation.NOT_NULL)\n+      .put(BuiltInFunctionDefinitions.AND, Operation.AND)\n+      .put(BuiltInFunctionDefinitions.OR, Operation.OR)\n+      .put(BuiltInFunctionDefinitions.NOT, Operation.NOT)\n+      .build();\n+\n+\n+  public static Optional<Expression> convert(org.apache.flink.table.expressions.Expression flinkExpression) {\n+    if (!(flinkExpression instanceof CallExpression)) {\n+      return Optional.empty();\n+    }\n+\n+    CallExpression call = (CallExpression) flinkExpression;\n+    Operation op = FILTERS.get(call.getFunctionDefinition());\n+    if (op != null) {\n+      switch (op) {\n+        case IS_NULL:\n+          FieldReferenceExpression isNullFilter = (FieldReferenceExpression) call.getResolvedChildren().get(0);\n+          return Optional.of(Expressions.isNull(isNullFilter.getName()));\n+\n+        case NOT_NULL:\n+          FieldReferenceExpression notNullExpression = (FieldReferenceExpression) call.getResolvedChildren().get(0);\n+          return Optional.of(Expressions.notNull(notNullExpression.getName()));\n+\n+        case LT:\n+          return convertComparisonExpression(Expressions::lessThan, call);\n+\n+        case LT_EQ:\n+          return convertComparisonExpression(Expressions::lessThanOrEqual, call);\n+\n+        case GT:\n+          return convertComparisonExpression(Expressions::greaterThan, call);\n+\n+        case GT_EQ:\n+          return convertComparisonExpression(Expressions::greaterThanOrEqual, call);\n+\n+        case EQ:\n+          return convertComparisonExpression(Expressions::equal, call);\n+\n+        case NOT_EQ:\n+          return convertComparisonExpression(Expressions::notEqual, call);\n+\n+        case IN:\n+          List<ResolvedExpression> args = call.getResolvedChildren();\n+          FieldReferenceExpression field = (FieldReferenceExpression) args.get(0);\n+          List<ResolvedExpression> values = args.subList(1, args.size());\n+\n+          List<Object> inputValues = values.stream().filter(\n+              expression -> {\n+                if (expression instanceof ValueLiteralExpression) {\n+                  return !((ValueLiteralExpression) flinkExpression).isNull();\n+                }\n+\n+                return false;\n+              }\n+          ).map(expression -> {\n+            ValueLiteralExpression valueLiteralExpression = (ValueLiteralExpression) expression;\n+            return valueLiteralExpression.getValueAs(valueLiteralExpression.getOutputDataType().getConversionClass())\n+                .get();\n+          }).collect(Collectors.toList());\n+          return Optional.of(Expressions.in(field.getName(), inputValues));\n+\n+        case NOT:\n+          Optional<Expression> child = convert(call.getResolvedChildren().get(0));\n+          if (child.isPresent()) {\n+            return Optional.of(Expressions.not(child.get()));\n+          }\n+\n+          return Optional.empty();\n+\n+        case AND: {\n+          return convertLogicExpression(Expressions::and, call);\n+        }\n+\n+        case OR: {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "originalPosition": 128}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU3ODk5NjE4", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-557899618", "createdAt": "2020-12-23T14:26:02Z", "commit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxNDoyNjowMlrOIKmRbA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxNDoyNjowMlrOIKmRbA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Nzk4MzcyNA==", "bodyText": "The flink's LIKE, BETWEEN, NOT_BETWEEN could also be pushed down, pls see https://github.com/generic-datalake/iceberg-poc/pull/2/files#diff-86160616589acf1dd526b10b73418a46fe60f9e5e5ab6946a4ea3c8f019542f5R78-R80.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r547983724", "createdAt": "2020-12-23T14:26:02Z", "author": {"login": "openinx"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,183 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.stream.Collectors;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinition;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.base.Preconditions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.NaNUtil;\n+\n+public class FlinkFilters {\n+  private FlinkFilters() {\n+  }\n+\n+  private static final Map<BuiltInFunctionDefinition, Operation> FILTERS = ImmutableMap\n+      .<BuiltInFunctionDefinition, Operation>builder()\n+      .put(BuiltInFunctionDefinitions.EQUALS, Operation.EQ)\n+      .put(BuiltInFunctionDefinitions.NOT_EQUALS, Operation.NOT_EQ)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN, Operation.GT)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, Operation.GT_EQ)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN, Operation.LT)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, Operation.LT_EQ)\n+      .put(BuiltInFunctionDefinitions.IN, Operation.IN)\n+      .put(BuiltInFunctionDefinitions.IS_NULL, Operation.IS_NULL)\n+      .put(BuiltInFunctionDefinitions.IS_NOT_NULL, Operation.NOT_NULL)\n+      .put(BuiltInFunctionDefinitions.AND, Operation.AND)\n+      .put(BuiltInFunctionDefinitions.OR, Operation.OR)\n+      .put(BuiltInFunctionDefinitions.NOT, Operation.NOT)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "originalPosition": 57}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTU3OTAyMjEx", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-557902211", "createdAt": "2020-12-23T14:30:22Z", "commit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxNDozMDoyMlrOIKmZgA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMC0xMi0yM1QxNDozMDoyMlrOIKmZgA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU0Nzk4NTc5Mg==", "bodyText": "I will suggest to have a more strict assertion to validate the pushed  filter's internal information, see https://github.com/generic-datalake/iceberg-poc/pull/2/files#diff-5d18d1ff127d1dc70a9a15bbe941f2b6f9d28b3015924f601ac1f722914099dbR96", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r547985792", "createdAt": "2020-12-23T14:30:22Z", "author": {"login": "openinx"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkTableSource.java", "diffHunk": "@@ -102,4 +105,154 @@ public void testLimitPushDown() {\n     Assert.assertEquals(\"should have 1 record\", 1, mixedResult.size());\n     Assert.assertArrayEquals(\"Should produce the expected records\", mixedResult.get(0), new Object[] {1, \"a\"});\n   }\n+\n+  @Test\n+  public void testFilterPushDown() {\n+    sql(\"INSERT INTO %s  VALUES (1,'a'),(2,'b'),(3,CAST(null AS VARCHAR))\", TABLE_NAME);\n+\n+    String expectedExplain = \"FilterPushDown\";\n+\n+    // not push down\n+    String sqlNoPushDown = \"SELECT * FROM \" + TABLE_NAME + \" WHERE data LIKE '%a%' \";\n+    String explainNoPushDown = getTableEnv().explainSql(sqlNoPushDown);\n+    assertFalse(\"explain should not contains FilterPushDown\", explainNoPushDown.contains(expectedExplain));\n+\n+    // equal\n+    String sqlLiteralRight = String.format(\"SELECT * FROM %s WHERE id = 1 \", TABLE_NAME);\n+    String explain = getTableEnv().explainSql(sqlLiteralRight);\n+    assertTrue(\"explain should contains FilterPushDown\", explain.contains(expectedExplain));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25"}, "originalPosition": 29}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "629c5afea86e90ac2c72fd8220d12a2543581b25", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/629c5afea86e90ac2c72fd8220d12a2543581b25", "committedDate": "2020-12-18T04:06:16Z", "message": "update  Expression to Optional"}, "afterCommit": {"oid": "eed220acffd423c949888ff8a1c9115ecb42c809", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/eed220acffd423c949888ff8a1c9115ecb42c809", "committedDate": "2020-12-25T01:46:35Z", "message": "fix some bugs and add test case"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "eed220acffd423c949888ff8a1c9115ecb42c809", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/eed220acffd423c949888ff8a1c9115ecb42c809", "committedDate": "2020-12-25T01:46:35Z", "message": "fix some bugs and add test case"}, "afterCommit": {"oid": "d23ce45cf0b1e500ac1a21a5b1d1d63352ff9cfd", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/d23ce45cf0b1e500ac1a21a5b1d1d63352ff9cfd", "committedDate": "2020-12-25T01:53:51Z", "message": "fix some bugs and add test case"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "d23ce45cf0b1e500ac1a21a5b1d1d63352ff9cfd", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/d23ce45cf0b1e500ac1a21a5b1d1d63352ff9cfd", "committedDate": "2020-12-25T01:53:51Z", "message": "fix some bugs and add test case"}, "afterCommit": {"oid": "1af16c70cc73eede503fce30737e8a49a1622c4d", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/1af16c70cc73eede503fce30737e8a49a1622c4d", "committedDate": "2020-12-25T02:08:42Z", "message": "fix some bugs and add test case"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "1af16c70cc73eede503fce30737e8a49a1622c4d", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/1af16c70cc73eede503fce30737e8a49a1622c4d", "committedDate": "2020-12-25T02:08:42Z", "message": "fix some bugs and add test case"}, "afterCommit": {"oid": "847b62f6648d83092e367e682984f38dccf0cfc9", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/847b62f6648d83092e367e682984f38dccf0cfc9", "committedDate": "2020-12-30T03:00:04Z", "message": "fix some bugs and add test case"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYwODgzNjMx", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-560883631", "createdAt": "2021-01-04T09:28:39Z", "commit": {"oid": "847b62f6648d83092e367e682984f38dccf0cfc9"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNFQwOToyODo0MFrOINqpMA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNFQwOToyODo0MFrOINqpMA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTIwMTA3Mg==", "bodyText": "Here we could remove the flinkExpression == null and just keep the\n    if (!(flinkExpression instanceof CallExpression)) {\n      return Optional.empty();\n    }\nBecause null will always meet the !(flinkExpression instanceof CallExpression) condition.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r551201072", "createdAt": "2021-01-04T09:28:40Z", "author": {"login": "openinx"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.flink.table.functions.FunctionDefinition;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.DateTimeUtil;\n+import org.apache.iceberg.util.NaNUtil;\n+\n+import static org.apache.iceberg.expressions.Expressions.isNaN;\n+\n+public class FlinkFilters {\n+  private FlinkFilters() {\n+  }\n+\n+  private static final Pattern STARTS_WITH_PATTERN = Pattern.compile(\"([^%]+)%\");\n+\n+  private static final Map<FunctionDefinition, Operation> FILTERS = ImmutableMap\n+      .<FunctionDefinition, Operation>builder()\n+      .put(BuiltInFunctionDefinitions.EQUALS, Operation.EQ)\n+      .put(BuiltInFunctionDefinitions.NOT_EQUALS, Operation.NOT_EQ)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN, Operation.GT)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, Operation.GT_EQ)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN, Operation.LT)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, Operation.LT_EQ)\n+      .put(BuiltInFunctionDefinitions.IN, Operation.IN)\n+      .put(BuiltInFunctionDefinitions.IS_NULL, Operation.IS_NULL)\n+      .put(BuiltInFunctionDefinitions.IS_NOT_NULL, Operation.NOT_NULL)\n+      .put(BuiltInFunctionDefinitions.AND, Operation.AND)\n+      .put(BuiltInFunctionDefinitions.OR, Operation.OR)\n+      .put(BuiltInFunctionDefinitions.NOT, Operation.NOT)\n+      .put(BuiltInFunctionDefinitions.LIKE, Operation.STARTS_WITH)\n+      .build();\n+\n+  public static Optional<Expression> convert(org.apache.flink.table.expressions.Expression flinkExpression) {\n+    if (flinkExpression == null || !(flinkExpression instanceof CallExpression)) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "847b62f6648d83092e367e682984f38dccf0cfc9"}, "originalPosition": 73}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYwODkwNTM3", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-560890537", "createdAt": "2021-01-04T09:39:10Z", "commit": {"oid": "847b62f6648d83092e367e682984f38dccf0cfc9"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNFQwOTozOToxMFrOINq-0Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNFQwOTozOToxMFrOINq-0Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTIwNjYwOQ==", "bodyText": "How about changing this to check whether the explainBetween contains a more detailed string FilterPushDown,the filters :ref(name=\"id\") >= 1,ref(name=\"id\") <= 2]]], fields=[id, data]) ?   explainBetween.contains(\"FilterPushDown\") is not so accurate for me.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r551206609", "createdAt": "2021-01-04T09:39:10Z", "author": {"login": "openinx"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkTableSource.java", "diffHunk": "@@ -75,32 +95,328 @@ public void clean() {\n \n   @Test\n   public void testLimitPushDown() {\n-    sql(\"INSERT INTO %s  VALUES (1,'a'),(2,'b')\", TABLE_NAME);\n-\n     String querySql = String.format(\"SELECT * FROM %s LIMIT 1\", TABLE_NAME);\n     String explain = getTableEnv().explainSql(querySql);\n     String expectedExplain = \"LimitPushDown : 1\";\n     Assert.assertTrue(\"explain should contains LimitPushDown\", explain.contains(expectedExplain));\n     List<Object[]> result = sql(querySql);\n-    Assert.assertEquals(\"should have 1 record\", 1, result.size());\n-    Assert.assertArrayEquals(\"Should produce the expected records\", result.get(0), new Object[] {1, \"a\"});\n+    assertEquals(\"should have 1 record\", 1, result.size());\n+    assertArrayEquals(\"Should produce the expected records\", result.get(0), new Object[] {1, \"a\"});\n \n     AssertHelpers.assertThrows(\"Invalid limit number: -1 \", SqlParserException.class,\n         () -> sql(\"SELECT * FROM %s LIMIT -1\", TABLE_NAME));\n \n-    Assert.assertEquals(\"should have 0 record\", 0, sql(\"SELECT * FROM %s LIMIT 0\", TABLE_NAME).size());\n+    assertEquals(\"should have 0 record\", 0, sql(\"SELECT * FROM %s LIMIT 0\", TABLE_NAME).size());\n \n-    String sqlLimitExceed = String.format(\"SELECT * FROM %s LIMIT 3\", TABLE_NAME);\n+    String sqlLimitExceed = String.format(\"SELECT * FROM %s LIMIT 4\", TABLE_NAME);\n     List<Object[]> resultExceed = sql(sqlLimitExceed);\n-    Assert.assertEquals(\"should have 2 record\", 2, resultExceed.size());\n+    assertEquals(\"should have 3 record\", 3, resultExceed.size());\n     List<Object[]> expectedList = Lists.newArrayList();\n     expectedList.add(new Object[] {1, \"a\"});\n     expectedList.add(new Object[] {2, \"b\"});\n-    Assert.assertArrayEquals(\"Should produce the expected records\", resultExceed.toArray(), expectedList.toArray());\n+    expectedList.add(new Object[] {3, null});\n+    assertArrayEquals(\"Should produce the expected records\", resultExceed.toArray(), expectedList.toArray());\n \n     String sqlMixed = String.format(\"SELECT * FROM %s WHERE id = 1 LIMIT 2\", TABLE_NAME);\n     List<Object[]> mixedResult = sql(sqlMixed);\n-    Assert.assertEquals(\"should have 1 record\", 1, mixedResult.size());\n-    Assert.assertArrayEquals(\"Should produce the expected records\", mixedResult.get(0), new Object[] {1, \"a\"});\n+    assertEquals(\"should have 1 record\", 1, mixedResult.size());\n+    assertArrayEquals(\"Should produce the expected records\", mixedResult.get(0), new Object[] {1, \"a\"});\n+  }\n+\n+  @Test\n+  public void testNoFilterPushDown() {\n+    String sql = String.format(\"SELECT * FROM %s \", TABLE_NAME);\n+    String explain = getTableEnv().explainSql(sql);\n+    assertFalse(\"explain should no contains FilterPushDown\", explain.contains(expectedFilterPushDownExplain));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownEqual() {\n+    String sqlLiteralRight = String.format(\"SELECT * FROM %s WHERE id = 1 \", TABLE_NAME);\n+    String explain = getTableEnv().explainSql(sqlLiteralRight);\n+    assertTrue(\"explain should contains FilterPushDown\", explain.contains(expectedFilterPushDownExplain));\n+\n+    List<Object[]> result = sql(sqlLiteralRight);\n+    assertEquals(\"should have 1 record\", 1, result.size());\n+    assertArrayEquals(\"Should produce the expected record\", result.get(0), new Object[] {1, \"a\"});\n+\n+    assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should push down expected filter\", \"id = 1\", FlinkUtil.describe(lastScanEvent.filter()));\n+\n+    // filter not push down\n+    String sqlEqualNull = String.format(\"SELECT * FROM %s WHERE data = NULL \", TABLE_NAME);\n+    String explainEqualNull = getTableEnv().explainSql(sqlEqualNull);\n+    assertFalse(\"explain should not contains FilterPushDown\", explainEqualNull.contains(expectedFilterPushDownExplain));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownEqualLiteralOnLeft() {\n+    String sqlLiteralLeft = String.format(\"SELECT * FROM %s WHERE 1 = id \", TABLE_NAME);\n+    String explainLeft = getTableEnv().explainSql(sqlLiteralLeft);\n+    assertTrue(\"explain should contains FilterPushDown\", explainLeft.contains(expectedFilterPushDownExplain));\n+\n+    List<Object[]> resultLeft = sql(sqlLiteralLeft);\n+    assertEquals(\"should have 1 record\", 1, resultLeft.size());\n+    assertArrayEquals(\"Should produce the expected record\", resultLeft.get(0), new Object[] {1, \"a\"});\n+\n+    assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should push down expected filter\", \"id = 1\", FlinkUtil.describe(lastScanEvent.filter()));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownNoEqual() {\n+    String sqlNE = String.format(\"SELECT * FROM %s WHERE id <> 1 \", TABLE_NAME);\n+    String explainNE = getTableEnv().explainSql(sqlNE);\n+    assertTrue(\"explain should contains FilterPushDown\", explainNE.contains(expectedFilterPushDownExplain));\n+\n+    List<Object[]> resultNE = sql(sqlNE);\n+    assertEquals(\"should have 2 record\", 2, resultNE.size());\n+    List<Object[]> expectedNE = Lists.newArrayList();\n+    expectedNE.add(new Object[] {2, \"b\"});\n+    expectedNE.add(new Object[] {3, null});\n+    assertArrayEquals(\"Should produce the expected record\", resultNE.toArray(), expectedNE.toArray());\n+    assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should push down expected filter\", \"id != 1\", FlinkUtil.describe(lastScanEvent.filter()));\n+\n+    String sqlNotEqualNull = String.format(\"SELECT * FROM %s WHERE data <> NULL \", TABLE_NAME);\n+    String explainNotEqualNull = getTableEnv().explainSql(sqlNotEqualNull);\n+    assertFalse(\"explain should not contains FilterPushDown\", explainNotEqualNull.contains(\n+        expectedFilterPushDownExplain));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownAnd() {\n+    String sqlAnd = String.format(\"SELECT * FROM %s WHERE id = 1 AND data = 'a' \", TABLE_NAME);\n+    String explainAnd = getTableEnv().explainSql(sqlAnd);\n+    assertTrue(\"explain should contains FilterPushDown\", explainAnd.contains(expectedFilterPushDownExplain));\n+\n+    List<Object[]> resultAnd = sql(sqlAnd);\n+    assertEquals(\"should have 1 record\", 1, resultAnd.size());\n+    assertArrayEquals(\"Should produce the expected record\", resultAnd.get(0), new Object[] {1, \"a\"});\n+\n+    assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should push down expected filter\", \"(id = 1 AND data = 'a')\",\n+        FlinkUtil.describe(lastScanEvent.filter()));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownOr() {\n+    String sqlOr = String.format(\"SELECT * FROM %s WHERE id = 1 OR data = 'b' \", TABLE_NAME);\n+    String explainOr = getTableEnv().explainSql(sqlOr);\n+    assertTrue(\"explain should contains FilterPushDown\", explainOr.contains(expectedFilterPushDownExplain));\n+    List<Object[]> resultOr = sql(sqlOr);\n+    assertEquals(\"should have 2 record\", 2, resultOr.size());\n+\n+    List<Object[]> expectedOR = Lists.newArrayList();\n+    expectedOR.add(new Object[] {1, \"a\"});\n+    expectedOR.add(new Object[] {2, \"b\"});\n+    assertArrayEquals(\"Should produce the expected record\", resultOr.toArray(), expectedOR.toArray());\n+\n+    assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should push down expected filter\", \"(id = 1 OR data = 'b')\",\n+        FlinkUtil.describe(lastScanEvent.filter()));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownGreaterThan() {\n+    String sqlGT = String.format(\"SELECT * FROM %s WHERE id > 1 \", TABLE_NAME);\n+    String explainGT = getTableEnv().explainSql(sqlGT);\n+    assertTrue(\"explain should contains FilterPushDown\", explainGT.contains(expectedFilterPushDownExplain));\n+\n+    List<Object[]> resultGT = sql(sqlGT);\n+    assertEquals(\"should have 2 record\", 2, resultGT.size());\n+    List<Object[]> expectedGT = Lists.newArrayList();\n+    expectedGT.add(new Object[] {2, \"b\"});\n+    expectedGT.add(new Object[] {3, null});\n+    assertArrayEquals(\"Should produce the expected record\", resultGT.toArray(), expectedGT.toArray());\n+\n+    assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should push down expected filter\", \"id > 1\", FlinkUtil.describe(lastScanEvent.filter()));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownGreaterThanEqual() {\n+    String sqlGTE = String.format(\"SELECT * FROM %s WHERE id >= 2 \", TABLE_NAME);\n+    String explainGTE = getTableEnv().explainSql(sqlGTE);\n+    assertTrue(\"explain should contains FilterPushDown\", explainGTE.contains(expectedFilterPushDownExplain));\n+    List<Object[]> resultGTE = sql(sqlGTE);\n+    assertEquals(\"should have 2 records\", 2, resultGTE.size());\n+\n+    List<Object[]> expectedGTE = Lists.newArrayList();\n+    expectedGTE.add(new Object[] {2, \"b\"});\n+    expectedGTE.add(new Object[] {3, null});\n+    assertArrayEquals(\"Should produce the expected record\", resultGTE.toArray(), expectedGTE.toArray());\n+\n+    assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should push down expected filter\", \"id >= 2\", FlinkUtil.describe(lastScanEvent.filter()));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownLessThan() {\n+    String sqlLT = String.format(\"SELECT * FROM %s WHERE id < 2 \", TABLE_NAME);\n+    String explainLT = getTableEnv().explainSql(sqlLT);\n+    assertTrue(\"explain should contains FilterPushDown\", explainLT.contains(expectedFilterPushDownExplain));\n+    List<Object[]> resultLT = sql(sqlLT);\n+    assertEquals(\"should have 1 record\", 1, resultLT.size());\n+    assertArrayEquals(\"Should produce the expected record\", resultLT.get(0), new Object[] {1, \"a\"});\n+\n+    assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should push down expected filter\", \"id < 2\", FlinkUtil.describe(lastScanEvent.filter()));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownLessThanEqual() {\n+    String sqlLTE = String.format(\"SELECT * FROM %s WHERE id <= 1 \", TABLE_NAME);\n+    String explainLTE = getTableEnv().explainSql(sqlLTE);\n+    assertTrue(\"explain should contains FilterPushDown\", explainLTE.contains(expectedFilterPushDownExplain));\n+    List<Object[]> resultLTE = sql(sqlLTE);\n+    assertEquals(\"should have 1 record\", 1, resultLTE.size());\n+    assertArrayEquals(\"Should produce the expected record\", resultLTE.get(0), new Object[] {1, \"a\"});\n+\n+    assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should push down expected filter\", \"id <= 1\", FlinkUtil.describe(lastScanEvent.filter()));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownIn() {\n+    String sqlIN = String.format(\"SELECT * FROM %s WHERE id IN (1,2) \", TABLE_NAME);\n+    String explainIN = getTableEnv().explainSql(sqlIN);\n+    assertTrue(\"explain should contains FilterPushDown\", explainIN.contains(expectedFilterPushDownExplain));\n+    List<Object[]> resultIN = sql(sqlIN);\n+    assertEquals(\"should have 2 records\", 2, resultIN.size());\n+    List<Object[]> expectedIN = Lists.newArrayList();\n+    expectedIN.add(new Object[] {1, \"a\"});\n+    expectedIN.add(new Object[] {2, \"b\"});\n+    assertArrayEquals(\"Should produce the expected record\", resultIN.toArray(), expectedIN.toArray());\n+    assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should push down expected filter\", \"(id = 1 OR id = 2)\",\n+        FlinkUtil.describe(lastScanEvent.filter()));\n+\n+    // in with null will not push down\n+    String sqlInNull = String.format(\"SELECT * FROM %s WHERE id IN (1,2,NULL) \", TABLE_NAME);\n+    String explainInNull = getTableEnv().explainSql(sqlInNull);\n+    assertFalse(\"explain should not contains FilterPushDown\", explainInNull.contains(expectedFilterPushDownExplain));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownNotIn() {\n+    String sqlNotIn = String.format(\"SELECT * FROM %s WHERE id NOT IN (3,2) \", TABLE_NAME);\n+    String explainNotIn = getTableEnv().explainSql(sqlNotIn);\n+    assertTrue(\"explain should contains FilterPushDown\", explainNotIn.contains(expectedFilterPushDownExplain));\n+    List<Object[]> resultNotIn = sql(sqlNotIn);\n+    assertEquals(\"should have 1 record\", 1, resultNotIn.size());\n+    assertArrayEquals(\"Should produce the expected record\", resultNotIn.get(0), new Object[] {1, \"a\"});\n+    assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should push down expected filter\", \"(id != 3 AND id != 2)\",\n+        FlinkUtil.describe(lastScanEvent.filter()));\n+\n+    String sqlNotInNull = String.format(\"SELECT * FROM %s WHERE id NOT IN (1,2,NULL) \", TABLE_NAME);\n+    String explainNotInNull = getTableEnv().explainSql(sqlNotInNull);\n+    assertFalse(\"explain should not contains FilterPushDown\", explainNotInNull.contains(expectedFilterPushDownExplain));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownIsNotNull() {\n+    String sqlNotNull = String.format(\"SELECT * FROM %s WHERE data IS NOT NULL\", TABLE_NAME);\n+    String explainNotNull = getTableEnv().explainSql(sqlNotNull);\n+    assertTrue(\"explain should contains FilterPushDown\", explainNotNull.contains(expectedFilterPushDownExplain));\n+    List<Object[]> resultNotNull = sql(sqlNotNull);\n+    assertEquals(\"should have 2 record\", 2, resultNotNull.size());\n+    List<Object[]> expected = Lists.newArrayList();\n+    expected.add(new Object[] {1, \"a\"});\n+    expected.add(new Object[] {2, \"b\"});\n+    assertArrayEquals(\"Should produce the expected record\", resultNotNull.toArray(), expected.toArray());\n+\n+    assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should push down expected filter\", \"data IS NOT NULL\",\n+        FlinkUtil.describe(lastScanEvent.filter()));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownIsNull() {\n+    String sqlNull = String.format(\"SELECT * FROM %s WHERE data IS  NULL\", TABLE_NAME);\n+    String explainNull = getTableEnv().explainSql(sqlNull);\n+    assertTrue(\"explain should contains FilterPushDown\", explainNull.contains(expectedFilterPushDownExplain));\n+    List<Object[]> resultNull = sql(sqlNull);\n+    assertEquals(\"should have 1 record\", 1, resultNull.size());\n+    assertArrayEquals(\"Should produce the expected record\", resultNull.get(0), new Object[] {3, null});\n+\n+    assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    assertEquals(\"Should push down expected filter\", \"data IS NULL\", FlinkUtil.describe(lastScanEvent.filter()));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownNot() {\n+    String sqlNot = String.format(\"SELECT * FROM %s WHERE NOT id = 1 \", TABLE_NAME);\n+    String explainNot = getTableEnv().explainSql(sqlNot);\n+    assertTrue(\"explain should contains FilterPushDown\", explainNot.contains(expectedFilterPushDownExplain));\n+    List<Object[]> resultNot = sql(sqlNot);\n+    assertEquals(\"should have 2 record\", 2, resultNot.size());\n+    List<Object[]> expectedNot = Lists.newArrayList();\n+    expectedNot.add(new Object[] {2, \"b\"});\n+    expectedNot.add(new Object[] {3, null});\n+    assertArrayEquals(\"Should produce the expected record\", resultNot.toArray(), expectedNot.toArray());\n+\n+    assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should push down expected filter\", \"id != 1\", FlinkUtil.describe(lastScanEvent.filter()));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownBetween() {\n+    String sqlBetween = String.format(\"SELECT * FROM %s WHERE id BETWEEN 1 AND 2 \", TABLE_NAME);\n+    String explainBetween = getTableEnv().explainSql(sqlBetween);\n+    assertTrue(\"explain should contains FilterPushDown\", explainBetween.contains(expectedFilterPushDownExplain));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "847b62f6648d83092e367e682984f38dccf0cfc9"}, "originalPosition": 345}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYwODk4MDEy", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-560898012", "createdAt": "2021-01-04T09:50:35Z", "commit": {"oid": "847b62f6648d83092e367e682984f38dccf0cfc9"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNFQwOTo1MDozNVrOINrWAg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNFQwOTo1MDozNVrOINrWAg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTIxMjU0Ng==", "bodyText": "getOnlyChild ?  the method name is confusing.   How about using singleton ?", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r551212546", "createdAt": "2021-01-04T09:50:35Z", "author": {"login": "openinx"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.flink.table.functions.FunctionDefinition;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.DateTimeUtil;\n+import org.apache.iceberg.util.NaNUtil;\n+\n+import static org.apache.iceberg.expressions.Expressions.isNaN;\n+\n+public class FlinkFilters {\n+  private FlinkFilters() {\n+  }\n+\n+  private static final Pattern STARTS_WITH_PATTERN = Pattern.compile(\"([^%]+)%\");\n+\n+  private static final Map<FunctionDefinition, Operation> FILTERS = ImmutableMap\n+      .<FunctionDefinition, Operation>builder()\n+      .put(BuiltInFunctionDefinitions.EQUALS, Operation.EQ)\n+      .put(BuiltInFunctionDefinitions.NOT_EQUALS, Operation.NOT_EQ)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN, Operation.GT)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, Operation.GT_EQ)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN, Operation.LT)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, Operation.LT_EQ)\n+      .put(BuiltInFunctionDefinitions.IN, Operation.IN)\n+      .put(BuiltInFunctionDefinitions.IS_NULL, Operation.IS_NULL)\n+      .put(BuiltInFunctionDefinitions.IS_NOT_NULL, Operation.NOT_NULL)\n+      .put(BuiltInFunctionDefinitions.AND, Operation.AND)\n+      .put(BuiltInFunctionDefinitions.OR, Operation.OR)\n+      .put(BuiltInFunctionDefinitions.NOT, Operation.NOT)\n+      .put(BuiltInFunctionDefinitions.LIKE, Operation.STARTS_WITH)\n+      .build();\n+\n+  public static Optional<Expression> convert(org.apache.flink.table.expressions.Expression flinkExpression) {\n+    if (flinkExpression == null || !(flinkExpression instanceof CallExpression)) {\n+      return Optional.empty();\n+    }\n+\n+    CallExpression call = (CallExpression) flinkExpression;\n+    Operation op = FILTERS.get(call.getFunctionDefinition());\n+    if (op != null) {\n+      switch (op) {\n+        case IS_NULL:\n+          Optional<String> name = toReference(getOnlyChild(call, FieldReferenceExpression.class).orElse(null));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "847b62f6648d83092e367e682984f38dccf0cfc9"}, "originalPosition": 82}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYwOTA1NDk5", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-560905499", "createdAt": "2021-01-04T10:01:37Z", "commit": {"oid": "847b62f6648d83092e367e682984f38dccf0cfc9"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNFQxMDowMTozN1rOINrsSg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNFQxMDowMTozN1rOINrsSg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTIxODI1MA==", "bodyText": "Pls consider the two cases:\nCase.1 :   a < 1; \nCase.2:    1 < a;\nHere we  convertBinaryExpress will parse the tuple2 as <a, 1>.  and the function will be  lessThan.  While in the actual the case.2 is totally different with case.1 because its meaning is :  a is greaterThan 1 .\nThat's why we introduced a reversed function in here,  for example,  the greaterThan's revered function is lessThan,  the lessThan's reversed function is greaterThan.   If the case 1 < a then we should call the reversed function here.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r551218250", "createdAt": "2021-01-04T10:01:37Z", "author": {"login": "openinx"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,270 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import java.util.stream.Collectors;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.flink.table.functions.FunctionDefinition;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.DateTimeUtil;\n+import org.apache.iceberg.util.NaNUtil;\n+\n+import static org.apache.iceberg.expressions.Expressions.isNaN;\n+\n+public class FlinkFilters {\n+  private FlinkFilters() {\n+  }\n+\n+  private static final Pattern STARTS_WITH_PATTERN = Pattern.compile(\"([^%]+)%\");\n+\n+  private static final Map<FunctionDefinition, Operation> FILTERS = ImmutableMap\n+      .<FunctionDefinition, Operation>builder()\n+      .put(BuiltInFunctionDefinitions.EQUALS, Operation.EQ)\n+      .put(BuiltInFunctionDefinitions.NOT_EQUALS, Operation.NOT_EQ)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN, Operation.GT)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, Operation.GT_EQ)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN, Operation.LT)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, Operation.LT_EQ)\n+      .put(BuiltInFunctionDefinitions.IN, Operation.IN)\n+      .put(BuiltInFunctionDefinitions.IS_NULL, Operation.IS_NULL)\n+      .put(BuiltInFunctionDefinitions.IS_NOT_NULL, Operation.NOT_NULL)\n+      .put(BuiltInFunctionDefinitions.AND, Operation.AND)\n+      .put(BuiltInFunctionDefinitions.OR, Operation.OR)\n+      .put(BuiltInFunctionDefinitions.NOT, Operation.NOT)\n+      .put(BuiltInFunctionDefinitions.LIKE, Operation.STARTS_WITH)\n+      .build();\n+\n+  public static Optional<Expression> convert(org.apache.flink.table.expressions.Expression flinkExpression) {\n+    if (flinkExpression == null || !(flinkExpression instanceof CallExpression)) {\n+      return Optional.empty();\n+    }\n+\n+    CallExpression call = (CallExpression) flinkExpression;\n+    Operation op = FILTERS.get(call.getFunctionDefinition());\n+    if (op != null) {\n+      switch (op) {\n+        case IS_NULL:\n+          Optional<String> name = toReference(getOnlyChild(call, FieldReferenceExpression.class).orElse(null));\n+          return name.map(Expressions::isNull);\n+\n+        case NOT_NULL:\n+          Optional<String> nameNotNull = toReference(getOnlyChild(call, FieldReferenceExpression.class).orElse(null));\n+          return nameNotNull.map(Expressions::notNull);\n+\n+        case LT:\n+          return convertComparisonExpression(Expressions::lessThan, call);\n+\n+        case LT_EQ:\n+          return convertComparisonExpression(Expressions::lessThanOrEqual, call);\n+\n+        case GT:\n+          return convertComparisonExpression(Expressions::greaterThan, call);\n+\n+        case GT_EQ:\n+          return convertComparisonExpression(Expressions::greaterThanOrEqual, call);\n+\n+        case EQ:\n+          return handleNaN(Expressions::equal, call);\n+\n+        case NOT_EQ:\n+          return handleNaN(Expressions::notEqual, call);\n+\n+        case IN:\n+          List<ResolvedExpression> args = call.getResolvedChildren();\n+          Optional<String> fieldName = toReference(args.get(0));\n+          List<ResolvedExpression> values = args.subList(1, args.size());\n+\n+          List<Object> inputValues = values.stream().filter(expression -> {\n+            if (expression instanceof ValueLiteralExpression) {\n+              return !((ValueLiteralExpression) expression).isNull();\n+            }\n+\n+            return false;\n+          }).map(expression -> {\n+            Optional<Object> value = toLiteral(expression);\n+            return value.get();\n+          }).collect(Collectors.toList());\n+\n+          return Optional.of(Expressions.in(fieldName.get(), inputValues));\n+\n+        case NOT:\n+          Optional<Expression> child = convert(getOnlyChild(call, CallExpression.class).orElse(null));\n+          return child.map(Expressions::not);\n+\n+        case AND:\n+          return convertLogicExpression(Expressions::and, call);\n+\n+        case OR:\n+          return convertLogicExpression(Expressions::or, call);\n+\n+        case STARTS_WITH:\n+          return convertLike(call);\n+      }\n+    }\n+\n+    return Optional.empty();\n+  }\n+\n+  private static <T extends ResolvedExpression> Optional<T> getOnlyChild(CallExpression call,\n+                                                                         Class<T> expectedChildClass) {\n+    List<ResolvedExpression> children = call.getResolvedChildren();\n+    if (children.size() != 1) {\n+      return Optional.empty();\n+    }\n+\n+    ResolvedExpression child = children.get(0);\n+    if (!expectedChildClass.isInstance(child)) {\n+      return Optional.empty();\n+    }\n+\n+    return Optional.of(expectedChildClass.cast(child));\n+  }\n+\n+  private static Optional<Expression> convertLike(CallExpression call) {\n+    Tuple2<String, Object> tuple2 = convertBinaryExpress(call);\n+    if (tuple2 == null) {\n+      return Optional.empty();\n+    }\n+\n+    String pattern = tuple2.f1.toString();\n+    Matcher matcher = STARTS_WITH_PATTERN.matcher(pattern);\n+\n+    // exclude special char of LIKE\n+    // '_' is the wildcard of the SQL LIKE\n+    if (!pattern.contains(\"_\") && matcher.matches()) {\n+      return Optional.of(Expressions.startsWith(tuple2.f0, matcher.group(1)));\n+    }\n+\n+    return Optional.empty();\n+  }\n+\n+  private static Optional<Expression> convertLogicExpression(BiFunction<Expression, Expression, Expression> function,\n+                                                             CallExpression call) {\n+    List<ResolvedExpression> args = call.getResolvedChildren();\n+    Optional<Expression> left = convert(args.get(0));\n+    Optional<Expression> right = convert(args.get(1));\n+    if (left.isPresent() && right.isPresent()) {\n+      return Optional.of(function.apply(left.get(), right.get()));\n+    }\n+\n+    return Optional.empty();\n+  }\n+\n+  private static Optional<Expression> convertComparisonExpression(BiFunction<String, Object, Expression> function,\n+                                                                  CallExpression call) {\n+    Tuple2<String, Object> tuple2 = convertBinaryExpress(call);\n+    if (tuple2 != null) {\n+      return Optional.of(function.apply(tuple2.f0, tuple2.f1));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "847b62f6648d83092e367e682984f38dccf0cfc9"}, "originalPosition": 192}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "847b62f6648d83092e367e682984f38dccf0cfc9", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/847b62f6648d83092e367e682984f38dccf0cfc9", "committedDate": "2020-12-30T03:00:04Z", "message": "fix some bugs and add test case"}, "afterCommit": {"oid": "5a6eac589182db4e2d2a2a73721548275a5776fc", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/5a6eac589182db4e2d2a2a73721548275a5776fc", "committedDate": "2021-01-05T03:20:49Z", "message": "fix some issues"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "5a6eac589182db4e2d2a2a73721548275a5776fc", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/5a6eac589182db4e2d2a2a73721548275a5776fc", "committedDate": "2021-01-05T03:20:49Z", "message": "fix some issues"}, "afterCommit": {"oid": "470882f163072d771880961d0a79ccc58cfa4d90", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/470882f163072d771880961d0a79ccc58cfa4d90", "committedDate": "2021-01-05T03:55:57Z", "message": "fix some issues"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYxNjcwNDkx", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-561670491", "createdAt": "2021-01-05T10:20:17Z", "commit": {"oid": "470882f163072d771880961d0a79ccc58cfa4d90"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNVQxMDoyMDoxN1rOIORrGw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNVQxMDoyMDoxN1rOIORrGw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTg0MDUzOQ==", "bodyText": "I'd prefer to have a basic args check here ( rather than introducing another similar sql(String query, Object... args) method:\nString query = args.length > 0 ? String.format(sql, args) : sql:\nTableResult tableResult = getTableEnv().executeSql(query);", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r551840539", "createdAt": "2021-01-05T10:20:17Z", "author": {"login": "openinx"}, "path": "flink/src/test/java/org/apache/iceberg/flink/FlinkTestBase.java", "diffHunk": "@@ -72,8 +72,21 @@ protected TableEnvironment getTableEnv() {\n     return tEnv;\n   }\n \n+  /**\n+   * if we have a sql with '%' , for example :  SELECT * FROM mytable WHERE data LIKE 'a%'. the format operation will\n+   * throw an exception, so we add a sql method to execute the original sql\n+   *\n+   * @param query the sql\n+   * @param args  the args to format sql\n+   * @return the formated sql\n+   */\n   protected List<Object[]> sql(String query, Object... args) {\n-    TableResult tableResult = getTableEnv().executeSql(String.format(query, args));\n+    String sql = String.format(query, args);\n+    return sql(sql);\n+  }\n+\n+  protected List<Object[]> sql(String sql) {\n+    TableResult tableResult = getTableEnv().executeSql(sql);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "470882f163072d771880961d0a79ccc58cfa4d90"}, "originalPosition": 19}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f931dadbce111418e6d2c94c3adf085b17cdf51f", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/f931dadbce111418e6d2c94c3adf085b17cdf51f", "committedDate": "2021-01-05T10:53:53Z", "message": "do not format sql when args length is 0"}, "afterCommit": {"oid": "1cf9b39191cc289a175f747ebce38b6138efdbe8", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/1cf9b39191cc289a175f747ebce38b6138efdbe8", "committedDate": "2021-01-05T11:14:42Z", "message": "do not format sql when args length is 0"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYxNzMzMDQy", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-561733042", "createdAt": "2021-01-05T12:00:33Z", "commit": {"oid": "1cf9b39191cc289a175f747ebce38b6138efdbe8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNVQxMjowMDozM1rOIOUpqA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNVQxMjowMDozM1rOIOUpqA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTg4OTMyMA==", "bodyText": "the BETWEEN, NOT_BETWEEN,IN expression will be auto convert by flink\n\n-> The BETWEEN, NOT_BETWEEN,IN expression will be converted by flink automatically.\n\nso we do not add the convert here\n\n-> so we do not add the conversion here.\n\nbe convert to\n\n-> be converted to", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r551889320", "createdAt": "2021-01-05T12:00:33Z", "author": {"login": "openinx"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.flink.table.functions.FunctionDefinition;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.DateTimeUtil;\n+import org.apache.iceberg.util.NaNUtil;\n+\n+import static org.apache.iceberg.expressions.Expressions.isNaN;\n+\n+public class FlinkFilters {\n+  private FlinkFilters() {\n+  }\n+\n+  private static final Pattern STARTS_WITH_PATTERN = Pattern.compile(\"([^%]+)%\");\n+\n+  private static final Map<FunctionDefinition, Operation> FILTERS = ImmutableMap\n+      .<FunctionDefinition, Operation>builder()\n+      .put(BuiltInFunctionDefinitions.EQUALS, Operation.EQ)\n+      .put(BuiltInFunctionDefinitions.NOT_EQUALS, Operation.NOT_EQ)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN, Operation.GT)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, Operation.GT_EQ)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN, Operation.LT)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, Operation.LT_EQ)\n+      .put(BuiltInFunctionDefinitions.IN, Operation.IN)\n+      .put(BuiltInFunctionDefinitions.IS_NULL, Operation.IS_NULL)\n+      .put(BuiltInFunctionDefinitions.IS_NOT_NULL, Operation.NOT_NULL)\n+      .put(BuiltInFunctionDefinitions.AND, Operation.AND)\n+      .put(BuiltInFunctionDefinitions.OR, Operation.OR)\n+      .put(BuiltInFunctionDefinitions.NOT, Operation.NOT)\n+      .put(BuiltInFunctionDefinitions.LIKE, Operation.STARTS_WITH)\n+      .build();\n+\n+  /**\n+   * convert flink expression to iceberg expression.\n+   * <p>\n+   * the BETWEEN, NOT_BETWEEN,IN expression will be auto convert by flink. the BETWEEN will be convert to (GT_EQ AND", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1cf9b39191cc289a175f747ebce38b6138efdbe8"}, "originalPosition": 74}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYxNzQ2MzM3", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-561746337", "createdAt": "2021-01-05T12:23:47Z", "commit": {"oid": "1cf9b39191cc289a175f747ebce38b6138efdbe8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNVQxMjoyMzo0N1rOIOVRdw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNVQxMjoyMzo0N1rOIOVRdw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTg5OTUxMQ==", "bodyText": "I think there's a bug here.   Assume the case:  a != NaN,   the handleNaN will return an iceberg expression:  Expressions.isNaN(name).  That's incorrect ?", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r551899511", "createdAt": "2021-01-05T12:23:47Z", "author": {"login": "openinx"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.flink.table.functions.FunctionDefinition;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.DateTimeUtil;\n+import org.apache.iceberg.util.NaNUtil;\n+\n+import static org.apache.iceberg.expressions.Expressions.isNaN;\n+\n+public class FlinkFilters {\n+  private FlinkFilters() {\n+  }\n+\n+  private static final Pattern STARTS_WITH_PATTERN = Pattern.compile(\"([^%]+)%\");\n+\n+  private static final Map<FunctionDefinition, Operation> FILTERS = ImmutableMap\n+      .<FunctionDefinition, Operation>builder()\n+      .put(BuiltInFunctionDefinitions.EQUALS, Operation.EQ)\n+      .put(BuiltInFunctionDefinitions.NOT_EQUALS, Operation.NOT_EQ)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN, Operation.GT)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, Operation.GT_EQ)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN, Operation.LT)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, Operation.LT_EQ)\n+      .put(BuiltInFunctionDefinitions.IN, Operation.IN)\n+      .put(BuiltInFunctionDefinitions.IS_NULL, Operation.IS_NULL)\n+      .put(BuiltInFunctionDefinitions.IS_NOT_NULL, Operation.NOT_NULL)\n+      .put(BuiltInFunctionDefinitions.AND, Operation.AND)\n+      .put(BuiltInFunctionDefinitions.OR, Operation.OR)\n+      .put(BuiltInFunctionDefinitions.NOT, Operation.NOT)\n+      .put(BuiltInFunctionDefinitions.LIKE, Operation.STARTS_WITH)\n+      .build();\n+\n+  /**\n+   * convert flink expression to iceberg expression.\n+   * <p>\n+   * the BETWEEN, NOT_BETWEEN,IN expression will be auto convert by flink. the BETWEEN will be convert to (GT_EQ AND\n+   * LT_EQ), the NOT_BETWEEN will be convert to (LT_EQ OR GT_EQ), the IN will be convert to OR, so we do not add the\n+   * convert here\n+   *\n+   * @param flinkExpression the flink expression\n+   * @return the iceberg expression\n+   */\n+  public static Optional<Expression> convert(org.apache.flink.table.expressions.Expression flinkExpression) {\n+    if (!(flinkExpression instanceof CallExpression)) {\n+      return Optional.empty();\n+    }\n+\n+    CallExpression call = (CallExpression) flinkExpression;\n+    Operation op = FILTERS.get(call.getFunctionDefinition());\n+    if (op != null) {\n+      switch (op) {\n+        case IS_NULL:\n+          Optional<String> name = toReference(singleton(call, FieldReferenceExpression.class).orElse(null));\n+          return name.map(Expressions::isNull);\n+\n+        case NOT_NULL:\n+          Optional<String> nameNotNull = toReference(singleton(call, FieldReferenceExpression.class).orElse(null));\n+          return nameNotNull.map(Expressions::notNull);\n+\n+        case LT:\n+          return convertComparisonExpression(Expressions::lessThan, Expressions::greaterThan, call);\n+\n+        case LT_EQ:\n+          return convertComparisonExpression(Expressions::lessThanOrEqual, Expressions::greaterThanOrEqual, call);\n+\n+        case GT:\n+          return convertComparisonExpression(Expressions::greaterThan, Expressions::lessThan, call);\n+\n+        case GT_EQ:\n+          return convertComparisonExpression(Expressions::greaterThanOrEqual, Expressions::lessThanOrEqual, call);\n+\n+        case EQ:\n+          return handleNaN(Expressions::equal, call);\n+\n+        case NOT_EQ:\n+          return handleNaN(Expressions::notEqual, call);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1cf9b39191cc289a175f747ebce38b6138efdbe8"}, "originalPosition": 114}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYxNzQ3Nzg0", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-561747784", "createdAt": "2021-01-05T12:26:12Z", "commit": {"oid": "1cf9b39191cc289a175f747ebce38b6138efdbe8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNVQxMjoyNjoxMlrOIOVWEg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNVQxMjoyNjoxMlrOIOVWEg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTkwMDY5MA==", "bodyText": "Will the flink convert the NOT_EQ to be NOT ( EQ ) ?  If sure, then we don't have to handle the NOT_EQ ?", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r551900690", "createdAt": "2021-01-05T12:26:12Z", "author": {"login": "openinx"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.flink.table.functions.FunctionDefinition;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.DateTimeUtil;\n+import org.apache.iceberg.util.NaNUtil;\n+\n+import static org.apache.iceberg.expressions.Expressions.isNaN;\n+\n+public class FlinkFilters {\n+  private FlinkFilters() {\n+  }\n+\n+  private static final Pattern STARTS_WITH_PATTERN = Pattern.compile(\"([^%]+)%\");\n+\n+  private static final Map<FunctionDefinition, Operation> FILTERS = ImmutableMap\n+      .<FunctionDefinition, Operation>builder()\n+      .put(BuiltInFunctionDefinitions.EQUALS, Operation.EQ)\n+      .put(BuiltInFunctionDefinitions.NOT_EQUALS, Operation.NOT_EQ)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN, Operation.GT)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, Operation.GT_EQ)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN, Operation.LT)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, Operation.LT_EQ)\n+      .put(BuiltInFunctionDefinitions.IN, Operation.IN)\n+      .put(BuiltInFunctionDefinitions.IS_NULL, Operation.IS_NULL)\n+      .put(BuiltInFunctionDefinitions.IS_NOT_NULL, Operation.NOT_NULL)\n+      .put(BuiltInFunctionDefinitions.AND, Operation.AND)\n+      .put(BuiltInFunctionDefinitions.OR, Operation.OR)\n+      .put(BuiltInFunctionDefinitions.NOT, Operation.NOT)\n+      .put(BuiltInFunctionDefinitions.LIKE, Operation.STARTS_WITH)\n+      .build();\n+\n+  /**\n+   * convert flink expression to iceberg expression.\n+   * <p>\n+   * the BETWEEN, NOT_BETWEEN,IN expression will be auto convert by flink. the BETWEEN will be convert to (GT_EQ AND\n+   * LT_EQ), the NOT_BETWEEN will be convert to (LT_EQ OR GT_EQ), the IN will be convert to OR, so we do not add the\n+   * convert here\n+   *\n+   * @param flinkExpression the flink expression\n+   * @return the iceberg expression\n+   */\n+  public static Optional<Expression> convert(org.apache.flink.table.expressions.Expression flinkExpression) {\n+    if (!(flinkExpression instanceof CallExpression)) {\n+      return Optional.empty();\n+    }\n+\n+    CallExpression call = (CallExpression) flinkExpression;\n+    Operation op = FILTERS.get(call.getFunctionDefinition());\n+    if (op != null) {\n+      switch (op) {\n+        case IS_NULL:\n+          Optional<String> name = toReference(singleton(call, FieldReferenceExpression.class).orElse(null));\n+          return name.map(Expressions::isNull);\n+\n+        case NOT_NULL:\n+          Optional<String> nameNotNull = toReference(singleton(call, FieldReferenceExpression.class).orElse(null));\n+          return nameNotNull.map(Expressions::notNull);\n+\n+        case LT:\n+          return convertComparisonExpression(Expressions::lessThan, Expressions::greaterThan, call);\n+\n+        case LT_EQ:\n+          return convertComparisonExpression(Expressions::lessThanOrEqual, Expressions::greaterThanOrEqual, call);\n+\n+        case GT:\n+          return convertComparisonExpression(Expressions::greaterThan, Expressions::lessThan, call);\n+\n+        case GT_EQ:\n+          return convertComparisonExpression(Expressions::greaterThanOrEqual, Expressions::lessThanOrEqual, call);\n+\n+        case EQ:\n+          return handleNaN(Expressions::equal, call);\n+\n+        case NOT_EQ:", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1cf9b39191cc289a175f747ebce38b6138efdbe8"}, "originalPosition": 113}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYxNzUxMDA4", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-561751008", "createdAt": "2021-01-05T12:31:57Z", "commit": {"oid": "1cf9b39191cc289a175f747ebce38b6138efdbe8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNVQxMjozMTo1N1rOIOVgMA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNVQxMjozMTo1N1rOIOVgMA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTkwMzI4MA==", "bodyText": "It's good to move this class to test packages, I saw nobody from production files would call this.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r551903280", "createdAt": "2021-01-05T12:31:57Z", "author": {"login": "openinx"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkUtil.java", "diffHunk": "@@ -0,0 +1,122 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import org.apache.iceberg.expressions.BoundPredicate;\n+import org.apache.iceberg.expressions.ExpressionVisitors;\n+import org.apache.iceberg.expressions.Literal;\n+import org.apache.iceberg.expressions.UnboundPredicate;\n+\n+public class FlinkUtil {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1cf9b39191cc289a175f747ebce38b6138efdbe8"}, "originalPosition": 30}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYxODUzMDg1", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-561853085", "createdAt": "2021-01-05T14:52:53Z", "commit": {"oid": "1cf9b39191cc289a175f747ebce38b6138efdbe8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNVQxNDo1Mjo1M1rOIOaORQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNVQxNDo1Mjo1M1rOIOaORQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTk4MDYxMw==", "bodyText": "It's better to use ImmutableList.of()  as the default filters because of the comment here, though there's large probability that when isFilterPushedDown() returns true the filters should always be non-nullable.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r551980613", "createdAt": "2021-01-05T14:52:53Z", "author": {"login": "openinx"}, "path": "flink/src/main/java/org/apache/iceberg/flink/IcebergTableSource.java", "diffHunk": "@@ -33,33 +37,37 @@\n import org.apache.flink.table.types.DataType;\n import org.apache.flink.table.utils.TableConnectorUtils;\n import org.apache.iceberg.flink.source.FlinkSource;\n+import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n \n /**\n  * Flink Iceberg table source.\n- * TODO: Implement {@link FilterableTableSource}\n  */\n public class IcebergTableSource\n-    implements StreamTableSource<RowData>, ProjectableTableSource<RowData>, LimitableTableSource<RowData> {\n+    implements StreamTableSource<RowData>, ProjectableTableSource<RowData>, FilterableTableSource<RowData>,\n+    LimitableTableSource<RowData> {\n \n   private final TableLoader loader;\n   private final TableSchema schema;\n   private final Map<String, String> properties;\n   private final int[] projectedFields;\n   private final boolean isLimitPushDown;\n   private final long limit;\n+  private final List<org.apache.iceberg.expressions.Expression> filters;\n \n   public IcebergTableSource(TableLoader loader, TableSchema schema, Map<String, String> properties) {\n-    this(loader, schema, properties, null, false, -1);\n+    this(loader, schema, properties, null, false, -1, null);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1cf9b39191cc289a175f747ebce38b6138efdbe8"}, "originalPosition": 41}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYxODYyMDIx", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-561862021", "createdAt": "2021-01-05T15:02:48Z", "commit": {"oid": "1cf9b39191cc289a175f747ebce38b6138efdbe8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNVQxNTowMjo0OFrOIOanLQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNVQxNTowMjo0OFrOIOanLQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTk4Njk4OQ==", "bodyText": "nit: how about rewrite those as:\n    List<org.apache.iceberg.expressions.Expression> expressions = Lists.newArrayList();\n    for (Expression predicate : predicates) {\n      FlinkFilters.convert(predicate).ifPresent(expressions::add);\n    }", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r551986989", "createdAt": "2021-01-05T15:02:48Z", "author": {"login": "openinx"}, "path": "flink/src/main/java/org/apache/iceberg/flink/IcebergTableSource.java", "diffHunk": "@@ -122,6 +135,24 @@ public boolean isLimitPushedDown() {\n \n   @Override\n   public TableSource<RowData> applyLimit(long newLimit) {\n-    return new IcebergTableSource(loader, schema, properties, projectedFields, true, newLimit);\n+    return new IcebergTableSource(loader, schema, properties, projectedFields, true, newLimit, filters);\n+  }\n+\n+  @Override\n+  public TableSource<RowData> applyPredicate(List<Expression> predicates) {\n+    List<org.apache.iceberg.expressions.Expression> expressions = Lists.newArrayList();\n+    for (Expression predicate : predicates) {\n+      Optional<org.apache.iceberg.expressions.Expression> expression = FlinkFilters.convert(predicate);\n+      if (expression.isPresent()) {\n+        expressions.add(expression.get());\n+      }\n+    }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1cf9b39191cc289a175f747ebce38b6138efdbe8"}, "originalPosition": 102}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYxODY5MzE1", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-561869315", "createdAt": "2021-01-05T15:11:01Z", "commit": {"oid": "1cf9b39191cc289a175f747ebce38b6138efdbe8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNVQxNToxMTowMVrOIOa74g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNVQxNToxMTowMVrOIOa74g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MTk5MjI5MA==", "bodyText": "It's good to have a assert the optional is present before get  its value:\n    Optional<org.apache.iceberg.expressions.Expression> expression = FlinkFilters.convert(expr);\n    Assert.assertTrue(expression.isPresent());", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r551992290", "createdAt": "2021-01-05T15:11:01Z", "author": {"login": "openinx"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkFilters.java", "diffHunk": "@@ -0,0 +1,277 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.math.BigDecimal;\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.Expressions;\n+import org.apache.flink.table.api.TableColumn;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.expressions.ApiExpressionUtils;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.Expression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.UnresolvedCallExpression;\n+import org.apache.flink.table.expressions.UnresolvedReferenceExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.expressions.utils.ApiExpressionDefaultVisitor;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.iceberg.expressions.And;\n+import org.apache.iceberg.expressions.Not;\n+import org.apache.iceberg.expressions.Or;\n+import org.apache.iceberg.expressions.UnboundPredicate;\n+import org.apache.iceberg.util.DateTimeUtil;\n+import org.junit.Test;\n+\n+import static org.apache.flink.table.api.Expressions.$;\n+import static org.apache.flink.table.api.Expressions.lit;\n+import static org.junit.Assert.assertEquals;\n+\n+public class TestFlinkFilters {\n+\n+  private static final TableSchema TABLE_SCHEMA = TableSchema.builder()\n+      .field(\"field1\", DataTypes.INT())\n+      .field(\"field2\", DataTypes.BIGINT())\n+      .field(\"field3\", DataTypes.FLOAT())\n+      .field(\"field4\", DataTypes.DOUBLE())\n+      .field(\"field5\", DataTypes.STRING())\n+      .field(\"field6\", DataTypes.BOOLEAN())\n+      .field(\"field7\", DataTypes.BINARY(10))\n+      .field(\"field8\", DataTypes.DECIMAL(10, 2))\n+      .field(\"field9\", DataTypes.DATE())\n+      .field(\"field10\", DataTypes.TIME())\n+      .field(\"field11\", DataTypes.TIMESTAMP())\n+      .field(\"field12\", DataTypes.TIMESTAMP_WITH_TIME_ZONE())\n+      .field(\"field13\", DataTypes.TIMESTAMP_WITH_LOCAL_TIME_ZONE())\n+      .build();\n+\n+  @Test\n+  public void testFlinkDataTypeEqual() {\n+    matchLiteral(\"field1\", 1, 1);\n+    matchLiteral(\"field2\", 10L, 10L);\n+    matchLiteral(\"field3\", 1.2F, 1.2F);\n+    matchLiteral(\"field4\", 3.4D, 3.4D);\n+    matchLiteral(\"field5\", \"abcd\", \"abcd\");\n+    matchLiteral(\"field6\", true, true);\n+    matchLiteral(\"field7\", new byte[] {'a', 'b'}, new byte[] {'a', 'b'});\n+    matchLiteral(\"field8\", BigDecimal.valueOf(10), BigDecimal.valueOf(10));\n+\n+    LocalDate date = LocalDate.parse(\"2020-12-23\");\n+    matchLiteral(\"field9\", date, DateTimeUtil.daysFromDate(date));\n+\n+    LocalTime time = LocalTime.parse(\"12:13:14\");\n+    matchLiteral(\"field10\", time, DateTimeUtil.microsFromTime(time));\n+\n+    LocalDateTime dateTime = LocalDateTime.parse(\"2020-12-23T12:13:14\");\n+    matchLiteral(\"field11\", dateTime, DateTimeUtil.microsFromTimestamp(dateTime));\n+\n+    Instant instant = Instant.parse(\"2020-12-23T12:13:14.00Z\");\n+    matchLiteral(\"field12\", instant, DateTimeUtil.microsFromInstant(instant));\n+\n+    matchLiteral(\"field13\", instant, DateTimeUtil.microsFromInstant(instant));\n+  }\n+\n+  @Test\n+  public void testEquals() {\n+    UnboundPredicate<Integer> expected = org.apache.iceberg.expressions.Expressions.equal(\"field1\", 1);\n+\n+    org.apache.iceberg.expressions.Expression actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field1\").isEqual(Expressions.lit(1)))).get();\n+    assertPredicatesMatch(expected, (UnboundPredicate) actual);\n+\n+    org.apache.iceberg.expressions.Expression actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(1).isEqual(Expressions.$(\"field1\")))).get();\n+    assertPredicatesMatch(expected, (UnboundPredicate) actual1);\n+  }\n+\n+  @Test\n+  public void testNotEquals() {\n+    UnboundPredicate<Integer> expected = org.apache.iceberg.expressions.Expressions.notEqual(\"field1\", 1);\n+\n+    org.apache.iceberg.expressions.Expression actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field1\").isNotEqual(Expressions.lit(1)))).get();\n+    assertPredicatesMatch(expected, (UnboundPredicate) actual);\n+\n+    org.apache.iceberg.expressions.Expression actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(1).isNotEqual(Expressions.$(\"field1\")))).get();\n+    assertPredicatesMatch(expected, (UnboundPredicate) actual1);\n+  }\n+\n+  @Test\n+  public void testGreaterThan() {\n+    UnboundPredicate<Integer> expected = org.apache.iceberg.expressions.Expressions.greaterThan(\"field1\", 1);\n+\n+    org.apache.iceberg.expressions.Expression actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field1\").isGreater(Expressions.lit(1)))).get();\n+    assertPredicatesMatch(expected, (UnboundPredicate) actual);\n+\n+    org.apache.iceberg.expressions.Expression actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(1).isLess(Expressions.$(\"field1\")))).get();\n+    assertPredicatesMatch(expected, (UnboundPredicate) actual1);\n+  }\n+\n+  @Test\n+  public void testGreaterThanEquals() {\n+    UnboundPredicate<Integer> expected = org.apache.iceberg.expressions.Expressions.greaterThanOrEqual(\"field1\", 1);\n+\n+    org.apache.iceberg.expressions.Expression actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field1\").isGreaterOrEqual(Expressions.lit(1)))).get();\n+    assertPredicatesMatch(expected, (UnboundPredicate) actual);\n+\n+    org.apache.iceberg.expressions.Expression actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(1).isLessOrEqual(Expressions.$(\"field1\")))).get();\n+    assertPredicatesMatch(expected, (UnboundPredicate) actual1);\n+  }\n+\n+  @Test\n+  public void testLessThan() {\n+    UnboundPredicate<Integer> expected = org.apache.iceberg.expressions.Expressions.lessThan(\"field1\", 1);\n+\n+    org.apache.iceberg.expressions.Expression actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field1\").isLess(Expressions.lit(1)))).get();\n+    assertPredicatesMatch(expected, (UnboundPredicate) actual);\n+\n+    org.apache.iceberg.expressions.Expression actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(1).isGreater(Expressions.$(\"field1\")))).get();\n+    assertPredicatesMatch(expected, (UnboundPredicate) actual1);\n+  }\n+\n+  @Test\n+  public void testLessThanEquals() {\n+    UnboundPredicate<Integer> expected = org.apache.iceberg.expressions.Expressions.lessThanOrEqual(\"field1\", 1);\n+\n+    org.apache.iceberg.expressions.Expression actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field1\").isLessOrEqual(Expressions.lit(1)))).get();\n+    assertPredicatesMatch(expected, (UnboundPredicate) actual);\n+\n+    org.apache.iceberg.expressions.Expression actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(1).isGreaterOrEqual(Expressions.$(\"field1\")))).get();\n+    assertPredicatesMatch(expected, (UnboundPredicate) actual1);\n+  }\n+\n+  @Test\n+  public void testIsNull() {\n+    Expression expr = resolve($(\"field1\").isNull());\n+    UnboundPredicate actual = (UnboundPredicate) FlinkFilters.convert(expr).get();\n+    UnboundPredicate<Object> expected = org.apache.iceberg.expressions.Expressions.isNull(\"field1\");\n+    assertPredicatesMatch(expected, actual);\n+  }\n+\n+  @Test\n+  public void testIsNotNull() {\n+    Expression expr = resolve($(\"field1\").isNotNull());\n+    UnboundPredicate actual = (UnboundPredicate) FlinkFilters.convert(expr).get();\n+    UnboundPredicate<Object> expected = org.apache.iceberg.expressions.Expressions.notNull(\"field1\");\n+    assertPredicatesMatch(expected, actual);\n+  }\n+\n+  @Test\n+  public void testAnd() {\n+    Expression expr = resolve(Expressions.$(\"field1\").isEqual(lit(1)).and(Expressions.$(\"field2\").isEqual(lit(2L))));\n+    And actual = (And) FlinkFilters.convert(expr).get();\n+    And expected = (And) org.apache.iceberg.expressions.Expressions.and(\n+        org.apache.iceberg.expressions.Expressions.equal(\"field1\", 1),\n+        org.apache.iceberg.expressions.Expressions.equal(\"field2\", 2L));\n+\n+    assertEquals(expected.op(), actual.op());\n+    assertEquals(expected.left().op(), actual.left().op());\n+    assertEquals(expected.right().op(), actual.right().op());\n+  }\n+\n+  @Test\n+  public void testOr() {\n+    Expression expr = resolve($(\"field1\").isEqual(lit(1)).or($(\"field2\").isEqual(lit(2L))));\n+    Or actual = (Or) FlinkFilters.convert(expr).get();\n+    Or expected = (Or) org.apache.iceberg.expressions.Expressions.or(\n+        org.apache.iceberg.expressions.Expressions.equal(\"field1\", 1),\n+        org.apache.iceberg.expressions.Expressions.equal(\"field2\", 2L));\n+\n+    assertEquals(expected.op(), actual.op());\n+    assertEquals(expected.left().op(), actual.left().op());\n+    assertEquals(expected.right().op(), actual.right().op());\n+  }\n+\n+  @Test\n+  public void testNot() {\n+    Expression expr = resolve(ApiExpressionUtils.unresolvedCall(\n+        BuiltInFunctionDefinitions.NOT, $(\"field1\").isEqual(lit(1))));\n+    Not actual = (Not) FlinkFilters.convert(expr).get();\n+    Not expected = (Not) org.apache.iceberg.expressions.Expressions.not(\n+        org.apache.iceberg.expressions.Expressions.equal(\"field1\", 1));\n+\n+    assertEquals(expected.op(), actual.op());\n+    assertPredicatesMatch((UnboundPredicate) expected.child(), (UnboundPredicate) actual.child());\n+  }\n+\n+  @Test\n+  public void testLike() {\n+    UnboundPredicate expected = org.apache.iceberg.expressions.Expressions.startsWith(\"field5\", \"abc\");\n+    Expression expr = resolve(ApiExpressionUtils.unresolvedCall(\n+        BuiltInFunctionDefinitions.LIKE, $(\"field5\"), lit(\"abc%\")));\n+    assertPredicatesMatch(expected, (UnboundPredicate) FlinkFilters.convert(expr).get());\n+  }\n+\n+  private void matchLiteral(String fieldName, Object flinkLiteral, Object icebergLiteral) {\n+    Expression expr = resolve(Expressions.$(fieldName).isEqual(Expressions.lit(flinkLiteral)));\n+    org.apache.iceberg.expressions.Expression actual = FlinkFilters.convert(expr).get();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1cf9b39191cc289a175f747ebce38b6138efdbe8"}, "originalPosition": 239}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYxODgzODEx", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-561883811", "createdAt": "2021-01-05T15:27:06Z", "commit": {"oid": "1cf9b39191cc289a175f747ebce38b6138efdbe8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNVQxNToyNzowN1rOIObkxw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNVQxNToyNzowN1rOIObkxw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjAwMjc1OQ==", "bodyText": "Pls add NaN cases for both equals and notEquals .", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r552002759", "createdAt": "2021-01-05T15:27:07Z", "author": {"login": "openinx"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkFilters.java", "diffHunk": "@@ -0,0 +1,277 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.math.BigDecimal;\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.Expressions;\n+import org.apache.flink.table.api.TableColumn;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.expressions.ApiExpressionUtils;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.Expression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.UnresolvedCallExpression;\n+import org.apache.flink.table.expressions.UnresolvedReferenceExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.expressions.utils.ApiExpressionDefaultVisitor;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.iceberg.expressions.And;\n+import org.apache.iceberg.expressions.Not;\n+import org.apache.iceberg.expressions.Or;\n+import org.apache.iceberg.expressions.UnboundPredicate;\n+import org.apache.iceberg.util.DateTimeUtil;\n+import org.junit.Test;\n+\n+import static org.apache.flink.table.api.Expressions.$;\n+import static org.apache.flink.table.api.Expressions.lit;\n+import static org.junit.Assert.assertEquals;\n+\n+public class TestFlinkFilters {\n+\n+  private static final TableSchema TABLE_SCHEMA = TableSchema.builder()\n+      .field(\"field1\", DataTypes.INT())\n+      .field(\"field2\", DataTypes.BIGINT())\n+      .field(\"field3\", DataTypes.FLOAT())\n+      .field(\"field4\", DataTypes.DOUBLE())\n+      .field(\"field5\", DataTypes.STRING())\n+      .field(\"field6\", DataTypes.BOOLEAN())\n+      .field(\"field7\", DataTypes.BINARY(10))\n+      .field(\"field8\", DataTypes.DECIMAL(10, 2))\n+      .field(\"field9\", DataTypes.DATE())\n+      .field(\"field10\", DataTypes.TIME())\n+      .field(\"field11\", DataTypes.TIMESTAMP())\n+      .field(\"field12\", DataTypes.TIMESTAMP_WITH_TIME_ZONE())\n+      .field(\"field13\", DataTypes.TIMESTAMP_WITH_LOCAL_TIME_ZONE())\n+      .build();\n+\n+  @Test\n+  public void testFlinkDataTypeEqual() {\n+    matchLiteral(\"field1\", 1, 1);\n+    matchLiteral(\"field2\", 10L, 10L);\n+    matchLiteral(\"field3\", 1.2F, 1.2F);\n+    matchLiteral(\"field4\", 3.4D, 3.4D);\n+    matchLiteral(\"field5\", \"abcd\", \"abcd\");\n+    matchLiteral(\"field6\", true, true);\n+    matchLiteral(\"field7\", new byte[] {'a', 'b'}, new byte[] {'a', 'b'});\n+    matchLiteral(\"field8\", BigDecimal.valueOf(10), BigDecimal.valueOf(10));\n+\n+    LocalDate date = LocalDate.parse(\"2020-12-23\");\n+    matchLiteral(\"field9\", date, DateTimeUtil.daysFromDate(date));\n+\n+    LocalTime time = LocalTime.parse(\"12:13:14\");\n+    matchLiteral(\"field10\", time, DateTimeUtil.microsFromTime(time));\n+\n+    LocalDateTime dateTime = LocalDateTime.parse(\"2020-12-23T12:13:14\");\n+    matchLiteral(\"field11\", dateTime, DateTimeUtil.microsFromTimestamp(dateTime));\n+\n+    Instant instant = Instant.parse(\"2020-12-23T12:13:14.00Z\");\n+    matchLiteral(\"field12\", instant, DateTimeUtil.microsFromInstant(instant));\n+\n+    matchLiteral(\"field13\", instant, DateTimeUtil.microsFromInstant(instant));\n+  }\n+\n+  @Test\n+  public void testEquals() {\n+    UnboundPredicate<Integer> expected = org.apache.iceberg.expressions.Expressions.equal(\"field1\", 1);\n+\n+    org.apache.iceberg.expressions.Expression actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field1\").isEqual(Expressions.lit(1)))).get();\n+    assertPredicatesMatch(expected, (UnboundPredicate) actual);\n+\n+    org.apache.iceberg.expressions.Expression actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(1).isEqual(Expressions.$(\"field1\")))).get();\n+    assertPredicatesMatch(expected, (UnboundPredicate) actual1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1cf9b39191cc289a175f747ebce38b6138efdbe8"}, "originalPosition": 107}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYxODg0NjM1", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-561884635", "createdAt": "2021-01-05T15:28:01Z", "commit": {"oid": "1cf9b39191cc289a175f747ebce38b6138efdbe8"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNVQxNToyODowMVrOIObnFg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wNVQxNToyODowMVrOIObnFg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MjAwMzM1MA==", "bodyText": "Nit: better to check ifPresent before get the value from Optional.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r552003350", "createdAt": "2021-01-05T15:28:01Z", "author": {"login": "openinx"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkFilters.java", "diffHunk": "@@ -0,0 +1,277 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.math.BigDecimal;\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.Expressions;\n+import org.apache.flink.table.api.TableColumn;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.expressions.ApiExpressionUtils;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.Expression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.UnresolvedCallExpression;\n+import org.apache.flink.table.expressions.UnresolvedReferenceExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.expressions.utils.ApiExpressionDefaultVisitor;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.iceberg.expressions.And;\n+import org.apache.iceberg.expressions.Not;\n+import org.apache.iceberg.expressions.Or;\n+import org.apache.iceberg.expressions.UnboundPredicate;\n+import org.apache.iceberg.util.DateTimeUtil;\n+import org.junit.Test;\n+\n+import static org.apache.flink.table.api.Expressions.$;\n+import static org.apache.flink.table.api.Expressions.lit;\n+import static org.junit.Assert.assertEquals;\n+\n+public class TestFlinkFilters {\n+\n+  private static final TableSchema TABLE_SCHEMA = TableSchema.builder()\n+      .field(\"field1\", DataTypes.INT())\n+      .field(\"field2\", DataTypes.BIGINT())\n+      .field(\"field3\", DataTypes.FLOAT())\n+      .field(\"field4\", DataTypes.DOUBLE())\n+      .field(\"field5\", DataTypes.STRING())\n+      .field(\"field6\", DataTypes.BOOLEAN())\n+      .field(\"field7\", DataTypes.BINARY(10))\n+      .field(\"field8\", DataTypes.DECIMAL(10, 2))\n+      .field(\"field9\", DataTypes.DATE())\n+      .field(\"field10\", DataTypes.TIME())\n+      .field(\"field11\", DataTypes.TIMESTAMP())\n+      .field(\"field12\", DataTypes.TIMESTAMP_WITH_TIME_ZONE())\n+      .field(\"field13\", DataTypes.TIMESTAMP_WITH_LOCAL_TIME_ZONE())\n+      .build();\n+\n+  @Test\n+  public void testFlinkDataTypeEqual() {\n+    matchLiteral(\"field1\", 1, 1);\n+    matchLiteral(\"field2\", 10L, 10L);\n+    matchLiteral(\"field3\", 1.2F, 1.2F);\n+    matchLiteral(\"field4\", 3.4D, 3.4D);\n+    matchLiteral(\"field5\", \"abcd\", \"abcd\");\n+    matchLiteral(\"field6\", true, true);\n+    matchLiteral(\"field7\", new byte[] {'a', 'b'}, new byte[] {'a', 'b'});\n+    matchLiteral(\"field8\", BigDecimal.valueOf(10), BigDecimal.valueOf(10));\n+\n+    LocalDate date = LocalDate.parse(\"2020-12-23\");\n+    matchLiteral(\"field9\", date, DateTimeUtil.daysFromDate(date));\n+\n+    LocalTime time = LocalTime.parse(\"12:13:14\");\n+    matchLiteral(\"field10\", time, DateTimeUtil.microsFromTime(time));\n+\n+    LocalDateTime dateTime = LocalDateTime.parse(\"2020-12-23T12:13:14\");\n+    matchLiteral(\"field11\", dateTime, DateTimeUtil.microsFromTimestamp(dateTime));\n+\n+    Instant instant = Instant.parse(\"2020-12-23T12:13:14.00Z\");\n+    matchLiteral(\"field12\", instant, DateTimeUtil.microsFromInstant(instant));\n+\n+    matchLiteral(\"field13\", instant, DateTimeUtil.microsFromInstant(instant));\n+  }\n+\n+  @Test\n+  public void testEquals() {\n+    UnboundPredicate<Integer> expected = org.apache.iceberg.expressions.Expressions.equal(\"field1\", 1);\n+\n+    org.apache.iceberg.expressions.Expression actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field1\").isEqual(Expressions.lit(1)))).get();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "1cf9b39191cc289a175f747ebce38b6138efdbe8"}, "originalPosition": 102}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "1cf9b39191cc289a175f747ebce38b6138efdbe8", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/1cf9b39191cc289a175f747ebce38b6138efdbe8", "committedDate": "2021-01-05T11:14:42Z", "message": "do not format sql when args length is 0"}, "afterCommit": {"oid": "f9cc573c9604c59ad6d98f63fb94edd1fd46fa47", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/f9cc573c9604c59ad6d98f63fb94edd1fd46fa47", "committedDate": "2021-01-06T06:09:34Z", "message": "fix some issues"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f9cc573c9604c59ad6d98f63fb94edd1fd46fa47", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/f9cc573c9604c59ad6d98f63fb94edd1fd46fa47", "committedDate": "2021-01-06T06:09:34Z", "message": "fix some issues"}, "afterCommit": {"oid": "f96e8a3e86dce66300a996b3e5ea76916e426816", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/f96e8a3e86dce66300a996b3e5ea76916e426816", "committedDate": "2021-01-06T06:22:55Z", "message": "fix some issues"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYzMjQwNjkw", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-563240690", "createdAt": "2021-01-07T06:34:19Z", "commit": {"oid": "f96e8a3e86dce66300a996b3e5ea76916e426816"}, "state": "COMMENTED", "comments": {"totalCount": 5, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wN1QwNjozNDoxOVrOIPgqPw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wN1QwNzoyMTozNFrOIPhlLw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzEzNDY1NQ==", "bodyText": "This key-value pairs could be removed , right ?", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r553134655", "createdAt": "2021-01-07T06:34:19Z", "author": {"login": "openinx"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,267 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.function.Function;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.flink.table.functions.FunctionDefinition;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.DateTimeUtil;\n+import org.apache.iceberg.util.NaNUtil;\n+\n+public class FlinkFilters {\n+  private FlinkFilters() {\n+  }\n+\n+  private static final Pattern STARTS_WITH_PATTERN = Pattern.compile(\"([^%]+)%\");\n+\n+  private static final Map<FunctionDefinition, Operation> FILTERS = ImmutableMap\n+      .<FunctionDefinition, Operation>builder()\n+      .put(BuiltInFunctionDefinitions.EQUALS, Operation.EQ)\n+      .put(BuiltInFunctionDefinitions.NOT_EQUALS, Operation.NOT_EQ)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN, Operation.GT)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, Operation.GT_EQ)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN, Operation.LT)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, Operation.LT_EQ)\n+      .put(BuiltInFunctionDefinitions.IN, Operation.IN)", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f96e8a3e86dce66300a996b3e5ea76916e426816"}, "originalPosition": 61}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzEzNjc3Mg==", "bodyText": "Nit:  It's better to rename it as parseFieldAndLiteral ?   The method is not actually convert expressions from flink expr to iceberg expr ?", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r553136772", "createdAt": "2021-01-07T06:41:23Z", "author": {"login": "openinx"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,267 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.function.Function;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.flink.table.functions.FunctionDefinition;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.DateTimeUtil;\n+import org.apache.iceberg.util.NaNUtil;\n+\n+public class FlinkFilters {\n+  private FlinkFilters() {\n+  }\n+\n+  private static final Pattern STARTS_WITH_PATTERN = Pattern.compile(\"([^%]+)%\");\n+\n+  private static final Map<FunctionDefinition, Operation> FILTERS = ImmutableMap\n+      .<FunctionDefinition, Operation>builder()\n+      .put(BuiltInFunctionDefinitions.EQUALS, Operation.EQ)\n+      .put(BuiltInFunctionDefinitions.NOT_EQUALS, Operation.NOT_EQ)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN, Operation.GT)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, Operation.GT_EQ)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN, Operation.LT)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, Operation.LT_EQ)\n+      .put(BuiltInFunctionDefinitions.IN, Operation.IN)\n+      .put(BuiltInFunctionDefinitions.IS_NULL, Operation.IS_NULL)\n+      .put(BuiltInFunctionDefinitions.IS_NOT_NULL, Operation.NOT_NULL)\n+      .put(BuiltInFunctionDefinitions.AND, Operation.AND)\n+      .put(BuiltInFunctionDefinitions.OR, Operation.OR)\n+      .put(BuiltInFunctionDefinitions.NOT, Operation.NOT)\n+      .put(BuiltInFunctionDefinitions.LIKE, Operation.STARTS_WITH)\n+      .build();\n+\n+  /**\n+   * convert flink expression to iceberg expression.\n+   * <p>\n+   * The BETWEEN, NOT_BETWEEN,IN expression will be converted by flink automatically. the BETWEEN will be converted to\n+   * (GT_EQ AND LT_EQ), the NOT_BETWEEN will be converted to (LT_EQ OR GT_EQ), the IN will be converted to OR, so we do\n+   * not add the conversion here\n+   *\n+   * @param flinkExpression the flink expression\n+   * @return the iceberg expression\n+   */\n+  public static Optional<Expression> convert(org.apache.flink.table.expressions.Expression flinkExpression) {\n+    if (!(flinkExpression instanceof CallExpression)) {\n+      return Optional.empty();\n+    }\n+\n+    CallExpression call = (CallExpression) flinkExpression;\n+    Operation op = FILTERS.get(call.getFunctionDefinition());\n+    if (op != null) {\n+      switch (op) {\n+        case IS_NULL:\n+          Optional<String> name = toReference(singleton(call, FieldReferenceExpression.class).orElse(null));\n+          return name.map(Expressions::isNull);\n+\n+        case NOT_NULL:\n+          Optional<String> nameNotNull = toReference(singleton(call, FieldReferenceExpression.class).orElse(null));\n+          return nameNotNull.map(Expressions::notNull);\n+\n+        case LT:\n+          return convertComparisonExpression(Expressions::lessThan, Expressions::greaterThan, call);\n+\n+        case LT_EQ:\n+          return convertComparisonExpression(Expressions::lessThanOrEqual, Expressions::greaterThanOrEqual, call);\n+\n+        case GT:\n+          return convertComparisonExpression(Expressions::greaterThan, Expressions::lessThan, call);\n+\n+        case GT_EQ:\n+          return convertComparisonExpression(Expressions::greaterThanOrEqual, Expressions::lessThanOrEqual, call);\n+\n+        case EQ:\n+          return handleNaN(Expressions::equal, Expressions::isNaN, call);\n+\n+        case NOT_EQ:\n+          return handleNaN(Expressions::notEqual, Expressions::notNaN, call);\n+\n+        case NOT:\n+          Optional<Expression> child = convert(singleton(call, CallExpression.class).orElse(null));\n+          return child.map(Expressions::not);\n+\n+        case AND:\n+          return convertLogicExpression(Expressions::and, call);\n+\n+        case OR:\n+          return convertLogicExpression(Expressions::or, call);\n+\n+        case STARTS_WITH:\n+          return convertLike(call);\n+      }\n+    }\n+\n+    return Optional.empty();\n+  }\n+\n+  private static <T extends ResolvedExpression> Optional<T> singleton(CallExpression call,\n+                                                                      Class<T> expectedChildClass) {\n+    List<ResolvedExpression> children = call.getResolvedChildren();\n+    if (children.size() != 1) {\n+      return Optional.empty();\n+    }\n+\n+    ResolvedExpression child = children.get(0);\n+    if (!expectedChildClass.isInstance(child)) {\n+      return Optional.empty();\n+    }\n+\n+    return Optional.of(expectedChildClass.cast(child));\n+  }\n+\n+  private static Optional<Expression> convertLike(CallExpression call) {\n+    Tuple2<String, Object> tuple2 = convertBinaryExpress(call);\n+    if (tuple2 == null) {\n+      return Optional.empty();\n+    }\n+\n+    String pattern = tuple2.f1.toString();\n+    Matcher matcher = STARTS_WITH_PATTERN.matcher(pattern);\n+\n+    // exclude special char of LIKE\n+    // '_' is the wildcard of the SQL LIKE\n+    if (!pattern.contains(\"_\") && matcher.matches()) {\n+      return Optional.of(Expressions.startsWith(tuple2.f0, matcher.group(1)));\n+    }\n+\n+    return Optional.empty();\n+  }\n+\n+  private static Optional<Expression> convertLogicExpression(BiFunction<Expression, Expression, Expression> function,\n+                                                             CallExpression call) {\n+    List<ResolvedExpression> args = call.getResolvedChildren();\n+    Optional<Expression> left = convert(args.get(0));\n+    Optional<Expression> right = convert(args.get(1));\n+    if (left.isPresent() && right.isPresent()) {\n+      return Optional.of(function.apply(left.get(), right.get()));\n+    }\n+\n+    return Optional.empty();\n+  }\n+\n+  private static Optional<Expression> convertComparisonExpression(\n+      BiFunction<String, Object, Expression> function, BiFunction<String, Object, Expression> reversedFunction,\n+      CallExpression call) {\n+    Tuple2<String, Object> tuple2 = convertBinaryExpress(call);\n+    if (tuple2 != null) {\n+      if (literalOnRight(call.getResolvedChildren())) {\n+        return Optional.of(function.apply(tuple2.f0, tuple2.f1));\n+      } else {\n+        return Optional.of(reversedFunction.apply(tuple2.f0, tuple2.f1));\n+      }\n+    } else {\n+      return Optional.empty();\n+    }\n+  }\n+\n+  private static Optional<String> toReference(org.apache.flink.table.expressions.Expression expression) {\n+    return expression instanceof FieldReferenceExpression ?\n+        Optional.of(((FieldReferenceExpression) expression).getName()) :\n+        Optional.empty();\n+  }\n+\n+  private static Optional<Object> toLiteral(org.apache.flink.table.expressions.Expression expression) {\n+    // Not support null literal\n+    return expression instanceof ValueLiteralExpression ?\n+        convertLiteral((ValueLiteralExpression) expression) :\n+        Optional.empty();\n+  }\n+\n+  private static Optional<Expression> handleNaN(BiFunction<String, Object, Expression> function,\n+                                                Function<String, Expression> functionNaN,\n+                                                CallExpression call) {\n+    Tuple2<String, Object> tuple2 = convertBinaryExpress(call);\n+    if (tuple2 == null) {\n+      return Optional.empty();\n+    }\n+\n+    String name = tuple2.f0;\n+    Object value = tuple2.f1;\n+\n+    if (NaNUtil.isNaN(value)) {\n+      return Optional.of(functionNaN.apply(name));\n+    } else {\n+      return Optional.of(function.apply(name, value));\n+    }\n+  }\n+\n+  private static Optional<Object> convertLiteral(ValueLiteralExpression expression) {\n+    Optional<?> value = expression.getValueAs(expression.getOutputDataType().getLogicalType().getDefaultConversion());\n+    return value.map(o -> {\n+      if (o instanceof LocalDateTime) {\n+        return DateTimeUtil.microsFromTimestamp((LocalDateTime) o);\n+      } else if (o instanceof Instant) {\n+        return DateTimeUtil.microsFromInstant((Instant) o);\n+      } else if (o instanceof LocalTime) {\n+        return DateTimeUtil.microsFromTime((LocalTime) o);\n+      } else if (o instanceof LocalDate) {\n+        return DateTimeUtil.daysFromDate((LocalDate) o);\n+      }\n+\n+      return o;\n+    });\n+  }\n+\n+  private static boolean literalOnRight(List<ResolvedExpression> args) {\n+    return args.get(0) instanceof FieldReferenceExpression && args.get(1) instanceof ValueLiteralExpression;\n+  }\n+\n+  private static Tuple2<String, Object> convertBinaryExpress(CallExpression call) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f96e8a3e86dce66300a996b3e5ea76916e426816"}, "originalPosition": 245}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzE0NzIzNQ==", "bodyText": "For the flink's Binary data type,  its default java type is  byte[],  while the iceberg's BinaryLiteral  will use ByteBuffer.    So we will need to convert it to ByteBuffer ?", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r553147235", "createdAt": "2021-01-07T07:14:16Z", "author": {"login": "openinx"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,267 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.function.Function;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.flink.table.functions.FunctionDefinition;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.DateTimeUtil;\n+import org.apache.iceberg.util.NaNUtil;\n+\n+public class FlinkFilters {\n+  private FlinkFilters() {\n+  }\n+\n+  private static final Pattern STARTS_WITH_PATTERN = Pattern.compile(\"([^%]+)%\");\n+\n+  private static final Map<FunctionDefinition, Operation> FILTERS = ImmutableMap\n+      .<FunctionDefinition, Operation>builder()\n+      .put(BuiltInFunctionDefinitions.EQUALS, Operation.EQ)\n+      .put(BuiltInFunctionDefinitions.NOT_EQUALS, Operation.NOT_EQ)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN, Operation.GT)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, Operation.GT_EQ)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN, Operation.LT)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, Operation.LT_EQ)\n+      .put(BuiltInFunctionDefinitions.IN, Operation.IN)\n+      .put(BuiltInFunctionDefinitions.IS_NULL, Operation.IS_NULL)\n+      .put(BuiltInFunctionDefinitions.IS_NOT_NULL, Operation.NOT_NULL)\n+      .put(BuiltInFunctionDefinitions.AND, Operation.AND)\n+      .put(BuiltInFunctionDefinitions.OR, Operation.OR)\n+      .put(BuiltInFunctionDefinitions.NOT, Operation.NOT)\n+      .put(BuiltInFunctionDefinitions.LIKE, Operation.STARTS_WITH)\n+      .build();\n+\n+  /**\n+   * convert flink expression to iceberg expression.\n+   * <p>\n+   * The BETWEEN, NOT_BETWEEN,IN expression will be converted by flink automatically. the BETWEEN will be converted to\n+   * (GT_EQ AND LT_EQ), the NOT_BETWEEN will be converted to (LT_EQ OR GT_EQ), the IN will be converted to OR, so we do\n+   * not add the conversion here\n+   *\n+   * @param flinkExpression the flink expression\n+   * @return the iceberg expression\n+   */\n+  public static Optional<Expression> convert(org.apache.flink.table.expressions.Expression flinkExpression) {\n+    if (!(flinkExpression instanceof CallExpression)) {\n+      return Optional.empty();\n+    }\n+\n+    CallExpression call = (CallExpression) flinkExpression;\n+    Operation op = FILTERS.get(call.getFunctionDefinition());\n+    if (op != null) {\n+      switch (op) {\n+        case IS_NULL:\n+          Optional<String> name = toReference(singleton(call, FieldReferenceExpression.class).orElse(null));\n+          return name.map(Expressions::isNull);\n+\n+        case NOT_NULL:\n+          Optional<String> nameNotNull = toReference(singleton(call, FieldReferenceExpression.class).orElse(null));\n+          return nameNotNull.map(Expressions::notNull);\n+\n+        case LT:\n+          return convertComparisonExpression(Expressions::lessThan, Expressions::greaterThan, call);\n+\n+        case LT_EQ:\n+          return convertComparisonExpression(Expressions::lessThanOrEqual, Expressions::greaterThanOrEqual, call);\n+\n+        case GT:\n+          return convertComparisonExpression(Expressions::greaterThan, Expressions::lessThan, call);\n+\n+        case GT_EQ:\n+          return convertComparisonExpression(Expressions::greaterThanOrEqual, Expressions::lessThanOrEqual, call);\n+\n+        case EQ:\n+          return handleNaN(Expressions::equal, Expressions::isNaN, call);\n+\n+        case NOT_EQ:\n+          return handleNaN(Expressions::notEqual, Expressions::notNaN, call);\n+\n+        case NOT:\n+          Optional<Expression> child = convert(singleton(call, CallExpression.class).orElse(null));\n+          return child.map(Expressions::not);\n+\n+        case AND:\n+          return convertLogicExpression(Expressions::and, call);\n+\n+        case OR:\n+          return convertLogicExpression(Expressions::or, call);\n+\n+        case STARTS_WITH:\n+          return convertLike(call);\n+      }\n+    }\n+\n+    return Optional.empty();\n+  }\n+\n+  private static <T extends ResolvedExpression> Optional<T> singleton(CallExpression call,\n+                                                                      Class<T> expectedChildClass) {\n+    List<ResolvedExpression> children = call.getResolvedChildren();\n+    if (children.size() != 1) {\n+      return Optional.empty();\n+    }\n+\n+    ResolvedExpression child = children.get(0);\n+    if (!expectedChildClass.isInstance(child)) {\n+      return Optional.empty();\n+    }\n+\n+    return Optional.of(expectedChildClass.cast(child));\n+  }\n+\n+  private static Optional<Expression> convertLike(CallExpression call) {\n+    Tuple2<String, Object> tuple2 = convertBinaryExpress(call);\n+    if (tuple2 == null) {\n+      return Optional.empty();\n+    }\n+\n+    String pattern = tuple2.f1.toString();\n+    Matcher matcher = STARTS_WITH_PATTERN.matcher(pattern);\n+\n+    // exclude special char of LIKE\n+    // '_' is the wildcard of the SQL LIKE\n+    if (!pattern.contains(\"_\") && matcher.matches()) {\n+      return Optional.of(Expressions.startsWith(tuple2.f0, matcher.group(1)));\n+    }\n+\n+    return Optional.empty();\n+  }\n+\n+  private static Optional<Expression> convertLogicExpression(BiFunction<Expression, Expression, Expression> function,\n+                                                             CallExpression call) {\n+    List<ResolvedExpression> args = call.getResolvedChildren();\n+    Optional<Expression> left = convert(args.get(0));\n+    Optional<Expression> right = convert(args.get(1));\n+    if (left.isPresent() && right.isPresent()) {\n+      return Optional.of(function.apply(left.get(), right.get()));\n+    }\n+\n+    return Optional.empty();\n+  }\n+\n+  private static Optional<Expression> convertComparisonExpression(\n+      BiFunction<String, Object, Expression> function, BiFunction<String, Object, Expression> reversedFunction,\n+      CallExpression call) {\n+    Tuple2<String, Object> tuple2 = convertBinaryExpress(call);\n+    if (tuple2 != null) {\n+      if (literalOnRight(call.getResolvedChildren())) {\n+        return Optional.of(function.apply(tuple2.f0, tuple2.f1));\n+      } else {\n+        return Optional.of(reversedFunction.apply(tuple2.f0, tuple2.f1));\n+      }\n+    } else {\n+      return Optional.empty();\n+    }\n+  }\n+\n+  private static Optional<String> toReference(org.apache.flink.table.expressions.Expression expression) {\n+    return expression instanceof FieldReferenceExpression ?\n+        Optional.of(((FieldReferenceExpression) expression).getName()) :\n+        Optional.empty();\n+  }\n+\n+  private static Optional<Object> toLiteral(org.apache.flink.table.expressions.Expression expression) {\n+    // Not support null literal\n+    return expression instanceof ValueLiteralExpression ?\n+        convertLiteral((ValueLiteralExpression) expression) :\n+        Optional.empty();\n+  }\n+\n+  private static Optional<Expression> handleNaN(BiFunction<String, Object, Expression> function,\n+                                                Function<String, Expression> functionNaN,\n+                                                CallExpression call) {\n+    Tuple2<String, Object> tuple2 = convertBinaryExpress(call);\n+    if (tuple2 == null) {\n+      return Optional.empty();\n+    }\n+\n+    String name = tuple2.f0;\n+    Object value = tuple2.f1;\n+\n+    if (NaNUtil.isNaN(value)) {\n+      return Optional.of(functionNaN.apply(name));\n+    } else {\n+      return Optional.of(function.apply(name, value));\n+    }\n+  }\n+\n+  private static Optional<Object> convertLiteral(ValueLiteralExpression expression) {\n+    Optional<?> value = expression.getValueAs(expression.getOutputDataType().getLogicalType().getDefaultConversion());\n+    return value.map(o -> {\n+      if (o instanceof LocalDateTime) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f96e8a3e86dce66300a996b3e5ea76916e426816"}, "originalPosition": 227}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzE0NzUxNQ==", "bodyText": "Pls see the iceberg expression literal types here : https://github.com/apache/iceberg/blob/master/api/src/main/java/org/apache/iceberg/types/Type.java#L30", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r553147515", "createdAt": "2021-01-07T07:15:10Z", "author": {"login": "openinx"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,267 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.function.Function;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.flink.table.functions.FunctionDefinition;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.DateTimeUtil;\n+import org.apache.iceberg.util.NaNUtil;\n+\n+public class FlinkFilters {\n+  private FlinkFilters() {\n+  }\n+\n+  private static final Pattern STARTS_WITH_PATTERN = Pattern.compile(\"([^%]+)%\");\n+\n+  private static final Map<FunctionDefinition, Operation> FILTERS = ImmutableMap\n+      .<FunctionDefinition, Operation>builder()\n+      .put(BuiltInFunctionDefinitions.EQUALS, Operation.EQ)\n+      .put(BuiltInFunctionDefinitions.NOT_EQUALS, Operation.NOT_EQ)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN, Operation.GT)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, Operation.GT_EQ)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN, Operation.LT)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, Operation.LT_EQ)\n+      .put(BuiltInFunctionDefinitions.IN, Operation.IN)\n+      .put(BuiltInFunctionDefinitions.IS_NULL, Operation.IS_NULL)\n+      .put(BuiltInFunctionDefinitions.IS_NOT_NULL, Operation.NOT_NULL)\n+      .put(BuiltInFunctionDefinitions.AND, Operation.AND)\n+      .put(BuiltInFunctionDefinitions.OR, Operation.OR)\n+      .put(BuiltInFunctionDefinitions.NOT, Operation.NOT)\n+      .put(BuiltInFunctionDefinitions.LIKE, Operation.STARTS_WITH)\n+      .build();\n+\n+  /**\n+   * convert flink expression to iceberg expression.\n+   * <p>\n+   * The BETWEEN, NOT_BETWEEN,IN expression will be converted by flink automatically. the BETWEEN will be converted to\n+   * (GT_EQ AND LT_EQ), the NOT_BETWEEN will be converted to (LT_EQ OR GT_EQ), the IN will be converted to OR, so we do\n+   * not add the conversion here\n+   *\n+   * @param flinkExpression the flink expression\n+   * @return the iceberg expression\n+   */\n+  public static Optional<Expression> convert(org.apache.flink.table.expressions.Expression flinkExpression) {\n+    if (!(flinkExpression instanceof CallExpression)) {\n+      return Optional.empty();\n+    }\n+\n+    CallExpression call = (CallExpression) flinkExpression;\n+    Operation op = FILTERS.get(call.getFunctionDefinition());\n+    if (op != null) {\n+      switch (op) {\n+        case IS_NULL:\n+          Optional<String> name = toReference(singleton(call, FieldReferenceExpression.class).orElse(null));\n+          return name.map(Expressions::isNull);\n+\n+        case NOT_NULL:\n+          Optional<String> nameNotNull = toReference(singleton(call, FieldReferenceExpression.class).orElse(null));\n+          return nameNotNull.map(Expressions::notNull);\n+\n+        case LT:\n+          return convertComparisonExpression(Expressions::lessThan, Expressions::greaterThan, call);\n+\n+        case LT_EQ:\n+          return convertComparisonExpression(Expressions::lessThanOrEqual, Expressions::greaterThanOrEqual, call);\n+\n+        case GT:\n+          return convertComparisonExpression(Expressions::greaterThan, Expressions::lessThan, call);\n+\n+        case GT_EQ:\n+          return convertComparisonExpression(Expressions::greaterThanOrEqual, Expressions::lessThanOrEqual, call);\n+\n+        case EQ:\n+          return handleNaN(Expressions::equal, Expressions::isNaN, call);\n+\n+        case NOT_EQ:\n+          return handleNaN(Expressions::notEqual, Expressions::notNaN, call);\n+\n+        case NOT:\n+          Optional<Expression> child = convert(singleton(call, CallExpression.class).orElse(null));\n+          return child.map(Expressions::not);\n+\n+        case AND:\n+          return convertLogicExpression(Expressions::and, call);\n+\n+        case OR:\n+          return convertLogicExpression(Expressions::or, call);\n+\n+        case STARTS_WITH:\n+          return convertLike(call);\n+      }\n+    }\n+\n+    return Optional.empty();\n+  }\n+\n+  private static <T extends ResolvedExpression> Optional<T> singleton(CallExpression call,\n+                                                                      Class<T> expectedChildClass) {\n+    List<ResolvedExpression> children = call.getResolvedChildren();\n+    if (children.size() != 1) {\n+      return Optional.empty();\n+    }\n+\n+    ResolvedExpression child = children.get(0);\n+    if (!expectedChildClass.isInstance(child)) {\n+      return Optional.empty();\n+    }\n+\n+    return Optional.of(expectedChildClass.cast(child));\n+  }\n+\n+  private static Optional<Expression> convertLike(CallExpression call) {\n+    Tuple2<String, Object> tuple2 = convertBinaryExpress(call);\n+    if (tuple2 == null) {\n+      return Optional.empty();\n+    }\n+\n+    String pattern = tuple2.f1.toString();\n+    Matcher matcher = STARTS_WITH_PATTERN.matcher(pattern);\n+\n+    // exclude special char of LIKE\n+    // '_' is the wildcard of the SQL LIKE\n+    if (!pattern.contains(\"_\") && matcher.matches()) {\n+      return Optional.of(Expressions.startsWith(tuple2.f0, matcher.group(1)));\n+    }\n+\n+    return Optional.empty();\n+  }\n+\n+  private static Optional<Expression> convertLogicExpression(BiFunction<Expression, Expression, Expression> function,\n+                                                             CallExpression call) {\n+    List<ResolvedExpression> args = call.getResolvedChildren();\n+    Optional<Expression> left = convert(args.get(0));\n+    Optional<Expression> right = convert(args.get(1));\n+    if (left.isPresent() && right.isPresent()) {\n+      return Optional.of(function.apply(left.get(), right.get()));\n+    }\n+\n+    return Optional.empty();\n+  }\n+\n+  private static Optional<Expression> convertComparisonExpression(\n+      BiFunction<String, Object, Expression> function, BiFunction<String, Object, Expression> reversedFunction,\n+      CallExpression call) {\n+    Tuple2<String, Object> tuple2 = convertBinaryExpress(call);\n+    if (tuple2 != null) {\n+      if (literalOnRight(call.getResolvedChildren())) {\n+        return Optional.of(function.apply(tuple2.f0, tuple2.f1));\n+      } else {\n+        return Optional.of(reversedFunction.apply(tuple2.f0, tuple2.f1));\n+      }\n+    } else {\n+      return Optional.empty();\n+    }\n+  }\n+\n+  private static Optional<String> toReference(org.apache.flink.table.expressions.Expression expression) {\n+    return expression instanceof FieldReferenceExpression ?\n+        Optional.of(((FieldReferenceExpression) expression).getName()) :\n+        Optional.empty();\n+  }\n+\n+  private static Optional<Object> toLiteral(org.apache.flink.table.expressions.Expression expression) {\n+    // Not support null literal\n+    return expression instanceof ValueLiteralExpression ?\n+        convertLiteral((ValueLiteralExpression) expression) :\n+        Optional.empty();\n+  }\n+\n+  private static Optional<Expression> handleNaN(BiFunction<String, Object, Expression> function,\n+                                                Function<String, Expression> functionNaN,\n+                                                CallExpression call) {\n+    Tuple2<String, Object> tuple2 = convertBinaryExpress(call);\n+    if (tuple2 == null) {\n+      return Optional.empty();\n+    }\n+\n+    String name = tuple2.f0;\n+    Object value = tuple2.f1;\n+\n+    if (NaNUtil.isNaN(value)) {\n+      return Optional.of(functionNaN.apply(name));\n+    } else {\n+      return Optional.of(function.apply(name, value));\n+    }\n+  }\n+\n+  private static Optional<Object> convertLiteral(ValueLiteralExpression expression) {\n+    Optional<?> value = expression.getValueAs(expression.getOutputDataType().getLogicalType().getDefaultConversion());\n+    return value.map(o -> {\n+      if (o instanceof LocalDateTime) {", "state": "SUBMITTED", "replyTo": {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzE0NzIzNQ=="}, "originalCommit": {"oid": "f96e8a3e86dce66300a996b3e5ea76916e426816"}, "originalPosition": 227}, {"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzE0OTc0Mw==", "bodyText": "If the literal type of flink is BINARY or VARBINARY,   then its java data type is  byte[],  while in iceberg we will use ByteBuffer to do the literal comparison.  So I think we need to convert it to ByteBuffer by ByteBuffer.wrap((byte[])o) .  Otherwise the iceberg literal comparing will throw a cast failure .\nPls see the java data type for iceberg type  here: https://github.com/apache/iceberg/blob/master/api/src/main/java/org/apache/iceberg/types/Type.java#L30\nBy the way,  I think you unit tests here https://github.com/apache/iceberg/pull/1893/files#diff-5d18d1ff127d1dc70a9a15bbe941f2b6f9d28b3015924f601ac1f722914099dbR81 is incorrect.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r553149743", "createdAt": "2021-01-07T07:21:34Z", "author": {"login": "openinx"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,267 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.function.Function;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.flink.table.functions.FunctionDefinition;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.DateTimeUtil;\n+import org.apache.iceberg.util.NaNUtil;\n+\n+public class FlinkFilters {\n+  private FlinkFilters() {\n+  }\n+\n+  private static final Pattern STARTS_WITH_PATTERN = Pattern.compile(\"([^%]+)%\");\n+\n+  private static final Map<FunctionDefinition, Operation> FILTERS = ImmutableMap\n+      .<FunctionDefinition, Operation>builder()\n+      .put(BuiltInFunctionDefinitions.EQUALS, Operation.EQ)\n+      .put(BuiltInFunctionDefinitions.NOT_EQUALS, Operation.NOT_EQ)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN, Operation.GT)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, Operation.GT_EQ)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN, Operation.LT)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, Operation.LT_EQ)\n+      .put(BuiltInFunctionDefinitions.IN, Operation.IN)\n+      .put(BuiltInFunctionDefinitions.IS_NULL, Operation.IS_NULL)\n+      .put(BuiltInFunctionDefinitions.IS_NOT_NULL, Operation.NOT_NULL)\n+      .put(BuiltInFunctionDefinitions.AND, Operation.AND)\n+      .put(BuiltInFunctionDefinitions.OR, Operation.OR)\n+      .put(BuiltInFunctionDefinitions.NOT, Operation.NOT)\n+      .put(BuiltInFunctionDefinitions.LIKE, Operation.STARTS_WITH)\n+      .build();\n+\n+  /**\n+   * convert flink expression to iceberg expression.\n+   * <p>\n+   * The BETWEEN, NOT_BETWEEN,IN expression will be converted by flink automatically. the BETWEEN will be converted to\n+   * (GT_EQ AND LT_EQ), the NOT_BETWEEN will be converted to (LT_EQ OR GT_EQ), the IN will be converted to OR, so we do\n+   * not add the conversion here\n+   *\n+   * @param flinkExpression the flink expression\n+   * @return the iceberg expression\n+   */\n+  public static Optional<Expression> convert(org.apache.flink.table.expressions.Expression flinkExpression) {\n+    if (!(flinkExpression instanceof CallExpression)) {\n+      return Optional.empty();\n+    }\n+\n+    CallExpression call = (CallExpression) flinkExpression;\n+    Operation op = FILTERS.get(call.getFunctionDefinition());\n+    if (op != null) {\n+      switch (op) {\n+        case IS_NULL:\n+          Optional<String> name = toReference(singleton(call, FieldReferenceExpression.class).orElse(null));\n+          return name.map(Expressions::isNull);\n+\n+        case NOT_NULL:\n+          Optional<String> nameNotNull = toReference(singleton(call, FieldReferenceExpression.class).orElse(null));\n+          return nameNotNull.map(Expressions::notNull);\n+\n+        case LT:\n+          return convertComparisonExpression(Expressions::lessThan, Expressions::greaterThan, call);\n+\n+        case LT_EQ:\n+          return convertComparisonExpression(Expressions::lessThanOrEqual, Expressions::greaterThanOrEqual, call);\n+\n+        case GT:\n+          return convertComparisonExpression(Expressions::greaterThan, Expressions::lessThan, call);\n+\n+        case GT_EQ:\n+          return convertComparisonExpression(Expressions::greaterThanOrEqual, Expressions::lessThanOrEqual, call);\n+\n+        case EQ:\n+          return handleNaN(Expressions::equal, Expressions::isNaN, call);\n+\n+        case NOT_EQ:\n+          return handleNaN(Expressions::notEqual, Expressions::notNaN, call);\n+\n+        case NOT:\n+          Optional<Expression> child = convert(singleton(call, CallExpression.class).orElse(null));\n+          return child.map(Expressions::not);\n+\n+        case AND:\n+          return convertLogicExpression(Expressions::and, call);\n+\n+        case OR:\n+          return convertLogicExpression(Expressions::or, call);\n+\n+        case STARTS_WITH:\n+          return convertLike(call);\n+      }\n+    }\n+\n+    return Optional.empty();\n+  }\n+\n+  private static <T extends ResolvedExpression> Optional<T> singleton(CallExpression call,\n+                                                                      Class<T> expectedChildClass) {\n+    List<ResolvedExpression> children = call.getResolvedChildren();\n+    if (children.size() != 1) {\n+      return Optional.empty();\n+    }\n+\n+    ResolvedExpression child = children.get(0);\n+    if (!expectedChildClass.isInstance(child)) {\n+      return Optional.empty();\n+    }\n+\n+    return Optional.of(expectedChildClass.cast(child));\n+  }\n+\n+  private static Optional<Expression> convertLike(CallExpression call) {\n+    Tuple2<String, Object> tuple2 = convertBinaryExpress(call);\n+    if (tuple2 == null) {\n+      return Optional.empty();\n+    }\n+\n+    String pattern = tuple2.f1.toString();\n+    Matcher matcher = STARTS_WITH_PATTERN.matcher(pattern);\n+\n+    // exclude special char of LIKE\n+    // '_' is the wildcard of the SQL LIKE\n+    if (!pattern.contains(\"_\") && matcher.matches()) {\n+      return Optional.of(Expressions.startsWith(tuple2.f0, matcher.group(1)));\n+    }\n+\n+    return Optional.empty();\n+  }\n+\n+  private static Optional<Expression> convertLogicExpression(BiFunction<Expression, Expression, Expression> function,\n+                                                             CallExpression call) {\n+    List<ResolvedExpression> args = call.getResolvedChildren();\n+    Optional<Expression> left = convert(args.get(0));\n+    Optional<Expression> right = convert(args.get(1));\n+    if (left.isPresent() && right.isPresent()) {\n+      return Optional.of(function.apply(left.get(), right.get()));\n+    }\n+\n+    return Optional.empty();\n+  }\n+\n+  private static Optional<Expression> convertComparisonExpression(\n+      BiFunction<String, Object, Expression> function, BiFunction<String, Object, Expression> reversedFunction,\n+      CallExpression call) {\n+    Tuple2<String, Object> tuple2 = convertBinaryExpress(call);\n+    if (tuple2 != null) {\n+      if (literalOnRight(call.getResolvedChildren())) {\n+        return Optional.of(function.apply(tuple2.f0, tuple2.f1));\n+      } else {\n+        return Optional.of(reversedFunction.apply(tuple2.f0, tuple2.f1));\n+      }\n+    } else {\n+      return Optional.empty();\n+    }\n+  }\n+\n+  private static Optional<String> toReference(org.apache.flink.table.expressions.Expression expression) {\n+    return expression instanceof FieldReferenceExpression ?\n+        Optional.of(((FieldReferenceExpression) expression).getName()) :\n+        Optional.empty();\n+  }\n+\n+  private static Optional<Object> toLiteral(org.apache.flink.table.expressions.Expression expression) {\n+    // Not support null literal\n+    return expression instanceof ValueLiteralExpression ?\n+        convertLiteral((ValueLiteralExpression) expression) :\n+        Optional.empty();\n+  }\n+\n+  private static Optional<Expression> handleNaN(BiFunction<String, Object, Expression> function,\n+                                                Function<String, Expression> functionNaN,\n+                                                CallExpression call) {\n+    Tuple2<String, Object> tuple2 = convertBinaryExpress(call);\n+    if (tuple2 == null) {\n+      return Optional.empty();\n+    }\n+\n+    String name = tuple2.f0;\n+    Object value = tuple2.f1;\n+\n+    if (NaNUtil.isNaN(value)) {\n+      return Optional.of(functionNaN.apply(name));\n+    } else {\n+      return Optional.of(function.apply(name, value));\n+    }\n+  }\n+\n+  private static Optional<Object> convertLiteral(ValueLiteralExpression expression) {\n+    Optional<?> value = expression.getValueAs(expression.getOutputDataType().getLogicalType().getDefaultConversion());\n+    return value.map(o -> {\n+      if (o instanceof LocalDateTime) {\n+        return DateTimeUtil.microsFromTimestamp((LocalDateTime) o);\n+      } else if (o instanceof Instant) {\n+        return DateTimeUtil.microsFromInstant((Instant) o);\n+      } else if (o instanceof LocalTime) {\n+        return DateTimeUtil.microsFromTime((LocalTime) o);\n+      } else if (o instanceof LocalDate) {\n+        return DateTimeUtil.daysFromDate((LocalDate) o);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f96e8a3e86dce66300a996b3e5ea76916e426816"}, "originalPosition": 234}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYzMjY5NDI5", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-563269429", "createdAt": "2021-01-07T07:46:54Z", "commit": {"oid": "f96e8a3e86dce66300a996b3e5ea76916e426816"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wN1QwNzo0Njo1NFrOIPiImA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wN1QwNzo0Njo1NFrOIPiImA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzE1ODgwOA==", "bodyText": "In this matchLiteral testing method,  we will provide both flink's java data type and iceberg's java data type ( for asserting).   I think it's not a good way to test those literals because if people don't quite understand what's the specific java data type that iceberg type is mapping,   then he may provide the wrong iceberg's java type to assert.  The BINARY type is an example.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r553158808", "createdAt": "2021-01-07T07:46:54Z", "author": {"login": "openinx"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkFilters.java", "diffHunk": "@@ -0,0 +1,306 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.math.BigDecimal;\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.stream.Collectors;\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.Expressions;\n+import org.apache.flink.table.api.TableColumn;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.expressions.ApiExpressionUtils;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.Expression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.UnresolvedCallExpression;\n+import org.apache.flink.table.expressions.UnresolvedReferenceExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.expressions.utils.ApiExpressionDefaultVisitor;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.iceberg.expressions.And;\n+import org.apache.iceberg.expressions.Not;\n+import org.apache.iceberg.expressions.Or;\n+import org.apache.iceberg.expressions.UnboundPredicate;\n+import org.apache.iceberg.util.DateTimeUtil;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import static org.apache.flink.table.api.Expressions.$;\n+import static org.apache.flink.table.api.Expressions.lit;\n+import static org.junit.Assert.assertEquals;\n+\n+public class TestFlinkFilters {\n+\n+  private static final TableSchema TABLE_SCHEMA = TableSchema.builder()\n+      .field(\"field1\", DataTypes.INT())\n+      .field(\"field2\", DataTypes.BIGINT())\n+      .field(\"field3\", DataTypes.FLOAT())\n+      .field(\"field4\", DataTypes.DOUBLE())\n+      .field(\"field5\", DataTypes.STRING())\n+      .field(\"field6\", DataTypes.BOOLEAN())\n+      .field(\"field7\", DataTypes.BINARY(10))\n+      .field(\"field8\", DataTypes.DECIMAL(10, 2))\n+      .field(\"field9\", DataTypes.DATE())\n+      .field(\"field10\", DataTypes.TIME())\n+      .field(\"field11\", DataTypes.TIMESTAMP())\n+      .field(\"field12\", DataTypes.TIMESTAMP_WITH_TIME_ZONE())\n+      .field(\"field13\", DataTypes.TIMESTAMP_WITH_LOCAL_TIME_ZONE())\n+      .build();\n+\n+  @Test\n+  public void testFlinkDataTypeEqual() {\n+    matchLiteral(\"field1\", 1, 1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f96e8a3e86dce66300a996b3e5ea76916e426816"}, "originalPosition": 75}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYzMjcyNDI1", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-563272425", "createdAt": "2021-01-07T07:53:23Z", "commit": {"oid": "f96e8a3e86dce66300a996b3e5ea76916e426816"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wN1QwNzo1MzoyM1rOIPiR5A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wN1QwNzo1MzoyM1rOIPiR5A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzE2MTE4OA==", "bodyText": "It's good to have test cases for all other data types except Integer.  I guess we may need few abstraction so that the test code won't duplicate too many.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r553161188", "createdAt": "2021-01-07T07:53:23Z", "author": {"login": "openinx"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkFilters.java", "diffHunk": "@@ -0,0 +1,306 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.math.BigDecimal;\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.stream.Collectors;\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.Expressions;\n+import org.apache.flink.table.api.TableColumn;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.expressions.ApiExpressionUtils;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.Expression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.UnresolvedCallExpression;\n+import org.apache.flink.table.expressions.UnresolvedReferenceExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.expressions.utils.ApiExpressionDefaultVisitor;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.iceberg.expressions.And;\n+import org.apache.iceberg.expressions.Not;\n+import org.apache.iceberg.expressions.Or;\n+import org.apache.iceberg.expressions.UnboundPredicate;\n+import org.apache.iceberg.util.DateTimeUtil;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+import static org.apache.flink.table.api.Expressions.$;\n+import static org.apache.flink.table.api.Expressions.lit;\n+import static org.junit.Assert.assertEquals;\n+\n+public class TestFlinkFilters {\n+\n+  private static final TableSchema TABLE_SCHEMA = TableSchema.builder()\n+      .field(\"field1\", DataTypes.INT())\n+      .field(\"field2\", DataTypes.BIGINT())\n+      .field(\"field3\", DataTypes.FLOAT())\n+      .field(\"field4\", DataTypes.DOUBLE())\n+      .field(\"field5\", DataTypes.STRING())\n+      .field(\"field6\", DataTypes.BOOLEAN())\n+      .field(\"field7\", DataTypes.BINARY(10))\n+      .field(\"field8\", DataTypes.DECIMAL(10, 2))\n+      .field(\"field9\", DataTypes.DATE())\n+      .field(\"field10\", DataTypes.TIME())\n+      .field(\"field11\", DataTypes.TIMESTAMP())\n+      .field(\"field12\", DataTypes.TIMESTAMP_WITH_TIME_ZONE())\n+      .field(\"field13\", DataTypes.TIMESTAMP_WITH_LOCAL_TIME_ZONE())\n+      .build();\n+\n+  @Test\n+  public void testFlinkDataTypeEqual() {\n+    matchLiteral(\"field1\", 1, 1);\n+    matchLiteral(\"field2\", 10L, 10L);\n+    matchLiteral(\"field3\", 1.2F, 1.2F);\n+    matchLiteral(\"field4\", 3.4D, 3.4D);\n+    matchLiteral(\"field5\", \"abcd\", \"abcd\");\n+    matchLiteral(\"field6\", true, true);\n+    matchLiteral(\"field7\", new byte[] {'a', 'b'}, new byte[] {'a', 'b'});\n+    matchLiteral(\"field8\", BigDecimal.valueOf(10), BigDecimal.valueOf(10));\n+\n+    LocalDate date = LocalDate.parse(\"2020-12-23\");\n+    matchLiteral(\"field9\", date, DateTimeUtil.daysFromDate(date));\n+\n+    LocalTime time = LocalTime.parse(\"12:13:14\");\n+    matchLiteral(\"field10\", time, DateTimeUtil.microsFromTime(time));\n+\n+    LocalDateTime dateTime = LocalDateTime.parse(\"2020-12-23T12:13:14\");\n+    matchLiteral(\"field11\", dateTime, DateTimeUtil.microsFromTimestamp(dateTime));\n+\n+    Instant instant = Instant.parse(\"2020-12-23T12:13:14.00Z\");\n+    matchLiteral(\"field12\", instant, DateTimeUtil.microsFromInstant(instant));\n+\n+    matchLiteral(\"field13\", instant, DateTimeUtil.microsFromInstant(instant));\n+  }\n+\n+  @Test\n+  public void testEquals() {\n+    UnboundPredicate<Integer> expected = org.apache.iceberg.expressions.Expressions.equal(\"field1\", 1);\n+\n+    org.apache.iceberg.expressions.Expression actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field1\").isEqual(Expressions.lit(1)))).orElse(null);\n+    assertPredicatesMatch(expected, (UnboundPredicate) actual);\n+\n+    org.apache.iceberg.expressions.Expression actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(1).isEqual(Expressions.$(\"field1\")))).orElse(null);\n+    assertPredicatesMatch(expected, (UnboundPredicate) actual1);\n+  }\n+\n+  @Test\n+  public void testEqualsNaN() {\n+    UnboundPredicate<Float> expected = org.apache.iceberg.expressions.Expressions.isNaN(\"field3\");\n+\n+    org.apache.iceberg.expressions.Expression actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field3\").isEqual(Expressions.lit(Float.NaN)))).orElse(null);\n+    assertPredicatesMatch(expected, (UnboundPredicate) actual);\n+\n+    org.apache.iceberg.expressions.Expression actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(Float.NaN).isEqual(Expressions.$(\"field3\")))).orElse(null);\n+    assertPredicatesMatch(expected, (UnboundPredicate) actual1);\n+  }\n+\n+  @Test\n+  public void testNotEquals() {\n+    UnboundPredicate<Integer> expected = org.apache.iceberg.expressions.Expressions.notEqual(\"field1\", 1);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f96e8a3e86dce66300a996b3e5ea76916e426816"}, "originalPosition": 127}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYzMjc1MjUw", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-563275250", "createdAt": "2021-01-07T07:59:03Z", "commit": {"oid": "f96e8a3e86dce66300a996b3e5ea76916e426816"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wN1QwNzo1OTowNFrOIPia_w==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wN1QwNzo1OTowNFrOIPia_w==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzE2MzUxOQ==", "bodyText": "Asserting that the explain contains FilterPushDown does not have much meaning because all explained string will contains that word ( see the IcebergTableSource#explainSource ).   The key part to assert is the last part:\nString.format(\", FilterPushDown,the filters :%s\", Joiner.on(\",\").join(filters));\nI mean we need to assert  Joiner.on(\",\").join(filters) part ( for all the following cases).", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r553163519", "createdAt": "2021-01-07T07:59:04Z", "author": {"login": "openinx"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkTableSource.java", "diffHunk": "@@ -75,32 +95,396 @@ public void clean() {\n \n   @Test\n   public void testLimitPushDown() {\n-    sql(\"INSERT INTO %s  VALUES (1,'a'),(2,'b')\", TABLE_NAME);\n-\n     String querySql = String.format(\"SELECT * FROM %s LIMIT 1\", TABLE_NAME);\n     String explain = getTableEnv().explainSql(querySql);\n     String expectedExplain = \"LimitPushDown : 1\";\n     Assert.assertTrue(\"explain should contains LimitPushDown\", explain.contains(expectedExplain));\n     List<Object[]> result = sql(querySql);\n-    Assert.assertEquals(\"should have 1 record\", 1, result.size());\n-    Assert.assertArrayEquals(\"Should produce the expected records\", result.get(0), new Object[] {1, \"a\"});\n+    assertEquals(\"should have 1 record\", 1, result.size());\n+    assertArrayEquals(\"Should produce the expected records\", result.get(0), new Object[] {1, \"a\"});\n \n     AssertHelpers.assertThrows(\"Invalid limit number: -1 \", SqlParserException.class,\n         () -> sql(\"SELECT * FROM %s LIMIT -1\", TABLE_NAME));\n \n-    Assert.assertEquals(\"should have 0 record\", 0, sql(\"SELECT * FROM %s LIMIT 0\", TABLE_NAME).size());\n+    assertEquals(\"should have 0 record\", 0, sql(\"SELECT * FROM %s LIMIT 0\", TABLE_NAME).size());\n \n-    String sqlLimitExceed = String.format(\"SELECT * FROM %s LIMIT 3\", TABLE_NAME);\n+    String sqlLimitExceed = String.format(\"SELECT * FROM %s LIMIT 4\", TABLE_NAME);\n     List<Object[]> resultExceed = sql(sqlLimitExceed);\n-    Assert.assertEquals(\"should have 2 record\", 2, resultExceed.size());\n+    assertEquals(\"should have 3 record\", 3, resultExceed.size());\n     List<Object[]> expectedList = Lists.newArrayList();\n     expectedList.add(new Object[] {1, \"a\"});\n     expectedList.add(new Object[] {2, \"b\"});\n-    Assert.assertArrayEquals(\"Should produce the expected records\", resultExceed.toArray(), expectedList.toArray());\n+    expectedList.add(new Object[] {3, null});\n+    assertArrayEquals(\"Should produce the expected records\", resultExceed.toArray(), expectedList.toArray());\n \n     String sqlMixed = String.format(\"SELECT * FROM %s WHERE id = 1 LIMIT 2\", TABLE_NAME);\n     List<Object[]> mixedResult = sql(sqlMixed);\n-    Assert.assertEquals(\"should have 1 record\", 1, mixedResult.size());\n-    Assert.assertArrayEquals(\"Should produce the expected records\", mixedResult.get(0), new Object[] {1, \"a\"});\n+    assertEquals(\"should have 1 record\", 1, mixedResult.size());\n+    assertArrayEquals(\"Should produce the expected records\", mixedResult.get(0), new Object[] {1, \"a\"});\n+  }\n+\n+  @Test\n+  public void testNoFilterPushDown() {\n+    String sql = String.format(\"SELECT * FROM %s \", TABLE_NAME);\n+    String explain = getTableEnv().explainSql(sql);\n+    assertFalse(\"explain should no contains FilterPushDown\", explain.contains(expectedFilterPushDownExplain));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f96e8a3e86dce66300a996b3e5ea76916e426816"}, "originalPosition": 107}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYzMjc4MDUx", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-563278051", "createdAt": "2021-01-07T08:04:30Z", "commit": {"oid": "f96e8a3e86dce66300a996b3e5ea76916e426816"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wN1QwODowNDozMVrOIPijSw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wN1QwODowNDozMVrOIPijSw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzE2NTY0Mw==", "bodyText": "Nit:  we could just use the assertEquals for two lists, don't have to convert it to array and then use assertArrayEquals ?", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r553165643", "createdAt": "2021-01-07T08:04:31Z", "author": {"login": "openinx"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkTableSource.java", "diffHunk": "@@ -75,32 +95,396 @@ public void clean() {\n \n   @Test\n   public void testLimitPushDown() {\n-    sql(\"INSERT INTO %s  VALUES (1,'a'),(2,'b')\", TABLE_NAME);\n-\n     String querySql = String.format(\"SELECT * FROM %s LIMIT 1\", TABLE_NAME);\n     String explain = getTableEnv().explainSql(querySql);\n     String expectedExplain = \"LimitPushDown : 1\";\n     Assert.assertTrue(\"explain should contains LimitPushDown\", explain.contains(expectedExplain));\n     List<Object[]> result = sql(querySql);\n-    Assert.assertEquals(\"should have 1 record\", 1, result.size());\n-    Assert.assertArrayEquals(\"Should produce the expected records\", result.get(0), new Object[] {1, \"a\"});\n+    assertEquals(\"should have 1 record\", 1, result.size());\n+    assertArrayEquals(\"Should produce the expected records\", result.get(0), new Object[] {1, \"a\"});\n \n     AssertHelpers.assertThrows(\"Invalid limit number: -1 \", SqlParserException.class,\n         () -> sql(\"SELECT * FROM %s LIMIT -1\", TABLE_NAME));\n \n-    Assert.assertEquals(\"should have 0 record\", 0, sql(\"SELECT * FROM %s LIMIT 0\", TABLE_NAME).size());\n+    assertEquals(\"should have 0 record\", 0, sql(\"SELECT * FROM %s LIMIT 0\", TABLE_NAME).size());\n \n-    String sqlLimitExceed = String.format(\"SELECT * FROM %s LIMIT 3\", TABLE_NAME);\n+    String sqlLimitExceed = String.format(\"SELECT * FROM %s LIMIT 4\", TABLE_NAME);\n     List<Object[]> resultExceed = sql(sqlLimitExceed);\n-    Assert.assertEquals(\"should have 2 record\", 2, resultExceed.size());\n+    assertEquals(\"should have 3 record\", 3, resultExceed.size());\n     List<Object[]> expectedList = Lists.newArrayList();\n     expectedList.add(new Object[] {1, \"a\"});\n     expectedList.add(new Object[] {2, \"b\"});\n-    Assert.assertArrayEquals(\"Should produce the expected records\", resultExceed.toArray(), expectedList.toArray());\n+    expectedList.add(new Object[] {3, null});\n+    assertArrayEquals(\"Should produce the expected records\", resultExceed.toArray(), expectedList.toArray());\n \n     String sqlMixed = String.format(\"SELECT * FROM %s WHERE id = 1 LIMIT 2\", TABLE_NAME);\n     List<Object[]> mixedResult = sql(sqlMixed);\n-    Assert.assertEquals(\"should have 1 record\", 1, mixedResult.size());\n-    Assert.assertArrayEquals(\"Should produce the expected records\", mixedResult.get(0), new Object[] {1, \"a\"});\n+    assertEquals(\"should have 1 record\", 1, mixedResult.size());\n+    assertArrayEquals(\"Should produce the expected records\", mixedResult.get(0), new Object[] {1, \"a\"});\n+  }\n+\n+  @Test\n+  public void testNoFilterPushDown() {\n+    String sql = String.format(\"SELECT * FROM %s \", TABLE_NAME);\n+    String explain = getTableEnv().explainSql(sql);\n+    assertFalse(\"explain should no contains FilterPushDown\", explain.contains(expectedFilterPushDownExplain));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownEqual() {\n+    String sqlLiteralRight = String.format(\"SELECT * FROM %s WHERE id = 1 \", TABLE_NAME);\n+    String explain = getTableEnv().explainSql(sqlLiteralRight);\n+    assertTrue(\"explain should contains FilterPushDown\", explain.contains(expectedFilterPushDownExplain));\n+\n+    List<Object[]> result = sql(sqlLiteralRight);\n+    assertEquals(\"should have 1 record\", 1, result.size());\n+    assertArrayEquals(\"Should produce the expected record\", result.get(0), new Object[] {1, \"a\"});", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f96e8a3e86dce66300a996b3e5ea76916e426816"}, "originalPosition": 118}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYzMjc4NTcy", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-563278572", "createdAt": "2021-01-07T08:05:34Z", "commit": {"oid": "f96e8a3e86dce66300a996b3e5ea76916e426816"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wN1QwODowNTozNVrOIPilAg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0wN1QwODowNTozNVrOIPilAg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1MzE2NjA4Mg==", "bodyText": "nit: If we use the static imported assertEquals before then we don't use Assert.assertEquals here ?  Make them to be unified.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r553166082", "createdAt": "2021-01-07T08:05:35Z", "author": {"login": "openinx"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkTableSource.java", "diffHunk": "@@ -75,32 +95,396 @@ public void clean() {\n \n   @Test\n   public void testLimitPushDown() {\n-    sql(\"INSERT INTO %s  VALUES (1,'a'),(2,'b')\", TABLE_NAME);\n-\n     String querySql = String.format(\"SELECT * FROM %s LIMIT 1\", TABLE_NAME);\n     String explain = getTableEnv().explainSql(querySql);\n     String expectedExplain = \"LimitPushDown : 1\";\n     Assert.assertTrue(\"explain should contains LimitPushDown\", explain.contains(expectedExplain));\n     List<Object[]> result = sql(querySql);\n-    Assert.assertEquals(\"should have 1 record\", 1, result.size());\n-    Assert.assertArrayEquals(\"Should produce the expected records\", result.get(0), new Object[] {1, \"a\"});\n+    assertEquals(\"should have 1 record\", 1, result.size());\n+    assertArrayEquals(\"Should produce the expected records\", result.get(0), new Object[] {1, \"a\"});\n \n     AssertHelpers.assertThrows(\"Invalid limit number: -1 \", SqlParserException.class,\n         () -> sql(\"SELECT * FROM %s LIMIT -1\", TABLE_NAME));\n \n-    Assert.assertEquals(\"should have 0 record\", 0, sql(\"SELECT * FROM %s LIMIT 0\", TABLE_NAME).size());\n+    assertEquals(\"should have 0 record\", 0, sql(\"SELECT * FROM %s LIMIT 0\", TABLE_NAME).size());\n \n-    String sqlLimitExceed = String.format(\"SELECT * FROM %s LIMIT 3\", TABLE_NAME);\n+    String sqlLimitExceed = String.format(\"SELECT * FROM %s LIMIT 4\", TABLE_NAME);\n     List<Object[]> resultExceed = sql(sqlLimitExceed);\n-    Assert.assertEquals(\"should have 2 record\", 2, resultExceed.size());\n+    assertEquals(\"should have 3 record\", 3, resultExceed.size());\n     List<Object[]> expectedList = Lists.newArrayList();\n     expectedList.add(new Object[] {1, \"a\"});\n     expectedList.add(new Object[] {2, \"b\"});\n-    Assert.assertArrayEquals(\"Should produce the expected records\", resultExceed.toArray(), expectedList.toArray());\n+    expectedList.add(new Object[] {3, null});\n+    assertArrayEquals(\"Should produce the expected records\", resultExceed.toArray(), expectedList.toArray());\n \n     String sqlMixed = String.format(\"SELECT * FROM %s WHERE id = 1 LIMIT 2\", TABLE_NAME);\n     List<Object[]> mixedResult = sql(sqlMixed);\n-    Assert.assertEquals(\"should have 1 record\", 1, mixedResult.size());\n-    Assert.assertArrayEquals(\"Should produce the expected records\", mixedResult.get(0), new Object[] {1, \"a\"});\n+    assertEquals(\"should have 1 record\", 1, mixedResult.size());\n+    assertArrayEquals(\"Should produce the expected records\", mixedResult.get(0), new Object[] {1, \"a\"});\n+  }\n+\n+  @Test\n+  public void testNoFilterPushDown() {\n+    String sql = String.format(\"SELECT * FROM %s \", TABLE_NAME);\n+    String explain = getTableEnv().explainSql(sql);\n+    assertFalse(\"explain should no contains FilterPushDown\", explain.contains(expectedFilterPushDownExplain));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownEqual() {\n+    String sqlLiteralRight = String.format(\"SELECT * FROM %s WHERE id = 1 \", TABLE_NAME);\n+    String explain = getTableEnv().explainSql(sqlLiteralRight);\n+    assertTrue(\"explain should contains FilterPushDown\", explain.contains(expectedFilterPushDownExplain));\n+\n+    List<Object[]> result = sql(sqlLiteralRight);\n+    assertEquals(\"should have 1 record\", 1, result.size());\n+    assertArrayEquals(\"Should produce the expected record\", result.get(0), new Object[] {1, \"a\"});\n+\n+    assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"Should push down expected filter\", \"id = 1\", FlinkUtil.describe(lastScanEvent.filter()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "f96e8a3e86dce66300a996b3e5ea76916e426816"}, "originalPosition": 121}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTYzMjgwNDA4", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-563280408", "createdAt": "2021-01-07T08:09:14Z", "commit": {"oid": "f96e8a3e86dce66300a996b3e5ea76916e426816"}, "state": "COMMENTED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "f96e8a3e86dce66300a996b3e5ea76916e426816", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/f96e8a3e86dce66300a996b3e5ea76916e426816", "committedDate": "2021-01-06T06:22:55Z", "message": "fix some issues"}, "afterCommit": {"oid": "246144b8b131fc0329205805a0c9840dc7d6495e", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/246144b8b131fc0329205805a0c9840dc7d6495e", "committedDate": "2021-01-08T02:41:46Z", "message": "fix  issues"}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "246144b8b131fc0329205805a0c9840dc7d6495e", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/246144b8b131fc0329205805a0c9840dc7d6495e", "committedDate": "2021-01-08T02:41:46Z", "message": "fix  issues"}, "afterCommit": {"oid": "c3b928c314f03a76a6e3c3448adab27dfa8c567f", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/c3b928c314f03a76a6e3c3448adab27dfa8c567f", "committedDate": "2021-01-08T03:34:09Z", "message": "fix  issues"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY0MzEwODI5", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-564310829", "createdAt": "2021-01-08T14:42:48Z", "commit": {"oid": "c3b928c314f03a76a6e3c3448adab27dfa8c567f"}, "state": "APPROVED", "comments": {"totalCount": 0, "pageInfo": {"startCursor": null, "endCursor": null, "hasNextPage": false, "hasPreviousPage": false}, "nodes": []}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY3Nzc4OTk4", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-567778998", "createdAt": "2021-01-14T01:04:19Z", "commit": {"oid": "c3b928c314f03a76a6e3c3448adab27dfa8c567f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQwMTowNDoxOVrOITLOVg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQwMTowNDoxOVrOITLOVg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Njk3Nzc1MA==", "bodyText": "I don't think that Expression needs to be fully-qualified.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r556977750", "createdAt": "2021-01-14T01:04:19Z", "author": {"login": "rdblue"}, "path": "api/src/main/java/org/apache/iceberg/expressions/ExpressionsUtil.java", "diffHunk": "@@ -0,0 +1,118 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.expressions;\n+\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+public class ExpressionsUtil {\n+  private ExpressionsUtil() {\n+  }\n+\n+  public static String describe(org.apache.iceberg.expressions.Expression expr) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3b928c314f03a76a6e3c3448adab27dfa8c567f"}, "originalPosition": 30}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY3Nzc5NzM2", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-567779736", "createdAt": "2021-01-14T01:06:17Z", "commit": {"oid": "c3b928c314f03a76a6e3c3448adab27dfa8c567f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQwMTowNjoxN1rOITLQrg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQwMTowNjoxN1rOITLQrg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Njk3ODM1MA==", "bodyText": "Nit: \"convert\" should be capitalized because it begins a sentence.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r556978350", "createdAt": "2021-01-14T01:06:17Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.function.Function;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.flink.table.functions.FunctionDefinition;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.DateTimeUtil;\n+import org.apache.iceberg.util.NaNUtil;\n+\n+public class FlinkFilters {\n+  private FlinkFilters() {\n+  }\n+\n+  private static final Pattern STARTS_WITH_PATTERN = Pattern.compile(\"([^%]+)%\");\n+\n+  private static final Map<FunctionDefinition, Operation> FILTERS = ImmutableMap\n+      .<FunctionDefinition, Operation>builder()\n+      .put(BuiltInFunctionDefinitions.EQUALS, Operation.EQ)\n+      .put(BuiltInFunctionDefinitions.NOT_EQUALS, Operation.NOT_EQ)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN, Operation.GT)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, Operation.GT_EQ)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN, Operation.LT)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, Operation.LT_EQ)\n+      .put(BuiltInFunctionDefinitions.IS_NULL, Operation.IS_NULL)\n+      .put(BuiltInFunctionDefinitions.IS_NOT_NULL, Operation.NOT_NULL)\n+      .put(BuiltInFunctionDefinitions.AND, Operation.AND)\n+      .put(BuiltInFunctionDefinitions.OR, Operation.OR)\n+      .put(BuiltInFunctionDefinitions.NOT, Operation.NOT)\n+      .put(BuiltInFunctionDefinitions.LIKE, Operation.STARTS_WITH)\n+      .build();\n+\n+  /**\n+   * convert flink expression to iceberg expression.", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3b928c314f03a76a6e3c3448adab27dfa8c567f"}, "originalPosition": 70}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY3NzgwMDU5", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-567780059", "createdAt": "2021-01-14T01:07:12Z", "commit": {"oid": "c3b928c314f03a76a6e3c3448adab27dfa8c567f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQwMTowNzoxMlrOITLRug==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQwMTowNzoxMlrOITLRug==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Njk3ODYxOA==", "bodyText": "Nits: missing a space in the list and the next sentence isn't capitalized.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r556978618", "createdAt": "2021-01-14T01:07:12Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.function.Function;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.flink.table.functions.FunctionDefinition;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.DateTimeUtil;\n+import org.apache.iceberg.util.NaNUtil;\n+\n+public class FlinkFilters {\n+  private FlinkFilters() {\n+  }\n+\n+  private static final Pattern STARTS_WITH_PATTERN = Pattern.compile(\"([^%]+)%\");\n+\n+  private static final Map<FunctionDefinition, Operation> FILTERS = ImmutableMap\n+      .<FunctionDefinition, Operation>builder()\n+      .put(BuiltInFunctionDefinitions.EQUALS, Operation.EQ)\n+      .put(BuiltInFunctionDefinitions.NOT_EQUALS, Operation.NOT_EQ)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN, Operation.GT)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, Operation.GT_EQ)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN, Operation.LT)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, Operation.LT_EQ)\n+      .put(BuiltInFunctionDefinitions.IS_NULL, Operation.IS_NULL)\n+      .put(BuiltInFunctionDefinitions.IS_NOT_NULL, Operation.NOT_NULL)\n+      .put(BuiltInFunctionDefinitions.AND, Operation.AND)\n+      .put(BuiltInFunctionDefinitions.OR, Operation.OR)\n+      .put(BuiltInFunctionDefinitions.NOT, Operation.NOT)\n+      .put(BuiltInFunctionDefinitions.LIKE, Operation.STARTS_WITH)\n+      .build();\n+\n+  /**\n+   * convert flink expression to iceberg expression.\n+   * <p>\n+   * The BETWEEN, NOT_BETWEEN,IN expression will be converted by flink automatically. the BETWEEN will be converted to", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3b928c314f03a76a6e3c3448adab27dfa8c567f"}, "originalPosition": 72}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY3Nzg1NjIy", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-567785622", "createdAt": "2021-01-14T01:22:08Z", "commit": {"oid": "c3b928c314f03a76a6e3c3448adab27dfa8c567f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQwMToyMjowOVrOITLkxw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQwMToyMjowOVrOITLkxw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Njk4MzQ5NQ==", "bodyText": "I don't think that this should pass null to toReference. It works because toReference does an instanceof check, but it isn't obvious that null is expected there.\nI think it would be better to use flatMap to run toReference if the FieldReferenceExpression is defined.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r556983495", "createdAt": "2021-01-14T01:22:09Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.function.Function;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.flink.table.functions.FunctionDefinition;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.DateTimeUtil;\n+import org.apache.iceberg.util.NaNUtil;\n+\n+public class FlinkFilters {\n+  private FlinkFilters() {\n+  }\n+\n+  private static final Pattern STARTS_WITH_PATTERN = Pattern.compile(\"([^%]+)%\");\n+\n+  private static final Map<FunctionDefinition, Operation> FILTERS = ImmutableMap\n+      .<FunctionDefinition, Operation>builder()\n+      .put(BuiltInFunctionDefinitions.EQUALS, Operation.EQ)\n+      .put(BuiltInFunctionDefinitions.NOT_EQUALS, Operation.NOT_EQ)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN, Operation.GT)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, Operation.GT_EQ)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN, Operation.LT)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, Operation.LT_EQ)\n+      .put(BuiltInFunctionDefinitions.IS_NULL, Operation.IS_NULL)\n+      .put(BuiltInFunctionDefinitions.IS_NOT_NULL, Operation.NOT_NULL)\n+      .put(BuiltInFunctionDefinitions.AND, Operation.AND)\n+      .put(BuiltInFunctionDefinitions.OR, Operation.OR)\n+      .put(BuiltInFunctionDefinitions.NOT, Operation.NOT)\n+      .put(BuiltInFunctionDefinitions.LIKE, Operation.STARTS_WITH)\n+      .build();\n+\n+  /**\n+   * convert flink expression to iceberg expression.\n+   * <p>\n+   * The BETWEEN, NOT_BETWEEN,IN expression will be converted by flink automatically. the BETWEEN will be converted to\n+   * (GT_EQ AND LT_EQ), the NOT_BETWEEN will be converted to (LT_EQ OR GT_EQ), the IN will be converted to OR, so we do\n+   * not add the conversion here\n+   *\n+   * @param flinkExpression the flink expression\n+   * @return the iceberg expression\n+   */\n+  public static Optional<Expression> convert(org.apache.flink.table.expressions.Expression flinkExpression) {\n+    if (!(flinkExpression instanceof CallExpression)) {\n+      return Optional.empty();\n+    }\n+\n+    CallExpression call = (CallExpression) flinkExpression;\n+    Operation op = FILTERS.get(call.getFunctionDefinition());\n+    if (op != null) {\n+      switch (op) {\n+        case IS_NULL:\n+          Optional<String> name = toReference(singleton(call, FieldReferenceExpression.class).orElse(null));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3b928c314f03a76a6e3c3448adab27dfa8c567f"}, "originalPosition": 89}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY3Nzg3NDI5", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-567787429", "createdAt": "2021-01-14T01:27:26Z", "commit": {"oid": "c3b928c314f03a76a6e3c3448adab27dfa8c567f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQwMToyNzoyN1rOITLrMg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQwMToyNzoyN1rOITLrMg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Njk4NTEzOA==", "bodyText": "I don't think that this method name is enough to see what's going on from reading it. How about a name like childAs or onlyChildAs? That makes it clear that the call's child will be returned and that there should be only one.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r556985138", "createdAt": "2021-01-14T01:27:27Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.function.Function;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.flink.table.functions.FunctionDefinition;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.DateTimeUtil;\n+import org.apache.iceberg.util.NaNUtil;\n+\n+public class FlinkFilters {\n+  private FlinkFilters() {\n+  }\n+\n+  private static final Pattern STARTS_WITH_PATTERN = Pattern.compile(\"([^%]+)%\");\n+\n+  private static final Map<FunctionDefinition, Operation> FILTERS = ImmutableMap\n+      .<FunctionDefinition, Operation>builder()\n+      .put(BuiltInFunctionDefinitions.EQUALS, Operation.EQ)\n+      .put(BuiltInFunctionDefinitions.NOT_EQUALS, Operation.NOT_EQ)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN, Operation.GT)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, Operation.GT_EQ)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN, Operation.LT)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, Operation.LT_EQ)\n+      .put(BuiltInFunctionDefinitions.IS_NULL, Operation.IS_NULL)\n+      .put(BuiltInFunctionDefinitions.IS_NOT_NULL, Operation.NOT_NULL)\n+      .put(BuiltInFunctionDefinitions.AND, Operation.AND)\n+      .put(BuiltInFunctionDefinitions.OR, Operation.OR)\n+      .put(BuiltInFunctionDefinitions.NOT, Operation.NOT)\n+      .put(BuiltInFunctionDefinitions.LIKE, Operation.STARTS_WITH)\n+      .build();\n+\n+  /**\n+   * convert flink expression to iceberg expression.\n+   * <p>\n+   * The BETWEEN, NOT_BETWEEN,IN expression will be converted by flink automatically. the BETWEEN will be converted to\n+   * (GT_EQ AND LT_EQ), the NOT_BETWEEN will be converted to (LT_EQ OR GT_EQ), the IN will be converted to OR, so we do\n+   * not add the conversion here\n+   *\n+   * @param flinkExpression the flink expression\n+   * @return the iceberg expression\n+   */\n+  public static Optional<Expression> convert(org.apache.flink.table.expressions.Expression flinkExpression) {\n+    if (!(flinkExpression instanceof CallExpression)) {\n+      return Optional.empty();\n+    }\n+\n+    CallExpression call = (CallExpression) flinkExpression;\n+    Operation op = FILTERS.get(call.getFunctionDefinition());\n+    if (op != null) {\n+      switch (op) {\n+        case IS_NULL:\n+          Optional<String> name = toReference(singleton(call, FieldReferenceExpression.class).orElse(null));\n+          return name.map(Expressions::isNull);\n+\n+        case NOT_NULL:\n+          Optional<String> nameNotNull = toReference(singleton(call, FieldReferenceExpression.class).orElse(null));\n+          return nameNotNull.map(Expressions::notNull);\n+\n+        case LT:\n+          return convertComparisonExpression(Expressions::lessThan, Expressions::greaterThan, call);\n+\n+        case LT_EQ:\n+          return convertComparisonExpression(Expressions::lessThanOrEqual, Expressions::greaterThanOrEqual, call);\n+\n+        case GT:\n+          return convertComparisonExpression(Expressions::greaterThan, Expressions::lessThan, call);\n+\n+        case GT_EQ:\n+          return convertComparisonExpression(Expressions::greaterThanOrEqual, Expressions::lessThanOrEqual, call);\n+\n+        case EQ:\n+          return handleNaN(Expressions::equal, Expressions::isNaN, call);\n+\n+        case NOT_EQ:\n+          return handleNaN(Expressions::notEqual, Expressions::notNaN, call);\n+\n+        case NOT:\n+          Optional<Expression> child = convert(singleton(call, CallExpression.class).orElse(null));\n+          return child.map(Expressions::not);\n+\n+        case AND:\n+          return convertLogicExpression(Expressions::and, call);\n+\n+        case OR:\n+          return convertLogicExpression(Expressions::or, call);\n+\n+        case STARTS_WITH:\n+          return convertLike(call);\n+      }\n+    }\n+\n+    return Optional.empty();\n+  }\n+\n+  private static <T extends ResolvedExpression> Optional<T> singleton(CallExpression call,", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3b928c314f03a76a6e3c3448adab27dfa8c567f"}, "originalPosition": 132}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY3Nzg4MDg4", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-567788088", "createdAt": "2021-01-14T01:29:09Z", "commit": {"oid": "c3b928c314f03a76a6e3c3448adab27dfa8c567f"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQwMToyOTowOVrOITLtwg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQwMToyOTowOVrOITLtwg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Njk4NTc5NA==", "bodyText": "If this is going to access children from this list directly using get(1) then it should also check that there are exactly 2 children.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r556985794", "createdAt": "2021-01-14T01:29:09Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.function.Function;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.flink.table.functions.FunctionDefinition;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.DateTimeUtil;\n+import org.apache.iceberg.util.NaNUtil;\n+\n+public class FlinkFilters {\n+  private FlinkFilters() {\n+  }\n+\n+  private static final Pattern STARTS_WITH_PATTERN = Pattern.compile(\"([^%]+)%\");\n+\n+  private static final Map<FunctionDefinition, Operation> FILTERS = ImmutableMap\n+      .<FunctionDefinition, Operation>builder()\n+      .put(BuiltInFunctionDefinitions.EQUALS, Operation.EQ)\n+      .put(BuiltInFunctionDefinitions.NOT_EQUALS, Operation.NOT_EQ)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN, Operation.GT)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, Operation.GT_EQ)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN, Operation.LT)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, Operation.LT_EQ)\n+      .put(BuiltInFunctionDefinitions.IS_NULL, Operation.IS_NULL)\n+      .put(BuiltInFunctionDefinitions.IS_NOT_NULL, Operation.NOT_NULL)\n+      .put(BuiltInFunctionDefinitions.AND, Operation.AND)\n+      .put(BuiltInFunctionDefinitions.OR, Operation.OR)\n+      .put(BuiltInFunctionDefinitions.NOT, Operation.NOT)\n+      .put(BuiltInFunctionDefinitions.LIKE, Operation.STARTS_WITH)\n+      .build();\n+\n+  /**\n+   * convert flink expression to iceberg expression.\n+   * <p>\n+   * The BETWEEN, NOT_BETWEEN,IN expression will be converted by flink automatically. the BETWEEN will be converted to\n+   * (GT_EQ AND LT_EQ), the NOT_BETWEEN will be converted to (LT_EQ OR GT_EQ), the IN will be converted to OR, so we do\n+   * not add the conversion here\n+   *\n+   * @param flinkExpression the flink expression\n+   * @return the iceberg expression\n+   */\n+  public static Optional<Expression> convert(org.apache.flink.table.expressions.Expression flinkExpression) {\n+    if (!(flinkExpression instanceof CallExpression)) {\n+      return Optional.empty();\n+    }\n+\n+    CallExpression call = (CallExpression) flinkExpression;\n+    Operation op = FILTERS.get(call.getFunctionDefinition());\n+    if (op != null) {\n+      switch (op) {\n+        case IS_NULL:\n+          Optional<String> name = toReference(singleton(call, FieldReferenceExpression.class).orElse(null));\n+          return name.map(Expressions::isNull);\n+\n+        case NOT_NULL:\n+          Optional<String> nameNotNull = toReference(singleton(call, FieldReferenceExpression.class).orElse(null));\n+          return nameNotNull.map(Expressions::notNull);\n+\n+        case LT:\n+          return convertComparisonExpression(Expressions::lessThan, Expressions::greaterThan, call);\n+\n+        case LT_EQ:\n+          return convertComparisonExpression(Expressions::lessThanOrEqual, Expressions::greaterThanOrEqual, call);\n+\n+        case GT:\n+          return convertComparisonExpression(Expressions::greaterThan, Expressions::lessThan, call);\n+\n+        case GT_EQ:\n+          return convertComparisonExpression(Expressions::greaterThanOrEqual, Expressions::lessThanOrEqual, call);\n+\n+        case EQ:\n+          return handleNaN(Expressions::equal, Expressions::isNaN, call);\n+\n+        case NOT_EQ:\n+          return handleNaN(Expressions::notEqual, Expressions::notNaN, call);\n+\n+        case NOT:\n+          Optional<Expression> child = convert(singleton(call, CallExpression.class).orElse(null));\n+          return child.map(Expressions::not);\n+\n+        case AND:\n+          return convertLogicExpression(Expressions::and, call);\n+\n+        case OR:\n+          return convertLogicExpression(Expressions::or, call);\n+\n+        case STARTS_WITH:\n+          return convertLike(call);\n+      }\n+    }\n+\n+    return Optional.empty();\n+  }\n+\n+  private static <T extends ResolvedExpression> Optional<T> singleton(CallExpression call,\n+                                                                      Class<T> expectedChildClass) {\n+    List<ResolvedExpression> children = call.getResolvedChildren();\n+    if (children.size() != 1) {\n+      return Optional.empty();\n+    }\n+\n+    ResolvedExpression child = children.get(0);\n+    if (!expectedChildClass.isInstance(child)) {\n+      return Optional.empty();\n+    }\n+\n+    return Optional.of(expectedChildClass.cast(child));\n+  }\n+\n+  private static Optional<Expression> convertLike(CallExpression call) {\n+    Tuple2<String, Object> tuple2 = parseFieldAndLiteral(call);\n+    if (tuple2 == null) {\n+      return Optional.empty();\n+    }\n+\n+    String pattern = tuple2.f1.toString();\n+    Matcher matcher = STARTS_WITH_PATTERN.matcher(pattern);\n+\n+    // exclude special char of LIKE\n+    // '_' is the wildcard of the SQL LIKE\n+    if (!pattern.contains(\"_\") && matcher.matches()) {\n+      return Optional.of(Expressions.startsWith(tuple2.f0, matcher.group(1)));\n+    }\n+\n+    return Optional.empty();\n+  }\n+\n+  private static Optional<Expression> convertLogicExpression(BiFunction<Expression, Expression, Expression> function,\n+                                                             CallExpression call) {\n+    List<ResolvedExpression> args = call.getResolvedChildren();", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "c3b928c314f03a76a6e3c3448adab27dfa8c567f"}, "originalPosition": 167}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY3Nzk1MTYw", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-567795160", "createdAt": "2021-01-14T01:49:27Z", "commit": {"oid": "0331d4923f15d6af157d27aa704cd2c3d9c5596c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQwMTo0OToyN1rOITMHHg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQwMTo0OToyN1rOITMHHg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1Njk5MjI4Ng==", "bodyText": "Similar to above, this shouldn't use orElse(null):\n          return onlyChildAs(call, CallExpression.class).flatMap(FlinkFilters::convert).map(Expressions::not);", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r556992286", "createdAt": "2021-01-14T01:49:27Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.function.Function;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.flink.table.functions.FunctionDefinition;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.DateTimeUtil;\n+import org.apache.iceberg.util.NaNUtil;\n+\n+public class FlinkFilters {\n+  private FlinkFilters() {\n+  }\n+\n+  private static final Pattern STARTS_WITH_PATTERN = Pattern.compile(\"([^%]+)%\");\n+\n+  private static final Map<FunctionDefinition, Operation> FILTERS = ImmutableMap\n+      .<FunctionDefinition, Operation>builder()\n+      .put(BuiltInFunctionDefinitions.EQUALS, Operation.EQ)\n+      .put(BuiltInFunctionDefinitions.NOT_EQUALS, Operation.NOT_EQ)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN, Operation.GT)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, Operation.GT_EQ)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN, Operation.LT)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, Operation.LT_EQ)\n+      .put(BuiltInFunctionDefinitions.IS_NULL, Operation.IS_NULL)\n+      .put(BuiltInFunctionDefinitions.IS_NOT_NULL, Operation.NOT_NULL)\n+      .put(BuiltInFunctionDefinitions.AND, Operation.AND)\n+      .put(BuiltInFunctionDefinitions.OR, Operation.OR)\n+      .put(BuiltInFunctionDefinitions.NOT, Operation.NOT)\n+      .put(BuiltInFunctionDefinitions.LIKE, Operation.STARTS_WITH)\n+      .build();\n+\n+  /**\n+   * Convert flink expression to iceberg expression.\n+   * <p>\n+   * the BETWEEN, NOT_BETWEEN, IN expression will be converted by flink automatically. the BETWEEN will be converted to\n+   * (GT_EQ AND LT_EQ), the NOT_BETWEEN will be converted to (LT_EQ OR GT_EQ), the IN will be converted to OR, so we do\n+   * not add the conversion here\n+   *\n+   * @param flinkExpression the flink expression\n+   * @return the iceberg expression\n+   */\n+  public static Optional<Expression> convert(org.apache.flink.table.expressions.Expression flinkExpression) {\n+    if (!(flinkExpression instanceof CallExpression)) {\n+      return Optional.empty();\n+    }\n+\n+    CallExpression call = (CallExpression) flinkExpression;\n+    Operation op = FILTERS.get(call.getFunctionDefinition());\n+    if (op != null) {\n+      switch (op) {\n+        case IS_NULL:\n+          Optional<String> name = toReference(singleton(call, FieldReferenceExpression.class).orElse(null));\n+          return name.map(Expressions::isNull);\n+\n+        case NOT_NULL:\n+          Optional<String> nameNotNull = toReference(singleton(call, FieldReferenceExpression.class).orElse(null));\n+          return nameNotNull.map(Expressions::notNull);\n+\n+        case LT:\n+          return convertComparisonExpression(Expressions::lessThan, Expressions::greaterThan, call);\n+\n+        case LT_EQ:\n+          return convertComparisonExpression(Expressions::lessThanOrEqual, Expressions::greaterThanOrEqual, call);\n+\n+        case GT:\n+          return convertComparisonExpression(Expressions::greaterThan, Expressions::lessThan, call);\n+\n+        case GT_EQ:\n+          return convertComparisonExpression(Expressions::greaterThanOrEqual, Expressions::lessThanOrEqual, call);\n+\n+        case EQ:\n+          return handleNaN(Expressions::equal, Expressions::isNaN, call);\n+\n+        case NOT_EQ:\n+          return handleNaN(Expressions::notEqual, Expressions::notNaN, call);\n+\n+        case NOT:\n+          Optional<Expression> child = convert(singleton(call, CallExpression.class).orElse(null));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0331d4923f15d6af157d27aa704cd2c3d9c5596c"}, "originalPosition": 115}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY3ODAzNzc2", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-567803776", "createdAt": "2021-01-14T02:15:36Z", "commit": {"oid": "0331d4923f15d6af157d27aa704cd2c3d9c5596c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQwMjoxNTozNlrOITMmFA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQwMjoxNTozNlrOITMmFA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzAwMDIxMg==", "bodyText": "I think that this class can be cleaned up by rewriting this method. I think this was intended to make reuse easier, but rewriting this allows removing several methods (literalOnRight, convertComparisonExpression, handleNaN, toReference, and toLiteral), gets rid of the strange method contract where Tuple2 and null are used, and also ensures that instanceof checks are done in just one place, rather than with multiple calls to literalOnRight.\nHere's what I rewrote it to:\n  private static Optional<Expression> convertFieldAndLiteral(BiFunction<String, Object, Expression> expr,\n                                                             CallExpression call) {\n    return convertFieldAndLiteral(expr, expr, call);\n  }\n\n  private static Optional<Expression> convertFieldAndLiteral(\n      BiFunction<String, Object, Expression> convertLR, BiFunction<String, Object, Expression> convertRL,\n      CallExpression call) {\n    List<ResolvedExpression> args = call.getResolvedChildren();\n    if (args.size() != 2) {\n      return Optional.empty();\n    }\n\n    org.apache.flink.table.expressions.Expression left = args.get(0);\n    org.apache.flink.table.expressions.Expression right = args.get(1);\n\n    if (left instanceof FieldReferenceExpression && right instanceof ValueLiteralExpression) {\n      String name = ((FieldReferenceExpression) left).getName();\n      Object lit = convertLiteral((ValueLiteralExpression) right);\n      return Optional.of(convertLR.apply(name, lit));\n\n    } else if (left instanceof ValueLiteralExpression && right instanceof FieldReferenceExpression) {\n      Object lit = convertLiteral((ValueLiteralExpression) left);\n      String name = ((FieldReferenceExpression) right).getName();\n      return Optional.of(convertRL.apply(name, lit));\n    }\n\n    return Optional.empty();\n  }\nThe comparison cases in the switch statement can then call this directly:\n      switch (op) {\n        case LT:\n          return convertFieldAndLiteral(Expressions::lessThan, Expressions::greaterThan, call);\n\n        case LT_EQ:\n          return convertFieldAndLiteral(Expressions::lessThanOrEqual, Expressions::greaterThanOrEqual, call);\n\n        case GT:\n          return convertFieldAndLiteral(Expressions::greaterThan, Expressions::lessThan, call);\n\n        case GT_EQ:\n          return convertFieldAndLiteral(Expressions::greaterThanOrEqual, Expressions::lessThanOrEqual, call);\n\n        case EQ:\n          return convertFieldAndLiteral((ref, lit) -> {\n            if (NaNUtil.isNaN(lit)) {\n              return Expressions.isNaN(ref);\n            } else {\n              return Expressions.equal(ref, lit);\n            }\n          }, call);\n\n        case NOT_EQ:\n          return convertFieldAndLiteral((ref, lit) -> {\n            if (NaNUtil.isNaN(lit)) {\n              return Expressions.notNaN(ref);\n            } else {\n              return Expressions.notEqual(ref, lit);\n            }\n          }, call);\nThe only problem is that convertLike can't call this. But that's okay because I don't think the reversed form of LIKE is actually supported anyway (\"a%\" LIKE col is not allowed, right?).\nSo I also rewrote convertLike:\n  private static Optional<Expression> convertLike(CallExpression call) {\n    List<ResolvedExpression> args = call.getResolvedChildren();\n    if (args.size() != 2) {\n      return Optional.empty();\n    }\n\n    org.apache.flink.table.expressions.Expression left = args.get(0);\n    org.apache.flink.table.expressions.Expression right = args.get(1);\n\n    if (left instanceof FieldReferenceExpression && right instanceof ValueLiteralExpression) {\n      String name = ((FieldReferenceExpression) left).getName();\n      return convertLiteral((ValueLiteralExpression) right).flatMap(lit -> {\n        if (lit instanceof String) {\n          String pattern = (String) lit;\n          Matcher matcher = STARTS_WITH_PATTERN.matcher(pattern);\n          // exclude special char of LIKE\n          // '_' is the wildcard of the SQL LIKE\n          if (!pattern.contains(\"_\") && matcher.matches()) {\n            return Optional.of(Expressions.startsWith(name, matcher.group(1)));\n          }\n        }\n\n        return Optional.empty();\n      });\n    }\n\n    return Optional.empty();\n  }", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r557000212", "createdAt": "2021-01-14T02:15:36Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,266 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.function.Function;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.flink.table.functions.FunctionDefinition;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.DateTimeUtil;\n+import org.apache.iceberg.util.NaNUtil;\n+\n+public class FlinkFilters {\n+  private FlinkFilters() {\n+  }\n+\n+  private static final Pattern STARTS_WITH_PATTERN = Pattern.compile(\"([^%]+)%\");\n+\n+  private static final Map<FunctionDefinition, Operation> FILTERS = ImmutableMap\n+      .<FunctionDefinition, Operation>builder()\n+      .put(BuiltInFunctionDefinitions.EQUALS, Operation.EQ)\n+      .put(BuiltInFunctionDefinitions.NOT_EQUALS, Operation.NOT_EQ)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN, Operation.GT)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, Operation.GT_EQ)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN, Operation.LT)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, Operation.LT_EQ)\n+      .put(BuiltInFunctionDefinitions.IS_NULL, Operation.IS_NULL)\n+      .put(BuiltInFunctionDefinitions.IS_NOT_NULL, Operation.NOT_NULL)\n+      .put(BuiltInFunctionDefinitions.AND, Operation.AND)\n+      .put(BuiltInFunctionDefinitions.OR, Operation.OR)\n+      .put(BuiltInFunctionDefinitions.NOT, Operation.NOT)\n+      .put(BuiltInFunctionDefinitions.LIKE, Operation.STARTS_WITH)\n+      .build();\n+\n+  /**\n+   * Convert flink expression to iceberg expression.\n+   * <p>\n+   * the BETWEEN, NOT_BETWEEN, IN expression will be converted by flink automatically. the BETWEEN will be converted to\n+   * (GT_EQ AND LT_EQ), the NOT_BETWEEN will be converted to (LT_EQ OR GT_EQ), the IN will be converted to OR, so we do\n+   * not add the conversion here\n+   *\n+   * @param flinkExpression the flink expression\n+   * @return the iceberg expression\n+   */\n+  public static Optional<Expression> convert(org.apache.flink.table.expressions.Expression flinkExpression) {\n+    if (!(flinkExpression instanceof CallExpression)) {\n+      return Optional.empty();\n+    }\n+\n+    CallExpression call = (CallExpression) flinkExpression;\n+    Operation op = FILTERS.get(call.getFunctionDefinition());\n+    if (op != null) {\n+      switch (op) {\n+        case IS_NULL:\n+          Optional<String> name = toReference(singleton(call, FieldReferenceExpression.class).orElse(null));\n+          return name.map(Expressions::isNull);\n+\n+        case NOT_NULL:\n+          Optional<String> nameNotNull = toReference(singleton(call, FieldReferenceExpression.class).orElse(null));\n+          return nameNotNull.map(Expressions::notNull);\n+\n+        case LT:\n+          return convertComparisonExpression(Expressions::lessThan, Expressions::greaterThan, call);\n+\n+        case LT_EQ:\n+          return convertComparisonExpression(Expressions::lessThanOrEqual, Expressions::greaterThanOrEqual, call);\n+\n+        case GT:\n+          return convertComparisonExpression(Expressions::greaterThan, Expressions::lessThan, call);\n+\n+        case GT_EQ:\n+          return convertComparisonExpression(Expressions::greaterThanOrEqual, Expressions::lessThanOrEqual, call);\n+\n+        case EQ:\n+          return handleNaN(Expressions::equal, Expressions::isNaN, call);\n+\n+        case NOT_EQ:\n+          return handleNaN(Expressions::notEqual, Expressions::notNaN, call);\n+\n+        case NOT:\n+          Optional<Expression> child = convert(singleton(call, CallExpression.class).orElse(null));\n+          return child.map(Expressions::not);\n+\n+        case AND:\n+          return convertLogicExpression(Expressions::and, call);\n+\n+        case OR:\n+          return convertLogicExpression(Expressions::or, call);\n+\n+        case STARTS_WITH:\n+          return convertLike(call);\n+      }\n+    }\n+\n+    return Optional.empty();\n+  }\n+\n+  private static <T extends ResolvedExpression> Optional<T> singleton(CallExpression call,\n+                                                                      Class<T> expectedChildClass) {\n+    List<ResolvedExpression> children = call.getResolvedChildren();\n+    if (children.size() != 1) {\n+      return Optional.empty();\n+    }\n+\n+    ResolvedExpression child = children.get(0);\n+    if (!expectedChildClass.isInstance(child)) {\n+      return Optional.empty();\n+    }\n+\n+    return Optional.of(expectedChildClass.cast(child));\n+  }\n+\n+  private static Optional<Expression> convertLike(CallExpression call) {\n+    Tuple2<String, Object> tuple2 = parseFieldAndLiteral(call);\n+    if (tuple2 == null) {\n+      return Optional.empty();\n+    }\n+\n+    String pattern = tuple2.f1.toString();\n+    Matcher matcher = STARTS_WITH_PATTERN.matcher(pattern);\n+\n+    // exclude special char of LIKE\n+    // '_' is the wildcard of the SQL LIKE\n+    if (!pattern.contains(\"_\") && matcher.matches()) {\n+      return Optional.of(Expressions.startsWith(tuple2.f0, matcher.group(1)));\n+    }\n+\n+    return Optional.empty();\n+  }\n+\n+  private static Optional<Expression> convertLogicExpression(BiFunction<Expression, Expression, Expression> function,\n+                                                             CallExpression call) {\n+    List<ResolvedExpression> args = call.getResolvedChildren();\n+    Optional<Expression> left = convert(args.get(0));\n+    Optional<Expression> right = convert(args.get(1));\n+    if (left.isPresent() && right.isPresent()) {\n+      return Optional.of(function.apply(left.get(), right.get()));\n+    }\n+\n+    return Optional.empty();\n+  }\n+\n+  private static Optional<Expression> convertComparisonExpression(\n+      BiFunction<String, Object, Expression> function, BiFunction<String, Object, Expression> reversedFunction,\n+      CallExpression call) {\n+    Tuple2<String, Object> tuple2 = parseFieldAndLiteral(call);\n+    if (tuple2 != null) {\n+      if (literalOnRight(call.getResolvedChildren())) {\n+        return Optional.of(function.apply(tuple2.f0, tuple2.f1));\n+      } else {\n+        return Optional.of(reversedFunction.apply(tuple2.f0, tuple2.f1));\n+      }\n+    } else {\n+      return Optional.empty();\n+    }\n+  }\n+\n+  private static Optional<String> toReference(org.apache.flink.table.expressions.Expression expression) {\n+    return expression instanceof FieldReferenceExpression ?\n+        Optional.of(((FieldReferenceExpression) expression).getName()) :\n+        Optional.empty();\n+  }\n+\n+  private static Optional<Object> toLiteral(org.apache.flink.table.expressions.Expression expression) {\n+    // Not support null literal\n+    return expression instanceof ValueLiteralExpression ?\n+        convertLiteral((ValueLiteralExpression) expression) :\n+        Optional.empty();\n+  }\n+\n+  private static Optional<Expression> handleNaN(BiFunction<String, Object, Expression> function,\n+                                                Function<String, Expression> functionNaN,\n+                                                CallExpression call) {\n+    Tuple2<String, Object> tuple2 = parseFieldAndLiteral(call);\n+    if (tuple2 == null) {\n+      return Optional.empty();\n+    }\n+\n+    String name = tuple2.f0;\n+    Object value = tuple2.f1;\n+\n+    if (NaNUtil.isNaN(value)) {\n+      return Optional.of(functionNaN.apply(name));\n+    } else {\n+      return Optional.of(function.apply(name, value));\n+    }\n+  }\n+\n+  private static Optional<Object> convertLiteral(ValueLiteralExpression expression) {\n+    Optional<?> value = expression.getValueAs(expression.getOutputDataType().getLogicalType().getDefaultConversion());\n+    return value.map(o -> {\n+      if (o instanceof LocalDateTime) {\n+        return DateTimeUtil.microsFromTimestamp((LocalDateTime) o);\n+      } else if (o instanceof Instant) {\n+        return DateTimeUtil.microsFromInstant((Instant) o);\n+      } else if (o instanceof LocalTime) {\n+        return DateTimeUtil.microsFromTime((LocalTime) o);\n+      } else if (o instanceof LocalDate) {\n+        return DateTimeUtil.daysFromDate((LocalDate) o);\n+      }\n+\n+      return o;\n+    });\n+  }\n+\n+  private static boolean literalOnRight(List<ResolvedExpression> args) {\n+    return args.get(0) instanceof FieldReferenceExpression && args.get(1) instanceof ValueLiteralExpression;\n+  }\n+\n+  private static Tuple2<String, Object> parseFieldAndLiteral(CallExpression call) {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0331d4923f15d6af157d27aa704cd2c3d9c5596c"}, "originalPosition": 244}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY3ODA0ODEx", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-567804811", "createdAt": "2021-01-14T02:18:33Z", "commit": {"oid": "0331d4923f15d6af157d27aa704cd2c3d9c5596c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQwMjoxODozNFrOITMqTw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQwMjoxODozNFrOITMqTw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzAwMTI5NQ==", "bodyText": "Expressions should not be plural. It should be ExpressionUtil instead.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r557001295", "createdAt": "2021-01-14T02:18:34Z", "author": {"login": "rdblue"}, "path": "api/src/main/java/org/apache/iceberg/expressions/ExpressionsUtil.java", "diffHunk": "@@ -0,0 +1,124 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.expressions;\n+\n+import java.nio.ByteBuffer;\n+import java.util.List;\n+import java.util.stream.Collectors;\n+\n+public class ExpressionsUtil {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0331d4923f15d6af157d27aa704cd2c3d9c5596c"}, "originalPosition": 26}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY3ODIxMjc2", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-567821276", "createdAt": "2021-01-14T03:10:15Z", "commit": {"oid": "0331d4923f15d6af157d27aa704cd2c3d9c5596c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQwMzoxMDoxNlrOITNj1A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQwMzoxMDoxNlrOITNj1A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzAxNjAyMA==", "bodyText": "Please remove these imports. The project's style is to use Assert.assertEquals and not import static methods in general. This also caused a lot of unnecessary changes.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r557016020", "createdAt": "2021-01-14T03:10:16Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkTableSource.java", "diffHunk": "@@ -19,26 +19,36 @@\n \n package org.apache.iceberg.flink;\n \n-\n import java.util.List;\n import org.apache.flink.table.api.SqlParserException;\n import org.apache.iceberg.AssertHelpers;\n import org.apache.iceberg.FileFormat;\n import org.apache.iceberg.catalog.Namespace;\n+import org.apache.iceberg.events.Listeners;\n+import org.apache.iceberg.events.ScanEvent;\n+import org.apache.iceberg.expressions.ExpressionsUtil;\n import org.apache.iceberg.relocated.com.google.common.collect.Lists;\n import org.junit.After;\n-import org.junit.Assert;\n import org.junit.Before;\n import org.junit.Test;\n import org.junit.runner.RunWith;\n import org.junit.runners.Parameterized;\n \n+import static org.junit.Assert.assertArrayEquals;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertFalse;\n+import static org.junit.Assert.assertTrue;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0331d4923f15d6af157d27aa704cd2c3d9c5596c"}, "originalPosition": 24}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY3ODIxMzMw", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-567821330", "createdAt": "2021-01-14T03:10:25Z", "commit": {"oid": "0331d4923f15d6af157d27aa704cd2c3d9c5596c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQwMzoxMDoyNVrOITNj-g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQwMzoxMDoyNVrOITNj-g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzAxNjA1OA==", "bodyText": "I don't think this line needed to change.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r557016058", "createdAt": "2021-01-14T03:10:25Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkTableSource.java", "diffHunk": "@@ -75,32 +95,436 @@ public void clean() {\n \n   @Test\n   public void testLimitPushDown() {\n-    sql(\"INSERT INTO %s  VALUES (1,'a'),(2,'b')\", TABLE_NAME);\n-\n     String querySql = String.format(\"SELECT * FROM %s LIMIT 1\", TABLE_NAME);\n     String explain = getTableEnv().explainSql(querySql);\n     String expectedExplain = \"LimitPushDown : 1\";\n-    Assert.assertTrue(\"explain should contains LimitPushDown\", explain.contains(expectedExplain));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0331d4923f15d6af157d27aa704cd2c3d9c5596c"}, "originalPosition": 72}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY3ODIyMzg2", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-567822386", "createdAt": "2021-01-14T03:13:27Z", "commit": {"oid": "0331d4923f15d6af157d27aa704cd2c3d9c5596c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQwMzoxMzoyOFrOITNnNw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQwMzoxMzoyOFrOITNnNw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzAxNjg4Nw==", "bodyText": "It looks like describe was moved just for tests. I don't think that was needed. If you need to produce a string from an expression, why not just use toString? That's what other assertions use, like the one for explainExpected above.\nCan you try reverting the describe change?", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r557016887", "createdAt": "2021-01-14T03:13:28Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkTableSource.java", "diffHunk": "@@ -75,32 +95,436 @@ public void clean() {\n \n   @Test\n   public void testLimitPushDown() {\n-    sql(\"INSERT INTO %s  VALUES (1,'a'),(2,'b')\", TABLE_NAME);\n-\n     String querySql = String.format(\"SELECT * FROM %s LIMIT 1\", TABLE_NAME);\n     String explain = getTableEnv().explainSql(querySql);\n     String expectedExplain = \"LimitPushDown : 1\";\n-    Assert.assertTrue(\"explain should contains LimitPushDown\", explain.contains(expectedExplain));\n+    assertTrue(\"explain should contains LimitPushDown\", explain.contains(expectedExplain));\n     List<Object[]> result = sql(querySql);\n-    Assert.assertEquals(\"should have 1 record\", 1, result.size());\n-    Assert.assertArrayEquals(\"Should produce the expected records\", result.get(0), new Object[] {1, \"a\"});\n+    assertEquals(\"should have 1 record\", 1, result.size());\n+    assertArrayEquals(\"Should produce the expected records\", result.get(0), new Object[] {1, \"a\"});\n \n     AssertHelpers.assertThrows(\"Invalid limit number: -1 \", SqlParserException.class,\n         () -> sql(\"SELECT * FROM %s LIMIT -1\", TABLE_NAME));\n \n-    Assert.assertEquals(\"should have 0 record\", 0, sql(\"SELECT * FROM %s LIMIT 0\", TABLE_NAME).size());\n+    assertEquals(\"should have 0 record\", 0, sql(\"SELECT * FROM %s LIMIT 0\", TABLE_NAME).size());\n \n-    String sqlLimitExceed = String.format(\"SELECT * FROM %s LIMIT 3\", TABLE_NAME);\n+    String sqlLimitExceed = String.format(\"SELECT * FROM %s LIMIT 4\", TABLE_NAME);\n     List<Object[]> resultExceed = sql(sqlLimitExceed);\n-    Assert.assertEquals(\"should have 2 record\", 2, resultExceed.size());\n+    assertEquals(\"should have 3 record\", 3, resultExceed.size());\n     List<Object[]> expectedList = Lists.newArrayList();\n     expectedList.add(new Object[] {1, \"a\"});\n     expectedList.add(new Object[] {2, \"b\"});\n-    Assert.assertArrayEquals(\"Should produce the expected records\", resultExceed.toArray(), expectedList.toArray());\n+    expectedList.add(new Object[] {3, null});\n+    assertArrayEquals(\"Should produce the expected records\", resultExceed.toArray(), expectedList.toArray());\n \n     String sqlMixed = String.format(\"SELECT * FROM %s WHERE id = 1 LIMIT 2\", TABLE_NAME);\n     List<Object[]> mixedResult = sql(sqlMixed);\n-    Assert.assertEquals(\"should have 1 record\", 1, mixedResult.size());\n-    Assert.assertArrayEquals(\"Should produce the expected records\", mixedResult.get(0), new Object[] {1, \"a\"});\n+    assertEquals(\"should have 1 record\", 1, mixedResult.size());\n+    assertArrayEquals(\"Should produce the expected records\", mixedResult.get(0), new Object[] {1, \"a\"});\n+  }\n+\n+  @Test\n+  public void testNoFilterPushDown() {\n+    String sql = String.format(\"SELECT * FROM %s \", TABLE_NAME);\n+    String explain = getTableEnv().explainSql(sql);\n+    assertFalse(\"explain should no contains FilterPushDown\", explain.contains(expectedFilterPushDownExplain));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownEqual() {\n+    String sqlLiteralRight = String.format(\"SELECT * FROM %s WHERE id = 1 \", TABLE_NAME);\n+    String explain = getTableEnv().explainSql(sqlLiteralRight);\n+    String explainExpected = \"FilterPushDown,the filters :ref(name=\\\"id\\\") == 1]]], fields=[id, data])\";\n+    assertTrue(\"explain should contains FilterPushDown\", explain.contains(explainExpected));\n+\n+    List<Object[]> result = sql(sqlLiteralRight);\n+    assertEquals(\"should have 1 record\", 1, result.size());\n+    assertArrayEquals(\"Should produce the expected record\", result.get(0), new Object[] {1, \"a\"});\n+\n+    assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    assertEquals(\"Should push down expected filter\", \"id = 1\", ExpressionsUtil.describe(lastScanEvent.filter()));\n+\n+    // filter not push down\n+    String sqlEqualNull = String.format(\"SELECT * FROM %s WHERE data = NULL \", TABLE_NAME);\n+    String explainEqualNull = getTableEnv().explainSql(sqlEqualNull);\n+    assertFalse(\"explain should not contains FilterPushDown\", explainEqualNull.contains(expectedFilterPushDownExplain));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownEqualLiteralOnLeft() {\n+    String sqlLiteralLeft = String.format(\"SELECT * FROM %s WHERE 1 = id \", TABLE_NAME);\n+    String explainLeft = getTableEnv().explainSql(sqlLiteralLeft);\n+    String explainExpected = \"FilterPushDown,the filters :ref(name=\\\"id\\\") == 1]]], fields=[id, data])\";\n+    assertTrue(\"explain should contains FilterPushDown\", explainLeft.contains(explainExpected));\n+\n+    List<Object[]> resultLeft = sql(sqlLiteralLeft);\n+    assertEquals(\"should have 1 record\", 1, resultLeft.size());\n+    assertArrayEquals(\"Should produce the expected record\", resultLeft.get(0), new Object[] {1, \"a\"});\n+\n+    assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    assertEquals(\"Should push down expected filter\", \"id = 1\", ExpressionsUtil.describe(lastScanEvent.filter()));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownNoEqual() {\n+    String sqlNE = String.format(\"SELECT * FROM %s WHERE id <> 1 \", TABLE_NAME);\n+    String explainNE = getTableEnv().explainSql(sqlNE);\n+    String explainExpected = \"FilterPushDown,the filters :ref(name=\\\"id\\\") != 1]]], fields=[id, data])\";\n+    assertTrue(\"explain should contains FilterPushDown\", explainNE.contains(explainExpected));\n+\n+    List<Object[]> resultNE = sql(sqlNE);\n+    assertEquals(\"should have 2 record\", 2, resultNE.size());\n+\n+    List<Object[]> expectedNE = Lists.newArrayList();\n+    expectedNE.add(new Object[] {2, \"b\"});\n+    expectedNE.add(new Object[] {3, null});\n+    assertArrayEquals(\"Should produce the expected record\", resultNE.toArray(), expectedNE.toArray());\n+    assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    assertEquals(\"Should push down expected filter\", \"id != 1\", ExpressionsUtil.describe(lastScanEvent.filter()));\n+\n+    String sqlNotEqualNull = String.format(\"SELECT * FROM %s WHERE data <> NULL \", TABLE_NAME);\n+    String explainNotEqualNull = getTableEnv().explainSql(sqlNotEqualNull);\n+    assertFalse(\"explain should not contains FilterPushDown\", explainNotEqualNull.contains(\n+        expectedFilterPushDownExplain));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownAnd() {\n+    String sqlAnd = String.format(\"SELECT * FROM %s WHERE id = 1 AND data = 'a' \", TABLE_NAME);\n+    String explainAnd = getTableEnv().explainSql(sqlAnd);\n+    String explainExpected =\n+        \"FilterPushDown,the filters :ref(name=\\\"id\\\") == 1,ref(name=\\\"data\\\") == \\\"a\\\"]]], fields=[id, data])\";\n+    assertTrue(\"explain should contains FilterPushDown\", explainAnd.contains(explainExpected));\n+\n+    List<Object[]> resultAnd = sql(sqlAnd);\n+    assertEquals(\"should have 1 record\", 1, resultAnd.size());\n+    assertArrayEquals(\"Should produce the expected record\", resultAnd.get(0), new Object[] {1, \"a\"});\n+\n+    assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    assertEquals(\"Should push down expected filter\", \"(id = 1 AND data = 'a')\",\n+        ExpressionsUtil.describe(lastScanEvent.filter()));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownOr() {\n+    String sqlOr = String.format(\"SELECT * FROM %s WHERE id = 1 OR data = 'b' \", TABLE_NAME);\n+    String explainOr = getTableEnv().explainSql(sqlOr);\n+    String explainExpected =\n+        \"FilterPushDown,the filters :(ref(name=\\\"id\\\") == 1 or ref(name=\\\"data\\\") == \\\"b\\\")]]], fields=[id, data])\";\n+    assertTrue(\"explain should contains FilterPushDown\", explainOr.contains(explainExpected));\n+\n+    List<Object[]> resultOr = sql(sqlOr);\n+    assertEquals(\"should have 2 record\", 2, resultOr.size());\n+\n+    List<Object[]> expectedOR = Lists.newArrayList();\n+    expectedOR.add(new Object[] {1, \"a\"});\n+    expectedOR.add(new Object[] {2, \"b\"});\n+    assertArrayEquals(\"Should produce the expected record\", resultOr.toArray(), expectedOR.toArray());\n+\n+    assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    assertEquals(\"Should push down expected filter\", \"(id = 1 OR data = 'b')\",\n+        ExpressionsUtil.describe(lastScanEvent.filter()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0331d4923f15d6af157d27aa704cd2c3d9c5596c"}, "originalPosition": 206}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY3ODIyODM4", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-567822838", "createdAt": "2021-01-14T03:14:52Z", "commit": {"oid": "0331d4923f15d6af157d27aa704cd2c3d9c5596c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQwMzoxNDo1MlrOITNozg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQwMzoxNDo1MlrOITNozg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzAxNzI5NA==", "bodyText": "Can you please remove the static imports?", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r557017294", "createdAt": "2021-01-14T03:14:52Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkFilters.java", "diffHunk": "@@ -0,0 +1,362 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.math.BigDecimal;\n+import java.nio.ByteBuffer;\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.stream.Collectors;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.Expressions;\n+import org.apache.flink.table.api.TableColumn;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.expressions.ApiExpressionUtils;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.Expression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.UnresolvedCallExpression;\n+import org.apache.flink.table.expressions.UnresolvedReferenceExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.expressions.utils.ApiExpressionDefaultVisitor;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.iceberg.expressions.And;\n+import org.apache.iceberg.expressions.BoundLiteralPredicate;\n+import org.apache.iceberg.expressions.Not;\n+import org.apache.iceberg.expressions.Or;\n+import org.apache.iceberg.expressions.UnboundPredicate;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n+import org.apache.iceberg.util.DateTimeUtil;\n+import org.junit.Test;\n+\n+import static org.apache.flink.table.api.Expressions.$;\n+import static org.apache.flink.table.api.Expressions.lit;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0331d4923f15d6af157d27aa704cd2c3d9c5596c"}, "originalPosition": 58}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY3ODIzMDQ2", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-567823046", "createdAt": "2021-01-14T03:15:32Z", "commit": {"oid": "0331d4923f15d6af157d27aa704cd2c3d9c5596c"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQwMzoxNTozM1rOITNpqA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQwMzoxNTozM1rOITNpqA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzAxNzUxMg==", "bodyText": "Is there a more descriptive name than LIST? What are these used for?", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r557017512", "createdAt": "2021-01-14T03:15:33Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkFilters.java", "diffHunk": "@@ -0,0 +1,362 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.math.BigDecimal;\n+import java.nio.ByteBuffer;\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.stream.Collectors;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.Expressions;\n+import org.apache.flink.table.api.TableColumn;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.expressions.ApiExpressionUtils;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.Expression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.UnresolvedCallExpression;\n+import org.apache.flink.table.expressions.UnresolvedReferenceExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.expressions.utils.ApiExpressionDefaultVisitor;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.iceberg.expressions.And;\n+import org.apache.iceberg.expressions.BoundLiteralPredicate;\n+import org.apache.iceberg.expressions.Not;\n+import org.apache.iceberg.expressions.Or;\n+import org.apache.iceberg.expressions.UnboundPredicate;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n+import org.apache.iceberg.util.DateTimeUtil;\n+import org.junit.Test;\n+\n+import static org.apache.flink.table.api.Expressions.$;\n+import static org.apache.flink.table.api.Expressions.lit;\n+import static org.junit.Assert.assertEquals;\n+import static org.junit.Assert.assertTrue;\n+\n+public class TestFlinkFilters {\n+\n+  private static final TableSchema TABLE_SCHEMA = TableSchema.builder()\n+      .field(\"field1\", DataTypes.INT())\n+      .field(\"field2\", DataTypes.BIGINT())\n+      .field(\"field3\", DataTypes.FLOAT())\n+      .field(\"field4\", DataTypes.DOUBLE())\n+      .field(\"field5\", DataTypes.STRING())\n+      .field(\"field6\", DataTypes.BOOLEAN())\n+      .field(\"field7\", DataTypes.BINARY(2))\n+      .field(\"field8\", DataTypes.DECIMAL(10, 2))\n+      .field(\"field9\", DataTypes.DATE())\n+      .field(\"field10\", DataTypes.TIME())\n+      .field(\"field11\", DataTypes.TIMESTAMP())\n+      .field(\"field12\", DataTypes.TIMESTAMP_WITH_LOCAL_TIME_ZONE())\n+      .build();\n+\n+  private static final List<Tuple2<String, Object>> LIST = ImmutableList.of(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "0331d4923f15d6af157d27aa704cd2c3d9c5596c"}, "originalPosition": 77}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "0331d4923f15d6af157d27aa704cd2c3d9c5596c", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/0331d4923f15d6af157d27aa704cd2c3d9c5596c", "committedDate": "2021-01-14T01:24:05Z", "message": "fix some issues"}, "afterCommit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/9417e9d241b873918dcbdfb4e8c17c5b30aed027", "committedDate": "2021-01-14T07:36:41Z", "message": "fix some issues"}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY4NDE5OTYx", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-568419961", "createdAt": "2021-01-14T16:42:51Z", "commit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNjo0Mjo1MVrOITtTBA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNjo0Mjo1MVrOITtTBA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzUzNjAwNA==", "bodyText": "Why not use lit.map instead of putting the if here?", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r557536004", "createdAt": "2021-01-14T16:42:51Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/FlinkFilters.java", "diffHunk": "@@ -0,0 +1,252 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.List;\n+import java.util.Map;\n+import java.util.Optional;\n+import java.util.function.BiFunction;\n+import java.util.regex.Matcher;\n+import java.util.regex.Pattern;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.flink.table.functions.FunctionDefinition;\n+import org.apache.iceberg.expressions.Expression;\n+import org.apache.iceberg.expressions.Expression.Operation;\n+import org.apache.iceberg.expressions.Expressions;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableMap;\n+import org.apache.iceberg.util.DateTimeUtil;\n+import org.apache.iceberg.util.NaNUtil;\n+\n+public class FlinkFilters {\n+  private FlinkFilters() {\n+  }\n+\n+  private static final Pattern STARTS_WITH_PATTERN = Pattern.compile(\"([^%]+)%\");\n+\n+  private static final Map<FunctionDefinition, Operation> FILTERS = ImmutableMap\n+      .<FunctionDefinition, Operation>builder()\n+      .put(BuiltInFunctionDefinitions.EQUALS, Operation.EQ)\n+      .put(BuiltInFunctionDefinitions.NOT_EQUALS, Operation.NOT_EQ)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN, Operation.GT)\n+      .put(BuiltInFunctionDefinitions.GREATER_THAN_OR_EQUAL, Operation.GT_EQ)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN, Operation.LT)\n+      .put(BuiltInFunctionDefinitions.LESS_THAN_OR_EQUAL, Operation.LT_EQ)\n+      .put(BuiltInFunctionDefinitions.IS_NULL, Operation.IS_NULL)\n+      .put(BuiltInFunctionDefinitions.IS_NOT_NULL, Operation.NOT_NULL)\n+      .put(BuiltInFunctionDefinitions.AND, Operation.AND)\n+      .put(BuiltInFunctionDefinitions.OR, Operation.OR)\n+      .put(BuiltInFunctionDefinitions.NOT, Operation.NOT)\n+      .put(BuiltInFunctionDefinitions.LIKE, Operation.STARTS_WITH)\n+      .build();\n+\n+  /**\n+   * Convert flink expression to iceberg expression.\n+   * <p>\n+   * the BETWEEN, NOT_BETWEEN, IN expression will be converted by flink automatically. the BETWEEN will be converted to\n+   * (GT_EQ AND LT_EQ), the NOT_BETWEEN will be converted to (LT_EQ OR GT_EQ), the IN will be converted to OR, so we do\n+   * not add the conversion here\n+   *\n+   * @param flinkExpression the flink expression\n+   * @return the iceberg expression\n+   */\n+  public static Optional<Expression> convert(org.apache.flink.table.expressions.Expression flinkExpression) {\n+    if (!(flinkExpression instanceof CallExpression)) {\n+      return Optional.empty();\n+    }\n+\n+    CallExpression call = (CallExpression) flinkExpression;\n+    Operation op = FILTERS.get(call.getFunctionDefinition());\n+    if (op != null) {\n+      switch (op) {\n+        case IS_NULL:\n+          return onlyChildAs(call, FieldReferenceExpression.class)\n+              .map(FieldReferenceExpression::getName)\n+              .map(Expressions::isNull);\n+\n+        case NOT_NULL:\n+          return onlyChildAs(call, FieldReferenceExpression.class)\n+              .map(FieldReferenceExpression::getName)\n+              .map(Expressions::notNull);\n+\n+        case LT:\n+          return convertFieldAndLiteral(Expressions::lessThan, Expressions::greaterThan, call);\n+\n+        case LT_EQ:\n+          return convertFieldAndLiteral(Expressions::lessThanOrEqual, Expressions::greaterThanOrEqual, call);\n+\n+        case GT:\n+          return convertFieldAndLiteral(Expressions::greaterThan, Expressions::lessThan, call);\n+\n+        case GT_EQ:\n+          return convertFieldAndLiteral(Expressions::greaterThanOrEqual, Expressions::lessThanOrEqual, call);\n+\n+        case EQ:\n+          return convertFieldAndLiteral((ref, lit) -> {\n+            if (NaNUtil.isNaN(lit)) {\n+              return Expressions.isNaN(ref);\n+            } else {\n+              return Expressions.equal(ref, lit);\n+            }\n+          }, call);\n+\n+        case NOT_EQ:\n+          return convertFieldAndLiteral((ref, lit) -> {\n+            if (NaNUtil.isNaN(lit)) {\n+              return Expressions.notNaN(ref);\n+            } else {\n+              return Expressions.notEqual(ref, lit);\n+            }\n+          }, call);\n+\n+        case NOT:\n+          return onlyChildAs(call, CallExpression.class).flatMap(FlinkFilters::convert).map(Expressions::not);\n+\n+        case AND:\n+          return convertLogicExpression(Expressions::and, call);\n+\n+        case OR:\n+          return convertLogicExpression(Expressions::or, call);\n+\n+        case STARTS_WITH:\n+          return convertLike(call);\n+      }\n+    }\n+\n+    return Optional.empty();\n+  }\n+\n+  private static <T extends ResolvedExpression> Optional<T> onlyChildAs(CallExpression call,\n+                                                                        Class<T> expectedChildClass) {\n+    List<ResolvedExpression> children = call.getResolvedChildren();\n+    if (children.size() != 1) {\n+      return Optional.empty();\n+    }\n+\n+    ResolvedExpression child = children.get(0);\n+    if (!expectedChildClass.isInstance(child)) {\n+      return Optional.empty();\n+    }\n+\n+    return Optional.of(expectedChildClass.cast(child));\n+  }\n+\n+  private static Optional<Expression> convertLike(CallExpression call) {\n+    List<ResolvedExpression> args = call.getResolvedChildren();\n+    if (args.size() != 2) {\n+      return Optional.empty();\n+    }\n+\n+    org.apache.flink.table.expressions.Expression left = args.get(0);\n+    org.apache.flink.table.expressions.Expression right = args.get(1);\n+\n+    if (left instanceof FieldReferenceExpression && right instanceof ValueLiteralExpression) {\n+      String name = ((FieldReferenceExpression) left).getName();\n+      return convertLiteral((ValueLiteralExpression) right).flatMap(lit -> {\n+        if (lit instanceof String) {\n+          String pattern = (String) lit;\n+          Matcher matcher = STARTS_WITH_PATTERN.matcher(pattern);\n+          // exclude special char of LIKE\n+          // '_' is the wildcard of the SQL LIKE\n+          if (!pattern.contains(\"_\") && matcher.matches()) {\n+            return Optional.of(Expressions.startsWith(name, matcher.group(1)));\n+          }\n+        }\n+\n+        return Optional.empty();\n+      });\n+    }\n+\n+    return Optional.empty();\n+  }\n+\n+  private static Optional<Expression> convertLogicExpression(BiFunction<Expression, Expression, Expression> function,\n+                                                             CallExpression call) {\n+    List<ResolvedExpression> args = call.getResolvedChildren();\n+    if (args == null || args.size() != 2) {\n+      return Optional.empty();\n+    }\n+\n+    Optional<Expression> left = convert(args.get(0));\n+    Optional<Expression> right = convert(args.get(1));\n+    if (left.isPresent() && right.isPresent()) {\n+      return Optional.of(function.apply(left.get(), right.get()));\n+    }\n+\n+    return Optional.empty();\n+  }\n+\n+  private static Optional<Object> convertLiteral(ValueLiteralExpression expression) {\n+    Optional<?> value = expression.getValueAs(expression.getOutputDataType().getLogicalType().getDefaultConversion());\n+    return value.map(o -> {\n+      if (o instanceof LocalDateTime) {\n+        return DateTimeUtil.microsFromTimestamp((LocalDateTime) o);\n+      } else if (o instanceof Instant) {\n+        return DateTimeUtil.microsFromInstant((Instant) o);\n+      } else if (o instanceof LocalTime) {\n+        return DateTimeUtil.microsFromTime((LocalTime) o);\n+      } else if (o instanceof LocalDate) {\n+        return DateTimeUtil.daysFromDate((LocalDate) o);\n+      }\n+\n+      return o;\n+    });\n+  }\n+\n+  private static Optional<Expression> convertFieldAndLiteral(BiFunction<String, Object, Expression> expr,\n+                                                             CallExpression call) {\n+    return convertFieldAndLiteral(expr, expr, call);\n+  }\n+\n+  private static Optional<Expression> convertFieldAndLiteral(\n+      BiFunction<String, Object, Expression> convertLR, BiFunction<String, Object, Expression> convertRL,\n+      CallExpression call) {\n+    List<ResolvedExpression> args = call.getResolvedChildren();\n+    if (args.size() != 2) {\n+      return Optional.empty();\n+    }\n+\n+    org.apache.flink.table.expressions.Expression left = args.get(0);\n+    org.apache.flink.table.expressions.Expression right = args.get(1);\n+\n+    if (left instanceof FieldReferenceExpression && right instanceof ValueLiteralExpression) {\n+      String name = ((FieldReferenceExpression) left).getName();\n+      Optional<Object> lit = convertLiteral((ValueLiteralExpression) right);\n+      if (lit.isPresent()) {\n+        return Optional.of(convertLR.apply(name, lit.get()));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "originalPosition": 240}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY4NDIyNDA0", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-568422404", "createdAt": "2021-01-14T16:45:18Z", "commit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNjo0NToxOFrOITtaIA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNjo0NToxOFrOITtaIA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzUzNzgyNA==", "bodyText": "Nit: typos in this message. Can you change the string to \", FilterPushDown: %s\"? Also, the joiner should be a static final constant and should use \", \" to separate the filters.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r557537824", "createdAt": "2021-01-14T16:45:18Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/IcebergTableSource.java", "diffHunk": "@@ -112,6 +120,10 @@ public String explainSource() {\n       explain += String.format(\", LimitPushDown : %d\", limit);\n     }\n \n+    if (isFilterPushedDown()) {\n+      explain += String.format(\", FilterPushDown,the filters :%s\", Joiner.on(\",\").join(filters));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "originalPosition": 79}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY4NDI4NTUy", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-568428552", "createdAt": "2021-01-14T16:51:33Z", "commit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNjo1MTozM1rOITtsSw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNjo1MTozM1rOITtsSw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU0MjQ3NQ==", "bodyText": "@openinx, is this guaranteed to only be called on a source that has not had predicates pushed? This ignores the existing predicates in this source. Maybe we should add a precondition to check that assumption.\nI think it is safe either way because this doesn't remove any predicates from the list. From reading the Javadoc, I think that will result in all predicates running in Flink also.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r557542475", "createdAt": "2021-01-14T16:51:33Z", "author": {"login": "rdblue"}, "path": "flink/src/main/java/org/apache/iceberg/flink/IcebergTableSource.java", "diffHunk": "@@ -122,6 +134,21 @@ public boolean isLimitPushedDown() {\n \n   @Override\n   public TableSource<RowData> applyLimit(long newLimit) {\n-    return new IcebergTableSource(loader, schema, properties, projectedFields, true, newLimit);\n+    return new IcebergTableSource(loader, schema, properties, projectedFields, true, newLimit, filters);\n+  }\n+\n+  @Override\n+  public TableSource<RowData> applyPredicate(List<Expression> predicates) {\n+    List<org.apache.iceberg.expressions.Expression> expressions = Lists.newArrayList();\n+    for (Expression predicate : predicates) {\n+      FlinkFilters.convert(predicate).ifPresent(expressions::add);\n+    }\n+\n+    return new IcebergTableSource(loader, schema, properties, projectedFields, isLimitPushDown, limit, expressions);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "originalPosition": 100}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY4NDI5MzA0", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-568429304", "createdAt": "2021-01-14T16:52:21Z", "commit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNjo1MjoyMVrOITtufA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNjo1MjoyMVrOITtufA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU0MzAzNg==", "bodyText": "Why was this change needed?", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r557543036", "createdAt": "2021-01-14T16:52:21Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/FlinkTestBase.java", "diffHunk": "@@ -73,15 +73,15 @@ protected TableEnvironment getTableEnv() {\n   }\n \n   protected static TableResult exec(TableEnvironment env, String query, Object... args) {\n-    return env.executeSql(String.format(query, args));\n+    return env.executeSql(args.length > 0 ? String.format(query, args) : query);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "originalPosition": 5}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY4NDI5ODkx", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-568429891", "createdAt": "2021-01-14T16:52:57Z", "commit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNjo1Mjo1N1rOITtwIQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNjo1Mjo1N1rOITtwIQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU0MzQ1Nw==", "bodyText": "I think that this change is correct, but I don't see why it was necessary in this commit. Wouldn't all of the tests run the same way without modifying this file at all?", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r557543457", "createdAt": "2021-01-14T16:52:57Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/FlinkTestBase.java", "diffHunk": "@@ -73,15 +73,15 @@ protected TableEnvironment getTableEnv() {\n   }\n \n   protected static TableResult exec(TableEnvironment env, String query, Object... args) {\n-    return env.executeSql(String.format(query, args));\n+    return env.executeSql(args.length > 0 ? String.format(query, args) : query);\n   }\n \n   protected TableResult exec(String query, Object... args) {\n     return exec(getTableEnv(), query, args);\n   }\n \n   protected List<Object[]> sql(String query, Object... args) {\n-    TableResult tableResult = exec(String.format(query, args));\n+    TableResult tableResult = exec(query, args);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "originalPosition": 14}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY4NDQxMjYy", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-568441262", "createdAt": "2021-01-14T17:04:39Z", "commit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzowNDozOVrOITuQAw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzowNDozOVrOITuQAw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU1MTYxOQ==", "bodyText": "Assertions should have context so that when one fails it is clear what went wrong. In this case, the assertion is testing that converting succeeded. So this should be Assert.assertTrue(\"Conversion should succeed\", actual.isPresent())", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r557551619", "createdAt": "2021-01-14T17:04:39Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkFilters.java", "diffHunk": "@@ -0,0 +1,361 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.math.BigDecimal;\n+import java.nio.ByteBuffer;\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.stream.Collectors;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.Expressions;\n+import org.apache.flink.table.api.TableColumn;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.expressions.ApiExpressionUtils;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.Expression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.UnresolvedCallExpression;\n+import org.apache.flink.table.expressions.UnresolvedReferenceExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.expressions.utils.ApiExpressionDefaultVisitor;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.iceberg.expressions.And;\n+import org.apache.iceberg.expressions.BoundLiteralPredicate;\n+import org.apache.iceberg.expressions.Not;\n+import org.apache.iceberg.expressions.Or;\n+import org.apache.iceberg.expressions.UnboundPredicate;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n+import org.apache.iceberg.util.DateTimeUtil;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestFlinkFilters {\n+\n+  private static final TableSchema TABLE_SCHEMA = TableSchema.builder()\n+      .field(\"field1\", DataTypes.INT())\n+      .field(\"field2\", DataTypes.BIGINT())\n+      .field(\"field3\", DataTypes.FLOAT())\n+      .field(\"field4\", DataTypes.DOUBLE())\n+      .field(\"field5\", DataTypes.STRING())\n+      .field(\"field6\", DataTypes.BOOLEAN())\n+      .field(\"field7\", DataTypes.BINARY(2))\n+      .field(\"field8\", DataTypes.DECIMAL(10, 2))\n+      .field(\"field9\", DataTypes.DATE())\n+      .field(\"field10\", DataTypes.TIME())\n+      .field(\"field11\", DataTypes.TIMESTAMP())\n+      .field(\"field12\", DataTypes.TIMESTAMP_WITH_LOCAL_TIME_ZONE())\n+      .build();\n+\n+  // A map list of fields and values used to verify the conversion of flink expression to iceberg expression\n+  private static final List<Tuple2<String, Object>> FIELD_VALUE_LIST = ImmutableList.of(\n+      Tuple2.of(\"field1\", 1),\n+      Tuple2.of(\"field2\", 2L),\n+      Tuple2.of(\"field3\", 3F),\n+      Tuple2.of(\"field4\", 4D),\n+      Tuple2.of(\"field5\", \"iceberg\"),\n+      Tuple2.of(\"field6\", true),\n+      Tuple2.of(\"field7\", new byte[] {'a', 'b'}),\n+      Tuple2.of(\"field8\", BigDecimal.valueOf(10)),\n+      Tuple2.of(\"field9\", DateTimeUtil.daysFromDate(LocalDate.now())),\n+      Tuple2.of(\"field10\", DateTimeUtil.microsFromTime(LocalTime.now())),\n+      Tuple2.of(\"field11\", DateTimeUtil.microsFromTimestamp(LocalDateTime.now())),\n+      Tuple2.of(\"field12\", DateTimeUtil.microsFromInstant(Instant.now()))\n+  );\n+\n+  @Test\n+  public void testFlinkDataTypeEqual() {\n+    matchLiteral(\"field1\", 1, 1);\n+    matchLiteral(\"field2\", 10L, 10L);\n+    matchLiteral(\"field3\", 1.2F, 1.2F);\n+    matchLiteral(\"field4\", 3.4D, 3.4D);\n+    matchLiteral(\"field5\", \"abcd\", \"abcd\");\n+    matchLiteral(\"field6\", true, true);\n+    matchLiteral(\"field7\", new byte[] {'a', 'b'}, ByteBuffer.wrap(new byte[] {'a', 'b'}));\n+    matchLiteral(\"field8\", BigDecimal.valueOf(10), BigDecimal.valueOf(10));\n+\n+    LocalDate date = LocalDate.parse(\"2020-12-23\");\n+    matchLiteral(\"field9\", date, DateTimeUtil.daysFromDate(date));\n+\n+    LocalTime time = LocalTime.parse(\"12:13:14\");\n+    matchLiteral(\"field10\", time, DateTimeUtil.microsFromTime(time));\n+\n+    LocalDateTime dateTime = LocalDateTime.parse(\"2020-12-23T12:13:14\");\n+    matchLiteral(\"field11\", dateTime, DateTimeUtil.microsFromTimestamp(dateTime));\n+\n+    Instant instant = Instant.parse(\"2020-12-23T12:13:14.00Z\");\n+    matchLiteral(\"field12\", instant, DateTimeUtil.microsFromInstant(instant));\n+  }\n+\n+  @Test\n+  public void testEquals() {\n+    for (Tuple2<String, Object> tuple2 : FIELD_VALUE_LIST) {\n+      UnboundPredicate<?> expected = org.apache.iceberg.expressions.Expressions.equal(tuple2.f0, tuple2.f1);\n+\n+      Optional<org.apache.iceberg.expressions.Expression> actual =\n+          FlinkFilters.convert(resolve(Expressions.$(tuple2.f0).isEqual(Expressions.lit(tuple2.f1))));\n+      Assert.assertTrue(actual.isPresent());\n+      assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+\n+      Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+          FlinkFilters.convert(resolve(Expressions.lit(tuple2.f1).isEqual(Expressions.$(tuple2.f0))));\n+      Assert.assertTrue(actual1.isPresent());\n+      assertPredicatesMatch(expected, (UnboundPredicate<?>) actual1.get());\n+    }\n+  }\n+\n+  @Test\n+  public void testEqualsNaN() {\n+    UnboundPredicate<Float> expected = org.apache.iceberg.expressions.Expressions.isNaN(\"field3\");\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field3\").isEqual(Expressions.lit(Float.NaN))));\n+    Assert.assertTrue(actual.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(Float.NaN).isEqual(Expressions.$(\"field3\"))));\n+    Assert.assertTrue(actual1.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual1.get());\n+  }\n+\n+  @Test\n+  public void testNotEquals() {\n+    for (Tuple2<String, Object> tuple2 : FIELD_VALUE_LIST) {\n+      UnboundPredicate<?> expected = org.apache.iceberg.expressions.Expressions.notEqual(tuple2.f0, tuple2.f1);\n+\n+      Optional<org.apache.iceberg.expressions.Expression> actual =\n+          FlinkFilters.convert(resolve(Expressions.$(tuple2.f0).isNotEqual(Expressions.lit(tuple2.f1))));\n+      Assert.assertTrue(actual.isPresent());\n+      assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+\n+      Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+          FlinkFilters.convert(resolve(Expressions.lit(tuple2.f1).isNotEqual(Expressions.$(tuple2.f0))));\n+      Assert.assertTrue(actual1.isPresent());\n+      assertPredicatesMatch(expected, (UnboundPredicate<?>) actual1.get());\n+    }\n+  }\n+\n+  @Test\n+  public void testNotEqualsNaN() {\n+    UnboundPredicate<Float> expected = org.apache.iceberg.expressions.Expressions.notNaN(\"field3\");\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field3\").isNotEqual(Expressions.lit(Float.NaN))));\n+    Assert.assertTrue(actual.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(Float.NaN).isNotEqual(Expressions.$(\"field3\"))));\n+    Assert.assertTrue(actual1.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual1.get());\n+  }\n+\n+  @Test\n+  public void testGreaterThan() {\n+    UnboundPredicate<Integer> expected = org.apache.iceberg.expressions.Expressions.greaterThan(\"field1\", 1);\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field1\").isGreater(Expressions.lit(1))));\n+    Assert.assertTrue(actual.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(1).isLess(Expressions.$(\"field1\"))));\n+    Assert.assertTrue(actual1.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual1.get());\n+  }\n+\n+  @Test\n+  public void testGreaterThanEquals() {\n+    UnboundPredicate<Integer> expected = org.apache.iceberg.expressions.Expressions.greaterThanOrEqual(\"field1\", 1);\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field1\").isGreaterOrEqual(Expressions.lit(1))));\n+    Assert.assertTrue(actual.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(1).isLessOrEqual(Expressions.$(\"field1\"))));\n+    Assert.assertTrue(actual1.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual1.get());\n+  }\n+\n+  @Test\n+  public void testLessThan() {\n+    UnboundPredicate<Integer> expected = org.apache.iceberg.expressions.Expressions.lessThan(\"field1\", 1);\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field1\").isLess(Expressions.lit(1))));\n+    Assert.assertTrue(actual.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(1).isGreater(Expressions.$(\"field1\"))));\n+    Assert.assertTrue(actual1.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual1.get());\n+  }\n+\n+  @Test\n+  public void testLessThanEquals() {\n+    UnboundPredicate<Integer> expected = org.apache.iceberg.expressions.Expressions.lessThanOrEqual(\"field1\", 1);\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field1\").isLessOrEqual(Expressions.lit(1))));\n+    Assert.assertTrue(actual.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(1).isGreaterOrEqual(Expressions.$(\"field1\"))));\n+    Assert.assertTrue(actual1.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual1.get());\n+  }\n+\n+  @Test\n+  public void testIsNull() {\n+    Expression expr = resolve(Expressions.$(\"field1\").isNull());\n+    Optional<org.apache.iceberg.expressions.Expression> actual = FlinkFilters.convert(expr);\n+    Assert.assertTrue(actual.isPresent());\n+    UnboundPredicate<Object> expected = org.apache.iceberg.expressions.Expressions.isNull(\"field1\");\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+  }\n+\n+  @Test\n+  public void testIsNotNull() {\n+    Expression expr = resolve(Expressions.$(\"field1\").isNotNull());\n+    Optional<org.apache.iceberg.expressions.Expression> actual = FlinkFilters.convert(expr);\n+    Assert.assertTrue(actual.isPresent());\n+    UnboundPredicate<Object> expected = org.apache.iceberg.expressions.Expressions.notNull(\"field1\");\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+  }\n+\n+  @Test\n+  public void testAnd() {\n+    Expression expr = resolve(\n+        Expressions.$(\"field1\").isEqual(Expressions.lit(1)).and(Expressions.$(\"field2\").isEqual(Expressions.lit(2L))));\n+    Optional<org.apache.iceberg.expressions.Expression> actual = FlinkFilters.convert(expr);\n+    Assert.assertTrue(actual.isPresent());\n+    And and = (And) actual.get();\n+    And expected = (And) org.apache.iceberg.expressions.Expressions.and(\n+        org.apache.iceberg.expressions.Expressions.equal(\"field1\", 1),\n+        org.apache.iceberg.expressions.Expressions.equal(\"field2\", 2L));\n+\n+    Assert.assertEquals(expected.op(), and.op());\n+    Assert.assertEquals(expected.left().op(), and.left().op());\n+    Assert.assertEquals(expected.right().op(), and.right().op());\n+  }\n+\n+  @Test\n+  public void testOr() {\n+    Expression expr = resolve(\n+        Expressions.$(\"field1\").isEqual(Expressions.lit(1)).or(Expressions.$(\"field2\").isEqual(Expressions.lit(2L))));\n+    Optional<org.apache.iceberg.expressions.Expression> actual = FlinkFilters.convert(expr);\n+    Assert.assertTrue(actual.isPresent());\n+    Or or = (Or) actual.get();\n+    Or expected = (Or) org.apache.iceberg.expressions.Expressions.or(\n+        org.apache.iceberg.expressions.Expressions.equal(\"field1\", 1),\n+        org.apache.iceberg.expressions.Expressions.equal(\"field2\", 2L));\n+\n+    Assert.assertEquals(expected.op(), or.op());\n+    Assert.assertEquals(expected.left().op(), or.left().op());\n+    Assert.assertEquals(expected.right().op(), or.right().op());\n+  }\n+\n+  @Test\n+  public void testNot() {\n+    Expression expr = resolve(ApiExpressionUtils.unresolvedCall(\n+        BuiltInFunctionDefinitions.NOT, Expressions.$(\"field1\").isEqual(Expressions.lit(1))));\n+    Optional<org.apache.iceberg.expressions.Expression> actual = FlinkFilters.convert(expr);\n+    Assert.assertTrue(actual.isPresent());\n+    Not not = (Not) actual.get();\n+    Not expected = (Not) org.apache.iceberg.expressions.Expressions.not(\n+        org.apache.iceberg.expressions.Expressions.equal(\"field1\", 1));\n+\n+    Assert.assertEquals(expected.op(), not.op());\n+    assertPredicatesMatch((UnboundPredicate<?>) expected.child(), (UnboundPredicate<?>) not.child());\n+  }\n+\n+  @Test\n+  public void testLike() {\n+    UnboundPredicate<?> expected = org.apache.iceberg.expressions.Expressions.startsWith(\"field5\", \"abc\");\n+    Expression expr = resolve(ApiExpressionUtils.unresolvedCall(\n+        BuiltInFunctionDefinitions.LIKE, Expressions.$(\"field5\"), Expressions.lit(\"abc%\")));\n+    Optional<org.apache.iceberg.expressions.Expression> actual = FlinkFilters.convert(expr);\n+    Assert.assertTrue(actual.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+  }\n+\n+  private void matchLiteral(String fieldName, Object flinkLiteral, Object icebergLiteral) {\n+    Expression expr = resolve(Expressions.$(fieldName).isEqual(Expressions.lit(flinkLiteral)));\n+    Optional<org.apache.iceberg.expressions.Expression> actual = FlinkFilters.convert(expr);\n+    Assert.assertTrue(actual.isPresent());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "originalPosition": 314}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY4NDQxNjcw", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-568441670", "createdAt": "2021-01-14T17:05:03Z", "commit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzowNTowNFrOITuRGA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzowNTowNFrOITuRGA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU1MTg5Ng==", "bodyText": "BoundLiteralPredicate is a parameterized type, so it should have parameters here.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r557551896", "createdAt": "2021-01-14T17:05:04Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkFilters.java", "diffHunk": "@@ -0,0 +1,361 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.math.BigDecimal;\n+import java.nio.ByteBuffer;\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.stream.Collectors;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.Expressions;\n+import org.apache.flink.table.api.TableColumn;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.expressions.ApiExpressionUtils;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.Expression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.UnresolvedCallExpression;\n+import org.apache.flink.table.expressions.UnresolvedReferenceExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.expressions.utils.ApiExpressionDefaultVisitor;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.iceberg.expressions.And;\n+import org.apache.iceberg.expressions.BoundLiteralPredicate;\n+import org.apache.iceberg.expressions.Not;\n+import org.apache.iceberg.expressions.Or;\n+import org.apache.iceberg.expressions.UnboundPredicate;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n+import org.apache.iceberg.util.DateTimeUtil;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestFlinkFilters {\n+\n+  private static final TableSchema TABLE_SCHEMA = TableSchema.builder()\n+      .field(\"field1\", DataTypes.INT())\n+      .field(\"field2\", DataTypes.BIGINT())\n+      .field(\"field3\", DataTypes.FLOAT())\n+      .field(\"field4\", DataTypes.DOUBLE())\n+      .field(\"field5\", DataTypes.STRING())\n+      .field(\"field6\", DataTypes.BOOLEAN())\n+      .field(\"field7\", DataTypes.BINARY(2))\n+      .field(\"field8\", DataTypes.DECIMAL(10, 2))\n+      .field(\"field9\", DataTypes.DATE())\n+      .field(\"field10\", DataTypes.TIME())\n+      .field(\"field11\", DataTypes.TIMESTAMP())\n+      .field(\"field12\", DataTypes.TIMESTAMP_WITH_LOCAL_TIME_ZONE())\n+      .build();\n+\n+  // A map list of fields and values used to verify the conversion of flink expression to iceberg expression\n+  private static final List<Tuple2<String, Object>> FIELD_VALUE_LIST = ImmutableList.of(\n+      Tuple2.of(\"field1\", 1),\n+      Tuple2.of(\"field2\", 2L),\n+      Tuple2.of(\"field3\", 3F),\n+      Tuple2.of(\"field4\", 4D),\n+      Tuple2.of(\"field5\", \"iceberg\"),\n+      Tuple2.of(\"field6\", true),\n+      Tuple2.of(\"field7\", new byte[] {'a', 'b'}),\n+      Tuple2.of(\"field8\", BigDecimal.valueOf(10)),\n+      Tuple2.of(\"field9\", DateTimeUtil.daysFromDate(LocalDate.now())),\n+      Tuple2.of(\"field10\", DateTimeUtil.microsFromTime(LocalTime.now())),\n+      Tuple2.of(\"field11\", DateTimeUtil.microsFromTimestamp(LocalDateTime.now())),\n+      Tuple2.of(\"field12\", DateTimeUtil.microsFromInstant(Instant.now()))\n+  );\n+\n+  @Test\n+  public void testFlinkDataTypeEqual() {\n+    matchLiteral(\"field1\", 1, 1);\n+    matchLiteral(\"field2\", 10L, 10L);\n+    matchLiteral(\"field3\", 1.2F, 1.2F);\n+    matchLiteral(\"field4\", 3.4D, 3.4D);\n+    matchLiteral(\"field5\", \"abcd\", \"abcd\");\n+    matchLiteral(\"field6\", true, true);\n+    matchLiteral(\"field7\", new byte[] {'a', 'b'}, ByteBuffer.wrap(new byte[] {'a', 'b'}));\n+    matchLiteral(\"field8\", BigDecimal.valueOf(10), BigDecimal.valueOf(10));\n+\n+    LocalDate date = LocalDate.parse(\"2020-12-23\");\n+    matchLiteral(\"field9\", date, DateTimeUtil.daysFromDate(date));\n+\n+    LocalTime time = LocalTime.parse(\"12:13:14\");\n+    matchLiteral(\"field10\", time, DateTimeUtil.microsFromTime(time));\n+\n+    LocalDateTime dateTime = LocalDateTime.parse(\"2020-12-23T12:13:14\");\n+    matchLiteral(\"field11\", dateTime, DateTimeUtil.microsFromTimestamp(dateTime));\n+\n+    Instant instant = Instant.parse(\"2020-12-23T12:13:14.00Z\");\n+    matchLiteral(\"field12\", instant, DateTimeUtil.microsFromInstant(instant));\n+  }\n+\n+  @Test\n+  public void testEquals() {\n+    for (Tuple2<String, Object> tuple2 : FIELD_VALUE_LIST) {\n+      UnboundPredicate<?> expected = org.apache.iceberg.expressions.Expressions.equal(tuple2.f0, tuple2.f1);\n+\n+      Optional<org.apache.iceberg.expressions.Expression> actual =\n+          FlinkFilters.convert(resolve(Expressions.$(tuple2.f0).isEqual(Expressions.lit(tuple2.f1))));\n+      Assert.assertTrue(actual.isPresent());\n+      assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+\n+      Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+          FlinkFilters.convert(resolve(Expressions.lit(tuple2.f1).isEqual(Expressions.$(tuple2.f0))));\n+      Assert.assertTrue(actual1.isPresent());\n+      assertPredicatesMatch(expected, (UnboundPredicate<?>) actual1.get());\n+    }\n+  }\n+\n+  @Test\n+  public void testEqualsNaN() {\n+    UnboundPredicate<Float> expected = org.apache.iceberg.expressions.Expressions.isNaN(\"field3\");\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field3\").isEqual(Expressions.lit(Float.NaN))));\n+    Assert.assertTrue(actual.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(Float.NaN).isEqual(Expressions.$(\"field3\"))));\n+    Assert.assertTrue(actual1.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual1.get());\n+  }\n+\n+  @Test\n+  public void testNotEquals() {\n+    for (Tuple2<String, Object> tuple2 : FIELD_VALUE_LIST) {\n+      UnboundPredicate<?> expected = org.apache.iceberg.expressions.Expressions.notEqual(tuple2.f0, tuple2.f1);\n+\n+      Optional<org.apache.iceberg.expressions.Expression> actual =\n+          FlinkFilters.convert(resolve(Expressions.$(tuple2.f0).isNotEqual(Expressions.lit(tuple2.f1))));\n+      Assert.assertTrue(actual.isPresent());\n+      assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+\n+      Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+          FlinkFilters.convert(resolve(Expressions.lit(tuple2.f1).isNotEqual(Expressions.$(tuple2.f0))));\n+      Assert.assertTrue(actual1.isPresent());\n+      assertPredicatesMatch(expected, (UnboundPredicate<?>) actual1.get());\n+    }\n+  }\n+\n+  @Test\n+  public void testNotEqualsNaN() {\n+    UnboundPredicate<Float> expected = org.apache.iceberg.expressions.Expressions.notNaN(\"field3\");\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field3\").isNotEqual(Expressions.lit(Float.NaN))));\n+    Assert.assertTrue(actual.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(Float.NaN).isNotEqual(Expressions.$(\"field3\"))));\n+    Assert.assertTrue(actual1.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual1.get());\n+  }\n+\n+  @Test\n+  public void testGreaterThan() {\n+    UnboundPredicate<Integer> expected = org.apache.iceberg.expressions.Expressions.greaterThan(\"field1\", 1);\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field1\").isGreater(Expressions.lit(1))));\n+    Assert.assertTrue(actual.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(1).isLess(Expressions.$(\"field1\"))));\n+    Assert.assertTrue(actual1.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual1.get());\n+  }\n+\n+  @Test\n+  public void testGreaterThanEquals() {\n+    UnboundPredicate<Integer> expected = org.apache.iceberg.expressions.Expressions.greaterThanOrEqual(\"field1\", 1);\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field1\").isGreaterOrEqual(Expressions.lit(1))));\n+    Assert.assertTrue(actual.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(1).isLessOrEqual(Expressions.$(\"field1\"))));\n+    Assert.assertTrue(actual1.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual1.get());\n+  }\n+\n+  @Test\n+  public void testLessThan() {\n+    UnboundPredicate<Integer> expected = org.apache.iceberg.expressions.Expressions.lessThan(\"field1\", 1);\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field1\").isLess(Expressions.lit(1))));\n+    Assert.assertTrue(actual.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(1).isGreater(Expressions.$(\"field1\"))));\n+    Assert.assertTrue(actual1.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual1.get());\n+  }\n+\n+  @Test\n+  public void testLessThanEquals() {\n+    UnboundPredicate<Integer> expected = org.apache.iceberg.expressions.Expressions.lessThanOrEqual(\"field1\", 1);\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field1\").isLessOrEqual(Expressions.lit(1))));\n+    Assert.assertTrue(actual.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(1).isGreaterOrEqual(Expressions.$(\"field1\"))));\n+    Assert.assertTrue(actual1.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual1.get());\n+  }\n+\n+  @Test\n+  public void testIsNull() {\n+    Expression expr = resolve(Expressions.$(\"field1\").isNull());\n+    Optional<org.apache.iceberg.expressions.Expression> actual = FlinkFilters.convert(expr);\n+    Assert.assertTrue(actual.isPresent());\n+    UnboundPredicate<Object> expected = org.apache.iceberg.expressions.Expressions.isNull(\"field1\");\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+  }\n+\n+  @Test\n+  public void testIsNotNull() {\n+    Expression expr = resolve(Expressions.$(\"field1\").isNotNull());\n+    Optional<org.apache.iceberg.expressions.Expression> actual = FlinkFilters.convert(expr);\n+    Assert.assertTrue(actual.isPresent());\n+    UnboundPredicate<Object> expected = org.apache.iceberg.expressions.Expressions.notNull(\"field1\");\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+  }\n+\n+  @Test\n+  public void testAnd() {\n+    Expression expr = resolve(\n+        Expressions.$(\"field1\").isEqual(Expressions.lit(1)).and(Expressions.$(\"field2\").isEqual(Expressions.lit(2L))));\n+    Optional<org.apache.iceberg.expressions.Expression> actual = FlinkFilters.convert(expr);\n+    Assert.assertTrue(actual.isPresent());\n+    And and = (And) actual.get();\n+    And expected = (And) org.apache.iceberg.expressions.Expressions.and(\n+        org.apache.iceberg.expressions.Expressions.equal(\"field1\", 1),\n+        org.apache.iceberg.expressions.Expressions.equal(\"field2\", 2L));\n+\n+    Assert.assertEquals(expected.op(), and.op());\n+    Assert.assertEquals(expected.left().op(), and.left().op());\n+    Assert.assertEquals(expected.right().op(), and.right().op());\n+  }\n+\n+  @Test\n+  public void testOr() {\n+    Expression expr = resolve(\n+        Expressions.$(\"field1\").isEqual(Expressions.lit(1)).or(Expressions.$(\"field2\").isEqual(Expressions.lit(2L))));\n+    Optional<org.apache.iceberg.expressions.Expression> actual = FlinkFilters.convert(expr);\n+    Assert.assertTrue(actual.isPresent());\n+    Or or = (Or) actual.get();\n+    Or expected = (Or) org.apache.iceberg.expressions.Expressions.or(\n+        org.apache.iceberg.expressions.Expressions.equal(\"field1\", 1),\n+        org.apache.iceberg.expressions.Expressions.equal(\"field2\", 2L));\n+\n+    Assert.assertEquals(expected.op(), or.op());\n+    Assert.assertEquals(expected.left().op(), or.left().op());\n+    Assert.assertEquals(expected.right().op(), or.right().op());\n+  }\n+\n+  @Test\n+  public void testNot() {\n+    Expression expr = resolve(ApiExpressionUtils.unresolvedCall(\n+        BuiltInFunctionDefinitions.NOT, Expressions.$(\"field1\").isEqual(Expressions.lit(1))));\n+    Optional<org.apache.iceberg.expressions.Expression> actual = FlinkFilters.convert(expr);\n+    Assert.assertTrue(actual.isPresent());\n+    Not not = (Not) actual.get();\n+    Not expected = (Not) org.apache.iceberg.expressions.Expressions.not(\n+        org.apache.iceberg.expressions.Expressions.equal(\"field1\", 1));\n+\n+    Assert.assertEquals(expected.op(), not.op());\n+    assertPredicatesMatch((UnboundPredicate<?>) expected.child(), (UnboundPredicate<?>) not.child());\n+  }\n+\n+  @Test\n+  public void testLike() {\n+    UnboundPredicate<?> expected = org.apache.iceberg.expressions.Expressions.startsWith(\"field5\", \"abc\");\n+    Expression expr = resolve(ApiExpressionUtils.unresolvedCall(\n+        BuiltInFunctionDefinitions.LIKE, Expressions.$(\"field5\"), Expressions.lit(\"abc%\")));\n+    Optional<org.apache.iceberg.expressions.Expression> actual = FlinkFilters.convert(expr);\n+    Assert.assertTrue(actual.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+  }\n+\n+  private void matchLiteral(String fieldName, Object flinkLiteral, Object icebergLiteral) {\n+    Expression expr = resolve(Expressions.$(fieldName).isEqual(Expressions.lit(flinkLiteral)));\n+    Optional<org.apache.iceberg.expressions.Expression> actual = FlinkFilters.convert(expr);\n+    Assert.assertTrue(actual.isPresent());\n+\n+    BoundLiteralPredicate predicate =", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "originalPosition": 316}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY4NDQ0MjY0", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-568444264", "createdAt": "2021-01-14T17:07:57Z", "commit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzowNzo1N1rOITuYyg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzowNzo1N1rOITuYyg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU1Mzg2Ng==", "bodyText": "These assertions also need context strings to identify which part of the predicate is tested, like \"Predicate operation should match\"", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r557553866", "createdAt": "2021-01-14T17:07:57Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkFilters.java", "diffHunk": "@@ -0,0 +1,361 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.math.BigDecimal;\n+import java.nio.ByteBuffer;\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.stream.Collectors;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.Expressions;\n+import org.apache.flink.table.api.TableColumn;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.expressions.ApiExpressionUtils;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.Expression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.UnresolvedCallExpression;\n+import org.apache.flink.table.expressions.UnresolvedReferenceExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.expressions.utils.ApiExpressionDefaultVisitor;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.iceberg.expressions.And;\n+import org.apache.iceberg.expressions.BoundLiteralPredicate;\n+import org.apache.iceberg.expressions.Not;\n+import org.apache.iceberg.expressions.Or;\n+import org.apache.iceberg.expressions.UnboundPredicate;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n+import org.apache.iceberg.util.DateTimeUtil;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestFlinkFilters {\n+\n+  private static final TableSchema TABLE_SCHEMA = TableSchema.builder()\n+      .field(\"field1\", DataTypes.INT())\n+      .field(\"field2\", DataTypes.BIGINT())\n+      .field(\"field3\", DataTypes.FLOAT())\n+      .field(\"field4\", DataTypes.DOUBLE())\n+      .field(\"field5\", DataTypes.STRING())\n+      .field(\"field6\", DataTypes.BOOLEAN())\n+      .field(\"field7\", DataTypes.BINARY(2))\n+      .field(\"field8\", DataTypes.DECIMAL(10, 2))\n+      .field(\"field9\", DataTypes.DATE())\n+      .field(\"field10\", DataTypes.TIME())\n+      .field(\"field11\", DataTypes.TIMESTAMP())\n+      .field(\"field12\", DataTypes.TIMESTAMP_WITH_LOCAL_TIME_ZONE())\n+      .build();\n+\n+  // A map list of fields and values used to verify the conversion of flink expression to iceberg expression\n+  private static final List<Tuple2<String, Object>> FIELD_VALUE_LIST = ImmutableList.of(\n+      Tuple2.of(\"field1\", 1),\n+      Tuple2.of(\"field2\", 2L),\n+      Tuple2.of(\"field3\", 3F),\n+      Tuple2.of(\"field4\", 4D),\n+      Tuple2.of(\"field5\", \"iceberg\"),\n+      Tuple2.of(\"field6\", true),\n+      Tuple2.of(\"field7\", new byte[] {'a', 'b'}),\n+      Tuple2.of(\"field8\", BigDecimal.valueOf(10)),\n+      Tuple2.of(\"field9\", DateTimeUtil.daysFromDate(LocalDate.now())),\n+      Tuple2.of(\"field10\", DateTimeUtil.microsFromTime(LocalTime.now())),\n+      Tuple2.of(\"field11\", DateTimeUtil.microsFromTimestamp(LocalDateTime.now())),\n+      Tuple2.of(\"field12\", DateTimeUtil.microsFromInstant(Instant.now()))\n+  );\n+\n+  @Test\n+  public void testFlinkDataTypeEqual() {\n+    matchLiteral(\"field1\", 1, 1);\n+    matchLiteral(\"field2\", 10L, 10L);\n+    matchLiteral(\"field3\", 1.2F, 1.2F);\n+    matchLiteral(\"field4\", 3.4D, 3.4D);\n+    matchLiteral(\"field5\", \"abcd\", \"abcd\");\n+    matchLiteral(\"field6\", true, true);\n+    matchLiteral(\"field7\", new byte[] {'a', 'b'}, ByteBuffer.wrap(new byte[] {'a', 'b'}));\n+    matchLiteral(\"field8\", BigDecimal.valueOf(10), BigDecimal.valueOf(10));\n+\n+    LocalDate date = LocalDate.parse(\"2020-12-23\");\n+    matchLiteral(\"field9\", date, DateTimeUtil.daysFromDate(date));\n+\n+    LocalTime time = LocalTime.parse(\"12:13:14\");\n+    matchLiteral(\"field10\", time, DateTimeUtil.microsFromTime(time));\n+\n+    LocalDateTime dateTime = LocalDateTime.parse(\"2020-12-23T12:13:14\");\n+    matchLiteral(\"field11\", dateTime, DateTimeUtil.microsFromTimestamp(dateTime));\n+\n+    Instant instant = Instant.parse(\"2020-12-23T12:13:14.00Z\");\n+    matchLiteral(\"field12\", instant, DateTimeUtil.microsFromInstant(instant));\n+  }\n+\n+  @Test\n+  public void testEquals() {\n+    for (Tuple2<String, Object> tuple2 : FIELD_VALUE_LIST) {\n+      UnboundPredicate<?> expected = org.apache.iceberg.expressions.Expressions.equal(tuple2.f0, tuple2.f1);\n+\n+      Optional<org.apache.iceberg.expressions.Expression> actual =\n+          FlinkFilters.convert(resolve(Expressions.$(tuple2.f0).isEqual(Expressions.lit(tuple2.f1))));\n+      Assert.assertTrue(actual.isPresent());\n+      assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+\n+      Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+          FlinkFilters.convert(resolve(Expressions.lit(tuple2.f1).isEqual(Expressions.$(tuple2.f0))));\n+      Assert.assertTrue(actual1.isPresent());\n+      assertPredicatesMatch(expected, (UnboundPredicate<?>) actual1.get());\n+    }\n+  }\n+\n+  @Test\n+  public void testEqualsNaN() {\n+    UnboundPredicate<Float> expected = org.apache.iceberg.expressions.Expressions.isNaN(\"field3\");\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field3\").isEqual(Expressions.lit(Float.NaN))));\n+    Assert.assertTrue(actual.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(Float.NaN).isEqual(Expressions.$(\"field3\"))));\n+    Assert.assertTrue(actual1.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual1.get());\n+  }\n+\n+  @Test\n+  public void testNotEquals() {\n+    for (Tuple2<String, Object> tuple2 : FIELD_VALUE_LIST) {\n+      UnboundPredicate<?> expected = org.apache.iceberg.expressions.Expressions.notEqual(tuple2.f0, tuple2.f1);\n+\n+      Optional<org.apache.iceberg.expressions.Expression> actual =\n+          FlinkFilters.convert(resolve(Expressions.$(tuple2.f0).isNotEqual(Expressions.lit(tuple2.f1))));\n+      Assert.assertTrue(actual.isPresent());\n+      assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+\n+      Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+          FlinkFilters.convert(resolve(Expressions.lit(tuple2.f1).isNotEqual(Expressions.$(tuple2.f0))));\n+      Assert.assertTrue(actual1.isPresent());\n+      assertPredicatesMatch(expected, (UnboundPredicate<?>) actual1.get());\n+    }\n+  }\n+\n+  @Test\n+  public void testNotEqualsNaN() {\n+    UnboundPredicate<Float> expected = org.apache.iceberg.expressions.Expressions.notNaN(\"field3\");\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field3\").isNotEqual(Expressions.lit(Float.NaN))));\n+    Assert.assertTrue(actual.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(Float.NaN).isNotEqual(Expressions.$(\"field3\"))));\n+    Assert.assertTrue(actual1.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual1.get());\n+  }\n+\n+  @Test\n+  public void testGreaterThan() {\n+    UnboundPredicate<Integer> expected = org.apache.iceberg.expressions.Expressions.greaterThan(\"field1\", 1);\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field1\").isGreater(Expressions.lit(1))));\n+    Assert.assertTrue(actual.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(1).isLess(Expressions.$(\"field1\"))));\n+    Assert.assertTrue(actual1.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual1.get());\n+  }\n+\n+  @Test\n+  public void testGreaterThanEquals() {\n+    UnboundPredicate<Integer> expected = org.apache.iceberg.expressions.Expressions.greaterThanOrEqual(\"field1\", 1);\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field1\").isGreaterOrEqual(Expressions.lit(1))));\n+    Assert.assertTrue(actual.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(1).isLessOrEqual(Expressions.$(\"field1\"))));\n+    Assert.assertTrue(actual1.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual1.get());\n+  }\n+\n+  @Test\n+  public void testLessThan() {\n+    UnboundPredicate<Integer> expected = org.apache.iceberg.expressions.Expressions.lessThan(\"field1\", 1);\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field1\").isLess(Expressions.lit(1))));\n+    Assert.assertTrue(actual.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(1).isGreater(Expressions.$(\"field1\"))));\n+    Assert.assertTrue(actual1.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual1.get());\n+  }\n+\n+  @Test\n+  public void testLessThanEquals() {\n+    UnboundPredicate<Integer> expected = org.apache.iceberg.expressions.Expressions.lessThanOrEqual(\"field1\", 1);\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field1\").isLessOrEqual(Expressions.lit(1))));\n+    Assert.assertTrue(actual.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(1).isGreaterOrEqual(Expressions.$(\"field1\"))));\n+    Assert.assertTrue(actual1.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual1.get());\n+  }\n+\n+  @Test\n+  public void testIsNull() {\n+    Expression expr = resolve(Expressions.$(\"field1\").isNull());\n+    Optional<org.apache.iceberg.expressions.Expression> actual = FlinkFilters.convert(expr);\n+    Assert.assertTrue(actual.isPresent());\n+    UnboundPredicate<Object> expected = org.apache.iceberg.expressions.Expressions.isNull(\"field1\");\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+  }\n+\n+  @Test\n+  public void testIsNotNull() {\n+    Expression expr = resolve(Expressions.$(\"field1\").isNotNull());\n+    Optional<org.apache.iceberg.expressions.Expression> actual = FlinkFilters.convert(expr);\n+    Assert.assertTrue(actual.isPresent());\n+    UnboundPredicate<Object> expected = org.apache.iceberg.expressions.Expressions.notNull(\"field1\");\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+  }\n+\n+  @Test\n+  public void testAnd() {\n+    Expression expr = resolve(\n+        Expressions.$(\"field1\").isEqual(Expressions.lit(1)).and(Expressions.$(\"field2\").isEqual(Expressions.lit(2L))));\n+    Optional<org.apache.iceberg.expressions.Expression> actual = FlinkFilters.convert(expr);\n+    Assert.assertTrue(actual.isPresent());\n+    And and = (And) actual.get();\n+    And expected = (And) org.apache.iceberg.expressions.Expressions.and(\n+        org.apache.iceberg.expressions.Expressions.equal(\"field1\", 1),\n+        org.apache.iceberg.expressions.Expressions.equal(\"field2\", 2L));\n+\n+    Assert.assertEquals(expected.op(), and.op());\n+    Assert.assertEquals(expected.left().op(), and.left().op());\n+    Assert.assertEquals(expected.right().op(), and.right().op());\n+  }\n+\n+  @Test\n+  public void testOr() {\n+    Expression expr = resolve(\n+        Expressions.$(\"field1\").isEqual(Expressions.lit(1)).or(Expressions.$(\"field2\").isEqual(Expressions.lit(2L))));\n+    Optional<org.apache.iceberg.expressions.Expression> actual = FlinkFilters.convert(expr);\n+    Assert.assertTrue(actual.isPresent());\n+    Or or = (Or) actual.get();\n+    Or expected = (Or) org.apache.iceberg.expressions.Expressions.or(\n+        org.apache.iceberg.expressions.Expressions.equal(\"field1\", 1),\n+        org.apache.iceberg.expressions.Expressions.equal(\"field2\", 2L));\n+\n+    Assert.assertEquals(expected.op(), or.op());\n+    Assert.assertEquals(expected.left().op(), or.left().op());\n+    Assert.assertEquals(expected.right().op(), or.right().op());\n+  }\n+\n+  @Test\n+  public void testNot() {\n+    Expression expr = resolve(ApiExpressionUtils.unresolvedCall(\n+        BuiltInFunctionDefinitions.NOT, Expressions.$(\"field1\").isEqual(Expressions.lit(1))));\n+    Optional<org.apache.iceberg.expressions.Expression> actual = FlinkFilters.convert(expr);\n+    Assert.assertTrue(actual.isPresent());\n+    Not not = (Not) actual.get();\n+    Not expected = (Not) org.apache.iceberg.expressions.Expressions.not(\n+        org.apache.iceberg.expressions.Expressions.equal(\"field1\", 1));\n+\n+    Assert.assertEquals(expected.op(), not.op());\n+    assertPredicatesMatch((UnboundPredicate<?>) expected.child(), (UnboundPredicate<?>) not.child());\n+  }\n+\n+  @Test\n+  public void testLike() {\n+    UnboundPredicate<?> expected = org.apache.iceberg.expressions.Expressions.startsWith(\"field5\", \"abc\");\n+    Expression expr = resolve(ApiExpressionUtils.unresolvedCall(\n+        BuiltInFunctionDefinitions.LIKE, Expressions.$(\"field5\"), Expressions.lit(\"abc%\")));\n+    Optional<org.apache.iceberg.expressions.Expression> actual = FlinkFilters.convert(expr);\n+    Assert.assertTrue(actual.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+  }\n+\n+  private void matchLiteral(String fieldName, Object flinkLiteral, Object icebergLiteral) {\n+    Expression expr = resolve(Expressions.$(fieldName).isEqual(Expressions.lit(flinkLiteral)));\n+    Optional<org.apache.iceberg.expressions.Expression> actual = FlinkFilters.convert(expr);\n+    Assert.assertTrue(actual.isPresent());\n+\n+    BoundLiteralPredicate predicate =\n+        (BoundLiteralPredicate<?>) ((UnboundPredicate<?>) actual.get())\n+            .bind(FlinkSchemaUtil.convert(TABLE_SCHEMA).asStruct(), false);\n+    Assert.assertTrue(predicate.test(icebergLiteral));\n+  }\n+\n+  private static Expression resolve(Expression originalExpression) {\n+    return originalExpression.accept(new ApiExpressionDefaultVisitor<Expression>() {\n+      @Override\n+      public Expression visit(UnresolvedReferenceExpression unresolvedReference) {\n+        String name = unresolvedReference.getName();\n+        Optional<TableColumn> field = TABLE_SCHEMA.getTableColumn(name);\n+        if (field.isPresent()) {\n+          int index = TABLE_SCHEMA.getTableColumns().indexOf(field.get());\n+          return new FieldReferenceExpression(name, field.get().getType(), 0, index);\n+        } else {\n+          return null;\n+        }\n+      }\n+\n+      @Override\n+      public Expression visit(UnresolvedCallExpression unresolvedCall) {\n+        List<ResolvedExpression> children =\n+            unresolvedCall.getChildren().stream().map(e -> (ResolvedExpression) e.accept(this))\n+                .collect(Collectors.toList());\n+        return new CallExpression(unresolvedCall.getFunctionDefinition(), children, DataTypes.STRING());\n+      }\n+\n+      @Override\n+      public Expression visit(ValueLiteralExpression valueLiteral) {\n+        return valueLiteral;\n+      }\n+\n+      @Override\n+      protected Expression defaultMethod(Expression expression) {\n+        throw new UnsupportedOperationException(String.format(\"unsupported expression: %s\", expression));\n+      }\n+    });\n+  }\n+\n+  private void assertPredicatesMatch(UnboundPredicate<?> expected, UnboundPredicate<?> actual) {\n+    Assert.assertEquals(expected.op(), actual.op());\n+    Assert.assertEquals(expected.literal(), actual.literal());\n+    Assert.assertEquals(expected.ref().name(), actual.ref().name());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "originalPosition": 359}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY4NDQ1NDY0", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-568445464", "createdAt": "2021-01-14T17:09:17Z", "commit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzowOToxN1rOITuceQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzowOToxN1rOITuceQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU1NDgwOQ==", "bodyText": "valueOf creates a decimal with a scale of 0, but the type's scale is 2. Can you create a big decimal that matches the type?", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r557554809", "createdAt": "2021-01-14T17:09:17Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkFilters.java", "diffHunk": "@@ -0,0 +1,361 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.math.BigDecimal;\n+import java.nio.ByteBuffer;\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.stream.Collectors;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.Expressions;\n+import org.apache.flink.table.api.TableColumn;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.expressions.ApiExpressionUtils;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.Expression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.UnresolvedCallExpression;\n+import org.apache.flink.table.expressions.UnresolvedReferenceExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.expressions.utils.ApiExpressionDefaultVisitor;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.iceberg.expressions.And;\n+import org.apache.iceberg.expressions.BoundLiteralPredicate;\n+import org.apache.iceberg.expressions.Not;\n+import org.apache.iceberg.expressions.Or;\n+import org.apache.iceberg.expressions.UnboundPredicate;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n+import org.apache.iceberg.util.DateTimeUtil;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestFlinkFilters {\n+\n+  private static final TableSchema TABLE_SCHEMA = TableSchema.builder()\n+      .field(\"field1\", DataTypes.INT())\n+      .field(\"field2\", DataTypes.BIGINT())\n+      .field(\"field3\", DataTypes.FLOAT())\n+      .field(\"field4\", DataTypes.DOUBLE())\n+      .field(\"field5\", DataTypes.STRING())\n+      .field(\"field6\", DataTypes.BOOLEAN())\n+      .field(\"field7\", DataTypes.BINARY(2))\n+      .field(\"field8\", DataTypes.DECIMAL(10, 2))\n+      .field(\"field9\", DataTypes.DATE())\n+      .field(\"field10\", DataTypes.TIME())\n+      .field(\"field11\", DataTypes.TIMESTAMP())\n+      .field(\"field12\", DataTypes.TIMESTAMP_WITH_LOCAL_TIME_ZONE())\n+      .build();\n+\n+  // A map list of fields and values used to verify the conversion of flink expression to iceberg expression\n+  private static final List<Tuple2<String, Object>> FIELD_VALUE_LIST = ImmutableList.of(\n+      Tuple2.of(\"field1\", 1),\n+      Tuple2.of(\"field2\", 2L),\n+      Tuple2.of(\"field3\", 3F),\n+      Tuple2.of(\"field4\", 4D),\n+      Tuple2.of(\"field5\", \"iceberg\"),\n+      Tuple2.of(\"field6\", true),\n+      Tuple2.of(\"field7\", new byte[] {'a', 'b'}),\n+      Tuple2.of(\"field8\", BigDecimal.valueOf(10)),\n+      Tuple2.of(\"field9\", DateTimeUtil.daysFromDate(LocalDate.now())),\n+      Tuple2.of(\"field10\", DateTimeUtil.microsFromTime(LocalTime.now())),\n+      Tuple2.of(\"field11\", DateTimeUtil.microsFromTimestamp(LocalDateTime.now())),\n+      Tuple2.of(\"field12\", DateTimeUtil.microsFromInstant(Instant.now()))\n+  );\n+\n+  @Test\n+  public void testFlinkDataTypeEqual() {\n+    matchLiteral(\"field1\", 1, 1);\n+    matchLiteral(\"field2\", 10L, 10L);\n+    matchLiteral(\"field3\", 1.2F, 1.2F);\n+    matchLiteral(\"field4\", 3.4D, 3.4D);\n+    matchLiteral(\"field5\", \"abcd\", \"abcd\");\n+    matchLiteral(\"field6\", true, true);\n+    matchLiteral(\"field7\", new byte[] {'a', 'b'}, ByteBuffer.wrap(new byte[] {'a', 'b'}));\n+    matchLiteral(\"field8\", BigDecimal.valueOf(10), BigDecimal.valueOf(10));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "originalPosition": 98}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY4NDQ2MjAw", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-568446200", "createdAt": "2021-01-14T17:10:07Z", "commit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzoxMDowN1rOITuejw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzoxMDowN1rOITuejw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU1NTM0Mw==", "bodyText": "Could you update this to use the Iceberg Pair class instead?", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r557555343", "createdAt": "2021-01-14T17:10:07Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkFilters.java", "diffHunk": "@@ -0,0 +1,361 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.math.BigDecimal;\n+import java.nio.ByteBuffer;\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.stream.Collectors;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.Expressions;\n+import org.apache.flink.table.api.TableColumn;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.expressions.ApiExpressionUtils;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.Expression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.UnresolvedCallExpression;\n+import org.apache.flink.table.expressions.UnresolvedReferenceExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.expressions.utils.ApiExpressionDefaultVisitor;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.iceberg.expressions.And;\n+import org.apache.iceberg.expressions.BoundLiteralPredicate;\n+import org.apache.iceberg.expressions.Not;\n+import org.apache.iceberg.expressions.Or;\n+import org.apache.iceberg.expressions.UnboundPredicate;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n+import org.apache.iceberg.util.DateTimeUtil;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestFlinkFilters {\n+\n+  private static final TableSchema TABLE_SCHEMA = TableSchema.builder()\n+      .field(\"field1\", DataTypes.INT())\n+      .field(\"field2\", DataTypes.BIGINT())\n+      .field(\"field3\", DataTypes.FLOAT())\n+      .field(\"field4\", DataTypes.DOUBLE())\n+      .field(\"field5\", DataTypes.STRING())\n+      .field(\"field6\", DataTypes.BOOLEAN())\n+      .field(\"field7\", DataTypes.BINARY(2))\n+      .field(\"field8\", DataTypes.DECIMAL(10, 2))\n+      .field(\"field9\", DataTypes.DATE())\n+      .field(\"field10\", DataTypes.TIME())\n+      .field(\"field11\", DataTypes.TIMESTAMP())\n+      .field(\"field12\", DataTypes.TIMESTAMP_WITH_LOCAL_TIME_ZONE())\n+      .build();\n+\n+  // A map list of fields and values used to verify the conversion of flink expression to iceberg expression\n+  private static final List<Tuple2<String, Object>> FIELD_VALUE_LIST = ImmutableList.of(", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "originalPosition": 74}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY4NDQ3Nzkw", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-568447790", "createdAt": "2021-01-14T17:11:53Z", "commit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzoxMTo1M1rOITujCw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzoxMTo1M1rOITujCw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU1NjQ5MQ==", "bodyText": "It would be better to check the cast instead of failing tests with ClassCastException if the wrong class is returned. Could you update assertPredicatesMatch to accept actual as an Expression and add an instanceof assertion in that method?", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r557556491", "createdAt": "2021-01-14T17:11:53Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkFilters.java", "diffHunk": "@@ -0,0 +1,361 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.math.BigDecimal;\n+import java.nio.ByteBuffer;\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.stream.Collectors;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.Expressions;\n+import org.apache.flink.table.api.TableColumn;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.expressions.ApiExpressionUtils;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.Expression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.UnresolvedCallExpression;\n+import org.apache.flink.table.expressions.UnresolvedReferenceExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.expressions.utils.ApiExpressionDefaultVisitor;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.iceberg.expressions.And;\n+import org.apache.iceberg.expressions.BoundLiteralPredicate;\n+import org.apache.iceberg.expressions.Not;\n+import org.apache.iceberg.expressions.Or;\n+import org.apache.iceberg.expressions.UnboundPredicate;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n+import org.apache.iceberg.util.DateTimeUtil;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestFlinkFilters {\n+\n+  private static final TableSchema TABLE_SCHEMA = TableSchema.builder()\n+      .field(\"field1\", DataTypes.INT())\n+      .field(\"field2\", DataTypes.BIGINT())\n+      .field(\"field3\", DataTypes.FLOAT())\n+      .field(\"field4\", DataTypes.DOUBLE())\n+      .field(\"field5\", DataTypes.STRING())\n+      .field(\"field6\", DataTypes.BOOLEAN())\n+      .field(\"field7\", DataTypes.BINARY(2))\n+      .field(\"field8\", DataTypes.DECIMAL(10, 2))\n+      .field(\"field9\", DataTypes.DATE())\n+      .field(\"field10\", DataTypes.TIME())\n+      .field(\"field11\", DataTypes.TIMESTAMP())\n+      .field(\"field12\", DataTypes.TIMESTAMP_WITH_LOCAL_TIME_ZONE())\n+      .build();\n+\n+  // A map list of fields and values used to verify the conversion of flink expression to iceberg expression\n+  private static final List<Tuple2<String, Object>> FIELD_VALUE_LIST = ImmutableList.of(\n+      Tuple2.of(\"field1\", 1),\n+      Tuple2.of(\"field2\", 2L),\n+      Tuple2.of(\"field3\", 3F),\n+      Tuple2.of(\"field4\", 4D),\n+      Tuple2.of(\"field5\", \"iceberg\"),\n+      Tuple2.of(\"field6\", true),\n+      Tuple2.of(\"field7\", new byte[] {'a', 'b'}),\n+      Tuple2.of(\"field8\", BigDecimal.valueOf(10)),\n+      Tuple2.of(\"field9\", DateTimeUtil.daysFromDate(LocalDate.now())),\n+      Tuple2.of(\"field10\", DateTimeUtil.microsFromTime(LocalTime.now())),\n+      Tuple2.of(\"field11\", DateTimeUtil.microsFromTimestamp(LocalDateTime.now())),\n+      Tuple2.of(\"field12\", DateTimeUtil.microsFromInstant(Instant.now()))\n+  );\n+\n+  @Test\n+  public void testFlinkDataTypeEqual() {\n+    matchLiteral(\"field1\", 1, 1);\n+    matchLiteral(\"field2\", 10L, 10L);\n+    matchLiteral(\"field3\", 1.2F, 1.2F);\n+    matchLiteral(\"field4\", 3.4D, 3.4D);\n+    matchLiteral(\"field5\", \"abcd\", \"abcd\");\n+    matchLiteral(\"field6\", true, true);\n+    matchLiteral(\"field7\", new byte[] {'a', 'b'}, ByteBuffer.wrap(new byte[] {'a', 'b'}));\n+    matchLiteral(\"field8\", BigDecimal.valueOf(10), BigDecimal.valueOf(10));\n+\n+    LocalDate date = LocalDate.parse(\"2020-12-23\");\n+    matchLiteral(\"field9\", date, DateTimeUtil.daysFromDate(date));\n+\n+    LocalTime time = LocalTime.parse(\"12:13:14\");\n+    matchLiteral(\"field10\", time, DateTimeUtil.microsFromTime(time));\n+\n+    LocalDateTime dateTime = LocalDateTime.parse(\"2020-12-23T12:13:14\");\n+    matchLiteral(\"field11\", dateTime, DateTimeUtil.microsFromTimestamp(dateTime));\n+\n+    Instant instant = Instant.parse(\"2020-12-23T12:13:14.00Z\");\n+    matchLiteral(\"field12\", instant, DateTimeUtil.microsFromInstant(instant));\n+  }\n+\n+  @Test\n+  public void testEquals() {\n+    for (Tuple2<String, Object> tuple2 : FIELD_VALUE_LIST) {\n+      UnboundPredicate<?> expected = org.apache.iceberg.expressions.Expressions.equal(tuple2.f0, tuple2.f1);\n+\n+      Optional<org.apache.iceberg.expressions.Expression> actual =\n+          FlinkFilters.convert(resolve(Expressions.$(tuple2.f0).isEqual(Expressions.lit(tuple2.f1))));\n+      Assert.assertTrue(actual.isPresent());\n+      assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+\n+      Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+          FlinkFilters.convert(resolve(Expressions.lit(tuple2.f1).isEqual(Expressions.$(tuple2.f0))));\n+      Assert.assertTrue(actual1.isPresent());\n+      assertPredicatesMatch(expected, (UnboundPredicate<?>) actual1.get());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "originalPosition": 126}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY4NDUxMTEw", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-568451110", "createdAt": "2021-01-14T17:15:45Z", "commit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzoxNTo0NVrOITusoA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzoxNTo0NVrOITusoA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU1ODk0NA==", "bodyText": "I think these should use assertPredicatesMatch instead of just checking the operation.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r557558944", "createdAt": "2021-01-14T17:15:45Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkFilters.java", "diffHunk": "@@ -0,0 +1,361 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.math.BigDecimal;\n+import java.nio.ByteBuffer;\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.stream.Collectors;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.Expressions;\n+import org.apache.flink.table.api.TableColumn;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.expressions.ApiExpressionUtils;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.Expression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.UnresolvedCallExpression;\n+import org.apache.flink.table.expressions.UnresolvedReferenceExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.expressions.utils.ApiExpressionDefaultVisitor;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.iceberg.expressions.And;\n+import org.apache.iceberg.expressions.BoundLiteralPredicate;\n+import org.apache.iceberg.expressions.Not;\n+import org.apache.iceberg.expressions.Or;\n+import org.apache.iceberg.expressions.UnboundPredicate;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n+import org.apache.iceberg.util.DateTimeUtil;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestFlinkFilters {\n+\n+  private static final TableSchema TABLE_SCHEMA = TableSchema.builder()\n+      .field(\"field1\", DataTypes.INT())\n+      .field(\"field2\", DataTypes.BIGINT())\n+      .field(\"field3\", DataTypes.FLOAT())\n+      .field(\"field4\", DataTypes.DOUBLE())\n+      .field(\"field5\", DataTypes.STRING())\n+      .field(\"field6\", DataTypes.BOOLEAN())\n+      .field(\"field7\", DataTypes.BINARY(2))\n+      .field(\"field8\", DataTypes.DECIMAL(10, 2))\n+      .field(\"field9\", DataTypes.DATE())\n+      .field(\"field10\", DataTypes.TIME())\n+      .field(\"field11\", DataTypes.TIMESTAMP())\n+      .field(\"field12\", DataTypes.TIMESTAMP_WITH_LOCAL_TIME_ZONE())\n+      .build();\n+\n+  // A map list of fields and values used to verify the conversion of flink expression to iceberg expression\n+  private static final List<Tuple2<String, Object>> FIELD_VALUE_LIST = ImmutableList.of(\n+      Tuple2.of(\"field1\", 1),\n+      Tuple2.of(\"field2\", 2L),\n+      Tuple2.of(\"field3\", 3F),\n+      Tuple2.of(\"field4\", 4D),\n+      Tuple2.of(\"field5\", \"iceberg\"),\n+      Tuple2.of(\"field6\", true),\n+      Tuple2.of(\"field7\", new byte[] {'a', 'b'}),\n+      Tuple2.of(\"field8\", BigDecimal.valueOf(10)),\n+      Tuple2.of(\"field9\", DateTimeUtil.daysFromDate(LocalDate.now())),\n+      Tuple2.of(\"field10\", DateTimeUtil.microsFromTime(LocalTime.now())),\n+      Tuple2.of(\"field11\", DateTimeUtil.microsFromTimestamp(LocalDateTime.now())),\n+      Tuple2.of(\"field12\", DateTimeUtil.microsFromInstant(Instant.now()))\n+  );\n+\n+  @Test\n+  public void testFlinkDataTypeEqual() {\n+    matchLiteral(\"field1\", 1, 1);\n+    matchLiteral(\"field2\", 10L, 10L);\n+    matchLiteral(\"field3\", 1.2F, 1.2F);\n+    matchLiteral(\"field4\", 3.4D, 3.4D);\n+    matchLiteral(\"field5\", \"abcd\", \"abcd\");\n+    matchLiteral(\"field6\", true, true);\n+    matchLiteral(\"field7\", new byte[] {'a', 'b'}, ByteBuffer.wrap(new byte[] {'a', 'b'}));\n+    matchLiteral(\"field8\", BigDecimal.valueOf(10), BigDecimal.valueOf(10));\n+\n+    LocalDate date = LocalDate.parse(\"2020-12-23\");\n+    matchLiteral(\"field9\", date, DateTimeUtil.daysFromDate(date));\n+\n+    LocalTime time = LocalTime.parse(\"12:13:14\");\n+    matchLiteral(\"field10\", time, DateTimeUtil.microsFromTime(time));\n+\n+    LocalDateTime dateTime = LocalDateTime.parse(\"2020-12-23T12:13:14\");\n+    matchLiteral(\"field11\", dateTime, DateTimeUtil.microsFromTimestamp(dateTime));\n+\n+    Instant instant = Instant.parse(\"2020-12-23T12:13:14.00Z\");\n+    matchLiteral(\"field12\", instant, DateTimeUtil.microsFromInstant(instant));\n+  }\n+\n+  @Test\n+  public void testEquals() {\n+    for (Tuple2<String, Object> tuple2 : FIELD_VALUE_LIST) {\n+      UnboundPredicate<?> expected = org.apache.iceberg.expressions.Expressions.equal(tuple2.f0, tuple2.f1);\n+\n+      Optional<org.apache.iceberg.expressions.Expression> actual =\n+          FlinkFilters.convert(resolve(Expressions.$(tuple2.f0).isEqual(Expressions.lit(tuple2.f1))));\n+      Assert.assertTrue(actual.isPresent());\n+      assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+\n+      Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+          FlinkFilters.convert(resolve(Expressions.lit(tuple2.f1).isEqual(Expressions.$(tuple2.f0))));\n+      Assert.assertTrue(actual1.isPresent());\n+      assertPredicatesMatch(expected, (UnboundPredicate<?>) actual1.get());\n+    }\n+  }\n+\n+  @Test\n+  public void testEqualsNaN() {\n+    UnboundPredicate<Float> expected = org.apache.iceberg.expressions.Expressions.isNaN(\"field3\");\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field3\").isEqual(Expressions.lit(Float.NaN))));\n+    Assert.assertTrue(actual.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(Float.NaN).isEqual(Expressions.$(\"field3\"))));\n+    Assert.assertTrue(actual1.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual1.get());\n+  }\n+\n+  @Test\n+  public void testNotEquals() {\n+    for (Tuple2<String, Object> tuple2 : FIELD_VALUE_LIST) {\n+      UnboundPredicate<?> expected = org.apache.iceberg.expressions.Expressions.notEqual(tuple2.f0, tuple2.f1);\n+\n+      Optional<org.apache.iceberg.expressions.Expression> actual =\n+          FlinkFilters.convert(resolve(Expressions.$(tuple2.f0).isNotEqual(Expressions.lit(tuple2.f1))));\n+      Assert.assertTrue(actual.isPresent());\n+      assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+\n+      Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+          FlinkFilters.convert(resolve(Expressions.lit(tuple2.f1).isNotEqual(Expressions.$(tuple2.f0))));\n+      Assert.assertTrue(actual1.isPresent());\n+      assertPredicatesMatch(expected, (UnboundPredicate<?>) actual1.get());\n+    }\n+  }\n+\n+  @Test\n+  public void testNotEqualsNaN() {\n+    UnboundPredicate<Float> expected = org.apache.iceberg.expressions.Expressions.notNaN(\"field3\");\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field3\").isNotEqual(Expressions.lit(Float.NaN))));\n+    Assert.assertTrue(actual.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(Float.NaN).isNotEqual(Expressions.$(\"field3\"))));\n+    Assert.assertTrue(actual1.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual1.get());\n+  }\n+\n+  @Test\n+  public void testGreaterThan() {\n+    UnboundPredicate<Integer> expected = org.apache.iceberg.expressions.Expressions.greaterThan(\"field1\", 1);\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field1\").isGreater(Expressions.lit(1))));\n+    Assert.assertTrue(actual.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(1).isLess(Expressions.$(\"field1\"))));\n+    Assert.assertTrue(actual1.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual1.get());\n+  }\n+\n+  @Test\n+  public void testGreaterThanEquals() {\n+    UnboundPredicate<Integer> expected = org.apache.iceberg.expressions.Expressions.greaterThanOrEqual(\"field1\", 1);\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field1\").isGreaterOrEqual(Expressions.lit(1))));\n+    Assert.assertTrue(actual.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(1).isLessOrEqual(Expressions.$(\"field1\"))));\n+    Assert.assertTrue(actual1.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual1.get());\n+  }\n+\n+  @Test\n+  public void testLessThan() {\n+    UnboundPredicate<Integer> expected = org.apache.iceberg.expressions.Expressions.lessThan(\"field1\", 1);\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field1\").isLess(Expressions.lit(1))));\n+    Assert.assertTrue(actual.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(1).isGreater(Expressions.$(\"field1\"))));\n+    Assert.assertTrue(actual1.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual1.get());\n+  }\n+\n+  @Test\n+  public void testLessThanEquals() {\n+    UnboundPredicate<Integer> expected = org.apache.iceberg.expressions.Expressions.lessThanOrEqual(\"field1\", 1);\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field1\").isLessOrEqual(Expressions.lit(1))));\n+    Assert.assertTrue(actual.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(1).isGreaterOrEqual(Expressions.$(\"field1\"))));\n+    Assert.assertTrue(actual1.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual1.get());\n+  }\n+\n+  @Test\n+  public void testIsNull() {\n+    Expression expr = resolve(Expressions.$(\"field1\").isNull());\n+    Optional<org.apache.iceberg.expressions.Expression> actual = FlinkFilters.convert(expr);\n+    Assert.assertTrue(actual.isPresent());\n+    UnboundPredicate<Object> expected = org.apache.iceberg.expressions.Expressions.isNull(\"field1\");\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+  }\n+\n+  @Test\n+  public void testIsNotNull() {\n+    Expression expr = resolve(Expressions.$(\"field1\").isNotNull());\n+    Optional<org.apache.iceberg.expressions.Expression> actual = FlinkFilters.convert(expr);\n+    Assert.assertTrue(actual.isPresent());\n+    UnboundPredicate<Object> expected = org.apache.iceberg.expressions.Expressions.notNull(\"field1\");\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+  }\n+\n+  @Test\n+  public void testAnd() {\n+    Expression expr = resolve(\n+        Expressions.$(\"field1\").isEqual(Expressions.lit(1)).and(Expressions.$(\"field2\").isEqual(Expressions.lit(2L))));\n+    Optional<org.apache.iceberg.expressions.Expression> actual = FlinkFilters.convert(expr);\n+    Assert.assertTrue(actual.isPresent());\n+    And and = (And) actual.get();\n+    And expected = (And) org.apache.iceberg.expressions.Expressions.and(\n+        org.apache.iceberg.expressions.Expressions.equal(\"field1\", 1),\n+        org.apache.iceberg.expressions.Expressions.equal(\"field2\", 2L));\n+\n+    Assert.assertEquals(expected.op(), and.op());\n+    Assert.assertEquals(expected.left().op(), and.left().op());\n+    Assert.assertEquals(expected.right().op(), and.right().op());\n+  }\n+\n+  @Test\n+  public void testOr() {\n+    Expression expr = resolve(\n+        Expressions.$(\"field1\").isEqual(Expressions.lit(1)).or(Expressions.$(\"field2\").isEqual(Expressions.lit(2L))));\n+    Optional<org.apache.iceberg.expressions.Expression> actual = FlinkFilters.convert(expr);\n+    Assert.assertTrue(actual.isPresent());\n+    Or or = (Or) actual.get();\n+    Or expected = (Or) org.apache.iceberg.expressions.Expressions.or(\n+        org.apache.iceberg.expressions.Expressions.equal(\"field1\", 1),\n+        org.apache.iceberg.expressions.Expressions.equal(\"field2\", 2L));\n+\n+    Assert.assertEquals(expected.op(), or.op());\n+    Assert.assertEquals(expected.left().op(), or.left().op());", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "originalPosition": 283}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY4NDUyNjkw", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-568452690", "createdAt": "2021-01-14T17:17:33Z", "commit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzoxNzozM1rOITuxdg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzoxNzozM1rOITuxdg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU2MDE4Mg==", "bodyText": "This suite also needs negative tests for LIKE with different wildcard locations:\n\nThe pattern is \"%abc\"\nThe pattern is \"%abc%\"\nThe pattern is \"abc%d\"\nThe pattern is \"%\"", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r557560182", "createdAt": "2021-01-14T17:17:33Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkFilters.java", "diffHunk": "@@ -0,0 +1,361 @@\n+/*\n+ * Licensed to the Apache Software Foundation (ASF) under one\n+ * or more contributor license agreements.  See the NOTICE file\n+ * distributed with this work for additional information\n+ * regarding copyright ownership.  The ASF licenses this file\n+ * to you under the Apache License, Version 2.0 (the\n+ * \"License\"); you may not use this file except in compliance\n+ * with the License.  You may obtain a copy of the License at\n+ *\n+ *   http://www.apache.org/licenses/LICENSE-2.0\n+ *\n+ * Unless required by applicable law or agreed to in writing,\n+ * software distributed under the License is distributed on an\n+ * \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY\n+ * KIND, either express or implied.  See the License for the\n+ * specific language governing permissions and limitations\n+ * under the License.\n+ */\n+\n+package org.apache.iceberg.flink;\n+\n+import java.math.BigDecimal;\n+import java.nio.ByteBuffer;\n+import java.time.Instant;\n+import java.time.LocalDate;\n+import java.time.LocalDateTime;\n+import java.time.LocalTime;\n+import java.util.List;\n+import java.util.Optional;\n+import java.util.stream.Collectors;\n+import org.apache.flink.api.java.tuple.Tuple2;\n+import org.apache.flink.table.api.DataTypes;\n+import org.apache.flink.table.api.Expressions;\n+import org.apache.flink.table.api.TableColumn;\n+import org.apache.flink.table.api.TableSchema;\n+import org.apache.flink.table.expressions.ApiExpressionUtils;\n+import org.apache.flink.table.expressions.CallExpression;\n+import org.apache.flink.table.expressions.Expression;\n+import org.apache.flink.table.expressions.FieldReferenceExpression;\n+import org.apache.flink.table.expressions.ResolvedExpression;\n+import org.apache.flink.table.expressions.UnresolvedCallExpression;\n+import org.apache.flink.table.expressions.UnresolvedReferenceExpression;\n+import org.apache.flink.table.expressions.ValueLiteralExpression;\n+import org.apache.flink.table.expressions.utils.ApiExpressionDefaultVisitor;\n+import org.apache.flink.table.functions.BuiltInFunctionDefinitions;\n+import org.apache.iceberg.expressions.And;\n+import org.apache.iceberg.expressions.BoundLiteralPredicate;\n+import org.apache.iceberg.expressions.Not;\n+import org.apache.iceberg.expressions.Or;\n+import org.apache.iceberg.expressions.UnboundPredicate;\n+import org.apache.iceberg.relocated.com.google.common.collect.ImmutableList;\n+import org.apache.iceberg.util.DateTimeUtil;\n+import org.junit.Assert;\n+import org.junit.Test;\n+\n+public class TestFlinkFilters {\n+\n+  private static final TableSchema TABLE_SCHEMA = TableSchema.builder()\n+      .field(\"field1\", DataTypes.INT())\n+      .field(\"field2\", DataTypes.BIGINT())\n+      .field(\"field3\", DataTypes.FLOAT())\n+      .field(\"field4\", DataTypes.DOUBLE())\n+      .field(\"field5\", DataTypes.STRING())\n+      .field(\"field6\", DataTypes.BOOLEAN())\n+      .field(\"field7\", DataTypes.BINARY(2))\n+      .field(\"field8\", DataTypes.DECIMAL(10, 2))\n+      .field(\"field9\", DataTypes.DATE())\n+      .field(\"field10\", DataTypes.TIME())\n+      .field(\"field11\", DataTypes.TIMESTAMP())\n+      .field(\"field12\", DataTypes.TIMESTAMP_WITH_LOCAL_TIME_ZONE())\n+      .build();\n+\n+  // A map list of fields and values used to verify the conversion of flink expression to iceberg expression\n+  private static final List<Tuple2<String, Object>> FIELD_VALUE_LIST = ImmutableList.of(\n+      Tuple2.of(\"field1\", 1),\n+      Tuple2.of(\"field2\", 2L),\n+      Tuple2.of(\"field3\", 3F),\n+      Tuple2.of(\"field4\", 4D),\n+      Tuple2.of(\"field5\", \"iceberg\"),\n+      Tuple2.of(\"field6\", true),\n+      Tuple2.of(\"field7\", new byte[] {'a', 'b'}),\n+      Tuple2.of(\"field8\", BigDecimal.valueOf(10)),\n+      Tuple2.of(\"field9\", DateTimeUtil.daysFromDate(LocalDate.now())),\n+      Tuple2.of(\"field10\", DateTimeUtil.microsFromTime(LocalTime.now())),\n+      Tuple2.of(\"field11\", DateTimeUtil.microsFromTimestamp(LocalDateTime.now())),\n+      Tuple2.of(\"field12\", DateTimeUtil.microsFromInstant(Instant.now()))\n+  );\n+\n+  @Test\n+  public void testFlinkDataTypeEqual() {\n+    matchLiteral(\"field1\", 1, 1);\n+    matchLiteral(\"field2\", 10L, 10L);\n+    matchLiteral(\"field3\", 1.2F, 1.2F);\n+    matchLiteral(\"field4\", 3.4D, 3.4D);\n+    matchLiteral(\"field5\", \"abcd\", \"abcd\");\n+    matchLiteral(\"field6\", true, true);\n+    matchLiteral(\"field7\", new byte[] {'a', 'b'}, ByteBuffer.wrap(new byte[] {'a', 'b'}));\n+    matchLiteral(\"field8\", BigDecimal.valueOf(10), BigDecimal.valueOf(10));\n+\n+    LocalDate date = LocalDate.parse(\"2020-12-23\");\n+    matchLiteral(\"field9\", date, DateTimeUtil.daysFromDate(date));\n+\n+    LocalTime time = LocalTime.parse(\"12:13:14\");\n+    matchLiteral(\"field10\", time, DateTimeUtil.microsFromTime(time));\n+\n+    LocalDateTime dateTime = LocalDateTime.parse(\"2020-12-23T12:13:14\");\n+    matchLiteral(\"field11\", dateTime, DateTimeUtil.microsFromTimestamp(dateTime));\n+\n+    Instant instant = Instant.parse(\"2020-12-23T12:13:14.00Z\");\n+    matchLiteral(\"field12\", instant, DateTimeUtil.microsFromInstant(instant));\n+  }\n+\n+  @Test\n+  public void testEquals() {\n+    for (Tuple2<String, Object> tuple2 : FIELD_VALUE_LIST) {\n+      UnboundPredicate<?> expected = org.apache.iceberg.expressions.Expressions.equal(tuple2.f0, tuple2.f1);\n+\n+      Optional<org.apache.iceberg.expressions.Expression> actual =\n+          FlinkFilters.convert(resolve(Expressions.$(tuple2.f0).isEqual(Expressions.lit(tuple2.f1))));\n+      Assert.assertTrue(actual.isPresent());\n+      assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+\n+      Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+          FlinkFilters.convert(resolve(Expressions.lit(tuple2.f1).isEqual(Expressions.$(tuple2.f0))));\n+      Assert.assertTrue(actual1.isPresent());\n+      assertPredicatesMatch(expected, (UnboundPredicate<?>) actual1.get());\n+    }\n+  }\n+\n+  @Test\n+  public void testEqualsNaN() {\n+    UnboundPredicate<Float> expected = org.apache.iceberg.expressions.Expressions.isNaN(\"field3\");\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field3\").isEqual(Expressions.lit(Float.NaN))));\n+    Assert.assertTrue(actual.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(Float.NaN).isEqual(Expressions.$(\"field3\"))));\n+    Assert.assertTrue(actual1.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual1.get());\n+  }\n+\n+  @Test\n+  public void testNotEquals() {\n+    for (Tuple2<String, Object> tuple2 : FIELD_VALUE_LIST) {\n+      UnboundPredicate<?> expected = org.apache.iceberg.expressions.Expressions.notEqual(tuple2.f0, tuple2.f1);\n+\n+      Optional<org.apache.iceberg.expressions.Expression> actual =\n+          FlinkFilters.convert(resolve(Expressions.$(tuple2.f0).isNotEqual(Expressions.lit(tuple2.f1))));\n+      Assert.assertTrue(actual.isPresent());\n+      assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+\n+      Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+          FlinkFilters.convert(resolve(Expressions.lit(tuple2.f1).isNotEqual(Expressions.$(tuple2.f0))));\n+      Assert.assertTrue(actual1.isPresent());\n+      assertPredicatesMatch(expected, (UnboundPredicate<?>) actual1.get());\n+    }\n+  }\n+\n+  @Test\n+  public void testNotEqualsNaN() {\n+    UnboundPredicate<Float> expected = org.apache.iceberg.expressions.Expressions.notNaN(\"field3\");\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field3\").isNotEqual(Expressions.lit(Float.NaN))));\n+    Assert.assertTrue(actual.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(Float.NaN).isNotEqual(Expressions.$(\"field3\"))));\n+    Assert.assertTrue(actual1.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual1.get());\n+  }\n+\n+  @Test\n+  public void testGreaterThan() {\n+    UnboundPredicate<Integer> expected = org.apache.iceberg.expressions.Expressions.greaterThan(\"field1\", 1);\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field1\").isGreater(Expressions.lit(1))));\n+    Assert.assertTrue(actual.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(1).isLess(Expressions.$(\"field1\"))));\n+    Assert.assertTrue(actual1.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual1.get());\n+  }\n+\n+  @Test\n+  public void testGreaterThanEquals() {\n+    UnboundPredicate<Integer> expected = org.apache.iceberg.expressions.Expressions.greaterThanOrEqual(\"field1\", 1);\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field1\").isGreaterOrEqual(Expressions.lit(1))));\n+    Assert.assertTrue(actual.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(1).isLessOrEqual(Expressions.$(\"field1\"))));\n+    Assert.assertTrue(actual1.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual1.get());\n+  }\n+\n+  @Test\n+  public void testLessThan() {\n+    UnboundPredicate<Integer> expected = org.apache.iceberg.expressions.Expressions.lessThan(\"field1\", 1);\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field1\").isLess(Expressions.lit(1))));\n+    Assert.assertTrue(actual.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(1).isGreater(Expressions.$(\"field1\"))));\n+    Assert.assertTrue(actual1.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual1.get());\n+  }\n+\n+  @Test\n+  public void testLessThanEquals() {\n+    UnboundPredicate<Integer> expected = org.apache.iceberg.expressions.Expressions.lessThanOrEqual(\"field1\", 1);\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual =\n+        FlinkFilters.convert(resolve(Expressions.$(\"field1\").isLessOrEqual(Expressions.lit(1))));\n+    Assert.assertTrue(actual.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+\n+    Optional<org.apache.iceberg.expressions.Expression> actual1 =\n+        FlinkFilters.convert(resolve(Expressions.lit(1).isGreaterOrEqual(Expressions.$(\"field1\"))));\n+    Assert.assertTrue(actual1.isPresent());\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual1.get());\n+  }\n+\n+  @Test\n+  public void testIsNull() {\n+    Expression expr = resolve(Expressions.$(\"field1\").isNull());\n+    Optional<org.apache.iceberg.expressions.Expression> actual = FlinkFilters.convert(expr);\n+    Assert.assertTrue(actual.isPresent());\n+    UnboundPredicate<Object> expected = org.apache.iceberg.expressions.Expressions.isNull(\"field1\");\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+  }\n+\n+  @Test\n+  public void testIsNotNull() {\n+    Expression expr = resolve(Expressions.$(\"field1\").isNotNull());\n+    Optional<org.apache.iceberg.expressions.Expression> actual = FlinkFilters.convert(expr);\n+    Assert.assertTrue(actual.isPresent());\n+    UnboundPredicate<Object> expected = org.apache.iceberg.expressions.Expressions.notNull(\"field1\");\n+    assertPredicatesMatch(expected, (UnboundPredicate<?>) actual.get());\n+  }\n+\n+  @Test\n+  public void testAnd() {\n+    Expression expr = resolve(\n+        Expressions.$(\"field1\").isEqual(Expressions.lit(1)).and(Expressions.$(\"field2\").isEqual(Expressions.lit(2L))));\n+    Optional<org.apache.iceberg.expressions.Expression> actual = FlinkFilters.convert(expr);\n+    Assert.assertTrue(actual.isPresent());\n+    And and = (And) actual.get();\n+    And expected = (And) org.apache.iceberg.expressions.Expressions.and(\n+        org.apache.iceberg.expressions.Expressions.equal(\"field1\", 1),\n+        org.apache.iceberg.expressions.Expressions.equal(\"field2\", 2L));\n+\n+    Assert.assertEquals(expected.op(), and.op());\n+    Assert.assertEquals(expected.left().op(), and.left().op());\n+    Assert.assertEquals(expected.right().op(), and.right().op());\n+  }\n+\n+  @Test\n+  public void testOr() {\n+    Expression expr = resolve(\n+        Expressions.$(\"field1\").isEqual(Expressions.lit(1)).or(Expressions.$(\"field2\").isEqual(Expressions.lit(2L))));\n+    Optional<org.apache.iceberg.expressions.Expression> actual = FlinkFilters.convert(expr);\n+    Assert.assertTrue(actual.isPresent());\n+    Or or = (Or) actual.get();\n+    Or expected = (Or) org.apache.iceberg.expressions.Expressions.or(\n+        org.apache.iceberg.expressions.Expressions.equal(\"field1\", 1),\n+        org.apache.iceberg.expressions.Expressions.equal(\"field2\", 2L));\n+\n+    Assert.assertEquals(expected.op(), or.op());\n+    Assert.assertEquals(expected.left().op(), or.left().op());\n+    Assert.assertEquals(expected.right().op(), or.right().op());\n+  }\n+\n+  @Test\n+  public void testNot() {\n+    Expression expr = resolve(ApiExpressionUtils.unresolvedCall(\n+        BuiltInFunctionDefinitions.NOT, Expressions.$(\"field1\").isEqual(Expressions.lit(1))));\n+    Optional<org.apache.iceberg.expressions.Expression> actual = FlinkFilters.convert(expr);\n+    Assert.assertTrue(actual.isPresent());\n+    Not not = (Not) actual.get();\n+    Not expected = (Not) org.apache.iceberg.expressions.Expressions.not(\n+        org.apache.iceberg.expressions.Expressions.equal(\"field1\", 1));\n+\n+    Assert.assertEquals(expected.op(), not.op());\n+    assertPredicatesMatch((UnboundPredicate<?>) expected.child(), (UnboundPredicate<?>) not.child());\n+  }\n+\n+  @Test\n+  public void testLike() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "originalPosition": 302}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY4NDUzNDk0", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-568453494", "createdAt": "2021-01-14T17:18:26Z", "commit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzoxODoyNlrOITu0EQ==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzoxODoyNlrOITu0EQ==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU2MDg0OQ==", "bodyText": "Typo: should be \"should not contain\"", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r557560849", "createdAt": "2021-01-14T17:18:26Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkTableSource.java", "diffHunk": "@@ -90,17 +103,418 @@ public void testLimitPushDown() {\n \n     Assert.assertEquals(\"should have 0 record\", 0, sql(\"SELECT * FROM %s LIMIT 0\", TABLE_NAME).size());\n \n-    String sqlLimitExceed = String.format(\"SELECT * FROM %s LIMIT 3\", TABLE_NAME);\n+    String sqlLimitExceed = String.format(\"SELECT * FROM %s LIMIT 4\", TABLE_NAME);\n     List<Object[]> resultExceed = sql(sqlLimitExceed);\n-    Assert.assertEquals(\"should have 2 record\", 2, resultExceed.size());\n+    Assert.assertEquals(\"should have 3 record\", 3, resultExceed.size());\n     List<Object[]> expectedList = Lists.newArrayList();\n     expectedList.add(new Object[] {1, \"a\"});\n     expectedList.add(new Object[] {2, \"b\"});\n+    expectedList.add(new Object[] {3, null});\n     Assert.assertArrayEquals(\"Should produce the expected records\", resultExceed.toArray(), expectedList.toArray());\n \n     String sqlMixed = String.format(\"SELECT * FROM %s WHERE id = 1 LIMIT 2\", TABLE_NAME);\n     List<Object[]> mixedResult = sql(sqlMixed);\n     Assert.assertEquals(\"should have 1 record\", 1, mixedResult.size());\n     Assert.assertArrayEquals(\"Should produce the expected records\", mixedResult.get(0), new Object[] {1, \"a\"});\n   }\n+\n+  @Test\n+  public void testNoFilterPushDown() {\n+    String sql = String.format(\"SELECT * FROM %s \", TABLE_NAME);\n+    String explain = getTableEnv().explainSql(sql);\n+    Assert.assertFalse(\"explain should no contains FilterPushDown\", explain.contains(expectedFilterPushDownExplain));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "originalPosition": 86}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY4NDU0MTAw", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-568454100", "createdAt": "2021-01-14T17:19:08Z", "commit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzoxOTowOFrOITu1xw==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzoxOTowOFrOITu1xw==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU2MTI4Nw==", "bodyText": "Thank you, these assertions look better now.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r557561287", "createdAt": "2021-01-14T17:19:08Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkTableSource.java", "diffHunk": "@@ -90,17 +103,418 @@ public void testLimitPushDown() {\n \n     Assert.assertEquals(\"should have 0 record\", 0, sql(\"SELECT * FROM %s LIMIT 0\", TABLE_NAME).size());\n \n-    String sqlLimitExceed = String.format(\"SELECT * FROM %s LIMIT 3\", TABLE_NAME);\n+    String sqlLimitExceed = String.format(\"SELECT * FROM %s LIMIT 4\", TABLE_NAME);\n     List<Object[]> resultExceed = sql(sqlLimitExceed);\n-    Assert.assertEquals(\"should have 2 record\", 2, resultExceed.size());\n+    Assert.assertEquals(\"should have 3 record\", 3, resultExceed.size());\n     List<Object[]> expectedList = Lists.newArrayList();\n     expectedList.add(new Object[] {1, \"a\"});\n     expectedList.add(new Object[] {2, \"b\"});\n+    expectedList.add(new Object[] {3, null});\n     Assert.assertArrayEquals(\"Should produce the expected records\", resultExceed.toArray(), expectedList.toArray());\n \n     String sqlMixed = String.format(\"SELECT * FROM %s WHERE id = 1 LIMIT 2\", TABLE_NAME);\n     List<Object[]> mixedResult = sql(sqlMixed);\n     Assert.assertEquals(\"should have 1 record\", 1, mixedResult.size());\n     Assert.assertArrayEquals(\"Should produce the expected records\", mixedResult.get(0), new Object[] {1, \"a\"});\n   }\n+\n+  @Test\n+  public void testNoFilterPushDown() {\n+    String sql = String.format(\"SELECT * FROM %s \", TABLE_NAME);\n+    String explain = getTableEnv().explainSql(sql);\n+    Assert.assertFalse(\"explain should no contains FilterPushDown\", explain.contains(expectedFilterPushDownExplain));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownEqual() {\n+    String sqlLiteralRight = String.format(\"SELECT * FROM %s WHERE id = 1 \", TABLE_NAME);\n+    String explain = getTableEnv().explainSql(sqlLiteralRight);\n+    String expectedFilter = \"ref(name=\\\"id\\\") == 1\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explain.contains(expectedFilter));\n+\n+    List<Object[]> result = sql(sqlLiteralRight);\n+    Assert.assertEquals(\"should have 1 record\", 1, result.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", result.get(0), new Object[] {1, \"a\"});\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "originalPosition": 101}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY4NDU0ODQ3", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-568454847", "createdAt": "2021-01-14T17:19:59Z", "commit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzoxOTo1OVrOITu3_Q==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzoxOTo1OVrOITu3_Q==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU2MTg1Mw==", "bodyText": "This should also test that the scan event had no filter if a scan event was created.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r557561853", "createdAt": "2021-01-14T17:19:59Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkTableSource.java", "diffHunk": "@@ -90,17 +103,418 @@ public void testLimitPushDown() {\n \n     Assert.assertEquals(\"should have 0 record\", 0, sql(\"SELECT * FROM %s LIMIT 0\", TABLE_NAME).size());\n \n-    String sqlLimitExceed = String.format(\"SELECT * FROM %s LIMIT 3\", TABLE_NAME);\n+    String sqlLimitExceed = String.format(\"SELECT * FROM %s LIMIT 4\", TABLE_NAME);\n     List<Object[]> resultExceed = sql(sqlLimitExceed);\n-    Assert.assertEquals(\"should have 2 record\", 2, resultExceed.size());\n+    Assert.assertEquals(\"should have 3 record\", 3, resultExceed.size());\n     List<Object[]> expectedList = Lists.newArrayList();\n     expectedList.add(new Object[] {1, \"a\"});\n     expectedList.add(new Object[] {2, \"b\"});\n+    expectedList.add(new Object[] {3, null});\n     Assert.assertArrayEquals(\"Should produce the expected records\", resultExceed.toArray(), expectedList.toArray());\n \n     String sqlMixed = String.format(\"SELECT * FROM %s WHERE id = 1 LIMIT 2\", TABLE_NAME);\n     List<Object[]> mixedResult = sql(sqlMixed);\n     Assert.assertEquals(\"should have 1 record\", 1, mixedResult.size());\n     Assert.assertArrayEquals(\"Should produce the expected records\", mixedResult.get(0), new Object[] {1, \"a\"});\n   }\n+\n+  @Test\n+  public void testNoFilterPushDown() {\n+    String sql = String.format(\"SELECT * FROM %s \", TABLE_NAME);\n+    String explain = getTableEnv().explainSql(sql);\n+    Assert.assertFalse(\"explain should no contains FilterPushDown\", explain.contains(expectedFilterPushDownExplain));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownEqual() {\n+    String sqlLiteralRight = String.format(\"SELECT * FROM %s WHERE id = 1 \", TABLE_NAME);\n+    String explain = getTableEnv().explainSql(sqlLiteralRight);\n+    String expectedFilter = \"ref(name=\\\"id\\\") == 1\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explain.contains(expectedFilter));\n+\n+    List<Object[]> result = sql(sqlLiteralRight);\n+    Assert.assertEquals(\"should have 1 record\", 1, result.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", result.get(0), new Object[] {1, \"a\"});\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+\n+    // filter not push down\n+    String sqlEqualNull = String.format(\"SELECT * FROM %s WHERE data = NULL \", TABLE_NAME);\n+    String explainEqualNull = getTableEnv().explainSql(sqlEqualNull);\n+    Assert.assertFalse(\"explain should not contains FilterPushDown\",\n+        explainEqualNull.contains(expectedFilterPushDownExplain));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "originalPosition": 107}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY4NDU2MTYz", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-568456163", "createdAt": "2021-01-14T17:21:32Z", "commit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzoyMTozMlrOITu70A==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzoyMTozMlrOITu70A==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU2MjgzMg==", "bodyText": "This should also check the scan event.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r557562832", "createdAt": "2021-01-14T17:21:32Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkTableSource.java", "diffHunk": "@@ -90,17 +103,418 @@ public void testLimitPushDown() {\n \n     Assert.assertEquals(\"should have 0 record\", 0, sql(\"SELECT * FROM %s LIMIT 0\", TABLE_NAME).size());\n \n-    String sqlLimitExceed = String.format(\"SELECT * FROM %s LIMIT 3\", TABLE_NAME);\n+    String sqlLimitExceed = String.format(\"SELECT * FROM %s LIMIT 4\", TABLE_NAME);\n     List<Object[]> resultExceed = sql(sqlLimitExceed);\n-    Assert.assertEquals(\"should have 2 record\", 2, resultExceed.size());\n+    Assert.assertEquals(\"should have 3 record\", 3, resultExceed.size());\n     List<Object[]> expectedList = Lists.newArrayList();\n     expectedList.add(new Object[] {1, \"a\"});\n     expectedList.add(new Object[] {2, \"b\"});\n+    expectedList.add(new Object[] {3, null});\n     Assert.assertArrayEquals(\"Should produce the expected records\", resultExceed.toArray(), expectedList.toArray());\n \n     String sqlMixed = String.format(\"SELECT * FROM %s WHERE id = 1 LIMIT 2\", TABLE_NAME);\n     List<Object[]> mixedResult = sql(sqlMixed);\n     Assert.assertEquals(\"should have 1 record\", 1, mixedResult.size());\n     Assert.assertArrayEquals(\"Should produce the expected records\", mixedResult.get(0), new Object[] {1, \"a\"});\n   }\n+\n+  @Test\n+  public void testNoFilterPushDown() {\n+    String sql = String.format(\"SELECT * FROM %s \", TABLE_NAME);\n+    String explain = getTableEnv().explainSql(sql);\n+    Assert.assertFalse(\"explain should no contains FilterPushDown\", explain.contains(expectedFilterPushDownExplain));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownEqual() {\n+    String sqlLiteralRight = String.format(\"SELECT * FROM %s WHERE id = 1 \", TABLE_NAME);\n+    String explain = getTableEnv().explainSql(sqlLiteralRight);\n+    String expectedFilter = \"ref(name=\\\"id\\\") == 1\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explain.contains(expectedFilter));\n+\n+    List<Object[]> result = sql(sqlLiteralRight);\n+    Assert.assertEquals(\"should have 1 record\", 1, result.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", result.get(0), new Object[] {1, \"a\"});\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+\n+    // filter not push down\n+    String sqlEqualNull = String.format(\"SELECT * FROM %s WHERE data = NULL \", TABLE_NAME);\n+    String explainEqualNull = getTableEnv().explainSql(sqlEqualNull);\n+    Assert.assertFalse(\"explain should not contains FilterPushDown\",\n+        explainEqualNull.contains(expectedFilterPushDownExplain));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownEqualLiteralOnLeft() {\n+    String sqlLiteralLeft = String.format(\"SELECT * FROM %s WHERE 1 = id \", TABLE_NAME);\n+    String explainLeft = getTableEnv().explainSql(sqlLiteralLeft);\n+    String expectedFilter = \"ref(name=\\\"id\\\") == 1\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainLeft.contains(expectedFilter));\n+\n+    List<Object[]> resultLeft = sql(sqlLiteralLeft);\n+    Assert.assertEquals(\"should have 1 record\", 1, resultLeft.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultLeft.get(0), new Object[] {1, \"a\"});\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownNoEqual() {\n+    String sqlNE = String.format(\"SELECT * FROM %s WHERE id <> 1 \", TABLE_NAME);\n+    String explainNE = getTableEnv().explainSql(sqlNE);\n+    String expectedFilter = \"ref(name=\\\"id\\\") != 1\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainNE.contains(expectedFilter));\n+\n+    List<Object[]> resultNE = sql(sqlNE);\n+    Assert.assertEquals(\"should have 2 record\", 2, resultNE.size());\n+\n+    List<Object[]> expectedNE = Lists.newArrayList();\n+    expectedNE.add(new Object[] {2, \"b\"});\n+    expectedNE.add(new Object[] {3, null});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultNE.toArray(), expectedNE.toArray());\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+\n+    String sqlNotEqualNull = String.format(\"SELECT * FROM %s WHERE data <> NULL \", TABLE_NAME);\n+    String explainNotEqualNull = getTableEnv().explainSql(sqlNotEqualNull);\n+    Assert.assertFalse(\"explain should not contains FilterPushDown\", explainNotEqualNull.contains(\n+        expectedFilterPushDownExplain));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "originalPosition": 145}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY4NDU2NTMw", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-568456530", "createdAt": "2021-01-14T17:21:57Z", "commit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzoyMTo1N1rOITu84g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzoyMTo1N1rOITu84g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU2MzEwNg==", "bodyText": "Nit: this newline isn't needed.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r557563106", "createdAt": "2021-01-14T17:21:57Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkTableSource.java", "diffHunk": "@@ -90,17 +103,418 @@ public void testLimitPushDown() {\n \n     Assert.assertEquals(\"should have 0 record\", 0, sql(\"SELECT * FROM %s LIMIT 0\", TABLE_NAME).size());\n \n-    String sqlLimitExceed = String.format(\"SELECT * FROM %s LIMIT 3\", TABLE_NAME);\n+    String sqlLimitExceed = String.format(\"SELECT * FROM %s LIMIT 4\", TABLE_NAME);\n     List<Object[]> resultExceed = sql(sqlLimitExceed);\n-    Assert.assertEquals(\"should have 2 record\", 2, resultExceed.size());\n+    Assert.assertEquals(\"should have 3 record\", 3, resultExceed.size());\n     List<Object[]> expectedList = Lists.newArrayList();\n     expectedList.add(new Object[] {1, \"a\"});\n     expectedList.add(new Object[] {2, \"b\"});\n+    expectedList.add(new Object[] {3, null});\n     Assert.assertArrayEquals(\"Should produce the expected records\", resultExceed.toArray(), expectedList.toArray());\n \n     String sqlMixed = String.format(\"SELECT * FROM %s WHERE id = 1 LIMIT 2\", TABLE_NAME);\n     List<Object[]> mixedResult = sql(sqlMixed);\n     Assert.assertEquals(\"should have 1 record\", 1, mixedResult.size());\n     Assert.assertArrayEquals(\"Should produce the expected records\", mixedResult.get(0), new Object[] {1, \"a\"});\n   }\n+\n+  @Test\n+  public void testNoFilterPushDown() {\n+    String sql = String.format(\"SELECT * FROM %s \", TABLE_NAME);\n+    String explain = getTableEnv().explainSql(sql);\n+    Assert.assertFalse(\"explain should no contains FilterPushDown\", explain.contains(expectedFilterPushDownExplain));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownEqual() {\n+    String sqlLiteralRight = String.format(\"SELECT * FROM %s WHERE id = 1 \", TABLE_NAME);\n+    String explain = getTableEnv().explainSql(sqlLiteralRight);\n+    String expectedFilter = \"ref(name=\\\"id\\\") == 1\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explain.contains(expectedFilter));\n+\n+    List<Object[]> result = sql(sqlLiteralRight);\n+    Assert.assertEquals(\"should have 1 record\", 1, result.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", result.get(0), new Object[] {1, \"a\"});\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+\n+    // filter not push down\n+    String sqlEqualNull = String.format(\"SELECT * FROM %s WHERE data = NULL \", TABLE_NAME);\n+    String explainEqualNull = getTableEnv().explainSql(sqlEqualNull);\n+    Assert.assertFalse(\"explain should not contains FilterPushDown\",\n+        explainEqualNull.contains(expectedFilterPushDownExplain));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownEqualLiteralOnLeft() {\n+    String sqlLiteralLeft = String.format(\"SELECT * FROM %s WHERE 1 = id \", TABLE_NAME);\n+    String explainLeft = getTableEnv().explainSql(sqlLiteralLeft);\n+    String expectedFilter = \"ref(name=\\\"id\\\") == 1\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainLeft.contains(expectedFilter));\n+\n+    List<Object[]> resultLeft = sql(sqlLiteralLeft);\n+    Assert.assertEquals(\"should have 1 record\", 1, resultLeft.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultLeft.get(0), new Object[] {1, \"a\"});\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownNoEqual() {\n+    String sqlNE = String.format(\"SELECT * FROM %s WHERE id <> 1 \", TABLE_NAME);\n+    String explainNE = getTableEnv().explainSql(sqlNE);\n+    String expectedFilter = \"ref(name=\\\"id\\\") != 1\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainNE.contains(expectedFilter));\n+\n+    List<Object[]> resultNE = sql(sqlNE);\n+    Assert.assertEquals(\"should have 2 record\", 2, resultNE.size());\n+\n+    List<Object[]> expectedNE = Lists.newArrayList();\n+    expectedNE.add(new Object[] {2, \"b\"});\n+    expectedNE.add(new Object[] {3, null});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultNE.toArray(), expectedNE.toArray());\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+\n+    String sqlNotEqualNull = String.format(\"SELECT * FROM %s WHERE data <> NULL \", TABLE_NAME);\n+    String explainNotEqualNull = getTableEnv().explainSql(sqlNotEqualNull);\n+    Assert.assertFalse(\"explain should not contains FilterPushDown\", explainNotEqualNull.contains(\n+        expectedFilterPushDownExplain));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownAnd() {\n+    String sqlAnd = String.format(\"SELECT * FROM %s WHERE id = 1 AND data = 'a' \", TABLE_NAME);\n+    String explainAnd = getTableEnv().explainSql(sqlAnd);\n+    String expectedFilter = \"ref(name=\\\"id\\\") == 1,ref(name=\\\"data\\\") == \\\"a\\\"\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainAnd.contains(expectedFilter));\n+\n+    List<Object[]> resultAnd = sql(sqlAnd);\n+    Assert.assertEquals(\"should have 1 record\", 1, resultAnd.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultAnd.get(0), new Object[] {1, \"a\"});\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert\n+        .assertEquals(\"should contains the push down filter\", \"(ref(name=\\\"id\\\") == 1 and ref(name=\\\"data\\\") == \\\"a\\\")\",", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "originalPosition": 161}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY4NDU3Mjgx", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-568457281", "createdAt": "2021-01-14T17:22:50Z", "commit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzoyMjo1MFrOITu_Gg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzoyMjo1MFrOITu_Gg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU2MzY3NA==", "bodyText": "The expected value comes first so that assertion failures show the right labels. If this failed, the actual filter would be shown as the expected filter.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r557563674", "createdAt": "2021-01-14T17:22:50Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkTableSource.java", "diffHunk": "@@ -90,17 +103,418 @@ public void testLimitPushDown() {\n \n     Assert.assertEquals(\"should have 0 record\", 0, sql(\"SELECT * FROM %s LIMIT 0\", TABLE_NAME).size());\n \n-    String sqlLimitExceed = String.format(\"SELECT * FROM %s LIMIT 3\", TABLE_NAME);\n+    String sqlLimitExceed = String.format(\"SELECT * FROM %s LIMIT 4\", TABLE_NAME);\n     List<Object[]> resultExceed = sql(sqlLimitExceed);\n-    Assert.assertEquals(\"should have 2 record\", 2, resultExceed.size());\n+    Assert.assertEquals(\"should have 3 record\", 3, resultExceed.size());\n     List<Object[]> expectedList = Lists.newArrayList();\n     expectedList.add(new Object[] {1, \"a\"});\n     expectedList.add(new Object[] {2, \"b\"});\n+    expectedList.add(new Object[] {3, null});\n     Assert.assertArrayEquals(\"Should produce the expected records\", resultExceed.toArray(), expectedList.toArray());\n \n     String sqlMixed = String.format(\"SELECT * FROM %s WHERE id = 1 LIMIT 2\", TABLE_NAME);\n     List<Object[]> mixedResult = sql(sqlMixed);\n     Assert.assertEquals(\"should have 1 record\", 1, mixedResult.size());\n     Assert.assertArrayEquals(\"Should produce the expected records\", mixedResult.get(0), new Object[] {1, \"a\"});\n   }\n+\n+  @Test\n+  public void testNoFilterPushDown() {\n+    String sql = String.format(\"SELECT * FROM %s \", TABLE_NAME);\n+    String explain = getTableEnv().explainSql(sql);\n+    Assert.assertFalse(\"explain should no contains FilterPushDown\", explain.contains(expectedFilterPushDownExplain));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownEqual() {\n+    String sqlLiteralRight = String.format(\"SELECT * FROM %s WHERE id = 1 \", TABLE_NAME);\n+    String explain = getTableEnv().explainSql(sqlLiteralRight);\n+    String expectedFilter = \"ref(name=\\\"id\\\") == 1\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explain.contains(expectedFilter));\n+\n+    List<Object[]> result = sql(sqlLiteralRight);\n+    Assert.assertEquals(\"should have 1 record\", 1, result.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", result.get(0), new Object[] {1, \"a\"});\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+\n+    // filter not push down\n+    String sqlEqualNull = String.format(\"SELECT * FROM %s WHERE data = NULL \", TABLE_NAME);\n+    String explainEqualNull = getTableEnv().explainSql(sqlEqualNull);\n+    Assert.assertFalse(\"explain should not contains FilterPushDown\",\n+        explainEqualNull.contains(expectedFilterPushDownExplain));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownEqualLiteralOnLeft() {\n+    String sqlLiteralLeft = String.format(\"SELECT * FROM %s WHERE 1 = id \", TABLE_NAME);\n+    String explainLeft = getTableEnv().explainSql(sqlLiteralLeft);\n+    String expectedFilter = \"ref(name=\\\"id\\\") == 1\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainLeft.contains(expectedFilter));\n+\n+    List<Object[]> resultLeft = sql(sqlLiteralLeft);\n+    Assert.assertEquals(\"should have 1 record\", 1, resultLeft.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultLeft.get(0), new Object[] {1, \"a\"});\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "originalPosition": 122}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY4NDU4NzM4", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-568458738", "createdAt": "2021-01-14T17:24:37Z", "commit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzoyNDozN1rOITvDcg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzoyNDozN1rOITvDcg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU2NDc4Ng==", "bodyText": "Needs to check the scan event.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r557564786", "createdAt": "2021-01-14T17:24:37Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkTableSource.java", "diffHunk": "@@ -90,17 +103,418 @@ public void testLimitPushDown() {\n \n     Assert.assertEquals(\"should have 0 record\", 0, sql(\"SELECT * FROM %s LIMIT 0\", TABLE_NAME).size());\n \n-    String sqlLimitExceed = String.format(\"SELECT * FROM %s LIMIT 3\", TABLE_NAME);\n+    String sqlLimitExceed = String.format(\"SELECT * FROM %s LIMIT 4\", TABLE_NAME);\n     List<Object[]> resultExceed = sql(sqlLimitExceed);\n-    Assert.assertEquals(\"should have 2 record\", 2, resultExceed.size());\n+    Assert.assertEquals(\"should have 3 record\", 3, resultExceed.size());\n     List<Object[]> expectedList = Lists.newArrayList();\n     expectedList.add(new Object[] {1, \"a\"});\n     expectedList.add(new Object[] {2, \"b\"});\n+    expectedList.add(new Object[] {3, null});\n     Assert.assertArrayEquals(\"Should produce the expected records\", resultExceed.toArray(), expectedList.toArray());\n \n     String sqlMixed = String.format(\"SELECT * FROM %s WHERE id = 1 LIMIT 2\", TABLE_NAME);\n     List<Object[]> mixedResult = sql(sqlMixed);\n     Assert.assertEquals(\"should have 1 record\", 1, mixedResult.size());\n     Assert.assertArrayEquals(\"Should produce the expected records\", mixedResult.get(0), new Object[] {1, \"a\"});\n   }\n+\n+  @Test\n+  public void testNoFilterPushDown() {\n+    String sql = String.format(\"SELECT * FROM %s \", TABLE_NAME);\n+    String explain = getTableEnv().explainSql(sql);\n+    Assert.assertFalse(\"explain should no contains FilterPushDown\", explain.contains(expectedFilterPushDownExplain));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownEqual() {\n+    String sqlLiteralRight = String.format(\"SELECT * FROM %s WHERE id = 1 \", TABLE_NAME);\n+    String explain = getTableEnv().explainSql(sqlLiteralRight);\n+    String expectedFilter = \"ref(name=\\\"id\\\") == 1\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explain.contains(expectedFilter));\n+\n+    List<Object[]> result = sql(sqlLiteralRight);\n+    Assert.assertEquals(\"should have 1 record\", 1, result.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", result.get(0), new Object[] {1, \"a\"});\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+\n+    // filter not push down\n+    String sqlEqualNull = String.format(\"SELECT * FROM %s WHERE data = NULL \", TABLE_NAME);\n+    String explainEqualNull = getTableEnv().explainSql(sqlEqualNull);\n+    Assert.assertFalse(\"explain should not contains FilterPushDown\",\n+        explainEqualNull.contains(expectedFilterPushDownExplain));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownEqualLiteralOnLeft() {\n+    String sqlLiteralLeft = String.format(\"SELECT * FROM %s WHERE 1 = id \", TABLE_NAME);\n+    String explainLeft = getTableEnv().explainSql(sqlLiteralLeft);\n+    String expectedFilter = \"ref(name=\\\"id\\\") == 1\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainLeft.contains(expectedFilter));\n+\n+    List<Object[]> resultLeft = sql(sqlLiteralLeft);\n+    Assert.assertEquals(\"should have 1 record\", 1, resultLeft.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultLeft.get(0), new Object[] {1, \"a\"});\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownNoEqual() {\n+    String sqlNE = String.format(\"SELECT * FROM %s WHERE id <> 1 \", TABLE_NAME);\n+    String explainNE = getTableEnv().explainSql(sqlNE);\n+    String expectedFilter = \"ref(name=\\\"id\\\") != 1\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainNE.contains(expectedFilter));\n+\n+    List<Object[]> resultNE = sql(sqlNE);\n+    Assert.assertEquals(\"should have 2 record\", 2, resultNE.size());\n+\n+    List<Object[]> expectedNE = Lists.newArrayList();\n+    expectedNE.add(new Object[] {2, \"b\"});\n+    expectedNE.add(new Object[] {3, null});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultNE.toArray(), expectedNE.toArray());\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+\n+    String sqlNotEqualNull = String.format(\"SELECT * FROM %s WHERE data <> NULL \", TABLE_NAME);\n+    String explainNotEqualNull = getTableEnv().explainSql(sqlNotEqualNull);\n+    Assert.assertFalse(\"explain should not contains FilterPushDown\", explainNotEqualNull.contains(\n+        expectedFilterPushDownExplain));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownAnd() {\n+    String sqlAnd = String.format(\"SELECT * FROM %s WHERE id = 1 AND data = 'a' \", TABLE_NAME);\n+    String explainAnd = getTableEnv().explainSql(sqlAnd);\n+    String expectedFilter = \"ref(name=\\\"id\\\") == 1,ref(name=\\\"data\\\") == \\\"a\\\"\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainAnd.contains(expectedFilter));\n+\n+    List<Object[]> resultAnd = sql(sqlAnd);\n+    Assert.assertEquals(\"should have 1 record\", 1, resultAnd.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultAnd.get(0), new Object[] {1, \"a\"});\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert\n+        .assertEquals(\"should contains the push down filter\", \"(ref(name=\\\"id\\\") == 1 and ref(name=\\\"data\\\") == \\\"a\\\")\",\n+            lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownOr() {\n+    String sqlOr = String.format(\"SELECT * FROM %s WHERE id = 1 OR data = 'b' \", TABLE_NAME);\n+    String explainOr = getTableEnv().explainSql(sqlOr);\n+    String expectedFilter = \"(ref(name=\\\"id\\\") == 1 or ref(name=\\\"data\\\") == \\\"b\\\")\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainOr.contains(expectedFilter));\n+\n+    List<Object[]> resultOr = sql(sqlOr);\n+    Assert.assertEquals(\"should have 2 record\", 2, resultOr.size());\n+\n+    List<Object[]> expectedOR = Lists.newArrayList();\n+    expectedOR.add(new Object[] {1, \"a\"});\n+    expectedOR.add(new Object[] {2, \"b\"});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultOr.toArray(), expectedOR.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownGreaterThan() {\n+    String sqlGT = String.format(\"SELECT * FROM %s WHERE id > 1 \", TABLE_NAME);\n+    String explainGT = getTableEnv().explainSql(sqlGT);\n+    String expectedFilter = \"ref(name=\\\"id\\\") > 1\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainGT.contains(expectedFilter));\n+\n+    List<Object[]> resultGT = sql(sqlGT);\n+    Assert.assertEquals(\"should have 2 record\", 2, resultGT.size());\n+\n+    List<Object[]> expectedGT = Lists.newArrayList();\n+    expectedGT.add(new Object[] {2, \"b\"});\n+    expectedGT.add(new Object[] {3, null});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultGT.toArray(), expectedGT.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownGreaterThanLiteralOnLeft() {\n+    String sqlGT = String.format(\"SELECT * FROM %s WHERE 3 > id \", TABLE_NAME);\n+    String explainGT = getTableEnv().explainSql(sqlGT);\n+    String expectedFilter = \"ref(name=\\\"id\\\") < 3\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainGT.contains(expectedFilter));\n+\n+    List<Object[]> resultGT = sql(sqlGT);\n+    Assert.assertEquals(\"should have 2 record\", 2, resultGT.size());\n+\n+    List<Object[]> expectedGT = Lists.newArrayList();\n+    expectedGT.add(new Object[] {1, \"a\"});\n+    expectedGT.add(new Object[] {2, \"b\"});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultGT.toArray(), expectedGT.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownGreaterThanEqual() {\n+    String sqlGTE = String.format(\"SELECT * FROM %s WHERE id >= 2 \", TABLE_NAME);\n+    String explainGTE = getTableEnv().explainSql(sqlGTE);\n+    String expectedFilter = \"ref(name=\\\"id\\\") >= 2\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainGTE.contains(expectedFilter));\n+\n+    List<Object[]> resultGTE = sql(sqlGTE);\n+    Assert.assertEquals(\"should have 2 records\", 2, resultGTE.size());\n+\n+    List<Object[]> expectedGTE = Lists.newArrayList();\n+    expectedGTE.add(new Object[] {2, \"b\"});\n+    expectedGTE.add(new Object[] {3, null});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultGTE.toArray(), expectedGTE.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownGreaterThanEqualLiteralOnLeft() {\n+    String sqlGTE = String.format(\"SELECT * FROM %s WHERE 2 >= id \", TABLE_NAME);\n+    String explainGTE = getTableEnv().explainSql(sqlGTE);\n+    String expectedFilter = \"ref(name=\\\"id\\\") <= 2\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainGTE.contains(expectedFilter));\n+\n+    List<Object[]> resultGTE = sql(sqlGTE);\n+    Assert.assertEquals(\"should have 2 records\", 2, resultGTE.size());\n+\n+    List<Object[]> expectedGTE = Lists.newArrayList();\n+    expectedGTE.add(new Object[] {1, \"a\"});\n+    expectedGTE.add(new Object[] {2, \"b\"});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultGTE.toArray(), expectedGTE.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownLessThan() {\n+    String sqlLT = String.format(\"SELECT * FROM %s WHERE id < 2 \", TABLE_NAME);\n+    String explainLT = getTableEnv().explainSql(sqlLT);\n+    String expectedFilter = \"ref(name=\\\"id\\\") < 2\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainLT.contains(expectedFilter));\n+\n+    List<Object[]> resultLT = sql(sqlLT);\n+    Assert.assertEquals(\"should have 1 record\", 1, resultLT.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultLT.get(0), new Object[] {1, \"a\"});\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownLessThanLiteralOnLeft() {\n+    String sqlLT = String.format(\"SELECT * FROM %s WHERE 2 < id \", TABLE_NAME);\n+    String explainLT = getTableEnv().explainSql(sqlLT);\n+    String expectedFilter = \"ref(name=\\\"id\\\") > 2\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainLT.contains(expectedFilter));\n+\n+    List<Object[]> resultLT = sql(sqlLT);\n+    Assert.assertEquals(\"should have 1 record\", 1, resultLT.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultLT.get(0), new Object[] {3, null});\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownLessThanEqual() {\n+    String sqlLTE = String.format(\"SELECT * FROM %s WHERE id <= 1 \", TABLE_NAME);\n+    String explainLTE = getTableEnv().explainSql(sqlLTE);\n+    String expectedFilter = \"ref(name=\\\"id\\\") <= 1\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainLTE.contains(expectedFilter));\n+\n+    List<Object[]> resultLTE = sql(sqlLTE);\n+    Assert.assertEquals(\"should have 1 record\", 1, resultLTE.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultLTE.get(0), new Object[] {1, \"a\"});\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownLessThanEqualLiteralOnLeft() {\n+    String sqlLTE = String.format(\"SELECT * FROM %s WHERE 3 <= id  \", TABLE_NAME);\n+    String explainLTE = getTableEnv().explainSql(sqlLTE);\n+    String expectedFilter = \"ref(name=\\\"id\\\") >= 3\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainLTE.contains(expectedFilter));\n+\n+    List<Object[]> resultLTE = sql(sqlLTE);\n+    Assert.assertEquals(\"should have 1 record\", 1, resultLTE.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultLTE.get(0), new Object[] {3, null});\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownIn() {\n+    String sqlIN = String.format(\"SELECT * FROM %s WHERE id IN (1,2) \", TABLE_NAME);\n+    String explainIN = getTableEnv().explainSql(sqlIN);\n+    String expectedFilter = \"(ref(name=\\\"id\\\") == 1 or ref(name=\\\"id\\\") == 2)\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainIN.contains(expectedFilter));\n+    List<Object[]> resultIN = sql(sqlIN);\n+    Assert.assertEquals(\"should have 2 records\", 2, resultIN.size());\n+\n+    List<Object[]> expectedIN = Lists.newArrayList();\n+    expectedIN.add(new Object[] {1, \"a\"});\n+    expectedIN.add(new Object[] {2, \"b\"});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultIN.toArray(), expectedIN.toArray());\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+\n+    // in with null will not push down\n+    String sqlInNull = String.format(\"SELECT * FROM %s WHERE id IN (1,2,NULL) \", TABLE_NAME);\n+    String explainInNull = getTableEnv().explainSql(sqlInNull);\n+    Assert.assertFalse(\"explain should not contains FilterPushDown\",\n+        explainInNull.contains(expectedFilterPushDownExplain));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "originalPosition": 340}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY4NDU4OTM4", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-568458938", "createdAt": "2021-01-14T17:24:51Z", "commit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzoyNDo1MVrOITvD-g==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzoyNDo1MVrOITvD-g==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU2NDkyMg==", "bodyText": "Needs to check the scan event.", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r557564922", "createdAt": "2021-01-14T17:24:51Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkTableSource.java", "diffHunk": "@@ -90,17 +103,418 @@ public void testLimitPushDown() {\n \n     Assert.assertEquals(\"should have 0 record\", 0, sql(\"SELECT * FROM %s LIMIT 0\", TABLE_NAME).size());\n \n-    String sqlLimitExceed = String.format(\"SELECT * FROM %s LIMIT 3\", TABLE_NAME);\n+    String sqlLimitExceed = String.format(\"SELECT * FROM %s LIMIT 4\", TABLE_NAME);\n     List<Object[]> resultExceed = sql(sqlLimitExceed);\n-    Assert.assertEquals(\"should have 2 record\", 2, resultExceed.size());\n+    Assert.assertEquals(\"should have 3 record\", 3, resultExceed.size());\n     List<Object[]> expectedList = Lists.newArrayList();\n     expectedList.add(new Object[] {1, \"a\"});\n     expectedList.add(new Object[] {2, \"b\"});\n+    expectedList.add(new Object[] {3, null});\n     Assert.assertArrayEquals(\"Should produce the expected records\", resultExceed.toArray(), expectedList.toArray());\n \n     String sqlMixed = String.format(\"SELECT * FROM %s WHERE id = 1 LIMIT 2\", TABLE_NAME);\n     List<Object[]> mixedResult = sql(sqlMixed);\n     Assert.assertEquals(\"should have 1 record\", 1, mixedResult.size());\n     Assert.assertArrayEquals(\"Should produce the expected records\", mixedResult.get(0), new Object[] {1, \"a\"});\n   }\n+\n+  @Test\n+  public void testNoFilterPushDown() {\n+    String sql = String.format(\"SELECT * FROM %s \", TABLE_NAME);\n+    String explain = getTableEnv().explainSql(sql);\n+    Assert.assertFalse(\"explain should no contains FilterPushDown\", explain.contains(expectedFilterPushDownExplain));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownEqual() {\n+    String sqlLiteralRight = String.format(\"SELECT * FROM %s WHERE id = 1 \", TABLE_NAME);\n+    String explain = getTableEnv().explainSql(sqlLiteralRight);\n+    String expectedFilter = \"ref(name=\\\"id\\\") == 1\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explain.contains(expectedFilter));\n+\n+    List<Object[]> result = sql(sqlLiteralRight);\n+    Assert.assertEquals(\"should have 1 record\", 1, result.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", result.get(0), new Object[] {1, \"a\"});\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+\n+    // filter not push down\n+    String sqlEqualNull = String.format(\"SELECT * FROM %s WHERE data = NULL \", TABLE_NAME);\n+    String explainEqualNull = getTableEnv().explainSql(sqlEqualNull);\n+    Assert.assertFalse(\"explain should not contains FilterPushDown\",\n+        explainEqualNull.contains(expectedFilterPushDownExplain));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownEqualLiteralOnLeft() {\n+    String sqlLiteralLeft = String.format(\"SELECT * FROM %s WHERE 1 = id \", TABLE_NAME);\n+    String explainLeft = getTableEnv().explainSql(sqlLiteralLeft);\n+    String expectedFilter = \"ref(name=\\\"id\\\") == 1\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainLeft.contains(expectedFilter));\n+\n+    List<Object[]> resultLeft = sql(sqlLiteralLeft);\n+    Assert.assertEquals(\"should have 1 record\", 1, resultLeft.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultLeft.get(0), new Object[] {1, \"a\"});\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownNoEqual() {\n+    String sqlNE = String.format(\"SELECT * FROM %s WHERE id <> 1 \", TABLE_NAME);\n+    String explainNE = getTableEnv().explainSql(sqlNE);\n+    String expectedFilter = \"ref(name=\\\"id\\\") != 1\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainNE.contains(expectedFilter));\n+\n+    List<Object[]> resultNE = sql(sqlNE);\n+    Assert.assertEquals(\"should have 2 record\", 2, resultNE.size());\n+\n+    List<Object[]> expectedNE = Lists.newArrayList();\n+    expectedNE.add(new Object[] {2, \"b\"});\n+    expectedNE.add(new Object[] {3, null});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultNE.toArray(), expectedNE.toArray());\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+\n+    String sqlNotEqualNull = String.format(\"SELECT * FROM %s WHERE data <> NULL \", TABLE_NAME);\n+    String explainNotEqualNull = getTableEnv().explainSql(sqlNotEqualNull);\n+    Assert.assertFalse(\"explain should not contains FilterPushDown\", explainNotEqualNull.contains(\n+        expectedFilterPushDownExplain));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownAnd() {\n+    String sqlAnd = String.format(\"SELECT * FROM %s WHERE id = 1 AND data = 'a' \", TABLE_NAME);\n+    String explainAnd = getTableEnv().explainSql(sqlAnd);\n+    String expectedFilter = \"ref(name=\\\"id\\\") == 1,ref(name=\\\"data\\\") == \\\"a\\\"\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainAnd.contains(expectedFilter));\n+\n+    List<Object[]> resultAnd = sql(sqlAnd);\n+    Assert.assertEquals(\"should have 1 record\", 1, resultAnd.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultAnd.get(0), new Object[] {1, \"a\"});\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert\n+        .assertEquals(\"should contains the push down filter\", \"(ref(name=\\\"id\\\") == 1 and ref(name=\\\"data\\\") == \\\"a\\\")\",\n+            lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownOr() {\n+    String sqlOr = String.format(\"SELECT * FROM %s WHERE id = 1 OR data = 'b' \", TABLE_NAME);\n+    String explainOr = getTableEnv().explainSql(sqlOr);\n+    String expectedFilter = \"(ref(name=\\\"id\\\") == 1 or ref(name=\\\"data\\\") == \\\"b\\\")\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainOr.contains(expectedFilter));\n+\n+    List<Object[]> resultOr = sql(sqlOr);\n+    Assert.assertEquals(\"should have 2 record\", 2, resultOr.size());\n+\n+    List<Object[]> expectedOR = Lists.newArrayList();\n+    expectedOR.add(new Object[] {1, \"a\"});\n+    expectedOR.add(new Object[] {2, \"b\"});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultOr.toArray(), expectedOR.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownGreaterThan() {\n+    String sqlGT = String.format(\"SELECT * FROM %s WHERE id > 1 \", TABLE_NAME);\n+    String explainGT = getTableEnv().explainSql(sqlGT);\n+    String expectedFilter = \"ref(name=\\\"id\\\") > 1\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainGT.contains(expectedFilter));\n+\n+    List<Object[]> resultGT = sql(sqlGT);\n+    Assert.assertEquals(\"should have 2 record\", 2, resultGT.size());\n+\n+    List<Object[]> expectedGT = Lists.newArrayList();\n+    expectedGT.add(new Object[] {2, \"b\"});\n+    expectedGT.add(new Object[] {3, null});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultGT.toArray(), expectedGT.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownGreaterThanLiteralOnLeft() {\n+    String sqlGT = String.format(\"SELECT * FROM %s WHERE 3 > id \", TABLE_NAME);\n+    String explainGT = getTableEnv().explainSql(sqlGT);\n+    String expectedFilter = \"ref(name=\\\"id\\\") < 3\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainGT.contains(expectedFilter));\n+\n+    List<Object[]> resultGT = sql(sqlGT);\n+    Assert.assertEquals(\"should have 2 record\", 2, resultGT.size());\n+\n+    List<Object[]> expectedGT = Lists.newArrayList();\n+    expectedGT.add(new Object[] {1, \"a\"});\n+    expectedGT.add(new Object[] {2, \"b\"});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultGT.toArray(), expectedGT.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownGreaterThanEqual() {\n+    String sqlGTE = String.format(\"SELECT * FROM %s WHERE id >= 2 \", TABLE_NAME);\n+    String explainGTE = getTableEnv().explainSql(sqlGTE);\n+    String expectedFilter = \"ref(name=\\\"id\\\") >= 2\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainGTE.contains(expectedFilter));\n+\n+    List<Object[]> resultGTE = sql(sqlGTE);\n+    Assert.assertEquals(\"should have 2 records\", 2, resultGTE.size());\n+\n+    List<Object[]> expectedGTE = Lists.newArrayList();\n+    expectedGTE.add(new Object[] {2, \"b\"});\n+    expectedGTE.add(new Object[] {3, null});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultGTE.toArray(), expectedGTE.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownGreaterThanEqualLiteralOnLeft() {\n+    String sqlGTE = String.format(\"SELECT * FROM %s WHERE 2 >= id \", TABLE_NAME);\n+    String explainGTE = getTableEnv().explainSql(sqlGTE);\n+    String expectedFilter = \"ref(name=\\\"id\\\") <= 2\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainGTE.contains(expectedFilter));\n+\n+    List<Object[]> resultGTE = sql(sqlGTE);\n+    Assert.assertEquals(\"should have 2 records\", 2, resultGTE.size());\n+\n+    List<Object[]> expectedGTE = Lists.newArrayList();\n+    expectedGTE.add(new Object[] {1, \"a\"});\n+    expectedGTE.add(new Object[] {2, \"b\"});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultGTE.toArray(), expectedGTE.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownLessThan() {\n+    String sqlLT = String.format(\"SELECT * FROM %s WHERE id < 2 \", TABLE_NAME);\n+    String explainLT = getTableEnv().explainSql(sqlLT);\n+    String expectedFilter = \"ref(name=\\\"id\\\") < 2\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainLT.contains(expectedFilter));\n+\n+    List<Object[]> resultLT = sql(sqlLT);\n+    Assert.assertEquals(\"should have 1 record\", 1, resultLT.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultLT.get(0), new Object[] {1, \"a\"});\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownLessThanLiteralOnLeft() {\n+    String sqlLT = String.format(\"SELECT * FROM %s WHERE 2 < id \", TABLE_NAME);\n+    String explainLT = getTableEnv().explainSql(sqlLT);\n+    String expectedFilter = \"ref(name=\\\"id\\\") > 2\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainLT.contains(expectedFilter));\n+\n+    List<Object[]> resultLT = sql(sqlLT);\n+    Assert.assertEquals(\"should have 1 record\", 1, resultLT.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultLT.get(0), new Object[] {3, null});\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownLessThanEqual() {\n+    String sqlLTE = String.format(\"SELECT * FROM %s WHERE id <= 1 \", TABLE_NAME);\n+    String explainLTE = getTableEnv().explainSql(sqlLTE);\n+    String expectedFilter = \"ref(name=\\\"id\\\") <= 1\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainLTE.contains(expectedFilter));\n+\n+    List<Object[]> resultLTE = sql(sqlLTE);\n+    Assert.assertEquals(\"should have 1 record\", 1, resultLTE.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultLTE.get(0), new Object[] {1, \"a\"});\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownLessThanEqualLiteralOnLeft() {\n+    String sqlLTE = String.format(\"SELECT * FROM %s WHERE 3 <= id  \", TABLE_NAME);\n+    String explainLTE = getTableEnv().explainSql(sqlLTE);\n+    String expectedFilter = \"ref(name=\\\"id\\\") >= 3\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainLTE.contains(expectedFilter));\n+\n+    List<Object[]> resultLTE = sql(sqlLTE);\n+    Assert.assertEquals(\"should have 1 record\", 1, resultLTE.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultLTE.get(0), new Object[] {3, null});\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownIn() {\n+    String sqlIN = String.format(\"SELECT * FROM %s WHERE id IN (1,2) \", TABLE_NAME);\n+    String explainIN = getTableEnv().explainSql(sqlIN);\n+    String expectedFilter = \"(ref(name=\\\"id\\\") == 1 or ref(name=\\\"id\\\") == 2)\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainIN.contains(expectedFilter));\n+    List<Object[]> resultIN = sql(sqlIN);\n+    Assert.assertEquals(\"should have 2 records\", 2, resultIN.size());\n+\n+    List<Object[]> expectedIN = Lists.newArrayList();\n+    expectedIN.add(new Object[] {1, \"a\"});\n+    expectedIN.add(new Object[] {2, \"b\"});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultIN.toArray(), expectedIN.toArray());\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+\n+    // in with null will not push down\n+    String sqlInNull = String.format(\"SELECT * FROM %s WHERE id IN (1,2,NULL) \", TABLE_NAME);\n+    String explainInNull = getTableEnv().explainSql(sqlInNull);\n+    Assert.assertFalse(\"explain should not contains FilterPushDown\",\n+        explainInNull.contains(expectedFilterPushDownExplain));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownNotIn() {\n+    String sqlNotIn = String.format(\"SELECT * FROM %s WHERE id NOT IN (3,2) \", TABLE_NAME);\n+    String explainNotIn = getTableEnv().explainSql(sqlNotIn);\n+    String expectedFilter = \"ref(name=\\\"id\\\") != 3,ref(name=\\\"id\\\") != 2\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainNotIn.contains(expectedFilter));\n+\n+    List<Object[]> resultNotIn = sql(sqlNotIn);\n+    Assert.assertEquals(\"should have 1 record\", 1, resultNotIn.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultNotIn.get(0), new Object[] {1, \"a\"});\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", \"(ref(name=\\\"id\\\") != 3 and ref(name=\\\"id\\\") != 2)\",\n+        lastScanEvent.filter().toString());\n+\n+    String sqlNotInNull = String.format(\"SELECT * FROM %s WHERE id NOT IN (1,2,NULL) \", TABLE_NAME);\n+    String explainNotInNull = getTableEnv().explainSql(sqlNotInNull);\n+    Assert.assertFalse(\"explain should not contains FilterPushDown\",\n+        explainNotInNull.contains(expectedFilterPushDownExplain));", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "originalPosition": 360}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY4NDYwNzk0", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-568460794", "createdAt": "2021-01-14T17:27:03Z", "commit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzoyNzowM1rOITvJkg==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzoyNzowM1rOITvJkg==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU2NjM1NA==", "bodyText": "It looks like Flink is rewriting the expression to notEq. Is there a test case where the not is passed to Iceberg? Maybe using a complex expression like not(or(eq(\"id\", 1), eq(\"id\", 2)))", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r557566354", "createdAt": "2021-01-14T17:27:03Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkTableSource.java", "diffHunk": "@@ -90,17 +103,418 @@ public void testLimitPushDown() {\n \n     Assert.assertEquals(\"should have 0 record\", 0, sql(\"SELECT * FROM %s LIMIT 0\", TABLE_NAME).size());\n \n-    String sqlLimitExceed = String.format(\"SELECT * FROM %s LIMIT 3\", TABLE_NAME);\n+    String sqlLimitExceed = String.format(\"SELECT * FROM %s LIMIT 4\", TABLE_NAME);\n     List<Object[]> resultExceed = sql(sqlLimitExceed);\n-    Assert.assertEquals(\"should have 2 record\", 2, resultExceed.size());\n+    Assert.assertEquals(\"should have 3 record\", 3, resultExceed.size());\n     List<Object[]> expectedList = Lists.newArrayList();\n     expectedList.add(new Object[] {1, \"a\"});\n     expectedList.add(new Object[] {2, \"b\"});\n+    expectedList.add(new Object[] {3, null});\n     Assert.assertArrayEquals(\"Should produce the expected records\", resultExceed.toArray(), expectedList.toArray());\n \n     String sqlMixed = String.format(\"SELECT * FROM %s WHERE id = 1 LIMIT 2\", TABLE_NAME);\n     List<Object[]> mixedResult = sql(sqlMixed);\n     Assert.assertEquals(\"should have 1 record\", 1, mixedResult.size());\n     Assert.assertArrayEquals(\"Should produce the expected records\", mixedResult.get(0), new Object[] {1, \"a\"});\n   }\n+\n+  @Test\n+  public void testNoFilterPushDown() {\n+    String sql = String.format(\"SELECT * FROM %s \", TABLE_NAME);\n+    String explain = getTableEnv().explainSql(sql);\n+    Assert.assertFalse(\"explain should no contains FilterPushDown\", explain.contains(expectedFilterPushDownExplain));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownEqual() {\n+    String sqlLiteralRight = String.format(\"SELECT * FROM %s WHERE id = 1 \", TABLE_NAME);\n+    String explain = getTableEnv().explainSql(sqlLiteralRight);\n+    String expectedFilter = \"ref(name=\\\"id\\\") == 1\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explain.contains(expectedFilter));\n+\n+    List<Object[]> result = sql(sqlLiteralRight);\n+    Assert.assertEquals(\"should have 1 record\", 1, result.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", result.get(0), new Object[] {1, \"a\"});\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+\n+    // filter not push down\n+    String sqlEqualNull = String.format(\"SELECT * FROM %s WHERE data = NULL \", TABLE_NAME);\n+    String explainEqualNull = getTableEnv().explainSql(sqlEqualNull);\n+    Assert.assertFalse(\"explain should not contains FilterPushDown\",\n+        explainEqualNull.contains(expectedFilterPushDownExplain));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownEqualLiteralOnLeft() {\n+    String sqlLiteralLeft = String.format(\"SELECT * FROM %s WHERE 1 = id \", TABLE_NAME);\n+    String explainLeft = getTableEnv().explainSql(sqlLiteralLeft);\n+    String expectedFilter = \"ref(name=\\\"id\\\") == 1\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainLeft.contains(expectedFilter));\n+\n+    List<Object[]> resultLeft = sql(sqlLiteralLeft);\n+    Assert.assertEquals(\"should have 1 record\", 1, resultLeft.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultLeft.get(0), new Object[] {1, \"a\"});\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownNoEqual() {\n+    String sqlNE = String.format(\"SELECT * FROM %s WHERE id <> 1 \", TABLE_NAME);\n+    String explainNE = getTableEnv().explainSql(sqlNE);\n+    String expectedFilter = \"ref(name=\\\"id\\\") != 1\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainNE.contains(expectedFilter));\n+\n+    List<Object[]> resultNE = sql(sqlNE);\n+    Assert.assertEquals(\"should have 2 record\", 2, resultNE.size());\n+\n+    List<Object[]> expectedNE = Lists.newArrayList();\n+    expectedNE.add(new Object[] {2, \"b\"});\n+    expectedNE.add(new Object[] {3, null});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultNE.toArray(), expectedNE.toArray());\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+\n+    String sqlNotEqualNull = String.format(\"SELECT * FROM %s WHERE data <> NULL \", TABLE_NAME);\n+    String explainNotEqualNull = getTableEnv().explainSql(sqlNotEqualNull);\n+    Assert.assertFalse(\"explain should not contains FilterPushDown\", explainNotEqualNull.contains(\n+        expectedFilterPushDownExplain));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownAnd() {\n+    String sqlAnd = String.format(\"SELECT * FROM %s WHERE id = 1 AND data = 'a' \", TABLE_NAME);\n+    String explainAnd = getTableEnv().explainSql(sqlAnd);\n+    String expectedFilter = \"ref(name=\\\"id\\\") == 1,ref(name=\\\"data\\\") == \\\"a\\\"\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainAnd.contains(expectedFilter));\n+\n+    List<Object[]> resultAnd = sql(sqlAnd);\n+    Assert.assertEquals(\"should have 1 record\", 1, resultAnd.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultAnd.get(0), new Object[] {1, \"a\"});\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert\n+        .assertEquals(\"should contains the push down filter\", \"(ref(name=\\\"id\\\") == 1 and ref(name=\\\"data\\\") == \\\"a\\\")\",\n+            lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownOr() {\n+    String sqlOr = String.format(\"SELECT * FROM %s WHERE id = 1 OR data = 'b' \", TABLE_NAME);\n+    String explainOr = getTableEnv().explainSql(sqlOr);\n+    String expectedFilter = \"(ref(name=\\\"id\\\") == 1 or ref(name=\\\"data\\\") == \\\"b\\\")\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainOr.contains(expectedFilter));\n+\n+    List<Object[]> resultOr = sql(sqlOr);\n+    Assert.assertEquals(\"should have 2 record\", 2, resultOr.size());\n+\n+    List<Object[]> expectedOR = Lists.newArrayList();\n+    expectedOR.add(new Object[] {1, \"a\"});\n+    expectedOR.add(new Object[] {2, \"b\"});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultOr.toArray(), expectedOR.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownGreaterThan() {\n+    String sqlGT = String.format(\"SELECT * FROM %s WHERE id > 1 \", TABLE_NAME);\n+    String explainGT = getTableEnv().explainSql(sqlGT);\n+    String expectedFilter = \"ref(name=\\\"id\\\") > 1\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainGT.contains(expectedFilter));\n+\n+    List<Object[]> resultGT = sql(sqlGT);\n+    Assert.assertEquals(\"should have 2 record\", 2, resultGT.size());\n+\n+    List<Object[]> expectedGT = Lists.newArrayList();\n+    expectedGT.add(new Object[] {2, \"b\"});\n+    expectedGT.add(new Object[] {3, null});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultGT.toArray(), expectedGT.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownGreaterThanLiteralOnLeft() {\n+    String sqlGT = String.format(\"SELECT * FROM %s WHERE 3 > id \", TABLE_NAME);\n+    String explainGT = getTableEnv().explainSql(sqlGT);\n+    String expectedFilter = \"ref(name=\\\"id\\\") < 3\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainGT.contains(expectedFilter));\n+\n+    List<Object[]> resultGT = sql(sqlGT);\n+    Assert.assertEquals(\"should have 2 record\", 2, resultGT.size());\n+\n+    List<Object[]> expectedGT = Lists.newArrayList();\n+    expectedGT.add(new Object[] {1, \"a\"});\n+    expectedGT.add(new Object[] {2, \"b\"});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultGT.toArray(), expectedGT.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownGreaterThanEqual() {\n+    String sqlGTE = String.format(\"SELECT * FROM %s WHERE id >= 2 \", TABLE_NAME);\n+    String explainGTE = getTableEnv().explainSql(sqlGTE);\n+    String expectedFilter = \"ref(name=\\\"id\\\") >= 2\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainGTE.contains(expectedFilter));\n+\n+    List<Object[]> resultGTE = sql(sqlGTE);\n+    Assert.assertEquals(\"should have 2 records\", 2, resultGTE.size());\n+\n+    List<Object[]> expectedGTE = Lists.newArrayList();\n+    expectedGTE.add(new Object[] {2, \"b\"});\n+    expectedGTE.add(new Object[] {3, null});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultGTE.toArray(), expectedGTE.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownGreaterThanEqualLiteralOnLeft() {\n+    String sqlGTE = String.format(\"SELECT * FROM %s WHERE 2 >= id \", TABLE_NAME);\n+    String explainGTE = getTableEnv().explainSql(sqlGTE);\n+    String expectedFilter = \"ref(name=\\\"id\\\") <= 2\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainGTE.contains(expectedFilter));\n+\n+    List<Object[]> resultGTE = sql(sqlGTE);\n+    Assert.assertEquals(\"should have 2 records\", 2, resultGTE.size());\n+\n+    List<Object[]> expectedGTE = Lists.newArrayList();\n+    expectedGTE.add(new Object[] {1, \"a\"});\n+    expectedGTE.add(new Object[] {2, \"b\"});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultGTE.toArray(), expectedGTE.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownLessThan() {\n+    String sqlLT = String.format(\"SELECT * FROM %s WHERE id < 2 \", TABLE_NAME);\n+    String explainLT = getTableEnv().explainSql(sqlLT);\n+    String expectedFilter = \"ref(name=\\\"id\\\") < 2\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainLT.contains(expectedFilter));\n+\n+    List<Object[]> resultLT = sql(sqlLT);\n+    Assert.assertEquals(\"should have 1 record\", 1, resultLT.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultLT.get(0), new Object[] {1, \"a\"});\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownLessThanLiteralOnLeft() {\n+    String sqlLT = String.format(\"SELECT * FROM %s WHERE 2 < id \", TABLE_NAME);\n+    String explainLT = getTableEnv().explainSql(sqlLT);\n+    String expectedFilter = \"ref(name=\\\"id\\\") > 2\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainLT.contains(expectedFilter));\n+\n+    List<Object[]> resultLT = sql(sqlLT);\n+    Assert.assertEquals(\"should have 1 record\", 1, resultLT.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultLT.get(0), new Object[] {3, null});\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownLessThanEqual() {\n+    String sqlLTE = String.format(\"SELECT * FROM %s WHERE id <= 1 \", TABLE_NAME);\n+    String explainLTE = getTableEnv().explainSql(sqlLTE);\n+    String expectedFilter = \"ref(name=\\\"id\\\") <= 1\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainLTE.contains(expectedFilter));\n+\n+    List<Object[]> resultLTE = sql(sqlLTE);\n+    Assert.assertEquals(\"should have 1 record\", 1, resultLTE.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultLTE.get(0), new Object[] {1, \"a\"});\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownLessThanEqualLiteralOnLeft() {\n+    String sqlLTE = String.format(\"SELECT * FROM %s WHERE 3 <= id  \", TABLE_NAME);\n+    String explainLTE = getTableEnv().explainSql(sqlLTE);\n+    String expectedFilter = \"ref(name=\\\"id\\\") >= 3\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainLTE.contains(expectedFilter));\n+\n+    List<Object[]> resultLTE = sql(sqlLTE);\n+    Assert.assertEquals(\"should have 1 record\", 1, resultLTE.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultLTE.get(0), new Object[] {3, null});\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownIn() {\n+    String sqlIN = String.format(\"SELECT * FROM %s WHERE id IN (1,2) \", TABLE_NAME);\n+    String explainIN = getTableEnv().explainSql(sqlIN);\n+    String expectedFilter = \"(ref(name=\\\"id\\\") == 1 or ref(name=\\\"id\\\") == 2)\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainIN.contains(expectedFilter));\n+    List<Object[]> resultIN = sql(sqlIN);\n+    Assert.assertEquals(\"should have 2 records\", 2, resultIN.size());\n+\n+    List<Object[]> expectedIN = Lists.newArrayList();\n+    expectedIN.add(new Object[] {1, \"a\"});\n+    expectedIN.add(new Object[] {2, \"b\"});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultIN.toArray(), expectedIN.toArray());\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+\n+    // in with null will not push down\n+    String sqlInNull = String.format(\"SELECT * FROM %s WHERE id IN (1,2,NULL) \", TABLE_NAME);\n+    String explainInNull = getTableEnv().explainSql(sqlInNull);\n+    Assert.assertFalse(\"explain should not contains FilterPushDown\",\n+        explainInNull.contains(expectedFilterPushDownExplain));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownNotIn() {\n+    String sqlNotIn = String.format(\"SELECT * FROM %s WHERE id NOT IN (3,2) \", TABLE_NAME);\n+    String explainNotIn = getTableEnv().explainSql(sqlNotIn);\n+    String expectedFilter = \"ref(name=\\\"id\\\") != 3,ref(name=\\\"id\\\") != 2\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainNotIn.contains(expectedFilter));\n+\n+    List<Object[]> resultNotIn = sql(sqlNotIn);\n+    Assert.assertEquals(\"should have 1 record\", 1, resultNotIn.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultNotIn.get(0), new Object[] {1, \"a\"});\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", \"(ref(name=\\\"id\\\") != 3 and ref(name=\\\"id\\\") != 2)\",\n+        lastScanEvent.filter().toString());\n+\n+    String sqlNotInNull = String.format(\"SELECT * FROM %s WHERE id NOT IN (1,2,NULL) \", TABLE_NAME);\n+    String explainNotInNull = getTableEnv().explainSql(sqlNotInNull);\n+    Assert.assertFalse(\"explain should not contains FilterPushDown\",\n+        explainNotInNull.contains(expectedFilterPushDownExplain));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownIsNotNull() {\n+    String sqlNotNull = String.format(\"SELECT * FROM %s WHERE data IS NOT NULL\", TABLE_NAME);\n+    String explainNotNull = getTableEnv().explainSql(sqlNotNull);\n+    String expectedFilter = \"not_null(ref(name=\\\"data\\\"))\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainNotNull.contains(expectedFilter));\n+\n+    List<Object[]> resultNotNull = sql(sqlNotNull);\n+    Assert.assertEquals(\"should have 2 record\", 2, resultNotNull.size());\n+\n+    List<Object[]> expected = Lists.newArrayList();\n+    expected.add(new Object[] {1, \"a\"});\n+    expected.add(new Object[] {2, \"b\"});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultNotNull.toArray(), expected.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownIsNull() {\n+    String sqlNull = String.format(\"SELECT * FROM %s WHERE data IS  NULL\", TABLE_NAME);\n+    String explainNull = getTableEnv().explainSql(sqlNull);\n+    String expectedFilter = \"is_null(ref(name=\\\"data\\\"))\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainNull.contains(expectedFilter));\n+\n+    List<Object[]> resultNull = sql(sqlNull);\n+    Assert.assertEquals(\"should have 1 record\", 1, resultNull.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultNull.get(0), new Object[] {3, null});\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownNot() {", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "originalPosition": 398}]}}, {"__typename": "PullRequestReview", "id": "MDE3OlB1bGxSZXF1ZXN0UmV2aWV3NTY4NDY0OTcx", "url": "https://github.com/apache/iceberg/pull/1893#pullrequestreview-568464971", "createdAt": "2021-01-14T17:31:36Z", "commit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "state": "COMMENTED", "comments": {"totalCount": 1, "pageInfo": {"startCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzozMTozNlrOITvVuA==", "endCursor": "Y3Vyc29yOnYyOpK0MjAyMS0wMS0xNFQxNzozMTozNlrOITvVuA==", "hasNextPage": false, "hasPreviousPage": false}, "nodes": [{"id": "MDI0OlB1bGxSZXF1ZXN0UmV2aWV3Q29tbWVudDU1NzU2OTQ2NA==", "bodyText": "@zhangjun0x01, I think this suite also needs to test the behavior of a few more cases to ensure that the assumptions about Flink's parser hold. Even if these result in parser errors, those are good tests to have to validate that if Flink ever does support parsing the expressions, Iceberg will do the right thing.\n\ndouble_col = NaN\ndouble_col <> NaN\nAll inequalities with NaN, like double_col < NaN\nAll inequalities with null, like data < null", "url": "https://github.com/apache/iceberg/pull/1893#discussion_r557569464", "createdAt": "2021-01-14T17:31:36Z", "author": {"login": "rdblue"}, "path": "flink/src/test/java/org/apache/iceberg/flink/TestFlinkTableSource.java", "diffHunk": "@@ -90,17 +103,418 @@ public void testLimitPushDown() {\n \n     Assert.assertEquals(\"should have 0 record\", 0, sql(\"SELECT * FROM %s LIMIT 0\", TABLE_NAME).size());\n \n-    String sqlLimitExceed = String.format(\"SELECT * FROM %s LIMIT 3\", TABLE_NAME);\n+    String sqlLimitExceed = String.format(\"SELECT * FROM %s LIMIT 4\", TABLE_NAME);\n     List<Object[]> resultExceed = sql(sqlLimitExceed);\n-    Assert.assertEquals(\"should have 2 record\", 2, resultExceed.size());\n+    Assert.assertEquals(\"should have 3 record\", 3, resultExceed.size());\n     List<Object[]> expectedList = Lists.newArrayList();\n     expectedList.add(new Object[] {1, \"a\"});\n     expectedList.add(new Object[] {2, \"b\"});\n+    expectedList.add(new Object[] {3, null});\n     Assert.assertArrayEquals(\"Should produce the expected records\", resultExceed.toArray(), expectedList.toArray());\n \n     String sqlMixed = String.format(\"SELECT * FROM %s WHERE id = 1 LIMIT 2\", TABLE_NAME);\n     List<Object[]> mixedResult = sql(sqlMixed);\n     Assert.assertEquals(\"should have 1 record\", 1, mixedResult.size());\n     Assert.assertArrayEquals(\"Should produce the expected records\", mixedResult.get(0), new Object[] {1, \"a\"});\n   }\n+\n+  @Test\n+  public void testNoFilterPushDown() {\n+    String sql = String.format(\"SELECT * FROM %s \", TABLE_NAME);\n+    String explain = getTableEnv().explainSql(sql);\n+    Assert.assertFalse(\"explain should no contains FilterPushDown\", explain.contains(expectedFilterPushDownExplain));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownEqual() {\n+    String sqlLiteralRight = String.format(\"SELECT * FROM %s WHERE id = 1 \", TABLE_NAME);\n+    String explain = getTableEnv().explainSql(sqlLiteralRight);\n+    String expectedFilter = \"ref(name=\\\"id\\\") == 1\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explain.contains(expectedFilter));\n+\n+    List<Object[]> result = sql(sqlLiteralRight);\n+    Assert.assertEquals(\"should have 1 record\", 1, result.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", result.get(0), new Object[] {1, \"a\"});\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+\n+    // filter not push down\n+    String sqlEqualNull = String.format(\"SELECT * FROM %s WHERE data = NULL \", TABLE_NAME);\n+    String explainEqualNull = getTableEnv().explainSql(sqlEqualNull);\n+    Assert.assertFalse(\"explain should not contains FilterPushDown\",\n+        explainEqualNull.contains(expectedFilterPushDownExplain));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownEqualLiteralOnLeft() {\n+    String sqlLiteralLeft = String.format(\"SELECT * FROM %s WHERE 1 = id \", TABLE_NAME);\n+    String explainLeft = getTableEnv().explainSql(sqlLiteralLeft);\n+    String expectedFilter = \"ref(name=\\\"id\\\") == 1\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainLeft.contains(expectedFilter));\n+\n+    List<Object[]> resultLeft = sql(sqlLiteralLeft);\n+    Assert.assertEquals(\"should have 1 record\", 1, resultLeft.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultLeft.get(0), new Object[] {1, \"a\"});\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownNoEqual() {\n+    String sqlNE = String.format(\"SELECT * FROM %s WHERE id <> 1 \", TABLE_NAME);\n+    String explainNE = getTableEnv().explainSql(sqlNE);\n+    String expectedFilter = \"ref(name=\\\"id\\\") != 1\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainNE.contains(expectedFilter));\n+\n+    List<Object[]> resultNE = sql(sqlNE);\n+    Assert.assertEquals(\"should have 2 record\", 2, resultNE.size());\n+\n+    List<Object[]> expectedNE = Lists.newArrayList();\n+    expectedNE.add(new Object[] {2, \"b\"});\n+    expectedNE.add(new Object[] {3, null});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultNE.toArray(), expectedNE.toArray());\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+\n+    String sqlNotEqualNull = String.format(\"SELECT * FROM %s WHERE data <> NULL \", TABLE_NAME);\n+    String explainNotEqualNull = getTableEnv().explainSql(sqlNotEqualNull);\n+    Assert.assertFalse(\"explain should not contains FilterPushDown\", explainNotEqualNull.contains(\n+        expectedFilterPushDownExplain));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownAnd() {\n+    String sqlAnd = String.format(\"SELECT * FROM %s WHERE id = 1 AND data = 'a' \", TABLE_NAME);\n+    String explainAnd = getTableEnv().explainSql(sqlAnd);\n+    String expectedFilter = \"ref(name=\\\"id\\\") == 1,ref(name=\\\"data\\\") == \\\"a\\\"\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainAnd.contains(expectedFilter));\n+\n+    List<Object[]> resultAnd = sql(sqlAnd);\n+    Assert.assertEquals(\"should have 1 record\", 1, resultAnd.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultAnd.get(0), new Object[] {1, \"a\"});\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert\n+        .assertEquals(\"should contains the push down filter\", \"(ref(name=\\\"id\\\") == 1 and ref(name=\\\"data\\\") == \\\"a\\\")\",\n+            lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownOr() {\n+    String sqlOr = String.format(\"SELECT * FROM %s WHERE id = 1 OR data = 'b' \", TABLE_NAME);\n+    String explainOr = getTableEnv().explainSql(sqlOr);\n+    String expectedFilter = \"(ref(name=\\\"id\\\") == 1 or ref(name=\\\"data\\\") == \\\"b\\\")\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainOr.contains(expectedFilter));\n+\n+    List<Object[]> resultOr = sql(sqlOr);\n+    Assert.assertEquals(\"should have 2 record\", 2, resultOr.size());\n+\n+    List<Object[]> expectedOR = Lists.newArrayList();\n+    expectedOR.add(new Object[] {1, \"a\"});\n+    expectedOR.add(new Object[] {2, \"b\"});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultOr.toArray(), expectedOR.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownGreaterThan() {\n+    String sqlGT = String.format(\"SELECT * FROM %s WHERE id > 1 \", TABLE_NAME);\n+    String explainGT = getTableEnv().explainSql(sqlGT);\n+    String expectedFilter = \"ref(name=\\\"id\\\") > 1\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainGT.contains(expectedFilter));\n+\n+    List<Object[]> resultGT = sql(sqlGT);\n+    Assert.assertEquals(\"should have 2 record\", 2, resultGT.size());\n+\n+    List<Object[]> expectedGT = Lists.newArrayList();\n+    expectedGT.add(new Object[] {2, \"b\"});\n+    expectedGT.add(new Object[] {3, null});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultGT.toArray(), expectedGT.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownGreaterThanLiteralOnLeft() {\n+    String sqlGT = String.format(\"SELECT * FROM %s WHERE 3 > id \", TABLE_NAME);\n+    String explainGT = getTableEnv().explainSql(sqlGT);\n+    String expectedFilter = \"ref(name=\\\"id\\\") < 3\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainGT.contains(expectedFilter));\n+\n+    List<Object[]> resultGT = sql(sqlGT);\n+    Assert.assertEquals(\"should have 2 record\", 2, resultGT.size());\n+\n+    List<Object[]> expectedGT = Lists.newArrayList();\n+    expectedGT.add(new Object[] {1, \"a\"});\n+    expectedGT.add(new Object[] {2, \"b\"});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultGT.toArray(), expectedGT.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownGreaterThanEqual() {\n+    String sqlGTE = String.format(\"SELECT * FROM %s WHERE id >= 2 \", TABLE_NAME);\n+    String explainGTE = getTableEnv().explainSql(sqlGTE);\n+    String expectedFilter = \"ref(name=\\\"id\\\") >= 2\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainGTE.contains(expectedFilter));\n+\n+    List<Object[]> resultGTE = sql(sqlGTE);\n+    Assert.assertEquals(\"should have 2 records\", 2, resultGTE.size());\n+\n+    List<Object[]> expectedGTE = Lists.newArrayList();\n+    expectedGTE.add(new Object[] {2, \"b\"});\n+    expectedGTE.add(new Object[] {3, null});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultGTE.toArray(), expectedGTE.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownGreaterThanEqualLiteralOnLeft() {\n+    String sqlGTE = String.format(\"SELECT * FROM %s WHERE 2 >= id \", TABLE_NAME);\n+    String explainGTE = getTableEnv().explainSql(sqlGTE);\n+    String expectedFilter = \"ref(name=\\\"id\\\") <= 2\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainGTE.contains(expectedFilter));\n+\n+    List<Object[]> resultGTE = sql(sqlGTE);\n+    Assert.assertEquals(\"should have 2 records\", 2, resultGTE.size());\n+\n+    List<Object[]> expectedGTE = Lists.newArrayList();\n+    expectedGTE.add(new Object[] {1, \"a\"});\n+    expectedGTE.add(new Object[] {2, \"b\"});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultGTE.toArray(), expectedGTE.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownLessThan() {\n+    String sqlLT = String.format(\"SELECT * FROM %s WHERE id < 2 \", TABLE_NAME);\n+    String explainLT = getTableEnv().explainSql(sqlLT);\n+    String expectedFilter = \"ref(name=\\\"id\\\") < 2\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainLT.contains(expectedFilter));\n+\n+    List<Object[]> resultLT = sql(sqlLT);\n+    Assert.assertEquals(\"should have 1 record\", 1, resultLT.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultLT.get(0), new Object[] {1, \"a\"});\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownLessThanLiteralOnLeft() {\n+    String sqlLT = String.format(\"SELECT * FROM %s WHERE 2 < id \", TABLE_NAME);\n+    String explainLT = getTableEnv().explainSql(sqlLT);\n+    String expectedFilter = \"ref(name=\\\"id\\\") > 2\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainLT.contains(expectedFilter));\n+\n+    List<Object[]> resultLT = sql(sqlLT);\n+    Assert.assertEquals(\"should have 1 record\", 1, resultLT.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultLT.get(0), new Object[] {3, null});\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownLessThanEqual() {\n+    String sqlLTE = String.format(\"SELECT * FROM %s WHERE id <= 1 \", TABLE_NAME);\n+    String explainLTE = getTableEnv().explainSql(sqlLTE);\n+    String expectedFilter = \"ref(name=\\\"id\\\") <= 1\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainLTE.contains(expectedFilter));\n+\n+    List<Object[]> resultLTE = sql(sqlLTE);\n+    Assert.assertEquals(\"should have 1 record\", 1, resultLTE.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultLTE.get(0), new Object[] {1, \"a\"});\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownLessThanEqualLiteralOnLeft() {\n+    String sqlLTE = String.format(\"SELECT * FROM %s WHERE 3 <= id  \", TABLE_NAME);\n+    String explainLTE = getTableEnv().explainSql(sqlLTE);\n+    String expectedFilter = \"ref(name=\\\"id\\\") >= 3\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainLTE.contains(expectedFilter));\n+\n+    List<Object[]> resultLTE = sql(sqlLTE);\n+    Assert.assertEquals(\"should have 1 record\", 1, resultLTE.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultLTE.get(0), new Object[] {3, null});\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownIn() {\n+    String sqlIN = String.format(\"SELECT * FROM %s WHERE id IN (1,2) \", TABLE_NAME);\n+    String explainIN = getTableEnv().explainSql(sqlIN);\n+    String expectedFilter = \"(ref(name=\\\"id\\\") == 1 or ref(name=\\\"id\\\") == 2)\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainIN.contains(expectedFilter));\n+    List<Object[]> resultIN = sql(sqlIN);\n+    Assert.assertEquals(\"should have 2 records\", 2, resultIN.size());\n+\n+    List<Object[]> expectedIN = Lists.newArrayList();\n+    expectedIN.add(new Object[] {1, \"a\"});\n+    expectedIN.add(new Object[] {2, \"b\"});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultIN.toArray(), expectedIN.toArray());\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+\n+    // in with null will not push down\n+    String sqlInNull = String.format(\"SELECT * FROM %s WHERE id IN (1,2,NULL) \", TABLE_NAME);\n+    String explainInNull = getTableEnv().explainSql(sqlInNull);\n+    Assert.assertFalse(\"explain should not contains FilterPushDown\",\n+        explainInNull.contains(expectedFilterPushDownExplain));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownNotIn() {\n+    String sqlNotIn = String.format(\"SELECT * FROM %s WHERE id NOT IN (3,2) \", TABLE_NAME);\n+    String explainNotIn = getTableEnv().explainSql(sqlNotIn);\n+    String expectedFilter = \"ref(name=\\\"id\\\") != 3,ref(name=\\\"id\\\") != 2\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainNotIn.contains(expectedFilter));\n+\n+    List<Object[]> resultNotIn = sql(sqlNotIn);\n+    Assert.assertEquals(\"should have 1 record\", 1, resultNotIn.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultNotIn.get(0), new Object[] {1, \"a\"});\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", \"(ref(name=\\\"id\\\") != 3 and ref(name=\\\"id\\\") != 2)\",\n+        lastScanEvent.filter().toString());\n+\n+    String sqlNotInNull = String.format(\"SELECT * FROM %s WHERE id NOT IN (1,2,NULL) \", TABLE_NAME);\n+    String explainNotInNull = getTableEnv().explainSql(sqlNotInNull);\n+    Assert.assertFalse(\"explain should not contains FilterPushDown\",\n+        explainNotInNull.contains(expectedFilterPushDownExplain));\n+  }\n+\n+  @Test\n+  public void testFilterPushDownIsNotNull() {\n+    String sqlNotNull = String.format(\"SELECT * FROM %s WHERE data IS NOT NULL\", TABLE_NAME);\n+    String explainNotNull = getTableEnv().explainSql(sqlNotNull);\n+    String expectedFilter = \"not_null(ref(name=\\\"data\\\"))\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainNotNull.contains(expectedFilter));\n+\n+    List<Object[]> resultNotNull = sql(sqlNotNull);\n+    Assert.assertEquals(\"should have 2 record\", 2, resultNotNull.size());\n+\n+    List<Object[]> expected = Lists.newArrayList();\n+    expected.add(new Object[] {1, \"a\"});\n+    expected.add(new Object[] {2, \"b\"});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultNotNull.toArray(), expected.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownIsNull() {\n+    String sqlNull = String.format(\"SELECT * FROM %s WHERE data IS  NULL\", TABLE_NAME);\n+    String explainNull = getTableEnv().explainSql(sqlNull);\n+    String expectedFilter = \"is_null(ref(name=\\\"data\\\"))\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainNull.contains(expectedFilter));\n+\n+    List<Object[]> resultNull = sql(sqlNull);\n+    Assert.assertEquals(\"should have 1 record\", 1, resultNull.size());\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultNull.get(0), new Object[] {3, null});\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownNot() {\n+    String sqlNot = String.format(\"SELECT * FROM %s WHERE NOT id = 1 \", TABLE_NAME);\n+    String explainNot = getTableEnv().explainSql(sqlNot);\n+    String expectedFilter = \"ref(name=\\\"id\\\") != 1\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainNot.contains(expectedFilter));\n+\n+    List<Object[]> resultNot = sql(sqlNot);\n+    Assert.assertEquals(\"should have 2 record\", 2, resultNot.size());\n+\n+    List<Object[]> expectedNot = Lists.newArrayList();\n+    expectedNot.add(new Object[] {2, \"b\"});\n+    expectedNot.add(new Object[] {3, null});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultNot.toArray(), expectedNot.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownBetween() {\n+    String sqlBetween = String.format(\"SELECT * FROM %s WHERE id BETWEEN 1 AND 2 \", TABLE_NAME);\n+    String explainBetween = getTableEnv().explainSql(sqlBetween);\n+    String expectedFilter = \"ref(name=\\\"id\\\") >= 1,ref(name=\\\"id\\\") <= 2\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainBetween.contains(expectedFilter));\n+\n+    List<Object[]> resultBetween = sql(sqlBetween);\n+    Assert.assertEquals(\"should have 2 record\", 2, resultBetween.size());\n+\n+    List<Object[]> expectedBetween = Lists.newArrayList();\n+    expectedBetween.add(new Object[] {1, \"a\"});\n+    expectedBetween.add(new Object[] {2, \"b\"});\n+    Assert.assertArrayEquals(\"Should produce the expected record\", resultBetween.toArray(), expectedBetween.toArray());\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", \"(ref(name=\\\"id\\\") >= 1 and ref(name=\\\"id\\\") <= 2)\",\n+        lastScanEvent.filter().toString());\n+  }\n+\n+  @Test\n+  public void testFilterPushDownNotBetween() {\n+    String sqlNotBetween = String.format(\"SELECT * FROM %s WHERE id  NOT BETWEEN 2 AND 3 \", TABLE_NAME);\n+    String explainNotBetween = getTableEnv().explainSql(sqlNotBetween);\n+    String expectedFilter = \"(ref(name=\\\"id\\\") < 2 or ref(name=\\\"id\\\") > 3)\";\n+    Assert.assertTrue(\"explain should contains the push down filter\", explainNotBetween.contains(expectedFilter));\n+\n+    List<Object[]> resultNotBetween = sql(sqlNotBetween);\n+    Assert.assertEquals(\"should have 1 record\", 1, resultNotBetween.size());\n+    Assert.assertArrayEquals(\"the not between should produce the expected record\", resultNotBetween.get(0),\n+        new Object[] {1, \"a\"});\n+\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+  }\n+\n+  @Test\n+  public void testFilterPushDownLike() {\n+    String sqlLike = \"SELECT * FROM \" + TABLE_NAME + \" WHERE data LIKE 'a%' \";\n+    String explainLike = getTableEnv().explainSql(sqlLike);\n+    String expectedFilter = \"ref(name=\\\"data\\\") startsWith \\\"\\\"a\\\"\\\"\";\n+    Assert\n+        .assertTrue(\"the like sql explain should contains the push down filter\", explainLike.contains(expectedFilter));\n+\n+    List<Object[]> resultLike = sql(sqlLike);\n+    Assert.assertEquals(\"should have 1 record\", 1, resultLike.size());\n+    Assert.assertArrayEquals(\"the like result should produce the expected record\", resultLike.get(0),\n+        new Object[] {1, \"a\"});\n+    Assert.assertEquals(\"Should create only one scan\", 1, scanEventCount);\n+    Assert.assertEquals(\"should contains the push down filter\", lastScanEvent.filter().toString(), expectedFilter);\n+\n+    // not push down\n+    String sqlNoPushDown = \"SELECT * FROM \" + TABLE_NAME + \" WHERE data LIKE '%a%' \";\n+    String explainNoPushDown = getTableEnv().explainSql(sqlNoPushDown);\n+    Assert.assertFalse(\"explain should not contains FilterPushDown\",\n+        explainNoPushDown.contains(expectedFilterPushDownExplain));\n+  }\n+\n+  @Test\n+  public void testFilterPushDown2Literal() {\n+    String sql2Literal = String.format(\"SELECT * FROM %s WHERE 1 > 0 \", TABLE_NAME);\n+    String explain2Literal = getTableEnv().explainSql(sql2Literal);\n+    Assert.assertFalse(\"explain should not contains FilterPushDown\",\n+        explain2Literal.contains(expectedFilterPushDownExplain));\n+  }", "state": "SUBMITTED", "replyTo": null, "originalCommit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027"}, "originalPosition": 480}]}}, {"__typename": "HeadRefForcePushedEvent", "beforeCommit": {"oid": "9417e9d241b873918dcbdfb4e8c17c5b30aed027", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/9417e9d241b873918dcbdfb4e8c17c5b30aed027", "committedDate": "2021-01-14T07:36:41Z", "message": "fix some issues"}, "afterCommit": {"oid": "edad5ee6f8c8e458de5c3a497876b6bf37d800e5", "author": {"user": null}, "url": "https://github.com/apache/iceberg/commit/edad5ee6f8c8e458de5c3a497876b6bf37d800e5", "committedDate": "2021-01-16T11:12:34Z", "message": "fix some issues, and add some test case"}}]}}}, "rateLimit": {"limit": 5000, "remaining": 3558, "cost": 1, "resetAt": "2021-10-29T19:57:52Z"}}}